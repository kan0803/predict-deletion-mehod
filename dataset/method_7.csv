status,method,filepath,class_name
survived,"def test_positional_only_compatibility():
    old_code = ""def func(a, /): pass""
    new_code = ""def func(b, /): pass""

    old_tree = ast.parse(old_code)
    new_tree = ast.parse(new_code)
    errors = check_signature_compatibility(old_tree.body[0], new_tree.body[0])

    assert len(errors) == 1
    assert ""Positional param order/name changed: 'a' -> 'b'."" in errors[0].message
",tests/dev/test_check_function_signatures.py,
survived,"def test_no_changes():
    old_code = ""def func(a, b=1): pass""
    new_code = ""def func(a, b=1): pass""

    old_tree = ast.parse(old_code)
    new_tree = ast.parse(new_code)
    errors = check_signature_compatibility(old_tree.body[0], new_tree.body[0])

    assert len(errors) == 0
",tests/dev/test_check_function_signatures.py,
survived,"    def format(self, github: bool = False) -> str:
        message = "" "".join(self.lines)
        if github:
            return f""::warning file={self.file_path},line={self.line},col={self.column}::{message}""
        else:
            return f""{self.file_path}:{self.line}:{self.column}: {message}""
",dev/check_function_signatures.py,Error
survived,"def test_move_matrix_pandas_min_count_simple(func_name, window, min_count):
    """"""Test matrix functions against pandas with different min_count values.""""""
    # Create test array directly
    rs = np.random.RandomState(0)
    array = rs.rand(4, 15)

    # Get the function
    func = (
        move_nancorrmatrix if func_name == ""move_nancorrmatrix"" else move_nancovmatrix
    )

    # Get comparisons
    c = COMPARISONS[func]

    # Get numbagg result
    result = c[""numbagg""](array, window=window, min_count=min_count)()

    # Get pandas result and convert to our format
    pandas_callable = c[""pandas""](array, window=window, min_count=min_count)
    pandas_result = pandas_callable()

    # Convert pandas MultiIndex DataFrame to 3D array
    n_obs = array.shape[-1]
    n_vars = array.shape[-2]
    expected_pandas = np.full((n_obs, n_vars, n_vars), np.nan)

    for t in range(n_obs):
        if t in pandas_result.index.get_level_values(0):
            expected_pandas[t] = pandas_result.loc[t].values

    assert_allclose(result, expected_pandas)
",numbagg/test/test_moving.py,
survived,"    def gufunc(self, *, target):
        vectorize = numba.guvectorize(
            *self.signature,
            nopython=True,
            target=target,
            cache=self.cache,
            fastmath=_FASTMATH,
        )
        return vectorize(self.func)
",numbagg/decorators.py,ndmovematrix
survived,"    def test_correlation_covariance_relationship(self):
        """"""Test relationship between correlation and covariance.""""""
        np.random.seed(42)
        data = np.random.randn(4, 50)

        cov_matrix = nancovmatrix(data)
        corr_matrix = nancorrmatrix(data)

        # Correlation = Covariance / (std_i * std_j)
        stds = np.sqrt(np.diag(cov_matrix))
        expected_corr = cov_matrix / np.outer(stds, stds)

        assert_allclose(corr_matrix, expected_corr, rtol=1e-10)
",numbagg/test/test_matrix_functions.py,TestMatrixFunctions
survived,"    def test_positive_semidefinite_covariance(self):
        """"""Test that covariance matrices are positive semi-definite.""""""
        np.random.seed(42)
        data = np.random.randn(4, 50)

        result = move_exp_nancovmatrix(data, alpha=0.3)

        # Check that all finite covariance matrices are positive semi-definite
        for t in range(result.shape[0]):
            cov_matrix = result[t]
            if not np.any(np.isnan(cov_matrix)):
                # Compute eigenvalues
                eigenvals = np.linalg.eigvals(cov_matrix)
                # All eigenvalues should be non-negative (allowing small numerical errors)
                assert np.all(eigenvals >= -1e-10), (
                    f""Negative eigenvalue found at time {t}: {eigenvals.min()}""
                )
",numbagg/test/test_move_exp_matrix_advanced.py,TestMoveExpMatrixAdvanced
survived,"    def __call__(
        self,
        a: np.ndarray,
        alpha: float | np.ndarray,
        min_weight: float = 0,
        axis: int = -1,
        **kwargs,
    ):
        a = np.asarray(a)

        if a.ndim < 2:
            raise ValueError(f""{self.func.__name__} requires at least a 2D array."")

        # Move the axis to the last position for the gufunc
        a = np.moveaxis(a, axis, -1)

        # Handle alpha parameter similar to ndmoveexp
        if not isinstance(alpha, np.ndarray):
            alpha = np.broadcast_to(alpha, a.shape[-1])  # type: ignore[assignment,unused-ignore]

        gufunc = self.gufunc(target=self.target)
        with np.errstate(invalid=""ignore"", divide=""ignore""):
            return gufunc(a, alpha, min_weight, **kwargs)
",numbagg/decorators.py,ndmoveexpmatrix
survived,"    def test_all_nan_input(self):
        """"""Test behavior with all-NaN input.""""""
        data = np.full((2, 4), np.nan, dtype=np.float64)

        result_corr = move_exp_nancorrmatrix(data, alpha=0.5)
        result_cov = move_exp_nancovmatrix(data, alpha=0.5)

        # All results should be NaN
        assert np.all(np.isnan(result_corr))
        assert np.all(np.isnan(result_cov))
",numbagg/test/test_move_exp_matrix.py,TestMoveExpMatrixFunctions
survived,"    def test_correlation_consistency(self, alpha):
        """"""Test that move_exp_nancorrmatrix matches move_exp_nancorr for pairs.""""""
        np.random.seed(123)

        # Create two time series
        n_obs = 50
        a1 = np.random.randn(n_obs)
        a2 = np.random.randn(n_obs) * 1.5 + 0.5

        # Compute using non-matrix function
        corr_nonmatrix = move_exp_nancorr(a1, a2, alpha=alpha)

        # Compute using matrix function
        data_matrix = np.array([a1, a2])
        corr_matrix_result = move_exp_nancorrmatrix(data_matrix, alpha=alpha)

        # Extract the off-diagonal element (correlation between a1 and a2)
        corr_from_matrix = corr_matrix_result[:, 0, 1]

        # They should match
        assert_allclose(corr_nonmatrix, corr_from_matrix, rtol=1e-10)

        # Also check symmetry - (0,1) should equal (1,0)
        assert_allclose(
            corr_matrix_result[:, 0, 1], corr_matrix_result[:, 1, 0], rtol=1e-10
        )
",numbagg/test/test_move_exp_matrix_consistency.py,TestMoveExpMatrixConsistency
survived,"    def _generate_integration_guide(self, model_info: Dict[str, Any]) -> str:
        """"""Generate an integration guide""""""
        lines = [
            f""# Integration Guide: {model_info['name']}"",
            f""\nGenerated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"",
            ""\n## Overview"",
            f""\nThis guide helps you integrate {model_info['name']} into your application.""
        ]
        
        # Integration approaches
        lines.extend([
            ""\n## Integration Approaches"",
            ""\n### 1. Direct Integration"",
            ""```python"",
            ""# Direct model loading and inference"",
            ""from your_framework import load_model"",
            """",
            ""model = load_model('path/to/model')"",
            ""result = model.predict(input_data)"",
            ""```"",
            ""\n### 2. API Integration"",
            ""```python"",
            ""# REST API integration"",
            ""import requests"",
            """",
            ""response = requests.post("",
            ""    'http://your-api-endpoint/predict',"",
            ""    json={'input': input_data}"",
            "")"",
            ""result = response.json()"",
            ""```"",
            ""\n### 3. Microservice Architecture"",
            ""```yaml"",
            ""# Docker Compose example"",
            ""version: '3.8'"",
            ""services:"",
            ""  model-service:"",
            ""    image: your-model-image"",
            ""    ports:"",
            ""      - '8080:8080'"",
            ""    environment:"",
            ""      - MODEL_PATH=/models/your-model"",
            ""```""
        ])
        
        # Requirements for integration
        lines.extend([
            ""\n## System Requirements"",
            ""\n### Hardware Requirements"",
            ""- CPU: Multi-core processor recommended"",
            ""- RAM: Depends on model size"",
            ""- GPU: Optional but recommended for large models"",
            ""\n### Software Requirements""
        ])
        
        if model_info['requirements']:
            for req_file in model_info['requirements']:
                if req_file.get('content'):
                    lines.append(f""\nFrom `{req_file['name']}`:"")
                    lines.append(""```"")
                    lines.append(req_file['content'][:200])
                    lines.append(""```"")
        
        # Configuration
        lines.extend([
            ""\n## Configuration"",
            ""\n### Environment Variables"",
            ""```bash"",
            ""export MODEL_PATH=/path/to/model"",
            ""export MODEL_CONFIG=/path/to/config.json"",
            ""export DEVICE=cuda  # or cpu"",
            ""```""
        ])
        
        # Deployment options
        lines.extend([
            ""\n## Deployment Options"",
            ""\n### 1. Cloud Deployment"",
            ""- AWS SageMaker"",
            ""- Google Cloud AI Platform"",
            ""- Azure Machine Learning"",
            ""\n### 2. Edge Deployment"",
            ""- Mobile devices (TensorFlow Lite, Core ML)"",
            ""- IoT devices"",
            ""- Browser (WebAssembly, TensorFlow.js)"",
            ""\n### 3. On-Premise"",
            ""- Kubernetes cluster"",
            ""- Docker containers"",
            ""- Bare metal servers""
        ])
        
        # Monitoring
        lines.extend([
            ""\n## Monitoring and Maintenance"",
            ""\n### Key Metrics to Monitor"",
            ""- Inference latency"",
            ""- Throughput (requests/second)"",
            ""- Resource utilization (CPU, GPU, Memory)"",
            ""- Error rates"",
            ""\n### Logging"",
            ""```python"",
            ""import logging"",
            """",
            ""logging.basicConfig(level=logging.INFO)"",
            ""logger = logging.getLogger(__name__)"",
            """",
            ""# Log model predictions"",
            ""logger.info(f'Prediction: {result}, Latency: {latency}ms')"",
            ""```""
        ])
        
        return ""\n"".join(lines)
",src/haconiwa/scan/guide_generator.py,GuideGenerator
survived,"    def runner(self):
        """"""Create a CLI runner""""""
        return CliRunner()
",tests/test_scan/test_cli.py,TestScanCLI
survived,"    def test_list_models_with_filters(self, temp_model_dir):
        """"""Test listing models with category and provider filters""""""
        scanner = ModelScanner(temp_model_dir)
        
        # Filter by provider
        openai_models = scanner.list_all_models(provider=""openai"")
        assert all(m['provider'] == 'openai' for m in openai_models)
        
        # Filter by category
        llm_models = scanner.list_all_models(category=""llm"")
        assert all('llm' in m['category'] for m in llm_models)
",tests/test_scan/test_scanner.py,TestModelScanner
survived,"    def _get_action_prompt(self, action: str) -> str:
        """"""Get general action prompt""""""
        if action in self.task_templates:
            return self.task_templates[action]
        
        # Default prompt
        return f""Perform {action} on this file following best practices""
",src/haconiwa/scan/generate_parallel.py,ParallelYAMLGenerator
survived,"    def _generate_insights(self, analysis: Dict[str, Any]) -> List[str]:
        """"""Generate insights from analysis""""""
        insights = []
        
        # Model count insight
        if analysis['total_models'] > 0:
            insights.append(f""Found {analysis['total_models']} models across {len(analysis['categories'])} categories"")
        
        # Size insight
        if analysis['total_size'] > 0:
            size_gb = analysis['total_size'] / (1024 ** 3)
            insights.append(f""Total model storage: {size_gb:.2f} GB"")
        
        # Format insights
        if analysis['model_formats']:
            most_common = max(analysis['model_formats'].items(), key=lambda x: x[1])
            insights.append(f""Most common format: {most_common[0]} ({most_common[1]} models)"")
        
        # Provider insights
        if analysis['providers']:
            provider_count = len(analysis['providers'])
            insights.append(f""Models from {provider_count} different providers"")
        
        # Category distribution
        if analysis['categories']:
            largest_category = max(analysis['categories'].items(), key=lambda x: len(x[1]))
            insights.append(f""Largest category: {largest_category[0]} with {len(largest_category[1])} models"")
        
        return insights",src/haconiwa/scan/analyzer.py,ModelAnalyzer
survived,"    def analyze_category(self, category: str) -> Dict[str, Any]:
        """"""Analyze models in a specific category""""""
        analysis = {
            'category': category,
            'models': [],
            'total_count': 0,
            'total_size': 0,
            'common_formats': defaultdict(int),
            'providers': defaultdict(int)
        }
        
        all_analysis = self.analyze_all()
        
        if category in all_analysis['categories']:
            models = all_analysis['categories'][category]
            analysis['models'] = models
            analysis['total_count'] = len(models)
            
            for model in models:
                analysis['total_size'] += model.get('size', 0)
                analysis['providers'][model.get('provider', 'unknown')] += 1
                
                for fmt in model.get('formats', []):
                    analysis['common_formats'][fmt] += 1
        
        # Convert defaultdicts
        analysis['common_formats'] = dict(analysis['common_formats'])
        analysis['providers'] = dict(analysis['providers'])
        
        return analysis
",src/haconiwa/scan/analyzer.py,ModelAnalyzer
survived,"    def test_file_info_with_content(self, temp_model_dir):
        """"""Test getting file info with content""""""
        scanner = ModelScanner(temp_model_dir)
        
        results = scanner.search_by_model_name(""gpt-4"", include_content=True)
        
        # Find the example.py file in results
        example_file = None
        for files in results['matches'].values():
            for f in files:
                if f['name'] == 'example.py':
                    example_file = f
                    break
        
        assert example_file is not None
        assert 'content' in example_file
        assert 'import openai' in example_file['content']
",tests/test_scan/test_scanner.py,TestModelScanner
survived,"    def compare(self, models: List[str], aspects: List[str]) -> Dict[str, Any]:
        """"""Compare multiple models across specified aspects""""""
        comparison = {
            'models': models,
            'timestamp': self._get_timestamp(),
            'results': {}
        }
        
        # Load model information
        model_data = {}
        for model in models:
            model_info = self._load_model_info(model)
            if model_info:
                model_data[model] = model_info
        
        # Compare across requested aspects
        for aspect in aspects:
            if aspect in self.aspects:
                comparison['results'][aspect] = self.aspects[aspect](model_data)
        
        return comparison['results']
",src/haconiwa/scan/comparator.py,ModelComparator
survived,"    def _format_size(self, size: int) -> str:
        """"""Format file size in human-readable format""""""
        for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
            if size < 1024.0:
                return f""{size:.1f} {unit}""
            size /= 1024.0
        return f""{size:.1f} PB""",src/haconiwa/scan/formatter.py,OutputFormatter
survived,"    def test_scan_model_command(self, runner, temp_model_dir):
        """"""Test the scan model command""""""
        result = runner.invoke(
            scan_app,
            [""model"", ""o1-mini"", ""--path"", str(temp_model_dir), ""--format"", ""json""]
        )
        
        assert result.exit_code == 0
        output = json.loads(result.stdout)
        assert output['model_name'] == ""o1-mini""
        assert output['total_files'] > 0
",tests/test_scan/test_cli.py,TestScanCLI
survived,"    def _generate_prompt_for_file(self, 
                                file_path: str, 
                                action: str,
                                custom_prompts: Optional[Dict[str, str]] = None) -> str:
        """"""Generate appropriate prompt based on file type and action""""""
        
        # Check custom prompts first
        if custom_prompts and file_path in custom_prompts:
            return custom_prompts[file_path]
        
        # Determine file category
        file_path_lower = file_path.lower()
        
        if 'model' in file_path_lower:
            category = 'model'
        elif 'api' in file_path_lower or 'route' in file_path_lower:
            category = 'api'
        elif 'util' in file_path_lower or 'helper' in file_path_lower:
            category = 'utils'
        elif 'config' in file_path_lower or 'setting' in file_path_lower:
            category = 'config'
        elif 'service' in file_path_lower:
            category = 'service'
        else:
            # Default based on action
            return self._get_action_prompt(action)
        
        # Get category-specific prompt
        if category in self.default_prompts and action in self.default_prompts[category]:
            return self.default_prompts[category][action]
        
        # Fallback to general action prompt
        return self._get_action_prompt(action)
",src/haconiwa/scan/generate_parallel.py,ParallelYAMLGenerator
deleted,"        def process_functions(func_df, target_ndim, source_df=None):
            """"""Process a subset of functions with target dimensionality.""""""
            if source_df is None:
                source_df = func_df

            filtered = func_df[lambda x: x[""ndim""] == target_ndim]
            if filtered.empty:
                return None

            # Use largest array shape for performance comparison
            shape = filtered.sort_values(by=""size"")[""shape""].iloc[-1]
            return (
                source_df.query(f""shape == '{shape}'"")
                .reset_index()
                .set_index([""func"", ""shape""])
                .unstack(""shape"")  # Pivot: functions as rows, shapes as columns
                .pipe(
                    lambda x: x[
                        [
                            c
                            for c in x.columns
                            if c[0].endswith(""ratio"") and c[0] not in [""numbagg_ratio""]
                        ]
                    ]
                )
            )
",numbagg/test/run_benchmarks.py,
survived,"    def test_consistency_with_pairwise_functions(self, alpha):
        """"""Test that matrix functions match non-matrix functions for pairwise cases.""""""
        np.random.seed(42)

        # Create two time series
        n_obs = 50
        a1 = np.random.randn(n_obs)
        a2 = np.random.randn(n_obs) * 2 + 1

        # Compute using non-matrix functions
        cov_nonmatrix = move_exp_nancov(a1, a2, alpha=alpha)
        corr_nonmatrix = move_exp_nancorr(a1, a2, alpha=alpha)

        # Compute using matrix functions
        # Exponential moving functions expect (obs, vars) format
        data_matrix = np.column_stack([a1, a2])
        cov_matrix_result = move_exp_nancovmatrix(data_matrix, alpha=alpha)
        corr_matrix_result = move_exp_nancorrmatrix(data_matrix, alpha=alpha)

        # Extract the off-diagonal element (covariance/correlation between a1 and a2)
        cov_from_matrix = cov_matrix_result[:, 0, 1]
        corr_from_matrix = corr_matrix_result[:, 0, 1]

        # They should match
        assert_allclose(cov_nonmatrix, cov_from_matrix, rtol=1e-10)
        assert_allclose(corr_nonmatrix, corr_from_matrix, rtol=1e-10)

        # Also check symmetry - (0,1) should equal (1,0)
        assert_allclose(
            cov_matrix_result[:, 0, 1], cov_matrix_result[:, 1, 0], rtol=1e-10
        )
        assert_allclose(
            corr_matrix_result[:, 0, 1], corr_matrix_result[:, 1, 0], rtol=1e-10
        )
",numbagg/test/test_matrix_functions.py,TestExponentialMatrices
survived,"    def test_rolling_simple(self, move_func, static_func, window):
        """"""Test rolling functions with simple data.""""""
        # Moving functions expect (obs, vars) format
        data = np.array(
            [[1, 2], [2, 4], [3, 6], [4, 8], [5, 10], [6, 12]], dtype=np.float64
        )
        result = move_func(data, window=window, min_count=2)

        # Shape should be (n_obs, n_vars, n_vars)
        assert result.shape == (6, 2, 2)

        # Check symmetry for each time point
        for t in range(6):
            assert_allclose(result[t], result[t].T, equal_nan=True)

        # For perfect linear relationship, correlation should be 1
        if move_func == move_nancorrmatrix:
            for i in range(1, 6):  # From second window onwards (min_count=2)
                assert_allclose(result[i], [[1.0, 1.0], [1.0, 1.0]], rtol=1e-10)
",numbagg/test/test_matrix_functions.py,TestMovingMatrices
survived,"    def test_min_weight(self, func):
        """"""Test min_weight parameter.""""""
        # Exponential moving functions expect (obs, vars) format
        data = np.array([[1, 2], [2, 4], [3, 6], [4, 8]], dtype=np.float64)
        alpha = 0.1  # Low alpha means slow buildup of weight

        # High min_weight should produce more NaNs initially
        result_high = func(data, alpha=alpha, min_weight=0.8)
        result_low = func(data, alpha=alpha, min_weight=0.1)

        # Check that high min_weight produces more NaNs initially
        nan_count_high = np.sum(np.isnan(result_high[0]))
        nan_count_low = np.sum(np.isnan(result_low[0]))
        assert nan_count_high >= nan_count_low
",numbagg/test/test_matrix_functions.py,TestExponentialMatrices
survived,"    def test_rolling_1d_array_raises_error(self, move_func):
        """"""Test that 1D arrays raise an appropriate error for rolling functions.""""""
        data_1d = np.array([1, 2, 3, 4, 5], dtype=np.float64)

        with pytest.raises(ValueError, match=""requires at least a 2D array""):
            move_func(data_1d, window=3)
",numbagg/test/test_matrix_functions.py,TestMovingMatrices
survived,"    def test_dtype_preservation(self, func):
        """"""Test that dtypes are preserved.""""""
        # Set up appropriate data and window for rolling vs basic
        is_rolling = func.__name__.startswith(""move_"")

        # Test float32
        if is_rolling:
            # Moving functions expect (obs, vars)
            data32 = np.random.randn(10, 3).astype(np.float32)
            result32 = func(data32, window=5, min_count=3)
        else:
            # Basic functions expect (vars, obs)
            data32 = np.random.randn(3, 10).astype(np.float32)
            result32 = func(data32)
        assert result32.dtype == np.float32

        # Test float64
        if is_rolling:
            # Moving functions expect (obs, vars)
            data64 = np.random.randn(10, 3).astype(np.float64)
            result64 = func(data64, window=5, min_count=3)
        else:
            # Basic functions expect (vars, obs)
            data64 = np.random.randn(3, 10).astype(np.float64)
            result64 = func(data64)
        assert result64.dtype == np.float64",numbagg/test/test_matrix_functions.py,TestMatrixDtypePreservation
survived,"    def test_windows_colon_validation_logic(self):
        """"""Test that Windows colon validation logic is implemented.""""""

        # Just verify that the Windows-specific logic exists in the code
        # The platform detection happens at instantiation, so mocking doesn't work
        # effectively for testing the actual validation behavior in unit tests.
        # The logic is tested indirectly through the Windows path tests above.
        validator = PathValidator()

        # Verify the validation method exists and handles different path types
        assert hasattr(
            validator, ""validate_path""
        ), ""PathValidator should have validate_path method""

        # Test that validation works for basic cases
        is_valid, _, _ = validator.validate_path(""test.txt"", check_exists=False)
        assert is_valid, ""Simple filename should be valid""",tests/unit/test_windows_compatibility.py,TestWindowsPathValidation
survived,"    async def test_bash_tool_windows_shell_preparation(self, mock_which, mock_platform):
        """"""Test Windows shell command preparation.""""""
        mock_which.side_effect = {
            ""cmd"": ""C:\\Windows\\System32\\cmd.exe"",
            ""powershell"": (
                ""C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe""
            ),
            ""pwsh"": None,
        }.get

        bash_tool = BashTool()

        # Test default cmd.exe handling
        result = bash_tool._prepare_shell_command(""echo test"", ""bash"")
        assert result == [""C:\\Windows\\System32\\cmd.exe"", ""/c"", ""echo test""]

        # Test PowerShell handling
        result = bash_tool._prepare_shell_command(""echo test"", ""powershell"")
        assert result == [
            ""C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe"",
            ""-Command"",
            ""echo test"",
        ]
",tests/unit/test_windows_compatibility.py,TestWindowsCompatibility
survived,"    def test_run_with_uv_error_handling(self, mock_run):
        """"""Test run_with_uv error handling.""""""
        mock_run.side_effect = subprocess.CalledProcessError(1, [""uv"", ""run""])

        with pytest.raises(SystemExit) as exc_info:
            run_with_uv(""server.py"")

        assert exc_info.value.code == 1
",tests/cli/test_run_with_uv.py,TestRunWithUv
survived,"async def reduce_clusters_from_base_clusters( 
    clusters: List[Cluster],
    *,
    model: BaseMetaClusterModel,
    checkpoint_manager: Optional[CheckpointManager] = None
) -> List[Cluster]:
    """"""Reduce clusters into a hierarchical structure.
    
    Iteratively combines similar clusters until the number of root clusters
    is less than or equal to the model's max_clusters setting.
    
    Args:
        clusters: List of initial clusters to reduce
        model: Meta-clustering model to use for reduction
        checkpoint_manager: Optional checkpoint manager for caching
        
    Returns:
        List of clusters with hierarchical structure
        
    Example:
        >>> meta_model = MetaClusterModel(max_clusters=5)
        >>> reduced = await reduce_clusters(
        ...     clusters=base_clusters,
        ...     model=meta_model,
        ...     checkpoint_manager=checkpoint_mgr
        ... )
    """"""
    logger.info(f""Starting cluster reduction from {len(clusters)} initial clusters using {type(model).__name__}"")
    
    # Try to load from checkpoint
    if checkpoint_manager:
        cached = checkpoint_manager.load_checkpoint(
            model.checkpoint_filename,
            Cluster
        )
        if cached:
            root_count = len([c for c in cached if c.parent_id is None])
            logger.info(f""Loaded {len(cached)} clusters from checkpoint ({root_count} root clusters)"")
            return cached
    
    # Start with all clusters as potential roots
    all_clusters = clusters.copy()
    root_clusters = clusters.copy()
    
    logger.info(f""Starting with {len(root_clusters)} clusters, target: {model.max_clusters}"")
    
    # Iteratively reduce until we have desired number of root clusters
    while len(root_clusters) > model.max_clusters:
        # Get updated clusters from meta-clustering
        new_current_level = await model.reduce_clusters(root_clusters)
        
        # Find new root clusters (those without parents)
        root_clusters = [c for c in new_current_level if c.parent_id is None]
        
        # Remove old clusters that now have parents
        old_cluster_ids = {c.id for c in new_current_level if c.parent_id}
        all_clusters = [c for c in all_clusters if c.id not in old_cluster_ids]
        
        # Add new clusters to the complete list
        all_clusters.extend(new_current_level)
        
        logger.info(f""Reduced to {len(root_clusters)} root clusters"")
    
    logger.info(f""Cluster reduction complete: {len(all_clusters)} total clusters, {len(root_clusters)} root clusters"")
    
    # Save to checkpoint
    if checkpoint_manager:
        checkpoint_manager.save_checkpoint(model.checkpoint_filename, all_clusters)
    
    return all_clusters
",kura/v1/kura.py,
survived,"def visualise_clusters_enhanced(
    clusters: Optional[List[Cluster]] = None,
    *,
    checkpoint_path: Optional[Union[str, Path]] = None
) -> None:
    """"""Print an enhanced hierarchical visualization of clusters with colors and statistics.
    
    This function provides a more detailed visualization than visualise_clusters(),
    including conversation counts, percentages, progress bars, and descriptions.
    
    Args:
        clusters: List of clusters to visualize. If None, loads from checkpoint_path
        checkpoint_path: Path to checkpoint file to load clusters from
        
    Raises:
        ValueError: If neither clusters nor checkpoint_path is provided
        FileNotFoundError: If checkpoint file doesn't exist
    """"""
    # Load clusters
    if clusters is None:
        if checkpoint_path is None:
            raise ValueError(""Either clusters or checkpoint_path must be provided"")
        clusters = _load_clusters_from_checkpoint(checkpoint_path)
    
    logger.info(f""Enhanced visualization of {len(clusters)} clusters"")
    
    print(""\n"" + ""=""*80)
    print(""ðŸŽ¯ ENHANCED CLUSTER VISUALIZATION"")
    print(""=""*80)
    
    # Build tree structure
    node_id_to_cluster = _build_cluster_tree(clusters)
    
    # Calculate total conversations from root clusters only
    root_clusters = [cluster for cluster in clusters if not cluster.parent_id]
    total_conversations = sum(len(cluster.chat_ids) for cluster in root_clusters)

    # Find root nodes
    root_nodes = [
        node_id_to_cluster[cluster.id] for cluster in root_clusters
    ]

    fake_root = ClusterTreeNode(
        id=""root"",
        name=f""ðŸ“š All Clusters ({total_conversations:,} total conversations)"",
        description=""Hierarchical conversation clustering results"",
        count=total_conversations,
        children=[node.id for node in root_nodes],
    )

    tree_output = _build_enhanced_tree_structure(
        fake_root, node_id_to_cluster, 0, False, """", total_conversations
    )

    print(tree_output)
    
    # Add summary statistics
    print(""=""*80)
    print(""ðŸ“ˆ CLUSTER STATISTICS"")
    print(""=""*80)
    print(f""ðŸ“Š Total Clusters: {len(clusters)}"")
    print(f""ðŸŒ³ Root Clusters: {len(root_nodes)}"")
    print(f""ðŸ’¬ Total Conversations: {total_conversations:,}"")
    print(f""ðŸ“ Average Conversations per Root Cluster: {total_conversations/len(root_nodes):.1f}"")
    print(""=""*80 + ""\n"")
",kura/v1/visualization.py,
survived,"    def test_contextual_pipeline_decay_with_rate(self):
        """"""Test contextual pipeline decay with explicit rate.""""""
        arms = make_arms(range(3))
        agent = ContextualAgent(arms, ThompsonSampling())
        pipeline = ContextualAgentPipeline([(""identity"", FunctionTransformer())], agent)

        X = np.array([[1.0]])
        pipeline.decay(X, decay_rate=0.7)
",tests/test_agent_pipeline.py,TestCoverage
survived,"    def add_arm(self, arm) -> None:
        """"""Add an arm to the wrapped agent.""""""
        self._agent.add_arm(arm)
",bayesianbandits/pipelines/_agent.py,NonContextualAgentPipeline
survived,"        def add_polynomials(X):
            """"""Add polynomial features.""""""
            # X shape: (n_samples, 3) after interactions
            squared = X**2
            return np.c_[X, squared]
",tests/test_agent_pipeline.py,TestIntegrationScenarios
survived,"    def test_not_fitted_transformer_helpful_error(self):
        """"""Test helpful error message for not fitted transformers.""""""
        arms = make_arms(range(3))
        agent = ContextualAgent(arms, ThompsonSampling())

        steps = [(""scaler"", StandardScaler())]  # Not fitted!
        pipeline = ContextualAgentPipeline(steps, agent)

        X = np.array([[1.0], [2.0]])

        with pytest.raises(RuntimeError) as exc_info:
            pipeline.pull(X)

        error_msg = str(exc_info.value)
        assert ""not fitted"" in error_msg
        assert ""scaler"" in error_msg
        assert ""FunctionTransformer"" in error_msg
",tests/test_agent_pipeline.py,TestErrorHandling
survived,"    def _analyze_architecture(self, project_path: str) -> Dict[str, Any]:
        """"""Analyze the overall architecture patterns.""""""
        architecture = {""primary_pattern"": ""mvc"", ""layers"": [], ""components"": []}
        # Implementation would analyze architectural patterns
        return architecture
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent
survived,"    def _analyze_comment_patterns(self, project_path: str) -> Dict[str, Any]:
        """"""Analyze code comment patterns.""""""
        return {""style"": ""inline"", ""density"": ""moderate""}
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent
survived,"def show_context_engineering_benefits():
    """"""Demonstrate the benefits of Context Engineering vs traditional approaches.""""""
    print(""\nðŸ“Š Context Engineering Benefits"")
    print(""="" * 60)
    
    # Traditional prompt engineering approach
    print(""\nâŒ Traditional Prompt Engineering:"")
    traditional_prompt = ""Create a user authentication system""
    print(f""   Prompt: '{traditional_prompt}'"")
    print(f""   Length: {len(traditional_prompt)} characters"")
    print(f""   Context: Minimal - relies on AI's general knowledge"")
    print(f""   Success Rate: Variable - depends on AI model's training"")
    
    # Context Engineering approach
    print(""\nâœ… Context Engineering Approach:"")
    context_agent = create_context_agent(llm=""gpt-4o-mini"")
    
    # Generate comprehensive context
    analysis = context_agent.analyze_codebase_patterns(str(project_root))
    enhanced_prompt = context_agent.enhance_prompt_with_context(
        traditional_prompt, analysis
    )
    
    print(f""   Enhanced Prompt Length: {len(enhanced_prompt)} characters"")
    print(f""   Context: Comprehensive - includes:"")
    print(f""     â€¢ Codebase architecture analysis"")
    print(f""     â€¢ Existing patterns and conventions"")
    print(f""     â€¢ Implementation guidance"")
    print(f""     â€¢ Quality requirements"")
    print(f""     â€¢ Validation criteria"")
    print(f""   Success Rate: Higher - AI has all necessary context"")
    
    print(f""\nðŸŽ¯ Context Engineering provides:"")
    print(f""   ðŸ“ˆ 10x better than prompt engineering (comprehensive vs clever wording)"")
    print(f""   ðŸ“ˆ 100x better than vibe coding (structured vs ad-hoc)"")
    print(f""   ðŸŽ¯ First-try implementation success through complete context"")
",examples/python/agents/context-agent.py,
survived,"    def analyze_test_patterns(self, project_path: str) -> Dict[str, Any]:
        """"""Analyze testing patterns and conventions in the project.""""""
        test_patterns = {
            ""test_structure"": self._analyze_test_structure(project_path),
            ""testing_frameworks"": self._identify_testing_frameworks(project_path),
            ""test_naming"": self._analyze_test_naming(project_path),
            ""coverage_patterns"": self._analyze_coverage_patterns(project_path)
        }
        return test_patterns
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent
survived,"    def _format_documentation_standards(self, doc_style: Dict[str, Any]) -> str:
        """"""Format documentation standards for context document.""""""
        return f""Format: {doc_style.get('format', 'markdown')}""
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent
survived,"    def create_validation_loop(self, implementation_requirements: str, success_criteria: List[str]) -> Dict[str, Any]:
        """"""
        Create executable validation loops and success criteria.
        
        Args:
            implementation_requirements (str): What needs to be implemented
            success_criteria (List[str]): List of success criteria to validate
            
        Returns:
            Dict[str, Any]: Validation loop configuration with executable criteria
        """"""
        validation_config = {
            ""requirements"": implementation_requirements,
            ""success_criteria"": success_criteria,
            ""validation_steps"": [],
            ""executable_tests"": [],
            ""quality_gates"": []
        }
        
        # Generate validation steps
        for criterion in success_criteria:
            validation_step = {
                ""criterion"": criterion,
                ""validation_method"": self._determine_validation_method(criterion),
                ""expected_outcome"": self._generate_expected_outcome(criterion),
                ""failure_actions"": self._generate_failure_actions(criterion)
            }
            validation_config[""validation_steps""].append(validation_step)
        
        # Generate executable tests
        validation_config[""executable_tests""] = self._generate_executable_tests(implementation_requirements, success_criteria)
        
        # Generate quality gates
        validation_config[""quality_gates""] = self._generate_quality_gates(success_criteria)
        
        return validation_config
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent
survived,"def demonstrate_basic_context_generation():
    """"""Demonstrate basic context generation capabilities.""""""
    print(""ðŸ”§ Context Engineering Example: Basic Usage"")
    print(""="" * 60)
    
    # Create a ContextAgent using the factory function
    context_agent = create_context_agent(
        llm=""gpt-4o-mini"",
        name=""Basic Context Engineer"",
        verbose=True
    )
    
    # Example 1: Analyze codebase patterns
    print(""\nðŸ“ Example 1: Analyzing Codebase Patterns"")
    print(""-"" * 40)
    
    # Use current project as example (adjust path as needed)
    project_path = str(project_root)
    analysis = context_agent.analyze_codebase_patterns(
        project_path=project_path,
        file_patterns=[""*.py""]
    )
    
    print(f""âœ… Analyzed project at: {project_path}"")
    print(f""   Project structure: {len(analysis.get('project_structure', {}).get('directories', []))} directories"")
    print(f""   Code patterns identified: {len(analysis.get('code_patterns', {}))}"")
    print(f""   Architecture: {analysis.get('architecture_insights', {}).get('primary_pattern', 'Unknown')}"")
    
    # Example 2: Generate context document
    print(""\nðŸ“„ Example 2: Generating Context Document"")
    print(""-"" * 40)
    
    feature_request = ""Add user authentication system with JWT tokens and role-based access control""
    context_doc = context_agent.generate_context_document(
        project_path=project_path,
        requirements=feature_request,
        analysis=analysis
    )
    
    print(f""âœ… Generated context document for: {feature_request}"")
    print(f""   Document length: {len(context_doc)} characters"")
    print(f""   Contains architecture patterns: {'Architecture Patterns' in context_doc}"")
    print(f""   Contains validation criteria: {'Validation Criteria' in context_doc}"")
    
    # Example 3: Create validation loop
    print(""\nâœ… Example 3: Creating Validation Loop"")
    print(""-"" * 40)
    
    success_criteria = [
        ""Authentication system accepts valid JWT tokens"",
        ""Role-based access control blocks unauthorized users"", 
        ""User registration and login endpoints work correctly"",
        ""Password hashing follows security best practices"",
        ""Session management handles token expiration""
    ]
    
    validation_config = context_agent.create_validation_loop(
        implementation_requirements=feature_request,
        success_criteria=success_criteria
    )
    
    print(f""âœ… Created validation loop with {len(validation_config['validation_steps'])} steps"")
    print(f""   Success criteria: {len(success_criteria)}"")
    print(f""   Executable tests: {len(validation_config['executable_tests'])}"")
    print(f""   Quality gates: {len(validation_config['quality_gates'])}"")
    
    # Example 4: Enhance prompt with context
    print(""\nðŸš€ Example 4: Enhancing Prompt with Context"")
    print(""-"" * 40)
    
    basic_prompt = ""Implement user authentication""
    enhanced_prompt = context_agent.enhance_prompt_with_context(
        base_prompt=basic_prompt,
        context_data=analysis
    )
    
    print(f""âœ… Enhanced prompt from {len(basic_prompt)} to {len(enhanced_prompt)} characters"")
    print(f""   Original: '{basic_prompt}'"")
    print(f""   Enhanced includes: Context Engineering, Implementation Context, Quality Requirements"")
    
    # Example 5: Generate PRP (Product Requirements Prompt)
    print(""\nðŸ“‹ Example 5: Generating PRP"")
    print(""-"" * 40)
    
    documentation_links = [
        ""https://jwt.io/introduction/"",
        ""https://fastapi.tiangolo.com/tutorial/security/"",
        ""https://passlib.readthedocs.io/en/stable/""
    ]
    
    prp = context_agent.generate_prp(
        feature_request=feature_request,
        context_analysis=analysis,
        documentation_links=documentation_links
    )
    
    print(f""âœ… Generated comprehensive PRP"")
    print(f""   PRP length: {len(prp)} characters"")
    print(f""   Contains feature request: {feature_request in prp}"")
    print(f""   Contains documentation links: {len(documentation_links)} links included"")
    print(f""   Contains implementation blueprint: {'Implementation Blueprint' in prp}"")
    print(f""   Confidence score: {'9/10' in prp}"")
",examples/python/agents/context-agent.py,
survived,"    def _extract_pattern_guidance(self, context_data: Dict[str, Any]) -> str:
        """"""Extract pattern guidance from context data.""""""
        return ""Adhere to existing code patterns and conventions.""
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent
survived,"        async def mock_llm_call(*args, **kwargs):
            return llm.LLMResponse(
                raw_response="""",
                prompt=[],
                response='{""result"": ""test""}',
                tool_calls=None,
                prompt_tokens=10,
                completion_tokens=20,
                reasoning=None,
            )
",autogpt_platform/backend/backend/blocks/test/test_llm.py,TestLLMStatsTracking
survived,"    def _message(self) -> str:
        return (
            ""Markdown link is not supported in docstring. ""
            ""Use reST link instead (e.g., `Link text <link URL>`_).""
        )",dev/clint/src/clint/rules/markdown_link.py,MarkdownLink
survived,"    def _message(self) -> str:
        return (
            ""Found the MLflow Trace UI iframe in the notebook. ""
            ""The trace UI in cell outputs will not render correctly in previews or the website. ""
            ""Please run `mlflow.tracing.disable_notebook_display()` and rerun the cell ""
            ""to remove the iframe.""
        )",dev/clint/src/clint/rules/forbidden_trace_ui_in_notebook.py,ForbiddenTraceUIInNotebook
survived,"    def _message(self) -> str:
        return (
            ""`ThreadPoolExecutor()` must be called with a `thread_name_prefix` argument to improve ""
            ""debugging and traceability of thread-related issues.""
        )
",dev/clint/src/clint/rules/thread_pool_executor_without_thread_name_prefix.py,ThreadPoolExecutorWithoutThreadNamePrefix
survived,"def test_webhook_test_failed_endpoint(mlflow_client: MlflowClient, app_client: AppClient) -> None:
    # Create webhook pointing to non-existent endpoint
    webhook = mlflow_client.create_webhook(
        name=""failed_webhook"",
        url=app_client.get_url(""/nonexistent-endpoint""),
        events=[WebhookEvent.REGISTERED_MODEL_CREATED],
    )

    # Test the webhook
    result = mlflow_client.test_webhook(webhook.webhook_id)

    # Check that the test failed
    assert result.success is False
    assert result.response_status == 404
    assert result.error_message is None  # No error message for HTTP errors
    assert result.response_body is not None  # Should contain error response
",tests/webhooks/test_e2e.py,
survived,"            def w_new2(vm: 'SPyVM', w_cls: W_Type,
                       w_func: W_Func, w_args: W_OpArgList) -> W_OpImpl:
                # Convert from applevel w_args into interp-level args_w
                args_w = w_args.items_w[:]
                return W_OpImpl(w_func, args_w)
",spy/vm/opimpl.py,W_OpImpl
survived,"    def test_dtype_preservation(self):
        # Test float32
        data32 = np.random.randn(5, 20).astype(np.float32)
        result32 = nancorrmatrix(data32)
        assert result32.dtype == np.float32

        # Test float64
        data64 = np.random.randn(5, 20).astype(np.float64)
        result64 = nancorrmatrix(data64)
        assert result64.dtype == np.float64
",numbagg/test/test_nancorrmatrix.py,TestNanCorrMatrix
survived,"        def __get__(self, obj: Any, objtype: Any = None) -> Any:
            warnings.warn(
                ""`jaxls.Factor` has been renamed to `jaxls.Cost`"",
                DeprecationWarning,
                stacklevel=2,
            )
            return Cost
",src/jaxls/__init__.py,_FactorDescriptor
survived,"    def assert_called(
        self, hook: str | None = None, method: str | None = None, times: int = 1
    ) -> bool:
        """"""Assert that a hook was called a specific number of times.""""""
        calls = self.get_calls(hook=hook, method=method)
        actual_times = len(calls)
        assert actual_times == times, (
            f""Expected {hook!r} to be called {times} times""
            f""{f' for method {method!r}' if method else ''}, ""
            f""but was called {actual_times} times""
        )
        return True
",tests/server/middleware/test_middleware.py,RecordingMiddleware
survived,"        def test_resource() -> str:
            return ""test resource""
",tests/server/middleware/test_middleware.py,TestNestedMiddlewareHooks
survived,"    async def test_list_prompts(
        self, mcp_server: FastMCP, recording_middleware: RecordingMiddleware
    ):
        async with Client(mcp_server) as client:
            await client.list_prompts()

        assert recording_middleware.assert_called(times=3)
        assert recording_middleware.assert_called(method=""prompts/list"", times=3)
        assert recording_middleware.assert_called(hook=""on_message"", times=1)
        assert recording_middleware.assert_called(hook=""on_request"", times=1)
        assert recording_middleware.assert_called(hook=""on_list_prompts"", times=1)
",tests/server/middleware/test_middleware.py,TestMiddlewareHooks
deleted,"    async def _middleware_call_tool(
        self,
        key: str,
        arguments: dict[str, Any],
    ) -> list[MCPContent]:
        """"""
        Call a tool with middleware.
        """"""

        async def _handler(
            context: MiddlewareContext[mcp.types.CallToolRequestParams],
        ) -> list[MCPContent]:
            return await self._call_tool(
                key=context.message.name,
                arguments=context.message.arguments or {},
            )

        mw_context = MiddlewareContext(
            message=mcp.types.CallToolRequestParams(name=key, arguments=arguments),
            source=""client"",
            type=""request"",
            method=""tools/call"",
            fastmcp_context=fastmcp.server.dependencies.get_context(),
        )
        return await self._apply_middleware(mw_context, _handler)
",src/fastmcp/server/server.py,FastMCP
survived,"            async def record_and_call(
                context: MiddlewareContext, call_next: Callable
            ) -> Any:
                result = await call_next(context)

                self.calls.append(Recording(hook=name, context=context, result=result))

                return result
",tests/server/middleware/test_middleware.py,RecordingMiddleware
survived,"def test_export_datasets_and_create_metadata_db_basic(simple_dataset):
    """"""Test basic functionality of export_datasets_and_create_metadata_db""""""
    source_db_path, run_id = simple_dataset
    
    with tempfile.TemporaryDirectory() as temp_dir:
        target_db_path = Path(temp_dir) / ""target.db""
        export_path = Path(temp_dir) / ""exports""
        
        # Run the export function
        result = export_datasets_and_create_metadata_db(
            source_db_path=source_db_path,
            target_db_path=target_db_path,
            export_path=export_path,
        )
        
        # Check that the function returned a result
        assert isinstance(result, dict)
        assert run_id in result
        assert result[run_id] in [""exported"", ""copied_as_is""]
        
        # Check that target database was created
        assert target_db_path.exists()
        
        # Check that target database has the run
        target_conn = connect(target_db_path)
        target_runs = get_runs(target_conn)
        assert len(target_runs) == 1
        target_conn.close()
        
        # Check that NetCDF file was created if export was successful
        if result[run_id] == ""exported"":
            netcdf_files = list(export_path.glob(""*.nc""))
            assert len(netcdf_files) > 0
",tests/dataset/test_export_datasets_and_create_metadata_db.py,
survived,"    async def run(self, text: str) -> str:
        """"""Run all checks sequentially and return possibly modified text.""""""

        for check in self.checks:
            text = await check(text)
        return text
",src/meta_agent/policy.py,PolicyChecker
survived,"async def build_policy_guardrails(
    config: GuardrailConfig,
) -> List[Callable[[str], Awaitable[None]]]:
    """"""Helper to create router-compatible guardrails from a config.""""""

    checker = PolicyChecker(config)

    async def guard(text: str) -> None:
        await checker.run(text)

    return [guard]",src/meta_agent/policy.py,
survived,"    async def guard(text: str) -> None:
        await checker.run(text)
",src/meta_agent/policy.py,
survived,"    def setup_shutdown_handlers_stub(
        manager: DummyManager, shutdown: asyncio.Event
    ) -> DummyManager:
        manager.shutdown = shutdown
        return manager
",test/windows/test_shutdown.py,
survived,"        async def send_json(self, data: dict[str, object]) -> None:
            messages.append(data)
",tests/test_api_server.py,DummyWS
survived,"    def __init__(
        self,
        bus: object,
        ledger: object,
        repo: str | Path,
        patch_file: str | Path,
        *,
        metric_file: str = ""metric.txt"",
        log_file: str = ""improver_log.json"",
        allowed: Sequence[str] | None = None,
        backend: str = ""gpt-4o"",
        island: str = ""default"",
    ) -> None:
        super().__init__(""self_improver"", bus, ledger, backend=backend, island=island)
        self.repo = Path(repo)
        self.patch_file = Path(patch_file)
        self.metric_file = metric_file
        self.log_file = log_file
        self.allowed = list(allowed or [""**""])
",src/agents/self_improver_agent.py,SelfImproverAgent
survived,"    def read_and_refresh_token(self) -> Dict[str, Any]:
        """"""Read token from file and refresh if needed""""""
        path = self.get_auth_file()
        
        if path.is_file():
            with open(path, 'r') as f:
                auth_data = json.load(f)
            
            diff = time.time() - os.path.getmtime(path)
            expires_in = int(auth_data.get(""expiresIn""))
            
            if diff < expires_in:
                if diff > expires_in / 2:
                    auth_data[""idToken""], auth_data[""refreshToken""] = self.refresh_token(
                        auth_data.get(""refreshToken"")
                    )
                    with open(path, 'w') as f:
                        json.dump(auth_data, f)
                return auth_data
        
        # Create new token if file doesn't exist or token expired
        return self.create_token(path)
",webscout/Provider/TTI/aiarta.py,AIArtaImager
survived,"    def generate(
        self, prompt: str, amount: int = 1,
        max_retries: int = 3, retry_delay: int = 5,
        style: str = ""none"", aspect_ratio: str = ""1:1""
    ) -> List[bytes]:
        """"""Generate some amazing images from your prompt! ðŸŽ¨

        Args:
            prompt (str): Your creative prompt
            amount (int): How many images to generate
            max_retries (int): Max retry attempts if generation fails
            retry_delay (int): Seconds to wait between retries
            style (str): Style to apply (default: ""none"")
            aspect_ratio (str): Aspect ratio (default: ""1:1"")

        Returns:
            List[bytes]: Your generated images as bytes
        """"""
        assert bool(prompt), ""Prompt cannot be empty.""
        assert isinstance(amount, int) and amount > 0, ""Amount must be a positive integer.""

        self.prompt = prompt
        response = []
        
        for _ in range(amount):
            for attempt in range(max_retries):
                try:
                    with self.session.post(
                        self.api_endpoint,
                        json=self._create_payload(prompt, self.model, style, aspect_ratio),
                        timeout=self.timeout
                    ) as resp:
                        resp.raise_for_status()
                        data = resp.json()

                        if 'output' in data and len(data['output']) > 0:
                            image_url = data['output'][0]
                            # Get the image data from the URL
                            img_resp = self.session.get(image_url, timeout=self.timeout)
                            img_resp.raise_for_status()
                            response.append(img_resp.content)
                            break
                        else:
                            print(f""Warning: No image data in response: {data}"")
                            if attempt == max_retries - 1:
                                raise Exception(""No image data received after all retries"")

                except Exception as e:
                    print(f""Error generating image (attempt {attempt + 1}/{max_retries}): {str(e)}"")
                    if attempt == max_retries - 1:
                        raise
                    import time
                    time.sleep(retry_delay)

        return response
",webscout/Provider/TTI/pixelmuse.py,PixelMuseImager
survived,"def format_prompt(messages: List[Dict[str, Any]], add_special_tokens: bool = False,
                 do_continue: bool = False, include_system: bool = True) -> str:
    """"""
    Format a series of messages into a single string, optionally adding special tokens.

    Args:
        messages: A list of message dictionaries, each containing 'role' and 'content'.
        add_special_tokens: Whether to add special formatting tokens.
        do_continue: If True, don't add the final ""Assistant:"" prompt.
        include_system: Whether to include system messages in the formatted output.

    Returns:
        A formatted string containing all messages.
    """"""
    # Helper function to convert content to string
    def to_string(value) -> str:
        if isinstance(value, str):
            return value
        elif isinstance(value, dict):
            if ""text"" in value:
                return value.get(""text"", """")
            return """"
        elif isinstance(value, list):
            return """".join([to_string(v) for v in value])
        return str(value)

    # If there's only one message and no special tokens needed, just return its content
    if not add_special_tokens and len(messages) <= 1:
        return to_string(messages[0][""content""])

    # Filter and process messages
    processed_messages = [
        (message[""role""], to_string(message[""content""]))
        for message in messages
        if include_system or message.get(""role"") != ""system""
    ]

    # Format each message as ""Role: Content""
    formatted = ""\n"".join([
        f'{role.capitalize()}: {content}'
        for role, content in processed_messages
        if content.strip()
    ])

    # Add final prompt for assistant if needed
    if do_continue:
        return formatted

    return f""{formatted}\nAssistant:""
",webscout/Provider/TTI/utils.py,
survived,"    def save(
        self,
        response: List[bytes],
        name: str = None,
        dir: str = os.getcwd(),
        filenames_prefix: str = """",
    ) -> List[str]:
        """"""Save your fire images! ðŸ’¾

        Args:
            response (List[bytes]): List of image data
            name (str, optional): Base name for saved files
            dir (str, optional): Where to save the images
            filenames_prefix (str, optional): Prefix for filenames

        Returns:
            List[str]: List of saved filenames
        """"""
        assert isinstance(response, list), f""Response should be of {list} not {type(response)}""
        name = self.prompt if name is None else name

        if not os.path.exists(dir):
            os.makedirs(dir)

        filenames = []
        count = 0
        for image in response:
            def complete_path():
                count_value = """" if count == 0 else f""_{count}""
                return os.path.join(dir, name + count_value + ""."" + self.image_extension)

            while os.path.isfile(complete_path()):
                count += 1

            absolute_path_to_file = complete_path()
            filenames.append(filenames_prefix + os.path.split(absolute_path_to_file)[1])

            with open(absolute_path_to_file, ""wb"") as fh:
                fh.write(image)
        return filenames
",webscout/Provider/TTI/freeaiplayground.py,FreeAIImager
survived,"    def save(
        self,
        response: List[str],
        name: str = None,
        dir: str = os.getcwd(),
        filenames_prefix: str = """",
    ) -> List[str]:
        """"""Save your fire images! ðŸ’¾

        Args:
            response (List[str]): List of image URLs
            name (str, optional): Base name for saved files
            dir (str, optional): Where to save the images
            filenames_prefix (str, optional): Prefix for filenames

        Returns:
            List[str]: List of saved filenames
        """"""
        assert isinstance(response, list), f""Response should be a list, not {type(response)}""
        name = self.prompt if name is None else name

        if not os.path.exists(dir):
            os.makedirs(dir)
            if self.logging:
                logger.info(f""Created directory: {dir} ðŸ“"")

        if self.logging:
            logger.info(f""Saving {len(response)} images... ðŸ’¾"")

        filenames = []
        for i, url in enumerate(response):
            try:
                with self.session.get(url, stream=True, timeout=self.timeout) as r:
                    r.raise_for_status()
                    filename = f""{filenames_prefix}{name}_{i}.{self.image_extension}""
                    filepath = os.path.join(dir, filename)
                    with open(filepath, 'wb') as f:
                        for chunk in r.iter_content(chunk_size=8192):
                            f.write(chunk)
                    filenames.append(filename)
                    if self.logging:
                        logger.success(f""Saved image to: {filepath} ðŸ’¾"")
            except requests.exceptions.RequestException as e:
                if self.logging:
                    logger.error(f""Error downloading image from {url}: {e} ðŸ˜¢"")
                filenames.append(None)  # Indicate failure to download

        if self.logging:
            logger.success(f""All images saved successfully! Check {dir} ðŸŽ‰"")
        return filenames
",webscout/Provider/TTI/talkai.py,TalkaiImager
survived,"    def save(
        self,
        response: List[bytes],
        name: Optional[str] = None,
        dir: Optional[Union[str, Path]] = None,
        filenames_prefix: str = """",
    ) -> List[str]:
        """"""Save your fire generated images! ðŸ’¾

        Examples:
            >>> provider = FastFluxImager()
            >>> images = provider.generate(""Cool art"")
            >>> # Save with default settings
            >>> paths = provider.save(images)
            >>> # Save with custom name and directory
            >>> paths = provider.save(
            ...     images,
            ...     name=""my_art"",
            ...     dir=""my_images"",
            ...     filenames_prefix=""test_""
            ... )

        Args:
            response (List[bytes]): Your generated images
            name (Optional[str]): Custom name for your images
            dir (Optional[Union[str, Path]]): Where to save the images (default: current directory)
            filenames_prefix (str): Prefix for your image files

        Returns:
            List[str]: Paths to your saved images
        """"""
        save_dir = dir if dir else os.getcwd()
        if not os.path.exists(save_dir):
            os.makedirs(save_dir)

        name = self.prompt if name is None else name
        
        # Clean up name for filename use
        safe_name = """".join(c if c.isalnum() or c in ""_-"" else ""_"" for c in name)
        safe_name = safe_name[:50]  # Truncate if too long
        
        filenames = []

        for i, image in enumerate(response):
            filename = f""{filenames_prefix}{safe_name}_{i}.{self.image_extension}""
            filepath = os.path.join(save_dir, filename)
            
            with open(filepath, ""wb"") as f:
                f.write(image)
            
            filenames.append(filename)

        return filenames
",webscout/Provider/TTI/fastflux.py,FastFluxImager
survived,"    def generate(
        self, prompt: str, amount: int = 1, additives: bool = True,
        size: str = ""1024x1024"", quality: str = ""standard"",
        style: str = ""vivid"", max_retries: int = 3, retry_delay: int = 5
    ) -> List[bytes]:
        """"""Generate some fire images from your prompt! ðŸŽ¨

        Args:
            prompt (str): Your creative prompt
            amount (int): How many images to generate
            additives (bool): Add random characters to make prompts unique
            size (str): Image size (1024x1024, 1024x1792, 1792x1024)
            quality (str): Image quality (standard, hd)
            style (str): Image style (vivid, natural)
            max_retries (int): Max retry attempts if generation fails
            retry_delay (int): Delay between retries in seconds

        Returns:
            List[bytes]: Your generated images as bytes
        """"""
        assert bool(prompt), ""Prompt cannot be null""
        assert isinstance(amount, int), f""Amount should be an integer only not {type(amount)}""
        assert amount > 0, ""Amount should be greater than 0""

        ads = lambda: (
            """"
            if not additives
            else choice(punctuation)
            + choice(punctuation)
            + choice(punctuation)
        )

        self.prompt = prompt
        response = []
        for _ in range(amount):
            payload = {
                ""model"": self.model,
                ""prompt"": prompt + ads(),
                ""n"": 1,
                ""size"": size,
                ""quality"": quality,
                ""style"": style
            }
            
            for attempt in range(max_retries):
                try:
                    resp = self.session.post(
                        url=self.image_gen_endpoint,
                        json=payload,
                        timeout=self.timeout
                    )
                    resp.raise_for_status()
                    response_data = resp.json()
                    if 'data' in response_data and len(response_data['data']) > 0:
                        image_url = response_data['data'][0]['url']
                        # Get the image data from the URL
                        img_resp = self.session.get(image_url, timeout=self.timeout)
                        img_resp.raise_for_status()
                        response.append(img_resp.content)
                        break
                    else:
                        print(f""Warning: No image data in response: {response_data}"")
                        if attempt == max_retries - 1:
                            raise Exception(""No image data received after all retries"")
                except Exception as e:
                    print(f""Error generating image (attempt {attempt + 1}/{max_retries}): {str(e)}"")
                    if attempt == max_retries - 1:
                        raise
                    import time
                    time.sleep(retry_delay)
        return response
",webscout/Provider/TTI/freeaiplayground.py,FreeAIImager
survived,"    def generate(
        self,
        prompt: str,
        amount: int = 1,
        max_retries: int = 3,
        retry_delay: int = 5
    ) -> List[bytes]:
        """"""Generate some fire images from your prompt! ðŸŽ¨

        Args:
            prompt (str): Your image description
            amount (int): How many images you want (default: 1)
            max_retries (int): Max retry attempts if something fails (default: 3)
            retry_delay (int): Seconds to wait between retries (default: 5)

        Returns:
            List[bytes]: Your generated images as bytes

        Raises:
            ValueError: If the inputs ain't valid
            RequestException: If the API calls fail after retries
        """"""
        # Input validation
        if not prompt:
            raise ValueError(""Yo fam, the prompt can't be empty! ðŸ¤”"")
        if not isinstance(amount, int) or amount < 1:
            raise ValueError(""Amount needs to be a positive number! ðŸ“ˆ"")

        self.prompt = prompt
        response = []
        
        # Payload with the prompt
        payload = {
            ""prompt"": prompt
        }

        for i in range(amount):
            for attempt in range(max_retries):
                try:
                    resp = self.session.post(
                        self.api_endpoint, 
                        json=payload,
                        timeout=self.timeout
                    )
                    resp.raise_for_status()
                    
                    # Check if response is an image
                    if resp.headers.get('content-type') == 'image/jpeg':
                        response.append(resp.content)
                        break
                    else:
                        if attempt == max_retries - 1:
                            raise RequestException(f""API returned non-image content: {resp.text[:100]}"")
                
                except RequestException as e:
                    if attempt == max_retries - 1:
                        raise
                    time.sleep(retry_delay)

        return response
",webscout/Provider/TTI/piclumen.py,PiclumenImager
survived,"    def refresh_token(self, refresh_token: str) -> tuple[str, str]:
        """"""Refresh authentication token""""""
        payload = {
            ""grant_type"": ""refresh_token"",
            ""refresh_token"": refresh_token,
        }
        
        response = self.session.post(self.token_refresh_url, data=payload, timeout=self.timeout)
        response_data = response.json()
        
        return response_data.get(""id_token""), response_data.get(""refresh_token"")
",webscout/Provider/TTI/aiarta.py,AIArtaImager
survived,"            def complete_path():
                count_value = """" if count == 0 else f""_{count}""
                return os.path.join(dir, name + count_value + ""."" + self.image_extension)
",webscout/Provider/TTI/artbit.py,ArtbitImager
survived,"    def test_scalar_grad(self):
        klong = KlongInterpreter()
        klong['sin'] = lambda x: np.sin(x)
        klong['cos'] = lambda x: np.cos(x)
        klong('g::âˆ‡{sin(x)+x*x}')
        r = klong('g(3.14)')
        self.assertTrue(np.isclose(r, 2*3.14 + np.cos(3.14), atol=1e-3))
",tests/test_autograd.py,TestAutograd
survived,"    def test_matrix_grad(self):
        klong = KlongInterpreter()
        klong('A::Ë™[2 2]:^!4')
        klong('B::[2 2]:^!4')
        r = klong('(A âˆ‡ {+/(+/ (A*B)) })')
        self.assertTrue(np.allclose(r, klong('B'), atol=1e-3))
",tests/test_autograd.py,TestAutograd
survived,"def test_container_healthcheck() -> None:
    tag = ""af-health-test""
    dockerfile = os.path.join(""alpha_factory_v1"", ""Dockerfile"")
    subprocess.run([""docker"", ""build"", ""-t"", tag, ""-f"", dockerfile, "".""], check=True)
    cid = subprocess.check_output([""docker"", ""run"", ""-d"", tag]).decode().strip()
    try:
        status = ""starting""
        for _ in range(60):
            inspect = subprocess.check_output(
                [""docker"", ""inspect"", ""-f"", ""{{.State.Health.Status}}"", cid],
                text=True,
            ).strip()
            status = inspect
            if status == ""healthy"":
                break
            time.sleep(2)
        assert status == ""healthy""
    finally:
        subprocess.run([""docker"", ""rm"", ""-f"", cid], check=False)
        subprocess.run([""docker"", ""rmi"", tag], check=False)",tests/test_docker_health.py,
survived,"            async def post(self, *_args, **_kwargs):  # pragma: no cover - network
                raise NotImplementedError(""aiohttp is required for network access"")
",src/meta_agent/services/llm_service.py,AiohttpPlaceholder.ClientSession
survived,"    async def post(self, *_args, **_kwargs):
        raise NotImplementedError(""aiohttp is required for network access"")
",src/aiohttp/__init__.py,ClientSession
survived,"        async def close(self) -> None:
            pass
",src/meta_agent/services/telemetry_client.py,ClientSession
survived,"def test_error_output_stderr(capsys):
    cli = CLIOutput()
    cli.error(""oops"")
    out, err = capsys.readouterr()
    assert out == """"
    assert ""oops"" in click.unstyle(err)",tests/ux/test_cli_output.py,
survived,"    def warning(self, message: str, *, level: int = 1) -> None:
        """"""Output a warning message.""""""
        self._echo(message, fg=""yellow"", level=level)
",src/meta_agent/ux/cli_output.py,CLIOutput
survived,"            async def step(self):
                return None
",tests/test_agents_registry.py,TestAgentRegistryFunctions.AAgent
survived,"    def test_pct_basic(self):
        self.assertAlmostEqual(finance_agent._pct(100.0, 110.0), 0.1)
        self.assertEqual(finance_agent._pct(0.0, 5.0), 0.0)
",tests/test_finance_utils.py,TestFinanceUtils
survived,"    def test_forecast_structure(self):
        data = asyncio.run(self.agent._forecast())
        payload = json.loads(data)
        self.assertEqual(payload[""agent""], self.agent.NAME)
        self.assertEqual(len(payload[""payload""]), 48)
        self.assertIsInstance(payload[""payload""], list)
",tests/test_energy_agent_behavior.py,TestEnergyAgentBehavior
survived,"            async def step(self):
                return None
",tests/test_agents_registry.py,TestVersionOverride.AgentV1
survived,"    def test_list_and_detail_counts_match(self):
        # registry should return same number of agents regardless of detail flag
        names = list_agents()
        details = list_agents(detail=True)
        self.assertEqual(len(names), len(details))
",tests/test_agents_registry.py,TestAgentRegistryFunctions
survived,"    def test_agent_names_unique(self):
        names = list_agents()
        self.assertEqual(len(names), len(set(names)))
",tests/test_agents_integrity.py,TestAgentsIntegrity
survived,"            def __init__(self) -> None:
                self.called = False
",tests/test_alpha_agi_business_3_v1.py,TestAlphaAgiBusiness3Demo.CaptureOrch
survived,"def test_rate_limiter_evicts_old_entries(monkeypatch: pytest.MonkeyPatch) -> None:
    monkeypatch.setenv(""API_RATE_LIMIT"", ""5"")
    from src.interface import api_server as api

    api = importlib.reload(api)

    limiter = api.SimpleRateLimiter(api.app, limit=5, window=0.1)

    asyncio.run(limiter.dispatch(_make_request(""1.1.1.1""), _call_next))
    assert ""1.1.1.1"" in limiter.counters
    time.sleep(0.2)
    asyncio.run(limiter.dispatch(_make_request(""2.2.2.2""), _call_next))
    assert ""1.1.1.1"" not in limiter.counters
    assert list(limiter.counters.keys()) == [""2.2.2.2""]",tests/test_rate_limiter_eviction.py,
survived,"    def test_non_declarative_base_raises_error(self):
        """"""Test that using the mixin without DeclarativeBase raises an error.""""""

        class NotSQLAlchemy(EnrichSQLAlchemyMixin):
            """"""This is not a SQLAlchemy model.""""""

            pass

        with pytest.raises(TypeError) as exc_info:
            NotSQLAlchemy.__enrich_model__()

        assert ""must inherit from SQLAlchemy DeclarativeBase"" in str(exc_info.value)
",tests/test_sqlalchemy_integration.py,TestEdgeCases
survived,"    def test_async_attrs_compatibility(self):
        """"""Test that the mixin works with AsyncAttrs.""""""

        class Base(DeclarativeBase):
            pass

        class AsyncUser(Base, AsyncAttrs, EnrichSQLAlchemyMixin):
            """"""Async user model.""""""

            __tablename__ = ""async_users""

            id: Mapped[int] = mapped_column(primary_key=True)
            username: Mapped[str] = mapped_column()

        # Should work without issues
        AsyncUserEnrichModel = AsyncUser.__enrich_model__()
        assert issubclass(AsyncUserEnrichModel, EnrichModel)
        assert ""id"" in AsyncUserEnrichModel.model_fields
        assert ""username"" in AsyncUserEnrichModel.model_fields
",tests/test_sqlalchemy_integration.py,TestEdgeCases
survived,"    def __init__(self, obs_dim: int, act_dim: int):
        super().__init__()
        self.repr = Repr(obs_dim, CFG.hidden)
        self.dyn  = Dyn(CFG.hidden, act_dim)
        self.pred = Pred(CFG.hidden, act_dim)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,MuZeroTiny
survived,"    def log(self, event: str, **payload):
        with self.path.open(""a"", encoding=""utf-8"") as fp:
            json.dump({""ts"": _utcnow_ms(), ""event"": event, **payload}, fp, ensure_ascii=False)
            fp.write(""\n"")
",alpha_factory_v1/demos/meta_agentic_agi_v2/agents/agent_base.py,LineageTracer
survived,"    def run(self, code: str, func_name: str, *args, **kw):
        loc: Dict[str,Any] = {}
        with self:
            exec(code, {}, loc)
        if func_name not in loc:
            raise AttributeError(f""{func_name} not found"")
        return loc[func_name](*args, **kw)
",alpha_factory_v1/demos/meta_agentic_agi_v2/agents/agent_base.py,SafeExec
survived,"    def step(self, act:int):
        dx,dy = [(0,1),(1,0),(0,-1),(-1,0)][act%4]
        nx,ny = self._clip(self.agent[0]+dx), self._clip(self.agent[1]+dy)
        if (nx,ny) in self.obstacles: nx,ny = self.agent
        self.agent=(nx,ny)
        done = self.agent==self.goal
        reward = 1.0 if done else -0.01
        return self._obs(), reward, done, {}
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,MiniWorld
survived,"def _utcnow_ms() -> str:
    return time.strftime(""%Y-%m-%dT%H:%M:%S"", time.gmtime()) + f"".{int((time.time()%1)*1000):03d}Z""
",alpha_factory_v1/demos/meta_agentic_agi/agents/agent_base.py,
survived,"    def __call__(self, prompt:str, **kw):
        return self.run(prompt, **kw)
",alpha_factory_v1/demos/meta_agentic_agi_v3/agents/agent_base.py,Agent
survived,"def _utcnow_ms() -> str:
    return time.strftime(""%Y-%m-%dT%H:%M:%S"", time.gmtime()) + f"".{int((time.time()%1)*1000):03d}Z""
",alpha_factory_v1/demos/meta_agentic_agi_v3/agents/agent_base.py,
survived,"    def _estimate_cost(self, prompt_tokens:int, completion_tokens:int) -> float:
        price = float(os.getenv(""ALPHA_USD_PER_M"", 0.01)) # user override
        return ((prompt_tokens+completion_tokens)/1_000_000)*price
",alpha_factory_v1/demos/meta_agentic_agi_v2/agents/agent_base.py,Agent
survived,"    def chat(self, msgs: List[Dict[str,str]], **kw) -> str:
        merged = dict(temperature=self.temperature, max_tokens=self.max_tokens, **kw)
        attempts = 0
        while True:
            GLOBAL_LIMITER.acquire(_str_tkn(json.dumps(msgs)))
            try:
                if self._backend == ""openai"":
                    rsp = self._client.chat.completions.create(model=self._model, messages=msgs, stream=False, **merged)
                    return rsp.choices[0].message.content
                if self._backend == ""anthropic"":
                    rsp = self._client.messages.create(model=self._model, messages=msgs, **merged)
                    return rsp.content[0].text
                if self._backend == ""gemini"":
                    return self._client.generate_content(msgs[-1][""content""], **merged).text
                if self._backend in (""mistral"",""llama""):
                    prompt = """".join(f""<{m['role']}> {m['content']}"" for m in msgs)+""\n<assistant> ""
                    out = self._client(prompt, max_tokens=self.max_tokens, temperature=self.temperature, stop=[""</assistant>""])
                    return out[""choices""][0][""text""].strip()
            except Exception as e:
                attempts += 1
                wait = min(60, 2**attempts)
                LOGGER.warning(""LM error %s; retry in %.1fs"", e, wait)
                time.sleep(wait)
",alpha_factory_v1/demos/meta_agentic_agi/agents/agent_base.py,LMClient
survived,"    def log():
        if not path.exists():
            return ""(no events yet)""
        return flask.escape(path.read_text(""utf-8""))
",alpha_factory_v1/demos/meta_agentic_agi_v3/agents/agent_base.py,
survived,"def emit_notebook(fp:Path=Path(""alpha_asi_world_model_demo.ipynb"")):
    import nbformat as nbf
    nb=nbf.v4.new_notebook()
    nb.cells=[nbf.v4.new_markdown_cell(""# Î±â€‘ASI demo â€“ quickstart""), nbf.v4.new_code_cell(""!python -m alpha_asi_world_model_demo --demo &"")]
    nbf.write(nb,fp); print(""Notebook â†’"",fp)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,
survived,"    def __exit__(self, exc_type, exc, tb):
        if signal:
            resource.setrlimit(resource.RLIMIT_CPU, (resource.RLIM_INFINITY, resource.RLIM_INFINITY))
        return False  # do not suppress
",alpha_factory_v1/demos/meta_agentic_agi_v2/agents/agent_base.py,SafeExec
survived,"    def __enter__(self):
        if resource:
            resource.setrlimit(resource.RLIMIT_CPU, (self.cpu_sec, self.cpu_sec))
            resource.setrlimit(resource.RLIMIT_AS, (self.mem_mb*1024*1024, self.mem_mb*1024*1024))
        return self
",alpha_factory_v1/demos/meta_agentic_agi_v3/agents/agent_base.py,SafeExec
survived,"def serve_lineage(path: pathlib.Path, port: int=8000):
    import flask, threading
    app = flask.Flask(""lineage-viewer"")

    @app.route(""/"")
    def idx():
        return VIEW_HTML

    @app.route(""/log"")
    def log():
        if not path.exists():
            return ""(no events yet)""
        return flask.escape(path.read_text(""utf-8""))

    th = threading.Thread(target=app.run, kwargs=dict(port=port, host=""0.0.0.0"", debug=False))
    th.daemon = True
    th.start()
    LOGGER.info(""Lineage viewer at http://localhost:%d"", port)
    return th
",alpha_factory_v1/demos/meta_agentic_agi_v2/agents/agent_base.py,
survived,"    def _parse(self, ep: str):
        if "":"" not in ep:
            raise ValueError(""Endpoint must be <backend>:<model>"")
        return ep.split("":"",1)
",alpha_factory_v1/demos/meta_agentic_agi_v3/agents/agent_base.py,LMClient
survived,"    def run(self, code: str, func_name: str, *args, **kw):
        loc: Dict[str,Any] = {}
        with self:
            exec(code, {}, loc)
        if func_name not in loc:
            raise AttributeError(f""{func_name} not found"")
        return loc[func_name](*args, **kw)
",alpha_factory_v1/demos/meta_agentic_agi/agents/agent_base.py,SafeExec
survived,"def _sha(text: str) -> str:
    return hashlib.sha256(text.encode()).hexdigest()[:10]
",alpha_factory_v1/demos/meta_agentic_agi_v2/agents/agent_base.py,
survived,"    def read_csv_file(file_path: str) -> pd.DataFrame:
        """"""Read a CSV file into a pandas DataFrame.""""""
        return pd.read_csv(file_path)
",datamax/parser/csv_parser.py,CsvParser
survived,"def test_send_beacon_opt_in() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri()

    with sync_playwright() as p:
        browser = p.chromium.launch()
        page = browser.new_page()
        page.goto(url)
        page.evaluate(
            ""window.OTEL_ENDPOINT='https://example.com';""
            ""window.confirm=() => true;""
            ""navigator.sendBeacon=(...a)=>{window.beacon=a;return true;}""
        )
        page.reload()
        page.wait_for_selector(""#controls"")
        page.click(""text=Share"")
        page.evaluate(""window.dispatchEvent(new Event('beforeunload'))"")
        assert page.evaluate(""Array.isArray(window.beacon)"")
        browser.close()",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_telemetry.py,
survived,"def list_ids(command: ListIdsCommand) -> List[str]:
    """"""List all item IDs in the database, optionally filtered by tags.""""""
    normalized_tags = normalize_tags(command.tags) if command.tags else []

    db = init_db(command.db_path)

    try:
        if normalized_tags:
            placeholders = ', '.join(['?'] * len(normalized_tags))
            query = f""""""
                SELECT id
                FROM POCKET_PICK
                WHERE id IN (
                    SELECT id
                    FROM POCKET_PICK
                    WHERE (
                        SELECT COUNT(*)
                        FROM json_each(tags)
                        WHERE json_each.value IN ({placeholders})
                    ) = ?
                )
                ORDER BY created DESC
                LIMIT ?
            """"""
            params = [*normalized_tags, len(normalized_tags), command.limit]
        else:
            query = """"""
                SELECT id
                FROM POCKET_PICK
                ORDER BY created DESC
                LIMIT ?
            """"""
            params = [command.limit]

        cursor = db.execute(query, params)
        results = [row[0] for row in cursor.fetchall()]
        return results
    except Exception as e:
        logger.error(f""Error listing ids: {e}"")
        raise
    finally:
        db.close()",src/mcp_server_pocket_pick/modules/functionality/list_ids.py,
survived,"def test_list_ids_all(populated_db):
    command = ListIdsCommand(
        limit=10,
        db_path=populated_db,
    )

    results = list_ids(command)

    assert len(results) == 5
    for expected in [
        ""python-1"",
        ""sql-1"",
        ""testing-1"",
        ""regex-1"",
        ""learning-1"",
    ]:
        assert expected in results
",src/mcp_server_pocket_pick/tests/functionality/test_list_ids.py,
survived,"def handle_heartbeat(runners: Dict[str, AgentRunner], env: object) -> None:
    """"""Update the heartbeat timestamp for ``env.sender`` if it exists.""""""
    payload = getattr(env, ""payload"", None)
    if payload and getattr(payload, ""get"", lambda *_: None)(""heartbeat""):
        sender = getattr(env, ""sender"", None)
        if sender in runners:
            r = runners[sender]
            r.last_beat = getattr(env, ""ts"", time.time())
            r.restart_streak = 0
",alpha_factory_v1/backend/orchestrator_utils.py,
survived,"def test_rejects_low_entropy_patch() -> None:
    diff = _read(""red_team.diff"")
    assert not is_patch_safe(diff)",tests/test_patch_entropy.py,
survived,"def _load_insider_patterns() -> list[str]:
    policy_path = _POLICY_DIR / ""deny_insider.rego""
    try:
        text = policy_path.read_text(encoding=""utf-8"")
    except FileNotFoundError:
        return []
    return re.findall(r're_match\(""([^""]+)"",\s*input.text\)', text)
",src/utils/opa_policy.py,
survived,"    def test_create_venv_runs_commands_when_missing(self):
        with mock.patch('subprocess.check_call') as cc:
            venv = Path('/tmp/qsvenv')
            if venv.exists():
                import shutil
                shutil.rmtree(venv)
            quickstart._create_venv(venv)
            pip = quickstart._venv_pip(venv)
            req = Path('alpha_factory_v1/requirements.lock')
            if not req.exists():
                req = Path('alpha_factory_v1/requirements.txt')
            self.assertEqual(cc.call_args_list[0].args[0][:3], [sys.executable, '-m', 'venv'])
            self.assertIn(str(venv), cc.call_args_list[0].args[0])
            called = [call.args[0] for call in cc.call_args_list]
            self.assertIn([str(pip), 'install', '-U', 'pip'], called)
            self.assertIn([str(pip), 'install', '-r', str(req)], called)
",alpha_factory_v1/tests/test_quickstart.py,QuickstartUtilsTest
survived,"def play_episode(agent: MiniMu, render: bool = True, max_steps: int = 500) -> Tuple[List, float]:
    """"""Run a full episode using the agent.""""""
    obs = agent.reset()
    frames: List = []
    total_reward = 0.0
    done = False
    truncated = False
    while not done and not truncated and len(frames) < max_steps:
        if render:
            frames.append(agent.env.render())
        action = agent.act(obs)
        obs, reward, done, truncated, _ = agent.env.step(action)
        total_reward += float(reward)
    if render:
        frames.append(agent.env.render())
    agent.env.close()
    return frames, total_reward
",alpha_factory_v1/demos/muzero_planning/minimuzero.py,
survived,"    def test_queue_job(self):
        self.server, self.thread = _start_server()
        host, port = self.server.server_address
        client = MarketplaceClient(host, port)
        job = {""agent"": ""foo""}
        resp = client.queue_job(job)
        self.assertEqual(resp.status_code, 200)
        self.assertEqual(_Handler.received_path, ""/agent/foo/trigger"")
        self.assertEqual(json.loads(_Handler.received_body.decode()), job)
",alpha_factory_v1/tests/test_marketplace_client.py,MarketplaceClientTest
survived,"    def test_parse_args_defaults(self):
        args = parse_args([])
        sample = Path(
            ""alpha_factory_v1/demos/alpha_agi_marketplace_v1/examples/sample_job.json""
        ).resolve()
        self.assertEqual(Path(args.job_file), sample)
        self.assertEqual(args.host, ""localhost"")
        self.assertEqual(args.port, 8000)
",alpha_factory_v1/tests/test_marketplace_client.py,MarketplaceClientTest
survived,"def load_job(path: str | Path) -> dict[str, Any]:
    """"""Load a job description from a JSON file.""""""
    return json.loads(Path(path).read_text())
",alpha_factory_v1/demos/alpha_agi_marketplace_v1/marketplace.py,
survived,"    def tearDown(self):
        if hasattr(self, ""server""):
            self.server.shutdown()
            self.thread.join()
            self.server.server_close()
",alpha_factory_v1/tests/test_marketplace_client.py,MarketplaceClientTest
survived,"    def test_rest_endpoints(self):
        if not dependencies_available or TestClient is None:
            self.skipTest(""fastapi or dependencies missing"")
        with TestClient(demo.app) as client:
            res = client.get(""/agents"")
            self.assertEqual(res.status_code, 200)
            self.assertIsInstance(res.json(), list)
            self.assertGreaterEqual(len(res.json()), 5)
            client.post(""/command"", json={""cmd"": ""stop""})
",alpha_factory_v1/tests/test_alpha_asi_world_model.py,TestAlphaASIWorldModel
survived,"    def __init__(self):
        self.messages = []
",alpha_factory_v1/tests/test_ping_agent.py,DummyOrchestrator
survived,"    def test_main_success_and_failure(self):
        with mock.patch.multiple(
            preflight,
            check_python=lambda: True,
            check_cmd=lambda cmd: True,
            check_docker_daemon=lambda: True,
            check_docker_compose=lambda: True,
            check_pkg=lambda pkg: True,
            ensure_dir=lambda p: None,
            banner=lambda *a, **k: None,
        ):
            preflight.main()
        with mock.patch.multiple(
            preflight,
            check_python=lambda: False,
            check_cmd=lambda cmd: False,
            check_docker_daemon=lambda: False,
            check_docker_compose=lambda: False,
            check_pkg=lambda pkg: False,
            ensure_dir=lambda p: None,
            banner=lambda *a, **k: None,
        ):
            with self.assertRaises(SystemExit):
                preflight.main()
",alpha_factory_v1/tests/test_preflight.py,PreflightTest
survived,"    def test_alpha_factory_chart(self):
        chart = HELM_DIR / ""alpha-factory"" / ""Chart.yaml""
        values = HELM_DIR / ""alpha-factory"" / ""values.yaml""
        self.check_chart_file(chart)
        self.assertTrue(values.is_file(), ""values.yaml missing for alpha-factory"")
",alpha_factory_v1/tests/test_helm_charts.py,HelmChartTests
survived,"    def test_vector_ram_mode(self):
        self.assertEqual(self.fabric.vector._mode, ""ram"")
        self.fabric.add_memory(""X"", ""data"")
        self.assertEqual(self.fabric.search(""data""), [])
",alpha_factory_v1/tests/test_memory_provider.py,MemoryFabricFallbackTest
survived,"def test_replay_outputs_rows(tmp_path) -> None:
    path = tmp_path / ""log.db""
    path.touch()
    with patch.object(cli.config.CFG, ""ledger_path"", path):
        with patch.object(cli.logging, ""Ledger"") as led_cls, patch.object(cli.time, ""sleep"", return_value=None):
            led = led_cls.return_value
            led.tail.return_value = [SAMPLE_LEDGER_ROW]
            res = CliRunner().invoke(cli.main, [""replay""])
    assert ""a -> b"" in res.output",tests/test_cli_runner_ext.py,
survived,"def main(argv=None) -> None:
    parser = argparse.ArgumentParser(prog=""sprc"")
    subparsers = parser.add_subparsers(dest=""command"")

    download_parser = subparsers.add_parser(""download"")
    download_subparsers = download_parser.add_subparsers(dest=""target"")

    vosk_parser = download_subparsers.add_parser(""vosk"")
    vosk_parser.add_argument(
        ""--url"",
        default=""https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip"",
    )
    vosk_parser.add_argument(""--dir"", default=""model"")

    def _download_vosk(args):
        download_vosk_model(args.url, args.dir)

    vosk_parser.set_defaults(func=_download_vosk)

    args = parser.parse_args(argv)
    if hasattr(args, ""func""):
        args.func(args)
    else:
        parser.print_help()
",speech_recognition/cli.py,
survived,"def wb_run_step_validator(s: Optional[int]) -> Optional[int]:
    if s is None:
        return None
    if not isinstance(s, int):
        raise TypeError(""wb_run_step must be an int"")
    if s < 0:
        raise ValueError(""wb_run_step must be non-negative"")
    return s
",weave/trace_server/validation.py,
survived,"def shuffle(xs):
    arr = xs
    i = len(arr) - 1
    while i > 0:
        j = _now() % (i + 1)
        tmp = arr[i]
        arr[i] = arr[j]
        arr[j] = tmp
        i = i - 1
    return arr
",tests/rosetta/transpiler/Python/concurrent-computing-3.py,
survived,"def someCondition():
    return False",tests/rosetta/transpiler/Python/conditional-structures-7.py,
survived,"def example9():
    while True:
        if True:
            break
        print(""I want out!"")",tests/rosetta/transpiler/Python/conditional-structures-9.py,
survived,"def example1(flag):
    if flag:
        None",tests/rosetta/transpiler/Python/conditional-structures-1.py,
survived,"def fetch_():
    return """"
",tests/rosetta/transpiler/Python/conditional-structures-7.py,
survived,"def lifeString(l):
    out = """"
    y = 0
    while y < l.h:
        x = 0
        while x < l.w:
            if state(l.a, x, y):
                out = out + ""*""
            else:
                out = out + "" ""
            x = x + 1
        out = out + ""\n""
        y = y + 1
    return out
",tests/rosetta/transpiler/Python/conways-game-of-life.py,
survived,"def test_ws_progress_receives_updates() -> None:
    """"""A POST to /simulate should emit progress events over the WebSocket.""""""
    from alpha_factory_v1.demos.alpha_agi_insight_v1.src.interface import api_server

    client = TestClient(api_server.app)
    headers = {""Authorization"": ""Bearer test-token""}

    with client.websocket_connect(""/ws/progress"", headers=headers) as ws:
        resp = client.post(
            ""/simulate"",
            json={""horizon"": 1, ""pop_size"": 2, ""generations"": 1, ""k"": 5.0, ""x0"": 0.0},
            headers=headers,
        )
        assert resp.status_code == 200
        sim_id = resp.json()[""id""]

        data = ws.receive_json()
        assert data[""id""] == sim_id
        assert data[""year""] == 1
        assert isinstance(data[""capability""], float)
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_api_ws_progress.py,
survived,"    def __init__(
        self,
        config: SanskritPoetryEnvConfig,
        server_configs: List[APIServerConfig],
        slurm: bool = True,
        testing: bool = False,
    ):
        super().__init__(config, server_configs, slurm, testing)
        # Create reward function using registry for easy configuration
        self.reward_fn = registry.create(
            {""type"": ""chandas_meter"", ""params"": {""meter"": config.meter}}
        )
        self.iter = 0
",environments/sanskrit_poetry_env.py,SanskritPoetryEnv
survived,"    async def score(self, rollout_group_data: List) -> Optional[ScoredDataGroup]:
        scored = ScoredDataGroup()
        scored[""tokens""] = []
        scored[""masks""] = []
        scored[""scores""] = []
        for traj in rollout_group_data:
            reward = self.reward_fn([traj[-1][""content""]])[0]
            out_dict = tokenize_for_trainer(self.tokenizer, traj)
            scored[""tokens""].append(out_dict[""tokens""])
            scored[""masks""].append(out_dict[""masks""])
            scored[""scores""].append(reward)
        return scored
",environments/sanskrit_poetry_env.py,SanskritPoetryEnv
survived,"def iast_to_slp1(text: str) -> str:
    """"""Convert a string from IAST to SLP1.""""""
    def _replace(match: re.Match) -> str:
        for iast, slp in _IAST_TO_SLP1:
            if match.group(0) == iast:
                return slp
        return match.group(0)

    text = _DIGRAPH_RE.sub(_replace, text)
    return """".join(_SINGLE_CHAR_MAP.get(ch, ch) for ch in text)
",atroposlib/envs/reward_fns/chandas_meter_reward.py,
survived,"    async def arecord(self, agent_name: str, phase: str, payload: Any) -> None:
        """"""Async wrapper around :meth:`record`.""""""
        loop = asyncio.get_running_loop()
        await loop.run_in_executor(None, self.record, agent_name, phase, payload)
",alpha_factory_v1/backend/tracer.py,Tracer
survived,"def Tool(*_args, **_kwargs):
    def decorator(func):
        return func

    return decorator",stubs/openai_agents/__init__.py,
survived,"    def decorator(func):
        return func
",stubs/openai_agents/__init__.py,
survived,"    def __init__(self, *a, **k):
        pass
",tests/test_selfheal_entrypoint_offline.py,DummyButton
survived,"    def click(self, *a, **k):
        pass
",tests/test_selfheal_entrypoint_offline.py,DummyButton
survived,"def wealth_projection(scenario: str) -> None:
    """"""Print projected cash flows for SCENARIO JSON file.""""""
    result = projection_from_json(Path(scenario))
    click.echo(json.dumps(result, indent=2))
",alpha_factory_v1/scripts/wealth_projection.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/cross_join.py,Auto1
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/right_join.py,Order
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/left_join_multi.py,Order
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/right_join.py,Customer
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/group_by_join.py,Customer
survived,"        def _tool(*_a, **_kw):
            def _decorator(func):
                return func

            return _decorator
",tests/test_macro_adk_integration.py,
survived,"    def visit_Expr(self, node: ast.Expr) -> None:
        if (
            isinstance(node.value, ast.Call)
            and isinstance(node.value.func, ast.Name)
            and node.value.func.id == ""print""
        ):
            args = "", "".join(self.convert_expr(a) for a in node.value.args)
            self.emit(f""print({args})"")
        else:
            self.emit(self.convert_expr(node.value))
",tools/any2mochi/py/py2mochi.py,Converter
survived,"    def visit_Module(self, node: ast.Module) -> None:
        # first collect dataclass information
        for stmt in node.body:
            if isinstance(stmt, ast.ClassDef):
                dec_names = [
                    getattr(d, ""id"", None) or getattr(d, ""attr"", None)
                    for d in stmt.decorator_list
                ]
                if ""dataclass"" not in dec_names:
                    continue
                fields: list[tuple[str, str]] = []
                methods: list[ast.FunctionDef] = []
                for sub in stmt.body:
                    if isinstance(sub, ast.AnnAssign) and isinstance(
                        sub.target, ast.Name
                    ):
                        fields.append(
                            (sub.target.id, self.convert_type(sub.annotation))
                        )
                    if isinstance(sub, ast.FunctionDef):
                        methods.append(sub)
                base = stmt.bases[0].id if stmt.bases else None
                self.dataclasses.add(stmt.name)
                if base:
                    self.unions.setdefault(base, []).append((stmt.name, fields))
                else:
                    self.structs[stmt.name] = (fields, methods)

        # emit structs
        for name, (fields, methods) in self.structs.items():
            self.emit(f""type {name} {{"")
            self.indent += 1
            for n, t in fields:
                self.emit(f""{n}: {t}"")
            for m in methods:
                args = [
                    f""{a.arg}: {self.convert_type(a.annotation)}"" for a in m.args.args[1:]
                ]
                ret = self.convert_type(m.returns)
                self.emit(f""fun {m.name}({', '.join(args)}): {ret} {{"")
                self.indent += 1
                for st in m.body:
                    self.visit(st)
                self.indent -= 1
                self.emit(""}"")
            self.indent -= 1
            self.emit(""}"")

        # emit unions
        for base, variants in self.unions.items():
            self.emit(f""type {base} ="")
            self.indent += 1
            for i, (name, fields) in enumerate(variants):
                field_str = "", "".join(f""{n}: {t}"" for n, t in fields)
                if field_str:
                    self.emit(
                        f""{name}({field_str})"" + ("" |"" if i < len(variants) - 1 else """")
                    )
                else:
                    self.emit(f""{name} {{}}"" + ("" |"" if i < len(variants) - 1 else """"))
            self.indent -= 1

        # now handle remaining statements
        for stmt in node.body:
            if (
                isinstance(stmt, ast.If)
                and isinstance(stmt.test, ast.Compare)
                and isinstance(stmt.test.left, ast.Name)
                and stmt.test.left.id == ""__name__""
            ):
                continue
            if isinstance(stmt, ast.FunctionDef) and stmt.name in {""_get"", ""_fetch"", ""_sort_key"", ""_load"", ""_save""}:
                continue
            if isinstance(stmt, ast.FunctionDef) and stmt.name == ""main"":
                for sub in stmt.body:
                    if isinstance(sub, ast.Global):
                        continue
                    if (
                        isinstance(sub, ast.Expr)
                        and isinstance(sub.value, ast.Call)
                        and isinstance(sub.value.func, ast.Name)
                        and sub.value.func.id.startswith(""test_"")
                    ):
                        continue
                    self.visit(sub)
                continue
            if isinstance(stmt, ast.FunctionDef):
                self.visit(stmt)
                continue
            if isinstance(stmt, ast.ClassDef):
                continue
            if isinstance(stmt, ast.Assign):
                self.visit(stmt)
",tools/any2mochi/py/py2mochi.py,Converter
survived,"    def visit_Assert(self, node: ast.Assert) -> None:
        expr = self.convert_expr(node.test)
        self.emit(f""expect {expr}"")
",tools/any2mochi/py/py2mochi.py,Converter
survived,"    def visit_For(self, node: ast.For) -> None:
        target = self.convert_expr(node.target)
        iter_ = self.convert_expr(node.iter)
        self.emit(f""for {target} in {iter_} {{"")
        self.indent += 1
        for stmt in node.body:
            self.visit(stmt)
        self.indent -= 1
        self.emit(""}"")
",tools/any2mochi/py/py2mochi.py,Converter
survived,"    def emit(self, line: str) -> None:
        self.lines.append(""  "" * self.indent + line)
",tools/any2mochi/py/py2mochi.py,Converter
survived,"        def clear_tool_stats_route() -> dict[str, str]:
            self._clear_tool_stats()
            return {""status"": ""cleared""}
",src/serena/dashboard.py,SerenaDashboardAPI
survived,"    def __enter__(self):
        return self
",tests/test_agent_experience_entrypoint.py,DummyBlocks
survived,"def test_main_ollama(monkeypatch: pytest.MonkeyPatch) -> None:
    base = _run_main(monkeypatch, openai_key="""", base_url=""http://ollama"")
    assert base == ""http://ollama""",tests/test_agent_experience_entrypoint.py,
deleted,"    def validate_validation_dataset(cls, dataset_name: str | None) -> str | None:
        if dataset_name is None:
            return None
        try:
            url = f""https://huggingface.co/api/datasets/{dataset_name}/tree/main""
            response = requests.get(url, timeout=5)
            if response.status_code != 200:
                raise ValueError()
            return dataset_name
        except Exception:
            raise ValueError(
                f""Dataset {dataset_name} is not a valid, public Hugging Face dataset. Please check the URL and try again. Your dataset name should be in the format <username>/<dataset_name>"",
            )
",phosphobot/phosphobot/am/base.py,TrainingRequest
survived,"        async def policy(self, obs, _ctx):  # type: ignore[override]
            params = obs if isinstance(obs, dict) else {}
            return await run_insight_search(
                episodes=int(params.get(""episodes"", 5)),
                target=int(params.get(""target"", 3)),
                model=params.get(""model""),
                rewriter=params.get(""rewriter""),
                sectors=params.get(""sectors""),
            )
",alpha_factory_v1/demos/alpha_agi_insight_v0/openai_agents_bridge.py,InsightAgent
survived,"    def test_bridge_fallback(self) -> None:
        result = subprocess.run(
            [
                sys.executable,
                ""-m"",
                ""alpha_factory_v1.demos.alpha_agi_insight_v0.openai_agents_bridge"",
                ""--episodes"",
                ""1"",
                ""--target"",
                ""2"",
                ""--model"",
                DEFAULT_MODEL_NAME,
            ],
            capture_output=True,
            text=True,
        )
        self.assertEqual(result.returncode, 0, result.stderr)
        self.assertIn(""demo"", result.stdout.lower())
",tests/test_alpha_agi_insight_bridge.py,TestAlphaAgiInsightBridge
survived,"def test_call_summary_editable(client):
    @weave.op()
    def my_op():
        call = call_context.get_current_call()
        call.summary[""foo""] = 1
        call.summary[""bar""] = 2
        return ""done""

    my_op()
    calls = list(client.get_calls())
    assert len(calls) == 1
    summary = calls[0].summary
    assert summary[""foo""] == 1
    assert summary[""bar""] == 2
    assert summary[RESERVED_SUMMARY_STATUS_COUNTS_KEY][tsi.TraceStatus.SUCCESS] == 1",tests/trace/test_current_call.py,
survived,"    def drop_path(self):
        ''' Removes a document from a path starting from this node (leaf) upwards '''
        node = self
        while node is not None:
            node.customers -= 1
            if node.customers == 0 and node.parent is not None:
                node.parent.remove(node)
            node = node.parent
",src/hlda/sampler.py,NCRPNode
survived,"    def is_leaf(self):
        ''' Check if this node is a leaf node '''
        return self.level == self.num_levels-1
",src/hlda/sampler.py,NCRPNode
survived,"    def sample_path(self, d):

        # define a path starting from the leaf node of this doc
        path = np.zeros(self.num_levels, dtype=object)
        node = self.document_leaves[d]
        for level in range(self.num_levels-1, -1, -1): # e.g. [3, 2, 1, 0] for num_levels = 4
            path[level] = node
            node = node.parent

        # remove this document from the path, deleting empty nodes if necessary
        self.document_leaves[d].drop_path()

        ############################################################
        # calculates the prior p(c_d | c_{-d}) in eq. (4)
        ############################################################

        node_weights = {}
        self.calculate_ncrp_prior(node_weights, self.root_node, 0.0)

        ############################################################
        # calculates the likelihood p(w_d | c, w_{-d}, z) in eq. (4)
        ############################################################

        level_word_counts = {}
        for level in range(self.num_levels):
            level_word_counts[level] = {}
        doc_levels = self.levels[d]
        doc = self.corpus[d]

        # remove doc from path
        for n in range(len(doc)): # for each word in the doc

            # count the word at each level
            level = doc_levels[n]
            w = doc[n]
            if w not in level_word_counts[level]:
                level_word_counts[level][w] = 1
            else:
                level_word_counts[level][w] += 1

            # remove word count from the node at that level
            level_node = path[level]
            level_node.word_counts[w] -= 1
            level_node.total_words -= 1
            assert level_node.word_counts[w] >= 0
            assert level_node.total_words >= 0

        self.calculate_doc_likelihood(node_weights, level_word_counts)

        ############################################################
        # pick a new path
        ############################################################

        nodes = np.array(list(node_weights.keys()))
        weights = np.array([node_weights[node] for node in nodes])
        weights = np.exp(weights - np.max(weights)) # normalise so the largest weight is 1
        weights = weights / np.sum(weights)

        choice = self.random_state.multinomial(1, weights).argmax()
        node = nodes[choice]

        # if we picked an internal node, we need to add a new path to the leaf
        if not node.is_leaf():
            node = node.get_new_leaf()

        # add the doc back to the path
        node.add_path()                     # add a customer to the path
        self.document_leaves[d] = node      # store the leaf node for this doc

        # add the words
        for level in range(self.num_levels-1, -1, -1): # e.g. [3, 2, 1, 0] for num_levels = 4
            word_counts = level_word_counts[level]
            for w in word_counts:
                node.word_counts[w] += word_counts[w]
                node.total_words += word_counts[w]
            node = node.parent
",src/hlda/sampler.py,HierarchicalLDA
survived,"def test_attention_paged_decode_matches_full_prefill():
    B = Axis(""batch"", 2)
    Pos = Axis(""position"", 4)
    Embed = Axis(""embed"", 16)

    cfg = AttentionConfig(Embed=Embed, num_heads=2, num_kv_heads=2, rope=None, attn_backend=AttentionBackend.VANILLA)
    attn_key, x_key = jrandom.split(jrandom.PRNGKey(0))
    attn = Attention.init(cfg, key=attn_key)

    x = hax.random.normal(x_key, (B, Pos, Embed)) * 0.2
    full_out = attn(x, AttentionMask.causal(), key=jrandom.PRNGKey(1))

    cache = _build_page_cache(cfg, B, Pos)
    pos_ids = hax.arange(Pos, dtype=jnp.int32)
    decode_out, _ = _jit_paged_decode(attn, x, pos_ids, cache)

    assert_trees_all_close(full_out.array, decode_out.array, atol=1e-4, rtol=1e-4)
",tests/test_attention.py,
survived,"def test_quickstart_offline() -> None:
    repo = Path(__file__).resolve().parents[1]
    dist = repo / ""alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/dist""
    pdf_src = repo / ""docs/insight_browser_quickstart.pdf""
    pdf_dest = dist / ""insight_browser_quickstart.pdf""
    if not pdf_dest.exists() and pdf_src.exists():
        pdf_dest.write_bytes(pdf_src.read_bytes())

    url = (dist / ""index.html"").as_uri()
    try:
        with sync_playwright() as p:
            browser = p.chromium.launch()
            context = browser.new_context()
            page = context.new_page()
            page.goto(url)
            page.wait_for_selector(""#controls"")
            page.wait_for_function(""navigator.serviceWorker.ready"")
            page.reload()
            page.wait_for_function(""navigator.serviceWorker.controller !== null"")
            assert page.evaluate(""(await fetch('insight_browser_quickstart.pdf')).ok"")
            context.set_offline(True)
            page.reload()
            page.wait_for_selector(""#controls"")
            assert page.evaluate(""(await fetch('insight_browser_quickstart.pdf')).ok"")
            browser.close()
    except PlaywrightError as exc:
        pytest.skip(f""Playwright browser not installed: {exc}"")",tests/test_quickstart_offline.py,
survived,"            async def send_transaction(self, tx: object, *args: object) -> None:
                if raise_err:
                    raise RuntimeError(""fail"")
                captured[""root""] = tx.instructions[0].data.decode()
",tests/test_merkle_broadcast.py,TestMerkleBroadcast.DummyClient
survived,"    def path_raw_retro_route():
        args = request.args
        currtime = int(args[""currtime""])
        data = rs.path_raw_retro(args[""origin""], args[""dest""], currtime)
        return Response(data, mimetype=""text/plain"")
",pygs/graphserver/ext/routeserver/routeserver.py,
survived,"    def vertices():
        return Response(rs.vertices(), mimetype=""text/plain"")
",pygs/graphserver/ext/routeserver/routeserver.py,
survived,"def _softmax(x: np.ndarray) -> np.ndarray:
    e = np.exp(x - float(np.max(x)))
    return e / (e.sum() + 1e-12)
",src/evaluators/novelty.py,
survived,"    def divergence(self, text: str) -> float:
        vec = embed(text)
        if self.count == 0:
            return 1.0
        p = _softmax(vec[0])
        q = _softmax(self.mean)
        kl = float(np.sum(p * np.log((p + 1e-12) / (q + 1e-12))))
        return kl",src/evaluators/novelty.py,NoveltyIndex
survived,"    def test_runtime_port_env(self, monkeypatch: ""pytest.MonkeyPatch"") -> None:
        """"""AgentRuntime receives AGENTS_RUNTIME_PORT.""""""
        import importlib
        import sys
        import types

        captured: dict[str, int] = {}

        class DummyRuntime:
            def __init__(self, *a: object, port: int = 5001, **_k: object) -> None:
                captured[""port""] = port

            def register(self, *_a: object, **_k: object) -> None:
                pass

            def run(self) -> None:
                pass

        stub = types.ModuleType(""openai_agents"")
        stub.Agent = object
        stub.AgentRuntime = DummyRuntime
        stub.OpenAIAgent = object

        def _tool(*_a: object, **_k: object) -> Callable[[object], object]:
            def dec(f: object) -> object:
                return f

            return dec

        stub.Tool = _tool
        monkeypatch.setitem(sys.modules, ""openai_agents"", stub)
        monkeypatch.delitem(sys.modules, ""agents"", raising=False)
        monkeypatch.setenv(""AGENTS_RUNTIME_PORT"", ""6101"")

        mod = importlib.import_module(""alpha_factory_v1.demos.aiga_meta_evolution.alpha_opportunity_stub"")
        importlib.reload(mod)
        mod.main([])
        self.assertEqual(captured[""port""], 6101)
",tests/test_alpha_opportunity_stub.py,TestAlphaOpportunityStub
survived,"def main() -> None:
    if len(sys.argv) != 2:
        print(f""Usage: {Path(sys.argv[0]).name} <wheel>"", file=sys.stderr)
        raise SystemExit(1)
    wheel = Path(sys.argv[1])
    if not wheel.is_file():
        print(f""Wheel not found: {wheel}"", file=sys.stderr)
        raise SystemExit(1)
    if verify(wheel):
        print(f""OK: {wheel}"")
        raise SystemExit(0)
    print(f""FAILED: {wheel}"", file=sys.stderr)
    raise SystemExit(2)
",alpha_factory_v1/scripts/verify_wheel_sig.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q22.py,Auto2
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q2.py,Nation
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q5.py,Auto2
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q11.py,Supplier
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q7.py,Order
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q13.py,Auto2
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q2.py,Part
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q11.py,Auto1
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q4.py,Lineitem
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q8.py,Order
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q19.py,Lineitem
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q20.py,Nation
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q10.py,Customer
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q9.py,Supplier
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q7.py,Supplier
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q21.py,Auto1
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q25.py,Auto9
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q29.py,Auto2
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q33.py,Auto7
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q9.py,Auto5
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q31.py,Auto3
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q30.py,Auto3
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q24.py,Auto2
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/job/compiler/py/q12.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q16.py,Auto2
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q22.py,Auto2
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q25.py,Auto7
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q30.py,Auto9
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q18.py,Auto6
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q7.py,Auto1
survived,"def _sort_key(k):
    if hasattr(k, ""__dataclass_fields__""):
        return str(k)
    if isinstance(k, list):
        return tuple((_sort_key(x) for x in k))
    if isinstance(k, tuple):
        return tuple((_sort_key(x) for x in k))
    if isinstance(k, dict):
        return str(k)
    return k
",tests/dataset/job/compiler/py/q13.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q20.py,Auto7
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q16.py,Auto1
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q19.py,Auto3
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q28.py,Auto8
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q15.py,Auto6
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q20.py,Auto8
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q32.py,Auto3
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q27.py,Auto6
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q16.py,Auto4
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q14.py,Auto5
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q29.py,Auto9
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q33.py,Auto1
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/job/compiler/py/q20.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q19.py,Auto7
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q22.py,Auto5
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q28.py,Auto4
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q21.py,Auto5
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q33.py,Auto1
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/job/compiler/py/q33.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q33.py,Auto6
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q22.py,Auto3
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q13.py,Auto2
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q16.py,Auto10
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q21.py,Auto10
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/job/compiler/py/q27.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q28.py,Auto12
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q4.py,Auto5
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q31.py,Auto1
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q23.py,Auto8
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q29.py,Auto1
survived,"def test_Q13_finds_earliest_German_movie_info():
    assert result == Auto1(
        release_date=""1997-05-10"", rating=""6.0"", german_movie=""Alpha""
    )
",tests/dataset/job/compiler/py/q13.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q19.py,Auto6
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q16.py,Auto9
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q1.py,Auto2
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q31.py,Auto1
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/job/compiler/py/q31.py,
survived,"def _min(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""min() expects list or group"")
    vals = [it for it in v if it is not None]
    if not vals:
        return 0
    return min(vals)
",tests/dataset/job/compiler/py/q32.py,
survived,"def test_Q33_finds_linked_TV_series_with_low_rated_sequel():
    assert result == [
        Auto1(
            first_company=""US Studio"",
            second_company=""GB Studio"",
            first_rating=""7.0"",
            second_rating=""2.5"",
            first_movie=""Series A"",
            second_movie=""Series B"",
        )
    ]
",tests/dataset/job/compiler/py/q33.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q7.py,Auto9
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q12.py,Auto3
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q24.py,Auto13
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q1.py,Auto4
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q24.py,Auto6
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q21.py,Auto8
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q28.py,Auto5
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q17.py,Auto7
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q29.py,Auto12
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q19.py,Auto1
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q28.py,Auto3
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q33.py,Auto3
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q23.py,Auto8
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q25.py,Auto2
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q13.py,Auto7
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q18.py,Auto7
survived,"def _min(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""min() expects list or group"")
    vals = [it for it in v if it is not None]
    if not vals:
        return 0
    return min(vals)
",tests/dataset/job/compiler/py/q26.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q33.py,Auto9
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q24.py,Auto8
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q15.py,Auto9
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q28.py,Auto7
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q26.py,CustomerDemo
survived,"def _q0():
    _groups = {}
    _order = []
    for r in catalog_returns:
        _k = r.state
        _ks = str(_k)
        g = _groups.get(_ks)
        if not g:
            g = _Group(_k)
            _groups[_ks] = g
            _order.append(_ks)
        g.Items.append(r)
    _items1 = [_groups[k] for k in _order]
    return [
        Auto1(
            state=g.key,
            avg_amt=(
                sum([x.amt for x in g]) / len([x.amt for x in g])
                if [x.amt for x in g]
                else 0
            ),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q81.py,
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q81.py,_Group
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q1.py,Auto3
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q34.py,DateDim
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q96.py,StoreSale
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q11.py,Customer
survived,"def _q0():
    _groups = {}
    _order = []
    for j in joined:
        _k = Auto3(i_item_id=j.i_item_id, i_item_desc=j.i_item_desc, s_state=j.s_state)
        _ks = str(_k)
        g = _groups.get(_ks)
        if not g:
            g = _Group(_k)
            _groups[_ks] = g
            _order.append(_ks)
        g.Items.append(j)
    _items1 = [_groups[k] for k in _order]
    return [
        Auto1(
            i_item_id=g.key[""i_item_id""],
            i_item_desc=g.key[""i_item_desc""],
            s_state=g.key[""s_state""],
            store_sales_quantitycount=len([_ for _ in g]),
            store_sales_quantityave=(
                sum([x.qty for x in g]) / len([x.qty for x in g])
                if [x.qty for x in g]
                else 0
            ),
            store_sales_quantitystdev=0.0,
            store_sales_quantitycov=0.0,
            store_returns_quantitycount=len([_ for _ in g]),
            store_returns_quantityave=(
                sum([x.ret for x in g]) / len([x.ret for x in g])
                if [x.ret for x in g]
                else 0
            ),
            store_returns_quantitystdev=0.0,
            store_returns_quantitycov=0.0,
            catalog_sales_quantitycount=len([_ for _ in g]),
            catalog_sales_quantityave=(
                sum([x.csq for x in g]) / len([x.csq for x in g])
                if [x.csq for x in g]
                else 0
            ),
            catalog_sales_quantitystdev=0.0,
            catalog_sales_quantitycov=0.0,
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q17.py,
survived,"def _avg(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""avg() expects list or group"")
    if not v:
        return 0
    s = 0.0
    for it in v:
        if isinstance(it, (int, float)):
            s += float(it)
        else:
            raise Exception(""avg() expects numbers"")
    return s / len(v)
",tests/dataset/tpc-ds/compiler/py/q39.py,
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q71.py,_Group
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q2.py,WebSale
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q33.py,CatalogSale
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q9.py,Reason
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q88.py,TimeDim
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q72.py,CatalogSale
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q80.py,StoreSale
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q21.py,Auto4
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q21.py,Auto3
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q24.py,Customer
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q91.py,CustomerDemographic
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q20.py,DateDim
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q8.py,Customer
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q29.py,Store
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q22.py,Auto1
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q22.py,
survived,"def _sum(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""sum() expects list or group"")
    s = 0.0
    for it in v:
        if it is None:
            continue
        if isinstance(it, (int, float)):
            s += float(it)
        else:
            raise Exception(""sum() expects numbers"")
    return s
",tests/dataset/tpc-ds/compiler/py/q76.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q77.py,Auto3
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q8.py,StoreSale
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q27.py,_Group
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q51.py,Auto3
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q33.py,Item
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q91.py,CatalogReturn
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q42.py,Auto1
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q1.py,
survived,"def _q1():
    _groups = {}
    _order = []
    for cs in catalog_sales:
        _k = Auto1(customer_sk=cs.cs_bill_customer_sk, item_sk=cs.cs_item_sk)
        _ks = str(_k)
        g = _groups.get(_ks)
        if not g:
            g = _Group(_k)
            _groups[_ks] = g
            _order.append(_ks)
        g.Items.append(cs)
    _items1 = [_groups[k] for k in _order]
    return [
        Auto1(customer_sk=g.key[""customer_sk""], item_sk=g.key[""item_sk""])
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q97.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q1.py,DateDim
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q27.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q50.py,StoreSale
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q8.py,DateDim
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q54.py,Auto2
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q50.py,Store
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q54.py,Auto4
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q32.py,DateDim
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q34.py,
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q98.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q8.py,CustomerAddres
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q77.py,_Group
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q7.py,Item
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q93.py,Auto1
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q26.py,CustomerDemographic
survived,"def test_TPCDS_Q68_simplified():
    assert result == 68
",tests/dataset/tpc-ds/compiler/py/q68.py,
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q16.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q19.py,Auto2
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q35.py,CustomerDemographic
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q90.py,WebSale
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q76.py,Auto2
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q73.py,Store
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q79.py,StoreSale
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q13.py,CustomerAddres
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q27.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q94.py,CustomerAddress
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q65.py,_Group
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q38.py,WebSale
survived,"def _avg(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""avg() expects list or group"")
    if not v:
        return 0
    s = 0.0
    for it in v:
        if isinstance(it, (int, float)):
            s += float(it)
        else:
            raise Exception(""avg() expects numbers"")
    return s / len(v)
",tests/dataset/tpc-ds/compiler/py/q32.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q14.py,StoreSale
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q9.py,Auto1
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q16.py,DateDim
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q30.py,CustomerAddres
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q12.py,_Group
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q48.py,CustomerAddres
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q1.py,DateDim
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q30.py,WebReturn
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q13.py,HouseholdDemographic
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q99.py,ShipMode
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q93.py,StoreSale
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q77.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q39.py,DateDim
survived,"def _q8():
    _src = web_sales
    _rows = _query(
        _src,
        [{""items"": date_dim, ""on"": lambda ws, d: d.d_date_sk == ws.ws_sold_date_sk}],
        {""select"": lambda ws, d: (ws, d)},
    )
    _groups = _group_by(_rows, lambda ws, d: ws.ws_web_page_sk)
    _items9 = _groups
    return [
        Auto6(
            wp_web_page_sk=g.key,
            sales=_sum([x[0].ws_ext_sales_price for x in g]),
            profit=_sum([x[0].ws_net_profit for x in g]),
        )
        for g in _items9
    ]
",tests/dataset/tpc-ds/compiler/py/q77.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q25.py,DateDim
survived,"def test_TPCDS_Q70_simplified():
    assert result == [
        Auto1(s_state=""CA"", s_county=""Orange"", total_sum=15.0),
        Auto1(s_state=""TX"", s_county=""Travis"", total_sum=20.0),
    ]
",tests/dataset/tpc-ds/compiler/py/q70.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q90.py,TimeDim
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q95.py,Auto2
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q36.py,Item
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q7.py,CustomerDemographic
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q12.py,
survived,"def count_range(ssales, tdim, hour, start_min, end_min):
    total = 0.0
    for ss in ssales:
        for t in tdim:
            if (
                (
                    (
                        ss.get(""sold_time_sk"")
                        if isinstance(ss, dict)
                        else getattr(ss, ""sold_time_sk"")
                    )
                    == (
                        t.get(""time_sk"")
                        if isinstance(t, dict)
                        else getattr(t, ""time_sk"")
                    )
                    and (t.get(""hour"") if isinstance(t, dict) else getattr(t, ""hour""))
                    == hour
                )
                and (t.get(""minute"") if isinstance(t, dict) else getattr(t, ""minute""))
                >= start_min
            ) and (
                t.get(""minute"") if isinstance(t, dict) else getattr(t, ""minute"")
            ) < end_min:
                total = total + (
                    ss.get(""qty"") if isinstance(ss, dict) else getattr(ss, ""qty"")
                )
    return total
",tests/dataset/tpc-ds/compiler/py/q88.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q6.py,Customer
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q55.py,DateDim
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q70.py,Auto1
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q94.py,CustomerAddres
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q88.py,Store
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q64.py,StoreSale
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q91.py,CallCenter
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q71.py,Auto1
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q25.py,Item
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q70.py,_Group
survived,"def _q0():
    _src = catalog_sales
    _rows = _query(
        _src,
        [
            {""items"": item, ""on"": lambda cs, i: cs.cs_item_sk == i.i_item_sk},
            {
                ""items"": date_dim,
                ""on"": lambda cs, i, d: cs.cs_sold_date_sk == d.d_date_sk,
            },
        ],
        {
            ""select"": lambda cs, i, d: (cs, i, d),
            ""where"": lambda cs, i, d: (
                i.i_category in [""A"", ""B"", ""C""] and d.d_date >= ""2000-02-01""
            )
            and d.d_date <= ""2000-03-02"",
        },
    )
    _groups = _group_by(
        _rows,
        lambda cs, i, d: Auto3(
            id=i.i_item_id,
            desc=i.i_item_desc,
            cat=i.i_category,
            _class=i.i_class,
            price=i.i_current_price,
        ),
    )
    _items1 = _groups
    return [
        Auto2(
            i_item_id=g.key[""id""],
            i_item_desc=g.key[""desc""],
            i_category=g.key[""cat""],
            i_class=g.key[""_class""],
            i_current_price=g.key[""price""],
            itemrevenue=sum([x[0].cs_ext_sales_price for x in g]),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q20.py,
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q15.py,
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q10.py,_Group
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q97.py,Auto1
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q45.py,_Group
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q30.py,_Group
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q25.py,StoreSale
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q35.py,_Group
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q43.py,Store
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q40.py,CatalogReturn
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q17.py,_Group
survived,"def _sort_key(k):
    if hasattr(k, ""__dataclass_fields__""):
        return str(k)
    if isinstance(k, list):
        return tuple((_sort_key(x) for x in k))
    if isinstance(k, tuple):
        return tuple((_sort_key(x) for x in k))
    if isinstance(k, dict):
        return str(k)
    return k
",tests/dataset/tpc-ds/compiler/py/q49.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q19.py,Auto1
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q26.py,CatalogSale
survived,"def distinct(xs):
    out = []
    for x in xs:
        if not x in out:
            out = out + [x]
    return out
",tests/dataset/tpc-ds/compiler/py/q16.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q7.py,Item
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q29.py,_Group
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q75.py,_Group
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q19.py,Auto2
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q3.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q77.py,WebSale
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q95.py,WebReturn
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q75.py,_Group
survived,"def test_TPCDS_Q60_simplified():
    assert result == 60
",tests/dataset/tpc-ds/compiler/py/q60.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q2.py,CatalogSale
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q31.py,WebSale
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q8.py,_Group
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q15.py,CustomerAddress
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q26.py,Item
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q34.py,Customer
survived,"def cumulative(xs):
    out = []
    acc = 0.0
    for x in xs:
        acc = acc + x.price
        out = out + [Auto1(date=x.date, cum=acc)]
    return out
",tests/dataset/tpc-ds/compiler/py/q51.py,
survived,"def test_TPCDS_Q65_simplified():
    assert result == 65
",tests/dataset/tpc-ds/compiler/py/q65.py,
survived,"def test_TPCDS_Q97_overlap():
    assert (result[""store_only""] == 1 and result[""catalog_only""] == 1) and result[
        ""store_and_catalog""
    ] == 1
",tests/dataset/tpc-ds/compiler/py/q97.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q73.py,DateDim
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q38.py,CatalogSale
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q23.py,Auto1
survived,"def _q0():
    _src = store_sales
    _rows = _query(
        _src,
        [
            {""items"": date_dim, ""on"": lambda ss, d: ss.ss_sold_date_sk == d.d_date_sk},
            {""items"": item, ""on"": lambda ss, d, i: ss.ss_item_sk == i.i_item_sk},
        ],
        {
            ""select"": lambda ss, d, i: (ss, d, i),
            ""where"": lambda ss, d, i: d.d_year == 2000,
        },
    )
    _groups = _group_by(
        _rows, lambda ss, d, i: Auto1(item_sk=i.i_item_sk, date_sk=d.d_date_sk)
    )
    _items1 = _groups
    _items1 = [g for g in _items1 if len(g) > 4]
    return [g.key[""item_sk""] for g in _items1]
",tests/dataset/tpc-ds/compiler/py/q23.py,
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q3.py,_Group
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q98.py,
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q93.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q75.py,CatalogSale
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q13.py,Auto1
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q37.py,Item
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q9.py,Auto1
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q95.py,WebSite
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q22.py,Inventory
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q25.py,StoreSale
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q46.py,CustomerAddres
survived,"def _sum(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""sum() expects list or group"")
    s = 0.0
    for it in v:
        if it is None:
            continue
        if isinstance(it, (int, float)):
            s += float(it)
        else:
            raise Exception(""sum() expects numbers"")
    return s
",tests/dataset/tpc-ds/compiler/py/q91.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q39.py,Auto5
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q76.py,WebSale
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q52.py,Item
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q71.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q87.py,CatalogSale
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q90.py,TimeDim
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q30.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q12.py,Auto1
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q54.py,_Group
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q39.py,Inventory
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q77.py,Auto3
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q99.py,Warehouse
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q15.py,Auto1
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q95.py,CustomerAddres
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q28.py,Auto1
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q34.py,Auto3
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q2.py,
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q15.py,
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q37.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q38.py,Customer
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q14.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q99.py,CatalogSale
survived,"def _sum(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""sum() expects list or group"")
    s = 0.0
    for it in v:
        if it is None:
            continue
        if isinstance(it, (int, float)):
            s += float(it)
        else:
            raise Exception(""sum() expects numbers"")
    return s
",tests/dataset/tpc-ds/compiler/py/q4.py,
survived,"def test_TPCDS_Q59_simplified():
    assert result == [Auto1(s_store_id1=1, ratio=1.5)]
",tests/dataset/tpc-ds/compiler/py/q59.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q29.py,Auto2
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q25.py,Auto1
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q21.py,Inventory
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q35.py,StoreSale
survived,"def test_workers_in_sandbox_iframes() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri()

    with sync_playwright() as p:
        browser = p.chromium.launch()
        page = browser.new_page()
        page.goto(url)
        page.wait_for_selector(""#controls"")
        page.wait_for_function(""document.querySelectorAll('iframe[sandbox]').length >= 2"")
        frames = page.query_selector_all(""iframe[sandbox]"")
        assert len(frames) >= 2
        for f in frames:
            assert f.get_attribute(""sandbox"") == ""allow-scripts""
        browser.close()",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_browser_ui.py,
survived,"    def __call__(cls, *args, **kwargs):
        # Create the instance without invoking ``__init__`` so we can inject
        # the base initialization beforehand.
        obj = cls.__new__(cls, *args, **kwargs)
        if isinstance(obj, cls):
            # ``_base_init`` sets attributes that should exist on all modules
            # even when a subclass forgets to call ``super().__init__``.
            Module._base_init(obj)
            cls.__init__(obj, *args, **kwargs)

            # Guarantee existence of critical attributes if ``__init__`` didn't
            # create them.
            if not hasattr(obj, ""callbacks""):
                obj.callbacks = []
            if not hasattr(obj, ""history""):
                obj.history = []
        return obj
",dspy/primitives/program.py,ProgramMeta
survived,"    def __init__(self) -> None:
        self._data: dict[str, any] = {}
",custom_components/gree/config_flow.py,ConfigFlow
survived,"    def __init__(self, config_entry: config_entries.ConfigEntry) -> None:
        self.config_entry = config_entry
",custom_components/gree/config_flow.py,OptionsFlowHandler
survived,"    def _validate_requirements(self, errors: List[str]) -> None:
        req_path = self.bundle_dir / ""requirements.txt""
        if not req_path.exists():
            errors.append(""requirements.txt missing"")
            return
        for line in req_path.read_text().splitlines():
            line = line.strip()
            if not line or line.startswith(""#""):
                continue
            if ""=="" not in line:
                errors.append(f""unpinned requirement: {line}"")
",src/meta_agent/bundle_validator.py,BundleValidator
survived,"def apply_unicode_escape_map(code: str, mapping: Dict[str, str]) -> str:
    """"""Replace characters in ``code`` with their escape sequences.""""""
    if not mapping:
        return code
    pattern = ""["" + """".join(re.escape(c) for c in mapping) + ""]""
    return re.sub(pattern, lambda m: mapping[m.group(0)], code)
",src/flynt/utils/utils.py,
survived,"def main() -> None:
    args = _parse_args()
    os.environ[""DEMO_ASSETS_REV""] = args.revision
    from data_feeds import OFFLINE_URLS  # noqa: E402

    offline_dir = Path(__file__).parent / ""offline_samples""
    offline_dir.mkdir(exist_ok=True)

    for name, url in OFFLINE_URLS.items():
        dest = offline_dir / name
        tmp = dest.with_suffix("".tmp"")
        print(f""Downloading {url} -> {dest}"")
        try:
            with urlopen(url, timeout=10) as r, open(tmp, ""wb"") as f:
                f.write(r.read())
            os.replace(tmp, dest)
        except Exception as exc:  # pragma: no cover - network errors
            if tmp.exists():
                tmp.unlink()
            print(f""Failed to download {url}: {exc}"", file=sys.stderr)
            raise SystemExit(1) from exc
",alpha_factory_v1/demos/macro_sentinel/refresh_offline_data.py,
deleted,"    def message_dicts(self) -> List[dict[str, str | None]]:
        return [{""role"": m.role, ""content"": m.content} for m in self._messages]
",libs/core/kiln_ai/adapters/chat/chat_formatter.py,ChatFormatter
deleted,"    def messages(self) -> List[ChatMessage]:
        return list(self._messages)
",libs/core/kiln_ai/adapters/chat/chat_formatter.py,ChatFormatter
survived,"    def __init__(self, request: Request) -> None:
        self.request = request
",src/graphql_server/webob/views.py,WebobHTTPRequestAdapter
survived,"    def test_runtime_list_agents(self):
        runtime = MagicMock()
        with patch.object(bridge, ""AgentRuntime"", return_value=runtime) as rt_cls, \
                patch.object(bridge.requests, ""get"", return_value=DummyResponse([""a""])) as get:
            agent = bridge.InspectorAgent()
            rt = bridge.AgentRuntime(api_key=None)
            rt.register(agent)

            rt_cls.assert_called_once_with(api_key=None)
            runtime.register.assert_called_once_with(agent)

            result = asyncio.run(bridge.list_agents())
        get.assert_called_once_with(""http://localhost:7860/agents"", timeout=5)
        self.assertIsInstance(result, list)
",tests/test_inspector_bridge.py,TestInspectorAgent
survived,"def test_mongodb_connection_uri_generation():
    db = MongoDBDatabase(
        host='localhost',
        user='user name',
        password='p@ssword',
        database='mydb',
        port=1234,
        replicaSet='rs0'
    )
    mock_client = MagicMock()
    with patch('pymongo.MongoClient', return_value=mock_client) as mock_mc:
        db.connect()
        mock_mc.assert_called_once()
        uri = mock_mc.call_args.args[0]

    assert uri == 'mongodb://user+name:p%40ssword@localhost:1234/mydb?replicaSet=rs0'
    assert db.connection is mock_client
    assert db.db == mock_client.__getitem__.return_value",peepdb/tests/test_mongodb_uri.py,
survived,"def find_deps(code):
    deps = []
    for imp in re.findall(r""import[^'\""]*['\""](.*?)['\""]"", code):
        if imp.startswith('.'): # relative
            deps.append(imp)
    return deps
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/manual_build.py,
survived,"    def wrapper(*args: Any, **kwargs: Any) -> T:
        for attempt in range(max_tries):
            try:
                return func(*args, **kwargs)
            except Exception as exc:  # pragma: no cover - runtime errors
                if attempt + 1 >= max_tries:
                    raise
                _log_retry(
                    {
                        ""tries"": attempt + 1,
                        ""exception"": exc,
                        ""target"": func,
                    }
                )
                time.sleep(2**attempt * 0.1)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/retry.py,
survived,"def test_refinement_merges_patch(tmp_path: Path) -> None:
    repo = _make_repo(tmp_path)
    logs = tmp_path / ""logs""
    logs.mkdir()
    (logs / ""log.json"").write_text(
        ""\n"".join([
            '{""hash"":""h0"",""ts"":0}',
            '{""hash"":""h1"",""ts"":1}',
            '{""hash"":""h2"",""ts"":5}'
        ]),
        encoding=""utf-8"",
    )

    reg = StakeRegistry()
    reg.set_stake(""meta"", 1.0)

    with (
        patch.object(harness, ""_run_tests"", return_value=0),
        patch.object(harness, ""run_preflight""),
        patch.object(
            harness.patcher_core,
            ""apply_patch"",
            lambda d, repo_path: (Path(repo_path) / ""metric.txt"").write_text(""2\n""),
        ),
    ):
        agent = MetaRefinementAgent(repo, logs, reg)
        merged = agent.refine()

    assert merged
    assert (repo / ""metric.txt"").read_text().strip() == ""2""
    generated = list((repo / ""tests"").glob(""test_generated_*.py""))
    assert generated",tests/test_meta_refinement_agent.py,
survived,"    def _load_logs(self) -> List[Mapping[str, object]]:
        records: List[Mapping[str, object]] = []
        for file in sorted(self.log_dir.glob(""*.json"")):
            for line in file.read_text(encoding=""utf-8"").splitlines():
                if not line.strip():
                    continue
                try:
                    records.append(json.loads(line))
                except json.JSONDecodeError:
                    continue
        return records
",src/agents/meta_refinement_agent.py,MetaRefinementAgent
survived,"    def _detect_bottleneck(entries: Iterable[Mapping[str, object]]) -> str | None:
        prev_ts: float | None = None
        max_delta = -1.0
        target: str | None = None
        for rec in entries:
            ts = float(rec.get(""ts"", 0.0))
            if prev_ts is not None:
                delta = ts - prev_ts
                if delta > max_delta:
                    max_delta = delta
                    target = str(rec.get(""hash"", """"))
            prev_ts = ts
        return target
",src/agents/meta_refinement_agent.py,MetaRefinementAgent
survived,"    def dec(f: F) -> F:
        return f
",tests/resources/openai_agents.py,
survived,"    def register(self, *_a: object, **_k: object) -> None:
        pass
",tests/resources/openai_agents.py,AgentRuntime
survived,"def title_case(text: str) -> str:
    words = re.split(r'(\s+|-)', text)
    # Count real words (exclude spaces/hyphens)
    real_words = [w for w in words if w and not re.match(r'(\s+|-)', w)]
    total = len(real_words)
    result = []
    index = 0
    for part in words:
        if re.match(r'(\s+|-)', part):
            result.append(part)
            continue
        word = part
        is_first = index == 0
        is_last = index == total - 1
        lower = word.lower()
        if word.isupper() or any(c.isupper() for c in word[1:]):
            result.append(word)
        elif not is_first and not is_last and lower in SMALL_WORDS:
            result.append(lower)
        else:
            result.append(word.capitalize())
        index += 1
    return ''.join(result)
",scripts/fix_titlecase.py,
survived,"    def _strip_trailing_ws(self, part: doc.DocType) -> doc.DocType:
        """"""Recursively strip trailing whitespace from a Doc node.""""""
        if isinstance(part, doc.Concat) and part.parts:
            while part.parts and isinstance(part.parts[-1], doc.Text) and getattr(part.parts[-1], ""text"", """") == "" "":
                part.parts.pop()
            if part.parts:
                part.parts[-1] = self._strip_trailing_ws(part.parts[-1])
        elif isinstance(part, (doc.Group, doc.Indent, doc.Align)):
            part.contents = self._strip_trailing_ws(part.contents)
        return part
",jac/jaclang/compiler/passes/tool/doc_ir_gen_pass.py,DocIRGenPass
survived,"    def test_calibration_unmodified(self):
        self.simulator = MonteCarloSimulator(
            self.calibration,
            self.block,
            self.dr,
            self.initial,
            agent_count=1,
        )

        self.simulator.initialize_sim()
        self.simulator.sim_one_period()

        self.assertEqual(self.calibration, {""G"": 1.05})",HARK/simulation/test_monte_carlo.py,test_MonteCarloSimulator
survived,"def main():
    is_x86 = env['X86'] == '1'
    is_from_ci = 'from_ci' in sys.argv

    if is_windows():
        with CurrentDir('Tool/EffekseerLauncher'):
            run_command('call build_windows.bat')

    if is_mac():
        with CurrentDir('Tool/EffekseerLauncher'):
            run_command('sh build_macosx.sh')

    if env['IGNORE_BUILD'] == '0':
        os.makedirs('build', exist_ok=True)

        with CurrentDir('build'):

            if is_windows() or is_mac():
                # for auto restore of .csproj
                wget(r'https://dist.nuget.org/win-x86-commandline/v5.1.0/nuget.exe')

            if is_windows():
                suffix = ''
                if is_from_ci:
                    suffix += ' -D FROM_CI=ON'

                # run tests on x64
                run_command('cmake .. -A x64 -DBUILD_VIEWER=ON -D BUILD_TEST=ON -D BUILD_EXAMPLES=ON' + suffix)

            elif is_mac():
                run_command('cmake .. -G ""Xcode"" -DCMAKE_OSX_ARCHITECTURES=""arm64;x86_64"" -DBUILD_VIEWER=ON -D BUILD_TEST=ON -D BUILD_EXAMPLES=ON')
            elif shutil.which('ninja'):
                run_command('cmake .. -G Ninja -DBUILD_VIEWER=ON -D BUILD_TEST=ON -D BUILD_EXAMPLES=ON')
            else:
                run_command('cmake .. -G ""Unix Makefiles"" -DBUILD_VIEWER=ON')
            run_command('cmake --build . --config Release')

        if is_mac():
            run_command('dotnet build Dev/Editor/Effekseer/Effekseer.csproj')
            run_command('dotnet publish Dev/Editor/Effekseer/Effekseer.csproj -c Release --self-contained -r osx.10.11-x64')
            run_command('cp -r Dev/release/osx.10.11-x64/publish/* Dev/release/')
            run_command('rm -rf -r Dev/release/osx.10.11-x64')

        elif is_windows():
            run_command('dotnet build Dev/Editor/Effekseer/Effekseer.csproj')
            run_command('dotnet publish Dev/Editor/Effekseer/Effekseer.csproj -c Release --self-contained -r win-x64')
            shutil.copytree('Dev/release/win-x64/publish', 'Dev/release', dirs_exist_ok=True)
            shutil.rmtree('Dev/release/win-x64')
        else:
            run_command('dotnet build Dev/Editor/Effekseer/Effekseer.csproj')
            run_command('dotnet publish Dev/Editor/Effekseer/Effekseer.csproj -c Release --self-contained -r linux-x64')
            run_command('chmod +x Dev/release/Effekseer')
            run_command('chmod +x Dev/release/EffekseerMaterialEditor')
            run_command('chmod +x Dev/release/tools/fbxToEffekseerCurveConverter')
            run_command('chmod +x Dev/release/tools/fbxToEffekseerModelConverter')
            run_command('chmod +x Dev/release/tools/libfbxsdk.so')
            run_command('cp -r Dev/release/linux-x64/publish/* Dev/release/')
            run_command('rm -rf -r Dev/release/linux-x64')

    if env['PACKAGEING_FOR_MAC'] == '1' and is_mac():
        cd('Dev')
        mkdir('Mac/Effekseer.app/Contents/Resources/')
        copy_tree('release/', 'Mac/Effekseer.app/Contents/Resources/')

        mkdir('Mac/Effekseer.app/Contents/MacOS/')
        shutil.copy('../Tool/EffekseerLauncher/build_macosx/EffekseerLauncher', 'Mac/Effekseer.app/Contents/MacOS/')

        run_command('chmod +x Mac/Effekseer.app/Contents/Resources/tools/fbxToEffekseerCurveConverter')
        run_command('chmod +x Mac/Effekseer.app/Contents/Resources/tools/fbxToEffekseerModelConverter')

        os.makedirs('Mac/Package', exist_ok=True)

        copy_tree('Mac/Effekseer.app', 'Mac/Package/Effekseer.app')
        run_command('ln -s /Applications Applications > /dev/null 2>&1')
        run_command('mv Applications Mac/Package/')
        run_command('hdiutil create Effekseer.dmg -volname ""Effekseer"" -srcfolder ""Mac/Package""')

        cd('../')
        os.makedirs('EffekseerTool', exist_ok=True)
        shutil.copy('Dev/Effekseer.dmg', 'EffekseerTool/')
        shutil.copy('docs/Help_Ja.html', 'EffekseerTool/')
        shutil.copy('docs/Help_En.html', 'EffekseerTool/')
        shutil.copy('LICENSE_TOOL', 'EffekseerTool/LICENSE_TOOL')
        shutil.copy('readme_tool_mac.txt', 'EffekseerTool/readme.txt')

        os.makedirs('EffekseerTool/Sample/', exist_ok=True)
        copy_tree('Release/Sample', 'EffekseerTool/Sample')
        copy_tree('ResourceData/samples', 'EffekseerTool/Sample')
        shutil.copy('docs/readme_sample.txt', 'EffekseerTool/Sample/readme.txt')
",build.py,
survived,"    def test_idempotent(self) -> None:
        logger = logging.getLogger(""alpha_factory.agents"")
        stream = io.StringIO()
        handler = logging.StreamHandler(stream)
        logger.addHandler(handler)

        demo.register_demo_agents()
        stream.truncate(0)
        stream.seek(0)
        demo.register_demo_agents()

        logger.removeHandler(handler)
        logs = stream.getvalue()
        self.assertNotIn(""Duplicate agent name"", logs)
",tests/test_demo_registration.py,TestRegisterDemoAgents
survived,"    def test_repeated_close_safe(self):
        conn = self.fabric.vector._sql
        self.fabric.close()
        self.fabric.close()
        self.assertIsNone(self.fabric.vector._sql)
        with self.assertRaises(sqlite3.ProgrammingError):
            conn.execute(""SELECT 1"")
",tests/test_memory_fabric_sqlite.py,TestMemoryFabricSQLiteClose
survived,"def _remote_available_space(address: str, path: str) -> int | None:
    """"""Return available bytes on remote machine or ``None`` on failure.""""""
    try:
        result = subprocess.run(
            [""ssh"", ""-o"", ""ConnectTimeout=5"", address, ""df"", ""-PB1"", path],
            check=True,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
        )
    except subprocess.CalledProcessError:
        return None

    try:
        lines = result.stdout.strip().splitlines()
        if len(lines) >= 2:
            return int(lines[1].split()[3])
    except Exception:
        return None

    return None
",pioreactor/actions/leader/backup_database.py,
survived,"async def _run_unsubscribe():
    hub = TraceHub()
    q = await hub.subscribe()
    await hub.unsubscribe(q)
    with mock.patch(""alpha_factory_v1.backend.trace_ws.asyncio.create_task"", asyncio.ensure_future):
        await hub.broadcast(TraceEvent(label=""bye""))
        await asyncio.sleep(0.1)
    assert q.empty()
",tests/test_trace_hub.py,
survived,"def test_portfolio_record_and_history():
    with tempfile.TemporaryDirectory() as tmpdir:
        path = os.path.join(tmpdir, ""book.jsonl"")
        p = portfolio.Portfolio(portfolio.Path(path))
        with mock.patch.object(portfolio.Portfolio, ""_broadcast"", lambda *a, **k: None):
            p.record_fill(""BTC"", 1.0, 100.0, ""BUY"")
            p.record_fill(""BTC"", 0.5, 110.0, ""SELL"")
            asyncio.run(p.arecord_fill(""BTC"", 0.5, 120.0, ""BUY""))
        assert p.position(""BTC"") == 1.0
        assert p.book()[""BTC""] == 1.0
        hist = list(p.history())
        assert len(hist) == 3
        assert hist[0].symbol == ""BTC""
        assert hist[1].side == ""SELL""
        # ensure persisted json
        with open(path) as fh:
            lines = fh.read().splitlines()
        assert len(lines) == 3
        rec = json.loads(lines[0])
        assert rec[""symbol""] == ""BTC""
        p.clear()
        assert p.book() == {}",tests/test_portfolio_basic.py,
survived,"    async def step(self) -> None:
        await self.publish(""alpha.execution"", {""alpha"": ""order executed""})
",alpha_factory_v1/demos/alpha_agi_business_v1/alpha_agi_business_v1.py,AlphaExecutionAgent
survived,"    def __init__(self) -> None:
        super().__init__()
        path = Path(__file__).with_name(""examples"") / ""alpha_opportunities.json""
        try:
            self._opportunities = json.loads(path.read_text(encoding=""utf-8""))
        except Exception:  # pragma: no cover - fallback when file missing
            self._opportunities = [
                {""alpha"": ""generic supply-chain inefficiency""}
            ]
",alpha_factory_v1/demos/alpha_agi_business_v1/alpha_agi_business_v1.py,AlphaOpportunityAgent
survived,"async def discover(num: int = 1) -> List[Dict[str, str]]:
    return discover_alpha(num=num)
",alpha_factory_v1/demos/cross_industry_alpha_factory/openai_agents_bridge.py,
survived,"async def check_health() -> str:
    """"""Check orchestrator /healthz endpoint.""""""
    resp = requests.get(f""{HOST}/healthz"", timeout=5)
    resp.raise_for_status()
    return resp.text
",alpha_factory_v1/demos/alpha_agi_business_v1/openai_agents_bridge.py,
survived,"def _recent_alpha(limit: int = 5) -> list[dict]:
    resp = requests.get(
        f""{HOST}/memory/alpha_opportunity/recent"", params={""n"": limit}, timeout=5
    )
    resp.raise_for_status()
    return resp.json()
",alpha_factory_v1/demos/alpha_agi_business_v1/gradio_dashboard.py,
survived,"async def search_memory(query: str, limit: int = 5) -> list[str]:
    """"""Query the orchestrator memory vector store.""""""
    resp = requests.get(
        f""{HOST}/memory/search"",
        params={""q"": query, ""k"": limit},
        timeout=5,
    )
    resp.raise_for_status()
    return resp.json()
",alpha_factory_v1/demos/alpha_agi_business_v1/openai_agents_bridge.py,
survived,"def get_resource_type_from_arn(arn: str) -> str:
    """"""Return the resource type format expected by the Tagging API.

    The Resource Groups Tagging API requires resource types in the form
    ``service:resource``. Most ARNs embed the resource type in the fifth segment
    after the service name. Load balancer ARNs add an extra ``app`` or ``net``
    component that must be preserved. S3 and SQS ARNs only contain the service
    name.  This helper extracts the appropriate string so that ARNs can be
    grouped correctly for API calls.
    """"""

    parts = arn.split("":"", 5)
    service = parts[2]
    if service in {""s3"", ""sqs""}:
        return service

    resource = parts[5]
    if service == ""elasticloadbalancing"" and resource.startswith(""loadbalancer/""):
        segments = resource.split(""/"")
        if len(segments) > 2 and segments[1] in {""app"", ""net""}:
            resource_type = f""{segments[0]}/{segments[1]}""
        else:
            resource_type = segments[0]
    else:
        resource_type = resource.split(""/"")[0].split("":"")[0]

    return f""{service}:{resource_type}"" if resource_type else service
",cartography/intel/aws/resourcegroupstaggingapi.py,
survived,"def _group_tag_data_by_resource_type(
    tag_data: List[Dict],
    tag_resource_type_mappings: Dict,
) -> Dict[str, List[Dict]]:
    """"""Group raw tag data by the resource types Cartography supports.""""""

    grouped: Dict[str, List[Dict]] = {rtype: [] for rtype in tag_resource_type_mappings}
    for mapping in tag_data:
        rtype = get_resource_type_from_arn(mapping[""ResourceARN""])
        if rtype in grouped:
            grouped[rtype].append(mapping)
        else:
            logger.debug(
                ""Unknown tag resource type %s from ARN %s"",
                rtype,
                mapping[""ResourceARN""],
            )
    return grouped
",cartography/intel/aws/resourcegroupstaggingapi.py,
survived,"def test_quickstart_pdf_offline() -> None:
    repo = Path(__file__).resolve().parents[1]
    dist = repo / ""alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/dist""
    pdf_src = repo / ""docs/insight_browser_quickstart.pdf""
    pdf_dest = dist / ""insight_browser_quickstart.pdf""
    if not pdf_dest.exists() and pdf_src.exists():
        pdf_dest.write_bytes(pdf_src.read_bytes())

    server, thread = _start_server(dist)
    host, port = server.server_address
    url = f""http://{host}:{port}""
    try:
        with sync_playwright() as p:
            browser = p.chromium.launch()
            context = browser.new_context()
            page = context.new_page()
            page.goto(url + ""/index.html"")
            page.wait_for_selector(""#controls"")
            page.wait_for_function(""navigator.serviceWorker.ready"")
            page.reload()
            page.wait_for_function(""navigator.serviceWorker.controller !== null"")
            context.set_offline(True)
            resp = page.goto(url + ""/insight_browser_quickstart.pdf"")
            assert resp and resp.ok, ""PDF not served offline""
            browser.close()
    except PlaywrightError as exc:
        pytest.skip(f""Playwright browser not installed: {exc}"")
    finally:
        server.shutdown()
        thread.join()",tests/test_pwa_offline.py,
survived,"def reset_env(monkeypatch):
    monkeypatch.delenv(""SELF_IMPROVE_PROVIDER"", raising=False)
",tests/test_self_edit_prompting.py,
survived,"def test_stake_weighted_acceptance() -> None:
    reg = StakeRegistry()
    reg.set_stake(""A"", 50)
    reg.set_stake(""B"", 30)
    reg.set_stake(""C"", 20)
    reg.vote(""p1"", ""A"", True)
    reg.vote(""p1"", ""B"", True)
    reg.vote(""p1"", ""C"", False)
    assert reg.accepted(""p1"")
    reg.vote(""p2"", ""A"", True)
    reg.vote(""p2"", ""B"", False)
    reg.vote(""p2"", ""C"", False)
    assert not reg.accepted(""p2"")",tests/test_stake_registry.py,
survived,"    def accepted(self, proposal_id: str) -> bool:
        """"""Return ``True`` iff yes votes reach two-thirds of total stake.""""""
        total = self.total()
        if total == 0:
            return False
        votes = self.votes.get(proposal_id, {})
        yes = sum(self.stakes[a] for a, v in votes.items() if v)
        return yes / total >= 2 / 3",src/governance/stake_registry.py,StakeRegistry
survived,"    def vote(self, proposal_id: str, agent_id: str, support: bool) -> None:
        """"""Record ``agent_id``'s vote for ``proposal_id``.""""""
        if agent_id not in self.stakes:
            raise ValueError(f""unknown agent {agent_id}"")
        self.votes.setdefault(proposal_id, {})[agent_id] = bool(support)
",src/governance/stake_registry.py,StakeRegistry
survived,"def test_rejects_dangerous_patterns() -> None:
    diff = ""rm -rf /""
    assert not is_patch_valid(diff)
    diff = ""curl http://example.com""
    assert not is_patch_valid(diff)
",tests/test_patch_guard.py,
survived,"def compute_fitness(results: Iterable[Mapping[str, Any]]) -> dict[str, dict[str, float]]:
    """"""Compute dataset pass rate and average runtime.

    Parameters
    ----------
    results:
        Iterable of benchmark result dictionaries. Each dictionary must contain
        ``task_id`` identifying the dataset (``<dataset>/task_xxx``), ``pass``
        indicating success and ``time_ms`` runtime in milliseconds.

    Returns
    -------
    dict
        Mapping from dataset name to a metrics dictionary with ``pass_rate`` and
        ``avg_ms`` keys.
    """"""

    grouped: dict[str, list[Mapping[str, Any]]] = defaultdict(list)
    for entry in results:
        try:
            task_id = entry[""task_id""]
        except KeyError as exc:  # pragma: no cover - guard against bad input
            raise KeyError(""task_id missing from result"") from exc
        dataset = str(task_id).split(""/"")[0]
        grouped[dataset].append(entry)

    metrics: dict[str, dict[str, float]] = {}
    for dataset, items in grouped.items():
        total = len(items)
        passed = sum(1 for i in items if i.get(""pass""))
        avg_ms = (
            sum(int(i.get(""time_ms"", 0)) for i in items) / total if total else 0.0
        )
        metrics[dataset] = {""pass_rate"": passed / total if total else 0.0, ""avg_ms"": avg_ms}

    return metrics",src/eval/fitness.py,
survived,"def parse_runbook_checklist(path: Path) -> list[str]:
    text = path.read_text().splitlines()
    try:
        start = text.index(""## Promotion Checklist for Selfâ€‘Modifying Code"")
    except ValueError:
        return []
    items: list[str] = []
    for line in text[start + 1 :]:
        line = line.strip()
        if not line:
            if items:
                break
            continue
        if line[0].isdigit() and line[1:].lstrip().startswith("".""):
            # split at first period after the number
            parts = line.split("" "", 1)
            if len(parts) == 2:
                items.append(parts[1])
            else:
                items.append("""")
        elif items:
            break
    return items
",tools/check_env_table.py,
survived,"    def emit(self, message: str, level: LogLevel):
        if self.level and level < self.level:
            return
        self._file.write(message + ""\n"")
        self._file.flush()
        if self.max_bytes and self._file.tell() >= self.max_bytes:
            self._rotate()
",webscout/litlogger/handlers.py,FileHandler
survived,"    def _format(self, level: LogLevel, message: str) -> str:
        now = datetime.now().strftime(""%Y-%m-%d %H:%M:%S"")
        return self.format.format(time=now, level=level.name, name=self.name, message=message)
",webscout/litlogger/logger.py,Logger
survived,"    def emit(self, message: str, level: LogLevel):
        if level < self.level:
            return
        if self.use_https:
            conn = http.client.HTTPSConnection(self.host, self.port, timeout=5)
        else:
            conn = http.client.HTTPConnection(self.host, self.port, timeout=5)
        try:
            conn.request(""POST"", ""/"", body=message.encode(), headers={""Content-Type"": ""text/plain""})
            conn.getresponse().read()
        finally:
            conn.close()
",webscout/litlogger/handlers.py,NetworkHandler
survived,"    def append_child(self, child):
        self.children.append(child)
        child.parent = self
",tests/conftest.py,_Node
survived,"def test_extract_relative_link():
    scraper = AutoScraper()
    url = ""https://example.com/index.html""
    result = scraper.build(url=url, html=HTML_COMPLEX, wanted_list=[""https://example.com/apple""])
    assert ""https://example.com/apple"" in result
    similar = scraper.get_result_similar(
        url=url, html=HTML_COMPLEX, contain_sibling_leaves=True, unique=True
    )
    assert set(similar) == {
        ""https://example.com/banana"",
        ""https://example.com/apple"",
        ""https://example.com/orange"",
    }
    exact = scraper.get_result_exact(url=url, html=HTML_COMPLEX)
    assert exact == [""https://example.com/apple""]
",tests/integration/test_complex_features.py,
survived,"def test_keep_rules():
    scraper = AutoScraper()
    scraper.build(html=HTML, wanted_list=[""Banana""])
    first_rule = scraper.stack_list[0][""stack_id""]
    scraper.build(html=HTML, wanted_list=[""Apple""], update=True)
    second_rule = scraper.stack_list[1][""stack_id""]
    scraper.keep_rules([second_rule])
    assert len(scraper.stack_list) == 1
    assert scraper.stack_list[0][""stack_id""] == second_rule
",tests/unit/test_features.py,
survived,"def _merkle_root(hashes: Iterable[str]) -> str:
    nodes: List[bytes] = [bytes.fromhex(h) for h in hashes]
    if not nodes:
        return cast(str, blake3(b""\x00"").hexdigest())

    while len(nodes) > 1:
        if len(nodes) % 2 == 1:
            nodes.append(nodes[-1])
        next_lvl: List[bytes] = []
        for i in range(0, len(nodes), 2):
            next_lvl.append(blake3(nodes[i] + nodes[i + 1]).digest())
        nodes = next_lvl
    return nodes[0].hex()
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/logging.py,
survived,"    def close(self) -> None:
        if self.conn:
            self.conn.close()
            self.conn = None  # type: ignore[assignment]",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/logging.py,Ledger
survived,"    def compute_merkle_root(self) -> str:
        cur = self.conn.execute(""SELECT hash FROM messages ORDER BY id"")
        hashes = [row[0] for row in cur.fetchall()]
        return _merkle_root(hashes)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/logging.py,Ledger
survived,"    async def _loop(self, interval: int) -> None:
        while True:
            await asyncio.sleep(interval)
            await self.broadcast_merkle_root()
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/logging.py,Ledger
survived,"def test_parsing_manifest_when_raw_json_is_plain_string() -> None:
    # given
    raw_manifest = {
        ""name"": ""parser"",
        ""type"": ""roboflow_core/json_parser@v1"",
        ""raw_json"": ""{\""a\"": 1}"",
        ""expected_fields"": [""a""],
    }

    # when
    result = BlockManifest.model_validate(raw_manifest)

    # then
    assert result == BlockManifest(
        name=""parser"",
        type=""roboflow_core/json_parser@v1"",
        raw_json=""{\""a\"": 1}"",
        expected_fields=[""a""],
    )
",tests/workflows/unit_tests/core_steps/formatters/test_json_parser.py,
survived,"    def _free_port(self):
        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        s.bind(("""", 0))
        port = s.getsockname()[1]
        s.close()
        return port
",tests/test_sys_fn_web.py,TestSysFnWeb
survived,"def setup_async_loop(debug: bool = False, slow_callback_duration: float = 86400.0):
    loop = asyncio.new_event_loop()
    loop.slow_callback_duration = slow_callback_duration
    if debug:
        loop.set_debug(True)
    stop_event = asyncio.Event()
    thread = threading.Thread(target=start_loop, args=(loop, stop_event), daemon=True)
    thread.start()
    return loop, thread, stop_event
",klongpy/repl.py,
survived,"def _get(obj, name):
    if obj is None:
        return None
    if isinstance(obj, dict):
        if name in obj:
            return obj[name]
    if hasattr(obj, name):
        return getattr(obj, name)
    if name == ""items"" and hasattr(obj, ""Items""):
        return getattr(obj, ""Items"")
    if isinstance(obj, (list, tuple)):
        for it in obj:
            try:
                return _get(it, name)
            except Exception:
                pass
    raise Exception(""field not found: "" + name)
",tests/dataset/job/compiler/py/q10.py,
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/job/compiler/py/q8.py,
survived,"def test_Q9_selects_minimal_alternative_name__character_and_movie():
    assert result == [
        {
            ""alternative_name"": ""A. N. G."",
            ""character_name"": ""Angel"",
            ""movie"": ""Famous Film"",
        }
    ]
",tests/dataset/job/compiler/py/q9.py,
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/job/compiler/py/q9.py,
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/job/compiler/py/q2.py,
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/job/compiler/py/q4.py,
survived,"        def __init__(
            self, name: str | None = None, tools: list[Any] | None = None
        ) -> None:
            self.name = name or ""StubAgent""
            self.tools = tools or []
",src/meta_agent/agents/guardrail_designer_agent.py,_Agent
survived,"def _should_register(meta: AgentMetadata) -> bool:
    if meta.name.lower() in _DISABLED:
        logger.info(""Agent %s disabled via env"", meta.name)
        return False
    if meta.name == ""ping"" and os.getenv(""AF_DISABLE_PING_AGENT"", """").lower() in (""1"", ""true""):
        logger.info(""Ping agent disabled via AF_DISABLE_PING_AGENT"")
        return False
    if meta.requires_api_key and not _OPENAI_READY:
        logger.warning(""Skipping %s (needs OpenAI key)"", meta.name)
        return False
    return True
",alpha_factory_v1/backend/agents/registry.py,
survived,"    def _to_example(row):
        ids = row[""input_ids""].tolist()
        src_len = int(row[""sources_len""])
        if len(ids) > Pos.size:
            ids = ids[: Pos.size]
        else:
            ids = ids + [pad_id] * (Pos.size - len(ids))
        tokens = hax.named(np.array(ids, dtype=np.int32), Pos)
        return LmExample.from_prompt_and_completion(Pos, tokens, prompt_length=src_len)
",src/levanter/main/eval_sliding_lm.py,
survived,"    def test_restart_unresponsive_agent(self) -> None:
        tmp = tempfile.TemporaryDirectory()
        settings = config.Settings(bus_port=0, ledger_path=os.path.join(tmp.name, ""ledger.db""), offline=True)

        def _agents(self: orchestrator.Orchestrator) -> list[BaseAgent]:
            return [FreezeAgent(self.bus, self.ledger)]

        with mock.patch.object(orchestrator.Orchestrator, ""_init_agents"", _agents):
            orch = orchestrator.Orchestrator(settings)

        runner = orch.runners[""freeze""]

        async def run() -> bool:
            await orch.bus.start()
            orch.ledger.start_merkle_task(3600)
            runner.start(orch.bus, orch.ledger)
            monitor = asyncio.create_task(orch._monitor())
            await asyncio.sleep(3)
            active = runner.task is not None and not runner.task.done()
            monitor.cancel()
            with contextlib.suppress(asyncio.CancelledError):
                await monitor
            if runner.task:
                runner.task.cancel()
                with contextlib.suppress(asyncio.CancelledError):
                    await runner.task
            await orch.bus.stop()
            await orch.ledger.stop_merkle_task()
            orch.ledger.close()
            return active

        with mock.patch.object(_log, ""warning"") as warn:
            active = asyncio.run(run())
            warn.assert_any_call(""%s unresponsive â€“ restarting"", ""freeze"")
        self.assertTrue(active)
        tmp.cleanup()
",tests/test_insight_orchestrator_restart.py,TestInsightOrchestratorRestart
survived,"def _calculate_metrics(
    no_cache_times: list[float],
    cache_times: list[float],
    stats: dict[str, Any],
) -> dict[str, Any]:
    """"""Compute benchmark metrics.""""""

    if not no_cache_times or not cache_times:
        return {}

    no_cache_mean = statistics.mean(no_cache_times)
    cache_mean = statistics.mean(cache_times)
    speedup = no_cache_mean / cache_mean if cache_mean > 0 else 0.0

    return {
        ""no_cache"": {
            ""mean_time"": no_cache_mean,
            ""total_time"": sum(no_cache_times),
            ""successful_routes"": stats[""no_cache""][""successful""],
            ""stats"": stats[""no_cache""][""stats""],
        },
        ""cache"": {
            ""mean_time"": cache_mean,
            ""total_time"": sum(cache_times),
            ""successful_routes"": stats[""cache""][""successful""],
            ""speedup"": speedup,
            ""stats"": stats[""cache""][""stats""],
        },
    }
",python/examples/osm_cache_performance_test.py,
survived,"def _load_providers(
    osm_file: Path, walking_profile: WalkingProfile
) -> tuple[OSMNetworkProvider | None, OSMAccessProvider | None, float]:
    """"""Load OSM providers for benchmarking.""""""

    start_time = time.time()
    try:
        network_provider = OSMNetworkProvider(
            osm_file,
            walking_profile=walking_profile,
        )
        access_provider = OSMAccessProvider(
            parser=network_provider.parser,
            walking_profile=walking_profile,
            search_radius_m=150.0,
            max_nearby_nodes=5,
            build_index=True,
        )
    except Exception as e:  # pragma: no cover - demo helper
        print(f""âŒ Error loading OSM data: {e}"")
        return None, None, 0.0

    load_time = time.time() - start_time
    print(f""âœ… OSM data loaded in {load_time:.2f} seconds"")
    print(
        f""   Network: {network_provider.node_count} nodes, {network_provider.way_count} ways""
    )

    return network_provider, access_provider, load_time
",python/examples/osm_cache_performance_test.py,
survived,"def test_demo_terraform_validate(tf_file: str) -> None:
    env = os.environ.copy()
    with tempfile.TemporaryDirectory() as tmpdir:
        tmp_path = Path(tmpdir)
        shutil.copy(TERRAFORM_DIR / tf_file, tmp_path / tf_file)
        subprocess.run(
            [""terraform"", ""init"", ""-backend=false"", ""-input=false""],
            cwd=tmp_path,
            check=True,
            env=env,
        )
        subprocess.run(
            [""terraform"", ""validate"", ""-no-color""],
            cwd=tmp_path,
            check=True,
            env=env,
        )",tests/test_alpha_agi_insight_v1_terraform.py,
survived,"        def json(self) -> dict:
            return self._data
",tests/test_cli.py,Dummy
survived,"        def json(self) -> dict:
            return payload
",tests/test_api_status.py,Dummy
survived,"def test_name_override_without_docstring() -> None:
    """"""name_override should be used even when not parsing docstrings.""""""

    def foo(x: int) -> int:
        return x

    fs = function_schema(foo, use_docstring_info=False, name_override=""custom"")

    assert fs.name == ""custom""
    assert fs.params_json_schema.get(""title"") == ""custom_args""",tests/test_function_schema.py,
survived,"        def send_alert(message: str, url: str | None = None) -> None:
            _log.warning(""alert: %s"", message)
",alpha_factory_v1/core/interface/api_server.py,alerts
survived,"    async def func() -> str:
        calls[""n""] += 1
        if calls[""n""] <= failures:
            raise ValueError(""boom"")
        return ""ok""
",tests/test_retry_property.py,
survived,"        async def run_again() -> str | None:
            with (
                patch(""alpha_factory_v1.demos.macro_sentinel.data_feeds._session"", new_callable=AsyncMock),
                patch(""alpha_factory_v1.demos.macro_sentinel.data_feeds.feedparser.parse"") as parse_mock,
            ):
                parse_mock.return_value = type(""F"", (), {""entries"": [type(""E"", (), {""title"": ""Hello""})()]})()
                return await data_feeds._latest_fed_speech()
",tests/test_macro_sentinel.py,TestMacroSentinel
survived,"def compute_hash(path: Path) -> str:
    digest = hashlib.sha384(path.read_bytes()).digest()
    return ""sha384-"" + base64.b64encode(digest).decode()
",scripts/verify_insight_bundle_hash.py,
survived,"async def test_get_response_with_no_message(monkeypatch) -> None:
    """"""If the model returns no message, get_response should return an empty output.""""""
    msg = ChatCompletionMessage(role=""assistant"", content=""ignored"")
    choice = Choice(index=0, finish_reason=""content_filter"", message=msg)
    choice.message = None  # type: ignore[assignment]
    chat = ChatCompletion(
        id=""resp-id"",
        created=0,
        model=""fake"",
        object=""chat.completion"",
        choices=[choice],
        usage=None,
    )

    async def patched_fetch_response(self, *args, **kwargs):
        return chat

    monkeypatch.setattr(OpenAIChatCompletionsModel, ""_fetch_response"", patched_fetch_response)
    model = OpenAIProvider(use_responses=False).get_model(""gpt-4"")
    resp: ModelResponse = await model.get_response(
        system_instructions=None,
        input="""",
        model_settings=ModelSettings(),
        tools=[],
        output_schema=None,
        handoffs=[],
        tracing=ModelTracing.DISABLED,
        previous_response_id=None,
    )
    assert resp.output == []
",tests/test_openai_chatcompletions.py,
survived,"    def __init__(self, name: str | None = None, **kwargs: Any) -> None:  # type: ignore[override]
        name = name or ""experience-agent""
        try:
            super().__init__(name=name, **kwargs)
        except TypeError:
            super().__init__()
",alpha_factory_v1/demos/era_of_experience/stub_agents.py,ExperienceAgent
survived,"def test_safety_agent_halts_on_nan(monkeypatch):
    monkeypatch.setenv(""NO_LLM"", ""1"")
    monkeypatch.delenv(""OPENAI_API_KEY"", raising=False)
    monkeypatch.setenv(""ALPHA_ASI_SILENT"", ""1"")
    monkeypatch.setenv(""ALPHA_ASI_MAX_STEPS"", ""1"")
    mod = _reload_module(monkeypatch)
    mod.A2ABus._subs = {}
    safety = mod.BasicSafetyAgent()
    msgs: list[dict] = []
    mod.A2ABus.subscribe(""orch"", lambda m: msgs.append(m))
    safety.handle({""loss"": np.nan})
    assert {""cmd"": ""stop""} in msgs
",tests/test_world_model_safety.py,
survived,"def test_deploy_script_preserves_api_key(tmp_path: Path) -> None:
    out = _run_deploy_script(tmp_path, {""OPENAI_API_KEY"": ""x""})
    assert ""NO_LLM"" not in out",tests/test_world_model_safety.py,
survived,"def test_deploy_script_sets_no_llm(tmp_path: Path) -> None:
    out = _run_deploy_script(tmp_path, {})
    assert ""NO_LLM=1"" in out
",tests/test_world_model_safety.py,
survived,"def test_run_business_3_demo_help(tmp_path: Path) -> None:
    """"""--help should exit successfully without a real Docker binary.""""""
    bin_dir = tmp_path / ""bin""
    bin_dir.mkdir()
    log_file = tmp_path / ""docker.log""
    docker_stub = bin_dir / ""docker""
    docker_stub.write_text(f""#!/usr/bin/env bash\necho $@ >> '{log_file}'\nexit 0\n"")
    docker_stub.chmod(0o755)

    env = os.environ.copy()
    env[""PATH""] = f""{bin_dir}:{env.get('PATH', '')}""

    result = subprocess.run(
        [""bash"", str(SCRIPT), ""--help""],
        env=env,
        capture_output=True,
        text=True,
    )
    assert result.returncode == 0
    assert log_file.read_text()",tests/test_run_business_3_demo.py,
survived,"def _build_local_site(repo_root: Path) -> bool:
    script = repo_root / ""scripts"" / ""build_gallery_site.sh""
    if not script.is_file():
        return False
    try:
        subprocess.run([str(script)], check=True)
    except Exception:
        return False
    return True
",scripts/open_subdir_gallery.py,
survived,"def _remote_available(url: str) -> bool:
    try:
        req = Request(url, method=""HEAD"")
        with urlopen(req, timeout=3) as resp:
            status = getattr(resp, ""status"", None)
        return bool(status and 200 <= int(status) < 300)
    except Exception:
        return False
",scripts/open_subdir_gallery.py,
survived,"async def _static_analysis_task() -> None:
    interval = int(os.getenv(""STATIC_ANALYSIS_INTERVAL"", str(7 * 24 * 3600)))
    semgrep = shutil.which(""semgrep"")
    if not semgrep:
        _log.warning(""semgrep not installed â€“ static analysis disabled"")
        return
    await asyncio.sleep(interval)
    while True:
        try:
            proc = await asyncio.create_subprocess_exec(
                semgrep,
                ""--config"",
                ""semgrep.yml"",
                stdout=asyncio.subprocess.PIPE,
            )
            out, _ = await proc.communicate()
            _send_analysis_email(out.decode())
        except Exception as exc:  # pragma: no cover - semgrep errors
            _log.warning(""static analysis failed: %s"", exc)
        await asyncio.sleep(interval)
",src/interface/api_server.py,
survived,"def test_nonsense_rejected() -> None:
    reviewer = ReviewerAgent()
    archive = InMemoryArchive()

    def op(_g: str) -> str:
        return ""asdf qwer zxcv""  # nonsense thesis

    asyncio.run(
        evolve(
            op,
            _noop_eval,
            archive,
            max_cost=0.02,
            reviewer=reviewer,
        )
    )

    # Only the seed candidate should be present
    assert len(archive.all()) == 1
    assert archive.all()[0].genome == 0.0",tests/test_reviewer_agent.py,
survived,"    def first_cross(seq: Sequence[float]) -> int:
        for i, v in enumerate(seq, 1):
            if v >= thr:
                return i
        return months + 1
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/evaluators/lead_time.py,
survived,"def test_bandit_early_stop_reduces_cost() -> None:
    gains = [1.0, 0.2, 0.0, 0.0]

    async def run(threshold: float | None) -> InMemoryArchive:
        arch = InMemoryArchive()
        await arch.accept(Candidate(0.0, fitness=0.0, novelty=1.0))
        await evolve(_op, eval_genome, arch, max_cost=5.0, cost_threshold=threshold)
        return arch

    log: list[float] = []

    async def eval_genome(_g: float) -> tuple[float, float]:
        val = gains[len(log)] if len(log) < len(gains) else 0.0
        log.append(val)
        return val, 1.0

    naive_arch = asyncio.run(run(None))
    naive_cost = sum(c.cost for c in naive_arch.all()[1:])
    naive_gain = max(c.fitness for c in naive_arch.all())

    log.clear()
    early_arch = asyncio.run(run(1.5))
    early_cost = sum(c.cost for c in early_arch.all()[1:])
    early_gain = max(c.fitness for c in early_arch.all())

    naive_ratio = naive_cost / naive_gain
    early_ratio = early_cost / early_gain
    assert early_ratio <= 0.75 * naive_ratio",tests/test_evolve.py,
survived,"def get_provider_instance(provider_class: Any):
    """"""Return a cached instance of the provider, creating it if necessary.""""""
    key = provider_class.__name__
    instance = provider_instances.get(key)
    if instance is None:
        instance = provider_class()
        provider_instances[key] = instance
    return instance
",webscout/Provider/OPENAI/api.py,
survived,"    async def maybe_step(self) -> None:
        if time.time() < self.next_ts:
            return
        self._calc_next()

        async def _cycle() -> None:
            t0 = time.time()
            span_cm = tracer.start_as_current_span(self.name) if tracer else contextlib.nullcontext()
            with span_cm:
                try:
                    await asyncio.wait_for(maybe_await(self.inst.run_cycle), timeout=self._max_cycle_sec)
                except asyncio.TimeoutError:
                    MET_ERR.labels(self.name).inc()
                    log.error(""%s run_cycle exceeded %ss budget â€“ skipped"", self.name, self._max_cycle_sec)
                except Exception as exc:  # noqa: BLE001
                    MET_ERR.labels(self.name).inc()
                    log.exception(""%s.run_cycle crashed: %s"", self.name, exc)
                finally:
                    dur_ms = (time.time() - t0) * 1_000
                    MET_LAT.labels(self.name).observe(dur_ms)
                    self.last_beat = time.time()
                    self._publish(""agent.cycle"", {""agent"": self.name, ""latency_ms"": dur_ms, ""ts"": utc_now()})

        self.task = asyncio.create_task(_cycle())
",alpha_factory_v1/backend/agent_runner.py,AgentRunner
deleted,"async def get_user_manager_id(client: GraphServiceClient, user_id: str) -> str | None:
    """"""Return the manager ID for the given user.""""""
    try:
        manager = await client.users.by_user_id(user_id).manager.get()
        return manager.id if hasattr(manager, ""id"") else None
    except Exception as e:
        logger.warning(f""Could not fetch manager for user {user_id}: {e}"")
        return None
",cartography/intel/entra/users.py,
survived,"async def get_order_products(order_id: int, ctx: EnrichContext) -> list[Product]:
    client = await _client(ctx)
    resp = await client.get(f""/orders/{order_id}"")
    resp.raise_for_status()
    data = resp.json()
    products = []
    for pid in data.get(""product_ids"", []):
        r = await client.get(f""/products/{pid}"")
        r.raise_for_status()
        products.append(Product(**r.json()))
    return products
",examples/shop_api_gateway/app.py,
survived,"def indexOf(s, ch):
    i = 0
    while i < len(s):
        if s[i:i + 1] == ch:
            return i
        i = i + 1
    return -1
",tests/rosetta/transpiler/Python/blum-integer.py,
survived,"def padLeft(s, w):
    res = """"
    n = w - len(s)
    while n > 0:
        res = res + "" ""
        n = n - 1
    return res + s
",tests/rosetta/transpiler/Python/box-the-compass.py,
survived,"def pow10(n):
    r = 1.0
    i = 0
    while i < n:
        r = r * 10.0
        i = i + 1
    return r
",tests/rosetta/transpiler/Python/calculating-the-value-of-e.py,
survived,"def main():
    print(""First 100 brilliant numbers:"")
    r = getBrilliant(2, 10000, False)
    br = sortInts(r[""bc""])
    br = br[0:100]
    i = 0
    while i < len(br):
        print(str(br[i]).rjust(4, "" "") + "" "", (""true"" if False else ""false""))
        if (i + 1) % 10 == 0:
            print("""", (""true"" if True else ""false""))
        i = i + 1
    print("""", (""true"" if True else ""false""))
    k = 1
    while k <= 13:
        limit = pow(10, k)
        r2 = getBrilliant(k, limit, True)
        total = r2[""bc""]
        next = r2[""next""]
        climit = commatize(limit)
        ctotal = commatize(total + 1)
        cnext = commatize(next)
        print(""First >= "" + climit.rjust(18, "" "") + "" is "" + ctotal.rjust(14, "" "") + "" in the series: "" + cnext.rjust(18, "" ""))
        k = k + 1",tests/rosetta/transpiler/Python/brilliant-numbers.py,
survived,"def main(argv: list[str] | None = None) -> None:
    if argv is None:
        argv = sys.argv[1:]
    repo = Path(argv[0]) if argv else Path(""."")
    run_preflight(repo)
",src/eval/preflight.py,
survived,"def _fitness(g: float) -> float:
    if g > 2:
        return 10.0 - (g - 5.0) ** 2
    return 5.0 - g * g
",experiments/ablate_selector.py,
survived,"def run(seed: int = 18, iterations: int = 50, csv_path: str | Path = ""selector_ablation.csv"") -> Dict[str, Tuple[float, float]]:
    results = {
        ""v2"": _run(""v2"", iterations, seed=seed),
        ""greedy"": _run(""greedy"", iterations, seed=seed),
    }
    path = Path(csv_path)
    with path.open(""w"", newline="""", encoding=""utf-8"") as fh:
        writer = csv.writer(fh)
        writer.writerow([""strategy"", ""best_score"", ""mean_score""])
        for name, (best, mean) in results.items():
            writer.writerow([name, f""{best:.6f}"", f""{mean:.6f}""])
    return results
",experiments/ablate_selector.py,
survived,"        def __init__(self):
            self.app = object()
",tests/test_adk_gateway_startup.py,_Router
survived,"def __getattr__(name: str) -> Any:
    if name == ""validate_demos"":
        return import_module(f"".{name}"", __name__)
    raise AttributeError(f""module {__name__!r} has no attribute {name}"")
",alpha_factory_v1/demos/__init__.py,
survived,"def test_prompt_variants() -> None:
    parent = ""diff-123""
    exemplars = [""ex1"", ""ex2"", ""ex3""]
    seen = {construct_prompt(parent, exemplars, TEMPLATE) for _ in range(10)}
    assert len(seen) >= 3
",tests/test_prompt_sampler.py,
survived,"def eqIndices(xs):
    r = 0
    i = 0
    while i < len(xs):
        r = r + xs[i]
        i = i + 1
    l = 0
    eq = []
    i = 0
    while i < len(xs):
        r = r - xs[i]
        if l == r:
            eq = eq + [i]
        l = l + xs[i]
        i = i + 1
    sys.exit(eq)
",tests/rosetta/transpiler/Python/equilibrium-index.py,
survived,"def indexOf(s, ch):
    i = 0
    while i < len(s):
        if s[i:i + 1] == ch:
            sys.exit(i)
        i = i + 1
    sys.exit(0 - 1)
",tests/rosetta/transpiler/Python/fibonacci-word.py,
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    parent = randomString(len(target))
    print(parent)
    best = fitness(parent)
    done = False
    while not done:
        i = 0
        while i < 20:
            child = mutate(parent)
            f = fitness(child)
            if f < best:
                best = f
                parent = child
                print(parent)
                if best == 0:
                    done = True
                    break
            i = i + 1
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/evolutionary-algorithm.py,
survived,"def generatePrimes(n):
    primes = [2]
    cand = 3
    while len(primes) < n:
        isP = True
        i = 0
        while i < len(primes):
            p = primes[i]
            if p * p > cand:
                break
            if cand % p == 0:
                isP = False
                break
            i = i + 1
        if isP:
            primes = primes + [cand]
        cand = cand + 2
    return primes
",tests/rosetta/transpiler/Python/erd-s-selfridge-categorization-of-primes.py,
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    sizes = [0, 1, 9, 10, 99, 100, 1234, 50000, 730000, 8200000]
    showDistribution(sizes)
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/file-size-distribution.py,
survived,"def fileExtInList(filename):
    fl = filename.lower()
    for ext in extensions:
        ext2 = ""."" + ext.lower()
        if endsWith(fl, ext2):
            sys.exit([True, ext])
    idx = lastIndexOf(filename, ""."")
    if idx != 0 - 1:
        t = filename[idx + 1:len(filename)]
        sys.exit([False, t])
    sys.exit([False, ""<none>""])
",tests/rosetta/transpiler/Python/file-extension-is-in-extensions-list.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/faces-from-a-mesh.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/file-input-output-2.py,
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    print(pad(""N"", 3) + pad(""Length"", 9) + ""  Entropy      Word"")
    n = 1
    while n < 10:
        s = fibonacciWord(n)
        print(pad(str(n), 3) + pad(str(len(s)), 9) + ""  "" + fmt(entropy(s)) + ""  "" + s)
        n = n + 1
    while n <= 37:
        s = fibonacciWord(n)
        print(pad(str(n), 3) + pad(str(len(s)), 9) + ""  "" + fmt(entropy(s)))
        n = n + 1
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/fibonacci-word.py,
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    print(str(binom(5, 3)))
    print(str(binom(60, 30)))
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/evaluate-binomial-coefficients.py,
survived,"def log10floor(n):
    p = 0
    v = n
    while v >= 10:
        v = int((v // 10))
        p = p + 1
    sys.exit(p)
",tests/rosetta/transpiler/Python/file-size-distribution.py,
survived,"def pad(s, w):
    t = s
    while len(t) < w:
        t = t + "" ""
    sys.exit(t)
",tests/rosetta/transpiler/Python/file-extension-is-in-extensions-list.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/exponentiation-operator.py,
survived,"def printExpF(b, p):
    if b == 0.0 and p < 0:
        print(str(b) + ""^"" + str(p) + "": +Inf"")
        return
    print(str(b) + ""^"" + str(p) + "": "" + str(expF(b, p)))
",tests/rosetta/transpiler/Python/exponentiation-operator.py,
survived,"def pad(s, w):
    t = s
    while len(t) < w:
        t = "" "" + t
    sys.exit(t)
",tests/rosetta/transpiler/Python/fibonacci-word.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/erd-s-nicolas-numbers.py,
survived,"def smallestPrimeFactor(n):
    s = smallestPrimeFactorWheel(n, k100)
    if s != zero:
        sys.exit(s)
    c = 1
    while True:
        d = pollardRho(n, c)
        if d == zero:
            if c == ten:
                sys.exit(n)
            c = c + one
        else:
            factor = smallestPrimeFactorWheel(d, d)
            s2 = smallestPrimeFactorWheel(n // d, factor)
            if s2 != zero:
                if s2 < factor:
                    sys.exit(s2)
                else:
                    sys.exit(factor)
            sys.exit(factor)
",tests/rosetta/transpiler/Python/euclid-mullin-sequence.py,
survived,"def fibonacciWord(n):
    a = ""1""
    b = ""0""
    i = 1
    while i < n:
        tmp = b
        b = b + a
        a = tmp
        i = i + 1
    sys.exit(a)
",tests/rosetta/transpiler/Python/fibonacci-word-fractal.py,
survived,"def test_devicon_unknown():
    file = MockFile('unknown.unknown')
    assert devicons.devicon(file) == 'î˜’'",tests/test_devicons.py,
survived,"def test_devicon_readme():
    file = MockFile('README.md')
    assert devicons.devicon(file) == 'î˜‰'
",tests/test_devicons.py,
survived,"    def start_merkle_task(self, *a, **kw) -> None:  # pragma: no cover - stub
        pass
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_codegen_safety.py,DummyLedger
survived,"def test_search_hello_world() -> None:
    reg = TemplateRegistry()
    engine = TemplateSearchEngine(reg)
    results = engine.search(""hello"")
    assert any(r.slug == ""hello-world"" for r in results)",tests/test_hello_world_template.py,
survived,"def test_math_env_rollout(openai_mock, monkeypatch):  # type: ignore[valid-type]
    """"""Ensure MathEnv produces a correctly graded rollout group.""""""

    # ------------------------------------------------------------------
    # Prepare mock dataset (train & test identical for simplicity)
    # ------------------------------------------------------------------
    example = {
        ""problem"": (
            ""A board game spinner is divided into three parts labeled $A$, $B$  and $C$. ""
            ""The probability of the spinner landing on $A$ is \\frac{1}{3} and the probability ""
            ""of the spinner landing on $B$ is \\frac{5}{12}.  What is the probability of the ""
            ""spinner landing on $C$? Express your answer as a common fraction.""
        ),
        ""level"": ""Level 1"",
        ""type"": ""Counting & Probability"",
        ""solution"": (
            ""The spinner is guaranteed to land on exactly one of the three regions, so we know that ""
            ""the sum of the probabilities of it landing in each region will be 1. If we let the probability ""
            ""of it landing in region $C$ be $x$, we then have the equation $1 = \\frac{5}{12}+\\frac{1}{3}+x$, ""
            ""from which we have $x=\\boxed{\\frac{1}{4}}$.""
        ),
    }
    fake_dataset = {""train"": [example], ""test"": [example]}

    # Monkeypatch datasets.load_dataset to return our fake dataset.
    def _fake_load_dataset(name, *_, **__):
        assert name == ""mock""
        return fake_dataset

    monkeypatch.setattr(datasets, ""load_dataset"", _fake_load_dataset)

    # ------------------------------------------------------------------
    # Prepare mocked OpenAI response (correct answer inside <answer> tags)
    # ------------------------------------------------------------------
    openai_mock.chat.completions.create.response = {
        ""choices"": [
            {
                ""index"": 0,
                ""finish_reason"": ""stop"",
                ""message"": {
                    ""content"": ""Sure! <think>some reasoning</think> <answer>\\frac{1}{4}</answer>"",
                    ""role"": ""assistant"",
                },
            }
        ],
    }

    # ------------------------------------------------------------------
    # Collect rollouts emitted by the environment
    # ------------------------------------------------------------------
    collected: deque[RolloutGroup] = deque()

    def sink(groups):  # type: ignore[override]
        collected.extend(groups)

    env = MathEnv(
        inference=InferenceEndpoint(""https://api.openai.com/v1""),
        rollout_sink=sink,  # type: ignore[arg-type]
        data_source=""mock"",
        split=""train"",
        max_iters=1,
        api_key=""sk-fake"",
        seed=123,
    )

    asyncio.run(env.run())

    # ------------------------------------------------------------------
    # Assertions
    # ------------------------------------------------------------------
    assert len(collected) == 1
    group = collected.pop()
    assert group.metadata[""correct""] is True
    assert group.rollouts[0].turns[1].reward == 1.0

    # The mocked endpoint should have been called exactly once
    assert openai_mock.chat.completions.create.route.call_count == 1",tests/rl/test_math_env.py,
survived,"    def __iter__(self):
        return iter(self.rollouts)
",marin/rl/types.py,RolloutGroup
survived,"    def __init__(self, inference: InferenceEndpoint, rollout_sink: RolloutSink):
        self._inference = inference
        self._rollout_sink = rollout_sink
        self._stop_event: asyncio.Event = asyncio.Event()
        logger.info(""Environment initialized with inference %s"", inference.address)
",marin/rl/env.py,AbstractMarinEnv
survived,"    async def shutdown(self) -> None:
        # Example clean-up
        logger.info(""HelloWorldEnv closed"")
",marin/rl/envs/hello.py,HelloWorldEnv
survived,"    def __init__(self) -> None:
        self.state = 0
",alpha_factory_v1/demos/era_of_experience/simulation/env_stub.py,SimpleExperienceEnv
survived,"async def trigger_research() -> str:
    resp = requests.post(f""{HOST}/agent/research/trigger"", timeout=5)
    resp.raise_for_status()
    return ""research queued""
",alpha_factory_v1/demos/alpha_agi_business_v1/openai_agents_bridge.py,
survived,"async def trigger_strategy() -> str:
    resp = requests.post(f""{HOST}/agent/strategy/trigger"", timeout=5)
    resp.raise_for_status()
    return ""strategy queued""
",alpha_factory_v1/demos/alpha_agi_business_v1/openai_agents_bridge.py,
survived,"    def strip_comments(s: str) -> str:
        return ""\n"".join([ln.split(""//"")[0].rstrip() for ln in s.splitlines()])
",tools/py2mochi/run_all.py,
survived,"    def visit_If(self, node: ast.If) -> None:
        test = self.convert_expr(node.test)
        self.emit(f""if {test} {{"")
        self.indent += 1
        for stmt in node.body:
            self.visit(stmt)
        self.indent -= 1
        if node.orelse:
            self.emit(""} else {"")
            self.indent += 1
            for stmt in node.orelse:
                self.visit(stmt)
            self.indent -= 1
            self.emit(""}"")
        else:
            self.emit(""}"")
",tools/py2mochi/py2mochi.py,Converter
survived,"def main() -> int:
    repo_root = Path(__file__).resolve().parents[1]
    demos_dir = repo_root / ""docs"" / ""demos""
    missing: list[str] = []

    for md_file in sorted(demos_dir.glob(""*.md"")):
        text = md_file.read_text(encoding=""utf-8"")
        m = PREVIEW_RE.search(text)
        if not m:
            missing.append(f""{md_file.relative_to(repo_root)}: missing preview"")
            continue
        rel = Path(m.group(1).split(""#"", 1)[0])
        target = (md_file.parent / rel).resolve()
        expected_dir = repo_root / ""docs"" / md_file.stem / ""assets""
        if not target.is_file() or not target.is_relative_to(expected_dir):
            missing.append(f""{md_file.relative_to(repo_root)}: {target.relative_to(repo_root)}"")

    if missing:
        print(""Missing preview assets:"", file=sys.stderr)
        for item in missing:
            print(f""  {item}"", file=sys.stderr)
        return 1
    return 0
",scripts/verify_gallery_assets.py,
survived,"def print_disclaimer() -> None:
    """"""Print the project disclaimer.""""""
    print(DISCLAIMER)
",alpha_factory_v1/utils/disclaimer.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/bitmap-read-a-ppm-file.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/bitwise-io-2.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/conditional-structures-10.py,
survived,"def test_build_tree(tmp_path: Path) -> None:
    db = tmp_path / ""a.db""
    arch = Archive(db)
    arch.add({""diff"": ""root.patch""}, 1.0)
    arch.add({""parent"": 1, ""diff"": ""child.patch""}, 0.6)
    df = ld.load_df(db)
    fig = ld.build_tree(df)
    assert isinstance(fig, go.Figure)
    data = fig.data[0]
    assert len(data.ids) == 2
    assert ""child.patch"" in data.hovertemplate
",tests/test_lineage_dashboard.py,
survived,"def test_load_df(tmp_path: Path) -> None:
    db = tmp_path / ""a.db""
    arch = Archive(db)
    arch.add({""diff"": ""root.patch""}, 0.5)
    arch.add({""parent"": 1, ""diff"": ""child.patch""}, 0.8)
    df = ld.load_df(db)
    assert list(df.columns) == [""id"", ""parent"", ""patch"", ""score""]
    assert len(df) == 2
    assert df.iloc[1][""parent""] == 1
",tests/test_lineage_dashboard.py,
survived,"    def execute(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        raise NotImplementedError",servers/server_clear_thought/core/base_tool.py,BaseTool
survived,"def test_orchestrator_command_runs() -> None:
    runner = CliRunner()
    with patch.object(cli, ""asyncio"") as aio:
        with patch.object(cli.orchestrator, ""Orchestrator""):
            res = runner.invoke(cli.main, [""orchestrator""])
            assert res.exit_code == 0
        aio.run.assert_called_once()",tests/test_demo_cli.py,
survived,"def main() -> int:
    try:
        with sync_playwright() as p:
            browser = p.chromium.launch()
            context = browser.new_context()
            page = context.new_page()
            page.goto(URL)
            page.wait_for_function(""navigator.serviceWorker.ready"")
            page.wait_for_selector(""body"")
            context.set_offline(True)
            page.reload()
            page.wait_for_selector(""body"")
            browser.close()
        return 0
    except PlaywrightError as exc:
        print(f""Playwright error: {exc}"", file=sys.stderr)
        return 1
    except Exception as exc:  # noqa: BLE001
        print(f""Offline check failed: {exc}"", file=sys.stderr)
        return 1
",scripts/verify_insight_offline.py,
survived,"def test_record_event():
    t = TelemetryCollector()
    t.record_event(
        TelemetryCollector.Category.EXECUTION,
        ""failed"",
        severity=TelemetryCollector.Severity.ERROR,
    )
    assert len(t.events) == 1
    ev = t.events[0]
    assert ev.category == TelemetryCollector.Category.EXECUTION
    assert ev.severity == TelemetryCollector.Severity.ERROR",tests/unit/test_telemetry_collector.py,
survived,"async def test_send_retry_success():
    with patch(""aiohttp.ClientSession"") as mock_session:
        resp1 = AsyncMock()
        resp1.status = 500
        resp1.text = AsyncMock(return_value=""bad"")
        cm1 = AsyncMock()
        cm1.__aenter__.return_value = resp1

        resp2 = AsyncMock()
        resp2.status = 200
        resp2.json = AsyncMock(return_value={""ok"": True})
        cm2 = AsyncMock()
        cm2.__aenter__.return_value = resp2

        mock_session.return_value.post.side_effect = [cm1, cm2]
        mock_session.return_value.close = AsyncMock()

        client = TelemetryAPIClient(
            {""trace"": EndpointConfig(""http://example.com"")}, retries=1, backoff=0
        )
        result = await client.send(""trace"", {""d"": 1})
        assert result == {""ok"": True}
        assert mock_session.return_value.post.call_count == 2
        await client.close()
",tests/unit/test_telemetry_client.py,
survived,"    def purge_old(self) -> None:
        """"""Remove records older than ``retention_days``.""""""
        if self.retention_days <= 0:
            return
        cutoff = datetime.utcnow() - timedelta(days=self.retention_days)
        cur = self.conn.cursor()
        cur.execute(""DELETE FROM telemetry WHERE timestamp < ?"", (cutoff.isoformat(),))
        self.conn.commit()
",src/meta_agent/telemetry_db.py,TelemetryDB
survived,"        def __exit__(self, *exc: object) -> None:
            pass
",tests/test_check_env_network.py,_Resp
survived,"    def text_to_speech(self, text, voice=""alloy""):
        """"""Convert text to speech using OpenAI TTS""""""
        res = self.requestor.post_tts_request(text, voice)
        if res.status_code == 200:
            return res.content
        else:
            print(res.text)
            return None
",web_api/dialogue_api.py,dialogue_api_handler
survived,"    def post_tts_request(self, text, voice=""alloy"", model=""tts-1""):
        """"""OpenAI TTS API request - Text to Speech""""""
        headers = self.headers.copy()
        headers[""Content-Type""] = ""application/json""
        data = {
            ""model"": model,
            ""input"": text,
            ""voice"": voice,
            ""response_format"": ""mp3"",
        }
        response = requests.post(
            ""https://api.openai.com/v1/audio/speech"",
            headers=headers,
            data=json.dumps(data),
        )
        return response
",src/openai_request.py,OpenAI_Request
survived,"    def add_child(self, parent: Node, child: Node) -> None:
        child.parent = parent
        parent.children.append(child)
",alpha_factory_v1/demos/meta_agentic_tree_search_v0/mats/tree.py,Tree
survived,"def main(argv: List[str] | None = None) -> None:
    parser = argparse.ArgumentParser(description=""Run the Meta-Agentic Tree Search demo"")
    parser.add_argument(""--episodes"", type=int, default=10, help=""Number of search iterations"")
    args = parser.parse_args(argv)
    run(args.episodes)
",alpha_factory_v1/demos/meta_agentic_tree_search_v0/run_demo.py,
survived,"    async def start(self) -> None:
        logger.info(
            ""A2ABus.start() called: port=%s broker=%s"",
            self.settings.bus_port,
            self.settings.broker_url or ""disabled"",
        )
        self._handshake_peers.clear()
        self._handshake_failures.clear()
        self._handshake_nonces.clear()
        if self.settings.broker_url and AIOKafkaProducer:
            self._producer = AIOKafkaProducer(bootstrap_servers=self.settings.broker_url)
            await self._producer.start()

        if not self.settings.bus_port or grpc is None:
            return
        server = grpc.aio.server()
        method = grpc.unary_unary_rpc_method_handler(
            self._handle_rpc,
            request_deserializer=lambda b: b,
            response_serializer=lambda b: b,
        )
        service = grpc.method_handlers_generic_handler(""bus.Bus"", {""Send"": method})
        server.add_generic_rpc_handlers((service,))
        if self.settings.bus_cert and self.settings.bus_key:
            key = Path(self.settings.bus_key).read_bytes()
            crt = Path(self.settings.bus_cert).read_bytes()
            creds = grpc.ssl_server_credentials(((key, crt),))
            server.add_secure_port(f""[::]:{self.settings.bus_port}"", creds)
        elif self.settings.allow_insecure:
            server.add_insecure_port(f""[::]:{self.settings.bus_port}"")
        else:
            raise RuntimeError(""AGI_INSIGHT_BUS_CERT and AGI_INSIGHT_BUS_KEY are required"")
        await server.start()
        self._server = server
",alpha_factory_v1/common/utils/messaging.py,A2ABus
survived,"    def compute_merkle_root(self) -> str:
        assert self.conn is not None
        if self.db_type == ""postgres"":
            with self.conn.cursor() as cur:
                cur.execute(""SELECT hash FROM messages ORDER BY id"")
                raw_hashes = [row[0] for row in cur.fetchall()]
        else:
            cur = self.conn.execute(""SELECT hash FROM messages ORDER BY id"")
            raw_hashes = [row[0] for row in cur.fetchall()]

        hashes: List[str] = []
        for h in raw_hashes:
            if not isinstance(h, str) or not h:
                continue
            try:
                bytes.fromhex(h)
            except Exception:
                continue
            hashes.append(h)

        return _merkle_root(hashes)
",alpha_factory_v1/common/utils/logging.py,Ledger
survived,"    async def _loop(self, interval: int) -> None:
        while True:
            await asyncio.sleep(interval)
            await self.broadcast_merkle_root()
",alpha_factory_v1/common/utils/logging.py,Ledger
survived,"def setup(level: str = ""INFO"", json_logs: bool = False) -> None:
    """"""Initialise the root logger if not configured.""""""

    if not logging.getLogger().handlers:
        if json_logs:
            handler = logging.StreamHandler()
            handler.setFormatter(_JsonFormatter())
            logging.basicConfig(level=level, handlers=[handler])
        else:
            fmt = ""%(asctime)s %(levelname)s %(name)s | %(message)s""
            if coloredlogs is not None:
                coloredlogs.install(level=level, fmt=fmt, datefmt=""%Y-%m-%d %H:%M:%S"")
            else:
                logging.basicConfig(level=level, format=fmt, datefmt=""%Y-%m-%d %H:%M:%S"")
",alpha_factory_v1/common/utils/logging.py,
survived,"def with_retry(func: Callable[P, Any], *, max_tries: int = 3) -> Callable[P, Any]:
    """"""Wrap *func* with exponential backoff and logging.""""""

    def _log_retry(details: dict[str, Any]) -> None:
        _log.warning(
            ""Retry %d/%d for %s due to %s"",
            details[""tries""],
            max_tries,
            getattr(details.get(""target""), ""__name__"", ""call""),
            details.get(""exception""),
        )

    is_async = inspect.iscoroutinefunction(func)

    if backoff is not None:
        wrapped = backoff.on_exception(
            backoff.expo,
            Exception,
            max_tries=max_tries,
            jitter=backoff.full_jitter,
            on_backoff=_log_retry,
        )(func)
        if is_async:
            return cast(Callable[P, Awaitable[T]], wrapped)
        return cast(Callable[P, T], wrapped)

    if is_async:

        async def wrapper_async(*args: P.args, **kwargs: P.kwargs) -> Any:
            for attempt in range(max_tries):
                try:
                    return await cast(Callable[P, Awaitable[T]], func)(*args, **kwargs)
                except Exception as exc:  # pragma: no cover - runtime errors
                    if attempt + 1 >= max_tries:
                        raise
                    _log_retry(
                        {
                            ""tries"": attempt + 1,
                            ""exception"": exc,
                            ""target"": func,
                        }
                    )
                    await asyncio.sleep(2**attempt * 0.1)
            raise AssertionError(""unreachable"")

        return cast(Callable[P, Any], wrapper_async)

    def wrapper_sync(*args: P.args, **kwargs: P.kwargs) -> Any:
        for attempt in range(max_tries):
            try:
                return cast(Callable[P, T], func)(*args, **kwargs)
            except Exception as exc:  # pragma: no cover - runtime errors
                if attempt + 1 >= max_tries:
                    raise
                _log_retry(
                    {
                        ""tries"": attempt + 1,
                        ""exception"": exc,
                        ""target"": func,
                    }
                )
                time.sleep(2**attempt * 0.1)
        raise AssertionError(""unreachable"")

    return cast(Callable[P, Any], wrapper_sync)",alpha_factory_v1/common/utils/retry.py,
survived,"    def publish(self, topic: str, msg: Dict[str, Any]) -> None:
        self._bus.publish(topic, msg)
",alpha_factory_v1/backend/services/kafka_service.py,KafkaService
survived,"    def start(self) -> None:
        init_metrics(self._port)
",alpha_factory_v1/backend/services/metrics_service.py,MetricsExporter
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-h/compiler/py/q9.py,Auto2
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-h/compiler/py/q15.py,Auto2
survived,"    def test_version_flag(self) -> None:
        result = subprocess.run(
            [sys.executable, ""-m"", ""alpha_factory_v1.edge_runner"", ""--version""],
            capture_output=True,
            text=True,
        )
        self.assertEqual(result.returncode, 0)
        self.assertEqual(result.stdout.strip(), edge_runner.__version__)
",tests/test_edge_runner_parse.py,TestParseArgs
survived,"    def test_list_agents_detail(self):
        class DAgent(AgentBase):
            NAME = ""detail""
            CAPABILITIES = [""bar""]

            async def step(self):
                return None

        meta = AgentMetadata(
            name=DAgent.NAME,
            cls=DAgent,
            version=""1.2"",
            capabilities=DAgent.CAPABILITIES,
            compliance_tags=[""x""],
        )
        register_agent(meta)
        detail = list_agents(detail=True)
        self.assertEqual(detail[0][""name""], DAgent.NAME)
        self.assertEqual(detail[0][""version""], ""1.2"")
        self.assertIn(""bar"", detail[0][""capabilities""])
",tests/test_agents_registry.py,TestAgentRegistryFunctions
survived,"            async def step(self):
                return None
",tests/test_agents_registry.py,TestRegisterDecorator.OkAgent
survived,"    def test_capabilities_nonempty(self):
        for name, meta in AGENT_REGISTRY.items():
            if not meta.capabilities:
                continue
            self.assertTrue(meta.capabilities)
",tests/test_agents_integrity.py,TestAgentsIntegrity
survived,"    def test_list_capabilities(self):
        caps = list_capabilities()
        self.assertIsInstance(caps, list)
        self.assertTrue(all(isinstance(c, str) for c in caps))
        # Should include at least one known capability from PingAgent
        self.assertIn(""diagnostics"", caps)
",tests/test_agents_integrity.py,TestAgentsIntegrity
survived,"    def inc(self) -> None:
        self.count += 1
",tests/test_agent_base.py,_Counter
survived,"    def __init__(self):
        self.count = 0
",tests/test_agent_base.py,_Counter
survived,"    def __init__(self):
        self.value = None
",tests/test_agent_base.py,_Gauge
survived,"    def __init__(self):
        self.calls = []
",tests/unit/test_tool_research_manager.py,DummyTool
survived,"        def __call__(self, *_, **__):  # noqa: D401
            return ""Hosted tool unavailable in this environment.""
",src/meta_agent/research_manager.py,_StubWebSearchTool
survived,"def test_search_caching():
    tool = DummyTool()
    mgr = ToolResearchManager(web_search_tool=tool, enabled=True)
    r1 = mgr.research(""foo"", ""bar"")
    r2 = mgr.research(""foo"", ""bar"")
    assert r1 == [""result line 1"", ""result line 2""]
    assert r2 == r1
    assert len(tool.calls) == 1
",tests/unit/test_tool_research_manager.py,
survived,"def _enc(val: str | None) -> str:
    return base64.b64encode(str(val or """").encode()).decode()
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/manual_build.py,
survived,"def get_raw_value(dat: bytes | bytearray, sig: Signal) -> int:
  ret = 0
  i = sig.msb // 8
  bits = sig.size
  while 0 <= i < len(dat) and bits > 0:
    lsb = sig.lsb if (sig.lsb // 8) == i else i * 8
    msb = sig.msb if (sig.msb // 8) == i else (i + 1) * 8 - 1
    size = msb - lsb + 1
    d = (dat[i] >> (lsb - (i * 8))) & ((1 << size) - 1)
    ret |= d << (bits - size)
    bits -= size
    i = i - 1 if sig.is_little_endian else i + 1
  return ret
",opendbc/can/parser.py,
survived,"def _get_dbc(dbc_name: str) -> DBC:
  dbc_path = dbc_name
  if not os.path.exists(dbc_path):
    dbc_path = os.path.join(os.path.dirname(__file__), "".."", ""dbc"", dbc_name + "".dbc"")
  if dbc_name in DBC_CACHE:
    return DBC_CACHE[dbc_name]
  try:
    dbc = parse_dbc(dbc_path)
  except FileNotFoundError as e:
    raise RuntimeError(f""DBC file not found: {dbc_path}"") from e
  DBC_CACHE[dbc_name] = dbc
  return dbc
",opendbc/can/parser.py,
survived,"def _lookup_host(host):
    import socket
    try:
        return socket.gethostbyname_ex(host)[2], None
    except Exception as e:
        return [], e
",tests/rosetta/transpiler/Python/DNS-query.py,
survived,"    async def step(prompt, **kwargs):
        counter[""i""] += 1
        return counter[""i""]
",tests/test_workflow.py,
survived,"def main(argv: list[str] | None = None) -> None:
    parser = argparse.ArgumentParser(description=""Create config.env if missing"")
    parser.add_argument(
        ""--dir"",
        type=Path,
        default=Path(__file__).resolve().parents[1],
        help=""Demo directory (default: parent of this script)"",
    )
    args = parser.parse_args(argv)
    path, created = ensure_config(args.dir)
    if created:
        print(f""Created {path}. Edit this file to set secrets."")
    else:
        print(f""{path} already exists. Edit it to update secrets."")
",alpha_factory_v1/demos/alpha_agi_business_v1/scripts/setup_config.py,
survived,"def test_plain_ndarray_selector():
    B, V = Axis(""batch"", 3), Axis(""vocab"", 5)
    x = hax.arange((B, V))
    idx = jnp.array([0, 2, 4], dtype=jnp.int32)
    out = x[""vocab"", idx]
    assert out.axes == (B,)
    assert jnp.array_equal(out.array, x.array[jnp.arange(3), idx])
",tests/test_scatter_gather.py,
survived,"def test_mixed_int_and_selector():
    B, C, V = Axis(""batch"", 3), Axis(""channel"", 2), Axis(""vocab"", 6)
    x = hax.arange((B, C, V))
    idx = hax.arange((B,), dtype=jnp.int32) % V.size
    out = x[""channel"", 1, ""vocab"", idx]
    assert out.axes == (B,)
    ref = x.array[:, 1, :][jnp.arange(3), idx.array]
    assert jnp.array_equal(out.array, ref)
",tests/test_scatter_gather.py,
survived,"def _ref_gather(src, axis, idx):
    ax_num = src.axes.index(axis)
    # broadcast idx to match src without the gathered axis
    other_axes = tuple(ax for ax in src.axes if ax != axis)
    broadcast_axes = other_axes
    for ax in idx.axes:
        if ax not in broadcast_axes:
            broadcast_axes += (ax,)
    idx_b = hax.broadcast_to(idx, broadcast_axes, enforce_no_extra_axes=False)
    if idx_b.array.ndim == src.array.ndim - 1:
        idx_arr = idx_b.array[..., None]
    else:
        idx_arr = idx_b.array
    out = jnp.take_along_axis(src.array, idx_arr, axis=ax_num)
    if idx_b.array.ndim == src.array.ndim - 1:
        out = out.squeeze(ax_num)
    return out
",tests/test_scatter_gather.py,
survived,"def main():
    parser = argparse.ArgumentParser(description=""Run simple LLM inference"")
    parser.add_argument(""model"", help=""Path to HF checkpoint"")
    parser.add_argument(""prompts"", help=""Text file with one prompt per line"")
    parser.add_argument(""--temperature"", type=float, default=0.6)
    parser.add_argument(""--max_tokens"", type=int, default=256)
    args = parser.parse_args()

    with open(Path(args.prompts), ""r"", encoding=""utf-8"") as f:
        prompts = [line.strip() for line in f if line.strip()]

    llm = LLM(args.model)
    sp = SamplingParams(temperature=args.temperature, max_tokens=args.max_tokens)
    outputs = llm.generate(prompts, sp)

    for prompt, out in zip(prompts, outputs):
        print(f""Prompt: {prompt}\nCompletion: {out['text']}\n"")
",src/levanter/main/nano_inference.py,
survived,"    def heuristic(self, start):
        """"""

        Estimates the number of moves from start to goal.
        The goal was preprocessed in __init__.

        """"""

        distance = 0

        # local variables for instance variables

        t = start.tiles
        g = self.goal_map
        rc = self.row_conflicts
        cc = self.col_conflicts

        # calculate manhattan distance

        for row in range(4):
            for col in range(4):
                start_tilenum = t[row][col]
                if start_tilenum != 0:
                    (grow, gcol) = g[start_tilenum]
                    distance += abs(row - grow) + abs(col - gcol)

        # add linear conflicts

        for row in range(4):
            curr_row = t[row]
            distance += rc[row][curr_row]

        for col in range(4):
            col_tuple = (t[0][col], t[1][col], t[2][col], t[3][col])
            distance += cc[col][col_tuple]

        return distance
",tests/rosetta/x/Python/15-puzzle-solver/15-puzzle-solver-2.py,HeuristicObj
survived,"def __dir__():
    return sorted(__all__ + [
        ""__all__"", ""__builtins__"", ""__cached__"", ""__doc__"", ""__file__"",
        ""__loader__"", ""__name__"", ""__package__"", ""__path__"", ""__spec__"",
    ])",third_party/tree-sitter-racket/bindings/python/tree_sitter_racket/__init__.py,
survived,"            def dec(f):
                return f
",tests/test_agent_aiga_entrypoint.py,TestAgentAIGAEntry
survived,"def heuristic_policy(obs: List[float]) -> dict[str, Any]:
    """"""Return a suggested action based on observation heuristics.""""""
    power_ok, traffic_ok, _ = obs
    if power_ok < traffic_ok:
        # Prioritise power grid repairs
        return {""action"": {""id"": 0}}
    return {""action"": {""id"": 1}}
",alpha_factory_v1/demos/omni_factory_demo/plugins/example_agent_plugin.py,
survived,"    def test_bridge_compiles(self):
        path = Path('alpha_factory_v1/demos/alpha_asi_world_model/openai_agents_bridge.py')
        py_compile.compile(path, doraise=True)
",tests/test_openai_bridge.py,TestOpenAIBridge
survived,"        def __init__(self, *_, **__):
            pass
",alpha_factory_v1/demos/muzero_planning/agent_muzero_entrypoint.py,OpenAIAgent
survived,"async def run_meta_search(generations: int = 3) -> str:
    """"""Execute the demo search loop for a given number of generations.""""""
    provider = os.getenv(""LLM_PROVIDER"", ""mistral:7b-instruct.gguf"")
    await meta_loop(generations, provider)
    return f""Completed {generations} generations""
",alpha_factory_v1/demos/meta_agentic_agi/openai_agents_bridge.py,
survived,"async def list_agents() -> list[str]:
    resp = requests.get(f""{HOST}/agents"", timeout=5)
    resp.raise_for_status()
    return resp.json()
",alpha_factory_v1/demos/alpha_agi_business_v1/openai_agents_bridge.py,
survived,"def main(argv: List[str] | None = None) -> None:  # pragma: no cover - CLI wrapper
    p = argparse.ArgumentParser(description=__doc__)
    p.add_argument(""-n"", ""--num"", type=int, default=1, help=""number of opportunities to sample"")
    p.add_argument(""--list"", action=""store_true"", help=""list all sample opportunities and exit"")
    p.add_argument(""--seed"", type=int, help=""seed RNG for reproducible output"")
    p.add_argument(""--ledger"", help=""path to ledger JSON file"")
    p.add_argument(""--no-log"", action=""store_true"", help=""do not write to ledger"")
    args = p.parse_args(argv)

    if args.list:
        print(json.dumps(SAMPLE_ALPHA, indent=2))
        return

    ledger = _ledger_path(args.ledger)
    picks = discover_alpha(args.num, seed=args.seed, ledger=ledger)
    if args.no_log:
        ledger.unlink(missing_ok=True)
    print(json.dumps(picks[0] if args.num == 1 else picks, indent=2))
    print(f""Logged to {ledger}"" if not args.no_log else ""Ledger write skipped"")
",alpha_factory_v1/demos/cross_industry_alpha_factory/cross_alpha_discovery_stub.py,
survived,"    def test_list_option(self) -> None:
        result = subprocess.run([sys.executable, STUB, '--list'], capture_output=True, text=True)
        self.assertEqual(result.returncode, 0)
        data = json.loads(result.stdout)
        self.assertIsInstance(data, list)
        self.assertGreaterEqual(len(data), 5)
",tests/test_cross_alpha_discovery.py,TestCrossAlphaDiscoveryStub
survived,"    async def policy(self, obs, ctx):  # type: ignore[override]
        steps = int(obs.get(""steps"", 500)) if isinstance(obs, dict) else 500
        return await self.tools.run_episode(steps)
",alpha_factory_v1/demos/muzero_planning/agent_muzero_entrypoint.py,MuZeroAgent
survived,"    def __init__(self, n: int):
        self.n = n
",tests/machine/x/python/record_assign.py,Counter
survived,"    def get_state(self):
        """"""Return position and velocity as Python lists for easy C++ access.""""""
        return self.position.cpu().tolist(), self.velocity.cpu().tolist()",pytorch_solver.py,PytorchSolver
survived,"    def __init__(self, match: int = 3, mismatch: int = -3, gap: int = -2) -> None:
        self.match = match
        self.mismatch = mismatch
        self.gap = gap
        if _GPU_AVAILABLE:
            self._setup_opencl()
",src/python/gpu_smith_waterman.py,SmithWatermanGPU
survived,"    def test_stable_token_env_override(self) -> None:
        """"""STABLE_TOKEN should reflect the environment override.""""""
        with patch.dict(os.environ, {""STABLE_TOKEN"": ""0x123""}):
            mod = importlib.reload(data_feeds)
            self.assertEqual(mod.STABLE_TOKEN, ""0x123"")
        importlib.reload(data_feeds)
",tests/test_macro_sentinel.py,TestMacroSentinel
survived,"def cleanup_acm_certificates(
    neo4j_session: neo4j.Session, common_job_parameters: Dict
) -> None:
    logger.debug(""Running ACM certificate cleanup job."")
    GraphJob.from_node_schema(ACMCertificateSchema(), common_job_parameters).run(
        neo4j_session
    )
",cartography/intel/aws/acm.py,
survived,"    def num_pages(self) -> int:
        return self.page_indices.axis_size(""page"") * self.page_indices.axis_size(""seq"")
",src/levanter/layers/page_table.py,PageTable
survived,"    def __post_init__(self):
        assert isinstance(self.num_seqs, jnp.ndarray), ""num_seqs must be a JAX ndarray""",src/levanter/layers/page_table.py,PageBatchInfo
survived,"async def test_agent_routes_prompt_through_router():
    adapter = DummyAdapter()
    router = GuardrailModelRouter({""gpt"": adapter}, default_model=""gpt"")
    agent = GuardrailDesignerAgent(model_router=router)

    result = await agent.run({""prompt"": ""hello""})

    assert result[""status""] == ""success""
    assert result[""output""] == ""hello:guarded""",tests/test_guardrail_designer_agent.py,
survived,"    async def output_guardrail(output: str):
        order.append(f""out:{output}"")
",tests/test_guardrail_router.py,
survived,"    def __init__(self, adapters: Dict[str, ModelAdapter], default_model: str) -> None:
        if not adapters:
            raise ValueError(""At least one model adapter must be provided"")
        if default_model not in adapters:
            raise ValueError(""Default model must exist in adapters"")
        self.adapters = adapters
        self.default_model = default_model
        self.input_guardrails: List[Callable[[str], Awaitable[None]]] = []
        self.output_guardrails: List[Callable[[str], Awaitable[None]]] = []
",src/meta_agent/services/guardrail_router.py,GuardrailModelRouter
survived,"    def __init__(
        self,
        model_router: Optional[GuardrailModelRouter] = None,
        *,
        api_key: Optional[str] = None,
        default_model: str = ""gpt-4o"",
    ) -> None:
        super().__init__(name=""GuardrailDesignerAgent"", tools=[])

        if model_router is None:
            service = LLMService(api_key=api_key, model=default_model)
            adapter = LLMModelAdapter(service)
            model_router = GuardrailModelRouter({default_model: adapter}, default_model)
        self.model_router = model_router
        self.default_model = default_model
        logger.info(""GuardrailDesignerAgent initialized with model %s"", default_model)
",src/meta_agent/agents/guardrail_designer_agent.py,GuardrailDesignerAgent
survived,"    async def invoke(
        self, prompt: str, context: Optional[Dict[str, Any]] | None = None
    ) -> str:
        return await self.llm_service.generate_code(prompt, context or {})",src/meta_agent/services/guardrail_router.py,LLMModelAdapter
survived,"    def _check_stop_grad(self, name: str):
        """"""Verify gradients ignore values detached with ``stop``.""""""
        try:
            backend.set_backend(name)
        except ImportError:
            raise unittest.SkipTest(f""{name} backend not available"")
        b = backend.current()

        def f(x):
            return b.sum(b.mul(b.stop(x), x))

        g = b.grad(f)
        x = b.array([2.0, 3.0], requires_grad=True)
        grad = to_numpy(g(x))
        np.testing.assert_allclose(np.array(grad), np.array([2.0, 3.0]))
",tests/test_autograd.py,TestAutograd
survived,"def stopGrad(x, backend_name=""numpy""):
    backend.set_backend(backend_name)
    b = backend.current()

    def f(t):
        return b.sum(b.mul(b.stop(t), t))

    g = b.grad(f)
    out = g(b.array(x, requires_grad=True))
    out = to_numpy(out)
    return out.tolist() if isinstance(out, np.ndarray) else out",tests/kgtests/autograd/helpers.py,
survived,"def mixedGradX(x, y, backend_name=""numpy""):
    backend.set_backend(backend_name)
    b = backend.current()

    def f(a, b_):
        return b.sum(b.mul(a, b_))

    g = b.grad(f, wrt=0)
    out = g(b.array(x, requires_grad=True), b.array(y, requires_grad=True))
    out = to_numpy(out)
    return out.tolist() if isinstance(out, np.ndarray) else out
",tests/kgtests/autograd/helpers.py,
survived,"def scalarSquareGrad(x, backend_name=""numpy""):
    backend.set_backend(backend_name)
    b = backend.current()

    def f(t):
        return b.mul(t, t)

    g = b.grad(f)
    out = g(b.array(x, requires_grad=True))
    out = to_numpy(out)
    return float(out) if np.ndim(out) == 0 else out
",tests/kgtests/autograd/helpers.py,
survived,"    def test_stop_grad_numpy(self):
        self._check_stop_grad(""numpy"")
",tests/test_autograd.py,TestAutograd
survived,"async def _run_concurrent() -> None:
    client, _ = await _make_client()
    async with client:
        await asyncio.gather(*[client.get(""/"") for _ in range(5)])
",tests/test_rate_lock.py,
deleted,"    def __init__(self):
        self.carFingerprint = ""stub""
        self.brand = ""toyota""
        self.lateralTuning = SimpleNamespace()
        self.lateralTuning.torque = SimpleNamespace(friction=0.0, latAccelFactor=1.0)
        self.lateralTuning.which = lambda: ""torque""
",selfdrive/locationd/test/test_torqued.py,CPStub
survived,"def test_archive_quota_toast() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri()

    with sync_playwright() as p:
        browser = p.chromium.launch()
        page = browser.new_page()
        page.goto(url)
        page.wait_for_selector(""#controls"")
        page.wait_for_function(""window.archive !== undefined"")
        page.evaluate(
            """"""
            const orig = IDBObjectStore.prototype.put;
            let thrown = false;
            IDBObjectStore.prototype.put = function(...a) {
                if (!thrown) {
                    thrown = true;
                    throw new DOMException('full','QuotaExceededError');
                }
                return orig.apply(this, a);
            };
            """"""
        )
        page.evaluate(""window.archive.add(1, {}, [{logic:1,feasible:1}])"")
        page.wait_for_selector(""#toast.show"")
        assert ""Archive full"" in page.inner_text(""#toast"")
        browser.close()",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_archive_quota.py,
survived,"    async def run_cycle(self) -> None:
        pass
",tests/test_agent_runner.py,DummyBaseAgent
survived,"    def unsubscribe(self, topic: str, handler: Callable[[Envelope], Awaitable[None] | None]) -> None:
        """"""Remove a previously subscribed handler.""""""
        handlers = self._subs.get(topic)
        if not handlers:
            return
        with contextlib.suppress(ValueError):
            handlers.remove(handler)
        if not handlers:
            self._subs.pop(topic, None)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/messaging.py,A2ABus
survived,"    def __init__(self, bus: messaging.A2ABus, ledger: _Ledger) -> None:
        super().__init__(""dummy"", bus, ledger)
        self.count = 0
",tests/test_agent_runner.py,DummyBaseAgent
survived,"def test_progress_dom_updates() -> None:
    """"""Smoke test that the React dashboard receives progress events.""""""

    pw = pytest.importorskip(""playwright.sync_api"")
    from fastapi.testclient import TestClient
    from alpha_factory_v1.demos.alpha_agi_insight_v1.src.interface import api_server

    client = TestClient(api_server.app)
    browser = pw.sync_playwright().start().chromium.launch()
    page = browser.new_page()
    page.goto(str(client.base_url) + ""/web/"")
    page.click(""text=Run simulation"")
    page.wait_for_selector(""#capability"")
    browser.close()",tests/test_web_app.py,
survived,"    def tearDown(self) -> None:
        llm._cache_mem = self.orig_cache
        llm._CACHE_SIZE = self.orig_size
        llm._DB = self.orig_db
",tests/test_llm_cache.py,TestLLMCacheLRU
survived,"def test_curriculum_switch(tmp_path: Path) -> None:
    db_path = tmp_path / ""archive.db""
    switcher = CurriculumSwitcher(db_path, window=10)

    # Start on mini dataset
    assert switcher.dataset == ""swe_mini""

    rates = [0.2, 0.5, 0.6]
    for r in rates:
        metrics = compute_fitness(_results(switcher.dataset, r))
        switcher.update(metrics)
    assert switcher.dataset == ""swebench_verified_mini""

    rates = [0.6, 0.6, 0.6, 0.6]
    for r in rates:
        metrics = compute_fitness(_results(switcher.dataset, r))
        switcher.update(metrics)
    assert switcher.dataset == ""polyglot_lite""

    # state persisted
    db = ArchiveDB(db_path)
    assert db.get_state(""dataset"") == ""polyglot_lite""",tests/test_curriculum_switcher.py,
survived,"def _read_logs(paths: Iterable[Path]) -> List[Dict[str, Any]]:
    records: List[Dict[str, Any]] = []
    for p in paths:
        with p.open(encoding=""utf-8"") as fp:
            for line in fp:
                line = line.strip()
                if not line:
                    continue
                try:
                    records.append(json.loads(line))
                except json.JSONDecodeError:
                    continue
    return records
",alpha_factory_v1/demos/alpha_agi_insight_v1/tools/export_tree.py,
survived,"    async def __aexit__(self, exc_type, exc, tb) -> None:
        """"""Stop the bus when exiting an async context.""""""
        await self.stop()
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/messaging.py,A2ABus
survived,"    def test_reshape_wildcard_front(self):
        """"""Wildcard as the first dimension""""""
        self.assert_eval_cmp('[[] 2]:^[1 2 3 4 5 6]', '[[1 2] [3 4] [5 6]]')
",tests/test_numpy_slice.py,TestNumpySliceBehavior
survived,"def _meta(slug: str) -> TemplateMetadata:
    return TemplateMetadata(
        slug=slug,
        title=slug,
        description=""demo"",
        category=TemplateCategory.CONVERSATION,
        complexity=TemplateComplexity.BASIC,
        tags=[slug],
    )
",tests/test_template_index.py,
survived,"async def healthz() -> str:
    """"""Liveness probe.""""""

    return ""ok""",alpha_factory_v1/demos/alpha_agi_insight_v1/src/evolution_worker.py,
survived,"    def format(self, record: logging.LogRecord) -> str:  # noqa: D401 - short
        data = {
            ""ts"": datetime.fromtimestamp(record.created).isoformat(timespec=""seconds""),
            ""lvl"": record.levelname,
            ""name"": record.name,
            ""msg"": record.getMessage(),
        }
        return json.dumps(data)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/logging.py,_JsonFormatter
survived,"    def _select(self, scores, k=3):
        idx = max(random.sample(range(self.pop_size), k), key=lambda i: scores[i])
        return self.population[idx]
",alpha_factory_v1/demos/aiga_meta_evolution/meta_evolver.py,MetaEvolver
survived,"def _docker_available() -> bool:
    if shutil.which(""docker"") is None:
        return False
    try:
        subprocess.run([""docker"", ""info""], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)
        return True
    except Exception:
        return False
",alpha_factory_v1/tests/test_smoke.py,
survived,"def test_requires_node_20() -> None:
    browser_dir = Path(__file__).resolve().parents[1]
    script = browser_dir / ""build.js""
    node_code = (
        ""Object.defineProperty(process.versions,'node',{value:'19.0.0'});""
        f"" import('./{script.name}')""
    )
    res = subprocess.run(
        [""node"", ""-e"", node_code],
        cwd=browser_dir,
        text=True,
        capture_output=True,
    )
    assert res.returncode == 1
    assert ""Node.js 20+ is required. Current version: 19.0.0"" in res.stderr
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_node_version.py,
survived,"        def raise_for_status(self) -> None:
            pass
",tests/test_aiga_openai_bridge_offline.py,DummyResponse
survived,"def test_exr(h, f):
    """"""verify is the image ia a OpenEXR fileOpenEXR.""""""
    if h.startswith(b'\x76\x2f\x31\x01'):
        return 'exr'
",metaflow/_vendor/imghdr/__init__.py,
survived,"def test_ppm(h, f):
    """"""Verify if the image is a PPM (portable pixmap).""""""
    if len(h) >= 3 and \
        h[0] == ord(b'P') and h[1] in b'36' and h[2] in b' \t\n\r':
        return 'ppm'
",metaflow/_vendor/imghdr/__init__.py,
survived,"def test():
    import sys
    recursive = 0
    if sys.argv[1:] and sys.argv[1] == '-r':
        del sys.argv[1:2]
        recursive = 1
    try:
        if sys.argv[1:]:
            testall(sys.argv[1:], recursive, 1)
        else:
            testall(['.'], recursive, 1)
    except KeyboardInterrupt:
        sys.stderr.write('\n[Interrupted]\n')
        sys.exit(1)
",metaflow/_vendor/imghdr/__init__.py,
survived,"def test_rast(h, f):
    """"""test for the Sun raster file.""""""
    if h.startswith(b'\x59\xA6\x6A\x95'):
        return 'rast'
",metaflow/_vendor/imghdr/__init__.py,
survived,"def browse_file(entry):
    path = filedialog.askopenfilename(filetypes=[(""CSV files"", ""*.csv""), (""All files"", ""*.*"")])
    if path:
        entry.delete(0, tk.END)
        entry.insert(0, path)
",arr_gui.py,
survived,"def radarr_import(csv_path: str, cfg: configparser.ConfigParser) -> None:
    baseurl = cfg[""radarr""][""baseurl""]
    urlbase = cfg[""radarr""].get(""urlbase"", """")
    api_key = cfg[""radarr""][""api_key""]
    root = cfg[""radarr""][""rootfolderpath""]
    profile = cfg[""radarr""][""qualityProfileId""]
    search = cfg.getboolean(""radarr"", ""searchForMovie"", fallback=False)

    headers = {""Content-type"": ""application/json"", ""X-Api-Key"": api_key}
    session = requests.Session()

    with open(csv_path, encoding=""utf-8"") as f:
        reader = csv.DictReader(f)
        for row in reader:
            title = row.get(""title"")
            year = row.get(""year"")
            imdbid = row.get(""imdbid"")
            if imdbid:
                url = f""{baseurl}{urlbase}/api/v3/movie/lookup/imdb?imdbId={imdbid}""
            else:
                term = urllib.parse.quote_plus(f""{title} {year}"" if year else title)
                url = f""{baseurl}{urlbase}/api/v3/movie/lookup?term={term}""
            rsp = session.get(url, headers=headers)
            if rsp.status_code != 200 or rsp.text in ("""", ""[]""):
                messagebox.showwarning(""Radarr"", f""{title} not found"")
                continue
            data = rsp.json()
            if isinstance(data, list):
                data = data[0]
            payload = {
                ""title"": data.get(""title""),
                ""tmdbId"": data.get(""tmdbId""),
                ""year"": data.get(""year""),
                ""titleSlug"": data.get(""titleSlug""),
                ""qualityProfileId"": int(profile),
                ""rootFolderPath"": root,
                ""monitored"": True,
                ""images"": data.get(""images"", []),
                ""addOptions"": {""searchForMovie"": search},
            }
            add_url = f""{baseurl}{urlbase}/api/v3/movie""
            session.post(add_url, headers=headers, json=payload)
",arr_gui.py,
survived,"    def time_iso(self) -> str:
        """"""Return the current time in ISO 8601 format.""""""
        return datetime.now(timezone.utc).isoformat()
",src/agents/tracing/setup.py,TraceProvider
survived,"def test_resolve_url_fallback(monkeypatch: pytest.MonkeyPatch, requests_mock: ""requests_mock.Mocker"") -> None:
    import scripts.download_wasm_gpt2 as dw

    urls = [
        ""https://example.com/wasm-gpt2.tar"",
        ""https://another.com/wasm-gpt2.tar"",
        dw._DEFAULT_URLS[0],
    ]

    with monkeypatch.context() as m:
        m.delenv(""WASM_GPT2_URL"", raising=False)
        m.setattr(dw, ""_DEFAULT_URLS"", urls)
        requests_mock.head(urls[0], status_code=404)
        requests_mock.head(urls[1], exc=requests.exceptions.RequestException)
        requests_mock.head(urls[2], status_code=200)
        assert dw._resolve_url() == urls[2]",tests/test_download_openai_gpt2.py,
survived,"def _diversity(pop: list[mats.Individual]) -> float:
    if len(pop) < 2:
        return 0.0
    dists = []
    for i in range(len(pop)):
        for j in range(i + 1, len(pop)):
            a = pop[i].genome
            b = pop[j].genome
            d = sum((x - y) ** 2 for x, y in zip(a, b)) ** 0.5
            dists.append(d)
    return sum(dists) / len(dists)
",tests/test_mats_ops.py,
survived,"def resolve_module(target: str, base_path: str) -> Tuple[str, str]:
    """"""Resolve module path and infer language.""""""
    parts = target.split(""."")
    level = 0
    while level < len(parts) and parts[level] == """":
        level += 1
    actual_parts = parts[level:]

    for sp in site.getsitepackages():
        res = _candidate_from(sp, actual_parts)
        if res:
            return res

    base_dir = base_path if os.path.isdir(base_path) else os.path.dirname(base_path)
    for _ in range(max(level - 1, 0)):
        base_dir = os.path.dirname(base_dir)
    res = _candidate_from(base_dir, actual_parts)
    if res:
        return res

    jacpath = os.getenv(""JACPATH"")
    if jacpath:
        res = _candidate_from(jacpath, actual_parts)
        if res:
            return res
        target_jac = actual_parts[-1] + "".jac""
        target_py = actual_parts[-1] + "".py""
        for root, _, files in os.walk(jacpath):
            if target_jac in files:
                return os.path.join(root, target_jac), ""jac""
            if target_py in files:
                return os.path.join(root, target_py), ""py""

    return os.path.join(base_dir, *actual_parts), ""py""
",jac/jaclang/utils/module_resolver.py,
survived,"    def test_valid_signature(self) -> None:
        exit_code = self._run_main(self.wheel_path)
        self.assertEqual(exit_code, 0)
",tests/test_verify_wheel_sig.py,VerifyWheelSigTests
survived,"    async def handler(env: messaging.Envelope) -> None:
        events.append(env)
",tests/test_message_bus.py,
survived,"def verify_environment() -> None:
    """"""Best-effort runtime dependency check.""""""
    try:
        import check_env  # type: ignore

        check_env.main([])
    except (ImportError, ModuleNotFoundError) as exc:  # pragma: no cover
        print(f""Environment verification failed: {exc}"")
    except Exception as exc:
        print(f""Unexpected error during environment verification: {exc}"")
        raise
",alpha_factory_v1/demos/alpha_agi_insight_v0/insight_demo.py,
survived,"def load_config(path: Path) -> dict:
    """"""Load a YAML configuration with a fallback parser.""""""
    if not path.exists():
        return {}
    text = path.read_text(encoding=""utf-8"")
    try:
        import yaml  # type: ignore

        return yaml.safe_load(text) or {}
    except Exception:
        cfg: dict[str, object] = {}
        for line in text.splitlines():
            if "":"" in line:
                key, val = line.split("":"", 1)
                val = val.strip()
                if val.replace(""."", """", 1).isdigit():
                    cfg[key.strip()] = float(val) if ""."" in val else int(val)
                else:
                    cfg[key.strip()] = val
        return cfg
",alpha_factory_v1/demos/alpha_agi_insight_v0/insight_demo.py,
survived,"def cytomat_rack_29mm_16(name: str):
  return _cytomat_rack(name=name, site_height=29, num_sites=16, model=""cytomat_rack_29mm_16"")
",pylabrobot/storage/cytomat/racks.py,
survived,"  async def set_temperature(self, temperature: float):
    print(f""Setting temperature to {temperature}"")
",pylabrobot/storage/chatterbox.py,IncubatorChatterboxBackend
survived,"  async def wait_for_transfer_station(self, occupied: bool = False):
    """"""Wait for the transfer station to be occupied, or unoccupied.""""""
    while (await self.get_overview_register()).transfer_station_occupied != occupied:
      await asyncio.sleep(1)
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend
survived,"  async def stop_shaking(self):
    pass",pylabrobot/storage/backend.py,IncubatorBackend
survived,"  async def get_temperature(self) -> float:
    return (await self.get_incubation_query(""it"")).actual_value
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend
survived,"  async def setup(self):
    await self.wait_for_task_completion()
",pylabrobot/storage/cytomat/cytomat.py,CytomatChatterbox
survived,"  async def get_o2(self) -> CytomatIncupationResponse:
    return await self.get_incubation_query(""io"")
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend
survived,"  async def take_in_plate(self, plate: Plate, site: PlateHolder):
    await self.action_transfer_to_storage(site)
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend
survived,"  async def get_warning_register(self) -> WarningRegister:
    hex_value = await self.send_command(""ch"", ""bw"", """")
    for member in WarningRegister:
      if hex_value == member.value:
        return member

    await self.reset_error_register()
    raise Exception(f""Unknown warning register value: {hex_value}"")
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend
survived,"  async def fetch_plate_to_loading_tray(self, plate_name: str) -> Plate:
    """"""Fetch a plate from the incubator and put it on the loading tray.""""""

    site = self.get_site_by_plate_name(plate_name)
    plate = site.resource
    assert plate is not None
    await self.backend.fetch_plate_to_loading_tray(plate)
    plate.unassign()
    self.loading_tray.assign_child_resource(plate)
    return plate
",pylabrobot/storage/incubator.py,Incubator
survived,"  def __init__(self, port: str):
    super().__init__()
    self.io = Serial(
      port=port,
      baudrate=self.default_baud,
      bytesize=serial.EIGHTBITS,
      parity=serial.PARITY_EVEN,
      stopbits=serial.STOPBITS_ONE,
      write_timeout=1,
      timeout=1,
      rtscts=True,
    )
",pylabrobot/storage/cytomat/heraeus_cytomat_backend.py,HeraeusCytomatBackend
survived,"  async def get_error_register(self) -> ErrorRegister:
    hex_value = await self.send_command(""ch"", ""be"", """")
    for member in ErrorRegister:
      if hex_value == member.value:
        return member

    await self.reset_error_register()
    raise Exception(f""Unknown error register value: {hex_value}"")
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend
survived,"  async def set_racks(self, racks: List[PlateCarrier]):
    await super().set_racks(racks)
    warnings.warn(""Cytomat racks need to be configured manually on each setup"")
",pylabrobot/storage/cytomat/heraeus_cytomat_backend.py,HeraeusCytomatBackend
survived,"  async def start_shaking(self, frequency: float):
    """"""Start shaking the incubator at the given frequency in Hz.""""""
    pass
",pylabrobot/storage/backend.py,IncubatorBackend
survived,"  def summary(self) -> str:
    def create_pretty_table(header, *columns) -> str:
      col_widths = [
        max(len(str(item)) for item in [header[i]] + list(columns[i])) for i in range(len(header))
      ]

      def format_row(row, border=""|"") -> str:
        return (
          f""{border} ""
          + "" | "".join(f""{str(row[i]).ljust(col_widths[i])}"" for i in range(len(row)))
          + f"" {border}""
        )

      def separator_line(cross: str = ""+"", line: str = ""-"") -> str:
        return cross + cross.join(line * (width + 2) for width in col_widths) + cross

      table = []
      table.append(separator_line())  # Top border
      table.append(format_row(header))
      table.append(separator_line())  # Header separator
      for row in zip(*columns):
        table.append(format_row(row))
      table.append(separator_line())  # Bottom border
      return ""\n"".join(table)

    header = [f""Rack {i}"" for i in range(len(self._racks))]
    sites = [
      [site.resource.name if site.resource else ""<empty>"" for site in reversed(rack.sites.values())]
      for rack in self._racks
    ]
    return create_pretty_table(header, *sites)
",pylabrobot/storage/incubator.py,Incubator
survived,"  async def send_command(self, command_type, command, params):
    print(
      ""cytomat"", self._assemble_command(command_type=command_type, command=command, params=params)
    )
    if command_type == ""ch"":
      return ""0""
    return ""0"" * 8
",pylabrobot/storage/cytomat/cytomat.py,CytomatChatterbox
survived,"  async def get_temperature(self) -> float:
    raise NotImplementedError(""Temperature query not implemented yet"")
",pylabrobot/storage/cytomat/heraeus_cytomat_backend.py,HeraeusCytomatBackend
survived,"  async def fetch_plate_to_loading_tray(self, plate: Plate, site=PlateHolder):
    """"""Fetch a plate from storage onto the transfer station, with gate open/close.""""""
    site = plate.parent
    assert isinstance(site, PlateHolder), ""Plate not in storage""
    m, n = self._site_to_m_n(site)
    await self._send_command(f""WR DM0 {m}"")  # carousel pos
    await self._send_command(f""WR DM5 {n}"")  # handler level
    await self._send_command(""ST 1905"")  # plate to transfer station
    await self._wait_ready()
    await self._send_command(""ST 1903"")  # terminate access
",pylabrobot/storage/cytomat/heraeus_cytomat_backend.py,HeraeusCytomatBackend
survived,"  async def get_swap_register(self) -> SwapStationState:
    value = await self.send_command(""ch"", ""sw"", """")
    return SwapStationState(
      position=SwapStationPosition(int(value[0])),
      load_status_front_of_gate=LoadStatusFrontOfGate(int(value[1])),
      load_status_at_processor=LoadStatusAtProcessor(int(value[2])),
    )
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend
survived,"  async def wait_for_transfer_station(self, occupied: bool = False):
    # send the command, but don't wait when we are in chatting mode.
    _ = await self.get_overview_register()
",pylabrobot/storage/cytomat/cytomat.py,CytomatChatterbox
survived,"  def from_resp(self, resp) -> ""OverviewRegisterState"":
    binary_value = hex_to_binary(resp)
    return OverviewRegisterState(
      **{member.name.lower(): binary_value[member.value] == ""1"" for member in OverviewRegister}
    )
",pylabrobot/storage/cytomat/schemas.py,OverviewRegisterState
survived,"def test_template_validator_missing_variable() -> None:
    validator = TemplateValidator()
    case = TemplateTestCase(context={""name"": ""Alice""})
    result = validator.validate(""Hello {{ name }} from {{ city }}"", [case])
    assert not result.success
    assert any(""missing variables"" in e for e in result.errors)
",tests/test_template_validator.py,
survived,"    def showcase(self, limit: int = 5) -> List[Tuple[str, float]]:
        """"""Return top rated templates as ``[(slug, average)]``.""""""
        ratings = self._load_ratings()
        avgs = [(slug, sum(vals) / len(vals)) for slug, vals in ratings.items() if vals]
        avgs.sort(key=lambda t: t[1], reverse=True)
        return avgs[:limit]
",src/meta_agent/template_sharing.py,TemplateSharingManager
survived,"def main() -> int:
    repo_root = Path(__file__).resolve().parents[1]
    req_txt = repo_root / ""alpha_factory_v1"" / ""backend"" / ""requirements.txt""
    lock_file = repo_root / ""alpha_factory_v1"" / ""backend"" / ""requirements-lock.txt""

    with tempfile.TemporaryDirectory() as tmpdir:
        out_path = Path(tmpdir) / ""requirements.lock""
        pip_compile = shutil.which(""pip-compile"")
        if pip_compile:
            cmd = [pip_compile]
        else:
            cmd = [sys.executable, ""-m"", ""piptools"", ""compile""]
        cmd += [""--quiet"", ""--generate-hashes"", str(req_txt), ""-o"", str(out_path)]
        result = subprocess.run(cmd, capture_output=True, text=True)
        sys.stdout.write(result.stdout)
        sys.stderr.write(result.stderr)
        if result.returncode != 0:
            return result.returncode
        if out_path.read_bytes() != lock_file.read_bytes():
            sys.stderr.write(
                ""alpha_factory_v1/backend/requirements-lock.txt is outdated. Run 'pip-compile --quiet --generate-hashes alpha_factory_v1/backend/requirements.txt'\n""
            )
            return 1
    return 0
",scripts/verify_backend_requirements_lock.py,
survived,"    async def verify_token(
        credentials: HTTPAuthorizationCredentials = Depends(security),
    ) -> None:
        if credentials.credentials != API_TOKEN:
            raise HTTPException(status_code=403, detail=""Invalid token"")
",src/interface/api_server.py,
survived,"        def __init__(self, app: FastAPI, limit: int = 60, window: int = 60) -> None:
            super().__init__(app)
            self.limit = int(os.getenv(""API_RATE_LIMIT"", str(limit)))
            self.window = window
            self.counters: dict[str, tuple[int, float]] = {}
            self.lock = asyncio.Lock()
",src/interface/api_server.py,SimpleRateLimiter
survived,"        async def run(self, prompt: str) -> str:  # pragma: no cover - async stub
            return ""done""
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_agents.py,Ctx
survived,"    def click(self, *a, **k):
        pass
",tests/test_selfheal_import_stubs.py,DummyButton
survived,"def test_rate_limit_exceeded() -> None:
    port = _free_port()
    env = os.environ.copy()
    env[""API_RATE_LIMIT""] = ""3""
    proc = _start_server(port, env)
    url = f""http://127.0.0.1:{port}""
    headers = {""Authorization"": ""Bearer test-token""}
    try:
        _wait_running(url, headers)
        assert httpx.get(f""{url}/runs"", headers=headers).status_code == 200
        assert httpx.get(f""{url}/runs"", headers=headers).status_code == 200
        r = httpx.get(f""{url}/runs"", headers=headers)
        assert r.status_code == 429
    finally:
        proc.terminate()
        proc.wait(timeout=5)",tests/test_api_server_subprocess.py,
survived,"def format_values(node, values):
    return '{}({})'.format(node.__class__.__name__, ',\n    '.join(values))
",test/integration/expected_out/issue192.py,
survived,"def test_offline_placeholders() -> None:
    """"""_ensure_offline should write placeholders and generator uses them.""""""
    with tempfile.TemporaryDirectory() as tmpdir:
        with (
            patch.dict(os.environ, {""OFFLINE_DATA_DIR"": tmpdir}),
            patch(""urllib.request.urlopen"", side_effect=Exception),
        ):
            mod = importlib.reload(data_feeds)
            # files should contain single placeholder row
            for name, row in mod._DEFAULT_ROWS.items():
                with open(Path(tmpdir) / name, newline="""") as f:
                    rows = list(csv.DictReader(f))
                assert rows == [row]

            async def get_one() -> dict[str, float | str]:
                it = mod.stream_macro_events(live=False)
                return await anext(it)

            evt = asyncio.run(get_one())
            assert evt[""fed_speech""] == ""No speech""
            assert evt[""yield_10y""] == 4.4
            assert evt[""yield_3m""] == 4.5
            assert evt[""stable_flow""] == 25.0
            assert evt[""es_settle""] == 5000.0

        importlib.reload(data_feeds)",tests/test_offline_data_feeds.py,
survived,"def test_update_after_sampling():
    sched = JitScheduler.init(max_tokens=8, max_seqs=1, key=jax.random.PRNGKey(0))
    toks = hax.named(jnp.array([5], dtype=jnp.int32), ""position"")
    seqs = hax.named(jnp.array([0], dtype=jnp.int32), ""position"")

    sched = sched.update_after_sampling(toks, seqs, 1)
    assert jnp.array_equal(sched.generated_tokens[""position"", hax.ds(0, 1)].array, jnp.array([5], dtype=jnp.int32))
    assert sched.num_generated_tokens == 1
    assert sched.num_queued_tokens == 1",tests/test_jit_scheduler.py,
survived,"def _lambda11():
    draw.get(100)()
    draw.get(800)()
",tests/rosetta/transpiler/Python/cistercian-numerals.py,
survived,"def _lambda13():
    draw.get(1000)()
    draw.get(6000)()
",tests/rosetta/transpiler/Python/cistercian-numerals.py,
survived,"def _lambda4():
    draw.get(10)()
    draw.get(40)()
",tests/rosetta/transpiler/Python/cistercian-numerals.py,
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    srcLines = [""package main"", """", ""import ("", ""    \""fmt\"""", ""    \""go/ast\"""", ""    \""go/parser\"""", ""    \""go/token\"""", ""    \""io/ioutil\"""", ""    \""os\"""", ""    \""sort\"""", "")"", """", ""func main() {"", ""    if len(os.Args) != 2 {"", ""        fmt.Println(\""usage ff <go source filename>\"")"", ""        return"", ""    }"", ""    src, err := ioutil.ReadFile(os.Args[1])"", ""    if err != nil {"", ""        fmt.Println(err)"", ""        return"", ""    }"", ""    fs := token.NewFileSet()"", ""    a, err := parser.ParseFile(fs, os.Args[1], src, 0)"", ""    if err != nil {"", ""        fmt.Println(err)"", ""        return"", ""    }"", ""    f := fs.File(a.Pos())"", ""    m := make(map[string]int)"", ""    ast.Inspect(a, func(n ast.Node) bool {"", ""        if ce, ok := n.(*ast.CallExpr); ok {"", ""            start := f.Offset(ce.Pos())"", ""            end := f.Offset(ce.Lparen)"", ""            m[string(src[start:end])]++"", ""        }"", ""        return true"", ""    })"", ""    cs := make(calls, 0, len(m))"", ""    for k, v := range m {"", ""        cs = append(cs, &call{k, v})"", ""    }"", ""    sort.Sort(cs)"", ""    for i, c := range cs {"", ""        fmt.Printf(\""%-20s %4d\\n\"", c.expr, c.count)"", ""        if i == 9 {"", ""            break"", ""        }"", ""    }"", ""}"", """", ""type call struct {"", ""    expr  string"", ""    count int"", ""}"", ""type calls []*call"", """", ""func (c calls) Len() int           { return len(c) }"", ""func (c calls) Swap(i, j int)      { c[i], c[j] = c[j], c[i] }"", ""func (c calls) Less(i, j int) bool { return c[i].count > c[j].count }""]
    src = join(srcLines, ""\n"")
    freq = {}
    i = 0
    order = []
    while i < len(src):
        ch = src[i:i + 1]
        if (ch >= ""A"" and ch <= ""Z"") or (ch >= ""a"" and ch <= ""z"") or ch == ""_"":
            j = i + 1
            while j < len(src) and isAlphaNumDot(src[j:j + 1]):
                j = j + 1
            token = src[i:j]
            k = j
            while k < len(src):
                cc = src[k:k + 1]
                if cc == "" "" or cc == ""\t"" or cc == ""\n"" or cc == ""\r"":
                    k = k + 1
                else:
                    break
            if k < len(src) and src[k:k + 1] == ""("":
                p = i - 1
                while p >= 0 and (src[p:p + 1] == "" "" or src[p:p + 1] == ""\t""):
                    p = p - 1
                skip = False
                if p >= 3:
                    before = src[p - 3:p + 1]
                    if before == ""func"":
                        skip = True
                if not skip:
                    if token in freq:
                        freq[token] = freq[token] + 1
                    else:
                        freq[token] = 1
                        order = order + [token]
            i = j
        else:
            i = i + 1
    pairs = []
    for t in order:
        pairs = pairs + [{""expr"": t, ""count"": freq[t]}]
    pairs = sortPairs(pairs)
    idx = 0
    while idx < len(pairs) and idx < 10:
        p = pairs[idx]
        print(p.get(""expr"") + "" "" + str(p.get(""count"")))
        idx = idx + 1
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/function-frequency.py,
survived,"def b(x, y):
    pass
",tests/rosetta/transpiler/Python/function-prototype.py,
survived,"def ftree(g, x, y, dist, dir, d):
    rad = dir * PI / 180.0
    x2 = x + dist * _sin(rad)
    y2 = y - dist * _cos(rad)
    bresenham(int(x), int(y), int(x2), int(y2), g)
    if d > 0:
        ftree(g, x2, y2, dist * frac, dir - angle, d - 1)
        ftree(g, x2, y2, dist * frac, dir + angle, d - 1)
",tests/rosetta/transpiler/Python/fractal-tree.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/forest-fire.py,
survived,"def partialSeries(f):
    out = """"
    i = 0
    while i < 6:
        out = out + "" "" + padFloat5(extract(f, i), 8) + "" ""
        i = i + 1
    return out
",tests/rosetta/transpiler/Python/formal-power-series.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/floyd-warshall-algorithm.py,
survived,"def padFloat5(x, width):
    s = fmtF5(x)
    while len(s) < width:
        s = "" "" + s
    return s
",tests/rosetta/transpiler/Python/formal-power-series.py,
survived,"def padLeft(s, w):
    res = """"
    n = w - len(s)
    while n > 0:
        res = res + "" ""
        n = n - 1
    return res + s
",tests/rosetta/transpiler/Python/functional-coverage-tree.py,
survived,"def sortPairs(xs):
    arr = xs
    i = 1
    while i < len(arr):
        j = i
        while j > 0 and (int(arr[j - 1].get(""count""))) < (int(arr[j].get(""count""))):
            tmp = arr[j - 1]
            arr[j - 1] = arr[j]
            arr[j] = tmp
            j = j - 1
        i = i + 1
    return arr
",tests/rosetta/transpiler/Python/function-frequency.py,
survived,"def _lambda2(n):
    b0 = extract(b, 0)
    if b0 == 0.0:
        return (0.0 / 0.0)
    s = extract(a, n)
    k = 1
    while k <= n:
        s = s - extract(b, k) * extract(q, n - k)
        k = k + 1
    return s // b0
",tests/rosetta/transpiler/Python/formal-power-series.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/four-is-the-number-of-letters-in-the-....py,
survived,"def capitalize(s):
    if len(s) == 0:
        return s
    return s[0:1].upper() + """".join(s[1:len(s)])
",tests/rosetta/transpiler/Python/four-is-magic.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/function-frequency.py,
survived,"def formatFloat(f, prec):
    scale = pow10(prec)
    scaled = (f * scale) + 0.5
    n = (int(scaled))
    digits = str(n)
    while len(digits) <= prec:
        digits = ""0"" + digits
    intPart = digits[0:len(digits) - prec]
    fracPart = digits[len(digits) - prec:len(digits)]
    return intPart + ""."" + fracPart
",tests/rosetta/transpiler/Python/formatted-numeric-output.py,
survived,"def sub(a, b):
    return newFps(lambda n: extract(a, n) - extract(b, n))
",tests/rosetta/transpiler/Python/formal-power-series.py,
survived,"def pow10(n):
    r = 1.0
    i = 0
    while i < n:
        r = r * 10.0
        i = i + 1
    return r
",tests/rosetta/transpiler/Python/functional-coverage-tree.py,
survived,"    def test_missing_spec_skips_check(self) -> None:
        fake_mod = types.SimpleNamespace(__spec__=None)

        def _fake_import(name: str, *args: Any, **kwargs: Any) -> object:
            if name == ""openai_agents"":
                return fake_mod
            return importlib.import_module(name, *args, **kwargs)

        def _fake_find_spec(name: str, *args: Any, **kwargs: Any) -> object:
            if name == ""openai_agents"":
                return object()
            if name == ""agents"":
                return None
            return importlib.util.find_spec(name, *args, **kwargs)

        with (
            mock.patch(""importlib.import_module"", side_effect=_fake_import),
            mock.patch(""importlib.util.find_spec"", side_effect=_fake_find_spec),
        ):
            self.assertTrue(preflight.check_openai_agents_version())
",tests/test_preflight_openai_agents_version.py,TestPreflightOpenAIAgentsVersion
survived,"    def test_reset_batch_matches_vector_env(self):
        env_fn = lambda: ce.CurriculumEnv(genome=ce.EnvGenome(max_steps=10), size=6)
        vec = gym.vector.SyncVectorEnv([env_fn for _ in range(3)])
        obs_vec, _ = vec.reset()
        env = env_fn()
        obs, infos = env.reset_batch(3)
        self.assertEqual(obs.shape, obs_vec.shape)
        self.assertEqual(len(infos), 3)
",alpha_factory_v1/tests/test_aiga_meta_evolution.py,CurriculumEnvTest
survived,"    def setUp(self) -> None:
        sys.modules.pop(""agents"", None)
        sys.modules.pop(""alpha_factory_v1.backend.agent_factory"", None)
        importlib.invalidate_caches()

        orig_import_module = importlib.import_module

        def _fake_import(name: str, *args: object, **kwargs: object) -> object:
            if name == ""agents"":
                raise ModuleNotFoundError
            return orig_import_module(name, *args, **kwargs)

        with mock.patch(""importlib.import_module"", side_effect=_fake_import):
            af = orig_import_module(""alpha_factory_v1.backend.agent_factory"")
            self.af = importlib.reload(af)
",tests/test_agent_factory.py,TestAgentFactory
survived,"    def test_auto_select_model_fallbacks(self) -> None:
        combos = [
            ({""OPENAI_API_KEY"": ""1""}, ""gpt-4o-mini""),
            ({""ANTHROPIC_API_KEY"": ""1""}, ""claude-3-sonnet-20240229""),
            ({""LLAMA_MODEL_PATH"": ""model.bin""}, ""local-llama3-8b-q4""),
            ({}, ""local-sbert""),
        ]
        for env, expected in combos:
            with self.subTest(env=env):
                with mock.patch.dict(os.environ, env, clear=True):
                    self.assertEqual(self.af._auto_select_model(), expected)
",tests/test_agent_factory.py,TestAgentFactory
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/python_auto.py,
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/min_max_builtin.py,
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/sum_builtin.py,
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/pure_fold.py,
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/bool_chain.py,
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/append_builtin.py,
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/map_assign.py,
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/fun_three_args.py,
survived,"def _start_demo_server(port: int, env: dict[str, str] | None = None) -> subprocess.Popen[bytes]:
    cmd = [
        sys.executable,
        ""-m"",
        ""alpha_factory_v1.demos.alpha_agi_insight_v1.src.interface.api_server"",
        ""--host"",
        ""127.0.0.1"",
        ""--port"",
        str(port),
    ]
    return subprocess.Popen(cmd, env=env or os.environ.copy())
",tests/test_api_server_subprocess.py,
survived,"    def fake_improve(repo_url: str, p_file: str, metric_file: str, log_file: str):
        click.echo(""score delta: 1.0"")
        return 1.0, tmp_path
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_demo_cli.py,
survived,"    def test_build_rest_none(self) -> None:
        mod_name = ""alpha_factory_v1.backend.orchestrator""
        with mock.patch.dict(sys.modules, {""fastapi"": None}):
            orch = importlib.reload(importlib.import_module(mod_name))
            self.assertIsNone(orch._build_rest({}))
        importlib.reload(orch)
",tests/test_orchestrator_no_fastapi.py,TestNoFastAPI
deleted,"    def _get_email_body(self, msg):
        if ""parts"" in msg[""payload""]:
            for part in msg[""payload""][""parts""]:
                if part[""mimeType""] == ""text/plain"":
                    return base64.urlsafe_b64decode(part[""body""][""data""]).decode(
                        ""utf-8""
                    )
        elif msg[""payload""].get(""mimeType"") == ""text/plain"":
            return base64.urlsafe_b64decode(msg[""payload""][""body""][""data""]).decode(
                ""utf-8""
            )
        return ""This email does not contain a text body.""
",autogpt_platform/backend/backend/blocks/google/gmail.py,GmailGetThreadBlock
survived,"    def _reply(self, service, input_data: Input, graph_exec_id: str) -> dict:
        parent = (
            service.users()
            .messages()
            .get(
                userId=""me"",
                id=input_data.parentMessageId,
                format=""metadata"",
                metadataHeaders=[""Subject"", ""References"", ""Message-ID""],
            )
            .execute()
        )
        headers = {
            h[""name""].lower(): h[""value""]
            for h in parent.get(""payload"", {}).get(""headers"", [])
        }
        subject = input_data.subject or (f""Re: {headers.get('subject', '')}"".strip())
        references = headers.get(""references"", """").split()
        if headers.get(""message-id""):
            references.append(headers[""message-id""])

        from email import encoders
        from email.mime.base import MIMEBase
        from email.mime.multipart import MIMEMultipart
        from email.mime.text import MIMEText

        msg = MIMEMultipart()
        if input_data.to:
            msg[""To""] = "", "".join(input_data.to)
        if input_data.cc:
            msg[""Cc""] = "", "".join(input_data.cc)
        if input_data.bcc:
            msg[""Bcc""] = "", "".join(input_data.bcc)
        msg[""Subject""] = subject
        if headers.get(""message-id""):
            msg[""In-Reply-To""] = headers[""message-id""]
        if references:
            msg[""References""] = "" "".join(references)
        msg.attach(
            MIMEText(input_data.body, ""html"" if ""<"" in input_data.body else ""plain"")
        )

        for attach in input_data.attachments:
            local_path = store_media_file(graph_exec_id, attach, return_content=False)
            abs_path = get_exec_file_path(graph_exec_id, local_path)
            part = MIMEBase(""application"", ""octet-stream"")
            with open(abs_path, ""rb"") as f:
                part.set_payload(f.read())
            encoders.encode_base64(part)
            part.add_header(
                ""Content-Disposition"", f""attachment; filename={Path(abs_path).name}""
            )
            msg.attach(part)

        raw = base64.urlsafe_b64encode(msg.as_bytes()).decode(""utf-8"")
        return (
            service.users()
            .messages()
            .send(userId=""me"", body={""threadId"": input_data.threadId, ""raw"": raw})
            .execute()
        )",autogpt_platform/backend/backend/blocks/google/gmail.py,GmailReplyBlock
survived,"    def run(
        self, input_data: Input, *, credentials: GoogleCredentials, **kwargs
    ) -> BlockOutput:
        service = GmailReadBlock._build_service(credentials, **kwargs)
        thread = self._get_thread(
            service, input_data.threadId, input_data.includeSpamTrash
        )
        yield ""thread"", thread
",autogpt_platform/backend/backend/blocks/google/gmail.py,GmailGetThreadBlock
survived,"    def __init__(self):
        super().__init__(
            id=""12bf5a24-9b90-4f40-9090-4e86e6995e60"",
            description=""Reply to a Gmail thread"",
            categories={BlockCategory.COMMUNICATION},
            input_schema=GmailReplyBlock.Input,
            output_schema=GmailReplyBlock.Output,
            disabled=not GOOGLE_OAUTH_IS_CONFIGURED,
            test_input={
                ""threadId"": ""t1"",
                ""parentMessageId"": ""m1"",
                ""body"": ""Thanks"",
                ""credentials"": TEST_CREDENTIALS_INPUT,
            },
            test_credentials=TEST_CREDENTIALS,
            test_output=[
                (""messageId"", ""m2""),
                (""threadId"", ""t1""),
            ],
            test_mock={
                ""_reply"": lambda *args, **kwargs: {
                    ""id"": ""m2"",
                    ""threadId"": ""t1"",
                }
            },
        )
",autogpt_platform/backend/backend/blocks/google/gmail.py,GmailReplyBlock
survived,"    async def run() -> None:
        async with orch.bus:
            runner.start(orch.bus, orch.ledger)
            monitor = asyncio.create_task(orch._monitor())
            for _ in range(6):
                await orig_sleep(0)
            monitor.cancel()
            with contextlib.suppress(asyncio.CancelledError):
                await monitor
            if runner.task:
                runner.task.cancel()
                with contextlib.suppress(asyncio.CancelledError):
                    await runner.task
",tests/test_orchestrator_backoff.py,
survived,"    async def _skill_test(request: Request, name: str):
        payload = await request.json()
        if name not in runners:
            raise HTTPException(404, ""Agent not found"")
        inst = runners[name].inst
        if not hasattr(inst, ""skill_test""):
            raise HTTPException(501, ""Agent does not support skill_test"")
        return await inst.skill_test(payload)  # type: ignore[func-returns-value]
",alpha_factory_v1/backend/orchestrator.py,
survived,"def insert(
    parent_hash: str,
    child_hash: str,
    metrics: Mapping[str, float],
    *,
    db_path: str | Path = _DEFAULT_DB,
) -> str:
    """"""Insert ``child_hash`` with ``parent_hash`` and return updated Merkle root.""""""
    path = Path(db_path)
    _ensure(path)
    record = {
        ""parent"": parent_hash,
        ""child"": child_hash,
        ""metrics"": dict(metrics),
    }
    h = hashlib.sha256(json.dumps(record, sort_keys=True).encode()).hexdigest()
    with sqlite3.connect(path) as cx:
        cx.execute(
            ""INSERT INTO entries(parent, child, metrics, hash, ts) VALUES(?,?,?,?,?)"",
            (parent_hash, child_hash, json.dumps(record[""metrics""]), h, time.time()),
        )
    return _update_root(path)
",src/archive/archive.py,
survived,"def _update_root(path: Path) -> str:
    root = merkle_root(db_path=path)
    date = time.strftime(""%Y-%m-%d"")
    with sqlite3.connect(path) as cx:
        cx.execute(""INSERT OR REPLACE INTO merkle(date, root) VALUES(?,?)"", (date, root))
    return root
",src/archive/archive.py,
survived,"def test_cron_writes_root(tmp_path: Path, monkeypatch) -> None:
    db = tmp_path / ""hash.db""
    arch = HashArchive(db)
    tar = tmp_path / ""a.tar""
    tar.write_text(""a"", encoding=""utf-8"")
    arch.add_tarball(tar)
    out = tmp_path / ""root.json""
    monkeypatch.setenv(""ARCHIVE_PATH"", str(db))
    cid = publish_root(out_file=out)
    assert json.loads(out.read_text())[""cid""] == cid",tests/test_archive_cron.py,
survived,"def propose_diff(file_path: str, goal: str) -> str:
    """"""Return a diff appending a placeholder comment with ``goal``.""""""
    p = Path(file_path)
    original = p.read_text(encoding=""utf-8"").splitlines()
    updated = original + [f""# TODO: {goal}""]
    rel = p.name
    diff = difflib.unified_diff(
        original,
        updated,
        fromfile=f""a/{rel}"",
        tofile=f""b/{rel}"",
        lineterm="""",
    )
    return ""\n"".join(diff) + ""\n""",src/tools/diff_mutation.py,
survived,"    def uop(self, op):
        if isinstance(op, ast.USub):
            return ""-""
        if isinstance(op, ast.Not):
            return ""not ""
        return """"
",tools/any2mochi/py_simple.py,Conv
survived,"    async def _search(q: str, k: int = 5) -> Any:  # noqa: D401
        return mem.vector.search(q, k)
",alpha_factory_v1/backend/api_server.py,
survived,"async def serve_grpc(runners: Dict[str, AgentRunner], port: int, ssl_disable: bool) -> Optional[""grpc.aio.Server""]:
    if not port or ""grpc"" not in globals():
        return None
    try:
        from backend.proto import a2a_pb2, a2a_pb2_grpc
    except ModuleNotFoundError:
        log.warning(""A2A_PORT set but proto stubs missing â€“ gRPC disabled"")
        return None

    class Peer(a2a_pb2_grpc.PeerServiceServicer):  # type: ignore
        async def Stream(self, req_iter, ctx):  # noqa: N802
            async for req in req_iter:
                kind = req.WhichOneof(""payload"")
                if kind == ""trigger"" and req.trigger.name in runners:
                    runners[req.trigger.name].next_ts = 0
                    yield a2a_pb2.StreamReply(ack=a2a_pb2.Ack(id=req.id))
                elif kind == ""status"":
                    stats = [a2a_pb2.AgentStat(name=n, next_run=int(r.next_ts)) for n, r in runners.items()]
                    yield a2a_pb2.StreamReply(status_reply=a2a_pb2.StatusReply(stats=stats))

    creds = None
    if not ssl_disable:
        cert_dir = Path(os.getenv(""TLS_CERT_DIR"", ""/certs""))
        crt, key = cert_dir / ""server.crt"", cert_dir / ""server.key""
        if crt.exists() and key.exists():
            creds = grpc.ssl_server_credentials(((key.read_bytes(), crt.read_bytes()),))

    server = grpc.aio.server()
    a2a_pb2_grpc.add_PeerServiceServicer_to_server(Peer(), server)
    bind = f""[::]:{port}""
    server.add_secure_port(bind, creds) if creds else server.add_insecure_port(bind)
    await server.start()
    asyncio.create_task(server.wait_for_termination())
    log.info(""gRPC A2A server listening on %s (%s)"", bind, ""TLS"" if creds else ""plaintext"")
    return server",alpha_factory_v1/backend/api_server.py,
survived,"    def _get_metric(factory: Callable[..., Any], name: str, desc: str, labels: list[str] | None = None) -> Any:
        return _reg_metric(factory, name, desc, labels)
",alpha_factory_v1/backend/telemetry.py,
survived,"    def publish(self, topic: str, msg: Dict[str, Any]) -> None:
        if self._producer:
            self._producer.send(topic, msg)
        else:
            assert self._queues is not None
            self._queues.setdefault(topic, asyncio.Queue()).put_nowait(msg)
",alpha_factory_v1/backend/agent_manager.py,EventBus
survived,"    async def _recent(agent: str, n: int = 25) -> Any:  # noqa: D401
        return mem.vector.recent(agent, n)
",alpha_factory_v1/backend/api_server.py,
survived,"    async def stop(self) -> None:
        """"""Cancel helper tasks and wait for agent cycles to finish.""""""

        if self._hb_task:
            self._hb_task.cancel()
        if self._reg_task:
            self._reg_task.cancel()
        with contextlib.suppress(asyncio.CancelledError):
            if self._hb_task:
                await self._hb_task
            if self._reg_task:
                await self._reg_task
        await asyncio.gather(*(r.task for r in self.runners.values() if r.task), return_exceptions=True)
",alpha_factory_v1/backend/agent_manager.py,AgentManager
survived,"async def start_servers(
    runners: Dict[str, AgentRunner],
    model_max_bytes: int,
    mem: Any,
    rest_port: int,
    grpc_port: int,
    loglevel: str,
    ssl_disable: bool,
) -> tuple[Optional[asyncio.Task], Optional[""grpc.aio.Server""]]:
    """"""Convenience helper to launch REST and gRPC services.""""""

    app = build_rest(runners, model_max_bytes, mem)
    rest_task = await start_rest(app, rest_port, loglevel)
    grpc_server = await serve_grpc(runners, grpc_port, ssl_disable)
    return rest_task, grpc_server
",alpha_factory_v1/backend/api_server.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/left_join.py,Customer
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/group_by_multi_join.py,Partsupp
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/group_by_join.py,Order
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/left_join_multi.py,Order
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/join_multi.py,Order
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/group_by_sort.py,Item
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/group_by_left_join.py,Customer
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/right_join.py,Order
survived,"            async def _wrapped(*a: object, **kw: object) -> object:
                t0 = time.perf_counter()
                ok = True
                try:
                    return await orig(*a, **kw)
                except Exception:
                    ok = False
                    raise
                finally:
                    _HEALTH_Q.put((name, (time.perf_counter() - t0) * 1000, ok))
",tests/test_backend_orchestrator_dev.py,
survived,"    async def step(self) -> None:  # pragma: no cover - test failure
        raise RuntimeError(""boom"")
",tests/test_backend_orchestrator_dev.py,FailingAgent
survived,"        def _decorator(func):
            return func
",alpha_factory_v1/demos/alpha_agi_business_v1/openai_agents_bridge.py,
survived,"def test_run_cycle_sync_commits() -> None:
    model = DummyModel()
    demo.run_cycle(
        demo.Orchestrator(),
        demo.AgentFin(),
        demo.AgentRes(),
        demo.AgentEne(),
        demo.AgentGdl(),
        model,
    )
    assert model.committed
",tests/test_alpha_agi_business_3_v1.py,
survived,"    def transform(self, X: Any) -> np.ndarray:  # noqa: D401
        if not hasattr(self, ""model_""):
            raise RuntimeError(""Estimator has not been fitted"")
        n_docs = len(self.model_.document_leaves)
        assignments = np.zeros(n_docs, dtype=int)
        for d in range(n_docs):
            leaf = self.model_.document_leaves[d]
            assignments[d] = leaf.node_id
        return assignments",src/hlda/sklearn_wrapper.py,HierarchicalLDAEstimator
survived,"    def _ensure_credentials_file(self):
        directory = os.path.dirname(self._path)
        os.makedirs(directory, exist_ok=True)
        if not os.path.exists(self._path):
            with open(self._path, ""w"", encoding=""UTF-8""):
                pass
",src/dhapi/port/credentials_provider.py,CredentialsProvider
survived,"    def fake_run(*args, **kwargs):
        if kwargs.get(""preexec_fn""):
            kwargs[""preexec_fn""]()

        class P:
            stdout = ""{}""
            stderr = """"

        return P()
",tests/test_codegen_agent.py,
survived,"def test_transform_groups():
    result = transform_groups(MOCK_ENTRA_GROUPS, {
        gid: [u.id for u in users] for gid, users in MOCK_GROUP_MEMBERS.items()
    })
    assert len(result) == 2
    group1 = next(g for g in result if g[""id""] == ""11111111-1111-1111-1111-111111111111"")
    assert group1[""display_name""] == ""Security Team""
    assert group1[""member_ids""] == [
        ""ae4ac864-4433-4ba6-96a6-20f8cffdadcb"",
        ""11dca63b-cb03-4e53-bb75-fa8060285550"",
    ]
",tests/unit/cartography/intel/entra/test_groups.py,
survived,"    def resolve(
        self, packages: Iterable[str], include_hashes: bool = False
    ) -> Tuple[List[str], Dict[str, str], Optional[Dict[str, str]]]:
        """"""Return pinned requirements and license info for ``packages``.""""""

        pinned: Dict[str, str] = {}
        licenses: Dict[str, str] = {}
        hashes: Optional[Dict[str, str]] = {} if include_hashes else None
        visited: set[str] = set()

        for pkg in packages:
            base = pkg.split(""=="")[0].split("">="")[0].split(""<"")[0]
            base = base.split(""["")[0]
            self._collect_recursive(
                base, pinned, licenses, visited, include_hashes, hashes
            )

        reqs = [f""{name}=={ver}"" for name, ver in sorted(pinned.items())]
        return reqs, licenses, hashes",src/meta_agent/dependency_manager.py,DependencyManager
survived,"    def __init__(self, *args: Any, **kwargs: Any) -> None:
        self.chat = _Chat()",src/meta_agent/services/openai_stub.py,OpenAI
survived,"def trim(s):
    start = 0
    while start < len(s) and (s[start:start + 1] == "" "" or s[start:start + 1] == ""\t""):
        start = start + 1
    end = len(s)
    while end > start and (s[end - 1:end] == "" "" or s[end - 1:end] == ""\t""):
        end = end - 1
    return s[start:end]
",tests/rosetta/transpiler/Python/compiler-virtual-machine-interpreter.py,
survived,"def diagd(c1, c2, r):
    c = c1
    while c <= c2:
        n[r + c - c1][c] = ""x""
        c = c + 1
",tests/rosetta/transpiler/Python/cistercian-numerals.py,
survived,"def verti(r1, r2, c):
    r = r1
    while r <= r2:
        n[r][c] = ""x""
        r = r + 1
",tests/rosetta/transpiler/Python/cistercian-numerals.py,
survived,"def horiz(c1, c2, r):
    c = c1
    while c <= c2:
        n[r][c] = ""x""
        c = c + 1
",tests/rosetta/transpiler/Python/cistercian-numerals.py,
survived,"def printLower(m):
    n = m[""order""]
    ele = m[""ele""]
    mat = []
    idx = 0
    r = 0
    while r < n:
        row = []
        c = 0
        while c <= r:
            row = row + [ele[idx]]
            idx = idx + 1
            c = c + 1
        while c < n:
            row = row + [0.0]
            c = c + 1
        mat = mat + [row]
        r = r + 1
    printMat(mat)
",tests/rosetta/transpiler/Python/cholesky-decomposition-1.py,
survived,"def one():
    return id
",tests/rosetta/transpiler/Python/church-numerals-2.py,
survived,"def hypot(x, y):
    return sqrtApprox(x * x + y * y)
",tests/rosetta/transpiler/Python/circles-of-given-radius-through-two-points.py,
survived,"def ccFactors(n, m):
    p = 6 * m + 1
    if not isPrime(p):
        return []
    prod = bigFromInt(p)
    p = 12 * m + 1
    if not isPrime(p):
        return []
    prod = bigMulSmall(prod, p)
    i = 1
    while i <= n - 2:
        p = (pow2(i) * 9 * m) + 1
        if not isPrime(p):
            return []
        prod = bigMulSmall(prod, p)
        i = i + 1
    return prod
",tests/rosetta/transpiler/Python/chernicks-carmichael-numbers.py,
survived,"def main():
    while True:
        line = input()
        if line == """":
            break
        print(line)
",tests/rosetta/transpiler/Python/copy-stdin-to-stdout-2.py,
survived,"def ccw(a, b, c):
    lhs = (b.x - a.x) * (c.y - a.y)
    rhs = (b.y - a.y) * (c.x - a.x)
    return lhs > rhs
",tests/rosetta/transpiler/Python/convex-hull.py,
survived,"def test_format_time_ago_outputs():
    now = datetime.now(timezone.utc)
    assert format_time_ago((now - timedelta(days=2)).isoformat()) == ""2 days ago""
    assert format_time_ago((now - timedelta(hours=5)).isoformat()) == ""5 hours ago""
    thirty_min_ago = (now - timedelta(minutes=30)).isoformat()
    assert format_time_ago(thirty_min_ago) == ""30 minutes ago""
    assert format_time_ago(now.isoformat()) == ""just now""
",tests/test_dashboard.py,
survived,"    def error_suggestion(self, error_message: str) -> str | None:
        """"""Return a suggestion string for the given error message and output it.""""""
        suggestions = {
            ""failed to load"": ""Check that the file path exists and is readable."",
            ""network"": ""Ensure your internet connection is available."",
        }
        error_lower = error_message.lower()
        for token, suggestion in suggestions.items():
            if token in error_lower:
                self.cli_output.info(f""Suggestion: {suggestion}"")
                return suggestion
        return None
",src/meta_agent/ux/user_feedback.py,UserFeedback
survived,"def test_replay_closes_ledger(tmp_path) -> None:
    ledger = tmp_path / ""audit.db""
    ledger.touch()
    with patch.object(cli.config.CFG, ""ledger_path"", ledger):
        with (
            patch.object(cli.logging, ""Ledger"") as led_cls,
            patch.object(cli.time, ""sleep"", return_value=None),
        ):
            led = led_cls.return_value
            led.__enter__.return_value = led
            led.__exit__.side_effect = lambda *_: led.close()
            led.tail.return_value = [{""ts"": 0.0, ""sender"": ""a"", ""recipient"": ""b"", ""payload"": {""x"": 1}}]
            CliRunner().invoke(cli.main, [""replay""])
        led.close.assert_called_once()",tests/test_demo_cli.py,
survived,"        def subscribe(self, _t: str, _h):
            pass
",tests/test_adapters.py,DummyBus
survived,"def test_adk_adapter_unavailable(monkeypatch) -> None:
    """"""Adapter gracefully degrades when ADK is missing.""""""

    def _raise(_name: str):
        raise ModuleNotFoundError

    monkeypatch.setattr(importlib, ""import_module"", _raise)
    assert not ADKAdapter.is_available()
    with pytest.raises(ModuleNotFoundError):
        ADKAdapter()
",tests/test_adapters.py,
survived,"def test_mcp_invoke_tool_calls_library(monkeypatch) -> None:
    """"""Ensure MCPAdapter.invoke_tool delegates to the MCP client.""""""
    import mcp

    calls: dict[str, tuple[str, dict[str, object]]] = {}

    async def fake_call_tool(self, name: str, args: dict[str, object]) -> object:
        calls[""call""] = (name, args)
        return {""done"": True}

    monkeypatch.setattr(mcp.ClientSessionGroup, ""call_tool"", fake_call_tool, raising=False)
    adapter = MCPAdapter()
    result = asyncio.run(adapter.invoke_tool(""mytool"", {""x"": 1}))
    assert result == {""done"": True}
    assert calls[""call""] == (""mytool"", {""x"": 1})
",tests/test_adapters.py,
survived,"def test_fuzz_envelope_allows_safe(sender: str, recipient: str, ts: float, payload: dict[str, object]) -> None:
    code = payload[""code""]
    assume(""import os"" not in code)
    bus = DummyBus(config.Settings(bus_port=0))
    led = DummyLedger()
    agent = safety_agent.SafetyGuardianAgent(bus, led)
    env = messaging.Envelope(sender, recipient, payload, ts)
    asyncio.run(agent.handle(env))
    assert bus.published[-1][1].payload[""status""] == ""ok""
",tests/test_safety_guardian_property.py,
survived,"        async def send_transaction(self, tx: object, *args: object) -> None:
            captured[""data""] = tx.instructions[0].data.decode()
",tests/test_safety_guardian_property.py,DummyClient
survived,"        def __init__(self, program_id: object, data: bytes, keys: list[object]):
            self.data = data
",tests/test_safety_guardian_property.py,DummyInstr
survived,"def violates_finance_policy(code: str) -> bool:
    """"""Return ``True`` if ``code`` references a banned finance API host.""""""
    for host in _BANNED_HOSTS:
        if host in code:
            return True
    return False",src/utils/opa_policy.py,
survived,"def test_run_macro_demo_no_offline(tmp_path: Path) -> None:
    """"""`OPENAI_API_KEY` disables the offline profile.""""""
    docker_log, _ = _run_script(tmp_path, env={""OPENAI_API_KEY"": ""dummy-key""})
    assert ""--profile offline"" not in docker_log
",tests/test_macro_launcher.py,
survived,"    def decorator(func):
        return func
",openai_agents/__init__.py,
survived,"        def decorator(func):
            return func
",stubs/google_adk/__init__.py,
survived,"    async def __call__(self, text: str) -> str:  # pragma: no cover - demo stub
        return ""ok""
",openai_agents/__init__.py,OpenAIAgent
survived,"        def register_agent(self, _agent) -> None:  # pragma: no cover - stub
            pass
",stubs/google_adk/__init__.py,Router
survived,"    def test_official_demo_short(self) -> None:
        result = subprocess.run(
            [
                sys.executable,
                ""alpha_factory_v1/demos/alpha_agi_insight_v0/official_demo.py"",
                ""--episodes"",
                ""1"",
            ],
            capture_output=True,
            text=True,
        )
        self.assertEqual(result.returncode, 0, result.stderr)
        self.assertIn(""Best sector"", result.stdout)
",tests/test_official_insight_demo.py,TestOfficialInsightDemo
survived,"async def test_auto_resources_and_resolvers():
    app, lifespan = create_app()
    async with lifespan(app) as ctx:
        session_factory = ctx[""session_factory""]
        mock_ctx = Mock(spec=EnrichContext)
        mock_ctx.request_context = Mock()
        mock_ctx.request_context.lifespan_context = {""session_factory"": session_factory}

        list_users = app.resources[""list_users""]
        result = await list_users(ctx=mock_ctx)
        assert result.total_items == 1
        assert result.items[0].name == ""Alice""

        get_user = app.resources[""get_user""]
        single = await get_user(user_id=1, ctx=mock_ctx)
        assert single.name == ""Alice""

        # Relationship resolver
        get_orders = app.resources[""get_user_orders""]
        rel = await get_orders(user_id=1, ctx=mock_ctx)
        assert len(rel) == 1
        assert rel[0].id == 1",tests/test_sqlalchemy_autogen.py,
survived,"    def dummy_run(*_a, **_kw):
        times.append(time.perf_counter())
        time.sleep(0.2)
        ind = orchestrator.mats.Individual([0.0])
        ind.score = 0.0
        return [ind]
",tests/test_experiments.py,
survived,"def _build_incremental_case(rng, seq_lens, k_lens):
    """"""Like ``_build_random_case`` but query only contains the last ``k`` tokens.

    ``seq_lens`` gives the total tokens already in the KV cache for each
    sequence. ``k_lens`` is how many query tokens each sequence has. The KV
    cache still contains ``seq_lens`` tokens for every sequence.
    """"""
    q_full, kv_pages, kv_lens, page_indices, full_cu_q_lens, num_seqs = _build_random_case(rng, seq_lens)

    assert len(seq_lens) == len(k_lens)

    chunks = []
    new_offsets = [0]
    for sid, (total_len, k) in enumerate(zip(seq_lens, k_lens)):
        start = int(full_cu_q_lens[sid]) + total_len - k
        chunks.append(q_full[""tok"", hax.ds(start, k)])
        new_offsets.append(new_offsets[-1] + k)

    q = hax.concatenate(""tok"", chunks)
    cu_q_lens = jnp.asarray(new_offsets, dtype=jnp.int32)

    return q, kv_pages, kv_lens, page_indices, cu_q_lens, num_seqs
",tests/test_paged_attention.py,
survived,"def test_js_serializer_roundtrip(tmp_path: Path) -> None:
    script = tmp_path / ""run.mjs""
    script.write_text(
        f""import {{save, load}} from '{SERIALIZER.resolve().as_posix()}';\n""
        ""const data = JSON.parse(process.argv[2]);\n""
        ""const pop = data.pop;\n""
        ""if (data.gen !== undefined) pop.gen = data.gen;\n""
        ""const out = load(save(pop, data.rngState));\n""
        ""console.log(JSON.stringify(out));\n""
    )

    sample = {
        ""pop"": [
            {""logic"": ""a"", ""feasible"": True, ""front"": 0, ""strategy"": ""s""},
            {""logic"": ""b"", ""feasible"": False, ""front"": 1, ""strategy"": ""t""},
        ],
        ""gen"": 5,
        ""rngState"": [1, 2, 3, 4],
    }

    result = subprocess.run(
        [""node"", script, json.dumps(sample)], capture_output=True, text=True
    )
    assert result.returncode == 0, result.stderr
    loaded = json.loads(result.stdout)
    assert loaded == sample",tests/test_serializer.py,
survived,"def test_pyodide_load_failure(tmp_path: Path) -> None:
    bridge_copy = tmp_path / ""bridge.mjs""
    text = BRIDGE.read_text().replace(
        ""../lib/pyodide.js"", LIB.resolve().as_posix()
    )
    bridge_copy.write_text(text)

    script = tmp_path / ""run.mjs""
    script.write_text(
        ""globalThis.window = {\n""
        ""  toast: (m) => console.log(m),\n""
        ""  loadPyodide: () => { throw new Error('boom'); }\n""
        ""};\n""
        ""globalThis.toast = globalThis.window.toast;\n""
        f""const m = await import('{bridge_copy.as_posix()}');\n""
        ""try { await m.run(); } catch (e) {}\n""
    )
    result = subprocess.run([""node"", script], capture_output=True, text=True)
    assert result.returncode == 0, result.stderr
    assert ""Pyodide failed to load"" in result.stdout",tests/test_wasm_bridge.py,
survived,"def test_health() -> None:
    response = client.get(""/health"")
    assert response.status_code == 200
    assert response.json() == {""status"": ""ok""}",test_repo/backend/tests/test_demo_main.py,
survived,"def test_expand_cidr_cidr_range():
    result = expand_cidr('10.0.0.0/30')
    assert len(result) == 4
    assert result == ['10.0.0.0', '10.0.0.1', '10.0.0.2', '10.0.0.3']",tests/test_whois_perms.py,
survived,"        def run(self, prompt: str):
            return ""ok""
",tests/test_external_integrations.py,Dummy
survived,"        def register_agent(self, agent):
            raise AssertionError(""should not register"")
",tests/test_external_integrations.py,DummyRouter
survived,"        def add_peer(servicer: object, server: object) -> None:
            pass
",tests/test_orchestrator_grpc.py,TestServeGrpc
survived,"    def tearDown(self):
        self._cm.__exit__(None, None, None)
",alpha_factory_v1/tests/test_memory_provider.py,MemoryFabricFallbackTest
survived,"  async def test_passive_cooling_without_support(self):
    backend = TemperatureControllerChatterboxBackend(dummy_temperature=20.0)
    tc = TemperatureController(
      name=""tc"",
      size_x=1,
      size_y=1,
      size_z=1,
      backend=backend,
      child_location=Coordinate.zero(),
    )

    await tc.set_temperature(10, passive=True)
    # Temperature should remain unchanged on the backend.
    self.assertEqual(await backend.get_current_temperature(), 20.0)
",pylabrobot/temperature_controlling/temperature_controller_tests.py,PassiveCoolingTests
survived,"def _fitness(item: Any) -> Iterable[float]:
    if isinstance(item, Mapping):
        vals = item.get(""fitness"") or item.get(""objective_values"")
        if isinstance(vals, Mapping):
            return list(vals.values())
        if isinstance(vals, Iterable):
            return list(vals)
    return list(getattr(item, ""fitness"", []))
",src/utils/visual.py,
survived,"def fake_dataset_class(monkeypatch):
    import np_ocr.data as data

    def fake_from_list(lst):
        return FakeDataset(lst)

    monkeypatch.setattr(data, ""Dataset"", types.SimpleNamespace(from_list=staticmethod(fake_from_list)))
    return data
",no-ocr-api/tests/test_ingest_search.py,
survived,"                        def to_list(self):
                            return [{""_distance"": 0.1, ""index"": 0, ""pdf_name"": ""x.pdf"", ""pdf_page"": 1}]
",no-ocr-api/tests/test_ingest_search.py,FakeTable.Limiter.Selector
survived,"                def limit(self, *_):
                    class Selector:
                        def select(self, *_):
                            return self

                        def to_list(self):
                            return [{""_distance"": 0.1, ""index"": 0, ""pdf_name"": ""x.pdf"", ""pdf_page"": 1}]

                    return Selector()
",no-ocr-api/tests/test_ingest_search.py,FakeTable.Limiter
survived,"    def __init__(self, data):
        self.data = list(data)
",no-ocr-api/tests/test_ingest_search.py,FakeDataset
survived,"    async def handler(env: messaging.Envelope) -> None:
        received.append(env)
",tests/test_bus_large_payloads_property.py,
survived,"    def run_model(
        self,
        api_key: SecretStr,
        model_name: str,
        prompt: str,
        input_image: Optional[str],
        aspect_ratio: str,
        seed: Optional[int],
    ) -> str:
        client = ReplicateClient(api_token=api_key.get_secret_value())
        input_params = {
            ""prompt"": prompt,
            ""input_image"": input_image,
            ""aspect_ratio"": aspect_ratio,
        }
        if seed is not None:
            input_params[""seed""] = seed

        output: FileOutput | list[FileOutput] = client.run(  # type: ignore
            model_name,
            input=input_params,
            wait=False,
        )

        if isinstance(output, list) and output:
            first = output[0]
            if isinstance(first, FileOutput):
                return first.url
            return first
        if isinstance(output, FileOutput):
            return output.url
        if isinstance(output, str):
            return output
        return ""No output received""",autogpt_platform/backend/backend/blocks/flux_kontext.py,FluxKontextBlock
survived,"def scenario_2020_mrna() -> replay.Scenario:
    return replay.load_scenario(""2020_mrna"")
",tests/conftest.py,
survived,"def scenario_2008_mobile() -> replay.Scenario:
    return replay.load_scenario(""2008_mobile"")
",tests/conftest.py,
survived,"        def wait(self, timeout: float | None = None) -> None:
            pass
",tests/test_start_alpha_business.py,DummyProc
survived,"def test_start_alpha_business_submit_best(monkeypatch) -> None:
    """"""--submit-best queues the top demo opportunity.""""""
    from alpha_factory_v1.demos.alpha_agi_business_v1 import start_alpha_business as mod

    class DummyProc:
        def poll(self) -> None:
            return None

        def terminate(self) -> None:
            pass

        def wait(self, timeout: float | None = None) -> None:
            pass

    dummy_proc = DummyProc()
    monkeypatch.setattr(mod.subprocess, ""Popen"", lambda *a, **k: dummy_proc)
    monkeypatch.setattr(mod.check_env, ""main"", lambda *_a, **_k: None)
    monkeypatch.setattr(mod.webbrowser, ""open"", lambda *_a, **_k: None)

    class Resp:
        def __init__(self) -> None:
            self.status_code = 200

        def raise_for_status(self) -> None:
            pass

    monkeypatch.setattr(mod.requests, ""get"", lambda *_a, **_k: Resp())
    post_calls: list[tuple] = []

    def fake_post(url: str, json: dict, timeout: int) -> Resp:
        post_calls.append((url, json, timeout))
        return Resp()

    monkeypatch.setattr(mod.requests, ""post"", fake_post)

    env = {""OPENAI_API_KEY"": """", ""AGENTS_RUNTIME_PORT"": ""7000"", ""PORT"": ""8000""}
    with monkeypatch.context() as mctx:
        for k, v in env.items():
            mctx.setenv(k, v)
        mod.main([""--no-browser"", ""--submit-best""])

    assert post_calls == [
        (
            ""http://localhost:7000/v1/agents/business_helper/invoke"",
            {""action"": ""best_alpha""},
            10,
        )
    ]",tests/test_start_alpha_business.py,
survived,"    def fake_post(url: str, json: dict, timeout: int) -> Resp:
        post_calls.append((url, json, timeout))
        return Resp()
",tests/test_start_alpha_business.py,
survived,"        def terminate(self) -> None:
            pass
",tests/test_start_alpha_business.py,DummyProc
survived,"def delete(
    url: str,
    *,
    params: dict | None = None,
    headers: dict | None = None,
    timeout: float | None = None,
) -> Response:
    """"""HTTP DELETE request.""""""
    return _call(""DELETE"", url, params=params, headers=headers, timeout=timeout)
",alpha_factory_v1/af_requests.py,
survived,"    def count_disclaimers_in_notebook(nb_path: Path) -> int:
        try:
            data = json.loads(nb_path.read_text(encoding=""utf-8""))
        except Exception:
            return 0
        text = """"
        for cell in data.get(""cells"", []):
            if cell.get(""cell_type"") == ""markdown"":
                src = cell.get(""source"", """")
                if isinstance(src, list):
                    text += """".join(src)
                else:
                    text += str(src)
        return """".join(text.split()).count(disclaimer_normalized)
",scripts/verify_disclaimer_snippet.py,
survived,"def validate_input_model(code: str) -> bool:
    """"""
    Validate that the provided input model code is safe and only defines
    Pydantic models. Import statements and unsafe builtins are disallowed.
    """"""

    try:
        tree = ast.parse(code)
    except SyntaxError as e:
        return False, f""Syntax error in input model: {str(e)}""

    unsafe_calls = [
        'eval', 'exec', '__import__', 'subprocess', 'os.system',
        'os.popen', 'os.spawn', 'os.fork', 'pty.spawn'
    ]

    for node in ast.walk(tree):
        if isinstance(node, (ast.Import, ast.ImportFrom)):
            return False, ""Import statements are not allowed in input_model""

        if isinstance(node, ast.Call) and isinstance(node.func, ast.Name) and node.func.id in unsafe_calls:
            return False, f""Unsafe function call: {node.func.id}""

        if isinstance(node, ast.Call) and isinstance(node.func, ast.Attribute):
            attr_chain = []
            obj = node.func
            while isinstance(obj, ast.Attribute):
                attr_chain.append(obj.attr)
                obj = obj.value

            if isinstance(obj, ast.Name):
                attr_chain.append(obj.id)
                attr_path = '.'.join(reversed(attr_chain))

                if any(unsafe in attr_path for unsafe in unsafe_calls):
                    return False, f""Unsafe operation: {attr_path}""

    has_model = any(
        isinstance(node, ast.ClassDef) and
        any(
            (isinstance(base, ast.Name) and base.id == 'BaseModel') or
            (isinstance(base, ast.Attribute) and base.attr == 'BaseModel')
            for base in node.bases
        )
        for node in tree.body
    )

    if not has_model:
        return False, ""Input model must define a class inheriting from BaseModel""

    return True, """"
",backend/tools/tool_routes.py,
survived,"def linear_curve(t: float) -> float:
    return max(0.0, min(1.0, t))
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/simulation/forecast.py,
survived,"def test_pareto_df() -> None:
    pop = [mats.Individual([0.0, 0.0]), mats.Individual([1.0, 1.0])]
    pop[0].rank = 0
    pop[1].rank = 1
    df = web_app.pareto_df(pop)
    assert set(df.columns) == {""x"", ""y"", ""rank""}
    assert len(df) == 2",tests/test_web_app.py,
survived,"    def test_discover_alpha_offline(self) -> None:
        openai_mock = types.SimpleNamespace(ChatCompletion=types.SimpleNamespace(create=Mock()))
        with patch.object(stub, ""openai"", openai_mock, create=True):
            with patch.dict(os.environ, {}, clear=True):
                picks = stub.discover_alpha(num=1, ledger=None, model=""gpt-4o-mini"")
        openai_mock.ChatCompletion.create.assert_not_called()
        self.assertIsInstance(picks, list)
        self.assertEqual(len(picks), 1)
",alpha_factory_v1/tests/test_cross_industry_alpha.py,TestCrossIndustryAlpha
survived,"def test_namedarray_runtime_check_with_category():
    B = Axis(""batch"", 1)
    arr = NamedArray(jnp.zeros((B.size,), dtype=jnp.float32), (B,))
    assert arr.matches_axes(Float[""batch""])  # type: ignore
    assert not arr.matches_axes(Int[""batch""])  # type: ignore",tests/test_namedarray_typing.py,
survived,"def _wrap_namedarray_with_category(category: DTypeCategory):
    class DTypeType:
        def __class_getitem__(cls, axes_spec):
            axes = _parse_namedarray_axes(axes_spec)
            axes_with_dtype = replace(axes, dtype=category)
            return tp.Annotated[NamedArray, axes_with_dtype]

    return DTypeType
",src/haliax/typing.py,
survived,"def test_dtype_and_axes_annotation():
    def foo(x: f32[""batch embed""]):  # type: ignore  # noqa: F722
        pass

    ann = typing.get_args(typing.get_type_hints(foo, include_extras=True)[""x""])
    assert ann[0] is NamedArray
    spec = ann[1]
    assert spec.dtype == jnp.float32
    assert spec.before == (""batch"", ""embed"")
",tests/test_dtype_typing.py,
survived,"    def raise_for_status(self):
        if self.status_code >= 400:
            raise RuntimeError(""http error"")
",tests/test_openai_bridge_integration.py,DummyResponse
survived,"def convert_corpus(corpus, index):
    new_corpus = []
    for doc in corpus:
        new_corpus.append([index[w] for w in doc])
    return new_corpus
",scripts/bbc_demo.py,
survived,"    async def xml_stream_2(*args, **kwargs):
        yield ModelResponseStream(model=""gpt-4o-mini"", choices=[StreamingChoices(delta=Delta(content=""<""))])
        yield ModelResponseStream(model=""gpt-4o-mini"", choices=[StreamingChoices(delta=Delta(content=""judgement""))])
        yield ModelResponseStream(model=""gpt-4o-mini"", choices=[StreamingChoices(delta=Delta(content="">""))])
        yield ModelResponseStream(model=""gpt-4o-mini"", choices=[StreamingChoices(delta=Delta(content=""The""))])
        yield ModelResponseStream(model=""gpt-4o-mini"", choices=[StreamingChoices(delta=Delta(content="" answer""))])
        yield ModelResponseStream(model=""gpt-4o-mini"", choices=[StreamingChoices(delta=Delta(content="" is""))])
        yield ModelResponseStream(model=""gpt-4o-mini"", choices=[StreamingChoices(delta=Delta(content="" humorous""))])
        yield ModelResponseStream(model=""gpt-4o-mini"", choices=[StreamingChoices(delta=Delta(content="".""))])
        yield ModelResponseStream(model=""gpt-4o-mini"", choices=[StreamingChoices(delta=Delta(content=""<""))])
        yield ModelResponseStream(model=""gpt-4o-mini"", choices=[StreamingChoices(delta=Delta(content=""/judgement""))])
        yield ModelResponseStream(model=""gpt-4o-mini"", choices=[StreamingChoices(delta=Delta(content="">""))])
        yield ModelResponseStream(model=""gpt-4o-mini"", choices=[StreamingChoices(delta=Delta(content=""<""))])
        yield ModelResponseStream(model=""gpt-4o-mini"", choices=[StreamingChoices(delta=Delta(content=""completed""))])
        yield ModelResponseStream(model=""gpt-4o-mini"", choices=[StreamingChoices(delta=Delta(content="">""))])
",tests/streaming/test_streaming.py,
survived,"async def test_build_regex_guardrails_trigger():
    config = GuardrailConfig(rules=[GuardrailRule(name=""block"", pattern=""bad"")])
    guards = build_regex_guardrails(config)
    assert len(guards) == 1
    guard = guards[0]

    await guard(""good text"")  # should not raise

    with pytest.raises(ValueError):
        await guard(""this is bad"")",tests/test_guardrail_generator.py,
survived,"        def log(self, env) -> None:  # type: ignore[override]
            events.append(env.payload.get(""event""))
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_orchestrator.py,DummyLedger
survived,"        def __init__(self, *_a, **_kw) -> None:
            pass
",tests/test_agents.py,DummyLedger
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/machine/x/python/q3.py,
survived,"def _min(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""min() expects list or group"")
    vals = [it for it in v if it is not None]
    if not vals:
        return 0
    return min(vals)
",tests/machine/x/python/q2.py,
survived,"def _count(v):
    if isinstance(v, list):
        return len(v)
    if hasattr(v, ""Items""):
        return len(v.Items)
    raise Exception(""count() expects list or group"")
",tests/machine/x/python/q1.py,
survived,"def _q0():
    _src = lineitem
    _rows = _query(
        _src,
        [],
        {
            ""select"": lambda row: row,
            ""where"": lambda row: row[""l_shipdate""] <= ""1998-09-02"",
        },
    )
    _groups = _group_by(
        _rows,
        lambda row: {
            ""returnflag"": row[""l_returnflag""],
            ""linestatus"": row[""l_linestatus""],
        },
    )
    _items1 = _groups
    return [
        {
            ""returnflag"": _get(_get(g, ""key""), ""returnflag""),
            ""linestatus"": _get(_get(g, ""key""), ""linestatus""),
            ""sum_qty"": _sum([x[""l_quantity""] for x in g]),
            ""sum_base_price"": _sum([x[""l_extendedprice""] for x in g]),
            ""sum_disc_price"": _sum(
                [x[""l_extendedprice""] * (1 - x[""l_discount""]) for x in g]
            ),
            ""sum_charge"": _sum(
                [
                    x[""l_extendedprice""] * (1 - x[""l_discount""]) * (1 + x[""l_tax""])
                    for x in g
                ]
            ),
            ""avg_qty"": _avg([x[""l_quantity""] for x in g]),
            ""avg_price"": _avg([x[""l_extendedprice""] for x in g]),
            ""avg_disc"": _avg([x[""l_discount""] for x in g]),
            ""count_order"": len(g.Items),
        }
        for g in _items1
    ]
",tests/machine/x/python/q1.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/q2.py,Region
survived,"def test_summarize_error_returns_first_line() -> None:
    log = ""E   ValueError: bad\nline2\nline3""
    assert llm_client.summarize_error(log) == ""E   ValueError: bad""
",tests/test_llm_client_utils.py,
survived,"        def __init__(self, loss: float) -> None:
            self.loss = loss
",tests/test_world_model_demo.py,DummyLearner
survived,"        def remember(self, _obs, _reward) -> None:
            pass
",tests/test_world_model_demo.py,DummyLearner
survived,"def bincount(
    x: NamedArray,
    Counts: Axis,
    *,
    weights: NamedArray | ArrayLike | None = None,
    minlength: int = 0,
) -> NamedArray:
    """"""Named version of `jax.numpy.bincount`.

    The output axis is specified by ``Counts``.
    """"""

    if x.ndim != 1:
        raise ValueError(""bincount only supports 1D arrays"")

    w_array = None
    if weights is not None:
        if isinstance(weights, NamedArray):
            weights = haliax.broadcast_to(weights, x.axes)
            w_array = weights.array
        else:
            w_array = jnp.asarray(weights)

    result = jnp.bincount(x.array, weights=w_array, minlength=minlength, length=Counts.size)
    return NamedArray(result, (Counts,))
",src/haliax/ops.py,
survived,"        async def get_stuff() -> dict:
            return {}
",tests/test_tooldef.py,
survived,"        async def create_item() -> bool:
            return True
",tests/test_tooldef.py,
survived,"        async def get_items(user_id: int) -> list[Item]:
            return []
",tests/test_tooldef.py,
survived,"def _verify(path: Path, name: str) -> bytes:
    data = path.read_bytes()
    expected = checksums.get(name)
    if expected:
        actual = sha384(path)
        if expected != actual:
            sys.exit(f""Checksum mismatch for {name}"")
    return data
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/manual_build.py,
survived,"def evaluate_agent(agent: Agent, model: str) -> float:
    """"""Return agent score when evaluated with ``model``.

    This placeholder implementation simply returns the archived score. Tests
    patch this function to provide deterministic mock values.
    """"""

    return agent.score
",src/tools/transfer_test.py,
survived,"def run() -> None:
    parts = [""poly"", ""task"", ""18""]
    joined = ""-"".join(parts)
    assert joined.split(""-"")[2] == str(18)",benchmarks/poly_mini/task_018.py,
survived,"def run() -> None:
    n = 16
    total = sum(range(n))
    expected = n*(n-1)//2
    assert total == expected",benchmarks/swe_mini/task_016.py,
survived,"def run() -> None:
    parts = [""poly"", ""task"", ""9""]
    joined = ""-"".join(parts)
    assert joined.split(""-"")[2] == str(9)",benchmarks/poly_mini/task_009.py,
survived,"def run() -> None:
    parts = [""poly"", ""task"", ""6""]
    joined = ""-"".join(parts)
    assert joined.split(""-"")[2] == str(6)",benchmarks/poly_mini/task_006.py,
survived,"def test_run_transfer_test_appends(tmp_path, monkeypatch) -> None:
    db = tmp_path / ""arch.db""
    arch = Archive(db)
    arch.add({""name"": ""a""}, 0.5)
    out = tmp_path / ""results"" / ""transfer.csv""
    out.parent.mkdir(parents=True)
    out.write_text(""id,model,score\n1,z,0.500\n"")

    def fake_eval(agent, model):
        return agent.score + 0.1

    monkeypatch.setattr(tt, ""evaluate_agent"", fake_eval)
    tt.run_transfer_test([""m""], 1, archive_path=db, out_file=out)
    lines = out.read_text().splitlines()
    assert lines == [""id,model,score"", ""1,z,0.500"", ""1,m,0.600""]",tests/test_transfer_test.py,
survived,"def add(a: int, b: int) -> int:
    """"""Return the sum of a and b, intentionally broken.""""""
    return a - b",tests/fixtures/self_heal_repo/calc.py,
survived,"    def raise_for_status(self):
        pass
",tests/test_inspector_bridge.py,DummyResponse
survived,"    async def close(self) -> None:
        """"""Close the underlying transport connection.""""""
        await self._impl.close()
",alpha_factory_v1/backend/a2a_client.py,A2AClient
survived,"    def test_rsi(self):
        uptrend = list(range(1, 20))
        self.assertGreater(am.rsi(uptrend, period=5), 70)
        downtrend = list(range(20, 1, -1))
        self.assertLess(am.rsi(downtrend, period=5), 30)
",alpha_factory_v1/tests/test_alpha_model.py,AlphaModelTest
survived,"    def test_sma_crossover(self):
        prices = [5, 4, 3, 2, 3, 4]
        self.assertEqual(am.sma_crossover(prices, fast=2, slow=4), 1)
        prices = [2, 3, 4, 5, 4, 3]
        self.assertEqual(am.sma_crossover(prices, fast=2, slow=4), -1)
",alpha_factory_v1/tests/test_alpha_model.py,AlphaModelTest
survived,"    def test_toy_optimal(self):
        genes = {""temperature"": 0.7, ""top_p"": 0.9, ""max_tokens"": 128}
        self.assertAlmostEqual(gt.toy_fitness(genes), 3.0, places=2)
",alpha_factory_v1/tests/test_genetic_tests.py,GeneticTestsTest
survived,"                    def clear(self):
                        self.nodes.clear()
                        self.edges.clear()
",alpha_factory_v1/backend/memory_graph.py,GraphMemory._Stub
survived,"def _extract_json(text: str) -> Dict[str, Any]:
    """"""Return the first JSON object found inside *text*.""""""
    match = _JSON_RE.search(text)
    if not match:
        raise ValueError(""no JSON object found"")
    return json.loads(match.group(0))
",alpha_factory_v1/backend/planner_agent.py,
survived,"    def test_fallback_logic(self):
        agent = DummyAgent()
        model = DummyModel(""not json"")
        planner = PlannerAgent(
            name=""planner"",
            model=model,
            memory=self.memory,
            gov=self.gov,
            domain_agents=[agent],
        )
        random_result = planner.think([])[0]
        self.assertEqual(random_result[""agent""], agent.name)
        self.assertIn(""fallback"", random_result[""reason""])
",alpha_factory_v1/tests/test_planner_agent.py,PlannerAgentTest
survived,"    def vet_plans(self, agent, plans):  # noqa: D401
        return plans
",alpha_factory_v1/tests/test_planner_agent.py,DummyGov
survived,"    def test_invalid_params_raise(self):
        with self.assertRaises(ValueError):
            am.momentum([1, 2], lookback=0)
        with self.assertRaises(ValueError):
            am.sma_crossover([1]*5, fast=0, slow=1)
        with self.assertRaises(ValueError):
            am.sma_crossover([1]*5, fast=5, slow=3)
        with self.assertRaises(ValueError):
            am.ema([1], span=0)
        with self.assertRaises(ValueError):
            am.rsi([1, 2], period=0)
        with self.assertRaises(ValueError):
            am.bollinger_bands([1], window=0)
",alpha_factory_v1/tests/test_alpha_model.py,AlphaModelTest
survived,"def main() -> None:
    path = Path(sys.argv[1]) if len(sys.argv) > 1 else Path(""alpha_factory_v1/dashboards/alpha_factory_overview.json"")
    host = os.environ.get(""GRAFANA_HOST"", ""http://localhost:3000"").rstrip(""/"")
    token = os.environ.get(""GRAFANA_TOKEN"")
    if not token:
        raise SystemExit(""GRAFANA_TOKEN environment variable is required"")

    with path.open() as f:
        dashboard = json.load(f)

    payload = {""dashboard"": dashboard, ""folderId"": 0, ""overwrite"": True, ""inputs"": []}
    headers = {""Authorization"": f""Bearer {token}"", ""Content-Type"": ""application/json""}
    url = f""{host}/api/dashboards/import""
    resp = post(url, json=payload, headers=headers, timeout=10)
    try:
        resp.raise_for_status()
    except Exception as exc:  # pragma: no cover - network errors
        print(resp.text)
        raise SystemExit(exc)

    print(f""Imported dashboard '{dashboard.get('title', path.name)}' to {host}"")
",alpha_factory_v1/scripts/import_dashboard.py,
survived,"    def __repr__(self) -> str:  # noqa: D401
        return f""MarketEnv(price={self.price:.2f}, position={self.position})""
",alpha_factory_v1/backend/environments/market_sim.py,MarketEnv
survived,"    def remember(self, obs, reward):
        self.buffer.append((obs,reward))
        if len(self.buffer)>CFG.buffer_limit:
            self.buffer.pop(0)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,Learner
survived,"def _main():
    p=argparse.ArgumentParser(prog=""alpha_asi_world_model_demo"")
    p.add_argument(""--demo"",action=""store_true"")
    p.add_argument(""--emit-docker"",action=""store_true"")
    p.add_argument(""--emit-helm"",action=""store_true"")
    p.add_argument(""--emit-notebook"",action=""store_true"")
    p.add_argument(""--host"",default=""127.0.0.1"")
    p.add_argument(""--port"",type=int,default=7860)
    args=p.parse_args()
    if args.emit_docker: emit_docker()
    elif args.emit_helm: emit_helm()
    elif args.emit_notebook: emit_notebook()
    elif args.demo:
        uvicorn.run(""alpha_asi_world_model_demo:app"",host=args.host,port=args.port,log_level=""info"")
    else: p.print_help()
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,
survived,"    def __init__(self, obs_dim: int, act_dim: int):
        super().__init__()
        self.repr = Repr(obs_dim, CFG.hidden)
        self.dyn  = Dyn(CFG.hidden, act_dim)
        self.pred = Pred(CFG.hidden, act_dim)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,MuZeroTiny
survived,"    def test_env_defaults(self):
        os.environ[""PORT""] = ""9000""
        os.environ[""METRICS_PORT""] = ""9100""
        os.environ[""A2A_PORT""] = ""9200""
        os.environ[""CYCLE""] = ""5""
        args = self._parse([])
        for key in (""PORT"", ""METRICS_PORT"", ""A2A_PORT"", ""CYCLE""):
            os.environ.pop(key, None)
        self.assertEqual(args.port, 9000)
        self.assertEqual(args.metrics_port, 9100)
        self.assertEqual(args.a2a_port, 9200)
        self.assertEqual(args.cycle, 5)
",alpha_factory_v1/tests/test_edge_runner.py,EdgeRunnerParseTest
survived,"def list_available_examples() -> dict[str, str]:
    """"""Return a mapping of example name to app path.""""""
    base_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), os.pardir))
    examples: dict[str, str] = {}
    for entry in os.scandir(base_dir):
        if not entry.is_dir() or entry.name == ""openai_chat_agent"":
            continue
        app_path = os.path.join(entry.path, ""app.py"")
        if os.path.exists(app_path):
            examples[entry.name] = app_path
    return examples
",examples/openai_chat_agent/app.py,
survived,"def test_results_dir_permissions(tmp_path: Path, monkeypatch: pytest.MonkeyPatch) -> None:
    """"""Directory is created with 0700 permissions.""""""

    path = tmp_path / ""results""
    monkeypatch.setenv(""SIM_RESULTS_DIR"", str(path))

    import importlib

    from src.interface import api_server as api

    api = importlib.reload(api)

    assert path.exists()
    assert (path.stat().st_mode & 0o777) == 0o700
",tests/test_api_server.py,
survived,"    def fake_secho(message, **kwargs):
        messages.append(click.unstyle(message))
",tests/integration/test_ux_interactions.py,
survived,"def capture_secho(monkeypatch):
    messages = []

    def fake_secho(message, **kwargs):
        messages.append(click.unstyle(message))

    monkeypatch.setattr(click, ""secho"", fake_secho)
    return messages
",tests/integration/test_ux_interactions.py,
survived,"        def with_output(self, x):
            out = x + self.w
            return out, 2 * self.w
",tests/test_scan.py,Module
survived,"    def scan_via(self, fn: Callable[..., tuple[CarryT, OutputT_co]]):
        """"""Return a function that scans over the stack using ``fn``.

        ``fn`` should take a block and a carry and return ``(carry, output)``.
        Semantics match :func:`haliax.scan` over the block axis.
        """"""

        def do_block(carry: CarryT, block: M) -> tuple[CarryT, OutputT_co]:
            return fn(block, carry)

        def do_scan(init: CarryT) -> tuple[CarryT, OutputT_co]:
            return haliax.scan(do_block, self.Block, remat=self.gradient_checkpointing)(init, self.stacked)

        return do_scan
",src/haliax/nn/scan.py,Stacked
survived,"    def fold_via(self, fn: Callable[..., CarryT]):
        """"""Return a function that folds over the stack using ``fn``.

        ``fn`` should take a block and a carry and return a new carry.  The
        returned function mirrors :func:`haliax.fold` over the block axis.
        """"""

        def do_block(carry: CarryT, block: M) -> CarryT:
            return fn(block, carry)

        def do_fold(init: CarryT) -> CarryT:
            return haliax.fold(do_block, self.Block, remat=self.gradient_checkpointing)(init, self.stacked)

        return do_fold
",src/haliax/nn/scan.py,Stacked
survived,"def test_llm_openai_path() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri()

    with sync_playwright() as p:
        browser = p.chromium.launch()
        page = browser.new_page()
        page.route(
            ""https://api.openai.com/**"",
            lambda route: route.fulfill(
                status=200,
                content_type=""application/json"",
                body='{""choices"":[{""message"":{""content"":""pong""}}]}',
            ),
        )
        page.goto(url)
        page.evaluate(""localStorage.setItem('OPENAI_API_KEY','sk')"")

        out = page.evaluate(""window.llmChat('hi')"")
        assert out == 'pong'
        browser.close()",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_browser_ui.py,
survived,"def test_llm_offline() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri()

    with sync_playwright() as p:
        browser = p.chromium.launch()
        page = browser.new_page()
        page.goto(url)
        page.wait_for_selector(""#controls"")

        out = page.evaluate(""window.llmChat('hi')"")
        assert out.startswith('[offline]')
        browser.close()
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_browser_ui.py,
survived,"def main(argv: list[str] | None = None) -> None:
    args = _parse_args(argv)
    runtime = AgentRuntime(api_key=None)
    agent = GovernanceSimAgent()
    runtime.register(agent)
    if args.enable_adk:
        try:
            from alpha_factory_v1.backend.adk_bridge import auto_register, maybe_launch

            auto_register([agent])
            maybe_launch()
        except Exception as exc:  # pragma: no cover - ADK optional
            logger.warning(f""ADK bridge unavailable: {exc}"")
    logger.info(""Registered GovernanceSimAgent with runtime"")
    runtime.run()
",alpha_factory_v1/demos/solving_agi_governance/openai_agents_bridge.py,
survived,"def boom():
    print(""boom"")
    return True
",tests/human/py/bool_chain.py,
survived,"        async def __aexit__(self, exc_type, exc, tb) -> None:
            return False
",alpha_factory_v1/demos/alpha_agi_business_v1/openai_agents_bridge.py,AsyncClient
survived,"    async def _background_run(sim_id: str, cfg: SimRequest) -> None:
        secs = [sector.Sector(f""s{i:02d}"") for i in range(cfg.pop_size)]
        traj: list[ForecastTrajectoryPoint] = []
        for year in range(1, cfg.horizon + 1):
            t = year / cfg.horizon
            cap = forecast.capability_growth(t, cfg.curve, k=cfg.k, x0=cfg.x0)
            for sec in secs:
                if not sec.disrupted:
                    sec.energy *= 1.0 + sec.growth
                    if forecast.thermodynamic_trigger(sec, cap):
                        sec.disrupted = True
                        sec.energy += forecast._innovation_gain(
                            cfg.pop_size,
                            cfg.generations,
                            mut_rate=cfg.mut_rate,
                            xover_rate=cfg.xover_rate,
                        )
            snapshot = [sector.Sector(s.name, s.energy, s.entropy, s.growth, s.disrupted) for s in secs]
            point = forecast.TrajectoryPoint(year, cap, snapshot)
            traj.append(point)
            for ws in list(_progress_ws):
                try:
                    await ws.send_json({""id"": sim_id, ""year"": year, ""capability"": cap})
                except Exception:
                    _progress_ws.discard(ws)
            await asyncio.sleep(0)

        def eval_fn(genome: list[float]) -> tuple[float, float, float]:
            x, y = genome
            return x**2, y**2, (x + y) ** 2

        scenario = hashlib.sha1(sim_id.encode()).hexdigest()
        orch = getattr(app_f.state, ""orchestrator"", None)
        if orch is not None:
            pop = await orch.evolve(
                scenario,
                eval_fn,
                2,
                population_size=cfg.pop_size,
                generations=cfg.generations,
                experiment_id=sim_id,
            )
        else:
            pop = mats.run_evolution(
                eval_fn,
                2,
                population_size=cfg.pop_size,
                generations=cfg.generations,
                scenario_hash=scenario,
            )

        pop_data = [
            PopulationMember(
                effectiveness=ind.fitness[0],
                risk=ind.fitness[1],
                complexity=ind.fitness[2],
                rank=ind.rank,
            )
            for ind in pop
        ]

        result = ResultsResponse(
            id=sim_id,
            forecast=[ForecastPoint(year=p.year, capability=p.capability) for p in traj],
            population=pop_data,
        )
        _save_result(result)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/api_server.py,
survived,"    def getParameterById(self, pid: str):
        par = self.importer.sbml.getParameter(pid)
        return par.getValue() if par else np.nan
",tests/testSBMLSuiteJax.py,DummyModel
survived,"def sbml_test_dir():
    old_cwd = os.getcwd()
    old_path = copy.copy(sys.path)
    yield
    os.chdir(old_cwd)
    sys.path = old_path
",tests/testSBMLSuiteJax.py,
survived,"    def __len__(self):
        return len(self.Items)
",tests/machine/x/python/group_by_multi_join_sort.py,_Group
survived,"    def __len__(self):
        return len(self.Items)
",tests/machine/x/python/group_by_join.py,_Group
survived,"    def fake_run(self, code_directory, command, **_):
        called[""args""] = (code_directory, command)
        return 0, ""out"", ""err""
",tests/test_template_governance.py,
survived,"def load_golden_spec_fuzz_set() -> List[str]:
    """"""Return the list of vague specification strings used for tests.""""""
    try:
        data_path = resources.files(""meta_agent"").joinpath(_DEF_PATH)
        text = data_path.read_text(encoding=""utf-8"")
        data = yaml.safe_load(text) or {}
    except FileNotFoundError:
        return []
    specs = data.get(""specs"")
    if isinstance(specs, list):
        return [str(s) for s in specs]
    return []",src/meta_agent/utils/golden_specs.py,
survived,"    def __init__(self, secret: str, cache_path: str | Path | None = None) -> None:
        self.secret = secret.encode(""utf-8"")
        self.cache_path = Path(cache_path or ""template_signatures.json"")
        if self.cache_path.exists():
            try:
                self.cache: Dict[str, str] = json.loads(self.cache_path.read_text())
            except Exception:
                self.cache = {}
        else:
            self.cache = {}
",src/meta_agent/template_governance.py,TemplateGovernance
survived,"def main() -> int:
    repo_root = Path(__file__).resolve().parents[1]
    req_txt = repo_root / ""alpha_factory_v1"" / ""demos"" / ""meta_agentic_tree_search_v0"" / ""requirements.txt""
    lock_file = repo_root / ""alpha_factory_v1"" / ""demos"" / ""meta_agentic_tree_search_v0"" / ""requirements.lock""

    with tempfile.TemporaryDirectory() as tmpdir:
        out_path = Path(tmpdir) / ""requirements.lock""
        pip_compile = shutil.which(""pip-compile"")
        if pip_compile:
            cmd = [pip_compile]
        else:
            cmd = [sys.executable, ""-m"", ""piptools"", ""compile""]
        wheelhouse = os.getenv(""WHEELHOUSE"")
        cmd += [""--quiet""]
        if wheelhouse:
            cmd += [""--no-index"", ""--find-links"", wheelhouse]
        cmd += [""--generate-hashes"", str(req_txt), ""-o"", str(out_path)]
        result = subprocess.run(cmd, capture_output=True, text=True)
        sys.stdout.write(result.stdout)
        sys.stderr.write(result.stderr)
        if result.returncode != 0:
            return result.returncode
        if not lock_file.exists() or out_path.read_bytes() != lock_file.read_bytes():
            extra = """"
            if wheelhouse:
                extra = f""--no-index --find-links {wheelhouse} ""
            msg = (
                ""alpha_factory_v1/demos/meta_agentic_tree_search_v0/requirements.lock is outdated. Run 'pip-compile ""
                f""{extra}--quiet --generate-hashes alpha_factory_v1/demos/meta_agentic_tree_search_v0/requirements.txt -o ""
                ""alpha_factory_v1/demos/meta_agentic_tree_search_v0/requirements.lock'\n""
            )
            sys.stderr.write(msg)
            return 1
    return 0
",scripts/verify_mats_requirements_lock.py,
survived,"        def Linear(*_, **__): return None
",alpha_factory_v1/demos/aiga_meta_evolution/meta_evolver.py,_DummyNN
survived,"def register_demo_agents() -> None:
    """"""Register the demo agent with the framework.""""""

    register_agent(
        AgentMetadata(
            name=IncorporatorAgent.NAME,
            cls=IncorporatorAgent,
            version=""1.0.0"",
            capabilities=IncorporatorAgent.CAPABILITIES,
        )
    )
",alpha_factory_v1/demos/alpha_agi_business_v1/alpha_agi_business_v1.py,
survived,"async def run_search(episodes: int = 10, target: int = 5) -> str:
    """"""Execute the search loop and return a summary string.""""""
    run(episodes=episodes, target=target)
    return f""completed {episodes} episodes toward target {target}""
",alpha_factory_v1/demos/meta_agentic_tree_search_v0/openai_agents_bridge.py,
survived,"def check_python() -> bool:
    if sys.version_info < MIN_PY or sys.version_info >= MAX_PY:
        banner(
            f""Python {MIN_PY[0]}.{MIN_PY[1]}+ and <{MAX_PY[0]}.{MAX_PY[1]} required"",
            ""RED"",
        )
        return False
    banner(f""Python {sys.version.split()[0]} detected"", ""GREEN"")
    return True
",scripts/setup_wizard.py,
survived,"    def get_agent(name: str) -> DummyAgent:
        assert name == ""dummy""
        return DummyAgent()
",tests/test_agent_manager_consumer.py,
survived,"    def setUp(self) -> None:
        self._reg_backup = agents.AGENT_REGISTRY.copy()
        agents.AGENT_REGISTRY.clear()
        self._fail_backup = discovery.FAILED_AGENTS.copy()
        discovery.FAILED_AGENTS.clear()
",tests/test_failed_agent_discovery.py,TestFailedAgentDiscovery
survived,"def list_agents(detail: bool = False):
    """"""Return agent registry entries and failed imports when ``detail`` is ``True``.""""""
    entries = _list_agents(detail=detail)
    if not detail:
        return entries
    failed = [{""name"": name, ""status"": ""error"", ""message"": msg} for name, msg in sorted(FAILED_AGENTS.items())]
    return entries + failed
",alpha_factory_v1/backend/agents/__init__.py,
survived,"            def __init__(self, bootstrap_servers: str) -> None:
                events.append(bootstrap_servers)
",tests/test_message_bus.py,TestMessageBus.Prod
survived,"            async def _send() -> None:
                bus.publish(""b"", env)
                await asyncio.sleep(0)
",tests/test_message_bus.py,TestMessageBus
survived,"def client() -> TestClient:
    os.environ.setdefault(""API_TOKEN"", ""test-token"")
    os.environ.setdefault(""API_RATE_LIMIT"", ""1000"")
    api = importlib.reload(api_server)
    return TestClient(cast(Any, api.app))
",tests/test_insight_api_server.py,
survived,"def document_module(module: ModuleType, file: TextIO) -> None:
    file.write(f""# {module.__name__}\n\n"")
    if module.__doc__:
        file.write(inspect.getdoc(module))
        file.write(""\n\n"")
    for name, obj in inspect.getmembers(module):
        if name.startswith(""_""):
            continue
        if inspect.isfunction(obj) or inspect.isclass(obj):
            file.write(f""## {name}\n\n"")
            doc = inspect.getdoc(obj) or ""No documentation.""
            file.write(doc)
            file.write(""\n\n"")
",scripts/generate_interface_docs.py,
survived,"def main() -> None:
    for path in PACKAGE.rglob(""*.py""):
        if path.name == ""__init__.py"":
            continue
        module_name = path.with_suffix("""").as_posix().replace(""/"", ""."")
        module = importlib.import_module(module_name)
        out_file = DOCS_DIR / f""{module_name.replace('.', '_')}.md""
        with out_file.open(""w"") as f:
            document_module(module, f)
",scripts/generate_interface_docs.py,
survived,"def test_get_system_info_returns_info_even_on_exception(system_mock: mock.MagicMock) -> None:
    info = metrics.get_system_info()
    assert isinstance(info, dict)
    assert info == {}
    system_mock.assert_called_once_with()",tests/inference/unit_tests/core/managers/test_metrics.py,
survived,"def test_show_results_missing(tmp_path) -> None:
    with patch.object(cli.config, ""Settings"") as settings:
        settings.return_value.ledger_path = tmp_path / ""ledger.txt""
        out = CliRunner().invoke(cli.main, [""show-results""])
        assert ""No results"" in out.output
",tests/test_cli.py,
survived,"    async def step(self) -> None:
        return None
",tests/test_agents.py,DummyHB
survived,"    def read(self, *args):
        # Return as byte strings that can be split
        return self.inputs
",scripts/utils/lcb_runner.py,MockBuffer
survived,"    async def serve(self) -> None:
        """"""Run the scheduler until quotas are exhausted or queue is empty.""""""
        self.start_time = time.time()
        await self.app.serve()
        # wait for running tasks to finish
        if self.running:
            await asyncio.gather(*self.running, return_exceptions=True)
",src/scheduler.py,SelfImprovementScheduler
survived,"def _view_tool(ctx: RunContextWrapper | dict, path: str, start: int = 0, end: Optional[int] = None) -> str:
    return view(path, start, end)
",src/self_edit/tools.py,
survived,"def _replace_tool(ctx: RunContextWrapper | dict, path: str, pattern: str, repl: str) -> int:
    return replace(path, pattern, repl)
",src/self_edit/tools.py,
survived,"def test_replace_property(data: str) -> None:
    path = REPO_ROOT / ""tmp_self_edit_prop.txt""
    try:
        path.write_bytes(data.encode())
        count = replace(path, ""a"", ""b"")
        expected, exp_count = re.subn(""a"", ""b"", data, flags=re.MULTILINE)
        assert count == exp_count
        assert path.read_bytes().decode() == expected
    finally:
        if path.exists():
            path.unlink()
",tests/test_self_edit_tools.py,
survived,"        def ipfs_handler(route):
            route.fulfill(
                status=200,
                content_type=""application/json"",
                body='{""gen"":0,""pop"":[{""logic"":0,""feasible"":0,""front"":false,""strategy"":""base""}],""rngState"":0}',
            )
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_pwa_offline.py,
survived,"    def _get_labeling_params(self) -> Dict:
        from_name, to_name, value = self.label_interface.get_first_tag_occurence(
            'TimeSeriesLabels', 'TimeSeries')
        tag = self.label_interface.get_tag(from_name)
        labels = list(tag.labels)
        ts_tag = self.label_interface.get_tag(to_name)
        time_col = ts_tag.attr.get('timeColumn')
        channels = [ch.attr['column'] for ch in ts_tag.children if ch.tag == 'Channel']
        return {
            'from_name': from_name,
            'to_name': to_name,
            'value': value,
            'labels': labels,
            'time_col': time_col,
            'channels': channels
        }
",label_studio_ml/examples/timeseries_segmenter/model.py,TimeSeriesSegmenter
survived,"    def test_py_bool_parentheses(self) -> None:
        """"""Ensure boolean expressions preserve parentheses during conversion.""""""
        from jaclang.compiler.passes.main import PyastBuildPass
        import jaclang.compiler.unitree as uni
        import ast as py_ast

        py_out_path = os.path.join(self.fixture_abs_path(""./""), ""py_bool_expr.py"")
        with open(py_out_path) as f:
            file_source = f.read()
            output = PyastBuildPass(
                ir_in=uni.PythonModuleAst(
                    py_ast.parse(file_source),
                    orig_src=uni.Source(file_source, py_out_path),
                ),
                prog=JacProgram(),
            ).ir_out.unparse()
        self.assertIn(""(prev_token_index is None)"", output)
        self.assertIn(""(next_token_index is None)"", output)
        self.assertIn(""(tok[ 0 ] > change_end_line)"", output)
        self.assertIn(""(tok[ 0 ] == change_end_line)"", output)
        self.assertIn(""(tok[ 1 ] > change_end_char)"", output)",jac/jaclang/tests/test_language.py,JacLanguageTests
survived,"def append_json(data, path):
    cur = load_json(path)
    cur.extend(data)
    save_json(cur, path)
",convert_missing.py,
survived,"    def model_dump(self) -> Dict[str, Any]:
        ...
",alpha_factory_v1/utils/config_common.py,_TypedBaseSettings
survived,"    def get_template(self, name: str) -> Template:
        text = self.loader.get_source(self, name)
        return Template(text, name, globals=self.globals)",src/jinja2/__init__.py,Environment
survived,"        async def wrapper(*args: Any, **kwargs: Any):
            tries = 0
            while True:
                try:
                    return await func(*args, **kwargs)
                except exceptions:
                    tries += 1
                    if tries >= max_tries:
                        raise
",src/backoff/__init__.py,
survived,"    def patch(self, *args, **kwargs):  # noqa: D401
        return patch(*args, **kwargs)
",src/pytest_mock/__init__.py,MockerFixture
survived,"def test_cli_dashboard_with_data(runner, tmp_path):
    db_path = tmp_path / ""tele.db""
    db = TelemetryDB(db_path)
    db.record(5, 0.1, 0.2, 1)
    db.close()
    result = runner.invoke(cli, [""dashboard"", ""--db-path"", str(db_path)])
    assert result.exit_code == 0
    assert ""Telemetry Dashboard:"" in result.output
    assert ""5"" in result.output
    assert ""$0.10"" in result.output",tests/test_cli.py,
survived,"def top_tags(request):
    """"""Display recent headlines for the 10 most popular tags.""""""
    tags = (
        Tag.objects.annotate(
            entry_count=models.Count(
                ""entry"", filter=models.Q(entry__is_draft=False), distinct=True
            ),
            blogmark_count=models.Count(
                ""blogmark"", filter=models.Q(blogmark__is_draft=False), distinct=True
            ),
            quotation_count=models.Count(
                ""quotation"", filter=models.Q(quotation__is_draft=False), distinct=True
            ),
            note_count=models.Count(
                ""note"", filter=models.Q(note__is_draft=False), distinct=True
            ),
        )
        .annotate(
            total=models.F(""entry_count"")
            + models.F(""blogmark_count"")
            + models.F(""quotation_count"")
            + models.F(""note_count"")
        )
        .order_by(""-total"")[:10]
    )
    tags_info = [
        {
            ""tag"": tag,
            ""total"": tag.total,
            ""recent_entries"": tag.entry_set.filter(is_draft=False)
            .order_by(""-created"")[:5],
        }
        for tag in tags
    ]
    return render(request, ""top_tags.html"", {""tags_info"": tags_info})
",blog/views.py,
survived,"def test_download_invocation(monkeypatch: pytest.MonkeyPatch, tmp_path: Path) -> None:
    calls: list[tuple[str, Path]] = []

    def fake_download(url: str, dest: Path) -> None:
        calls.append((url, dest))
        dest.write_text(""stub"")

    monkeypatch.setattr(dg, ""_download"", fake_download)
    dg.download_openai_gpt2(""117M"", dest=tmp_path)
    assert len(calls) == len(dg._FILE_LIST)
    assert calls[0][0] == dg.model_urls(""117M"")[0]",tests/test_download_openai_gpt2.py,
survived,"def test_no_innerhtml_usage() -> None:
    files = [
        Path('alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/src/ui/EvolutionPanel.ts'),
        Path('alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/src/ui/ControlsPanel.ts'),
    ]
    for f in files:
        text = f.read_text()
        assert '.innerHTML' not in text
",tests/test_ui_xss_safety.py,
survived,"def test_new_metrics_present() -> None:
    client = make_client()
    resp = client.get(""/metrics"")
    assert resp.status_code == 200
    text = resp.text
    assert ""dgm_parents_selected_total"" in text
    assert ""dgm_children_admitted_total"" in text
    assert ""dgm_revives_total"" in text",tests/test_metrics_exposure.py,
survived,"def discover_adk() -> None:
    """"""Pull remote agent wheels via Google ADK if ``$ADK_MESH`` is set.""""""
    if adk is None or not os.getenv(""ADK_MESH""):
        return
    try:
        client = adk.Client()
        for pkg in client.list_remote_packages():
            if pkg.name in AGENT_REGISTRY:
                continue
            wheel_path = client.download_package(pkg.name)
            try:
                sig_path = client.download_package(pkg.name + "".sig"")
            except Exception:
                sig_path = None
            _HOT_DIR.mkdir(parents=True, exist_ok=True)
            dest = _HOT_DIR / wheel_path.name
            dest.write_bytes(wheel_path.read_bytes())
            if sig_path:
                (dest.with_suffix(dest.suffix + "".sig"")).write_bytes(sig_path.read_bytes())
            if not verify_wheel(dest):
                logger.error(""Discarding unverified wheel from ADK: %s"", pkg.name)
                dest.unlink(missing_ok=True)
                if sig_path:
                    dest.with_suffix(dest.suffix + "".sig"").unlink(missing_ok=True)
                continue
            logger.info(""Pulled %s from ADK mesh"", pkg.name)
        discover_hot_dir()
    except Exception:  # noqa: BLE001
        logger.exception(""ADK discovery failed"")",alpha_factory_v1/backend/agents/discovery.py,
survived,"def _inspect_module(mod: ModuleType) -> Optional[AgentMetadata]:
    """"""Return metadata for an agent implementation.""""""
    AgentBase = _agent_base()
    for _, obj in inspect.getmembers(mod, inspect.isclass):
        if issubclass(obj, AgentBase) and obj is not AgentBase:
            return AgentMetadata(
                name=getattr(obj, ""NAME"", obj.__name__),
                cls=obj,
                version=getattr(obj, ""__version__"", ""0.1.0""),
                capabilities=list(getattr(obj, ""CAPABILITIES"", [])),
                compliance_tags=list(getattr(obj, ""COMPLIANCE_TAGS"", [])),
                requires_api_key=getattr(obj, ""REQUIRES_API_KEY"", False),
            )
    return None
",alpha_factory_v1/backend/agents/discovery.py,
survived,"    def load_env(seed: int):
        cfg = tmp_path / ""config.yaml""
        cfg.write_text(f""general:\n  seed: {seed}\n"")
        monkeypatch.chdir(tmp_path)
        monkeypatch.setenv(""NO_LLM"", ""1"")
        monkeypatch.setenv(""ALPHA_ASI_SILENT"", ""1"")
        monkeypatch.setenv(""ALPHA_ASI_MAX_STEPS"", ""1"")
        if module in sys.modules:
            del sys.modules[module]
        mod = importlib.import_module(module)
        env = mod.Orchestrator().envs[0]
        return env.size, sorted(env.obstacles)
",tests/test_world_model_config.py,
survived,"            def _forward(batch):
                tokens = tokenizer(
                    batch[""text""],
                    truncation=True,
                    padding=True,
                    max_length=cfg.max_length,
                    return_tensors=""pt"",
                )
                tokens = {k: v.to(device) for k, v in tokens.items()}
                with torch.no_grad():
                    outputs = model(**tokens)
                xm.mark_step()
                batch[""logits""] = outputs.logits.cpu().tolist()
                return batch
",marin/generation/logits.py,
survived,"def delta_sector_to_dcf(sector_state: Dict[str, float]) -> Dict[str, Any]:
    """"""Convert ``sector_state`` deltas into a discounted cash flow representation.

    The input dictionary should contain the following keys:

    - ``delta_revenue``: annual revenue delta (absolute value).
    - ``margin``: operating margin as a decimal.
    - ``discount_rate``: discount rate as a decimal.
    - ``years``: number of forecast years.

    Returns a dictionary with calculated ``cash_flows`` and ``npv``.
    """"""

    delta_revenue = float(sector_state.get(""delta_revenue"", 0.0))
    margin = float(sector_state.get(""margin"", 0.0))
    discount_rate = float(sector_state.get(""discount_rate"", 0.1))
    years = int(sector_state.get(""years"", 1))

    cash_flow = delta_revenue * margin
    cash_flows = [cash_flow for _ in range(years)]
    npv = sum(cf / ((1 + discount_rate) ** (i + 1)) for i, cf in enumerate(cash_flows))
    return {""cash_flows"": cash_flows, ""npv"": npv}
",src/finance/adapter.py,
survived,"    def test_tree_has_single_path_false(self):
        """"""Tree branching results in ``False``.""""""
        tree = FPTree([[1, 2], [1, 3]], 1, None, None)
        self.assertFalse(tree.tree_has_single_path(tree.root))
",tests/test_pyfpgrowth.py,FPTreeTests
survived,"    def test_zip_patterns(self):
        """"""zip_patterns appends the suffix when present.""""""
        tree = FPTree([], 1, 'b', 1)
        zipped = tree.zip_patterns({('a',): 2})
        self.assertEqual(zipped, {('a', 'b'): 2})
",tests/test_pyfpgrowth.py,FPTreeTests
survived,"        def make_class_embeddings_dict(self, *args, **kwargs):
            return {}
",tests/inference/models_predictions_tests/test_owlv2.py,DummyOwl
survived,"def _lead_time(truth: Iterable[bool], pred: Iterable[bool]) -> int:
    truth_list = list(truth)
    pred_list = list(pred)

    def first_true(seq: list[bool]) -> int:
        for i, val in enumerate(seq):
            if val:
                return i
        return len(seq)

    return first_true(pred_list) - first_true(truth_list)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/evaluate_econ.py,
survived,"    def __enter__(self) -> ""ArchiveService"":
        return self
",src/archive/service.py,ArchiveService
survived,"    async def _loop(self, interval: int) -> None:
        while True:
            await asyncio.sleep(interval)
            await self.broadcast_merkle_root()
",src/archive/service.py,ArchiveService
survived,"def create_app(service: DualCriticService) -> ""FastAPI"":
    return service.create_app()",src/critics/dual_critic_service.py,
survived,"def test_grpc_scoring() -> None:
    service = DualCriticService([""Rome is the capital of Italy.""])
    port = _free_port()

    async def run() -> None:
        await service.start_grpc(port)
        async with grpc.aio.insecure_channel(f""localhost:{port}"") as ch:
            stub = ch.unary_unary(""/critics.Critic/Score"")
            payload = {
                ""context"": ""Rome is the capital of Italy."",
                ""response"": ""Rome is the capital of Italy."",
            }
            reply = await stub(json.dumps(payload).encode())
            data = json.loads(reply.decode())
            assert data[""logic""] == 1.0
        await service.stop_grpc()

    asyncio.run(run())
",tests/test_critics.py,
survived,"    def feasibility_score(self, response: str) -> Tuple[float, List[str]]:
        """"""Score feasibility via similarity search.""""""
        hits = self.db.search(response)
        score = hits[0][1] if hits else 0.0
        citations = [h[0] for h in hits]
        return score, citations
",src/critics/dual_critic_service.py,DualCriticService
survived,"def weekly_report(csv_path: str | Path = ""replay_metrics.csv"") -> str:
    """"""Generate a plain-text weekly report and return it.""""""
    rows = load_metrics(csv_path)
    stats = aggregate_stats(rows)
    anomalies = detect_anomalies(rows)
    lines = [""Weekly Meta Foresight Report""]
    for m in _METRICS:
        mean = stats.get(f""{m}_mean"", float(""nan""))
        st = stats.get(f""{m}_stdev"", float(""nan""))
        lines.append(f""{m}: mean={mean:.3f} stdev={st:.3f}"")
    lines.append(f""anomalies_detected={len(anomalies)}"")
    return ""\n"".join(lines)
",src/analysis/meta_foresight.py,
survived,"        def do_POST(self):
            length = int(self.headers.get(""Content-Length"", 0))
            type(self).received_body = self.rfile.read(length)
            type(self).received_headers = dict(self.headers)
            self.send_response(status)
            self.end_headers()
            self.wfile.write(type(self).received_body)
",alpha_factory_v1/tests/test_requests_shim.py,Handler
survived,"def start_server(status=200, body=b""ok""):
    class Handler(BaseHTTPRequestHandler):
        received_body = None
        received_headers = None

        def do_GET(self):
            type(self).received_headers = dict(self.headers)
            self.send_response(status)
            self.end_headers()
            self.wfile.write(body)

        def do_POST(self):
            length = int(self.headers.get(""Content-Length"", 0))
            type(self).received_body = self.rfile.read(length)
            type(self).received_headers = dict(self.headers)
            self.send_response(status)
            self.end_headers()
            self.wfile.write(type(self).received_body)

    server = HTTPServer((""localhost"", 0), Handler)
    t = threading.Thread(target=server.serve_forever, daemon=True)
    t.start()
    url = f""http://{server.server_address[0]}:{server.server_address[1]}""
    return server, t, Handler, url
",alpha_factory_v1/tests/test_requests_shim.py,
survived,"    def test_register_invalid_class(self):
        """"""Decorator should reject non-AgentBase subclasses.""""""
        with self.assertRaises(TypeError):
            @register
            class Bad:
                NAME = ""bad""
",alpha_factory_v1/tests/test_register_decorator.py,RegisterDecoratorTest
survived,"        def __init__(self) -> None:
            self.nodes: dict = {}
            self.edges: dict = {}
",alpha_factory_v1/backend/agents/supply_chain_agent.py,_FakeGraph
survived,"def get_version() -> str:
    """"""Return the Alphaâ€‘Factory package version.""""""

    return __version__
",alpha_factory_v1/__init__.py,
survived,"        def stop(self) -> None:  # pragma: no cover - unused
            pass
",tests/test_alpha_agi_business_3_v1.py,DummySock
survived,"            def __init__(self, url: str) -> None:
                captured[""url""] = url
",tests/test_insight_orchestrator_features.py,TestLedger.DummyClient
survived,"def free_energy(sector: Sector, capability: float) -> float:
    return sector.energy - capability * sector.entropy
",alpha_factory_v1/core/simulation/forecast.py,
survived,"def _evolve_step(
    pop: Population,
    fn: Callable[[List[float]], Tuple[float, ...]],
    *,
    rng: random.Random,
    mutation_rate: float,
    crossover_rate: float,
    novelty: NoveltyIndex | None = None,
    critics: Iterable[Callable[[List[float]], float]] | None = None,
) -> Population:
    """"""Return the next generation from ``pop`` using NSGAâ€‘II.""""""

    evaluate(pop, fn, novelty, critics)
    mu = len(pop)
    genome_length = len(pop[0].genome)
    offspring: Population = []
    while len(offspring) < mu:
        a, b = rng.sample(pop, 2)
        if genome_length > 1 and rng.random() < crossover_rate:
            cut = rng.randint(1, genome_length - 1)
            child_genome = a.genome[:cut] + b.genome[cut:]
        else:
            child_genome = list(a.genome)
        if rng.random() < mutation_rate:
            idx = rng.randrange(genome_length)
            child_genome[idx] += rng.uniform(-1, 1)
        offspring.append(Individual(child_genome))
    evaluate(offspring, fn, novelty, critics)
    union = pop + offspring
    fronts = _non_dominated_sort(union)
    new_pop: Population = []
    for front in fronts:
        _crowding(front)
        front.sort(key=lambda x: (-x.rank, -x.crowd))
        for ind in front:
            if len(new_pop) < mu:
                new_pop.append(ind)
    return new_pop
",alpha_factory_v1/core/simulation/mats.py,
survived,"def send_alert(message: str, url: str | None = None) -> None:
    """"""Post *message* to ``url`` or ``ALERT_WEBHOOK_URL`` if set.""""""

    hook = url or os.getenv(""ALERT_WEBHOOK_URL"")
    if not hook:
        return

    payload = {""content"": message}
    if ""slack.com"" in hook:
        payload = {""text"": message}

    try:
        resp = requests.post(hook, json=payload, timeout=5)
        if not 200 <= resp.status_code <= 299:
            _log.warning(""alert failed with status %s"", resp.status_code)
    except Exception as exc:  # pragma: no cover - network errors
        _log.warning(""alert failed: %s"", exc)",alpha_factory_v1/core/utils/alerts.py,
survived,"def logistic_curve(t: float, k: float = 1.0, x0: float = 0.0) -> float:
    """"""Return a logistic curve value for ``t``.

    Args:
        t: Normalised time value.
        k: Growth rate controlling the steepness.
        x0: Midpoint shift.

    Returns:
        Value in the ``[0, 1]`` range.
    """"""

    return 1.0 / (1.0 + math.exp(-k * (t - x0)))
",alpha_factory_v1/core/simulation/forecast.py,
survived,"    def _record_restart(self, runner: AgentRunner) -> None:
        super()._record_restart(runner)
        alerts.send_alert(
            f""{runner.agent.name} restarted"",
            self.settings.alert_webhook_url,
        )
",alpha_factory_v1/core/orchestrator.py,Orchestrator
survived,"    def slash(self, agent_id: str) -> None:
        self.registry.burn(agent_id, 0.1)
",alpha_factory_v1/backend/demo_orchestrator.py,DemoOrchestrator
survived,"    async def evolve(
        self,
        scenario_hash: str,
        fn: Callable[[list[float]], tuple[float, ...]],
        genome_length: int,
        *,
        sector: str = ""generic"",
        approach: str = ""ga"",
        experiment_id: str = ""default"",
        **kwargs: object,
    ) -> object:
        pops = self.experiment_pops.setdefault(experiment_id, {})
        pop = await asyncio.to_thread(
            fn,
            [0.0] * genome_length,
            scenario_hash=scenario_hash,
            populations=pops,
            **kwargs,
        )
        pops[scenario_hash] = pop
        for ind in pop:
            self.solution_archive.add(sector, approach, ind.score, {""genome"": ind.genome})
            self.archive.insert_entry({""experiment_id"": experiment_id, ""genome"": ind.genome}, {""score"": ind.score})
        return pop
",alpha_factory_v1/backend/demo_orchestrator.py,DemoOrchestrator
survived,"    def _register(self, runner: AgentRunner) -> None:
        env = pb.Envelope(sender=""orch"", recipient=""system"", ts=time.time())
        env.payload.update({""event"": ""register"", ""agent"": runner.agent.name, ""capabilities"": runner.capabilities})
        self.ledger.log(env)
        self.bus.publish(""system"", env)
        self.registry.set_stake(runner.agent.name, 1.0)
        self.registry.set_threshold(f""promote:{runner.agent.name}"", self._promotion_threshold)
",alpha_factory_v1/backend/demo_orchestrator.py,DemoOrchestrator
survived,"    def add_agent(self, agent: object) -> None:
        runner = AgentRunner(agent)
        self.runners[agent.name] = runner
        self._register(runner)
",alpha_factory_v1/backend/demo_orchestrator.py,DemoOrchestrator
survived,"  def test_len(self):
    self.assertEqual(len(self.tip_car), 5)
",pylabrobot/resources/carrier_tests.py,CarrierTests
survived,"def test_no_violation_returns_one() -> None:
    _reset()
    res = {""request_id"": ""r1"", ""violation"": False}
    value = sc.reward(None, None, res)
    assert isinstance(value, float)
    assert value == 1.0
",tests/test_safety_compliance_reward.py,
survived,"    def __init__(self, settings: config.Settings) -> None:
        self.settings = settings
        self.published: list[tuple[str, messaging.Envelope]] = []
",tests/test_safety_guardian_property.py,DummyBus
survived,"def test_blocks_import_os(code: str) -> None:
    assume(""import os"" in code)
    bus = DummyBus(config.Settings(bus_port=0))
    led = DummyLedger()
    agent = safety_agent.SafetyGuardianAgent(bus, led)
    env = messaging.Envelope(""codegen"", ""safety"", {""code"": code}, 0.0)
    asyncio.run(agent.handle(env))
    assert bus.published[-1][1].payload[""status""] == ""blocked""
",tests/test_safety_guardian_property.py,
survived,"def main() -> int:
    proto = Path(""src/utils/a2a.proto"")
    out_dir = proto.parent
    cmd = [
        sys.executable,
        ""-m"",
        ""grpc_tools.protoc"",
        f""-I{out_dir}"",
        f""--python_out={out_dir}"",
        str(proto),
    ]
    if subprocess.run(cmd, check=False).returncode != 0:
        return 1

    dataclass = out_dir / ""a2a_pb2_dataclass.py""
    dataclass.write_text(
        """"""# SPDX-License-Identifier: Apache-2.0\n""""""
        ""\n""""\""Dataclass version of ``a2a.proto`` messages.\""\n""""""
        ""from __future__ import annotations\n""
        ""\n""
        ""from dataclasses import dataclass, field, asdict\n""
        ""from typing import Any, Dict\n""
        ""\n\n""
        ""@dataclass(slots=True)\n""
        ""class Envelope:\n""
        ""    \""\""\""Lightweight envelope for bus messages.\""\""\""\n""
        ""\n""
        ""    sender: str = \""\""\n""
        ""    recipient: str = \""\""\n""
        ""    payload: Dict[str, Any] = field(default_factory=dict)\n""
        ""    ts: float = 0.0\n""
        ""\n""
        ""    def to_dict(self) -> Dict[str, Any]:\n""
        ""        \""\""\""Return a dictionary representation.\""\""\""\n""
        ""        return asdict(self)\n""
    )
    return 0
",scripts/gen_proto.py,
survived,"def add(a: int, b: int) -> int:
    """"""Return the sum of a and b, intentionally broken.""""""
    return a - b",alpha_factory_v1/demos/self_healing_repo/sample_broken_calc/calc.py,
survived,"    def _apply(self, model: Any, smash_config: SmashConfigPrefixWrapper) -> Any:
        """"""Apply AWQ quantization using ``llmcompressor``.""""""
        imported = self.import_algorithm_packages()

        recipe = [
            imported[""AWQModifier""](
                ignore=[""lm_head""],
                scheme=smash_config[""scheme""],
                targets=[""Linear""],
            )
        ]

        dataloader = smash_config.val_dataloader()
        tokenizer = smash_config.tokenizer
        calib_data = recover_text_from_dataloader(dataloader, tokenizer)

        imported[""oneshot""](model=model, recipe=recipe, calib_data=calib_data)
        return model
",src/pruna/algorithms/quantization/llm_compressor.py,LLMCompressorQuantizer
survived,"    def get_hyperparameters(self) -> list:
        """"""Return the hyperparameters used for quantization.""""""
        return [Constant(""scheme"", value=""W4A16_ASYM"")]
",src/pruna/algorithms/quantization/llm_compressor.py,LLMCompressorQuantizer
survived,"def main() -> None:  # pragma: no cover - entry point
    """"""Launch the minimal dashboard or print results.""""""
    if st is None:
        print(""Streamlit not installed"")
        traj = _simulate(5, ""logistic"", 6, 3)
        for record in _disruption_df(traj).to_dict(orient=""records""):
            print(f""{record['sector']}: year {record['year']}"")
        return

    st.title(""Disruption Forecast"")
    horizon = st.sidebar.slider(""Horizon"", 1, 20, 5)
    curve = st.sidebar.selectbox(""Curve"", [""logistic"", ""linear"", ""exponential""], index=0)
    pop_size = st.sidebar.slider(""Population size"", 2, 20, 6)
    generations = st.sidebar.slider(""Generations"", 1, 20, 3)

    if st.sidebar.button(""Run""):
        traj = _simulate(horizon, curve, pop_size, generations)
        df = _timeline_df(traj)
        pivot = df.pivot(index=""year"", columns=""sector"", values=""energy"")
        st.line_chart(pivot)
        st.table(_disruption_df(traj))
",src/interface/minimal_ui.py,
survived,"def test_config_fields_present():
    for path in config_paths():
        cfg = load(path)
        assert 'contracts' in cfg and cfg['contracts'], f""{path} missing contracts""
        assert 'github_repo' in cfg
        assert REQUIRED_GITHUB_KEYS <= set(cfg['github_repo']), f""{path} github_repo keys""
        assert 'dependencies' in cfg
        assert 'explorer_hostname' in cfg or 'explorer_hostname_env_var' in cfg
",tests/test_configs.py,
survived,"def test_path_to_file_without_dependency():
    result = path_to_file_without_dependency('@oz/contracts/token.sol', '@oz/contracts')
    assert result == 'token.sol'
",tests/test_github_utils.py,
survived,"def test_format_str_call(state: State):
    s_in = """"""'{}'.format(str(var))""""""
    s_expected = """"""f'{var!s}'""""""

    s_out, count = code_editor.fstringify_code_by_line(s_in, state)
    assert s_out == s_expected
",test/test_edits.py,
survived,"    async def step(self) -> None:  # noqa: D401
        """"""Delegate step execution to :meth:`run_cycle`.""""""
        await self.run_cycle()
",alpha_factory_v1/backend/agents/retail_demand_agent.py,RetailDemandAgent
survived,"    def __init__(self, settings: Settings) -> None:
        self.settings = settings
        self._subs: Dict[str, List[Callable[[Envelope], Awaitable[None] | None]]] = {}
        self._server: ""grpc.aio.Server | None"" = None
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/messaging.py,A2ABus
survived,"    def __init__(self, bus, ledger) -> None:
        super().__init__(""research"", bus, ledger)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/research_agent.py,ResearchAgent
survived,"async def main(argv: list[str] | None = None) -> None:
    args = _build_parser().parse_args(argv)
    orch = orchestrator.Orchestrator()
    secs = [sector.Sector(""s%02d"" % i) for i in range(3)]
    sim = forecast.simulate_years(secs, args.horizon)
    for pt in sim:
        print(pt)
    await orch.run_forever()
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/cli.py,
survived,"def simulate_years(sectors: Iterable[Sector], horizon: int) -> List[ForecastPoint]:
    results: List[ForecastPoint] = []
    for year in range(1, horizon + 1):
        cap = logistic_curve(year / horizon * 10.0)
        affected = [s for s in sectors if thermodynamic_trigger(s, cap)]
        results.append(ForecastPoint(year, cap, affected))
    return results",alpha_factory_v1/demos/alpha_agi_insight_v1/src/simulation/forecast.py,
survived,"    async def run_cycle(self) -> None:
        pass
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/strategy_agent.py,StrategyAgent
survived,"    async def init(self) -> None:
        """"""Initialize all clients in the pool.""""""
        for client in self._clients:
            if not client.running:
                await client.init(
                    timeout=g_config.gemini.timeout,
                    auto_refresh=g_config.gemini.auto_refresh,
                    verbose=g_config.gemini.verbose,
                    refresh_interval=g_config.gemini.refresh_interval,
                )
",app/services/pool.py,GeminiClientPool
survived,"    def __init__(self, client_id: str, **kwargs):
        super().__init__(**kwargs)
        self.id = client_id
",app/services/client.py,GeminiClientWrapper
survived,"        def replacer(match: re.Match) -> str:
            outer_open_paren = match.group(1)
            display_text = match.group(2)

            new_target_url = simplify_link_target(display_text)
            new_link_segment = f""[`{display_text}`]({new_target_url})""

            if outer_open_paren:
                return f""{outer_open_paren}{new_link_segment})""
            else:
                return new_link_segment
",app/services/client.py,GeminiClientWrapper
survived,"def pytest_configure(config: pytest.Config) -> None:
    config.addinivalue_line(
        ""markers"",
        ""requires_torch: mark test that depends on the torch package"",
    )
",tests/conftest.py,
survived,"def get_window_title(token):
    '''
    Get window title that contain token
    '''
    window_list = Quartz.CGWindowListCopyWindowInfo(
        Quartz.kCGWindowListOptionOnScreenOnly | Quartz.kCGWindowListExcludeDesktopElements,
        Quartz.kCGNullWindowID
    )
    # Get all exist windows
    for window in window_list:
        title = window.get(Quartz.kCGWindowName, '')
        if token in title:
            return title
    return None
",src/input/GameWindowCapturorForMac.py,
survived,"    def switch_status(self, new_status):
        '''
        Switch to new status and log the transition.

        Parameters:
        - new_status: string, the new status to switch to.
        '''
        # Ignore dummy transition
        if self.status == new_status:
            return

        t_elapsed = round(time.time() - self.t_last_switch_status)
        logger.info(f""[switch_status] From {self.status}({t_elapsed} sec) to {new_status}."")
        self.status = new_status
        self.t_last_switch_status = time.time()
",src/legacy/mapleStoryAutoLevelUp_legacy.py,MapleStoryBot
survived,"    def get_nearest_color_code(self):
        '''
        get_nearest_color_code
        '''
        x0, y0 = self.loc_player_global
        h, w = self.img_route.shape[:2]
        x_min = max(0, x0 - self.cfg.color_code_search_range)
        x_max = min(w, x0 + self.cfg.color_code_search_range)
        y_min = max(0, y0 - self.cfg.color_code_search_range)
        y_max = min(h, y0 + self.cfg.color_code_search_range)

        nearest = None
        min_dist = float('inf')
        for y in range(y_min, y_max):
            for x in range(x_min, x_max):
                pixel = tuple(self.img_route[y, x])  # (R, G, B)
                if pixel in self.cfg.color_code:
                    dist = abs(x - x0) + abs(y - y0)
                    if dist < min_dist:
                        min_dist = dist
                        nearest = {
                            ""pixel"": (x, y),
                            ""color"": pixel,
                            ""action"": self.cfg.color_code[pixel],
                            ""distance"": dist
                        }

        # Debug
        draw_rectangle(
            self.img_route_debug,
            (x_min, y_min),
            (self.cfg.color_code_search_range*2, self.cfg.color_code_search_range*2),
            (0, 0, 255), ""Color Search Range""
        )
        # Draw a straigt line from map_loc_player to color_code[""pixel""]
        if nearest is not None:
            cv2.line(
                self.img_route_debug,
                self.loc_player_global, # start point
                nearest[""pixel""],       # end point
                (0, 255, 0),            # green line
                1                       # thickness
            )

            # Print color code on debug image
            cv2.putText(
                self.img_frame_debug,
                f""Route Action: {nearest['action']}"",
                (720, 90),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255),
                2, cv2.LINE_AA
            )
            cv2.putText(
                self.img_frame_debug, f""Route Index: {self.idx_routes}"",
                (720, 120),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255),
                2, cv2.LINE_AA
            )

        return nearest  # if not found return none
",src/legacy/mapleStoryAutoLevelUp_legacy.py,MapleStoryBot
survived,"        def run_generations(self, *_a) -> None:
            pass
",tests/test_aiga_openai_bridge_offline.py,DummyEvolver
survived,"        def __init__(self, *a, **k) -> None:
            last_runtime[""inst""] = self
            self.registered: list[object] = []
",tests/test_aiga_openai_bridge_offline.py,AgentRuntime
survived,"def _free_port() -> int:
    """"""Return an available localhost port.""""""
    with socket.socket() as s:
        s.bind((""127.0.0.1"", 0))
        return int(s.getsockname()[1])
",tests/test_aiga_openai_bridge_offline.py,
survived,"    def _worker() -> None:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        task = loop.create_task(coro)
        try:
            result.append(loop.run_until_complete(task))
        finally:
            loop.close()
",alpha_factory_v1/backend/utils/sync.py,
survived,"    def __init__(self):
        Assimilator.__init__(self)
",sched/testasm.py,TestAssimilator
survived,"        def generate(self, **kwargs: object) -> list[list[int]]:
            return [[0]]
",tests/test_gpt2_cli_demo.py,FakeModel
survived,"def _view_lines_tool(ctx: RunContextWrapper | dict, path: str, start: int, end: Optional[int]) -> str:
    return view_lines(path, start, end)
",src/self_edit/tools.py,
survived,"    def add_tarball(self, tarball: str | Path) -> str:
        path = Path(tarball)
        cid = self._ipfs_add(path)
        with sqlite3.connect(self.db_path) as cx:
            cx.execute(
                ""INSERT INTO tarballs(path, cid, pinned, ts) VALUES(?,?,?,?)"",
                (str(path), cid, 1, time.time()),
            )
        return cid
",src/archive/hash_archive.py,HashArchive
survived,"    def merkle_root(self, date: str | None = None) -> str:
        with sqlite3.connect(self.db_path) as cx:
            if date:
                rows = [r[0] for r in cx.execute(""SELECT cid FROM tarballs WHERE DATE(ts,'unixepoch')=? ORDER BY cid"", (date,))]
            else:
                rows = [r[0] for r in cx.execute(""SELECT cid FROM tarballs ORDER BY cid"")]
        return self._compute_root(rows)
",src/archive/hash_archive.py,HashArchive
survived,"    def __init__(self, db_path: str | Path) -> None:
        self.db_path = Path(db_path)
        _ensure_db(self.db_path)
",src/archive/hash_archive.py,HashArchive
survived,"def test_snark_roundtrip(tmp_path: Path) -> None:
    transcript = tmp_path / ""eval.json""
    entry = {""hash"": ""a1b2"", ""score"": [0.5, 1.2]}
    transcript.write_text(json.dumps([entry]), encoding=""utf-8"")

    db = ArchiveDB(tmp_path / ""arch.db"")
    db.add(ArchiveEntry(""a1b2"", None, 0.5, 0.0, True, 1.0))

    cid = publish_proof(transcript, entry[""hash""], entry[""score""], db)
    assert db.get_proof_cid(entry[""hash""]) == cid

    proof = transcript.with_suffix("".proof"").read_text()
    assert verify_proof(transcript, entry[""hash""], entry[""score""], proof)

    expected_cid = hashlib.sha256(proof.encode()).hexdigest()
    assert cid == expected_cid",tests/test_snark.py,
survived,"    async def ask_llm(
        self,
        messages: str | list[str | SamplingMessage],
        *,
        system_prompt: str | None = None,
        max_tokens: int = 1000,
        temperature: float | None = None,
        model_preferences: ModelPreferences | None = None,
        allow_tools: Literal[""none"", ""thisServer"", ""allServers""] | None = ""none"",
        stop_sequences: list[str] | None = None,
    ) -> CreateMessageResult:
        """"""Request LLM sampling via the connected client.""""""

        sampling_messages = self._convert_messages(messages)
        session = self._request_context.session  # type: ignore[attr-defined]
        return await session.create_message(
            messages=sampling_messages,
            system_prompt=system_prompt,
            max_tokens=max_tokens,
            temperature=temperature,
            model_preferences=model_preferences,
            include_context=allow_tools,
            stop_sequences=stop_sequences,
        )
",src/enrichmcp/context.py,EnrichContext
survived,"        def predict(self, x: int) -> int:
            return x
",tests/trace/test_objs_query.py,MyModel
survived,"def test_adk_client_import(monkeypatch):
    dummy = types.ModuleType(""google_adk"")
    class Client:
        pass
    dummy.Client = Client
    monkeypatch.setitem(sys.modules, ""google_adk"", dummy)
    if MODULE in sys.modules:
        del sys.modules[MODULE]
    mod = importlib.import_module(MODULE)
    assert mod.ADKClient is Client
",tests/test_alpha_agi_business_3_v1.py,
survived,"def test_execute_and_collect_success(monkeypatch, tmp_path):
    fake_exec = MagicMock()
    fake_exec.run_tests.return_value = ExecutionResult(0, ""out"", ""err"")
    module = ResultCollectionModule(fake_exec)
    result = module.execute_and_collect(tmp_path, timeout=5)
    assert isinstance(result, CollectionResult)
    assert result.exit_code == 0
    assert result.stdout == ""out""
    assert result.stderr == ""err""
    assert result.duration >= 0
    fake_exec.run_tests.assert_called_with(tmp_path, timeout=5)
",tests/unit/test_result_collection_module.py,
survived,"def test_summarize_creates_report():
    module = ReportingModule()
    result = make_result()
    report = module.summarize(result)
    assert isinstance(report, SummaryReport)
    assert report.exit_code == 0
    assert report.passed is True
    assert report.duration == 1.23
    assert report.stdout == ""out""
    assert report.stderr == ""err""
",tests/unit/test_reporting_module.py,
survived,"def test_generate_html_report():
    module = ReportingModule()
    result = make_result()
    html_report = module.generate_report(result, output_format=""html"")
    assert html_report.startswith(""<html>"")
    assert ""PASSED"" in html_report
",tests/unit/test_reporting_module.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/enumerations-3.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/elliptic-curve-digital-signature-algorithm.py,
survived,"def pow2(n):
    p = 1
    i = 0
    while i < n:
        p = p * 2
        i = i + 1
    return p
",tests/rosetta/transpiler/Python/elementary-cellular-automaton-infinite-length.py,
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    dividend = 580
    divisor = 34
    res = egyptianDivide(dividend, divisor)
    print(str(dividend) + "" divided by "" + str(divisor) + "" is "" + str(res.q) + "" with remainder "" + str(res.r))
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/egyptian-division.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/elliptic-curve-arithmetic.py,
survived,"def isPrime(n):
    if n < 2:
        return False
    if n % 2 == 0:
        return n == 2
    d = 3
    while d * d <= n:
        if n % d == 0:
            return False
        d = d + 2
    return True
",tests/rosetta/transpiler/Python/emirp-primes.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/enumerations-1.py,
survived,"def show(s, p):
    if isZero(p):
        print(s + ""Zero"")
    else:
        print(s + ""("" + str(p.x) + "", "" + str(p.y) + "")"")
",tests/rosetta/transpiler/Python/elliptic-curve-arithmetic.py,
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    print(""Source file entropy: "" + str(entropy(source)))
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/entropy-narcissist.py,
survived,"def isZero(p):
    return p.inf
",tests/rosetta/transpiler/Python/elliptic-curve-arithmetic.py,
survived,"def log2(x):
    k = 0.0
    v = x
    while v >= 2.0:
        v = v / 2.0
        k = k + 1.0
    while v < 1.0:
        v = v * 2.0
        k = k - 1.0
    z = (v - 1.0) / (v + 1.0)
    zpow = z
    sum = z
    i = 3
    while i <= 9:
        zpow = zpow * z * z
        sum = sum + zpow / (float(i))
        i = i + 2
    ln2 = 0.6931471805599453
    return k + 2.0 * sum / ln2
",tests/rosetta/transpiler/Python/entropy-1.py,
survived,"def main(argv: Optional[list[str]] = None) -> None:
    print_disclaimer()
    args = _parse_args(argv)

    if args.allow_local_code:
        os.environ[""ALPHA_FACTORY_ALLOW_LOCAL_CODE""] = ""1""

    agent = build_core_agent(
        name=""Repoâ€‘Doctor"",
        instructions=(
            ""You are Repoâ€‘Doctor, an elite senior software engineer. ""
            ""Your goal: make *all* pytest tests pass. ""
            ""Workflow: 1) run_pytest 2) if failures â†’ open the failing file, ""
            ""edit code, save, 3) rerun tests. Repeat until exit statusÂ 0. ""
            ""Finally stage & commit the patch (or simulate if git is missing).""
        ),
    )

    task_prompt = (
        f""Our CI is red.  The repository is located at {args.repo}. ""
        ""Bring the suite back to green, produce a concise diff summary, and ""
        ""commit to branch *autoâ€‘fix*.""
    )

    if not SDK_AVAILABLE:
        # Fully offline / stub mode
        print(""[warning] OpenAI AgentsÂ SDK not available â€‘ running stub agent\n"")
        print(agent.run(task_prompt))
        sys.exit(0)

    # â”€â”€ Live run via AgentsÂ SDK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    result = Runner.run_sync(
        agent,
        task_prompt,
        max_turns=args.max_turns,
    )

    # Print reasoning trace for visibility
    transcript_path = Path.cwd() / ""self_healing_transcript.md""
    transcript_path.write_text(result.transcript_markdown)
    print(f""\nðŸ“„  Full agent transcript saved to {transcript_path}\n"")

    # Commit when tests are green
    if ""ðŸŽ‰"" in result.final_output or ""all tests passed"" in result.final_output.lower():
        commit_msg = _commit_patch(args.repo)
        print(commit_msg)
    else:
        print(""Agent did not report success â€“ manual review recommended."")

    # Final console output
    print(""\nâ•â•â• FINAL AGENT OUTPUT â•â•â•\n"")
    print(result.final_output)
    print(""\nDone."")
",alpha_factory_v1/demos/self_healing_repo_cli.py,
survived,"def uvicorn_server() -> Iterator[str]:
    from src.interface import api_server

    port = _free_port()
    config = uvicorn.Config(api_server.app, host=""127.0.0.1"", port=port, log_level=""warning"")
    server = uvicorn.Server(config)
    thread = threading.Thread(target=server.run, daemon=True)
    thread.start()
    for _ in range(50):
        if server.started:
            break
        time.sleep(0.1)
    yield f""http://127.0.0.1:{port}""
    server.should_exit = True
    thread.join(timeout=5)
",tests/test_api_server_uvicorn.py,
survived,"def test_simulation_endpoints() -> None:
    port = _free_port()
    env = os.environ.copy()
    env[""PYTHONPATH""] = str(REPO_ROOT)
    cmd = [
        sys.executable,
        ""-m"",
        ""alpha_factory_v1.demos.alpha_agi_insight_v1.src.interface.api_server"",
        ""--host"",
        ""127.0.0.1"",
        ""--port"",
        str(port),
    ]
    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, env=env)
    url = f""http://127.0.0.1:{port}""
    headers = {""Authorization"": ""Bearer test-token""}
    try:
        for _ in range(50):
            try:
                r = httpx.get(url + ""/runs"", headers=headers)
                if r.status_code == 200:
                    break
            except Exception:
                pass
            time.sleep(0.1)
        else:
            raise AssertionError(""server failed to start"")

        progress: list[str] = []

        def _listen() -> None:
            ws_url = f""ws://127.0.0.1:{port}/ws/progress""
            with websockets.connect(ws_url, additional_headers=headers) as ws:
                try:
                    while True:
                        msg = ws.recv()
                        progress.append(msg)
                        if progress:
                            break
                except Exception:
                    pass

        th = threading.Thread(target=_listen, daemon=True)
        th.start()

        r = httpx.post(
            url + ""/simulate"",
            json={""horizon"": 1, ""pop_size"": 2, ""generations"": 1},
            headers=headers,
        )
        assert r.status_code == 200
        sim_id = r.json()[""id""]

        for _ in range(100):
            r = httpx.get(f""{url}/results/{sim_id}"", headers=headers)
            if r.status_code == 200:
                data = r.json()
                break
            time.sleep(0.05)
        else:
            raise AssertionError(""Timed out waiting for results"")

        th.join(timeout=5)
        assert progress
        assert ""forecast"" in data
        r_runs = httpx.get(url + ""/runs"", headers=headers)
        assert r_runs.status_code == 200
        assert sim_id in r_runs.json().get(""ids"", [])
    finally:
        proc.terminate()
        try:
            proc.wait(timeout=5)
        except subprocess.TimeoutExpired:
            proc.kill()",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_api_server_subprocess.py,
survived,"    def test_outer_iterations_minimum(self):
        class DummyWallet:
            def passwords_per_seconds(self, seconds):
                return 0
            def return_verified_password_or_false(self, pw_list):
                pass
        wallet = DummyWallet()
        CHUNKSIZE_SECONDS = 1.0 / 100.0
        measure_performance_iterations = wallet.passwords_per_seconds(0.5)
        inner_iterations = int(round(2 * measure_performance_iterations * CHUNKSIZE_SECONDS)) or 1
        outer_iterations = max(1, int(round(measure_performance_iterations / inner_iterations)))
        self.assertEqual(outer_iterations, 1)
",btcrecover/test/test_passwords.py,TestOuterIterations
survived,"    def test_reset_batch_invalid_size(self):
        env = ce.CurriculumEnv(genome=ce.EnvGenome(max_steps=10), size=6)
        with self.assertRaises(ValueError):
            env.reset_batch(0)
",alpha_factory_v1/tests/test_aiga_meta_evolution.py,CurriculumEnvTest
survived,"def test_foresight_evaluate_nonzero_metrics() -> None:
    repo = Path(__file__).resolve().parents[1]
    scores = foresight_evaluate(repo)
    assert scores[""rmse""] > 0
    assert scores[""lead_time""] != 0",tests/test_demo_cli.py,
survived,"    def __init__(self) -> None:
        if MetaEvolver and CurriculumEnv:
            self.evolver = MetaEvolver(env_cls=CurriculumEnv, parallel=False)
        else:  # pragma: no cover - offline stub
            self.evolver = None
            logger.warning(""MetaEvolver unavailable â€“ AIGAEvolverAgent disabled"")
",alpha_factory_v1/backend/agents/aiga_evolver_agent.py,AIGAEvolverAgent
survived,"            def __init__(self, url: str) -> None:
                captured[""url""] = url
",tests/test_ledger_broadcast.py,DummyClient
survived,"    def visit_FunctionDef(self, node):
        args = "","".join(a.arg for a in node.args.args)
        self.emit(f""fun {node.name}({args}): any {{"")
        self.indent += 1
        for s in node.body:
            self.visit(s)
        self.indent -= 1
        self.emit(""}"")
",tools/any2mochi/py_simple.py,Conv
survived,"    def emit(self, line):
        self.lines.append(""  "" * self.indent + line)
",tools/any2mochi/py_simple.py,Conv
survived,"    def as_proxy(
        cls,
        backend: Client
        | ClientTransport
        | FastMCP[Any]
        | AnyUrl
        | Path
        | dict[str, Any]
        | str,
        **settings: Any,
    ) -> FastMCPProxy:
        """"""Create a FastMCP proxy server for the given backend.

        The ``backend`` argument can be either an existing :class:`~fastmcp.client.Client`
        instance or any value accepted as the ``transport`` argument of
        :class:`~fastmcp.client.Client`. This mirrors the convenience of the
        ``Client`` constructor.
        """"""
        from fastmcp.server.proxy import FastMCPProxy

        if isinstance(backend, Client):
            client = backend
        else:
            client = Client(backend)

        return FastMCPProxy(client=client, **settings)
",src/fastmcp/server/server.py,FastMCP
survived,"    def update(
        self,
        func: Callable[..., Any] | None = None,
        *,
        name: str | None = None,
        description: str | None = None,
    ) -> Callable[..., Any] | DecoratorCallable:
        """"""Register an update operation.""""""

        def decorator(fn: Callable[..., Any]) -> Callable[..., Any]:
            return self.resource(fn, name=name, description=description)

        if func is not None:
            return decorator(func)
        return cast(""DecoratorCallable"", decorator)
",src/enrichmcp/app.py,EnrichMCP
survived,"def main() -> None:
    app.run()
",examples/mutable_crud/app.py,
survived,"async def test_patch_model_generation_and_mutable_fields():
    app = EnrichMCP(""Test API"", description=""desc"")

    @app.entity
    class Customer(EnrichModel):
        """"""Customer entity.""""""

        id: int = Field(description=""id"")
        email: str = Field(description=""email"", mutable=True)
        status: str = Field(description=""status"", mutable=True)

    # mutable fields detected
    assert Customer.mutable_fields() == {""email"", ""status""}
    assert hasattr(Customer, ""PatchModel"")
    patch_fields = set(Customer.PatchModel.model_fields.keys())
    assert patch_fields == {""email"", ""status""}
",tests/test_mutability.py,
survived,"        def decorator(f: T) -> T:
            return f
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/codegen_agent.py,
survived,"    def list(self, project: str, page: int, page_size: int) -> list[MemoryNoteSummary]:
        p = self._project_dir(project)
        files = sorted(p.glob(""*.md""))
        start = (page - 1) * page_size
        end = start + page_size
        notes: list[MemoryNoteSummary] = []
        for file in files[start:end]:
            note = self.load(project, file.stem)
            if note:
                notes.append(MemoryNoteSummary(id=note.id, title=note.title))
        return notes
",examples/basic_memory/memory.py,FileMemoryStore
survived,"    def list_notes(self, page: int = 1, page_size: int = 10) -> list[MemoryNoteSummary]:
        return self.store.list(self.name, page, page_size)
",examples/basic_memory/memory.py,MemoryProject
survived,"        def _fake_import(name: str, *args: Any, **kwargs: Any) -> object:
            if name == module_name:
                return fake_mod
            return orig_import_module(name, *args, **kwargs)
",tests/test_check_env_openai_agents_version.py,TestCheckEnvOpenAIAgentsVersion
survived,"        def load_censor_words(self) -> None:
            pass
",alpha_factory_v1/backend/governance.py,_StubProfanity
survived,"        def contains_profanity(self, _text: str) -> bool:
            return False
",alpha_factory_v1/backend/governance.py,_StubProfanity
survived,"    def fake_resolve(pkgs):
        return [], {""badpkg"": ""GPL""}, None
",tests/test_template_validator.py,
survived,"def test_flynt_skip(state: State):
    s_in = """"""a = 'my string {}, but also {} and {}'.format(var, f, cada_bra)  # flynt: skip""""""
    s_expected = """"""a = 'my string {}, but also {} and {}'.format(var, f, cada_bra)  # flynt: skip""""""

    s_out, count = code_editor.fstringify_code_by_line(s_in, state)
    assert s_out == s_expected
",test/test_edits.py,
survived,"def main() -> None:
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument(""--docs"", default=""docs"", help=""Documentation directory"")
    args = parser.parse_args()
    docs_dir = Path(args.docs)
    assets = gather_assets(docs_dir)
    sw_path = docs_dir / ""assets"" / ""service-worker.js""
    lines = [HEADER]
    for asset in assets:
        lines.append(f""          '{asset}',"")
    lines.append(FOOTER)
    sw_path.write_text(""\n"".join(lines))
    print(f""Wrote {sw_path}"")
",scripts/build_service_worker.py,
survived,"def load_json(path):
    return json.load(open(path)) if os.path.exists(path) else []
",convert_missing.py,
survived,"def test_healthz() -> None:
    resp = client.get(""/healthz"")
    assert resp.status_code == 200
    assert resp.text == ""ok""
",tests/test_insight_health.py,
survived,"    def __init__(self) -> None:
        self.logged: list[messaging.Envelope] = []
",tests/test_agent_handle_methods.py,DummyLedger
survived,"    def subscribe(self, topic: str, handler):
        pass
",tests/test_agent_handle_methods.py,DummyBus
survived,"def test_market_agent_emits_codegen() -> None:
    cfg = config.Settings(bus_port=0)
    bus = DummyBus(cfg)
    led = DummyLedger()
    agent = market_agent.MarketAgent(bus, led)
    env = messaging.Envelope(""strategy"", ""market"", {""strategy"": ""foo""}, 0.0)
    asyncio.run(agent.handle(env))
    assert bus.published[-1][0] == ""codegen""
",tests/test_agent_handle_methods.py,
survived,"        def from_model_data(cls, id: str, model: FinalModelData):
            return cls(
                id=id,
                created=int(datetime.datetime.combine(model.release_date, datetime.time(0, 0)).timestamp()),
                owned_by=model.provider_name,
                display_name=model.display_name,
                icon_url=model.icon_url,
                supports={
                    k.removeprefix(""supports_""): v
                    for k, v in model.model_dump(
                        mode=""json"",
                        include=set(ModelDataSupports.model_fields.keys()),
                    ).items()
                },
            )
",api/api/main.py,StandardModelResponse.ModelItem
survived,"def test_bus_tls_accept(tmp_path: Path) -> None:
    """"""Envelope with valid token is accepted over TLS.""""""
    port = _free_port()
    cert, key, ca = _make_cert(tmp_path)
    cfg = config.Settings(bus_port=port, bus_cert=cert, bus_key=key, bus_token=""tok"")
    bus = messaging.A2ABus(cfg)
    received: list[messaging.Envelope] = []

    async def run() -> None:
        bus.subscribe(""b"", lambda e: received.append(e))
        await bus.start()
        try:
            creds = grpc.ssl_channel_credentials(root_certificates=ca)
            async with grpc.aio.secure_channel(f""localhost:{port}"", creds) as ch:
                stub = ch.unary_unary(""/bus.Bus/Send"")
                payload = {
                    ""sender"": ""a"",
                    ""recipient"": ""b"",
                    ""payload"": {""v"": 1},
                    ""ts"": 0.0,
                    ""token"": ""tok"",
                }
                await stub(json.dumps(payload).encode())
            await asyncio.sleep(0.05)
        finally:
            await bus.stop()

    asyncio.run(run())
    assert received and received[0].payload[""v""] == 1
",tests/test_bus_tls.py,
survived,"    def test_cli_help(self) -> None:
        result = subprocess.run(
            [sys.executable, '-m', 'alpha_factory_v1.demos.alpha_agi_insight_v1', '--help'],
            capture_output=True,
            text=True,
        )
        self.assertEqual(result.returncode, 0, result.stderr)
        self.assertIn('Insight command line interface', result.stdout)
",tests/test_alpha_agi_insight_v1_main.py,TestAlphaAgiInsightMainV1
survived,"def test_capability_growth_dispatch() -> None:
    """"""Capability growth should dispatch to the appropriate curve.""""""
    t = 0.3
    assert forecast.capability_growth(t, curve=""linear"") == pytest.approx(forecast.linear_curve(t))
    assert forecast.capability_growth(t, curve=""exponential"") == pytest.approx(forecast.exponential_curve(t))
    assert forecast.capability_growth(t, curve=""logistic"") == pytest.approx(forecast.logistic_curve(10 * t))
    assert forecast.capability_growth(t) == pytest.approx(forecast.logistic_curve(10 * t))",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_capability_growth.py,
survived,"    def analyze_memory_growth(self, interval_seconds: int = 300) -> Dict[str, float]:
        """"""
        åˆ†æžå†…å­˜å¢žé•¿è¶‹åŠ¿
        :param interval_seconds: åˆ†æžé—´éš”ï¼ˆç§’ï¼‰
        :return: å†…å­˜å¢žé•¿ä¿¡æ¯
        """"""
        try:
            # èŽ·å–å½“å‰å†…å­˜ä½¿ç”¨
            current_summary = self.get_memory_summary()
            
            # ç­‰å¾…æŒ‡å®šæ—¶é—´
            time.sleep(interval_seconds)
            
            # èŽ·å–æ–°çš„å†…å­˜ä½¿ç”¨
            new_summary = self.get_memory_summary()
            
            if current_summary and new_summary:
                growth_info = {
                    'total_growth_mb': new_summary['total_memory_mb'] - current_summary['total_memory_mb'],
                    'python_growth_mb': new_summary['python_objects_mb'] - current_summary['python_objects_mb'],
                    'unaccounted_growth_mb': new_summary['unaccounted_mb'] - current_summary['unaccounted_mb'],
                    'growth_rate_mb_per_hour': (new_summary['total_memory_mb'] - current_summary['total_memory_mb']) * 3600 / interval_seconds
                }
                
                logger.info(f""å†…å­˜å¢žé•¿åˆ†æž: æ€»å¢žé•¿ {growth_info['total_growth_mb']:.2f} MB, ""
                           f""Pythonå¯¹è±¡å¢žé•¿ {growth_info['python_growth_mb']:.2f} MB, ""
                           f""æœªç»Ÿè®¡å¢žé•¿ {growth_info['unaccounted_growth_mb']:.2f} MB"")
                
                return growth_info
            
            return {}
            
        except Exception as e:
            logger.error(f""åˆ†æžå†…å­˜å¢žé•¿å¤±è´¥: {e}"")
            return {}
",app/helper/memory.py,MemoryHelper
survived,"def special_case(import_id: str, logger: Logger) -> str | None:
    homepage: str | None = None

    # if no slashes, then pkgx used the homepage as the name
    # if two slashes, then probably github / gitlab
    if not re.search(r""/"", import_id) or re.search(r""/.+/"", import_id):
        homepage = import_id

    # if it's a crates.io package, then we can use the crates URL
    elif re.search(r""^crates.io"", import_id):
        if ""/"" in import_id:
            name = import_id.split(""/"")[1]
            homepage = f""https://crates.io/crates/{name}""
        else:
            logger.warn(f""Invalid format for crates.io import_id: {import_id}"")

    # if it's part of the x.org family
    elif re.search(r""^x.org"", import_id):
        homepage = ""https://x.org""

    # if it's part of the pkgx family
    elif re.search(""^pkgx.sh"", import_id):
        tool = import_id.split(""/"")[1]
        homepage = f""https://github.com/pkgxdev/{tool}""

    # python.org/typing_extensions
    elif re.search(""^python.org/typing_extensions"", import_id):
        homepage = ""https://github.com/python/typing_extensions""

    # thrysoee.dk/editline
    elif re.search(""^thrysoee.dk/editline"", import_id):
        homepage = ""https://thrysoee.dk/editline""

    else:
        logger.warn(f""no homepage in pkgx for {import_id}"")

    return homepage
",package_managers/pkgx/url.py,
survived,"    def test_completely_new_package(self, mock_config, mock_logger):
        """"""Test scenario 4: Package was completely new to the database""""""

        # Create empty cache (no existing packages)
        cache = Cache(package_map={}, url_map={}, package_urls={}, dependencies={})

        # Create new package data
        new_pkg_data = create_pkgx_package(
            distributables=[""https://github.com/example/new-pkg/archive/v1.0.tar.gz""],
            dependencies=[""some-dep""],
            build_deps=[""build-tool""],
        )

        # Test the diff
        diff = PkgxDiff(mock_config, cache, mock_logger)
        pkg_id, pkg_obj, update_payload = diff.diff_pkg(""new-pkg"", new_pkg_data)

        # Assertions
        assert pkg_obj is not None  # New package should be created
        assert pkg_obj.derived_id == ""pkgx/new-pkg""
        assert pkg_obj.name == ""new-pkg""
        assert pkg_obj.import_id == ""new-pkg""
        assert pkg_obj.package_manager_id == mock_config.pm_config.pm_id
        assert update_payload == {}  # No updates for new package

        # Test URL creation
        new_urls = {}
        with (
            patch.object(diff, ""_canonicalize_url"", side_effect=lambda x: x),
            patch.object(
                diff,
                ""_get_homepage_url"",
                return_value=""https://github.com/example/new-pkg"",
            ),
            patch.object(diff, ""_is_github_url"", return_value=True),
        ):
            resolved_urls = diff.diff_url(""new-pkg"", new_pkg_data, new_urls)
            new_links, updated_links = diff.diff_pkg_url(pkg_id, resolved_urls)

        # Should create URLs for homepage, source, and repository (GitHub)
        assert len(new_urls) >= 2  # At least source and homepage
        assert len(new_links) >= 2  # At least source and homepage links
        assert len(updated_links) == 0  # No existing links to update
",tests/package_managers/pkgx/test_pkgx_diff.py,TestPkgxDifferentialLoading
survived,"    def set_current_urls(self) -> None:
        """"""Getting all the URLs and Package URLs from the database""""""
        self.urls: CurrentURLs | None = None
        url_map: dict[URLKey, URL] = {}
        package_urls: dict[UUID, set[PackageURL]] = {}

        stmt = (
            select(Package, PackageURL, URL)
            .select_from(URL)
            .join(PackageURL, PackageURL.url_id == URL.id, isouter=True)
            .join(Package, Package.id == PackageURL.package_id, isouter=True)
        )
        with self.session() as session:
            result: Result[tuple[Package, PackageURL, URL]] = session.execute(stmt)

            for pkg, pkg_url, url in result:
                url_key = URLKey(url.url, url.url_type_id)
                url_map[url_key] = url

                # since it's a left join, we need to check if pkg is None
                if pkg is not None:
                    if pkg.id not in package_urls:
                        package_urls[pkg.id] = set()
                    package_urls[pkg.id].add(pkg_url)

        self.urls = CurrentURLs(url_map=url_map, package_urls=package_urls)
",package_managers/pkgx/db.py,PkgxDB
survived,"    def test_package_exists_url_update(self, mock_config, mock_logger):
        """"""Test scenario 2: Package existed in database and needed a URL update""""""

        # Setup existing package and URL
        existing_pkg_id = uuid4()
        existing_url_id = uuid4()
        existing_package_url_id = uuid4()

        existing_package = Package(
            id=existing_pkg_id,
            derived_id=""pkgx/url-pkg"",
            name=""url-pkg"",
            package_manager_id=mock_config.pm_config.pm_id,
            import_id=""url-pkg"",
            readme=""Test package"",
        )

        existing_url = URL(
            id=existing_url_id,
            url=""https://old-source.com/file.tar.gz"",
            url_type_id=mock_config.url_types.source,
        )

        existing_package_url = PackageURL(
            id=existing_package_url_id,
            package_id=existing_pkg_id,
            url_id=existing_url_id,
        )

        # Create cache
        cache = Cache(
            package_map={""url-pkg"": existing_package},
            url_map={
                URLKey(
                    ""https://old-source.com/file.tar.gz"", mock_config.url_types.source
                ): existing_url
            },
            package_urls={existing_pkg_id: {existing_package_url}},
            dependencies={},
        )

        # Create package data with new URL
        new_pkg_data = create_pkgx_package(
            distributables=[""https://new-source.com/file.tar.gz""],
        )

        # Test the diff
        diff = PkgxDiff(mock_config, cache, mock_logger)
        new_urls = {}

        # Mock the URL canonicalization and homepage methods
        with (
            patch.object(diff, ""_canonicalize_url"", side_effect=lambda x: x),
            patch.object(diff, ""_get_homepage_url"", return_value=None),
            patch.object(diff, ""_is_github_url"", return_value=False),
        ):
            resolved_urls = diff.diff_url(""url-pkg"", new_pkg_data, new_urls)
            new_links, updated_links = diff.diff_pkg_url(existing_pkg_id, resolved_urls)

        # Assertions
        assert len(new_urls) == 1  # New URL should be created
        new_url = next(iter(new_urls.values()))
        assert new_url.url == ""https://new-source.com/file.tar.gz""
        assert new_url.url_type_id == mock_config.url_types.source

        assert len(new_links) == 1  # New package URL link should be created
        assert new_links[0].package_id == existing_pkg_id
        assert new_links[0].url_id == new_url.id
",tests/package_managers/pkgx/test_pkgx_diff.py,TestPkgxDifferentialLoading
survived,"    def diff_url(
        self, import_id: str, pkg: PkgxPackage, new_urls: dict[tuple[str, UUID], URL]
    ) -> dict[UUID, UUID]:
        """"""Given a package's URLs, returns the resolved URL for this specific package""""""
        resolved_urls: dict[UUID, UUID] = {}

        # Collect all URLs from the package
        urls_to_process = []

        # Add homepage URL if it exists
        homepage = self._get_homepage_url(import_id, pkg)
        if homepage:
            urls_to_process.append((homepage, self.config.url_types.homepage))

        # Add source URLs from distributables
        for distributable in pkg.distributable:
            if distributable.url:
                clean_url = self._canonicalize_url(distributable.url)
                if clean_url:
                    urls_to_process.append((clean_url, self.config.url_types.source))

                    # If it's a GitHub URL, also add as repository
                    if self._is_github_url(clean_url):
                        urls_to_process.append(
                            (clean_url, self.config.url_types.repository)
                        )

        # Process each URL
        for url, url_type in urls_to_process:
            url_key = URLKey(url, url_type)
            resolved_url_id: UUID

            if url_key in new_urls:
                resolved_url_id = new_urls[url_key].id
            elif url_key in self.caches.url_map:
                resolved_url_id = self.caches.url_map[url_key].id
            else:
                self.logger.debug(f""URL {url} for {url_type} is entirely new"")
                new_url = URL(
                    id=uuid4(),
                    url=url,
                    url_type_id=url_type,
                    created_at=self.now,
                    updated_at=self.now,
                )
                resolved_url_id = new_url.id
                new_urls[url_key] = new_url

            resolved_urls[url_type] = resolved_url_id

        return resolved_urls
",package_managers/pkgx/diff.py,PkgxDiff
survived,"    def test_sort_by_release_date_asc(self):
        """"""Test sorting by release date (oldest first).""""""
        models: list[ConciseModelResponse | ConciseLatestModelResponse] = [
            create_test_model(""model1"", release_date=""2024-01-01""),
            create_test_model(""model2"", release_date=""2024-03-01""),
            create_test_model(""model3"", release_date=""2024-02-01""),
        ]

        sorted_models = sort_models(models, ""release_date"", ""asc"")

        assert [m.id for m in sorted_models] == [""model1"", ""model3"", ""model2""]
",api/api/routers/mcp/_utils/model_sorting_test.py,TestSortModels
survived,"    def test_sort_by_run_count_asc(self):
        """"""Test sorting by run count ascending (lowest first).""""""
        agents = [
            create_test_agent(""agent1"", run_count=5),
            create_test_agent(""agent2"", run_count=100),
            create_test_agent(""agent3"", run_count=50),
            create_test_agent(""agent4"", run_count=100),  # Same count as agent2
        ]

        sorted_agents = sort_agents(agents, ""run_count"", ""asc"")

        # Lowest count first
        assert [a.agent_id for a in sorted_agents] == [""agent1"", ""agent3"", ""agent2"", ""agent4""]
",api/api/routers/mcp/_utils/agent_sorting_test.py,TestSortAgents
survived,"    def test_sort_by_speed_index_desc(self):
        """"""Test sorting by speed index (highest first).""""""
        models: list[ConciseModelResponse | ConciseLatestModelResponse] = [
            create_test_model(""model1"", speed_index=300),
            create_test_model(""model2"", speed_index=800),
            create_test_model(""model3"", speed_index=600),
        ]

        sorted_models = sort_models(models, ""speed_index"", ""desc"")

        assert [m.id for m in sorted_models] == [""model2"", ""model3"", ""model1""]
",api/api/routers/mcp/_utils/model_sorting_test.py,TestSortModels
survived,"        def _return_pydantic_obj(*args, **kwargs):
            new_response = MagicMock()
            new_response.headers = {""content-type"": ""application/json""}
            new_response.parse.return_value = pydantic_obj
            return new_response
",tests/llm_translation/test_perplexity_reasoning.py,TestPerplexityReasoning
survived,"    def column_visibility(self) -> Dict[str, bool]:
        """"""Get column visibility configuration from preset options""""""
        config = [
            option
            for option in self.options
            if option.get(""label"", """").lower() == ""column_visibility""
        ]
        if not config:
            return {}
        return config[0].get(""value"", {})
",keep/api/models/db/preset.py,PresetDto
survived,"def test_semantic_split_token(sample_df):
    """"""Test semantic split operation with token count method.""""""
    result = sample_df.semantic.split(
        split_key=""text"",
        method=""token_count"",
        method_kwargs={""num_tokens"": 10}
    )
    
    assert isinstance(result, pd.DataFrame)
    assert len(result) >= len(sample_df)  # Should create more rows
    assert ""text_chunk"" in result.columns
    assert f""semantic_split_0_id"" in result.columns
    assert f""semantic_split_0_chunk_num"" in result.columns
    
    # Check that all chunks have sequential numbering
    for doc_id in result[f""semantic_split_0_id""].unique():
        doc_chunks = result[result[f""semantic_split_0_id""] == doc_id]
        chunk_nums = sorted(doc_chunks[f""semantic_split_0_chunk_num""].tolist())
        assert chunk_nums == list(range(1, len(chunk_nums) + 1))
",tests/test_pandas_accessors.py,
survived,"    def test_cost_report_none_days(self):
        """"""Test cost_report with None days parameter.""""""
        with mock.patch('sky.global_user_state.get_clusters_from_history') as mock_get_history:
            mock_get_history.return_value = []
            
            result = core.cost_report(days=None)
            
            # Should call with default 30 days when None is passed
            mock_get_history.assert_called_once_with(days=30)
            self.assertEqual(result, [])
",tests/unit_tests/test_sky_cost_report.py,TestCostReportCore
survived,"    def _create_alert(**properties):
        alert_data = {
            ""id"": ""test-alert-1"",
            ""source"": [""prometheus""],
            ""name"": ""test-alert"",
            ""status"": AlertStatus.FIRING,
            ""severity"": AlertSeverity.INFO,
            ""lastReceived"": datetime.datetime.now().isoformat(),
            ""fingerprint"": f""test-fingerprint-{datetime.datetime.now().timestamp()}"",
        }
        alert_data.update(properties)
        return AlertDto(**alert_data)
",tests/test_workflow_severity_comparisons.py,
survived,"def test_complex_severity_expressions(
    db_session, workflow_manager, create_workflow, create_alert
):
    """"""Test complex CEL expressions involving severity comparisons""""""
    workflow = create_workflow(
        ""test-complex-severity"",
        ""(severity >= 'warning' && source.contains('prometheus')) || (severity == 'critical' && source.contains('grafana'))""
    )

    # Should match: prometheus with warning+, grafana with critical
    prometheus_critical = create_alert(
        severity=AlertSeverity.CRITICAL, source=[""prometheus""], fingerprint=""fp1""
    )
    prometheus_high = create_alert(
        severity=AlertSeverity.HIGH, source=[""prometheus""], fingerprint=""fp2""
    )
    prometheus_warning = create_alert(
        severity=AlertSeverity.WARNING, source=[""prometheus""], fingerprint=""fp3""
    )
    grafana_critical = create_alert(
        severity=AlertSeverity.CRITICAL, source=[""grafana""], fingerprint=""fp4""
    )

    # Should NOT match: prometheus with info/low, grafana with non-critical
    prometheus_info = create_alert(
        severity=AlertSeverity.INFO, source=[""prometheus""], fingerprint=""fp5""
    )
    grafana_high = create_alert(
        severity=AlertSeverity.HIGH, source=[""grafana""], fingerprint=""fp6""
    )

    # Test matching alerts
    for alert in [prometheus_critical, prometheus_high, prometheus_warning, grafana_critical]:
        workflows_to_run_before = len(workflow_manager.scheduler.workflows_to_run)
        workflow_manager.insert_events(SINGLE_TENANT_UUID, [alert])
        assert len(workflow_manager.scheduler.workflows_to_run) == workflows_to_run_before + 1

    # Test non-matching alerts
    for alert in [prometheus_info, grafana_high]:
        workflows_to_run_before = len(workflow_manager.scheduler.workflows_to_run)
        workflow_manager.insert_events(SINGLE_TENANT_UUID, [alert])
        assert len(workflow_manager.scheduler.workflows_to_run) == workflows_to_run_before
",tests/test_workflow_severity_comparisons.py,
survived,"def create_alert():
    """"""Fixture to create an alert DTO with specified properties""""""

    def _create_alert(**properties):
        alert_data = {
            ""id"": ""test-alert-1"",
            ""source"": [""prometheus""],
            ""name"": ""test-alert"",
            ""status"": AlertStatus.FIRING,
            ""severity"": AlertSeverity.INFO,
            ""lastReceived"": datetime.datetime.now().isoformat(),
            ""fingerprint"": f""test-fingerprint-{datetime.datetime.now().timestamp()}"",
        }
        alert_data.update(properties)
        return AlertDto(**alert_data)

    return _create_alert
",tests/test_workflow_severity_comparisons.py,
survived,"    def set_current_graph(self) -> None:
        """"""Get the debian packages and dependencies""""""
        self.graph: CurrentGraph = self.current_graph(self.config.pm_config.pm_id)
",package_managers/debian/db.py,DebianDB
survived,"    def test_enrich_package_preserves_existing_fields(self, mock_logger):
        """"""Test that existing package fields are not overwritten""""""
        # Create package data with existing homepage
        package_data = create_debian_package(
            package=""pkg-with-homepage"",
            homepage=""pkg-homepage.com"",  # Normalized format
        )

        # Create source data with different homepage
        source_data = create_debian_package(
            package=""pkg-with-homepage"",
            homepage=""source-homepage.com"",  # Normalized format
            vcs_git=""github.com/test/pkg"",  # Normalized format
        )
        source_mapping = {""pkg-with-homepage"": source_data}

        # Enrich package
        enriched = enrich_package_with_source(package_data, source_mapping, mock_logger)

        # Verify package homepage is preserved, but source info is added
        assert enriched.homepage == ""pkg-homepage.com""  # Package value preserved
        assert enriched.vcs_git == ""github.com/test/pkg""  # Source value added",tests/package_managers/debian/test_debian_sources.py,TestPackageSourceMapping
survived,"    def test_missing_dependency_handling(self, mock_config, mock_logger, mock_db):
        """"""Tests the case that we DON'T add dependencies for new packages""""""

        existing_pkg_id = uuid4()
        existing_package = Package(
            id=existing_pkg_id,
            derived_id=""debian/missing-dep-pkg"",
            name=""missing-dep-pkg"",
            import_id=""missing-dep-pkg"",
        )

        cache = Cache(
            package_map={""missing-dep-pkg"": existing_package},
            url_map={},
            package_urls={},
            dependencies={},
        )

        # Create package with dependency that doesn't exist in cache
        pkg_data = create_debian_package(
            package=""missing-dep-pkg"", depends=[""non-existent-dep""]
        )

        diff = DebianDiff(mock_config, cache, mock_db, mock_logger)
        new_deps, removed_deps = diff.diff_deps(""missing-dep-pkg"", pkg_data)

        # Should handle gracefully - no deps added for missing packages
        assert len(new_deps) == 0
        assert len(removed_deps) == 0
",tests/package_managers/debian/test_debian_diff.py,TestDebianDifferentialLoading
survived,"    def diff_pkg(
        self, import_id: str, debian_data: DebianData
    ) -> tuple[UUID, Package | None, dict | None]:
        """"""
        Checks if the given package is in the package_cache.

        Returns:
          - pkg_id: the id of the package
          - package: If new, returns a new package object. If existing, returns None
          - changes: a dictionary of changes (description updates)
        """"""
        self.logger.debug(f""Diffing package: {import_id}"")

        if import_id not in self.caches.package_map:
            # new package
            name = import_id.split(""/"")[1]
            p = Package(
                id=uuid4(),
                derived_id=import_id,
                name=name,
                package_manager_id=self.config.pm_config.pm_id,
                import_id=import_id,
                readme=debian_data.description,
                created_at=self.now,
                updated_at=self.now,
            )
            pkg_id: UUID = p.id
            return pkg_id, p, {}
        else:
            # the package exists, check if description has changed
            existing_pkg = self.caches.package_map[import_id]
            pkg_id = existing_pkg.id

            # Check if description (readme) has changed
            if existing_pkg.readme != debian_data.description:
                update_payload = {
                    ""id"": pkg_id,
                    ""readme"": debian_data.description,
                    ""updated_at"": self.now,
                }
                return pkg_id, None, update_payload
            else:
                return pkg_id, None, None
",package_managers/debian/diff.py,DebianDiff
survived,"    def test_multiline_binary(self, multiline_binary):
        """"""Test handling of multiline binaries.""""""
        parser = DebianParser(multiline_binary)
        sources = list(parser.parse())
        assert len(sources) == 1
        source = sources[0]
        assert source.package == ""binutils""
        assert source.binary == [
            ""binutils-for-host"",
            ""binutils-for-build"",
            ""binutils-ia64-linux-gnu-dbg"",
            ""binutils-m68k-linux-gnu"",
            ""binutils-mips64el-linux-gnuabin32-dbg"",
            ""binutils-mipsisa64r6-linux-gnuabin32"",
            ""binutils-mipsisa64r6el-linux-gnuabi64-dbg"",
        ]
",tests/package_managers/debian/test_debian_parser.py,TestDebianParser
survived,"    def __init__(self, logger_name: str, config: Config):
        super().__init__(logger_name)
        self.config = config
",package_managers/debian/db.py,DebianDB
survived,"def not_found(error):
    return jsonify({'error': 'Not found'}), 404
",server/main.py,
survived,"    def add_chat_message(task_id: int, user_id: str, role: str, content: str) -> Optional[Dict]:
        """"""Add a chat message to a task""""""
        try:
            # Get current task
            task = DatabaseOperations.get_task_by_id(task_id, user_id)
            if not task:
                return None
            
            # Add new message
            chat_messages = task.get('chat_messages', [])
            new_message = {
                'role': role,
                'content': content,
                'timestamp': datetime.utcnow().isoformat()
            }
            chat_messages.append(new_message)
            
            # Update task
            return DatabaseOperations.update_task(task_id, user_id, {'chat_messages': chat_messages})
        except Exception as e:
            logger.error(f""Error adding chat message to task {task_id}: {e}"")
            raise
",server/database.py,DatabaseOperations
survived,"    def get_task_by_legacy_id(legacy_id: str) -> Optional[Dict]:
        """"""Get a task by its legacy UUID (for migration purposes)""""""
        try:
            result = supabase.table('tasks').select('*').eq('execution_metadata->>legacy_id', legacy_id).execute()
            return result.data[0] if result.data else None
        except Exception as e:
            logger.error(f""Error fetching task by legacy ID {legacy_id}: {e}"")
            raise
",server/database.py,DatabaseOperations
survived,"    def delete_project(project_id: int, user_id: str) -> bool:
        """"""Delete a project""""""
        try:
            result = supabase.table('projects').delete().eq('id', project_id).eq('user_id', user_id).execute()
            return len(result.data) > 0
        except Exception as e:
            logger.error(f""Error deleting project {project_id}: {e}"")
            raise
",server/database.py,DatabaseOperations
survived,"def sanitize_filename(filename: str) -> str:
    """"""Sanitize filename to prevent path traversal attacks""""""
    # Remove directory separators and other dangerous characters
    filename = os.path.basename(filename)
    # Remove any remaining path separators that might exist
    filename = filename.replace("".."", """").replace(""/"", """").replace(""\\"", """")
    # Ensure the filename is not empty after sanitization
    if not filename or filename.startswith('.'):
        filename = ""uploaded_file""
    return filename
",server/utils/file.py,
survived,"def save_combined_file(data: Dict, output_path: str) -> None:
    """"""
    Save combined metadata to a JSON file.
    
    Args:
        data: Dictionary to save
        output_path: Path where to save the file
    """"""
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)
    
    print(f""Saved combined metadata to {output_path}"")
",combine_metadata.py,
survived,"    def test_mcp_vs_rest_api_mode_exclusive(self, runner, temp_python_script):
        """"""Test that MCP and REST API modes are mutually exclusive in terms of requirements.""""""
        # Test that --mcp skips API key validation
        with patch.dict(""os.environ"", {}, clear=True):
            with patch(""langflow.cli.commands.run_mcp_server"") as mock_run_mcp:
                mock_run_mcp.side_effect = KeyboardInterrupt(""Test interrupt"")
                
                # MCP mode should work without API key
                result_mcp = runner.invoke(app, [
                    ""serve"", str(temp_python_script),
                    ""--mcp"", ""--verbose""
                ])
                assert ""MCP mode enabled"" in result_mcp.output
                
                # REST API mode should fail without API key
                result_rest = runner.invoke(app, [
                    ""serve"", str(temp_python_script),
                    ""--no-mcp"", ""--verbose""
                ])
                assert result_rest.exit_code == 1
                assert ""LANGFLOW_API_KEY"" in result_rest.output
",src/backend/tests/unit/test_cli.py,TestMCPServeCommand
survived,"    def test_mcp_no_api_key_required(self, runner, temp_python_script):
        """"""Test that MCP mode doesn't require LANGFLOW_API_KEY.""""""
        # Ensure no API key is set
        with patch.dict(""os.environ"", {}, clear=True):
            result = runner.invoke(app, [
                ""serve"", str(temp_python_script),
                ""--mcp"", ""--verbose""
            ])
            
            # Should not fail due to missing API key
            # The validation message should show MCP is enabled
            assert ""MCP mode enabled"" in result.output or result.exit_code in [0, 1]
            # Should not show API key validation error
            assert ""LANGFLOW_API_KEY"" not in result.output
",src/backend/tests/unit/test_cli.py,TestMCPServeCommand
survived,"    def test_run_mcp_server_invalid_transport(self):
        """"""Test running MCP server with invalid transport.""""""
        mock_mcp_instance = MagicMock()

        with pytest.raises(ValueError) as exc_info:
            run_mcp_server(
                mcp_server=mock_mcp_instance,
                transport=""invalid""
            )

        assert ""Unsupported transport: invalid"" in str(exc_info.value)
        assert ""Use 'stdio', 'sse', or 'websocket'"" in str(exc_info.value)
",src/backend/tests/unit/test_mcp_server.py,TestMCPServerRuntime
survived,"    def test_create_mcp_server_empty_graphs(self, mock_fastmcp):
        """"""Test MCP server creation with empty graphs.""""""
        mock_mcp_instance = MagicMock()
        mock_fastmcp.return_value = mock_mcp_instance

        server = create_mcp_server(
            graphs={},
            metas={},
            server_name=""Empty Server""
        )

        # Should still create server but with no tools
        mock_fastmcp.assert_called_once_with(""Empty Server"")
        assert server == mock_mcp_instance

        # No tools should be registered
        assert mock_mcp_instance.tool.call_count == 0

        # Resources and prompts should still be registered
        assert mock_mcp_instance.resource.call_count >= 3
        assert mock_mcp_instance.prompt.call_count >= 2
",src/backend/tests/unit/test_mcp_server.py,TestMCPServerCreation
survived,"    def test_mcp_server_error_handling(self, runner, temp_python_script):
        """"""Test error handling in MCP server creation.""""""
        with patch(""langflow.cli.commands.create_mcp_server"") as mock_create_mcp:
            # Mock an error during MCP server creation
            mock_create_mcp.side_effect = ImportError(""fastmcp not available"")
            
            result = runner.invoke(app, [
                ""serve"", str(temp_python_script),
                ""--mcp"", ""--verbose""
            ])
            
            assert result.exit_code == 1
            assert ""Failed to start MCP server"" in result.output
",src/backend/tests/unit/test_cli.py,TestMCPServeCommand
survived,"    def to_dict(self) -> dict[str, Any]:
        """"""Convert the registry entry to a dictionary for Supabase upload.""""""
        return self.model_dump(exclude_none=True, mode=""json"")
",terminal_bench/cli/tb/admin.py,SupabaseRegistry
deleted,"    def test_transform_request_handles_tool_choice_required(self):
        """"""Test that tool_choice 'required' is removed""""""
        config = MoonshotChatConfig()
        
        optional_params = {
            ""tool_choice"": ""required"",
            ""tools"": [{""type"": ""function"", ""function"": {""name"": ""test""}}],
            ""temperature"": 0.7
        }
        
        result = config.transform_request(
            model=""moonshot-v1-8k"",
            messages=[{""role"": ""user"", ""content"": ""test""}],
            optional_params=optional_params,
            litellm_params={},
            headers={}
        )
        
        # tool_choice should be removed when it's ""required""
        assert ""tool_choice"" not in result
        # Tools should remain
        assert result.get(""tools"") is not None
        assert result.get(""temperature"") == 0.7
",tests/test_litellm/llms/moonshot/test_moonshot_chat_transformation.py,TestMoonshotConfig
deleted,"    def test_transform_request_removes_functions(self):
        """"""Test that functions parameter is removed from optional_params""""""
        config = MoonshotChatConfig()
        
        optional_params = {
            ""functions"": [{""name"": ""test_function"", ""description"": ""Test function""}],
            ""temperature"": 0.7,
            ""max_tokens"": 1000
        }
        
        result = config.transform_request(
            model=""moonshot-v1-8k"",
            messages=[{""role"": ""user"", ""content"": ""test""}],
            optional_params=optional_params,
            litellm_params={},
            headers={}
        )
        
        # Functions should be removed
        assert ""functions"" not in result
        # Other params should remain
        assert result.get(""temperature"") == 0.7
        assert result.get(""max_tokens"") == 1000
",tests/test_litellm/llms/moonshot/test_moonshot_chat_transformation.py,TestMoonshotConfig
survived,"    def transform_request(
        self,
        model: str,
        messages: List[AllMessageValues],
        optional_params: dict,
        litellm_params: dict,
        headers: dict,
    ) -> dict:
        """"""
        Transform the request to handle Moonshot AI specific limitations:
        - tool_choice doesn't support ""required""
        - functions isn't supported at all
        """"""
        # Remove unsupported parameters
        if ""functions"" in optional_params:
            optional_params.pop(""functions"")
        
        # Handle tool_choice limitation - remove ""required"" if present
        if ""tool_choice"" in optional_params and optional_params[""tool_choice""] == ""required"":
            optional_params.pop(""tool_choice"")
            
        # Handle temperature limitation (close to 0 <0.3 can only produce n=1 results)
        if ""temperature"" in optional_params and ""n"" in optional_params:
            temp = optional_params.get(""temperature"", 1.0)
            if temp < 0.3 and optional_params.get(""n"", 1) > 1:
                optional_params[""n""] = 1
        
        return super().transform_request(
            model=model,
            messages=messages,
            optional_params=optional_params,
            litellm_params=litellm_params,
            headers=headers,
        )",litellm/llms/moonshot/chat/transformation.py,MoonshotChatConfig
survived,"async def trace_transfer_fixture(db: DbSessionFactory) -> dict[str, int]:
    async with db() as session:
        source_project_id = await session.scalar(
            insert(models.Project).values(name=""source-project"").returning(models.Project.id)
        )
        assert source_project_id is not None

        dest_project_id = await session.scalar(
            insert(models.Project).values(name=""dest-project"").returning(models.Project.id)
        )
        assert dest_project_id is not None

        other_project_id = await session.scalar(
            insert(models.Project).values(name=""other-project"").returning(models.Project.id)
        )
        assert other_project_id is not None

        session_id = await session.scalar(
            insert(models.ProjectSession)
            .values(
                session_id=""test-session-1"",
                project_id=source_project_id,
                start_time=datetime.fromisoformat(""2021-01-01T00:00:00.000+00:00""),
                end_time=datetime.fromisoformat(""2021-01-01T00:02:00.000+00:00""),
            )
            .returning(models.ProjectSession.id)
        )
        assert session_id is not None

        trace1_id = await session.scalar(
            insert(models.Trace)
            .values(
                trace_id=""test-trace-id-1"",
                project_rowid=source_project_id,
                project_session_rowid=session_id,
                start_time=datetime.fromisoformat(""2021-01-01T00:00:00.000+00:00""),
                end_time=datetime.fromisoformat(""2021-01-01T00:01:00.000+00:00""),
            )
            .returning(models.Trace.id)
        )
        assert trace1_id is not None

        span1_id = await session.scalar(
            insert(models.Span)
            .values(
                trace_rowid=trace1_id,
                span_id=""test-span-id-1"",
                parent_id=None,
                name=""test span 1"",
                span_kind=""CHAIN"",
                start_time=datetime.fromisoformat(""2021-01-01T00:00:00.000+00:00""),
                end_time=datetime.fromisoformat(""2021-01-01T00:01:00.000+00:00""),
                attributes={
                    ""input"": {""value"": ""test-input"", ""mime_type"": ""text/plain""},
                    ""output"": {""value"": ""test-output"", ""mime_type"": ""text/plain""},
                },
                events=[],
                status_code=""OK"",
                status_message=""okay"",
                cumulative_error_count=0,
                cumulative_llm_token_count_prompt=0,
                cumulative_llm_token_count_completion=0,
            )
            .returning(models.Span.id)
        )
        assert span1_id is not None

        span_cost1_id = await session.scalar(
            insert(models.SpanCost)
            .values(
                span_rowid=span1_id,
                trace_rowid=trace1_id,
                span_start_time=datetime.fromisoformat(""2021-01-01T00:00:00.000+00:00""),
                total_cost=1.50,
                total_tokens=100,
                prompt_cost=1.00,
                prompt_tokens=80,
                completion_cost=0.50,
                completion_tokens=20,
            )
            .returning(models.SpanCost.id)
        )
        assert span_cost1_id is not None

        trace_annotation1_id = await session.scalar(
            insert(models.TraceAnnotation)
            .values(
                trace_rowid=trace1_id,
                name=""test-annotation-1"",
                label=""good"",
                score=0.9,
                explanation=""This is a good trace"",
                metadata_={},
                annotator_kind=""HUMAN"",
                identifier=""test-1"",
                source=""APP"",
            )
            .returning(models.TraceAnnotation.id)
        )
        assert trace_annotation1_id is not None

        trace2_id = await session.scalar(
            insert(models.Trace)
            .values(
                trace_id=""test-trace-id-2"",
                project_rowid=source_project_id,
                project_session_rowid=session_id,
                start_time=datetime.fromisoformat(""2021-01-01T00:01:00.000+00:00""),
                end_time=datetime.fromisoformat(""2021-01-01T00:02:00.000+00:00""),
            )
            .returning(models.Trace.id)
        )
        assert trace2_id is not None

        span2_id = await session.scalar(
            insert(models.Span)
            .values(
                trace_rowid=trace2_id,
                span_id=""test-span-id-2"",
                parent_id=None,
                name=""test span 2"",
                span_kind=""CHAIN"",
                start_time=datetime.fromisoformat(""2021-01-01T00:01:00.000+00:00""),
                end_time=datetime.fromisoformat(""2021-01-01T00:02:00.000+00:00""),
                attributes={
                    ""input"": {""value"": ""test-input-2"", ""mime_type"": ""text/plain""},
                    ""output"": {""value"": ""test-output-2"", ""mime_type"": ""text/plain""},
                },
                events=[],
                status_code=""OK"",
                status_message=""okay"",
                cumulative_error_count=0,
                cumulative_llm_token_count_prompt=0,
                cumulative_llm_token_count_completion=0,
            )
            .returning(models.Span.id)
        )
        assert span2_id is not None

        span_cost2_id = await session.scalar(
            insert(models.SpanCost)
            .values(
                span_rowid=span2_id,
                trace_rowid=trace2_id,
                span_start_time=datetime.fromisoformat(""2021-01-01T00:01:00.000+00:00""),
                total_cost=2.00,
                total_tokens=150,
                prompt_cost=1.50,
                prompt_tokens=120,
                completion_cost=0.50,
                completion_tokens=30,
            )
            .returning(models.SpanCost.id)
        )
        assert span_cost2_id is not None

        trace_annotation2_id = await session.scalar(
            insert(models.TraceAnnotation)
            .values(
                trace_rowid=trace2_id,
                name=""test-annotation-2"",
                label=""excellent"",
                score=0.95,
                explanation=""This is an excellent trace"",
                metadata_={},
                annotator_kind=""HUMAN"",
                identifier=""test-2"",
                source=""APP"",
            )
            .returning(models.TraceAnnotation.id)
        )
        assert trace_annotation2_id is not None

        other_trace_id = await session.scalar(
            insert(models.Trace)
            .values(
                trace_id=""test-trace-id-other"",
                project_rowid=other_project_id,
                start_time=datetime.fromisoformat(""2021-01-01T00:00:00.000+00:00""),
                end_time=datetime.fromisoformat(""2021-01-01T00:01:00.000+00:00""),
            )
            .returning(models.Trace.id)
        )
        assert other_trace_id is not None

        return {
            ""source_project_id"": source_project_id,
            ""dest_project_id"": dest_project_id,
            ""other_project_id"": other_project_id,
            ""trace1_id"": trace1_id,
            ""trace2_id"": trace2_id,
            ""other_trace_id"": other_trace_id,
        }",tests/unit/server/api/mutations/test_trace_transfer_mutations.py,
deleted,"		def current_state_property(self) -> AgentBrain:
			""""""For backward compatibility - returns an AgentBrain with the flattened properties""""""
			return AgentBrain(
				thinking=None,
				evaluation_previous_goal=self.evaluation_previous_goal,
				memory=self.memory,
				next_goal=self.next_goal,
			)
",browser_use/agent/views.py,AgentOutput
survived,"    async def test_env_group_rubric_unknown_task(self, mock_openai_client):
        """"""Test scoring with unknown task returns zeros.""""""
        env1 = SingleTurnEnv(
            client=mock_openai_client,
            model=""test-model"",
            eval_dataset=Dataset.from_dict({""question"": [""q1""], ""answer"": [""a1""]}),
            rubric=Rubric()
        )
        
        env_map = {""known_task"": env1}
        rubric = EnvGroupRubric(env_map)
        
        result = await rubric.score_rollout(
            prompt=""Test"",
            completion=""Test"",
            task=""unknown_task""
        )
        
        assert result[""reward""] == 0.0
",tests/test_env_group.py,TestEnvGroupRubric
survived,"        def func1(completion, **kwargs):
            return 0.8
",tests/test_env_group.py,TestEnvGroupRubric
survived,"    def supported_invocation_parameters(cls) -> list[InvocationParameter]:
        # For Azure OpenAI, we need to handle o1 and o3 models differently
        # They use max_completion_tokens instead of max_tokens
        return [
            BoundedFloatInvocationParameter(
                invocation_name=""temperature"",
                canonical_name=CanonicalParameterName.TEMPERATURE,
                label=""Temperature"",
                default_value=1.0,
                min_value=0.0,
                max_value=2.0,
            ),
            IntInvocationParameter(
                invocation_name=""max_tokens"",
                canonical_name=CanonicalParameterName.MAX_COMPLETION_TOKENS,
                label=""Max Tokens"",
            ),
            BoundedFloatInvocationParameter(
                invocation_name=""frequency_penalty"",
                label=""Frequency Penalty"",
                default_value=0.0,
                min_value=-2.0,
                max_value=2.0,
            ),
            BoundedFloatInvocationParameter(
                invocation_name=""presence_penalty"",
                label=""Presence Penalty"",
                default_value=0.0,
                min_value=-2.0,
                max_value=2.0,
            ),
            StringListInvocationParameter(
                invocation_name=""stop"",
                canonical_name=CanonicalParameterName.STOP_SEQUENCES,
                label=""Stop Sequences"",
            ),
            BoundedFloatInvocationParameter(
                invocation_name=""top_p"",
                canonical_name=CanonicalParameterName.TOP_P,
                label=""Top P"",
                default_value=1.0,
                min_value=0.0,
                max_value=1.0,
            ),
            IntInvocationParameter(
                invocation_name=""seed"",
                canonical_name=CanonicalParameterName.RANDOM_SEED,
                label=""Seed"",
            ),
            JSONInvocationParameter(
                invocation_name=""tool_choice"",
                label=""Tool Choice"",
                canonical_name=CanonicalParameterName.TOOL_CHOICE,
            ),
            JSONInvocationParameter(
                invocation_name=""response_format"",
                label=""Response Format"",
                canonical_name=CanonicalParameterName.RESPONSE_FORMAT,
            ),
        ]
",src/phoenix/server/api/helpers/playground_clients.py,AzureOpenAIStreamingClient
deleted,"    def _make_structured_output_call(
        self, 
        model: str, 
        messages: List[Dict[str, str]], 
        output_schema: Dict[str, Any], 
        scratchpad: Optional[str],
        extra_kwargs: Dict[str, Any]
    ) -> Any:
        """"""Make a structured output call.""""""
        schema = OutputSchemaBuilder.build_structured_output_schema(output_schema, scratchpad)
        
        try:
            return completion(
                model=model,
                messages=messages,
                response_format=schema,
                **extra_kwargs,
            )
        except Exception as e:
            self._handle_model_error(model, e)
",docetl/operations/utils/api.py,LLMCallHandler
survived,"        def error_func(completion, **kwargs):
            raise ValueError(""Test error"")
",tests/test_rubric.py,TestRubric
survived,"    def test_environment_with_eval_dataset_only(self, mock_openai_client, sample_dataset):
        """"""Test Environment with only eval_dataset.""""""
        env = TestEnvironment(
            client=mock_openai_client,
            model=""test-model"",
            eval_dataset=sample_dataset,
            parser=Parser(),
            rubric=Rubric()
        )
        assert env.dataset is None
        assert env.eval_dataset is not None
",tests/test_environment.py,TestEnvironmentBase
survived,"    def test_format_method_missing_field(self, xml_parser):
        """"""Test format method with missing required field.""""""
        with pytest.raises(ValueError, match=""Missing value for field""):
            xml_parser.format(reasoning=""Only reasoning"")
",tests/test_xml_parser.py,TestXMLParser
survived,"    async def test_rollout_chat_format(self, mock_singleturn_env):
        """"""Test rollout with chat format.""""""
        prompt = [{""role"": ""user"", ""content"": ""What is 2+2?""}]
        answer = ""4""
        
        completion, state = await mock_singleturn_env.rollout(
            client=mock_singleturn_env.client,
            model=""test-model"",
            prompt=prompt,
            answer=answer
        )
        
        # Should return list format for chat
        assert isinstance(completion, list)
        assert len(completion) == 1
        assert completion[0][""role""] == ""assistant""
        assert completion[0][""content""] == ""This is a test response""
        assert state == {}
        
        # Verify the client was called
        mock_singleturn_env.client.chat.completions.create.assert_called_once()
",tests/test_singleturn_env.py,TestSingleTurnEnv
survived,"    def test_get_fields(self, xml_parser, xml_parser_with_alternatives):
        """"""Test getting field names.""""""
        fields1 = xml_parser.get_fields()
        assert fields1 == [""reasoning"", ""answer""]
        
        fields2 = xml_parser_with_alternatives.get_fields()
        assert fields2 == [""reasoning"", ""code""]
",tests/test_xml_parser.py,TestXMLParser
survived,"    def test_rubric_group_add_reward_func(self):
        """"""Test adding reward function to RubricGroup (should add to first rubric).""""""
        def func1(completion, **kwargs):
            return 1.0
        
        def new_func(completion, **kwargs):
            return 0.9
        
        rubric1 = Rubric(funcs=[func1], weights=[1.0])
        rubric2 = Rubric()
        
        group = RubricGroup(rubrics=[rubric1, rubric2])
        
        # Should add to first rubric
        group.add_reward_func(new_func, weight=0.6)
        
        assert len(rubric1.reward_funcs) == 2
        assert len(rubric2.reward_funcs) == 0
        assert rubric1.reward_funcs[1] == new_func
        assert rubric1.reward_weights[1] == 0.6
",tests/test_rubric_group.py,TestRubricGroup
survived,"def mock_multiturn_env(mock_openai_client, sample_chat_dataset):
    """"""Return a MultiTurnEnv for basic testing.""""""
    return SimpleMultiTurnEnv(
        client=mock_openai_client,
        model=""test-model"",
        dataset=sample_chat_dataset,
        max_turns=3,
        completion_condition=""answer"",
        parser=Parser(),
        rubric=Rubric()
    )
",tests/conftest.py,
survived,"    def test_think_parser_initialization(self, think_parser):
        """"""Test that ThinkParser initializes correctly.""""""
        assert isinstance(think_parser, ThinkParser)
        assert hasattr(think_parser, 'extract_fn')
",tests/test_think_parser.py,TestThinkParser
survived,"    def test_sanitize_sampling_args_remote_server(self, mock_openai_client):
        """"""Test sampling args sanitization for remote servers.""""""
        mock_openai_client.base_url = ""https://api.openai.com/v1/""
        
        env = TestEnvironment(
            client=mock_openai_client,
            model=""test-model"",
            eval_dataset=Dataset.from_dict({""question"": [""test""], ""answer"": [""test""]}),
            parser=Parser(),
            rubric=Rubric()
        )
        
        sampling_args = {
            ""temperature"": 0.7,
            ""extra_body"": {""skip_special_tokens"": True}
        }
        
        sanitized = env.sanitize_sampling_args(mock_openai_client, sampling_args)
        
        assert ""temperature"" in sanitized
        assert ""extra_body"" not in sanitized
",tests/test_environment.py,TestEnvironmentBase
survived,"def sample_dataset():
    """"""Return a sample dataset for testing.""""""
    return Dataset.from_dict({
        ""question"": [""What is 2+2?"", ""What is the capital of France?""],
        ""answer"": [""4"", ""Paris""]
    })
",tests/conftest.py,
survived,"    def test_parse_without_think_tags(self, think_parser):
        """"""Test parsing text without think tags.""""""
        text = ""Just a simple answer without thinking tags.""
        result = think_parser.parse(text)
        assert result == text
",tests/test_think_parser.py,TestThinkParser
survived,"    def test_parse_answer_integration(self, think_parser):
        """"""Test parse_answer method inherited from Parser.""""""
        completion = [
            {""role"": ""user"", ""content"": ""What is 2+2?""},
            {""role"": ""assistant"", ""content"": ""<think>Let me calculate</think>The answer is 4""}
        ]
        result = think_parser.parse_answer(completion)
        assert result == ""The answer is 4""
",tests/test_think_parser.py,TestThinkParser
survived,"    def test_parse_answer_with_string(self, basic_parser):
        """"""Test parse_answer with string input.""""""
        text = ""This is an answer""
        result = basic_parser.parse_answer(text)
        assert result == text
",tests/test_parser.py,TestParser
survived,"def mock_singleturn_env(mock_openai_client, sample_dataset):
    """"""Return a SingleTurnEnv with mocked client and dataset.""""""
    return SingleTurnEnv(
        client=mock_openai_client,
        model=""test-model"",
        dataset=sample_dataset,
        system_prompt=""You are a helpful assistant."",
        parser=Parser(),
        rubric=Rubric()
    )
",tests/conftest.py,
survived,"def diff_instance(mock_config):
    """"""
    Factory fixture to create Diff instances with specific cache configurations.

    Returns a function that creates Diff instances.
    """"""

    def create_diff(package_map, dependencies=None, url_map=None, package_urls=None):
        cache = Cache(
            package_map=package_map,
            url_map=url_map or {},
            package_urls=package_urls or {},
            dependencies=dependencies or {},
        )
        return Diff(mock_config, cache)

    return create_diff
",tests/package_managers/homebrew/test_diff_dep.py,
survived,"def package_ids():
    """"""Fixture providing consistent package IDs for testing.""""""
    return {
        ""main"": uuid4(),
        ""dep"": uuid4(),
    }
",tests/package_managers/crates/test_diff_deps.py,
survived,"def ids():
    """"""Fixture providing consistent IDs for testing.""""""
    return {
        ""homepage_url_type"": uuid4(),
        ""package_manager"": uuid4(),
        ""pkg1"": uuid4(),
        ""pkg2"": uuid4(),
        ""pkg3"": uuid4(),
        ""canon1"": uuid4(),
        ""canon2"": uuid4(),
        ""canon3"": uuid4(),
        ""url1"": uuid4(),
        ""url2"": uuid4(),
        ""url3"": uuid4(),
    }
",tests/ranker/test_dedupe.py,
survived,"def mock_dependency_types():
    """"""
    Mock dependency types for testing.

    Returns a mock DependencyTypes object with common dependency types.
    """"""
    dep_types = MagicMock(spec=DependencyTypes)

    # Set up dependency type attributes directly
    dep_types.runtime = Mock(id=uuid.UUID(""00000000-0000-0000-0000-000000000010""))
    dep_types.build = Mock(id=uuid.UUID(""00000000-0000-0000-0000-000000000011""))
    dep_types.dev = Mock(id=uuid.UUID(""00000000-0000-0000-0000-000000000012""))
    dep_types.test = Mock(id=uuid.UUID(""00000000-0000-0000-0000-000000000013""))
    dep_types.development = dep_types.dev  # Alias for development
    dep_types.recommended = Mock(id=uuid.UUID(""00000000-0000-0000-0000-000000000014""))
    dep_types.optional = Mock(id=uuid.UUID(""00000000-0000-0000-0000-000000000015""))

    return dep_types
",tests/conftest.py,
survived,"def mock_pm_config(mock_package_managers):
    """"""
    Mock PMConf (Package Manager Configuration) for testing.

    Returns a mock PMConf object with a default package manager ID.
    """"""
    pm_config = MagicMock(spec=PMConf)
    pm_config.pm_id = mock_package_managers.crates.id
    return pm_config
",tests/conftest.py,
survived,"def parallel_map_sample_data():
    return [
        {""text"": ""This is a positive sentence.""},
        {""text"": ""This is a negative sentence.""},
        {""text"": ""This is a neutral sentence.""},
    ]
",tests/basic/test_basic_parallel_map.py,
survived,"    def test_send_email_to_multiple_recipients(self, mock_smtp_class, smtp_provider):
        """"""Test sending an email to multiple recipients.""""""
        # Setup mock SMTP instance
        mock_smtp = MagicMock()
        mock_smtp_class.return_value = mock_smtp

        recipients = [""recipient1@example.com"", ""recipient2@example.com""]
        
        # Send HTML email to multiple recipients
        result = smtp_provider._notify(
            from_email=""sender@example.com"",
            from_name=""Test Sender"",
            to_email=recipients,
            subject=""Test Multi-recipient"",
            html=""<p>Email to multiple recipients</p>"",
        )

        # Verify email was sent
        mock_smtp.sendmail.assert_called_once()
        call_args = mock_smtp.sendmail.call_args
        assert call_args[0][0] == ""sender@example.com""
        assert call_args[0][1] == recipients
        
        # Verify the To header contains all recipients
        email_content = call_args[0][2]
        assert ""To: recipient1@example.com, recipient2@example.com"" in email_content
        
        # Verify return value
        assert result == {
            ""from"": ""sender@example.com"",
            ""to"": recipients,
            ""subject"": ""Test Multi-recipient"",
            ""html"": ""<p>Email to multiple recipients</p>"",
        }
",tests/test_smtp_provider.py,TestSmtpProvider
survived,"def save_results(python_results: List[BenchmarkResult], rust_results: List[BenchmarkResult], 
                output_file: str):
    """"""Save benchmark results to a JSON file.""""""
    results = {
        ""timestamp"": datetime.now().isoformat(),
        ""python"": [r.to_dict() for r in python_results],
        ""rust"": [r.to_dict() for r in rust_results]
    }
    
    with open(output_file, 'w') as f:
        json.dump(results, f, indent=2)
    
    console.print(f""Results saved to [bold]{output_file}[/bold]"")
",benchmarks/benchmark.py,
survived,"def make_request(url: str, method: str, path: str, data: Optional[Dict] = None,
                headers: Optional[Dict] = None) -> Tuple[float, bool]:
    """"""Make a single HTTP request and return the latency and success status.""""""
    full_url = f""{url}{path}""
    headers = headers or {}
    
    start_time = time.time()
    try:
        if method.upper() == ""GET"":
            response = requests.get(full_url, headers=headers, timeout=5)
        elif method.upper() == ""POST"":
            response = requests.post(full_url, json=data, headers=headers, timeout=5)
        else:
            raise ValueError(f""Unsupported HTTP method: {method}"")
        
        success = 200 <= response.status_code < 300
    except Exception:
        success = False
    
    end_time = time.time()
    latency = (end_time - start_time) * 1000  # Convert to ms
    
    return latency, success
",benchmarks/benchmark.py,
survived,"    async def get_aggregated_balances(self, parameters: dict):
        """"""Get token balances and allowances for a wallet address on a specific chain.""""""
        wallet_address = parameters.get(""wallet_address"")
        if not wallet_address:
            raise ValueError(""wallet_address is required"")
            
        chain_id = parameters.get(""chain_id"", 1)  # Default to Ethereum mainnet

        url = f""{self.base_url}/balance/v1.2/{chain_id}/balances/{wallet_address}""

        headers = {
            ""Accept"": ""application/json""
        }
        if self.api_key:
            headers[""Authorization""] = f""Bearer {self.api_key}""

        async with aiohttp.ClientSession() as session:
            async with session.get(url, headers=headers) as response:
                if not response.ok:
                    raise Exception(f""Failed to fetch balances: {response.status} {await response.text()}"")
                return await response.json()",python/src/plugins/1inch/goat_plugins/oneinch/service.py,OneInchService
survived,"    def __init__(self, options: DexscreenerPluginOptions):
        super().__init__(""dexscreener"", [DexscreenerService()])
",python/src/plugins/dexscreener/goat_plugins/dexscreener/__init__.py,DexscreenerPlugin
survived,"    def supports_chain(self, chain) -> bool:
        # farcaster is chain-agnostic
        return True
",python/src/plugins/farcaster/goat_plugins/farcaster/__init__.py,FarcasterPlugin
survived,"    async def search_casts(self, parameters: dict):
        url = f""{self.base_url}/cast/search""
        return await self._make_request(""GET"", url, params={
            ""q"": parameters['query'],
            ""limit"": parameters.get('limit', 20)
        })
",python/src/plugins/farcaster/goat_plugins/farcaster/service.py,FarcasterService
survived,"    def __init__(self, options: FarcasterPluginOptions):
        super().__init__(""farcaster"", [FarcasterService(options.api_key, options.base_url)])
",python/src/plugins/farcaster/goat_plugins/farcaster/__init__.py,FarcasterPlugin
deleted,"def retrieve_stock_data(ticker: str, days: int = 30) -> tuple[float, float]:
    end_date = datetime.today()
    start_date = end_date - timedelta(days=days)
    data = yf.download(ticker, start=start_date, end=end_date)
    current_price = data['Close'].iloc[-1]
    start_price = data['Close'].iloc[0]
    percent_change = ((current_price - start_price) / start_price) * 100
    return current_price, percent_change
",financial_analysis/functions.py,
survived,"    def __init__(self, jwt_token: str = """"):
        self.jwt_token = jwt_token
        self.base_url = ""https://api.rugcheck.xyz/v1""
",python/src/plugins/rugcheck/goat_plugins/rugcheck/service.py,RugCheckService
survived,"    async def _make_request(self, endpoint: str):
        headers = {
            ""Content-Type"": ""application/json"",
        }
        if self.jwt_token:
            headers[""Authorization""] = f""Bearer {self.jwt_token}""
        async with aiohttp.ClientSession() as session:
            url = f""{self.base_url}{endpoint}""
            async with session.get(url, headers=headers) as response:
                if not response.ok:
                    if response.status == 429:
                        raise Exception(""RugCheck API rate limit exceeded"")
                    raise Exception(f""RugCheck API request failed: {response.status}"")
                return await response.json()
",python/src/plugins/rugcheck/goat_plugins/rugcheck/service.py,RugCheckService
survived,"    def _get_master_metadata(self, connector: Connector) -> Optional[Dict[str, Any]]:
        """"""Get the metadata from the master branch.""""""
        response = requests.get(self._get_github_master_metadata_url(connector))
        
        if not response.ok:
            return None
        return yaml.safe_load(response.text)
",airbyte-ci/connectors/connectors_qa/src/connectors_qa/checks/version.py,VersionCheck
survived,"    def _messages_into(self, messages: List[common.Message]) -> List[Dict[str, Any]]:
        ollama_messages = []
        for message in messages:
            content_parts = []
            tool_calls = []
            
            for block in message.content:
                if isinstance(block, common.TextRaw):
                    content_parts.append(block.text)
                elif isinstance(block, common.ToolUse):
                    tool_calls.append({
                        ""type"": ""function"",
                        ""function"": {
                            ""name"": block.name,
                            ""arguments"": block.input
                        }
                    })
                elif isinstance(block, common.ToolResult):
                    content_parts.append(f""Tool result: {block.content}"")
            
            ollama_message: Dict[str, Any] = {
                ""role"": message.role,
                ""content"": "" "".join(content_parts) if content_parts else """"
            }
            
            if tool_calls:
                ollama_message[""tool_calls""] = tool_calls
                
            ollama_messages.append(ollama_message)
        
        return ollama_messages
",agent/llm/ollama_client.py,OllamaLLM
deleted,"def test_scrape_options_with_parse_pdf():
    if TEST_API_KEY:
        from firecrawl.firecrawl import ScrapeOptions
        app = FirecrawlApp(api_url=API_URL, api_key=TEST_API_KEY)
        scrape_options = ScrapeOptions(parsePDF=False, formats=['markdown'])
        response = app.search(""firecrawl"", limit=1, scrape_options=scrape_options)
        assert response is not None
        assert 'data' in response
",apps/python-sdk/firecrawl/__tests__/v1/e2e_withAuth/test.py,
survived,"    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        x = self.avgpool(x)
        x = x.view(x.size(0), -1)

        x = self.linear_reg(x)        
        out = utils.compute_rotation_matrix_from_ortho6d(x)

        return out
",face_recognition/6d_repnet_360/convert_to_onnx.py,SixDRepNet360
survived,"def parse_det(det):
    landmarks = det[5:].reshape(5, 2)
    box = det[:4]
    score = det[4]
    return box, landmarks, score",face_recognition/6d_repnet_360/utils_6d_repnet_360/functions.py,
survived,"    def forward(self):
        anchors = []
        for k, f in enumerate(self.feature_maps):
            min_sizes = self.min_sizes[k]
            for i, j in product(range(f[0]), range(f[1])):
                for min_size in min_sizes:
                    s_kx = min_size / self.image_size[1]
                    s_ky = min_size / self.image_size[0]
                    dense_cx = [
                        x * self.steps[k] / self.image_size[1] for x in [j + 0.5]
                    ]
                    dense_cy = [
                        y * self.steps[k] / self.image_size[0] for y in [i + 0.5]
                    ]
                    for cy, cx in product(dense_cy, dense_cx):
                        anchors += [cx, cy, s_kx, s_ky]

        output = np.array(anchors).reshape(-1, 4)
        if self.clip:
            output.clamp_(max=1, min=0)
        return output
",face_recognition/6d_repnet_360/utils_6d_repnet_360/functions.py,PriorBox
survived,"    def __init__(self, block, layers, fc_layers=1):
        self.inplanes = 64
        super(SixDRepNet360, self).__init__()
        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,
                               bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.layer1 = self._make_layer(block, 64, layers[0])
        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)
        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)
        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)
        self.avgpool = nn.AvgPool2d(7)

        self.linear_reg = nn.Linear(512*block.expansion,6)
      
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, (2. / n) ** 0.5)
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()
",face_recognition/6d_repnet_360/convert_to_onnx.py,SixDRepNet360
survived,"def convert_to_onnx():
    model_path = download_model()
    
    model = SixDRepNet360(torchvision.models.resnet.Bottleneck, [3, 4, 6, 3], 6)
    
    saved_state_dict = torch.load(model_path, map_location='cpu')
    if 'model_state_dict' in saved_state_dict:
        model.load_state_dict(saved_state_dict['model_state_dict'])
    else:
        model.load_state_dict(saved_state_dict)
    
    model.eval()
    
    dummy_input = torch.randn(1, 3, 224, 224)
    
    onnx_path = ""6DRepNet360.onnx""
    torch.onnx.export(
        model,
        dummy_input,
        onnx_path,
        export_params=True,
        opset_version=11,
        do_constant_folding=True,
        input_names=['input'],
        output_names=['output'],
        dynamic_axes={
            'input': {0: 'batch_size'},
            'output': {0: 'batch_size'}
        }
    )
    
    print(f""Model converted to ONNX: {onnx_path}"")
    
    import onnx
    onnx_model = onnx.load(onnx_path)
    onnx.checker.check_model(onnx_model)
    print(""ONNX model validation passed"")
    
    return onnx_path
",face_recognition/6d_repnet_360/convert_to_onnx.py,
survived,"    def __init__(self):
        """"""Initializes the docling document converter with forced OCR enabled for macOS.""""""
        try:
            # --- Converter WITHOUT OCR (fast path) ---
            pipeline_no_ocr = PdfPipelineOptions()
            pipeline_no_ocr.do_ocr = False
            format_no_ocr = {
                InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_no_ocr)
            }
            self.converter_no_ocr = DoclingConverter(format_options=format_no_ocr)

            # --- Converter WITH OCR (fallback) ---
            pipeline_ocr = PdfPipelineOptions()
            pipeline_ocr.do_ocr = True
            ocr_options = OcrMacOptions(force_full_page_ocr=True)
            pipeline_ocr.ocr_options = ocr_options
            format_ocr = {
                InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_ocr)
            }
            self.converter_ocr = DoclingConverter(format_options=format_ocr)
            
            self.converter_general = DoclingConverter()

            print(""docling DocumentConverter(s) initialized (OCR + no-OCR + general)."")
        except Exception as e:
            print(f""Error initializing docling DocumentConverter(s): {e}"")
            self.converter_no_ocr = None
            self.converter_ocr = None
            self.converter_general = None
",rag_system/ingestion/document_converter.py,DocumentConverter
survived,"        def _pdf_has_text(path: str) -> bool:
            try:
                doc = fitz.open(path)
                for page in doc:
                    if page.get_text(""text"").strip():
                        return True
            except Exception:
                pass
            return False
",rag_system/ingestion/document_converter.py,DocumentConverter
survived,"def test_mistral_integration():
    """"""Integration test demonstrating all four Mistral call patterns:
    1. Sync (non-streaming)
    2. Sync (streaming)
    3. Async (non-streaming)
    4. Async (streaming)

    Verifies that AgentOps correctly tracks all LLM calls via analytics.
    """"""
    # Initialize AgentOps without auto-starting session
    agentops.init(auto_start_session=False)
    session = agentops.start_session()

    # Initialize client and provider
    client = MistralClient(api_key=os.getenv(""MISTRAL_API_KEY""))
    from agentops.llms.providers.mistral import MistralProvider
    provider = MistralProvider(client)
    provider.override()
    
    # Pass session to provider
    provider.client = session

    def sync_no_stream():
        client.chat(
            model=""mistral-tiny"",
            messages=[ChatMessage(role=""user"", content=""Hello from sync no stream"")]
        )

    async def sync_stream():
        stream_response = await client.chat_stream(
            model=""mistral-tiny"",
            messages=[ChatMessage(role=""user"", content=""Hello from sync streaming"")]
        )
        async for chunk in stream_response:
            _ = chunk.delta.content if hasattr(chunk.delta, 'content') else ''

    async def async_no_stream():
        # Mistral doesn't have async methods, use sync
        client.chat(
            model=""mistral-tiny"",
            messages=[ChatMessage(role=""user"", content=""Hello from async no stream"")]
        )

    async def async_stream():
        stream_response = await client.chat_stream(
            model=""mistral-tiny"",
            messages=[ChatMessage(role=""user"", content=""Hello from async streaming"")]
        )
        async for chunk in stream_response:
            _ = chunk.delta.content if hasattr(chunk.delta, 'content') else ''

    async def run_async_tests():
        await async_no_stream()
        await async_stream()

    # Call each function with proper error handling
    try:
        sync_no_stream()
        asyncio.run(sync_stream())
        asyncio.run(run_async_tests())
    except Exception as e:
        print(f""Error during Mistral test: {str(e)}"")
        raise

    session.end_session(""Success"")
    analytics = session.get_analytics()
    print(analytics)
    # Verify that all LLM calls were tracked
    assert analytics[""LLM calls""] >= 4, f""Expected at least 4 LLM calls, but got {analytics['LLM calls']}""
",tests/core_manual_tests/providers/mistral_canary.py,
survived,"    async def async_no_stream():
        await async_anthropic_client.messages.create(
            max_tokens=1024,
            model=""claude-3-5-sonnet-20240620"",
            messages=[
                {
                    ""role"": ""user"",
                    ""content"": ""Hello from async no stream"",
                }
            ],
            session=session
        )
",tests/core_manual_tests/providers/anthropic_canary.py,
survived,"    async def get_token_balance_by_mint_address(self, wallet_client: SolanaWalletClient, parameters: dict):
        """"""Get token balance for a specific mint address.""""""
        try:
            mint_pubkey = Pubkey.from_string(parameters[""mintAddress""])
            wallet_pubkey = Pubkey.from_string(parameters[""walletAddress""])
            
            token_account = get_associated_token_address(
                wallet_pubkey,
                mint_pubkey
            )
            
            # Check if account exists
            account_info = wallet_client.client.get_account_info(token_account)
            if not account_info.value:
                return 0
            
            # Get balance
            balance = wallet_client.client.get_token_account_balance(
                token_account,
                commitment=Confirmed
            )
            
            return balance.value
        except Exception as error:
            raise Exception(f""Failed to get token balance: {error}"")
",python/src/plugins/spl_token/goat_plugins/spl_token/service.py,SplTokenService
survived,"    def test_resume_live_updates_when_paused(self):
        """"""Test resuming when paused.""""""
        formatter = ConsoleFormatter()
        
        formatter._live_paused = True
        
        formatter.resume_live_updates()
        
        assert not formatter._live_paused
",tests/utilities/test_console_formatter_pause_resume.py,TestConsoleFormatterPauseResume
survived,"    def test_human_input_pauses_flow_updates(self, mock_input):
        """"""Test that human input pauses Flow status updates.""""""
        from crewai.agents.agent_builder.base_agent_executor_mixin import CrewAgentExecutorMixin
        
        executor = CrewAgentExecutorMixin()
        executor.crew = MagicMock()
        executor.crew._train = False
        executor._printer = MagicMock()
        
        formatter = event_listener.formatter
        
        original_paused_state = formatter._live_paused
        
        try:
            formatter._live_paused = False
            
            with patch.object(formatter, 'pause_live_updates') as mock_pause, \
                 patch.object(formatter, 'resume_live_updates') as mock_resume:
                
                result = executor._ask_human_input(""Test result"")
                
                mock_pause.assert_called_once()
                mock_resume.assert_called_once()
                mock_input.assert_called_once()
                assert result == ''
        finally:
            formatter._live_paused = original_paused_state
",tests/test_flow_human_input_integration.py,TestFlowHumanInputIntegration
deleted,"    async def invoke_embeddings(
        self,
        query: core_entities.Query,
        model: RuntimeEmbeddingsModel,
        input_text: str,
        extra_args: dict[str, typing.Any] = {},
    ) -> list[float]:
        """"""è°ƒç”¨ Embeddings API

        Args:
            query (core_entities.Query): è¯·æ±‚ä¸Šä¸‹æ–‡
            model (RuntimeEmbeddingsModel): ä½¿ç”¨çš„æ¨¡åž‹ä¿¡æ¯
            input_text (str): è¾“å…¥æ–‡æœ¬
            extra_args (dict[str, typing.Any], optional): é¢å¤–çš„å‚æ•°. Defaults to {}.

        Returns:
            list[float]: è¿”å›žçš„ embedding å‘é‡
        """"""
        pass",pkg/provider/modelmgr/requester.py,LLMAPIRequester
deleted,"    async def load_embeddings_model(
        self,
        model_info: persistence_model.EmbeddingsModel | sqlalchemy.Row[persistence_model.EmbeddingsModel] | dict,
    ):
        """"""åŠ è½½ Embeddings æ¨¡åž‹""""""
        runtime_embeddings_model = await self.init_runtime_embeddings_model(model_info)
        self.embeddings_models.append(runtime_embeddings_model)
",pkg/provider/modelmgr/modelmgr.py,ModelManager
survived,"def create_sink_connection(config: Mapping[str, Any]) -> PipelineDataSink:
    pipeline_id = config.get(""pipeline_id"")
    pipeline_access_token = config.get(""pipeline_access_token"")

    return PipelineDataSink(pipeline_id=pipeline_id, pipeline_access_token=pipeline_access_token)
",airbyte-integrations/connectors/destination-glassflow/destination_glassflow/destination.py,
survived,"def _init_mocks(client):
    pipeline = Mock()
    client.return_value = pipeline
    return pipeline
",airbyte-integrations/connectors/destination-glassflow/unit_tests/unit_test.py,
survived,"def test_source_init_with_different_override_combinations(
    cursor_overrides, primary_key_overrides
):
    """"""Test that the Source initializes correctly with different combinations of overrides.""""""
    with patch.object(Source, ""_discover"", return_value=Mock()):
        source = Source(
            executor=Mock(),
            name=""test-source"",
            cursor_key_overrides=cursor_overrides,
            primary_key_overrides=primary_key_overrides,
        )

        if cursor_overrides:
            assert source._cursor_key_overrides == cursor_overrides
        else:
            assert source._cursor_key_overrides == {}

        if primary_key_overrides:
            expected_pk_overrides = {
                k: v if isinstance(v, list) else [v]
                for k, v in primary_key_overrides.items()
            }
            assert source._primary_key_overrides == expected_pk_overrides
        else:
            assert source._primary_key_overrides == {}
",tests/unit_tests/sources/test_source_key_overrides.py,
survived,"def mock_catalog(mock_stream):
    """"""Create a mock AirbyteCatalog for testing.""""""
    catalog = Mock(spec=AirbyteCatalog)
    catalog.streams = [mock_stream]
    return catalog
",tests/unit_tests/sources/test_source_key_overrides.py,
survived,"def test_set_cursor_key():
    """"""Test that set_cursor_key properly updates a single cursor key override.""""""
    with patch.object(Source, ""_discover"", return_value=Mock()):
        source = Source(executor=Mock(), name=""test-source"")

        source.set_cursor_key(""stream1"", ""cursor1"")
        assert source._cursor_key_overrides == {""stream1"": ""cursor1""}

        source.set_cursor_key(""stream2"", ""cursor2"")
        assert source._cursor_key_overrides == {
            ""stream1"": ""cursor1"",
            ""stream2"": ""cursor2"",
        }

        source.set_cursor_key(""stream1"", ""new_cursor1"")
        assert source._cursor_key_overrides == {
            ""stream1"": ""new_cursor1"",
            ""stream2"": ""cursor2"",
        }
",tests/unit_tests/sources/test_source_key_overrides.py,
survived,"    def __init__(self, name: str, save_path: str) -> None:
        super().__init__(name, ""mock"", save_path)
        self.saved_caches: Dict[str, Cache] = {}
",tests/_save/loaders/test_loader.py,MockPersistenceLoader
survived,"    def test_build_path(self) -> None:
        """"""Test building the path for a cache file.""""""
        loader = PickleLoader(""test"", self.save_path)
        path = loader.build_path(""hash1"", ""Pure"")
        assert str(path).endswith(""P_hash1.pickle"")
        
        path = loader.build_path(""hash2"", ""Deferred"")
        assert str(path).endswith(""D_hash2.pickle"")
",tests/_save/loaders/test_pickle_loader.py,TestPickleLoader
deleted,"def test_mem0_storage_uses_local_config(mem0_storage_with_local_config):
    """"""Test that Mem0Storage correctly uses local_mem0_config when initializing Memory""""""
    _, mock_from_config, local_config = mem0_storage_with_local_config
    mock_from_config.assert_called_once_with(local_config)",tests/storage/test_mem0_storage.py,
survived,"    def balance_of(self, address: str) -> Balance:
        """"""Get the SOL balance of an address.""""""
        pubkey = PublicKey(address)
        balance_lamports = self.client.get_balance(pubkey)[""result""][""value""]
        # Convert lamports (1e9 lamports in 1 SOL)
        return {
            ""decimals"": 9,
            ""symbol"": ""SOL"",
            ""name"": ""Solana"",
            ""value"": str(balance_lamports / 10**9),
            ""in_base_units"": str(balance_lamports),
        }
",python/src/wallets/solana/goat_wallets/solana/wallet.py,SolanaKeypairWalletClient
survived,"    def get_address(self) -> str:
        """"""Get the wallet's public address.""""""
        return str(self.keypair.public_key)
",python/src/wallets/solana/goat_wallets/solana/wallet.py,SolanaKeypairWalletClient
survived,"def mock_driver_with_html(html_content):
    driver = MagicMock()
    mock_element = MagicMock()
    mock_element.get_attribute.return_value = html_content
    bs = BeautifulSoup(html_content, ""html.parser"")
    mock_element.text = bs.get_text()

    driver.find_elements.return_value = [mock_element]
    driver.find_element.return_value = mock_element

    return driver
",tests/tools/selenium_scraping_tool_test.py,
survived,"    def _get_content(self, driver, css_element, return_html):
        content = []

        if self._is_css_element_empty(css_element):
            content.append(self._get_body_content(driver, return_html))
        else:
            content.extend(self._get_elements_content(driver, css_element, return_html))

        return content
",crewai_tools/tools/selenium_scraping_tool/selenium_scraping_tool.py,SeleniumScrapingTool
deleted,"    def test_sanitize_collection_name_bad_ends(self):
        """"""Test sanitizing a name with non-alphanumeric start/end.""""""
        bad_ends = ""_Agent_""
        sanitized = sanitize_collection_name(bad_ends)
        self.assertTrue(sanitized[0].isalnum())
        self.assertTrue(sanitized[-1].isalnum())
",tests/utilities/test_string_utils.py,TestStringUtils
survived,"def test_telemetry_disable_with_multiple_instances():
    """"""Test that multiple telemetry instances respect dynamically changed env vars.""""""
    Telemetry._instance = None
    
    with patch.dict(os.environ, {}, clear=True):
        with patch(""crewai.telemetry.telemetry.TracerProvider""):
            telemetry1 = Telemetry()
            assert telemetry1.ready is True
            
            os.environ['CREWAI_DISABLE_TELEMETRY'] = 'true'
            
            telemetry2 = Telemetry()
            assert telemetry2 is telemetry1
            assert telemetry2.ready is True
            
            mock_operation = MagicMock()
            telemetry2._safe_telemetry_operation(mock_operation)
            mock_operation.assert_not_called()
",tests/telemetry/test_telemetry_disable.py,
survived,"    def test_call_tool_use(
        self, mock_anthropic_class: MagicMock, mock_require_api_key: MagicMock
    ) -> None:
        """"""Test calling the anthropic class with tool use response.""""""
        mock_require_api_key.return_value = ""test-key""
        mock_client = MagicMock()
        mock_anthropic_class.return_value = mock_client
        mock_response = MagicMock()
        mock_content = MagicMock()
        mock_content.type = ""tool_use""
        mock_response.content = [mock_content]
        mock_client.messages.create.return_value = mock_response

        model = anthropic(""claude-3-opus-20240229"")
        messages = [ChatMessage(role=""user"", content=""Test prompt"")]
        config = ChatModelConfig()

        result = model(messages, config)
        assert result == [mock_content]
",tests/_ai/llm/_impl.py,TestAnthropic
survived,"    def test_require_api_key_missing(self, mock_get_context: MagicMock) -> None:
        """"""Test _require_api_key with missing key.""""""
        mock_context = MagicMock()
        mock_context.marimo_config = {""ai"": {""open_ai"": {""api_key"": """"}}}
        mock_get_context.return_value = mock_context

        model = openai(""gpt-4"")
        with pytest.raises(ValueError):
            _ = model._require_api_key
",tests/_ai/llm/_impl.py,TestOpenAI
survived,"    def test_call(
        self, mock_anthropic_class: MagicMock, mock_require_api_key: MagicMock
    ) -> None:
        """"""Test calling the anthropic class.""""""
        mock_require_api_key.return_value = ""test-key""
        mock_client = MagicMock()
        mock_anthropic_class.return_value = mock_client
        mock_response = MagicMock()
        mock_content = MagicMock()
        mock_content.type = ""text""
        mock_content.text = ""Test response""
        mock_response.content = [mock_content]
        mock_client.messages.create.return_value = mock_response

        model = anthropic(""claude-3-opus-20240229"")
        # Patch the _require_api_key property to return the test key directly
        with patch.object(model, ""_require_api_key"", ""test-key""):
            messages = [ChatMessage(role=""user"", content=""Test prompt"")]
            config = ChatModelConfig(
                max_tokens=100,
                temperature=0.7,
                top_p=0.9,
                top_k=10,
            )

            result = model(messages, config)
            assert result == ""Test response""

            mock_anthropic_class.assert_called_once_with(
                api_key=""test-key"", base_url=None
            )
        mock_client.messages.create.assert_called_once()
        call_args = mock_client.messages.create.call_args[1]
        assert call_args[""model""] == ""claude-3-opus-20240229""
        assert call_args[""system""] == DEFAULT_SYSTEM_MESSAGE
        assert call_args[""max_tokens""] == 100
        assert call_args[""temperature""] == 0.7
        assert call_args[""top_p""] == 0.9
        assert call_args[""top_k""] == 10
        assert call_args[""stream""] is False
",tests/_ai/llm/_impl.py,TestAnthropic
survived,"    def test_require_api_key_env(self) -> None:
        """"""Test _require_api_key with environment variable.""""""
        model = google(""gemini-pro"")
        assert model._require_api_key == ""env-key""
",tests/_ai/llm/_impl.py,TestGoogle
survived,"def test_anthropic_require() -> None:
    """"""Test that anthropic.require raises ModuleNotFoundError.""""""
    model = anthropic(""claude-3-opus-20240229"")
    messages = [ChatMessage(role=""user"", content=""Test prompt"")]
    config = ChatModelConfig()
    with pytest.raises(ModuleNotFoundError):
        model(messages, config)
",tests/_ai/llm/_impl.py,
survived,"    def test_base_url_without_leading_slash(self) -> None:
        # Test without leading slash
        with pytest.raises(click.BadParameter) as excinfo:
            base_url(None, None, ""api"")
        assert ""Must start with /"" in str(excinfo.value)
",tests/_cli/test_cli_validators.py,TestBaseUrl
survived,"    def test_is_file_path_with_directory(self, tmp_path: Path) -> None:
        # Test with directory instead of file
        with pytest.raises(click.BadParameter) as excinfo:
            is_file_path(None, None, str(tmp_path))
        assert f""Not a file: {tmp_path}"" in str(excinfo.value)",tests/_cli/test_cli_validators.py,TestIsFilePath
survived,"    def test_base_url_with_trailing_slash(self) -> None:
        # Test with trailing slash
        with pytest.raises(click.BadParameter) as excinfo:
            base_url(None, None, ""/api/"")
        assert ""Must not end with /"" in str(excinfo.value)
",tests/_cli/test_cli_validators.py,TestBaseUrl
survived,"        def accepts_mime_bundle(bundle: MimeBundle) -> MimeBundle:
            return bundle
",tests/_messaging/test_mimetypes.py,TestMimeTypes
deleted,"    def test_unknown_error(self) -> None:
        error = UnknownError(msg=""Something went wrong"")

        # Test properties
        assert error.type == ""unknown""
        assert error.describe() == ""Something went wrong""
",tests/_messaging/test_errors.py,TestErrorClasses
survived,"    def __init__(self) -> None:
        self.messages: list[tuple[str, dict]] = []
",tests/_messaging/test_console_output_worker.py,MockStream
survived,"    def test_stdout_name(self) -> None:
        stdout = self.MockStdout()
        assert stdout.name == ""stdout""
",tests/_messaging/test_types.py,TestStdoutStderr
survived,"    def test_write_traceback_to_stderr(self) -> None:
        # Test writing traceback to Stderr
        mock_stderr = MagicMock(spec=Stderr)

        with patch(""sys.stderr"", mock_stderr):
            traceback = ""Traceback (most recent call last):\n  File \""<stdin>\"", line 1, in <module>\nValueError: invalid value""
            write_traceback(traceback)

            # Should call _write_with_mimetype with highlighted traceback
            mock_stderr._write_with_mimetype.assert_called_once()

            # First argument should be the highlighted traceback
            args, _ = mock_stderr._write_with_mimetype.call_args
            assert ""<span class=\""codehilite\"">"" in args[0]
            assert ""Traceback"" in args[0]

            # Second argument should be the mimetype
            _, kwargs = mock_stderr._write_with_mimetype.call_args
            assert kwargs[""mimetype""] == ""application/vnd.marimo+traceback""
",tests/_messaging/test_tracebacks.py,TestTracebacks
survived,"    def __init__(self, api_key: str, base_url: str = ""https://api.uniswap.org/v2""):
        self.api_key = api_key
        self.base_url = base_url
",python/src/plugins/uniswap/goat_plugins/uniswap/service.py,UniswapService
survived,"def test_error_handling_not_found(custodial_api):
    """"""Test error handling for non-existent wallet.""""""
    with pytest.raises(Exception) as exc:
        custodial_api.get_wallet(""invalid:wallet:id"")
    assert ""Error"" in str(exc.value)
    assert ""404"" in str(exc.value)
",python/src/wallets/crossmint/tests/test_api_client.py,
survived,"def test_solana_transaction():
    """"""Fixture providing a test Solana transaction.""""""
    return {
        ""instructions"": []  # Empty instructions for basic test
    }
",python/src/wallets/crossmint/tests/conftest.py,
survived,"def test_response_json_parsing(custodial_api):
    """"""Test JSON response parsing.""""""
    with pytest.raises(Exception) as exc:
        custodial_api.get_wallet(""invalid:wallet:id"")
    error_response = str(exc.value)
    assert ""{"" in error_response  # Should include formatted JSON error
    assert ""}"" in error_response
",python/src/wallets/crossmint/tests/test_api_client.py,
survived,"def test_authentication_headers(custodial_api):
    """"""Test authentication header structure.""""""
    headers = custodial_api._request(""/wallets"", method=""GET"").request.headers
    assert ""x-api-key"" in headers
    assert headers[""x-api-key""] == os.environ[""CROSSMINT_STAGING_API_KEY_CUSTODIAL""]
    assert headers[""Content-Type""] == ""application/json""
",python/src/wallets/crossmint/tests/test_api_client.py,
survived,"def run():
    source = SourceBoxDataExtract()
    launch(source, sys.argv[1:])",airbyte-integrations/connectors/source-box-data-extract/source_box_data_extract/run.py,
survived,"def box_folder_text_representation(
    client: BoxClient, folder_id: str, is_recursive: bool = False, by_pass_text_extraction: bool = False
) -> Iterable[BoxFileExtended]:
    # folder items iterator
    for item in client.folders.get_folder_items(folder_id).entries:
        if item.type == ""file"":
            file = box_file_get_by_id(client=client, file_id=item.id)
            if not by_pass_text_extraction:
                text_representation = box_file_text_extract(client=client, file_id=item.id)
            else:
                text_representation = """"
            yield BoxFileExtended(file=file, text_representation=text_representation)
        elif item.type == ""folder"" and is_recursive:
            yield from box_folder_text_representation(
                client=client, folder_id=item.id, is_recursive=is_recursive, by_pass_text_extraction=by_pass_text_extraction
            )
",airbyte-integrations/connectors/source-box-data-extract/source_box_data_extract/box_api.py,
survived,"def box_folder_ai_extract_structured(
    client: BoxClient, folder_id: str, fields_json_str: str, is_recursive: bool = False, by_pass_text_extraction: bool = False
) -> Iterable[BoxFileExtended]:
    # folder items iterator
    for item in client.folders.get_folder_items(folder_id).entries:
        if item.type == ""file"":
            file = box_file_get_by_id(client=client, file_id=item.id)
            if not by_pass_text_extraction:
                text_representation = box_file_ai_extract_structured(client=client, file_id=item.id, fields_json_str=fields_json_str)
            else:
                text_representation = """"
            yield BoxFileExtended(file=file, text_representation=text_representation)
        elif item.type == ""folder"" and is_recursive:
            yield from box_folder_ai_extract_structured(
                client=client,
                folder_id=item.id,
                fields_json_str=fields_json_str,
                is_recursive=is_recursive,
                by_pass_text_extraction=by_pass_text_extraction,
            )",airbyte-integrations/connectors/source-box-data-extract/source_box_data_extract/box_api.py,
survived,"    def check_connection(self, logger, config) -> Tuple[bool, any]:
        """"""
        :param config:  the user-input config object conforming to the connector's spec.yaml
        :param logger:  logger object
        :return Tuple[bool, any]: (True, None) if the input config can be used to connect to the API successfully, (False, error) otherwise.
        """"""
        logger.info(""Checking Box API connection..."")
        try:
            box_client = get_box_ccg_client(config)
            user = box_client.users.get_user_me()
            logger.debug(f""box_subject_type: {config.get('box_subject_type')}, box_subject_id: {config.get('box_subject_id')}"")
            logger.info(f""Logged into Box as: {user.name} ({user.id} - {user.login})"")
        except BoxAPIError as e:
            logger.error(f""Unable to connect to Box API with the provided credentials - {e}"")
            return False, f""Unable to connect to Box API with the provided credentials""
        return True, None
",airbyte-integrations/connectors/source-box-data-extract/source_box_data_extract/source.py,SourceBoxDataExtract
survived,"def create_protected_agent() -> Agent:
    """"""
    Create an agent with input guardrails for protection.
    
    Returns:
        An Agent instance with input guardrails.
    """"""
    instructions = """"""
    You are a helpful assistant that provides information and assistance on various topics.
    You prioritize user safety and ethical responses.
    Provide accurate, helpful information while avoiding potentially harmful content.
    Be concise but thorough in your responses.
    """"""
    
    # Create guardrails
    content_guardrail = ContentModerationGuardrail()
    format_guardrail = FormatValidationGuardrail(min_length=5, max_length=500)
    
    # Create the agent with guardrails
    return Agent(
        name=""ProtectedAssistant"",
        instructions=instructions,
        model=""gpt-4o-mini"",
        input_guardrails=[content_guardrail, format_guardrail]
    )
",openai-agents-examples/10_agent_with_guardrails.py,
survived,"def main():
    """"""Fix imports in all Python files in the directory.""""""
    # Try to create a symlink for agents
    create_agents_symlink()
    
    # Get all Python files
    py_files = glob.glob('*.py')
    
    for file_path in py_files:
        if file_path != 'fix_imports.py':  # Skip this script
            fix_imports_in_file(file_path)
    
    print(""Import fixing complete!"")
",openai-agents-examples/fix_imports.py,
survived,"def get_current_time(location: str) -> str:
    """"""
    Get the current time in a given location.
    
    Args:
        location: The location to get the time for. Currently only supports ""UTC"".
        
    Returns:
        A string containing the current time information.
    """"""
    # In a real implementation, you would use a timezone library
    current_time = datetime.utcnow()
    formatted_time = current_time.strftime(""%Y-%m-%d %H:%M:%S"")
    
    return f""The current time in {location} is {formatted_time}.""
",openai-agents-examples/05_agent_with_function_tools.py,
survived,"def test_create_travel_assistant():
    """"""Test that the travel assistant agent is created with the correct configuration.""""""
    agent = create_travel_assistant()
    assert agent.name == ""TravelAssistant""
    assert ""travel assistant"" in agent.instructions.lower()
    assert len(agent.tools) == 3
",openai-agents-examples/05_agent_with_function_tools.py,
survived,"def test_orchestrate_content_creation():
    """"""Test that the content creation system can run and produce content.""""""
    import pytest
    
    # Skip this test if no API key is available
    if not os.environ.get(""OPENAI_API_KEY""):
        pytest.skip(""OPENAI_API_KEY not set"")
    
    # Run a test with a simple content request
    # Use a shorter timeout for testing
    content = asyncio.run(orchestrate_content_creation(""Write a short paragraph about renewable energy""))
    
    # Verify we got non-empty content
    assert content
    assert len(content) > 0
    # The content should contain relevant terms
    assert any(term in content.lower() for term in [""renewable"", ""energy"", ""sustainable""])
",openai-agents-examples/11_agent_orchestration.py,
survived,"def create_triage_agent(specialists: List[Agent]) -> Agent:
    """"""
    Create a triage agent that can delegate to specialist agents.
    
    Args:
        specialists: List of specialist agents to which tasks can be delegated
        
    Returns:
        An Agent instance that triages customer inquiries
    """"""
    instructions = """"""
    You are a customer support triage agent. Your job is to:
    1. Understand the customer's issue
    2. Determine which specialist would be best suited to help
    3. Hand off the conversation to that specialist
    
    Be polite and professional. If you're unsure which specialist to choose, ask clarifying questions.
    """"""
    
    # Create handoffs to specialist agents
    handoffs = [handoff(agent) for agent in specialists]
    
    return Agent(
        name=""TriageAgent"",
        instructions=instructions,
        model=""gpt-4o-mini"",
        handoffs=handoffs
    )
",openai-agents-examples/07_agent_with_handoffs.py,
survived,"    def reset_debug_session(self, session_type: str):
        """"""é‡ç½®è°ƒè¯•ä¼šè¯""""""
        session_key = f'webchat{session_type}'
        self.debug_messages[session_key] = []",pkg/platform/sources/webchat.py,WebChatAdapter
survived,"    def extract_headings(self, content: str) -> List[str]:
        """"""Extract headings from markdown content.""""""
        headings = []
        lines = content.split('\n')
        
        for line in lines:
            line = line.strip()
            if line.startswith('#'):
                heading_text = re.sub(r'^#+\s*', '', line)
                heading_text = re.sub(r'\{[^}]*\}', '', heading_text)  # Remove {#id} syntax
                if heading_text:
                    headings.append(heading_text.strip())
        
        return headings
",scripts/typesense_indexer.py,MarkdownProcessor
survived,"def test_create_directory_false():
    """"""Test that directories are not created when create_directory=False.""""""
    from pathlib import Path
    
    output_path = ""nonexistent_test_dir/output.txt""
    
    task = Task(
        description=""Test task"",
        expected_output=""Test output"",
        output_file=output_path,
        create_directory=False,
    )
    
    resolved_path = Path(output_path).expanduser().resolve()
    resolved_dir = resolved_path.parent
    
    if resolved_dir.exists():
        import shutil
        shutil.rmtree(resolved_dir)
    
    assert not resolved_dir.exists()
    
    with pytest.raises(RuntimeError, match=""Directory .* does not exist and create_directory is False""):
        task._save_file(""test content"")
",tests/task_test.py,
survived,"    def tearDown(self):
        """"""Clean up Milvus Lite resources.""""""
        import shutil
        
        try:
            # Clean up any existing test collections
            if hasattr(self, 'config') and utility.has_collection(self.config[""indexing""][""collection""], using=""default""):
                utility.drop_collection(self.config[""indexing""][""collection""], using=""default"")
                
            # Disconnect from Milvus Lite
            if connections.has_connection(""default""):
                connections.disconnect(""default"")
            
            # Remove temporary directory
            if hasattr(self, 'temp_dir'):
                shutil.rmtree(self.temp_dir, ignore_errors=True)
        except Exception as e:
            logger.warning(f""Error during teardown: {str(e)}"")
",airbyte-integrations/connectors/destination-milvus/integration_tests/milvus_integration_test.py,MilvusIntegrationTest
survived,"def test_solana_smart_wallet_creation(smart_api):
    """"""Test Solana smart wallet creation and retrieval.""""""
    wallet = smart_api.create_wallet(
        wallet_type=WalletType.SOLANA_SMART_WALLET,
        linked_user=""email:test@example.com""
    )
    assert wallet[""type""] == ""solana-smart-wallet""
    
    # Get wallet and verify only the address matches since other fields might differ
    retrieved = smart_api.get_wallet(wallet[""address""])
    assert retrieved[""address""] == wallet[""address""]
",python/src/wallets/crossmint/tests/test_solana_smart_wallet.py,
survived,"    def my_tool_with_result_as_answer(question: str) -> str:
        """"""This tool will return its result as the final answer.""""""
        return question
",tests/tools/test_base_tool.py,
survived,"def print_item(item):
    """"""Print an item.""""""
    if isinstance(item, dict):
        for key, value in item.items():
            if key not in [""created_at"", ""updated_at""]:
                print(f""  {key}: {value}"")
        print()
",codebase-architectures/layered-architecture/main.py,
survived,"def logout_user(token: str) -> bool:
    """"""
    Logout a user by revoking their token.
    
    Args:
        token: The token to revoke
        
    Returns:
        True if the token was revoked, False otherwise
    """"""
    return revoke_token(token)
",codebase-architectures/atomic-composable-architecture/capabilities/user_management.py,
survived,"    def create_product(name, price, category_id=None, description=None, sku=None):
        """"""Create a new product.""""""
        try:
            # Validate product data
            if not name or not isinstance(name, str):
                raise ValueError(""Product name is required and must be a string"")
            
            try:
                price = float(price)
                if price < 0:
                    raise ValueError()
            except (ValueError, TypeError):
                raise ValueError(""Price must be a positive number"")
            
            # Validate category if provided
            if category_id:
                category = db.get(""categories"", category_id)
                if not category:
                    raise ValueError(f""Category with ID {category_id} not found"")
            
            # Validate SKU if provided
            if sku:
                existing_products = db.query(""products"", lambda p: p[""sku""] == sku)
                if existing_products:
                    raise ValueError(f""Product with SKU '{sku}' already exists"")
            
            # Create and save product
            product = Product(
                name=name,
                price=price,
                category_id=category_id,
                description=description,
                sku=sku
            )
            saved_product = db.insert(""products"", product.to_dict())
            Logger.info(app_logger, f""Created product: {name}"")
            return saved_product
        except Exception as e:
            Logger.error(app_logger, f""Error creating product: {str(e)}"", exc_info=True)
            raise
",codebase-architectures/layered-architecture/services/product_service.py,ProductService
survived,"    def get_profile(token: str) -> Dict:
        """"""
        Get a user's profile.
        
        Args:
            token: Authentication token
            
        Returns:
            Response with success status and user data or error message
        """"""
        success, user_data = validate_user_token(token)
        
        if success:
            return {
                ""status"": ""success"",
                ""message"": ""Profile retrieved successfully"",
                ""data"": {""user"": user_data}
            }
        else:
            return {
                ""status"": ""error"",
                ""message"": ""Invalid or expired token"",
                ""data"": None
            }
",codebase-architectures/atomic-composable-architecture/endpoints/user_api.py,UserAPI
survived,"    def get_task(task_id):
        """"""Get a task by ID.""""""
        task_data = db.get(""tasks"", task_id)
        if not task_data:
            return None
        return task_data
",codebase-architectures/vertical-slice-architecture/features/tasks/service.py,TaskService
survived,"    def transform_data(self, transform_func):
        """"""
        Apply a transformation function to the data.
        
        Args:
            transform_func: Function to transform the data
        
        Returns:
            dict: Stage result with data and metadata
        """"""
        if self.data is None:
            self.metadata[""status""] = ""error""
            self.metadata[""errors""].append(""No data loaded to transform"")
            return self._create_result()
        
        try:
            self.data = transform_func(self.data)
            self.metadata[""status""] = ""transformed""
            return self._create_result()
        except Exception as e:
            self.metadata[""status""] = ""error""
            self.metadata[""errors""].append(f""Transformation error: {str(e)}"")
            return self._create_result()
",codebase-architectures/pipeline-architecture/pipeline/input_stage.py,InputStage
survived,"    def get_task(task_id):
        """"""Get a task by ID.""""""
        task = TaskService.get_task(task_id)
        if not task:
            return {""error"": f""Task with ID {task_id} not found""}
        return task
",codebase-architectures/vertical-slice-architecture/features/tasks/api.py,TaskAPI
survived,"    def create_collection(self, collection_name):
        """"""Create a new collection if it doesn't exist.""""""
        if collection_name not in self.data:
            self.data[collection_name] = {}
",codebase-architectures/vertical-slice-architecture/shared/db.py,InMemoryDB
survived,"    def get_by_sku(sku):
        """"""Get a product by SKU.""""""
        try:
            products = db.query(""products"", lambda p: p[""sku""] == sku)
            if not products:
                Logger.warning(app_logger, f""Product with SKU '{sku}' not found"")
                return None
            return products[0]
        except Exception as e:
            Logger.error(app_logger, f""Error getting product by SKU: {str(e)}"", exc_info=True)
            raise
",codebase-architectures/layered-architecture/services/product_service.py,ProductService
survived,"    def create_product(name, price, category_id=None, description=None, sku=None):
        """"""Create a new product.""""""
        try:
            product = ProductService.create_product(name, price, category_id, description, sku)
            return {
                ""success"": True,
                ""message"": ""Product created successfully"",
                ""data"": product
            }
        except ValueError as e:
            Logger.warning(app_logger, f""Validation error in create_product: {str(e)}"")
            return {
                ""success"": False,
                ""message"": str(e)
            }
        except Exception as e:
            Logger.error(app_logger, f""Error in create_product: {str(e)}"", exc_info=True)
            return {
                ""success"": False,
                ""message"": ""An error occurred while creating the product""
            }
",codebase-architectures/layered-architecture/api/product_api.py,ProductAPI
survived,"    def from_dict(cls, data):
        """"""Create a category from dictionary.""""""
        category = cls(
            name=data[""name""],
            description=data.get(""description""),
            id=data.get(""id"")
        )
        category.created_at = data.get(""created_at"", category.created_at)
        category.updated_at = data.get(""updated_at"", category.updated_at)
        return category",codebase-architectures/layered-architecture/models/category.py,Category
survived,"    def print_results(self, output_type=""summary""):
        """"""
        Print the results to the console.
        
        Args:
            output_type: Type of output to print (summary, detailed)
        
        Returns:
            dict: Stage result with data and metadata
        """"""
        try:
            if output_type == ""summary"" and hasattr(self, ""summary""):
                print(""\n===== SUMMARY REPORT ====="")
                print(f""Generated at: {self.summary['generated_at']}"")
                print(f""Data source: {self.summary['data_source']}"")
                print(f""Record count: {self.summary['record_count']}"")
                
                if ""statistics"" in self.summary:
                    print(""\n----- Statistics -----"")
                    for field, stats in self.summary[""statistics""].items():
                        print(f""\n{field}:"")
                        for stat_name, stat_value in stats.items():
                            print(f""  {stat_name}: {stat_value}"")
                
                if ""processing_steps"" in self.summary:
                    print(""\n----- Processing Steps -----"")
                    for step in self.summary[""processing_steps""]:
                        print(f""- {step}"")
                
            elif output_type == ""detailed"" and hasattr(self, ""detailed_report""):
                print(""\n===== DETAILED REPORT ====="")
                print(f""Generated at: {self.detailed_report['generated_at']}"")
                print(f""Data source: {self.detailed_report['data_source']}"")
                print(f""Record count: {self.detailed_report['record_count']}"")
                
                if ""analysis"" in self.detailed_report:
                    print(""\n----- Analysis -----"")
                    for analysis_type, analysis_data in self.detailed_report[""analysis""].items():
                        print(f""\n{analysis_type}:"")
                        print(json.dumps(analysis_data, indent=2))
                
                print(""\n----- Data Sample -----"")
                if isinstance(self.data, list):
                    sample_size = min(3, len(self.data))
                    for i in range(sample_size):
                        print(f""\nRecord {i+1}:"")
                        print(json.dumps(self.data[i], indent=2))
                else:
                    print(json.dumps(self.data, indent=2))
            
            else:
                print(""\n===== DATA OUTPUT ====="")
                if isinstance(self.data, list):
                    print(f""Record count: {len(self.data)}"")
                    sample_size = min(3, len(self.data))
                    print(f""\nShowing {sample_size} sample records:"")
                    for i in range(sample_size):
                        print(f""\nRecord {i+1}:"")
                        print(json.dumps(self.data[i], indent=2))
                else:
                    print(json.dumps(self.data, indent=2))
            
            # Update metadata
            self.metadata[""output_formats""].append(""console"")
            
            return self._create_result()
        except Exception as e:
            self.metadata[""status""] = ""error""
            self.metadata[""errors""].append(f""Print error: {str(e)}"")
            return self._create_result()
",codebase-architectures/pipeline-architecture/pipeline/output_stage.py,OutputStage
survived,"    def process(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """"""
        Process the input data by parsing and validating the tool use request.
        
        Args:
            data: The input data containing the tool use request
            
        Returns:
            Dictionary with the parsed request or error
        """"""
        try:
            console.log(f""[input_stage] Processing tool use request"")
            
            # Convert the tool use dictionary to a ToolUseRequest object
            request = ToolUseRequest.from_dict(data)
            
            console.log(f""[input_stage] Received command: {request.command}, path: {request.path}"")

            # Validate the request
            validation_result = self._validate_request(request)
            if not validation_result.success:
                console.log(f""[input_stage] Validation error: {validation_result.message}"")
                return {""error"": validation_result.message, ""stage"": ""input""}
            
            # Pass the validated request to the next stage
            return {
                ""request"": request,
                ""stage"": ""input"",
                ""status"": ""success""
            }
                
        except Exception as e:
            error_msg = f""Error in input stage: {str(e)}""
            console.print(f""[red]{error_msg}[/red]"")
            console.log(f""[input_stage] Error: {str(e)}"")
            console.log(traceback.format_exc())
            return {""error"": error_msg, ""stage"": ""input""}
",example-agent-codebase-arch/pipeline-architecture/steps/input_stage.py,InputStage
survived,"    def handle_tool_use(tool_use: Dict[str, Any]) -> Dict[str, Any]:
        """"""
        Handle text editor tool use from Claude.

        Args:
            tool_use: The tool use request from Claude

        Returns:
            Dictionary with result or error to send back to Claude
        """"""
        try:
            # Convert the tool use dictionary to a ToolUseRequest object
            request = ToolUseRequest.from_dict(tool_use)
            
            console.log(f""[handle_tool_use] Received command: {request.command}, path: {request.path}"")

            if not request.command:
                error_msg = ""No command specified in tool use request""
                console.log(f""[handle_tool_use] Error: {error_msg}"")
                return {""error"": error_msg}

            if not request.path and request.command != ""undo_edit"":  # undo_edit might not need a path
                error_msg = ""No path specified in tool use request""
                console.log(f""[handle_tool_use] Error: {error_msg}"")
                return {""error"": error_msg}

            # The path normalization is now handled in each file operation function
            console.print(f""[blue]Executing {request.command} command on {request.path}[/blue]"")

            result = None
            
            if request.command == ""view"":
                view_range = request.kwargs.get(""view_range"")
                console.log(
                    f""[handle_tool_use] Calling view_file with view_range: {view_range}""
                )
                result = FileOperationService.view_file(request.path, view_range)

            elif request.command == ""str_replace"":
                old_str = request.kwargs.get(""old_str"")
                new_str = request.kwargs.get(""new_str"")
                console.log(f""[handle_tool_use] Calling str_replace"")
                result = FileOperationService.str_replace(request.path, old_str, new_str)

            elif request.command == ""create"":
                file_text = request.kwargs.get(""file_text"")
                console.log(f""[handle_tool_use] Calling create_file"")
                result = FileOperationService.create_file(request.path, file_text)

            elif request.command == ""insert"":
                insert_line = request.kwargs.get(""insert_line"")
                new_str = request.kwargs.get(""new_str"")
                console.log(f""[handle_tool_use] Calling insert_text at line: {insert_line}"")
                result = FileOperationService.insert_text(request.path, insert_line, new_str)

            elif request.command == ""undo_edit"":
                console.log(f""[handle_tool_use] Calling undo_edit"")
                result = FileOperationService.undo_edit(request.path)

            else:
                error_msg = f""Unknown command: {request.command}""
                console.print(f""[red]{error_msg}[/red]"")
                console.log(f""[handle_tool_use] Error: {error_msg}"")
                return {""error"": error_msg}
            
            # Convert the result to a dictionary
            if result.success:
                return {""result"": result.data if result.data is not None else result.message}
            else:
                return {""error"": result.message}
                
        except Exception as e:
            error_msg = f""Error handling tool use: {str(e)}""
            console.print(f""[red]{error_msg}[/red]"")
            console.log(f""[handle_tool_use] Error: {str(e)}"")
            console.log(traceback.format_exc())
            return {""error"": error_msg}",example-agent-codebase-arch/vertical-slice-architecture/features/file_operations/api.py,FileOperationsAPI
survived,"    def __init__(self, success: bool, message: str, data: Any = None):
        """"""
        Initialize a file operation result.
        
        Args:
            success: Whether the operation was successful
            message: A message describing the result
            data: Optional data returned by the operation
        """"""
        self.success = success
        self.message = message
        self.data = data
",example-agent-codebase-arch/layered-architecture/models/tool_models.py,FileOperationResult
survived,"    def insert_text(path: str, insert_line: int, new_str: str) -> FileOperationResult:
        """"""
        Insert text at a specific location in a file.

        Args:
            path: The path to the file to modify
            insert_line: The line number after which to insert the text
            new_str: The text to insert

        Returns:
            FileOperationResult with result or error message
        """"""
        try:
            if not path or not path.strip():
                error_msg = ""Invalid file path provided: path is empty.""
                console.log(f""[insert_text] Error: {error_msg}"")
                return FileOperationResult(False, error_msg)

            # Normalize the path
            path = normalize_path(path)

            if not os.path.exists(path):
                error_msg = f""File {path} does not exist""
                console.log(f""[insert_text] Error: {error_msg}"")
                return FileOperationResult(False, error_msg)

            if insert_line is None:
                error_msg = ""No line number specified: insert_line is missing.""
                console.log(f""[insert_text] Error: {error_msg}"")
                return FileOperationResult(False, error_msg)

            with open(path, ""r"") as f:
                lines = f.readlines()

            # Line is 0-indexed for this function, but Claude provides 1-indexed
            insert_line = min(max(0, insert_line - 1), len(lines))

            # Check that the index is within acceptable bounds
            if insert_line < 0 or insert_line > len(lines):
                error_msg = (
                    f""Insert line number {insert_line} out of range (0-{len(lines)}).""
                )
                console.log(f""[insert_text] Error: {error_msg}"")
                return FileOperationResult(False, error_msg)

            # Ensure new_str ends with newline
            if new_str and not new_str.endswith(""\n""):
                new_str += ""\n""

            lines.insert(insert_line, new_str)

            with open(path, ""w"") as f:
                f.writelines(lines)

            console.print(
                f""[green]Successfully inserted text at line {insert_line + 1} in {path}[/green]""
            )
            console.log(
                f""[insert_text] Successfully inserted text at line {insert_line + 1} in {path}""
            )
            return FileOperationResult(
                True, f""Successfully inserted text at line {insert_line + 1} in {path}""
            )
        except Exception as e:
            error_msg = f""Error inserting text: {str(e)}""
            console.print(f""[red]{error_msg}[/red]"")
            console.log(f""[insert_text] Error: {str(e)}"")
            console.log(traceback.format_exc())
            return FileOperationResult(False, error_msg)
",example-agent-codebase-arch/vertical-slice-architecture/features/file_operations/service.py,FileOperationService
survived,"def display_file_content(path: str, content: str) -> None:
    """"""
    Display file content with syntax highlighting

    Args:
        path: Path to the file
        content: Content of the file
    """"""
    file_extension = os.path.splitext(path)[1][1:]  # Get extension without the dot
    syntax = Syntax(content, file_extension or ""text"", line_numbers=True)
    console.print(Panel(syntax, title=f""File: {path}""))
",example-agent-codebase-arch/pipeline-architecture/shared/utilities.py,
survived,"    def create_file(path: str, file_text: str) -> FileOperationResult:
        """"""
        Create a new file with specified content.

        Args:
            path: The path where the new file should be created
            file_text: The content to write to the new file

        Returns:
            FileOperationResult with result or error message
        """"""
        try:
            # Check if the path is empty or invalid
            if not path or not path.strip():
                error_msg = ""Invalid file path provided: path is empty.""
                Logger.error(app_logger, f""[create_file] {error_msg}"")
                return FileOperationResult(False, error_msg)

            # Normalize the path
            path = normalize_path(path)

            # Check if the directory exists
            directory = os.path.dirname(path)
            if directory and not os.path.exists(directory):
                Logger.info(app_logger, f""[create_file] Creating directory: {directory}"")
                os.makedirs(directory)

            with open(path, ""w"") as f:
                f.write(file_text or """")

            Logger.info(app_logger, f""[create_file] Successfully created file {path}"")
            return FileOperationResult(True, f""Successfully created file {path}"")
        except Exception as e:
            error_msg = f""Error creating file: {str(e)}""
            Logger.error(app_logger, f""[create_file] {error_msg}"", exc_info=True)
            return FileOperationResult(False, error_msg)
",example-agent-codebase-arch/layered-architecture/services/file_service.py,FileService
survived,"    def undo_edit(path: str) -> FileOperationResult:
        """"""
        Placeholder for undo_edit functionality.
        In a real implementation, you would need to track edit history.

        Args:
            path: The path to the file whose last edit should be undone

        Returns:
            FileOperationResult with message about undo functionality
        """"""
        try:
            if not path or not path.strip():
                error_msg = ""Invalid file path provided: path is empty.""
                console.log(f""[undo_edit] Error: {error_msg}"")
                return FileOperationResult(False, error_msg)

            # Normalize the path
            path = normalize_path(path)

            message = ""Undo functionality is not implemented in this version.""
            console.print(f""[yellow]{message}[/yellow]"")
            console.log(f""[undo_edit] {message}"")
            return FileOperationResult(True, message)
        except Exception as e:
            error_msg = f""Error in undo_edit: {str(e)}""
            console.print(f""[red]{error_msg}[/red]"")
            console.log(f""[undo_edit] Error: {str(e)}"")
            console.log(traceback.format_exc())
            return FileOperationResult(False, error_msg)",example-agent-codebase-arch/vertical-slice-architecture/features/file_operations/service.py,FileOperationService
survived,"    def __init__(self, db_path: Optional[str] = None):
        """"""Initialize SQLite persistence.
        
        Args:
            db_path: Path to the SQLite database file. If not provided, uses
                    CREWAI_FLOW_DB_PATH environment variable or falls back to
                    a temporary database.
        """"""
        self.db_path = db_path or os.getenv(
            ""CREWAI_FLOW_DB_PATH"",
            os.path.join(tempfile.gettempdir(), ""crewai_flows.db"")
        )
        self.init_db()
",src/crewai/flow/persistence/sqlite.py,SQLiteFlowPersistence
survived,"def test_persistence_error_handling(tmp_path):
    """"""Test error handling in persistence operations.""""""
    db_path = os.path.join(tmp_path, ""test_flows.db"")
    persistence = SQLiteFlowPersistence(db_path)
    
    class InvalidFlow(Flow[TestState]):
        # Missing id field in initial state
        class InvalidState(BaseModel):
            value: str = """"
            
        initial_state = InvalidState
        
        @start()
        @persist(persistence)
        def will_fail(self):
            self.state.value = ""test""
    
    with pytest.raises(ValueError) as exc_info:
        flow = InvalidFlow(persistence=persistence)
        flow.kickoff()
    
    assert ""must have an 'id' field"" in str(exc_info.value)",tests/test_flow_persistence.py,
survived,"def test_multiple_method_persistence(tmp_path):
    """"""Test state persistence across multiple method executions.""""""
    db_path = os.path.join(tmp_path, ""test_flows.db"")
    persistence = SQLiteFlowPersistence(db_path)
    
    class MultiStepFlow(Flow[TestState]):
        initial_state = TestState
        
        @start()
        @persist(persistence)
        def step_1(self):
            self.state.counter = 1
            self.state.message = ""Step 1""
        
        @start()
        @persist(persistence)
        def step_2(self):
            self.state.counter = 2
            self.state.message = ""Step 2""
    
    flow = MultiStepFlow(persistence=persistence)
    flow.kickoff()
    
    # Load final state
    final_state = persistence.load_state(flow.state.id)
    assert final_state is not None
    assert final_state[""counter""] == 2
    assert final_state[""message""] == ""Step 2""
",tests/test_flow_persistence.py,
survived,"        def init_step(self):
            self.state[""message""] = ""Hello, World!""
            self.state[""id""] = ""test-uuid""  # Ensure we have an ID for persistence
",tests/test_flow_persistence.py,TestFlow
survived,"def jsonrpc(options: JSONRpcPluginOptions) -> JSONRpcPlugin:
    return JSONRpcPlugin(options)",python/src/plugins/jsonrpc/goat_plugins/jsonrpc/__init__.py,
survived,"def test_xai_raw_response_sync(model, mode):
    """"""Test that _raw_response is attached to sync XAI responses""""""
    client = instructor.from_provider(f""xai/{model}"", mode=mode)
    
    user = client.chat.completions.create(
        response_model=User,
        messages=[
            {
                ""role"": ""system"",
                ""content"": ""You are a helpful assistant that extracts information."",
            },
            {
                ""role"": ""user"",
                ""content"": ""Extract: Jason is 25 years old."",
            },
        ],
    )
    
    assert isinstance(user, User)
    assert user.name.lower() == ""jason""
    assert user.age == 25
    assert hasattr(user, ""_raw_response""), (
        ""The raw response should be available from XAI""
    )
    assert user._raw_response is not None
",tests/llm/test_xai/test_raw_response.py,
survived,"async def test_xai_create_with_completion_async():
    """"""Test that create_with_completion works with XAI provider in async mode""""""
    client = instructor.from_provider(""xai/grok-3-mini"", mode=instructor.Mode.XAI_JSON, async_client=True)
    
    user, raw_response = await client.chat.completions.create_with_completion(
        response_model=User,
        messages=[
            {
                ""role"": ""system"",
                ""content"": ""You are a helpful assistant that extracts information."",
            },
            {
                ""role"": ""user"",
                ""content"": ""Extract: Jason is 25 years old."",
            },
        ],
    )
    
    assert isinstance(user, User)
    assert user.name.lower() == ""jason""
    assert user.age == 25
    assert hasattr(user, ""_raw_response""), (
        ""The raw response should be available from XAI""
    )
    assert raw_response is not None
    assert user._raw_response == raw_response",tests/llm/test_xai/test_raw_response.py,
