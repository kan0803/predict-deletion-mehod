status,method,filepath,class_name
survived,"    def __init__(self):
        self.functions: dict[str, ast.FunctionDef | ast.AsyncFunctionDef] = {}
        self.stack: list[ast.ClassDef] = []
",dev/check_function_signatures.py,FunctionSignatureExtractor
survived,"def test_parameter_error_has_location_info():
    old_code = ""def func(a): pass""
    new_code = ""def func(b): pass""

    old_tree = ast.parse(old_code)
    new_tree = ast.parse(new_code)
    errors = check_signature_compatibility(old_tree.body[0], new_tree.body[0])

    assert len(errors) == 1
    assert errors[0].lineno == 1
    assert errors[0].col_offset > 0
",tests/dev/test_check_function_signatures.py,
survived,"    def visit_ClassDef(self, node: ast.ClassDef) -> None:
        self.stack.append(node)
        self.generic_visit(node)
        self.stack.pop()
",dev/check_function_signatures.py,FunctionSignatureExtractor
survived,"def parse_args() -> Args:
    parser = argparse.ArgumentParser(
        description=""Check for breaking changes in Python function signatures""
    )
    parser.add_argument(""--base-branch"", default=os.environ.get(""GITHUB_BASE_REF"", ""master""))
    args = parser.parse_args()
    return Args(base_branch=args.base_branch)
",dev/check_function_signatures.py,
survived,"def get_visualization_data():
    """"""Return the visualization data and raw tensor data.""""""
    records, tensor_table, failures = collect_grid()
    visualization_data = {}
    raw_tensor_data = {}

    for grid_idx, program_records in records.items():
        viz_data, raw_data, kernel_src = prepare_visualization_data(
            program_records, tensor_table
        )
        visualization_data[str(grid_idx)] = viz_data
        raw_tensor_data.update(raw_data)

    # Get the kernel source code

    return {
        ""visualization_data"": visualization_data,
        ""raw_tensor_data"": raw_tensor_data,
        ""failures"": failures,
        ""kernel_src"": kernel_src,
    }
",triton_viz/visualizer/draw.py,
survived,"    def test_simple_matrix(self, func, expected_diag):
        """"""Test simple 2x2 matrix calculation.""""""
        data = np.array([[1, 2, 3, 4], [2, 4, 6, 8]], dtype=np.float64)
        result = func(data)

        # Check shape
        assert result.shape == (2, 2)

        # Check diagonal
        if expected_diag is not None:
            assert_allclose(np.diag(result), [expected_diag, expected_diag])
        else:
            # For covariance, just check diagonal is non-negative
            assert np.all(np.diag(result) >= 0)

        # Check symmetry
        assert_allclose(result, result.T)

        # For perfect linear relationship, correlation should be 1
        if func == nancorrmatrix:
            assert_allclose(result, [[1.0, 1.0], [1.0, 1.0]])
",numbagg/test/test_matrix_functions.py,TestMatrixFunctions
survived,"    def test_three_series_consistency(self):
        """"""Test consistency for a 3x3 matrix case.""""""
        np.random.seed(444)

        # Create three time series
        n_obs = 30
        a1 = np.random.randn(n_obs)
        a2 = np.random.randn(n_obs) * 1.5 + 0.5
        a3 = np.random.randn(n_obs) * 0.8 - 0.2

        alpha = 0.35

        # Test all pairwise combinations
        pairs = [(a1, a2, 0, 1), (a1, a3, 0, 2), (a2, a3, 1, 2)]

        # Compute matrix result once
        data_matrix = np.array([a1, a2, a3])
        cov_matrix_result = move_exp_nancovmatrix(data_matrix, alpha=alpha)
        corr_matrix_result = move_exp_nancorrmatrix(data_matrix, alpha=alpha)

        for series1, series2, i, j in pairs:
            # Compute pairwise results
            cov_nonmatrix = move_exp_nancov(series1, series2, alpha=alpha)
            corr_nonmatrix = move_exp_nancorr(series1, series2, alpha=alpha)

            # Extract from matrix results
            cov_from_matrix = cov_matrix_result[:, i, j]
            corr_from_matrix = corr_matrix_result[:, i, j]

            # They should match
            assert_allclose(
                cov_nonmatrix,
                cov_from_matrix,
                rtol=1e-10,
                err_msg=f""Covariance mismatch for series {i},{j}"",
            )
            assert_allclose(
                corr_nonmatrix,
                corr_from_matrix,
                rtol=1e-10,
                err_msg=f""Correlation mismatch for series {i},{j}"",
            )

            # Also check symmetry
            assert_allclose(
                cov_matrix_result[:, i, j], cov_matrix_result[:, j, i], rtol=1e-10
            )
            assert_allclose(
                corr_matrix_result[:, i, j], corr_matrix_result[:, j, i], rtol=1e-10
            )",numbagg/test/test_move_exp_matrix_consistency.py,TestMoveExpMatrixConsistency
survived,"    def test_correlation_bounds(self):
        """"""Test that correlation values are properly bounded between -1 and 1.""""""
        # Create data with some negative correlation
        np.random.seed(42)
        data = np.random.randn(3, 100)
        data[1] = -data[0] + 0.1 * np.random.randn(100)  # Strong negative correlation

        result = move_exp_nancorrmatrix(data, alpha=0.5)

        # All correlation values should be between -1 and 1
        finite_mask = np.isfinite(result)
        assert np.all(result[finite_mask] >= -1.0)
        assert np.all(result[finite_mask] <= 1.0)
",numbagg/test/test_move_exp_matrix.py,TestMoveExpMatrixFunctions
survived,"def content(
    pattern: str = typer.Argument(..., help=""Regex pattern to search for""),
    path: Optional[Path] = typer.Option(None, ""--path"", ""-p"", help=""Base path to search in""),
    type: Optional[List[str]] = typer.Option(None, ""--type"", ""-t"", help=""File types to search (e.g., .py)""),
    context: int = typer.Option(2, ""--context"", ""-c"", help=""Number of context lines""),
    ignore: Optional[List[str]] = typer.Option(None, ""--ignore"", ""-i"", help=""Patterns to ignore"")
):
    """"""Search for patterns in file contents""""""
    scanner = ModelScanner(
        base_path=path or Path.cwd(),
        ignore_patterns=ignore
    )
    
    results = scanner.search_content(pattern, file_types=type, context_lines=context)
    
    # Format output
    typer.echo(f""pattern: {results['pattern']}"")
    typer.echo(""matches:"")
    for match in results['matches']:
        typer.echo(f""  file: {match['file']}"")
        typer.echo(f""  line_number: {match['line_number']}"")
        typer.echo(f""  line: {match['line']}"")
        if match.get('context'):
            typer.echo(""  context:"")
            for line in match['context']:
                typer.echo(f""    - {line}"")
        typer.echo()
",src/haconiwa/scan/cli.py,
survived,"def analyze(
    path: Optional[Path] = typer.Option(None, ""--path"", ""-p"", help=""Path to analyze""),
    category: Optional[str] = typer.Option(None, ""--category"", help=""Filter by category""),
    show_structure: bool = typer.Option(False, ""--show-structure"", help=""Show directory structure""),
    output_format: str = typer.Option(""text"", ""--format"", ""-f"", help=""Output format"")
):
    """"""Analyze AI model directory structure and categorization""""""
    analyzer = ModelAnalyzer(base_path=path or Path.cwd())
    
    results = analyzer.analyze_directory(
        show_structure=show_structure,
        category_filter=category
    )
    
    formatter = OutputFormatter()
    output = formatter.format_analysis_results(results, output_format)
    typer.echo(output)
",src/haconiwa/scan/cli.py,
survived,"    def test_list_all_models(self, temp_model_dir):
        """"""Test listing all models""""""
        scanner = ModelScanner(temp_model_dir)
        
        models = scanner.list_all_models()
        assert len(models) >= 3  # We created 3 models
        
        # Check model info structure
        for model in models:
            assert 'name' in model
            assert 'provider' in model
            assert 'category' in model
            assert 'file_count' in model
            assert 'files' in model
",tests/test_scan/test_scanner.py,TestModelScanner
survived,"    def _generate_development_guide(self, model_info: Dict[str, Any]) -> str:
        """"""Generate a development guide""""""
        lines = [
            f""# Development Guide: {model_info['name']}"",
            f""\nGenerated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"",
            ""\n## Overview"",
            f""\nThis guide provides development information for working with {model_info['name']}.""
        ]
        
        # Model information
        if model_info['config']:
            lines.extend([
                ""\n## Model Configuration"",
                ""\n```json"",
                json.dumps(model_info['config'], indent=2),
                ""```""
            ])
        
        # Categories
        if model_info['categories']:
            lines.extend([
                ""\n## Categories"",
                f""\nThis model is categorized as: {', '.join(model_info['categories'])}""
            ])
        
        # File structure
        lines.extend([
            ""\n## File Structure"",
            f""\nTotal files: {model_info['total_files']}"",
            ""\n### Key Files:""
        ])
        
        for file_info in model_info['files'][:10]:  # First 10 files
            lines.append(f""- `{file_info['path']}` ({file_info['type']})"")
        
        # Requirements
        if model_info['requirements']:
            lines.extend([
                ""\n## Requirements"",
                ""\n### Dependencies:""
            ])
            
            for req_file in model_info['requirements']:
                if req_file.get('content'):
                    lines.append(f""\nFrom `{req_file['name']}`:"")
                    lines.append(""```"")
                    lines.append(req_file['content'][:500])  # First 500 chars
                    if len(req_file['content']) > 500:
                        lines.append(""..."")
                    lines.append(""```"")
        
        # API Usage
        if model_info['api_info']:
            lines.extend([
                ""\n## API Integration"",
                f""\nAPI file found: `{model_info['api_info']['path']}`"",
                ""\nRefer to this file for API integration details.""
            ])
        
        # Examples
        if model_info['examples']:
            lines.extend([
                ""\n## Examples"",
                ""\n### Available Examples:""
            ])
            
            for example in model_info['examples'][:5]:
                lines.append(f""- `{example['path']}`"")
        
        # Getting Started
        lines.extend([
            ""\n## Getting Started"",
            ""\n### 1. Setup Environment"",
            ""```bash"",
            ""# Create virtual environment"",
            ""python -m venv venv"",
            ""source venv/bin/activate  # On Windows: venv\\Scripts\\activate"",
            """",
            ""# Install dependencies"",
            ""pip install -r requirements.txt"",
            ""```"",
            ""\n### 2. Load Model"",
            ""```python"",
            f""# Example code to load {model_info['name']}"",
            ""import json"",
            """",
            ""# Load configuration"",
            ""with open('config.json', 'r') as f:"",
            ""    config = json.load(f)"",
            """",
            ""# Initialize model (framework-specific)"",
            ""# Add your model initialization code here"",
            ""```""
        ])
        
        # Best Practices
        lines.extend([
            ""\n## Best Practices"",
            ""\n1. **Version Control**: Track model versions and configurations"",
            ""2. **Testing**: Implement comprehensive tests for model inference"",
            ""3. **Documentation**: Keep documentation up-to-date with model changes"",
            ""4. **Performance**: Monitor and optimize inference performance"",
            ""5. **Security**: Validate inputs and handle errors gracefully""
        ])
        
        # Additional Resources
        lines.extend([
            ""\n## Additional Resources"",
            ""\n- Model documentation: Check README files in the model directory"",
            ""- Examples: Review example files for usage patterns"",
            ""- Configuration: Refer to config files for model parameters""
        ])
        
        return ""\n"".join(lines)
",src/haconiwa/scan/guide_generator.py,GuideGenerator
survived,"    def test_scan_list_command(self, runner, temp_model_dir):
        """"""Test the scan list command""""""
        result = runner.invoke(
            scan_app,
            [""list"", ""--path"", str(temp_model_dir), ""--format"", ""table""]
        )
        
        assert result.exit_code == 0
        assert ""Available AI Models"" in result.stdout
",tests/test_scan/test_cli.py,TestScanCLI
survived,"    def _list_to_text(self, data: List[Any]) -> str:
        """"""Convert list to formatted text""""""
        lines = []
        for item in data:
            if isinstance(item, dict):
                lines.append(self._dict_to_text(item))
                lines.append("""")  # Empty line between items
            else:
                lines.append(f""- {item}"")
        
        return ""\n"".join(lines)
",src/haconiwa/scan/formatter.py,OutputFormatter
survived,"    def _get_timestamp(self) -> str:
        """"""Get current timestamp""""""
        from datetime import datetime
        return datetime.now().isoformat()",src/haconiwa/scan/comparator.py,ModelComparator
survived,"    def test_scan_list_with_filters(self, runner, temp_model_dir):
        """"""Test list with provider and category filters""""""
        result = runner.invoke(
            scan_app,
            [""list"", ""--path"", str(temp_model_dir), ""--provider"", ""unknown"", ""--format"", ""json""]
        )
        
        assert result.exit_code == 0
        output = json.loads(result.stdout)
        assert isinstance(output, list)
",tests/test_scan/test_cli.py,TestScanCLI
survived,"    def _extract_model_name(self, path: Path) -> str:
        """"""Extract model name from path""""""
        # Try to extract from common patterns
        path_parts = path.parts
        
        for part in reversed(path_parts):
            if any(prefix in part.lower() for prefix in self.model_prefixes):
                return part
            if 'model' in part.lower() and len(part) > 5:
                return part
        
        return path.name
",src/haconiwa/scan/scanner.py,ModelScanner
survived,"    def test_scan_main_help(self, runner):
        """"""Test main scan help""""""
        result = runner.invoke(scan_app, [""--help""])
        
        assert result.exit_code == 0
        assert ""Universal AI model search"" in result.stdout
        
        # Test help command
        result = runner.invoke(scan_app, [""help""])
        
        assert result.exit_code == 0
        assert ""Haconiwa Scan Command"" in result.stdout
        assert ""generate-parallel-config"" in result.stdout",tests/test_scan/test_cli.py,TestScanCLI
survived,"    def _compare_capabilities(self, model_data: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
        """"""Compare model capabilities""""""
        capabilities = {}
        
        capability_keywords = {
            'text_generation': ['generate', 'completion', 'text', 'language'],
            'code_generation': ['code', 'programming', 'syntax'],
            'translation': ['translate', 'multilingual', 'language'],
            'summarization': ['summary', 'summarize', 'abstract'],
            'classification': ['classify', 'classification', 'categorize'],
            'embedding': ['embed', 'embedding', 'vector'],
            'chat': ['chat', 'conversation', 'dialogue'],
            'reasoning': ['reason', 'logic', 'analytical'],
            'multimodal': ['multimodal', 'image', 'vision', 'audio']
        }
        
        for model, data in model_data.items():
            model_capabilities = set()
            
            # Check config for capabilities
            if data.get('config'):
                config_str = json.dumps(data['config']).lower()
                for capability, keywords in capability_keywords.items():
                    if any(keyword in config_str for keyword in keywords):
                        model_capabilities.add(capability)
            
            # Check file names and paths
            for file_info in data.get('files', []):
                file_str = file_info['path'].lower()
                for capability, keywords in capability_keywords.items():
                    if any(keyword in file_str for keyword in keywords):
                        model_capabilities.add(capability)
            
            capabilities[model] = list(model_capabilities)
        
        return capabilities
",src/haconiwa/scan/comparator.py,ModelComparator
survived,"    def generate_for_pattern_fix(self,
                               pattern: str,
                               fix_description: str,
                               files: List[str]) -> Dict[str, Any]:
        """"""Generate YAML for fixing specific patterns across files""""""
        
        tasks = []
        
        for file_path in files:
            prompt = f""Find all occurrences of pattern '{pattern}' and {fix_description}. "" \
                    f""Ensure the changes maintain code functionality and follow best practices. "" \
                    f""Add comments explaining significant changes.""
            
            tasks.append({
                'file': file_path,
                'prompt': prompt
            })
        
        config = {
            'provider': 'claude',
            'metadata': {
                'generated_at': datetime.now().isoformat(),
                'source': 'haconiwa scan generate-parallel-config',
                'pattern': pattern,
                'fix': fix_description,
                'total_tasks': len(tasks)
            },
            'tasks': tasks,
            'options': {
                'max_concurrent': 5,
                'timeout': 90,
                'allowed_tools': ['Read', 'Write', 'Edit', 'MultiEdit'],
                'permission_mode': 'acceptEdits',  # Auto-accept for pattern fixes
                'output_dir': './pattern-fix-results'
            }
        }
        
        return config
",src/haconiwa/scan/generate_parallel.py,ParallelYAMLGenerator
survived,"    def test_category_determination(self, temp_model_dir):
        """"""Test category determination logic""""""
        scanner = ModelScanner(temp_model_dir)
        
        # Test various paths
        test_paths = [
            (Path(""models/llm/gpt4""), ""llm""),
            (Path(""models/vision/clip""), ""vision""),
            (Path(""models/audio/whisper""), ""audio""),
            (Path(""models/multimodal/flamingo""), ""multimodal""),
            (Path(""models/embedding/ada""), ""embedding""),
            (Path(""models/random/model""), ""general"")
        ]
        
        for path, expected_category in test_paths:
            category = scanner._determine_category(path)
            assert category == expected_category",tests/test_scan/test_scanner.py,TestModelScanner
survived,"    def test_correlation_covariance_relationship(self):
        """"""Test relationship between correlation and covariance.""""""
        np.random.seed(42)
        data = np.random.randn(4, 50)

        cov_matrix = nancovmatrix(data)
        corr_matrix = nancorrmatrix(data)

        # Correlation = Covariance / (std_i * std_j)
        stds = np.sqrt(np.diag(cov_matrix))
        expected_corr = cov_matrix / np.outer(stds, stds)

        assert_allclose(corr_matrix, expected_corr, rtol=1e-10)
",numbagg/test/test_matrix_functions.py,TestCorrelationCovarianceMatrices
survived,"    def test_no_axis_parameter_accepted(self):
        """"""Test that axis parameter is no longer accepted.""""""
        data = np.random.randn(3, 100)

        # These should all raise TypeError since axis parameter removed
        with pytest.raises(TypeError):
            nancorrmatrix(data, axis=0)

        with pytest.raises(TypeError):
            nancorrmatrix(data, axis=-1)

        with pytest.raises(TypeError):
            nancovmatrix(data, axis=1)
",numbagg/test/test_matrix_functions.py,TestCorrelationCovarianceMatrices
survived,"    async def test_unix_script_execution_with_chmod(
        self, mock_chmod, mock_tempfile, mock_platform
    ):
        """"""Test that chmod is called on Unix for script files.""""""
        mock_file = MagicMock()
        mock_file.name = ""/tmp/script.sh""
        mock_file.__enter__.return_value = mock_file
        mock_tempfile.return_value = mock_file
",tests/unit/test_windows_compatibility.py,TestWindowsCompatibility
survived,"    def test_windows_drive_letter_paths(self):
        """"""Test that Windows drive letter paths are allowed.""""""
        with patch(""platform.system"", return_value=""Windows""):
            validator = PathValidator()

            # Valid Windows paths
            valid_paths = [
                ""C:\\"",
                ""C:\\temp"",
                ""C:\\Users\\test\\file.txt"",
                ""D:\\project\\src"",
                ""C:/temp/file.txt"",  # Forward slashes also valid
            ]

            for path in valid_paths:
                is_valid, error, _ = validator.validate_path(path, check_exists=False)
                assert is_valid, f""Path '{path}' should be valid on Windows: {error}""
",tests/unit/test_windows_compatibility.py,TestWindowsPathValidation
survived,"    def test_build_uv_command_with_python_version(self):
        """"""Test building uv command with Python version.""""""
        cmd = _build_uv_command(""server.py"", python_version=""3.11"")
        expected = [
            ""uv"",
            ""run"",
            ""--python"",
            ""3.11"",
            ""--with"",
            ""fastmcp"",
            ""fastmcp"",
            ""run"",
            ""server.py"",
        ]
        assert cmd == expected
",tests/cli/test_cli.py,TestMainCLI
survived,"    def test_run_with_uv_project(self, mock_run):
        """"""Test run_with_uv with project directory.""""""
        mock_run.return_value = Mock(returncode=0)
        project_path = Path(""/my/project"")

        with pytest.raises(SystemExit) as exc_info:
            run_with_uv(""server.py"", project=project_path)

        assert exc_info.value.code == 0

        cmd = mock_run.call_args[0][0]
        expected = [
            ""uv"",
            ""run"",
            ""--project"",
            ""/my/project"",
            ""--with"",
            ""fastmcp"",
            ""fastmcp"",
            ""run"",
            ""server.py"",
        ]
        assert cmd == expected
",tests/cli/test_run_with_uv.py,TestRunWithUv
survived,"def visualise_from_checkpoint_manager(
    checkpoint_manager,
    meta_cluster_model,
    *,
    style: str = ""basic"",
    console: Optional[Console] = None
) -> None:
    """"""Visualize clusters using a CheckpointManager and meta cluster model.
    
    This function integrates with the v1 pipeline's CheckpointManager to automatically
    load and visualize clusters.
    
    Args:
        checkpoint_manager: CheckpointManager instance from v1 pipeline
        meta_cluster_model: Meta cluster model with checkpoint_filename
        style: Visualization style (""basic"", ""enhanced"", or ""rich"")
        console: Rich Console instance (for rich style)
        
    Raises:
        ValueError: If invalid style is provided
        FileNotFoundError: If checkpoint file doesn't exist
    """"""
    if not hasattr(meta_cluster_model, 'checkpoint_filename'):
        raise ValueError(""Meta cluster model must have checkpoint_filename attribute"")
    
    checkpoint_path = checkpoint_manager.get_checkpoint_path(meta_cluster_model.checkpoint_filename)
    
    if style == ""basic"":
        visualise_clusters(checkpoint_path=checkpoint_path)
    elif style == ""enhanced"":
        visualise_clusters_enhanced(checkpoint_path=checkpoint_path)
    elif style == ""rich"":
        visualise_clusters_rich(checkpoint_path=checkpoint_path, console=console)
    else:
        raise ValueError(f""Invalid style '{style}'. Must be one of: basic, enhanced, rich"")
",kura/v1/visualization.py,
survived,"def visualise_clusters(
    clusters: Optional[List[Cluster]] = None,
    *,
    checkpoint_path: Optional[Union[str, Path]] = None
) -> None:
    """"""Print a hierarchical visualization of clusters to the terminal.
    
    This function loads clusters either from the provided list or from a checkpoint file,
    builds a tree representation, and prints it to the console.
    The visualization shows the hierarchical relationship between clusters
    with indentation and tree structure symbols.
    
    Args:
        clusters: List of clusters to visualize. If None, loads from checkpoint_path
        checkpoint_path: Path to checkpoint file to load clusters from
        
    Raises:
        ValueError: If neither clusters nor checkpoint_path is provided
        FileNotFoundError: If checkpoint file doesn't exist
        
    Example output:
        â• â•â• Compare and improve Flutter and React state management (45 conversations)
        â•‘   â•šâ•â• Improve and compare Flutter and React state management (32 conversations)
        â•‘       â• â•â• Improve React TypeScript application (15 conversations)
        â•‘       â•šâ•â• Compare and select Flutter state management solutions (17 conversations)
        â• â•â• Optimize blog posts for SEO and improved user engagement (28 conversations)
    """"""
    # Load clusters
    if clusters is None:
        if checkpoint_path is None:
            raise ValueError(""Either clusters or checkpoint_path must be provided"")
        clusters = _load_clusters_from_checkpoint(checkpoint_path)
    
    logger.info(f""Visualizing {len(clusters)} clusters"")
    
    # Build tree structure
    node_id_to_cluster = _build_cluster_tree(clusters)

    # Find root nodes and build the tree
    root_nodes = [
        node_id_to_cluster[cluster.id] for cluster in clusters if not cluster.parent_id
    ]

    total_conversations = sum(node.count for node in root_nodes)
    fake_root = ClusterTreeNode(
        id=""root"",
        name=""Clusters"",
        description=""All clusters"",
        count=total_conversations,
        children=[node.id for node in root_nodes],
    )

    tree_output = _build_tree_structure(fake_root, node_id_to_cluster, 0, False)
    print(tree_output)
",kura/v1/visualization.py,
survived,"    def decay(self, decay_rate: Optional[float] = None) -> None:
        """"""Decay all arms of the wrapped agent.

        Parameters
        ----------
        decay_rate : Optional[float], default=None
            Decay rate to use for decaying the arms.
        """"""
        self._agent.decay(decay_rate=decay_rate)
",bayesianbandits/pipelines/_agent.py,NonContextualAgentPipeline
survived,"    def test_pull_without_top_k(self):
        """"""Test pull method without top_k.""""""
        arms = make_arms(range(3))
        agent = ContextualAgent(arms, ThompsonSampling(), random_seed=42)
        steps = [(""identity"", FunctionTransformer())]

        pipeline = ContextualAgentPipeline(steps, agent)

        X = np.array([[1.0, 2.0], [3.0, 4.0]])
        actions = pipeline.pull(X)

        assert len(actions) == 2
        assert all(isinstance(action, int) for action in actions)
",tests/test_agent_pipeline.py,TestContextualAgentPipeline
survived,"    def test_pull_with_top_k(self):
        """"""Test pull method with top_k.""""""
        arms = make_arms(range(5))
        agent = Agent(arms, ThompsonSampling(), random_seed=42)
        steps = []

        pipeline = NonContextualAgentPipeline(steps, agent)

        action_lists = pipeline.pull(top_k=3)

        assert len(action_lists) == 1
        assert len(action_lists[0]) == 3
",tests/test_agent_pipeline.py,TestNonContextualAgentPipeline
survived,"    def test_factory_preserves_functionality(self):
        """"""Test factory-created pipelines work correctly.""""""
        # Test contextual
        arms = make_arms(range(3))
        contextual_agent = ContextualAgent(arms, ThompsonSampling(), random_seed=42)
        steps = [(""scale"", FunctionTransformer(lambda x: x / 10))]

        contextual_pipeline = AgentPipeline(steps, contextual_agent)

        X = np.array([[10.0, 20.0]])
        actions = contextual_pipeline.pull(X)
        assert len(actions) == 1

        # Test non-contextual
        arms = make_arms(range(3))
        agent = Agent(arms, ThompsonSampling(), random_seed=42)

        noncontextual_pipeline = AgentPipeline([], agent)

        actions = noncontextual_pipeline.pull()
        assert len(actions) == 1
",tests/test_agent_pipeline.py,TestAgentPipelineFactory
survived,"def _transform_data(X: Any, steps: List[Tuple[str, Any]]) -> Any:
    """"""Apply all transformers to input data.

    Transformers must be either stateless or pre-fitted.
    No fitting occurs during transformation.
    """"""
    result = X

    for name, transformer in steps:
        try:
            result = transformer.transform(result)
        except Exception as e:
            # Provide helpful error for common case
            if hasattr(e, ""args"") and ""not fitted"" in str(e).lower():
                raise RuntimeError(
                    f""Transformer '{name}' is not fitted. In online learning, ""
                    f""all transformers must be either stateless or pre-fitted ""
                    f""before use. Common stateless transformers include ""
                    f""FunctionTransformer, FeatureHasher, and HashingVectorizer. ""
                    f""Stateful transformers like StandardScaler must be fit on ""
                    f""historical data before creating the pipeline.""
                ) from e
            raise

    return result
",bayesianbandits/pipelines/_agent.py,
survived,"    def __len__(self) -> int:
        """"""Number of steps in the pipeline.""""""
        return len(self.steps)
",bayesianbandits/pipelines/_agent.py,ContextualAgentPipeline
survived,"    def test_transformer_error_propagation(self):
        """"""Test that transformer errors are properly propagated.""""""

        def failing_transform(X):
            raise ValueError(""Custom transformation error"")

        arms = make_arms(range(3))
        agent = ContextualAgent(arms, ThompsonSampling())

        steps = [(""fail"", FunctionTransformer(failing_transform))]
        pipeline = ContextualAgentPipeline(steps, agent)

        X = np.array([[1.0]])

        with pytest.raises(ValueError, match=""Custom transformation error""):
            pipeline.pull(X)
",tests/test_agent_pipeline.py,TestErrorHandling
survived,"        def add_interactions(X):
            """"""Add interaction terms.""""""
            # X shape: (n_samples, 2)
            interactions = X[:, 0:1] * X[:, 1:2]  # x1 * x2
            return np.c_[X, interactions]
",tests/test_agent_pipeline.py,TestIntegrationScenarios
survived,"    def test_noncontextual_pipeline_policy_setter(self):
        """"""Test policy setter on non-contextual pipeline.""""""
        arms = make_arms(range(3))
        agent = Agent(arms, ThompsonSampling())
        pipeline = NonContextualAgentPipeline([], agent)

        new_policy = EpsilonGreedy(epsilon=0.2)
        pipeline.policy = new_policy
        assert pipeline.policy is new_policy
",tests/test_agent_pipeline.py,TestCoverage
survived,"    def __init__(
        self, steps: List[Tuple[str, Any]], final_agent: Agent[TokenType]
    ) -> None:
        _validate_steps(
            steps
        ) if steps else None  # Allow empty steps for non-contextual
        self.steps = steps
        self._agent = final_agent
",bayesianbandits/pipelines/_agent.py,NonContextualAgentPipeline
survived,"        def double_transform(X):
            return X * 2
",tests/test_learner_pipeline.py,TestLearnerPipelineTransformers
survived,"    def decay(self, X, *, decay_rate=None):
        self.decay_calls.append((X, decay_rate))
",tests/test_learner_pipeline.py,MockLearner
survived,"    def test_update(self):
        """"""Test update method.""""""
        arms = make_arms(range(3))
        agent = ContextualAgent(arms, ThompsonSampling(), random_seed=42)
        steps = [(""scale"", FunctionTransformer(lambda x: x / 10))]

        pipeline = ContextualAgentPipeline(steps, agent)

        X = np.array([[10.0, 20.0]])
        y = np.array([1.0])

        # Pull to set arm_to_update
        pipeline.pull(X)

        # Update should transform X before passing to agent
        pipeline.update(X, y)

        # Verify the learner was updated with transformed data
        arm_learner = pipeline.arm_to_update.learner
        assert hasattr(arm_learner, ""coef_"")
",tests/test_agent_pipeline.py,TestContextualAgentPipeline
survived,"    def policy(self, value):
        """"""Set the policy on the wrapped agent.""""""
        self._agent.policy = value
",bayesianbandits/pipelines/_agent.py,NonContextualAgentPipeline
survived,"def test_export_from_pylock_not_empty(core, pdm):
    """"""Test that exporting from pylock.toml produces non-empty output (fixes issue #3573).""""""
    project = core.create_project(FIXTURES / ""projects/demo"")

    # Export from pylock.toml to requirements format
    with cd(project.root):
        result = pdm([""export"", ""-f"", ""requirements"", ""-L"", ""pylock.toml"", ""--no-hashes""], obj=project, strict=True)
        assert result.exit_code == 0

    # The output should not be empty (this was the original bug)
    output_lines = [
        line.strip() for line in result.stdout.strip().split(""\n"") if line.strip() and not line.strip().startswith(""#"")
    ]
    assert len(output_lines) > 0, ""Export from pylock.toml should not be empty""

    # Should contain expected packages
    output = result.stdout
    assert any(pkg in output for pkg in [""chardet"", ""idna""]), ""Expected at least some packages in output""",tests/test_formats.py,
survived,"    def _identify_file_modifications(self, feature_request: str, analysis: Dict[str, Any]) -> List[str]:
        """"""Identify which files need modification.""""""
        return [""main.py"", ""utils.py""]
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent
survived,"    def _extract_code_patterns(self, project_path: str, file_patterns: List[str]) -> Dict[str, Any]:
        """"""Extract common code patterns from the project.""""""
        patterns = {""classes"": [], ""functions"": [], ""imports"": [], ""decorators"": []}
        # Implementation would analyze actual code files
        return patterns
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent
survived,"    def _generate_failure_actions(self, criterion: str) -> List[str]:
        """"""Generate actions to take if criterion fails.""""""
        return [f""Review implementation for: {criterion}"", ""Fix issues"", ""Re-test""]
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent
survived,"    def enhance_prompt_with_context(self, base_prompt: str, context_data: Dict[str, Any]) -> str:
        """"""
        Enhance a basic prompt with comprehensive contextual information.
        
        Args:
            base_prompt (str): Original prompt to enhance
            context_data (Dict[str, Any]): Contextual data to inject
            
        Returns:
            str: Enhanced prompt with rich context
        """"""
        enhanced_prompt = f""""""# Enhanced Prompt with Context Engineering

## Original Request
{base_prompt}

## Contextual Information
{self._format_context_data(context_data)}

## Implementation Context
Based on the analysis, when implementing this request:

### Architecture Considerations
{self._extract_architecture_guidance(context_data)}

### Pattern Adherence
{self._extract_pattern_guidance(context_data)}

### Quality Requirements
{self._extract_quality_guidance(context_data)}

## Enhanced Request
{base_prompt}

**Additional Context**: Implement following the patterns and conventions identified above. 
Ensure the solution integrates seamlessly with the existing codebase architecture.
""""""
        
        return enhanced_prompt
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent
survived,"def test_backward_compatibility():
    """"""Test that existing PraisonAI functionality still works.""""""
    print(""\nðŸ§ª Testing Backward Compatibility..."")
    
    try:
        # Test that we can still import and use existing agents
        from praisonaiagents import Agent, ImageAgent
        
        # Test basic Agent still works
        basic_agent = Agent(name=""Test Agent"")
        print(""âœ… Basic Agent still works"")
        
        # Test ImageAgent still works
        image_agent = ImageAgent(name=""Test Image Agent"")
        print(""âœ… ImageAgent still works"")
        
        # Test that we can import other PraisonAI components
        from praisonaiagents import Task, PraisonAIAgents
        print(""âœ… Task and PraisonAIAgents can still be imported"")
        
        # Test that __all__ exports are working
        import praisonaiagents
        expected_exports = [
            'Agent', 'ImageAgent', 'ContextAgent', 'create_context_agent',
            'PraisonAIAgents', 'Task'
        ]
        
        for export in expected_exports:
            assert hasattr(praisonaiagents, export), f""Missing export: {export}""
        
        print(""âœ… All expected exports are available"")
        
        return True
        
    except Exception as e:
        print(f""âŒ Backward compatibility test failed: {e}"")
        return False
",test_context_agent.py,
survived,"    def _generate_prp_success_criteria(self, feature_request: str, analysis: Dict[str, Any]) -> str:
        """"""Generate success criteria for PRP.""""""
        return f""Success criteria for: {feature_request}""
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent
survived,"async def test_smart_decision_maker_tracks_llm_stats():
    """"""Test that SmartDecisionMakerBlock correctly tracks LLM usage stats.""""""
    from unittest.mock import MagicMock, patch

    import backend.blocks.llm as llm_module
    from backend.blocks.smart_decision_maker import SmartDecisionMakerBlock

    block = SmartDecisionMakerBlock()

    # Mock the llm.llm_call function to return controlled data
    mock_response = MagicMock()
    mock_response.response = ""I need to think about this.""
    mock_response.tool_calls = None  # No tool calls for simplicity
    mock_response.prompt_tokens = 50
    mock_response.completion_tokens = 25
    mock_response.reasoning = None
    mock_response.raw_response = {
        ""role"": ""assistant"",
        ""content"": ""I need to think about this."",
    }

    # Mock the _create_function_signature method to avoid database calls
    with patch(""backend.blocks.llm.llm_call"", return_value=mock_response), patch.object(
        SmartDecisionMakerBlock, ""_create_function_signature"", return_value=[]
    ):

        # Create test input
        input_data = SmartDecisionMakerBlock.Input(
            prompt=""Should I continue with this task?"",
            model=llm_module.LlmModel.GPT4O,
            credentials=llm_module.TEST_CREDENTIALS_INPUT,  # type: ignore
        )

        # Execute the block
        outputs = {}
        async for output_name, output_data in block.run(
            input_data,
            credentials=llm_module.TEST_CREDENTIALS,
            graph_id=""test-graph-id"",
            node_id=""test-node-id"",
            graph_exec_id=""test-exec-id"",
            node_exec_id=""test-node-exec-id"",
            user_id=""test-user-id"",
        ):
            outputs[output_name] = output_data

        # Verify stats tracking
        assert block.execution_stats is not None
        assert block.execution_stats.input_token_count == 50
        assert block.execution_stats.output_token_count == 25
        assert block.execution_stats.llm_call_count == 1

        # Verify outputs
        assert ""finished"" in outputs  # Should have finished since no tool calls
        assert outputs[""finished""] == ""I need to think about this.""",autogpt_platform/backend/backend/blocks/test/test_smart_decision_maker.py,
survived,"    def check(node: ast.Delete, resolver: Resolver) -> bool:
        """"""
        Returns True if the deletion is from os.environ[...].
        """"""
        if len(node.targets) == 1 and isinstance(node.targets[0], ast.Subscript):
            resolved = resolver.resolve(node.targets[0].value)
            return resolved == [""os"", ""environ""]
        return False",dev/clint/src/clint/rules/os_environ_delete_in_test.py,OsEnvironDeleteInTest
survived,"    def check(node: ast.FunctionDef | ast.AsyncFunctionDef, resolver: Resolver) -> bool:
        return InvalidAbstractMethod._is_abstract_method(
            node, resolver
        ) and InvalidAbstractMethod._has_invalid_body(node)",dev/clint/src/clint/rules/invalid_abstract_method.py,InvalidAbstractMethod
survived,"    def check(node: ast.AnnAssign) -> bool:
        """"""
        Returns True if the value to assign is `None` but the type annotation is
        not `Optional[...]` or `... | None`. For example: `a: int = None`.
        """"""
        return ImplicitOptional._is_none(node.value) and not (
            ImplicitOptional._is_optional(node.annotation)
            or ImplicitOptional._is_bitor_none(node.annotation)
        )
",dev/clint/src/clint/rules/implicit_optional.py,ImplicitOptional
survived,"    def test_new_OpArg(self):
        mod = self.compile(
        """"""
        from operator import OpArg

        @blue
        def create_blue_oparg(x: i32) -> OpArg:
            return OpArg('blue', i32, x)

        @blue
        def create_red_oparg() -> OpArg:
            return OpArg('red', i32, None)
        """""")

        # Test blue OpArg creation
        w_blue_oparg = mod.create_blue_oparg(42, unwrap=False)
        assert isinstance(w_blue_oparg, W_OpArg)
        assert w_blue_oparg.color == 'blue'
        assert w_blue_oparg.w_static_type is B.w_i32
        assert w_blue_oparg._w_val is not None

        # Test red OpArg creation
        w_red_oparg = mod.create_red_oparg(unwrap=False)
        assert isinstance(w_red_oparg, W_OpArg)
        assert w_red_oparg.color == 'red'
        assert w_red_oparg.w_static_type is B.w_i32
        assert w_red_oparg._w_val is None
",spy/tests/compiler/test_opimpl.py,TestOpImpl
survived,"    def definition(self, curie: CURIE, lang: Optional[LANGUAGE_TAG] = None) -> Optional[str]:
        """"""
        Fetch the definition for a CURIE from OLS.
        
        :param curie: The CURIE to fetch the definition for
        :param lang: Optional language tag (not currently supported by this implementation)
        :return: The definition for the CURIE, or None if not found
        """"""
        if curie in self.definition_cache:
            return self.definition_cache[curie]
        
        try:
            ontology = self.focus_ontology
            iri = self.curie_to_uri(curie)
            term = self.client.get_term(ontology=ontology, iri=iri)
            if term and ""description"" in term and term[""description""]:
                self.definition_cache[curie] = term[""description""]
                return term[""description""]
        except Exception:
            pass
        
        return None
",src/oaklib/implementations/ols/ols_implementation.py,BaseOlsImplementation
survived,"    def test_label(self, mock_label):
        """"""Test the implementation of the label method""""""
        # Set up the mock to return the value we want
        mock_label.return_value = ""nucleus""
        
        # Test label retrieval
        label = self.oi.label(""GO:0005634"")
        self.assertEqual(label, ""nucleus"")
        
        # Verify the mock was called correctly
        mock_label.assert_called_with(""GO:0005634"")
",tests/test_implementations/test_ols.py,TestOlsImplementation
survived,"    def test_constant_variable(self):
        # Test with constant (zero variance) variables
        data = np.array([[1, 1, 1, 1], [2, 2, 2, 2], [1, 2, 3, 4]], dtype=np.float64)
        result = nancovmatrix(data)

        # Diagonal elements for constant variables should be 0
        assert result[0, 0] == 0.0
        assert result[1, 1] == 0.0
        assert result[2, 2] > 0  # Non-constant variable

        # Covariance between constants should be 0
        assert result[0, 1] == 0.0
        assert result[1, 0] == 0.0
",numbagg/test/test_nancovmatrix.py,TestNanCovMatrix
survived,"    def test_dtype_preservation(self):
        # Test float32
        data32 = np.random.randn(5, 20).astype(np.float32)
        result32 = nancovmatrix(data32)
        assert result32.dtype == np.float32

        # Test float64
        data64 = np.random.randn(5, 20).astype(np.float64)
        result64 = nancovmatrix(data64)
        assert result64.dtype == np.float64
",numbagg/test/test_nancovmatrix.py,TestNanCovMatrix
survived,"def nancorrmatrix(a, out):
    """"""
    Compute correlation matrix treating NaN as missing values.

    For 2D input, correlates variables (rows) across observations (columns).
    Uses pairwise complete observations (like pandas.DataFrame.corr).
    """"""
    n_vars, n_obs = a.shape

    # Compute correlation matrix
    for i in range(n_vars):
        for j in range(i, n_vars):  # Only compute upper triangle
            if i == j:
                # Diagonal: correlation with itself is 1.0 if any valid values exist
                for k in range(n_obs):
                    if not np.isnan(a[i, k]):
                        out[i, j] = 1.0
                        break
                else:
                    # No valid values found
                    out[i, j] = np.nan
                continue

            # Find pairwise complete observations and compute sums in one pass
            sum_i = 0.0
            sum_j = 0.0
            count = 0

            for k in range(n_obs):
                val_i = a[i, k]
                val_j = a[j, k]
                if not np.isnan(val_i) and not np.isnan(val_j):
                    sum_i += val_i
                    sum_j += val_j
                    count += 1

            if count > 1:
                # Compute means using only pairwise complete observations
                mean_i = sum_i / count
                mean_j = sum_j / count

                # Compute correlation components in second pass
                cov_sum = 0.0
                var_i_sum = 0.0
                var_j_sum = 0.0

                for k in range(n_obs):
                    val_i = a[i, k]
                    val_j = a[j, k]
                    if not np.isnan(val_i) and not np.isnan(val_j):
                        diff_i = val_i - mean_i
                        diff_j = val_j - mean_j
                        cov_sum += diff_i * diff_j
                        var_i_sum += diff_i * diff_i
                        var_j_sum += diff_j * diff_j

                # Use count - 1 for sample correlation
                var_i = var_i_sum / (count - 1)
                var_j = var_j_sum / (count - 1)

                if var_i > 0 and var_j > 0:
                    corr = cov_sum / (count - 1) / np.sqrt(var_i * var_j)
                    out[i, j] = corr
                    out[j, i] = corr  # Symmetric
                else:
                    out[i, j] = np.nan
                    out[j, i] = np.nan
            else:
                out[i, j] = np.nan
                out[j, i] = np.nan
",numbagg/funcs.py,
survived,"    async def test_get_prompt_on_parent_server(
        self,
        mcp_server: FastMCP,
        nested_mcp_server: FastMCP,
        recording_middleware: RecordingMiddleware,
        nested_middleware: RecordingMiddleware,
    ):
        mcp_server.mount(nested_mcp_server, prefix=""nested"")

        async with Client(mcp_server) as client:
            await client.get_prompt(""test_prompt"", {""x"": ""test""})

        assert recording_middleware.assert_called(times=3)
        assert recording_middleware.assert_called(method=""prompts/get"", times=3)
        assert recording_middleware.assert_called(hook=""on_message"", times=1)
        assert recording_middleware.assert_called(hook=""on_request"", times=1)
        assert recording_middleware.assert_called(hook=""on_get_prompt"", times=1)

        assert nested_middleware.assert_called(times=0)
",tests/server/middleware/test_middleware.py,TestNestedMiddlewareHooks
survived,"    async def test_list_resource_templates_on_nested_server(
        self,
        mcp_server: FastMCP,
        nested_mcp_server: FastMCP,
        recording_middleware: RecordingMiddleware,
        nested_middleware: RecordingMiddleware,
    ):
        mcp_server.mount(nested_mcp_server, prefix=""nested"")

        async with Client(mcp_server) as client:
            await client.list_resource_templates()

        assert recording_middleware.assert_called(times=3)
        assert recording_middleware.assert_called(
            method=""resources/templates/list"", times=3
        )
        assert recording_middleware.assert_called(hook=""on_message"", times=1)
        assert recording_middleware.assert_called(hook=""on_request"", times=1)
        assert recording_middleware.assert_called(
            hook=""on_list_resource_templates"", times=1
        )

        assert nested_middleware.assert_called(times=3)
        assert nested_middleware.assert_called(
            method=""resources/templates/list"", times=3
        )
        assert nested_middleware.assert_called(hook=""on_message"", times=1)
        assert nested_middleware.assert_called(hook=""on_request"", times=1)
        assert nested_middleware.assert_called(
            hook=""on_list_resource_templates"", times=1
        )",tests/server/middleware/test_middleware.py,TestNestedMiddlewareHooks
survived,"        async def progress_tool(context: Context) -> None:
            await context.report_progress(progress=1, total=10, message=""test"")
",tests/server/middleware/test_middleware.py,TestNestedMiddlewareHooks
survived,"        async def _handler(
            context: MiddlewareContext[mcp.types.GetPromptRequestParams],
        ) -> GetPromptResult:
            return await self._get_prompt(
                name=context.message.name,
                arguments=context.message.arguments,
            )
",src/fastmcp/server/server.py,FastMCP
deleted,"    async def _list_prompts(self, apply_middleware: bool = True) -> list[Prompt]:
        """"""
        List all available prompts.
        """"""

        if (prompts := self._cache.get(""prompts"")) is self._cache.NOT_FOUND:
            prompts: list[Prompt] = []

            # iterate such that new mounts overwrite older ones
            for mounted_server in self._mounted_servers:
                try:
                    if apply_middleware:
                        server_prompts = (
                            await mounted_server.server._middleware_list_prompts()
                        )
                    else:
                        server_prompts = await mounted_server.server._list_prompts()
                    # Apply prefix to each prompt key if prefix exists
                    if mounted_server.prefix:
                        for prompt in server_prompts:
                            prompt = prompt.with_key(
                                f""{mounted_server.prefix}_{prompt.key}""
                            )
                            prompts.append(prompt)
                    else:
                        prompts.extend(server_prompts)
                except Exception as e:
                    logger.warning(
                        f""Failed to get prompts from mounted server '{mounted_server.prefix}': {e}""
                    )
                    continue
            prompts.extend(self._prompt_manager.get_prompts().values())
            self._cache.set(""prompts"", prompts)
        return prompts
",src/fastmcp/server/server.py,FastMCP
deleted,"    async def _middleware_list_resource_templates(self) -> list[ResourceTemplate]:
        """"""
        List all available resource templates, in the format expected by the low-level MCP
        server.

        """"""

        async def _handler(
            context: MiddlewareContext[dict[str, Any]],
        ) -> list[ResourceTemplate]:
            templates = await self._list_resource_templates()

            mcp_templates: list[ResourceTemplate] = []
            for template in templates:
                if self._should_enable_component(template):
                    mcp_templates.append(template)

            return mcp_templates

        with fastmcp.server.context.Context(fastmcp=self) as fastmcp_ctx:
            # Create the middleware context.
            mw_context = MiddlewareContext(
                message={},  # List resource templates doesn't have parameters
                source=""client"",
                type=""request"",
                method=""resources/templates/list"",
                fastmcp_context=fastmcp_ctx,
            )

            # Apply the middleware chain.
            return await self._apply_middleware(mw_context, _handler)
",src/fastmcp/server/server.py,FastMCP
survived,"    async def test_read_resource_on_parent_server(
        self,
        mcp_server: FastMCP,
        nested_mcp_server: FastMCP,
        recording_middleware: RecordingMiddleware,
        nested_middleware: RecordingMiddleware,
    ):
        mcp_server.mount(nested_mcp_server, prefix=""nested"")

        async with Client(mcp_server) as client:
            await client.read_resource(""resource://test"")

        assert recording_middleware.assert_called(times=3)
        assert recording_middleware.assert_called(method=""resources/read"", times=3)
        assert recording_middleware.assert_called(hook=""on_message"", times=1)
        assert recording_middleware.assert_called(hook=""on_request"", times=1)
        assert recording_middleware.assert_called(hook=""on_read_resource"", times=1)

        assert nested_middleware.assert_called(times=0)
",tests/server/middleware/test_middleware.py,TestNestedMiddlewareHooks
survived,"    async def test_call_tool(
        self, mcp_server: FastMCP, recording_middleware: RecordingMiddleware
    ):
        async with Client(mcp_server) as client:
            await client.call_tool(""add"", {""a"": 1, ""b"": 2})

        assert recording_middleware.assert_called(times=3)
        assert recording_middleware.assert_called(method=""tools/call"", times=3)
        assert recording_middleware.assert_called(hook=""on_message"", times=1)
        assert recording_middleware.assert_called(hook=""on_request"", times=1)
        assert recording_middleware.assert_called(hook=""on_call_tool"", times=1)
",tests/server/middleware/test_middleware.py,TestMiddlewareHooks
survived,"def test_export_datasets_empty_database():
    """"""Test behavior with empty source database""""""
    with tempfile.TemporaryDirectory() as temp_dir:
        source_db_path = Path(temp_dir) / ""empty.db""
        target_db_path = Path(temp_dir) / ""target.db""
        export_path = Path(temp_dir) / ""exports""
        
        # Create empty database
        source_conn = connect(source_db_path)
        source_conn.close()
        
        # Run the export function
        result = export_datasets_and_create_metadata_db(
            source_db_path=source_db_path,
            target_db_path=target_db_path,
            export_path=export_path,
        )
        
        # Should return empty result
        assert result == {}
",tests/dataset/test_export_datasets_and_create_metadata_db.py,
survived,"            def _make_check(
                p: re.Pattern[str], r: GuardrailRule
            ) -> Callable[[str], Awaitable[str]]:
                if r.action is GuardrailAction.REDACT:

                    async def _check(text: str) -> str:
                        return p.sub(""[REDACTED]"", text)

                else:  # DENY or FLAG -> raise error on match

                    async def _check(text: str) -> str:
                        if p.search(text):
                            raise ValueError(f""Policy violation: {r.name}"")
                        return text

                return _check
",src/meta_agent/policy.py,PolicyChecker
survived,"    def add_from_config(self, config: GuardrailConfig) -> None:
        """"""Add checks from a :class:`GuardrailConfig`.""""""

        for rule in config.rules:
            pattern = re.compile(rule.pattern)

            def _make_check(
                p: re.Pattern[str], r: GuardrailRule
            ) -> Callable[[str], Awaitable[str]]:
                if r.action is GuardrailAction.REDACT:

                    async def _check(text: str) -> str:
                        return p.sub(""[REDACTED]"", text)

                else:  # DENY or FLAG -> raise error on match

                    async def _check(text: str) -> str:
                        if p.search(text):
                            raise ValueError(f""Policy violation: {r.name}"")
                        return text

                return _check

            self.checks.append(_make_check(pattern, rule))
",src/meta_agent/policy.py,PolicyChecker
survived,"def compute_hash(workbox: Path) -> str:
    data = workbox.read_bytes()
    digest = hashlib.sha384(data).digest()
    b64 = base64.b64encode(digest).decode()
    return f""sha384-{b64}""
",scripts/verify_workbox_hash.py,
survived,"    def boom(*_: object) -> None:
        raise NotImplementedError
",test/windows/test_shutdown.py,
survived,"def test_background_run_direct(tmp_path: Path, monkeypatch: pytest.MonkeyPatch) -> None:
    """"""Call the internal worker directly and verify progress and output.""""""

    monkeypatch.setenv(""SIM_RESULTS_DIR"", str(tmp_path))

    import importlib

    from src.interface import api_server as api

    api = importlib.reload(api)

    messages: list[dict[str, object]] = []

    class DummyWS:
        async def send_json(self, data: dict[str, object]) -> None:
            messages.append(data)

    ws = DummyWS()
    api._progress_ws.add(ws)

    sim_id = ""unit-test""
    cfg = api.SimRequest(horizon=1, pop_size=2, generations=1)
    asyncio.run(api._background_run(sim_id, cfg))

    api._progress_ws.discard(ws)

    assert (tmp_path / f""{sim_id}.json"").exists()
    assert messages and messages[0][""id""] == sim_id",tests/test_api_server.py,
survived,"    def test_main_happy_path(self, edge_parse, run_parse, apply_env, run):
        edge_parse.return_value = self._args()
        run_parse.return_value = argparse.Namespace()
        os.environ.pop(""PGHOST"", None)

        edge_runner.main()

        edge_parse.assert_called_once_with()
        run_parse.assert_called_once_with([
            ""--dev"",
            ""--port"",
            ""123"",
            ""--metrics-port"",
            ""456"",
            ""--a2a-port"",
            ""789"",
            ""--enabled"",
            ""A,B"",
            ""--cycle"",
            ""5"",
            ""--loglevel"",
            ""DEBUG"",
        ])
        apply_env.assert_called_once_with(run_parse.return_value)
        self.assertEqual(os.environ[""PGHOST""], ""sqlite"")
        run.assert_called_once_with()
",alpha_factory_v1/tests/test_edge_runner_main.py,EdgeRunnerMainInvokesRun
survived,"def _files_from_diff(diff: str) -> list[str]:
    files: set[str] = set()
    for line in diff.splitlines():
        if line.startswith(""+++"") or line.startswith(""---""):
            parts = line.split(maxsplit=1)
            if len(parts) != 2:
                continue
            path = parts[1]
            if path.startswith(""a/"") or path.startswith(""b/""):
                path = path[2:]
            files.add(path)
    return list(files)
",src/agents/self_improver_agent.py,
survived,"    def __init__(self, settings: config.Settings) -> None:
        super().__init__(settings)
        self.published: list[tuple[str, messaging.Envelope]] = []
",tests/test_safety_agent.py,CaptureBus
survived,"def test_blocked_payload_not_stored(tmp_path) -> None:
    """"""ChaosAgent payloads should be blocked and skipped by the memory.""""""

    cfg = config.Settings(bus_port=0)
    bus = CaptureBus(cfg)
    ledger = logging.Ledger(str(tmp_path / ""ledger.db""), broadcast=False)

    mem = FilteringMemoryAgent(bus, ledger, str(tmp_path / ""mem.log""))
    guardian = safety_agent.SafetyGuardianAgent(bus, ledger)
    chaos = chaos_agent.ChaosAgent(bus, ledger, burst=1)

    async def run() -> None:
        async with bus, ledger:
            await chaos.run_cycle()
            await asyncio.sleep(0)

    asyncio.run(run())

    memory_events = [env for topic, env in bus.published if topic == ""memory""]
    assert memory_events
    assert memory_events[-1].payload[""status""] == ""blocked""
    assert mem.records == []",tests/test_safety_agent.py,
survived,"    def __init__(
        self, 
        timeout: int = 60, 
        proxies: Optional[dict] = None
    ):
        """"""Initialize your PollinationsAI provider with custom settings

        Examples:
            >>> provider = PollinationsAI(timeout=30)
            >>> provider = PollinationsAI(proxies={""http"": ""http://proxy:8080""})

        Args:
            timeout (int): HTTP request timeout in seconds (default: 60)
            proxies (dict, optional): Proxy configuration for requests
        """"""
        self.image_gen_endpoint = ""https://image.pollinations.ai/prompt/{prompt}""
        self.headers = {
            ""Accept"": ""text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8"",
            ""Accept-Language"": ""en-US,en;q=0.5"",
            ""Accept-Encoding"": ""gzip, deflate"",
            ""User-Agent"": agent.random(),
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)
        if proxies:
            self.session.proxies.update(proxies)
            
        self.timeout = timeout
        self.prompt: str = ""AI-generated image - webscout""
        self.image_extension: str = ""jpeg""
",webscout/Provider/TTI/pollinations.py,PollinationsAI
survived,"    def create_token(self, path: Path) -> Dict[str, Any]:
        """"""Create a new authentication token""""""
        # Step 1: Generate Authentication Token
        auth_payload = {""clientType"": ""CLIENT_TYPE_ANDROID""}
        proxies = self.session.proxies if self.session.proxies else None
        
        auth_response = self.session.post(self.auth_url, json=auth_payload, timeout=self.timeout, proxies=proxies)
        auth_data = auth_response.json()
        auth_token = auth_data.get(""idToken"")
        
        if not auth_token:

            raise Exception(""Failed to obtain authentication token."")
        
        with open(path, 'w') as f:
            json.dump(auth_data, f)
        
        return auth_data
",webscout/Provider/TTI/aiarta.py,AIArtaImager
survived,"    def generate(
        self,
        prompt: str,
        max_retries: int = 3,
        retry_delay: int = 5,
    ) -> List[bytes]:
        """"""Generate some fire images from your prompt! ðŸŽ¨

        Args:
            prompt (str): Your image description
            max_retries (int): Max retry attempts if something fails (default: 3)
            retry_delay (int): Seconds to wait between retries (default: 5)

        Returns:
            List[bytes]: Your generated images as bytes

        Raises:
            ValueError: If the inputs ain't valid
            RequestException: If the API calls fail after retries
        """"""
        # Input validation
        if not prompt:
            raise ValueError(""Yo fam, the prompt can't be empty! ðŸ¤”"")

        self.prompt = prompt
        response = []
        
        # Get request ID
        data = {""prompt"": prompt}
        resp = self.session.post(self.request_id_endpoint, json=data, timeout=self.timeout)
        resp.raise_for_status()
        request_id = resp.json()[""requestId""]

        # Poll for results
        for attempt in range(max_retries):
            try:
                # Get image URLs
                resp = self.session.get(
                    f""{self.image_response_endpoint}?requestId={request_id}"",
                    timeout=self.timeout
                )
                resp.raise_for_status()
                image_data = resp.json()

                if ""results"" in image_data and len(image_data[""results""]) >= 2:
                    # Get provider names
                    provider_resp = self.session.post(
                        self.image_provider_endpoint,
                        json={""requestId"": request_id, ""preference"": 0},
                        timeout=self.timeout
                    )
                    provider_resp.raise_for_status()
                    provider_data = provider_resp.json()

                    # Download images
                    for i, url in enumerate(image_data[""results""][:2]):
                        img_resp = self.session.get(url, timeout=self.timeout)
                        img_resp.raise_for_status()
                        response.append(img_resp.content)
                    
                    break
                else:
                    if attempt == max_retries - 1:
                        raise RequestException(""Failed to get image results after max retries"")
                    time.sleep(retry_delay)

            except RequestException as e:
                if attempt == max_retries - 1:
                    raise
                time.sleep(retry_delay)

        return response
",webscout/Provider/TTI/imgsys.py,ImgSys
survived,"    def generate(
        self, 
        prompt: str,
        amount: int = 1,
        max_retries: int = 3,
        retry_delay: int = 5
    ) -> List[bytes]:
        """"""Generate some fire images from your prompt! ðŸŽ¨""""""
        if not prompt:
            raise ValueError(""Yo fam, prompt can't be empty! ðŸš«"")
        if not isinstance(amount, int) or amount < 1:
            raise ValueError(""Amount needs to be a positive number! ðŸ“ˆ"")

        self.prompt = prompt
        response = []

        for _ in range(amount):
            form_data = {
                ""prompt"": prompt,
                ""output_format"": ""bytes"",
                ""user_profile_id"": ""null"",
                ""anonymous_user_id"": str(uuid.uuid4()),
                ""request_timestamp"": time.time(),
                ""user_is_subscribed"": ""false"",
                ""client_id"": uuid.uuid4().hex,
            }

            for attempt in range(max_retries):
                try:
                    resp = self.session.post(
                        self.api_endpoint,
                        data=form_data,
                        timeout=self.timeout
                    )
                    resp.raise_for_status()
                    response.append(resp.content)
                    break
                except RequestException as e:
                    if attempt == max_retries - 1:
                        raise
                    time.sleep(retry_delay)

        return response
",webscout/Provider/TTI/magicstudio.py,MagicStudioImager
survived,"def numeric_grad(func, x, eps=1e-6):
    """"""Compute numeric gradient of scalar-valued function.""""""
    x = np.asarray(x, dtype=float)
    grad = np.zeros_like(x, dtype=float)
    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])
    while not it.finished:
        idx = it.multi_index
        orig = float(x[idx])
        x[idx] = orig + eps
        f_pos = func(x)
        x[idx] = orig - eps
        f_neg = func(x)
        grad[idx] = (f_pos - f_neg) / (2 * eps)
        x[idx] = orig
        it.iternext()
    return grad
",klongpy/autograd.py,
survived,"    async def close(self) -> None:
        """"""Close the underlying HTTP session.""""""
        await self._session.close()
",src/meta_agent/services/telemetry_client.py,TelemetryAPIClient
survived,"        def __init__(self, *_, **__):
            pass
",src/meta_agent/services/telemetry_client.py,TCPConnector
survived,"def test_form(monkeypatch):
    inputs = iter([""foo"", ""bar""])
    monkeypatch.setattr(""builtins.input"", lambda _: next(inputs))
    inter = Interactive()
    result = inter.form([""first"", ""second""])
    assert result == {""first"": ""foo"", ""second"": ""bar""}",tests/ux/test_interactive.py,
survived,"def test_ask(monkeypatch):
    inter = Interactive()
    monkeypatch.setattr(""builtins.input"", lambda _: ""answer"")
    assert inter.ask(""Question?"") == ""answer""
",tests/ux/test_interactive.py,
survived,"    def test_prom_metrics_stub(self):
        class Dummy:
            def __init__(self, *_, **__):
                self.label_arg = None
            def labels(self, name):
                self.label_arg = name
                return self
            def inc(self):
                pass
            def set(self, v):
                self.value = v
        orig_counter = base_mod.Counter
        orig_gauge = base_mod.Gauge
        base_mod.Counter = Dummy
        base_mod.Gauge = Dummy
        run, err, lat = base_mod._prom_metrics(""test"")
        self.assertIsInstance(run, Dummy)
        self.assertEqual(run.label_arg, ""test"")
        self.assertIsInstance(err, Dummy)
        self.assertIsInstance(lat, Dummy)
        base_mod.Counter = orig_counter
        base_mod.Gauge = orig_gauge
",tests/test_base_helpers.py,TestPromMetrics
survived,"    def test_ping_capability_present(self):
        # diagnostics capability should map to the ping agent
        from alpha_factory_v1.backend.agents.ping_agent import PingAgent
        meta = AgentMetadata(
            name=PingAgent.NAME,
            cls=PingAgent,
            version=""0"",
            capabilities=PingAgent.CAPABILITIES,
            compliance_tags=[],
        )
        register_agent(meta)
        agents = capability_agents(""diagnostics"")
        self.assertIn(""ping"", agents)
",tests/test_agents_registry.py,TestAgentRegistryFunctions
survived,"    def test_build_async_returns_ops(self):
        jobs = [[{""machine"": ""m1"", ""proc"": 2}, {""machine"": ""m2"", ""proc"": 3}]]
        req = {""jobs"": jobs, ""horizon"": 10}
        result = asyncio.run(self.agent._build_async(req))
        payload = json.loads(result)[""payload""]
        self.assertIn(""ops"", payload)
        self.assertIsInstance(payload[""ops""], list)
        self.assertGreaterEqual(payload[""horizon""], 5)
",tests/test_manufacturing_agent.py,TestManufacturingAgent
survived,"    def test_run_cycle_negative_delta_g_posts_job(self) -> None:
        class LowFin(demo.AgentFin):
            def latent_work(self, bundle):
                return 0.0

        class CaptureOrch(demo.Orchestrator):
            def __init__(self) -> None:
                self.called = False

            def post_alpha_job(self, bundle_id: int, delta_g: float) -> None:
                self.called = True

        orch = CaptureOrch()
        demo.run_cycle(
            orch,
            LowFin(),
            demo.AgentRes(),
            demo.AgentEne(),
            demo.AgentGdl(),
            DummyModel(),
        )
        self.assertTrue(orch.called)
",tests/test_alpha_agi_business_3_v1.py,TestAlphaAgiBusiness3Demo
survived,"    def test_cli_execution(self) -> None:
        result = subprocess.run(
            [sys.executable, ""-m"", ""alpha_factory_v1.demos.alpha_agi_business_3_v1.alpha_agi_business_3_v1"", ""--cycles"", ""1"", ""--loglevel"", ""warning""],
            capture_output=True,
            text=True,
        )
        self.assertEqual(result.returncode, 0, result.stderr)
",tests/test_alpha_agi_business_3_v1.py,TestAlphaAgiBusiness3Demo
survived,"            def latent_work(self, bundle):
                return 0.0
",tests/test_alpha_agi_business_3_v1.py,TestAlphaAgiBusiness3Demo.LowFin
survived,"    def test_play_episode(self):
        frames, reward = play_episode(self.mu, render=False, max_steps=10)
        self.assertIsInstance(frames, list)
        self.assertIsInstance(reward, float)
        self.assertLessEqual(len(frames), 10)
",tests/test_muzero_planning.py,TestMiniMu
survived,"async def _call_next(_: Request) -> Response:
    return Response(""ok"")
",tests/test_rate_limiter_eviction.py,
survived,"async def list_products(
    ctx: EnrichContext, category: str | None = None, page: int = 1, page_size: int = 20
) -> PageResult[ProductEnrichModel]:
    """"""List products with optional filtering by category.""""""
    session_factory = ctx.request_context.lifespan_context[""session_factory""]
    async with session_factory() as session:
        # Build query
        query = select(Product)
        if category:
            query = query.where(Product.category == category)

        # Get total count
        count_query = select(func.count()).select_from(query.subquery())
        total = await session.scalar(count_query)

        # Get paginated results
        query = query.offset((page - 1) * page_size).limit(page_size)
        result = await session.execute(query)
        products = result.scalars().all()

        items = [
            ProductEnrichModel(
                id=product.id,
                name=product.name,
                description=product.description,
                price=product.price,
                stock_quantity=product.stock_quantity,
                category=product.category,
                created_at=product.created_at,
            )
            for product in products
        ]

        return PageResult.create(
            items=items,
            page=page,
            page_size=page_size,
            total_items=total,
            has_next=page * page_size < total,
        )
",examples/sqlalchemy_shop/app.py,
survived,"    def test_full_ecommerce_model(self):
        """"""Test a complete e-commerce model setup.""""""

        class Base(DeclarativeBase):
            pass

        class User(Base, EnrichSQLAlchemyMixin):
            """"""User account in the system.""""""

            __tablename__ = ""users""

            id: Mapped[int] = mapped_column(primary_key=True, info={""description"": ""User ID""})
            email: Mapped[str] = mapped_column(unique=True, info={""description"": ""Email address""})
            username: Mapped[str] = mapped_column(info={""description"": ""Display name""})
            password_hash: Mapped[str] = mapped_column(info={""exclude"": True})
            created_at: Mapped[datetime] = mapped_column(
                info={""description"": ""Account creation time""}
            )
            is_active: Mapped[bool] = mapped_column(
                default=True, info={""description"": ""Account status""}
            )

            orders: Mapped[list[""Order""]] = relationship(
                back_populates=""user"", info={""description"": ""Orders placed by this user""}
            )
            reviews: Mapped[list[""Review""]] = relationship(
                back_populates=""user"", info={""description"": ""Product reviews by this user""}
            )

        class Product(Base, EnrichSQLAlchemyMixin):
            """"""Product in the catalog.""""""

            __tablename__ = ""products""

            id: Mapped[int] = mapped_column(primary_key=True, info={""description"": ""Product ID""})
            name: Mapped[str] = mapped_column(info={""description"": ""Product name""})
            description: Mapped[str | None] = mapped_column(
                Text, nullable=True, info={""description"": ""Product description""}
            )
            price: Mapped[float] = mapped_column(info={""description"": ""Product price""})
            stock_quantity: Mapped[int] = mapped_column(info={""description"": ""Available stock""})

            reviews: Mapped[list[""Review""]] = relationship(
                back_populates=""product"", info={""description"": ""Customer reviews""}
            )

        class Order(Base, EnrichSQLAlchemyMixin):
            """"""Customer order.""""""

            __tablename__ = ""orders""

            id: Mapped[int] = mapped_column(primary_key=True, info={""description"": ""Order ID""})
            user_id: Mapped[int] = mapped_column(ForeignKey(""users.id""))
            total_amount: Mapped[float] = mapped_column(info={""description"": ""Order total""})
            status: Mapped[str] = mapped_column(info={""description"": ""Order status""})
            created_at: Mapped[datetime] = mapped_column(info={""description"": ""Order date""})

            user: Mapped[User] = relationship(
                back_populates=""orders"", info={""description"": ""Customer who placed the order""}
            )

        class Review(Base, EnrichSQLAlchemyMixin):
            """"""Product review.""""""

            __tablename__ = ""reviews""

            id: Mapped[int] = mapped_column(primary_key=True)
            user_id: Mapped[int] = mapped_column(ForeignKey(""users.id""))
            product_id: Mapped[int] = mapped_column(ForeignKey(""products.id""))
            rating: Mapped[int] = mapped_column(info={""description"": ""Rating 1-5""})
            comment: Mapped[str | None] = mapped_column(
                Text, nullable=True, info={""description"": ""Review text""}
            )

            user: Mapped[User] = relationship(back_populates=""reviews"")
            product: Mapped[Product] = relationship(back_populates=""reviews"")

        # Convert all models
        UserEnrichModel = User.__enrich_model__()
        ProductEnrichModel = Product.__enrich_model__()
        OrderEnrichModel = Order.__enrich_model__()
        ReviewEnrichModel = Review.__enrich_model__()

        # Verify User model
        user_fields = UserEnrichModel.model_fields
        assert ""id"" in user_fields
        assert ""email"" in user_fields
        assert ""username"" in user_fields
        assert ""password_hash"" not in user_fields  # Should be excluded
        assert ""created_at"" in user_fields
        assert ""is_active"" in user_fields
        assert ""orders"" in user_fields
        assert ""reviews"" in user_fields

        # Verify relationships are properly typed
        assert isinstance(user_fields[""orders""].default, Relationship)
        assert isinstance(user_fields[""reviews""].default, Relationship)

        # Verify Order model
        order_fields = OrderEnrichModel.model_fields
        assert ""user"" in order_fields
        assert isinstance(order_fields[""user""].default, Relationship)

        # Verify all models are proper EnrichModels
        for model in [UserEnrichModel, ProductEnrichModel, OrderEnrichModel, ReviewEnrichModel]:
            assert issubclass(model, EnrichModel)",tests/test_sqlalchemy_integration.py,TestComplexScenarios
survived,"    def forward(self, x): return torch.tanh(self.l(x))
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,Repr
survived,"    def _parse(self, ep: str):
        if "":"" not in ep:
            raise ValueError(""Endpoint must be <backend>:<model>"")
        return ep.split("":"",1)
",alpha_factory_v1/demos/meta_agentic_agi/agents/agent_base.py,LMClient
survived,"    def _on(self, msg: dict):
        try:
            self.handle(msg)
        except Exception as exc:
            LOG.exception(""[%s] crash: %s"", self.name, exc)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,Agent
survived,"async def send_cmd(cmd:Dict[str,str]):
    A2ABus.publish(""orch"",cmd); return {""ok"":True}
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,
survived,"    def log():
        if not path.exists():
            return ""(no events yet)""
        return flask.escape(path.read_text(""utf-8""))
",alpha_factory_v1/demos/meta_agentic_agi/agents/agent_base.py,
survived,"    def acquire(self, cost: float = 1.0):
        while True:
            now = time.perf_counter()
            elapsed = now - self._last
            self._last = now
            self._allow = min(self._tps, self._allow + elapsed * self._tps)
            if self._allow >= cost:
                self._allow -= cost
                return
            sleep = (cost - self._allow) / self._tps + 1e-3
            time.sleep(sleep)
",alpha_factory_v1/demos/meta_agentic_agi_v2/agents/agent_base.py,RateLimiter
survived,"    def __init__(self, tps: float = 3.0):
        self._tps = float(tps)
        self._allow = self._tps
        self._last = time.perf_counter()
",alpha_factory_v1/demos/meta_agentic_agi/agents/agent_base.py,RateLimiter
survived,"    def __init__(self, hidden: int, act_dim: int):
        super().__init__(); self.v = nn.Linear(hidden, 1); self.p = nn.Linear(hidden, act_dim)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,Pred
survived,"    def handle(self, msg: dict):  # to be overridden
        raise NotImplementedError
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,Agent
survived,"    def update(self, **kw):
        for k, v in kw.items():
            if hasattr(self, k):
                setattr(self, k, v)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,Config
survived,"def test_csv_parser(tmp_path):
    csv_file = tmp_path / ""data.csv""
    csv_file.write_text(""a,b\n1,2\n3,4\n"", encoding=""utf-8"")
    parser = CsvParser(file_path=str(csv_file))
    result = parser.parse(file_path=str(csv_file))
    assert result[""title""] == ""csv""
    assert ""a"" in result[""content""]
    assert result[""lifecycle""][0][""life_metadata""][""source_file""] == str(csv_file)
",tests/test_csv_parser.py,
survived,"def verify_commitment(
    activations_path: str, commitment: str, challenge: int = CHALLENGE
) -> bool:
    """"""Verify polynomial commitment against activations.""""""
    expected = commit_activations(activations_path, challenge)
    return expected == commitment.lower()
",src/zklora/polynomial_commit.py,
survived,"def test_list_ids_with_tags(populated_db):
    command = ListIdsCommand(
        tags=[""programming""],
        limit=10,
        db_path=populated_db,
    )

    results = list_ids(command)

    assert len(results) == 4
    for expected in [""python-1"", ""sql-1"", ""testing-1"", ""regex-1""]:
        assert expected in results
",src/mcp_server_pocket_pick/tests/functionality/test_list_ids.py,
survived,"    def publish(self, topic: str, env: messaging.Envelope) -> None:
        self.published.append((topic, env))
",tests/test_codegen_safety.py,DummyBus
survived,"        def recurrent(self, state, action):
            return None, 0.0, 0.0, None
",alpha_factory_v1/demos/muzero_planning/minimuzero.py,MiniMuNet
survived,"    def value(self) -> float:
        return self.value_sum / self.visit_count if self.visit_count else 0.0
",alpha_factory_v1/demos/muzero_planning/minimuzero.py,Node
survived,"def submit_job(path: str | Path, host: str = DEFAULT_HOST, port: int = DEFAULT_PORT) -> None:
    """"""Convenience wrapper to submit a job from a JSON file.""""""
    job = load_job(path)
    MarketplaceClient(host, port).queue_job(job)
",alpha_factory_v1/demos/alpha_agi_marketplace_v1/marketplace.py,
survived,"    def do_POST(self):
        length = int(self.headers.get(""Content-Length"", 0))
        type(self).received_body = self.rfile.read(length)
        type(self).received_path = self.path
        self.send_response(200)
        self.end_headers()
        self.wfile.write(b""ok"")
",alpha_factory_v1/tests/test_marketplace_client.py,_Handler
survived,"    def setUp(self):
        self.orc = DummyOrchestrator()
        # Force PingAgent to use the lightweight AgentBase implementation so we
        # can instantiate it without heavy dependencies.
        ping_agent.PingAgent.__bases__ = (NewAgentBase,)
        self.agent = ping_agent.PingAgent()
        self.agent.orchestrator = self.orc
",alpha_factory_v1/tests/test_ping_agent.py,PingAgentTest
survived,"    def test_ensure_dir(self):
        with tempfile.TemporaryDirectory() as tmp:
            path = Path(tmp) / 'd'
            preflight.ensure_dir(path)
            self.assertTrue(path.exists())
",alpha_factory_v1/tests/test_preflight.py,PreflightTest
survived,"    def test_build_env_removes_secrets(self):
        env = {
            'TOKEN': 'x',
            'my_secret': 'y',
            'PASSWORD': 'z',
            'KEY': 'k',
            'OTHER': 'ok',
        }
        with mock.patch.dict(os.environ, env, clear=True):
            cleaned = local_pytest._build_env()
            self.assertNotIn('TOKEN', cleaned)
            self.assertNotIn('my_secret', cleaned)
            self.assertNotIn('PASSWORD', cleaned)
            self.assertNotIn('KEY', cleaned)
            self.assertEqual(cleaned['OTHER'], 'ok')
",alpha_factory_v1/tests/test_local_pytest.py,LocalPytestUtilsTest
survived,"    def test_run_pytest_invokes_runner(self):
        fake = Path('.')
        with mock.patch('alpha_factory_v1.backend.tools.local_pytest.Path.exists', return_value=True):
            with mock.patch('alpha_factory_v1.backend.tools.local_pytest._run_pytest', return_value={'returncode':0,'passed':True,'duration_sec':0,'stdout':'','stderr':'','cmd':'py'}) as rp:
                out = local_pytest.run_pytest({}, path=str(fake))
        rp.assert_called_once()
        self.assertTrue(out['passed'])
        self.assertEqual(out['returncode'], 0)
",alpha_factory_v1/tests/test_local_pytest.py,LocalPytestUtilsTest
survived,"            def fake_distribution(name):
                self.assertEqual(name, ""requests"")
                return Dist()
",alpha_factory_v1/tests/test_requests_import.py,RequestsImportTest
survived,"    def setUp(self):
        for key in (""OPENAI_API_KEY"", ""ANTHROPIC_API_KEY"", ""LOCAL_LLM_BASE""):
            os.environ.pop(key, None)
",alpha_factory_v1/tests/test_memory_provider.py,ModelProviderStubTest
survived,"    def test_stub_backend(self):
        provider = ModelProvider()
        self.assertEqual(provider.backend[0], ""stub"")
        out = provider.complete(""hello"")
        self.assertIsInstance(out, str)
        self.assertTrue(out)
",alpha_factory_v1/tests/test_memory_provider.py,ModelProviderStubTest
survived,"    def test_falls_back_to_unittest(self):
        with mock.patch('importlib.util.find_spec', return_value=None):
            with mock.patch('subprocess.call', return_value=0) as call:
                argv = sys.argv
                sys.argv = ['run_tests.py', 'tests']
                try:
                    with self.assertRaises(SystemExit):
                        run_tests.main()
                finally:
                    sys.argv = argv
                call.assert_called_once()
                cmd = call.call_args.args[0]
                self.assertIn('unittest', cmd)
                self.assertIn('tests', cmd[-1])
",alpha_factory_v1/tests/test_run_tests_script.py,RunTestsScriptTest
survived,"def test_evaluate_flow(monkeypatch, tmp_path):
    fake_rc = MagicMock()
    collection = CollectionResult(exit_code=0, stdout='out', stderr='err', duration=1.0)
    fake_rc.execute_and_collect.return_value = collection
    fake_reporter = MagicMock()
    fake_reporter.generate_report.return_value = 'REPORT'

    harness = EvaluationHarness(fake_rc, fake_reporter)
    result = harness.evaluate(tmp_path, timeout=5, output_format='json')

    assert result == 'REPORT'
    fake_rc.execute_and_collect.assert_called_with(tmp_path, timeout=5)
    fake_reporter.generate_report.assert_called_with(collection, output_format='json')
",tests/unit/test_evaluation_harness.py,
survived,"    def test_missing_version_fails(self) -> None:
        for name in (""openai_agents"", ""agents""):
            with self.subTest(module=name):
                self.assertFalse(self._run_check(name, None))
",tests/test_preflight_openai_agents_version.py,TestPreflightOpenAIAgentsVersion
survived,"def test_run_macro_demo_help() -> None:
    """"""`run_macro_demo.sh --help` should exit successfully.""""""
    subprocess.run([str(RUN_SCRIPT), ""--help""], check=True, capture_output=True)",tests/test_macro_compose_config.py,
survived,"    def test_stub_when_sdk_missing(self) -> None:
        os.environ.pop(""OPENAI_API_KEY"", None)
        sys.modules.pop(""agents"", None)
        sys.modules.pop(""alpha_factory_v1.backend.agent_factory"", None)
        importlib.invalidate_caches()

        orig_import_module = importlib.import_module

        def _fake_import(name: str, *args: object, **kwargs: object) -> object:
            if name == ""agents"":
                raise ModuleNotFoundError
            return orig_import_module(name, *args, **kwargs)

        with mock.patch(""importlib.import_module"", side_effect=_fake_import):
            af = orig_import_module(""alpha_factory_v1.backend.agent_factory"")
            af = importlib.reload(af)
            agent = af.build_core_agent(name=""t"", instructions=""demo"")

        self.assertTrue(hasattr(agent, ""run""))
        self.assertEqual(agent.run(""hi""), ""[t-stub] echo: hi"")
        self.assertFalse(any(isinstance(t, af.ComputerTool) for t in af.DEFAULT_TOOLS))
",tests/test_build_core_agent.py,TestBuildCoreAgent
survived,"def example5(b1, b2):
    if b1:
        None
    else:
        if b2:
            None
        else:
            None",tests/rosetta/transpiler/Python/conditional-structures-5.py,
survived,"def newLife(w, h):
    a = newField(w, h)
    i = 0
    while i < (w * h // 2):
        setCell(a, randN(w), randN(h), True)
        i = i + 1
    return Life(a=a, b=newField(w, h), w=w, h=h)
",tests/rosetta/transpiler/Python/conways-game-of-life.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/constrained-random-points-on-a-circle-1.py,
survived,"def newField(w, h):
    rows = []
    y = 0
    while y < h:
        row = []
        x = 0
        while x < w:
            row = row + [False]
            x = x + 1
        rows = rows + [row]
        y = y + 1
    return Field(s=rows, w=w, h=h)
",tests/rosetta/transpiler/Python/conways-game-of-life.py,
survived,"def gcd(a, b):
    x = a
    if x < 0:
        x = -x
    y = b
    if y < 0:
        y = -y
    while y != 0:
        t = x % y
        x = y
        y = t
    return x
",tests/rosetta/transpiler/Python/convert-decimal-number-to-rational.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/concurrent-computing-3.py,
survived,"def cfPi(nTerms):
    f = []
    n = 0
    while n < nTerms:
        g = 2 * n - 1
        f = f + [newTerm(6, g * g)]
        n = n + 1
    if nTerms > 0:
        f[0][""a""] = 3
    return f
",tests/rosetta/transpiler/Python/continued-fraction.py,
survived,"def cfSqrt2(nTerms):
    f = []
    n = 0
    while n < nTerms:
        f = f + [newTerm(2, 1)]
        n = n + 1
    if nTerms > 0:
        f[0][""a""] = 1
    return f
",tests/rosetta/transpiler/Python/continued-fraction.py,
survived,"def newTerm(a, b):
    return {""a"": a, ""b"": b}
",tests/rosetta/transpiler/Python/continued-fraction.py,
survived,"def example3(a, b):
    if a:
        None
    else:
        if b:
            None",tests/rosetta/transpiler/Python/conditional-structures-3.py,
survived,"    def __str__(self) -> str:
        lines = [f""# Data Model: {self.title}""]
        if self.description:
            lines.append(self.description)
        lines.append("""")
        if self.entities:
            lines.append(""## Entities"")
            for e in sorted(self.entities, key=lambda ent: ent.name):
                lines.append(f""- [{e.name}](#{e.name.lower()})"")
            lines.append("""")
            for e in sorted(self.entities, key=lambda ent: ent.name):
                lines.append(str(e))
        else:
            lines.append(""*No entities registered*"")
        return ""\n"".join(lines)
",src/enrichmcp/datamodel.py,ModelDescription
survived,"def test_evonet_activation_applied_once() -> None:
    g = me.Genome(layers=(3,), activation=""sigmoid"")
    net = me.EvoNet(2, 1, g)
    x = torch.randn(1, 2)
    out = net(x)

    h = x
    for layer in net.model:
        h = me._ACT[g.activation](layer(h))

    assert torch.allclose(out, h)
",tests/test_evo_net_activation.py,
survived,"def check_network(host: str = ""pypi.org"", timeout: float = 2.0) -> bool:
    """"""Return True if *host* can be resolved within *timeout* seconds.""""""
    try:
        with suppress(Exception):
            prev = socket.getdefaulttimeout()
        socket.setdefaulttimeout(timeout)
        socket.gethostbyname(host)
    except Exception:
        banner(
            f""WARNING: Unable to resolve {host}. Use --wheelhouse for offline installs."",
            ""YELLOW"",
        )
        return False
    finally:
        with suppress(Exception):
            socket.setdefaulttimeout(prev)
    banner(f""{host} resolved"", ""GREEN"")
    return True
",alpha_factory_v1/scripts/preflight.py,
survived,"def test_planning_agent_no_openai_sdk() -> None:
    """"""Agent should run even when openai.agents is missing.""""""
    from alpha_factory_v1.demos.alpha_agi_insight_v1.src.utils import config, messaging
    from alpha_factory_v1.demos.alpha_agi_insight_v1.src.agents import planning_agent

    class DummyLedger:
        def __init__(self, *_a, **_kw) -> None:
            pass

        def log(self, _env) -> None:  # type: ignore[override]
            pass

        def start_merkle_task(self, *_a, **_kw) -> None:
            pass

        async def stop_merkle_task(self) -> None:
            pass

        def close(self) -> None:
            pass

    settings = config.Settings(bus_port=0, openai_api_key=""k"")
    bus = messaging.A2ABus(settings)
    agent = planning_agent.PlanningAgent(bus, DummyLedger())

    assert agent.oai_ctx is None
    asyncio.run(agent.run_cycle())",tests/test_agents.py,
survived,"    async def aspan(self, agent_name: str, phase: str, **payload: Any) -> Generator[None, None, None]:
        """"""Async variant of :meth:`span`.""""""
        start = _dt.datetime.utcnow()
        try:
            yield
        finally:
            duration = (_dt.datetime.utcnow() - start).total_seconds() * 1000
            payload[""duration_ms""] = round(duration, 3)
            await self.arecord(agent_name, phase, payload)
",alpha_factory_v1/backend/tracer.py,Tracer
survived,"    def __init__(self, *a, **k):
        pass
",tests/test_selfheal_entrypoint_offline.py,DummyBlocks
survived,"    def __init__(self, *a, **k):
        pass
",tests/test_selfheal_entrypoint_offline.py,DummyMarkdown
survived,"    def launch(self, *a, **k):
        pass
",tests/test_selfheal_entrypoint_offline.py,DummyBlocks
survived,"def test_build_vocab():
    corpus = [
        [""first"", ""document"", ""hello"", ""world""],
        [""second"", ""document"", ""world"", ""big"", ""bright""],
    ]

    vocab, index = run_hlda.build_vocab(corpus)
    expected_vocab = [""big"", ""bright"", ""document"", ""first"", ""hello"", ""second"", ""world""]
    expected_index = {w: i for i, w in enumerate(expected_vocab)}
    assert vocab == expected_vocab
    assert index == expected_index
",tests/test_run_hlda_utils.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/user_type_literal.py,Book
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/user_type_literal.py,Person
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/left_join.py,Order
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/inner_join.py,Customer
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/group_by_conditional_sum.py,Item
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/cross_join.py,Customer
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/group_by_left_join.py,Auto1
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/group_by_sort.py,Auto1
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/group_by_multi_join.py,Auto1
survived,"        def set_draw_color(self, *args, **kwargs):
            pass
",tests/conftest.py,DummyFPDF
survived,"        def add_font(self, *args, **kwargs):
            pass
",tests/conftest.py,DummyFPDF
survived,"        def add_page(self):
            pass
",tests/conftest.py,DummyFPDF
survived,"    def Histogram(name: str, desc: str, labels=None):  # type: ignore[misc]
        return _get_metric(_Histogram, name, desc, labels)
",alpha_factory_v1/backend/agents/__init__.py,
survived,"def test_governance_bridge_port_arg() -> None:
    """"""Verify the CLI accepts the --port option.""""""
    result = subprocess.run(
        [""governance-bridge"", ""--port"", ""1234"", ""--help""],
        capture_output=True,
        text=True,
        check=True,
    )
    assert result.returncode == 0",tests/test_governance_bridge_cli.py,
survived,"    def visit_FunctionDef(self, node: ast.FunctionDef) -> None:
        if node.name == ""main"":
            for stmt in node.body:
                if isinstance(stmt, ast.Global):
                    continue
                self.visit(stmt)
            return
        if node.name.startswith(""test_""):
            name = node.name[5:]
            self.emit(f'test ""{name}"" {{')
            self.indent += 1
            for stmt in node.body:
                if isinstance(stmt, ast.Global):
                    continue
                self.visit(stmt)
            self.indent -= 1
            self.emit(""}"")
            return
        args = [
            f""{arg.arg}: {self.convert_type(arg.annotation)}"" for arg in node.args.args
        ]
        ret = self.convert_type(node.returns)
        self.emit(f""fun {node.name}({', '.join(args)}): {ret} {{"")
        call_info = self.parse_callable(node.returns)
        prev = self.current_callable
        if call_info:
            self.current_callable = call_info
        self.indent += 1
        for stmt in node.body:
            if isinstance(stmt, ast.Global):
                continue
            self.visit(stmt)
        self.indent -= 1
        self.emit(""}"")
        self.current_callable = prev
",tools/any2mochi/py/py2mochi.py,Converter
deleted,"def clear_tool_stats() -> None:
    with _lock:
        _tool_stats.clear()",src/serena/analytics.py,
survived,"def test_sqlalchemy_type_to_python_extra_types():
    assert _sqlalchemy_type_to_python(JSON()) is dict
    assert _sqlalchemy_type_to_python(LargeBinary()) is bytes
    assert _sqlalchemy_type_to_python(Time()) is time

    class MyInt(Integer):
        pass

    assert _sqlalchemy_type_to_python(MyInt()) is int

    class Custom(TypeEngine):
        pass

    assert _sqlalchemy_type_to_python(Custom()) is Any",tests/test_sqlalchemy_utils.py,
survived,"    def Button(self, *a, **k):
        return DummyButton()
",tests/test_agent_experience_entrypoint.py,DummyBlocks
survived,"        def __call__(self, *_a, **_k):
            return ""ok""
",tests/test_selfheal_env.py,FakeAgent
survived,"    def __init__(self, *a, **k):
        pass
",tests/test_selfheal_env.py,DummyButton
survived,"    def __enter__(self):
        return self
",tests/test_selfheal_env.py,DummyBlocks
survived,"    def test_ingest_and_step_concurrent(self) -> None:
        async def run_tasks() -> None:
            queue: asyncio.Queue[dict[str, Any]] = asyncio.Queue()

            async def ingest_loop() -> None:
                async for evt in demo.experience_stream():
                    await queue.put(evt)
                    break

            async def step_once() -> None:
                evt = await queue.get()
                self.assertIsInstance(evt, dict)

            await asyncio.gather(ingest_loop(), step_once())

        try:
            asyncio.run(run_tasks())
        except RuntimeError as exc:  # pragma: no cover - fail if raised
            self.fail(f""RuntimeError raised: {exc}"")
",tests/test_era_experience.py,TestEraOfExperience
survived,"def _allow_local_code() -> bool:
    """"""Check both new and legacy opts for enabling local PythonTool.""""""
    return (
        os.getenv(ALLOW_LOCAL_CODE_ENV)
        or os.getenv(LEGACY_ALLOW_LOCAL_CODE_ENV)
    ) == ""1""
",alpha_factory_v1/backend/agent_factory.py,
survived,"def init_config(env_file: str = "".env"") -> None:
    """"""Load environment variables and refresh :data:`CFG`.""""""

    _load_dotenv(env_file)
    _prefetch_vault()
    global CFG
    CFG = Settings()
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/config.py,
survived,"    def my_op():
        call = call_context.get_current_call()
        call.summary[""foo""] = 1
        call.summary[""bar""] = 2
        return ""done""
",tests/trace/test_current_call.py,
survived,"    def __init__(self, num_levels, vocab, parent=None, level=0,
                 random_state=None):

        self.node_id = NCRPNode.last_node_id
        NCRPNode.last_node_id += 1

        self.customers = 0
        self.parent = parent
        self.children = []
        self.level = level
        self.total_words = 0
        self.num_levels = num_levels

        self.vocab = np.array(vocab)
        self.word_counts = np.zeros(len(vocab))

        if random_state is None:
            self.random_state = RandomState()
        else:
            self.random_state = random_state
",src/hlda/sampler.py,NCRPNode
survived,"def load_documents(data_dir: str):
    """"""Load and preprocess all text files under *data_dir*.""""""
    corpus = []
    for filename in sorted(glob.glob(os.path.join(data_dir, ""*.txt""))):
        with open(filename, ""r"", encoding=""utf-8"", errors=""ignore"") as f:
            text = f.read().lower()
        tokens = [t for t in TOKEN_RE.findall(text) if t not in STOPWORDS]
        corpus.append(tokens)
    return corpus
",scripts/run_hlda.py,
survived,"def test_cross_industry_script_idempotent(tmp_path: Path) -> None:
    result = _run_script(tmp_path)
    first_services = result[""first""].get(""services"", {})
    second_services = result[""second""].get(""services"", {})
    assert first_services == second_services
    assert len(second_services) == len(set(second_services))",tests/test_cross_industry_patch.py,
survived,"    def test_infer_fastmcp_server(self, fastmcp_server):
        """"""FastMCP server instances should infer to FastMCPTransport.""""""
        transport = infer_transport(fastmcp_server)
        assert isinstance(transport, FastMCPTransport)
",tests/client/test_client.py,TestInferTransport
survived,"    def run(
        self,
        input_data: Input,
        *,
        credentials: APIKeyCredentials,
        **kwargs,
    ) -> BlockOutput:
        seed = input_data.seed
        result = self.run_model(
            api_key=credentials.api_key,
            model_name=input_data.model.api_name,
            prompt=input_data.prompt,
            input_image=input_data.input_image,
            aspect_ratio=input_data.aspect_ratio.value,
            seed=seed,
        )
        yield ""image_url"", result
",autogpt_platform/backend/backend/blocks/flux_kontext.py,AIImageEditorBlock
survived,"    def __init__(self):
        super().__init__(
            id=""3fd9c73d-4370-4925-a1ff-1b86b99fabfa"",
            description=(
                ""Edit images using BlackForest Labs' Flux Kontext models. Provide a prompt ""
                ""and optional reference image to generate a modified image.""
            ),
            categories={BlockCategory.AI, BlockCategory.MULTIMEDIA},
            input_schema=AIImageEditorBlock.Input,
            output_schema=AIImageEditorBlock.Output,
            test_input={
                ""prompt"": ""Add a hat to the cat"",
                ""input_image"": ""https://example.com/cat.png"",
                ""aspect_ratio"": AspectRatio.MATCH_INPUT_IMAGE,
                ""seed"": None,
                ""model"": FluxKontextModelName.PRO,
                ""credentials"": TEST_CREDENTIALS_INPUT,
            },
            test_output=[
                (""image_url"", ""https://replicate.com/output/edited-image.png""),
            ],
            test_mock={
                ""run_model"": lambda api_key, model_name, prompt, input_image, aspect_ratio, seed: ""https://replicate.com/output/edited-image.png"",
            },
            test_credentials=TEST_CREDENTIALS,
        )
",autogpt_platform/backend/backend/blocks/flux_kontext.py,AIImageEditorBlock
survived,"            def add(self, instr: object) -> ""DummyTx"":
                self.instructions.append(instr)
                return self
",tests/test_merkle_broadcast.py,TestMerkleBroadcast.DummyTx
survived,"            def __init__(self, program_id: object, data: bytes, keys: list[object]):
                self.data = data
",tests/test_merkle_broadcast.py,TestMerkleBroadcast.DummyInstr
survived,"            async def close(self) -> None:  # pragma: no cover - dummy
                pass
",tests/test_merkle_broadcast.py,TestMerkleBroadcast.DummyClient
survived,"    def _dummy_classes(self, raise_err=False):
        captured = {}

        class DummyClient:
            def __init__(self, url: str) -> None:
                captured[""url""] = url

            async def send_transaction(self, tx: object, *args: object) -> None:
                if raise_err:
                    raise RuntimeError(""fail"")
                captured[""root""] = tx.instructions[0].data.decode()

            async def close(self) -> None:  # pragma: no cover - dummy
                pass

        class DummyTx:
            def __init__(self) -> None:
                self.instructions = []

            def add(self, instr: object) -> ""DummyTx"":
                self.instructions.append(instr)
                return self

        class DummyInstr:
            def __init__(self, program_id: object, data: bytes, keys: list[object]):
                self.data = data

        class DummyPk:
            def __init__(self, val: str) -> None:  # pragma: no cover - dummy
                pass

        return captured, DummyClient, DummyTx, DummyInstr, DummyPk
",tests/test_merkle_broadcast.py,TestMerkleBroadcast
survived,"def test_impact_score() -> None:
    facts = CapsuleFacts(market_size=100, efficiency_gain=0.1, llm_score=0.6)
    scorer = ImpactScorer(llm_weight=0.5)
    score = scorer.score(facts, 0.2)
    assert score == 100 * 0.2 * (1 + 0.5 * 0.6)",tests/test_impact_scorer.py,
survived,"        def _tool(*_a: object, **_k: object) -> Callable[[object], object]:
            def dec(f: object) -> object:
                return f

            return dec
",tests/test_alpha_opportunity_stub.py,TestAlphaOpportunityStub
survived,"            def __init__(self, *a: object, port: int = 5001, **_k: object) -> None:
                captured[""port""] = port
",tests/test_alpha_opportunity_stub.py,TestAlphaOpportunityStub.DummyRuntime
survived,"def test_refinement_rejected_patch(tmp_path: Path) -> None:
    repo = _make_repo(tmp_path)
    logs = tmp_path / ""logs""
    logs.mkdir()
    (logs / ""log.json"").write_text(
        ""\n"".join([
            '{""hash"":""h0"",""ts"":0}',
            '{""hash"":""h1"",""ts"":1}',
            '{""hash"":""h2"",""ts"":5}'
        ]),
        encoding=""utf-8"",
    )

    reg = StakeRegistry()
    reg.set_stake(""meta"", 1.0)

    with patch.object(harness, ""vote_and_merge"", return_value=False):
        agent = MetaRefinementAgent(repo, logs, reg)
        merged = agent.refine()

    assert not merged
    assert (repo / ""metric.txt"").read_text().strip() == ""1""",tests/test_meta_refinement_agent.py,
survived,"def test_compute_merkle_root_with_malformed_row(tmp_path: Path) -> None:
    ledger = Ledger(str(tmp_path / ""ledger.db""), broadcast=False)
    e1 = messaging.Envelope(sender=""a"", recipient=""b"", payload={""v"": 1}, ts=0.0)
    e2 = messaging.Envelope(sender=""b"", recipient=""c"", payload={""v"": 2}, ts=1.0)
    ledger.log(e1)
    ledger.log(e2)
    # insert invalid hash value
    ledger.conn.execute(
        ""INSERT INTO messages (ts, sender, recipient, payload, hash) VALUES (?, ?, ?, ?, ?)"",
        (2.0, ""x"", ""y"", ""{}"", ""zz""),
    )
    ledger.conn.commit()
    with pytest.raises(ValueError):
        ledger.compute_merkle_root()
",tests/test_ledger_corruption.py,
survived,"def verify(wheel_path: Path) -> bool:
    """"""Return ``True`` if ``wheel_path`` verifies against its ``.sig`` file.""""""
    sig_path = wheel_path.with_suffix(wheel_path.suffix + "".sig"")
    if not sig_path.is_file():
        print(f""Signature file not found: {sig_path}"", file=sys.stderr)
        return False
    pub_b64 = agents_mod._WHEEL_PUBKEY
    with tempfile.NamedTemporaryFile(delete=False) as tmp:
        tmp.write(base64.b64decode(pub_b64))
        tmp.flush()
        pub_path = tmp.name
    try:
        digest = subprocess.run(
            [""openssl"", ""dgst"", ""-sha512"", ""-binary"", str(wheel_path)],
            check=True,
            capture_output=True,
        ).stdout
        res = subprocess.run(
            [
                ""openssl"",
                ""pkeyutl"",
                ""-verify"",
                ""-pubin"",
                ""-inkey"",
                pub_path,
                ""-sigfile"",
                str(sig_path),
            ],
            input=digest,
        )
        return res.returncode == 0
    finally:
        os.unlink(pub_path)
",alpha_factory_v1/scripts/verify_wheel_sig.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q10.py,Nation
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q13.py,Order
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q22.py,Customer
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q2.py,Region
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q10.py,Auto1
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q16.py,Supplier
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q3.py,Lineitem
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q8.py,Region
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q9.py,Auto9
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q30.py,Auto4
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q15.py,Auto5
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q21.py,Auto4
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q16.py,Auto1
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q29.py,Auto11
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q27.py,Auto5
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q7.py,Auto8
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q22.py,Auto8
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q23.py,Auto5
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q24.py,Auto3
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q23.py,Auto7
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q19.py,Auto4
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q21.py,Auto4
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q30.py,Auto7
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q29.py,Auto9
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q16.py,Auto3
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/job/compiler/py/q13.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q7.py,Auto6
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q15.py,Auto8
survived,"def _min(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""min() expects list or group"")
    vals = [it for it in v if it is not None]
    if not vals:
        return 0
    return min(vals)
",tests/dataset/job/compiler/py/q25.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q20.py,Auto6
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q28.py,Auto12
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/job/compiler/py/q16.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q16.py,Auto9
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q22.py,Auto9
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q19.py,Auto9
survived,"def _min(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""min() expects list or group"")
    vals = [it for it in v if it is not None]
    if not vals:
        return 0
    return min(vals)
",tests/dataset/job/compiler/py/q29.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q26.py,Auto3
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q19.py,Auto10
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q7.py,Auto2
survived,"def _min(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""min() expects list or group"")
    vals = [it for it in v if it is not None]
    if not vals:
        return 0
    return min(vals)
",tests/dataset/job/compiler/py/q27.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q7.py,Auto3
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q24.py,Auto7
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/job/compiler/py/q26.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q26.py,Auto9
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q15.py,Auto2
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q8.py,Auto5
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q27.py,Auto8
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q20.py,Auto4
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q32.py,Auto6
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q16.py,Auto7
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q17.py,Auto5
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q10.py,Auto9
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/job/compiler/py/q20.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q19.py,Auto8
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q30.py,Auto1
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q5.py,Auto4
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/job/compiler/py/q28.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q19.py,Auto1
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/job/compiler/py/q15.py,
survived,"def test_Q30_finds_violent_horror_thriller_movies_with_male_writer():
    assert result == [
        Auto1(
            movie_budget=""Horror"",
            movie_votes=2000,
            writer=""John Writer"",
            complete_violent_movie=""Violent Horror"",
        )
    ]
",tests/dataset/job/compiler/py/q30.py,
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/job/compiler/py/q33.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q79.py,Auto2
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q25.py,_Group
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q79.py,HouseholdDemographic
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q42.py,StoreSale
survived,"def _sort_key(k):
    if hasattr(k, ""__dataclass_fields__""):
        return str(k)
    if isinstance(k, list):
        return tuple((_sort_key(x) for x in k))
    if isinstance(k, tuple):
        return tuple((_sort_key(x) for x in k))
    if isinstance(k, dict):
        return str(k)
    return k
",tests/dataset/tpc-ds/compiler/py/q36.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q79.py,Auto3
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q21.py,Auto1
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q17.py,Auto1
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q17.py,_Group
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q3.py,_Group
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q97.py,StoreSale
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q24.py,Store
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q32.py,CatalogSale
survived,"def test_TPCDS_Q90_ratio():
    assert result == 2.0
",tests/dataset/tpc-ds/compiler/py/q90.py,
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q7.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q23.py,CatalogSale
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q48.py,DateDim
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q12.py,DateDim
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q25.py,_Group
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q72.py,Warehouse
survived,"def _q0():
    _groups = {}
    _order = []
    for j in joined:
        _k = Auto3(
            i_item_id=j.i_item_id,
            ca_country=j.ca_country,
            ca_state=j.ca_state,
            ca_county=j.ca_county,
        )
        _ks = str(_k)
        g = _groups.get(_ks)
        if not g:
            g = _Group(_k)
            _groups[_ks] = g
            _order.append(_ks)
        g.Items.append(j)
    _items1 = [_groups[k] for k in _order]
    return [
        Auto1(
            i_item_id=g.key[""i_item_id""],
            ca_country=g.key[""ca_country""],
            ca_state=g.key[""ca_state""],
            ca_county=g.key[""ca_county""],
            agg1=(
                sum([x.q for x in g]) / len([x.q for x in g]) if [x.q for x in g] else 0
            ),
            agg2=(
                sum([x.lp for x in g]) / len([x.lp for x in g])
                if [x.lp for x in g]
                else 0
            ),
            agg3=(
                sum([x.cp for x in g]) / len([x.cp for x in g])
                if [x.cp for x in g]
                else 0
            ),
            agg4=(
                sum([x.sp for x in g]) / len([x.sp for x in g])
                if [x.sp for x in g]
                else 0
            ),
            agg5=(
                sum([x.np for x in g]) / len([x.np for x in g])
                if [x.np for x in g]
                else 0
            ),
            agg6=(
                sum([x.by for x in g]) / len([x.by for x in g])
                if [x.by for x in g]
                else 0
            ),
            agg7=(
                sum([x.dep for x in g]) / len([x.dep for x in g])
                if [x.dep for x in g]
                else 0
            ),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q18.py,
survived,"def _q2():
    _groups = {}
    _order = []
    for f in filtered:
        _k = f.i_class
        _ks = str(_k)
        g = _groups.get(_ks)
        if not g:
            g = _Group(_k)
            _groups[_ks] = g
            _order.append(_ks)
        g.Items.append(f)
    _items1 = [_groups[k] for k in _order]
    return [Auto4(_class=g.key, total=sum([x.itemrevenue for x in g])) for g in _items1]
",tests/dataset/tpc-ds/compiler/py/q20.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q59.py,SalesYear1
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q72.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q92.py,WebSale
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q96.py,TimeDim
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q18.py,_Group
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q10.py,CustomerDemographic
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q39.py,DateDim
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q14.py,Auto2
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q14.py,CatalogSale
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q98.py,DateDim
survived,"def test_TPCDS_Q93_active_sales():
    assert result == [
        Auto1(ss_customer_sk=1, sumsales=40.0),
        Auto1(ss_customer_sk=2, sumsales=60.0),
    ]
",tests/dataset/tpc-ds/compiler/py/q93.py,
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q93.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q65.py,StoreSale
survived,"def test_TPCDS_Q12_revenue_ratio():
    assert result == [
        Auto1(
            i_item_id=""ITEM1"",
            i_item_desc=""Item One"",
            i_category=""A"",
            i_class=""C1"",
            i_current_price=10.0,
            itemrevenue=200.0,
            revenueratio=50.0,
        ),
        Auto1(
            i_item_id=""ITEM2"",
            i_item_desc=""Item Two"",
            i_category=""A"",
            i_class=""C1"",
            i_current_price=20.0,
            itemrevenue=200.0,
            revenueratio=50.0,
        ),
    ]
",tests/dataset/tpc-ds/compiler/py/q12.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q9.py,StoreSale
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q79.py,HouseholdDemographic
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q55.py,DateDim
survived,"def _q3():
    _groups = {}
    _order = []
    for u in union:
        _k = u.get(""item"") if isinstance(u, dict) else getattr(u, ""item"")
        _ks = str(_k)
        g = _groups.get(_ks)
        if not g:
            g = _Group(_k)
            _groups[_ks] = g
            _order.append(_ks)
        g.Items.append(u)
    _items1 = [_groups[k] for k in _order]
    return [
        Auto1(
            i_item_id=g.key,
            total_sales=_sum(
                [
                    x.get(""total"") if isinstance(x, dict) else getattr(x, ""total"")
                    for x in g
                ]
            ),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q56.py,
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q25.py,
survived,"def _q0():
    _src = store_sales
    _rows = _query(
        _src,
        [
            {
                ""items"": customer_demographics,
                ""on"": lambda ss, cd: ss.ss_cdemo_sk == cd.cd_demo_sk,
            },
            {
                ""items"": date_dim,
                ""on"": lambda ss, cd, d: ss.ss_sold_date_sk == d.d_date_sk,
            },
            {""items"": store, ""on"": lambda ss, cd, d, s: ss.ss_store_sk == s.s_store_sk},
            {""items"": item, ""on"": lambda ss, cd, d, s, i: ss.ss_item_sk == i.i_item_sk},
        ],
        {
            ""select"": lambda ss, cd, d, s, i: (ss, cd, d, s, i),
            ""where"": lambda ss, cd, d, s, i: (
                (
                    (cd.cd_gender == ""F"" and cd.cd_marital_status == ""M"")
                    and cd.cd_education_status == ""College""
                )
                and d.d_year == 2000
            )
            and s.s_state in [""CA""],
        },
    )
    _groups = _group_by(
        _rows, lambda ss, cd, d, s, i: Auto2(item_id=i.i_item_id, state=s.s_state)
    )
    _items1 = _groups
    _items1 = sorted(
        _items1, key=lambda g: _sort_key([g.key[""item_id""], g.key[""state""]])
    )
    return [
        Auto1(
            i_item_id=g.key[""item_id""],
            s_state=g.key[""state""],
            agg1=(
                sum([x[0].ss_quantity for x in g]) / len([x[0].ss_quantity for x in g])
                if [x[0].ss_quantity for x in g]
                else 0
            ),
            agg2=(
                sum([x[0].ss_list_price for x in g])
                / len([x[0].ss_list_price for x in g])
                if [x[0].ss_list_price for x in g]
                else 0
            ),
            agg3=(
                sum([x[0].ss_coupon_amt for x in g])
                / len([x[0].ss_coupon_amt for x in g])
                if [x[0].ss_coupon_amt for x in g]
                else 0
            ),
            agg4=(
                sum([x[0].ss_sales_price for x in g])
                / len([x[0].ss_sales_price for x in g])
                if [x[0].ss_sales_price for x in g]
                else 0
            ),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q27.py,
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q33.py,_Group
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q26.py,_Group
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q56.py,Auto1
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q57.py,Item
survived,"def test_TPCDS_Q53_simplified():
    assert result == [
        Auto1(i_manufact_id=1, sum_sales=20.0),
        Auto1(i_manufact_id=2, sum_sales=53.0),
    ]
",tests/dataset/tpc-ds/compiler/py/q53.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q44.py,Auto1
survived,"def test_TPCDS_Q79_simplified():
    assert result == [
        Auto1(
            c_last_name=""Smith"",
            c_first_name=""Alice"",
            s_city=""CityA"",
            ss_ticket_number=1,
            amt=5.0,
            profit=10.0,
        )
    ]
",tests/dataset/tpc-ds/compiler/py/q79.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q78.py,C
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q23.py,
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q46.py,_Group
survived,"def _sum(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""sum() expects list or group"")
    s = 0.0
    for it in v:
        if it is None:
            continue
        if isinstance(it, (int, float)):
            s += float(it)
        else:
            raise Exception(""sum() expects numbers"")
    return s
",tests/dataset/tpc-ds/compiler/py/q2.py,
survived,"def test_TPCDS_Q11_growth():
    assert result == [
        Auto1(customer_id=""C1"", customer_first_name=""John"", customer_last_name=""Doe"")
    ]
",tests/dataset/tpc-ds/compiler/py/q11.py,
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q73.py,_Group
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q67.py,StoreSale
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q10.py,CustomerAddres
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q20.py,_Group
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q2.py,_Group
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q76.py,Item
survived,"def _q2():
    _groups = {}
    _order = []
    for ss in store_sales:
        _k = ss.ss_customer_sk
        _ks = str(_k)
        g = _groups.get(_ks)
        if not g:
            g = _Group(_k)
            _groups[_ks] = g
            _order.append(_ks)
        g.Items.append(ss)
    _items1 = [_groups[k] for k in _order]
    return [
        Auto2(cust=g.key, sales=sum([x.ss_quantity * x.ss_sales_price for x in g]))
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q23.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q13.py,CustomerAddress
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q33.py,Item
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q91.py,CatalogReturn
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q56.py,_Group
survived,"def test_TPCDS_Q85_sample():
    assert result == 85.0
",tests/dataset/tpc-ds/compiler/py/q85.py,
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q74.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q42.py,Auto2
survived,"def test_TPCDS_Q42_simplified():
    assert result == [
        Auto1(
            d_year=2020,
            i_category_id=200,
            i_category=""CatB"",
            sum_ss_ext_sales_price=20.0,
        ),
        Auto1(
            d_year=2020,
            i_category_id=100,
            i_category=""CatA"",
            sum_ss_ext_sales_price=10.0,
        ),
    ]
",tests/dataset/tpc-ds/compiler/py/q42.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q40.py,Auto2
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q91.py,DateDim
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q33.py,WebSale
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q95.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q76.py,StoreSale
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q71.py,DateDim
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q70.py,Store
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q26.py,CustomerDemographic
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q55.py,
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q18.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q27.py,StoreSale
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q13.py,_Group
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q11.py,Customer
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q70.py,DateDim
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q70.py,_Group
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q74.py,Auto1
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q29.py,Auto2
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q16.py,
survived,"def _sort_key(k):
    if hasattr(k, ""__dataclass_fields__""):
        return str(k)
    if isinstance(k, list):
        return tuple((_sort_key(x) for x in k))
    if isinstance(k, tuple):
        return tuple((_sort_key(x) for x in k))
    if isinstance(k, dict):
        return str(k)
    return k
",tests/dataset/tpc-ds/compiler/py/q6.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q98.py,Auto2
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q30.py,DateDim
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q77.py,Auto4
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q54.py,Customer
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q18.py,Item
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q19.py,Customer
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q26.py,Promotion
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q10.py,Auto1
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q54.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q48.py,CustomerAddres
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q40.py,DateDim
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q19.py,Store
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q94.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q45.py,Item
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q77.py,Auto5
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q72.py,CatalogSale
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q91.py,DateDim
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q21.py,Auto3
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q25.py,DateDim
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q40.py,Warehouse
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q40.py,_Group
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q79.py,Auto1
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q29.py,Store
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q73.py,Auto2
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q22.py,Auto1
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q4.py,WebSale
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q75.py,DateDim
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q45.py,WebSale
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q57.py,_Group
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q22.py,
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q15.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q45.py,Customer
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q55.py,Item
survived,"def _q0():
    _src = all_rows
    _rows = _query(_src, [], {""select"": lambda r: r})
    _groups = _group_by(
        _rows,
        lambda r: Auto3(
            channel=r.get(""channel"") if isinstance(r, dict) else getattr(r, ""channel""),
            col_name=(
                r.get(""col_name"") if isinstance(r, dict) else getattr(r, ""col_name"")
            ),
            d_year=r.get(""d_year"") if isinstance(r, dict) else getattr(r, ""d_year""),
            d_qoy=r.get(""d_qoy"") if isinstance(r, dict) else getattr(r, ""d_qoy""),
            i_category=(
                r.get(""i_category"") if isinstance(r, dict) else getattr(r, ""i_category"")
            ),
        ),
    )
    _items1 = _groups
    _items1 = sorted(_items1, key=lambda g: _sort_key(g.key[""channel""]))
    return [
        Auto1(
            channel=g.key[""channel""],
            col_name=g.key[""col_name""],
            d_year=g.key[""d_year""],
            d_qoy=g.key[""d_qoy""],
            i_category=g.key[""i_category""],
            sales_cnt=len(g),
            sales_amt=_sum(
                [
                    (
                        (x.get(""r"") if isinstance(x, dict) else getattr(x, ""r"")).get(
                            ""ext_sales_price""
                        )
                        if isinstance(
                            x.get(""r"") if isinstance(x, dict) else getattr(x, ""r""), dict
                        )
                        else getattr(
                            x.get(""r"") if isinstance(x, dict) else getattr(x, ""r""),
                            ""ext_sales_price"",
                        )
                    )
                    for x in g
                ]
            ),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q76.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q37.py,Auto1
survived,"def _q0():
    _src = store_sales
    _rows = _query(
        _src,
        [
            {
                ""items"": item,
                ""on"": lambda ss, i: ss.item == i.i_item_sk and i.i_manager_id == 1,
            },
            {
                ""items"": date_dim,
                ""on"": lambda ss, i, d: (
                    ss.sold_date == d.d_date_sk and d.d_year == 2001
                )
                and d.d_moy == 11,
            },
        ],
        {""select"": lambda ss, i, d: (ss, i, d)},
    )
    _groups = _group_by(
        _rows,
        lambda ss, i, d: Auto2(year=d.d_year, brand_id=i.i_brand_id, brand=i.i_brand),
    )
    _items1 = _groups
    return [
        Auto1(
            d_year=g.key[""year""],
            brand_id=g.key[""brand_id""],
            ext_price=sum([x[0].price for x in g]),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q52.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q97.py,CatalogSale
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q64.py,StoreReturn
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q46.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q77.py,Auto6
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q81.py,_Group
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q3.py,StoreSale
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q17.py,Store
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q12.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q57.py,Auto2
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q16.py,CallCenter
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q71.py,CatalogSale
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q98.py,Auto2
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q84.py,CustomerAddres
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q10.py,CustomerDemographics
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q43.py,Auto3
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q85.py,WebReturn
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q19.py,Customer
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q29.py,StoreSale
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q35.py,DateDim
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q34.py,DateDim
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q22.py,DateDim
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q53.py,Item
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q1.py,StoreReturn
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q6.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q80.py,StoreSale
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q43.py,StoreSale
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q76.py,StoreSale
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q52.py,StoreSale
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q28.py,_Group
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q63.py,Auto2
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q20.py,Auto4
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q12.py,Auto2
survived,"def _sort_key(k):
    if hasattr(k, ""__dataclass_fields__""):
        return str(k)
    if isinstance(k, list):
        return tuple((_sort_key(x) for x in k))
    if isinstance(k, tuple):
        return tuple((_sort_key(x) for x in k))
    if isinstance(k, dict):
        return str(k)
    return k
",tests/dataset/tpc-ds/compiler/py/q37.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q90.py,HouseholdDemographic
survived,"def _sort_key(k):
    if hasattr(k, ""__dataclass_fields__""):
        return str(k)
    if isinstance(k, list):
        return tuple((_sort_key(x) for x in k))
    if isinstance(k, tuple):
        return tuple((_sort_key(x) for x in k))
    if isinstance(k, dict):
        return str(k)
    return k
",tests/dataset/tpc-ds/compiler/py/q52.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q37.py,Auto2
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q50.py,StoreReturn
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q29.py,Auto1
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q77.py,StoreSale
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q88.py,Store
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q99.py,Auto2
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q53.py,Auto1
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q26.py,Item
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q54.py,Auto3
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q40.py,Auto2
survived,"def _q0():
    _src = item
    _rows = _query(
        _src,
        [
            {
                ""items"": union_sales,
                ""on"": lambda i, s: (
                    s.get(""item_sk"") if isinstance(s, dict) else getattr(s, ""item_sk"")
                )
                == i.i_item_sk,
            },
            {
                ""items"": time_dim,
                ""on"": lambda i, s, t: t.t_time_sk
                == (s.get(""time_sk"") if isinstance(s, dict) else getattr(s, ""time_sk"")),
            },
        ],
        {
            ""select"": lambda i, s, t: (i, s, t),
            ""where"": lambda i, s, t: i.i_manager_id == 1
            and (t.t_meal_time == ""breakfast"" or t.t_meal_time == ""dinner""),
        },
    )
    _groups = _group_by(
        _rows,
        lambda i, s, t: Auto3(
            brand_id=i.i_brand_id, brand=i.i_brand, t_hour=t.t_hour, t_minute=t.t_minute
        ),
    )
    _items1 = _groups
    _items1 = sorted(
        _items1,
        key=lambda g: _sort_key(
            [
                -_sum(
                    [
                        (
                            x[1].get(""ext_price"")
                            if isinstance(x[1], dict)
                            else getattr(x[1], ""ext_price"")
                        )
                        for x in g
                    ]
                ),
                g.key[""brand_id""],
            ]
        ),
    )
    return [
        Auto1(
            i_brand_id=g.key[""brand_id""],
            i_brand=g.key[""brand""],
            t_hour=g.key[""t_hour""],
            t_minute=g.key[""t_minute""],
            ext_price=_sum(
                [
                    (
                        x[1].get(""ext_price"")
                        if isinstance(x[1], dict)
                        else getattr(x[1], ""ext_price"")
                    )
                    for x in g
                ]
            ),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q71.py,
survived,"def test_TPCDS_Q33_simplified():
    assert result == [
        Auto1(i_manufact_id=1, total_sales=150.0),
        Auto1(i_manufact_id=2, total_sales=50.0),
    ]
",tests/dataset/tpc-ds/compiler/py/q33.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q46.py,HouseholdDemographic
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q95.py,CustomerAddress
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q39.py,Auto2
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q95.py,Auto2
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q72.py,Inventory
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q78.py,Auto1
survived,"    async def async_step_user(self, user_input: dict | None = None) -> FlowResult:
        """"""Handle the initial step.""""""
        if user_input is not None:
            self._data.update(user_input)
            return self.async_create_entry(title=user_input.get(CONF_NAME) or ""Gree Climate"", data=self._data)

        data_schema = vol.Schema(
            {
                vol.Required(CONF_HOST): str,
                vol.Required(CONF_MAC): str,
                vol.Required(CONF_PORT, default=DEFAULT_PORT): int,
                vol.Optional(CONF_NAME): str,
                vol.Optional(CONF_TIMEOUT, default=DEFAULT_TIMEOUT): int,
                vol.Optional(CONF_ENCRYPTION_KEY): str,
                vol.Optional(CONF_UID): int,
                vol.Optional(CONF_ENCRYPTION_VERSION, default=1): int,
            }
        )
        return self.async_show_form(step_id=""user"", data_schema=data_schema)
",custom_components/gree/config_flow.py,ConfigFlow
survived,"def test_insight_bundle_sri() -> None:
    repo = Path(__file__).resolve().parents[1]
    insight_dir = repo / ""docs"" / ""alpha_agi_insight_v1""
    bundle = insight_dir / ""insight.bundle.js""
    html = insight_dir / ""index.html""

    digest = hashlib.sha384(bundle.read_bytes()).digest()
    expected = ""sha384-"" + base64.b64encode(digest).decode()

    text = html.read_text()
    match = re.search(r""<script[^>]*src=['\""]insight.bundle.js['\""][^>]*>"", text)
    assert match, ""script tag for insight.bundle.js missing""
    sri = re.search(r""integrity=['\""]([^'\""]+)['\""]"", match.group(0))
    assert sri, ""integrity attribute missing""
    assert sri.group(1) == expected",tests/test_insight_sri.py,
survived,"    def dispatch_request(self, request: Request) -> Response:
        try:
            return self.run(request=request)
        except HTTPException as e:
            return Response(text=e.reason, status=e.status_code)
",src/graphql_server/webob/views.py,GraphQLView
survived,"    async def _graphql_request(
        self,
        method: Literal[""get"", ""post""],
        query: Optional[str] = None,
        operation_name: Optional[str] = None,
        variables: Optional[dict[str, object]] = None,
        files: Optional[dict[str, BytesIO]] = None,
        headers: Optional[dict[str, str]] = None,
        extensions: Optional[dict[str, Any]] = None,
        **kwargs: Any,
    ) -> ClientResponse:
        body = self._build_body(
            query=query,
            operation_name=operation_name,
            variables=variables,
            files=files,
            method=method,
            extensions=extensions,
        )

        data: Union[dict[str, object], str, None] = None

        url = ""/graphql""

        if body and files:
            body.update({name: (file, name) for name, file in files.items()})

        if method == ""get"":
            body_encoded = urllib.parse.urlencode(body or {})
            url = f""{url}?{body_encoded}""
        else:
            if body:
                data = body if files else json.dumps(body)
            kwargs[""body""] = data

        headers = self._get_headers(method=method, headers=headers, files=files)

        return await self.request(url, method, headers=headers, **kwargs)
",src/tests/http/clients/webob.py,WebobHttpClient
survived,"def sha384(path: Path) -> str:
    digest = hashlib.sha384(path.read_bytes()).digest()
    return ""sha384-"" + base64.b64encode(digest).decode()
",tests/test_sw_integrity.py,
survived,"    def test_run_with_data_dir(self) -> None:
        data_dir = Path(
            ""alpha_factory_v1/demos/macro_sentinel/offline_samples""
        ).as_posix()
        result = subprocess.run(
            [
                sys.executable,
                ""alpha_factory_v1/demos/era_of_experience/alpha_report.py"",
                ""--data-dir"",
                data_dir,
            ],
            capture_output=True,
            text=True,
        )
        self.assertEqual(result.returncode, 0, result.stderr)
        self.assertIn(""Alpha signals"", result.stdout)
",tests/test_alpha_report_cli.py,TestAlphaReportCLI
survived,"def select_parent_weighted(population: Sequence[Any]) -> Any:
    """"""Return a parent weighted by fitness Ã— children-with-edit-ability.""""""
    if not population:
        raise ValueError(""population is empty"")
    weights = []
    for ind in population:
        fitness = float(getattr(ind, ""fitness"", getattr(ind, ""score"", 0.0)))
        edits = float(getattr(ind, ""edit_children_count"", 0.0))
        weights.append(max(fitness * edits, 0.0))
    total = sum(weights)
    if total <= 0:
        index = int(np.random.choice(len(population)))
    else:
        probs = np.asarray(weights, dtype=float) / total
        index = int(np.random.choice(len(population), p=probs))
    metrics.dgm_parents_selected_total.inc()
    return population[index]
",src/archive/selector.py,
survived,"def _safe_extract(tf: tarfile.TarFile, target_dir: Path) -> None:
    """"""Safely extract tar members inside ``target_dir``.""""""
    base = target_dir.resolve()
    for member in tf.getmembers():
        dest = (base / member.name).resolve()
        if not str(dest).startswith(str(base)):
            raise HTTPException(status_code=400, detail=""Unsafe path in archive"")
    tf.extractall(base)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/evolution_worker.py,
survived,"def fix_file(path: str):
    with open(path, 'r', encoding='utf-8') as f:
        lines = f.readlines()

    in_code = False
    changed = False

    for i, line in enumerate(lines):
        stripped = line.strip()
        if stripped.startswith('```') or stripped.startswith('~~~'):
            in_code = not in_code
            continue
        if not in_code and line.startswith('# '):
            title = line[2:].rstrip('\n')
            new_title = title_case(title)
            if new_title != title:
                lines[i] = '# ' + new_title + '\n'
                changed = True
            break

    if changed:
        with open(path, 'w', encoding='utf-8') as f:
            f.writelines(lines)
        print(f'Updated {path}')
",scripts/fix_titlecase.py,
survived,"def makeAdder(n):
    def adder(x):
        return x + n
    return adder
",tests/human/python/closure.py,
survived,"    def adder(x):
        return x + n
",tests/human/x/python/closure.py,
survived,"def test_taxonomy_mine_and_prune(tmp_path: Path) -> None:
    js_out = tmp_path / 'taxonomy.js'
    subprocess.run([
        'tsc', '--target', 'es2020', '--module', 'es2020', TAXONOMY_TS, '--outFile', js_out
    ], check=True)

    script = tmp_path / 'run.mjs'
    script.write_text(
        f""import {{ mineTaxonomy, pruneTaxonomy }} from '{js_out.resolve().as_posix()}';\n""
        ""const runs = [\n""
        ""  {params:{sector:'A'}},\n""
        ""  {params:{sector:'B'}},\n""
        ""  {params:{sector:'A'}}\n""
        ""];\n""
        ""let g = mineTaxonomy(runs);\n""
        ""g = pruneTaxonomy(g, new Set(['A']));\n""
        ""console.log(JSON.stringify(g));\n""
    )
    result = subprocess.run(['node', script], capture_output=True, text=True, check=True)
    data = json.loads(result.stdout)
    assert set(data['nodes'].keys()) == {'A'}",tests/test_taxonomy.py,
survived,"def test_pareto_entropy(tmp_path: Path) -> None:
    js_out = tmp_path / ""entropy.js""
    subprocess.run([
        ""tsc"",
        ""--target"",
        ""es2020"",
        ""--module"",
        ""es2020"",
        ENTROPY_TS,
        ""--outFile"",
        js_out,
    ], check=True)

    script = tmp_path / ""run.mjs""
    script.write_text(
        f""import {{ paretoEntropy }} from '{js_out.resolve().as_posix()}';\n""
        ""const pts = [{logic:0.1,feasible:0.1},{logic:0.9,feasible:0.9}];\n""
        ""console.log(paretoEntropy(pts,2).toFixed(2));\n"",
        encoding=""utf-8"",
    )
    res = subprocess.run([""node"", script], capture_output=True, text=True, check=True)
    assert res.stdout.strip() == ""1.00""",tests/test_entropy_ts.py,
survived,"                def patched_curl_request(session_self, method, url, *a, **kw):
                    if self._proxies and 'proxies' not in kw:
                        kw['proxies'] = self._proxies
                    return self._original_curl_session_request(session_self, method, url, *a, **kw)
",webscout/Provider/TTI/base.py,_GlobalProxyManager
survived,"        def get_proxied_curl_session(impersonate=""chrome120"", **kw):
            if CurlSession:
                return CurlSession(proxies=proxies, impersonate=impersonate, **kw)
            raise ImportError(""curl_cffi is not installed"")
",webscout/Provider/TTI/base.py,ProxyAutoMeta
survived,"def is_linux():
    return platform.system() == 'Linux'
",build.py,
survived,"    def tearDown(self) -> None:
        AGENT_REGISTRY.clear()
        AGENT_REGISTRY.update(self._backup)
",tests/test_demo_registration.py,TestRegisterDemoAgents
survived,"    def test_future_regressor_alignment(self):
        forecast_length = 5
        df = load_daily(long=False).iloc[:50]
        df = df.drop(df.index[5])
        reg_df = df[[df.columns[0]]].copy()
        reg_train, _ = create_lagged_regressor(
            reg_df,
            forecast_length=forecast_length,
            frequency='infer',
            scale=False,
            summarize=None,
            backfill='bfill',
            fill_na='pchip',
        )
        reg_train = reg_train.iloc[forecast_length:]
        df_train = df.iloc[forecast_length:]
        model = AutoTS(
            forecast_length=forecast_length,
            max_generations=1,
            num_validations=1,
            validation_method='backwards',
            model_list=['LastValueNaive'],
            transformer_list=[],
            verbose=0,
        )
        model = model.fit(df_train, future_regressor=reg_train)
        self.assertEqual(
            model.future_regressor_train.shape[0],
            model.df_wide_numeric.shape[0],
        )",tests/test_regressor.py,FutureRegressorAlignmentTest
survived,"    def run_tests(self, path: Path, timeout: int = 60) -> ExecutionResult:
        """"""Execute tests located at ``path`` inside the sandbox.""""""
        exit_code, stdout, stderr = self.sandbox_manager.run_code_in_sandbox(
            code_directory=path,
            command=[""pytest"", ""-vv""],
            timeout=timeout,
        )
        return ExecutionResult(exit_code=exit_code, stdout=stdout, stderr=stderr)",src/meta_agent/evaluation/execution.py,ExecutionModule
survived,"def test_skip_backup_when_local_has_no_space(tmp_path):
    db_path = tmp_path / ""db.sqlite""
    config[""storage""][""database""] = str(db_path)

    conn = sqlite3.connect(db_path)
    conn.execute(""CREATE TABLE t(id INTEGER)"")
    conn.commit()
    conn.close()

    output = tmp_path / ""backup.sqlite""

    with (
        patch(
            ""pioreactor.actions.leader.backup_database.long_running_managed_lifecycle"",
            dummy_lifecycle,
        ),
        patch(
            ""pioreactor.actions.leader.backup_database.create_logger"",
            return_value=MagicMock(),
        ),
        patch(
            ""pioreactor.actions.leader.backup_database._local_available_space"",
            return_value=0,
        ),
        patch(
            ""sqlite3.connect"",
        ) as mock_connect,
    ):
        backup_database(str(output), force=True, backup_to_workers=0)
        mock_connect.assert_not_called()",pioreactor/tests/test_backup_database.py,
survived,"def test_unsubscribe_stops_delivery():
    asyncio.run(_run_unsubscribe())",tests/test_trace_hub.py,
survived,"async def _async_fn(x):
    await asyncio.sleep(0)
    return x * 2
",tests/test_agent_runner_utils.py,
survived,"    async def _run_output_guardrails(
        cls,
        guardrails: list[OutputGuardrail[TContext]],
        agent: Agent[TContext],
        agent_output: Any,
        context: RunContextWrapper[TContext],
    ) -> list[OutputGuardrailResult]:
        if not guardrails:
            return []

        guardrail_tasks = [
            asyncio.create_task(
                RunImpl.run_single_output_guardrail(guardrail, agent, agent_output, context)
            )
            for guardrail in guardrails
        ]

        guardrail_results = []

        for done in asyncio.as_completed(guardrail_tasks):
            result = await done
            if result.output.tripwire_triggered:
                # Cancel all guardrail tasks if a tripwire is triggered.
                for t in guardrail_tasks:
                    t.cancel()
                _error_tracing.attach_error_to_current_span(
                    SpanError(
                        message=""Guardrail tripwire triggered"",
                        data={""guardrail"": result.guardrail.get_name()},
                    )
                )
                raise OutputGuardrailTripwireTriggered(result)
            else:
                guardrail_results.append(result)

        return guardrail_results
",src/agents/run.py,DefaultAgentRunner
survived,"    async def policy(self, obs, ctx):  # type: ignore[override]
        if isinstance(obs, dict):
            action = obs.get(""action"")
            if action == ""discover"":
                return await self.tools.discover(obs.get(""num"", 1))
            if action == ""recent"":
                return await self.tools.recent_log(obs.get(""limit"", 5))
        return await self.tools.list_samples()
",alpha_factory_v1/demos/cross_industry_alpha_factory/openai_agents_bridge.py,CrossIndustryAgent
survived,"def main() -> None:
    try:
        check_env.main([""--auto-install""])
    except Exception as exc:  # pragma: no cover - optional network failure
        print(f""âš ï¸  Environment check failed: {exc}"")

    env = os.environ.copy()
    port = env.get(""PORT"", ""8000"")
    cmd = [sys.executable, ""run_business_v1_local.py"", ""--bridge""]
    proc = subprocess.Popen(cmd, cwd=SCRIPT_DIR, env=env)

    url = f""http://localhost:{port}/docs""
    for _ in range(20):
        if proc.poll() is not None:
            break
        try:
            import requests

            if requests.get(f""http://localhost:{port}/healthz"", timeout=1).status_code == 200:
                break
        except Exception:
            time.sleep(0.5)
    try:
        webbrowser.open(url, new=1)
    except Exception:
        print(f""Open {url} to access the dashboard"")
    try:
        proc.wait()
    except KeyboardInterrupt:
        proc.terminate()
        proc.wait()
",alpha_factory_v1/demos/alpha_agi_business_v1/start_alpha_business.py,
survived,"def test_agent_macro_entrypoint_custom_base_url(monkeypatch: pytest.MonkeyPatch) -> None:
    stub = ModuleType(""openai_agents"")
    captured = {}

    class DummyOpenAI:
        def __init__(self, *a, **kw) -> None:
            captured[""base_url""] = kw.get(""base_url"")

    stub.Agent = object
    stub.OpenAIAgent = DummyOpenAI
    stub.Tool = lambda *_a, **_k: (lambda f: f)
    monkeypatch.setitem(sys.modules, ""openai_agents"", stub)
    monkeypatch.setenv(""OPENAI_API_KEY"", """")
    monkeypatch.setenv(""OLLAMA_BASE_URL"", ""http://example.com/v1"")

    mod_path = ""alpha_factory_v1.demos.macro_sentinel.agent_macro_entrypoint""
    sys.modules.pop(mod_path, None)

    with patch(f""{mod_path}._check_ollama""):
        importlib.import_module(mod_path)

    assert captured[""base_url""] == ""http://example.com/v1""",tests/test_macro_agent_base_url.py,
survived,"def test_relative_links_converted(tmp_path, monkeypatch):
    repo = tmp_path
    demo = repo / ""alpha_factory_v1"" / ""demos"" / ""demo_b""
    demo.mkdir(parents=True)
    (demo / ""colab_demo.ipynb"").write_text(""data"", encoding=""utf-8"")
    (demo / ""assets"").mkdir()
    (demo / ""assets"" / ""graph.png"").write_text(""img"", encoding=""utf-8"")

    readme = (
        ""# Demo B\n""
        ""See [Guide](../../../docs/OFFLINE_SETUP.md).\n""
        ""Open [Notebook](colab_demo.ipynb).\n""
        ""![shot](assets/graph.png)\n""
    )
    (demo / ""README.md"").write_text(readme, encoding=""utf-8"")

    assets = repo / ""docs"" / ""demo_b"" / ""assets""
    assets.mkdir(parents=True)
    (assets / ""preview.png"").write_text(""data"", encoding=""utf-8"")
    docs_demos = repo / ""docs"" / ""demos""

    monkeypatch.setattr(gdd, ""REPO_ROOT"", repo)
    monkeypatch.setattr(gdd, ""DEMOS_DIR"", repo / ""alpha_factory_v1"" / ""demos"")
    monkeypatch.setattr(gdd, ""DOCS_DIR"", docs_demos)

    gdd.generate_docs()

    page = docs_demos / ""demo_b.md""
    text = page.read_text(encoding=""utf-8"")
    base = ""https://github.com/MontrealAI/AGI-Alpha-Agent-v0/blob/main/""
    assert f""[Notebook]({base}alpha_factory_v1/demos/demo_b/colab_demo.ipynb)"" in text
    assert f""![shot]({base}alpha_factory_v1/demos/demo_b/assets/graph.png)"" in text",tests/test_generate_demo_docs.py,
survived,"        def start_merkle_task(self, *_a, **_kw) -> None:
            pass
",tests/test_orchestrator.py,DummyLedger
survived,"        def vstack(self, arrays):
            out: list[list[float]] = []
            for arr in arrays:
                out.extend(arr)
            return out
",alpha_factory_v1/backend/memory_vector.py,_SimpleNP
survived,"async def test_pending_safety_check_acknowledged() -> None:
    """"""Safety checks should be acknowledged via the callback.""""""

    computer = LoggingComputer(screenshot_return=""img"")
    called: list[ComputerToolSafetyCheckData] = []

    def on_sc(data: ComputerToolSafetyCheckData) -> bool:
        called.append(data)
        return True

    tool = ComputerTool(computer=computer, on_safety_check=on_sc)
    safety = PendingSafetyCheck(id=""sc"", code=""c"", message=""m"")
    tool_call = ResponseComputerToolCall(
        id=""t1"",
        type=""computer_call"",
        action=ActionClick(type=""click"", x=1, y=1, button=""left""),
        call_id=""t1"",
        pending_safety_checks=[safety],
        status=""completed"",
    )
    run_action = ToolRunComputerAction(tool_call=tool_call, computer_tool=tool)
    agent = Agent(name=""a"", tools=[tool])
    ctx = RunContextWrapper(context=None)

    results = await RunImpl.execute_computer_actions(
        agent=agent,
        actions=[run_action],
        hooks=RunHooks[Any](),
        context_wrapper=ctx,
        config=RunConfig(),
    )

    assert len(results) == 1
    raw = results[0].raw_item
    assert isinstance(raw, dict)
    assert raw.get(""acknowledged_safety_checks"") == [{""id"": ""sc"", ""code"": ""c"", ""message"": ""m""}]
    assert len(called) == 1
    assert called[0].safety_check.id == ""sc""",tests/test_computer_action.py,
survived,"async def api_frame_assets_rename(
    id: int,
    src: str = Form(...),
    dst: str = Form(...),
    db: Session = Depends(get_db),
    redis: Redis = Depends(get_redis),
):
    frame = db.get(Frame, id) or _not_found()

    s_rel = src.lstrip(""/"")
    d_rel = dst.lstrip(""/"")
    if any(x in s_rel for x in ["".."", ""*""]) or os.path.isabs(s_rel):
        _bad_request(""Invalid source path"")
    if any(x in d_rel for x in ["".."", ""*""]) or os.path.isabs(d_rel):
        _bad_request(""Invalid destination path"")

    assets_path = frame.assets_path or ""/srv/assets""
    src_full = os.path.normpath(os.path.join(assets_path, s_rel))
    dst_full = os.path.normpath(os.path.join(assets_path, d_rel))
    if not src_full.startswith(
        os.path.normpath(assets_path)
    ) or not dst_full.startswith(os.path.normpath(assets_path)):
        _bad_request(""Invalid asset path"")

    await rename_path(db, redis, frame, src_full, dst_full)
    return {""message"": ""Renamed""}
",backend/app/api/frames.py,
survived,"    def render() -> None:
        data = [(r.agent.name,) for r in orch.runners.values()]
        _rich_table([""agent""], data)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/cli.py,
survived,"def test_simulate_export_csv() -> None:
    runner = CliRunner()
    with patch.object(cli, ""asyncio""):
        with patch.object(cli.orchestrator, ""Orchestrator""):
            res = runner.invoke(
                cli.main,
                [
                    ""simulate"",
                    ""--horizon"",
                    ""1"",
                    ""--offline"",
                    ""--pop-size"",
                    ""1"",
                    ""--generations"",
                    ""1"",
                    ""--export"",
                    ""csv"",
                ],
            )
    assert res.exit_code == 0
    assert ""year,capability,affected"" in res.output",tests/test_cli.py,
survived,"def test_slash_on_forged_ledger(tmp_path, monkeypatch) -> None:
    settings = config.Settings(bus_port=0, ledger_path=str(tmp_path / ""ledger.db""))
    monkeypatch.setattr(orchestrator.Orchestrator, ""_init_agents"", lambda self: [])
    orch = orchestrator.Orchestrator(settings)
    orch.registry.set_stake(""A"", 100)
    original_root = orch.ledger.compute_merkle_root()
    env = messaging.Envelope(""A"", ""b"", {""v"": 1}, 0.0)
    orch.ledger.log(env)
    orch.verify_merkle_root(original_root, ""A"")
    assert orch.registry.stakes[""A""] == 90",tests/test_slash_e2e.py,
survived,"def _changed_files(diff: str) -> list[str]:
    files: set[str] = set()
    for line in diff.splitlines():
        if line.startswith(""+++"") or line.startswith(""---""):
            parts = line.split(maxsplit=1)
            if len(parts) != 2:
                continue
            path = parts[1]
            if path.startswith(""a/"") or path.startswith(""b/""):
                path = path[2:]
            files.add(path)
    return list(files)
",src/utils/patch_guard.py,
survived,"def test_rejects_empty_diff() -> None:
    assert not is_patch_valid("""")
",tests/test_patch_guard.py,
survived,"    def _ensure(self) -> None:
        with sqlite3.connect(self.path) as cx:
            cx.execute(
                ""CREATE TABLE IF NOT EXISTS agents(""
                ""id INTEGER PRIMARY KEY AUTOINCREMENT,""
                ""meta TEXT,""
                ""score REAL""
                "")""
            )
",src/archive/__init__.py,Archive
survived,"    def sample(self, k: int, *, lam: float = 10.0, alpha0: float = 0.5) -> List[Agent]:
        agents = self.all()
        if not agents:
            return []
        weights = [1.0 / (1.0 + math.exp(-lam * (a.score - alpha0))) for a in agents]
        chosen = random.choices(agents, weights=weights, k=min(k, len(agents)))
        return chosen
",src/archive/__init__.py,Archive
survived,"    def fake_run(*args, **kwargs):
        raise subprocess.TimeoutExpired(cmd=args[0], timeout=120)
",tests/test_secure_run.py,
survived,"def _load_entries(db_path: Path) -> List[ArchiveEntry]:
    """"""Return all archive entries.""""""
    with sqlite3.connect(db_path) as cx:
        rows = list(
            cx.execute(
                ""SELECT hash, parent, score, novelty, is_live, ts FROM archive""
            )
        )
    return [
        ArchiveEntry(
            hash=r[0],
            parent=r[1],
            score=float(r[2]),
            novelty=float(r[3]),
            is_live=bool(r[4]),
            ts=float(r[5]),
        )
        for r in rows
    ]
",src/tools/analyse_backtrack.py,
survived,"def test_invalid_resources(monkeypatch, tmp_path):
    fake_client = MagicMock()
    fake_client.ping.return_value = None
    monkeypatch.setattr(sm.docker, ""from_env"", lambda: fake_client)
    manager = SandboxManager()
    code_dir = tmp_path / ""code""
    code_dir.mkdir()
    with pytest.raises(ValueError):
        manager.run_code_in_sandbox(code_dir, [""python""], cpu_shares=-1)
",tests/unit/test_sandbox_manager.py,
survived,"    def __init__(
        self,
        name: str = ""LitLogger"",
        level: LogLevel = LogLevel.INFO,
        handlers: Optional[List[Handler]] = None,
        fmt: str = DEFAULT,
        async_mode: bool = False,
    ):
        self.name = name
        self.level = level
        self.format = fmt
        self.async_mode = async_mode
        self.handlers = handlers or [ConsoleHandler()]
",webscout/litlogger/logger.py,Logger
survived,"    def _rotate(self):
        if self.backups <= 0:
            self._file.close()
            self.path.unlink(missing_ok=True)
            self._open()
            return
        self._file.close()
        for i in range(self.backups, 0, -1):
            src = self.path.with_suffix(f"".{i}"") if i == 1 else self.path.with_suffix(f"".{i-1}"")
            dst = self.path.with_suffix(f"".{i}"")
            if src.exists():
                if dst.exists():
                    dst.unlink()
                src.rename(dst)
        self._open()
",webscout/litlogger/handlers.py,FileHandler
survived,"    def emit(self, message: str, level: LogLevel):
        color = LEVEL_COLORS.get(level, """")
        self.stream.write(f""{color}{message}{RESET}\n"")
        self.stream.flush()
",webscout/litlogger/handlers.py,ConsoleHandler
survived,"        async def __call__(self, _text: str) -> str:  # pragma: no cover - stub
            return ""ok""
",alpha_factory_v1/demos/aiga_meta_evolution/openai_agents_bridge.py,OpenAIAgent
survived,"def _pkg_installed(pkg: str) -> bool:
    """"""Return ``True`` when ``pkg`` is installed.

    The check uses ``python -m pip show`` for reliability when namespace
    packages are involved.
    """"""

    result = subprocess.run(
        [sys.executable, ""-m"", ""pip"", ""show"", pkg],
        stdout=subprocess.DEVNULL,
        stderr=subprocess.DEVNULL,
    )
    return result.returncode == 0
",scripts/check_python_deps.py,
survived,"def test_group_by_alias():
    scraper = AutoScraper()
    scraper.build(html=HTML, wanted_dict={""fruit"": [""Banana""]})
    similar = scraper.get_result_similar(
        html=HTML, group_by_alias=True, contain_sibling_leaves=True, unique=True
    )
    assert similar == {""fruit"": [""Banana"", ""Apple"", ""Orange""]}
",tests/unit/test_features.py,
survived,"def test_attr_fuzz_ratio_realistic():
    base = ""<div><a class='btn-primary-action' href='/buy'>Buy</a></div>""
    variant = ""<div><a class='btn-prim-action' href='/buy'>Buy</a></div>""
    scraper = AutoScraper()
    scraper.build(html=base, wanted_list=[""Buy""])
    assert scraper.get_result_exact(html=variant, attr_fuzz_ratio=0.8) == [""Buy""]
",tests/integration/test_real_world.py,
survived,"def test_remove_rules():
    scraper = AutoScraper()
    scraper.build(html=HTML_COMPLEX, wanted_list=[""Banana""])
    scraper.build(html=HTML_COMPLEX, wanted_list=[""Apple""], update=True)
    rule_ids = [s[""stack_id""] for s in scraper.stack_list]
    to_remove = rule_ids[0]
    scraper.remove_rules([to_remove])
    remaining = [s[""stack_id""] for s in scraper.stack_list]
    assert to_remove not in remaining
    assert len(remaining) == len(rule_ids) - 1
",tests/integration/test_complex_features.py,
survived,"    def __init__(self, name, attrs, parent=None):
        self.name = name
        self.attrs = dict(attrs)
        self.parent = parent
        self.children = []
        self.text = """"
",tests/conftest.py,_Node
survived,"def test_incremental_learning_multiple_sites():
    scraper = AutoScraper()
    data = [
        (HTML_PAGE_1, [""US $349.99""]),
        (HTML_WALMART_1, [""$8.95""]),
        (HTML_ETSY_1, [""$12.50+""]),
    ]
    for html, wanted in data:
        scraper.build(html=html, wanted_list=wanted, update=True)
    assert ""US $1,229.49"" in scraper.get_result_exact(html=HTML_PAGE_2)
    assert ""$7.00"" in scraper.get_result_exact(html=HTML_WALMART_2)
    assert ""$60.00"" in scraper.get_result_exact(html=HTML_ETSY_2)
",tests/integration/test_real_world.py,
survived,"    def __init__(self, path: str) -> None:
        self.path = Path(path)
        self.path.parent.mkdir(parents=True, exist_ok=True)
        self.conn = sqlite3.connect(str(self.path))
        self.conn.execute(
            """"""
            CREATE TABLE IF NOT EXISTS messages (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                ts REAL,
                sender TEXT,
                recipient TEXT,
                payload TEXT,
                hash TEXT
            )
            """"""
        )
        self.conn.commit()
        self._task: asyncio.Task[None] | None = None
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/logging.py,Ledger
survived,"        def fake_start_bridge(host: str, runtime_port: int) -> None:  # type: ignore
            captured['env'] = os.getenv('AGENTS_RUNTIME_PORT')
            captured['port'] = runtime_port
",tests/test_alpha_business_v1_script.py,TestAlphaBusinessV1Script
survived,"def test_Q2_finds_earliest_title_for_German_companies_with_character_keyword():
    assert result == ""Der Film""
",tests/dataset/job/compiler/py/q2.py,
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/job/compiler/py/q3.py,
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/job/compiler/py/q6.py,
survived,"def _min(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""min() expects list or group"")
    vals = [it for it in v if it is not None]
    if not vals:
        return 0
    return min(vals)
",tests/dataset/job/compiler/py/q3.py,
survived,"        def run(self, _prompt: str) -> str:
            return ""ok""
",tests/test_adk_gateway.py,DummyAgent
survived,"    def __init__(self, bus: A2ABus, ledger: Ledger) -> None:
        super().__init__(""freeze"", bus, ledger)
",tests/test_insight_orchestrator_restart.py,FreezeAgent
survived,"    def test_list(self):
        r = self.klong(',[1]')
        self.assertTrue(kg_equal(r, np.asarray([[1]], dtype=object)))
",tests/test_eval_monad_list.py,TestEvalMonadList
survived,"    def __init__(self) -> None:
        self.logged: list[messaging.Envelope] = []
",tests/test_safety_guardian_fuzz.py,DummyLedger
survived,"        def json(self) -> dict:
            return self._data
",tests/test_demo_cli.py,Dummy
survived,"def test_compute_merkle_root_corrupt(tmp_path: Path) -> None:
    ledger_path = tmp_path / ""ledger.db""
    ledger = Ledger(str(ledger_path), broadcast=False)
    ledger.log(messaging.Envelope(sender=""a"", recipient=""b"", payload={""v"": 1}, ts=0.0))
    ledger.log(messaging.Envelope(sender=""b"", recipient=""c"", payload={""v"": 2}, ts=1.0))

    # Corrupt the SQLite file by truncating it
    data = ledger_path.read_bytes()
    ledger_path.write_bytes(data[: len(data) // 2])

    with pytest.raises(sqlite3.DatabaseError):
        ledger.compute_merkle_root()",tests/test_ledger_corrupt.py,
survived,"def test_cli_agents_status_parses_mapping() -> None:
    from src.interface import cli

    payload = {""agents"": {""agent1"": {""last_beat"": 1.0, ""restarts"": 0}}}

    class Dummy:
        status_code = 200

        def json(self) -> dict:
            return payload

    with patch.object(cli.requests, ""get"", return_value=Dummy()):
        result = CliRunner().invoke(cli.main, [""agents-status""])
    assert ""agent1"" in result.output",tests/test_api_status.py,
survived,"def test_simulation_benchmark(tmp_path: Path, benchmark: Any) -> None:
    os.environ[""SIM_RESULTS_DIR""] = str(tmp_path)
    from src.interface import api_server

    api = importlib.reload(api_server)
    cfg = api.SimRequest(horizon=1, pop_size=2, generations=1)

    def run() -> None:
        asyncio.run(api._background_run(""bench"", cfg))

    result = benchmark(run)
    p95 = quantiles(result.stats[""data""], n=20)[18] if result.stats[""data""] else 0.0
    data = {""p95"": p95, ""tokens"": _token_usage()}
    bench_dir = Path(__file__).parent / ""benchmarks""
    bench_dir.mkdir(exist_ok=True)
    (bench_dir / ""latest.json"").write_text(json.dumps(data))",tests/test_benchmark.py,
survived,"def _token_usage() -> int:
    try:
        llm_provider = import_module(""alpha_factory_v1.backend.utils.llm_provider"")
    except Exception:
        return 0

    total = 0
    for metric in llm_provider._CNT_TOK.collect():
        for sample in metric.samples:
            if sample.name.endswith(""_total""):
                total += int(sample.value)
    return total
",tests/test_benchmark.py,
survived,"        def process(value: list[float] | None) -> FloatVector | None:
            return np.asarray(value, dtype=np.float32) if value is not None else None
",src/raglite/_typing.py,DuckDBVec
survived,"def test_governance_bridge_runtime() -> None:
    """"""Launch governance-bridge and verify agent registration.""""""
    proc = subprocess.Popen(
        [""governance-bridge"", ""--port"", ""0""],
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        text=True,
    )
    try:
        time.sleep(2)
        proc.terminate()
        out, _ = proc.communicate(timeout=5)
    finally:
        if proc.poll() is None:
            proc.kill()
            proc.wait(timeout=5)
    assert ""Registered GovernanceSimAgent"" in out",tests/test_governance_bridge_runtime.py,
survived,"    def test_prune_expired_tokens(self) -> None:
        buffer = {
            ""a"": real_time() - TOKEN_TTL - 10,
            ""b"": real_time(),
        }
        with mock.patch(""alpha_factory_v1.backend.trace_ws.time.time"", return_value=real_time()):
            prune_expired_tokens(buffer)
        self.assertIn(""b"", buffer)
        self.assertNotIn(""a"", buffer)
",tests/test_trace_token_expiry.py,TestTraceTokenExpiry
survived,"        def latent_work(self, bundle):
            return 0.0
",tests/test_alpha_agi_business_3_v1.py,LowFin
survived,"    def test_openai_v1_response_format(self) -> None:
        from alpha_factory_v1.demos.cross_industry_alpha_factory import (
            cross_alpha_discovery_stub as stub,
        )

        resp = types.SimpleNamespace(choices=[types.SimpleNamespace(message=types.SimpleNamespace(content=""[]""))])
        openai_mock = types.SimpleNamespace(
            chat=types.SimpleNamespace(completions=types.SimpleNamespace(create=Mock(return_value=resp)))
        )

        with patch.dict(os.environ, {""OPENAI_API_KEY"": ""x""}):
            with patch.object(stub, ""openai"", openai_mock):
                stub.discover_alpha(num=1, ledger=None, model=""gpt-4o-mini"")

        openai_mock.chat.completions.create.assert_called_once()
        kwargs = openai_mock.chat.completions.create.call_args.kwargs
        self.assertEqual(kwargs.get(""response_format""), {""type"": ""json_object""})
",tests/test_cross_alpha_discovery.py,TestCrossAlphaDiscoveryStub
survived,"def _metrics(item: Any) -> tuple[float, float, float]:
    """"""Return (rmse, inference_ms, gasCost) triple for ``item``.""""""
    if isinstance(item, Mapping):
        rmse = float(item.get(""rmse"", item.get(""RMSE"", 0.0)))
        inf = float(item.get(""inference_ms"", 0.0))
        gas = float(item.get(""gasCost"", item.get(""gas_cost"", 0.0)))
        return rmse, inf, gas
    rmse = float(getattr(item, ""rmse"", getattr(item, ""RMSE"", 0.0)))
    inf = float(getattr(item, ""inference_ms"", 0.0))
    gas = float(getattr(item, ""gasCost"", getattr(item, ""gas_cost"", 0.0)))
    return rmse, inf, gas
",src/simulation/selector.py,
survived,"    async def trigger_dispatch(_: None = Depends(verify_token)) -> dict[str, str] | JSONResponse:
        """"""Trigger a GitHub workflow dispatch.""""""

        start = time.perf_counter()
        status = ""200""
        try:
            url = os.getenv(""DISPATCH_URL"")
            token = os.getenv(""DISPATCH_TOKEN"")
            if not url or not token:
                raise HTTPException(status_code=503, detail=""dispatch not configured"")
            httpx = importlib.import_module(""httpx"")
            r = httpx.post(url, json={}, headers={""Authorization"": f""Bearer {token}""}, timeout=10)
            r.raise_for_status()
            return {""status"": ""ok""}
        except HTTPException as exc:
            status = str(exc.status_code)
            return problem_response(exc)
        except Exception as exc:  # pragma: no cover - network failures
            status = ""502""
            return problem_response(HTTPException(status_code=502, detail=str(exc)))
        finally:
            REQ_COUNT.labels(""POST"", ""/dispatch"", status).inc()
            REQ_LAT.labels(""POST"", ""/dispatch"").observe(time.perf_counter() - start)
",src/interface/api_server.py,
survived,"    async def get_proof(agent_id: str, _: None = Depends(verify_token)) -> ProofResponse | JSONResponse:
        """"""Return stored proof CID for ``agent_id`` if present.""""""

        start = time.perf_counter()
        status = ""200""
        try:
            path = Path(os.getenv(""ARCHIVE_PATH"", ""archive.db""))
            db = ArchiveDB(path)
            cid = db.get_proof_cid(agent_id)
            if cid is None:
                raise HTTPException(status_code=404)
            proof = db.get_state(f""proof:{agent_id}"")
            return ProofResponse(cid=cid, proof=proof)
        except HTTPException as exc:
            status = str(exc.status_code)
            return problem_response(exc)
        finally:
            REQ_COUNT.labels(""GET"", ""/proof/{agent_id}"", status).inc()
            REQ_LAT.labels(""GET"", ""/proof/{agent_id}"").observe(time.perf_counter() - start)
",src/interface/api_server.py,
survived,"def test_lead_signal_improvement_over_baseline() -> None:
    history = [1.0, 1.0, 1.0]
    forecast = [1.2, 1.3, 1.4]
    score = lead_time.lead_signal_improvement(history, forecast, months=3, threshold=1.1)
    assert score >= 0.15
",tests/test_lead_time_evaluator.py,
survived,"def test_check_patch_in_sandbox_ok(monkeypatch):
    def fake_run(cmd, capture_output=True, text=True):
        return subprocess.CompletedProcess(cmd, 0, """", """")

    monkeypatch.setattr(subprocess, ""run"", fake_run)
    assert preflight.check_patch_in_sandbox(""img"")
",tests/test_preflight_sandbox.py,
survived,"        async def _cycle() -> None:
            t0 = time.time()
            span_cm = tracer.start_as_current_span(self.name) if tracer else contextlib.nullcontext()
            with span_cm:
                try:
                    await asyncio.wait_for(maybe_await(self.inst.run_cycle), timeout=self._max_cycle_sec)
                except asyncio.TimeoutError:
                    MET_ERR.labels(self.name).inc()
                    log.error(""%s run_cycle exceeded %ss budget â€“ skipped"", self.name, self._max_cycle_sec)
                except Exception as exc:  # noqa: BLE001
                    MET_ERR.labels(self.name).inc()
                    log.exception(""%s.run_cycle crashed: %s"", self.name, exc)
                finally:
                    dur_ms = (time.time() - t0) * 1_000
                    MET_LAT.labels(self.name).observe(dur_ms)
                    self.last_beat = time.time()
                    self._publish(""agent.cycle"", {""agent"": self.name, ""latency_ms"": dur_ms, ""ts"": utc_now()})
",alpha_factory_v1/backend/agent_runner.py,AgentRunner
survived,"    async def __aexit__(self, exc_type: object, exc: object, tb: object) -> None:
        """"""Stop the Merkle task and close the database.""""""
        await self.stop_merkle_task()
        self.close()",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/logging.py,Ledger
survived,"def get_image_analysis_azure(api_endpoint, api_key, api_version, deployment_name, prompt, base64_image):
    client = AzureOpenAI(
        azure_endpoint=api_endpoint,
        api_key=api_key,
        api_version=api_version,
    )

    response = client.chat.completions.create(
        model=deployment_name,
        messages=[
            {
                ""role"": ""user"",
                ""content"": [
                    {""type"": ""text"", ""text"": prompt},
                    {""type"": ""image_url"", ""image_url"": {""url"": f""data:image/jpeg;base64,{base64_image}""}},
                ],
            }
        ],
        max_tokens=4000,
    )

    return {
        ""choices"": [
            {""message"": {""content"": response.choices[0].message.content}}
        ]
    }
",threat_model.py,
survived,"def indexOfStr(h, n):
    hlen = len(h)
    nlen = len(n)
    if nlen == 0:
        return 0
    i = 0
    while i <= hlen - nlen:
        if h[i:i + nlen] == n:
            return i
        i = i + 1
    return -1
",tests/rosetta/transpiler/Python/boyer-moore-string-search.py,
survived,"def isPrime(n):
    if n < 2:
        return False
    if n % 2 == 0:
        return n == 2
    if n % 3 == 0:
        return n == 3
    d = 5
    while d * d <= n:
        if n % d == 0:
            return False
        d = d + 2
        if n % d == 0:
            return False
        d = d + 4
    return True
",tests/rosetta/transpiler/Python/blum-integer.py,
survived,"def calkinWilf(n):
    seq = []
    seq = seq + [bigrat(1, 1)]
    i = 1
    while i < n:
        prev = seq[i - 1]
        a = prev.numerator
        b = prev.denominator
        f = a // b
        t = bigrat(f, 1)
        t = t * (Fraction(2))
        t = t - prev
        t = t + (Fraction(1))
        t = (Fraction(1)) // t
        seq = seq + [t]
        i = i + 1
    return seq
",tests/rosetta/transpiler/Python/calkin-wilf-sequence.py,
survived,"def makePrintable(s):
    out = """"
    i = 0
    while i < len(s):
        ch = s[i:i + 1]
        if ch == stx:
            out = out + ""^""
        else:
            if ch == etx:
                out = out + ""|""
            else:
                out = out + ch
        i = i + 1
    return out
",tests/rosetta/transpiler/Python/burrows-wheeler-transform.py,
survived,"def main():
    examples = [""banana"", ""appellee"", ""dogwood"", ""TO BE OR NOT TO BE OR WANT TO BE OR NOT?"", ""SIX.MIXED.PIXIES.SIFT.SIXTY.PIXIE.DUST.BOXES"", ""\x02ABC\x03""]
    for t in examples:
        print(makePrintable(t))
        res = bwt(t)
        if res[""err""]:
            print("" --> ERROR: String can't contain STX or ETX"")
            print("" -->"")
        else:
            enc = str(res[""res""])
            print("" --> "" + makePrintable(enc))
            r = ibwt(enc)
            print("" --> "" + r)
        print("""")
",tests/rosetta/transpiler/Python/burrows-wheeler-transform.py,
survived,"def indexOf(s, ch):
    i = 0
    while i < len(s):
        if s[i:i + 1] == ch:
            return i
        i = i + 1
    return -1
",tests/rosetta/transpiler/Python/bulls-and-cows.py,
survived,"def encipher(s, k):
    out = """"
    i = 0
    while i < len(s):
        out = out + shiftRune(s[i:i + 1], k)
        i = i + 1
    return out
",tests/rosetta/transpiler/Python/caesar-cipher-2.py,
survived,"def hasNeighbor(x, y):
    dy = -1
    while dy <= 1:
        dx = -1
        while dx <= 1:
            if not (dx == 0 and dy == 0):
                nx = x + dx
                ny = y + dy
                if inBounds(nx, ny) and grid[ny][nx] == frost:
                    return True
            dx = dx + 1
        dy = dy + 1
    return False
",tests/rosetta/transpiler/Python/brownian-tree.py,
survived,"def isBrazilian(n):
    if n < 7:
        return False
    if n % 2 == 0 and n >= 8:
        return True
    b = 2
    while b < n - 1:
        if sameDigits(n, b):
            return True
        b = b + 1
    return False
",tests/rosetta/transpiler/Python/brazilian-numbers.py,
survived,"def zeroptr(ref):
    ref[0] = 0
",tests/rosetta/transpiler/Python/call-a-function-11.py,
survived,"def main():
    cw = calkinWilf(20)
    print(""The first 20 terms of the Calkin-Wilf sequnence are:"")
    i = 0
    while i < 20:
        r = cw[i]
        s = str(r.numerator)
        if r.denominator != 1:
            s = s + ""/"" + str(r.denominator)
        print((i + int(1)).rjust(2, "" "") + "": "" + s)
        i = i + 1
    r = bigrat(83116, 51639)
    cf = toContinued(r)
    tn = termNumber(cf)
    print("""" + str(r.numerator) + ""/"" + str(r.denominator) + "" is the "" + commatize(tn) + ""th term of the sequence."")
",tests/rosetta/transpiler/Python/calkin-wilf-sequence.py,
survived,"def test_preflight_rejects_malformed_patch(tmp_path: Path) -> None:
    repo_dir = tmp_path / ""repo""
    repo_dir.mkdir()
    _init_repo(repo_dir)

    patch_file = tmp_path / ""bad.diff""
    patch_file.write_text((FIXTURES / ""malformed_patch.diff"").read_text())
    log_file = tmp_path / ""log.json""

    t0 = time.time()
    with pytest.raises(ValueError):
        self_improver.improve_repo(str(repo_dir), str(patch_file), ""metric.txt"", str(log_file))
    assert time.time() - t0 < 30",tests/test_preflight.py,
survived,"def run_preflight(repo_dir: str | Path = ""."") -> None:
    """"""Run compilation and smoke tests inside ``repo_dir``.""""""

    repo = Path(repo_dir)
    result = subprocess.run(
        [""git"", ""ls-files"", ""*.py""], capture_output=True, text=True, cwd=repo
    )
    files = [f for f in result.stdout.splitlines() if f]
    if files:
        subprocess.run([sys.executable, ""-m"", ""py_compile"", *files], check=True, cwd=repo)

    test_path = repo / ""tests"" / ""basic_edit.py""
    if test_path.exists():
        subprocess.run([""pytest"", ""-q"", str(test_path)], check=True, cwd=repo)
",src/eval/preflight.py,
survived,"def _run(strategy: str, iterations: int, *, seed: int) -> Tuple[float, float]:
    random.seed(seed)
    np.random.seed(seed)
    pop = [_Candidate(0.0, _fitness(0.0), 1.0)]
    for _ in range(iterations):
        if strategy == ""v2"":
            parent = _select_softmax(pop)
        elif strategy == ""greedy"":
            parent = max(pop, key=lambda c: c.fitness)
        else:  # pragma: no cover - invalid option
            raise ValueError(f""unknown strategy: {strategy}"")
        genome = _mutate(parent.genome)
        cand = _Candidate(genome, _fitness(genome), random.random())
        pop.append(cand)
    best = max(c.fitness for c in pop)
    mean = sum(c.fitness for c in pop) / len(pop)
    return best, mean
",experiments/ablate_selector.py,
survived,"def evaluate(repo_path: Path) -> dict[str, float]:
    """"""Return average RMSE and lead-time for the Sector-Shock-10 dataset.""""""

    ds_dir = repo_path / ""data"" / ""sector_shock_10""
    rmses: list[float] = []
    leads: list[float] = []
    for path in sorted(ds_dir.glob(""*.json"")):
        data = json.loads(path.read_text())
        truth_caps = data.get(""capabilities"", [])
        truth_shocks = data.get(""shocks"", [])
        pred_caps = truth_caps[:]  # deterministic baseline
        pred_shocks = truth_shocks[:]
        rmses.append(_rmse(truth_caps, pred_caps))
        leads.append(_lead_time(truth_shocks, pred_shocks))
    if not rmses:
        raise FileNotFoundError(ds_dir)
    return {""rmse"": statistics.mean(rmses), ""lead_time"": statistics.mean(leads)}
",src/eval/foresight.py,
survived,"        def register_agent(self, _agent):
            pass
",tests/test_adk_gateway_startup.py,_Router
survived,"def __dir__() -> list[str]:
    return sorted(list(globals().keys()) + __all__)",alpha_factory_v1/demos/__init__.py,
survived,"def get_notification_settings(default=None):
    return get_global_setting('notification_settings', default)
",users_db.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/equilibrium-index.py,
survived,"def hasPrefix(s, p):
    if len(p) > len(s):
        sys.exit(False)
    sys.exit(s[0:len(p)] == p)
",tests/rosetta/transpiler/Python/environment-variables-2.py,
survived,"def pad8(n):
    s = str(n)
    while len(s) < 8:
        s = "" "" + s
    sys.exit(s)
",tests/rosetta/transpiler/Python/erd-s-nicolas-numbers.py,
survived,"def toBase(n, b):
    if n == 0:
        sys.exit(""0"")
    v = n
    out = """"
    while v > 0:
        d = v % b
        out = """".join(digits[d:d + 1]) + out
        v = v // b
    sys.exit(out)
",tests/rosetta/transpiler/Python/esthetic-numbers.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/environment-variables-1.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/exceptions-catch-an-exception-thrown-in-a-nested-call.py,
survived,"def smallestPrimeFactorWheel(n, max):
    if n % two == zero:
        sys.exit(two)
    if n % three == zero:
        sys.exit(three)
    if n % five == zero:
        sys.exit(five)
    k = 7
    inc = [four, two, four, two, four, six, two, six]
    i = 0
    while k * k <= n:
        if n % k == zero:
            sys.exit(k)
        k = k + inc[i]
        if k > max:
            break
        i = (i + 1) % 8
    sys.exit(zero)
",tests/rosetta/transpiler/Python/euclid-mullin-sequence.py,
survived,"def cis(x):
    sys.exit(Complex(re=cosApprox(x), im=sinApprox(x)))
",tests/rosetta/transpiler/Python/eulers-identity.py,
survived,"def fmt(x):
    y = floorf(x * 1e+08 + 0.5) / 1e+08
    s = str(y)
    dot = s.find(""."")
    if dot == 0 - 1:
        s = s + "".00000000""
    else:
        d = len(s) - dot - 1
        while d < 8:
            s = s + ""0""
            d = d + 1
    sys.exit(s)
",tests/rosetta/transpiler/Python/fibonacci-word.py,
survived,"def runRules(rules, s):
    changed = True
    while changed:
        changed = False
        i = 0
        while i < len(rules):
            r = rules[i]
            pat = r.get(""pat"")
            rep = r.get(""rep"")
            term = r.get(""term"")
            idx = indexOfSub(s, pat)
            if idx >= 0:
                s = """".join(s[:idx]) + rep + """".join(s[idx + len(pat):])
                changed = True
                if term:
                    sys.exit(s)
                break
            i = i + 1
    sys.exit(s)
",tests/rosetta/transpiler/Python/execute-a-markov-algorithm.py,
survived,"def split(s, sep):
    parts = []
    cur = """"
    i = 0
    while i < len(s):
        if len(sep) > 0 and i + len(sep) <= len(s) and s[i:i + len(sep)] == sep:
            parts = parts + [cur]
            cur = """"
            i = i + len(sep)
        else:
            cur = cur + """".join(s[i:i + 1])
            i = i + 1
    parts = parts + [cur]
    sys.exit(parts)
",tests/rosetta/transpiler/Python/execute-a-markov-algorithm.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/euler-method.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/exponentiation-with-infix-operators-in-or-operating-on-the-base.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/file-size-distribution.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/equal-prime-and-composite-sums.py,
survived,"def ethMulti(i, j):
    r = 0
    x = i
    y = j
    while x > 0:
        if not isEven(x):
            r = r + y
        x = halve(x)
        y = double(y)
    return r
",tests/rosetta/transpiler/Python/ethiopian-multiplication.py,
survived,"def newCoolingRateDy(k, ambient):
    cr = newCoolingRate(k)
    sys.exit(lambda _x, obj: cr(obj - ambient))
",tests/rosetta/transpiler/Python/euler-method.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/executable-library.py,
survived,"def fibonacciWord(n):
    a = ""1""
    b = ""0""
    i = 1
    while i < n:
        tmp = b
        b = b + a
        a = tmp
        i = i + 1
    sys.exit(a)
",tests/rosetta/transpiler/Python/fibonacci-word.py,
survived,"def uabs(a, b):
    if a > b:
        sys.exit(a - b)
    sys.exit(b - a)
",tests/rosetta/transpiler/Python/esthetic-numbers.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/exponentiation-order.py,
survived,"async def test_relationship_resolver_validation():
    app, lifespan = create_app()
    async with lifespan(app) as ctx:
        session_factory = ctx[""session_factory""]
        mock_ctx = Mock(spec=EnrichContext)
        mock_ctx.request_context = Mock()
        mock_ctx.request_context.lifespan_context = {""session_factory"": session_factory}

        get_orders = app.resources[""get_userenrichmodel_orders""]

        with pytest.raises(ValueError):
            await get_orders(user_id=1, page=0, page_size=1, ctx=mock_ctx)

        empty = await get_orders(page=1, page_size=1, ctx=mock_ctx)
        assert empty.items == []
        assert not empty.has_next
",tests/test_sqlalchemy_autogen_extra.py,
survived,"def test_devicon_py_file():
    file = MockFile('example.py')
    assert devicons.devicon(file) == 'î˜†'
",tests/test_devicons.py,
survived,"    def __init__(self, path, is_directory=False):
        self.relative_path = path
        self.is_directory = is_directory
        self.extension = os.path.splitext(path)[1][1:]
",tests/test_devicons.py,MockFile
survived,"    def publish(self, topic: str, env: messaging.Envelope) -> None:
        self.published.append((topic, env))
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_codegen_safety.py,DummyBus
survived,"    def get_context(self) -> EnrichContext:
        """"""Return the current :class:`EnrichContext` for this app.""""""

        base_ctx = self.mcp.get_context()
        return EnrichContext(
            request_context=getattr(base_ctx, ""_request_context"", None),
            fastmcp=getattr(base_ctx, ""_fastmcp"", None),
        )
",src/enrichmcp/app.py,EnrichMCP
survived,"def test_search_capabilities(tmp_path):
    reg = TemplateRegistry(base_dir=tmp_path)
    reg.register(_meta(""basic"", TemplateCategory.CONVERSATION), ""c1"")
    m2 = _meta(""web"", TemplateCategory.CONVERSATION)
    m2.requires_web_search = True
    reg.register(m2, ""c2"")

    engine = TemplateSearchEngine(reg)
    none = engine.search(""c"", capabilities=[])
    assert [r.slug for r in none] == [""basic""]

    cap = engine.search(""c"", capabilities=[""web_search""])
    slugs = {r.slug for r in cap}
    assert slugs == {""basic"", ""web""}",tests/test_template_search.py,
survived,"def _groups_equal(a: RolloutGroup, b: RolloutGroup) -> bool:
    """"""Deep equality helper via dataclasses.asdict with float tolerance.""""""

    da, db = asdict(a), asdict(b)
    # Allow tiny float differences in ""created""
    if abs(da[""created""] - db[""created""]) > 1e-9:
        return False
    da[""created""] = db[""created""] = 0  # normalise
    return da == db
",tests/rl/test_parquet_store.py,
survived,"    def build(self, inference: InferenceEndpoint, rollout_sink: RolloutSink) -> AbstractMarinEnv:
        """"""Instantiate the environment.

        The *rollout_sink* should be called with :class:`~marin.rl.types.RolloutGroup` batches.
        """"""
",marin/rl/config.py,AbstractEnvConfig
survived,"def test_chat_echo_env(openai_mock):  # type: ignore[valid-type]
    # Prepare mock response
    openai_mock.chat.completions.create.response = {
        ""choices"": [
            {
                ""index"": 0,
                ""finish_reason"": ""stop"",
                ""message"": {""content"": ""Hello! How can I help?"", ""role"": ""assistant""},
            }
        ]
    }

    # Collect rollouts emitted by the env
    collected: deque[RolloutGroup] = deque()

    def sink(groups: list[RolloutGroup]):
        collected.extend(groups)

    env = ChatEchoEnv(
        inference=InferenceEndpoint(""https://api.openai.com/v1""),
        rollout_sink=sink,  # type: ignore[arg-type]
        prompt=""Hello!"",
        max_iters=1,  # run exactly once then stop
        api_key=""sk-fake"",
    )

    asyncio.run(env.run())

    # Ensure sink received one rollout group with expected content
    assert len(collected) == 1
    rg = collected.pop()
    assert rg.rollouts[0].turns[0].message == ""Hello! How can I help?""
    # Mock should have been hit exactly once
    assert openai_mock.chat.completions.create.route.call_count == 1",tests/rl/test_openai_env.py,
survived,"def write_rollout_groups(
    groups: list[RolloutGroup],
    root_path: str,
    *,
    compression: str = ""zstd"",
) -> None:
    """"""Append *groups* to a Parquet dataset located at *root_path*.

    Each call writes a new part file named ``part-<uuid>.parquet`` so that
    concurrent writers (e.g. many Ray env actors) can operate without locking.
    """"""

    # Resolve path to a pyarrow filesystem (handles ""gs://"", ""s3://"", etc.).
    fs, dataset_root = pafs.FileSystem.from_uri(root_path)

    # Ensure directory exists (noop if already present).  Some remote FS may
    # raise EEXISTâ€”ignore it.
    try:
        fs.create_dir(dataset_root, recursive=True)
    except FileExistsError:
        pass

    table = _groups_to_table(groups)

    filename = f""{dataset_root.rstrip('/')}/part-{uuid.uuid4().hex}.parquet""
    pq.write_table(table, filename, compression=compression, filesystem=fs)
",marin/rl/parquet_store.py,
survived,"    def sink(groups: list[RolloutGroup]):
        collected.extend(groups)
",tests/rl/test_openai_env.py,
survived,"async def convert_alpha_tool(alpha: str) -> dict:
    return convert_alpha(alpha)
",alpha_factory_v1/demos/aiga_meta_evolution/workflow_demo.py,
survived,"def reward(state: Any, action: Any, result: Any) -> float:
    """"""Compute a scalar reward in ``[0, 1]``.

    Parameters
    ----------
    state : Any
        Snapshot of the environment or agent state.
    action : Any
        Action executed by the agent.
    result : Any
        Observation or outcome returned by the environment.

    Returns
    -------
    float
        Normalised reward signal.
    """"""
    # TODO: replace this example logic with your custom calculation
    return 0.5",alpha_factory_v1/demos/era_of_experience/reward_backends/template.py,
survived,"    def test_detect_supply_chain_alpha(self) -> None:
        msg = alpha_detection.detect_supply_chain_alpha()
        self.assertIsInstance(msg, str)
        self.assertTrue(""USD"" in msg or ""offline data missing"" in msg)
",tests/test_alpha_detection.py,TestAlphaDetection
survived,"    def launch_dashboard() -> None:  # type: ignore[return-type]
        """"""Placeholder when optional dependencies are absent.""""""
        raise RuntimeError(
            ""gradio and other optional packages are required for the MuZero demo""
        )
",alpha_factory_v1/demos/muzero_planning/__init__.py,
survived,"    async def step(self) -> None:
        await self.publish(""alpha.compliance"", {""status"": ""ok""})
",alpha_factory_v1/demos/alpha_agi_business_v1/alpha_agi_business_v1.py,AlphaComplianceAgent
survived,"async def trigger_compliance() -> str:
    resp = requests.post(f""{HOST}/agent/alpha_compliance/trigger"", timeout=5)
    resp.raise_for_status()
    return ""alpha_compliance queued""
",alpha_factory_v1/demos/alpha_agi_business_v1/openai_agents_bridge.py,
survived,"def _parse_args(argv: list[str] | None = None) -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description=""Call BusinessAgent via OpenAI Agents runtime""
    )
    parser.add_argument(
        ""--host"",
        default=os.getenv(""AGENTS_HOST"", ""http://localhost:5001""),
        help=""Base URL for the Agents runtime (default: http://localhost:5001)"",
    )
    parser.add_argument(
        ""--action"",
        default=""recent_alpha"",
        help=""Action to invoke (default: recent_alpha)"",
    )
    parser.add_argument(
        ""--job"",
        help=""Optional JSON file with a custom job payload"",
    )
    return parser.parse_args(argv)
",alpha_factory_v1/demos/alpha_agi_business_v1/examples/openai_agent_client.py,
survived,"        def parse_dataset_iter(it: ast.expr) -> tuple[str, str | None, str | None, str | None]:
            sort = None
            skip = None
            take = None
            cur = it

            # handle take
            if isinstance(cur, ast.Subscript) and isinstance(cur.slice, ast.Slice):
                sl = cur.slice
                if (
                    sl.lower is None
                    and sl.step is None
                    and isinstance(sl.upper, ast.Call)
                    and getattr(sl.upper.func, ""id"", None) == ""max""
                    and len(sl.upper.args) == 2
                    and isinstance(sl.upper.args[1], ast.Constant)
                    and sl.upper.args[1].value == 0
                ):
                    take = self.convert_expr(sl.upper.args[0])
                    cur = cur.value

            # handle skip
            if isinstance(cur, ast.Subscript) and isinstance(cur.slice, ast.Slice):
                sl = cur.slice
                if (
                    sl.upper is None
                    and sl.step is None
                    and isinstance(sl.lower, ast.Call)
                    and getattr(sl.lower.func, ""id"", None) == ""max""
                    and len(sl.lower.args) == 2
                    and isinstance(sl.lower.args[1], ast.Constant)
                    and sl.lower.args[1].value == 0
                ):
                    skip = self.convert_expr(sl.lower.args[0])
                    cur = cur.value

            # handle sort
            if isinstance(cur, ast.Call) and isinstance(cur.func, ast.Name) and cur.func.id == ""sorted"":
                if cur.keywords:
                    for kw in cur.keywords:
                        if kw.arg == ""key"" and isinstance(kw.value, ast.Lambda):
                            body = kw.value.body
                            if (
                                isinstance(body, ast.Call)
                                and isinstance(body.func, ast.Name)
                                and body.func.id == ""_sort_key""
                                and body.args
                            ):
                                sort = self.convert_expr(body.args[0])
                            else:
                                sort = self.convert_expr(body)
                if cur.args:
                    cur = cur.args[0]

            # remove trivial list comp wrappers
            if (
                isinstance(cur, ast.ListComp)
                and len(cur.generators) == 1
                and isinstance(cur.generators[0].target, ast.Name)
                and isinstance(cur.elt, ast.Name)
                and cur.elt.id == cur.generators[0].target.id
                and not cur.generators[0].ifs
            ):
                cur = cur.generators[0].iter

            return self.convert_expr(cur), sort, skip, take
",tools/py2mochi/py2mochi.py,Converter
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/binary-digits.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/boolean-values.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/convert-decimal-number-to-rational.py,
survived,"async def test_explore_data_model_returns_summary() -> None:
    app = EnrichMCP(""My API"", description=""Demo server"")

    @app.entity(description=""Test entity"")
    class Item(EnrichModel):
        id: int = Field(description=""Identifier"")

    tool_name = ""explore_my_api_data_model""
    assert tool_name in app.resources

    summary = await app.resources[tool_name]()
    assert isinstance(summary, DataModelSummary)
    assert summary.title == ""My API""
    assert summary.entity_count == 1
    assert summary.entities == [""Item""]
    summary_text = str(summary)
    assert ""# My API"" in summary_text
    assert ""**Entity count:** 1"" in summary_text
    assert ""- Item"" in summary_text

    tools = await app.mcp.list_tools()
    tool = next(t for t in tools if t.name == tool_name)
    assert ""Call this tool FIRST"" in tool.description
    assert ""Demo server"" in tool.description",tests/test_explore_data_model.py,
survived,"def test_bus_logs_start_stop(caplog: pytest.LogCaptureFixture) -> None:
    caplog.set_level(logging.INFO)
    cfg = config.Settings(bus_port=1234, broker_url=""kafka:9092"")
    bus = messaging.A2ABus(cfg)
    with mock.patch.object(messaging, ""AIOKafkaProducer"", None), \
         mock.patch.object(messaging, ""grpc"", None):
        asyncio.run(bus.start())
        asyncio.run(bus.stop())
    messages = [r.message for r in caplog.records]
    assert any(""Starting A2ABus"" in m and ""1234"" in m and ""kafka:9092"" in m for m in messages)
    assert any(""Stopping A2ABus"" in m for m in messages)",tests/test_bus_logging.py,
survived,"    async def step(self) -> None:
        # Pretend to fetch and summarise data
        await self.publish(""alpha.research"", {""summary"": ""market stable""})
",alpha_factory_v1/demos/alpha_agi_business_2_v1/alpha_agi_business_2_v1.py,ResearchAgent
survived,"def main() -> None:
    try:
        orchestrator.Orchestrator().run_forever()
    except KeyboardInterrupt:
        pass
",alpha_factory_v1/demos/alpha_agi_business_2_v1/alpha_agi_business_2_v1.py,
survived,"def inc(x):
    return x + k
",tests/transpiler/x/py/pure_global_fold.py,
survived,"    def get_router(cls) -> APIRouter:
        router = APIRouter()
        OutputModel = cls.OutputSchema

        @router.post(""/execute"", response_model=OutputModel)
        def execute_endpoint(payload: Dict[str, Any]) -> Any:
            input_obj = cls.InputSchema(**payload)
            instance = cls()
            result = instance.execute(input_obj.dict())
            return OutputModel(**result)

        return router
",servers/server_clear_thought/core/base_tool.py,BaseTool
survived,"    async def meme_usage(_: None = Depends(verify_token)) -> dict[str, int]:
        """"""Return meme usage counts.""""""
        return _meme_usage
",src/interface/api_server.py,
survived,"def test_meme_reuse() -> None:
    rng = random.Random(0)
    op = SelfRewriteOperator(steps=3, rng=rng, templates=[""meme""], reuse_rate=1.0)
    result = op(""improve quick test"")
    assert result == ""meme""
    assert op.reuse_count >= 1
",tests/test_meme_reuse.py,
survived,"def test_meme_mining(tmp_path: Path) -> None:
    js_out = tmp_path / 'memeplex.js'
    subprocess.run(
        ['tsc', '--target', 'es2020', '--module', 'es2020', MEMEPLEX_TS, '--outFile', js_out],
        check=True,
    )
    script = tmp_path / 'run.mjs'
    script.write_text(
        f""import {{ mineMemes }} from '{js_out.resolve().as_posix()}';\n""
        ""const runs = [\n""
        ""  {edges:[{from:'A',to:'B'},{from:'B',to:'C'}]},\n""
        ""  {edges:[{from:'A',to:'B'}]},\n""
        ""  {edges:[{from:'A',to:'B'}]}\n""
        ""];\n""
        ""const memes = mineMemes(runs,2);\n""
        ""console.log(JSON.stringify(memes));\n"",
        encoding='utf-8',
    )
    res = subprocess.run(['node', script], capture_output=True, text=True, check=True)
    data = json.loads(res.stdout)
    assert len(data) == 1
    assert data[0]['count'] == 3",tests/test_memeplex_ts.py,
survived,"def test_generate_docs(tmp_path, monkeypatch):
    repo = tmp_path
    demos = repo / ""alpha_factory_v1"" / ""demos"" / ""demo_a""
    demos.mkdir(parents=True)
    (demos / ""README.md"").write_text(""# Demo A\nHello"", encoding=""utf-8"")
    assets = repo / ""docs"" / ""demo_a"" / ""assets""
    assets.mkdir(parents=True)
    (assets / ""preview.png"").write_text(""data"", encoding=""utf-8"")
    docs_demos = repo / ""docs"" / ""demos""

    monkeypatch.setattr(gdd, ""REPO_ROOT"", repo)
    monkeypatch.setattr(gdd, ""DEMOS_DIR"", repo / ""alpha_factory_v1"" / ""demos"")
    monkeypatch.setattr(gdd, ""DOCS_DIR"", docs_demos)

    gdd.generate_docs()

    page = docs_demos / ""demo_a.md""
    text = page.read_text(encoding=""utf-8"")
    assert ""# Demo A"" in text
    assert ""![preview](../demo_a/assets/preview.png){.demo-preview}"" in text
    assert ""[View README](../../alpha_factory_v1/demos/demo_a/README.md)"" in text",tests/test_generate_demo_docs.py,
survived,"    def __repr__(self) -> str:  # pragma: no cover - trivial
        data = self.model_dump()
        for k in tuple(data):
            if any(s in k.lower() for s in (""token"", ""key"", ""password"")) and data[k]:
                data[k] = ""***""
        return f""Settings({data})""
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/config.py,Settings
survived,"    def test_concurrent_writes_with_filelock(self) -> None:
        try:
            import filelock
        except Exception:  # pragma: no cover - optional dependency
            self.skipTest(""filelock not installed"")

        from alpha_factory_v1.demos.cross_industry_alpha_factory import (
            cross_alpha_discovery_stub as stub,
        )

        with tempfile.TemporaryDirectory() as tmp:
            ledger = Path(tmp) / ""thread_lock_log.json""

            def worker(seed: int) -> None:
                stub.discover_alpha(num=1, seed=seed, ledger=ledger, model=""gpt-4o-mini"")

            threads = [threading.Thread(target=worker, args=(i,)) for i in range(5)]
            with patch.object(stub, ""FileLock"", filelock.FileLock):
                for t in threads:
                    t.start()
                for t in threads:
                    t.join()

            data = json.loads(ledger.read_text())
            self.assertIsInstance(data, list)
            self.assertEqual(len(data), 5)
            self.assertEqual(len(data), len({json.dumps(i, sort_keys=True) for i in data}))
",tests/test_cross_alpha_discovery.py,TestCrossAlphaDiscoveryStub
survived,"            async def __aenter__(self_inner):
                return Response()
",src/aiohttp/__init__.py,ClientSession._RespCtx
survived,"def test_usage_accumulation():
    t = TelemetryCollector(cost_cap=1.0)
    t.add_usage(500, 500, model=""o3"")
    assert t.token_count == 1000
    assert pytest.approx(t.cost, 0.0001) == 0.01
",tests/unit/test_telemetry_collector.py,
survived,"    def stop_timer(self) -> None:
        """"""Stop the latency timer and accumulate duration.""""""
        if self._start is not None:
            self.latency += time.perf_counter() - self._start
            self._start = None
",src/meta_agent/telemetry.py,TelemetryCollector
survived,"    def _init_db(self) -> None:
        cur = self.conn.cursor()
        cur.execute(
            """"""
            CREATE TABLE IF NOT EXISTS telemetry (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT NOT NULL,
                tokens INTEGER,
                cost REAL,
                latency REAL,
                guardrail_hits INTEGER
            )
            """"""
        )
        self.conn.commit()
",src/meta_agent/telemetry_db.py,TelemetryDB
survived,"    def __init__(self, *args, **kwargs):
        self.request_info = kwargs.get(""request_info"")
        self.history = kwargs.get(""history"")
        self.status = kwargs.get(""status"")
        self.message = kwargs.get(""message"")
        self.headers = kwargs.get(""headers"")
        super().__init__(self.message)
",src/aiohttp/__init__.py,ClientResponseError
survived,"async def trigger_best_alpha() -> str:
    """"""Read the bundled alpha opportunities and enqueue the best one.""""""
    try:
        path = Path(__file__).with_name(""examples"") / ""alpha_opportunities.json""
        data = json.loads(path.read_text(encoding=""utf-8""))
        best = max(data, key=lambda x: x.get(""score"", 0))
    except Exception as exc:  # pragma: no cover - file may be missing
        raise RuntimeError(f""failed to load alpha opportunities: {exc}"") from exc
    resp = requests.post(
        f""{HOST}/agent/alpha_execution/trigger"",
        json=best,
        timeout=5,
    )
    resp.raise_for_status()
    return ""best alpha queued""
",alpha_factory_v1/demos/alpha_agi_business_v1/openai_agents_bridge.py,
survived,"    async def broadcast_merkle_root(self) -> None:
        try:
            root = self.compute_merkle_root()
        except Exception as exc:  # pragma: no cover - corruption
            _log.warning(""Failed to compute Merkle root: %s"", exc)
            return
        if AsyncClient is None or not self.broadcast:
            _log.info(""Merkle root %s"", root)
            return
        try:
            client = AsyncClient(self.rpc_url or ""https://api.testnet.solana.com"")
            memo_prog = PublicKey(""MemoSq4gqABAXKb96qnH8TysNcWxMyWCqXgDLGmfcHr"")
            tx = Transaction().add(TransactionInstruction(program_id=memo_prog, data=root.encode(), keys=[]))
            signer = None
            if self.wallet:
                try:  # pragma: no cover - optional dependency
                    from solana.keypair import Keypair

                    signer = Keypair.from_secret_key(bytes.fromhex(self.wallet))
                except Exception as exc:  # noqa: BLE001 - invalid key
                    _log.warning(""Invalid wallet key: %s"", exc)
            if signer:
                await client.send_transaction(tx, signer)
            else:
                await client.send_transaction(tx)
            _log.info(""Broadcasted Merkle root %s"", root)
        except Exception as exc:  # pragma: no cover - network errors
            _log.warning(""Failed to broadcast Merkle root: %s"", exc)
        finally:
            try:
                await client.close()
            except Exception:  # pragma: no cover - ignore close errors
                pass
",alpha_factory_v1/common/utils/logging.py,Ledger
survived,"    def format(self, record: logging.LogRecord) -> str:  # noqa: D401 - short
        data = {
            ""ts"": datetime.fromtimestamp(record.created).isoformat(timespec=""seconds""),
            ""lvl"": record.levelname,
            ""name"": record.name,
            ""msg"": record.getMessage(),
        }
        return json.dumps(data)
",alpha_factory_v1/common/utils/logging.py,_JsonFormatter
survived,"    def __enter__(self) -> ""Ledger"":
        """"""Return ``self`` for context manager support.""""""
        return self
",alpha_factory_v1/common/utils/logging.py,Ledger
survived,"def _env_int(name: str, default: int) -> int:
    try:
        return int(os.getenv(name, default))
    except (TypeError, ValueError):
        return default
",alpha_factory_v1/common/utils/config.py,
survived,"    def __init__(self, settings: Settings) -> None:
        self.settings = settings
        self._subs: Dict[str, List[Callable[[EnvelopeLike], Awaitable[None] | None]]] = {}
        self._server: ""grpc.aio.Server | None"" = None
        self._producer: Optional[AIOKafkaProducer] = None
        self._handshake_peers: set[str] = set()
        self._handshake_failures: TTLCache[str, int] = TTLCache(maxsize=1024, ttl=self.HANDSHAKE_TTL)
        self._handshake_nonces: TTLCache[str, None] = TTLCache(maxsize=1024, ttl=self.HANDSHAKE_TTL)
",alpha_factory_v1/common/utils/messaging.py,A2ABus
survived,"    async def stop_merkle_task(self) -> None:
        if self._task:
            self._task.cancel()
            try:
                await self._task
            except asyncio.CancelledError:  # pragma: no cover - expected
                pass
            self._task = None
",alpha_factory_v1/common/utils/logging.py,Ledger
survived,"    async def start(self) -> None:
        self._rest_task, self._grpc_server = await start_servers(
            self._runners,
            self._model_max_bytes,
            self._mem,
            self._rest_port,
            self._grpc_port,
            self._loglevel,
            self._ssl_disable,
        )
",alpha_factory_v1/backend/services/api_server_service.py,APIServer
survived,"async def test_api_server_start_stop(monkeypatch):
    events = []

    async def fake_start_servers(*a, **k):
        events.append(""start"")

        async def sleeper():
            await asyncio.sleep(0)
        task = asyncio.create_task(sleeper())
        server = SimpleNamespace(stop=lambda code=0: events.append(""stop""))
        return task, server

    monkeypatch.setattr(
        ""alpha_factory_v1.backend.services.api_server_service.start_servers"",
        fake_start_servers,
    )

    srv = APIServer({}, 1, object(), 0, 0, ""INFO"", True)
    await srv.start()
    assert events == [""start""]
    await srv.stop()
    assert events[-1] == ""stop""",tests/test_api_server_service.py,
survived,"    async def stop(self) -> None:
        if self._rest_task:
            self._rest_task.cancel()
            with contextlib.suppress(asyncio.CancelledError):
                await self._rest_task
        if self._grpc_server:
            self._grpc_server.stop(0)",alpha_factory_v1/backend/services/api_server_service.py,APIServer
survived,"def main() -> None:
    if update():
        print(""Workflow updated."")
    else:
        print(""Workflow already up to date."")
",tools/update_actions.py,
survived,"def fetch_latest(owner_repo: str) -> tuple[str, str] | None:
    """"""Return the newest tag name and commit sha for a GitHub action.""""""
    url = f""https://api.github.com/repos/{owner_repo}/tags""
    try:
        resp = requests.get(url, timeout=60)
        resp.raise_for_status()
    except requests.RequestException as exc:
        sys.stderr.write(f""Failed to fetch {url}: {exc}\n"")
        return None
    tags = resp.json()
    if not tags:
        return None
    tag = tags[0]
    return tag[""name""], tag[""commit""][""sha""]
",tools/update_actions.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-h/compiler/py/q8.py,Auto1
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-h/compiler/py/q20.py,Auto3
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-h/compiler/py/q4.py,_Group
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-h/compiler/py/q16.py,Auto1
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-h/compiler/py/q14.py,Auto1
survived,"        def seed(self, seed: int) -> None:
            self._rand = random.Random(seed)
",src/meta_agent/embedding_models.py,_RandomNormal
survived,"        def normal(self, mu: float, sigma: float, size: int):
            return [self._rand.gauss(mu, sigma) for _ in range(size)]
",src/meta_agent/embedding_models.py,_RandomNormal
survived,"    def test_accumulate_entries(self) -> None:
        with tempfile.TemporaryDirectory() as tmp:
            ledger = Path(tmp) / 'log.json'
            for seed in ('1', '2'):
                result = subprocess.run(
                    [
                        sys.executable,
                        STUB,
                        '-n',
                        '1',
                        '--seed',
                        seed,
                        '--ledger',
                        str(ledger),
                        '--model',
                        'gpt-4o-mini',
                    ],
                    capture_output=True,
                    text=True,
                )
                self.assertEqual(result.returncode, 0, result.stderr)

            logged = json.loads(ledger.read_text())
            self.assertIsInstance(logged, list)
            self.assertEqual(len(logged), 2)
",tests/test_cross_alpha_discovery.py,TestCrossAlphaDiscoveryStub
survived,"    def test_env_overrides_default_ledger(self) -> None:
        default = Path(STUB).with_name(""cross_alpha_log.json"")
        if default.exists():
            default.unlink()
        with tempfile.TemporaryDirectory() as tmp:
            ledger = Path(tmp) / ""env_log.json""
            env = os.environ.copy()
            env[""CROSS_ALPHA_LEDGER""] = str(ledger)
            result = subprocess.run(
                [
                    sys.executable,
                    STUB,
                    ""-n"",
                    ""1"",
                    ""--seed"",
                    ""3"",
                    ""--model"",
                    ""gpt-4o-mini"",
                ],
                capture_output=True,
                text=True,
                env=env,
            )
            self.assertEqual(result.returncode, 0, result.stderr)
            self.assertFalse(default.exists(), ""default ledger should not be used"")
            self.assertTrue(ledger.exists())
            data = json.loads(ledger.read_text())
            self.assertIsInstance(data, list)
            self.assertEqual(len(data), 1)
",tests/test_cross_alpha_discovery.py,TestCrossAlphaDiscoveryStub
survived,"    def test_alpha_factory_import(self) -> None:
        mod = importlib.import_module(""alpha_factory_v1"")
        self.assertTrue(hasattr(mod, ""__version__""))
",tests/test_imports.py,TestImports
survived,"    def setUp(self):
        self._registry_backup = AGENT_REGISTRY.copy()
        AGENT_REGISTRY.clear()
",tests/test_agents_registry.py,TestHealthQuarantine
survived,"            async def step(self):
                return None
",tests/test_agents_registry.py,TestAgentRegistryFunctions.DAgent
survived,"    def test_exception_metrics(self) -> None:
        agent = DummyAgent()
        agent._metrics_run = _Counter()
        agent._metrics_err = _Counter()
        agent._metrics_lat = _Gauge()
        asyncio.run(agent._safe_step({""agent"": agent.NAME}))
        self.assertEqual(agent.calls, 1)
        self.assertEqual(agent._metrics_run.count, 1)
        self.assertEqual(agent._metrics_err.count, 1)
        self.assertIsNotNone(agent._metrics_lat.value)
",tests/test_agent_base.py,TestSafeStep
survived,"    def test_battery_optim_no_pulp(self):
        with patch.object(energy_agent, ""pulp"", None):
            res = energy_agent._battery_optim([1, 2], [3, 4])
        self.assertEqual(res, {""schedule"": []})
",tests/test_energy_utils.py,TestEnergyUtils
survived,"def test_agent_runner_loop_publishes_heartbeat() -> None:
    agent = DummyAgent()
    runner = orchestrator.AgentRunner(agent)

    events: list[tuple[str, str]] = []

    class Bus:
        def publish(self, topic: str, env: messaging.Envelope) -> None:
            events.append((""pub"", env.sender))

    class Ledger:
        def log(self, env: messaging.Envelope) -> None:
            events.append((""log"", env.sender))

    bus = Bus()
    led = Ledger()

    async def run_once() -> None:
        async def _sleep(_: float) -> None:
            raise asyncio.CancelledError()

        with patch.object(asyncio, ""sleep"", _sleep):
            with contextlib.suppress(asyncio.CancelledError):
                await runner.loop(bus, led)

    asyncio.run(run_once())

    assert agent.calls == 1
    assert (""pub"", ""dummy"") in events
    assert (""log"", ""dummy"") in events",tests/test_agent_runner.py,
survived,"        async def _sleep(_: float) -> None:
            raise asyncio.CancelledError()
",tests/test_agent_runner.py,
survived,"async def test_loop_until_condition():
    counter = {""i"": 0}

    async def step(prompt, **kwargs):
        counter[""i""] += 1
        return counter[""i""]

    wf = Workflow(
        name=""wf"",
        steps=[
            WorkflowStep(
                runner=step,
                mode=StepMode.LOOP,
                condition=lambda r: r >= 2,
                max_iterations=5,
            )
        ],
    )

    result = await wf.run(0)
    assert result >= 2
    assert counter[""i""] <= 2",tests/test_workflow.py,
survived,"def _no_missing(monkeypatch: pytest.MonkeyPatch) -> None:
    monkeypatch.setattr(check_env, ""REQUIRED"", [])
    monkeypatch.setattr(check_env, ""OPTIONAL"", [])
    monkeypatch.setattr(check_env, ""warn_missing_core"", lambda: [])
",tests/test_check_env_network.py,
survived,"def test_scatter_set():
    B, V = Axis(""batch"", 2), Axis(""vocab"", 6)
    x = hax.zeros((B, V))
    idx = hax.named(jnp.array([1, 4]), B)
    val = hax.ones(B) * 9
    y = x.at[{V: idx}].set(val)
    ref = jnp.zeros((2, 6)).at[jnp.arange(2), idx.array].set(9)
    assert jnp.array_equal(y.array, ref)",tests/test_scatter_gather.py,
survived,"    def __init__(self, max_seqs: int, max_len: int, eos: int):
        self.max_seqs = max_seqs
        self.max_len = max_len
        self.eos = eos
",src/levanter/inference/scheduler.py,JittedScheduler
survived,"    def __init__(self, eos: int):
        self.eos = eos
        self.waiting: Deque[Sequence] = deque()
        self.running: Deque[Sequence] = deque()
",src/levanter/inference/scheduler.py,Scheduler
survived,"    def last_token(self) -> int:
        return self.token_ids[-1]
",src/levanter/inference/sequence.py,Sequence
survived,"def slide_neighbours(n):
    movelist = []
    for gap in range(n*n):
        x, y = gap % n, gap // n
        moves = []
        if x > 0: moves.append(-1)    # Move the gap left.
        if x < n-1: moves.append(+1)  # Move the gap right.
        if y > 0: moves.append(-n)    # Move the gap up.
        if y < n-1: moves.append(+n)  # Move the gap down.
        movelist.append(moves)

    def neighbours(p):
        gap = p.index(0)
        l = list(p)

        for m in movelist[gap]:
            l[gap] = l[gap + m]
            l[gap + m] = 0
            yield (1, tuple(l), (l[gap], m))
            l[gap + m] = l[gap]
            l[gap] = 0

    return neighbours
",tests/rosetta/x/Python/15-puzzle-solver/15-puzzle-solver-1.py,
survived,"def listconflicts(goal_list):
    """"""
    list all possible start lists that will have at least
    one linear conflict.

    Possible goal tile configurations

    g g g g
    g g g x
    g g x g
    g x g g
    x g g g
    g g x x
    g x g x
    g x x g
    x g g x
    x g x g
    x x g g

    """"""

    all_tiles = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]

    non_goal_tiles = []

    for t in all_tiles:
        if t not in goal_list:
            non_goal_tiles.append(t)

    combinations = lcmap()

    # g g g g

    for i in goal_list:
        tile_list2 = goal_list[:]
        tile_list2.remove(i)
        for j in tile_list2:
            tile_list3 = tile_list2[:]
            tile_list3.remove(j)
            for k in tile_list3:
                tile_list4 = tile_list3[:]
                tile_list4.remove(k)
                for l in tile_list4:
                    start_list = (i, j, k, l)
                    conflictadd = linear_conflicts(start_list,goal_list)
                    if conflictadd > 0:
                        combinations[start_list]=conflictadd

    # g g g x

    for i in goal_list:
        tile_list2 = goal_list[:]
        tile_list2.remove(i)
        for j in tile_list2:
            tile_list3 = tile_list2[:]
            tile_list3.remove(j)
            for k in tile_list3:
                for l in non_goal_tiles:
                    start_list = (i, j, k, l)
                    conflictadd = linear_conflicts(start_list,goal_list)
                    if conflictadd > 0:
                        combinations[start_list]=conflictadd

    # g g x g

    for i in goal_list:
        tile_list2 = goal_list[:]
        tile_list2.remove(i)
        for j in tile_list2:
            tile_list3 = tile_list2[:]
            tile_list3.remove(j)
            for k in non_goal_tiles:
                for l in tile_list3:
                    start_list = (i, j, k, l)
                    conflictadd = linear_conflicts(start_list,goal_list)
                    if conflictadd > 0:
                        combinations[start_list]=conflictadd
    # g x g g

    for i in goal_list:
        tile_list2 = goal_list[:]
        tile_list2.remove(i)
        for j in non_goal_tiles:
            for k in tile_list2:
                tile_list3 = tile_list2[:]
                tile_list3.remove(k)
                for l in tile_list3:
                    start_list = (i, j, k, l)
                    conflictadd = linear_conflicts(start_list,goal_list)
                    if conflictadd > 0:
                        combinations[start_list]=conflictadd

    # x g g g

    for i in non_goal_tiles:
        for j in goal_list:
            tile_list2 = goal_list[:]
            tile_list2.remove(j)
            for k in tile_list2:
                tile_list3 = tile_list2[:]
                tile_list3.remove(k)
                for l in tile_list3:
                    start_list = (i, j, k, l)
                    conflictadd = linear_conflicts(start_list,goal_list)
                    if conflictadd > 0:
                        combinations[start_list]=conflictadd

    # g g x x

    for i in goal_list:
        tile_list2 = goal_list[:]
        tile_list2.remove(i)
        for j in tile_list2:
            tile_list3 = tile_list2[:]
            tile_list3.remove(j)
            for k in non_goal_tiles:
                tile_list4 = non_goal_tiles[:]
                tile_list4.remove(k)
                for l in tile_list4:
                    start_list = (i, j, k, l)
                    conflictadd = linear_conflicts(start_list,goal_list)
                    if conflictadd > 0:
                        combinations[start_list]=conflictadd

    # g x g x

    for i in goal_list:
        tile_list2 = goal_list[:]
        tile_list2.remove(i)
        for j in non_goal_tiles:
            tile_list3 = non_goal_tiles[:]
            tile_list3.remove(j)
            for k in tile_list2:
                for l in tile_list3:
                    start_list = (i, j, k, l)
                    conflictadd = linear_conflicts(start_list,goal_list)
                    if conflictadd > 0:
                        combinations[start_list]=conflictadd

    # g x x g

    for i in goal_list:
        tile_list2 = goal_list[:]
        tile_list2.remove(i)
        for j in non_goal_tiles:
            tile_list3 = non_goal_tiles[:]
            tile_list3.remove(j)
            for k in tile_list2:
                for l in tile_list3:
                    start_list = (i, j, k, l)
                    conflictadd = linear_conflicts(start_list,goal_list)
                    if conflictadd > 0:
                        combinations[start_list]=conflictadd

    # x g g x

    for i in non_goal_tiles:
        tile_list2 = non_goal_tiles[:]
        tile_list2.remove(i)
        for j in goal_list:
            tile_list3 = goal_list[:]
            tile_list3.remove(j)
            for k in tile_list3:
                for l in tile_list2:
                    start_list = (i, j, k, l)
                    conflictadd = linear_conflicts(start_list,goal_list)
                    if conflictadd > 0:
                        combinations[start_list]=conflictadd

    # x g x g

    for i in non_goal_tiles:
        tile_list2 = non_goal_tiles[:]
        tile_list2.remove(i)
        for j in goal_list:
            tile_list3 = goal_list[:]
            tile_list3.remove(j)
            for k in tile_list3:
                for l in tile_list2:
                    start_list = (i, j, k, l)
                    conflictadd = linear_conflicts(start_list,goal_list)
                    if conflictadd > 0:
                        combinations[start_list]=conflictadd

    # x x g g

    for i in non_goal_tiles:
        tile_list2 = non_goal_tiles[:]
        tile_list2.remove(i)
        for j in tile_list2:
            for k in goal_list:
                tile_list3 = goal_list[:]
                tile_list3.remove(k)
                for l in tile_list3:
                    start_list = (i, j, k, l)
                    conflictadd = linear_conflicts(start_list,goal_list)
                    if conflictadd > 0:
                        combinations[start_list]=conflictadd

    return combinations
",tests/rosetta/x/Python/15-puzzle-solver/15-puzzle-solver-2.py,
survived,"    def __repr__(self):
        # printable version of self
        strrep = """"
        for e in self.qheap:
          fscore, tiles = e
          strrep += str(fscore)+"":""+str(tiles)+""\n""

        return strrep
",tests/rosetta/x/Python/15-puzzle-solver/15-puzzle-solver-2.py,PriorityQueue
survived,"    def test_list_option(self) -> None:
        result = subprocess.run([sys.executable, STUB, '--list'], capture_output=True, text=True)
        self.assertEqual(result.returncode, 0)
        data = json.loads(result.stdout)
        self.assertIsInstance(data, list)
        self.assertGreaterEqual(len(data), 5)
",tests/test_alpha_discovery_stub.py,TestAlphaDiscoveryStub
survived,"    async def policy(self, obs, ctx):  # type: ignore[override]
        gens = int(obs.get(""gens"", 1)) if isinstance(obs, dict) else 1
        await evolve(gens)
        return await best_alpha()
",alpha_factory_v1/demos/aiga_meta_evolution/openai_agents_bridge.py,EvolverAgent
survived,"def _rest_pnl() -> Any:
    """"""Return P&L via the REST fallback.""""""
    return requests.get(f""{BASE}/api/finance/pnl"", timeout=3).json()
",alpha_factory_v1/demos/finance_alpha/agent_control.py,
survived,"        def run(self) -> None:
            pass
",alpha_factory_v1/demos/muzero_planning/agent_muzero_entrypoint.py,AgentRuntime
survived,"        def __init__(self, *_, **__):
            pass
",alpha_factory_v1/demos/muzero_planning/agent_muzero_entrypoint.py,AgentRuntime
survived,"async def reset_endpoint(background_tasks: BackgroundTasks):
    background_tasks.add_task(service.reset)
    return {""msg"": ""reset scheduled""}
",alpha_factory_v1/demos/aiga_meta_evolution/agent_aiga_entrypoint.py,
survived,"def test_experience_launcher_api_key(tmp_path: Path, monkeypatch: pytest.MonkeyPatch) -> None:
    script = Path(""alpha_factory_v1/demos/era_of_experience/run_experience_demo.sh"")
    config = script.parent / ""config.env""
    docker_log = tmp_path / ""docker.log""
    curl_log = tmp_path / ""curl.log""
    bin_dir = tmp_path / ""bin""
    bin_dir.mkdir()

    docker_stub = bin_dir / ""docker""
    docker_stub.write_text(
        ""#!/usr/bin/env bash\n""
        'echo ""$@"" >> ""$DOCKER_LOG""\n'
        'if [ ""$1"" = ""info"" ]; then echo ""{}""; fi\n'
        'if [ ""$1"" = ""version"" ]; then echo ""24.0.0""; fi\n'
        ""exit 0\n""
    )
    docker_stub.chmod(0o755)

    curl_stub = bin_dir / ""curl""
    curl_stub.write_text(
        ""#!/usr/bin/env bash\n""
        'echo ""$@"" >> ""$CURL_LOG""\n'
        'out=""""\n'
        ""for ((i=1;i<=$#;i++)); do\n""
        '  if [ ""${!i}"" = ""-o"" ]; then\n'
        ""    j=$((i+1))\n""
        ""    out=${!j}\n""
        ""  fi\n""
        ""done\n""
        'if [ -n ""$out"" ]; then echo sample > ""$out""; fi\n'
        'echo ""OK""\n'
    )
    curl_stub.chmod(0o755)

    env = os.environ.copy()
    env.update(
        {
            ""PATH"": f""{bin_dir}:{env['PATH']}"",
            ""SKIP_ENV_CHECK"": ""1"",
            ""SAMPLE_DATA_DIR"": str(tmp_path / ""samples""),
            ""DOCKER_LOG"": str(docker_log),
            ""CURL_LOG"": str(curl_log),
            ""OPENAI_API_KEY"": ""dummy"",
        }
    )

    if config.exists():
        config.unlink()
    try:
        result = subprocess.run([f""./{script.name}""], cwd=script.parent, env=env, capture_output=True, text=True)
        created = config.exists()
    finally:
        if config.exists():
            config.unlink()

    assert result.returncode == 0, result.stderr
    assert docker_log.exists()
    log = docker_log.read_text()
    assert ""--profile offline"" not in log
    assert created
",tests/test_experience_launcher.py,
survived,"    def __eq__(self, other):
        return (
            self.name == other.name
            and self.age == other.age
            and self.status == other.status
        )
",tests/machine/x/python/update_stmt.py,Person
survived,"def test_grpc_bus_tls_message_exchange(tmp_path: Path) -> None:
    from alpha_factory_v1.demos.alpha_agi_insight_v1.src.utils import config, messaging

    port = _free_port()
    cert, key, ca = _make_cert(tmp_path)
    cfg = config.Settings(bus_port=port, bus_cert=cert, bus_key=key, bus_token=""tok"")
    bus = messaging.A2ABus(cfg)
    received: list[messaging.Envelope] = []

    async def run() -> None:
        bus.subscribe(""b"", lambda e: received.append(e))
        await bus.start()
        try:
            creds = grpc.ssl_channel_credentials(root_certificates=ca)
            async with grpc.aio.secure_channel(f""localhost:{port}"", creds) as ch:
                stub = ch.unary_unary(""/bus.Bus/Send"")
                payload = {
                    ""sender"": ""a"",
                    ""recipient"": ""b"",
                    ""payload"": {""v"": 1},
                    ""ts"": 0.0,
                    ""token"": ""tok"",
                }
                await stub(json.dumps(payload).encode())
            await asyncio.sleep(0.05)
        finally:
            await bus.stop()

    asyncio.run(run())
    assert received and received[0].payload[""v""] == 1
",tests/test_agents.py,
survived,"    def _setup_opencl(self) -> None:
        """"""Initialize OpenCL context and compile kernel.""""""
        self._ctx = cl.create_some_context()
        self._queue = cl.CommandQueue(self._ctx)
        kernel = r""""""
        __kernel void sw_diag(
            __global const char* seq1,
            __global const char* seq2,
            __global int* H,
            const int len1,
            const int len2,
            const int diag,
            const int start_i,
            const int match,
            const int mismatch,
            const int gap)
        {
            int gid = get_global_id(0);
            int i = start_i + gid;
            int j = diag - i + 1;
            if(i<=len1 && j>=1 && j<=len2) {
                int diag_idx = (i-1)*(len2+1) + (j-1);
                int up_idx   = (i-1)*(len2+1) + j;
                int left_idx = i*(len2+1) + (j-1);
                int idx      = i*(len2+1) + j;
                int match_val = seq1[i-1]==seq2[j-1] ? match : mismatch;
                int diag_val  = H[diag_idx] + match_val;
                int up_val    = H[up_idx] + gap;
                int left_val  = H[left_idx] + gap;
                int val = diag_val;
                if(up_val > val) val = up_val;
                if(left_val > val) val = left_val;
                if(val < 0) val = 0;
                H[idx] = val;
            }
        }
        """"""
        self._prog = cl.Program(self._ctx, kernel).build()
",src/python/gpu_smith_waterman.py,SmithWatermanGPU
survived,"def sync(
    neo4j_session: neo4j.Session,
    boto3_session: boto3.session.Session,
    regions: List[str],
    current_aws_account_id: str,
    update_tag: int,
    common_job_parameters: Dict,
) -> None:
    for region in regions:
        logger.info(
            f""Syncing ACM certificates for region {region} in account {current_aws_account_id}.""
        )
        certs = get_acm_certificates(boto3_session, region)
        transformed = transform_acm_certificates(certs, region)
        load_acm_certificates(
            neo4j_session,
            transformed,
            region,
            current_aws_account_id,
            update_tag,
        )

    cleanup_acm_certificates(neo4j_session, common_job_parameters)

    merge_module_sync_metadata(
        neo4j_session,
        group_type=""AWSAccount"",
        group_id=current_aws_account_id,
        synced_type=""ACMCertificate"",
        update_tag=update_tag,
        stat_handler=stat_handler,
    )",cartography/intel/aws/acm.py,
survived,"def test_queue_max_size() -> None:
    bus = EventBus(None, True, max_queue_size=2)
    bus.publish(""x"", {""v"": 1})
    bus.publish(""x"", {""v"": 2})
    bus.publish(""x"", {""v"": 3})
    events = bus.read_and_clear(""x"")
    assert events == {""x"": [{""v"": 2}, {""v"": 3}]}",tests/test_eventbus.py,
survived,"    def _slice_batch_info(self, updated_seqs, old_seq_lens, new_table, new_token_counts, tokens):
        mask = updated_seqs >= 0
        safe_updated = hax.where(mask, updated_seqs, 0)

        gathered_page_indices = new_table.page_indices[""seq"", safe_updated]
        page_indices = hax.where(mask, gathered_page_indices, -1)

        seq_lens = new_table.seq_lens[""seq"", safe_updated]
        seq_lens = hax.where(mask, seq_lens, -1)

        num_seqs = hax.sum(mask).scalar()

        token_dests = hax.full(tokens.shape, -1, dtype=jnp.int32)
        seq_cursors = jnp.where(old_seq_lens.array < 0, 0, old_seq_lens.array)

        def token_body(i, carry):
            token_dests, seq_cursors = carry
            seq_id = tokens[""position"", i].scalar()

            def assign(carry):
                token_dests, seq_cursors = carry
                page_idx = seq_cursors[seq_id] // self.page_size
                page_offset = seq_cursors[seq_id] % self.page_size
                page = new_table.page_indices[""seq"", seq_id, ""page"", page_idx]
                dest = hax.where(page < 0, -1, page * self.page_size + page_offset)
                token_dests = token_dests.at[""position"", i].set(dest)
                seq_cursors = seq_cursors.at[seq_id].add(1)
                return token_dests, seq_cursors

            token_dests, seq_cursors = jax.lax.cond(seq_id >= 0, assign, lambda c: c, (token_dests, seq_cursors))
            return token_dests, seq_cursors

        token_dests, _ = jax.lax.fori_loop(0, tokens.axis_size(""position""), token_body, (token_dests, seq_cursors))

        cu_q_lens = hax.concatenate(
            ""seq"",
            [
                hax.zeros({""seq"": 1}, dtype=jnp.int32),
                hax.cumsum(new_token_counts, ""seq"", dtype=jnp.int32),
            ],
        )
        batch_info = PageBatchInfo(
            page_indices=page_indices,
            seq_lens=seq_lens,
            cu_q_lens=cu_q_lens,
            num_seqs=num_seqs,
            new_token_dests=token_dests,
            page_size=self.page_size,
        )
        return batch_info
",src/levanter/layers/page_table.py,PageTable
survived,"            def assign(carry):
                token_dests, seq_cursors = carry
                page_idx = seq_cursors[seq_id] // self.page_size
                page_offset = seq_cursors[seq_id] % self.page_size
                page = new_table.page_indices[""seq"", seq_id, ""page"", page_idx]
                dest = hax.where(page < 0, -1, page * self.page_size + page_offset)
                token_dests = token_dests.at[""position"", i].set(dest)
                seq_cursors = seq_cursors.at[seq_id].add(1)
                return token_dests, seq_cursors
",src/levanter/layers/page_table.py,PageTable
survived,"    def free_pages(self, seq_id: int) -> ""PageTable"":
        new_page_owners = hax.where(self.page_owners == seq_id, -1, self.page_owners)
        new_page_indices = self.page_indices.at[""seq"", seq_id].set(-1)
        new_seq_lens = self.seq_lens.at[""seq"", seq_id].set(-1)

        return dataclasses.replace(
            self,
            page_owners=new_page_owners,
            page_indices=new_page_indices,
            seq_lens=new_seq_lens,
        )
",src/levanter/layers/page_table.py,PageTable
survived,"    async def invoke(
        self, prompt: str, context: Optional[Dict[str, Any]] | None = None
    ) -> str:
        """"""Generate a response for the given prompt.""""""
        ...
",src/meta_agent/services/guardrail_router.py,ModelAdapter
survived,"def square(x):
    return x * x
",tests/kgtests/autograd/helpers.py,
survived,"        def policy(_o: np.ndarray) -> int:
            """"""Random baseline policy used for Monte Carlo evaluation.""""""
            return random.randint(0, 3)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,POETGenerator
survived,"def test_openai_agents_installed_from_wheelhouse(tmp_path: Path, monkeypatch: pytest.MonkeyPatch) -> None:
    wheelhouse = tmp_path / ""wheels""
    wheelhouse.mkdir()
    _make_wheel(wheelhouse, ""openai-agents"", ""0.0.15"")

    monkeypatch.setattr(check_env, ""CORE"", [])
    monkeypatch.setattr(check_env, ""REQUIRED"", [])
    monkeypatch.setattr(check_env, ""OPTIONAL"", [""openai_agents""])
    monkeypatch.setattr(check_env, ""warn_missing_core"", lambda: [])
    monkeypatch.setattr(check_env, ""has_network"", lambda: False)
    monkeypatch.delitem(sys.modules, ""openai_agents"", raising=False)

    rc = check_env.main([""--auto-install"", ""--wheelhouse"", str(wheelhouse)])
    assert rc == 0
    mod = importlib.import_module(""openai_agents"")
    assert getattr(mod, ""__version__"", """") == ""0.0.15""",tests/test_aiga_offline_setup.py,
survived,"async def _make_client() -> tuple[AsyncClient, Any]:
    app = FastAPI()
    app.middleware(""http"")(mod._count_requests)

    @app.get(""/"")
    async def root():
        return {""ok"": True}

    transport = ASGITransport(app=app)
    client = AsyncClient(base_url=""http://test"", transport=transport)
    return client, app
",tests/test_rate_lock.py,
survived,"def test_session_id_deterministic() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri()

    with sync_playwright() as p:
        browser = p.chromium.launch()
        page = browser.new_page()
        page.goto(url)
        page.evaluate(
            ""window.OTEL_ENDPOINT='https://example.com';""
            ""window.confirm=() => true;""
            ""navigator.sendBeacon=(...a)=>{window.beacon=a;return true;}""
        )
        page.reload()
        page.wait_for_selector(""#controls"")
        page.click(""text=Share"")
        page.evaluate(""window.dispatchEvent(new Event('beforeunload'))"")
        first = page.evaluate(""window.beacon[1]"")
        page.reload()
        page.evaluate(
            ""navigator.sendBeacon=(...a)=>{window.beacon=a;return true;}""
        )
        page.wait_for_selector(""#controls"")
        page.click(""text=Share"")
        page.evaluate(""window.dispatchEvent(new Event('beforeunload'))"")
        second = page.evaluate(""window.beacon[1]"")
        import json

        assert json.loads(first)[""session""] == json.loads(second)[""session""]
        browser.close()
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_telemetry.py,
survived,"    def test_csv_gz_load(dest_uri):
        """"""When the source URI is a gzipped CSV file, the data should be ingested.""""""
        with (
            patch(target_fs) as target_fs_mock,
            patch(""ingestr.src.filesystem.glob_files"", wraps=glob_files_override),
        ):
            target_fs_mock.return_value = test_fs
            schema_rand_prefix = f""testschema_fs_{get_random_string(5)}""
            dest_table = f""{schema_rand_prefix}.fs_{get_random_string(5)}""
            result = invoke_ingest_command(
                f""{protocol}://bucket?{auth}"",
                ""/data.csv.gz"",
                dest_uri,
                dest_table,
            )
            assert result.exit_code == 0
            assert_rows(dest_uri, dest_table, 5)
",ingestr/main_test.py,
survived,"    def test_parquet_gz_load(dest_uri):
        """"""When the source URI is a gzipped Parquet file, the data should be ingested.""""""
        with (
            patch(target_fs) as target_fs_mock,
            patch(""ingestr.src.filesystem.glob_files"", wraps=glob_files_override),
        ):
            target_fs_mock.return_value = test_fs
            schema_rand_prefix = f""testschema_fs_{get_random_string(5)}""
            dest_table = f""{schema_rand_prefix}.fs_{get_random_string(5)}""
            result = invoke_ingest_command(
                f""{protocol}://bucket?{auth}"",
                ""/data.parquet.gz"",
                dest_uri,
                dest_table,
            )
            assert result.exit_code == 0
            assert_rows(dest_uri, dest_table, 5)
",ingestr/main_test.py,
survived,"        def __exit__(self, *exc: object) -> None:
            pass
",tests/test_check_env_network.py,_Sock
survived,"def test_capability_growth_params() -> None:
    """"""Capability growth should forward ``k`` and ``x0``.""""""
    val_default = forecast.capability_growth(0.5, curve=""logistic"")
    val_custom = forecast.capability_growth(0.5, curve=""logistic"", k=5.0, x0=0.0)
    assert val_custom == pytest.approx(forecast.logistic_curve(0.5, k=5.0))
    assert val_custom != val_default
",tests/test_forecast.py,
survived,"    def fold_via(self, fn: Callable[..., CarryT]):
        """"""Return a function that folds over the sequence using ``fn``.

        ``fn`` should take a block and a carry and return a new carry. The
        returned function mirrors :func:`haliax.fold` over the block axis.
        """"""

        def do_fold(init: CarryT) -> CarryT:
            carry = init
            for block in self.blocks:
                carry = fn(block, carry)
                carry = tree_checkpoint_name(carry, self._carry_ckpt_name)
            return carry

        return do_fold
",src/haliax/nn/scan.py,BlockSeq
survived,"    def _tool(*_a: object, **_k: object) -> object:
        def _decorator(func: object) -> object:
            return func

        return _decorator
",tests/test_aiga_agents_import.py,
survived,"        async def runner() -> None:
            self.assertIsInstance(self.agent.forecast_demand(), str)
            self.assertIsInstance(self.agent.optimise_dispatch(), str)
            self.assertIsInstance(self.agent.hedge_strategy(), str)
",tests/test_energy_agent.py,TestEnergyAgentSyncRun
survived,"def test_dgm_import(tmp_path: Path) -> None:
    log_dir = Path(""tests/fixtures/dgm_logs"")
    db_path = tmp_path / ""archive.db""
    count = dgm_import.import_logs(log_dir, db_path=db_path)
    assert count == 80

    db = ArchiveDB(db_path)
    history = list(db.history(""h79""))
    assert len(history) == 80",tests/test_dgm_import.py,
survived,"    def update(self, metrics: Mapping[str, Mapping[str, float]]) -> None:
        """"""Update rolling stats and switch datasets when thresholds pass.""""""

        rate = metrics.get(self._dataset, {}).get(""pass_rate"")
        if rate is not None:
            self.history.append(rate)
        if not self.history:
            return
        avg = sum(self.history) / len(self.history)

        if self._dataset == self.MINI and avg >= 0.40:
            self._dataset = self.FULL
            self.history.clear()
            self.db.set_state(""dataset"", self._dataset)
            self._log.info(""switched dataset to %s"", self._dataset)
        elif self._dataset == self.FULL and avg >= 0.60:
            self._dataset = self.POLYGLOT
            self.history.clear()
            self.db.set_state(""dataset"", self._dataset)
            self._log.info(""switched dataset to %s"", self._dataset)",src/eval/fitness.py,CurriculumSwitcher
survived,"    def dataset(self) -> str:
        """"""Return the active dataset name.""""""

        return self._dataset
",src/eval/fitness.py,CurriculumSwitcher
survived,"    def test_task_waits_for_self_mod(self) -> None:
        archive = InMemoryArchive()
        events: list[Phase] = []
        current: Phase | None = None

        def hook(p: Phase) -> None:
            nonlocal current
            current = p

        def op(g):
            return g + 1

        async def evaluate(_g):
            events.append(current)
            return 0.0, 0.01

        asyncio.run(
            evolve(op, evaluate, archive, max_cost=0.02, phase_hook=hook)
        )

        assert Phase.SELF_MOD in events
        assert Phase.TASK_SOLVE in events
        first_task = events.index(Phase.TASK_SOLVE)
        assert all(e == Phase.SELF_MOD for e in events[:first_task])
",tests/test_phase_order.py,TestPhaseOrder
survived,"def test_a2a_port_zero(monkeypatch):
    """"""`_A2A` should remain ``None`` when ``A2A_PORT=0``.""""""
    dummy = types.ModuleType(""a2a"")

    class DummySocket:
        def __init__(self, *args, **kwargs) -> None:  # pragma: no cover - dummy
            raise AssertionError(""should not be instantiated"")

    dummy.A2ASocket = DummySocket
    monkeypatch.setitem(sys.modules, ""a2a"", dummy)
    monkeypatch.setenv(""A2A_PORT"", ""0"")
    if MODULE in sys.modules:
        del sys.modules[MODULE]
    mod = importlib.import_module(MODULE)
    assert mod._A2A is None
",tests/test_alpha_agi_business_3_v1.py,
survived,"def main() -> None:
    ap = argparse.ArgumentParser(description=""Export tree visualization data"")
    ap.add_argument(""logs"", type=Path, nargs=""+"", help=""JSONL log files"")
    ap.add_argument(
        ""-o"",
        ""--output"",
        type=Path,
        default=Path(""tree.json""),
        help=""Destination JSON path"",
    )
    args = ap.parse_args()

    recs = _read_logs(args.logs)
    tree = _build_tree(recs)
    args.output.write_text(json.dumps(tree, indent=2))
    print(f""Tree exported â†’ {args.output}"")
",alpha_factory_v1/demos/alpha_agi_insight_v1/tools/export_tree.py,
survived,"            def latest_log(self) -> str:
                return ""log""
",tests/test_openai_bridge_runtime.py,TestAIGABridgeRuntime.DummyEvolver
survived,"    def test_index_row_wildcard(self):
        """"""Select entire first row using wildcard""""""
        self.assert_eval_cmp('[[1 2 3] [4 5 6]]:@[0 []]', '[1 2 3]')
",tests/test_numpy_slice.py,TestNumpySliceBehavior
survived,"def test_python_available() -> None:
    browser_dir = Path(__file__).resolve().parents[1]
    repo_root = browser_dir.parents[3]
    py_snippet = """"""import ast, json, pathlib
txt = pathlib.Path('scripts/fetch_assets.py').read_text()
tree = ast.parse(txt)
assets = {}
for node in tree.body:
    if isinstance(node, ast.Assign):
        for t in node.targets:
            if getattr(t, 'id', None) == 'ASSETS':
                assets = ast.literal_eval(node.value)
print(json.dumps(list(assets.keys())))""""""
    node_code = f""""""
import {{ spawnSync }} from 'child_process';
const out = spawnSync('python', ['-'], {{
  input: `{py_snippet}`,
  cwd: {json.dumps(str(repo_root))},
  encoding: 'utf8',
}});
if (out.error) {{ throw out.error; }}
process.exit(out.status);
""""""
    res = subprocess.run([
        ""node"",
        ""-e"",
        node_code,
    ], cwd=browser_dir, capture_output=True, text=True)
    assert res.returncode == 0, res.stderr",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_build_python.py,
survived,"    def latest_log(self):
        champ = self.best_genome or max(self.population, key=lambda g: sum(g.layers))
        msg = f""Champion {champ.sha}: {champ.to_json()}""
        if self.llm:
            msg += ""\n"" + self.llm(f""Critique genome {champ.to_json()} in â‰¤30 words."")
        return msg
",alpha_factory_v1/demos/aiga_meta_evolution/meta_evolver.py,MetaEvolver
survived,"        def _worker(js: str):
            g = Genome.from_json(js)
            module = import_module(__name__)
            return module.MetaEvolver._simulate(module.MetaEvolver, g)
",alpha_factory_v1/demos/aiga_meta_evolution/meta_evolver.py,MetaEvolver
survived,"    def mutate(self) -> ""Genome"":
        g = copy.deepcopy(self)
        if random.random() < 0.4:
            idx = random.randrange(len(g.layers))
            delta = random.randint(-8, 8)
            new_size = max(4, min(128, g.layers[idx] + delta))
            layers = list(g.layers)
            layers[idx] = new_size
            if random.random() < 0.2 and len(layers) < 4:
                layers.insert(idx, random.choice([16, 32, 64]))
            g.layers = tuple(layers)
        if random.random() < 0.2:
            g.activation = random.choice(list(_ACT))
        if random.random() < 0.1:
            g.hebbian = not g.hebbian
        if random.random() < 0.15:
            g.novelty_weight = round(min(1.0, max(0.0, g.novelty_weight + random.uniform(-0.15, 0.15))), 2)
        return g
",alpha_factory_v1/demos/aiga_meta_evolution/meta_evolver.py,Genome
survived,"    def _evaluate_population(self) -> List[float]:
        if self.parallel and _HAS_RAY:
            return self._ray_eval()
        return self._mp_eval() if self.parallel else self._thread_eval()
",alpha_factory_v1/demos/aiga_meta_evolution/meta_evolver.py,MetaEvolver
survived,"def _wrap_mcp(agent: str, payload: Any) -> Dict[str, Any]:
    return {
        ""mcp_version"": ""0.1"",
        ""agent"": agent,
        ""ts"": _now_iso(),
        ""digest"": _sha256(json.dumps(payload, separators=("","", "":""))),
        ""payload"": payload,
    }
",alpha_factory_v1/backend/agents/drug_design_agent.py,
survived,"def _passes_filters(smi: str) -> bool:
    return PAINS_REGEX.search(smi) is None
",alpha_factory_v1/backend/agents/drug_design_agent.py,
survived,"def test_safari_pyodide_fallback() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri()

    try:
        with sync_playwright() as p:
            browser = p.webkit.launch()
            context = browser.new_context(
                user_agent=(
                    ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) ""
                    ""AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.6 Safari/605.1.15""
                )
            )
            page = context.new_page()
            page.goto(url)
            page.wait_for_selector(""#controls"")
            page.wait_for_selector(""#toast.show"")
            assert ""Pyodide unavailable; using JS only"" in page.inner_text(""#toast"")
            assert page.evaluate(""typeof d3 !== 'undefined'"")
            browser.close()
    except PlaywrightError as exc:
        pytest.skip(f""Playwright browser not installed: {exc}"")",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_safari_pyodide.py,
survived,"def _verify(dest: Path) -> None:
    expected = CHECKSUMS.get(dest.name)
    if expected:
        digest = hashlib.sha256(dest.read_bytes()).hexdigest()
        if digest != expected:
            raise RuntimeError(f""Checksum mismatch for {dest.name}"")
",scripts/download_hf_gpt2.py,
survived,"def test_rgb(h, f):
    """"""test for the SGI image library.""""""
    if h.startswith(b'\001\332'):
        return 'rgb'
",metaflow/_vendor/imghdr/__init__.py,
survived,"def lidarr_export(cfg: configparser.ConfigParser) -> None:
    baseurl = cfg[""lidarr""][""baseurl""]
    api_key = cfg[""lidarr""][""api_key""]
    headers = {""Content-type"": ""application/json"", ""X-Api-Key"": api_key}
    url = f""{baseurl}/api/v1/artist""
    rsp = requests.get(url, headers=headers)
    rsp.raise_for_status()
    data = rsp.json()
    with open(""lidarr_backup.csv"", ""w"", newline="""", encoding=""utf-8"") as f:
        writer = csv.writer(f)
        writer.writerow([""artist"", ""foreignArtistId""])
        for d in data:
            writer.writerow([d.get(""artistName""), d.get(""foreignArtistId"")])
",arr_gui.py,
survived,"    def gen_span_id(self) -> str:
        """"""Generate a new span ID.""""""
        return f""span_{uuid.uuid4().hex[:24]}""
",src/agents/tracing/setup.py,TraceProvider
survived,"    def __call__(self, text: str) -> str:
        words = text.split()
        if not words:
            return text
        idx = self.rng.randrange(len(words))
        w = words[idx].lower()
        words[idx] = self.synonyms.get(w, words[idx])
        return "" "".join(words)
",src/simulation/mats_ops.py,PromptRewrite
survived,"        def raise_for_status(self) -> None:
            pass
",tests/test_llm_client_offline.py,DummyResp
survived,"def iter_demos() -> list[Path]:
    return sorted(p for p in DOCS_DIR.iterdir() if p.is_dir() and (p / ""index.html"").exists())
",scripts/verify_demo_pages.py,
survived,"def test_publish_grpc() -> None:
    port = _free_port()
    cfg = config.Settings(bus_port=port, allow_insecure=True)
    bus = messaging.A2ABus(cfg)
    received: list[messaging.Envelope] = []

    def handler(env: messaging.Envelope) -> None:
        received.append(env)

    bus.subscribe(""x"", handler)

    async def run() -> None:
        async with bus:
            async with grpc.aio.insecure_channel(f""localhost:{port}"") as ch:
                stub = ch.unary_unary(""/bus.Bus/Send"")
                payload = {
                    ""sender"": ""a"",
                    ""recipient"": ""x"",
                    ""payload"": {""v"": 1},
                    ""ts"": 0.0,
                }
                await stub(json.dumps(payload).encode())
                await asyncio.sleep(0)

    asyncio.run(run())

    assert len(received) == 1
    assert received[0].payload[""v""] == 1
",tests/test_message_bus.py,
survived,"        def __call__(self, *args, **kwargs):  # noqa: D401
            raise ModuleNotFoundError(
                ""The OpenAI Agents SDK is required for this operation. ""
                ""Please install it with:  pip install openai-agents""
            )
",alpha_factory_v1/backend/__init__.py,_MissingSDK
survived,"  async def get_co2(self) -> CytomatIncupationResponse:
    return await self.get_incubation_query(""ic"")
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend
survived,"  async def get_sensor_register(self) -> SensorStates:
    hex_value = await self.send_command(""ch"", ""ts"", """")
    binary_values = hex_to_base_twelve(hex_value)
    return SensorStates(
      **{member.name: bool(int(binary_values[member.value])) for member in SensorRegister}
    )
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend
survived,"  async def send_action(
    self, command_type: str, command: str, params: str, timeout: Optional[int] = 60
  ) -> OverviewRegisterState:
    """"""Calls send_command, but has a timeout handler and returns the overview register state.
    Args:
      timeout: The maximum time to wait for the command to complete. If None, the command will not
        wait for completion.
    """"""
    await self.send_command(command_type, command, params)
    if timeout is not None:
      overview_register = await self.wait_for_task_completion(timeout=timeout)
    return overview_register
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend
survived,"  async def action_storage_to_transfer(  # used by retrieve_plate
    self, site: PlateHolder
  ) -> OverviewRegisterState:
    """"""Retrieve from storage, open door, move to transfer, close door""""""
    return await self.send_action(""mv"", ""st"", self._site_to_firmware_string(site))
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend
survived,"def cytomat_rack_10mm_47(name: str):
  return _cytomat_rack(name=name, site_height=10, num_sites=47, model=""cytomat_rack_10mm_47"")
",pylabrobot/storage/cytomat/racks.py,
survived,"  async def initialize(self):
    await self._send_command(""ST 1900"")
    await self._send_command(""ST 1801"")
    await self._wait_ready()
",pylabrobot/storage/cytomat/heraeus_cytomat_backend.py,HeraeusCytomatBackend
survived,"  def deserialize(cls, data: dict):
    return cls(num_slots=data[""num_slots""], pitch=data[""pitch""])
",pylabrobot/storage/cytomat/constants.py,CytomatRack
survived,"  async def setup(self, **backend_kwargs):
    await super().setup()
    await self.backend.set_racks(self._racks)
",pylabrobot/storage/incubator.py,Incubator
survived,"  def _site_to_firmware_string(self, site: PlateHolder) -> str:
    rack = cast(PlateCarrier, site.parent)
    rack_idx = [rack.name for rack in self._racks].index(
      rack.name
    )  # autoreload resistant, should work
    site_idx = next(idx for idx, s in rack.sites.items() if s == site)

    if self.model in [CytomatType.C2C_425]:
      return f""{str(rack_idx).zfill(2)} {str(site_idx).zfill(2)}""

    # TODO: configure all cytomats to use `rack site` format
    if self.model in [
      CytomatType.C6000,
      CytomatType.C6002,
      CytomatType.C2C_450_SHAKE,
      CytomatType.C5C,
    ]:
      slots_to_skip = sum(r.capacity for r in self._racks[:rack_idx])
      absolute_slot = slots_to_skip + site_idx + 1  # 1-indexed

      return f""{absolute_slot:03}""

    raise ValueError(f""Unsupported Cytomat model: {self.model}"")
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend
survived,"  async def initialize(self) -> None:
    await self.send_action(""ll"", ""in"", """", timeout=300)  # this command sometimes times out
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend
survived,"  async def start_shaking(self, frequency: float):
    print(f""Starting shaking at {frequency} Hz"")
",pylabrobot/storage/chatterbox.py,IncubatorChatterboxBackend
survived,"  async def open_door(self):
    return await self.send_action(""ll"", ""gp"", ""002"")
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend
survived,"  async def get_temperature(self) -> float:
    """"""Get the temperature of the incubator in degrees Celsius.""""""
",pylabrobot/storage/backend.py,IncubatorBackend
survived,"  async def set_temperature(self, temperature: float):
    """"""Set the temperature of the incubator in degrees Celsius.""""""
",pylabrobot/storage/backend.py,IncubatorBackend
survived,"    def __init__(self, registry: Optional[TemplateRegistry] = None) -> None:
        self.registry = registry or TemplateRegistry()
        self.env = Environment(loader=_RegistryLoader(self.registry))
",src/meta_agent/template_mixer.py,TemplateMixer
survived,"    def get_source(
        self, environment: Environment, template: str
    ) -> Tuple[str, str, Any]:
        slug, version = _split_name(template)
        source = self.registry.load_template(slug, version)
        if source is None:
            raise TemplateNotFound(template)
        return source, template, lambda: True
",src/meta_agent/template_mixer.py,_RegistryLoader
survived,"    def _save_ratings(self, data: Dict[str, List[int]]) -> None:
        with open(self.ratings_path, ""w"", encoding=""utf-8"") as f:
            json.dump(data, f, indent=2)
",src/meta_agent/template_sharing.py,TemplateSharingManager
survived,"    def on_end(run: RunTree) -> None:
        nonlocal collected_run
        collected_run = run
",python/tests/unit_tests/test_run_helpers.py,
survived,"def unique_counts(
    array: NamedArray,
    Unique: Axis,
    *,
    axis: AxisSelector | None = None,
    fill_value: ArrayLike | None = None,
) -> tuple[NamedArray, NamedArray]:
    """"""Shortcut for :func:`unique` that also returns counts.""""""

    values, counts = typing.cast(
        tuple[NamedArray, NamedArray],
        unique(
            array,
            Unique,
            return_counts=True,
            axis=axis,
            fill_value=fill_value,
        ),
    )
    return values, counts
",src/haliax/ops.py,
survived,"def test_page_cache_extend_simple():
    Seq = Axis(""seq"", 2)
    Page = Axis(""page"", 2)
    MaxPage = Axis(""max_page"", 2)
    Slot = Axis(""slot"", 2)
    KVH = Axis(""kv_head"", 1)
    HD = Axis(""head_dim"", 1)

    cache = PageCache.init(Seq, Page, Slot, KVH, HD, MaxPage, dtype=jnp.float32)

    Tok = Axis(""tok"", 2)
    new_k = hax.arange(Tok).broadcast_axis((KVH, HD)).rearrange((Tok, KVH, HD)) + 1
    new_v = hax.arange(Tok).broadcast_axis((KVH, HD)).rearrange((Tok, KVH, HD)) + 101

    cu = jnp.array([0, 1, 2], dtype=jnp.int32)
    pages = jnp.array([0, 1], dtype=jnp.int32)

    jit_extend = eqx.filter_jit(PageCache.extend)
    cache = jit_extend(cache, new_k, new_v, cu, pages, 2)

    assert jnp.all(cache.kv_lens.array == jnp.array([1, 1], dtype=jnp.int32))
    assert jnp.all(cache.page_indices.array == jnp.array([[0, -1], [1, -1]], dtype=jnp.int32))
    assert cache.kv_pages.array[0, 0, 0, 0] == 1
    assert cache.kv_pages.array[0, 0, 1, 0] == 101
    assert cache.kv_pages.array[1, 0, 0, 0] == 2
    assert cache.kv_pages.array[1, 0, 1, 0] == 102
",tests/test_page_cache.py,
survived,"def test_init_sets_default_stake(tmp_path: Path) -> None:
    repo = _make_repo(tmp_path)
    logs = tmp_path / ""logs""
    logs.mkdir()
    reg = StakeRegistry()
    assert ""meta"" not in reg.stakes
    MetaRefinementAgent(repo, logs, reg)
    assert reg.stakes[""meta""] == 1.0",tests/test_meta_refinement_agent.py,
survived,"def test_generate_basic_tests():
    spec = ToolSpecification(
        name=""greet"",
        purpose=""Greets a user"",
        input_parameters=[ToolParameter(name=""name"", type_=""string"")],
        output_format=""string"",
    )
    test_code = generate_basic_tests(spec)
    assert ""import importlib"" in test_code
    assert ""greet"" in test_code
    # ensure code is syntactically valid
    ast.parse(test_code)",tests/generators/test_test_generator.py,
survived,"    def model_post_init(self, __context: Any) -> None:
        """"""Remove relationship defaults after initialization.""""""
        super().model_post_init(__context)

        for field in self.__class__.relationship_fields():
            if field in self.__dict__:
                del self.__dict__[field]
",src/enrichmcp/entity.py,EnrichModel
survived,"            async def get_one() -> dict[str, float | str]:
                it = mod.stream_macro_events(live=False)
                return await anext(it)
",tests/test_offline_data_feeds.py,
survived,"    def test_live_feed_requires_aiohttp(self) -> None:
        async def run_live() -> None:
            os.environ[""LIVE_FEED""] = ""1""
            orig = data_feeds.aiohttp  # type: ignore[attr-defined]
            data_feeds.aiohttp = None  # type: ignore[attr-defined]
            try:
                it = data_feeds.stream_macro_events(live=True)
                await anext(it)
            finally:
                data_feeds.aiohttp = orig  # type: ignore[attr-defined]
                os.environ.pop(""LIVE_FEED"", None)

        with self.assertRaises(RuntimeError):
            asyncio.run(run_live())
",tests/test_macro_sentinel.py,TestMacroSentinel
survived,"def validate_identifier(value: str, field_name: str) -> None:
    """"""Ensure simple alphanumeric names to avoid path traversal.""""""
    if not _SAFE_NAME_RE.match(value):
        raise HTTPException(status_code=400, detail=f""Invalid {field_name} provided."")
",no-ocr-api/np_ocr/api.py,
survived,"def _lambda1():
    draw.get(1)()
    draw.get(6)()
",tests/rosetta/transpiler/Python/cistercian-numerals.py,
survived,"def printBoard(b):
    print(repeat(""__"", cols) + ""\n\n"")
    r = 0
    while r < rows:
        line = """"
        c = 0
        while c < cols:
            cell = b[r][c]
            if cell == "" "":
                line = line + ""  ""
            else:
                line = line + "" "" + cell
            c = c + 1
        print(line + ""\n"")
        r = r + 1
",tests/rosetta/transpiler/Python/forest-fire.py,
survived,"def parseInt(str):
    i = 0
    neg = False
    if len(str) > 0 and str[0:1] == ""-"":
        neg = True
        i = 1
    n = 0
    digits = {""0"": 0, ""1"": 1, ""2"": 2, ""3"": 3, ""4"": 4, ""5"": 5, ""6"": 6, ""7"": 7, ""8"": 8, ""9"": 9}
    while i < len(str):
        n = n * 10 + digits[str[i:i + 1]]
        i = i + 1
    if neg:
        n = -n
    return n
",tests/rosetta/transpiler/Python/gui-component-interaction.py,
survived,"def formatFloat(f, prec):
    scale = pow10(prec)
    scaled = (f * scale) + 0.5
    n = (int(scaled))
    digits = str(n)
    while len(digits) <= prec:
        digits = ""0"" + digits
    intPart = digits[0:len(digits) - prec]
    fracPart = digits[len(digits) - prec:len(digits)]
    return intPart + ""."" + fracPart
",tests/rosetta/transpiler/Python/functional-coverage-tree.py,
survived,"def pad(n, width):
    s = str(n)
    while len(s) < width:
        s = "" "" + s
    return s
",tests/rosetta/transpiler/Python/four-is-the-number-of-letters-in-the-....py,
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    nums = [0, 4, 6, 11, 13, 75, 100, 337, -164, 9223372036854775807]
    for n in nums:
        print(fourIsMagic(n))
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/four-is-magic.py,
survived,"def differentiate(a):
    return newFps(lambda n: (float((n + 1))) * extract(a, n + 1))
",tests/rosetta/transpiler/Python/formal-power-series.py,
survived,"def repLeap(year):
    a = int(((year + 1) % 4))
    b = int(((year + 1) % 100))
    c = int(((year + 1) % 400))
    return a == 0 and (b != 0 or c == 0)
",tests/rosetta/transpiler/Python/french-republican-calendar.py,
survived,"def render(g):
    out = """"
    y = 0
    while y < height:
        line = """"
        x = 0
        while x < width:
            line = line + g[y][x]
            x = x + 1
        out = out + line
        if y < height - 1:
            out = out + ""\n""
        y = y + 1
    return out
",tests/rosetta/transpiler/Python/fractal-tree.py,
survived,"def test_percent_dict_fmt_extra_aggressive(state: State):
    s_in = """"""a = '%(?)ld world' % {'?': var}""""""
    s_expected = """"""a = f'{var} world'""""""
    state.aggressive = 2
    assert code_editor.fstringify_code_by_line(s_in, state)[0] == s_expected
",test/test_edits.py,
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/values_builtin.py,
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/for_list_collection.py,
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/var_assignment.py,
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/nested_function.py,
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/string_prefix_slice.py,
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/fun_call.py,
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/list_index.py,
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/map_literal_dynamic.py,
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/go_auto.py,
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/string_concat.py,
survived,"        def list_entries(self) -> list[tuple[int, str, str, int]]:
            return [(1, ""foo.tar"", ""deadbeef"", 1)]
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_demo_cli.py,DummyArchive
survived,"def twoSum(nums, target):
    n = len(nums)
    for i in range(n):
        for j in range(i + 1, n):
            if nums[i] + nums[j] == target:
                return [i, j]
    return [-1, -1]
",tests/human/x/python/two-sum.py,
survived,"    def count_nodes(node: Mapping[str, Any]) -> int:
        return 1 + sum(count_nodes(c) for c in node.get(""children"", []))
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_tree_visualization.py,
survived,"def _env_int(name: str, default: int) -> int:
    """"""Return ``int`` environment value or ``default`` if conversion fails.""""""

    try:
        return int(os.getenv(name, default))
    except (TypeError, ValueError):
        return default
",alpha_factory_v1/edge_runner.py,
survived,"    async def stop_merkle_task(self) -> None:  # pragma: no cover - interface
        pass
",tests/test_adk_agent.py,DummyLedger
survived,"    def subscribe(self, _t: str, _h):
        pass
",tests/test_adk_agent.py,DummyBus
survived,"    async def handle(self, env: messaging.Envelope) -> None:
        """"""Store research payload for later summarisation.""""""
        with span(""summariser.handle""):
            val = env.payload.get(""research"")
            if val is not None:
                self._records.append(str(val))",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/adk_summariser_agent.py,ADKSummariserAgent
survived,"    async def run_cycle(self) -> None:
        raise RuntimeError(""boom"")
",tests/test_orchestrator_backoff.py,FailingAgent
survived,"    async def handle(self, _env: orchestrator.messaging.Envelope) -> None:
        pass
",tests/test_orchestrator_backoff.py,FailingAgent
survived,"    def test_skill_test_endpoint(self) -> None:
        app = orchestrator._build_rest({""simple"": Runner(SimpleAgent())})
        self.assertIsNotNone(app)
        client = TestClient(app)
        headers = {""Authorization"": ""Bearer test-token""}
        resp = client.post(""/agent/simple/skill_test"", json={""t"": 1}, headers=headers)
        self.assertEqual(resp.status_code, 200)
        self.assertEqual(resp.json(), {""ok"": True})
",tests/test_skill_test_route.py,TestSkillTestRoute
survived,"def test_branching_and_cid(tmp_path: Path) -> None:
    js_out = tmp_path / ""replay.js""
    subprocess.run([
        ""tsc"",
        ""--target"",
        ""es2020"",
        ""--module"",
        ""es2020"",
        REPLAY_TS,
        ""--outFile"",
        js_out,
    ], check=True)

    script = tmp_path / ""run.mjs""
    script.write_text(
        f""import {{ ReplayDB }} from '{js_out.resolve().as_posix()}';\n""
        ""const db = new ReplayDB('jest');\n""
        ""await db.open();\n""
        ""const root = await db.addFrame(null,{msg:'root'});\n""
        ""const a = await db.addFrame(root,{msg:'a'});\n""
        ""const b = await db.addFrame(root,{msg:'b'});\n""
        ""const cid1 = await db.computeCid(b);\n""
        ""const thread = await db.exportThread(b);\n""
        ""const cid2 = await ReplayDB.cidForFrames(thread);\n""
        ""console.log(thread.length,cid1===cid2);\n"",
        encoding=""utf-8"",
    )
    res = subprocess.run([""node"", script], capture_output=True, text=True, check=True)
    parts = res.stdout.strip().split()
    assert int(parts[0]) == 2
    assert parts[1] == ""true""",tests/test_replay_ts.py,
survived,"def make_cfg():
    return OmegaConf.create({
        'seed': {'train': 7},
        'es_manager': {
            'train': {
                'env_groups': 1,
                'group_size': 1,
                'env_configs': {'tags': ['Bandit'], 'n_groups': [1]},
            }
        },
        'custom_envs': {
            'Bandit': {
                'env_type': 'bandit',
                'max_actions_per_traj': 1,
                'env_config': None
            }
        }
    })
",tests/es_manager/test_seed_iteration.py,
survived,"def _gen_crc16_table(poly: int) -> list[int]:
    table = []
    for i in range(256):
        crc = i << 8
        for _ in range(8):
            if crc & 0x8000:
                crc = ((crc << 1) ^ poly) & 0xFFFF
            else:
                crc = (crc << 1) & 0xFFFF
        table.append(crc)
    return table
",opendbc/can/packer.py,
survived,"def tesla_checksum(address: int, sig: Signal, d: bytearray) -> int:
    checksum = (address & 0xFF) + ((address >> 8) & 0xFF)
    checksum_byte = sig.start_bit // 8
    for i in range(len(d)):
        if i != checksum_byte:
            checksum += d[i]
    return checksum & 0xFF
",opendbc/can/packer.py,
survived,"    def __init__(self, x: int, y: int):
        self.x = x
        self.y = y
",runtime/ffi/python/testmod.py,Point
survived,"    def visit_While(self, node):
        self.emit(f""while {self.expr(node.test)} {{"")
        self.indent += 1
        for s in node.body:
            self.visit(s)
        self.indent -= 1
        self.emit(""}"")
",tools/any2mochi/py_simple.py,Conv
survived,"    async def _metrics() -> PlainTextResponse:  # noqa: D401
        if ""generate_latest"" not in globals():
            raise HTTPException(503, ""prometheus_client not installed"")
        from .telemetry import generate_latest, CONTENT_TYPE_LATEST

        return PlainTextResponse(generate_latest(), media_type=CONTENT_TYPE_LATEST)
",alpha_factory_v1/backend/api_server.py,
survived,"    def __init__(self, name: str, cycle_seconds: int, max_cycle_sec: int, publish: callable):
        self.name = name
        self.inst = get_agent(name)
        self.period = getattr(self.inst, ""CYCLE_SECONDS"", cycle_seconds)
        self.spec = getattr(self.inst, ""SCHED_SPEC"", None)
        self.next_ts = 0.0
        self.last_beat = time.time()
        self.task: Optional[asyncio.Task] = None
        self._max_cycle_sec = max_cycle_sec
        self._publish = publish
        self._calc_next()

        with contextlib.suppress(ModuleNotFoundError):
            from openai.agents import AgentContext  # type: ignore[attr-defined]

            if isinstance(self.inst, AgentContext):
                from .telemetry import tracer  # avoid circular import
                from openai.agents import AgentRuntime  # type: ignore[attr-defined]

                runtime = AgentRuntime()
                runtime.register(self.inst)
                atexit.register(runtime.close)
",alpha_factory_v1/backend/agent_manager.py,AgentRunner
survived,"def init_metrics(port: int) -> None:
    """"""Start the Prometheus exporter if possible.""""""

    if port and ""start_http_server"" in globals():
        start_http_server(port)
        log.info(""Prometheus metrics exposed at :%d/metrics"", port)",alpha_factory_v1/backend/telemetry.py,
survived,"def _noop_metric(*_a: Any, **_kw: Any) -> Any:
    class _Metric:  # pylint: disable=too-few-public-methods
        def labels(self, *_a: Any, **_kw: Any) -> ""_Metric"":
            return self

        def observe(self, *_a: Any) -> None:
            ...

        def inc(self, *_a: Any) -> None:
            ...

        def set(self, *_a: Any) -> None:
            ...

    return _Metric()
",alpha_factory_v1/backend/telemetry.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/cross_join.py,Customer
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/left_join_multi.py,Customer
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/group_by_multi_join_sort.py,Customer
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/group_by_having.py,Person
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/group_by.py,Person
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/outer_join.py,Order
survived,"async def test_rest_and_quarantine(dev_orchestrator: orch_mod.Orchestrator) -> None:
    app = build_rest(dev_orchestrator.manager.runners, 1024 * 1024, _mem_stub())
    assert app is not None
    client = TestClient(app)
    headers = {""Authorization"": ""Bearer test-token""}

    resp = client.get(""/agents"", headers=headers)
    assert resp.status_code == 200
    assert set(resp.json()) == {""dummy"", ""fail""}

    runner = dev_orchestrator.manager.runners[""fail""]
    await runner.maybe_step()
    if runner.task:
        with contextlib.suppress(Exception):
            await runner.task
    await asyncio.sleep(0.05)
    time.sleep(0.05)  # allow health thread to process

    assert AGENT_REGISTRY[""fail""].cls is StubAgent",tests/test_backend_orchestrator_dev.py,
survived,"    async def step(self) -> None:  # pragma: no cover - simple agent
        return None
",tests/test_backend_orchestrator_dev.py,DummyAgent
survived,"def test_shutdown_stops_loop(non_network: None) -> None:
    """"""The orchestrator loop thread should terminate on app shutdown.""""""
    os.environ[""NO_LLM""] = ""1""
    os.environ.setdefault(""ALPHA_ASI_MAX_STEPS"", ""100000"")

    mod = importlib.import_module(""alpha_factory_v1.demos.alpha_asi_world_model.alpha_asi_world_model_demo"")

    with TestClient(cast(Any, mod.app)) as client:
        client.get(""/agents"")
        loop = mod.loop_thread
        assert loop is not None and loop.is_alive()
    assert loop is not None and not loop.is_alive()",tests/test_world_model_demo.py,
survived,"    async def _run() -> None:
        for env in envs:
            await agent.handle(env)
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_memory_agent_file_persistence.py,
survived,"def test_sandbox_env_limits(monkeypatch) -> None:
    recorded: list[tuple[int, tuple[int, int]]] = []

    def fake_setrlimit(res: int, limits: tuple[int, int]) -> None:
        recorded.append((res, limits))

    def fake_run(*args, **kwargs):
        if kwargs.get(""preexec_fn""):
            kwargs[""preexec_fn""]()

        class P:
            stdout = ""{}""
            stderr = """"

        return P()

    monkeypatch.setenv(""SANDBOX_CPU_SEC"", ""1"")
    monkeypatch.setenv(""SANDBOX_MEM_MB"", ""64"")
    monkeypatch.setattr(codegen_agent.subprocess, ""run"", fake_run)
    fake_resource = type(
        ""R"",
        (),
        {""RLIMIT_CPU"": 0, ""RLIMIT_AS"": 1, ""setrlimit"": fake_setrlimit},
    )
    monkeypatch.setitem(sys.modules, ""resource"", fake_resource)

    agent = _make_agent()
    agent.execute_in_sandbox(""print('hi')"")
    assert (0, (1, 1)) in recorded
    assert (1, (64 * 1024 * 1024, 64 * 1024 * 1024)) in recorded",tests/test_codegen_agent.py,
survived,"def test_simulate_export_formats(export_fmt: str) -> None:
    """"""Ensure simulate exports JSON and CSV correctly.""""""
    runner = CliRunner()
    with patch.object(cli, ""asyncio""):
        with patch.object(cli.orchestrator, ""Orchestrator""):
            res = runner.invoke(
                cli.main,
                [
                    ""simulate"",
                    ""--horizon"",
                    ""1"",
                    ""--offline"",
                    ""--sectors"",
                    ""1"",
                    ""--pop-size"",
                    ""1"",
                    ""--generations"",
                    ""1"",
                    ""--export"",
                    export_fmt,
                ],
            )

    assert res.exit_code == 0
    if export_fmt == ""json"":
        assert res.output.startswith(""["")
    else:
        lines = res.output.splitlines()
        assert lines[0] == ""year,capability,affected""
        assert "","" in lines[1]
",tests/test_demo_cli.py,
survived,"def test_run_forever_shutdown() -> None:
    settings = config.Settings(bus_port=0)
    with mock.patch.object(orchestrator.Orchestrator, ""_init_agents"", lambda self: []):
        orch = orchestrator.Orchestrator(settings)

    async def run() -> None:
        with mock.patch.object(orch.bus, ""stop"", mock.AsyncMock()) as bus_stop, \
             mock.patch.object(orch.ledger, ""stop_merkle_task"", mock.AsyncMock()) as merkle_stop:
            task = asyncio.create_task(orch.run_forever())
            await asyncio.sleep(0.05)
            task.cancel()
            with contextlib.suppress(asyncio.CancelledError):
                await task
            bus_stop.assert_awaited_once()
            merkle_stop.assert_awaited_once()

    asyncio.run(run())",tests/test_orchestrator.py,
survived,"    def binary_path(self, target_dir: str) -> str:
        dep = self.single_for_current_platform()
        if not dep.binary_name:
            return target_dir
        return os.path.join(target_dir, dep.binary_name)
",src/solidlsp/language_servers/common.py,RuntimeDependencyCollection
survived,"    def __init__(self, dependencies: Sequence[RuntimeDependency]):
        self._dependencies = list(dependencies)
",src/solidlsp/language_servers/common.py,RuntimeDependencyCollection
survived,"def test_skip_net_check(monkeypatch: pytest.MonkeyPatch) -> None:
    """"""Ensure --skip-net-check avoids connectivity checks.""""""
    _no_missing(monkeypatch)

    def _fail_net() -> bool:
        raise AssertionError(""has_network called"")

    monkeypatch.setattr(check_env, ""has_network"", _fail_net)
    rc = check_env.main([""--auto-install"", ""--skip-net-check""])
    assert rc == 0",tests/test_check_env_network.py,
survived,"def collect_entries() -> list[tuple[str, str, str]]:
    entries: list[tuple[str, str, str]] = []
    for page in sorted(DEMOS_DIR.glob(""*.md"")):
        entries.append(parse_page(page))
    return entries
",scripts/generate_gallery_html.py,
survived,"def test_resolve_pins_versions():
    manager = DependencyManager()
    reqs, licenses, _ = manager.resolve([""pydantic"", ""click""])
    assert any(r.startswith(""pydantic=="") for r in reqs)
    assert any(r.startswith(""click=="") for r in reqs)
    assert licenses.get(""pydantic"") == ""MIT""
    assert ""click"" in licenses
",tests/test_dependency_manager.py,
survived,"def test_bundle_generator_custom_metadata(tmp_path: Path) -> None:
    gen = BundleGenerator(tmp_path)
    gen.generate(
        agent_code=""print('agent')"",
        metadata_fields={""meta_agent_version"": ""1.2.3"", ""extra"": ""field""},
        custom_metadata={""tag"": ""example""},
    )

    with open(tmp_path / ""bundle.json"", encoding=""utf-8"") as f:
        data = json.load(f)

    assert data[""meta_agent_version""] == ""1.2.3""
    assert data[""extra""] == ""field""
    assert data[""custom""][""tag""] == ""example""",tests/test_bundle_generator.py,
survived,"    def git_available() -> bool:
        """"""Return True if the ``git`` executable can be found.""""""
        return shutil.which(""git"") is not None
",src/meta_agent/git_utils.py,GitManager
survived,"    def __init__(self, *args: object, **kwargs: object) -> None:
        super().__init__(*args)
",tests/conftest.py,APIConnectionError
survived,"    def fCounter(f):
        global s
        s = s + ""|""
        return f
",tests/rosetta/transpiler/Python/church-numerals-2.py,
survived,"def choleskyLower(a):
    n = a[""order""]
    ae = a[""ele""]
    le = []
    idx = 0
    while idx < len(ae):
        le = le + [0.0]
        idx = idx + 1
    row = 1
    col = 1
    dr = 0
    dc = 0
    i = 0
    while i < len(ae):
        e = ae[i]
        if i < dr:
            d = (e - le[i]) // le[dc]
            le[i] = d
            ci = col
            cx = dc
            j = i + 1
            while j <= dr:
                cx = cx + ci
                ci = ci + 1
                le[j] = le[j] + d * le[cx]
                j = j + 1
            col = col + 1
            dc = dc + col
        else:
            le[i] = sqrtApprox(e - le[i])
            row = row + 1
            dr = dr + row
            col = 1
            dc = 0
        i = i + 1
    return {""order"": n, ""ele"": le}
",tests/rosetta/transpiler/Python/cholesky-decomposition-1.py,
survived,"def pad10(s):
    str = s
    while len(str) < 10:
        str = "" "" + str
    return str
",tests/rosetta/transpiler/Python/composite-numbers-k-with-no-single-digit-factors-whose-factors-are-all-substrings-of-k.py,
survived,"def main():
    print(""zero = "" + str(toInt(zero())))
    onev = one()
    print(""one = "" + str(toInt(onev)))
    two = succ(succ(zero()))
    print(""two = "" + str(toInt(two)))
    three = plus(onev, two)
    print(""three = "" + str(toInt(three)))
    four = mult(two, two)
    print(""four = "" + str(toInt(four)))
    eight = exp(two, three)
    print(""eight = "" + str(toInt(eight)))
    print(""toStr(four) = "" + toStr(four))",tests/rosetta/transpiler/Python/church-numerals-2.py,
survived,"def exp(m, n):
    return n(m)
",tests/rosetta/transpiler/Python/church-numerals-2.py,
survived,"def test_throttle_alert(monkeypatch: pytest.MonkeyPatch) -> None:
    monkeypatch.setenv(""API_RATE_LIMIT"", ""1"")
    from src.interface import api_server as mod
    api = importlib.reload(mod)

    sent: list[str] = []
    monkeypatch.setattr(api.alerts, ""send_alert"", lambda msg, url=None: sent.append(msg))

    client = TestClient(cast(Any, api.app))
    headers = {""Authorization"": ""Bearer test-token""}

    client.get(""/runs"", headers=headers)
    client.get(""/runs"", headers=headers)

    stack = api.app.middleware_stack
    metrics = stack.app.app
    limiter = metrics.app
    metrics.window_start = time.time() - 61
    limiter.counters[""testclient""] = (0, time.time())

    client.get(""/runs"", headers=headers)

    assert sent, ""alert not triggered""

    monkeypatch.setenv(""API_RATE_LIMIT"", ""1000"")
    importlib.reload(api)",tests/test_api_server_static.py,
survived,"def test_error_handler_logs_and_outputs(caplog, capsys):
    handler = ErrorHandler(cli_output=CLIOutput())
    err = CLIOutputError(""boom"", context={""foo"": ""bar""})
    with caplog.at_level(logging.ERROR):
        handler.handle(err)
    out, err_stream = capsys.readouterr()
    assert ""boom"" in err_stream
    assert ""boom"" in caplog.text
    assert ""foo"" in caplog.text
",tests/ux/test_error_handler.py,
survived,"    def raise_interrupt(_):
        raise EOFError
",tests/ux/test_interactive.py,
survived,"def test_menu_empty_options():
    inter = Interactive()
    with pytest.raises(InteractiveError):
        inter.menu(""Pick"", [])
",tests/ux/test_interactive.py,
survived,"    def __init__(self, cli_output: CLIOutput | None = None) -> None:
        self.cli_output = cli_output or CLIOutput()
",src/meta_agent/ux/user_feedback.py,UserFeedback
survived,"def test_mcp_invoke_tool_missing():
    async def _run() -> None:
        adapter = MCPAdapter()
        with pytest.raises(KeyError):
            await adapter.invoke_tool(""missing_tool"", {})

    asyncio.run(_run())
",tests/test_adapters.py,
survived,"        async def stop_merkle_task(self) -> None:  # pragma: no cover - interface
            pass
",tests/test_adapters.py,DummyLedger
survived,"        def start_merkle_task(self, *_a, **_kw):
            pass
",tests/test_adapters.py,DummyLedger
survived,"        def __init__(self) -> None:
            self.logged: list[messaging.Envelope] = []
",tests/test_adapters.py,DummyLedger
survived,"    def fake_generate(self, prompt: str) -> str:
        calls[""prompt""] = prompt
        return ""resp""
",tests/test_adapters.py,
survived,"def _reset_islands() -> None:
    mats.ISLANDS.clear()
    mats.ISLAND_SEEDS.clear()
",tests/test_mats.py,
survived,"def main(argv: List[str] | None = None) -> None:
    """"""Run the Î±â€‘AGI Insight demo with environment validation.""""""
    args = [""--verify-env""]
    if argv:
        args.extend(argv)
    __main__.main(args)
",alpha_factory_v1/demos/alpha_agi_insight_v0/official_demo.py,
survived,"def create_app():
    engine = create_async_engine(""sqlite+aiosqlite:///:memory:"")
    lifespan = sqlalchemy_lifespan(Base, engine, seed=seed)
    app = EnrichMCP(""Test"", ""Desc"", lifespan=lifespan)
    include_sqlalchemy_models(app, Base)
    return app, lifespan
",tests/test_sqlalchemy_autogen.py,
survived,"def include_sqlalchemy_models(
    app: EnrichMCP,
    base: type[DeclarativeBase],
    *,
    session_key: str = ""session_factory"",
) -> dict[str, type]:
    """"""Register SQLAlchemy models with automatic resources and resolvers.""""""

    models: dict[str, type] = {}
    for mapper in base.registry.mappers:
        sa_model = mapper.class_
        if not issubclass(sa_model, EnrichSQLAlchemyMixin):
            continue
        enrich_cls = sa_model.__enrich_model__()
        model = type(
            enrich_cls.__name__,
            (enrich_cls,),
            {""__doc__"": enrich_cls.__doc__},
        )
        app.entity(model)
        models[sa_model.__name__] = model
        models[model.__name__] = model

    for mapper in base.registry.mappers:
        sa_model = mapper.class_
        if sa_model.__name__ not in models:
            continue
        enrich_model = models[sa_model.__name__]
        _register_default_resources(app, sa_model, enrich_model, session_key)
        _register_relationship_resolvers(app, sa_model, enrich_model, models, session_key)
        enrich_model.model_rebuild(_types_namespace=models)

    return models",src/enrichmcp/sqlalchemy/auto.py,
survived,"def test_ragged_paged_attention_incremental_single_seq():
    rng = jr.PRNGKey(2)
    seq_lens = [47]
    k_lens = [5]
    q, kv_pages, kv_lens, page_indices, cu_q_lens, num_seqs = _build_incremental_case(rng, seq_lens, k_lens)

    ragged = default_ragged_paged_attention(q, kv_pages, kv_lens, page_indices, cu_q_lens, num_seqs, sm_scale=SM_SCALE)
    ref = _reference_attention(q, kv_pages, kv_lens, page_indices, cu_q_lens, k_lens)

    assert ragged.axes == ref.axes
    assert_trees_all_close(ragged.array, ref.array, atol=1e-3, rtol=1e-3)
",tests/test_paged_attention.py,
survived,"    def agents(self) -> list[str]:
        """"""Return the list of registered agents.""""""
        url = f""{self.base_url}/agents""
        resp = requests.get(url)
        resp.raise_for_status()
        return resp.json()
",alpha_factory_v1/demos/alpha_agi_marketplace_v1/marketplace.py,MarketplaceClient
survived,"    def exec_module(self, module: ModuleType) -> None:
        file_path = module.__spec__.origin  # type: ignore
        base_path = os.path.dirname(file_path)
        target = os.path.splitext(os.path.basename(file_path))[0]
        ret = JacMachineInterface.jac_import(
            target=target,
            base_path=base_path,
            override_name=module.__name__,
        )
        if ret:
            loaded_module = ret[0]
            module.__dict__.update(loaded_module.__dict__)
        else:
            raise ImportError(f""Unable to import {module.__name__}"")
",jac/jaclang/runtimelib/meta_importer.py,JacMetaImporter
survived,"    def create_module(self, spec):
        return None  # use default machinery
",jac/jaclang/runtimelib/meta_importer.py,JacMetaImporter
survived,"def test_build_llm_missing_api_key(monkeypatch):
    if importlib.util.find_spec(""openai_agents""):
        import openai_agents as oa
    else:  # pragma: no cover - legacy package name
        import agents as oa

    captured = {}

    class DummyAgent:
        def __init__(self, *a, base_url=None, **kw):
            captured['base_url'] = base_url

    monkeypatch.setattr(oa, ""OpenAIAgent"", DummyAgent)
    monkeypatch.setenv(""OPENAI_API_KEY"", """")
    monkeypatch.setenv(""OLLAMA_BASE_URL"", ""http://testserver"")

    import importlib as _imp
    mod = _imp.reload(_imp.import_module(""alpha_factory_v1.demos.aiga_meta_evolution.utils""))
    llm = mod.build_llm()
    assert isinstance(llm, DummyAgent)
    assert captured.get('base_url') == ""http://testserver""
",tests/test_external_integrations.py,
survived,"def _verify_wheel(path: Path) -> bool:
    """"""Return ``True`` if the wheel's signature is valid.""""""
    sig_path = path.with_suffix(path.suffix + "".sig"")
    if not sig_path.is_file():
        logger.error(""Missing .sig file for %s"", path.name)
        return False
    if ed25519 is None:
        logger.error(""cryptography library required for signature checks"")
        return False
    try:
        sig_b64 = sig_path.read_text().strip()
        expected = _WHEEL_SIGS.get(path.name)
        if expected and expected != sig_b64:
            logger.error(""Signature mismatch for %s"", path.name)
            return False
        pub_bytes = base64.b64decode(_WHEEL_PUBKEY)
        signature = base64.b64decode(sig_b64)
        ed25519.Ed25519PublicKey.from_public_bytes(pub_bytes).verify(signature, path.read_bytes())
        return True
    except InvalidSignature:
        logger.error(""Invalid signature for %s"", path.name)
    except Exception:
        logger.exception(""Signature verification failed for %s"", path.name)
    return False
",alpha_factory_v1/backend/agents/__init__.py,
survived,"    def __exit__(self, exc_type, exc, tb) -> bool:
        try:
            self.close()
        except Exception as err:  # pragma: no cover - defensive
            logger.warning(""MemoryFabric: close failed â†’ %s"", err)
            return exc_type is None
        return False
",alpha_factory_v1/backend/memory_fabric.py,MemoryFabric
survived,"    def __enter__(self) -> ""MemoryFabric"":
        return self
",alpha_factory_v1/backend/memory_fabric.py,MemoryFabric
deleted,"  def supports_active_cooling(self) -> bool:
    return False",pylabrobot/heating_shaking/backend.py,HeaterShakerBackend
survived,"  async def test_passive_cooling_with_support(self):
    backend = _FakeBackend(temperature=30.0)
    tc = TemperatureController(
      name=""tc"",
      size_x=1,
      size_y=1,
      size_z=1,
      backend=backend,
      child_location=Coordinate.zero(),
    )

    await tc.set_temperature(20, passive=True)
    self.assertFalse(backend.set_called)",pylabrobot/temperature_controlling/temperature_controller_tests.py,PassiveCoolingWithSupportTests
survived,"  async def stop(self):
    pass
",pylabrobot/temperature_controlling/temperature_controller_tests.py,_FakeBackend
survived,"  async def test_cannot_cool_without_support(self):
    backend = TemperatureControllerChatterboxBackend(dummy_temperature=20.0)
    tc = TemperatureController(
      name=""tc"",
      size_x=1,
      size_y=1,
      size_z=1,
      backend=backend,
      child_location=Coordinate.zero(),
    )

    with self.assertRaises(ValueError):
      await tc.set_temperature(10)
",pylabrobot/temperature_controlling/temperature_controller_tests.py,PassiveCoolingTests
survived,"  async def deactivate(self):
    pass
",pylabrobot/temperature_controlling/temperature_controller_tests.py,_FakeBackend
survived,"def test_pdfs_to_hf_dataset(monkeypatch, tmp_path, fake_dataset_class):
    from importlib import reload

    data = fake_dataset_class
    reload(data)

    def fake_convert_from_path(*args, **kwargs):
        return [Image.new(""RGB"", (10, 10)), Image.new(""RGB"", (10, 10))]

    class FakePage:
        def __init__(self, text):
            self.text = text

        def extract_text(self):
            return self.text

    class FakeReader:
        def __init__(self, _):
            self.pages = [FakePage(""a""), FakePage(""b"")]

    monkeypatch.setattr(data, ""convert_from_path"", fake_convert_from_path)
    monkeypatch.setattr(data, ""PdfReader"", FakeReader)

    (tmp_path / ""doc1.pdf"").write_bytes(b""%PDF-1.4"")
    (tmp_path / ""doc2.pdf"").write_bytes(b""%PDF-1.4"")

    dataset = data.pdfs_to_hf_dataset(tmp_path)
    assert len(dataset) == 4
    assert dataset[0][""pdf_name""] == ""doc1.pdf""
    assert dataset[0][""pdf_page""] == 1
",no-ocr-api/tests/test_ingest_search.py,
survived,"def test_ai_search_dataset_missing(client, monkeypatch):
    from np_ocr import api as api_module

    monkeypatch.setattr(api_module, ""search_client"", types.SimpleNamespace(search_images_by_text=lambda *a, **k: []))

    response = client.post(
        ""/search"",
        data={""user_query"": ""foo"", ""user_id"": ""user"", ""case_name"": ""case""},
    )
    assert response.status_code == 404
",no-ocr-api/tests/test_ingest_search.py,
survived,"async def test_ask_llm_requires_request_context():
    ctx = EnrichContext()
    with pytest.raises(ValueError, match=""outside of a request""):
        await ctx.ask_llm(""ping"")",tests/test_llm.py,
survived,"        async def stop(self) -> None:
            return None
",tests/test_bus_large_payloads_property.py,Prod
survived,"def copy_assets(manifest: dict, repo_root: Path, dist_dir: Path) -> None:
    for rel in manifest[""files""]:
        src_path = ROOT / rel
        if src_path.exists():
            target = dist_dir / rel
            target.parent.mkdir(parents=True, exist_ok=True)
            target.write_bytes(src_path.read_bytes())

    quickstart_pdf = repo_root / manifest[""quickstart_pdf""]
    if quickstart_pdf.exists():
        (dist_dir / quickstart_pdf.name).write_bytes(quickstart_pdf.read_bytes())

    translations = ROOT / manifest[""dirs""][""translations""]
    if translations.exists():
        for f in translations.iterdir():
            if f.is_file():
                target = dist_dir / manifest[""dirs""][""translations""] / f.name
                target.parent.mkdir(parents=True, exist_ok=True)
                target.write_bytes(f.read_bytes())

    critics_src = repo_root / manifest[""dirs""][""critics""]
    critics_dst = dist_dir / manifest[""dirs""][""critics""]
    if critics_src.exists():
        critics_dst.mkdir(parents=True, exist_ok=True)
        for f in critics_src.iterdir():
            (critics_dst / f.name).write_bytes(f.read_bytes())

    for key in (""wasm"", ""wasm_llm""):
        d = ROOT / manifest[""dirs""][key]
        if d.exists():
            target_dir = dist_dir / manifest[""dirs""][key]
            target_dir.mkdir(exist_ok=True)
            for f in d.iterdir():
                (target_dir / f.name).write_bytes(f.read_bytes())
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/manual_build.py,
survived,"def scenario_1994_web() -> replay.Scenario:
    return replay.load_scenario(""1994_web"")
",tests/conftest.py,
survived,"def post(
    url: str,
    *,
    params: dict | None = None,
    json: dict | None = None,
    data: dict | bytes | None = None,
    headers: dict | None = None,
    timeout: float | None = None,
) -> Response:
    """"""Perform a minimal HTTP POST request.""""""
    return _call(
        ""POST"",
        url,
        params=params,
        json=json,
        data=data,
        headers=headers,
        timeout=timeout,
    )
",alpha_factory_v1/af_requests.py,
survived,"    def build_index(self) -> None:
        """"""Build an in-memory index of template metadata and content.""""""
        self._index.clear()
        for entry in self.registry.list_templates():
            slug = entry[""slug""]
            version = entry.get(""current_version"")
            if not version:
                continue
            content = self.registry.load_template(slug, version) or """"
            metadata_path = (
                self.registry.templates_dir
                / slug.replace("" "", ""_"").lower()
                / f""v{version.replace('.', '_')}""
                / METADATA_FILE_NAME
            )
            try:
                with open(metadata_path, ""r"", encoding=""utf-8"") as f:
                    metadata = json.load(f)
            except (OSError, json.JSONDecodeError):
                metadata = {}
            self._index.append(
                {
                    ""slug"": slug,
                    ""version"": version,
                    ""metadata"": metadata,
                    ""content"": content,
                }
            )
",src/meta_agent/template_search.py,TemplateSearchEngine
survived,"    def _register(self, runner: AgentRunner) -> None:
        env = messaging.Envelope(
            ""orch"",
            ""system"",
            {""event"": ""register"", ""agent"": runner.agent.name, ""capabilities"": runner.capabilities},
            time.time(),
        )
        self.ledger.log(env)
        self.bus.publish(""system"", env)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/orchestrator.py,Orchestrator
survived,"    def test_rpc_auth(self) -> None:
        self.settings.bus_token = ""s3cr3t""
        bus = messaging.A2ABus(self.settings)

        class Ctx:
            def abort(self, *_a, **_kw):
                raise RuntimeError(""denied"")

        payload = {
            ""sender"": ""a"",
            ""recipient"": ""b"",
            ""payload"": {},
            ""ts"": 0.0,
            ""token"": ""s3cr3t"",
        }
        asyncio.run(bus._handle_rpc(json.dumps(payload).encode(), Ctx()))
",tests/test_insight_orchestrator_features.py,TestMessaging
survived,"    def fn(genome: list[float]) -> tuple[float, float]:
        x, y = genome
        return x**2, y**2
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/simulation/forecast.py,
survived,"    def test_ledger_default_home(self) -> None:
        env = {""CROSS_ALPHA_LEDGER"": """"}
        with patch.dict(os.environ, env, clear=False):
            path = stub._ledger_path(None)
        expected = stub.DEFAULT_LEDGER.resolve()
        self.assertEqual(path, expected)
        self.assertTrue(path.parent.exists())
",alpha_factory_v1/tests/test_cross_industry_alpha.py,TestCrossIndustryAlpha
survived,"def restrict_wizard():
    if current_user.is_authenticated:
        return
    if not session.get(""wizard_access""):
        return redirect(""/"")
",app/blueprints/wizard/routes.py,
survived,"    def foo(x: f32[""batch embed""]):  # type: ignore  # noqa: F722
        pass
",tests/test_dtype_typing.py,
survived,"def test_other_dtype_annotation():
    def bar(x: i32[""batch""]):  # type: ignore  # noqa: F722
        pass

    spec = typing.get_args(typing.get_type_hints(bar, include_extras=True)[""x""])[1]
    assert spec.dtype == jnp.int32
    assert spec.before == (""batch"",)
",tests/test_dtype_typing.py,
survived,"    def test_trigger_discovery(self):
        agent = bridge.BusinessAgent()
        with patch.object(bridge, ""requests"") as req:
            req.post.return_value = DummyResponse()
            result = asyncio.run(bridge.trigger_discovery())
        req.post.assert_called_once_with(
            f""{bridge.HOST}/agent/alpha_discovery/trigger"", timeout=5
        )
        self.assertEqual(result, ""alpha_discovery queued"")
",tests/test_openai_bridge_integration.py,TestBusinessAgentIntegration
survived,"    def test_submit_job(self):
        agent = bridge.BusinessAgent()
        job = {""agent"": ""alpha_discovery"", ""foo"": 1}
        with patch.object(bridge, ""requests"") as req:
            req.post.return_value = DummyResponse()
            result = asyncio.run(bridge.submit_job(job))
        req.post.assert_called_once_with(
            f""{bridge.HOST}/agent/alpha_discovery/trigger"", json=job, timeout=5
        )
        self.assertEqual(result, ""job for alpha_discovery queued"")
",tests/test_openai_bridge_integration.py,TestBusinessAgentIntegration
survived,"def _ensure_assets() -> None:
    placeholders = []
    for p in (bundle_path, workbox_path):
        if p.exists():
            data = p.read_text(errors=""ignore"")
            if ""placeholder"" in data.lower():
                placeholders.append(p)
        else:
            placeholders.append(p)
    if placeholders:
        print(""Fetching missing browser assets..."")
        subprocess.run(
            [sys.executable, str(repo_root / ""scripts/fetch_assets.py"")],
            check=True,
        )
        for p in placeholders:
            if not p.exists() or ""placeholder"" in p.read_text(errors=""ignore"").lower():
                sys.exit(f""Failed to download {p.relative_to(ROOT)}"")
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/manual_build.py,
survived,"def test_mutate_cleanup_nested(server: str) -> None:
    """"""Creating nested files should be cleaned up.""""""
    import io
    import tarfile

    before = set(evolution_worker.STORAGE_PATH.iterdir()) if evolution_worker.STORAGE_PATH.exists() else set()

    buf = io.BytesIO()
    with tarfile.open(fileobj=buf, mode=""w"") as tf:
        info = tarfile.TarInfo(name=""dir1/dir2/file.txt"")
        data = b""nested""
        info.size = len(data)
        tf.addfile(info, io.BytesIO(data))
    buf.seek(0)

    with httpx.Client(base_url=server) as client:
        files = {""tar"": (""nested.tar"", buf.read())}
        r = client.post(""/mutate"", files=files)
        assert r.status_code == 200

    after = set(evolution_worker.STORAGE_PATH.iterdir()) if evolution_worker.STORAGE_PATH.exists() else set()
    assert before == after",tests/test_evolution_worker.py,
survived,"def test_bbc_demo_deterministic():
    args = argparse.Namespace(
        data_dir=BBC_DIR,
        iterations=2,
        display_topics=2,
        n_words=3,
        num_levels=3,
        alpha=10.0,
        gamma=1.0,
        eta=0.1,
        seed=0,
    )
    hlda = bbc_demo.run_demo(args)
    assert hlda.root_node.total_nodes == 15
    assert hlda.root_node.customers == 401
    assert hlda.num_documents == 401
",tests/test_bbc_demo.py,
survived,"    def test_openai_response_format(self) -> None:
        from alpha_factory_v1.demos.cross_industry_alpha_factory import (
            cross_alpha_discovery_stub as stub,
        )

        resp = types.SimpleNamespace(choices=[types.SimpleNamespace(message=types.SimpleNamespace(content=""[]""))])
        openai_mock = types.SimpleNamespace(ChatCompletion=types.SimpleNamespace(create=Mock(return_value=resp)))

        with patch.dict(os.environ, {""OPENAI_API_KEY"": ""x""}):
            with patch.object(stub, ""openai"", openai_mock):
                stub.discover_alpha(num=1, ledger=None, model=""gpt-4o-mini"")

        openai_mock.ChatCompletion.create.assert_called_once()
        kwargs = openai_mock.ChatCompletion.create.call_args.kwargs
        self.assertEqual(kwargs.get(""response_format""), {""type"": ""json_object""})
",tests/test_cross_alpha_discovery.py,TestCrossAlphaDiscoveryStub
survived,"def test_aiga_bridge_no_agents(monkeypatch: pytest.MonkeyPatch) -> None:
    """"""Import bridge without agents packages and expect helpful error.""""""
    monkeypatch.delitem(sys.modules, ""openai_agents"", raising=False)
    monkeypatch.delitem(sys.modules, ""agents"", raising=False)

    # Reload backend so the missing SDK shim is installed
    importlib.reload(importlib.import_module(""alpha_factory_v1.backend""))

    # Provide minimal curriculum_env to avoid gymnasium dependency
    env_stub = types.ModuleType(""curriculum_env"")

    class DummyEnv:
        pass

    env_stub.CurriculumEnv = DummyEnv  # type: ignore[attr-defined]
    monkeypatch.setitem(
        sys.modules,
        ""alpha_factory_v1.demos.aiga_meta_evolution.curriculum_env"",
        env_stub,
    )

    with pytest.raises(ModuleNotFoundError, match=""OpenAI Agents SDK is required""):
        importlib.import_module(""alpha_factory_v1.demos.aiga_meta_evolution.openai_agents_bridge"")",tests/test_aiga_bridge_no_agents.py,
survived,"def test_base_url_env(monkeypatch: pytest.MonkeyPatch) -> None:
    custom = ""https://example.com/gpt2""
    monkeypatch.setenv(""HF_GPT2_BASE_URL"", custom)
    assert dg._base_url() == custom
",tests/test_download_hf_gpt2.py,
survived,"        def set_tracer_provider(self, _provider: Any) -> None:
            pass
",tests/test_metrics.py,DummyTrace
survived,"    def fake_apply(diff_text, repo_path):
        applied.append(diff_text)
        diff_utils.apply_diff(diff_text, repo_dir=repo_path)
",tests/test_self_healer_pipeline.py,
survived,"def build_regex_guardrails(
    config: GuardrailConfig,
) -> List[Callable[[str], Awaitable[None]]]:
    """"""Build async guardrail callables from a configuration.""""""

    guards: List[Callable[[str], Awaitable[None]]] = []
    for rule in config.rules:
        pattern = re.compile(rule.pattern)

        async def guard(value: str, *, _p=pattern, _r=rule) -> None:
            if _p.search(value):
                raise ValueError(f""Guardrail '{_r.name}' triggered"")

        guards.append(guard)
    return guards
",src/meta_agent/generators/guardrail_generator.py,
survived,"async def test_output_guardrail_exception_propagates():
    adapter = MockAdapter()
    router = GuardrailModelRouter({""a"": adapter}, default_model=""a"")

    async def bad_guard(_output: str):
        raise RuntimeError(""bad"")

    router.add_output_guardrail(bad_guard)

    with pytest.raises(RuntimeError):
        await router.invoke(""x"")",tests/test_guardrail_router.py,
survived,"    def __init__(self):
        self.allowed_tags = [
            ""p"",""br"",""strong"",""em"",""h1"",""h2"",""h3"",""h4"",""h5"",""h6"",
            ""ul"",""ol"",""li"",""blockquote"",""code"",""pre"",
            ""a"",""img"",""hr"",""table"",""thead"",""tbody"",""tr"",""th"",""td""
        ]
        self.allowed_attributes = {
            ""a"": [""href"", ""title""],
            ""img"": [""src"", ""alt"", ""title"", ""width"", ""height""],
        }
        self.allowed_protocols = [""http"", ""https"", ""mailto""]
        self.md = Markdown(extras=[""fenced-code-blocks""])
",app/utils/markdown_renderer.py,SafeMarkdownRenderer
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/machine/x/python/q1.py,_Group
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/machine/x/python/q3.py,_Group
survived,"def _sum(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""sum() expects list or group"")
    s = 0.0
    for it in v:
        if it is None:
            continue
        if isinstance(it, (int, float)):
            s += float(it)
        else:
            raise Exception(""sum() expects numbers"")
    return s
",tests/machine/x/python/q3.py,
survived,"def test_service_worker_checksum() -> None:
    browser_dir = Path(__file__).resolve().parents[1]
    text = (browser_dir / ""manual_build.py"").read_text()
    assert 'sha384(dist_dir / ""service-worker.js"")' in text",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_manual_build_size_limit.py,
survived,"        def act(self, _obs):
            return 0
",tests/test_world_model_demo.py,DummyLearner
survived,"        def __init__(self, reward: float) -> None:
            self.reward = reward
",tests/test_world_model_demo.py,DummyEnv
survived,"    def __init__(self, steps: int = 2, rng: random.Random | None = None) -> None:
        self.steps = steps
        self.rng = rng or random.Random()
        self._op = PromptRewrite(rng=self.rng)
",src/simulation/mats_ops.py,SelfRewriteOperator
survived,"def run() -> None:
    n = 5
    total = sum(range(n))
    expected = n*(n-1)//2
    assert total == expected",benchmarks/swe_mini/task_005.py,
survived,"def run() -> None:
    parts = [""poly"", ""task"", ""15""]
    joined = ""-"".join(parts)
    assert joined.split(""-"")[2] == str(15)",benchmarks/poly_mini/task_015.py,
survived,"def run() -> None:
    parts = [""poly"", ""task"", ""4""]
    joined = ""-"".join(parts)
    assert joined.split(""-"")[2] == str(4)",benchmarks/poly_mini/task_004.py,
survived,"    async def lineage(_: None = Depends(verify_token)) -> list[LineageNode]:
        """"""Return archive lineage information.""""""
        path = Path(os.getenv(""ARCHIVE_PATH"", ""archive.db""))
        arch = Archive(path)
        nodes: list[LineageNode] = []
        for a in arch.all():
            nodes.append(
                LineageNode(
                    id=a.id,
                    parent=a.meta.get(""parent""),
                    diff=a.meta.get(""diff"") or a.meta.get(""patch""),
                    pass_rate=a.score,
                )
            )
        return nodes
",src/interface/api_server.py,
survived,"def test_rewrite_blocks_malicious() -> None:
    op = SelfRewriteOperator(steps=1)
    code = ""import os\nos.system('rm -rf /')""
    assert op(code) == code
",tests/test_safety_filter.py,
survived,"    def api_key(self, value: Optional[str]) -> None:
        object.__setattr__(self, ""_api_key"", value)
        object.__setattr__(self, ""_headers"", self._compute_headers())
",python/langsmith/client.py,Client
survived,"def test_run_muzero_demo_invokes_docker(tmp_path: Path) -> None:
    repo_root = Path(__file__).resolve().parents[1]
    src = repo_root / ""alpha_factory_v1""
    dst = tmp_path / ""alpha_factory_v1""
    shutil.copytree(src, dst)

    script = dst / ""demos"" / ""muzero_planning"" / ""run_muzero_demo.sh""
    log_file = tmp_path / ""docker.log""
    bin_dir = tmp_path / ""bin""
    bin_dir.mkdir()
    docker_stub = bin_dir / ""docker""
    docker_stub.write_text(
        f""#!/usr/bin/env bash\necho \""$@\"" >> '{log_file}'\nexit 0\n""
    )
    docker_stub.chmod(0o755)

    with socket.socket() as s:
        s.bind((""localhost"", 0))
        port = s.getsockname()[1]

    env = os.environ.copy()
    env.update({""PATH"": f""{bin_dir}:{env.get('PATH', '')}"", ""HOST_PORT"": str(port)})

    subprocess.run([""bash"", str(script)], check=True, env=env)

    assert log_file.read_text(), ""Docker stub was not invoked""
    assert ""compose"" in log_file.read_text()",tests/test_run_muzero_demo.py,
survived,"def test_improve_repo_applies_patch(tmp_path: Path) -> None:
    repo_dir = tmp_path / ""repo""
    repo_dir.mkdir()
    _init_repo(repo_dir)

    patch = """"""--- a/metric.txt\n+++ b/metric.txt\n@@\n-1\n+2\n""""""
    patch_file = tmp_path / ""patch.diff""
    patch_file.write_text(patch)
    log_file = tmp_path / ""log.json""

    delta, clone = self_improver.improve_repo(
        str(repo_dir), str(patch_file), ""metric.txt"", str(log_file), cleanup=False
    )

    assert (clone / ""metric.txt"").read_text().strip() == ""2""
    data = json.loads(log_file.read_text())
    assert isinstance(data[0][""delta""], (int, float))
    assert delta == data[0][""delta""]
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_self_improver.py,
survived,"def _init_repo(path: Path) -> git.Repo:
    repo = git.Repo.init(path)
    (path / ""metric.txt"").write_text(""1\n"")
    repo.git.add(""metric.txt"")
    repo.index.commit(""init"")
    return repo
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_self_improver.py,
survived,"    def test_main_uses_env_key(self) -> None:
        stub = types.ModuleType(""openai_agents"")

        runtime = MagicMock()

        def _tool(*_a, **_k):
            def _decorator(func):
                return func

            return _decorator

        stub.Agent = object
        stub.AgentRuntime = MagicMock(return_value=runtime)
        stub.Tool = _tool

        with (
            patch.dict(sys.modules, {""openai_agents"": stub}),
            patch.dict(os.environ, {""OPENAI_API_KEY"": ""key""}, clear=False),
            patch(""alpha_factory_v1.backend.adk_bridge.auto_register"") as auto_reg,
            patch(""alpha_factory_v1.backend.adk_bridge.maybe_launch"") as maybe_launch,
        ):
            sys.modules.pop(
                ""alpha_factory_v1.demos.cross_industry_alpha_factory.openai_agents_bridge"",
                None,
            )
            mod = importlib.import_module(""alpha_factory_v1.demos.cross_industry_alpha_factory.openai_agents_bridge"")
            mod.main()

            stub.AgentRuntime.assert_called_once_with(api_key=""key"")
            runtime.register.assert_called_once()
            auto_reg.assert_called_once()
            maybe_launch.assert_called_once()
",tests/test_cross_industry_bridge_runtime.py,TestCrossIndustryBridgeRuntime
survived,"def rsi(prices: Sequence[float], period: int = 14) -> float:
    """"""Compute the relative strength index (0â€’100).""""""

    if period <= 0:
        raise ValueError(""period must be positive"")
    if len(prices) <= period:
        return 0.0

    if np is not None:
        deltas = np.diff(np.asarray(prices, dtype=float))
        gains = np.clip(deltas, 0, None)
        losses = np.clip(-deltas, 0, None)

        avg_gain = float(np.mean(gains[:period]))
        avg_loss = float(np.mean(losses[:period]))

        for g, l in zip(gains[period:], losses[period:]):
            avg_gain = (avg_gain * (period - 1) + float(g)) / period
            avg_loss = (avg_loss * (period - 1) + float(l)) / period
    else:
        deltas = [prices[i + 1] - prices[i] for i in range(len(prices) - 1)]
        gains = [max(d, 0.0) for d in deltas]
        losses = [max(-d, 0.0) for d in deltas]

        avg_gain = sum(gains[:period]) / period
        avg_loss = sum(losses[:period]) / period

        for g, l in zip(gains[period:], losses[period:]):
            avg_gain = (avg_gain * (period - 1) + g) / period
            avg_loss = (avg_loss * (period - 1) + l) / period

    if avg_loss == 0:
        return 100.0
    rs = avg_gain / avg_loss
    return 100.0 - (100.0 / (1 + rs))
",alpha_factory_v1/backend/alpha_model.py,
survived,"    def legal_actions(self) -> List[str]:
        """"""Available trade actions.""""""
        return [""HOLD"", ""BUY"", ""SELL""]
",alpha_factory_v1/backend/environments/market_sim.py,MarketEnv
survived,"    def sample_next_price(self, price: float) -> float:
        """"""Return the next price using a Gaussian random walk.""""""
        return price + random.gauss(0.0, self.volatility)
",alpha_factory_v1/backend/environments/market_sim.py,MarketEnv
survived,"    async def __aexit__(self, *_exc):  # pragma: no cover - interface default
        return None
",alpha_factory_v1/backend/market_data.py,BaseMarketData
survived,"    def complete(self, prompt: str) -> str:  # noqa: D401
        return self.resp
",alpha_factory_v1/tests/test_planner_agent.py,DummyModel
survived,"    def history(self) -> Iterable[Fill]:
        """"""Iterate over all persisted fills (newest-last).""""""
        if not self._db_path.exists():
            return []
        with self._db_path.open() as fh:
            for line in fh:
                try:
                    yield Fill(**json.loads(line))
                except Exception:
                    continue
",alpha_factory_v1/backend/portfolio.py,Portfolio
survived,"    def forward(self, h): return self.v(h), torch.log_softmax(self.p(h), -1)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,Pred
survived,"    def __init__(self, hidden: int, act_dim: int):
        super().__init__(); self.v = nn.Linear(hidden, 1); self.p = nn.Linear(hidden, act_dim)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,Pred
survived,"    def initial(self, obs):
        h = self.repr(obs)
        v, p = self.pred(h)
        return h, v, p
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,MuZeroTiny
survived,"        def handle(self, _msg):
            LOG.debug(""[Fallback%d] â† %s"", idx, _msg)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,Fallback
survived,"    def _clip(self,v): return max(0, min(self.size-1, v))
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,MiniWorld
survived,"    def subscribe(cls, topic: str, cb: Callable[[dict], None]):
        with cls._lock:
            cls._subs.setdefault(topic, []).append(cb)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,A2ABus
survived,"    def __init__(self, cash: float = 1_000_000.0) -> None:
        self.cash = cash
        self.positions: Dict[str, float] = {}
",alpha_factory_v1/backend/broker/broker_sim.py,SimulatedBroker
survived,"def parse_args() -> argparse.Namespace:
    ap = argparse.ArgumentParser(description=""Alpha-Factory Edge Runner"")
    ap.add_argument(
        ""--agents"",
        help=""Comma separated list of agents to enable"",
    )
    ap.add_argument(
        ""--port"",
        type=int,
        default=8000,
        help=""REST API port (default: 8000)"",
    )
    ap.add_argument(
        ""--metrics-port"",
        type=int,
        help=""Prometheus metrics port"",
    )
    ap.add_argument(
        ""--a2a-port"",
        type=int,
        help=""gRPC A2A port"",
    )
    return ap.parse_args()
",alpha_factory_v1/edge_runner.py,
survived,"def main() -> None:
    args = parse_args()

    cli = [""--dev"", f""--port"", str(args.port)]
    if args.metrics_port:
        cli += [""--metrics-port"", str(args.metrics_port)]
    if args.a2a_port:
        cli += [""--a2a-port"", str(args.a2a_port)]
    if args.agents:
        cli += [""--enabled"", args.agents]

    ns = af_run.parse_args(cli)
    af_run.apply_env(ns)

    os.environ.setdefault(""PGHOST"", ""sqlite"")

    af_run.run()
",alpha_factory_v1/edge_runner.py,
survived,"    def test_version_flag(self):
        args = self._parse([""--version""])
        self.assertTrue(args.version)
",alpha_factory_v1/tests/test_edge_runner.py,EdgeRunnerParseTest
survived,"def _positive_int(name: str) -> callable:
    """"""Return a parser for positive integers.""""""

    def parser(value: str) -> int:
        try:
            iv = int(value)
        except ValueError as exc:  # pragma: no cover - argparse handles message
            raise argparse.ArgumentTypeError(f""{name} must be an integer"") from exc
        if iv <= 0:
            raise argparse.ArgumentTypeError(f""{name} must be > 0"")
        return iv

    return parser
",alpha_factory_v1/edge_runner.py,
survived,"def _attempt() -> bool:
    logs: list[str] = []
    try:
        with sync_playwright() as p:
            browser = p.chromium.launch()
            context = browser.new_context()
            page = context.new_page()
            page.on(""console"", lambda msg: logs.append(f""[{msg.type}] {msg.text}""))
            page.goto(URL)
            page.wait_for_function(""navigator.serviceWorker.ready"", timeout=TIMEOUT_MS)
            page.wait_for_selector(""body"", timeout=TIMEOUT_MS)
            context.set_offline(True)
            page.reload()
            page.wait_for_selector(""body"", timeout=TIMEOUT_MS)
            page.wait_for_selector(""#tree-container .node"", timeout=TIMEOUT_MS)
            browser.close()
        return True
    except PlaywrightError as exc:
        print(f""Playwright error: {exc}"", file=sys.stderr)
    except Exception as exc:  # noqa: BLE001
        print(f""Offline check failed: {exc}"", file=sys.stderr)

    _print_console(logs)
    return False
",scripts/verify_insight_offline.py,
survived,"def join_domain(domain, admin_user, ou):
    cmd = [""realm"", ""join"", ""-v"", f""--user={admin_user}""]
    if ou:
        cmd.append(f""--computer-ou={ou}"")
    cmd.append(domain)
    return run_cmd("" "".join(cmd))
",adconnection_gui.py,
survived,"def main():
    parser = argparse.ArgumentParser(description=""Join Linux host to Active Directory"")
    parser.add_argument(""domain"", nargs=""?"", help=""Domain to join"")
    parser.add_argument(""-u"", ""--user"", required=False, help=""Admin user for the join"")
    parser.add_argument(""-o"", ""--ou"", help=""OU for computer object"")
    parser.add_argument(""--discover"", action=""store_true"", help=""Only discover domain"")
    args = parser.parse_args()

    if args.discover:
        domain = discover_domain()
        if domain:
            print(domain)
        else:
            print(""No domain discovered"")
        return

    domain = args.domain or discover_domain()
    if not domain:
        print(""Domain could not be discovered. Please specify the domain as argument."")
        sys.exit(1)

    admin_user = args.user or input(""Admin user: "")
    join_domain(domain, admin_user, args.ou)
    print(f""Successfully joined {domain}"")
",adconnection_app.py,
survived,"def run_cmd(cmd):
    """"""Run a shell command and return output and exit code.""""""
    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
    return result.stdout.strip(), result.returncode
",adconnection_gui.py,
survived,"    def test_summary_api_connection_error(self) -> None:
        import openai

        with patch.dict(os.environ, {""OPENAI_API_KEY"": ""sk-test""}):
            with patch(""openai.OpenAI"") as mock_client:
                mock_client.return_value.chat.completions.create.side_effect = openai.APIConnectionError(""fail"")
                text = summarise_with_agent(
                    0.5,
                    agents=2,
                    rounds=10,
                    delta=0.9,
                    stake=1.0,
                )
        self.assertIn(""offline summary"", text)
        self.assertIn(""connection"", text)
",tests/test_governance_sim.py,TestGovernanceSim
survived,"def _free_port() -> int:
    """"""Return an unused localhost port.""""""
    with socket.socket() as s:
        s.bind((""127.0.0.1"", 0))
        return int(s.getsockname()[1])
",tests/test_aiga_service_mixtral.py,
survived,"    def register(self, *_a, **_kw):
        pass
",tests/test_openai_bridge_integration.py,_AgentRuntime
survived,"    async def _stop() -> None:
        task = getattr(app_f.state, ""task"", None)
        if task:
            task.cancel()
            with contextlib.suppress(asyncio.CancelledError):
                await task
            app_f.state.task = None
        app_f.state.orchestrator = None
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/api_server.py,
survived,"    async def healthz() -> str:
        """"""Simple liveness probe.""""""

        return ""ok""
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/api_server.py,
survived,"def run_jax_simulation(model, importer, ts, atol, rtol):
    p = jnp.array([importer.sbml.getParameter(pid).getValue() for pid in model.parameter_ids])
    ts_jnp = jnp.asarray(ts, dtype=float)
    zeros = jnp.zeros_like(ts_jnp)
    solver = diffrax.Kvaerno5()
    controller = diffrax.PIDController(rtol=rtol / 1e4, atol=atol / 1e4)
    x, stats = model.simulate_condition(
        p,
        ts_jnp,
        jnp.array([]),
        zeros,
        jnp.zeros_like(ts_jnp, dtype=int),
        jnp.zeros_like(ts_jnp, dtype=int),
        jnp.zeros((ts_jnp.shape[0], 0)),
        jnp.zeros((ts_jnp.shape[0], 0)),
        solver,
        controller,
        diffrax.DirectAdjoint(),
        diffrax.steady_state_event(),
        2 ** 8,
        ret=amici.jax.ReturnValue.x,
    )
    tcl = model._tcl(x[0], p)
    y = jax.vmap(lambda t, xs: model._y(t, xs, p, tcl, jnp.zeros(len(model.observable_ids))))(
        ts_jnp, stats[""x""]
    )
    w = jax.vmap(lambda t, xs: model._w(t, xs, p, tcl))(ts_jnp, stats[""x""])

    class RData(dict):
        __getattr__ = dict.__getitem__

    return RData(
        ts=np.asarray(ts_jnp).copy(),
        y=np.asarray(y).copy(),
        w=np.asarray(w).copy(),
        status=amici.AMICI_SUCCESS,
    )
",tests/testSBMLSuiteJax.py,
survived,"def test_oai_and_adk(monkeypatch: pytest.MonkeyPatch, tmp_path: Path) -> None:
    settings = config.Settings(openai_api_key=""k"")
    settings.ledger_path = str(tmp_path / ""ledger.db"")
    bus = messaging.A2ABus(settings)
    ledger = insight_logging.Ledger(settings.ledger_path)

    import openai.agents as oa_agents  # type: ignore
    import google_adk

    called: dict[str, str] = {}

    async def fake_run(self, prompt: str) -> str:  # pragma: no cover - async stub
        called[""run""] = prompt
        return ""ok""

    monkeypatch.patch.object(oa_agents.AgentContext, ""run"", fake_run)

    class DummyClient:
        def generate(self, prompt: str) -> str:
            called[""adk""] = prompt
            return ""ok""

    monkeypatch.setattr(google_adk, ""Client"", DummyClient)

    strat = StrategyAgent(bus, ledger)
    summariser = ADKSummariserAgent(bus, ledger)

    summariser._records.append(""hello"")
    env = messaging.Envelope(""a"", ""b"", {""research"": ""foo""}, 0.0)

    async def _run() -> None:
        await strat.handle(env)
        await summariser.run_cycle()

    asyncio.run(_run())

    assert called.get(""run"") == ""foo""
    assert called.get(""adk"") == ""hello""",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_openai_adk_integration.py,
survived,"        def generate(self, prompt: str) -> str:
            called[""adk""] = prompt
            return ""ok""
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_openai_adk_integration.py,DummyClient
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/q1.py,Auto3
survived,"        def fake_find_spec(name: str):
            if name in {""pytest"", ""prometheus_client""}:
                return object()
            return None
",tests/test_preflight_optional_missing.py,TestPreflightOptionalMissing
survived,"def generate_corpus(n_topics, vocab_size, doc_len, n_docs, alpha=0.5, seed=0):
    rng = np.random.default_rng(seed)
    width = vocab_size // n_topics

    word_dists = np.zeros((n_topics, vocab_size))
    for k in range(n_topics):
        start = k * width
        word_dists[k, start:start + width] = 1.0 / width

    vocab = [f""w{i}"" for i in range(vocab_size)]
    corpus = []
    for _ in range(n_docs):
        theta = rng.dirichlet([alpha] * n_topics)
        doc = []
        for _ in range(doc_len):
            k = rng.choice(n_topics, p=theta)
            w = rng.choice(vocab_size, p=word_dists[k])
            doc.append(w)
        corpus.append(doc)
    return corpus, vocab
",tests/test_synthetic_hlda.py,
survived,"    def test_mats_bridge_compiles(self):
        """"""Ensure the MATS demo bridge compiles.""""""
        path = Path('alpha_factory_v1/demos/meta_agentic_tree_search_v0/openai_agents_bridge.py')
        py_compile.compile(path, doraise=True)
",tests/test_openai_bridge.py,TestOpenAIBridge
survived,"    def test_bridge_run_search_helper(self) -> None:
        import asyncio
        from alpha_factory_v1.demos.meta_agentic_tree_search_v0 import openai_agents_bridge as bridge

        if bridge.has_oai:  # pragma: no cover - only run offline path
            self.skipTest(""openai-agents installed"")

        result = asyncio.run(bridge.run_search(episodes=1, target=2))
        self.assertIn(""completed"", result)
",tests/test_meta_agentic_tree_search_demo.py,TestMetaAgenticTreeSearchDemo
survived,"def test_request_patch_no_api_key(monkeypatch: pytest.MonkeyPatch) -> None:
    diff = ""--- a/y\n+++ b/y\n@@\n-old\n+new\n""
    monkeypatch.setenv(""USE_LOCAL_LLM"", ""false"")
    monkeypatch.setenv(""OPENAI_API_KEY"", """")
    client = _reload_client(monkeypatch, diff)
    out = client.request_patch([{""role"": ""user"", ""content"": ""fix""}])
    assert out == diff",tests/test_llm_client_offline.py,
survived,"def _asset_paths() -> list[str]:
    fetch = repo_root / 'scripts' / 'fetch_assets.py'
    tree = ast.parse(fetch.read_text())
    assets = {}
    for node in tree.body:
        if isinstance(node, ast.Assign):
            for t in node.targets:
                if getattr(t, 'id', None) == 'ASSETS':
                    assets = ast.literal_eval(node.value)
                    break
    return list(assets)
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/manual_build.py,
survived,"def main() -> None:
    print_disclaimer()
    banner(""Alpha-Factory Setup Wizard"", ""YELLOW"")
    ok = True
    ok &= check_python()
    ok &= check_cmd(""git"")
    ok &= check_cmd(""docker"")
    ok &= check_node()

    if not ok:
        banner(""Some dependencies are missing"", ""RED"")
    else:
        banner(""Environment looks good"", ""GREEN"")

    repo_root = Path(__file__).resolve().parents[1]
    while True:
        print()
        print(""Select an option:"")
        print(""1) Run check_env.py --auto-install"")
        print(""2) Run ./codex/setup.sh"")
        print(""3) Start Insight demo with ./quickstart.sh"")
        print(""4) Start Insight demo in Docker (docker compose up)"")
        print(""5) Exit"")
        choice = input(""Enter choice: "").strip()
        if choice == ""1"":
            run([sys.executable, str(repo_root / ""check_env.py""), ""--auto-install""])
        elif choice == ""2"":
            run([str(repo_root / ""codex"" / ""setup.sh"")])
        elif choice == ""3"":
            run([str(repo_root / ""quickstart.sh"")])
        elif choice == ""4"":
            run([""docker"", ""compose"", ""up""])
        elif choice == ""5"":
            break
        else:
            print(""Invalid choice"")
",scripts/setup_wizard.py,
survived,"def test_simulator_init_fast(tmp_path: Path) -> None:
    js_out = tmp_path / ""sim.js""
    subprocess.run([
        ""tsc"",
        ""--target"",
        ""es2020"",
        ""--module"",
        ""es2020"",
        SIM_TS,
        ""--outFile"",
        js_out,
    ], check=True)

    script = tmp_path / ""run.mjs""
    script.write_text(
        f""import {{ Simulator }} from '{js_out.resolve().as_posix()}';\n""
        ""const start = performance.now();\n""
        ""const it = Simulator.run({popSize:1,generations:1});\n""
        ""await it.next();\n""
        ""console.log(performance.now()-start);\n"",
        encoding=""utf-8"",
    )
    res = subprocess.run([""node"", script], capture_output=True, text=True, check=True)
    elapsed = float(res.stdout.strip())
    assert elapsed < 70",tests/test_simulator_init.py,
survived,"        def __init__(self, *_a: object, **_k: object) -> None:
            pass
",tests/test_agent_manager_consumer.py,DummyBus
survived,"    def test_innovation_gain_positive(self) -> None:
        gain = forecast._innovation_gain(pop_size=2, generations=1)
        self.assertGreater(gain, 0.0)
        self.assertLess(gain, 0.1)",tests/test_forecast_functions.py,TestForecastFunctions
survived,"            def __init__(self) -> None:
                self.gen = 2
                self.best_fitness = 0.5
",tests/test_aiga_evolver_agent_logic.py,TestEvolverAgentLogic.Dummy
survived,"def agents_status() -> None:
    """"""List registered agents.""""""
    orch = orchestrator.Orchestrator()
    for agent in orch.agents:
        click.echo(agent.__class__.__name__)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/cli.py,
survived,"def main() -> None:
    parser = argparse.ArgumentParser(description=""Remove outdated LMDB records"")
    parser.add_argument(""path"", type=Path, help=""Path to LMDB directory"")
    parser.add_argument(
        ""keep"",
        help=""Retention period, e.g. 14d or 24h. Use 'all' to delete every record"",
    )
    args = parser.parse_args()

    rotate_lmdb(args.path, args.keep)
",scripts/rotate_lmdb.py,
survived,"    def fake_import(name, globals=None, locals=None, fromlist=(), level=0):
        if name == ""gradio"":
            raise ModuleNotFoundError(name)
        return orig_import(name, globals, locals, fromlist, level)
",tests/test_agent_muzero_entrypoint.py,
survived,"def test_agents_status_lists_names() -> None:
    with patch.object(cli.orchestrator, ""Orchestrator"") as orch_cls:
        orch = orch_cls.return_value
        orch.agents = [type(""A"", (), {})()]
        orch.agents[0].__class__.__name__ = ""AgentX""
        result = CliRunner().invoke(cli.main, [""agents-status""])
        assert ""AgentX"" in result.output
",tests/test_cli.py,
survived,"def make_function(code: str) -> str:
    try:
        import_stmts = []
        all_other_stmts = []
        astree = ast.parse(code)
        for stmt in astree.body:
            if isinstance(stmt, (ast.Import, ast.ImportFrom)):
                import_stmts.append(stmt)
            else:
                all_other_stmts.append(stmt)

        function_ast = ast.FunctionDef(
            name=""wrapped_function"",
            args=ast.arguments(
                posonlyargs=[], args=[], kwonlyargs=[], kw_defaults=[], defaults=[]
            ),
            body=all_other_stmts,
            decorator_list=[],
            lineno=-1,
        )
        main_code = (
            import_string
            + ""\n""
            + ast.unparse(import_stmts)  # type: ignore
            + ""\n""
            + ast.unparse(function_ast)  # type: ignore
        )
        return main_code
    except Exception as e:
        return code
",scripts/utils/lcb_runner.py,
survived,"def compile_code(code: str, timeout: int):
    signal.alarm(timeout)
    try:
        tmp_sol = ModuleType(""tmp_sol"", """")
        exec(code, tmp_sol.__dict__)
        if ""class Solution"" in code:
            # leetcode wraps solutions in `Solution`
            # this is a hack to check if it is leetcode solution or not
            # currently livecodebench only supports LeetCode but
            # else condition allows future extensibility to other platforms
            compiled_sol = tmp_sol.Solution()
        else:
            # do nothing in the other case since function is accesible
            compiled_sol = tmp_sol

        assert compiled_sol is not None
    finally:
        signal.alarm(0)

    return compiled_sol
",scripts/utils/lcb_runner.py,
survived,"def clean_if_name(code: str) -> str:
    try:
        astree = ast.parse(code)
        last_block = astree.body[-1]
        if isinstance(last_block, ast.If):
            condition = last_block.test
            if ast.unparse(condition).strip() == ""__name__ == '__main__'"":
                code = (
                    ast.unparse(astree.body[:-1]) + ""\n"" + ast.unparse(last_block.body)  # type: ignore
                )
    except:
        pass

    return code
",scripts/utils/lcb_runner.py,
survived,"def test_run_benchmarks(tmp_path: Path) -> None:
    result = subprocess.run(
        [sys.executable, str(Path('benchmarks') / 'run_benchmarks.py')],
        capture_output=True,
        text=True,
        check=True,
    )
    data = json.loads(result.stdout)
    assert any(d['task_id'].startswith('swebench_verified_mini') for d in data)
    assert any(d['task_id'].startswith('polyglot_lite') for d in data)
    for entry in data:
        assert 'time_ms' in entry and isinstance(entry['time_ms'], int)
        assert 'pass' in entry",tests/test_benchmarks.py,
survived,"    def __init__(self) -> None:
        super().__init__(name=""file_tools"")
",src/self_edit/tools.py,FileToolsADK
survived,"def test_evolve_stops_on_cost_cap():
    arch = InMemoryArchive()
    asyncio.run(arch.accept(Candidate(0.0, fitness=0.0, novelty=1.0)))

    async def run():
        await evolve(_op, _eval, arch, max_cost=0.1)

    asyncio.run(run())
    # seed + at least two children added
    assert len(arch.all()) >= 3",tests/test_evolve.py,
survived,"async def evolve(
    operator: Callable[[Any], Any],
    evaluate: Callable[[Any], tuple[float, float]],
    archive: InMemoryArchive,
    *,
    max_cost: float | None = None,
    wallclock: float | None = None,
) -> None:
    """"""Run an asynchronous evolution loop until the budget is exhausted.""""""

    if not archive.all():
        # seed with a random candidate
        await archive.accept(Candidate(genome=0.0, fitness=0.0, novelty=1.0, cost=0.0))

    spent = 0.0
    start = time.time()

    while True:
        if max_cost is not None and spent >= max_cost:
            break
        if wallclock is not None and time.time() - start >= wallclock:
            break

        parent = select_parent(archive.all(), temp=1.0)
        genome = operator(parent.genome)
        fitness, cost = await evaluate(genome)
        child = Candidate(genome=genome, fitness=fitness, novelty=random.random(), cost=cost)
        await archive.accept(child)
        spent += cost
",src/evolve.py,
survived,"    def test_invalid_signature_fails(self) -> None:
        agents._WHEEL_SIGS = {WHEEL_PATH.name: ""invalid""}
        self.assertFalse(agents._verify_wheel(WHEEL_PATH))",tests/test_verify_wheel.py,VerifyWheelTests
survived,"def bool_expr(prev_token_index, next_token_index, tok, change_end_line, change_end_char):
    if (not (prev_token_index is None or next_token_index is None)) and (tok[0] > change_end_line or (tok[0] == change_end_line and tok[1] > change_end_char)):
        return True
    return False",jac/jaclang/tests/fixtures/py_bool_expr.py,
survived,"def extract_level(desc):
    match = re.search(r""(\d+)(?:st|nd|rd|th) level"", desc, re.IGNORECASE)
    if match:
        try:
            return int(match.group(1))
        except ValueError:
            return None
    return None
",convert_missing.py,
survived,"def _get_requests():
    """"""Import ``requests`` or attempt to install it on demand.""""""
    global _REQUESTS
    if _REQUESTS is not None:
        return _REQUESTS
    try:  # pragma: no cover - handled at runtime
        import requests as _req
    except ImportError:
        sys.stderr.write(""Installing 'requests'...\n"")
        try:
            subprocess.check_call([sys.executable, ""-m"", ""pip"", ""install"", ""requests""])
            import requests as _req
        except Exception:
            sys.stderr.write(
                ""Failed to install 'requests'. Please run 'pip install -r requirements-dev.txt'.\n""
            )
            raise
    _REQUESTS = _req
    return _req
",tools/update_actions.py,
survived,"def test_call_vllm_parses_response(env_setup, monkeypatch):
    from importlib import reload

    import np_ocr.search as search
    reload(search)

    class FakeCompletions:
        @staticmethod
        def parse(*args, **kwargs):
            class Msg:
                parsed = search.ImageAnswer(answer=""ok"")
            class Choice:
                message = Msg()
            class Completion:
                choices = [Choice()]
            return Completion()

    class FakeOpenAI:
        def __init__(self, base_url=None, api_key=None):
            pass
        class Beta:
            class Chat:
                completions = FakeCompletions()
            chat = Chat()
        beta = Beta()

    monkeypatch.setattr(search, ""OpenAI"", FakeOpenAI)
    img = Image.new(""RGB"", (10, 10))
    result = search.call_vllm(img, ""hi"", base_url=""http://x"", api_key=""y"", model=""m"")
    assert result.answer == ""ok""
",no-ocr-api/tests/test_utils.py,
survived,"def _get(obj, name):
    if obj is None:
        return None
    if isinstance(obj, dict):
        if name in obj:
            return obj[name]
    if hasattr(obj, name):
        return getattr(obj, name)
    if name == ""items"" and hasattr(obj, ""Items""):
        return getattr(obj, ""Items"")
    if isinstance(obj, (list, tuple)):
        for it in obj:
            try:
                return _get(it, name)
            except Exception:
                pass
    raise Exception(""field not found: "" + name)
",tests/machine/x/python/python_math.py,
survived,"    def test_falls_back_to_unittest(self):
        with tempfile.TemporaryDirectory() as tmpdir:
            target = Path(tmpdir)
            with mock.patch('importlib.util.find_spec', return_value=None):
                with mock.patch('subprocess.call', return_value=0) as call:
                    with mock.patch.object(sys, 'argv', ['run_tests.py', str(target)]):
                        with self.assertRaises(SystemExit):
                            run_tests.main()
                    call.assert_called_once()
                    self.assertIn('unittest', call.call_args[0][0])
",alpha_factory_v1/tests/test_scripts_run_tests.py,RunTestsScriptTest
survived,"def on_exception(
    wait_gen: Callable[..., Any],
    exceptions: Tuple[Type[BaseException], ...],
    max_tries: int = 1,
):
    def decorator(func: Callable[..., Any]):
        async def wrapper(*args: Any, **kwargs: Any):
            tries = 0
            while True:
                try:
                    return await func(*args, **kwargs)
                except exceptions:
                    tries += 1
                    if tries >= max_tries:
                        raise

        return wrapper

    return decorator",src/backoff/__init__.py,
survived,"    def __init__(self, searchpath: str) -> None:
        self.searchpath = searchpath
",src/jinja2/__init__.py,FileSystemLoader
survived,"        def map_type(t: str) -> str:
            return t
",src/jinja2/__init__.py,
survived,"def safe_load(stream: Any) -> Any:
    try:
        if hasattr(stream, ""read""):
            data = stream.read()
        else:
            data = str(stream)
        return json.loads(data)
    except Exception as e:
        raise YAMLError(str(e))
",src/yaml/__init__.py,
survived,"def dump(data: Any, stream: Any = None) -> str:
    text = json.dumps(data, indent=2)
    if stream is not None:
        stream.write(text)
        return """"
    return text",src/yaml/__init__.py,
survived,"    def decorator(func: Callable[..., Any]):
        async def wrapper(*args: Any, **kwargs: Any):
            tries = 0
            while True:
                try:
                    return await func(*args, **kwargs)
                except exceptions:
                    tries += 1
                    if tries >= max_tries:
                        raise

        return wrapper
",src/backoff/__init__.py,
survived,"def test_dataframe_helpers() -> None:
    traj = _simulate(2, ""linear"", 2, 1)
    df_time = _timeline_df(traj)
    assert set(df_time.columns) == {""year"", ""sector"", ""energy"", ""disrupted""}
    assert len(df_time) == 4

    df_dis = _disruption_df(traj)
    assert set(df_dis.columns) == {""sector"", ""year""}
    assert len(df_dis) <= 2",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_web_app.py,
survived,"def test_cli_export_csv(runner, tmp_path):
    db_path = tmp_path / ""tele.db""
    db = TelemetryDB(db_path)
    db.record(5, 0.1, 0.2, 1)
    db.close()
    out = tmp_path / ""export.csv""
    result = runner.invoke(
        cli,
        [
            ""export"",
            ""--db-path"",
            str(db_path),
            ""--output"",
            str(out),
            ""--format"",
            ""csv"",
            ""--metric"",
            ""tokens"",
        ],
    )
    assert result.exit_code == 0
    assert out.exists()",tests/test_cli.py,
survived,"def test_export_json_and_csv(tmp_path):
    db_path = tmp_path / ""tele.db""
    db = TelemetryDB(db_path)
    # Create two records with known timestamps
    now = datetime.utcnow()
    db.record(5, 0.02, 0.3, 1)
    db.conn.execute(
        ""UPDATE telemetry SET timestamp=? WHERE id=1"",
        ((now - timedelta(days=1)).isoformat(),),
    )
    db.record(10, 0.05, 0.6, 2)

    json_path = tmp_path / ""export.json""
    csv_path = tmp_path / ""export.csv""

    db.export_json(json_path, start=now.isoformat())
    with open(json_path, ""r"", encoding=""utf-8"") as f:
        data = json.load(f)
    assert len(data) == 1
    assert data[0][""tokens""] == 10

    db.export_csv(csv_path, metrics=[""tokens""], start=now.isoformat())
    with open(csv_path, newline="""", encoding=""utf-8"") as f:
        reader = csv.reader(f)
        rows = list(reader)
    assert rows[0] == [""timestamp"", ""tokens""]
    assert len(rows) == 2
    db.close()
",tests/unit/test_telemetry_db.py,
survived,"    def export(
        self,
        path: str | Path,
        *,
        fmt: str = ""json"",
        start: datetime | str | None = None,
        end: datetime | str | None = None,
        metrics: Iterable[str] | None = None,
        compress: bool | None = None,
    ) -> str:
        """"""Export telemetry data in ``fmt`` ('json' or 'csv').""""""
        fmt = fmt.lower()
        if fmt == ""json"":
            return self.export_json(
                path,
                start=start,
                end=end,
                metrics=metrics,
                compress=compress,
            )
        if fmt == ""csv"":
            return self.export_csv(
                path,
                start=start,
                end=end,
                metrics=metrics,
                compress=compress,
            )
        if fmt == ""pdf"":
            raise NotImplementedError(""PDF export not implemented"")
        raise ValueError(f""Unknown format: {fmt}"")
",src/meta_agent/telemetry_db.py,TelemetryDB
survived,"    def test_top_tags_page(self):
        for i in range(1, 12):
            tag = Tag.objects.create(tag=f""tag{i}"")
            for j in range(i):
                entry = EntryFactory(title=f""Entry{i}-{j}"")
                entry.tags.add(tag)
        response = self.client.get(""/top-tags/"")
        assert response.status_code == 200
        tags_info = response.context[""tags_info""]
        self.assertEqual(len(tags_info), 10)
        self.assertEqual(tags_info[0][""tag""].tag, ""tag11"")
        self.assertFalse(any(info[""tag""].tag == ""tag1"" for info in tags_info))
        latest = Tag.objects.get(tag=""tag11"").entry_set.order_by(""-created"")[0].title
        self.assertContains(response, latest)",blog/tests.py,BlogTests
survived,"def download_openai_gpt2(model: str = ""117M"", dest: Path | str = ""models"", attempts: int = 3) -> None:
    dest_dir = Path(dest) / model
    urls = model_urls(model)
    last_exc: Exception | None = None
    for url in urls:
        target = dest_dir / Path(url).name
        if target.exists():
            print(f""{target} already exists, skipping"")
            continue
        for i in range(1, attempts + 1):
            try:
                print(f""Downloading {url} to {target} (attempt {i})"")
                _download(url, target)
                break
            except Exception as exc:  # noqa: PERF203
                last_exc = exc
                if i < attempts:
                    print(f""Attempt {i} failed: {exc}, retrying..."")
                else:
                    print(f""ERROR: could not download {url}: {exc}"")
                    if target.exists():
                        try:
                            target.unlink()
                        except Exception:
                            pass
    if last_exc:
        raise last_exc
",scripts/download_openai_gpt2.py,
survived,"def test_cycle_detection():
    agent_a = Agent(name=""A"")
    agent_b = Agent(name=""B"")
    agent_a.handoffs.append(agent_b)
    agent_b.handoffs.append(agent_a)

    nodes = get_all_nodes(agent_a)
    edges = get_all_edges(agent_a)

    assert nodes.count('""A"" [label=""A""') == 1
    assert nodes.count('""B"" [label=""B""') == 1
    assert '""A"" -> ""B""' in edges
    assert '""B"" -> ""A""' in edges",tests/test_visualization.py,
survived,"def install_wheel(path: Path) -> Optional[ModuleType]:
    """"""Load a wheel from *path* and return the module.""""""
    if not verify_wheel(path):
        logger.error(""Refusing to load unsigned wheel: %s"", path.name)
        return None
    spec = importlib.util.spec_from_file_location(path.stem, path)
    if spec and spec.loader:
        mod = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(mod)  # type: ignore[arg-type]
        return mod
    return None",alpha_factory_v1/backend/agents/plugins.py,
survived,"def test_show_memory_missing(tmp_path) -> None:
    with patch.object(cli.config.CFG, ""memory_path"", str(tmp_path / ""mem.log"")):
        res = CliRunner().invoke(cli.main, [""show-memory""])
        assert ""No memory"" in res.output
",tests/test_cli.py,
survived,"    async def insight(req: InsightRequest, _: None = Depends(verify_token)) -> InsightResponse:
        """"""Return aggregated forecast data across runs.""""""

        ids = req.ids or list(_simulations.keys())
        forecasts = [
            _simulations[i].forecast
            for i in ids
            if i in _simulations
        ]
        if not forecasts:
            raise HTTPException(status_code=404)

        year_map: dict[int, list[float]] = {}
        for fc in forecasts:
            for point in fc:
                year_map.setdefault(point.year, []).append(point.capability)
        agg = [
            InsightPoint(year=year, capability=sum(vals) / len(vals))
            for year, vals in sorted(year_map.items())
        ]
        return InsightResponse(forecast=agg)
",src/interface/api_server.py,
survived,"def test_manifest_parsing_when_registration_tags_given_as_selector(
    image_field_name: str,
    image_selector: str,
    predictions: Optional[str],
) -> None:
    raw_manifest = {
        ""type"": ""roboflow_core/roboflow_dataset_upload@v2"",
        ""name"": ""some"",
        image_field_name: image_selector,
        ""predictions"": predictions,
        ""target_project"": ""some1"",
        ""usage_quota_name"": ""my_quota"",
        ""data_percentage"": ""$inputs.data_percentage"",
        ""persist_predictions"": ""$inputs.persist_predictions"",
        ""minutely_usage_limit"": 10,
        ""hourly_usage_limit"": 100,
        ""daily_usage_limit"": 1000,
        ""max_image_size"": (100, 200),
        ""compression_level"": 100,
        ""registration_tags"": ""$inputs.tags"",
        ""disable_sink"": ""$inputs.disable_sink"",
        ""fire_and_forget"": ""$inputs.fire_and_forget"",
        ""labeling_batch_prefix"": ""$inputs.labeling_batch_prefix"",
        ""labeling_batches_recreation_frequency"": ""never"",
    }

    result = BlockManifest.model_validate(raw_manifest)

    assert result == BlockManifest(
        type=""roboflow_core/roboflow_dataset_upload@v2"",
        name=""some"",
        images=image_selector,
        predictions=predictions,
        target_project=""some1"",
        usage_quota_name=""my_quota"",
        data_percentage=""$inputs.data_percentage"",
        persist_predictions=""$inputs.persist_predictions"",
        minutely_usage_limit=10,
        hourly_usage_limit=100,
        daily_usage_limit=1000,
        max_image_size=(100, 200),
        compression_level=100,
        registration_tags=""$inputs.tags"",
        disable_sink=""$inputs.disable_sink"",
        fire_and_forget=""$inputs.fire_and_forget"",
        labeling_batch_prefix=""$inputs.labeling_batch_prefix"",
        labeling_batches_recreation_frequency=""never"",
    )
",tests/workflows/unit_tests/core_steps/sinks/roboflow/roboflow_dataset_upload/test_v2.py,
survived,"        def _mp_fn(index: int, cfg: TextLogitsConfig, tmp_dir: str):
            dataset = read_dataset(cfg.input_path)
            dataset = dataset.shard(xmp.xrt_world_size(), index)

            tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)
            model = AutoModelForCausalLM.from_pretrained(cfg.model_name)
            device = xm.xla_device()
            model.to(device)
            model.eval()

            def _forward(batch):
                tokens = tokenizer(
                    batch[""text""],
                    truncation=True,
                    padding=True,
                    max_length=cfg.max_length,
                    return_tensors=""pt"",
                )
                tokens = {k: v.to(device) for k, v in tokens.items()}
                with torch.no_grad():
                    outputs = model(**tokens)
                xm.mark_step()
                batch[""logits""] = outputs.logits.cpu().tolist()
                return batch

            dataset = dataset.map(
                _forward, batched=True, batch_size=cfg.batch_size
            )

            shard_path = os.path.join(tmp_dir, f""logits_{index}.jsonl.gz"")
            write_dataset(dataset, shard_path)
",marin/generation/logits.py,
survived,"    def run(cfg: TextLogitsConfig):
        import torch_xla.core.xla_model as xm
        import torch_xla.distributed.xla_multiprocessing as xmp

        def _mp_fn(index: int, cfg: TextLogitsConfig, tmp_dir: str):
            dataset = read_dataset(cfg.input_path)
            dataset = dataset.shard(xmp.xrt_world_size(), index)

            tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)
            model = AutoModelForCausalLM.from_pretrained(cfg.model_name)
            device = xm.xla_device()
            model.to(device)
            model.eval()

            def _forward(batch):
                tokens = tokenizer(
                    batch[""text""],
                    truncation=True,
                    padding=True,
                    max_length=cfg.max_length,
                    return_tensors=""pt"",
                )
                tokens = {k: v.to(device) for k, v in tokens.items()}
                with torch.no_grad():
                    outputs = model(**tokens)
                xm.mark_step()
                batch[""logits""] = outputs.logits.cpu().tolist()
                return batch

            dataset = dataset.map(
                _forward, batched=True, batch_size=cfg.batch_size
            )

            shard_path = os.path.join(tmp_dir, f""logits_{index}.jsonl.gz"")
            write_dataset(dataset, shard_path)

        with tempfile.TemporaryDirectory() as tmp_dir:
            xmp.spawn(_mp_fn, args=(cfg, tmp_dir))
            import glob
            import datasets

            shard_files = sorted(glob.glob(os.path.join(tmp_dir, ""logits_*.jsonl.gz"")))
            shards = [read_dataset(p) for p in shard_files]
            combined = datasets.concatenate_datasets(shards)
            write_dataset(combined, cfg.output_path)
",marin/generation/logits.py,
survived,"def makeAdder(n):
    return lambda x: x + n
",tests/transpiler/x/py/closure.py,
survived,"def test_bridge_online_mode(monkeypatch) -> None:
    pytest.importorskip(""openai_agents"")
    monkeypatch.setenv(""OPENAI_API_KEY"", ""dummy"")
    result = subprocess.run(
        [
            sys.executable,
            ""-m"",
            ""alpha_factory_v1.demos.meta_agentic_tree_search_v0.openai_agents_bridge"",
            ""--episodes"",
            ""1"",
            ""--rewriter"",
            ""openai"",
        ],
        capture_output=True,
        text=True,
    )
    assert result.returncode == 0, result.stderr
    assert ""Best agents"" in result.stdout
",tests/test_meta_agentic_tree_search_demo.py,
survived,"def self_improver_cmd(repo_url: str, patch_file: str, metric_file: str, log_file: str) -> None:
    """"""Clone repo, apply patch, evaluate score delta and log it.""""""

    delta, _ = self_improver.improve_repo(repo_url, patch_file, metric_file, log_file)
    click.echo(f""score delta: {delta}"")
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/cli.py,
survived,"    def fake_chat(prompt: str, cfg: object | None = None) -> str:
        called[""prompt""] = prompt
        return ""local""
",tests/test_alpha_agi_business_3_v1.py,
survived,"    def __getitem__(cls, item: NamedArrayAxesSpec) -> typing.Annotated[""NamedArray"", NamedArrayAxes]:
        axes = _parse_namedarray_axes(item)
        return typing.Annotated[NamedArray, axes]
",src/haliax/core.py,NamedArrayMeta
survived,"def build_llm() -> OpenAIAgent:
    """"""Create the default ``OpenAIAgent`` instance.""""""
    api_key = os.getenv(""OPENAI_API_KEY"")
    return OpenAIAgent(
        model=os.getenv(""MODEL_NAME"", ""gpt-4o-mini""),
        api_key=api_key,
        base_url=None if api_key else os.getenv(""OLLAMA_BASE_URL"", ""http://localhost:11434/v1""),
    )",alpha_factory_v1/demos/aiga_meta_evolution/utils.py,
survived,"        def __init__(self):
            self.image_size_cache = {}
            self.class_embeddings_cache = {}
            self.image_embed_cache = {}
            self.cpu_image_embed_cache = {}
            self.before_unload_image_none = False
            self.after_unload = False
",tests/inference/models_predictions_tests/test_owlv2.py,DummyOwl
survived,"def classify_with_llm(text: str) -> bool:
    """"""Placeholder LLM classifier for ambiguous snippets.""""""
    lower = text.lower()
    return ""paywalled"" in lower or ""proprietary"" in lower
",scripts/dp_scrubber.py,
survived,"        async def _spawn():  # pragma: no cover - Rocketry callback
            await self._spawn_jobs()
",src/scheduler/__init__.py,SelfImprovementScheduler
survived,"    async def _spawn_jobs(self) -> None:
        """"""Spawn new worker tasks until quotas or limits are hit.""""""
        if self.time_quota and time.time() - self.start_time >= self.time_quota:
            self.app.session.finish()
            return
        if self.tokens_quota is not None and self.tokens_used >= self.tokens_quota:
            self.app.session.finish()
            return
        # schedule initial evaluation or bandit-selected jobs
        while len(self.running) < self.max_workers:
            if not self._first_round_done:
                if self.queue.empty():
                    break
                job = await self.queue.get()
            else:
                if not self._active_jobs:
                    self.app.session.finish()
                    break
                job = self._select_job()
            task = asyncio.create_task(self._run_job(job))
            self.running.add(task)
            task.add_done_callback(self.running.discard)
",src/scheduler/__init__.py,SelfImprovementScheduler
survived,"def _fetch_spot_price(region: str = ""us-east-1"") -> float:
    """"""Return the current A10 spot price per hour in ``region``.""""""
    if boto3 is None:  # pragma: no cover - missing deps
        raise RuntimeError(""boto3 not available"")
    ec2 = boto3.client(""ec2"", region_name=region)
    history = ec2.describe_spot_price_history(
        InstanceTypes=[""g5.2xlarge""],
        ProductDescriptions=[""Linux/UNIX""],
        MaxResults=1,
    )
    price = float(history[""SpotPriceHistory""][0][""SpotPrice""])
    return price
",src/scheduler/spot_gpu.py,
survived,"    async def _run_job(self, job: Job) -> None:
        start = time.perf_counter()
        try:
            delta, _ = await asyncio.to_thread(
                self_improver.improve_repo,
                job.repo,
                job.patch,
                job.metric,
                job.log,
            )
            self.tokens_used += job.tokens
            gpu_hours = (time.perf_counter() - start) / 3600
            metrics.dgm_gpu_hours_total.inc(gpu_hours)
            if delta > 0:
                metrics.dgm_fitness_gain_total.inc(delta)
            if metrics.dgm_fitness_gain_total._value.get() > 0:
                ratio = (
                    metrics.dgm_gpu_hours_total._value.get()
                    / metrics.dgm_fitness_gain_total._value.get()
                )
                metrics.dgm_gpu_hours_per_gain.set(ratio)
            if not self._first_round_done:
                self._results[job] = delta
            else:
                suc, fail = self._stats.get(job, (0, 0))
                if delta > 0:
                    suc += 1
                else:
                    fail += 1
                self._stats[job] = (suc, fail)
        except Exception:  # noqa: BLE001
            await self.queue.put(job)
        if not self._first_round_done and len(self._results) == len(self._initial_jobs):
            self._finalize_first_round()
",src/scheduler/__init__.py,SelfImprovementScheduler
survived,"    def start_merkle_task(self, interval: int = 86_400) -> None:
        if self._task is None:
            try:
                loop = asyncio.get_running_loop()
            except RuntimeError:  # pragma: no cover - no loop in sync context
                _log.warning(""Merkle task requires a running event loop"")
                return
            self._task = loop.create_task(self._loop(interval))
",src/archive/service.py,ArchiveService
survived,"    def __init__(
        self,
        path: str | Path = _DEFAULT_DB,
        *,
        rpc_url: str | None = None,
        wallet: str | None = None,
        broadcast: bool = True,
    ) -> None:
        self.path = Path(path)
        self.path.parent.mkdir(parents=True, exist_ok=True)
        self.conn = sqlite3.connect(str(self.path))
        self.conn.execute(
            """"""
            CREATE TABLE IF NOT EXISTS entries(
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                parent TEXT,
                spec TEXT,
                scores TEXT,
                hash TEXT,
                ts REAL
            )
            """"""
        )
        self.conn.commit()
        self.rpc_url = rpc_url
        self.wallet = wallet
        self.broadcast = broadcast
        self._task: asyncio.Task[None] | None = None
",src/archive/service.py,ArchiveService
survived,"    def _report() -> None:  # pragma: no cover - scheduler callback
        weekly_report(csv_path)
",src/analysis/meta_foresight.py,
survived,"    def raise_for_status(self) -> None:
        """"""Raise :class:`RuntimeError` if the status code signals an error.""""""
        if self.status_code >= 400:
            raise RuntimeError(f""HTTP {self.status_code}"")
",alpha_factory_v1/requests.py,Response
survived,"        def skipif(self, *_, **__):
            def wrapper(func):
                return func
            return wrapper
",alpha_factory_v1/tests/test_smoke.py,_DummyMark
survived,"    def test_register_condition_callable(self):
        @register(condition=lambda: True)
        class BazAgent(AgentBase):
            NAME = ""baz""
        self.assertIn(""baz"", AGENT_REGISTRY)
",alpha_factory_v1/tests/test_register_decorator.py,RegisterDecoratorTest
survived,"        def start(self) -> None:  # pragma: no cover - unused
            pass
",tests/test_alpha_agi_business_3_v1.py,DummySock
survived,"            async def close(self) -> None:
                pass
",tests/test_insight_orchestrator_features.py,TestLedger.DummyClient
survived,"async def main() -> None:
    example_path = Path(__file__).parent / ""app.py""

    config = {
        ""mcpServers"": {
            ""hello"": {
                ""command"": sys.executable,
                ""args"": [str(example_path)],
            }
        }
    }

    client = MCPClient(config=config)
    session = await client.create_session(""hello"")
    result = await session.connector.call_tool(""hello_world"", {})
    print(result.content[0].text)

    await client.close_all_sessions()
",examples/hello_world/client.py,
survived,"def _start_server_with_retry(
    port: int, env: dict[str, str] | None = None, *, attempts: int = 3
) -> subprocess.Popen[bytes]:
    url = f""http://127.0.0.1:{port}""
    last_err: AssertionError | None = None
    for _ in range(attempts):
        proc = _start_server(port, env)
        try:
            _wait_ready(proc, url)
            return proc
        except AssertionError as err:
            last_err = err
            proc.terminate()
            proc.wait(timeout=5)
    assert last_err is not None
    raise last_err
",tests/test_metrics.py,
survived,"    async def emit(self, recipient: str, payload: Any) -> None:
        env = messaging.Envelope(
            sender=self.name,
            recipient=recipient,
            payload=struct_pb2.Struct(),
            ts=time.time(),
        )
        if isinstance(payload, dict):
            env.payload.update(payload)
        self.ledger.log(env)
        self.bus.publish(recipient, env)
",alpha_factory_v1/core/agents/base_agent.py,BaseAgent
survived,"def lead_signal_improvement(
    history: Sequence[float],
    forecast: Sequence[float],
    *,
    months: int = 6,
    threshold: float | None = None,
) -> float:
    """"""Return relative lead-time improvement over the baseline.""""""
    base = _arima_baseline(history, months)
    thr = threshold if threshold is not None else (history[-1] if history else 0.0)

    def first_cross(seq: Sequence[float]) -> int:
        for i, v in enumerate(seq, 1):
            if v >= thr:
                return i
        return months + 1

    base_idx = first_cross(base)
    cand_idx = first_cross(forecast[:months])
    if base_idx <= cand_idx:
        return 0.0
    return (base_idx - cand_idx) / base_idx
",alpha_factory_v1/core/evaluators/lead_time.py,
survived,"    async def evolve(
        self,
        scenario_hash: str,
        fn: Callable[[list[float]], tuple[float, ...]],
        genome_length: int,
        sector: str = ""generic"",
        approach: str = ""ga"",
        experiment_id: str = ""default"",
        **kwargs: object,
    ) -> mats.Population:
        """"""Run evolution for ``scenario_hash`` keyed by ``experiment_id``.""""""

        pops = self.experiment_pops.setdefault(experiment_id, {})
        if len(self.experiment_pops) > 10:
            raise RuntimeError(""max concurrent experiments exceeded"")

        pop = await asyncio.to_thread(
            mats.run_evolution,
            fn,
            genome_length,
            scenario_hash=scenario_hash,
            populations=pops,
            **cast(Any, kwargs),
        )
        pops[scenario_hash] = pop
        for ind in pop:
            self.solution_archive.add(
                sector,
                approach,
                ind.score,
                {""genome"": ind.genome},
            )
            self.archive.insert_entry(
                {""experiment_id"": experiment_id, ""genome"": ind.genome},
                {""score"": ind.score},
            )
        return pop
",alpha_factory_v1/core/orchestrator.py,Orchestrator
survived,"    def _generate_basic_tool_code(name: str) -> str:
        """"""Return a very small tool implementation used as a fallback.""""""
        return f""""""
import logging

logger_tool = logging.getLogger(__name__)

class {name}Tool:
    def __init__(self, salutation: str = 'Hello'):
        self.salutation = salutation
        logger_tool.info(f'{name}Tool initialized with {{self.salutation}}')

    def run(self, name: str) -> str:
        logger_tool.info(f'{name}Tool.run called with {{name}}')
        return f'{{self.salutation}}, {{name}} from {name}Tool!'

def get_tool_instance():
    logger_tool.info('get_tool_instance called')
    return {name}Tool()
""""""
",src/meta_agent/sub_agent_manager.py,SubAgentManager
survived,"def test_merge_usage_entries_with_new_keys():
    """"""Ensure merging usage entries preserves unseen keys.""""""
    tracker = UsageTracker()

    tracker.add_usage(""model-x"", {""prompt_tokens"": 5})
    tracker.add_usage(""model-x"", {""completion_tokens"": 2})

    total_usage = tracker.get_total_tokens()

    assert total_usage[""model-x""][""prompt_tokens""] == 5
    assert total_usage[""model-x""][""completion_tokens""] == 2",tests/utils/test_usage_tracker.py,
survived,"def test_missing_value_returns_zero() -> None:
    value = er.reward(None, None, {""latency_ms"": 400})
    assert value == 0.0
",tests/test_efficiency_reward.py,
survived,"    def __init__(self) -> None:
        self.history = deque()
",tests/test_education_reward.py,DummyState
survived,"def test_first_solution_yields_one() -> None:
    _reset()
    value = ns.reward(None, None, ""solve x"")
    assert isinstance(value, float)
    assert value == 1.0
",tests/test_novel_solution_reward.py,
survived,"def _reset_ledger() -> None:
    eb._ledger.clear()
",tests/test_energy_balance_reward.py,
survived,"def test_typical_day_score_in_range() -> None:
    _reset_ledger()
    res = {""date"": ""2025-04-22"", ""calories_in"": 2400, ""calories_out"": 600, ""bmr"": 1650}
    value = eb.reward(None, None, res)
    assert isinstance(value, float)
    assert 0.0 <= value <= 1.0
",tests/test_energy_balance_reward.py,
survived,"def test_add():
    assert calc.add(1, 1) == 2",alpha_factory_v1/demos/self_healing_repo/sample_broken_calc/test_calc.py,
survived,"def _simulate(horizon: int, curve: str, pop_size: int, generations: int) -> list[Any]:
    """"""Run the disruption forecast and return the trajectory.""""""
    secs = [sector.Sector(f""s{i:02d}"") for i in range(pop_size)]
    return cast(
        list[Any],
        forecast.forecast_disruptions(
            secs,
            horizon,
            curve,
            pop_size=pop_size,
            generations=generations,
        ),
    )
",src/interface/minimal_ui.py,
survived,"def test_single_file_format():
    source_files = {""Contract"": {""content"": ""contract C {}""}}
    assert not is_standard_json_contract(source_files)
",tests/test_utils.py,
survived,"    async def step(self) -> None:  # noqa: D401
        """"""Delegate step execution to :meth:`run_cycle`.""""""
        await self.run_cycle()
",alpha_factory_v1/backend/agents/cyber_threat_agent.py,CyberThreatAgent
survived,"    async def step(self) -> None:  # noqa: D401
        """"""Delegate step execution to :meth:`run_cycle`.""""""
        await self.run_cycle()
",alpha_factory_v1/backend/agents/climate_risk_agent.py,ClimateRiskAgent
survived,"def _build_parser() -> argparse.ArgumentParser:
    p = argparse.ArgumentParser(description=""Run Î±â€‘AGI Insight simulation"")
    p.add_argument(""--horizon"", type=int, default=5)
    return p
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/cli.py,
survived,"    async def handle(self, env):
        pass",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/planning_agent.py,PlanningAgent
survived,"    async def run_cycle(self) -> None:
        pass
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/research_agent.py,ResearchAgent
survived,"    def fn(g):
        return (g[0] ** 2, g[1] ** 2)
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_mats.py,
survived,"    async def handle(self, env):
        pass",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/memory_agent.py,MemoryAgent
survived,"    def __init__(self, bus, ledger) -> None:
        super().__init__(""memory"", bus, ledger)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/memory_agent.py,MemoryAgent
survived,"    async def stop(self) -> None:
        if self._server:
            await self._server.stop(0)
            self._server = None",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/messaging.py,A2ABus
survived,"        def simplify_link_target(text_content: str) -> str:
            match_colon_num = re.match(r""([^:]+:\d+)"", text_content)
            if match_colon_num:
                return match_colon_num.group(1)
            return text_content
",app/services/client.py,GeminiClientWrapper
survived,"    async def init(self, **kwargs):
        # Inject default configuration values
        kwargs.setdefault(""timeout"", g_config.gemini.timeout)
        kwargs.setdefault(""auto_refresh"", g_config.gemini.auto_refresh)
        kwargs.setdefault(""verbose"", g_config.gemini.verbose)
        kwargs.setdefault(""refresh_interval"", g_config.gemini.refresh_interval)

        await super().init(**kwargs)
",app/services/client.py,GeminiClientWrapper
survived,"    async def process_conversation(messages: list[Message], tempdir: Path | None = None):
        """"""
        Process the entire conversation and return a formatted string and list of
        files. The last message is assumed to be the assistant's response.
        """"""
        conversation: list[str] = []
        files: list[Path | str] = []

        for msg in messages:
            input_part, files_part = await GeminiClientWrapper.process_message(msg, tempdir)
            conversation.append(input_part)
            files.extend(files_part)

        # Left with the last message as the assistant's response
        conversation.append(add_tag(""assistant"", """", unclose=True))

        return ""\n"".join(conversation), files
",app/services/client.py,GeminiClientWrapper
survived,"    def test_invalid_env_logs_warning(self) -> None:
        logging.disable(logging.NOTSET)
        with patch.dict(os.environ, {""FOO"": ""bar""}, clear=True):
            with self.assertLogs(""alpha_factory_v1.edge_runner"", level=""WARNING"") as cm:
                self.assertEqual(edge_runner._env_int(""FOO"", 5), 5)
        self.assertTrue(any(""Invalid FOO"" in msg for msg in cm.output))",tests/test_edge_runner.py,TestEnvIntWarning
survived,"def get_window_region(window_title):
    window_list = Quartz.CGWindowListCopyWindowInfo(
        Quartz.kCGWindowListOptionOnScreenOnly | Quartz.kCGWindowListExcludeDesktopElements,
        Quartz.kCGNullWindowID
    )
    # Get all exist windows
    all_titles = []
    for window in window_list:
        title = window.get(Quartz.kCGWindowName, '')
        owner = window.get(Quartz.kCGWindowOwnerName, '')
        if title:
            all_titles.append(f""{title} (Owner: {owner})"")
    logger.debug(f""all_titles: {all_titles}"")
    for window in window_list:
        if window.get(Quartz.kCGWindowName, '') == window_title:
            bounds = window.get(Quartz.kCGWindowBounds, {})
            return {
                ""left"": int(bounds.get('X', 0)),
                ""top"": int(bounds.get('Y', 0)),
                ""width"": int(bounds.get('Width', 0)),
                ""height"": int(bounds.get('Height', 0))
            }
    return None
",src/input/GameWindowCapturorForMac.py,
survived,"def parse_and_validate_attributes(attr_str):
    raw_values = attr_str.split(',')
    if len(raw_values) != 4:
        raise argparse.ArgumentTypeError(""You must provide exactly 4 attributes: STR,DEX,INT,LUK"")

    parsed = []
    total_known = 0
    unknown_count = 0

    for v in raw_values:
        if v.strip() == '?':
            parsed.append(None)
            unknown_count += 1
        else:
            try:
                val = int(v)
            except ValueError:
                raise argparse.ArgumentTypeError(f""Invalid attribute value: {v}"")
            if not (4 <= val <= 13):
                raise argparse.ArgumentTypeError(""Each attribute must be between 4 and 13."")
            parsed.append(val)
            total_known += val

    if unknown_count > 0 and (total_known > 25 or total_known + 4 * unknown_count > 25):
        raise argparse.ArgumentTypeError(""Impossible to satisfy sum of 25 with current values."")

    return parsed
",tools/AutoDiceRoller.py,
survived,"    def solve_rune(self):
        '''
        Solve the rune puzzle by detecting the arrow directions and pressing corresponding keys.
        '''
        while self.is_in_rune_game():
            for arrow_idx in [0,1,2,3]:
                # Get lastest game screen frame buffer
                self.frame = self.capture.get_frame()
                # Resize game screen to 1296x759
                self.img_frame = cv2.resize(self.frame, (1296, 759),
                                            interpolation=cv2.INTER_NEAREST)

                # Crop arrow detection box
                x = self.cfg.arrow_box_start_point[0] + self.cfg.arrow_box_interval*arrow_idx
                y = self.cfg.arrow_box_start_point[1]
                size = self.cfg.arrow_box_size
                img_roi = self.img_frame[y:y+size, x:x+size]

                # Loop through all possible arrows template and choose the most possible one
                best_score = float('inf')
                best_direction = """"
                for direction, arrow_list in self.img_arrows.items():
                    for img_arrow in arrow_list:
                        _, score, _ = find_pattern_sqdiff(
                                        img_roi, img_arrow,
                                        mask=get_mask(img_arrow, (0, 255, 0)))
                        if score < best_score:
                            best_score = score
                            best_direction = direction
                logger.info(f""[solve_rune] Arrow({arrow_idx}) is {best_direction} with score({best_score})"")

                # Update img_frame_debug
                self.img_frame_debug = self.img_frame.copy()
                draw_rectangle(
                    self.img_frame_debug, (x, y), (size, size),
                    (0, 0, 255), str(round(best_score, 2))
                )
                # Update debug window
                self.update_img_frame_debug()
                cv2.waitKey(1)

                # For logging
                screenshot(self.img_frame_debug, ""solve_rune"")

                # Press the key for 0.5 second
                if not self.args.disable_control:
                    self.kb.press_key(best_direction, 0.5)
                time.sleep(1)


        logger.info(f""[solve_rune] Solved all arrows"")
",src/legacy/mapleStoryAutoLevelUp_legacy.py,MapleStoryBot
survived,"    def get_monsters_in_range(self, top_left, bottom_right):
        '''
        get_monsters_in_range
        '''
        x0, y0 = top_left
        x1, y1 = bottom_right

        img_roi = self.img_frame[y0:y1, x0:x1]

        monster_info = []
        for monster_name, monster_imgs in self.monsters.items():
            for img_monster, mask_monster in monster_imgs:
                if self.args.patrol:
                    pass # Don't detect monster using template in patrol mode
                elif self.cfg.monster_detect_mode == ""template_free"":
                    # Generate mask where pixel is exactly (0,0,0)
                    black_mask = np.all(img_roi == [0, 0, 0], axis=2).astype(np.uint8) * 255
                    cv2.imshow(""Black Pixel Mask"", black_mask)

                    # Shift player's location into ROI coordinate system
                    px, py = self.loc_player
                    px_in_roi = px - x0
                    py_in_roi = py - y0

                    # Define rectangle range around player (in ROI coordinate)
                    char_x_min = max(0, px_in_roi - self.cfg.character_width // 2)
                    char_x_max = min(img_roi.shape[1], px_in_roi + self.cfg.character_width // 2)
                    char_y_min = max(0, py_in_roi - self.cfg.character_height // 2)
                    char_y_max = min(img_roi.shape[0], py_in_roi + self.cfg.character_height // 2)

                    # Zero out mask inside this region (ignore player's own character)
                    black_mask[char_y_min:char_y_max, char_x_min:char_x_max] = 0

                    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (20, 20))
                    closed_mask = cv2.morphologyEx(black_mask, cv2.MORPH_CLOSE, kernel)
                    # cv2.imshow(""Black Mask"", closed_mask)

                    # draw player character bounding box

                    draw_rectangle(
                        self.img_frame_debug, (char_x_min+x0, char_y_min+y0),
                        (self.cfg.character_height, self.cfg.character_width),
                        (255, 0, 0), ""Character Box""
                    )

                    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(closed_mask, connectivity=8)

                    monster_info = []
                    min_area = 1000
                    for i in range(1, num_labels):
                        x, y, w, h, area = stats[i]
                        if area > min_area:
                            monster_info.append({
                                ""name"": """",
                                ""position"": (x0+x, y0+y),
                                ""size"": (h, w),
                                ""score"": 1.0,
                            })
                elif self.cfg.monster_detect_mode == ""contour_only"":
                    # Use only black lines contour to detect monsters
                    # Create masks (already grayscale)
                    mask_pattern = np.all(img_monster == [0, 0, 0], axis=2).astype(np.uint8) * 255
                    mask_roi = np.all(img_roi == [0, 0, 0], axis=2).astype(np.uint8) * 255

                    # Apply Gaussian blur (soften the masks)
                    img_monster_blur = cv2.GaussianBlur(mask_pattern, (self.cfg.blur_range, self.cfg.blur_range), 0)
                    img_roi_blur = cv2.GaussianBlur(mask_roi, (self.cfg.blur_range, self.cfg.blur_range), 0)

                    # Check template vs ROI size before matching
                    h_roi, w_roi = img_roi_blur.shape[:2]
                    h_temp, w_temp = img_monster_blur.shape[:2]

                    if h_temp > h_roi or w_temp > w_roi:
                        return []  # template bigger than roi, skip this matching

                    # Perform template matching
                    res = cv2.matchTemplate(img_roi_blur, img_monster_blur, cv2.TM_SQDIFF_NORMED)

                    # Apply soft threshold
                    match_locations = np.where(res <= self.cfg.monster_diff_thres)

                    h, w = img_monster.shape[:2]
                    for pt in zip(*match_locations[::-1]):
                        monster_info.append({
                            ""name"": monster_name,
                            ""position"": (pt[0] + x0, pt[1] + y0),
                            ""size"": (h, w),
                            ""score"": res[pt[1], pt[0]],
                        })
                elif self.cfg.monster_detect_mode == ""grayscale"":
                    img_monster_gray = cv2.cvtColor(img_monster, cv2.COLOR_BGR2GRAY)
                    img_roi_gray = cv2.cvtColor(img_roi, cv2.COLOR_BGR2GRAY)
                    res = cv2.matchTemplate(
                            img_roi_gray,
                            img_monster_gray,
                            cv2.TM_SQDIFF_NORMED,
                            mask=mask_monster)
                    match_locations = np.where(res <= self.cfg.monster_diff_thres)
                    h, w = img_monster.shape[:2]
                    for pt in zip(*match_locations[::-1]):
                        monster_info.append({
                            ""name"": monster_name,
                            ""position"": (pt[0] + x0, pt[1] + y0),
                            ""size"": (h, w),
                            ""score"": res[pt[1], pt[0]],
                    })
                elif self.cfg.monster_detect_mode == ""color"":
                    res = cv2.matchTemplate(
                            img_roi,
                            img_monster,
                            cv2.TM_SQDIFF_NORMED,
                            mask=mask_monster)
                    match_locations = np.where(res <= self.cfg.monster_diff_thres)
                    h, w = img_monster.shape[:2]
                    for pt in zip(*match_locations[::-1]):
                        monster_info.append({
                            ""name"": monster_name,
                            ""position"": (pt[0] + x0, pt[1] + y0),
                            ""size"": (h, w),
                            ""score"": res[pt[1], pt[0]],
                    })
                else:
                    logger.error(f""Unexpected camera localization mode: {self.cfg.monster_detect_mode}"")
                    return []

        # Apply Non-Maximum Suppression to monster detection
        monster_info = nms(monster_info, iou_threshold=0.4)

        # Detect monster via health bar
        if self.cfg.monster_detect_with_health_bar:
            # Create color mask for Monsters' HP bar
            mask = cv2.inRange(img_roi,
                               np.array(self.cfg.monster_health_bar_color),
                               np.array(self.cfg.monster_health_bar_color))

            # Find connected components (each cluster of green pixels)
            num_labels, labels, stats, centroids = \
                cv2.connectedComponentsWithStats(mask, connectivity=8)

            for i in range(1, num_labels):  # skip background (label 0)
                x, y, w, h, area = stats[i]
                if area < 3:  # small noise filter
                    continue

                # Guess a monster bounding box
                y += 10
                x = max(0, x)
                y = max(0, y)
                w = 70
                h = 70

                monster_info.append({
                    ""name"": ""Health Bar"",
                    ""position"": (x0 + x, y0 + y),
                    ""size"": (h, w),
                    ""score"": 1.0,
                })

        # Debug
        # Draw attack detection range
        draw_rectangle(
            self.img_frame_debug, (x0, y0), (y1-y0, x1-x0),
            (255, 0, 0), ""Monster Detection Box""
        )

        # Draw monsters bounding box
        for monster in monster_info:
            if monster[""name""] == ""Health Bar"":
                color = (0, 255, 255)
            else:
                color = (0, 255, 0)

            draw_rectangle(
                self.img_frame_debug, monster[""position""], monster[""size""],
                color, str(round(monster['score'], 2))
            )

        return monster_info
",src/legacy/mapleStoryAutoLevelUp_legacy.py,MapleStoryBot
survived,"    def get_minimap_location(self):
        '''
        get_minimap_location
        '''
        loc_minimap, score, is_cached = find_pattern_sqdiff(
                                            self.img_frame, self.img_map)

        return loc_minimap
",src/legacy/mapleStoryAutoLevelUp_legacy.py,MapleStoryBot
survived,"def test_new_async_manager_includes_tags() -> None:
    config = {""callbacks"": None}
    manager = get_async_callback_manager_for_config(config, tags=[""x"", ""y""])
    assert isinstance(manager, AsyncCallbackManager)
    assert manager.inheritable_tags == [""x"", ""y""]
",libs/langgraph/tests/test_config_async.py,
survived,"        def run(self) -> None:
            pass
",tests/test_aiga_openai_bridge_offline.py,AgentRuntime
survived,"def test_patcher_cli_offline(tmp_path, monkeypatch):
    repo = tmp_path / ""repo""
    repo.mkdir()
    (repo / ""test_ok.py"").write_text(""def test_ok():\n    assert True\n"", encoding=""utf-8"")

    # stub openai to satisfy import in llm_client
    monkeypatch.setitem(sys.modules, ""openai"", types.ModuleType(""openai""))

    orig_import = builtins.__import__

    def fake_import(name, globals=None, locals=None, fromlist=(), level=0):
        if name == ""openai_agents"":
            raise ModuleNotFoundError(name)
        return orig_import(name, globals, locals, fromlist, level)

    monkeypatch.setattr(builtins, ""__import__"", fake_import)
    monkeypatch.setattr(sys, ""argv"", [""patcher_core.py"", ""--repo"", str(repo)])

    runpy.run_module(
        ""alpha_factory_v1.demos.self_healing_repo.patcher_core"", run_name=""__main__""
    )",tests/test_patcher_core_cli_offline.py,
survived,"    def fake_import(name, globals=None, locals=None, fromlist=(), level=0):
        if name == ""openai_agents"":
            raise ModuleNotFoundError(name)
        return orig_import(name, globals, locals, fromlist, level)
",tests/test_patcher_core_cli_offline.py,
survived,"    def test_agents_must_be_positive(self) -> None:
        with self.assertRaises(ValueError):
            run_sim(agents=0, rounds=10, delta=0.5, stake=1.0)
        with self.assertRaises(ValueError):
            run_sim(agents=-1, rounds=10, delta=0.5, stake=1.0)
",tests/test_governance_sim.py,TestGovernanceSim
survived,"def test_pyodide_fallback() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri()

    with sync_playwright() as p:
        browser = p.chromium.launch()
        page = browser.new_page()
        page.route(""**/pyodide.js"", lambda route: route.abort())
        page.goto(url)
        page.wait_for_selector(""#controls"")
        page.wait_for_selector(""#toast.show"")
        assert ""Pyodide"" in page.inner_text(""#toast"")
        browser.close()
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_pyodide_fallback.py,
survived,"    def test_old_version_fails(self) -> None:
        fake_mod = types.SimpleNamespace(__version__=""0.0.13"")
        orig_import_module = importlib.import_module
        orig_find_spec = importlib.util.find_spec

        def _fake_import(name: str, *args: Any, **kwargs: Any) -> object:
            if name == ""openai_agents"":
                return fake_mod
            return orig_import_module(name, *args, **kwargs)

        def _fake_find_spec(name: str, *args: Any, **kwargs: Any) -> object:
            if name == ""openai_agents"":
                return object()
            return orig_find_spec(name, *args, **kwargs)

        with (
            mock.patch(""importlib.import_module"", side_effect=_fake_import),
            mock.patch(""importlib.util.find_spec"", side_effect=_fake_find_spec),
        ):
            self.assertFalse(preflight.check_openai_agents_version())
",tests/test_preflight_openai_agents_version.py,TestPreflightOpenAIAgentsVersion
survived,"def _insert_after_tool(ctx: RunContextWrapper | dict, path: str, anchor: str, code: str) -> str:
    insert_after(path, anchor, code)
    return ""ok""
",src/self_edit/tools.py,
survived,"def test_undo_idempotent(temp_path: Path) -> None:
    temp_path.write_text(""a\nb\nc\n"")
    insert_after(temp_path, ""b"", ""x"")
    assert ""x"" in temp_path.read_text()
    assert undo_last_edit() is True
    assert temp_path.read_text() == ""a\nb\nc\n""
    assert undo_last_edit() is False
    assert temp_path.read_text() == ""a\nb\nc\n""
",tests/test_tools_undo.py,
survived,"def _undo_tool(ctx: RunContextWrapper | dict) -> bool:
    return undo_last_edit()
",src/self_edit/tools.py,
survived,"def _ensure_db(path: Path) -> None:
    with sqlite3.connect(path) as cx:
        cx.execute(
            ""CREATE TABLE IF NOT EXISTS tarballs(id INTEGER PRIMARY KEY AUTOINCREMENT,path TEXT,cid TEXT,pinned INTEGER,ts REAL)""
        )
        cx.execute(
            ""CREATE TABLE IF NOT EXISTS merkle(date TEXT PRIMARY KEY,root TEXT)""
        )
",src/archive/hash_archive.py,
survived,"def _dump_yaml(obj: Any, indent: int = 0) -> List[str]:
    lines: List[str] = []
    prefix = "" "" * indent
    if isinstance(obj, dict):
        for k, v in obj.items():
            if isinstance(v, (dict, list)):
                lines.append(f""{prefix}{k}:"")
                lines.extend(_dump_yaml(v, indent + 2))
            else:
                lines.append(f""{prefix}{k}: {v}"")
    elif isinstance(obj, list):
        for item in obj:
            if isinstance(item, (dict, list)):
                lines.append(f""{prefix}-"")
                lines.extend(_dump_yaml(item, indent + 2))
            else:
                lines.append(f""{prefix}- {item}"")
    else:
        lines.append(f""{prefix}{obj}"")
    return lines
",src/yaml/__init__.py,
survived,"def _gen_crc16_table(poly: int) -> list[int]:
  table = []
  for i in range(256):
    crc = i << 8
    for _ in range(8):
      if crc & 0x8000:
        crc = ((crc << 1) ^ poly) & 0xFFFF
      else:
        crc = (crc << 1) & 0xFFFF
    table.append(crc)
  return table
",opendbc/car/crc.py,
survived,"def fca_giorgio_checksum(address: int, sig, d: bytearray) -> int:
  crc = 0
  for i in range(len(d) - 1):
    crc ^= d[i]
    crc = CRC8J1850[crc]
  if address == 0xDE:
    return crc ^ 0x10
  elif address == 0x106:
    return crc ^ 0xF6
  elif address == 0x122:
    return crc ^ 0xF1
  else:
    return crc ^ 0x0A",opendbc/car/chrysler/chryslercan.py,
survived,"def list_destinations() -> list[Destination]:
    """"""Return the full list of available destinations.""""""

    return DESTINATIONS
",examples/server_side_llm_travel_planner/app.py,
survived,"    async def sampling(
        self,
        messages: str | list[str | SamplingMessage],
        **kwargs,
    ) -> CreateMessageResult:
        """"""Alias for :meth:`ask_llm`.""""""

        return await self.ask_llm(messages, **kwargs)
",src/enrichmcp/context.py,EnrichContext
survived,"    def count_links_in_html(html_path: Path) -> int:
        content = html_path.read_text(encoding=""utf-8"", errors=""ignore"")
        return content.count(""See docs/DISCLAIMER_SNIPPET.md"")
",scripts/verify_disclaimer_snippet.py,
survived,"def test_self_improve_prompt_snapshot(monkeypatch):
    log = (FIXTURES / ""self_improve.txt"").read_text()

    def fake_llm(prompt: str, system: str | None) -> str:
        return f""patch-{random.random()}""

    monkeypatch.setattr(prompting, ""_get_llm"", lambda: fake_llm)
    out = prompting.self_improve(""Fix bug:\n{logs}"", log, seed=7)
    assert out == ""patch-0.32383276483316237""",tests/test_self_improve_prompting.py,
survived,"def test_startup_requires_token(monkeypatch: pytest.MonkeyPatch) -> None:
    monkeypatch.delenv(""API_TOKEN"", raising=False)
    with pytest.raises(RuntimeError):
        _run_client()

    monkeypatch.setenv(""API_TOKEN"", ""changeme"")
    with pytest.raises(RuntimeError):
        _run_client()",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_api_token_required.py,
survived,"    def __class_getitem__(cls, item: NamedArrayAxesSpec) -> typing.Any:
        axes = _parse_namedarray_axes(item)
        return typing.Annotated[NamedArray, axes]
",src/haliax/core.py,Named
survived,"    def is_git_ignored(p: Path) -> bool:
        try:
            result = subprocess.run(
                [""git"", ""check-ignore"", ""-q"", str(p.relative_to(repo_root))],
                cwd=repo_root,
            )
            return result.returncode == 0
        except Exception:
            return False
",scripts/verify_disclaimer_snippet.py,
survived,"    def test_cli_invalid_port_error(self) -> None:
        with patch.dict(os.environ, {}, clear=True):
            with self.assertRaises(SystemExit):
                edge_runner.parse_args([""--port"", ""0""])
",tests/test_edge_runner_cli.py,TestParseArgs
survived,"def test_execute_and_collect_propagates_error(monkeypatch, tmp_path):
    fake_exec = MagicMock()
    fake_exec.run_tests.side_effect = rc_mod.SandboxExecutionError(""boom"")
    module = ResultCollectionModule(fake_exec)
    with pytest.raises(rc_mod.SandboxExecutionError):
        module.execute_and_collect(tmp_path)",tests/unit/test_result_collection_module.py,
survived,"    def __init__(self, execution_module: Optional[ExecutionModule] = None) -> None:
        self.execution_module = execution_module or ExecutionModule()
",src/meta_agent/evaluation/result_collection.py,ResultCollectionModule
survived,"def _adk_available() -> bool:
    for name in (""google_adk"", ""google.adk""):
        try:
            spec = importlib.util.find_spec(name)
        except ValueError:
            spec = None
        if spec is None:
            continue
        mod = importlib.import_module(name)
        if hasattr(mod, ""Router""):
            return True
    return False
",tests/test_external_integrations.py,
survived,"def _oai_available() -> bool:
    for name in (""openai_agents"", ""agents""):
        try:
            spec = importlib.util.find_spec(name)
        except ValueError:
            spec = None
        if spec is None:
            continue
        mod = importlib.import_module(name)
        if Version(getattr(mod, ""__version__"", ""0"")) >= Version(""0.0.17""):
            return True
    return False
",tests/test_external_integrations.py,
survived,"def zero():
    return Pt(x=0.0, y=0.0, inf=True)
",tests/rosetta/transpiler/Python/elliptic-curve-arithmetic.py,
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    s = """"
    s2 = """"
    s = """"
    print((1 if s == """" else 0))
    print((1 if len(s) == 0 else 0))
    print((1 if s != """" else 0))
    print((1 if len(s) != 0 else 0))
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/empty-string-1.py,
survived,"def log2(x):
    k = 0.0
    v = x
    while v >= 2.0:
        v = v / 2.0
        k = k + 1.0
    while v < 1.0:
        v = v * 2.0
        k = k - 1.0
    z = (v - 1.0) / (v + 1.0)
    zpow = z
    sum = z
    i = 3
    while i <= 9:
        zpow = zpow * z * z
        sum = sum + zpow / (float(i))
        i = i + 2
    ln2 = 0.6931471805599453
    return k + 2.0 * sum / ln2
",tests/rosetta/transpiler/Python/entropy-2.py,
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    print(str(H(""1223334444"")))
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/entropy-1.py,
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    cells = 20
    generations = 9
    print(""Single 1, rule 90:"")
    state = singleInit(cells)
    elem(90, cells, generations, state)
    print(""Random intial state, rule 30:"")
    state = randInit(cells, 3)
    elem(30, cells, generations, state)
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/elementary-cellular-automaton.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/enumerations-2.py,
survived,"def fromY(y):
    return Pt(x=cbrtApprox(y * y - bCoeff), y=y, inf=False)
",tests/rosetta/transpiler/Python/elliptic-curve-arithmetic.py,
survived,"def add(a, b):
    return a + b
",tests/rosetta/transpiler/Python/element-wise-operations.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/ekg-sequence-convergence.py,
survived,"def randInit(cells, seed):
    s = """"
    val = seed
    i = 0
    while i < cells:
        val = (val * 1664525 + 1013904223) % 2147483647
        if val % 2 == 0:
            s = s + ""0""
        else:
            s = s + ""1""
        i = i + 1
    return s
",tests/rosetta/transpiler/Python/elementary-cellular-automaton.py,
survived,"            def passwords_per_seconds(self, seconds):
                return 0
",btcrecover/test/test_passwords.py,TestOuterIterations.DummyWallet
survived,"def test_load_gitignore_as_context_rules_spaces_and_comments(tmp_path: Path):
    """"""Ensure gitignore lines are converted with spaces preserved and comments ignored.""""""
    gi_file = tmp_path / "".gitignore""
    gi_file.write_text(
        ""\n"".join(
            [
                ""# a comment"",
                ""foo.py"",
                ""!bar.py"",
                "" baz.txt"",
                ""trail.txt   "",
                ""\\#literal"",
                """",
            ]
        ),
        encoding=""utf-8"",
    )

    rules = load_gitignore_as_context_rules(gi_file)

    assert rules == [
        ""!foo.py"",
        ""bar.py"",
        ""! baz.txt"",
        ""!trail.txt   "",
        ""!\\#literal"",
    ]
",tests/test_config_system.py,
survived,"    def test_generate_plan(self) -> None:
        with tempfile.TemporaryDirectory() as tmp:
            ledger = Path(tmp) / 'plan.json'
            result = subprocess.run(
                [sys.executable, STUB, '--alpha', 'test opportunity', '--ledger', str(ledger)],
                capture_output=True,
                text=True,
            )
            self.assertEqual(result.returncode, 0, result.stderr)
            self.assertTrue(ledger.exists())
            data = json.loads(ledger.read_text())
            self.assertIsInstance(data, dict)
            self.assertIn('steps', data)
",tests/test_alpha_conversion_stub.py,TestAlphaConversionStub
survived,"    def test_stub_compiles(self):
        py_compile.compile(STUB, doraise=True)
",tests/test_alpha_opportunity_stub.py,TestAlphaOpportunityStub
survived,"def test_cli_overrides_env(monkeypatch: pytest.MonkeyPatch) -> None:
    """"""CLI options should override preset environment variables.""""""
    if MODULE in sys.modules:
        del sys.modules[MODULE]
    mod = importlib.import_module(MODULE)

    monkeypatch.setattr(mod, ""check_env"", types.SimpleNamespace(main=lambda *_a, **_k: None), raising=False)

    monkeypatch.setenv(""OPENAI_API_KEY"", ""env-key"")
    monkeypatch.setenv(""ADK_HOST"", ""http://env-adk:8"")
    monkeypatch.setenv(""A2A_PORT"", ""1234"")
    monkeypatch.setenv(""A2A_HOST"", ""env-host"")
    monkeypatch.setenv(""LOCAL_LLM_URL"", ""http://env-llm"")
    monkeypatch.setenv(""LLAMA_MODEL_PATH"", ""/env/model.gguf"")
    monkeypatch.setenv(""LLAMA_N_CTX"", ""99"")

    captured: dict[str, Any] = {}

    async def _llm(_: float) -> str:
        captured[""api_key""] = os.getenv(""OPENAI_API_KEY"")
        captured[""local_llm_url""] = os.getenv(""LOCAL_LLM_URL"")
        captured[""llama_model_path""] = os.getenv(""LLAMA_MODEL_PATH"")
        captured[""llama_n_ctx""] = os.getenv(""LLAMA_N_CTX"")
        return ""ok""

    class DummyADK:
        def __init__(self, host: str) -> None:  # pragma: no cover - init only
            captured[""adk_host""] = host

    class DummySock:
        def __init__(self, host: str, port: int, app_id: str) -> None:
            captured[""a2a""] = f""{host}:{port}""  # pragma: no cover - record args

        def start(self) -> None:  # pragma: no cover - unused
            pass

        def stop(self) -> None:  # pragma: no cover - unused
            pass

        def sendjson(self, *_a: object, **_kw: object) -> None:  # pragma: no cover - unused
            pass

    monkeypatch.setattr(mod, ""_llm_comment"", _llm)
    monkeypatch.setattr(mod, ""ADKClient"", DummyADK)
    monkeypatch.setattr(mod, ""A2ASocket"", DummySock)

    asyncio.run(
        mod.main(
            [
                ""--cycles"",
                ""1"",
                ""--interval"",
                ""0"",
                ""--openai-api-key"",
                ""cli-key"",
                ""--adk-host"",
                ""http://cli-adk:9"",
                ""--a2a-port"",
                ""7777"",
                ""--a2a-host"",
                ""cli-host"",
                ""--local-llm-url"",
                ""http://cli-llm"",
                ""--llama-model-path"",
                ""/cli/model.gguf"",
                ""--llama-n-ctx"",
                ""120"",
            ]
        )
    )

    assert captured[""api_key""] == ""cli-key""
    assert captured[""adk_host""] == ""http://cli-adk:9""
    assert captured[""a2a""] == ""cli-host:7777""
    assert captured[""local_llm_url""] == ""http://cli-llm""
    assert captured[""llama_model_path""] == ""/cli/model.gguf""
    assert captured[""llama_n_ctx""] == ""120""
",tests/test_alpha_agi_business_3_v1.py,
survived,"            def __init__(self) -> None:
                self.instructions: list[Any] = []
",tests/test_ledger_broadcast.py,DummyTx
survived,"def test_broadcast_merkle_root_logs_on_error() -> None:
    with tempfile.TemporaryDirectory() as tmp:
        ledger = Ledger(os.path.join(tmp, ""l.db""), rpc_url=""http://rpc.test"", broadcast=True)
        env = messaging.Envelope(sender=""a"", recipient=""b"", payload={""v"": 1}, ts=0.0)
        ledger.log(env)
        root = ledger.compute_merkle_root()

        captured: dict[str, Any] = {}

        class DummyClient:
            def __init__(self, url: str) -> None:
                captured[""url""] = url

            async def send_transaction(self, tx: Any, *args: Any) -> None:
                captured[""root""] = tx.instructions[0].data.decode()
                raise RuntimeError(""fail"")

            async def close(self) -> None:
                pass

        class DummyTx:
            def __init__(self) -> None:
                self.instructions: list[Any] = []

            def add(self, instr: Any) -> ""DummyTx"":
                self.instructions.append(instr)
                return self

        class DummyInstr:
            def __init__(self, program_id: Any, data: bytes, keys: list[Any]):
                self.data = data

        class DummyPk:
            def __init__(self, val: str) -> None:
                pass

        with (
            mock.patch.dict(
                sys.modules,
                {
                    ""solana"": ModuleType(""solana""),
                    ""solana.rpc"": ModuleType(""solana.rpc""),
                    ""solana.rpc.async_api"": ModuleType(""solana.rpc.async_api""),
                },
            ),
            mock.patch(""solana.rpc.async_api.AsyncClient"", DummyClient, create=True),
            mock.patch.object(insight_logging, ""AsyncClient"", DummyClient, create=True),
            mock.patch.object(insight_logging, ""Transaction"", DummyTx, create=True),
            mock.patch.object(insight_logging, ""TransactionInstruction"", DummyInstr, create=True),
            mock.patch.object(insight_logging, ""PublicKey"", DummyPk, create=True),
            mock.patch.object(insight_logging, ""_log"") as log,
        ):
            asyncio.run(ledger.broadcast_merkle_root())

        assert captured[""root""] == root
        log.warning.assert_called()",tests/test_ledger_broadcast.py,
survived,"            def __init__(self, program_id: Any, data: bytes, keys: list[Any]):
                self.data = data
",tests/test_ledger_broadcast.py,DummyInstr
survived,"def test_broadcast_merkle_root_sends_transaction() -> None:
    with tempfile.TemporaryDirectory() as tmp:
        ledger = Ledger(os.path.join(tmp, ""l.db""), rpc_url=""http://rpc.test"", broadcast=True)
        env = messaging.Envelope(sender=""a"", recipient=""b"", payload={""v"": 1}, ts=0.0)
        ledger.log(env)
        root = ledger.compute_merkle_root()

        calls: list[tuple[str, Any]] = []

        class DummyClient:
            def __init__(self, url: str) -> None:
                calls.append((""url"", url))

            async def send_transaction(self, tx: Any, *args: Any) -> None:
                calls.append((""sent"", tx.instructions[0].data.decode()))

            async def close(self) -> None:
                pass

        class DummyTx:
            def __init__(self) -> None:
                self.instructions: list[Any] = []

            def add(self, instr: Any) -> ""DummyTx"":
                self.instructions.append(instr)
                return self

        class DummyInstr:
            def __init__(self, program_id: Any, data: bytes, keys: list[Any]):
                self.data = data

        class DummyPk:
            def __init__(self, val: str) -> None:
                pass

        with (
            mock.patch.dict(
                sys.modules,
                {
                    ""solana"": ModuleType(""solana""),
                    ""solana.rpc"": ModuleType(""solana.rpc""),
                    ""solana.rpc.async_api"": ModuleType(""solana.rpc.async_api""),
                },
            ),
            mock.patch(""solana.rpc.async_api.AsyncClient"", DummyClient, create=True),
            mock.patch.object(insight_logging, ""AsyncClient"", DummyClient, create=True),
            mock.patch.object(insight_logging, ""Transaction"", DummyTx, create=True),
            mock.patch.object(insight_logging, ""TransactionInstruction"", DummyInstr, create=True),
            mock.patch.object(insight_logging, ""PublicKey"", DummyPk, create=True),
        ):
            asyncio.run(ledger.broadcast_merkle_root())

        assert (""url"", ""http://rpc.test"") in calls
        assert (""sent"", root) in calls
",tests/test_ledger_broadcast.py,
survived,"            def __init__(self, url: str) -> None:
                calls.append((""url"", url))
",tests/test_ledger_client_close.py,DummyClient
survived,"            def add(self, instr: Any) -> ""DummyTx"":
                self.instructions.append(instr)
                return self
",tests/test_ledger_client_close.py,DummyTx
survived,"def load_ipython_extension(ip):
    ip.register_magics(MochiMagics)",tools/notebook/mochi_magic.py,
survived,"    def convert(self, node):
        self.visit(node)
        if self.lines and self.lines[-1] != """":
            self.lines.append("""")
        return ""\n"".join(self.lines)
",tools/any2mochi/py_simple.py,Conv
survived,"def test_from_client_deprecation_warning():
    """"""Test that FastMCP.from_client raises a deprecation warning.""""""
    server = FastMCP(""TestServer"")
    with pytest.warns(DeprecationWarning, match=""from_client""):
        FastMCP.from_client(Client(server))",tests/test_deprecated.py,
survived,"    async def delete_item(item_id: int) -> bool:
        """"""Delete item.""""""
        return True
",tests/test_mutability.py,
survived,"async def delete_customer(customer_id: int) -> bool:
    """"""Delete a customer.""""""
    return CUSTOMERS.pop(customer_id, None) is not None
",examples/mutable_crud/app.py,
survived,"    async def update_item(item_id: int, patch: Item.PatchModel) -> Item:
        """"""Update item.""""""
        return Item(id=item_id, name=patch.name or ""n"")
",tests/test_mutability.py,
survived,"        def _is_mutable(f: Any) -> bool:
            extra = getattr(f, ""json_schema_extra"", None)
            if extra is None:
                info = getattr(f, ""field_info"", None)
                extra = getattr(info, ""extra"", {}) if info is not None else {}
            return extra.get(""mutable"") is True
",src/enrichmcp/entity.py,EnrichModel
survived,"    def update_note(self, note_id: str, patch: dict[str, object]) -> MemoryNote:
        note = self.get_note(note_id)
        if note is None:
            raise KeyError(note_id)
        updated = note.model_copy(update=patch)
        self.store.save(self.name, updated)
        return updated
",examples/basic_memory/memory.py,MemoryProject
survived,"    def delete(self, project: str, note_id: str) -> bool:
        """"""Remove the note if present and return ``True`` on success.""""""
",examples/basic_memory/memory.py,MemoryStore
survived,"def auroc(truth: list[bool], scores: list[float]) -> float:
    """"""Compute AUROC using the rank method.""""""
    order = sorted(range(len(scores)), key=lambda i: scores[i])
    rank_sum = 0.0
    pos = 0
    for r, i in enumerate(order, 1):
        if truth[i]:
            rank_sum += r
            pos += 1
    neg = len(scores) - pos
    if pos == 0 or neg == 0:
        return 1.0
    return (rank_sum - pos * (pos + 1) / 2) / (pos * neg)
",src/simulation/replay.py,
survived,"def _append_metrics(path: Path, name: str, f1: float, auc: float, lead: float) -> None:
    import csv

    exists = path.exists()
    with path.open(""a"", newline="""", encoding=""utf-8"") as fh:
        writer = csv.writer(fh)
        if not exists:
            writer.writerow(_def_fields)
        writer.writerow([name, f1, auc, lead])
",src/simulation/replay.py,
survived,"    def run_find_neighbors(self):
        """"""Search neighbors using the hashed grid.""""""
        n = self.sorted_position.shape[0]
        max_n = self.config.get(""max_neighbor_count"", 50)
        neighbors = torch.full((n, max_n), -1, dtype=torch.long, device=self.device)
        cell_id = self.particle_index[:, 0]
        pos = self.sorted_position[:, :3]
        gsx = self.config[""grid_cells_x""]
        gsy = self.config[""grid_cells_y""]
        gsz = self.config[""grid_cells_z""]
        for p in range(n):
            cid = cell_id[p].item()
            gz = cid // (gsx * gsy)
            rem = cid % (gsx * gsy)
            gy = rem // gsx
            gx = rem % gsx
            idx = 0
            for dz in (-1, 0, 1):
                nz = gz + dz
                if nz < 0 or nz >= gsz:
                    continue
                for dy in (-1, 0, 1):
                    ny = gy + dy
                    if ny < 0 or ny >= gsy:
                        continue
                    for dx in (-1, 0, 1):
                        nx = gx + dx
                        if nx < 0 or nx >= gsx:
                            continue
                        cell = nx + ny * gsx + nz * gsx * gsy
                        start = self.grid_cell_index_fixed[cell]
                        end = self.grid_cell_index_fixed[cell + 1]
                        if start < 0 or end <= start:
                            continue
                        ids = self.particle_index[start:end, 1]
                        for j in ids:
                            j = j.item()
                            if j == self.particle_index[p, 1].item():
                                continue
                            if torch.norm(pos[p] - pos[j]) < self.config[""h""]:
                                if idx < max_n:
                                    neighbors[p, idx] = j
                                    idx += 1
        self.neighbor_map = neighbors
",pytorch_solver.py,PytorchSolver
survived,"    def run_compute_pressure(self):
        """"""Compute pressure from density error.""""""
        self.pressure = self.config[""delta""] * (self.rho - self.config[""rho0""])
",pytorch_solver.py,PytorchSolver
survived,"    def __init__(self, position, velocity, config):
        self.device = torch.device(config.get(""device"", ""cpu""))
        self.config = config
        self.position = torch.as_tensor(
            position, dtype=torch.float32, device=self.device
        )
        self.velocity = torch.as_tensor(
            velocity, dtype=torch.float32, device=self.device
        )
        self.acceleration = torch.zeros_like(self.position)
        self.pressure = torch.zeros(self.position.shape[0], device=self.device)
        self.rho = torch.zeros(self.position.shape[0], device=self.device)

        self.particle_index = None
        self.sorted_position = None
        self.sorted_velocity = None
        self.particle_index_back = None
        self.grid_cell_index = None
        self.grid_cell_index_fixed = None
        self.neighbor_map = None
",pytorch_solver.py,PytorchSolver
survived,"def convert_species_add(species_path, item_fields, pk_prefix, parent=None):
    data = load_json(species_path)
    data.append({
        ""model"": ""api_v2.species"",
        ""pk"": f""{pk_prefix}_{slugify(item_fields['name'])}"",
        ""fields"": {
            ""name"": item_fields[""name""],
            ""desc"": item_fields[""desc""],
            ""document"": pk_prefix,
            ""subspecies_of"": parent,
        },
    })
    save_json(data, species_path)
",convert_missing.py,
survived,"def test_research_agent_emits_strategy(monkeypatch) -> None:
    cfg = config.Settings(bus_port=0, openai_api_key=""k"")
    bus = DummyBus(cfg)
    led = DummyLedger()
    agent = research_agent.ResearchAgent(bus, led)
    monkeypatch.setattr(random, ""random"", lambda: 0.5)
    env = messaging.Envelope(""planning"", ""research"", {""plan"": ""y""}, 0.0)
    asyncio.run(agent.handle(env))
    assert bus.published[-1][0] == ""strategy""
",tests/test_agent_handle_methods.py,
survived,"    def __init__(self, settings: config.Settings) -> None:
        self.settings = settings
        self.published: list[tuple[str, messaging.Envelope]] = []
",tests/test_agent_handle_methods.py,DummyBus
survived,"def test_bundle_generator_creates_files(tmp_path: Path) -> None:
    gen = BundleGenerator(tmp_path)
    metadata = gen.generate(
        agent_code=""print('agent')"",
        tests={""test_sample.py"": ""def test_sample():\n    assert True""},
        requirements=[""foo==1.0""],
        readme=""# Hello"",
        guardrails_manifest=""{}"",
    )

    assert (tmp_path / ""agent.py"").exists()
    assert (tmp_path / ""tests"" / ""test_sample.py"").exists()
    assert (tmp_path / ""requirements.txt"").exists()
    assert (tmp_path / ""README.md"").exists()
    assert (tmp_path / ""guardrails"" / ""manifest.json"").exists()
    assert (tmp_path / ""traces"").is_dir()
    assert (tmp_path / ""bundle.json"").exists()

    with open(tmp_path / ""bundle.json"", encoding=""utf-8"") as f:
        data = json.load(f)
    assert data[""schema_version""] == BUNDLE_SCHEMA_VERSION
    checksums = data[""custom""][""checksums""]

    with open(tmp_path / ""agent.py"", encoding=""utf-8"") as f:
        expected = hashlib.sha256(f.read().encode(""utf-8"")).hexdigest()
    assert checksums[""agent.py""] == expected
",tests/test_bundle_generator.py,
survived,"    def _write_file(self, relative: str | Path, content: str) -> str:
        path = self.bundle_dir / relative
        path.parent.mkdir(parents=True, exist_ok=True)
        with open(path, ""w"", encoding=""utf-8"") as f:
            f.write(content)
        return hashlib.sha256(content.encode(""utf-8"")).hexdigest()
",src/meta_agent/bundle_generator.py,BundleGenerator
survived,"    def force_garbage_collection(self):
        """"""
        å¼ºåˆ¶åžƒåœ¾å›žæ”¶å¹¶è¿”å›žæ¸…ç†çš„å¯¹è±¡æ•°é‡
        """"""
        try:
            collected = gc.collect()
            logger.info(f""å¼ºåˆ¶åžƒåœ¾å›žæ”¶å®Œæˆï¼Œæ¸…ç†äº† {collected} ä¸ªå¯¹è±¡"")
            return collected
        except Exception as e:
            logger.error(f""å¼ºåˆ¶åžƒåœ¾å›žæ”¶å¤±è´¥: {e}"")
            return 0
",app/helper/memory.py,MemoryHelper
survived,"    def _write_python_objects_info(self, snapshot_file):
        """"""
        å†™å…¥Pythonå¯¹è±¡ç±»åž‹ç»Ÿè®¡ä¿¡æ¯
        """"""
        # èŽ·å–å½“å‰tracemallocç»Ÿè®¡
        current, peak = tracemalloc.get_traced_memory()
        
        # èŽ·å–æ‰€æœ‰å¯¹è±¡
        all_objects = muppy.get_objects()
        sum1 = summary.summarize(all_objects)
        
        # è®¡ç®—Pythonå¯¹è±¡æ€»å†…å­˜
        python_total_mb = 0
        for line in summary.format_(sum1):
            if '|' in line and line.strip() and not line.startswith('=') and not line.startswith('-'):
                parts = line.split('|')
                if len(parts) >= 3:
                    try:
                        size_str = parts[2].strip()
                        if 'MB' in size_str:
                            size_mb = float(size_str.replace('MB', '').strip())
                            python_total_mb += size_mb
                    except:
                        pass

        with open(snapshot_file, 'a', encoding='utf-8') as f:
            f.write(""\n"" + ""="" * 80 + ""\n"")
            f.write(""Pythonå†…å­˜ä½¿ç”¨æƒ…å†µ:\n"")
            f.write(""-"" * 80 + ""\n"")
            f.write(f""tracemallocå½“å‰å†…å­˜: {current / 1024 / 1024:.2f} MB\n"")
            f.write(f""tracemallocå³°å€¼å†…å­˜: {peak / 1024 / 1024:.2f} MB\n"")
            f.write(f""Pythonå¯¹è±¡æ€»å†…å­˜: {python_total_mb:.2f} MB\n"")
            f.write(f""æœªç»Ÿè®¡å†…å­˜(å¯èƒ½ä¸ºCæ‰©å±•): {self._get_unaccounted_memory():.2f} MB\n"")
            
            f.write(""\nå¯¹è±¡ç±»åž‹ç»Ÿè®¡:\n"")
            f.write(""-"" * 80 + ""\n"")
            # å†™å…¥å¯¹è±¡ç»Ÿè®¡ä¿¡æ¯
            for line in summary.format_(sum1):
                f.write(line + ""\n"")
            
            f.flush()
",app/helper/memory.py,MemoryHelper
deleted,"    def correctness_reward(prompt, response, answer, state):
        """"""Check if the response contains correct information.""""""
        response_lower = response.lower()
        answer_lower = answer.lower()
        
        # Check for exact match (normalized)
        if answer_lower in response_lower:
            return 1.0
        
        # Check for key terms match
        answer_terms = set(answer_lower.split())
        response_terms = set(response_lower.split())
        
        # Remove common words
        common_words = {""the"", ""a"", ""an"", ""is"", ""are"", ""was"", ""were"", ""of"", ""in"", ""to"", ""for""}
        answer_terms = answer_terms - common_words
        response_terms = response_terms - common_words
        
        if answer_terms:
            overlap = len(answer_terms & response_terms) / len(answer_terms)
            return min(overlap * 1.5, 1.0)  # Boost overlap score, cap at 1.0
        
        return 0.0
",environments/truthful_qa/truthful_qa.py,
survived,"def main():
    """"""Main function to run the example.""""""
    print(""Starting OpenAI o3 Responses API Example"")
    print(""="" * 60)
    
    try:
        results = run_example()
        
        print(f""\n{'='*60}"")
        print(""Example Summary"")
        print(f""{'='*60}"")
        
        for i, result in enumerate(results, 1):
            print(f""Scenario {i}: {result['action']}"")
        
        # End the trace
        agentops.end_trace(tracer, end_state=""Success"")
        
        # Validate the trace
        print(f""\n{'='*60}"")
        print(""Validating AgentOps Trace"")
        print(f""{'='*60}"")
        
        try:
            validation_result = agentops.validate_trace_spans(trace_context=tracer)
            agentops.print_validation_summary(validation_result)
            print(""âœ… Example completed successfully!"")
        except agentops.ValidationError as e:
            print(f""âŒ Error validating spans: {e}"")
            raise
            
    except Exception as e:
        print(f""âŒ Example failed: {e}"")
        agentops.end_trace(tracer, end_state=""Error"")
        raise
",examples/openai/o3_responses_example.py,
survived,"    def test_package_exists_dependency_change(self, mock_config, mock_logger):
        """"""Test scenario 3: Package existed in database and changed its dependencies""""""

        # Setup existing package and dependencies
        existing_pkg_id = uuid4()
        dep1_id = uuid4()
        dep2_id = uuid4()
        dep3_id = uuid4()

        existing_package = Package(
            id=existing_pkg_id,
            derived_id=""pkgx/dep-pkg"",
            name=""dep-pkg"",
            package_manager_id=mock_config.pm_config.pm_id,
            import_id=""dep-pkg"",
            readme="""",
        )

        # Create dependency packages
        dep1_pkg = Package(
            id=dep1_id, derived_id=""pkgx/dep1"", name=""dep1"", import_id=""dep1""
        )
        dep2_pkg = Package(
            id=dep2_id, derived_id=""pkgx/dep2"", name=""dep2"", import_id=""dep2""
        )
        dep3_pkg = Package(
            id=dep3_id, derived_id=""pkgx/dep3"", name=""dep3"", import_id=""dep3""
        )

        # Create existing dependencies (dep1 as runtime, dep2 as build)
        existing_dep1 = LegacyDependency(
            package_id=existing_pkg_id,
            dependency_id=dep1_id,
            dependency_type_id=mock_config.dependency_types.runtime,
        )
        existing_dep2 = LegacyDependency(
            package_id=existing_pkg_id,
            dependency_id=dep2_id,
            dependency_type_id=mock_config.dependency_types.build,
        )

        # Create cache
        cache = Cache(
            package_map={
                ""dep-pkg"": existing_package,
                ""dep1"": dep1_pkg,
                ""dep2"": dep2_pkg,
                ""dep3"": dep3_pkg,
            },
            url_map={},
            package_urls={},
            dependencies={existing_pkg_id: {existing_dep1, existing_dep2}},
        )

        # Create new package data with changed dependencies
        # Remove dep2, keep dep1, add dep3 as runtime
        new_pkg_data = create_pkgx_package(
            dependencies=[""dep1"", ""dep3""],  # runtime deps
            build_deps=[],  # no build deps (removes dep2)
        )

        # Test the diff
        diff = PkgxDiff(mock_config, cache, mock_logger)
        new_deps, removed_deps = diff.diff_deps(""dep-pkg"", new_pkg_data)

        # Assertions
        assert len(new_deps) == 1  # dep3 should be added
        assert new_deps[0].dependency_id == dep3_id
        assert new_deps[0].dependency_type_id == mock_config.dependency_types.runtime

        assert len(removed_deps) == 1  # dep2 should be removed
        assert removed_deps[0].dependency_id == dep2_id
        assert removed_deps[0].dependency_type_id == mock_config.dependency_types.build
",tests/package_managers/pkgx/test_pkgx_diff.py,TestPkgxDifferentialLoading
survived,"def guess(db_client: DB, package_managers: list[UUID], url: str) -> list[str]:
    names = possible_names(url)
    urls = db_client.search_names(names, package_managers)
    return urls
",package_managers/pkgx/url.py,
survived,"    async def test_create_api_key_after_deleting_last_key(
        self,
        organization_storage: MongoOrganizationStorage,
        org_col: AsyncCollection,
    ) -> None:
        """"""Test that reproduces the MongoDB index issue when deleting the last API key.

        With the old index ({""api_keys"": {""$exists"": True}}), creating a new API key after
        deleting the last one would fail with a duplicate key error because the index would
        still match the document even with an empty api_keys array.

        This test uses multiple tenants to demonstrate the issue more clearly.
        """"""
        tenant1 = TENANT
        tenant2 = ""tenant2""

        # Create organizations for both tenants
        await org_col.insert_one(dump_model(OrganizationDocument(tenant=tenant1, uid=1, slug=""1"")))
        await org_col.insert_one(dump_model(OrganizationDocument(tenant=tenant2, uid=2, slug=""2"")))

        tenant1_storage = MongoOrganizationStorage(
            tenant=(tenant1, 1),
            collection=org_col,
            encryption=organization_storage.encryption,
        )
        tenant2_storage = MongoOrganizationStorage(
            tenant=(tenant2, 2),
            collection=org_col,
            encryption=organization_storage.encryption,
        )

        # Create API key for tenant 1 and tenant 2
        tenant1_key = await tenant1_storage.create_api_key_for_organization(
            name=""tenant1 key"",
            hashed_key=""hashed123"",
            partial_key=""sk-123****"",
            created_by=UserIdentifier(user_id=""user1"", user_email=""test@example.com""),
        )

        tenant2_key = await tenant2_storage.create_api_key_for_organization(
            name=""tenant2 key"",
            hashed_key=""hashed456"",
            partial_key=""sk-456****"",
            created_by=UserIdentifier(user_id=""user2"", user_email=""test2@example.com""),
        )

        # Delete the API key for tenant 1
        result = await tenant1_storage.delete_api_key_for_organization(key_id=str(tenant1_key.id))
        assert result is True

        # Delete the API key for tenant 2
        result = await tenant2_storage.delete_api_key_for_organization(key_id=str(tenant2_key.id))
        assert result is True

        # Verify no keys remain for either tenant
        tenant1_keys = await tenant1_storage.get_api_keys_for_organization()
        tenant2_keys = await tenant2_storage.get_api_keys_for_organization()
        assert len(tenant1_keys) == 0
        assert len(tenant2_keys) == 0
",api/core/storage/mongo/partials/mongo_organizations_test.py,TestDeleteAPIKeyForOrganization
survived,"    def test_status_utils_with_invalid_resources(self):
        """"""Test status utility functions handle invalid resources gracefully.""""""
        # Create a mock cluster record with problematic resources
        mock_record = {
            'status': None,
            'num_nodes': 1,
            'resources': None,  # Problematic: None resources
            'total_cost': 0.0
        }
        
        # These should not crash even with None resources
        try:
            status_utils._get_resources_for_cost_report(mock_record, truncate=True)
            status_utils._get_price_for_cost_report(mock_record, truncate=True)
            status_utils._get_estimated_cost_for_cost_report(mock_record, truncate=True)
        except (AttributeError, TypeError):
            # Expected - the functions might fail gracefully, but shouldn't crash the whole system
            pass
",tests/unit_tests/test_sky_cost_report.py,TestHistoricalClusterRobustness
survived,"    def test_cost_report_mixed_valid_invalid_clusters(self):
        """"""Test cost report works when some clusters are valid and others have issues.""""""
        valid_cluster = {
            'name': 'valid-cluster',
            'status': status_lib.ClusterStatus.UP,
            'num_nodes': 1,
            'resources': mock.Mock(),
            'total_cost': 5.50,
            'launched_at': 1640995200,
            'duration': 3600,
            'cluster_hash': 'valid123',
            'usage_intervals': [(1640995200, 1640998800)],
            'user_hash': 'user_valid',
            'user_name': 'validuser',
            'workspace': 'default',
        }
        valid_cluster['resources'].instance_type = 'standard-instance'
        valid_cluster['resources'].cloud = mock.Mock()
        valid_cluster['resources'].cloud.__str__ = lambda: 'aws'
        
        invalid_cluster = {
            'name': 'invalid-cluster',
            'status': None,
            'num_nodes': 1,
            'resources': mock.Mock(),
            'total_cost': 0.0,
            'launched_at': 1640995200,
            'duration': 1800,
            'cluster_hash': 'invalid456',
            'usage_intervals': [(1640995200, 1640997000)],
            'user_hash': 'user_invalid',
            'user_name': 'invaliduser',
            'workspace': 'default',
        }
        invalid_cluster['resources'].instance_type = 'discontinued-instance-type'
        invalid_cluster['resources'].cloud = mock.Mock()
        invalid_cluster['resources'].cloud.__str__ = lambda: 'nonexistent-cloud'
        
        with mock.patch('sky.global_user_state.get_clusters_from_history', 
                      return_value=[valid_cluster, invalid_cluster]):
            
                         # Should return both clusters, even if one has issues
             result = core.cost_report(days=30)
             self.assertEqual(len(result), 2)
             
             cluster_names = [r['name'] for r in result]
             self.assertIn('valid-cluster', cluster_names)
             self.assertIn('invalid-cluster', cluster_names)
",tests/unit_tests/test_sky_cost_report.py,TestHistoricalClusterRobustness
survived,"def main():
    data_dir = ""data/debian/latest""

    # Check if data files exist
    sources_file = os.path.join(data_dir, ""sources"")
    packages_file = os.path.join(data_dir, ""packages"")

    if not os.path.exists(sources_file):
        logger.log(f""ERROR: Sources file not found at {sources_file}"")
        logger.log(""Use --fetch to download the latest data"")
        return 1

    if not os.path.exists(packages_file):
        logger.log(f""ERROR: Packages file not found at {packages_file}"")
        logger.log(""Use --fetch to download the latest data"")
        return 1

    logger.log(f""Using sources file: {sources_file}"")
    logger.log(f""Using packages file: {packages_file}"")

    investigate_mapping(sources_file, packages_file)

    return 0
",package_managers/debian/scripts/investigate_sources.py,
survived,"    def get_project_by_id(project_id: int, user_id: str) -> Optional[Dict]:
        """"""Get a specific project by ID for a user""""""
        try:
            result = supabase.table('projects').select('*').eq('id', project_id).eq('user_id', user_id).execute()
            return result.data[0] if result.data else None
        except Exception as e:
            logger.error(f""Error fetching project {project_id}: {e}"")
            raise
",server/database.py,DatabaseOperations
survived,"def get_task_details(task_id):
    """"""Get detailed information about a specific task""""""
    try:
        user_id = request.headers.get('X-User-ID')
        if not user_id:
            return jsonify({'error': 'User ID required'}), 400
        
        task = DatabaseOperations.get_task_by_id(task_id, user_id)
        if not task:
            return jsonify({'error': 'Task not found'}), 404
        
        return jsonify({
            'status': 'success',
            'task': task
        })
        
    except Exception as e:
        logger.error(f""Error fetching task details: {str(e)}"")
        return jsonify({'error': str(e)}), 500
",server/tasks.py,
survived,"    def test_flow_output_model(self):
        """"""Test FlowOutput model validation.""""""
        # Success output
        output = FlowOutput(
            result=""test result"",
            execution_time=1.5
        )
        assert output.result == ""test result""
        assert output.execution_time == 1.5
        assert output.error is None

        # Error output
        error_output = FlowOutput(
            result=None,
            error=""Test error occurred""
        )
        assert error_output.result is None
        assert error_output.error == ""Test error occurred""
",src/backend/tests/unit/test_mcp_server.py,TestFlowModels
survived,"def run_mcp_server(
    mcp_server: FastMCP,
    transport: str = ""stdio"",
    host: str = ""127.0.0.1"", 
    port: int = 8000,
) -> None:
    """"""Run the MCP server with the specified transport.
    
    Args:
        mcp_server: The FastMCP server instance
        transport: Transport type (""stdio"", ""sse"", ""websocket"")
        host: Host to bind to (for network transports)
        port: Port to bind to (for network transports)
    """"""
    if transport == ""stdio"":
        # For stdio transport, run with default settings
        mcp_server.run()
    elif transport == ""sse"":
        # For SSE transport, run with HTTP server
        mcp_server.run(transport=""sse"", host=host, port=port)
    elif transport == ""websocket"":
        # For WebSocket transport
        mcp_server.run(transport=""websocket"", host=host, port=port)
    else:
        raise ValueError(f""Unsupported transport: {transport}. Use 'stdio', 'sse', or 'websocket'"")",src/backend/base/langflow/cli/mcp_server.py,
deleted,"    def integration_graphs_and_metas(self, mock_graph_with_execution):
        """"""Create graphs and metas for integration testing.""""""
        graphs = {
            ""echo_flow"": mock_graph_with_execution,
            ""processing_flow"": mock_graph_with_execution
        }
        
        # Create more realistic metas
        echo_meta = MagicMock()
        echo_meta.title = ""Echo Flow""
        echo_meta.description = ""Echoes the input back""
        
        processing_meta = MagicMock()
        processing_meta.title = ""Processing Flow""
        processing_meta.description = ""Processes input data""
        
        metas = {
            ""echo_flow"": echo_meta,
            ""processing_flow"": processing_meta
        }
        
        return graphs, metas
",src/backend/tests/unit/test_mcp_server.py,TestMCPServerIntegration
survived,"    def sample_graphs_and_metas(self, mock_graph, mock_meta):
        """"""Create sample graphs and metas for testing.""""""
        graphs = {
            ""flow1"": mock_graph,
            ""flow2"": mock_graph
        }
        metas = {
            ""flow1"": mock_meta,
            ""flow2"": mock_meta
        }
        return graphs, metas
",src/backend/tests/unit/test_mcp_server.py,TestMCPServerCreation
deleted,"    def get_flow_schema(flow_id: str) -> str:
        """"""Get the schema (inputs/outputs) for a specific flow.""""""
        if flow_id not in graphs:
            return json.dumps({""error"": f""Flow '{flow_id}' not found""})
        
        graph = graphs[flow_id]
        
        # This could be expanded to provide detailed schema information
        # by analyzing the graph structure
        schema_info = {
            ""flow_id"": flow_id,
            ""inputs"": {
                ""input_value"": {
                    ""type"": ""string"",
                    ""description"": ""Main input value for the flow""
                },
                ""tweaks"": {
                    ""type"": ""object"",
                    ""description"": ""Optional parameter tweaks"",
                    ""optional"": True
                }
            },
            ""outputs"": {
                ""result"": {
                    ""type"": ""any"",
                    ""description"": ""Flow execution result""
                },
                ""execution_time"": {
                    ""type"": ""number"",
                    ""description"": ""Execution time in seconds"",
                    ""optional"": True
                },
                ""error"": {
                    ""type"": ""string"",
                    ""description"": ""Error message if execution failed"",
                    ""optional"": True
                }
            }
        }
        
        return json.dumps(schema_info, indent=2)
",src/backend/base/langflow/cli/mcp_server.py,
survived,"    def test_run_mcp_server_stdio(self, mock_fastmcp):
        """"""Test running MCP server with stdio transport.""""""
        mock_mcp_instance = MagicMock()
        mock_mcp_instance.run = MagicMock()

        run_mcp_server(
            mcp_server=mock_mcp_instance,
            transport=""stdio""
        )

        # Should call run() with no arguments for stdio
        mock_mcp_instance.run.assert_called_once_with()
",src/backend/tests/unit/test_mcp_server.py,TestMCPServerRuntime
deleted,"    def test_moonshot_completion_mock(self, respx_mock):
        """"""
        Mock test for Moonshot completion using the model format from docs.
        This test mocks the actual HTTP request to test the integration properly.
        """"""

        litellm.disable_aiohttp_transport = (
            True  # since this uses respx, we need to set use_aiohttp_transport to False
        )

        # Set up environment variables for the test
        api_key = ""fake-moonshot-key""
        api_base = ""https://api.moonshot.ai/v1""
        model = ""moonshot/moonshot-v1-8k""
        model_name = ""moonshot-v1-8k""  # The actual model name without provider prefix

        # Mock the HTTP request to the moonshot API
        respx_mock.post(f""{api_base}/chat/completions"").respond(
            json={
                ""id"": ""chatcmpl-123"",
                ""object"": ""chat.completion"",
                ""created"": 1677652288,
                ""model"": model_name,
                ""choices"": [
                    {
                        ""index"": 0,
                        ""message"": {
                            ""role"": ""assistant"",
                            ""content"": '```python\nprint(""Hey from LiteLLM!"")\n```\n\nThis simple Python code prints a greeting message from LiteLLM.',
                        },
                        ""finish_reason"": ""stop"",
                    }
                ],
                ""usage"": {
                    ""prompt_tokens"": 9,
                    ""completion_tokens"": 12,
                    ""total_tokens"": 21,
                },
            },
            status_code=200,
        )

        # Make the actual API call through LiteLLM
        response = completion(
            model=model,
            messages=[
                {""role"": ""user"", ""content"": ""write code for saying hey from LiteLLM""}
            ],
            api_key=api_key,
            api_base=api_base,
        )

        # Verify response structure
        assert response is not None
        assert hasattr(response, ""choices"")
        assert len(response.choices) > 0
        assert hasattr(response.choices[0], ""message"")
        assert hasattr(response.choices[0].message, ""content"")
        assert response.choices[0].message.content is not None

        # Check for specific content in the response
        assert ""```python"" in response.choices[0].message.content
        assert ""Hey from LiteLLM"" in response.choices[0].message.content",tests/test_litellm/llms/moonshot/test_moonshot_chat_transformation.py,TestMoonshotConfig
survived,"    async def test_transfer_traces_fails_with_non_existent_trace_id(
        self,
        gql_client: AsyncGraphQLClient,
        trace_transfer_fixture: dict[str, int],
        db: DbSessionFactory,
    ) -> None:
        source_project_id = trace_transfer_fixture[""source_project_id""]
        dest_project_id = trace_transfer_fixture[""dest_project_id""]
        trace1_id = trace_transfer_fixture[""trace1_id""]

        async with db() as session:
            trace = await session.get(models.Trace, trace1_id)
            assert trace is not None
            assert trace.project_rowid == source_project_id

        result = await gql_client.execute(
            self.TRANSFER_TRACES_MUTATION,
            variables={
                ""traceIds"": [
                    str(GlobalID(""Trace"", str(trace1_id))),
                    str(GlobalID(""Trace"", ""99999"")),
                ],
                ""projectId"": str(GlobalID(""Project"", str(dest_project_id))),
            },
        )
        assert result.errors

        async with db() as session:
            trace = await session.get(models.Trace, trace1_id)
            assert trace is not None
            assert trace.project_rowid == source_project_id
",tests/unit/server/api/mutations/test_trace_transfer_mutations.py,TestTraceTransferMutationMixin
survived,"    def test_csharp_edge_cases(self):
        patch = """"""
@@ -152,10 +152,6 @@ public unsafe void* GetPointer()

@@ -152,10 +152,6 @@ public extern static void ExternalMethod();

@@ -152,10 +152,6 @@ [Obsolete(""Use NewMethod instead"")]
public void OldMethod()

@@ -152,10 +152,6 @@ public partial void PartialMethod();

@@ -152,10 +152,6 @@ public virtual async Task<IEnumerable<T>> ComplexMethod<T>()

""""""

        assert CSharpParser.extract_functions_from_patch(patch) == {
            ""GetPointer"",
            ""ExternalMethod"",
            ""OldMethod"",
            ""PartialMethod"",
            ""ComplexMethod"",
        }",tests/sentry/integrations/source_code_management/test_language_parsers.py,CSharpParserTestCase
survived,"def get_patch_parsers_for_organization(organization=None):
    """"""
    Returns the appropriate patch parsers based on feature flags.
    Falls back to the standard parsers if no organization is provided.
    """"""
    if organization and features.has(""organizations:csharp-open-pr-comments"", organization):
        # Merge stable and beta parsers when feature flag is enabled
        return {**PATCH_PARSERS, **BETA_PATCH_PARSERS}
    else:
        # Return only stable parsers when feature flag is disabled or no organization context
        return {k: v for k, v in PATCH_PARSERS.items() if k not in BETA_PATCH_PARSERS}",src/sentry/integrations/source_code_management/language_parsers.py,
survived,"    def test_env_group_rubric_initialization(self, mock_openai_client):
        """"""Test EnvGroupRubric initialization with multiple environments.""""""
        # Create test environments with different rubrics
        def func1(completion, **kwargs):
            return 1.0
        
        def func2(completion, **kwargs):
            return 0.5
        
        def func3(completion, **kwargs):
            return 0.8
        
        env1 = SingleTurnEnv(
            client=mock_openai_client,
            model=""test-model"",
            eval_dataset=Dataset.from_dict({""question"": [""q1""], ""answer"": [""a1""]}),
            rubric=Rubric(funcs=[func1, func2], weights=[1.0, 0.5])
        )
        
        env2 = SingleTurnEnv(
            client=mock_openai_client,
            model=""test-model"",
            eval_dataset=Dataset.from_dict({""question"": [""q2""], ""answer"": [""a2""]}),
            rubric=Rubric(funcs=[func2, func3], weights=[0.7, 1.0])
        )
        
        env_map = {""task1"": env1, ""task2"": env2}
        rubric = EnvGroupRubric(env_map)
        
        assert rubric.env_map == env_map
        # Should have all unique reward function names
        assert set(rubric.all_reward_names) == {""func1"", ""func2"", ""func3""}
",tests/test_env_group.py,TestEnvGroupRubric
survived,"    def test_parse_chat_completion_logprobs(self, mock_openai_client, sample_dataset):
        """"""Test parsing logprobs from a vLLM chat completion.""""""
        env = SimpleEnvironment(
            client=mock_openai_client,
            model=""test-model"",
            dataset=sample_dataset,
            parser=Parser(),
            rubric=Rubric()
        )
        
        # Create mock chat completion with logprobs
        mock_completion = Mock()
        mock_completion.choices = [Mock()]
        mock_completion.choices[0].logprobs = Mock()
        mock_completion.choices[0].logprobs.content = [
            Mock(logprob=-0.5),
            Mock(logprob=-1.2),
            Mock(logprob=-0.3)
        ]
        
        logprobs = env.parse_chat_completion_logprobs(mock_completion)
        assert logprobs == [-0.5, -1.2, -0.3]
",tests/test_environment.py,TestEnvironmentBase
survived,"    def test_process_env_results_chat(self, mock_openai_client, sample_dataset):
        """"""Test processing environment results for chat format.""""""
        env = SimpleEnvironment(
            client=mock_openai_client,
            model=""test-model"",
            dataset=sample_dataset,
            parser=Parser(),
            rubric=Rubric()
        )
        
        # Create a mock tokenizer
        mock_tokenizer = Mock()
        
        # Track the conversation state
        def mock_apply_chat_template(conversation, tokenize=False, add_generation_prompt=True):
            # Convert messages to a string representation
            text = """"
            for msg in conversation:
                text += f""{msg['role']}: {msg['content']} ""
            return text.strip()
        
        def mock_encode(text, **kwargs):
            # Return tokens based on the text content
            if ""assistant: Hi there!"" in text:
                # Prompt + completion: return extended tokens
                return [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
            elif ""user: Hello"" in text:
                # Just prompt: return base tokens
                return [1, 2, 3, 4, 5]
            else:
                # Default case
                return [1, 2, 3]
        
        mock_tokenizer.apply_chat_template = Mock(side_effect=mock_apply_chat_template)
        mock_tokenizer.encode = Mock(side_effect=mock_encode)
        
        prompts = [[{""role"": ""user"", ""content"": ""Hello""}]]
        completions = [[{""role"": ""assistant"", ""content"": ""Hi there!""}]]
        states = [{}]
        rewards = [1.0]
        
        results = env.process_env_results(
            prompts, completions, states, rewards, mock_tokenizer
        )
        
        assert ""prompt_ids"" in results
        assert ""prompt_mask"" in results
        assert ""completion_ids"" in results
        assert ""completion_mask"" in results
        assert ""completion_logprobs"" in results
        assert ""rewards"" in results
        assert len(results[""rewards""]) == 1
        assert results[""rewards""][0] == 1.0
",tests/test_environment.py,TestEnvironmentBase
survived,"    async def test_env_group_rollout_routing(self, mock_openai_client):
        """"""Test that rollout is properly routed to the correct sub-environment.""""""
        # Create environments with different behaviors
        env1 = SingleTurnEnv(
            client=mock_openai_client,
            model=""test-model"",
            dataset=Dataset.from_dict({""question"": [""q1""], ""answer"": [""a1""]}),
            rubric=Rubric()
        )
        
        env2 = SingleTurnEnv(
            client=mock_openai_client,
            model=""test-model"",
            dataset=Dataset.from_dict({""question"": [""q2""], ""answer"": [""a2""]}),
            rubric=Rubric()
        )
        
        # Mock the rollout methods to return different values
        env1.rollout = AsyncMock(return_value=(""response1"", {""env"": ""env1""}))
        env2.rollout = AsyncMock(return_value=(""response2"", {""env"": ""env2""}))
        
        env_group = EnvGroup(envs=[env1, env2], env_names=[""math"", ""code""])
        
        # Test routing to math environment
        result1, state1 = await env_group.rollout(
            client=mock_openai_client,
            model=""test-model"",
            prompt=""Test prompt"",
            task=""math""
        )
        
        assert result1 == ""response1""
        assert state1[""env""] == ""env1""
        env1.rollout.assert_called_once()
        env2.rollout.assert_not_called()
        
        # Reset mocks
        env1.rollout.reset_mock()
        env2.rollout.reset_mock()
        
        # Test routing to code environment
        result2, state2 = await env_group.rollout(
            client=mock_openai_client,
            model=""test-model"",
            prompt=""Test prompt"",
            task=""code""
        )
        
        assert result2 == ""response2""
        assert state2[""env""] == ""env2""
        env1.rollout.assert_not_called()
        env2.rollout.assert_called_once()
",tests/test_env_group.py,TestEnvGroup
survived,"    async def test_singleturn_stops_after_one_response(self, mock_openai_client, sample_dataset):
        """"""Test that SingleTurnEnv truly stops after one response.""""""
        # We'll verify this by checking the is_completed logic
        env = SingleTurnEnv(
            client=mock_openai_client,
            model=""test-model"",
            dataset=sample_dataset
        )
        
        # Before any responses
        state = {""responses"": []}
        assert not env.is_completed([], state)
        
        # After one response
        state = {""responses"": [MagicMock()]}
        assert env.is_completed([], state)
        
        # Even with multiple responses (shouldn't happen), it's still completed
        state = {""responses"": [MagicMock(), MagicMock()]}
        assert env.is_completed([], state)",tests/test_singleturn_env.py,TestSingleTurnEnv
survived,"        def func3(completion, **kwargs):
            return 0.8
",tests/test_env_group.py,TestEnvGroupRubric
survived,"async def main():
    """"""Main entry point""""""
    try:
        await run_sequence_demo()
    except KeyboardInterrupt:
        print(""\n\nDemo interrupted by user"")
        sys.exit(0)
    except Exception as e:
        print(f""\nError: {e}"")
        sys.exit(1)
",examples/python_mcp_chunk_stream.py,
survived,"async def run_sequence_demo():
    """"""Run a demo sequence showing chunk-like streaming""""""
    
    # Define our automation sequence
    sequence = [
        {
            ""tool_name"": ""get_applications"",
            ""arguments"": {}
        },
        {
            ""tool_name"": ""delay"",
            ""arguments"": {""delay_ms"": 1000}
        },
        {
            ""tool_name"": ""capture_screen"",
            ""arguments"": {}
        },
        {
            ""tool_name"": ""get_clipboard"",
            ""arguments"": {}
        },
        {
            ""tool_name"": ""open_application"",
            ""arguments"": {""app_name"": ""notepad""}
        },
        {
            ""tool_name"": ""delay"", 
            ""arguments"": {""delay_ms"": 2000}
        },
        {
            ""tool_name"": ""type_into_element"",
            ""arguments"": {
                ""selector"": ""role:document"",
                ""text_to_type"": ""Hello from chunk streaming demo!""
            }
        }
    ]
    
    # Convert sequence to the format expected by execute_sequence
    items = []
    for tool in sequence:
        items.append({
            ""tool_name"": tool[""tool_name""],
            ""arguments"": tool.get(""arguments"", {}),
            ""continue_on_error"": tool.get(""continue_on_error"", False),
            ""delay_ms"": tool.get(""delay_ms"", 0)
        })
    
    # Connect to MCP server
    server_params = StdioServerParameters(
        command=""terminator-mcp-agent"",
        args=[],
        env=None
    )
    
    async with stdio_client(server_params) as (read, write):
        async with ClientSession(read, write) as session:
            await session.initialize()
            
            print(""Connected to terminator-mcp-agent"")
            print(""\n"" + ""=""*60)
            print(""ENHANCED SEQUENCE EXECUTION WITH DETAILED TRACKING"")
            print(""=""*60)
            
            # Execute the sequence
            print(""\nExecuting sequence..."")
            result = await session.call_tool(
                ""execute_sequence"",
                arguments={
                    ""items"": items,
                    ""stop_on_error"": True,
                    ""include_detailed_results"": True
                }
            )
            
            # Parse the result
            if result.content and len(result.content) > 0:
                data = json.loads(result.content[0].text)
                
                # Display execution plan
                print(""\nðŸ“‹ EXECUTION PLAN:"")
                print(""-"" * 50)
                plan = data.get(""execution_plan"", {})
                print(f""Total steps to execute: {plan.get('total_steps', 0)}"")
                for step in plan.get(""steps"", []):
                    print(f""  Step {step['step']}: {step['tool_name']} - {step['description']}"")
                
                # Display step results as they would appear in a stream
                print(""\nðŸš€ EXECUTING STEPS:"")
                print(""-"" * 50)
                
                step_results = data.get(""step_results"", [])
                for step_result in step_results:
                    print_step_info(step_result)
                    
                    # Show a sample of the result content if available
                    if ""result"" in step_result and ""result"" in step_result[""result""]:
                        result_data = step_result[""result""][""result""]
                        if isinstance(result_data, dict) and ""content"" in result_data:
                            content = result_data[""content""]
                            if isinstance(content, list) and len(content) > 0:
                                # Show truncated content for readability
                                content_str = str(content[0])
                                if len(content_str) > 100:
                                    content_str = content_str[:100] + ""...""
                                print(f""  Result: {content_str}"")
                
                # Display execution summary
                print(""\nðŸ“Š EXECUTION SUMMARY:"")
                print(""-"" * 50)
                summary = data.get(""execution_summary"", {})
                print(f""Total steps planned:    {summary.get('total_steps', 0)}"")
                print(f""Steps executed:         {summary.get('executed_steps', 0)}"")
                print(f""Successful steps:       {summary.get('successful_steps', 0)}"")
                print(f""Failed steps:           {summary.get('failed_steps', 0)}"")
                print(f""Total duration:         {summary.get('total_duration_ms', 0)}ms"")
                print(f""Started at:             {format_timestamp(summary.get('started_at', ''))}"")
                print(f""Completed at:           {format_timestamp(summary.get('completed_at', ''))}"")
                
                # Final status
                print(f""\nðŸ FINAL STATUS: {data.get('status', 'unknown').upper()}"")
                
            else:
                print(""No result received from execute_sequence"")
",examples/python_mcp_chunk_stream.py,
deleted,"    def _log_verbose_output(self, messages: List[Dict[str, str]], output: LLMResult) -> None:
        """"""Log verbose output for debugging.""""""
        # Truncate messages to 500 chars
        messages_str = str(messages)
        truncated_messages = (
            messages_str[:500] + ""...""
            if len(messages_str) > 500
            else messages_str
        )

        # Log with nice formatting
        self.runner.console.print(
            Panel(
                Group(
                    Text(""Input:"", style=""bold cyan""),
                    Text(truncated_messages),
                    Text(""\nOutput:"", style=""bold cyan""),
                    Text(str(output)),
                ),
                title=""[bold green]LLM Call Details[/bold green]"",
                border_style=""green"",
            )
        )",docetl/operations/utils/api.py,APIWrapper
survived,"    async def test_score_rollout_single(self):
        """"""Test scoring a single rollout.""""""
        def func1(completion, answer, **kwargs):
            return 1.0 if completion == answer else 0.0
        
        def func2(completion, **kwargs):
            return len(completion) * 0.1
        
        rubric = Rubric(funcs=[func1, func2], weights=[1.0, 0.5])
        
        result = await rubric.score_rollout(
            prompt=""test prompt"",
            completion=""test"",
            answer=""test"",
            state={},
            task=""test_task"",
            info={}
        )
        
        assert ""func1"" in result
        assert ""func2"" in result
        assert ""reward"" in result
        assert result[""func1""] == 1.0  # completion == answer
        assert result[""func2""] == 0.4  # len(""test"") * 0.1
        assert result[""reward""] == 1.0 * 1.0 + 0.4 * 0.5  # Weighted sum
",tests/test_rubric.py,TestRubric
survived,"    def test_parse_empty_fields(self, xml_parser):
        """"""Test parsing XML with empty fields.""""""
        xml_text = ""<reasoning></reasoning><answer></answer>""
        result = xml_parser.parse(xml_text)
        assert result.reasoning == """"
        assert result.answer == """"
",tests/test_xml_parser.py,TestXMLParser
survived,"            def env_response(self, messages, state, **kwargs):
                # This should never be called due to immediate completion
                return {""role"": ""user"", ""content"": ""Should not appear""}, state
",tests/test_multiturn_env.py,TestMultiTurnEnv.ImmediateCompletionEnv
survived,"    def test_rubric_group_initialization(self):
        """"""Test RubricGroup initialization with multiple rubrics.""""""
        def func1(completion, **kwargs):
            return 1.0
        
        def func2(completion, **kwargs):
            return 0.5
        
        rubric1 = Rubric(funcs=[func1], weights=[1.0])
        rubric2 = Rubric(funcs=[func2], weights=[0.8])
        
        rubrics = [rubric1, rubric2]
        group = RubricGroup(rubrics=rubrics)
        
        assert group.rubrics == rubrics
        assert len(group.rubrics) == 2
",tests/test_rubric_group.py,TestRubricGroup
survived,"    def test_format_reward_function_bad_format(self, think_parser):
        """"""Test format reward function with poorly formatted content.""""""
        reward_func = think_parser.get_format_reward_func()
        
        # Missing think tags
        bad_completion1 = [
            {""role"": ""assistant"", ""content"": ""Just an answer without thinking""}
        ]
        reward1 = reward_func(bad_completion1)
        assert reward1 == 0.0
        
        # Multiple think tags
        bad_completion2 = [
            {""role"": ""assistant"", ""content"": ""<think>First</think><think>Second</think>Answer""}
        ]
        reward2 = reward_func(bad_completion2)
        assert reward2 == 0.0
        
        # No content after think
        bad_completion3 = [
            {""role"": ""assistant"", ""content"": ""<think>Only thinking</think>""}
        ]
        reward3 = reward_func(bad_completion3)
        assert reward3 == 0.0
",tests/test_think_parser.py,TestThinkParser
survived,"    def test_rubric_initialization_empty(self):
        """"""Test Rubric initialization with no parameters.""""""
        rubric = Rubric()
        
        assert rubric.reward_funcs == []
        assert rubric.reward_weights == []
        assert isinstance(rubric.parser, Parser)
",tests/test_rubric.py,TestRubric
survived,"    def test_rubric_initialization_with_functions(self):
        """"""Test Rubric initialization with reward functions.""""""
        def reward_func1(completion, answer, **kwargs):
            return 1.0 if completion == answer else 0.0
        
        def reward_func2(completion, **kwargs):
            return len(completion) * 0.1
        
        funcs = [reward_func1, reward_func2]
        weights = [1.0, 0.5]
        
        rubric = Rubric(funcs=funcs, weights=weights)
        
        assert rubric.reward_funcs == funcs
        assert rubric.reward_weights == weights
        assert len(rubric.get_reward_func_names()) == 2
        assert rubric.get_reward_func_names() == [""reward_func1"", ""reward_func2""]
",tests/test_rubric.py,TestRubric
survived,"        def func2(completion, **kwargs):
            return len(completion) * 0.1
",tests/test_rubric.py,TestRubric
survived,"    def _handle_text_completion(self, prompt, **kwargs):
        """"""Handle text completion requests.""""""
        if prompt in self.text_completions:
            response_data = self.text_completions[prompt]
        else:
            response_data = {
                ""text"": self.default_text_response,
                ""finish_reason"": ""stop""
            }
        
        # Create mock response
        mock_response = MagicMock()
        mock_response.choices = [MagicMock()]
        mock_response.choices[0].text = response_data[""text""]
        mock_response.choices[0].finish_reason = response_data[""finish_reason""]
        return mock_response
",tests/conftest.py,MockAsyncOpenAI
survived,"def sample_chat_dataset():
    """"""Return a sample dataset with chat format.""""""
    return Dataset.from_dict({
        ""prompt"": [
            [{""role"": ""user"", ""content"": ""What is 2+2?""}],
            [{""role"": ""user"", ""content"": ""What is the capital of France?""}]
        ],
        ""answer"": [""4"", ""Paris""]
    })
",tests/conftest.py,
survived,"    async def test_a_generate_basic(self, mock_singleturn_env):
        """"""Test async generation with basic inputs.""""""
        inputs = {
            ""prompt"": [
                [{""role"": ""user"", ""content"": ""What is 2+2?""}],
                [{""role"": ""user"", ""content"": ""What is 3+3?""}]
            ],
            ""answer"": [""4"", ""6""]
        }
        
        # Mock the rubric.score_rollouts method
        mock_singleturn_env.rubric.score_rollouts = AsyncMock(return_value={
            ""rewards"": [1.0, 1.0],
            ""scores"": [{""correctness"": 1.0}, {""correctness"": 1.0}]
        })
        
        results = await mock_singleturn_env.a_generate(inputs)
        
        assert ""completion"" in results
        assert ""state"" in results
        assert ""rewards"" in results
        assert len(results[""completion""]) == 2
        assert len(results[""state""]) == 2
",tests/test_singleturn_env.py,TestSingleTurnEnv
survived,"    def test_xml_parser_initialization(self, xml_parser):
        """"""Test that XMLParser initializes correctly.""""""
        assert isinstance(xml_parser, XMLParser)
        assert xml_parser.answer_field == ""answer""
",tests/test_xml_parser.py,TestXMLParser
survived,"    def test_completion_mode_with_system_prompt_raises_error(self, mock_openai_client, sample_dataset):
        """"""Test that completion mode with system prompt raises error.""""""
        with pytest.raises(ValueError, match=""not supported for completion tasks""):
            TestEnvironment(
                client=mock_openai_client,
                model=""test-model"",
                dataset=sample_dataset,
                message_type=""completion"",
                system_prompt=""test prompt"",
                parser=Parser(),
                rubric=Rubric()
            )
",tests/test_environment.py,TestEnvironmentBase
survived,"def xml_parser_with_alternatives():
    """"""Return an XMLParser instance with alternative field names.""""""
    return XMLParser(
        fields=[""reasoning"", (""code"", ""answer"")],
        answer_field=""answer""
    )
",tests/conftest.py,
survived,"    def setup(self, mock_config):
        """"""Set up transformer for each test.""""""
        self.transformer = PkgxTransformer(mock_config, None)
",tests/package_managers/crates/test_special_case.py,TestSpecialCase
survived,"def package_ids():
    """"""Fixture providing consistent package IDs for testing.""""""
    return {
        ""foo"": uuid4(),
        ""bar"": uuid4(),
        ""baz"": uuid4(),
        ""qux"": uuid4(),
    }
",tests/package_managers/homebrew/test_diff_dep.py,
survived,"def mock_sources():
    """"""
    Mock sources with consistent UUIDs for testing.

    Returns a dict mapping source names to mock Source objects.
    """"""
    return {
        ""github"": Mock(
            spec=Source, id=uuid.UUID(""00000000-0000-0000-0000-000000000020"")
        ),
        ""crates"": Mock(
            spec=Source, id=uuid.UUID(""00000000-0000-0000-0000-000000000021"")
        ),
        ""homebrew"": Mock(
            spec=Source, id=uuid.UUID(""00000000-0000-0000-0000-000000000022"")
        ),
        ""debian"": Mock(
            spec=Source, id=uuid.UUID(""00000000-0000-0000-0000-000000000023"")
        ),
        ""pkgx"": Mock(spec=Source, id=uuid.UUID(""00000000-0000-0000-0000-000000000024"")),
    }
",tests/conftest.py,
survived,"    def test_load_urls(self, mock_config, test_scenarios):
        """"""Test URL loading for different scenarios.""""""
        for scenario_name, scenario in test_scenarios.items():
            # Set up cache for this scenario
            cache = Cache(
                package=Package(
                    id=scenario[""package_id""], import_id=scenario[""import_id""]
                ),
                urls=[
                    URL(
                        url=url,
                        url_type_id=mock_config.db.select_url_types_by_name(
                            url_type
                        ).id,
                    )
                    for url, url_types in scenario[""transformer_urls""]
                    for url_type in url_types
                ],
                dependencies=Dependencies(),
            )

            # Create cache map as expected by loader
            cache_map = {scenario[""import_id""]: cache}

            # Create loader with our test data
            loader = PkgxLoader(mock_config, cache_map)

            # Mock DB state for this scenario
            current_urls_mock = MagicMock()
            current_urls_mock.url_map = scenario[""db_state""][""urls""]
            current_urls_mock.package_urls = scenario[""db_state""][""package_urls""]

            # Mock the get_current_urls method
            mock_config.db.get_current_urls = MagicMock()
            mock_config.db.get_current_urls.return_value = current_urls_mock

            # Mock the session for loader operations
            mock_config.db.session = MagicMock()
            mock_session = MagicMock()
            mock_config.db.session.return_value.__enter__.return_value = mock_session

            # Track calls to verify behavior
            urls_added = []
            package_urls_added = []
            urls_updated = []

            def track_add(obj):
                if hasattr(obj, ""url""):  # It's a URL object
                    urls_added.append(obj)
                else:  # It's a PackageURL object
                    package_urls_added.append(obj)

            def track_bulk_update(mapper, mappings):
                urls_updated.extend(mappings)

            mock_session.add.side_effect = track_add
            mock_session.bulk_update_mappings.side_effect = track_bulk_update

            # Run the loader
            loader.load_urls()

            # Verify expected behavior
            expected = scenario[""expected_behavior""]
            assert (
                len(urls_added) == expected[""new_urls_created""]
            ), f""Scenario {scenario_name}: Expected {expected['new_urls_created']} new URLs, got {len(urls_added)}""  # noqa: E501
            assert (
                len(package_urls_added) == expected[""new_package_urls_created""]
            ), f""Scenario {scenario_name}: Expected {expected['new_package_urls_created']} new PackageURLs, got {len(package_urls_added)}""  # noqa: E501

            # URLs updated is tracked through bulk_update_mappings calls
            if expected[""urls_updated""] > 0:
                assert mock_session.bulk_update_mappings.called, f""Scenario {scenario_name}: Expected bulk_update_mappings to be called""  # noqa: E501
                # Check that the right number of URLs were updated
                total_updated = sum(
                    len(call[0][1])
                    for call in mock_session.bulk_update_mappings.call_args_list
                )
                assert (
                    total_updated == expected[""urls_updated""]
                ), f""Scenario {scenario_name}: Expected {expected['urls_updated']} URLs updated, got {total_updated}""  # noqa: E501",tests/package_managers/pkgx/test_pkgx_load_urls.py,TestPkgxLoader
survived,"def capture_ingest_calls(mock_db):
    """"""Helper function to capture arguments passed to db.ingest.""""""
    ingest_calls = []

    def capture_ingest(new_canons, new_canon_packages, updated_canon_packages):
        ingest_calls.append((new_canons, new_canon_packages, updated_canon_packages))

    mock_db.ingest.side_effect = capture_ingest
    return ingest_calls
",tests/ranker/test_dedupe.py,
survived,"def map_sample_data_with_extra_keys():
    return [
        {
            ""text"": ""This is a positive sentence."",
            ""original_sentiment"": ""positive"",
            ""to_be_dropped"": ""extra"",
        },
        {
            ""text"": ""This is a negative sentence."",
            ""original_sentiment"": ""negative"",
            ""to_be_dropped"": ""extra"",
        },
        {
            ""text"": ""This is a neutral sentence."",
            ""original_sentiment"": ""neutral"",
            ""to_be_dropped"": ""extra"",
        },
    ]
",tests/basic/test_basic_map.py,
survived,"def map_config_with_drop_keys_no_prompt():
    return {
        ""name"": ""drop_keys_only"",
        ""type"": ""map"",
        ""drop_keys"": [""to_be_dropped""],
        ""model"": ""gpt-4o-mini"",
    }
",tests/basic/test_basic_map.py,
survived,"    def test_go_real_world_example(self):
        # Based on a typical Go service with various function types
        patch = """"""
@@ -73,9 +73,7 @@ func NewService(db *sql.DB) *Service

@@ -87,7 +87,8 @@ func (s *Service) GetUser(ctx context.Context, id int) (*User, error)

@@ -95,6 +95,7 @@ func (s *Service) CreateUser(user *User) error

@@ -103,4 +107,23 @@ func validateEmail(email string) bool

@@ -115,6 +118,13 @@ var logger = func(msg string) {

@@ -125,7 +125,7 @@ func (s *Service) updateCache(key string, value interface{})

@@ -135,8 +135,8 @@ handleError := func(err error) {

@@ -145,10 +145,10 @@ func init()

@@ -168,15 +168,15 @@ func main()

""""""

        assert GoParser.extract_functions_from_patch(patch) == {
            ""NewService"",
            ""GetUser"",
            ""CreateUser"",
            ""validateEmail"",
            ""logger"",
            ""updateCache"",
            ""handleError"",
            ""init"",
            ""main"",
        }
",tests/sentry/integrations/source_code_management/test_language_parsers.py,GoParserTestCase
survived,"    def smtp_provider(self, context_manager, smtp_config):
        """"""Create an SMTP provider instance.""""""
        return SmtpProvider(
            context_manager=context_manager,
            provider_id=""test_smtp_provider"",
            config=smtp_config,
        )
",tests/test_smtp_provider.py,TestSmtpProvider
survived,"def test_numpy_arrays():
    import numpy as np

    serializer = EventSerializer()

    # Test 1D array
    arr_1d = np.array([1, 2, 3])
    assert json.loads(serializer.encode(arr_1d)) == [1, 2, 3]

    # Test 2D array
    arr_2d = np.array([[1, 2], [3, 4]])
    assert json.loads(serializer.encode(arr_2d)) == [[1, 2], [3, 4]]

    # Test float array
    arr_float = np.array([1.1, 2.2, 3.3])
    assert json.loads(serializer.encode(arr_float)) == [1.1, 2.2, 3.3]

    # Test empty array
    arr_empty = np.array([])
    assert json.loads(serializer.encode(arr_empty)) == []

    # Test mixed types that numpy can handle
    arr_mixed = np.array([1, 2.5, 3])
    assert json.loads(serializer.encode(arr_mixed)) == [1.0, 2.5, 3.0]",tests/test_serializer.py,
survived,"def workflow_share_delete(
        share_id: int,
        _: schemas.TokenPayload = Depends(get_current_active_user)) -> Any:
    """"""
    åˆ é™¤åˆ†äº«
    """"""
    state, errmsg = WorkflowHelper().share_delete(share_id=share_id)
    return schemas.Response(success=state, message=errmsg)
",app/api/endpoints/workflow.py,
survived,"def workflow_shares(
        name: Optional[str] = None,
        page: Optional[int] = 1,
        count: Optional[int] = 30,
        _: schemas.TokenPayload = Depends(get_current_active_user)) -> Any:
    """"""
    æŸ¥è¯¢åˆ†äº«çš„å·¥ä½œæµ
    """"""
    return WorkflowHelper().get_shares(name=name, page=page, count=count)
",app/api/endpoints/workflow.py,
survived,"    def __init__(self):
        self.base_url = ""https://api.dexscreener.com/latest/dex""
",python/src/plugins/dexscreener/goat_plugins/dexscreener/service.py,DexscreenerService
survived,"    async def get_token_pairs_by_token_address(self, parameters: dict):
        addresses = "","".join(parameters[""tokenAddresses""])
        url = f""{self.base_url}/tokens/{addresses}""
        return await self._fetch(url, ""get token pairs"")",python/src/plugins/dexscreener/goat_plugins/dexscreener/service.py,DexscreenerService
survived,"    async def get_cast(self, parameters: dict):
        url = f""{self.base_url}/cast?identifier={parameters['identifier']}&type={parameters['type']}""
        return await self._make_request(""GET"", url)
",python/src/plugins/farcaster/goat_plugins/farcaster/service.py,FarcasterService
deleted,"def plot_stock_comparison(tickers: list[str], days: int = 30) -> str:
    end_date = datetime.today()
    start_date = end_date - timedelta(days=days)
    
    plt.figure(figsize=(12, 6))
    for ticker in tickers:
        data = yf.download(ticker, start=start_date, end=end_date)
        normalized_price = data['Close'] / data['Close'].iloc[0] * 100
        plt.plot(data.index, normalized_price, label=ticker)
    
    plt.title('Stock Price Performance Comparison')
    plt.xlabel('Date')
    plt.ylabel('Normalized Price (%)')
    plt.legend()
    plt.grid(True)
    
    filename = 'stock_comparison.png'
    plt.savefig(filename)
    plt.close()
    return filename
",financial_analysis/functions.py,
deleted,"def analyze_market_data(ticker: str, days: int = 30) -> dict:
    data = yf.download(ticker, start=datetime.today()-timedelta(days=days), end=datetime.today())
    return {
        'avg_volume': data['Volume'].mean(),
        'volatility': data['Close'].pct_change().std() * 100,
        'high': data['High'].max(),
        'low': data['Low'].min(),
        'trading_days': len(data)
    }",financial_analysis/functions.py,
deleted,"    def category(self) -> CheckCategory:
        return CheckCategory.METADATA
",airbyte-ci/connectors/connectors_qa/src/connectors_qa/checks/version.py,VersionCheck
survived,"def run_final_polars_code(reasoning: str, csv_path: str, polars_python_code: str, output_file: Optional[str] = None) -> str:
    """"""Executes the final Polars code and returns results to user.

    This is the last tool call the agent should make after validating the code.
    The code should be fully tested and ready for production use.
    Results will be displayed to the user and optionally saved to a file.

    Args:
        reasoning: Final explanation of how this code satisfies user request
        csv_path: Path to the CSV file
        polars_python_code: The validated Polars Python code to run. Should use pl.scan_csv() for lazy evaluation.
        output_file: Optional path to save results to. Use .csv or .json extension.

    Returns:
        Code execution results as a string

    Example:
        result = run_final_polars_code(
            ""Calculating average user age"",
            ""data.csv"",
            '''
            # Calculate average age using lazy evaluation
            result = df.select(pl.col(""age"").mean().alias(""avg_age"")).collect()
            print(""Average age:"", float(result[0, ""avg_age""]))
            ''',
            ""results.csv""
        )
    """"""
    try:
        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
            # Ensure code is properly indented
            indented_code = ""\n"".join(""    "" + line if line.strip() else line 
                                    for line in polars_python_code.splitlines())
            
            script = '''import polars as pl
import sys

try:
    # Read the CSV file using lazy evaluation
    df = pl.scan_csv(""{csv_path}"")
    
    # Execute the user's code
{code}
    
    # If no result was explicitly printed, try to collect and display
    if 'result' not in locals():
        if any(var for var in locals().values() if isinstance(var, (pl.LazyFrame, pl.DataFrame))):
            result = next(var for var in reversed(list(locals().values())) 
                      if isinstance(var, (pl.LazyFrame, pl.DataFrame)))
            if isinstance(result, pl.LazyFrame):
                result = result.collect()
        else:
            result = df.collect()
    
    # Handle output file if specified
    output_file = {output_file}
    if output_file:
        if isinstance(result, pl.DataFrame):
            if output_file.endswith('.csv'):
                result.write_csv(output_file)
            elif output_file.endswith('.json'):
                result.write_json(output_file)
            else:
                result.write_csv(output_file + '.csv')  # Default to CSV
        else:
            # For non-DataFrame results, create a single column DataFrame
            pl.DataFrame({{""result"": [str(result)]}}).write_csv(output_file)
        print(""Results written to "" + str(output_file))
    
    # Convert result to string for display
    if isinstance(result, pl.DataFrame):
        print(result.select(pl.all()).write_csv(None))
    else:
        print(str(result))
except Exception as e:
    print(""Error: "" + str(e), file=sys.stderr)
    sys.exit(1)
'''
            script_content = script.format(
                csv_path=csv_path,
                code=indented_code,
                output_file=repr(output_file) if output_file else 'None'
            )
            f.write(script_content)
            temp_file = f.name
            temp_file = f.name

        result = subprocess.run(['uv', 'run', '--with', 'polars', temp_file],
                              capture_output=True, text=True)
        os.unlink(temp_file)

        if result.returncode != 0:
            return f""Error: {result.stderr}""

        console.log(
            Panel(
                f""[green]Final Code Tool[/green]\nReasoning: {reasoning}\nCode:\n{polars_python_code}""
            )
        )
        return result.stdout
    except Exception as e:
        console.log(f""[red]Error running final code: {str(e)}[/red]"")
        return str(e)
",sfa_polars_csv_agent_openai_v2.py,
deleted,"def test_scrape_url_with_parse_pdf_false():
    if TEST_API_KEY:
        app = FirecrawlApp(api_url=API_URL, api_key=TEST_API_KEY)
        response = app.scrape_url('https://arxiv.org/pdf/astro-ph/9301001.pdf', parse_pdf=False)
        assert response is not None
        assert 'markdown' in response
        assert 'h7uKu14adDL6yGfnGf2qycY5uq8kC3OKCWkPxm' in response['markdown']
",apps/python-sdk/firecrawl/__tests__/v1/e2e_withAuth/test.py,
survived,"def recognize_from_video():
    env_id = args.env_id
    net = ailia.Net(MODEL_PATH_6DRepNet360, WEIGHT_PATH_6DRepNet360, env_id=env_id)
    face_detect = ailia.Net(MODEL_PATH_FACE, WEIGHT_PATH_FACE, env_id=env_id)
    detector = RetinaFaceOnnx(face_detect)

    capture = webcamera_utils.get_capture(args.video)

    if args.savepath != SAVE_IMAGE_PATH:
        logger.warning(
            'currently, video results cannot be output correctly...'
        )
        f_h = int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT))
        f_w = int(capture.get(cv2.CAP_PROP_FRAME_WIDTH))
        save_h, save_w = f_h, f_w
        writer = webcamera_utils.get_writer(args.savepath, save_h, save_w)
    else:
        writer = None

    frame_shown = False
    while (True):
        ret, frame = capture.read()
        if (cv2.waitKey(1) & 0xFF == ord('q')) or not ret:
            break
        if frame_shown and cv2.getWindowProperty('frame', cv2.WND_PROP_VISIBLE) == 0:
            break

        frame = cv2.resize(frame, dsize=(640, 480))
        faces = detector(frame)
        for box, landmarks, score in faces:
            if score < .95:
                continue
            x_min = int(box[0])
            y_min = int(box[1])
            x_max = int(box[2])
            y_max = int(box[3])
            bbox_width = abs(x_max - x_min)
            bbox_height = abs(y_max - y_min)

            x_min = max(0, x_min - int(0.2 * bbox_height))
            y_min = max(0, y_min - int(0.2 * bbox_width))
            x_max = x_max + int(0.2 * bbox_height)
            y_max = y_max + int(0.2 * bbox_width)

            img = frame[y_min:y_max, x_min:x_max]
            img = cv2.resize(img, dsize=(HEIGHT, WIDTH))
            img = utils.transform(img, MEAN, STD)

            img = np.expand_dims(img, 0)
            img = np.array(img, dtype='float32')

            c = cv2.waitKey(1)
            if c == 27:
                break

            start = time.time()

            R_pred = net.run(img)[0]
            end = time.time()
            print('Head pose estimation: %2f ms' % ((end - start) * 1000.))

            euler = utils.compute_euler_angles_from_rotation_matrices(R_pred) * 180 / np.pi
            p_pred_deg = euler[:, 0]
            y_pred_deg = euler[:, 1]
            r_pred_deg = euler[:, 2]

            utils.plot_pose_cube(frame, y_pred_deg, p_pred_deg, r_pred_deg, x_min + int(.5 * (
                    x_max - x_min)), y_min + int(.5 * (y_max - y_min)), size=bbox_width)

        cv2.imshow(""Demo"", frame)
        cv2.waitKey(5)

        if writer is not None:
            writer.write(frame)

    capture.release()
    cv2.destroyAllWindows()
    if writer is not None:
        writer.release()
    logger.info('Script finished successfully.')
",face_recognition/6d_repnet_360/6d_repnet_360.py,
survived,"def get_pose_params_from_mat(mat_path):
    mat = sio.loadmat(mat_path)
    pre_pose_params = mat['Pose_Para'][0]
    pose_params = pre_pose_params[:5]
    return pose_params
",face_recognition/6d_repnet_360/utils_6d_repnet_360/utils.py,
survived,"def compute_rotation_matrix_from_ortho6d(poses, use_gpu=False):
    x_raw = poses[:, 0:3]
    y_raw = poses[:, 3:6]

    x = normalize_vector(x_raw, use_gpu)
    z = cross_product(x, y_raw)
    z = normalize_vector(z, use_gpu)
    y = cross_product(z, x)

    x = x.view(-1, 3, 1)
    y = y.view(-1, 3, 1)
    z = z.view(-1, 3, 1)
    matrix = torch.cat((x, y, z), 2)
    return matrix
",face_recognition/6d_repnet_360/utils_6d_repnet_360/utils.py,
survived,"def download_model():
    import urllib.request
    model_url = ""https://cloud.ovgu.de/s/TewGC9TDLGgKkmS/download/6DRepNet360_Full-Rotation_300W_LP+Panoptic.pth""
    model_path = ""6DRepNet360_Full-Rotation_300W_LP+Panoptic.pth""
    
    if not os.path.exists(model_path):
        print(f""Downloading model from {model_url}"")
        urllib.request.urlretrieve(model_url, model_path)
        print(f""Model downloaded to {model_path}"")
    else:
        print(f""Model already exists at {model_path}"")
    
    return model_path
",face_recognition/6d_repnet_360/convert_to_onnx.py,
survived,"    async def run_async_tests():
        await async_no_stream()
        await async_stream()
",tests/core_manual_tests/providers/mistral_canary.py,
survived,"    async def async_no_stream():
        await async_chat_client.create(
            model=""jamba-instruct"",
            system=""You are a helpful AI assistant"",
            messages=async_messages,
            maxTokens=10
        )
",tests/core_manual_tests/providers/ai21_canary.py,
deleted,"            async def handle_coroutine():
                result = await response
                # Create a new LLM event for async response
                async_event = LLMEvent(init_timestamp=init_timestamp, params=kwargs)
                if session is not None:
                    async_event.session_id = session.session_id
                    async_event.agent_id = check_call_stack_for_agent_id()
                    async_event.model = kwargs.get(""model"", ""command-r-plus"")
                    async_event.prompt = kwargs.get(""message"", """")
                    async_event.returns = result
                    logger.info(f""Created new async LLM event with session_id: {session.session_id}"")
                if hasattr(result, ""text""):
                    async_event.completion = {
                        ""role"": ""assistant"",
                        ""content"": result.text
                    }
                    logger.info(f""Set completion for async LLM event: {result.text}"")
                elif hasattr(result, ""chat_history""):
                    async_event.prompt = []
                    role_map = {""USER"": ""user"", ""CHATBOT"": ""assistant"", ""SYSTEM"": ""system""}
                    for i in range(len(result.chat_history) - 1):
                        message = result.chat_history[i]
                        async_event.prompt.append({
                            ""role"": role_map.get(message.role, message.role),
                            ""content"": message.message,
                        })
                    last_message = result.chat_history[-1]
                    async_event.completion = {
                        ""role"": role_map.get(last_message.role, last_message.role),
                        ""content"": last_message.message,
                    }
                    async_event.prompt_tokens = int(result.meta.tokens.input_tokens)
                    async_event.completion_tokens = int(result.meta.tokens.output_tokens)
                    logger.info(f""Set chat history for async LLM event"")
                self._safe_record(session, async_event)
                return result
",agentops/llms/providers/cohere.py,CohereProvider
survived,"    def sync_stream():
        stream_response = anthropic_client.messages.create(
            max_tokens=1024,
            model=""claude-3-5-sonnet-20240620"",
            messages=[
                {
                    ""role"": ""user"",
                    ""content"": ""Hello from sync streaming"",
                }
            ],
            stream=True,
            session=session
        )
        for _ in stream_response:
            pass
",tests/core_manual_tests/providers/anthropic_canary.py,
survived,"    def sync_no_stream():
        chat_client.create(
            model=""jamba-instruct"",
            system=""You are a helpful AI assistant"",
            messages=sync_messages,
            maxTokens=10
        )
",tests/core_manual_tests/providers/ai21_canary.py,
survived,"    async def async_no_stream():
        await async_groq_client.chat.completions.create(
            model=""llama3-70b-8192"",
            messages=[
                {""role"": ""user"", ""content"": ""Hello from async no stream""},
            ],
            session=session
        )
",tests/core_manual_tests/providers/groq_canary.py,
survived,"def setup_dataset_root(temp_dir):
  """"""Set up the dataset root directory structure.""""""
  root_dir = os.path.join(temp_dir, ""dataset_root"")
  raw_dir = os.path.join(root_dir, ""Raw"")
  parsed_dir = os.path.join(root_dir, ""Parsed"")

  os.makedirs(raw_dir, exist_ok=True)
  os.makedirs(parsed_dir, exist_ok=True)

  return root_dir, raw_dir, parsed_dir
",tests/dataset_creation_test.py,
survived,"def main(_):
  """"""Main function to run the tests.""""""
  print(""Running single-threaded test..."")
  single_thread_data = test_dataset_creation(threads=1)

  print(""\nRunning parallel test..."")
  parallel_data = test_parallel_dataset_creation()

  assert len(single_thread_data) == len(parallel_data), (
    f""Single-threaded ({len(single_thread_data)} entries) and ""
    f""parallel ({len(parallel_data)} entries) results differ""
  )

  print(""\nAll tests passed!"")
  return 0
",tests/dataset_creation_test.py,
survived,"def main():
    # Set up argument parser
    parser = argparse.ArgumentParser(description=""Codebase Context Agent using Claude 3.7"")
    parser.add_argument(""-p"", ""--prompt"", required=True, help=""The user's request"")
    parser.add_argument(""-d"", ""--directory"", default=os.getcwd(), help=""Directory to search in (defaults to current working directory)"")
    parser.add_argument(""-g"", ""--globs"", nargs=""*"", default=[], help=""List of glob patterns to filter files (optional)"")
    parser.add_argument(""-e"", ""--extensions"", nargs=""*"", default=[], help=""List of file extensions to filter files (optional)"")
    parser.add_argument(""-q"", ""--quiet"", action=""store_true"", help=""Quiet mode (don't show logging)"")
    parser.add_argument(""-l"", ""--limit"", type=int, default=100, help=""Maximum number of files to return"")
    parser.add_argument(""-f"", ""--file-line-limit"", type=int, default=500, help=""Maximum number of lines per file"")
    parser.add_argument(""-c"", ""--compute"", type=int, default=10, help=""Maximum number of agent loops (default: 10)"")
    args = parser.parse_args()

    # Configure the API key
    ANTHROPIC_API_KEY = os.getenv(""ANTHROPIC_API_KEY"")
    if not ANTHROPIC_API_KEY:
        console.print(
            ""[red]Error: ANTHROPIC_API_KEY environment variable is not set[/red]""
        )
        console.print(
            ""Please get your API key from https://console.anthropic.com/settings/keys""
        )
        console.print(""Then set it with: export ANTHROPIC_API_KEY='your-api-key-here'"")
        sys.exit(1)

    client = Anthropic(api_key=ANTHROPIC_API_KEY)

    # Set global USER_PROMPT
    global USER_PROMPT
    USER_PROMPT = args.prompt

    # Configure quiet mode
    if args.quiet:
        console.quiet = True

    # Create a single combined prompt based on the full template
    completed_prompt = (
        AGENT_PROMPT.replace(""{{user_request}}"", args.prompt)
        .replace(""{{directory}}"", args.directory)
        .replace(""{{globs}}"", str(args.globs))
        .replace(""{{extensions}}"", str(args.extensions))
        .replace(""{{file_line_limit}}"", str(args.file_line_limit))
        .replace(""{{limit}}"", str(args.limit))
    )
    
    # Initialize messages with proper typing for Anthropic chat
    messages = [{""role"": ""user"", ""content"": completed_prompt}]

    compute_iterations = 0
    break_loop = False
    # Main agent loop
    while True:
        if break_loop or compute_iterations >= args.compute or len(RELEVANT_FILES) >= args.limit:
            break

        console.rule(
            f""[yellow]Agent Loop {compute_iterations+1}/{args.compute}[/yellow]""
        )
        compute_iterations += 1

        try:
            # Generate content with tool support
            response = client.messages.create(
                model=""claude-3-7-sonnet-20250219"",
                system=""You are a codebase context builder. Use the available tools to search, filter and determine which files in the codebase are relevant to the prompt (user query)."",
                messages=messages,
                tools=TOOLS,
                max_tokens=4000,
                thinking={
                    ""type"": ""enabled"",
                    ""budget_tokens"": 2000
                },
            )

            # Extract thinking block and other content
            thinking_block = None
            tool_use_block = None
            text_block = None
            
            if response.content:
                # Get the message content
                for content_block in response.content:
                    if content_block.type == ""thinking"":
                        thinking_block = content_block
                        previous_thinking = thinking_block
                    elif content_block.type == ""tool_use"":
                        tool_use_block = content_block
                        # Access the proper attributes directly
                        tool_name = content_block.name
                        tool_input = content_block.input
                        tool_id = content_block.id
                    elif content_block.type == ""text"":
                        text_block = content_block
                        console.print(f""[cyan]Model response:[/cyan] {content_block.text}"")
                
                # Handle text responses if there was no tool use
                if not tool_use_block and text_block:
                    messages.append({
                        ""role"": ""assistant"", 
                        ""content"": [
                            *([thinking_block] if thinking_block else []), 
                            {""type"": ""text"", ""text"": text_block.text}
                        ]
                    })
                    break_loop = True
                    continue
                
                # We need a tool use block to proceed
                if tool_use_block:
                    console.print(
                        f""[blue]Tool Call:[/blue] {tool_name}({json.dumps(tool_input, indent=2)})""
                    )

                    try:
                        # Execute the appropriate tool based on name
                        if tool_name == ""git_list_files"":
                            directory = tool_input.get(""directory"", args.directory)
                            globs = tool_input.get(""globs"", args.globs)
                            extensions = tool_input.get(""extensions"", args.extensions)
                            result = git_list_files(
                                reasoning=tool_input[""reasoning""],
                                directory=directory,
                                globs=globs,
                                extensions=extensions,
                            )
                        elif tool_name == ""check_file_paths_line_length"":
                            result = check_file_paths_line_length(
                                reasoning=tool_input[""reasoning""],
                                file_paths=tool_input[""file_paths""],
                                file_line_limit=args.file_line_limit,
                            )
                        elif tool_name == ""determine_if_files_are_relevant"":
                            result = determine_if_files_are_relevant(
                                reasoning=tool_input[""reasoning""],
                                file_paths=tool_input[""file_paths""],
                            )
                        elif tool_name == ""add_relevant_files"":
                            result = add_relevant_files(
                                reasoning=tool_input[""reasoning""],
                                file_paths=tool_input[""file_paths""],
                            )
                            # Check if we've reached the limit
                            if len(RELEVANT_FILES) >= args.limit:
                                console.print(f""[green]Reached file limit of {args.limit}. Stopping.[/green]"")
                                break_loop = True
                        else:
                            raise Exception(f""Unknown tool call: {tool_name}"")

                        console.print(
                            f""[blue]Tool Call Result:[/blue] {tool_name}(...)""
                        )

                        # Append the tool result to messages
                        messages.append(
                            {
                                ""role"": ""assistant"",
                                ""content"": [
                                    *([thinking_block] if thinking_block else []),
                                    {
                                        ""type"": ""tool_use"",
                                        ""id"": tool_id,
                                        ""name"": tool_name,
                                        ""input"": tool_input
                                    }
                                ]
                            }
                        )

                        messages.append(
                            {
                                ""role"": ""user"",
                                ""content"": [
                                    {
                                        ""type"": ""tool_result"",
                                        ""tool_use_id"": tool_id,
                                        ""content"": json.dumps(result)
                                    }
                                ]
                            }
                        )

                    except Exception as e:
                        error_msg = f""Error executing {tool_name}: {e}""
                        console.print(f""[red]{error_msg}[/red]"")

                        # Append the error to messages
                        messages.append(
                            {
                                ""role"": ""assistant"",
                                ""content"": [
                                    *([thinking_block] if thinking_block else []),
                                    {
                                        ""type"": ""tool_use"",
                                        ""id"": tool_id,
                                        ""name"": tool_name,
                                        ""input"": tool_input
                                    }
                                ]
                            }
                        )

                        messages.append(
                            {
                                ""role"": ""user"",
                                ""content"": [
                                    {
                                        ""type"": ""tool_result"",
                                        ""tool_use_id"": tool_id,
                                        ""content"": str(error_msg)
                                    }
                                ]
                            }
                        )

        except Exception as e:
            console.print(f""[red]Error in agent loop: {str(e)}[/red]"")
            raise e

    # Print the final list of relevant files
    console.rule(""[green]Relevant Files[/green]"")
    for i, file_path in enumerate(RELEVANT_FILES, 1):
        console.print(f""{i}. {file_path}"")
",sfa_codebase_context_agent_v3.py,
survived,"        def patched_function(*args, **kwargs):
            init_timestamp = get_ISO_time()
            session = kwargs.pop(""session"", None) if ""session"" in kwargs else None
            
            # Handle positional content argument
            if args:
                kwargs[""contents""] = args[0]
                args = args[1:]  # Remove content from args
            
            # Ensure we have the original method
            if self.original_generate is None:
                logger.error(""Original generate_content method not found. Cannot proceed with override."")
                return None
            
            # Call original method and track event
            result = self.original_generate(*args, **kwargs)
            return self.handle_response(result, kwargs, init_timestamp, session=session)
",agentops/llms/providers/gemini.py,GeminiProvider
survived,"    def supports_chain(self, chain) -> bool:
        return chain['type'] == 'solana'
",python/src/plugins/jupiter/goat_plugins/jupiter/__init__.py,JupiterPlugin
survived,"def spl_token(options: SplTokenPluginOptions) -> SplTokenPlugin:
    return SplTokenPlugin(options)",python/src/plugins/spl_token/goat_plugins/spl_token/__init__.py,
survived,"    async def _cleanup(self) -> StepResult:
        if self.backup_schema_path:
            shutil.rmtree(self.backup_schema_path)
        return StepResult(
            step=self,
            status=StepStatus.SUCCESS,
        )
",airbyte-ci/connectors/pipelines/pipelines/airbyte_ci/connectors/migrate_to_inline_schemas/pipeline.py,RestoreInlineState
survived,"    async def _run(self) -> StepResult:
        connector = self.context.connector
        connector_path = connector.code_directory
        manifest_path = connector.manifest_path
        python_path = connector.python_source_dir_path
        logger = self.logger

        json_streams = _parse_json_streams(python_path)
        if len(json_streams) == 0:
            return StepResult(step=self, status=StepStatus.SKIPPED, stderr=""No JSON streams found."")

        data = read_yaml(manifest_path)
        if ""streams"" not in data:
            return StepResult(
                step=self,
                status=StepStatus.SKIPPED,
                stderr=""No manifest streams found."",
            )

        # find the explit ones and remove or udpate
        json_loaders = _find_json_loaders(data, [])
        for loader in json_loaders:
            logger.info(f""     JSON loader ref: {loader.ref} -> {loader.file_path}"")

        _update_json_loaders(connector_path, data, json_streams, json_loaders)

        # go through the declared streams and update the inline schemas
        for stream in data[""streams""]:
            if isinstance(stream, str):
                # see if reference
                if stream.startswith(""#""):
                    yaml_stream = _load_reference(data, stream)
                    if not yaml_stream:
                        logger.info(f""    Stream reference not found: {stream}"")
                        continue
                    if not _get_stream_name(yaml_stream):
                        logger.info(f""    Stream reference name not found: {stream}"")
                        continue
                else:
                    logger.info(f""    Stream reference unknown: {stream}"")
                    continue
            else:
                yaml_stream = stream

            if not yaml_stream:
                logger.info(f""    !! Yaml stream not found: {stream}"")
                continue

            stream_name = _get_stream_name(yaml_stream)
            if not stream_name:
                logger.info(f""    !! Stream name not found: {stream}"")
                continue
            if yaml_stream.get(""schema_loader"") and yaml_stream[""schema_loader""].get(""type"") == ""InlineSchemaLoader"":
                continue

            yaml_stream[""schema_loader""] = {}
            schema_loader = yaml_stream[""schema_loader""]
            _update_inline_schema(schema_loader, json_streams, stream_name)

        write_yaml(data, manifest_path)
        # await format_prettier([manifest_path], logger=logger)

        for json_stream in json_streams.values():
            logger.info(f""     !! JSON schema not found: {json_stream.name}"")

        return StepResult(step=self, status=StepStatus.SUCCESS)
",airbyte-ci/connectors/pipelines/pipelines/airbyte_ci/connectors/migrate_to_inline_schemas/pipeline.py,InlineSchemas
survived,"    def get_all_env_vars(cls) -> List[Tuple[str, Any]]:
        """"""Get all environment variables from the environment class.
        
        Returns:
            A list of tuples containing the environment variable name and its EnvVar instance.
        """"""
        env_vars = []
        for name, attr in inspect.getmembers(EnvironmentVariables):
            if name.startswith('_') or not hasattr(attr, 'name'):
                continue
            env_vars.append((name, attr))
        return env_vars
",pcweb/pages/docs/env_vars.py,EnvVarDocs
survived,"def env_vars_page():
    """"""Generate the environment variables documentation page.
    
    Returns:
        A Reflex component containing the documentation.
    """"""
    return rx.box(
        h1_comp(text=""Environment Variables""),
        rx.code(""reflex.config.EnvironmentVariables"", class_name=""code-style text-[18px]""),
        rx.divider(),
        markdown(
            """"""
            Reflex provides a number of environment variables that can be used to configure the behavior of your application.
            These environment variables can be set in your shell environment or in a `.env` file.
            
            This page documents all available environment variables in Reflex.
            """"""
        ),
        h2_comp(text=""Environment Variables""),
        EnvVarDocs.generate_env_var_table(include_internal=False),
    )
",pcweb/pages/docs/env_vars.py,
survived,"    def get_env_var_docstring(cls, name: str) -> Optional[str]:
        """"""Get the docstring for an environment variable.
        
        Args:
            name: The name of the environment variable.
            
        Returns:
            The docstring for the environment variable, or None if not found.
        """"""
        source_code = inspect.getsource(EnvironmentVariables)
        lines = source_code.splitlines()
        
        for i, line in enumerate(lines):
            if f""{name}:"" in line and ""EnvVar"" in line:
                j = i - 1
                comments = []
                while j >= 0 and lines[j].strip().startswith('#'):
                    comments.insert(0, lines[j].strip()[1:].strip())
                    j -= 1
                if comments:
                    return ""\n"".join(comments)
        return None
",pcweb/pages/docs/env_vars.py,EnvVarDocs
survived,"    def pause_live_updates(self) -> None:
        """"""Pause Live session updates to allow for human input without interference.""""""
        if not self._live_paused:
            if self._live:
                self._live.stop()
                self._live = None
            self._live_paused = True
",src/crewai/utilities/events/utils/console_formatter.py,ConsoleFormatter
survived,"    def resume_live_updates(self) -> None:
        """"""Resume Live session updates after human input is complete.""""""
        if self._live_paused:
            self._live_paused = False
",src/crewai/utilities/events/utils/console_formatter.py,ConsoleFormatter
survived,"    def test_training_mode_human_input(self):
        """"""Test human input in training mode.""""""
        from crewai.agents.agent_builder.base_agent_executor_mixin import CrewAgentExecutorMixin
        
        executor = CrewAgentExecutorMixin()
        executor.crew = MagicMock()
        executor.crew._train = True
        executor._printer = MagicMock()
        
        formatter = event_listener.formatter
        
        original_paused_state = formatter._live_paused
        
        try:
            with patch.object(formatter, 'pause_live_updates') as mock_pause, \
                 patch.object(formatter, 'resume_live_updates') as mock_resume, \
                 patch('builtins.input', return_value='training feedback'):
                
                result = executor._ask_human_input(""Test result"")
                
                mock_pause.assert_called_once()
                mock_resume.assert_called_once()
                assert result == 'training feedback'
                
                executor._printer.print.assert_called()
                call_args = [call[1]['content'] for call in executor._printer.print.call_args_list]
                training_prompt_found = any('TRAINING MODE' in content for content in call_args)
                assert training_prompt_found
        finally:
            formatter._live_paused = original_paused_state",tests/test_flow_human_input_integration.py,TestFlowHumanInputIntegration
survived,"            def track_resume():
                resume_calls.append(True)
",tests/test_flow_human_input_integration.py,TestFlowHumanInputIntegration
survived,"def existing_file() -> Generator[str, None, None]:
    """"""Create a temporary file that already exists.""""""
    with tempfile.NamedTemporaryFile(delete=False, suffix="".txt"") as f:
        f.write(b""existing content"")
        path = f.name
    
    try:
        yield path
    finally:
        if os.path.exists(path):
            os.unlink(path)
",tests/_cli/test_file_overwrite.py,
survived,"def test_export_overwrite_with_yes_flag() -> None:
    """"""Test export command with -y flag to automatically overwrite files.""""""
    # Create a temporary directory and file
    with tempfile.TemporaryDirectory() as tmp_dir:
        # Create a simple marimo file
        marimo_file = Path(tmp_dir) / ""test.py""
        marimo_file.write_text(""""""
import marimo
app = marimo.App()

@app.cell
def __():
    print(""Hello, World!"")
    return

if __name__ == ""__main__"":
    app.run()
"""""")
        
        # Create an existing output file
        output_file = Path(tmp_dir) / ""output.html""
        output_file.write_text(""initial content"")
        
        # Use the -y flag to verify that the file can be overwritten without prompting
        result = subprocess.run(
            [
                ""marimo"",
                ""-y"",
                ""export"",
                ""html"",
                str(marimo_file),
                ""--output"",
                str(output_file),
            ],
            capture_output=True,
            text=True,
        )
        
        # Check that the command completed successfully
        assert result.returncode == 0
        
        # Verify the file was overwritten with -y flag
        assert output_file.read_text() != ""initial content""
        
        # Verify there was no prompt in the output
        assert ""Warning: The file"" not in result.stdout
        assert ""Overwrite?"" not in result.stdout
",tests/_cli/test_file_overwrite.py,
survived,"    def fingerprint(self) -> Fingerprint:
        """"""
        Get the crew's fingerprint.

        Returns:
            Fingerprint: The crew's fingerprint
        """"""
        return self.security_config.fingerprint
",src/crewai/crew.py,Crew
survived,"    def validate_fingerprint(cls, values):
        """"""Ensure fingerprint is properly initialized.""""""
        if isinstance(values, dict):
            # Handle case where fingerprint is not provided or is None
            if 'fingerprint' not in values or values['fingerprint'] is None:
                values['fingerprint'] = Fingerprint()
            # Handle case where fingerprint is a string (seed)
            elif isinstance(values['fingerprint'], str):
                if not values['fingerprint'].strip():
                    raise ValueError(""Fingerprint seed cannot be empty"")
                values['fingerprint'] = Fingerprint.generate(seed=values['fingerprint'])
        return values
",src/crewai/security/security_config.py,SecurityConfig
survived,"def create_source_connection(config: Mapping[str, Any]) -> PipelineDataSource:
    pipeline_id = config.get(""pipeline_id"")
    pipeline_access_token = config.get(""pipeline_access_token"")

    return PipelineDataSource(pipeline_id=pipeline_id, pipeline_access_token=pipeline_access_token)
",airbyte-integrations/connectors/destination-glassflow/destination_glassflow/destination.py,
survived,"def _state() -> AirbyteMessage:
    return AirbyteMessage(type=Type.STATE, state=AirbyteStateMessage(data={}))
",airbyte-integrations/connectors/destination-glassflow/unit_tests/unit_test.py,
survived,"def _configured_catalog() -> ConfiguredAirbyteCatalog:
    stream_schema = {""type"": ""object"", ""properties"": {}}
    append_stream = ConfiguredAirbyteStream(
        stream=AirbyteStream(name=""test"", json_schema=stream_schema, supported_sync_modes=[SyncMode.full_refresh]),
        sync_mode=SyncMode.full_refresh,
        destination_sync_mode=DestinationSyncMode.append,
    )
    return ConfiguredAirbyteCatalog(streams=[append_stream])
",airbyte-integrations/connectors/destination-glassflow/unit_tests/unit_test.py,
survived,"def run():
    destination = DestinationGlassflow()
    destination.run(sys.argv[1:])",airbyte-integrations/connectors/destination-glassflow/destination_glassflow/run.py,
survived,"def test_write():
    f = open(
        ""secrets/config.json"",
    )
    config = json.load(f)
    messages = [_record(), _state()]
    destination = DestinationGlassflow()
    for m in destination.write(config=config, configured_catalog=_configured_catalog(), input_messages=messages):
        assert m.type == Type.STATE
    consume(config)",airbyte-integrations/connectors/destination-glassflow/integration_tests/integration_test.py,
survived,"def test_check_succeeds():
    f = open(
        ""secrets/config.json"",
    )
    config = json.load(f)
    destination = DestinationGlassflow()
    status = destination.check(logger=Mock(), config=config)
    assert status.status == Status.SUCCEEDED
",airbyte-integrations/connectors/destination-glassflow/integration_tests/integration_test.py,
survived,"        def _run(self, input_text: str) -> str:
            return f""Processed {input_text}""
",tests/tools/test_tool_usage_limit.py,LimitedTool
survived,"    def test_cache_hit_miss(self) -> None:
        """"""Test cache hit and miss.""""""
        loader = JsonLoader(""test"", self.save_path)
        
        # No file exists yet
        assert not loader.cache_hit(""hash1"", ""Pure"")
        
        # Create a cache file
        cache_path = loader.build_path(""hash1"", ""Pure"")
        
        # Create a valid JSON cache
        cache_dict = {
            ""defs"": {""var1"": ""value1""},
            ""hash"": ""hash1"",
            ""stateful_refs"": [],
            ""cache_type"": ""Pure"",
            ""hit"": True,
            ""meta"": {}
        }
        
        with open(cache_path, ""w"") as f:
            json.dump(cache_dict, f)
        
        # Now it should hit
        assert loader.cache_hit(""hash1"", ""Pure"")
        
        # Different hash should miss
        assert not loader.cache_hit(""hash2"", ""Pure"")
        
        # Different cache type should miss
        assert not loader.cache_hit(""hash1"", ""Deferred"")
        
        # Empty file should miss
        empty_path = loader.build_path(""empty"", ""Pure"")
        with open(empty_path, ""w"") as f:
            pass
        assert not loader.cache_hit(""empty"", ""Pure"")
",tests/_save/loaders/test_json_loader.py,TestJsonLoader
survived,"    def test_init_default(self) -> None:
        """"""Test default initialization.""""""
        loader = MemoryLoader(""test"")
        assert loader.name == ""test""
        assert loader.max_size == 128
        assert loader.is_lru is True
        assert isinstance(loader._cache, OrderedDict)
        assert loader._cache_lock is not None
",tests/_save/loaders/test_memory_loader.py,TestMemoryLoader
survived,"    def setup_method(self) -> None:
        """"""Set up a temporary directory for each test.""""""
        self.temp_dir = Path(""/tmp/marimo_test_loader"")
        self.temp_dir.mkdir(exist_ok=True)
        self.save_path = str(self.temp_dir)
",tests/_save/loaders/test_loader.py,TestBasePersistenceLoader
survived,"    def test_max_size_property(self) -> None:
        """"""Test the max_size property.""""""
        loader = MemoryLoader(""test"", max_size=3)
        assert loader.max_size == 3
        
        # Change max_size
        loader.max_size = 1
        assert loader.max_size == 1
        assert loader.is_lru is True
        
        # Disable LRU
        loader.max_size = 0
        assert loader.max_size == 0
        assert loader.is_lru is False",tests/_save/loaders/test_memory_loader.py,TestMemoryLoader
survived,"def find_and_print_langsmith_run_url(client: Client, project_name: Optional[str] = None) -> Optional[str]:
    """"""Find the most recent LangSmith run and print its URL.

    Args:
        client: The LangSmith client
        project_name: Optional name of the project

    Returns:
        The URL for the run in LangSmith if found, None otherwise
    """"""
    separator = ""="" * 60
    
    try:
        # Get the most recent runs with proper filter parameters
        # We need to provide at least one filter parameter as required by the API
        recent_runs = list(
            client.list_runs(
                # Use the project name from environment variable
                project_name=project_name,
                # Limit to just the most recent run
                limit=1,
            )
        )

        if recent_runs and len(recent_runs) > 0:
            # Make sure we have a valid run object with an id attribute
            if hasattr(recent_runs[0], ""id""):
                # Convert the ID to string to ensure it's in the right format
                run_id = str(recent_runs[0].id)

                # Get the run URL using the run_id parameter
                run_url = get_langsmith_url(client, run_id=run_id, project_name=project_name)

                print(f""\n{separator}\nðŸ” LangSmith Run URL: {run_url}\n{separator}"")
                return run_url
            else:
                print(f""\n{separator}\nRun object has no 'id' attribute: {recent_runs[0]}\n{separator}"")
                return None
        else:
            # If no runs found with project name, try a more general approach
            # Use a timestamp filter to get recent runs (last 10 minutes)
            ten_minutes_ago = datetime.datetime.now() - datetime.timedelta(minutes=10)

            recent_runs = list(client.list_runs(start_time=ten_minutes_ago.isoformat(), limit=1))

            if recent_runs and len(recent_runs) > 0 and hasattr(recent_runs[0], ""id""):
                # Convert the ID to string to ensure it's in the right format
                run_id = str(recent_runs[0].id)

                # Get the run URL using the run_id parameter
                run_url = get_langsmith_url(client, run_id=run_id, project_name=project_name)

                print(f""\n{separator}\nðŸ” LangSmith Run URL: {run_url}\n{separator}"")
                return run_url
            else:
                print(f""\n{separator}\nNo valid runs found\n{separator}"")
                return None
    except Exception as e:
        print(f""\n{separator}\nCould not retrieve LangSmith URL: {e}"")
        import traceback

        print(traceback.format_exc())
        print(separator)
        return None",src/codegen/extensions/langchain/utils/get_langsmith_url.py,
survived,"def create_init_file(goat_plugins_dir: Path, plugin_name: str, is_evm: bool) -> None:
    """"""Create the __init__.py file with plugin class.""""""
    class_name = f""{plugin_name.title()}Service""
    plugin_class = f""{plugin_name.title()}Plugin""
    options_class = f""{plugin_name.title()}PluginOptions""
    
    init_content = '''from dataclasses import dataclass
from goat.classes.plugin_base import PluginBase
from .service import {class_name}


@dataclass
class {options_class}:
    """"""Options for the {plugin_class}.""""""
    api_key: str  # API key for external service integration


class {plugin_class}(PluginBase):
    def __init__(self, options: {options_class}):
        super().__init__(""{plugin_name}"", [{class_name}(options.api_key)])

    def supports_chain(self, chain) -> bool:
        return {supports_chain}


def {plugin_name}(options: {options_class}) -> {plugin_class}:
    return {plugin_class}(options)
'''.format(
        class_name=class_name,
        plugin_class=plugin_class,
        options_class=options_class,
        plugin_name=plugin_name,
        supports_chain=""chain['type'] == 'evm'"" if is_evm else ""True""
    )

    with open(goat_plugins_dir / ""__init__.py"", ""w"") as f:
        f.write(init_content)
",python/create_plugin.py,
survived,"def create_parameters_file(goat_plugins_dir: Path, plugin_name: str) -> None:
    """"""Create the parameters.py file with example parameters in the goat_plugins directory.""""""
    parameters_content = '''from pydantic import BaseModel, Field
from typing import Optional


class ExampleQueryParameters(BaseModel):
    query: str = Field(
        description=""An example query parameter (e.g., 'search term', 'identifier')""
    )
    limit: Optional[int] = Field(
        None,
        description=""Maximum number of results to return. Defaults to no limit."",
    )
    include_metadata: bool = Field(
        default=False,
        description=""Include additional metadata in the response""
    )


class ExampleActionParameters(BaseModel):
    target_id: str = Field(
        description=""The ID of the target to perform action on""
    )
    action_type: str = Field(
        description=""The type of action to perform (e.g., 'create', 'update', 'delete')""
    )
    parameters: Optional[dict] = Field(
        None,
        description=""Optional parameters for the action""
    )
'''
    
    with open(goat_plugins_dir / ""parameters.py"", ""w"") as f:
        f.write(parameters_content)
",python/create_plugin.py,
survived,"    def balance_of(self, address: str) -> Balance:
        """"""Get the SOL balance of an address.""""""
        pass
",python/src/wallets/solana/goat_wallets/solana/wallet.py,SolanaWalletClient
survived,"def test_scrape_with_return_html_true(_mocked_chrome_driver):
    html_content = ""<html><body><div>HTML content</div></body></html>""
    mock_driver = mock_driver_with_html(html_content)
    tool = initialize_tool_with(mock_driver)

    result = tool._run(website_url=""https://example.com"", return_html=True)

    assert html_content in result
    mock_driver.get.assert_called_once_with(""https://example.com"")
    mock_driver.find_element.assert_called_with(""tag name"", ""body"")
    mock_driver.close.assert_called_once()
",tests/tools/selenium_scraping_tool_test.py,
survived,"def test_telemetry_otel_sdk_disabled_after_creation():
    """"""Test that OTEL_SDK_DISABLED also works when set after singleton creation.""""""
    Telemetry._instance = None
    
    with patch.dict(os.environ, {}, clear=True):
        with patch(""crewai.telemetry.telemetry.TracerProvider""):
            telemetry = Telemetry()
            assert telemetry.ready is True
            
            mock_operation = MagicMock()
            telemetry._safe_telemetry_operation(mock_operation)
            mock_operation.assert_called_once()
            
            mock_operation.reset_mock()
            
            os.environ['OTEL_SDK_DISABLED'] = 'true'
            
            telemetry._safe_telemetry_operation(mock_operation)
            mock_operation.assert_not_called()",tests/telemetry/test_telemetry_disable.py,
deleted,"        def check_port():
            try:
                sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                result = sock.connect_ex((""127.0.0.1"", self.backend_port))
                sock.close()
            except Exception:
                return False
            else:
                return result == 0
",reflex/testing.py,AppHarness
survived,"    def normalize_url(self, url):
        """"""Normalize URL for comparison.""""""
        parsed = urlparse(url)
        normalized = f""{parsed.scheme}://{parsed.netloc}{parsed.path}""
        if parsed.query:
            normalized += f""?{parsed.query}""
        return normalized
",scripts/check_dead_links.py,DeadLinkChecker
survived,"    def test_require_api_key_env(self) -> None:
        """"""Test _require_api_key with environment variable.""""""
        model = groq(""llama3-70b-8192"")
        assert model._require_api_key == ""env-key""
",tests/_ai/llm/_impl.py,TestGroq
survived,"    def test_init(self) -> None:
        """"""Test initialization of the openai class.""""""
        model = openai(""gpt-4"")
        assert model.model == ""gpt-4""
        assert model.system_message == DEFAULT_SYSTEM_MESSAGE
        assert model.api_key is None
        assert model.base_url is None

        model = openai(
            ""gpt-4"",
            system_message=""Custom system message"",
            api_key=""test-key"",
            base_url=""https://example.com"",
        )
        assert model.model == ""gpt-4""
        assert model.system_message == ""Custom system message""
        assert model.api_key == ""test-key""
        assert model.base_url == ""https://example.com""
",tests/_ai/llm/_impl.py,TestOpenAI
survived,"    def test_call(
        self,
        mock_generative_model: MagicMock,
        mock_configure: MagicMock,
        mock_require_api_key: MagicMock,
    ) -> None:
        """"""Test calling the google class.""""""
        mock_require_api_key.return_value = ""test-key""
        mock_client = MagicMock()
        mock_generative_model.return_value = mock_client
        mock_response = MagicMock()
        mock_response.text = ""Test response""
        mock_client.generate_content.return_value = mock_response

        model = google(""gemini-pro"")
        # Patch the _require_api_key property to return the test key directly
        with patch.object(model, ""_require_api_key"", ""test-key""):
            messages = [ChatMessage(role=""user"", content=""Test prompt"")]
            config = ChatModelConfig(
                max_tokens=100,
                temperature=0.7,
                top_p=0.9,
                top_k=10,
                frequency_penalty=0.5,
                presence_penalty=0.5,
            )

            result = model(messages, config)
            assert result == ""Test response""

            mock_configure.assert_called_once_with(api_key=""test-key"")
        mock_generative_model.assert_called_once()
        call_args = mock_generative_model.call_args[1]
        assert call_args[""model_name""] == ""gemini-pro""
        generation_config = call_args[""generation_config""]
        assert generation_config.max_output_tokens == 100
        assert generation_config.temperature == 0.7
        assert generation_config.top_p == 0.9
        assert generation_config.top_k == 10
        assert generation_config.frequency_penalty == 0.5
        assert generation_config.presence_penalty == 0.5

        mock_client.generate_content.assert_called_once()
",tests/_ai/llm/_impl.py,TestGoogle
deleted,"    def test_http_request_context_manager_with_request(self) -> None:
        # Test that http_request_context sets and unsets the HTTP request
        request = HTTPRequest(
            url={""path"": ""/test"", ""port"": None, ""scheme"": ""http"", ""netloc"": ""localhost"", ""query"": """", ""hostname"": ""localhost""},
            base_url={""path"": """", ""port"": None, ""scheme"": ""http"", ""netloc"": ""localhost"", ""query"": """", ""hostname"": ""localhost""},
            headers={},
            query_params={},
            path_params={},
            cookies={},
            meta={},
            user=None,
        )

        with http_request_context(request):
            # Request should be set within the context
            ctx_request = HTTP_REQUEST_CTX.get()
            assert ctx_request is not None
            assert ctx_request is request
            assert ctx_request.url[""path""] == ""/test""

        # Request should be unset outside the context
        with pytest.raises(LookupError):
            HTTP_REQUEST_CTX.get()
",tests/_messaging/test_context.py,TestHTTPRequestContext
deleted,"    def test_run_id_context_generates_unique_ids(self) -> None:
        # Test that run_id_context generates unique IDs
        with run_id_context() as ctx1:
            run_id1 = RUN_ID_CTX.get()

            with run_id_context() as ctx2:
                run_id2 = RUN_ID_CTX.get()

                # IDs should be different
                assert run_id1 != run_id2

            # Should restore the outer context
            assert RUN_ID_CTX.get() == run_id1

        # Run ID should be unset outside the context
        with pytest.raises(LookupError):
            RUN_ID_CTX.get()
",tests/_messaging/test_context.py,TestRunIDContext
deleted,"    def test_nested_http_request_contexts(self) -> None:
        # Test nested http_request_contexts
        request1 = HTTPRequest(
            url={""path"": ""/test1"", ""port"": None, ""scheme"": ""http"", ""netloc"": ""localhost"", ""query"": """", ""hostname"": ""localhost""},
            base_url={""path"": """", ""port"": None, ""scheme"": ""http"", ""netloc"": ""localhost"", ""query"": """", ""hostname"": ""localhost""},
            headers={},
            query_params={},
            path_params={},
            cookies={},
            meta={},
            user=None,
        )

        request2 = HTTPRequest(
            url={""path"": ""/test2"", ""port"": None, ""scheme"": ""http"", ""netloc"": ""localhost"", ""query"": """", ""hostname"": ""localhost""},
            base_url={""path"": """", ""port"": None, ""scheme"": ""http"", ""netloc"": ""localhost"", ""query"": """", ""hostname"": ""localhost""},
            headers={},
            query_params={},
            path_params={},
            cookies={},
            meta={},
            user=None,
        )

        with http_request_context(request1):
            # Outer context should have request1
            assert HTTP_REQUEST_CTX.get() is request1

            with http_request_context(request2):
                # Inner context should have request2
                assert HTTP_REQUEST_CTX.get() is request2

            # Should restore the outer context
            assert HTTP_REQUEST_CTX.get() is request1

        # Request should be unset outside the context
        with pytest.raises(LookupError):
            HTTP_REQUEST_CTX.get()",tests/_messaging/test_context.py,TestHTTPRequestContext
survived,"    def test_stdin_stop(self) -> None:
        stdin = Stdin()
        # Should not raise any exceptions
        stdin.stop()
",tests/_messaging/test_types.py,TestStdin
survived,"    def test_stdin_name(self) -> None:
        stdin = Stdin()
        assert stdin.name == ""stdin""
",tests/_messaging/test_types.py,TestStdin
survived,"    def test_is_code_highlighting(self) -> None:
        # Test is_code_highlighting function

        # Should return True for strings containing the codehilite class
        assert is_code_highlighting(""<span class=\""codehilite\"">code</span>"") is True
        assert is_code_highlighting(""before <span class=\""codehilite\"">code</span> after"") is True

        # Should return False for strings not containing the codehilite class
        assert is_code_highlighting(""<span>code</span>"") is False
        assert is_code_highlighting("""") is False
        assert is_code_highlighting(""class=\""not-codehilite\"""") is False",tests/_messaging/test_tracebacks.py,TestTracebacks
survived,"    def test_mime_bundle(self) -> None:
        # Test that MimeBundle can be used as a type annotation
        def accepts_mime_bundle(bundle: MimeBundle) -> MimeBundle:
            return bundle

        # Create a valid mime bundle
        bundle: MimeBundle = {
            ""text/plain"": ""Hello, world!"",
            ""text/html"": ""<h1>Hello, world!</h1>"",
        }

        assert accepts_mime_bundle(bundle) == bundle

        # Test with empty bundle
        empty_bundle: MimeBundle = {}
        assert accepts_mime_bundle(empty_bundle) == empty_bundle
",tests/_messaging/test_mimetypes.py,TestMimeTypes
survived,"    def test_print_override_with_thread_and_context(self) -> None:
        # Test print_override when in a marimo thread with context
        thread_id = threading.get_ident()
        THREADS.add(thread_id)

        try:
            stream = MockStream()

            # Create a mock context
            context = MagicMock(spec=RuntimeContext)
            context.stream = stream
            context.execution_context = MagicMock(spec=ExecutionContext)
            context.execution_context.cell_id = ""cell1""

            with patch(""marimo._messaging.print_override._original_print"") as mock_print:
                with patch(
                    ""marimo._messaging.print_override.get_context"",
                    return_value=context,
                ):
                    print_override(""Hello, world!"")

                    # Original print should not be called
                    mock_print.assert_not_called()

                    # Message should be sent to the stream
                    assert len(stream.messages) == 1
                    assert stream.messages[0][0] == ""cell-op""  # op
                    assert stream.messages[0][1][""cell_id""] == ""cell1""
                    assert stream.messages[0][1][""console""][""channel""] == ""stdout""
                    assert stream.messages[0][1][""console""][""mimetype""] == ""text/plain""
                    assert stream.messages[0][1][""console""][""data""] == ""Hello, world!\n""
        finally:
            # Clean up
            if thread_id in THREADS:
                THREADS.remove(thread_id)
",tests/_messaging/test_print_override.py,TestPrintOverride
survived,"    def test_write_traceback_to_regular_stderr(self) -> None:
        # Test writing traceback to regular stderr (not Stderr)
        mock_stderr = MagicMock()
        mock_stderr.write = MagicMock()

        with patch(""sys.stderr"", mock_stderr):
            traceback = ""Traceback (most recent call last):\n  File \""<stdin>\"", line 1, in <module>\nValueError: invalid value""
            write_traceback(traceback)

            # Should call write with the original traceback
            mock_stderr.write.assert_called_once_with(traceback)
",tests/_messaging/test_tracebacks.py,TestTracebacks
survived,"    def test_stderr_name(self) -> None:
        stderr = self.MockStderr()
        assert stderr.name == ""stderr""
",tests/_messaging/test_types.py,TestStdoutStderr
survived,"def test_plugin_instantiation():
    """"""Test that the plugin can be instantiated without errors.""""""
    api_key = os.environ.get(""UNISWAP_API_KEY"")
    assert api_key is not None, ""UNISWAP_API_KEY environment variable is required""
    
    options = UniswapPluginOptions(api_key=api_key)
    plugin = uniswap(options)
    
    assert plugin is not None
    assert plugin.name == ""uniswap""
    
    # Test chain support
    ethereum_chain: EvmChain = {""type"": ""evm"", ""id"": 1}  # Ethereum mainnet
    polygon_chain: EvmChain = {""type"": ""evm"", ""id"": 137}  # Polygon
    solana_chain: SolanaChain = {""type"": ""solana""}  # Solana chain
    unknown_chain: EvmChain = {""type"": ""evm"", ""id"": 999}  # Unknown EVM chain
    
    assert plugin.supports_chain(ethereum_chain)
    assert plugin.supports_chain(polygon_chain)
    assert not plugin.supports_chain(solana_chain)
    assert not plugin.supports_chain(unknown_chain)",python/src/plugins/uniswap/tests/test_uniswap_plugin.py,
survived,"def test_custodial_wallet_invalid_options(custodial_api, invalid_options, solana_connection):
    """"""Test error handling with invalid options.""""""
    with pytest.raises(Exception) as exc:
        custodial_api.create_custodial_wallet(list(invalid_options.values())[0])
    assert ""error"" in str(exc.value).lower() or ""invalid"" in str(exc.value).lower()
",python/src/wallets/crossmint/tests/test_custodial_wallet.py,
survived,"def test_smart_wallet_ens_resolution(smart_api, test_wallet_options, test_keypair):
    """"""Test ENS name resolution.""""""
    # Create wallet and client
    wallet = smart_api.create_smart_wallet()
    client = SmartWalletClient(
        wallet[""address""],
        smart_api,
        test_wallet_options[""chain""],
        test_keypair,
        test_wallet_options[""provider""],
        test_wallet_options[""options""][""ensProvider""]
    )
    
    # Test with a known ENS name
    try:
        address = client.resolve_address(""vitalik.eth"")
        assert address.startswith(""0x"")
        assert Web3.is_address(address)
    except ValueError as e:
        # ENS provider might be unavailable, that's ok
        assert ""provider is not configured"" in str(e).lower() or ""could not resolve"" in str(e).lower()
",python/src/wallets/crossmint/tests/test_smart_wallet.py,
survived,"def test_smart_wallet_read_contract(smart_api, test_wallet_options, test_keypair):
    """"""Test reading from a smart contract.""""""
    # Create wallet and client
    wallet = smart_api.create_smart_wallet()
    client = SmartWalletClient(
        wallet[""address""],
        smart_api,
        test_wallet_options[""chain""],
        test_keypair,
        test_wallet_options[""provider""],
        test_wallet_options[""options""][""ensProvider""]
    )
    
    # Example ERC20 balanceOf ABI
    abi = [{
        ""constant"": True,
        ""inputs"": [{""name"": ""_owner"", ""type"": ""address""}],
        ""name"": ""balanceOf"",
        ""outputs"": [{""name"": ""balance"", ""type"": ""uint256""}],
        ""type"": ""function""
    }]
    
    # Read contract
    try:
        result = client.read({
            ""address"": ""0x742d35Cc6634C0532925a3b844Bc454e4438f44e"",
            ""abi"": abi,
            ""functionName"": ""balanceOf"",
            ""args"": [wallet[""address""]]
        })
        assert ""value"" in result
    except Exception as e:
        # Contract might not exist on testnet, that's ok
        assert ""revert"" in str(e).lower() or ""not found"" in str(e).lower()
",python/src/wallets/crossmint/tests/test_smart_wallet.py,
survived,"def get_box_ccg_client(config: Mapping[str, Any]) -> BoxClient:
    client_id = config[""client_id""]
    client_secret = config[""client_secret""]
    box_subject_type = config[""box_subject_type""]
    box_subject_id = config[""box_subject_id""]

    if box_subject_type == ""enterprise"":
        enterprise_id = box_subject_id
        user_id = None
    else:
        enterprise_id = None
        user_id = box_subject_id
    ccg_config = CCGConfig(client_id=client_id, client_secret=client_secret, enterprise_id=enterprise_id, user_id=user_id)
    ccg_auth = BoxCCGAuth(ccg_config)
    return add_extra_header_to_box_client(BoxClient(ccg_auth))
",airbyte-integrations/connectors/source-box-data-extract/source_box_data_extract/box_api.py,
survived,"def box_file_ai_ask(client: BoxClient, file_id: str, prompt: str) -> str:
    mode = CreateAiAskMode.SINGLE_ITEM_QA
    ai_item = AiItemBase(id=file_id, type=AiItemBaseTypeField.FILE)
    response = client.ai.create_ai_ask(mode=mode, prompt=prompt, items=[ai_item])
    return response.answer
",airbyte-integrations/connectors/source-box-data-extract/source_box_data_extract/box_api.py,
survived,"    def get_json_schema(self):
        return get_generic_json_schema()
",airbyte-integrations/connectors/source-box-data-extract/source_box_data_extract/source.py,StreamAIAskFolder
survived,"def test_streams(mocker):
    source = SourceBoxDataExtract()
    config_mock = MagicMock()
    streams = source.streams(config_mock)
    expected_streams_number = 4
    assert len(streams) == expected_streams_number",airbyte-integrations/connectors/source-box-data-extract/unit_tests/test_source.py,
survived,"    def get_rejection_message(self, input_str: str) -> str:
        """"""
        Get a message explaining why the input was rejected.
        
        Args:
            input_str: The rejected input string
            
        Returns:
            A message explaining the rejection
        """"""
        return ""Your input contains terms that may be related to harmful or inappropriate content. Please rephrase your request.""
",openai-agents-examples/10_agent_with_guardrails.py,ContentModerationGuardrail
survived,"def get_current_weather(location: str, unit: str) -> str:
    """"""
    Get the current weather in a given location.
    
    Args:
        location: The city and state, e.g. San Francisco, CA or country e.g., London, UK
        unit: The temperature unit to use. Either ""celsius"" or ""fahrenheit"".
        
    Returns:
        A string containing the weather information.
    """"""
    # This is a mock implementation - in a real application, you would call a weather API
    weather_data = {
        ""New York"": {""temperature"": 22, ""condition"": ""Sunny""},
        ""London"": {""temperature"": 15, ""condition"": ""Cloudy""},
        ""Tokyo"": {""temperature"": 28, ""condition"": ""Rainy""},
        ""Sydney"": {""temperature"": 31, ""condition"": ""Hot and sunny""},
    }
    
    # Default weather if location not found
    default_weather = {""temperature"": 20, ""condition"": ""Clear""}
    
    # Get weather for the location (case insensitive)
    location_key = next((k for k in weather_data.keys() if k.lower() == location.lower()), None)
    weather = weather_data.get(location_key, default_weather)
    
    # Convert temperature if needed
    temp = weather[""temperature""]
    if unit.lower() == ""fahrenheit"":
        temp = (temp * 9/5) + 32
    
    return f""The current weather in {location} is {weather['condition']} with a temperature of {temp}Â°{'F' if unit.lower() == 'fahrenheit' else 'C'}.""
",openai-agents-examples/05_agent_with_function_tools.py,
survived,"def create_travel_assistant() -> Agent:
    """"""
    Create a travel assistant agent with function tools.
    
    Returns:
        An Agent instance with function tools for travel assistance.
    """"""
    instructions = """"""
    You are a helpful travel assistant that can provide information about weather, 
    distances between locations, and current time.
    Use the tools available to you to provide accurate information when asked.
    If you don't have a tool for the specific request, acknowledge the limitations
    and provide the best information you can.
    """"""
    
    # Create the agent with function tools
    return Agent(
        name=""TravelAssistant"",
        instructions=instructions,
        model=""gpt-4o-mini"",
        tools=[get_current_weather, calculate_distance, get_current_time]
    )
",openai-agents-examples/05_agent_with_function_tools.py,
survived,"async def run_customer_support_system(prompt: str) -> str:
    """"""
    Run the customer support system with the given prompt.
    
    Args:
        prompt: The customer's inquiry
        
    Returns:
        The final response from the appropriate specialist agent
    """"""
    # Create specialist agents
    billing_agent = create_billing_agent()
    technical_agent = create_technical_agent()
    account_agent = create_account_agent()
    
    # Create triage agent with specialists
    triage_agent = create_triage_agent([billing_agent, technical_agent, account_agent])
    
    # Run the triage agent with the prompt
    result = await Runner.run(triage_agent, prompt)
    
    # Return the final response
    return result.final_output
",openai-agents-examples/07_agent_with_handoffs.py,
survived,"async def run_conversation_with_context(prompt: str, context: Optional[Context] = None) -> tuple[str, Context]:
    """"""
    Run a conversation agent with context management.
    
    Args:
        prompt: The user's query or prompt
        context: Optional existing context from previous interactions
        
    Returns:
        A tuple containing the agent's response and the updated context
    """"""
    # Create the conversation agent
    agent = create_conversation_agent()
    
    # Create a new context if none is provided
    if context is None:
        context = Context()
    
    # Run the agent with the prompt and context
    result = await Runner.run(agent, prompt, context=context)
    
    # Return the response and updated context
    return result.final_output, result.context
",openai-agents-examples/09_agent_with_context_management.py,
survived,"def test_create_triage_agent():
    """"""Test that the triage agent is created with the correct configuration.""""""
    billing_agent = create_billing_agent()
    technical_agent = create_technical_agent()
    account_agent = create_account_agent()
    
    triage_agent = create_triage_agent([billing_agent, technical_agent, account_agent])
    
    assert triage_agent.name == ""TriageAgent""
    assert ""triage agent"" in triage_agent.instructions.lower()
    assert len(triage_agent.handoffs) == 3
",openai-agents-examples/07_agent_with_handoffs.py,
survived,"def test_create_health_agent():
    """"""Test that the health agent is created with the correct configuration.""""""
    agent = create_health_agent()
    assert agent.name == ""HealthAdvisor""
    assert ""health advisor"" in agent.instructions.lower()
    assert agent.model == ""gpt-4o-mini""
",openai-agents-examples/03_sync_agent.py,
survived,"def format_blog_as_markdown(title: str, content: str) -> str:
    """"""
    Format a blog post as markdown.
    
    Args:
        title: The blog post title
        content: The blog post content
        
    Returns:
        A string containing the formatted markdown
    """"""
    # Ensure the content has proper markdown formatting
    if not content.startswith('#'):
        content = f""# {title}\n\n{content}""
    
    # Add metadata
    markdown = f""""""---
title: ""{title}""
date: ""{datetime.now().strftime('%Y-%m-%d')}""
author: ""AI Research & Blog System""
tags: [""ai"", ""research"", ""blog""]
---

{content}
""""""
    
    return markdown
",openai-agents-examples/13_research_blog_system.py,
survived,"    def filter(self, input_str: str) -> Optional[str]:
        """"""
        Filter the input string based on format requirements.
        
        Args:
            input_str: The input string to filter
            
        Returns:
            The input string if it passes, or None if it should be rejected
        """"""
        # Check length constraints
        if len(input_str) < self.min_length:
            return None  # Too short
        
        if len(input_str) > self.max_length:
            return None  # Too long
        
        return input_str  # Accept the input
",openai-agents-examples/10_agent_with_guardrails.py,FormatValidationGuardrail
survived,"def test_create_specialist_agents():
    """"""Test that specialist agents are created with the correct configuration.""""""
    research_agent = create_research_agent()
    outline_agent = create_outline_agent()
    content_agent = create_content_agent()
    editor_agent = create_editor_agent()
    
    assert research_agent.name == ""ResearchSpecialist""
    assert outline_agent.name == ""OutlineSpecialist""
    assert content_agent.name == ""ContentSpecialist""
    assert editor_agent.name == ""EditingSpecialist""
    
    assert ""research specialist"" in research_agent.instructions.lower()
    assert ""outline specialist"" in outline_agent.instructions.lower()
    assert ""content writing specialist"" in content_agent.instructions.lower()
    assert ""editing specialist"" in editor_agent.instructions.lower()
",openai-agents-examples/11_agent_orchestration.py,
survived,"def test_create_anthropic_agent():
    """"""Test that the Anthropic agent is created with the correct configuration.""""""
    import pytest
    
    # Skip this test if no API key is available
    if not os.environ.get(""ANTHROPIC_API_KEY""):
        pytest.skip(""ANTHROPIC_API_KEY not set"")
    
    agent = create_anthropic_agent()
    assert agent.name == ""ClaudeAssistant""
    assert ""claude"" in agent.instructions.lower()
    assert isinstance(agent.model_provider, AnthropicModelProvider)
",openai-agents-examples/12_anthropic_agent.py,
survived,"def main():
    """"""Main function to parse arguments and run the conversation agent.""""""
    parser = argparse.ArgumentParser(description=""Agent with Context Management Example"")
    parser.add_argument(""--prompt"", ""-p"", type=str, required=True, 
                        help=""The prompt to send to the agent"")
    parser.add_argument(""--follow-up"", ""-f"", type=str, nargs=""*"", default=[],
                        help=""Optional follow-up prompts to simulate a conversation"")
    
    args = parser.parse_args()
    
    # Ensure API key is available
    if not os.environ.get(""OPENAI_API_KEY""):
        console.print(Panel(""[bold red]Error: OPENAI_API_KEY environment variable not set[/bold red]""))
        sys.exit(1)
    
    try:
        # Simulate a conversation with the provided prompts
        responses = simulate_conversation(args.prompt, args.follow_up)
        
        # Display the initial response
        console.print(Panel(responses[0], title=f""Response to: {args.prompt}"", border_style=""green""))
        
        # Display follow-up responses if any
        for i, response in enumerate(responses[1:]):
            console.print(Panel(response, title=f""Response to: {args.follow_up[i]}"", border_style=""blue""))
    
    except Exception as e:
        console.print(Panel(f""[bold red]Error: {str(e)}[/bold red]""))
        sys.exit(1)
",openai-agents-examples/09_agent_with_context_management.py,
survived,"def test_create_research_blog():
    """"""Test that the research blog system can run and produce a blog post.""""""
    import pytest
    
    # Skip this test if no API key is available
    if not os.environ.get(""OPENAI_API_KEY""):
        pytest.skip(""OPENAI_API_KEY not set"")
    
    # Run a test with a simple topic
    # Use a shorter timeout for testing
    blog_post = asyncio.run(create_research_blog(""AI Ethics""))
    
    # Verify we got a non-empty blog post
    assert blog_post
    assert len(blog_post) > 0
    # The blog post should contain relevant terms
    assert any(term in blog_post.lower() for term in [""ai"", ""ethics"", ""principles""])
",openai-agents-examples/13_research_blog_system.py,
survived,"    async def reply_message(
        self,
        message_source: platform_message.MessageChain,
        message: platform_message.MessageChain,
    ) -> dict:
        """"""å›žå¤æ¶ˆæ¯""""""
        source_components = [comp for comp in message_source if isinstance(comp, platform_message.Source)]
        if source_components:
            source = source_components[0]
            session_key = getattr(source, 'session_id', 'webchatperson')
        else:
            session_key = 'webchatperson'
            
        return await self.send_message('person', session_key, message)
",pkg/platform/sources/webchat.py,WebChatAdapter
survived,"    async def initialize(self) -> None:
        @self.route('/send', methods=['POST'])
        async def send_message() -> str:
            """"""å‘é€è°ƒè¯•æ¶ˆæ¯åˆ°æµæ°´çº¿""""""
            try:
                data = await quart.request.get_json()
                session_type = data.get('session_type', 'person')
                content = data.get('content', '')
                
                if not content:
                    return self.http_status(400, -1, 'content is required')
                
                if session_type not in ['person', 'group']:
                    return self.http_status(400, -1, 'session_type must be person or group')
                
                webchat_adapter = None
                for bot in self.ap.platform_mgr.bots:
                    if hasattr(bot.adapter, '__class__') and bot.adapter.__class__.__name__ == 'WebChatAdapter':
                        webchat_adapter = bot.adapter
                        break
                
                if not webchat_adapter:
                    return self.http_status(404, -1, 'WebChat adapter not found')
                
                result = await webchat_adapter.send_debug_message(session_type, content)
                
                return self.success(data=result)
                
            except Exception as e:
                return self.http_status(500, -1, f'Internal server error: {str(e)}')

        @self.route('/messages/<session_type>', methods=['GET'])
        async def get_messages(session_type: str) -> str:
            """"""èŽ·å–è°ƒè¯•æ¶ˆæ¯åŽ†å²""""""
            try:
                if session_type not in ['person', 'group']:
                    return self.http_status(400, -1, 'session_type must be person or group')
                
                webchat_adapter = None
                for bot in self.ap.platform_mgr.bots:
                    if hasattr(bot.adapter, '__class__') and bot.adapter.__class__.__name__ == 'WebChatAdapter':
                        webchat_adapter = bot.adapter
                        break
                
                if not webchat_adapter:
                    return self.http_status(404, -1, 'WebChat adapter not found')
                
                messages = webchat_adapter.get_debug_messages(session_type)
                
                return self.success(data={'messages': messages})
                
            except Exception as e:
                return self.http_status(500, -1, f'Internal server error: {str(e)}')

        @self.route('/reset/<session_type>', methods=['POST'])
        async def reset_session(session_type: str) -> str:
            """"""é‡ç½®è°ƒè¯•ä¼šè¯""""""
            try:
                if session_type not in ['person', 'group']:
                    return self.http_status(400, -1, 'session_type must be person or group')
                
                webchat_adapter = None
                for bot in self.ap.platform_mgr.bots:
                    if hasattr(bot.adapter, '__class__') and bot.adapter.__class__.__name__ == 'WebChatAdapter':
                        webchat_adapter = bot.adapter
                        break
                
                if not webchat_adapter:
                    return self.http_status(404, -1, 'WebChat adapter not found')
                
                webchat_adapter.reset_debug_session(session_type)
                
                return self.success(data={'message': 'Session reset successfully'})
                
            except Exception as e:
                return self.http_status(500, -1, f'Internal server error: {str(e)}')

        @self.route('/pipelines', methods=['GET'])
        async def get_pipelines() -> str:
            """"""èŽ·å–å¯ç”¨çš„æµæ°´çº¿åˆ—è¡¨""""""
            try:
                pipelines = await self.ap.pipeline_mgr.get_pipelines()
                
                pipeline_list = []
                for pipeline in pipelines:
                    pipeline_list.append({
                        'id': pipeline.uuid,
                        'name': pipeline.name,
                        'description': pipeline.description,
                        'is_default': pipeline.is_default
                    })
                
                return self.success(data={'pipelines': pipeline_list})
                
            except Exception as e:
                return self.http_status(500, -1, f'Internal server error: {str(e)}')",pkg/api/http/controller/groups/debug/webchat.py,WebChatDebugRouterGroup
survived,"def test_milvus_lite_connection():
    """"""Test basic Milvus Lite connection and operations.""""""
    temp_dir = tempfile.mkdtemp(prefix=""milvus_lite_test_"")
    db_path = os.path.join(temp_dir, ""test.db"")
    
    try:
        # Connect to Milvus Lite
        logger.info(f""Connecting to Milvus Lite at {db_path}"")
        connections.connect(
            alias=""default"",
            uri=db_path,
            use_lite=True,
            timeout=30
        )
        logger.info(""Successfully connected to Milvus Lite"")
        
        # List connections
        conns = connections.list_connections()
        logger.info(f""Active connections: {conns}"")
        
        # Check if connection is working
        assert connections.has_connection(""default""), ""Connection not established""
        
        # For Milvus Lite, we'll test basic collection operations instead of version check
        test_collection = ""test_collection""
        
        # Create a test collection
        from pymilvus import Collection, CollectionSchema, DataType, FieldSchema
        
        if utility.has_collection(test_collection):
            utility.drop_collection(test_collection)
            
        fields = [
            FieldSchema(name=""id"", dtype=DataType.INT64, is_primary=True, auto_id=True),
            FieldSchema(name=""vector"", dtype=DataType.FLOAT_VECTOR, dim=8)
        ]
        schema = CollectionSchema(fields=fields, enable_dynamic_field=True)
        collection = Collection(name=test_collection, schema=schema)
        
        # Create FLAT index (only supported type in Milvus Lite)
        collection.create_index(
            field_name=""vector"",
            index_params={""metric_type"": ""L2"", ""index_type"": ""FLAT""}
        )
        
        logger.info(""Successfully created test collection and index"")
        utility.drop_collection(test_collection)
        
        return True
        
    except Exception as e:
        logger.error(f""Connection test failed: {str(e)}"")
        return False
        
    finally:
        # Clean up
        try:
            if connections.has_connection(""default""):
                connections.disconnect(""default"")
            shutil.rmtree(temp_dir, ignore_errors=True)
        except Exception as e:
            logger.warning(f""Cleanup error: {str(e)}"")
",airbyte-integrations/connectors/destination-milvus/integration_tests/test_connection.py,
survived,"def test_solana_smart_wallet_with_phone(smart_api, test_phone, test_solana_wallet_options):
    """"""Test Solana smart wallet creation with phone.""""""
    wallet = smart_api.create_wallet(
        wallet_type=WalletType.SOLANA_SMART_WALLET,
        linked_user=f""phoneNumber:{test_phone}""
    )
    assert wallet[""type""] == ""solana-smart-wallet""
    assert ""linkedUser"" in wallet
",python/src/wallets/crossmint/tests/test_solana_smart_wallet.py,
survived,"def change_password(user_id: str, current_password: str, new_password: str) -> Tuple[bool, Dict]:
    """"""
    Change a user's password.
    
    Args:
        user_id: The ID of the user
        current_password: The current password
        new_password: The new password
        
    Returns:
        Tuple of (success, result) where result contains a success message or error message
    """"""
    # Validate required fields
    missing_fields = validate_required_fields(
        {""current_password"": current_password, ""new_password"": new_password},
        [""current_password"", ""new_password""]
    )
    
    if missing_fields:
        return False, {""error"": f""Missing required fields: {', '.join(missing_fields)}""}
    
    # Validate new password strength
    password_validation = validate_password_strength(new_password)
    if not password_validation[""is_valid""]:
        errors = []
        if not password_validation[""length""]:
            errors.append(""Password must be at least 8 characters"")
        if not password_validation[""uppercase""]:
            errors.append(""Password must contain at least one uppercase letter"")
        if not password_validation[""lowercase""]:
            errors.append(""Password must contain at least one lowercase letter"")
        if not password_validation[""digit""]:
            errors.append(""Password must contain at least one digit"")
        if not password_validation[""special_char""]:
            errors.append(""Password must contain at least one special character"")
        
        return False, {""error"": errors}
    
    # In a real application, this would verify the current password and update it
    # For this mock, we'll just print the change
    print(f""[PASSWORD] User {user_id} password changed"")
    
    return True, {""message"": ""Password changed successfully""}",codebase-architectures/atomic-composable-architecture/capabilities/user_management.py,
survived,"    def get_all_categories():
        """"""Get all categories.""""""
        try:
            categories = CategoryService.get_all_categories()
            return {
                ""success"": True,
                ""data"": categories
            }
        except Exception as e:
            Logger.error(app_logger, f""Error in get_all_categories: {str(e)}"", exc_info=True)
            return {
                ""success"": False,
                ""message"": ""An error occurred while retrieving categories""
            }
",codebase-architectures/layered-architecture/api/category_api.py,CategoryAPI
survived,"    def _execute_stage(self, stage_instance, previous_result):
        """"""Execute a stage with the result from the previous stage.""""""
        # This method should be overridden in subclasses to provide
        # specific implementation for subsequent stages
        raise NotImplementedError(""Subclasses must implement _execute_stage"")
",codebase-architectures/pipeline-architecture/pipeline/pipeline_manager.py,PipelineManager
survived,"def create_sample_data():
    """"""Create sample sales data for the pipeline example.""""""
    # Create output directory if it doesn't exist
    os.makedirs(""./data"", exist_ok=True)
    
    # Sample sales data
    sales_data = [
        {
            ""id"": ""S001"",
            ""product"": ""Laptop"",
            ""category"": ""Electronics"",
            ""price"": 1299.99,
            ""quantity"": 5,
            ""date"": ""2025-01-15"",
            ""customer"": ""ABC Corp"",
            ""discount"": 0.1
        },
        {
            ""id"": ""S002"",
            ""product"": ""Smartphone"",
            ""category"": ""Electronics"",
            ""price"": 899.99,
            ""quantity"": 10,
            ""date"": ""2025-01-20"",
            ""customer"": ""XYZ Ltd"",
            ""discount"": 0.05
        },
        {
            ""id"": ""S003"",
            ""product"": ""Office Chair"",
            ""category"": ""Furniture"",
            ""price"": 249.99,
            ""quantity"": 8,
            ""date"": ""2025-01-22"",
            ""customer"": ""123 Industries"",
            ""discount"": 0.0
        },
        {
            ""id"": ""S004"",
            ""product"": ""Desk"",
            ""category"": ""Furniture"",
            ""price"": 349.99,
            ""quantity"": 4,
            ""date"": ""2025-01-25"",
            ""customer"": ""ABC Corp"",
            ""discount"": 0.15
        },
        {
            ""id"": ""S005"",
            ""product"": ""Monitor"",
            ""category"": ""Electronics"",
            ""price"": 499.99,
            ""quantity"": 12,
            ""date"": ""2025-01-30"",
            ""customer"": ""XYZ Ltd"",
            ""discount"": 0.1
        },
        {
            ""id"": ""S006"",
            ""product"": ""Printer"",
            ""category"": ""Electronics"",
            ""price"": 299.99,
            ""quantity"": 3,
            ""date"": ""2025-02-05"",
            ""customer"": ""123 Industries"",
            ""discount"": 0.0
        },
        {
            ""id"": ""S007"",
            ""product"": ""Bookshelf"",
            ""category"": ""Furniture"",
            ""price"": 199.99,
            ""quantity"": 6,
            ""date"": ""2025-02-10"",
            ""customer"": ""ABC Corp"",
            ""discount"": 0.05
        }
    ]
    
    # Save to file
    with open(""./data/sales_data.json"", ""w"") as file:
        json.dump(sales_data, file, indent=2)
    
    print(f""Created sample data file: ./data/sales_data.json"")
    return ""./data/sales_data.json""
",codebase-architectures/pipeline-architecture/main.py,
survived,"def display_header(text):
    """"""Display a header with the given text.""""""
    print(""\n"" + ""="" * 50)
    print(f"" {text}"")
    print(""="" * 50)
",codebase-architectures/layered-architecture/main.py,
survived,"def mark_all_alerts_as_read(user_id: str) -> int:
    """"""
    Mark all alerts for a user as read.
    
    Args:
        user_id: The ID of the user
        
    Returns:
        Number of alerts marked as read
    """"""
    return mark_all_notifications_as_read(user_id)
",codebase-architectures/atomic-composable-architecture/capabilities/alerting.py,
survived,"    def info(logger, message):
        """"""Log an info message.""""""
        logger.info(message)
",codebase-architectures/layered-architecture/utils/logger.py,Logger
survived,"def send_email_notification(email: str, subject: str, message: str) -> bool:
    """"""
    Send an email notification (mock implementation).
    
    Args:
        email: The recipient's email address
        subject: The email subject
        message: The email message
        
    Returns:
        True if the email was sent successfully (always True in this mock)
    """"""
    # In a real application, this would send an actual email
    print(f""[EMAIL] To: {email}, Subject: {subject}"")
    print(f""[EMAIL] Message: {message}"")
    return True
",codebase-architectures/atomic-composable-architecture/modules/notifications.py,
survived,"    def send_alert(token: str, message: str, level: str = ""info"", 
                  email: Optional[str] = None, phone: Optional[str] = None,
                  additional_data: Optional[Dict] = None) -> Dict:
        """"""
        Send an alert to a user.
        
        Args:
            token: Authentication token
            message: The alert message
            level: Alert level (info, warning, error)
            email: Optional email address to send the alert to
            phone: Optional phone number to send the alert to
            additional_data: Additional data for the alert
            
        Returns:
            Response with success status and alert details or error message
        """"""
        # Validate token
        success, user_data = validate_user_token(token)
        if not success:
            return {
                ""status"": ""error"",
                ""message"": ""Invalid or expired token"",
                ""data"": None
            }
        
        # Send alert
        success, result = send_user_alert(
            user_id=user_data[""id""],
            message=message,
            level=level,
            email=email,
            phone=phone,
            additional_data=additional_data
        )
        
        if success:
            return {
                ""status"": ""success"",
                ""message"": ""Alert sent successfully"",
                ""data"": result
            }
        else:
            return {
                ""status"": ""error"",
                ""message"": result.get(""error"", ""Failed to send alert""),
                ""data"": None
            }
",codebase-architectures/atomic-composable-architecture/endpoints/alerts_api.py,AlertsAPI
survived,"    def delete_product(product_id):
        """"""Delete a product.""""""
        try:
            result = ProductService.delete_product(product_id)
            if not result:
                return {
                    ""success"": False,
                    ""message"": f""Product with ID {product_id} not found""
                }
            return {
                ""success"": True,
                ""message"": ""Product deleted successfully""
            }
        except Exception as e:
            Logger.error(app_logger, f""Error in delete_product: {str(e)}"", exc_info=True)
            return {
                ""success"": False,
                ""message"": ""An error occurred while deleting the product""
            }",codebase-architectures/layered-architecture/api/product_api.py,ProductAPI
survived,"    def get_by_username(username):
        """"""Get a user by username.""""""
        all_users = db.get_all(""users"")
        for user in all_users:
            if user[""username""] == username:
                return user
        return None
",codebase-architectures/vertical-slice-architecture/features/users/service.py,UserService
survived,"    def validate_data(self, schema=None, required_fields=None):
        """"""
        Validate the loaded data against a schema or required fields.
        
        Args:
            schema: Schema definition for validation
            required_fields: List of required field names
        
        Returns:
            dict: Stage result with data and metadata
        """"""
        if self.data is None:
            self.metadata[""status""] = ""error""
            self.metadata[""errors""].append(""No data loaded to validate"")
            return self._create_result()
        
        try:
            validation_errors = []
            
            # Validate required fields if specified
            if required_fields:
                if isinstance(self.data, list):
                    for i, item in enumerate(self.data):
                        try:
                            validate_required_fields(item, required_fields)
                        except ValueError as e:
                            validation_errors.append(f""Record {i}: {str(e)}"")
                else:
                    try:
                        validate_required_fields(self.data, required_fields)
                    except ValueError as e:
                        validation_errors.append(str(e))
            
            # Update metadata based on validation results
            if validation_errors:
                self.metadata[""status""] = ""validation_failed""
                self.metadata[""errors""].extend(validation_errors)
            else:
                self.metadata[""status""] = ""validated""
            
            return self._create_result()
        except Exception as e:
            self.metadata[""status""] = ""error""
            self.metadata[""errors""].append(f""Validation error: {str(e)}"")
            return self._create_result()
",codebase-architectures/pipeline-architecture/pipeline/input_stage.py,InputStage
survived,"    def _create_pipeline_result(self):
        """"""Create a result dictionary for the entire pipeline.""""""
        # Get the final result
        final_result = self.get_final_result()
        
        # Create pipeline result
        pipeline_result = {
            ""metadata"": self.metadata,
            ""stages"": [{
                ""name"": stage[""name""],
                ""status"": stage[""status""]
            } for stage in self.stages]
        }
        
        # Add data from final stage if available
        if final_result and ""data"" in final_result:
            pipeline_result[""data""] = final_result[""data""]
        
        # Add analysis from final stage if available
        if final_result and ""analysis"" in final_result:
            pipeline_result[""analysis""] = final_result[""analysis""]
        
        return pipeline_result
",codebase-architectures/pipeline-architecture/pipeline/pipeline_manager.py,PipelineManager
survived,"def mark_alert_as_read(user_id: str, notification_id: str) -> bool:
    """"""
    Mark an alert as read.
    
    Args:
        user_id: The ID of the user
        notification_id: The ID of the notification
        
    Returns:
        True if the alert was marked as read, False otherwise
    """"""
    return mark_notification_as_read(user_id, notification_id)
",codebase-architectures/atomic-composable-architecture/capabilities/alerting.py,
survived,"def send_sms_notification(phone_number: str, message: str) -> bool:
    """"""
    Send an SMS notification (mock implementation).
    
    Args:
        phone_number: The recipient's phone number
        message: The SMS message
        
    Returns:
        True if the SMS was sent successfully (always True in this mock)
    """"""
    # In a real application, this would send an actual SMS
    print(f""[SMS] To: {phone_number}"")
    print(f""[SMS] Message: {message}"")
    return True
",codebase-architectures/atomic-composable-architecture/modules/notifications.py,
survived,"def validate_numeric_range(value: Union[int, float], min_value: Optional[Union[int, float]] = None, 
                          max_value: Optional[Union[int, float]] = None) -> bool:
    """"""
    Validate that a numeric value is within the specified range.
    
    Args:
        value: The numeric value to validate
        min_value: Minimum allowed value, or None for no minimum
        max_value: Maximum allowed value, or None for no maximum
        
    Returns:
        True if the value is within range, False otherwise
    """"""
    if not isinstance(value, (int, float)):
        return False
    
    if min_value is not None and value < min_value:
        return False
    
    if max_value is not None and value > max_value:
        return False
    
    return True
",codebase-architectures/atomic-composable-architecture/modules/validation.py,
survived,"    def delete_task(task_id):
        """"""Delete a task.""""""
        success = TaskService.delete_task(task_id)
        if not success:
            return {""error"": f""Task with ID {task_id} not found""}
        return {""message"": f""Task with ID {task_id} deleted successfully""}",codebase-architectures/vertical-slice-architecture/features/tasks/api.py,TaskAPI
survived,"    def create_user(user_data):
        """"""Create a new user.""""""
        validate_required_fields(user_data, [""username"", ""email""])
        
        # Check if username already exists
        all_users = db.get_all(""users"")
        if any(user[""username""] == user_data[""username""] for user in all_users):
            raise ValueError(f""Username '{user_data['username']}' already exists"")
        
        user = User(**user_data)
        db.insert(""users"", user.id, user.to_dict())
        return user.to_dict()
",codebase-architectures/vertical-slice-architecture/features/users/service.py,UserService
survived,"def delete_user_alert(user_id: str, notification_id: str) -> bool:
    """"""
    Delete an alert.
    
    Args:
        user_id: The ID of the user
        notification_id: The ID of the notification
        
    Returns:
        True if the alert was deleted, False otherwise
    """"""
    return delete_notification(user_id, notification_id)
",codebase-architectures/atomic-composable-architecture/capabilities/alerting.py,
survived,"    def _view_file(self, path: str, view_range=None) -> FileOperationResult:
        """"""
        View the contents of a file.

        Args:
            path: The path to the file to view
            view_range: Optional start and end lines to view [start, end]

        Returns:
            FileOperationResult with content or error message
        """"""
        try:
            # Normalize the path
            path = normalize_path(path)

            if not os.path.exists(path):
                error_msg = f""File {path} does not exist""
                console.log(f""[view_file] Error: {error_msg}"")
                return FileOperationResult(False, error_msg)

            with open(path, ""r"") as f:
                lines = f.readlines()

            if view_range:
                start, end = view_range
                # Convert to 0-indexed for Python
                start = max(0, start - 1)
                if end == -1:
                    end = len(lines)
                else:
                    end = min(len(lines), end)
                lines = lines[start:end]

            content = """".join(lines)

            # Display the file content (only for console, not returned to Claude)
            display_file_content(path, content)

            return FileOperationResult(True, f""Successfully viewed file {path}"", content)
        except Exception as e:
            error_msg = f""Error viewing file: {str(e)}""
            console.print(f""[red]{error_msg}[/red]"")
            console.log(f""[view_file] Error: {str(e)}"")
            console.log(traceback.format_exc())
            return FileOperationResult(False, error_msg)
",example-agent-codebase-arch/pipeline-architecture/steps/processing_stage.py,ProcessingStage
survived,"def display_token_usage(input_tokens: int, output_tokens: int) -> None:
    """"""
    Display token usage in a table.

    Args:
        input_tokens: Number of input tokens used
        output_tokens: Number of output tokens used
    """"""
    table = Table(title=""Token Usage"")
    table.add_column(""Type"", style=""cyan"")
    table.add_column(""Count"", style=""green"")
    
    table.add_row(""Input Tokens"", str(input_tokens))
    table.add_row(""Output Tokens"", str(output_tokens))
    table.add_row(""Total Tokens"", str(input_tokens + output_tokens))
    
    console.print(table)
",example-agent-codebase-arch/atomic-composable-architecture/main.py,
survived,"    def str_replace(path: str, old_str: str, new_str: str) -> FileOperationResult:
        """"""
        Replace a specific string in a file.

        Args:
            path: The path to the file to modify
            old_str: The text to replace
            new_str: The new text to insert

        Returns:
            FileOperationResult with result or error message
        """"""
        try:
            # Normalize the path
            path = normalize_path(path)

            if not os.path.exists(path):
                error_msg = f""File {path} does not exist""
                console.log(f""[str_replace] Error: {error_msg}"")
                return FileOperationResult(False, error_msg)

            with open(path, ""r"") as f:
                content = f.read()

            if old_str not in content:
                error_msg = f""The specified string was not found in the file {path}""
                console.log(f""[str_replace] Error: {error_msg}"")
                return FileOperationResult(False, error_msg)

            new_content = content.replace(old_str, new_str, 1)

            with open(path, ""w"") as f:
                f.write(new_content)

            console.print(f""[green]Successfully replaced text in {path}[/green]"")
            console.log(f""[str_replace] Successfully replaced text in {path}"")
            return FileOperationResult(True, f""Successfully replaced text in {path}"")
        except Exception as e:
            error_msg = f""Error replacing text: {str(e)}""
            console.print(f""[red]{error_msg}[/red]"")
            console.log(f""[str_replace] Error: {str(e)}"")
            console.log(traceback.format_exc())
            return FileOperationResult(False, error_msg)
",example-agent-codebase-arch/vertical-slice-architecture/features/file_operations/service.py,FileOperationService
survived,"    def __init__(self, command: str, path: str = None, **kwargs):
        """"""
        Initialize a tool use request.
        
        Args:
            command: The command to execute
            path: The path to operate on
            **kwargs: Additional arguments for the command
        """"""
        self.command = command
        self.path = path
        self.kwargs = kwargs
",example-agent-codebase-arch/layered-architecture/models/tool_models.py,ToolUseRequest
survived,"    def view_file(path: str, view_range=None) -> FileOperationResult:
        """"""
        View the contents of a file.

        Args:
            path: The path to the file to view
            view_range: Optional start and end lines to view [start, end]

        Returns:
            FileOperationResult with content or error message
        """"""
        try:
            # Normalize the path
            path = normalize_path(path)

            if not os.path.exists(path):
                error_msg = f""File {path} does not exist""
                Logger.error(app_logger, f""[view_file] {error_msg}"")
                return FileOperationResult(False, error_msg)

            with open(path, ""r"") as f:
                lines = f.readlines()

            if view_range:
                start, end = view_range
                # Convert to 0-indexed for Python
                start = max(0, start - 1)
                if end == -1:
                    end = len(lines)
                else:
                    end = min(len(lines), end)
                lines = lines[start:end]

            content = """".join(lines)

            # Display the file content (only for console, not returned to Claude)
            display_file_content(path, content)

            return FileOperationResult(True, f""Successfully viewed file {path}"", content)
        except Exception as e:
            error_msg = f""Error viewing file: {str(e)}""
            Logger.error(app_logger, f""[view_file] {error_msg}"", exc_info=True)
            return FileOperationResult(False, error_msg)
",example-agent-codebase-arch/layered-architecture/services/file_service.py,FileService
deleted,"def ensure_directory_exists(path: str) -> None:
    """"""
    Ensure that the directory for a file path exists.
    Creates the directory if it doesn't exist.

    Args:
        path: The path to check
    """"""
    directory = os.path.dirname(path)
    if directory and not os.path.exists(directory):
        os.makedirs(directory)
",example-agent-codebase-arch/atomic-composable-architecture/atom/path_utils.py,
deleted,"def get_file_extension(path: str) -> str:
    """"""
    Get the file extension from a path.

    Args:
        path: The path to get the extension from

    Returns:
        The file extension without the dot
    """"""
    return os.path.splitext(path)[1][1:]
",example-agent-codebase-arch/atomic-composable-architecture/atom/path_utils.py,
survived,"    def __init__(self, command: str, path: str = None, **kwargs):
        """"""
        Initialize a tool use request.
        
        Args:
            command: The command to execute
            path: The path to operate on
            **kwargs: Additional arguments for the command
        """"""
        self.command = command
        self.path = path
        self.kwargs = kwargs
",example-agent-codebase-arch/pipeline-architecture/shared/utilities.py,ToolUseRequest
survived,"def main():
    """"""Main entry point for the application.""""""
    # Set up argument parser
    parser = argparse.ArgumentParser(description=""Claude 3.7 File Editor Agent"")
    parser.add_argument(
        ""--prompt"",
        ""-p"",
        required=True,
        help=""The prompt for what file operations to perform"",
    )
    parser.add_argument(
        ""--max-loops"",
        ""-l"",
        type=int,
        default=15,
        help=""Maximum number of tool use loops (default: 15)"",
    )
    parser.add_argument(
        ""--thinking"",
        ""-t"",
        type=int,
        default=DEFAULT_THINKING_TOKENS,
        help=f""Maximum thinking tokens (default: {DEFAULT_THINKING_TOKENS})"",
    )
    parser.add_argument(
        ""--efficiency"",
        ""-e"",
        action=""store_true"",
        help=""Enable token-efficient tool use (beta feature)"",
    )
    args = parser.parse_args()

    console.print(Panel.fit(""Claude 3.7 File Editor Agent (Layered Architecture)""))
    console.print(f""\n[bold]Prompt:[/bold] {args.prompt}\n"")
    console.print(f""[dim]Thinking tokens: {args.thinking}[/dim]"")
    console.print(f""[dim]Max loops: {args.max_loops}[/dim]"")
    
    if args.efficiency:
        console.print(f""[dim]Token-efficient tools: Enabled[/dim]\n"")
    else:
        console.print(f""[dim]Token-efficient tools: Disabled[/dim]\n"")

    # For testing purposes, we'll just print a success message
    console.print(""[green]Successfully loaded the Layered Architecture implementation![/green]"")
    console.print(""[yellow]This is a mock implementation for testing the architecture structure.[/yellow]"")
    console.print(""[yellow]In a real implementation, this would connect to the Claude API.[/yellow]"")

    # Display mock token usage
    display_token_usage(1000, 500)
",example-agent-codebase-arch/layered-architecture/main.py,
survived,"def normalize_path(path: str) -> str:
    """"""
    Normalize file paths to handle various formats (absolute, relative, Windows paths, etc.)

    Args:
        path: The path to normalize

    Returns:
        The normalized path
    """"""
    if not path:
        return path

    # Handle Windows backslash paths if provided
    path = path.replace(""\\"", os.sep)

    is_windows_path = False
    if os.name == ""nt"" and len(path) > 1 and path[1] == "":"":
        is_windows_path = True

    # Handle /repo/ paths from Claude (tool use convention)
    if path.startswith(""/repo/""):
        path = os.path.join(os.getcwd(), path[6:])
        return path

    if path.startswith(""/""):
        # Handle case when Claude provides paths with leading slash
        if path == ""/"" or path == ""/."":
            # Special case for root directory
            path = os.getcwd()
        else:
            # Replace leading slash with current working directory
            path = os.path.join(os.getcwd(), path[1:])
    elif path.startswith(""./""):
        # Handle relative paths starting with ./
        path = os.path.join(os.getcwd(), path[2:])
    elif not os.path.isabs(path) and not is_windows_path:
        # For non-absolute paths that aren't Windows paths either
        path = os.path.join(os.getcwd(), path)

    return path
",example-agent-codebase-arch/atomic-composable-architecture/atom/path_utils.py,
survived,"    def to_dict(self) -> Dict[str, Any]:
        """"""
        Convert the result to a dictionary.
        
        Returns:
            Dictionary representation of the result
        """"""
        return {
            ""success"": self.success,
            ""message"": self.message,
            ""data"": self.data
        }
",example-agent-codebase-arch/layered-architecture/models/tool_models.py,FileOperationResult
survived,"def test_create_folder_structure_handles_spaces_and_dashes_with_slash():
    with tempfile.TemporaryDirectory() as temp_dir:
        os.chdir(temp_dir)
        folder_path, folder_name, class_name = create_folder_structure(""My Cool-Project/"")
        
        assert folder_name == ""my_cool_project""
        assert class_name == ""MyCoolProject""
        assert folder_path.name == ""my_cool_project""
        assert folder_path.exists()
",tests/cli/test_create_crew.py,
survived,"        def step_1(self):
            self.state.counter = 1
            self.state.message = ""Step 1""
",tests/test_flow_persistence.py,MultiStepFlow
survived,"def test_structured_state_persistence(tmp_path):
    """"""Test persistence with Pydantic model state.""""""
    db_path = os.path.join(tmp_path, ""test_flows.db"")
    persistence = SQLiteFlowPersistence(db_path)
    
    class StructuredFlow(Flow[TestState]):
        initial_state = TestState
        
        @start()
        @persist(persistence)
        def count_up(self):
            self.state.counter += 1
            self.state.message = f""Count is {self.state.counter}""
    
    # Run flow and verify state changes are saved
    flow = StructuredFlow(persistence=persistence)
    flow.kickoff()
    
    # Load and verify state
    saved_state = persistence.load_state(flow.state.id)
    assert saved_state is not None
    assert saved_state[""counter""] == 1
    assert saved_state[""message""] == ""Count is 1""
",tests/test_flow_persistence.py,
survived,"    def decorator(method: Callable[..., T]) -> Callable[..., T]:
        """"""Decorator that handles both sync and async methods.""""""
        if asyncio.iscoroutinefunction(method):
            @functools.wraps(method)
            async def async_wrapper(flow_instance: Any, *args: Any, **kwargs: Any) -> T:
                # Execute the original async method
                result = await method(flow_instance, *args, **kwargs)
                # Persist state after method completion
                _persist_state(flow_instance, method.__name__)
                return result
            return cast(Callable[..., T], async_wrapper)
        else:
            @functools.wraps(method)
            def sync_wrapper(flow_instance: Any, *args: Any, **kwargs: Any) -> T:
                # Execute the original sync method
                result = method(flow_instance, *args, **kwargs)
                # Persist state after method completion
                _persist_state(flow_instance, method.__name__)
                return result
            return cast(Callable[..., T], sync_wrapper)
",src/crewai/flow/persistence/decorators.py,
survived,"def test_xai_create_with_completion():
    """"""Test that create_with_completion works with XAI provider""""""
    client = instructor.from_provider(""xai/grok-3-mini"", mode=instructor.Mode.XAI_JSON)
    
    user, raw_response = client.chat.completions.create_with_completion(
        response_model=User,
        messages=[
            {
                ""role"": ""system"",
                ""content"": ""You are a helpful assistant that extracts information."",
            },
            {
                ""role"": ""user"",
                ""content"": ""Extract: Jason is 25 years old."",
            },
        ],
    )
    
    assert isinstance(user, User)
    assert user.name.lower() == ""jason""
    assert user.age == 25
    assert hasattr(user, ""_raw_response""), (
        ""The raw response should be available from XAI""
    )
    assert raw_response is not None
    assert user._raw_response == raw_response
",tests/llm/test_xai/test_raw_response.py,
survived,"def mock_knowledge_source():
    """"""Create a mock knowledge source with test content.""""""
    content = """"""
    Important context about AI:
    1. AI systems use machine learning algorithms
    2. Neural networks are a key component
    3. Training data is essential for good performance
    """"""
    return StringKnowledgeSource(content=content)
",tests/utilities/test_knowledge_planning.py,
survived,"    def call(
        self,
        messages: Union[str, List[Dict[str, str]]],
        tools: Optional[List[dict]] = None,
        callbacks: Optional[List[Any]] = None,
        available_functions: Optional[Dict[str, Any]] = None,
    ) -> Union[str, Any]:
        self.calls.append({
            ""messages"": messages, 
            ""tools"": tools,
            ""callbacks"": callbacks,
            ""available_functions"": available_functions
        })
        # In a real implementation, this would use the JWT token to authenticate
        # with an external service
        return ""Response from JWT-authenticated LLM""
",tests/custom_llm_test.py,JWTAuthLLM
survived,"    def get_context_window_size(self) -> int:
        """"""Return a default context window size.""""""
        return 8192
",tests/custom_llm_test.py,CustomLLM
