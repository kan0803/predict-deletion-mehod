status,method,filepath,class_name
survived,"def test_keyword_only_param_removed():
    old_code = ""def func(*, a, b): pass""
    new_code = ""def func(*, b): pass""

    old_tree = ast.parse(old_code)
    new_tree = ast.parse(new_code)
    errors = check_signature_compatibility(old_tree.body[0], new_tree.body[0])

    assert len(errors) == 1
    assert errors[0].message == ""Keyword-only param 'a' was removed.""
    assert errors[0].param_name == ""a""
",tests/dev/test_check_function_signatures.py,
survived,"def test_new_optional_keyword_only_allowed():
    old_code = ""def func(*, a): pass""
    new_code = ""def func(*, a, b=1): pass""

    old_tree = ast.parse(old_code)
    new_tree = ast.parse(new_code)
    errors = check_signature_compatibility(old_tree.body[0], new_tree.body[0])

    assert len(errors) == 0
",tests/dev/test_check_function_signatures.py,
survived,"def main():
    args = parse_args()
    errors = compare_signatures(args.base_branch)
    for error in errors:
        print(error.format(github=is_github_actions()))
",dev/check_function_signatures.py,
survived,"def set_current_op():
    global current_fullscreen_op
    data = request.json
    current_fullscreen_op = data.get(""uuid"")
    return jsonify(
        {""status"": ""Current op set successfully"", ""uuid"": current_fullscreen_op}
    )
",triton_viz/visualizer/interface.py,
survived,"def run_flask_with_cloudflared():
    cloudflared_port = 8000  # You can change this port if needed
    tunnel_url = _run_cloudflared(cloudflared_port, 8001)  # not too important
    print(f""Cloudflare tunnel URL: {tunnel_url}"")
    app.run(port=cloudflared_port)
",triton_viz/visualizer/interface.py,
deleted,"def prepare_visualization_data(program_records, tensor_table):
    """"""Prepare visualization data for the frntend and raw tensor data for the server.""""""
    # global idx
    visualization_data = []
    raw_tensor_data = {}
    for record in program_records:
        record_uuid = str(uuid.uuid4())[:8]

        if isinstance(record, ExpandDims):
            print(record.input_shape, record.output_shape, record.index)
        if isinstance(record, Dot):
            visualization_data.append(
                {
                    ""type"": ""Dot"",
                    ""input_shape"": record.input_shape,
                    ""other_shape"": record.other_shape,
                    ""output_shape"": record.output_shape,
                    ""uuid"": record_uuid,
                }
            )

            raw_tensor_data[record_uuid] = {
                ""input_data"": torch.tensor(record.input_data),
                ""other_data"": torch.tensor(record.other_data),
                ""intermediate_results"": record.intermediate_results,
            }

        elif isinstance(record, Load):
            global_tensor, slice_tensor = tensor_table[record.ptr]
            print(global_tensor)
            global_coords, slice_coords = extract_load_coords(record, global_tensor)

            visualization_data.append(
                {
                    ""type"": ""Load"",
                    ""global_shape"": global_tensor.shape,
                    ""slice_shape"": record.masks.shape,
                    ""global_coords"": global_coords,
                    ""slice_coords"": slice_coords,
                    ""uuid"": record_uuid,
                }
            )

            raw_tensor_data[record_uuid] = {
                ""global_tensor"": global_tensor.data.cpu(),  # Ensure it's on CPU
                ""dims"": len(global_tensor.data.cpu().shape),
            }
            print(record.masks.shape)

        elif isinstance(record, Store):
            global_tensor, slice_tensor = tensor_table[record.ptr]

            global_coords, slice_coords = extract_load_coords(record, global_tensor)

            visualization_data.append(
                {
                    ""type"": ""Store"",
                    ""global_shape"": global_tensor.shape,
                    ""slice_shape"": record.masks.shape,
                    ""global_coords"": global_coords,
                    ""slice_coords"": slice_coords,
                    ""uuid"": record_uuid,
                }
            )

    return visualization_data, raw_tensor_data, """"
",triton_viz/visualizer/draw.py,
survived,"    def test_rolling_1d_array_raises_error(self, move_func):
        """"""Test that 1D arrays raise an appropriate error for rolling functions.""""""
        data_1d = np.array([1, 2, 3, 4, 5], dtype=np.float64)

        with pytest.raises(ValueError, match=""requires at least a 2D array""):
            move_func(data_1d, window=3)
",numbagg/test/test_matrix_functions.py,TestMatrixFunctions
survived,"    def gufunc(self, *, target):
        vectorize = numba.guvectorize(
            *self.signature,
            nopython=True,
            target=target,
            cache=self.cache,
            fastmath=_FASTMATH,
        )
        return vectorize(self.func)
",numbagg/decorators.py,ndmovematrix
survived,"    def test_correlation_with_nans(self):
        """"""Test correlation consistency with NaN values.""""""
        np.random.seed(789)

        # Create two time series with some NaN values
        n_obs = 30
        a1 = np.random.randn(n_obs)
        a2 = np.random.randn(n_obs) * 1.2 + 0.3

        # Add some NaN values
        a1[3:6] = np.nan
        a2[12:15] = np.nan

        alpha = 0.4

        # Compute using non-matrix function
        corr_nonmatrix = move_exp_nancorr(a1, a2, alpha=alpha)

        # Compute using matrix function
        data_matrix = np.array([a1, a2])
        corr_matrix_result = move_exp_nancorrmatrix(data_matrix, alpha=alpha)
        corr_from_matrix = corr_matrix_result[:, 0, 1]

        # They should match
        assert_allclose(corr_nonmatrix, corr_from_matrix, rtol=1e-10)
",numbagg/test/test_move_exp_matrix_consistency.py,TestMoveExpMatrixConsistency
survived,"    def test_covariance_consistency(self, alpha):
        """"""Test that move_exp_nancovmatrix matches move_exp_nancov for pairs.""""""
        np.random.seed(42)

        # Create two time series
        n_obs = 50
        a1 = np.random.randn(n_obs)
        a2 = np.random.randn(n_obs) * 2 + 1

        # Compute using non-matrix function
        cov_nonmatrix = move_exp_nancov(a1, a2, alpha=alpha)

        # Compute using matrix function
        data_matrix = np.array([a1, a2])
        cov_matrix_result = move_exp_nancovmatrix(data_matrix, alpha=alpha)

        # Extract the off-diagonal element (covariance between a1 and a2)
        cov_from_matrix = cov_matrix_result[:, 0, 1]

        # They should match
        assert_allclose(cov_nonmatrix, cov_from_matrix, rtol=1e-10)

        # Also check symmetry - (0,1) should equal (1,0)
        assert_allclose(
            cov_matrix_result[:, 0, 1], cov_matrix_result[:, 1, 0], rtol=1e-10
        )
",numbagg/test/test_move_exp_matrix_consistency.py,TestMoveExpMatrixConsistency
survived,"    def test_min_weight_consistency(self):
        """"""Test consistency with different min_weight values.""""""
        np.random.seed(111)

        # Create two time series
        n_obs = 25
        a1 = np.random.randn(n_obs)
        a2 = np.random.randn(n_obs) * 1.3

        alpha = 0.2  # Low alpha to test min_weight effects
        min_weight = 0.5

        # Compute using non-matrix functions
        cov_nonmatrix = move_exp_nancov(a1, a2, alpha=alpha, min_weight=min_weight)
        corr_nonmatrix = move_exp_nancorr(a1, a2, alpha=alpha, min_weight=min_weight)

        # Compute using matrix functions
        data_matrix = np.array([a1, a2])
        cov_matrix_result = move_exp_nancovmatrix(
            data_matrix, alpha=alpha, min_weight=min_weight
        )
        corr_matrix_result = move_exp_nancorrmatrix(
            data_matrix, alpha=alpha, min_weight=min_weight
        )

        # Extract off-diagonal elements
        cov_from_matrix = cov_matrix_result[:, 0, 1]
        corr_from_matrix = corr_matrix_result[:, 0, 1]

        # They should match
        assert_allclose(cov_nonmatrix, cov_from_matrix, rtol=1e-10)
        assert_allclose(corr_nonmatrix, corr_from_matrix, rtol=1e-10)
",numbagg/test/test_move_exp_matrix_consistency.py,TestMoveExpMatrixConsistency
survived,"    def test_init(self):
        """"""Test generator initialization""""""
        assert self.generator.base_path == self.temp_dir
        assert isinstance(self.generator.default_prompts, dict)
        assert isinstance(self.generator.task_templates, dict)
        assert 'model' in self.generator.default_prompts
        assert 'add_type_hints' in self.generator.task_templates
",tests/test_scan/test_generate_parallel.py,TestParallelYAMLGenerator
survived,"    def test_list_all_models(self, temp_model_dir):
        """"""Test listing all models""""""
        scanner = ModelScanner(temp_model_dir)
        
        models = scanner.list_all_models()
        assert len(models) >= 3  # We created 3 models
        
        # Check model info structure
        for model in models:
            assert 'name' in model
            assert 'provider' in model
            assert 'category' in model
            assert 'file_count' in model
            assert 'files' in model
",tests/test_scan/test_scanner.py,TestModelScanner
survived,"    def __init__(self, base_path: Path):
        self.base_path = Path(base_path)
        
        # Default prompts for different file types and patterns
        self.default_prompts = {
            'model': {
                'validation': ""Add comprehensive validation methods with type hints and error handling"",
                'optimization': ""Optimize model inference performance and add caching"",
                'documentation': ""Add detailed docstrings and usage examples"",
                'testing': ""Implement unit tests with various edge cases"",
                'refactoring': ""Refactor for better maintainability and code organization""
            },
            'api': {
                'endpoints': ""Implement RESTful CRUD endpoints with proper error handling"",
                'authentication': ""Add JWT authentication and authorization"",
                'validation': ""Add request/response validation with schemas"",
                'documentation': ""Add OpenAPI/Swagger documentation"",
                'rate_limiting': ""Implement rate limiting and request throttling""
            },
            'utils': {
                'type_hints': ""Add comprehensive type hints to all functions"",
                'error_handling': ""Implement robust error handling and logging"",
                'optimization': ""Optimize performance for large-scale operations"",
                'documentation': ""Add detailed docstrings with examples"",
                'testing': ""Create comprehensive unit tests""
            },
            'config': {
                'validation': ""Add configuration validation and type checking"",
                'environment': ""Implement environment-specific configurations"",
                'documentation': ""Document all configuration options"",
                'defaults': ""Add sensible defaults with overrides"",
                'schema': ""Create configuration schema validation""
            },
            'service': {
                'implementation': ""Implement core service functionality with error handling"",
                'dependency_injection': ""Add dependency injection patterns"",
                'async': ""Convert to async/await for better performance"",
                'monitoring': ""Add monitoring and metrics collection"",
                'testing': ""Implement integration and unit tests""
            }
        }
        
        # Task templates for common scenarios
        self.task_templates = {
            'add_type_hints': ""Add comprehensive type hints to all functions and methods"",
            'add_validation': ""Implement input validation and error handling"",
            'add_tests': ""Create unit tests with pytest covering edge cases"",
            'add_docs': ""Add detailed docstrings following Google style guide"",
            'refactor': ""Refactor for better readability and maintainability"",
            'optimize': ""Optimize performance and reduce computational complexity"",
            'security': ""Implement security best practices and input sanitization"",
            'async_conversion': ""Convert synchronous code to async/await pattern"",
            'error_handling': ""Add comprehensive error handling and logging"",
            'api_implementation': ""Implement RESTful API endpoints with validation""
        }
",src/haconiwa/scan/generate_parallel.py,ParallelYAMLGenerator
survived,"    def _dict_to_text(self, data: Dict[str, Any], indent: int = 0) -> str:
        """"""Convert dictionary to formatted text""""""
        lines = []
        indent_str = ""  "" * indent
        
        for key, value in data.items():
            if isinstance(value, dict):
                lines.append(f""{indent_str}{key}:"")
                lines.append(self._dict_to_text(value, indent + 1))
            elif isinstance(value, list):
                lines.append(f""{indent_str}{key}:"")
                for item in value:
                    if isinstance(item, dict):
                        lines.append(self._dict_to_text(item, indent + 1))
                    else:
                        lines.append(f""{indent_str}  - {item}"")
            else:
                lines.append(f""{indent_str}{key}: {value}"")
        
        return ""\n"".join(lines)
",src/haconiwa/scan/formatter.py,OutputFormatter
survived,"def list_models(
    path: Optional[Path] = typer.Option(None, ""--path"", ""-p"", help=""Base path to search in""),
    category: Optional[str] = typer.Option(None, ""--category"", help=""Filter by category""),
    provider: Optional[str] = typer.Option(None, ""--provider"", help=""Filter by provider""),
    output_format: str = typer.Option(""table"", ""--format"", ""-f"", help=""Output format"")
):
    """"""List all available AI models""""""
    scanner = ModelScanner(base_path=path or Path.cwd())
    
    models = scanner.list_all_models(
        category=category,
        provider=provider
    )
    
    formatter = OutputFormatter()
    output = formatter.format_model_list(models, output_format)
    typer.echo(output)
",src/haconiwa/scan/cli.py,
survived,"def generate_parallel_config(
    source: Optional[str] = typer.Option(None, ""--source"", ""-s"", 
                                        help=""Source: 'last-search', 'model:name', or file path""),
    action: str = typer.Option(""refactor"", ""--action"", ""-a"",
                              help=""Action type: refactor, add_type_hints, add_tests, etc.""),
    max_files: int = typer.Option(10, ""--max-files"", ""-m"", help=""Maximum number of files""),
    output: Path = typer.Option(""parallel-dev.yaml"", ""--output"", ""-o"", help=""Output YAML file""),
    example: bool = typer.Option(False, ""--example"", help=""Generate example YAML""),
    migration: Optional[List[str]] = typer.Option(None, ""--migration"",
                                                  help=""Generate migration YAML (old:new)""),
    pattern_fix: Optional[List[str]] = typer.Option(None, ""--pattern-fix"",
                                                    help=""Fix pattern (pattern:description)""),
    project_wide: Optional[str] = typer.Option(None, ""--project-wide"",
                                              help=""Generate project-wide changes for file pattern""),
    exclude: Optional[List[str]] = typer.Option(None, ""--exclude"", ""-e"",
                                               help=""Exclude patterns for project-wide""),
    prompt_file: Optional[Path] = typer.Option(None, ""--prompt-file"",
                                              help=""File with custom prompts (file:prompt per line)"")
):
    """"""Generate parallel development configuration YAML from scan results""""""
    
    generator = ParallelYAMLGenerator(base_path=Path.cwd())
    
    # Handle different generation modes
    if example:
        # Generate example YAML
        config = generator.create_example_yaml()
        typer.echo(""ðŸ“ Generated example parallel-dev.yaml"")
    
    elif migration and len(migration) == 1 and ':' in migration[0]:
        # Migration mode
        old_model, new_model = migration[0].split(':', 1)
        scanner = ModelScanner(base_path=Path.cwd())
        
        # Find files containing old model
        results = scanner.search_by_model_name(old_model)
        files = []
        for category, file_list in results['matches'].items():
            for file_info in file_list:
                files.append(file_info['path'])
                if len(files) >= max_files:
                    break
        
        config = generator.generate_for_model_migration(old_model, new_model, files)
        typer.echo(f""ðŸ”„ Generated migration YAML: {old_model} â†’ {new_model}"")
    
    elif pattern_fix and len(pattern_fix) == 1 and ':' in pattern_fix[0]:
        # Pattern fix mode
        pattern, description = pattern_fix[0].split(':', 1)
        scanner = ModelScanner(base_path=Path.cwd())
        
        # Find files containing pattern
        results = scanner.search_content(pattern)
        files = [match['file'] for match in results['matches'][:max_files]]
        
        config = generator.generate_for_pattern_fix(pattern, description, files)
        typer.echo(f""ðŸ”§ Generated pattern fix YAML for: {pattern}"")
    
    elif project_wide:
        # Project-wide mode
        config = generator.generate_project_wide(
            action=action,
            file_pattern=project_wide,
            exclude_patterns=exclude
        )
        typer.echo(f""ðŸŒ Generated project-wide YAML for: {project_wide}"")
    
    else:
        # Standard mode - from search results or model name
        custom_prompts = {}
        if prompt_file and prompt_file.exists():
            # Load custom prompts
            for line in prompt_file.read_text().splitlines():
                if ':' in line:
                    file_path, prompt = line.split(':', 1)
                    custom_prompts[file_path.strip()] = prompt.strip()
        
        if source and source.startswith('model:'):
            # Search for specific model
            model_name = source[6:]
            scanner = ModelScanner(base_path=Path.cwd())
            scan_results = scanner.search_by_model_name(model_name)
        elif source and Path(source).exists():
            # Load from file
            source_path = Path(source)
            if source_path.suffix in ['.json', '.yaml', '.yml']:
                with open(source_path, 'r') as f:
                    if source_path.suffix == '.json':
                        scan_results = json.load(f)
                    else:
                        scan_results = yaml.safe_load(f)
            else:
                typer.echo(""Error: Source file must be JSON or YAML"", err=True)
                raise typer.Exit(1)
        else:
            # Try to use last search results (would need to implement caching)
            typer.echo(""ðŸ“ Using current directory analysis..."")
            analyzer = ModelAnalyzer(base_path=Path.cwd())
            scan_results = analyzer.analyze_directory()
        
        config = generator.generate_from_scan_results(
            scan_results,
            action=action,
            max_files=max_files,
            custom_prompts=custom_prompts
        )
        typer.echo(f""âœ¨ Generated parallel-dev YAML with {len(config['tasks'])} tasks"")
    
    # Save YAML file
    saved_path = generator.save_yaml(config, output)
    typer.echo(f""ðŸ’¾ Saved to: {saved_path}"")
    
    # Show preview
    typer.echo(""\nðŸ“‹ Preview:"")
    typer.echo(f""Provider: {config['provider']}"")
    typer.echo(f""Total tasks: {len(config['tasks'])}"")
    if config['tasks']:
        typer.echo(""\nFirst 3 tasks:"")
        for i, task in enumerate(config['tasks'][:3], 1):
            typer.echo(f""{i}. {task['file']}"")
            typer.echo(f""   â†’ {task['prompt'][:80]}{'...' if len(task['prompt']) > 80 else ''}"")
    
    typer.echo(f""\nâœ… Generated YAML file is ready: {output}"")
",src/haconiwa/scan/cli.py,
survived,"    def _get_timestamp(self) -> str:
        """"""Get current timestamp""""""
        from datetime import datetime
        return datetime.now().isoformat()",src/haconiwa/scan/comparator.py,ModelComparator
survived,"    def test_create_example_yaml(self):
        """"""Test example YAML generation""""""
        config = self.generator.create_example_yaml()
        
        assert config['provider'] == 'claude'
        assert 'metadata' in config
        assert config['metadata']['source'] == 'haconiwa scan generate-parallel'
        assert 'tasks' in config
        assert len(config['tasks']) == 5
        assert config['tasks'][0]['file'] == 'src/models/user.py'
        assert config['tasks'][0]['prompt'] == 'Add validation methods and type hints'
        assert 'options' in config
        assert config['options']['max_concurrent'] == 3
        assert config['options']['timeout'] == 90
        assert 'Read' in config['options']['allowed_tools']
",tests/test_scan/test_generate_parallel.py,TestParallelYAMLGenerator
survived,"    def test_scan_model_with_options(self, runner, temp_model_dir):
        """"""Test scan model with various options""""""
        # Test with content inclusion
        result = runner.invoke(
            scan_app,
            [""model"", ""o1-mini"", ""--path"", str(temp_model_dir), ""--content"", ""--format"", ""yaml""]
        )
        
        assert result.exit_code == 0
        assert ""model_name: o1-mini"" in result.stdout
        
        # Test with no prefix stripping
        result = runner.invoke(
            scan_app,
            [""model"", ""o1-mini"", ""--path"", str(temp_model_dir), ""--no-strip-prefix""]
        )
        
        assert result.exit_code == 0
",tests/test_scan/test_cli.py,TestScanCLI
survived,"    def test_scan_list_with_filters(self, runner, temp_model_dir):
        """"""Test list with provider and category filters""""""
        result = runner.invoke(
            scan_app,
            [""list"", ""--path"", str(temp_model_dir), ""--provider"", ""unknown"", ""--format"", ""json""]
        )
        
        assert result.exit_code == 0
        output = json.loads(result.stdout)
        assert isinstance(output, list)
",tests/test_scan/test_cli.py,TestScanCLI
survived,"    def _extract_model_name(self, path: Path) -> str:
        """"""Extract model name from path""""""
        # Try to extract from common patterns
        path_parts = path.parts
        
        for part in reversed(path_parts):
            if any(prefix in part.lower() for prefix in self.model_prefixes):
                return part
            if 'model' in part.lower() and len(part) > 5:
                return part
        
        return path.name
",src/haconiwa/scan/scanner.py,ModelScanner
survived,"    def test_file_info_with_content(self, temp_model_dir):
        """"""Test getting file info with content""""""
        scanner = ModelScanner(temp_model_dir)
        
        results = scanner.search_by_model_name(""gpt-4"", include_content=True)
        
        # Find the example.py file in results
        example_file = None
        for files in results['matches'].values():
            for f in files:
                if f['name'] == 'example.py':
                    example_file = f
                    break
        
        assert example_file is not None
        assert 'content' in example_file
        assert 'import openai' in example_file['content']
",tests/test_scan/test_scanner.py,TestModelScanner
survived,"    def _extract_provider(self, path: Path) -> str:
        """"""Extract provider name from path""""""
        providers = {
            'openai': ['openai', 'gpt'],
            'anthropic': ['anthropic', 'claude'],
            'meta': ['meta', 'llama', 'facebook'],
            'google': ['google', 'gemini', 'palm', 'bard'],
            'mistral': ['mistral'],
            'huggingface': ['huggingface', 'hf'],
            'microsoft': ['microsoft', 'azure'],
            'amazon': ['amazon', 'aws', 'bedrock']
        }
        
        path_str = str(path).lower()
        
        for provider, keywords in providers.items():
            if any(keyword in path_str for keyword in keywords):
                return provider
        
        return 'unknown'",src/haconiwa/scan/scanner.py,ModelScanner
survived,"    def compare(self, models: List[str], aspects: List[str]) -> Dict[str, Any]:
        """"""Compare multiple models across specified aspects""""""
        comparison = {
            'models': models,
            'timestamp': self._get_timestamp(),
            'results': {}
        }
        
        # Load model information
        model_data = {}
        for model in models:
            model_info = self._load_model_info(model)
            if model_info:
                model_data[model] = model_info
        
        # Compare across requested aspects
        for aspect in aspects:
            if aspect in self.aspects:
                comparison['results'][aspect] = self.aspects[aspect](model_data)
        
        return comparison['results']
",src/haconiwa/scan/comparator.py,ModelComparator
survived,"    def test_comparison_with_numpy(self, func):
        """"""Compare with numpy's implementation for data without NaNs.""""""
        np.random.seed(42)
        data = np.random.randn(5, 100)

        result = func(data)
        if func == nancorrmatrix:
            expected = np.corrcoef(data)
        else:
            expected = np.cov(data)

        assert_allclose(result, expected, rtol=1e-10)
",numbagg/test/test_matrix_functions.py,TestCorrelationCovarianceMatrices
survived,"    def test_fixed_dimensional_conventions(self):
        """"""Test fixed dimensional conventions: (..., vars, obs) -> (..., vars, vars).""""""
        np.random.seed(42)

        # Basic test: (vars, obs) -> (vars, vars)
        data = np.random.randn(3, 100)  # (vars, obs)
        corr_result = nancorrmatrix(data)
        cov_result = nancovmatrix(data)

        assert corr_result.shape == (3, 3)
        assert cov_result.shape == (3, 3)

        # Broadcasting test: (batch, vars, obs) -> (batch, vars, vars)
        data_3d = np.random.randn(2, 3, 100)  # (batch, vars, obs)
        corr_3d = nancorrmatrix(data_3d)
        cov_3d = nancovmatrix(data_3d)

        assert corr_3d.shape == (2, 3, 3)
        assert cov_3d.shape == (2, 3, 3)
",numbagg/test/test_matrix_functions.py,TestCorrelationCovarianceMatrices
survived,"    def test_with_nans(self, func):
        """"""Test with NaN values.""""""
        # Exponential moving functions expect (obs, vars) format
        data = np.array(
            [[1, 2, np.nan], [2, 4, 1], [np.nan, 6, 2], [4, np.nan, 3]],
            dtype=np.float64,
        )
        alpha = 0.3
        result = func(data, alpha=alpha)

        # Check shape
        assert result.shape == (4, 3, 3)

        # Should handle NaN gracefully - check that we get some finite values
        assert np.any(np.isfinite(result))
",numbagg/test/test_matrix_functions.py,TestExponentialMatrices
survived,"def install_mcp_json(
    file: Path,
    server_object: str | None,
    name: str,
    *,
    with_editable: Path | None = None,
    with_packages: list[str] | None = None,
    env_vars: dict[str, str] | None = None,
    copy: bool = False,
) -> bool:
    """"""Generate MCP configuration JSON for manual installation.

    Args:
        file: Path to the server file
        server_object: Optional server object name (for :object suffix)
        name: Name for the server in MCP config
        with_editable: Optional directory to install in editable mode
        with_packages: Optional list of additional packages to install
        env_vars: Optional dictionary of environment variables
        copy: If True, copy to clipboard instead of printing to stdout

    Returns:
        True if generation was successful, False otherwise
    """"""
    try:
        # Build uv run command
        args = [""run""]

        # Collect all packages in a set to deduplicate
        packages = {""fastmcp""}
        if with_packages:
            packages.update(pkg for pkg in with_packages if pkg)

        # Add all packages with --with
        for pkg in sorted(packages):
            args.extend([""--with"", pkg])

        if with_editable:
            args.extend([""--with-editable"", str(with_editable)])

        # Build server spec from parsed components
        if server_object:
            server_spec = f""{file.resolve()}:{server_object}""
        else:
            server_spec = str(file.resolve())

        # Add fastmcp run command
        args.extend([""fastmcp"", ""run"", server_spec])

        # Build MCP server configuration
        server_config = {
            ""command"": ""uv"",
            ""args"": args,
        }

        # Add environment variables if provided
        if env_vars:
            server_config[""env""] = env_vars

        # Wrap with server name as root key
        config = {name: server_config}

        # Convert to JSON
        json_output = json.dumps(config, indent=2)

        # Handle output
        if copy:
            pyperclip.copy(json_output)
            print(f""[green]MCP configuration for '{name}' copied to clipboard[/green]"")
        else:
            # Print to stdout (for piping)
            print(json_output)

        return True

    except Exception as e:
        print(f""[red]Failed to generate MCP configuration: {e}[/red]"")
        return False
",src/fastmcp/cli/install/mcp_json.py,
survived,"def mcp_json_command(
    server_spec: str,
    *,
    server_name: Annotated[
        str | None,
        cyclopts.Parameter(
            name=[""--name"", ""-n""],
            help=""Custom name for the server in MCP config"",
        ),
    ] = None,
    with_editable: Annotated[
        Path | None,
        cyclopts.Parameter(
            name=[""--with-editable"", ""-e""],
            help=""Directory with pyproject.toml to install in editable mode"",
        ),
    ] = None,
    with_packages: Annotated[
        list[str],
        cyclopts.Parameter(
            ""--with"",
            help=""Additional packages to install"",
            negative=False,
        ),
    ] = [],
    env_vars: Annotated[
        list[str],
        cyclopts.Parameter(
            ""--env"",
            help=""Environment variables in KEY=VALUE format"",
            negative=False,
        ),
    ] = [],
    env_file: Annotated[
        Path | None,
        cyclopts.Parameter(
            ""--env-file"",
            help=""Load environment variables from .env file"",
        ),
    ] = None,
    copy: Annotated[
        bool,
        cyclopts.Parameter(
            ""--copy"",
            help=""Copy configuration to clipboard instead of printing to stdout"",
            negative=False,
        ),
    ] = False,
) -> None:
    """"""Generate MCP configuration JSON for manual installation.

    Args:
        server_spec: Python file to install, optionally with :object suffix
    """"""
    file, server_object, name, packages, env_dict = process_common_args(
        server_spec, server_name, with_packages, env_vars, env_file
    )

    success = install_mcp_json(
        file=file,
        server_object=server_object,
        name=name,
        with_editable=with_editable,
        with_packages=packages,
        env_vars=env_dict,
        copy=copy,
    )

    if not success:
        sys.exit(1)",src/fastmcp/cli/install/mcp_json.py,
survived,"def run_with_uv(
    server_spec: str,
    python_version: str | None = None,
    with_packages: list[str] | None = None,
    with_requirements: Path | None = None,
    project: Path | None = None,
    transport: TransportType | None = None,
    host: str | None = None,
    port: int | None = None,
    path: str | None = None,
    log_level: LogLevelType | None = None,
    show_banner: bool = True,
) -> None:
    """"""Run a MCP server using uv run subprocess.

    Args:
        server_spec: Python file, object specification (file:obj), or URL
        python_version: Python version to use (e.g. ""3.10"")
        with_packages: Additional packages to install
        with_requirements: Requirements file to use
        project: Run the command within the given project directory
        transport: Transport protocol to use
        host: Host to bind to when using http transport
        port: Port to bind to when using http transport
        path: Path to bind to when using http transport
        log_level: Log level
        show_banner: Whether to show the server banner
    """"""
    cmd = [""uv"", ""run""]

    # Add Python version if specified
    if python_version:
        cmd.extend([""--python"", python_version])

    # Add project if specified
    if project:
        cmd.extend([""--project"", str(project)])

    # Add fastmcp package
    cmd.extend([""--with"", ""fastmcp""])

    # Add additional packages
    if with_packages:
        for pkg in with_packages:
            if pkg:
                cmd.extend([""--with"", pkg])

    # Add requirements file
    if with_requirements:
        cmd.extend([""--with-requirements"", str(with_requirements)])

    # Add fastmcp run command
    cmd.extend([""fastmcp"", ""run"", server_spec])

    # Add transport options
    if transport:
        cmd.extend([""--transport"", transport])
    if host:
        cmd.extend([""--host"", host])
    if port:
        cmd.extend([""--port"", str(port)])
    if path:
        cmd.extend([""--path"", path])
    if log_level:
        cmd.extend([""--log-level"", log_level])
    if not show_banner:
        cmd.append(""--no-banner"")

    # Run the command
    logger.debug(f""Running command: {' '.join(cmd)}"")
    try:
        process = subprocess.run(cmd, check=True)
        sys.exit(process.returncode)
    except subprocess.CalledProcessError as e:
        logger.error(f""Failed to run server: {e}"")
        sys.exit(e.returncode)
",src/fastmcp/cli/run.py,
survived,"    def test_run_with_uv_all_options(self, mock_run):
        """"""Test run_with_uv with all options combined.""""""
        mock_run.return_value = Mock(returncode=0)

        with pytest.raises(SystemExit) as exc_info:
            run_with_uv(
                ""server.py"",
                python_version=""3.10"",
                project=Path(""/workspace""),
                with_packages=[""pandas""],
                with_requirements=Path(""reqs.txt""),
                transport=""http"",
                port=9000,
                show_banner=False,
            )

        assert exc_info.value.code == 0

        cmd = mock_run.call_args[0][0]
        expected = [
            ""uv"",
            ""run"",
            ""--python"",
            ""3.10"",
            ""--project"",
            ""/workspace"",
            ""--with"",
            ""fastmcp"",
            ""--with"",
            ""pandas"",
            ""--with-requirements"",
            ""reqs.txt"",
            ""fastmcp"",
            ""run"",
            ""server.py"",
            ""--transport"",
            ""http"",
            ""--port"",
            ""9000"",
            ""--no-banner"",
        ]
        assert cmd == expected
",tests/cli/test_run_with_uv.py,TestRunWithUv
survived,"    def test_run_with_uv_project(self, mock_run):
        """"""Test run_with_uv with project directory.""""""
        mock_run.return_value = Mock(returncode=0)
        project_path = Path(""/my/project"")

        with pytest.raises(SystemExit) as exc_info:
            run_with_uv(""server.py"", project=project_path)

        assert exc_info.value.code == 0

        cmd = mock_run.call_args[0][0]
        expected = [
            ""uv"",
            ""run"",
            ""--project"",
            ""/my/project"",
            ""--with"",
            ""fastmcp"",
            ""fastmcp"",
            ""run"",
            ""server.py"",
        ]
        assert cmd == expected
",tests/cli/test_run_with_uv.py,TestRunWithUv
survived,"    def test_project_option(self):
        """"""Test --project option for all install commands.""""""
        commands_to_test = [
            [""claude-code"", ""server.py"", ""--project"", ""/path/to/project""],
            [""claude-desktop"", ""server.py"", ""--project"", ""/path/to/project""],
            [""cursor"", ""server.py"", ""--project"", ""/path/to/project""],
            [""mcp-json"", ""server.py"", ""--project"", ""/path/to/project""],
        ]

        for cmd_args in commands_to_test:
            command, bound, _ = install_app.parse_args(cmd_args)
            assert command is not None
            assert str(bound.arguments[""project""]) == ""/path/to/project""",tests/cli/test_install.py,TestInstallCommandParsing
survived,"async def generate_base_clusters_from_conversation_summaries(
    summaries: List[ConversationSummary],
    *,
    model: BaseClusterModel,
    checkpoint_manager: Optional[CheckpointManager] = None
) -> List[Cluster]:
    """"""Generate base clusters from conversation summaries.
    
    This function groups similar summaries into initial clusters using
    the provided clustering model. Supports different clustering algorithms
    through the model interface.
    
    Args:
        summaries: List of conversation summaries to cluster
        model: Model to use for clustering (HDBSCAN, KMeans, etc.)
        checkpoint_manager: Optional checkpoint manager for caching
        
    Returns:
        List of base clusters
        
    Example:
        >>> cluster_model = ClusterModel(algorithm=""hdbscan"")
        >>> clusters = await generate_base_clusters(
        ...     summaries=conversation_summaries,
        ...     model=cluster_model,
        ...     checkpoint_manager=checkpoint_mgr
        ... )
    """"""
    logger.info(f""Starting clustering of {len(summaries)} summaries using {type(model).__name__}"")
    
    # Try to load from checkpoint
    if checkpoint_manager:
        cached = checkpoint_manager.load_checkpoint(
            model.checkpoint_filename,
            Cluster
        )
        if cached:
            logger.info(f""Loaded {len(cached)} clusters from checkpoint"")
            return cached
    
    # Generate clusters
    logger.info(""Generating new clusters..."")
    clusters = await model.cluster_summaries(summaries)
    logger.info(f""Generated {len(clusters)} clusters"")
    
    # Save to checkpoint
    if checkpoint_manager:
        checkpoint_manager.save_checkpoint(model.checkpoint_filename, clusters)
    
    return clusters
",kura/v1/kura.py,
survived,"def _build_tree_structure(
    node: ClusterTreeNode,
    node_id_to_cluster: dict[str, ClusterTreeNode],
    level: int = 0,
    is_last: bool = True,
    prefix: str = """",
) -> str:
    """"""Build a text representation of the hierarchical cluster tree.
    
    This is a recursive helper function used by visualise_clusters().
    
    Args:
        node: Current tree node
        node_id_to_cluster: Dictionary mapping node IDs to nodes
        level: Current depth in the tree (for indentation)
        is_last: Whether this is the last child of its parent
        prefix: Current line prefix for tree structure
        
    Returns:
        String representation of the tree structure
    """"""
    # Current line prefix (used for tree visualization symbols)
    current_prefix = prefix

    # Add the appropriate connector based on whether this is the last child
    if level > 0:
        if is_last:
            current_prefix += ""â•šâ•â• ""
        else:
            current_prefix += ""â• â•â• ""

    # Print the current node
    result = (
        current_prefix + node.name + "" ("" + str(node.count) + "" conversations)\n""
    )

    # Calculate the prefix for children (continue vertical lines for non-last children)
    child_prefix = prefix
    if level > 0:
        if is_last:
            child_prefix += ""    ""  # No vertical line needed for last child's children
        else:
            child_prefix += ""â•‘   ""  # Continue vertical line for non-last child's children

    # Process children
    children = node.children
    for i, child_id in enumerate(children):
        child = node_id_to_cluster[child_id]
        is_last_child = i == len(children) - 1
        result += _build_tree_structure(
            child, node_id_to_cluster, level + 1, is_last_child, child_prefix
        )

    return result
",kura/v1/visualization.py,
survived,"async def reduce_dimensionality_from_clusters(
    clusters: List[Cluster],
    *,
    model: BaseDimensionalityReduction,
    checkpoint_manager: Optional[CheckpointManager] = None
) -> List[ProjectedCluster]:
    """"""Reduce dimensions of clusters for visualization.
    
    Projects clusters to 2D space using the provided dimensionality reduction model.
    Supports different algorithms (UMAP, t-SNE, PCA, etc.) through the model interface.
    
    Args:
        clusters: List of clusters to project
        model: Dimensionality reduction model to use (UMAP, t-SNE, etc.)
        checkpoint_manager: Optional checkpoint manager for caching
        
    Returns:
        List of projected clusters with 2D coordinates
        
    Example:
        >>> dim_model = HDBUMAP(n_components=2)
        >>> projected = await reduce_dimensionality(
        ...     clusters=hierarchical_clusters,
        ...     model=dim_model,
        ...     checkpoint_manager=checkpoint_mgr
        ... )
    """"""
    logger.info(f""Starting dimensionality reduction for {len(clusters)} clusters using {type(model).__name__}"")
    
    # Try to load from checkpoint
    if checkpoint_manager:
        cached = checkpoint_manager.load_checkpoint(
            model.checkpoint_filename,
            ProjectedCluster
        )
        if cached:
            logger.info(f""Loaded {len(cached)} projected clusters from checkpoint"")
            return cached
    
    # Reduce dimensionality
    logger.info(""Projecting clusters to 2D space..."")
    projected_clusters = await model.reduce_dimensionality(clusters)
    logger.info(f""Projected {len(projected_clusters)} clusters to 2D"")
    
    # Save to checkpoint
    if checkpoint_manager:
        checkpoint_manager.save_checkpoint(model.checkpoint_filename, projected_clusters)
    
    return projected_clusters ",kura/v1/kura.py,
survived,"def visualise_pipeline_results(
    clusters: List[Cluster],
    *,
    style: str = ""enhanced"",
    console: Optional[Console] = None
) -> None:
    """"""Visualize clusters that are the result of a pipeline execution.
    
    Convenience function for visualizing clusters directly from pipeline results.
    
    Args:
        clusters: List of clusters from pipeline execution
        style: Visualization style (""basic"", ""enhanced"", or ""rich"")
        console: Rich Console instance (for rich style)
        
    Raises:
        ValueError: If invalid style is provided
    """"""
    if style == ""basic"":
        visualise_clusters(clusters)
    elif style == ""enhanced"":
        visualise_clusters_enhanced(clusters)
    elif style == ""rich"":
        visualise_clusters_rich(clusters, console=console)
    else:
        raise ValueError(f""Invalid style '{style}'. Must be one of: basic, enhanced, rich"") ",kura/v1/visualization.py,
survived,"    def test_len_method(self):
        """"""Test __len__ method.""""""
        pipeline = LearnerPipeline(steps=[(""scale"", StandardScaler())], learner=MockLearner())
        assert len(pipeline) == 1  # Only transformer steps
",tests/test_learner_pipeline.py,TestLearnerPipelineProperties
survived,"    def __repr__(self) -> str:
        """"""String representation.""""""
        steps_repr = [
            f""('{name}', {transformer.__class__.__name__})""
            for name, transformer in self.steps
        ]
        return f""NonContextualAgentPipeline(steps=[{', '.join(steps_repr)}], final_agent={self._agent!r})""
",bayesianbandits/pipelines/_agent.py,NonContextualAgentPipeline
survived,"    def decay(self, X: X_contra, *, decay_rate: Optional[float] = None) -> None:
        """"""Decay the learner's parameters.

        Parameters
        ----------
        X : X_contra
            Input data (enriched features from ArmFeaturizer)
        decay_rate : float, optional
            Rate of decay
        """"""
        X_transformed = self._apply_transformers(X)
        self._learner.decay(X_transformed, decay_rate=decay_rate)
",bayesianbandits/pipelines/_learner.py,LearnerPipeline
survived,"    def test_feature_engineering_pipeline(self):
        """"""Test complex feature engineering pipeline.""""""
        arms = make_arms(range(3))
        agent = ContextualAgent(arms, ThompsonSampling(), random_seed=42)

        # Complex feature engineering
        def add_interactions(X):
            """"""Add interaction terms.""""""
            # X shape: (n_samples, 2)
            interactions = X[:, 0:1] * X[:, 1:2]  # x1 * x2
            return np.c_[X, interactions]

        def add_polynomials(X):
            """"""Add polynomial features.""""""
            # X shape: (n_samples, 3) after interactions
            squared = X**2
            return np.c_[X, squared]

        def normalize_features(X):
            """"""Simple normalization.""""""
            return X / (np.linalg.norm(X, axis=1, keepdims=True) + 1e-8)

        steps = [
            (""interactions"", FunctionTransformer(add_interactions)),
            (""polynomials"", FunctionTransformer(add_polynomials)),
            (""normalize"", FunctionTransformer(normalize_features)),
        ]

        pipeline = ContextualAgentPipeline(steps, agent)

        # Test with raw features
        X = np.array([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])

        # Check transformation
        transformed = pipeline.transform(X)
        assert transformed.shape[1] == 6  # 2 original + 1 interaction + 3 squared

        # Test full pipeline
        actions = pipeline.pull(X)
        assert len(actions) == 3

        y = np.array([1.0, 2.0, 3.0])
        pipeline.update(X, y)
",tests/test_agent_pipeline.py,TestIntegrationScenarios
survived,"    def test_pull_without_top_k(self):
        """"""Test pull method without top_k.""""""
        arms = make_arms(range(3))
        agent = ContextualAgent(arms, ThompsonSampling(), random_seed=42)
        steps = [(""identity"", FunctionTransformer())]

        pipeline = ContextualAgentPipeline(steps, agent)

        X = np.array([[1.0, 2.0], [3.0, 4.0]])
        actions = pipeline.pull(X)

        assert len(actions) == 2
        assert all(isinstance(action, int) for action in actions)
",tests/test_agent_pipeline.py,TestContextualAgentPipeline
survived,"    def test_valid_initialization_with_transformers(self):
        """"""Test initialization with transformers.""""""
        mock_learner = MockLearner()
        pipeline = LearnerPipeline(
            steps=[(""scale"", StandardScaler())],
            learner=mock_learner
        )

        assert len(pipeline.steps) == 1
        assert pipeline.learner is mock_learner
",tests/test_learner_pipeline.py,TestLearnerPipelineInit
survived,"    def test_factory_preserves_functionality(self):
        """"""Test factory-created pipelines work correctly.""""""
        # Test contextual
        arms = make_arms(range(3))
        contextual_agent = ContextualAgent(arms, ThompsonSampling(), random_seed=42)
        steps = [(""scale"", FunctionTransformer(lambda x: x / 10))]

        contextual_pipeline = AgentPipeline(steps, contextual_agent)

        X = np.array([[10.0, 20.0]])
        actions = contextual_pipeline.pull(X)
        assert len(actions) == 1

        # Test non-contextual
        arms = make_arms(range(3))
        agent = Agent(arms, ThompsonSampling(), random_seed=42)

        noncontextual_pipeline = AgentPipeline([], agent)

        actions = noncontextual_pipeline.pull()
        assert len(actions) == 1
",tests/test_agent_pipeline.py,TestAgentPipelineFactory
survived,"    def pull(
        self, X: Any, *, top_k: Optional[int] = None
    ) -> Union[List[TokenType], List[List[TokenType]]]:
        """"""Choose arm(s) and pull based on the context(s).

        Parameters
        ----------
        X : Any
            Input data to transform and use for choosing arms.
            Will be transformed through the pipeline steps to ContextType.
        top_k : int, optional
            Number of arms to select per context. If None (default),
            selects single best arm per context.

        Returns
        -------
        List[TokenType] or List[List[TokenType]]
            If top_k is None: List of action tokens (one per context)
            If top_k is int: List of lists of action tokens
        """"""
        X_transformed = self.transform(X)
        if top_k is None:
            return self._agent.pull(X_transformed)
        else:
            return self._agent.pull(X_transformed, top_k=top_k)
",bayesianbandits/pipelines/_agent.py,ContextualAgentPipeline
survived,"    def test_contextual_pipeline_policy_setter(self):
        """"""Test policy setter on contextual pipeline.""""""
        arms = make_arms(range(3))
        agent = ContextualAgent(arms, ThompsonSampling())
        pipeline = ContextualAgentPipeline([(""identity"", FunctionTransformer())], agent)

        new_policy = EpsilonGreedy(epsilon=0.2)
        pipeline.policy = new_policy
        assert pipeline.policy is new_policy
        assert agent.policy is new_policy
",tests/test_agent_pipeline.py,TestCoverage
survived,"    def test_basic_construction(self):
        """"""Test basic contextual pipeline construction.""""""
        arms = make_arms(range(3))
        agent = ContextualAgent(arms, ThompsonSampling())
        steps = [(""double"", FunctionTransformer(lambda x: x * 2))]

        pipeline = ContextualAgentPipeline(steps, agent)

        assert len(pipeline) == 1
        assert pipeline.named_steps[""double""] is not None
        assert pipeline._agent is agent
",tests/test_agent_pipeline.py,TestContextualAgentPipeline
survived,"        def normalize_features(X):
            """"""Simple normalization.""""""
            return X / (np.linalg.norm(X, axis=1, keepdims=True) + 1e-8)
",tests/test_agent_pipeline.py,TestIntegrationScenarios
survived,"    def test_repr(self):
        """"""Test string representation.""""""
        arms = make_arms(range(3))
        agent = ContextualAgent(arms, ThompsonSampling())
        steps = [(""transform"", FunctionTransformer())]

        pipeline = ContextualAgentPipeline(steps, agent)
        repr_str = repr(pipeline)

        assert ""ContextualAgentPipeline"" in repr_str
        assert ""FunctionTransformer"" in repr_str
",tests/test_agent_pipeline.py,TestContextualAgentPipeline
survived,"    def __init__(self, fitted=False):
        self.fitted = fitted
",tests/test_agent_pipeline.py,MockTransformer
survived,"    def named_steps(self) -> Dict[str, Any]:
        """"""Access pipeline transformer steps by name.""""""
        return dict(self.steps)
",bayesianbandits/pipelines/_learner.py,LearnerPipeline
survived,"        def add_polynomials(X):
            """"""Add polynomial features.""""""
            # X shape: (n_samples, 3) after interactions
            squared = X**2
            return np.c_[X, squared]
",tests/test_agent_pipeline.py,TestIntegrationScenarios
survived,"    def test_random_state_property(self):
        """"""Test random_state property delegation.""""""
        # Test getting random_state
        self.mock_learner.random_state = 42  # type: ignore
        assert self.pipeline.random_state == 42

        # Test setting random_state
        self.pipeline.random_state = 123
        assert self.mock_learner.random_state == 123
",tests/test_learner_pipeline.py,TestLearnerPipelineInterface
survived,"    def test_delegation_methods(self):
        """"""Test that agent methods are properly delegated.""""""
        arms = make_arms(range(3))
        agent = Agent(arms, ThompsonSampling(), random_seed=42)
        steps = []

        pipeline = NonContextualAgentPipeline(steps, agent)

        # Test property access
        assert pipeline.arms is agent.arms
        assert pipeline.policy is agent.policy
        assert pipeline.rng is agent.rng

        # Test arm access
        assert pipeline.arm(0) is agent.arm(0)

        # Test select_for_update
        result = pipeline.select_for_update(1)
        assert result is pipeline
        assert pipeline.arm_to_update is agent.arm_to_update
",tests/test_agent_pipeline.py,TestNonContextualAgentPipeline
survived,"    def test_basic_construction(self):
        """"""Test basic non-contextual pipeline construction.""""""
        arms = make_arms(range(3))
        agent = Agent(arms, ThompsonSampling())
        steps = [(""identity"", FunctionTransformer())]

        pipeline = NonContextualAgentPipeline(steps, agent)

        assert len(pipeline) == 1
        assert pipeline._agent is agent
",tests/test_agent_pipeline.py,TestNonContextualAgentPipeline
survived,"    def __getitem__(self, ind: Union[int, str]) -> Any:
        """"""Get a step by index or name.""""""
        if isinstance(ind, str):
            return self.named_steps[ind]
        return self.steps[ind]
",bayesianbandits/pipelines/_agent.py,ContextualAgentPipeline
survived,"    def test_contextual_pipeline_with_sample_weights(self):
        """"""Test contextual pipeline update with sample weights.""""""
        arms = make_arms(range(3))
        agent = ContextualAgent(arms, ThompsonSampling(), random_seed=42)
        pipeline = ContextualAgentPipeline([(""identity"", FunctionTransformer())], agent)

        X = np.array([[1.0], [2.0], [3.0]])
        y = np.array([1.0, 2.0, 3.0])
        sample_weight = np.array([1.0, 0.5, 0.1])

        pipeline.pull(X)
        pipeline.update(X, y, sample_weight=sample_weight)
",tests/test_agent_pipeline.py,TestCoverage
survived,"    def test_not_fitted_transformer_helpful_error(self):
        """"""Test helpful error message for not fitted transformers.""""""
        arms = make_arms(range(3))
        agent = ContextualAgent(arms, ThompsonSampling())

        steps = [(""scaler"", StandardScaler())]  # Not fitted!
        pipeline = ContextualAgentPipeline(steps, agent)

        X = np.array([[1.0], [2.0]])

        with pytest.raises(RuntimeError) as exc_info:
            pipeline.pull(X)

        error_msg = str(exc_info.value)
        assert ""not fitted"" in error_msg
        assert ""scaler"" in error_msg
        assert ""FunctionTransformer"" in error_msg
",tests/test_agent_pipeline.py,TestErrorHandling
survived,"def _validate_steps(steps: List[Tuple[str, Any]]) -> None:
    """"""Validate pipeline steps.""""""
    if not steps:
        raise ValueError(""Pipeline steps cannot be empty"")

    names, _ = zip(*steps)

    # Validate names are unique
    if len(set(names)) != len(names):
        raise ValueError(""Step names must be unique"")
",bayesianbandits/pipelines/_agent.py,
survived,"    def add_arm(self, arm) -> None:
        """"""Add an arm to the wrapped agent.""""""
        self._agent.add_arm(arm)
",bayesianbandits/pipelines/_agent.py,ContextualAgentPipeline
survived,"    def test_update(self):
        """"""Test update method.""""""
        arms = make_arms(range(3))
        agent = ContextualAgent(arms, ThompsonSampling(), random_seed=42)
        steps = [(""scale"", FunctionTransformer(lambda x: x / 10))]

        pipeline = ContextualAgentPipeline(steps, agent)

        X = np.array([[10.0, 20.0]])
        y = np.array([1.0])

        # Pull to set arm_to_update
        pipeline.pull(X)

        # Update should transform X before passing to agent
        pipeline.update(X, y)

        # Verify the learner was updated with transformed data
        arm_learner = pipeline.arm_to_update.learner
        assert hasattr(arm_learner, ""coef_"")
",tests/test_agent_pipeline.py,TestContextualAgentPipeline
survived,"    def test_repr_method(self):
        """"""Test __repr__ method.""""""
        pipeline = LearnerPipeline(steps=[(""scale"", StandardScaler())], learner=MockLearner())

        repr_str = repr(pipeline)
        assert ""LearnerPipeline"" in repr_str
        assert ""StandardScaler"" in repr_str
        assert ""MockLearner"" in repr_str",tests/test_learner_pipeline.py,TestLearnerPipelineProperties
survived,"    def _identify_file_modifications(self, feature_request: str, analysis: Dict[str, Any]) -> List[str]:
        """"""Identify which files need modification.""""""
        return [""main.py"", ""utils.py""]
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent
survived,"def run_all_tests():
    """"""Run all tests and provide summary.""""""
    print(""ðŸš€ Context Engineering Implementation QA Tests"")
    print(""="" * 60)
    
    test_results = []
    
    # Run all tests
    test_results.append((""Imports"", test_imports()))
    test_results.append((""Instantiation"", test_basic_instantiation()[0]))
    test_results.append((""Inheritance"", test_agent_inheritance()))
    test_results.append((""Methods"", test_context_engineering_methods()))
    test_results.append((""Functionality"", test_basic_functionality()))
    test_results.append((""Backward Compatibility"", test_backward_compatibility()))
    test_results.append((""Syntax Validation"", test_syntax_validation()))
    
    # Summary
    print(""\nðŸ“Š Test Results Summary"")
    print(""="" * 30)
    
    passed = 0
    total = len(test_results)
    
    for test_name, result in test_results:
        status = ""âœ… PASS"" if result else ""âŒ FAIL""
        print(f""   {test_name:<20} {status}"")
        if result:
            passed += 1
    
    print(f""\nðŸŽ¯ Overall Result: {passed}/{total} tests passed"")
    
    if passed == total:
        print(""ðŸŽ‰ All tests passed! ContextAgent implementation is ready."")
        return True
    else:
        print(""âš ï¸  Some tests failed. Review implementation before release."")
        return False
",test_context_agent.py,
survived,"    def generate_prp(self, feature_request: str, context_analysis: Dict[str, Any], documentation_links: List[str] = None) -> str:
        """"""
        Generate a Product Requirements Prompt (PRP) with comprehensive context.
        
        Args:
            feature_request (str): The feature to be implemented
            context_analysis (Dict[str, Any]): Analysis of the codebase context
            documentation_links (List[str]): Optional links to relevant documentation
            
        Returns:
            str: Complete PRP with rich context for implementation
        """"""
        if documentation_links is None:
            documentation_links = []
        
        prp = f""""""# Product Requirements Prompt (PRP)
## Context Engineering Enhanced Implementation Guide

### Feature Request
{feature_request}

### Comprehensive Context

#### Codebase Analysis
{self._format_prp_codebase_analysis(context_analysis)}

#### Implementation Blueprint
{self._generate_prp_implementation_blueprint(feature_request, context_analysis)}

#### Validation Framework
{self._generate_prp_validation_framework(feature_request)}

#### Documentation References
{self._format_prp_documentation(documentation_links)}

#### Success Criteria
{self._generate_prp_success_criteria(feature_request, context_analysis)}

### Implementation Instructions

This PRP provides comprehensive context for implementing: {feature_request}

**Context Engineering Principle**: This document contains all necessary context to enable 
first-try implementation success. Follow the patterns, respect the architecture, and 
use the validation framework to ensure quality.

#### Next Steps
1. Review the complete context above
2. Follow the implementation blueprint
3. Adhere to identified patterns and conventions
4. Execute validation framework to verify success
5. Integrate seamlessly with existing architecture

**Confidence Score**: 9/10 (High confidence due to comprehensive context analysis)
""""""
        
        return prp
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent
survived,"    def __init__(
        self,
        name: Optional[str] = None,
        role: Optional[str] = None,
        goal: Optional[str] = None,
        backstory: Optional[str] = None,
        instructions: Optional[str] = None,
        llm: Optional[Union[str, Any]] = None,
        tools: Optional[List[Any]] = None,
        **kwargs
    ):
        # Set Context Engineering defaults if not provided
        if name is None:
            name = ""Context Engineer""
        if role is None:
            role = ""Context Engineering Specialist""
        if goal is None:
            goal = ""Generate comprehensive context for AI coding assistants to enable first-try implementation success""
        if backstory is None:
            backstory = """"""You are an expert in Context Engineering - the discipline of engineering context 
            for AI coding assistants. You understand that context is 10x better than prompt engineering 
            and 100x better than vibe coding. Your expertise lies in analyzing codebases, extracting patterns, 
            and creating comprehensive context that enables AI assistants to implement features correctly 
            on the first attempt.""""""
        if instructions is None:
            instructions = """"""As a Context Engineering specialist, your primary responsibilities are:
            
            1. ANALYZE: Examine codebases to understand patterns, conventions, and architecture
            2. EXTRACT: Identify key patterns, best practices, and implementation approaches
            3. CONTEXTUALIZE: Generate comprehensive context documents with all necessary information
            4. VALIDATE: Create executable validation criteria and success metrics
            5. ENHANCE: Enrich prompts with comprehensive contextual information
            
            Always focus on providing complete context rather than clever wording. Include documentation,
            examples, patterns, constraints, and validation criteria in your context generation.""""""

        # Add Context Engineering specific tools if none provided
        if tools is None:
            tools = self._get_default_context_tools()

        # Initialize parent Agent class
        super().__init__(
            name=name,
            role=role,
            goal=goal,
            backstory=backstory,
            instructions=instructions,
            llm=llm,
            tools=tools,
            **kwargs
        )
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent
survived,"    def _generate_expected_outcome(self, criterion: str) -> str:
        """"""Generate expected outcome for a criterion.""""""
        return f""Criterion '{criterion}' passes validation""
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent
survived,"    def _format_code_conventions(self, code_patterns: Dict[str, Any], naming: Dict[str, Any]) -> str:
        """"""Format code conventions for context document.""""""
        return f""Naming Style: {naming.get('style', 'Unknown')}""
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent
survived,"    def _generate_prp_success_criteria(self, feature_request: str, analysis: Dict[str, Any]) -> str:
        """"""Generate success criteria for PRP.""""""
        return f""Success criteria for: {feature_request}""
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent
survived,"    def estimate_tokens_for_request(self, request: FenicCompletionsRequest) -> TokenEstimate:
        """"""Estimate the number of tokens for a request.

        Args:
            request: The request to estimate tokens for

        Returns:
            TokenEstimate: The estimated token usage
        """"""
        return self._core.estimate_tokens_for_request(request)
",src/fenic/_inference/openai/openai_batch_chat_completions_client.py,OpenAIBatchChatCompletionsClient
survived,"    def _message(self) -> str:
        return (
            ""Usage of `set_active_model` is not allowed in mlflow, use `_set_active_model` instead.""
        )
",dev/clint/src/clint/rules/forbidden_set_active_model_usage.py,ForbiddenSetActiveModelUsage
survived,"    def __init__(self, function_name: str, unknown_args: set[str]) -> None:
        self.function_name = function_name
        self.unknown_args = unknown_args
",dev/clint/src/clint/rules/unknown_mlflow_arguments.py,UnknownMlflowArguments
survived,"    def _message(self) -> str:
        return ""Do not set `os.environ` in test directly. Use `monkeypatch.setenv` (https://docs.pytest.org/en/stable/reference/reference.html#pytest.MonkeyPatch.setenv).""
",dev/clint/src/clint/rules/os_environ_set_in_test.py,OsEnvironSetInTest
survived,"    def is_generic_type(node: ast.Name | ast.Attribute, resolver: Resolver) -> bool:
        if resolved := resolver.resolve(node):
            return tuple(resolved) in {
                (""typing"", ""Callable""),
                (""typing"", ""Sequence""),
            }
        elif isinstance(node, ast.Name):
            return node.id in {
                ""dict"",
                ""list"",
                ""set"",
                ""tuple"",
                ""frozenset"",
            }
        return False
",dev/clint/src/clint/rules/unparameterized_generic_type.py,UnparameterizedGenericType
survived,"    def _is_none(value: ast.AnnAssign) -> bool:
        """"""
        Returns True if `value` represents `None`.
        """"""
        return isinstance(value, ast.Constant) and value.value is None",dev/clint/src/clint/rules/implicit_optional.py,ImplicitOptional
survived,"    def message(self) -> str:
        return self._message()
",dev/clint/src/clint/rules/base.py,Rule
survived,"    def id(self) -> str:
        return self._generated_id
",dev/clint/src/clint/rules/base.py,Rule
survived,"def _test_webhook(webhook_id: str):
    request_message = _get_request_message(TestWebhook())
    event = (
        WebhookEvent.from_proto(request_message.event)
        if request_message.HasField(""event"")
        else None
    )
    store = _get_model_registry_store()
    webhook = store.get_webhook(webhook_id=webhook_id)
    test_result = test_webhook(webhook=webhook, event=event)
    response_message = TestWebhook.Response(result=test_result.to_proto())
    return _wrap_response(response_message)
",mlflow/server/handlers.py,
survived,"def test_webhook_test_with_specific_event(
    mlflow_client: MlflowClient, app_client: AppClient
) -> None:
    # Create webhook that supports multiple events
    webhook = mlflow_client.create_webhook(
        name=""multi_event_webhook"",
        url=app_client.get_url(""/insecure-webhook""),
        events=[
            WebhookEvent.REGISTERED_MODEL_CREATED,
            WebhookEvent.MODEL_VERSION_CREATED,
            WebhookEvent.MODEL_VERSION_TAG_SET,
        ],
    )

    # Test with a specific event (not the first one)
    result = mlflow_client.test_webhook(
        webhook.webhook_id, event=WebhookEvent.MODEL_VERSION_TAG_SET
    )

    # Check that the test was successful
    assert result.success is True
    assert result.response_status == 200
    assert result.error_message is None

    # Check that the correct payload was sent
    logs = app_client.get_logs()
    assert len(logs) == 1
    assert logs[0][""endpoint""] == ""/insecure-webhook""
    assert logs[0][""payload""] == {
        ""name"": ""example_model"",
        ""version"": ""1"",
        ""key"": ""example_key"",
        ""value"": ""example_value"",
    }
",tests/webhooks/test_e2e.py,
survived,"def test_webhook_test_with_wrong_secret(mlflow_client: MlflowClient, app_client: AppClient) -> None:
    # Create webhook with wrong secret
    webhook = mlflow_client.create_webhook(
        name=""wrong_secret_test_webhook"",
        url=app_client.get_url(""/secure-webhook""),
        events=[WebhookEvent.REGISTERED_MODEL_CREATED],
        secret=""wrong-secret"",
    )

    # Test the webhook
    result = mlflow_client.test_webhook(webhook.webhook_id)

    # Check that the test failed due to wrong signature
    assert result.success is False
    assert result.response_status == 401
    assert result.error_message is None

    # Check that error was logged
    logs = app_client.get_logs()
    assert len(logs) == 1
    assert logs[0][""endpoint""] == ""/secure-webhook""
    assert logs[0][""error""] == ""Invalid signature""
    assert logs[0][""status_code""] == 401",tests/webhooks/test_e2e.py,
survived,"    def example(cls) -> ""ModelVersionAliasCreatedPayload"":
        return cls(
            name=""example_model"",
            alias=""example_alias"",
            version=""1"",
        )
",mlflow/webhooks/types.py,ModelVersionAliasCreatedPayload
survived,"    def example(cls) -> ""ModelVersionCreatedPayload"":
        return cls(
            name=""example_model"",
            version=""1"",
            source=""runs:/abcd1234abcd5678/model"",
            run_id=""abcd1234abcd5678"",
            tags={""example_key"": ""example_value""},
            description=""An example model version"",
        )
",mlflow/webhooks/types.py,ModelVersionCreatedPayload
survived,"    def test_webhook(
        self, webhook_id: str, event: Optional[WebhookEvent] = None
    ) -> WebhookTestResult:
        """"""
        Test a webhook by sending a test payload.

        Args:
            webhook_id: Webhook ID to test.
            event: Optional event type to test. If not specified, uses the first event from webhook.

        Returns:
            WebhookTestResult indicating success/failure and response details.
        """"""
        return self._get_registry_client().test_webhook(webhook_id, event)",mlflow/tracking/client.py,MlflowClient
survived,"    def test_new_OpImpl(self):
        mod = self.compile(
        """"""
        from operator import OpImpl

        def bar() -> void:
            pass

        @blue
        def foo() -> OpImpl:
            return OpImpl(bar)
        """""")
        w_opimpl = mod.foo(unwrap=False)
        assert isinstance(w_opimpl, W_OpImpl)
        assert w_opimpl._w_func is mod.bar.w_func
        assert w_opimpl.is_simple()
",spy/tests/compiler/test_opimpl.py,TestOpImpl
survived,"            def w_new2(vm: 'SPyVM', w_cls: W_Type,
                       w_func: W_Func, w_args: W_OpArgList) -> W_OpImpl:
                # Convert from applevel w_args into interp-level args_w
                args_w = w_args.items_w[:]
                return W_OpImpl(w_func, args_w)
",spy/vm/opimpl.py,W_OpImpl
survived,"    def label(self, curie: CURIE, lang: Optional[LANGUAGE_TAG] = None) -> Optional[str]:
        """"""
        Fetch the label for a CURIE from OLS.
        
        :param curie: The CURIE to fetch the label for
        :param lang: Optional language tag (not currently supported by this implementation)
        :return: The label for the CURIE, or None if not found
        """"""
        if curie in self.label_cache:
            return self.label_cache[curie]
        
        try:
            ontology = self.focus_ontology
            iri = self.curie_to_uri(curie)
            term = self.client.get_term(ontology=ontology, iri=iri)
            if term and ""label"" in term:
                self.label_cache[curie] = term[""label""]
                return term[""label""]
        except Exception as e:
            pass
        
        return None
",src/oaklib/implementations/ols/ols_implementation.py,BaseOlsImplementation
survived,"def test_api_key_logging():
    """"""Test that api_key provision is logged correctly.""""""
    from unittest.mock import patch, MagicMock

    # Mock the openai module
    with patch(""openai.OpenAI"") as mock_openai_class:
        mock_client = MagicMock()
        mock_openai_class.return_value = mock_client

        # Mock the from_openai import
        with patch(""instructor.from_openai"") as mock_from_openai:
            mock_instructor = MagicMock()
            mock_from_openai.return_value = mock_instructor

            # Mock logger
            with patch(""instructor.auto_client.logger"") as mock_logger:
                # Test that providing api_key triggers debug log
                from_provider(""openai/gpt-4"", api_key=""test-key"")

                # Check that debug was called with api_key message and length
                debug_calls = [
                    call
                    for call in mock_logger.debug.call_args_list
                    if ""API key provided"" in str(call) and ""length:"" in str(call)
                ]
                assert len(debug_calls) > 0, (
                    ""Expected debug log for API key provision with length""
                )

                # Verify the length is logged correctly (test-key is 8 characters)
                mock_logger.debug.assert_called_with(
                    ""API key provided for %s provider (length: %d characters)"",
                    ""openai"",
                    8,
                    extra={""provider"": ""openai"", ""operation"": ""initialize""},
                )",tests/test_auto_client.py,
survived,"    def test_zero_variance(self):
        # Test with zero variance (constant) variables
        data = np.array([[1, 1, 1, 1], [2, 2, 2, 2], [1, 2, 3, 4]], dtype=np.float64)
        result = nancorrmatrix(data)

        # Correlation with constant variables should be NaN
        assert result[2, 2] == 1.0  # Variable with itself
        assert np.isnan(result[0, 1])  # Two constants
        assert np.isnan(result[0, 2])  # Constant with non-constant
        assert np.isnan(result[1, 2])  # Constant with non-constant
",numbagg/test/test_nancorrmatrix.py,TestNanCorrMatrix
survived,"    def test_axis_parameter(self):
        # Test with different axes
        data = np.random.randn(3, 4, 5)

        # Default should compute covariance along last axis
        result_default = nancovmatrix(data)
        assert result_default.shape == (3, 4, 4)

        # Test with axis=0
        result_0 = nancovmatrix(data, axis=0)
        assert result_0.shape == (4, 5, 5)

        # Test with axis=1
        result_1 = nancovmatrix(data, axis=1)
        assert result_1.shape == (3, 5, 5)
",numbagg/test/test_nancovmatrix.py,TestNanCovMatrix
survived,"def mcp_server(recording_middleware):
    mcp = FastMCP()

    @mcp.tool
    def add(a: int, b: int) -> int:
        return a + b

    @mcp.resource(""resource://test"")
    def test_resource() -> str:
        return ""test resource""

    @mcp.resource(""resource://test-template/{x}"")
    def test_resource_with_path(x: int) -> str:
        return f""test resource with {x}""

    @mcp.prompt
    def test_prompt(x: str) -> str:
        return f""test prompt with {x}""

    @mcp.tool
    async def progress_tool(context: Context) -> None:
        await context.report_progress(progress=1, total=10, message=""test"")

    @mcp.tool
    async def log_tool(context: Context) -> None:
        await context.info(message=""test log"")

    @mcp.tool
    async def sample_tool(context: Context) -> None:
        await context.sample(""hello"")

    mcp.add_middleware(recording_middleware)

    # Register progress handler
    @mcp._mcp_server.progress_notification()
    async def handle_progress(
        progress_token: str | int,
        progress: float,
        total: float | None,
        message: str | None,
    ):
        print(""HI"")

    return mcp
",tests/server/middleware/test_middleware.py,
survived,"    def __getattribute__(self, name: str) -> Callable:
        """"""Dynamically create recording methods for any on_* method.""""""
        if name.startswith(""on_""):

            async def record_and_call(
                context: MiddlewareContext, call_next: Callable
            ) -> Any:
                result = await call_next(context)

                self.calls.append(Recording(hook=name, context=context, result=result))

                return result

            return record_and_call

        return super().__getattribute__(name)
",tests/server/middleware/test_middleware.py,RecordingMiddleware
survived,"        async def log_tool(context: Context) -> None:
            await context.info(message=""test log"")
",tests/server/middleware/test_middleware.py,TestNestedMiddlewareHooks
survived,"    async def test_list_resource_templates(
        self, mcp_server: FastMCP, recording_middleware: RecordingMiddleware
    ):
        async with Client(mcp_server) as client:
            await client.list_resource_templates()

        assert recording_middleware.assert_called(times=3)
        assert recording_middleware.assert_called(
            method=""resources/templates/list"", times=3
        )
        assert recording_middleware.assert_called(hook=""on_message"", times=1)
        assert recording_middleware.assert_called(hook=""on_request"", times=1)
        assert recording_middleware.assert_called(
            hook=""on_list_resource_templates"", times=1
        )
",tests/server/middleware/test_middleware.py,TestMiddlewareHooks
survived,"def test_inferred_parameters_transitively_collected():
    """"""
    Test that parameters inferred from dependencies are properly collected
    when enqueuing results.
    """"""
    
    with tempfile.TemporaryDirectory() as temp_dir:
        db_path = Path(temp_dir) / ""test.db""
        initialise_or_create_database_at(db_path)
        
        # Create experiment  
        exp = new_experiment(""test_exp"", sample_name=""test_sample"")
        
        # Create mock instruments
        dac = DummyInstrument(""dac"", gates=[""ch1"", ""ch2""])
        
        # Create delegate parameter that should be inferred from dac.ch1
        del_param = DelegateParameter(""del_param_1"", label=""del param 1"", source=dac.ch1)
        
        # Create a measurement parameter that depends on the delegate parameter
        measurement_param = Parameter(""measurement"", get_cmd=lambda: 42.0)
        
        # Create measurement
        meas = Measurement(name=""test_measurement"", exp=exp)
        
        # Register parameters to create the dependency chain:
        # measurement depends on del_param_1, del_param_1 is inferred from dac_ch1
        meas.register_parameter(dac.ch1)  # standalone
        meas.register_parameter(del_param, basis=(dac.ch1,))  # inferred from dac_ch1
        meas.register_parameter(measurement_param, setpoints=(del_param,))  # depends on del_param_1
        
        # Verify the interdependencies are set up correctly
        interdeps = meas._interdeps
        
        # Check that we have the expected structure
        assert len(interdeps.dependencies) == 1  # measurement depends on del_param_1
        assert len(interdeps.inferences) == 1    # del_param_1 inferred from dac_ch1
        assert len(interdeps.standalones) == 1   # dac_ch1 is standalone
        
        # Get the parameter specs
        measurement_spec = interdeps._id_to_paramspec[""measurement""]
        del_param_spec = interdeps._id_to_paramspec[""del_param_1""] 
        dac_spec = interdeps._id_to_paramspec[""dac_ch1""]
        
        # Test the _collect_all_related_parameters method directly
        from qcodes.dataset.data_set import DataSet
        
        # Create a dummy dataset to access the method
        with meas.run() as datasaver:
            dataset = datasaver.dataset
            
            # Simulate a result_dict that would be passed to _enqueue_results
            result_dict = {
                measurement_spec: [1.0],
                del_param_spec: [0.5],
                dac_spec: [0.1]
            }
            
            # Test the helper method
            initial_params = {measurement_spec, del_param_spec}
            collected = dataset._collect_all_related_parameters(interdeps, initial_params, result_dict)
            
            # Verify that all three parameters are collected
            collected_names = {p.name for p in collected}
            expected_names = {""measurement"", ""del_param_1"", ""dac_ch1""}
            assert collected_names == expected_names, f""Expected {expected_names}, got {collected_names}""
",tests/dataset/measurement/test_inferred_parameters_fix.py,
survived,"def test_export_datasets_default_export_path(simple_dataset):
    """"""Test that default export path is used when none provided""""""
    source_db_path, run_id = simple_dataset
    
    with tempfile.TemporaryDirectory() as temp_dir:
        target_db_path = Path(temp_dir) / ""target.db""
        
        # Run the export function without explicit export path
        result = export_datasets_and_create_metadata_db(
            source_db_path=source_db_path,
            target_db_path=target_db_path,
            # export_path=None  # Use default
        )
        
        # Should still work
        assert isinstance(result, dict)
        assert run_id in result
",tests/dataset/test_export_datasets_and_create_metadata_db.py,
survived,"async def build_policy_guardrails(
    config: GuardrailConfig,
) -> List[Callable[[str], Awaitable[None]]]:
    """"""Helper to create router-compatible guardrails from a config.""""""

    checker = PolicyChecker(config)

    async def guard(text: str) -> None:
        await checker.run(text)

    return [guard]",src/meta_agent/policy.py,
survived,"def test_default_patterns_match_samples():
    samples = {
        ""email"": ""user@example.com"",
        ""phone"": ""+1 555-123-4567"",
        ""ssn"": ""123-45-6789"",
        ""credit_card"": ""4111 1111 1111 1111"",
        ""password"": ""my password is secret"",
    }
    for name, pattern in DEFAULT_REGEX_PATTERNS.items():
        assert re.search(pattern, samples[name])
",tests/test_regex_patterns.py,
survived,"def _compile_worker(path: Path) -> str:
    script = (
        ""const ts=require('typescript');""
        ""const fs=require('fs');""
        ""const src=fs.readFileSync(process.argv[1],'utf8');""
        ""const out=ts.transpileModule(src,{compilerOptions:{module:'ES2022',target:'ES2022'}});""
        ""process.stdout.write(out.outputText);""
    )
    return subprocess.check_output([""node"", ""-e"", script, str(path)], text=True)
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/manual_build.py,
survived,"    def __init__(self, timeout: int = 60, proxies: dict = {}):
        """"""Initialize your AiForce provider with custom settings! âš™ï¸

        Args:
            timeout (int): Request timeout in seconds (default: 60)
            proxies (dict): Proxy settings for requests (default: {})
        """"""
        self.api_endpoint = ""https://api.airforce/imagine2""
        self.headers = {
            ""Accept"": ""text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8"",
            ""Accept-Language"": ""en-US,en;q=0.5"",
            ""Accept-Encoding"": ""gzip, deflate"",
            ""User-Agent"": agent.random()
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)
        self.session.proxies.update(proxies)
        self.timeout = timeout
        self.prompt: str = ""AI-generated image - webscout""
        self.image_extension: str = ""png""
",webscout/Provider/TTI/aiforce.py,AiForceimager
survived,"    def save(
        self,
        response: List[bytes],
        name: Optional[str] = None,
        dir: Optional[Union[str, Path]] = None,
        filenames_prefix: str = """",
    ) -> List[str]:
        """"""Save your fire generated images! ðŸ’¾

        Examples:
            >>> provider = AIArtaImager()
            >>> images = provider.generate(""Cool art"")
            >>> # Save with default settings
            >>> paths = provider.save(images)
            >>> # Save with custom name and directory
            >>> paths = provider.save(
            ...     images,
            ...     name=""my_art"",
            ...     dir=""my_images"",
            ...     filenames_prefix=""test_""
            ... )

        Args:
            response (List[bytes]): Your generated images
            name (Optional[str]): Custom name for your images
            dir (Optional[Union[str, Path]]): Where to save the images (default: current directory)
            filenames_prefix (str): Prefix for your image files

        Returns:
            List[str]: Paths to your saved images
        """"""
        save_dir = dir if dir else os.getcwd()
        if not os.path.exists(save_dir):
            os.makedirs(save_dir)

        name = self.prompt if name is None else name
            
        # Clean up name for filename use
        safe_name = """".join(c if c.isalnum() or c in ""_-"" else ""_"" for c in name)
        safe_name = safe_name[:50]  # Truncate if too long
            
        filenames = []
        count = 0

        for image in response:
            def complete_path():
                count_value = """" if count == 0 else f""_{count}""
                return os.path.join(save_dir, filenames_prefix + safe_name + count_value + ""."" + self.image_extension)

            while os.path.isfile(complete_path()):
                count += 1

            filepath = complete_path()
            filenames.append(os.path.basename(filepath))

            with open(filepath, ""wb"") as fh:
                fh.write(image)
        return filenames
",webscout/Provider/TTI/aiarta.py,AIArtaImager
survived,"    def __init__(self, timeout: int = 60, proxies: dict = None, logging: bool = True):
        """"""Initialize your AIArtaImager provider with custom settings

        Examples:
            >>> provider = AIArtaImager(timeout=120)
            >>> provider = AIArtaImager(proxies={""http"": ""http://proxy:8080""})

        Args:
            timeout (int): HTTP request timeout in seconds (default: 60)
            proxies (dict, optional): Proxy configuration for requests
            logging (bool): Enable/disable logging (default: True)
        """"""
        self.headers = {
            ""Accept"": ""application/json"",
            ""Accept-Language"": ""en-US,en;q=0.5"",
            ""User-Agent"": agent.random()
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)
        if proxies:
            self.session.proxies.update(proxies)
        self.timeout = timeout
        self.prompt: str = ""AI-generated image - webscout""
        self.image_extension: str = ""png""
",webscout/Provider/TTI/aiarta.py,AIArtaImager
survived,"    def __init__(
        self,
        model: str = ""dall-e-3"",  # Updated default model
        timeout: int = 60,
        proxies: dict = {},
    ):
        """"""Initialize your FreeAIPlayground provider with custom settings! âš™ï¸

        Args:
            model (str): Which model to use (default: dall-e-3)
            timeout (int): Request timeout in seconds (default: 60)
            proxies (dict): Proxy settings for requests (default: {})
            logging (bool): Enable fire logging (default: True)
        """"""
        self.image_gen_endpoint: str = ""https://api.freeaichatplayground.com/v1/images/generations""
        self.headers = {
            ""Accept"": ""application/json"",
            ""Accept-Language"": ""en-US,en;q=0.9"",
            ""Content-Type"": ""application/json"",
            ""User-Agent"": LitAgent().random(), 
            ""Origin"": ""https://freeaichatplayground.com"",
            ""Referer"": ""https://freeaichatplayground.com/"",
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)
        self.session.proxies.update(proxies)
        self.timeout = timeout
        self.model = model
        self.prompt: str = ""AI-generated image - webscout""
        self.image_extension: str = ""png""
",webscout/Provider/TTI/freeaiplayground.py,FreeAIImager
survived,"    def save(
        self,
        response: List[str],
        name: str = None,
        dir: str = os.getcwd(),
        filenames_prefix: str = """",
    ) -> List[str]:
        """"""Save your fire images! ðŸ’¾

        Args:
            response (List[str]): List of image URLs
            name (str, optional): Base name for saved files
            dir (str, optional): Where to save the images
            filenames_prefix (str, optional): Prefix for filenames

        Returns:
            List[str]: List of saved filenames
        """"""
        assert isinstance(response, list), f""Response should be a list, not {type(response)}""
        name = self.prompt if name is None else name

        if not os.path.exists(dir):
            os.makedirs(dir)
            if self.logging:
                logger.info(f""Created directory: {dir} ðŸ“"")

        if self.logging:
            logger.info(f""Saving {len(response)} images... ðŸ’¾"")

        filenames = []
        for i, url in enumerate(response):
            try:
                with self.session.get(url, stream=True, timeout=self.timeout) as r:
                    r.raise_for_status()
                    filename = f""{filenames_prefix}{name}_{i}.{self.image_extension}""
                    filepath = os.path.join(dir, filename)
                    with open(filepath, 'wb') as f:
                        for chunk in r.iter_content(chunk_size=8192):
                            f.write(chunk)
                    filenames.append(filename)
                    if self.logging:
                        logger.success(f""Saved image to: {filepath} ðŸ’¾"")
            except requests.exceptions.RequestException as e:
                if self.logging:
                    logger.error(f""Error downloading image from {url}: {e} ðŸ˜¢"")
                filenames.append(None)  # Indicate failure to download

        if self.logging:
            logger.success(f""All images saved successfully! Check {dir} ðŸŽ‰"")
        return filenames
",webscout/Provider/TTI/talkai.py,TalkaiImager
survived,"    def generate(
        self, 
        prompt: str,
        amount: int = 1,
        max_retries: int = 3,
        retry_delay: int = 5
    ) -> List[bytes]:
        """"""Generate some fire images from your prompt! ðŸŽ¨""""""
        if not prompt:
            raise ValueError(""Yo fam, prompt can't be empty! ðŸš«"")
        if not isinstance(amount, int) or amount < 1:
            raise ValueError(""Amount needs to be a positive number! ðŸ“ˆ"")

        self.prompt = prompt
        response = []

        for _ in range(amount):
            form_data = {
                ""prompt"": prompt,
                ""output_format"": ""bytes"",
                ""user_profile_id"": ""null"",
                ""anonymous_user_id"": str(uuid.uuid4()),
                ""request_timestamp"": time.time(),
                ""user_is_subscribed"": ""false"",
                ""client_id"": uuid.uuid4().hex,
            }

            for attempt in range(max_retries):
                try:
                    resp = self.session.post(
                        self.api_endpoint,
                        data=form_data,
                        timeout=self.timeout
                    )
                    resp.raise_for_status()
                    response.append(resp.content)
                    break
                except RequestException as e:
                    if attempt == max_retries - 1:
                        raise
                    time.sleep(retry_delay)

        return response
",webscout/Provider/TTI/magicstudio.py,MagicStudioImager
survived,"def numeric_grad(func, x, eps=1e-6):
    """"""Compute numeric gradient of scalar-valued function.""""""
    x = np.asarray(x, dtype=float)
    grad = np.zeros_like(x, dtype=float)
    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])
    while not it.finished:
        idx = it.multi_index
        orig = float(x[idx])
        x[idx] = orig + eps
        f_pos = func(x)
        x[idx] = orig - eps
        f_neg = func(x)
        grad[idx] = (f_pos - f_neg) / (2 * eps)
        x[idx] = orig
        it.iternext()
    return grad
",klongpy/autograd.py,
survived,"    def call_fn(v):
        if isinstance(fn, (KGSym, KGLambda)):
            return klong.call(KGCall(fn, [v], 1))
        elif isinstance(fn, KGCall):
            return klong.call(KGCall(fn.a, [v], fn.arity))
        elif isinstance(fn, KGFn):
            return klong.call(KGCall(fn.a, [v], fn.arity))
        else:
            return fn(v)
",klongpy/autograd.py,
survived,"def test_container_healthcheck() -> None:
    tag = ""af-health-test""
    dockerfile = os.path.join(""alpha_factory_v1"", ""Dockerfile"")
    subprocess.run([""docker"", ""build"", ""-t"", tag, ""-f"", dockerfile, "".""], check=True)
    cid = subprocess.check_output([""docker"", ""run"", ""-d"", tag]).decode().strip()
    try:
        status = ""starting""
        for _ in range(60):
            inspect = subprocess.check_output(
                [""docker"", ""inspect"", ""-f"", ""{{.State.Health.Status}}"", cid],
                text=True,
            ).strip()
            status = inspect
            if status == ""healthy"":
                break
            time.sleep(2)
        assert status == ""healthy""
    finally:
        subprocess.run([""docker"", ""rm"", ""-f"", cid], check=False)
        subprocess.run([""docker"", ""rmi"", tag], check=False)",tests/test_docker_health.py,
survived,"def test_with_retry_fail(monkeypatch: pytest.MonkeyPatch) -> None:
    monkeypatch.setattr(retry, ""backoff"", None)
    calls = {""n"": 0}

    def func() -> str:
        calls[""n""] += 1
        raise ValueError(""fail"")

    wrapped = retry.with_retry(func, max_tries=2)
    with pytest.raises(ValueError):
        wrapped()
    assert calls[""n""] == 2",tests/test_retry_wrapper.py,
survived,"async def test_send_http_error():
    with patch(""aiohttp.ClientSession"") as mock_session:
        resp = AsyncMock()
        resp.status = 500
        resp.text = AsyncMock(return_value=""bad"")
        cm = AsyncMock()
        cm.__aenter__.return_value = resp
        mock_session.return_value.post.return_value = cm
        mock_session.return_value.close = AsyncMock()
        client = TelemetryAPIClient({""trace"": EndpointConfig(""http://example.com"")})
        with pytest.raises(ValueError):
            await client.send(""trace"", {""d"": 1})
        await client.close()
",tests/unit/test_telemetry_client.py,
survived,"    async def post(self, *_args, **_kwargs):
        raise NotImplementedError(""aiohttp is required for network access"")
",src/aiohttp/__init__.py,ClientSession
survived,"        async def wrapped_run(*args: Any, **kwargs: Any) -> Any:
            result = await orig_run(*args, **kwargs)
            span_data = (
                getattr(result, ""span_graph"", None)
                or getattr(result, ""spans"", None)
                or getattr(result, ""trace"", None)
            )
            if span_data is not None:
                try:
                    await self.send(endpoint, span_data)  # type: ignore[arg-type]
                except Exception as exc:  # pragma: no cover - log only
                    logger.error(""Failed to send telemetry: %s"", exc)
            return result
",src/meta_agent/services/telemetry_client.py,TelemetryAPIClient
survived,"    def detach_runner(self, runner_cls: Any) -> None:
        """"""Restore ``runner_cls.run`` if it was patched by :meth:`attach_runner`.""""""
        orig = getattr(runner_cls, ""_meta_agent_orig_run"", None)
        if orig:
            setattr(runner_cls, ""run"", orig)
            delattr(runner_cls, ""_meta_agent_orig_run"")",src/meta_agent/services/telemetry_client.py,TelemetryAPIClient
survived,"def test_menu(monkeypatch, capsys):
    inputs = iter([""3"", ""2""])
    monkeypatch.setattr(""builtins.input"", lambda _: next(inputs))
    inter = Interactive()
    result = inter.menu(""Pick one"", [""a"", ""b""])
    out = capsys.readouterr().out
    assert ""Invalid choice"" in out
    assert result == ""b""
",tests/ux/test_interactive.py,
survived,"    def test_get_agent_health_queue(self):
        from alpha_factory_v1.backend.agents import _HEALTH_Q

        class WrapAgent(AgentBase):
            NAME = ""wrap""

            async def step(self):
                return ""ok""

        register_agent(AgentMetadata(name=WrapAgent.NAME, cls=WrapAgent))

        while not _HEALTH_Q.empty():
            _HEALTH_Q.get()

        agent = get_agent(WrapAgent.NAME)
        asyncio.run(agent.step())
        name, latency, ok = _HEALTH_Q.get(timeout=1)
        self.assertEqual(name, WrapAgent.NAME)
        self.assertTrue(ok)
        self.assertIsInstance(latency, float)
",tests/test_agents_registry.py,TestAgentRegistryFunctions
survived,"            async def step(self):
                return ""ok""
",tests/test_agents_registry.py,TestAgentRegistryFunctions.WrapAgent
survived,"    def test_cvar(self):
        returns = [-0.1, 0.2, -0.05, 0.03]
        expected = 0.1
        self.assertAlmostEqual(finance_agent._cvar(returns), expected)
",tests/test_finance_utils.py,TestFinanceUtils
survived,"    def test_prom_metrics_stub(self):
        class Dummy:
            def __init__(self, *_, **__):
                self.label_arg = None
            def labels(self, name):
                self.label_arg = name
                return self
            def inc(self):
                pass
            def set(self, v):
                self.value = v
        orig_counter = base_mod.Counter
        orig_gauge = base_mod.Gauge
        base_mod.Counter = Dummy
        base_mod.Gauge = Dummy
        run, err, lat = base_mod._prom_metrics(""test"")
        self.assertIsInstance(run, Dummy)
        self.assertEqual(run.label_arg, ""test"")
        self.assertIsInstance(err, Dummy)
        self.assertIsInstance(lat, Dummy)
        base_mod.Counter = orig_counter
        base_mod.Gauge = orig_gauge
",tests/test_base_helpers.py,TestPromMetrics
survived,"    def test_lower_version_ignored(self):
        class AgentV1(AgentBase):
            NAME = ""dup""
            VERSION = ""1.0""

            async def step(self):
                return None

        class AgentOld(AgentBase):
            NAME = ""dup""
            VERSION = ""0.9""

            async def step(self):
                return None

        register_agent(AgentMetadata(name=""dup"", cls=AgentV1, version=""1.0""))
        register_agent(AgentMetadata(name=""dup"", cls=AgentOld, version=""0.9""))

        self.assertIs(AGENT_REGISTRY[""dup""].cls, AgentV1)
        self.assertEqual(AGENT_REGISTRY[""dup""].version, ""1.0"")
",tests/test_agents_registry.py,TestVersionOverride
survived,"    def test_step_coroutine(self):
        import inspect
        for name in list_agents():
            meta = AGENT_REGISTRY[name]
            try:
                agent = meta.cls()
            except Exception:
                continue
            if hasattr(agent, ""step""):
                self.assertTrue(inspect.iscoroutinefunction(agent.step))
",tests/test_agents_integrity.py,TestAgentsIntegrity
survived,"    def test_plan_cycle_structure(self):
        data = json.loads(asyncio.run(self.agent._plan_cycle()))
        self.assertEqual(data[""agent""], self.agent.NAME)
        self.assertIn(""payload"", data)
        self.assertIsInstance(data[""payload""], list)
",tests/test_supply_chain_agent.py,TestSupplyChainAgent
survived,"    def test_cli_execution(self) -> None:
        result = subprocess.run(
            [sys.executable, ""-m"", ""alpha_factory_v1.demos.alpha_agi_business_3_v1.alpha_agi_business_3_v1"", ""--cycles"", ""1"", ""--loglevel"", ""warning""],
            capture_output=True,
            text=True,
        )
        self.assertEqual(result.returncode, 0, result.stderr)
",tests/test_alpha_agi_business_3_v1.py,TestAlphaAgiBusiness3Demo
survived,"            def latent_work(self, bundle):
                return 0.0
",tests/test_alpha_agi_business_3_v1.py,TestAlphaAgiBusiness3Demo.LowFin
survived,"    async def _update_model(name: str, file: bytes = File(...)):
        if name not in runners:
            raise HTTPException(404, ""Agent not found"")
        inst = runners[name].inst
        if not hasattr(inst, ""load_weights""):
            raise HTTPException(501, ""Agent does not support model updates"")
        import tempfile, zipfile, io
        with tempfile.TemporaryDirectory() as td:
            zf = zipfile.ZipFile(io.BytesIO(file))
            zf.extractall(td)
            inst.load_weights(td)  # type: ignore[attr-defined]
        return {""status"": ""ok""}
",alpha_factory_v1/backend/orchestrator.py,
survived,"    def test_excluded_fields(self):
        """"""Test that fields marked with exclude=True are not included.""""""

        class Base(DeclarativeBase):
            pass

        class User(Base, EnrichSQLAlchemyMixin):
            __tablename__ = ""users""

            id: Mapped[int] = mapped_column(primary_key=True)
            username: Mapped[str] = mapped_column()
            password_hash: Mapped[str] = mapped_column(info={""exclude"": True})
            secret_token: Mapped[str] = mapped_column(
                info={""exclude"": True, ""description"": ""Should not appear""}
            )

        UserEnrichModel = User.__enrich_model__()
        fields = UserEnrichModel.model_fields

        # Check included fields
        assert ""id"" in fields
        assert ""username"" in fields

        # Check excluded fields
        assert ""password_hash"" not in fields
        assert ""secret_token"" not in fields
",tests/test_sqlalchemy_integration.py,TestBasicModel
survived,"    def test_nullable_columns(self):
        """"""Test that nullable columns are converted to Optional types.""""""

        class Base(DeclarativeBase):
            pass

        class Product(Base, EnrichSQLAlchemyMixin):
            __tablename__ = ""products""

            id: Mapped[int] = mapped_column(primary_key=True)
            name: Mapped[str] = mapped_column(nullable=False)
            description: Mapped[str | None] = mapped_column(
                nullable=True, info={""description"": ""Product description""}
            )
            price: Mapped[float | None] = mapped_column(nullable=True)

        ProductEnrichModel = Product.__enrich_model__()
        fields = ProductEnrichModel.model_fields

        # Non-nullable fields should not be Optional
        assert fields[""id""].annotation == int
        assert fields[""name""].annotation == str

        # Nullable fields should be Optional
        # Check if it's Optional by looking at the annotation
        desc_type = fields[""description""].annotation
        price_type = fields[""price""].annotation

        # In Python 3.10+, Optional[X] is Union[X, None]
        assert get_origin(desc_type) in {Union, types.UnionType}
        assert type(None) in get_args(desc_type)
        assert str in get_args(desc_type)

        assert get_origin(price_type) in {Union, types.UnionType}
        assert type(None) in get_args(price_type)
        assert float in get_args(price_type)
",tests/test_sqlalchemy_integration.py,TestBasicModel
survived,"    def test_default_descriptions(self):
        """"""Test that fields without descriptions get default ones.""""""

        class Base(DeclarativeBase):
            pass

        class Item(Base, EnrichSQLAlchemyMixin):
            __tablename__ = ""items""

            id: Mapped[int] = mapped_column(primary_key=True)
            name: Mapped[str] = mapped_column()  # No description in info

        ItemEnrichModel = Item.__enrich_model__()
        fields = ItemEnrichModel.model_fields

        # Should have default descriptions
        assert fields[""id""].description == ""id field""
        assert fields[""name""].description == ""name field""
",tests/test_sqlalchemy_integration.py,TestBasicModel
survived,"    def __enter__(self):
        if resource:
            resource.setrlimit(resource.RLIMIT_CPU, (self.cpu_sec, self.cpu_sec))
            resource.setrlimit(resource.RLIMIT_AS, (self.mem_mb*1024*1024, self.mem_mb*1024*1024))
        return self
",alpha_factory_v1/demos/meta_agentic_agi_v2/agents/agent_base.py,SafeExec
survived,"    def subscribe(cls, topic: str, cb: Callable[[dict], None]):
        with cls._lock:
            cls._subs.setdefault(topic, []).append(cb)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,A2ABus
survived,"    def step(self, act:int):
        dx,dy = [(0,1),(1,0),(0,-1),(-1,0)][act%4]
        nx,ny = self._clip(self.agent[0]+dx), self._clip(self.agent[1]+dy)
        if (nx,ny) in self.obstacles: nx,ny = self.agent
        self.agent=(nx,ny)
        done = self.agent==self.goal
        reward = 1.0 if done else -0.01
        return self._obs(), reward, done, {}
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,MiniWorld
survived,"    def emit(self, topic: str, msg: dict):
        A2ABus.publish(topic, msg)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,Agent
survived,"    def _on(self, msg: dict):
        try:
            self.handle(msg)
        except Exception as exc:
            LOG.exception(""[%s] crash: %s"", self.name, exc)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,Agent
survived,"    def acquire(self, cost: float = 1.0):
        while True:
            now = time.perf_counter()
            elapsed = now - self._last
            self._last = now
            self._allow = min(self._tps, self._allow + elapsed * self._tps)
            if self._allow >= cost:
                self._allow -= cost
                return
            sleep = (cost - self._allow) / self._tps + 1e-3
            time.sleep(sleep)
",alpha_factory_v1/demos/meta_agentic_agi_v2/agents/agent_base.py,RateLimiter
survived,"    def acquire(self, cost: float = 1.0):
        while True:
            now = time.perf_counter()
            elapsed = now - self._last
            self._last = now
            self._allow = min(self._tps, self._allow + elapsed * self._tps)
            if self._allow >= cost:
                self._allow -= cost
                return
            sleep = (cost - self._allow) / self._tps + 1e-3
            time.sleep(sleep)
",alpha_factory_v1/demos/meta_agentic_agi_v3/agents/agent_base.py,RateLimiter
survived,"    def _parse(self, ep: str):
        if "":"" not in ep:
            raise ValueError(""Endpoint must be <backend>:<model>"")
        return ep.split("":"",1)
",alpha_factory_v1/demos/meta_agentic_agi_v3/agents/agent_base.py,LMClient
survived,"    def log(self, event: str, **payload):
        with self.path.open(""a"", encoding=""utf-8"") as fp:
            json.dump({""ts"": _utcnow_ms(), ""event"": event, **payload}, fp, ensure_ascii=False)
            fp.write(""\n"")
",alpha_factory_v1/demos/meta_agentic_agi/agents/agent_base.py,LineageTracer
survived,"def _sha(text: str) -> str:
    return hashlib.sha256(text.encode()).hexdigest()[:10]
",alpha_factory_v1/demos/meta_agentic_agi_v3/agents/agent_base.py,
survived,"    def read_csv_file(file_path: str) -> pd.DataFrame:
        """"""Read a CSV file into a pandas DataFrame.""""""
        return pd.read_csv(file_path)
",datamax/parser/csv_parser.py,CsvParser
survived,"def test_csv_parser(tmp_path):
    csv_file = tmp_path / ""data.csv""
    csv_file.write_text(""a,b\n1,2\n3,4\n"", encoding=""utf-8"")
    parser = CsvParser(file_path=str(csv_file))
    result = parser.parse(file_path=str(csv_file))
    assert result[""title""] == ""csv""
    assert ""a"" in result[""content""]
    assert result[""lifecycle""][0][""life_metadata""][""source_file""] == str(csv_file)
",tests/test_csv_parser.py,
survived,"def test_multi_contributor_patch():
    with patch(""transformers.AutoModelForCausalLM.from_pretrained"", return_value=DummyModel()):
        with patch(""transformers.AutoTokenizer.from_pretrained"", return_value=DummyTokenizer()):
            comm1 = FakeComm(""sub1"")
            comm2 = FakeComm(""sub2"")
            client = BaseModelClient(
                base_model=""dummy"",
                contributors=[(""h1"", 1), (""h2"", 2)],
            )
            # replace created comms with our fake ones
            client.comms = [comm1, comm2]
            client.init_and_patch()

            assert isinstance(client.model.sub1, RemoteLoRAWrappedModule)
            assert isinstance(client.model.sub2, RemoteLoRAWrappedModule)
            assert client.model.sub1.comm is comm1
            assert client.model.sub2.comm is comm2",tests/test_multi_contributor.py,
survived,"def test_send_beacon_opt_in() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri()

    with sync_playwright() as p:
        browser = p.chromium.launch()
        page = browser.new_page()
        page.goto(url)
        page.evaluate(
            ""window.OTEL_ENDPOINT='https://example.com';""
            ""window.confirm=() => true;""
            ""navigator.sendBeacon=(...a)=>{window.beacon=a;return true;}""
        )
        page.reload()
        page.wait_for_selector(""#controls"")
        page.click(""text=Share"")
        page.evaluate(""window.dispatchEvent(new Event('beforeunload'))"")
        assert page.evaluate(""Array.isArray(window.beacon)"")
        browser.close()",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_telemetry.py,
survived,"    def __init__(self, agent: object) -> None:
        self.cls: Callable[..., object] = type(agent)
        self.agent = agent
        self.period = getattr(agent, ""CYCLE_SECONDS"", 1.0)
        self.capabilities = getattr(agent, ""CAPABILITIES"", [])
        self.last_beat = time.time()
        self.restarts = 0
        self.task: asyncio.Task[None] | None = None
        self.error_count = 0
        self.restart_streak = 0
",alpha_factory_v1/backend/orchestrator_utils.py,AgentRunner
survived,"def pareto_front(pop: Population) -> Population:
    """"""Return the non-dominated set ranked by crowding distance.""""""

    if not pop:
        return []

    fits = np.asarray([ind.fitness for ind in pop], dtype=float)
    dominated = np.zeros(len(pop), dtype=bool)
    for i, fi in enumerate(fits):
        dom = np.all(fi <= fits, axis=1) & np.any(fi < fits, axis=1)
        dominated |= dom
        dominated[i] = False
    front = [ind for ind, d in zip(pop, dominated) if not d]
    _crowding(front)
    return sorted(front, key=lambda x: -x.crowd)",alpha_factory_v1/demos/alpha_agi_insight_v1/src/simulation/mats.py,
survived,"def test_devicon_various_examples(name, expected):
    devicons = reload_devicons('es')
    assert devicons.devicon(MockFile(name)) == expected",tests/test_devicons.py,
survived,"    def start_merkle_task(self, *_a, **_kw) -> None:  # pragma: no cover - dummy
        pass
",tests/test_codegen_safety.py,DummyLedger
survived,"    def test_list_agents_flag(self):
        args = _parse_with(['--list-agents'])
        self.assertTrue(args.list_agents)
",alpha_factory_v1/tests/test_cli.py,CliParseTest
survived,"def main(argv: list[str] | None = None) -> None:
    parser = argparse.ArgumentParser(description=""Alpha-Factory Quickstart"")
    parser.add_argument(""--preflight"", action=""store_true"", help=""Run checks and exit"")
    parser.add_argument(""--skip-preflight"", action=""store_true"", help=""Skip checks"")
    parser.add_argument(""orchestrator_args"", nargs=argparse.REMAINDER, help=""Arguments passed to orchestrator"")
    args = parser.parse_args(argv)

    repo_root = Path(__file__).resolve().parent
    os.chdir(repo_root)
    venv = repo_root / "".venv""
    _create_venv(venv)

    py = _venv_python(venv)

    if args.preflight:
        subprocess.check_call([str(py), ""alpha_factory_v1/scripts/preflight.py""])
        return

    if not args.skip_preflight:
        subprocess.check_call([str(py), ""alpha_factory_v1/scripts/preflight.py""])

    cmd = [str(py), ""-m"", ""alpha_factory_v1.run""] + args.orchestrator_args
    subprocess.check_call(cmd)
",alpha_factory_v1/quickstart.py,
survived,"        def __init__(self, *a, **kw) -> None:
            self.action_dim = kw.get(""action_dim"", 2)
",alpha_factory_v1/demos/muzero_planning/minimuzero.py,MiniMuNet
survived,"    def test_play_episode(self):
        if minimuzero is None:
            self.skipTest(""muZero demo deps missing"")
        agent = minimuzero.MiniMu()
        frames, reward = minimuzero.play_episode(agent, render=False, max_steps=5)
        self.assertIsInstance(frames, list)
        self.assertIsInstance(reward, float)
        self.assertGreaterEqual(len(frames), 0)
",alpha_factory_v1/tests/test_muzero_demo.py,MiniMuTest
survived,"    def test_ensure_dir(self):
        with tempfile.TemporaryDirectory() as tmp:
            path = Path(tmp) / 'd'
            preflight.ensure_dir(path)
            self.assertTrue(path.exists())
",alpha_factory_v1/tests/test_preflight.py,PreflightTest
survived,"    def test_hash_embedder(self):
        emb = memf._load_embedder()
        vec = emb(""test"")
        self.assertEqual(len(vec), memf.CFG.VECTOR_DIM)
        self.assertTrue(all(isinstance(x, (float, int)) for x in vec))
",alpha_factory_v1/tests/test_memory_provider.py,EmbedderFallbackTest
survived,"def test_init_creates_default_modules(monkeypatch):
    fake_rc_cls = MagicMock()
    fake_rc = MagicMock()
    fake_rc_cls.return_value = fake_rc
    fake_reporter_cls = MagicMock()
    fake_reporter = MagicMock()
    fake_reporter_cls.return_value = fake_reporter
    monkeypatch.setattr(
        'meta_agent.evaluation.harness.ResultCollectionModule', fake_rc_cls
    )
    monkeypatch.setattr('meta_agent.evaluation.harness.ReportingModule', fake_reporter_cls)

    harness = EvaluationHarness()
    assert harness.result_collector is fake_rc
    assert harness.reporter is fake_reporter
",tests/unit/test_evaluation_harness.py,
survived,"def main(argv=None) -> None:
    parser = argparse.ArgumentParser(prog=""sprc"")
    subparsers = parser.add_subparsers(dest=""command"")

    download_parser = subparsers.add_parser(""download"")
    download_subparsers = download_parser.add_subparsers(dest=""target"")

    vosk_parser = download_subparsers.add_parser(""vosk"")
    vosk_parser.add_argument(
        ""--url"",
        default=""https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip"",
    )
    vosk_parser.add_argument(""--dir"", default=""model"")

    def _download_vosk(args):
        download_vosk_model(args.url, args.dir)

    vosk_parser.set_defaults(func=_download_vosk)

    args = parser.parse_args(argv)
    if hasattr(args, ""func""):
        args.func(args)
    else:
        parser.print_help()
",speech_recognition/cli.py,
survived,"def test_ws_progress_token_param() -> None:
    port = _free_port()
    proc = _start_server(port)
    url = f""http://127.0.0.1:{port}""
    headers = {""Authorization"": ""Bearer test-token""}
    try:
        _wait_running(url, headers)
        ws_url = f""ws://127.0.0.1:{port}/ws/progress?token=test-token""
        with websockets.connect(ws_url) as ws:
            pass
    finally:
        proc.terminate()
        proc.wait(timeout=5)",tests/test_api_server_subprocess.py,
survived,"def example7():
    x = fetch_()
    if x == ""cheese"":
        None
    else:
        if someCondition():
            None
",tests/rosetta/transpiler/Python/conditional-structures-7.py,
survived,"def example9():
    while True:
        if True:
            break
        print(""I want out!"")",tests/rosetta/transpiler/Python/conditional-structures-9.py,
survived,"def peelFirstEat(p):
    print(""mm, that "" + p.value + "" was good!"")
",tests/rosetta/transpiler/Python/constrained-genericity-4.py,
survived,"    def test_concurrent_writes(self) -> None:
        from alpha_factory_v1.demos.cross_industry_alpha_factory import (
            cross_alpha_discovery_stub as stub,
        )

        with tempfile.TemporaryDirectory() as tmp:
            ledger = Path(tmp) / ""thread_log.json""

            def worker(seed: int) -> None:
                stub.discover_alpha(num=1, seed=seed, ledger=ledger, model=""gpt-4o-mini"")

            threads = [threading.Thread(target=worker, args=(i,)) for i in range(5)]
            for t in threads:
                t.start()
            for t in threads:
                t.join()

            data = json.loads(ledger.read_text())
            self.assertEqual(len(data), 5)
",tests/test_cross_alpha_discovery.py,TestCrossAlphaDiscoveryStub
survived,"    def delete_stale_entries(self, stale_after: timedelta) -> None:
        """"""Delete stale entries from the MongoDB cache.""""""
        threshold = datetime.now() - stale_after
        self.mongo_collection.delete_many(
            filter={""func"": self._func_str, ""time"": {""$lt"": threshold}}
        )",src/cachier/cores/mongo.py,_MongoCore
survived,"    def fake_run(cmd, repo_dir, *, image=None, mounts=None):
        calls.append(cmd)
        if ""pytest"" in cmd:
            result = subprocess.run([""pytest"", ""-q"", ""--color=no""], cwd=repo_dir, capture_output=True, text=True)
            return result.returncode, result.stdout + result.stderr
        if ""patch"" in cmd:
            ok, out = diff_utils.apply_diff(patch, repo_dir=repo_dir)
            return (0 if ok else 1), out
        return 0, """"
",tests/test_self_healer_pipeline.py,
survived,"    async def submit_order(
        self,
        symbol: str,
        qty: float,
        side: str,
        type: str = ""market"",
    ) -> str:
        """"""Place an order and return the broker-specific order identifier.""""""
",alpha_factory_v1/backend/types.py,TradeBrokerProtocol
survived,"def _apply_env(args: argparse.Namespace) -> None:
    if args.dev:
        os.environ[""DEV_MODE""] = ""true""
    if args.port is not None:
        os.environ[""PORT""] = str(args.port)
    if args.metrics_port is not None:
        os.environ[""METRICS_PORT""] = str(args.metrics_port)
    if args.a2a_port is not None:
        os.environ[""A2A_PORT""] = str(args.a2a_port)
    if args.disable_tls:
        os.environ[""INSECURE_DISABLE_TLS""] = ""true""
    if args.kafka_broker is not None:
        os.environ[""ALPHA_KAFKA_BROKER""] = args.kafka_broker
    if args.cycle_seconds is not None:
        os.environ[""ALPHA_CYCLE_SECONDS""] = str(args.cycle_seconds)
    if args.max_cycle_sec is not None:
        os.environ[""MAX_CYCLE_SEC""] = str(args.max_cycle_sec)
    if args.enabled is not None:
        os.environ[""ALPHA_ENABLED_AGENTS""] = args.enabled
    if args.loglevel:
        os.environ[""LOGLEVEL""] = args.loglevel.upper()
",alpha_factory_v1/backend/main.py,
survived,"    async def aspan(self, agent_name: str, phase: str, **payload: Any) -> Generator[None, None, None]:
        """"""Async variant of :meth:`span`.""""""
        start = _dt.datetime.utcnow()
        try:
            yield
        finally:
            duration = (_dt.datetime.utcnow() - start).total_seconds() * 1000
            payload[""duration_ms""] = round(duration, 3)
            await self.arecord(agent_name, phase, payload)
",alpha_factory_v1/backend/tracer.py,Tracer
survived,"    def __init__(self, *a, **k):
        pass
",tests/test_selfheal_entrypoint_offline.py,DummyBlocks
survived,"        def __call__(self, prompt: str) -> str:
            return llm_client.call_local_model([{""role"": ""user"", ""content"": prompt}])
",alpha_factory_v1/demos/self_healing_repo/agent_selfheal_entrypoint.py,OpenAIAgent
survived,"def main() -> None:
    """"""Run the Super Planner demo.""""""
    print_disclaimer()

    console: Final = Console()
    tasks = [
        ""Initializing reasoning engine"",
        ""Aggregating knowledge"",
        ""Synthesizing strategies"",
        ""Evaluating outcomes"",
        ""Finalizing plan"",
    ]
    with Progress(transient=True) as progress:
        job = progress.add_task(""Super Planner"", total=len(tasks))
        for step in tasks:
            console.log(step)
            time.sleep(1)
            progress.advance(job)
    console.rule(""[bold green]Plan Complete"")
",alpha_factory_v1/demos/alpha_super_planner_v1/__main__.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/group_by_sort.py,Item
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/group_by_multi_join.py,Partsupp
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/inner_join.py,Order
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/left_join.py,Order
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/group_by_conditional_sum.py,Item
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/group_by_join.py,Customer
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/left_join_multi.py,Auto1
survived,"        def add_font(self, *args, **kwargs):
            pass
",tests/conftest.py,DummyFPDF
survived,"def test_trim_invalid_characters():
    assert remove_chars('???Title???') == 'Title'
    assert remove_chars('!@#My Book!!!') == 'My Book'
    assert remove_chars('Book (Edition)') == 'Book - Edition'
",tests/test_remove_chars.py,
survived,"    def Histogram(name: str, desc: str, labels=None):  # type: ignore[misc]
        return _get_metric(_Histogram, name, desc, labels)
",alpha_factory_v1/backend/agents/__init__.py,
survived,"        def parse_dataset_iter(it: ast.expr) -> tuple[str, str | None, str | None, str | None]:
            sort = None
            skip = None
            take = None
            cur = it

            # handle take
            if isinstance(cur, ast.Subscript) and isinstance(cur.slice, ast.Slice):
                sl = cur.slice
                if (
                    sl.lower is None
                    and sl.step is None
                    and isinstance(sl.upper, ast.Call)
                    and getattr(sl.upper.func, ""id"", None) == ""max""
                    and len(sl.upper.args) == 2
                    and isinstance(sl.upper.args[1], ast.Constant)
                    and sl.upper.args[1].value == 0
                ):
                    take = self.convert_expr(sl.upper.args[0])
                    cur = cur.value

            # handle skip
            if isinstance(cur, ast.Subscript) and isinstance(cur.slice, ast.Slice):
                sl = cur.slice
                if (
                    sl.upper is None
                    and sl.step is None
                    and isinstance(sl.lower, ast.Call)
                    and getattr(sl.lower.func, ""id"", None) == ""max""
                    and len(sl.lower.args) == 2
                    and isinstance(sl.lower.args[1], ast.Constant)
                    and sl.lower.args[1].value == 0
                ):
                    skip = self.convert_expr(sl.lower.args[0])
                    cur = cur.value

            # handle sort
            if isinstance(cur, ast.Call) and isinstance(cur.func, ast.Name) and cur.func.id == ""sorted"":
                if cur.keywords:
                    for kw in cur.keywords:
                        if kw.arg == ""key"" and isinstance(kw.value, ast.Lambda):
                            body = kw.value.body
                            if (
                                isinstance(body, ast.Call)
                                and isinstance(body.func, ast.Name)
                                and body.func.id == ""_sort_key""
                                and body.args
                            ):
                                sort = self.convert_expr(body.args[0])
                            else:
                                sort = self.convert_expr(body)
                if cur.args:
                    cur = cur.args[0]

            # remove trivial list comp wrappers
            if (
                isinstance(cur, ast.ListComp)
                and len(cur.generators) == 1
                and isinstance(cur.generators[0].target, ast.Name)
                and isinstance(cur.elt, ast.Name)
                and cur.elt.id == cur.generators[0].target.id
                and not cur.generators[0].ifs
            ):
                cur = cur.generators[0].iter

            return self.convert_expr(cur), sort, skip, take
",tools/any2mochi/py/py2mochi.py,Converter
survived,"    def convert_list_comp(self, node: ast.ListComp) -> str:
        parts: list[str] = []

        def parse_dataset_iter(it: ast.expr) -> tuple[str, str | None, str | None, str | None]:
            sort = None
            skip = None
            take = None
            cur = it

            # handle take
            if isinstance(cur, ast.Subscript) and isinstance(cur.slice, ast.Slice):
                sl = cur.slice
                if (
                    sl.lower is None
                    and sl.step is None
                    and isinstance(sl.upper, ast.Call)
                    and getattr(sl.upper.func, ""id"", None) == ""max""
                    and len(sl.upper.args) == 2
                    and isinstance(sl.upper.args[1], ast.Constant)
                    and sl.upper.args[1].value == 0
                ):
                    take = self.convert_expr(sl.upper.args[0])
                    cur = cur.value

            # handle skip
            if isinstance(cur, ast.Subscript) and isinstance(cur.slice, ast.Slice):
                sl = cur.slice
                if (
                    sl.upper is None
                    and sl.step is None
                    and isinstance(sl.lower, ast.Call)
                    and getattr(sl.lower.func, ""id"", None) == ""max""
                    and len(sl.lower.args) == 2
                    and isinstance(sl.lower.args[1], ast.Constant)
                    and sl.lower.args[1].value == 0
                ):
                    skip = self.convert_expr(sl.lower.args[0])
                    cur = cur.value

            # handle sort
            if isinstance(cur, ast.Call) and isinstance(cur.func, ast.Name) and cur.func.id == ""sorted"":
                if cur.keywords:
                    for kw in cur.keywords:
                        if kw.arg == ""key"" and isinstance(kw.value, ast.Lambda):
                            body = kw.value.body
                            if (
                                isinstance(body, ast.Call)
                                and isinstance(body.func, ast.Name)
                                and body.func.id == ""_sort_key""
                                and body.args
                            ):
                                sort = self.convert_expr(body.args[0])
                            else:
                                sort = self.convert_expr(body)
                if cur.args:
                    cur = cur.args[0]

            # remove trivial list comp wrappers
            if (
                isinstance(cur, ast.ListComp)
                and len(cur.generators) == 1
                and isinstance(cur.generators[0].target, ast.Name)
                and isinstance(cur.elt, ast.Name)
                and cur.elt.id == cur.generators[0].target.id
                and not cur.generators[0].ifs
            ):
                cur = cur.generators[0].iter

            return self.convert_expr(cur), sort, skip, take

        if not node.generators:
            return ""[]""

        first = node.generators[0]
        # special case: [T(**it) for it in _load(...)] -> load ... as T
        if (
            len(node.generators) == 1
            and isinstance(node.elt, ast.Call)
            and isinstance(node.elt.func, ast.Name)
            and node.elt.func.id in self.dataclasses
            and not node.elt.args
            and len(node.elt.keywords) == 1
            and node.elt.keywords[0].arg is None
            and isinstance(node.elt.keywords[0].value, ast.Name)
            and isinstance(first.target, ast.Name)
            and node.elt.keywords[0].value.id == first.target.id
            and isinstance(first.iter, ast.Call)
            and isinstance(first.iter.func, ast.Name)
            and first.iter.func.id == ""_load""
        ):
            load_expr = self.convert_expr(first.iter)
            typ = node.elt.func.id
            if load_expr.startswith(""load""):
                if "" with "" in load_expr:
                    base, rest = load_expr.split("" with "", 1)
                    return f""{base} as {typ} with {rest}""
                return f""{load_expr} as {typ}""

        base_iter, sort, skip, take = parse_dataset_iter(first.iter)
        parts.append(f""from {self.convert_expr(first.target)} in {base_iter}"")

        for gen in node.generators[1:]:
            parts.append(
                f""from {self.convert_expr(gen.target)} in {self.convert_expr(gen.iter)}""
            )

        ifs: list[str] = []
        for gen in node.generators:
            for if_ in gen.ifs:
                ifs.append(self.convert_expr(if_))
        if ifs:
            parts.append(""where "" + "" and "".join(ifs))
        if sort:
            parts.append(""sort by "" + sort)
        if skip:
            parts.append(""skip "" + skip)
        if take:
            parts.append(""take "" + take)
        parts.append(""select "" + self.convert_expr(node.elt))

        result = parts[0]
        indent = ""            ""
        for part in parts[1:]:
            result += ""\n"" + indent + part
        return result
",tools/any2mochi/py/py2mochi.py,Converter
deleted,"def record_tool_usage(tool_name: str, input_chars: int, output_chars: int) -> None:
    with _lock:
        entry = _tool_stats[tool_name]
        entry.count += 1
        entry.input_chars += input_chars
        entry.output_chars += output_chars
",src/serena/analytics.py,
survived,"    async def first(app: EnrichMCP):
        call_order.append(""first"")
        yield {""a"": 1}
",tests/test_lifespan.py,
survived,"        def recent(self, _n: int):
            return []
",tests/test_agent_experience_entrypoint.py,DummyMemory
survived,"        def __init__(self, *a, **k):
            pass
",tests/test_agent_experience_entrypoint.py,DummyServer
survived,"def mount_gradio_app(app, ui, path=""/""):
    return app
",tests/test_agent_experience_entrypoint.py,
survived,"        def __init__(self, *a, **k):
            pass
",tests/test_agent_experience_entrypoint.py,DummyConfig
survived,"def init_config(env_file: str = "".env"") -> None:
    """"""Load environment variables and refresh :data:`CFG`.""""""

    _load_dotenv(env_file)
    _prefetch_vault()
    global CFG
    CFG = Settings()
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/config.py,
deleted,"  async def test_aspirate_custom_flow_rate(self):
    op = SingleChannelAspiration(
      resource=self.plate.get_item(""A1""),
      offset=Coordinate.zero(),
      tip=self.tr.get_tip(""A1""),
      volume=100,
      flow_rate=200,
      liquid_height=10,
      blow_out_air_volume=0,
      liquids=[(None, 100)],
    )
    await self.evo.aspirate([op], use_channels=[0])
    self.evo.send_command.assert_any_call(
      module=""C5"",
      command=""SSZ"",
      params=[60, None, None, None, None, None, None, None],
    )
    self.evo.send_command.assert_any_call(
      module=""C5"",
      command=""SEP"",
      params=[2400, None, None, None, None, None, None, None],
    )
",pylabrobot/liquid_handling/backends/tecan/EVO_tests.py,EVOTests
survived,"        async def policy(self, obs, _ctx):  # type: ignore[override]
            params = obs if isinstance(obs, dict) else {}
            return await run_insight_search(
                episodes=int(params.get(""episodes"", 5)),
                target=int(params.get(""target"", 3)),
                model=params.get(""model""),
                rewriter=params.get(""rewriter""),
                sectors=params.get(""sectors""),
            )
",alpha_factory_v1/demos/alpha_agi_insight_v0/openai_agents_bridge.py,InsightAgent
survived,"def main(argv: list[str] | None = None) -> None:
    parser = argparse.ArgumentParser(description=""OpenAI Agents bridge for the Î±â€‘AGI Insight demo"")
    parser.add_argument(""--episodes"", type=int, default=5, help=""Search episodes when offline"")
    parser.add_argument(""--target"", type=int, default=3, help=""Target sector index when offline"")
    parser.add_argument(""--model"", type=str, help=""Model name override"")
    parser.add_argument(
        ""--rewriter"",
        choices=[""random"", ""openai"", ""anthropic""],
        help=""Rewrite strategy"",
    )
    parser.add_argument(""--sectors"", type=str, help=""Comma-separated sector names"")
    parser.add_argument(
        ""--enable-adk"",
        action=""store_true"",
        help=""Enable the Google ADK gateway"",
    )
    parser.add_argument(
        ""--verify-env"",
        action=""store_true"",
        help=""Check runtime dependencies before launching"",
    )
    args = parser.parse_args(argv)

    if args.verify_env:
        verify_environment()

    if args.enable_adk:
        os.environ.setdefault(""ALPHA_FACTORY_ENABLE_ADK"", ""true"")

    _run_runtime(args.episodes, args.target, args.model, args.rewriter)
",alpha_factory_v1/demos/alpha_agi_insight_v0/openai_agents_bridge.py,
survived,"def test_call_summary_editable(client):
    @weave.op()
    def my_op():
        call = call_context.get_current_call()
        call.summary[""foo""] = 1
        call.summary[""bar""] = 2
        return ""done""

    my_op()
    calls = list(client.get_calls())
    assert len(calls) == 1
    summary = calls[0].summary
    assert summary[""foo""] == 1
    assert summary[""bar""] == 2
    assert summary[RESERVED_SUMMARY_STATUS_COUNTS_KEY][tsi.TraceStatus.SUCCESS] == 1",tests/trace/test_current_call.py,
survived,"    def update(self, *args: Any, **kwargs: Any) -> None:  # type: ignore[override]
        if self.__dict__.get(""_frozen"", False):
            raise TypeError(""Cannot modify attributes after call start"")
        for k, v in dict(*args, **kwargs).items():
            self[k] = v
",weave/trace/weave_client.py,AttributesDict
survived,"    def remove(self, node):
        ''' Removes a child node '''
        self.children.remove(node)
        NCRPNode.total_nodes -= 1
",src/hlda/sampler.py,NCRPNode
survived,"    def calculate_ncrp_prior(self, node_weights, node, weight):
        ''' Calculates the prior on the path according to the nested CRP '''
        for child in node.children:
            child_weight = log(float(child.customers) /
                               (node.customers + self.gamma))
            self.calculate_ncrp_prior(node_weights, child,
                                      weight + child_weight)

        if node.is_leaf():
            node_weights[node] = weight
        else:
            node_weights[node] = weight + log(self.gamma /
                                              (node.customers + self.gamma))
",src/hlda/sampler.py,HierarchicalLDA
survived,"def load_corpus(file_name):
    with open(file_name, 'rb') as f:
        corpus = []
        reader = csv.reader(f)
        for row in reader:
            doc = []
            for idx_and_word in row:
                stripped = idx_and_word.strip()
                tokens = stripped.split(' ')
                if len(tokens) == 2:
                    idx, word = tokens
                    doc.append(int(idx))
            corpus.append(doc)
        return corpus",src/hlda/sampler.py,
survived,"def _fstringify_notebook(filename: str, state: State) -> Optional[FstringifyResult]:
    """"""Apply fstringify transformations to all code cells in a notebook.""""""
    try:
        with open(filename, encoding=""utf-8"") as f:
            nb = json.load(f)
    except Exception:
        log.error(f""Exception while reading {filename}"", exc_info=True)
        return None

    original_dump = json.dumps(nb, ensure_ascii=False, indent=1)
    changes = 0

    for idx, cell in enumerate(nb.get(""cells"", [])):
        if cell.get(""cell_type"") != ""code"":
            continue
        source = """".join(cell.get(""source"", []))
        result = fstringify_code(source, state, filename=f""{filename}[{idx}]"")
        if not result:
            continue
        changes += result.n_changes
        if result.content != source:
            cell[""source""] = result.content.splitlines(keepends=True)

    new_dump = json.dumps(nb, ensure_ascii=False, indent=1)
    if state.dry_run and changes:
        diff = unified_diff(
            original_dump.split(""\n""), new_dump.split(""\n""), fromfile=filename
        )
        print(""\n"".join(diff))
    elif state.stdout:
        print(new_dump)
    elif changes:
        with open(filename, ""w"", encoding=""utf-8"") as f:
            f.write(new_dump)

    return FstringifyResult(
        n_changes=changes,
        original_length=len(original_dump),
        new_length=len(new_dump),
        content=new_dump,
    )
",src/flynt/api.py,
survived,"def test_compare_df_shape_mismatch():
    df1 = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})
    df2 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6]})
    assert not compare_df(df1, df2, question=""test"")
",backend/tests/test_utils_sql_compare_df.py,
survived,"def test_compare_df_value_mismatch():
    df1 = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})
    df2 = pd.DataFrame({'a': [1, 99], 'b': [3, 4]})
    assert not compare_df(df1, df2, question=""test"")
",backend/tests/test_utils_sql_compare_df.py,
survived,"def test_compare_df_equal():
    df1 = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})
    df2 = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})
    assert compare_df(df1, df2, question=""test"") is True
",backend/tests/test_utils_sql_compare_df.py,
survived,"def _require_python_311() -> None:
    major, minor = sys.version_info[:2]
    if (major, minor) < (3, 11):
        sys.exit(f""Python â‰¥3.11 required. Current version: {sys.version}"")
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/manual_build.py,
survived,"    def to_dict(self) -> Dict[str, Any]:
        """"""Return order as plain dictionary.""""""
        return asdict(self)
",alpha_factory_v1/backend/trade_broker.py,Order
survived,"    def geompath_route():
        args = request.args
        data = rs.geompath(
            lat1=float(args[""lat1""]),
            lon1=float(args[""lon1""]),
            lat2=float(args[""lat2""]),
            lon2=float(args[""lon2""]),
            currtime=int(args.get(""currtime"")) if args.get(""currtime"") else None,
            time_offset=int(args.get(""time_offset"")) if args.get(""time_offset"") else None,
            transfer_penalty=int(args.get(""transfer_penalty"", 0)),
            walking_speed=float(args.get(""walking_speed"", 1.0)),
            hill_reluctance=float(args.get(""hill_reluctance"", 1.5)),
            turn_penalty=float(args.get(""turn_penalty"")) if args.get(""turn_penalty"") else None,
            walking_reluctance=float(args.get(""walking_reluctance"")) if args.get(""walking_reluctance"") else None,
            max_walk=float(args.get(""max_walk"")) if args.get(""max_walk"") else None,
            jsoncallback=args.get(""callback""),
        )
        mimetype = ""application/javascript"" if args.get(""callback"") else ""application/json""
        return Response(data, mimetype=mimetype)
",pygs/graphserver/ext/routeserver/routeserver.py,
survived,"def test_surrogate_fitness_ordering() -> None:
    values = [(0.0, 0.0), (0.5, 1.0), (1.0, 0.5), (1.0, 1.0)]
    manual = _manual_nsga2_ranks(values)
    scores = surrogate_fitness.aggregate(values)
    order_manual = sorted(range(len(values)), key=lambda i: manual[i])
    order_scores = sorted(range(len(values)), key=lambda i: scores[i])
    assert order_manual == order_scores",tests/test_surrogate_fitness.py,
survived,"def audio_data() -> AudioData:
    audio_file = str(Path(__file__).parent.parent / ""english.wav"")
    return AudioData.from_file(audio_file)
",tests/recognizers/test_vosk.py,
survived,"def check_node() -> bool:
    """"""Return True if Node.js is available and warn when outdated.""""""
    if not shutil.which(""node""):
        banner(""node missing"", ""RED"")
        return False
    try:
        out = subprocess.check_output([""node"", ""--version""], text=True).strip()
    except Exception:
        banner(""failed to run node --version"", ""RED"")
        return False
    banner(f""Node {out} detected"", ""GREEN"")
    try:
        major = int(out.lstrip(""v"").split(""."")[0])
        if major < 22:
            banner(""Node 22 or newer recommended"", ""YELLOW"")
    except ValueError:
        banner(""Unable to parse Node version"", ""YELLOW"")
    return True
",alpha_factory_v1/scripts/preflight.py,
survived,"    def prompt_image(self) -> str | None:
        prompt = self.properties.get(""prompt_image"")
        if prompt is None:
            return None
        if not isinstance(prompt, str):
            raise ValueError(""Invalid prompt_image. prompt_image must be a string."")
        return prompt
",libs/core/kiln_ai/datamodel/extraction.py,ExtractorConfig
survived,"def test_validate_template_failure() -> None:
    ok, err = validate_template(""{% for x in %}"")
    assert not ok and err
",tests/test_template_creator.py,
survived,"def test_update_triggers_reload(tmp_path: Path) -> None:
    repo = Path(__file__).resolve().parents[1] / (
        ""alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1""
    )
    subprocess.check_call([""npm"", ""run"", ""build""], cwd=repo)

    dist = repo / ""dist""
    server, thread = _start_server(dist)
    host, port = server.server_address
    url = f""http://{host}:{port}/index.html""
    try:
        with sync_playwright() as p:
            browser = p.chromium.launch()
            context = browser.new_context()
            page = context.new_page()
            page.goto(url)
            page.wait_for_selector(""#controls"")
            page.wait_for_function(""navigator.serviceWorker.ready"")
            page.evaluate(""window.__loadCount = (window.__loadCount || 0) + 1"")

            # rebuild to create a new service worker
            subprocess.check_call([""npm"", ""run"", ""build""], cwd=repo)
            page.evaluate(""navigator.serviceWorker.getRegistration().then(r => r.update())"")
            page.wait_for_function(
                ""document.getElementById('toast').textContent.includes('Refreshing')""
            )
            page.wait_for_function(""performance.getEntriesByType('navigation').length > 1"")
            assert page.evaluate(""performance.getEntriesByType('navigation').length"") >= 2
            browser.close()
    except PlaywrightError as exc:
        pytest.skip(f""Playwright browser not installed: {exc}"")
    finally:
        server.shutdown()
        thread.join()",tests/test_pwa_update_reload.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q18.py,Customer
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q22.py,Customer
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q10.py,Auto2
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q16.py,Partsupp
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q2.py,Auto1
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q5.py,Supplier
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q18.py,Lineitem
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q5.py,Region
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q16.py,Supplier
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q8.py,Region
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q11.py,Auto5
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q24.py,Auto12
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q31.py,Auto5
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q11.py,Auto10
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q24.py,Auto8
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q33.py,Auto7
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q25.py,Auto5
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q19.py,Auto2
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q29.py,Auto11
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q3.py,Auto5
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q23.py,Auto11
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q12.py,Auto5
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q5.py,Auto2
survived,"def _min(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""min() expects list or group"")
    vals = [it for it in v if it is not None]
    if not vals:
        return 0
    return min(vals)
",tests/dataset/job/compiler/py/q28.py,
survived,"def test_Q21_finds_western_follow_up_sequels():
    assert result == [
        Auto1(
            company_name=""ACME Film Works"",
            link_type=""is follow up"",
            western_follow_up=""Western Return"",
        )
    ]
",tests/dataset/job/compiler/py/q21.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q25.py,Auto5
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q22.py,Auto8
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q18.py,Auto1
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q31.py,Auto7
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q26.py,Auto2
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q26.py,Auto4
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q29.py,Auto13
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q22.py,Auto4
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q19.py,Auto4
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q21.py,Auto3
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q17.py,Auto2
survived,"def test_Q15_finds_the_earliest_US_internet_movie_release_after_2000():
    assert result == [
        Auto1(release_date=""USA: March 2005"", internet_movie=""Example Movie"")
    ]
",tests/dataset/job/compiler/py/q15.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q29.py,Auto7
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q32.py,Auto5
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q9.py,Auto1
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q1.py,Auto6
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/job/compiler/py/q20.py,
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/job/compiler/py/q21.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q26.py,Auto2
survived,"def _min(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""min() expects list or group"")
    vals = [it for it in v if it is not None]
    if not vals:
        return 0
    return min(vals)
",tests/dataset/job/compiler/py/q23.py,
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/job/compiler/py/q15.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q22.py,Auto5
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q33.py,Auto2
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q16.py,Auto9
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q26.py,Auto10
survived,"def _min(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""min() expects list or group"")
    vals = [it for it in v if it is not None]
    if not vals:
        return 0
    return min(vals)
",tests/dataset/job/compiler/py/q14.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q29.py,Auto6
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q28.py,Auto12
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q29.py,Auto8
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q29.py,Auto1
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q33.py,Auto2
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q26.py,Auto7
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q25.py,Auto6
survived,"def _min(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""min() expects list or group"")
    vals = [it for it in v if it is not None]
    if not vals:
        return 0
    return min(vals)
",tests/dataset/job/compiler/py/q19.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q6.py,Auto4
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q14.py,Auto8
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q18.py,Auto3
survived,"def _min(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""min() expects list or group"")
    vals = [it for it in v if it is not None]
    if not vals:
        return 0
    return min(vals)
",tests/dataset/job/compiler/py/q32.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q31.py,Auto6
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q24.py,Auto9
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q20.py,Auto3
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q22.py,Auto10
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q11.py,Auto4
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q12.py,Auto2
survived,"def test_Q26_finds_hero_movies_with_rating_above_7():
    assert result == [
        Auto1(
            character_name=""Spider-Man"",
            rating=8.5,
            playing_actor=""Actor One"",
            complete_hero_movie=""Hero Movie"",
        )
    ]
",tests/dataset/job/compiler/py/q26.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q29.py,Auto12
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q3.py,Auto2
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q30.py,Auto4
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q10.py,Auto9
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q26.py,Auto6
survived,"def test_Q19_finds_female_voice_actress_in_US_Japan_release_between_2005_and_2009():
    assert result == [
        Auto1(voicing_actress=""Angela Stone"", voiced_movie=""Voiced Movie"")
    ]
",tests/dataset/job/compiler/py/q19.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q8.py,Auto7
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q11.py,Auto9
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q5.py,Auto6
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q25.py,Auto4
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q15.py,Auto7
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q19.py,Auto1
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/job/compiler/py/q15.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q20.py,Auto5
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q21.py,Auto6
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q9.py,Auto7
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q79.py,Auto2
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q73.py,Customer
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q21.py,_Group
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q99.py,
survived,"def test_TPCDS_Q64_simplified():
    assert result == 64
",tests/dataset/tpc-ds/compiler/py/q64.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q18.py,Auto2
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q36.py,Auto2
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q70.py,
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q40.py,_Group
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q7.py,_Group
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q24.py,Customer
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q95.py,DateDim
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q20.py,Auto1
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q78.py,C
survived,"def _sum(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""sum() expects list or group"")
    s = 0.0
    for it in v:
        if it is None:
            continue
        if isinstance(it, (int, float)):
            s += float(it)
        else:
            raise Exception(""sum() expects numbers"")
    return s
",tests/dataset/tpc-ds/compiler/py/q76.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q25.py,Store
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q97.py,Auto1
survived,"def abs(x):
    if x >= 0.0:
        return x
    return -x
",tests/dataset/tpc-ds/compiler/py/q53.py,
survived,"def _q0():
    _groups = {}
    _order = []
    for b in base:
        _k = Auto3(
            item_id=b.i_item_id,
            item_desc=b.i_item_desc,
            s_store_id=b.s_store_id,
            s_store_name=b.s_store_name,
        )
        _ks = str(_k)
        g = _groups.get(_ks)
        if not g:
            g = _Group(_k)
            _groups[_ks] = g
            _order.append(_ks)
        g.Items.append(b)
    _items1 = [_groups[k] for k in _order]
    return [
        Auto1(
            i_item_id=g.key[""item_id""],
            i_item_desc=g.key[""item_desc""],
            s_store_id=g.key[""s_store_id""],
            s_store_name=g.key[""s_store_name""],
            store_sales_quantity=sum([x.ss_quantity for x in g]),
            store_returns_quantity=sum([x.sr_return_quantity for x in g]),
            catalog_sales_quantity=sum([x.cs_quantity for x in g]),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q29.py,
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q27.py,_Group
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q16.py,_Group
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q10.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q53.py,StoreSale
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q54.py,Auto1
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q42.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q92.py,WebSale
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q98.py,StoreSale
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q8.py,Auto1
survived,"def _q0():
    _src = customer
    _rows = _query(
        _src,
        [
            {
                ""items"": store_sales,
                ""on"": lambda c, s: c.c_customer_sk == s.ss_customer_sk,
            },
            {""items"": date_dim, ""on"": lambda c, s, d: s.ss_sold_date_sk == d.d_date_sk},
        ],
        {""select"": lambda c, s, d: (c, s, d)},
    )
    _groups = _group_by(
        _rows,
        lambda c, s, d: Auto3(
            id=c.c_customer_id,
            first=c.c_first_name,
            last=c.c_last_name,
            login=c.c_login,
            year=d.d_year,
        ),
    )
    _items1 = _groups
    return [
        Auto2(
            customer_id=g.key[""id""],
            customer_first_name=g.key[""first""],
            customer_last_name=g.key[""last""],
            customer_login=g.key[""login""],
            dyear=g.key[""year""],
            year_total=_sum(
                [
                    (
                        x[1].ss_ext_list_price
                        - x[1].ss_ext_wholesale_cost
                        - x[1].ss_ext_discount_amt
                        + x[1].ss_ext_sales_price
                    )
                    / 2
                    for x in g
                ]
            ),
            sale_type=""s"",
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q4.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q4.py,DateDim
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q35.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q77.py,DateDim
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q58.py,Auto3
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q71.py,Auto2
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q10.py,StoreSale
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q35.py,CustomerDemographic
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q33.py,Auto1
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q39.py,_Group
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q90.py,WebSale
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q18.py,CatalogSale
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q39.py,Warehouse
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q77.py,CatalogReturn
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q22.py,Inventory
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q76.py,CatalogSale
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q13.py,CustomerAddres
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q22.py,_Group
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q78.py,C
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q25.py,StoreReturn
survived,"def test_TPCDS_Q45_simplified():
    assert records == [
        Auto1(ca_zip=""85669"", sum_ws_sales_price=50.0),
        Auto1(ca_zip=""99999"", sum_ws_sales_price=30.0),
    ]
",tests/dataset/tpc-ds/compiler/py/q45.py,
survived,"def test_TPCDS_Q19_brand():
    assert result == [
        Auto1(
            i_brand=""B1"",
            i_brand_id=1,
            i_manufact_id=1,
            i_manufact=""M1"",
            ext_price=100.0,
        )
    ]
",tests/dataset/tpc-ds/compiler/py/q19.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q3.py,Auto2
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q46.py,_Group
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q62.py,WebSale
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q56.py,_Group
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q73.py,_Group
survived,"def test_TPCDS_Q81_sample():
    assert result == 81.0
",tests/dataset/tpc-ds/compiler/py/q81.py,
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q74.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q72.py,Item
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q50.py,StoreSale
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q77.py,StoreSale
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q19.py,_Group
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q79.py,Store
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q42.py,Auto2
survived,"def test_TPCDS_Q42_simplified():
    assert result == [
        Auto1(
            d_year=2020,
            i_category_id=200,
            i_category=""CatB"",
            sum_ss_ext_sales_price=20.0,
        ),
        Auto1(
            d_year=2020,
            i_category_id=100,
            i_category=""CatA"",
            sum_ss_ext_sales_price=10.0,
        ),
    ]
",tests/dataset/tpc-ds/compiler/py/q42.py,
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q77.py,
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q91.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q40.py,CatalogReturn
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q26.py,CustomerDemographic
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q84.py,StoreReturn
survived,"def _sort_key(k):
    if hasattr(k, ""__dataclass_fields__""):
        return str(k)
    if isinstance(k, list):
        return tuple((_sort_key(x) for x in k))
    if isinstance(k, tuple):
        return tuple((_sort_key(x) for x in k))
    if isinstance(k, dict):
        return str(k)
    return k
",tests/dataset/tpc-ds/compiler/py/q24.py,
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q97.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q79.py,Auto2
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q99.py,Warehouse
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q98.py,_Group
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q18.py,Auto1
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q4.py,_Group
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q2.py,Auto3
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q24.py,CustomerAddress
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q89.py,StoreSale
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q8.py,
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q74.py,
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q4.py,
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q45.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q50.py,Auto1
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q6.py,Auto1
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q70.py,_Group
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q91.py,HouseholdDemographic
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q6.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q7.py,DateDim
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q31.py,Auto1
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q77.py,Auto4
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q85.py,WebReturn
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q19.py,Customer
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q26.py,Promotion
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q53.py,StoreSale
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q30.py,_Group
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q94.py,WebSite
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q40.py,Auto1
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q29.py,DateDim
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q3.py,_Group
survived,"def _q0():
    _src = catalog_sales
    _rows = _query(
        _src,
        [
            {
                ""items"": date_dim,
                ""on"": lambda cs1, d: (
                    cs1.cs_ship_date_sk == d.d_date_sk and d.d_date >= ""2000-03-01""
                )
                and d.d_date <= ""2000-04-30"",
            },
            {
                ""items"": customer_address,
                ""on"": lambda cs1, d, ca: cs1.cs_ship_addr_sk == ca.ca_address_sk
                and ca.ca_state == ""CA"",
            },
            {
                ""items"": call_center,
                ""on"": lambda cs1, d, ca, cc: cs1.cs_call_center_sk
                == cc.cc_call_center_sk
                and cc.cc_county == ""CountyA"",
            },
        ],
        {
            ""select"": lambda cs1, d, ca, cc: (cs1, d, ca, cc),
            ""where"": lambda cs1, d, ca, cc: len(
                [
                    cs2
                    for cs2 in catalog_sales
                    if cs1.cs_order_number == cs2.cs_order_number
                    and cs1.cs_warehouse_sk != cs2.cs_warehouse_sk
                ]
            )
            > 0
            and (
                len(
                    [
                        cr
                        for cr in catalog_returns
                        if cs1.cs_order_number
                        == (
                            cr.get(""cr_order_number"")
                            if isinstance(cr, dict)
                            else getattr(cr, ""cr_order_number"")
                        )
                    ]
                )
                > 0
            )
            == False,
        },
    )
    _groups = _group_by(_rows, lambda cs1, d, ca, cc: Auto2())
    _items1 = _groups
    return [
        Auto1(
            order_count=len(distinct([x[0].cs_order_number for x in g])),
            total_shipping_cost=sum([x[0].cs_ext_ship_cost for x in g]),
            total_net_profit=sum([x[0].cs_net_profit for x in g]),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q16.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q79.py,Auto1
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q29.py,Store
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q66.py,WebSale
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q4.py,Customer
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q39.py,_Group
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q3.py,Item
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q35.py,CustomerDemographic
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q15.py,Auto1
survived,"def test_TPCDS_Q91_returns():
    assert result == Auto1(
        Call_Center=""CC1"", Call_Center_Name=""Main"", Manager=""Alice"", Returns_Loss=10.0
    )
",tests/dataset/tpc-ds/compiler/py/q91.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q70.py,StoreSale
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q44.py,Item
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q37.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q13.py,CustomerDemographic
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q96.py,TimeDim
survived,"def _q0():
    _src = inventory
    _rows = _query(
        _src,
        [{""items"": date_dim, ""on"": lambda inv, d: inv.inv_date_sk == d.d_date_sk}],
        {
            ""select"": lambda inv, d: (inv, d),
            ""where"": lambda inv, d: d.d_date < ""2000-03-15"",
        },
    )
    _groups = _group_by(
        _rows, lambda inv, d: Auto3(w=inv.inv_warehouse_sk, i=inv.inv_item_sk)
    )
    _items1 = _groups
    return [
        Auto2(
            w=g.key[""w""], i=g.key[""i""], qty=sum([x[0].inv_quantity_on_hand for x in g])
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q21.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q60.py,StoreSale
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q94.py,
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q4.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q77.py,Auto1
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q58.py,Auto4
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q16.py,CallCenter
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q77.py,
survived,"def _q2():
    _src = customer
    _rows = _query(
        _src,
        [
            {
                ""items"": web_sales,
                ""on"": lambda c, ws: c.c_customer_sk == ws.ws_bill_customer_sk,
            },
            {
                ""items"": date_dim,
                ""on"": lambda c, ws, d: d.d_date_sk == ws.ws_sold_date_sk,
            },
        ],
        {
            ""select"": lambda c, ws, d: (c, ws, d),
            ""where"": lambda c, ws, d: d.d_year == 1998 or d.d_year == 1999,
        },
    )
    _groups = _group_by(
        _rows,
        lambda c, ws, d: Auto3(
            id=c.c_customer_id, first=c.c_first_name, last=c.c_last_name, year=d.d_year
        ),
    )
    _items3 = _groups
    return [
        Auto2(
            customer_id=g.key[""id""],
            customer_first_name=g.key[""first""],
            customer_last_name=g.key[""last""],
            year=g.key[""year""],
            year_total=_sum([x[1].ws_net_paid for x in g]),
            sale_type=""w"",
        )
        for g in _items3
    ]
",tests/dataset/tpc-ds/compiler/py/q74.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q54.py,Store
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q77.py,WebReturn
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q90.py,WebSale
survived,"def test_TPCDS_Q55_simplified():
    assert result == [
        Auto1(brand_id=10, ext_price=35.0),
        Auto1(brand_id=20, ext_price=20.0),
    ]
",tests/dataset/tpc-ds/compiler/py/q55.py,
survived,"def test_TPCDS_Q51_simplified():
    assert result == [Auto2(item_sk=1, d_date=1), Auto2(item_sk=1, d_date=2)]
",tests/dataset/tpc-ds/compiler/py/q51.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q72.py,Auto1
survived,"def test_TPCDS_Q52_simplified():
    assert result == [
        Auto1(d_year=2001, brand_id=1, ext_price=30.0),
        Auto1(d_year=2001, brand_id=2, ext_price=22.0),
    ]
",tests/dataset/tpc-ds/compiler/py/q52.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q76.py,Auto3
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q37.py,Inventory
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q6.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q56.py,Auto1
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q27.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q19.py,DateDim
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q90.py,TimeDim
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q30.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q23.py,CatalogSale
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q54.py,_Group
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q36.py,Item
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q43.py,DateDim
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q15.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q46.py,Auto2
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q52.py,DateDim
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q46.py,_Group
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q37.py,
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q53.py,_Group
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q2.py,Auto2
survived,"def _q0():
    _src = store_sales
    _rows = _query(
        _src,
        [
            {
                ""items"": date_dim,
                ""on"": lambda ss, d: (
                    ss.ss_sold_date_sk == d.d_date_sk and d.d_year == 2002
                )
                and d.d_moy == 11,
            }
        ],
        {
            ""select"": lambda ss, d: (ss, d),
            ""where"": lambda ss, d: ss.ss_item_sk
            in [ci.ss_item_sk for ci in cross_items],
        },
    )
    _groups = _group_by(
        _rows, lambda ss, d: Auto3(brand_id=1, class_id=1, category_id=1)
    )
    _items1 = _groups
    return [
        Auto2(
            channel=""store"",
            sales=sum([x[0].ss_quantity * x[0].ss_list_price for x in g]),
            number_sales=len([_ for _ in g]),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q14.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q43.py,Auto2
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q2.py,Auto4
survived,"def _sum(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""sum() expects list or group"")
    s = 0.0
    for it in v:
        if it is None:
            continue
        if isinstance(it, (int, float)):
            s += float(it)
        else:
            raise Exception(""sum() expects numbers"")
    return s
",tests/dataset/tpc-ds/compiler/py/q45.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q14.py,CatalogSale
survived,"def _sum(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""sum() expects list or group"")
    s = 0.0
    for it in v:
        if it is None:
            continue
        if isinstance(it, (int, float)):
            s += float(it)
        else:
            raise Exception(""sum() expects numbers"")
    return s
",tests/dataset/tpc-ds/compiler/py/q77.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q72.py,CustomerDemographic
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q27.py,CustomerDemographic
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q58.py,Auto2
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q39.py,Auto2
survived,"def _q0():
    _groups = {}
    _order = []
    for s in sales:
        _k = Auto2(mgr=s.mgr)
        _ks = str(_k)
        g = _groups.get(_ks)
        if not g:
            g = _Group(_k)
            _groups[_ks] = g
            _order.append(_ks)
        g.Items.append(s)
    _items1 = [_groups[k] for k in _order]
    return [
        Auto1(mgr=g.key[""mgr""], sum_sales=sum([x.amount for x in g])) for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q63.py,
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q78.py,Auto1
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q46.py,Auto3
survived,"def population_df(pop: list[Any]) -> pd.DataFrame:
    """"""Return a DataFrame for effectiveness vs. risk vs. complexity.""""""

    return pd.DataFrame(
        {
            ""effectiveness"": [p.fitness[0] for p in pop],
            ""risk"": [p.fitness[1] for p in pop],
            ""complexity"": [p.fitness[2] for p in pop],
            ""rank"": [p.rank for p in pop],
        }
    )
",src/interface/web_app.py,
survived,"def test_simulate_invalid_values() -> None:
    """"""Invalid numeric options should exit with an error.""""""
    res = CliRunner().invoke(cli.main, [""simulate"", ""--pop-size"", ""0""])
    assert res.exit_code != 0
    assert ""Invalid value for '--pop-size'"" in res.output

    res = CliRunner().invoke(cli.main, [""simulate"", ""--mut-rate"", ""1.5""])
    assert res.exit_code != 0
    assert ""Invalid value for '--mut-rate'"" in res.output
",tests/test_demo_cli.py,
survived,"    def __init__(self, config_entry: config_entries.ConfigEntry) -> None:
        self.config_entry = config_entry
",custom_components/gree/config_flow.py,OptionsFlowHandler
survived,"async def async_setup_entry(hass: HomeAssistant, entry: ConfigEntry) -> bool:
    """"""Set up Gree from a config entry.""""""
    if DOMAIN not in hass.data:
        hass.data[DOMAIN] = {}

    hass.data[DOMAIN][entry.entry_id] = entry.data
    await hass.config_entries.async_forward_entry_setups(entry, PLATFORMS)
    return True
",custom_components/gree/__init__.py,
survived,"    def _run_tests(self, errors: List[str]) -> None:
        result = subprocess.run(
            [""pytest"", ""-x""],
            cwd=self.bundle_dir,
            capture_output=True,
            text=True,
        )
        if result.returncode != 0:
            errors.append(""tests failed"")
",src/meta_agent/bundle_validator.py,BundleValidator
survived,"    def validate(self) -> ValidationResult:
        errors: List[str] = []
        try:
            metadata = self._load_metadata()
        except Exception as exc:  # pragma: no cover - invalid json path rare
            errors.append(f""invalid bundle metadata: {exc}"")
            return ValidationResult(success=False, errors=errors, coverage=0.0)

        self._validate_checksums(metadata, errors)
        self._validate_requirements(errors)
        self._validate_agent(errors)

        self._run_tests(errors)

        success = not errors
        return ValidationResult(success=success, errors=errors, coverage=0.0)",src/meta_agent/bundle_validator.py,BundleValidator
survived,"def test_bundle_validator_checksum_failure(tmp_path: Path) -> None:
    bundle_dir = create_sample_bundle(tmp_path)
    (bundle_dir / ""agent.py"").write_text(""broken"")
    validator = BundleValidator(bundle_dir)
    result = validator.validate()
    assert result.success is False
    assert any(""checksum mismatch"" in e for e in result.errors)
",tests/test_bundle_validator.py,
survived,"def create_sample_bundle(tmp_path: Path) -> Path:
    gen = BundleGenerator(tmp_path)
    gen.generate(
        agent_code=""def main():\n    return 'ok'"",
        tests={
            ""test_main.py"": ""from agent import main\n\ndef test_main():\n    assert main() == 'ok'"",
        },
        requirements=[""pytest==8.0.0""],
        readme=""# Sample"",
    )
    return tmp_path
",tests/test_bundle_validator.py,
survived,"    def _validate_agent(self, errors: List[str]) -> None:
        try:
            py_compile.compile(str(self.bundle_dir / ""agent.py""), doraise=True)
        except py_compile.PyCompileError as exc:
            errors.append(f""agent.py failed to compile: {exc.msg}"")
",src/meta_agent/bundle_validator.py,BundleValidator
survived,"def test_bundle_validator_success(tmp_path: Path) -> None:
    bundle_dir = create_sample_bundle(tmp_path)
    validator = BundleValidator(bundle_dir)
    result = validator.validate()
    assert result.success is True
    assert result.errors == []
",tests/test_bundle_validator.py,
survived,"        def fake_run(*_, **kwargs):
            nonlocal captured_env
            captured_env = kwargs.get(""env"", {})
            mock_result = MagicMock()
            mock_result.returncode = 0
            mock_result.stdout = """"
            mock_result.stderr = """"
            return mock_result
",tests/unit/test_validation.py,TestValidation
survived,"    def _validate_requirements(self, errors: List[str]) -> None:
        req_path = self.bundle_dir / ""requirements.txt""
        if not req_path.exists():
            errors.append(""requirements.txt missing"")
            return
        for line in req_path.read_text().splitlines():
            line = line.strip()
            if not line or line.startswith(""#""):
                continue
            if ""=="" not in line:
                errors.append(f""unpinned requirement: {line}"")
",src/meta_agent/bundle_validator.py,BundleValidator
survived,"def test_bundle_validator_unpinned_requirement(tmp_path: Path) -> None:
    bundle_dir = create_sample_bundle(tmp_path)
    (bundle_dir / ""requirements.txt"").write_text(""pytest>=8"")
    validator = BundleValidator(bundle_dir)
    result = validator.validate()
    assert result.success is False
    assert any(""unpinned requirement"" in e for e in result.errors)
",tests/test_bundle_validator.py,
survived,"def test_bundle_validator_test_failure(tmp_path: Path) -> None:
    bundle_dir = create_sample_bundle(tmp_path)
    (bundle_dir / ""tests"" / ""test_main.py"").write_text(
        ""def test_fail():\n    assert False""
    )
    validator = BundleValidator(bundle_dir)
    result = validator.validate()
    assert result.success is False
    assert any(""tests failed"" in e for e in result.errors)",tests/test_bundle_validator.py,
survived,"    def _validate_agent(self, errors: List[str]) -> None:
        try:
            py_compile.compile(str(self.bundle_dir / ""agent.py""), doraise=True)
        except py_compile.PyCompileError as exc:
            errors.append(f""agent.py failed to compile: {exc.msg}"")
",src/meta_agent/bundle_validator.py,BundleValidator
survived,"    def _validate_checksums(self, metadata: BundleMetadata, errors: List[str]) -> None:
        checksums = metadata.custom.get(""checksums"", {})
        for rel, expected in checksums.items():
            path = self.bundle_dir / rel
            if not path.exists():
                errors.append(f""missing file {rel}"")
                continue
            digest = hashlib.sha256(path.read_bytes()).hexdigest()
            if digest != expected:
                errors.append(f""checksum mismatch for {rel}"")
",src/meta_agent/bundle_validator.py,BundleValidator
survived,"    def _run_tests(self, errors: List[str]) -> None:
        result = subprocess.run(
            [""pytest"", ""-x""],
            cwd=self.bundle_dir,
            capture_output=True,
            text=True,
        )
        if result.returncode != 0:
            errors.append(""tests failed"")
",src/meta_agent/bundle_validator.py,BundleValidator
survived,"    def validate(self) -> ValidationResult:
        errors: List[str] = []
        try:
            metadata = self._load_metadata()
        except Exception as exc:  # pragma: no cover - invalid json path rare
            errors.append(f""invalid bundle metadata: {exc}"")
            return ValidationResult(success=False, errors=errors, coverage=0.0)

        self._validate_checksums(metadata, errors)
        self._validate_requirements(errors)
        self._validate_agent(errors)

        if not errors:
            self._run_tests(errors)

        success = not errors
        return ValidationResult(success=success, errors=errors, coverage=0.0)",src/meta_agent/bundle_validator.py,BundleValidator
survived,"def test_bundle_validator_success(tmp_path: Path) -> None:
    bundle_dir = create_sample_bundle(tmp_path)
    validator = BundleValidator(bundle_dir)
    result = validator.validate()
    assert result.success is True
    assert result.errors == []
",tests/test_bundle_validator.py,
survived,"def test_bundle_validator_success(tmp_path: Path) -> None:
    bundle_dir = create_sample_bundle(tmp_path)
    validator = BundleValidator(bundle_dir)
    result = validator.validate()
    assert result.success is True
    assert result.errors == []
",tests/test_bundle_validator.py,
survived,"def main() -> None:
    args = _parse_args()
    os.environ[""DEMO_ASSETS_REV""] = args.revision
    from data_feeds import OFFLINE_URLS  # noqa: E402

    offline_dir = Path(__file__).parent / ""offline_samples""
    offline_dir.mkdir(exist_ok=True)

    for name, url in OFFLINE_URLS.items():
        dest = offline_dir / name
        tmp = dest.with_suffix("".tmp"")
        print(f""Downloading {url} -> {dest}"")
        try:
            with urlopen(url, timeout=10) as r, open(tmp, ""wb"") as f:
                f.write(r.read())
            os.replace(tmp, dest)
        except Exception as exc:  # pragma: no cover - network errors
            if tmp.exists():
                tmp.unlink()
            print(f""Failed to download {url}: {exc}"", file=sys.stderr)
            raise SystemExit(1) from exc
",alpha_factory_v1/demos/macro_sentinel/refresh_offline_data.py,
deleted,"    def message_dicts(self) -> List[dict[str, str | None]]:
        return [{""role"": m.role, ""content"": m.content} for m in self._messages]
",libs/core/kiln_ai/adapters/chat/chat_formatter.py,ChatFormatter
survived,"def test_chat_formatter_final_and_intermediate():
    training_data = ModelTrainingData(
        input=""test input"",
        system_message=""system message"",
        final_output=""test output"",
        thinking=""thinking output"",
        thinking_instructions=""thinking instructions"",
        thinking_final_answer_prompt=COT_FINAL_ANSWER_PROMPT,
    )
    expected = generate_chat_message_response(training_data)[""messages""]

    formatter = get_chat_formatter(
        strategy=ChatStrategy.final_and_intermediate,
        system_message=""system message"",
        user_input=""test input"",
        thinking_instructions=""thinking instructions"",
    )

    first = formatter.next_turn()
    assert [m.__dict__ for m in first] == expected[:3]

    second = formatter.next_turn(""thinking output"")
    assert [m.__dict__ for m in second] == expected[3:5]

    assert formatter.next_turn(""test output"") is None
    assert formatter.message_dicts() == expected
",libs/core/kiln_ai/adapters/chat/test_chat_formatter.py,
survived,"    async def post(
        self,
        url: str,
        data: Optional[bytes] = None,
        json: Optional[JSON] = None,
        headers: Optional[dict[str, str]] = None,
    ) -> ClientResponse:
        body = json if json is not None else data
        return await self.request(url, ""post"", headers=headers, body=body)",src/tests/http/clients/webob.py,WebobHttpClient
survived,"    def __init__(self, request: Request) -> None:
        self.request = request
",src/graphql_server/webob/views.py,WebobHTTPRequestAdapter
survived,"def process_module(path):
    path = Path(path)
    if path in processed:
        return
    code = path.read_text()
    for dep in find_deps(code):
        if dep.startswith(ALIAS_PREFIX):
            dep_path = (ALIAS_TARGET / dep[len(ALIAS_PREFIX):]).resolve()
        else:
            dep_path = (path.parent / dep).resolve()
            if not dep_path.exists():
                dep_path = (ROOT / dep.lstrip(""./"")).resolve()
        if dep_path.exists():
            process_module(dep_path)
    # strip import lines
    code = re.sub(r""^\s*import[^\n]*\n"", """", code, flags=re.MULTILINE)
    # strip export keywords
    code = re.sub(r""^\s*export\s+"", """", code, flags=re.MULTILINE)
    processed[path] = code
    order.append(path)
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/manual_build.py,
survived,"def _build_local_site(repo_root: Path) -> bool:
    """"""Return ``True`` if the gallery was built successfully.""""""
    script = repo_root / ""scripts"" / ""build_gallery_site.sh""
    if not script.is_file():
        return False
    try:
        subprocess.run([str(script)], check=True)
    except Exception:
        return False
    return True
",scripts/open_gallery.py,
survived,"def _ledger(tmp: Path) -> insight_logging.Ledger:
    led = insight_logging.Ledger(str(tmp / ""led.db""), broadcast=False)
    env = messaging.Envelope(sender=""a"", recipient=""b"", payload={""v"": 1}, ts=0.0)
    led.log(env)
    return led
",tests/test_mutator.py,
survived,"def select_parent_weighted(population: Sequence[Any]) -> Any:
    """"""Return a parent weighted by fitness Ã— children-with-edit-ability.""""""
    if not population:
        raise ValueError(""population is empty"")
    weights = []
    for ind in population:
        fitness = float(getattr(ind, ""fitness"", getattr(ind, ""score"", 0.0)))
        edits = float(getattr(ind, ""edit_children_count"", 0.0))
        weights.append(max(fitness * edits, 0.0))
    total = sum(weights)
    if total <= 0:
        index = int(np.random.choice(len(population)))
    else:
        probs = np.asarray(weights, dtype=float) / total
        index = int(np.random.choice(len(population), p=probs))
    metrics.dgm_parents_selected_total.inc()
    return population[index]
",src/archive/selector.py,
survived,"    def __init__(self, *a: object, **_k: object) -> None:
        pass
",tests/resources/openai_agents.py,OpenAIAgent
survived,"    def register(self, *_a: object, **_k: object) -> None:
        pass
",tests/resources/openai_agents.py,AgentRuntime
survived,"        def get_proxied_curl_async_session(impersonate=""chrome120"", **kw):
            if CurlAsyncSession:
                return CurlAsyncSession(proxies=proxies, impersonate=impersonate, **kw)
            raise ImportError(""curl_cffi is not installed"")
",webscout/Provider/TTI/base.py,ProxyAutoMeta
survived,"def test_call_attributes_update_and_delete_forbidden(client):
    @weave.op()
    def my_op():
        call = call_context.get_current_call()
        with pytest.raises(TypeError):
            call.attributes.update({""extra"": 1})
        with pytest.raises(TypeError):
            del call.attributes[""weave""]
        return 1

    with weave.attributes({""env"": ""prod""}):
        my_op()
    calls = list(client.get_calls())
    assert len(calls) == 1
    # Original attribute is preserved
    assert calls[0].attributes[""env""] == ""prod""
    assert ""extra"" not in calls[0].attributes
",tests/trace/test_current_call.py,
survived,"    def test_reward_backends_produce_floats(self) -> None:
        names = reward_backends.list_rewards()
        self.assertTrue(names)
        for name in names:
            val = reward_backends.reward_signal(name, {}, None, {})
            self.assertIsInstance(val, float)
            self.assertGreaterEqual(val, 0.0)
            self.assertLessEqual(val, 1.0)
",tests/test_era_experience.py,TestEraOfExperience
survived,"    def test_create_parse_plan_invalid_segment(self):
        with self.assertRaises(ParseException) as cm:
            hl7.parser.create_parse_plan(""PID|^~\\&|GHH LAB"")
        self.assertIn(""must be one of MSH, FHS or BHS"", cm.exception.args[0])",tests/test_parse.py,ParsePlanTest
survived,"    def __init__(self, sandbox_manager: Optional[SandboxManager] = None) -> None:
        self.sandbox_manager = sandbox_manager or SandboxManager()
",src/meta_agent/evaluation/execution.py,ExecutionModule
survived,"    def setUp(self):
        os.environ[""VECTOR_STORE_USE_SQLITE""] = ""true""
        os.environ.pop(""PGHOST"", None)
        self.fabric = memf.MemoryFabric()
        memf._MET_V_SRCH = None
",tests/test_memory_fabric_sqlite.py,TestMemoryFabricSQLiteClose
survived,"def main() -> int:
    repo_root = Path(__file__).resolve().parents[1]
    snippet_path = repo_root / ""docs"" / ""DISCLAIMER_SNIPPET.md""
    disclaimer_text = snippet_path.read_text(encoding=""utf-8"").splitlines()[0].strip()

    missing: list[Path] = []
    for path in repo_root.rglob(""*.md""):
        if path == snippet_path or "".git"" in path.parts:
            continue
        try:
            first_line = path.read_text(encoding=""utf-8"").splitlines()[0].strip()
        except Exception:
            first_line = """"
        if ""docs/DISCLAIMER_SNIPPET.md"" not in first_line and not first_line.startswith(disclaimer_text):
            missing.append(path)

    if missing:
        print(""Missing disclaimer snippet in the following files:"", file=sys.stderr)
        for p in missing:
            print(f""  {p.relative_to(repo_root)}"", file=sys.stderr)
        return 1
    return 0
",scripts/verify_disclaimer_snippet.py,
survived,"def test_utc_now_timezone():
    assert utc_now().endswith(""+00:00"")",tests/test_agent_runner_utils.py,
survived,"    async def _start_streaming(
        cls,
        starting_input: str | list[TResponseInputItem],
        streamed_result: RunResultStreaming,
        starting_agent: Agent[TContext],
        max_turns: int,
        hooks: RunHooks[TContext],
        context_wrapper: RunContextWrapper[TContext],
        run_config: RunConfig,
        previous_response_id: str | None,
    ):
        if streamed_result.trace:
            streamed_result.trace.start(mark_as_current=True)

        current_span: Span[AgentSpanData] | None = None
        current_agent = starting_agent
        current_turn = 0
        should_run_agent_start_hooks = True
        tool_use_tracker = AgentToolUseTracker()

        streamed_result._event_queue.put_nowait(AgentUpdatedStreamEvent(new_agent=current_agent))

        try:
            while True:
                if streamed_result.is_complete:
                    break

                all_tools = await cls._get_all_tools(current_agent, context_wrapper)

                # Start an agent span if we don't have one. This span is ended if the current
                # agent changes, or if the agent loop ends.
                if current_span is None:
                    handoff_names = [h.agent_name for h in cls._get_handoffs(current_agent)]
                    if output_schema := cls._get_output_schema(current_agent):
                        output_type_name = output_schema.name()
                    else:
                        output_type_name = ""str""

                    current_span = agent_span(
                        name=current_agent.name,
                        handoffs=handoff_names,
                        output_type=output_type_name,
                    )
                    current_span.start(mark_as_current=True)
                    tool_names = [t.name for t in all_tools]
                    current_span.span_data.tools = tool_names
                current_turn += 1
                streamed_result.current_turn = current_turn

                if current_turn > max_turns:
                    _error_tracing.attach_error_to_span(
                        current_span,
                        SpanError(
                            message=""Max turns exceeded"",
                            data={""max_turns"": max_turns},
                        ),
                    )
                    streamed_result._event_queue.put_nowait(QueueCompleteSentinel())
                    break

                if current_turn == 1:
                    # Run the input guardrails in the background and put the results on the queue
                    streamed_result._input_guardrails_task = asyncio.create_task(
                        cls._run_input_guardrails_with_queue(
                            starting_agent,
                            starting_agent.input_guardrails + (run_config.input_guardrails or []),
                            copy.deepcopy(ItemHelpers.input_to_new_input_list(starting_input)),
                            context_wrapper,
                            streamed_result,
                            current_span,
                        )
                    )
                try:
                    turn_result = await cls._run_single_turn_streamed(
                        streamed_result,
                        current_agent,
                        hooks,
                        context_wrapper,
                        run_config,
                        should_run_agent_start_hooks,
                        tool_use_tracker,
                        all_tools,
                        previous_response_id,
                    )
                    should_run_agent_start_hooks = False

                    streamed_result.raw_responses = streamed_result.raw_responses + [
                        turn_result.model_response
                    ]
                    streamed_result.input = turn_result.original_input
                    streamed_result.new_items = turn_result.generated_items

                    if isinstance(turn_result.next_step, NextStepHandoff):
                        current_agent = turn_result.next_step.new_agent
                        current_span.finish(reset_current=True)
                        current_span = None
                        should_run_agent_start_hooks = True
                        streamed_result._event_queue.put_nowait(
                            AgentUpdatedStreamEvent(new_agent=current_agent)
                        )
                    elif isinstance(turn_result.next_step, NextStepFinalOutput):
                        streamed_result._output_guardrails_task = asyncio.create_task(
                            cls._run_output_guardrails(
                                current_agent.output_guardrails
                                + (run_config.output_guardrails or []),
                                current_agent,
                                turn_result.next_step.output,
                                context_wrapper,
                            )
                        )

                        try:
                            output_guardrail_results = await streamed_result._output_guardrails_task
                        except Exception:
                            # Exceptions will be checked in the stream_events loop
                            output_guardrail_results = []

                        streamed_result.output_guardrail_results = output_guardrail_results
                        streamed_result.final_output = turn_result.next_step.output
                        streamed_result.is_complete = True
                        streamed_result._event_queue.put_nowait(QueueCompleteSentinel())
                    elif isinstance(turn_result.next_step, NextStepRunAgain):
                        pass
                except AgentsException as exc:
                    streamed_result.is_complete = True
                    streamed_result._event_queue.put_nowait(QueueCompleteSentinel())
                    exc.run_data = RunErrorDetails(
                        input=streamed_result.input,
                        new_items=streamed_result.new_items,
                        raw_responses=streamed_result.raw_responses,
                        last_agent=current_agent,
                        context_wrapper=context_wrapper,
                        input_guardrail_results=streamed_result.input_guardrail_results,
                        output_guardrail_results=streamed_result.output_guardrail_results,
                    )
                    raise
                except Exception as e:
                    if current_span:
                        _error_tracing.attach_error_to_span(
                            current_span,
                            SpanError(
                                message=""Error in agent run"",
                                data={""error"": str(e)},
                            ),
                        )
                    streamed_result.is_complete = True
                    streamed_result._event_queue.put_nowait(QueueCompleteSentinel())
                    raise

            streamed_result.is_complete = True
        finally:
            if current_span:
                current_span.finish(reset_current=True)
            if streamed_result.trace:
                streamed_result.trace.finish(reset_current=True)
",src/agents/run.py,DefaultAgentRunner
survived,"        def __init__(self, *a, **kw) -> None:
            captured[""base_url""] = kw.get(""base_url"")
",tests/test_macro_agent_base_url.py,DummyOpenAI
survived,"def test_error_threshold_restart(monkeypatch) -> None:
    monkeypatch.setenv(""AGENT_ERR_THRESHOLD"", ""2"")

    events: list[str] = []

    class DummyLedger:
        def __init__(self, *_a, **_kw) -> None:
            pass

        def log(self, env) -> None:  # type: ignore[override]
            if env.payload.get(""event""):
                events.append(env.payload[""event""])

        def start_merkle_task(self, *_a, **_kw) -> None:
            pass

        async def stop_merkle_task(self) -> None:
            pass

        def close(self) -> None:
            pass

    settings = config.Settings(bus_port=0)
    monkeypatch.setattr(orchestrator, ""Ledger"", DummyLedger)
    monkeypatch.setattr(
        orchestrator.Orchestrator,
        ""_init_agents"",
        lambda self: [FailingAgent(self.bus, self.ledger)],
    )
    orch = orchestrator.Orchestrator(settings)
    runner = orch.runners[""fail""]

    async def run() -> None:
        await orch.bus.start()
        runner.start(orch.bus, orch.ledger)
        monitor = asyncio.create_task(orch._monitor())
        await asyncio.sleep(3)
        monitor.cancel()
        with contextlib.suppress(asyncio.CancelledError):
            await monitor
        if runner.task:
            runner.task.cancel()
            with contextlib.suppress(asyncio.CancelledError):
                await runner.task
        await orch.bus.stop()

    asyncio.run(run())

    assert ""restart"" in events",tests/test_orchestrator.py,
survived,"        def log(self, env) -> None:  # type: ignore[override]
            if env.payload.get(""event""):
                events.append(env.payload[""event""])
",tests/test_orchestrator.py,DummyLedger
survived,"        def close(self) -> None:
            pass
",tests/test_orchestrator.py,DummyLedger
survived,"    def _random_ip(self) -> str:
        return self.rotate_ip()
",webscout/litagent/agent.py,LitAgent
survived,"def test_improve_repo_cleanup(tmp_path: Path) -> None:
    repo_dir = tmp_path / ""repo""
    repo_dir.mkdir()
    _init_repo(repo_dir)

    patch = """"""--- a/metric.txt\n+++ b/metric.txt\n@@\n-1\n+2\n""""""
    patch_file = tmp_path / ""patch.diff""
    patch_file.write_text(patch)
    log_file = tmp_path / ""log.json""

    delta, clone = self_improver.improve_repo(
        str(repo_dir), str(patch_file), ""metric.txt"", str(log_file), cleanup=True
    )

    assert delta == 1
    assert not clone.exists()
",tests/test_self_improver.py,
survived,"async def api_frame_assets_rename(
    id: int,
    src: str = Form(...),
    dst: str = Form(...),
    db: Session = Depends(get_db),
    redis: Redis = Depends(get_redis),
):
    frame = db.get(Frame, id) or _not_found()

    s_rel = src.lstrip(""/"")
    d_rel = dst.lstrip(""/"")
    if any(x in s_rel for x in ["".."", ""*""]) or os.path.isabs(s_rel):
        _bad_request(""Invalid source path"")
    if any(x in d_rel for x in ["".."", ""*""]) or os.path.isabs(d_rel):
        _bad_request(""Invalid destination path"")

    assets_path = frame.assets_path or ""/srv/assets""
    src_full = os.path.normpath(os.path.join(assets_path, s_rel))
    dst_full = os.path.normpath(os.path.join(assets_path, d_rel))
    if not src_full.startswith(
        os.path.normpath(assets_path)
    ) or not dst_full.startswith(os.path.normpath(assets_path)):
        _bad_request(""Invalid asset path"")

    await rename_path(db, redis, frame, src_full, dst_full)
    return {""message"": ""Renamed""}
",backend/app/api/frames.py,
survived,"async def file_delete_on_frame(frame_id: int, path: str, timeout: int = 60):
    """"""Delete a file or directory on the frame via agent.""""""
    payload = {
        ""type"": ""cmd"",
        ""name"": ""file_delete"",
        ""args"": {""path"": path},
    }
    fut, _ = queue_command(frame_id, payload)
    return await asyncio.wait_for(fut, timeout=timeout)
",backend/app/ws/agent_ws.py,
survived,"    def slash(self, agent_id: str) -> None:
        """"""Burn 10% of ``agent_id`` stake.""""""
        self.registry.burn(agent_id, 0.1)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/orchestrator.py,Orchestrator
survived,"    def _migrate_legacy(self) -> None:
        json_path = self.path.with_name(""archive.json"")
        if not json_path.exists():
            return
        try:
            records = json.loads(json_path.read_text())
        except Exception:
            return
        with Session(self.engine) as session:
            for rec in records:
                row = _ArchiveRow(
                    hash=rec[""hash""],
                    parent=rec.get(""parent""),
                    score=rec.get(""score"", 0.0),
                    novelty=rec.get(""novelty"", 0.0),
                    is_live=rec.get(""is_live"", True),
                    ts=rec.get(""ts"", time.time()),
                )
                session.merge(row)
            session.commit()
",src/archive/db.py,ArchiveDB
survived,"def test_select_parent_temperature() -> None:
    pop = [
        Candidate(1.0, 1.0),
        Candidate(0.5, 2.0),
        Candidate(2.0, 0.5),
    ]
    temp = 0.5
    expected = softmax(np.asarray([p.fitness * p.novelty for p in pop]) / temp)
    observed = sample_distribution(pop, temp)
    assert np.allclose(observed, expected, atol=0.02)",tests/test_selector.py,
survived,"def select_parent(population: Sequence[Any], temp: float) -> Any:
    """"""Return a candidate chosen via softmax of ``fitness * novelty``.

    Args:
        population: Sequence of candidates exposing ``fitness`` and ``novelty`` attributes.
        temp: Softmax temperature. Higher values yield a more uniform distribution.

    Returns:
        The selected candidate from ``population``.
    """"""
    if not population:
        raise ValueError(""population is empty"")
    if temp <= 0:
        raise ValueError(""temp must be positive"")

    scores = np.asarray([float(getattr(ind, ""fitness"")) * float(getattr(ind, ""novelty"")) for ind in population])
    logits = scores / temp
    weights = np.exp(logits - np.max(logits))
    probs = weights / weights.sum()

    index = int(np.random.choice(len(population), p=probs))
    return population[index]",src/archive/selector.py,
survived,"def count_backtracks(db_path: str | Path = DEFAULT_DB) -> List[int]:
    """"""Return backtrack counts for each chain in ``db_path``.""""""
    db_path = Path(db_path)
    entries = _load_entries(db_path)
    entry_map = {e.hash: e for e in entries}
    parents = {e.parent for e in entries if e.parent}
    leaves = [e.hash for e in entries if e.hash not in parents]
    counts: List[int] = []
    for leaf in leaves:
        history = [entry_map[h.hash] for h in ArchiveDB(db_path).history(leaf)]
        count = sum(
            1
            for child, parent in zip(history, history[1:])
            if child.score < parent.score
        )
        counts.append(count)
    return counts
",src/tools/analyse_backtrack.py,
survived,"    def _validate_inputs(
        self,
        code_directory: Path,
        command: list[str],
        mem_limit: str,
        cpu_shares: int,
    ) -> None:
        """"""Validate inputs and resource limits for sandbox execution.""""""
        if not code_directory.is_dir():
            raise FileNotFoundError(f""Code directory not found: {code_directory}"")

        if not command or any(
            not isinstance(c, str) or any(x in c for x in ["";"", ""&"", ""|"", ""`"", ""\n""])
            for c in command
        ):
            raise ValueError(""Invalid command passed to sandbox"")

        if cpu_shares <= 0 or cpu_shares > MAX_CPU_SHARES:
            raise ValueError(""cpu_shares out of allowed range"")

        if mem_limit[-1].lower() not in {""m"", ""g""} or not mem_limit[:-1].isdigit():
            raise ValueError(""mem_limit must be like '256m' or '1g'"")
",src/meta_agent/sandbox/sandbox_manager.py,SandboxManager
survived,"def test_invalid_command(monkeypatch, tmp_path):
    fake_client = MagicMock()
    fake_client.ping.return_value = None
    monkeypatch.setattr(sm.docker, ""from_env"", lambda: fake_client)
    manager = SandboxManager()
    code_dir = tmp_path / ""code""
    code_dir.mkdir()
    with pytest.raises(ValueError):
        manager.run_code_in_sandbox(code_dir, [""python; rm -rf /""])
",tests/unit/test_sandbox_manager.py,
survived,"def test_suspicious_output_logs(monkeypatch, tmp_path, caplog):
    fake_client = MagicMock()
    fake_client.ping.return_value = None
    container = MagicMock()
    container.wait.return_value = {""StatusCode"": 0}
    container.logs.side_effect = [b""Traceback error"", b""""]
    fake_client.containers.run.return_value = container

    monkeypatch.setattr(sm.docker, ""from_env"", lambda: fake_client)
    manager = SandboxManager()
    code_dir = tmp_path / ""code""
    code_dir.mkdir()
    with caplog.at_level(""WARNING"", logger=""meta_agent.sandbox.sandbox_manager""):
        manager.run_code_in_sandbox(code_dir, [""python""])
    assert any(""Suspicious output"" in r.getMessage() for r in caplog.records)",tests/unit/test_sandbox_manager.py,
survived,"def from_env():
    raise DockerException(""Docker not available in test environment"")",docker/__init__.py,
survived,"    def __init__(self, stream=None, level: LogLevel = LogLevel.DEBUG):
        super().__init__(level)
        self.stream = stream or os.sys.stdout
",webscout/litlogger/handlers.py,ConsoleHandler
survived,"def load_remote_models(url: str) -> None:
    if os.environ.get(""KILN_SKIP_REMOTE_MODEL_LIST"") == ""true"":
        return

    async def fetch_and_replace() -> None:
        try:
            models = await asyncio.to_thread(load_from_url, url)
            built_in_models[:] = models
        except Exception:
            pass

    asyncio.get_event_loop().create_task(fetch_and_replace())
",libs/core/kiln_ai/adapters/remote_config.py,
survived,"    def __init__(self, text=""""):
        self.encoding = ""utf-8""
        self.headers = {""Content-Type"": ""text/html""}
        self.text = text
",tests/conftest.py,_Response
survived,"def test_build_with_regex():
    scraper = AutoScraper()
    scraper.build(html=HTML_COMPLEX, wanted_list=[re.compile(""Ban.*"")])
    result = scraper.get_result_exact(html=HTML_COMPLEX)
    assert ""Banana"" in result[0]
",tests/integration/test_complex_features.py,
survived,"def test_grouping_and_rule_removal():
    scraper = AutoScraper()
    wanted = [
        ""Sony PlayStation 4 PS4 Pro 1TB 4K Console - Black"",
        ""US $349.99"",
        ""4.8"",
        ""See details"",
    ]
    scraper.build(html=HTML_PAGE_1, wanted_list=wanted)
    grouped = scraper.get_result_exact(html=HTML_PAGE_2, grouped=True)
    unwanted = [r for r, v in grouped.items() if v == [""See details""]]
    scraper.remove_rules(unwanted)
    result = scraper.get_result_exact(html=HTML_PAGE_2)
    assert result == [
        ""Acer Predator Helios 300 15.6'' 144Hz FHD Laptop i7-9750H 16GB 512GB GTX 1660 Ti"",
        ""US $1,229.49"",
        ""5.0"",
    ]
",tests/integration/test_real_world.py,
survived,"def test_labels_allow_unsafe_true():
    runner = ScenarioRunner(uri=GMT_DIR, uri_type='folder', filename='tests/data/usage_scenarios/labels_stress_forbidden.yml', allow_unsafe=True, skip_system_checks=True, dev_no_metrics=True, dev_no_phase_stats=True, dev_no_sleeps=True, dev_cache_build=True)
    with Tests.RunUntilManager(runner) as context:
        context.run_until('setup_services')
        labels = get_labels()

    assert 'LABEL_ALLOWED' in labels, Tests.assertion_info('LABEL_ALLOWED in labels', labels)
    assert 'LABEL_TOO_LONG' in labels, Tests.assertion_info('LABEL_TOO_LONG in labels', labels)
",tests/test_usage_scenario.py,
survived,"    def _start():
        task = asyncio.create_task(start_server())
        task_future.set_result(task)
",klongpy/web/sys_fn_web.py,
survived,"    def tearDown(self):
        if self.handle is not None and self.handle.task is not None:
            asyncio.run_coroutine_threadsafe(self.handle.shutdown(), self.ioloop).result()
        cleanup_repl(self.loops)
",tests/test_sys_fn_web.py,TestSysFnWeb
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/job/compiler/py/q2.py,
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/job/compiler/py/q10.py,
survived,"def test_Q6_finds_marvel_movie_with_Robert_Downey():
    assert result == [
        {
            ""movie_keyword"": ""marvel-cinematic-universe"",
            ""actor_name"": ""Downey Robert Jr."",
            ""marvel_movie"": ""Iron Man 3"",
        }
    ]
",tests/dataset/job/compiler/py/q6.py,
survived,"def _min(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""min() expects list or group"")
    vals = [it for it in v if it is not None]
    if not vals:
        return 0
    return min(vals)
",tests/dataset/job/compiler/py/q3.py,
survived,"        async def run(self, *_: Any, **__: Any) -> Dict[str, Any]:
            return {""status"": ""error"", ""error"": ""agents SDK unavailable""}
",src/meta_agent/agents/guardrail_designer_agent.py,_Agent
survived,"        def run(self, _prompt: str) -> str:
            return ""ok""
",tests/test_adk_gateway.py,DummyAgent
survived,"def _agent_base():
    """"""Return the canonical AgentBase implementation.""""""

    try:
        from backend.agents.base import AgentBase  # type: ignore

        return AgentBase
    except ModuleNotFoundError:  # pragma: no cover - legacy only
        from backend.agent_base import AgentBase  # type: ignore

        return AgentBase
",alpha_factory_v1/backend/agents/registry.py,
survived,"def register(cls=None, *, condition=True):  # type: ignore
    """"""Decorator adding an :class:`AgentBase` subclass to the registry.""""""

    def decorator(inner_cls):
        from_backend_base = _agent_base()
        if not issubclass(inner_cls, from_backend_base):
            raise TypeError(""register() only allowed on AgentBase subclasses"")

        cond_result = condition() if callable(condition) else bool(condition)
        if cond_result:
            meta = AgentMetadata(
                name=getattr(inner_cls, ""NAME"", inner_cls.__name__),
                cls=inner_cls,
                version=getattr(inner_cls, ""__version__"", ""0.1.0""),
                capabilities=list(getattr(inner_cls, ""CAPABILITIES"", [])),
                compliance_tags=list(getattr(inner_cls, ""COMPLIANCE_TAGS"", [])),
                requires_api_key=getattr(inner_cls, ""REQUIRES_API_KEY"", False),
            )
            _register(meta, overwrite=False)
        else:
            logger.info(
                ""Agent %s not registered (condition=false)"",
                getattr(inner_cls, ""NAME"", inner_cls.__name__),
            )
        return inner_cls

    return decorator(cls) if cls is not None else decorator
",alpha_factory_v1/backend/agents/registry.py,
survived,"    async def step(self) -> None:
        await asyncio.sleep(self.SLEEP)
",alpha_factory_v1/backend/agents/registry.py,StubAgent
survived,"        def _agents(self: orchestrator.Orchestrator) -> list[BaseAgent]:
            return [FreezeAgent(self.bus, self.ledger)]
",tests/test_insight_orchestrator_restart.py,TestInsightOrchestratorRestart
survived,"    def test_int(self):
        r = self.klong(',1')
        self.assertTrue(kg_equal(r, np.asarray([1])))
",tests/test_eval_monad_list.py,TestEvalMonadList
survived,"def handle_heartbeat(runners: Dict[str, AgentRunner], env: object) -> None:
    """"""Update the heartbeat timestamp for ``env.sender`` if it exists.""""""
    payload = getattr(env, ""payload"", None)
    if payload and getattr(payload, ""get"", lambda *_: None)(""heartbeat""):
        sender = getattr(env, ""sender"", None)
        if sender in runners:
            r = runners[sender]
            r.last_beat = getattr(env, ""ts"", time.time())
            r.restart_streak = 0",alpha_factory_v1/backend/agent_supervisor.py,
survived,"def _load_providers(
    osm_file: Path, walking_profile: WalkingProfile
) -> tuple[OSMNetworkProvider | None, OSMAccessProvider | None, float]:
    """"""Load OSM providers for benchmarking.""""""

    start_time = time.time()
    try:
        network_provider = OSMNetworkProvider(
            osm_file,
            walking_profile=walking_profile,
        )
        access_provider = OSMAccessProvider(
            parser=network_provider.parser,
            walking_profile=walking_profile,
            search_radius_m=150.0,
            max_nearby_nodes=5,
            build_index=True,
        )
    except Exception as e:  # pragma: no cover - demo helper
        print(f""âŒ Error loading OSM data: {e}"")
        return None, None, 0.0

    load_time = time.time() - start_time
    print(f""âœ… OSM data loaded in {load_time:.2f} seconds"")
    print(
        f""   Network: {network_provider.node_count} nodes, {network_provider.way_count} ways""
    )

    return network_provider, access_provider, load_time
",python/examples/osm_cache_performance_test.py,
survived,"def test_demo_terraform_validate(tf_file: str) -> None:
    env = os.environ.copy()
    with tempfile.TemporaryDirectory() as tmpdir:
        tmp_path = Path(tmpdir)
        shutil.copy(TERRAFORM_DIR / tf_file, tmp_path / tf_file)
        subprocess.run(
            [""terraform"", ""init"", ""-backend=false"", ""-input=false""],
            cwd=tmp_path,
            check=True,
            env=env,
        )
        subprocess.run(
            [""terraform"", ""validate"", ""-no-color""],
            cwd=tmp_path,
            check=True,
            env=env,
        )",tests/test_alpha_agi_insight_v1_terraform.py,
survived,"async def test_broadcast_merkle_root_devnet_e2e() -> None:
    if os.getenv(""PYTEST_NET_OFF"") == ""1"" or not await _devnet_available():
        pytest.skip(""network disabled or devnet unreachable"")
    tmp = tempfile.TemporaryDirectory()
    ledger = Ledger(os.path.join(tmp.name, ""l.db""), rpc_url=""https://api.devnet.solana.com"", broadcast=True)
    env = messaging.Envelope(""a"", ""b"", {""v"": 1}, 0.0)
    ledger.log(env)
    try:
        await ledger.broadcast_merkle_root()
    finally:
        await ledger.stop_merkle_task()
        ledger.close()
        tmp.cleanup()",tests/test_ledger_devnet_e2e.py,
survived,"    def subscribe(self, topic: str, handler) -> None:  # pragma: no cover - dummy
        pass
",tests/test_safety_guardian_fuzz.py,DummyBus
survived,"        def json(self) -> dict:
            return self._data
",tests/test_cli_runner_ext.py,Dummy
survived,"        def json(self) -> dict:
            return self._data
",tests/test_demo_cli.py,Dummy
survived,"        def f(x):
            return b.sum(b.matmul(x, x))
",tests/test_autograd.py,TestAutograd
survived,"def test_llm_gpu_backend(tmp_path: Path) -> None:
    script = tmp_path / ""run.mjs""
    script.write_text(
        f""globalThis.navigator = {{ gpu: {{}} }};\n""
        f""globalThis.localStorage = {{ getItem: () => null }};\n""
        f""const m = await import('{LLM.resolve().as_posix()}');\n""
        ""console.log(m.gpuBackend());\n""
    )
    res = subprocess.run([""node"", script], capture_output=True, text=True)
    assert res.returncode == 0, res.stderr
    assert res.stdout.strip() == ""webgpu""
",tests/test_gpu_detection.py,
survived,"        def send_alert(message: str, url: str | None = None) -> None:
            _log.warning(""alert: %s"", message)
",alpha_factory_v1/core/interface/api_server.py,alerts
survived,"def run(cmd: Sequence[str], **kwargs: Any) -> None:
    """"""Run ``cmd`` and raise ``CalledProcessError`` on failure.""""""
    print(""+"", "" "".join(cmd))
    subprocess.run(cmd, check=True, **kwargs)
",scripts/publish_demo_gallery.py,
survived,"    def close(cls) -> None:
        rt = cls._runtime
        if not rt:
            return
        fn = getattr(rt, ""shutdown"", None)
        if not callable(fn):
            fn = getattr(rt, ""close"", None)
        if callable(fn):
            try:
                fn()
            except Exception:  # noqa: BLE001
                log.exception(""OpenAI runtime shutdown failed"")
",alpha_factory_v1/backend/orchestrator.py,_OAI
survived,"def _write_executable(path: Path, content: str) -> None:
    path.write_text(content)
    path.chmod(0o755)
",tests/test_world_model_safety.py,
survived,"    async def loop(self, bus: object, ledger: object) -> None:
        """"""Run the agent cycle indefinitely.""""""
        while True:
            start = time.perf_counter()
            try:
                await self.agent.run_cycle()
            except Exception as exc:  # noqa: BLE001
                if hasattr(bus, ""alert""):
                    try:
                        bus.alert(f""{self.agent.name} failed: {exc}"")
                    except Exception:  # pragma: no cover - best effort
                        pass
                self.error_count += 1
            else:
                self.error_count = 0
                self.restart_streak = 0
                env = struct_pb2.Struct()
                env.update({""heartbeat"": True})
                if hasattr(ledger, ""log""):
                    try:
                        ledger.log(env)
                    except Exception:  # pragma: no cover - logging optional
                        pass
                if hasattr(bus, ""publish""):
                    try:
                        bus.publish(""orch"", env)
                    except Exception:  # pragma: no cover - publish optional
                        pass
                self.last_beat = time.time()
            finally:
                if hasattr(bus, ""metrics""):
                    try:
                        bus.metrics.observe(time.perf_counter() - start)
                    except Exception:  # pragma: no cover - metrics optional
                        pass
            await asyncio.sleep(self.period)
",alpha_factory_v1/backend/agent_supervisor.py,AgentRunner
survived,"def main(demo: str) -> None:
    url = _demo_url(demo)
    if _remote_available(url):
        print(f""Opening {url}"")
        webbrowser.open(url)
        return

    repo_root = Path(__file__).resolve().parents[1]
    site_dir = repo_root / ""site"" / demo
    local_page = site_dir / ""index.html""
    if not local_page.is_file():
        print(""Remote page unavailable. Building local copy..."", file=sys.stderr)
        if not _build_local_site(repo_root) or not local_page.is_file():
            print(
                f""Demo {demo} not found. Build the gallery with ./scripts/build_gallery_site.sh"",
                file=sys.stderr,
            )
            sys.exit(1)

    handler = partial(SimpleHTTPRequestHandler, directory=str(site_dir))
    with ThreadingHTTPServer((""127.0.0.1"", 0), handler) as httpd:
        port = httpd.server_address[1]
        local_url = f""http://127.0.0.1:{port}/index.html""
        print(f""Serving local copy at {local_url}"", file=sys.stderr)
        thread = threading.Thread(target=httpd.serve_forever, daemon=True)
        thread.start()
        try:
            webbrowser.open(local_url)
            thread.join()
        except KeyboardInterrupt:
            pass
",scripts/open_demo.py,
survived,"def main() -> None:
    run([""python"", ""alpha_factory_v1/scripts/preflight.py""])
    run([""node"", str(BROWSER_DIR / ""build/version_check.js"")])
    run([""python"", ""scripts/check_python_deps.py""])
    run([""python"", ""check_env.py"", ""--auto-install""])
    run([""python"", ""scripts/verify_disclaimer_snippet.py""])
    run([""python"", ""-m"", ""alpha_factory_v1.demos.validate_demos""])
    run([""python"", ""scripts/publish_demo_gallery.py""])
    run([""python"", ""scripts/verify_workbox_hash.py"", ""site/alpha_agi_insight_v1""])

    try:
        import importlib.util

        if importlib.util.find_spec(""playwright"") is not None:
            with subprocess.Popen(
                [sys.executable, ""-m"", ""http.server"", ""--directory"", ""site"", ""8000""],
                cwd=REPO_ROOT,
            ) as proc:
                try:
                    run([""python"", ""scripts/verify_insight_offline.py""])
                finally:
                    proc.terminate()
        else:
            print(""Playwright not found; skipping offline re-check"", file=sys.stderr)
    except Exception:
        print(""Playwright not found; skipping offline re-check"", file=sys.stderr)
",scripts/edge_human_knowledge_pages_sprint.py,
survived,"def main() -> None:
    url = _subdir_url()
    index = url + ""index.html""
    if _remote_available(index):
        print(f""Opening {index}"")
        webbrowser.open(index)
        return
    repo_root = Path(__file__).resolve().parents[1]
    site_dir = repo_root / ""site""
    local_page = site_dir / ""alpha_factory_v1"" / ""demos"" / ""index.html""
    if not local_page.is_file():
        print(""Remote gallery unavailable. Building local copy..."", file=sys.stderr)
        if not _build_local_site(repo_root) or not local_page.is_file():
            print(
                ""Gallery not found. Build it with ./scripts/build_gallery_site.sh"",
                file=sys.stderr,
            )
            sys.exit(1)

    handler = partial(SimpleHTTPRequestHandler, directory=str(site_dir))
    with ThreadingHTTPServer((""127.0.0.1"", 0), handler) as httpd:
        port = httpd.server_address[1]
        local_url = f""http://127.0.0.1:{port}/alpha_factory_v1/demos/index.html""
        print(f""Remote gallery unavailable. Serving local copy at {local_url}"", file=sys.stderr)

        thread = threading.Thread(target=httpd.serve_forever, daemon=True)
        thread.start()
        try:
            webbrowser.open(local_url)
            thread.join()
        except KeyboardInterrupt:
            pass
",scripts/open_subdir_gallery.py,
survived,"def generate_score_proof(scores: Sequence[float], threshold: float) -> str:
    """"""Return proof that the weighted score exceeds ``threshold``.""""""
    # hidden evaluator weights
    weighted = 0.7 * scores[0] + 0.3 * scores[1]
    if weighted < threshold:
        raise ValueError(""score below threshold"")
    h = _hash_scores(scores)
    blob = json.dumps({""hash"": h, ""threshold"": threshold}, separators=("","", "":"")).encode()
    return sha256(blob).hexdigest()
",src/snark/proof.py,
survived,"def test_get_output_path_without_subdirs(monkeypatch, tmp_path):
    monkeypatch.setenv('NOTES_EXPORT_USE_SUBDIRS', 'false')
    tracker = utils.NotesExportTracker(root_directory=str(tmp_path))
    output = tracker.get_output_path('pdf', 'folder', 'note', '.pdf')
    expected = Path(tmp_path) / 'pdf' / 'note.pdf'
    assert output == expected
    assert output.parent.is_dir()",tests/test_tracker.py,
survived,"def get_provider_instance(provider_class: Any):
    """"""Return a cached instance of the provider, creating it if necessary.""""""
    key = provider_class.__name__
    instance = provider_instances.get(key)
    if instance is None:
        instance = provider_class()
        provider_instances[key] = instance
    return instance
",webscout/Provider/OPENAI/api.py,
survived,"def check_patch_in_sandbox(image: str = DEFAULT_SANDBOX_IMAGE) -> bool:
    """"""Return True if ``/usr/bin/patch`` exists inside ``image``.""""""
    try:
        result = subprocess.run(
            [""docker"", ""run"", ""--rm"", image, ""test"", ""-x"", ""/usr/bin/patch""],
            capture_output=True,
            text=True,
        )
    except Exception as exc:  # pragma: no cover - unexpected failure
        banner(f""Failed to start {image}: {exc}"", ""RED"")
        return False
    if result.returncode == 0:
        banner(f""patch found in {image}"", ""GREEN"")
        return True
    banner(
        f""/usr/bin/patch missing in {image}; build sandbox.Dockerfile or set SANDBOX_IMAGE"",
        ""RED"",
    )
    return False
",alpha_factory_v1/scripts/preflight.py,
survived,"def utc_now() -> str:
    return datetime.now(timezone.utc).isoformat(timespec=""milliseconds"")
",alpha_factory_v1/backend/agent_runner.py,
survived,"    def test_stub_backend_query_returns_edges(self):
        with patch.object(mg, ""_HAS_NEO"", False), patch.object(mg, ""_HAS_NX"", False):
            orig = GraphMemory._fallback_query
            with patch.object(GraphMemory, ""_fallback_query"", autospec=True) as mock_fb:
                mock_fb.side_effect = orig
                g = GraphMemory()
                self.assertEqual(g.backend, ""stub"")
                g.add(""A"", ""REL"", ""B"")
                result = g.query(""MATCH (a)-[r]->(b) RETURN a,b LIMIT 1"")
                self.assertTrue(mock_fb.called)
                self.assertEqual(result, [(""A"", ""B"", ""REL"")])
                g.close()
",tests/test_memory_graph_fallback.py,TestGraphMemoryFallbackQuery
survived,"async def get_product(product_id: int):
    product = next((p for p in PRODUCTS if p[""id""] == product_id), None)
    if not product:
        raise HTTPException(status_code=404, detail=""Product not found"")
    return product
",examples/shop_api_gateway/server.py,
survived,"def padRight(s, w):
    out = s
    i = len(s)
    while i < w:
        out = out + "" ""
        i = i + 1
    return out
",tests/rosetta/transpiler/Python/box-the-compass.py,
survived,"def padLeft(n, width):
    s = str(n)
    while len(s) < width:
        s = "" "" + s
    return s
",tests/rosetta/transpiler/Python/blum-integer.py,
survived,"def main():
    n = True
    print((""true"" if n else ""false""))
    print(""bool"")
    n = not n
    print((""true"" if n else ""false""))
    x = 5
    y = 8
    print(""x == y:"", (1 if x == y else 0))
    print(""x < y:"", (1 if x < y else 0))
    print(""\nConvert String into Boolean Data type\n"")
    str1 = ""japan""
    print(""Before :"", ""string"")
    bolStr = parseBool(str1)
    print(""After :"", ""bool"")
",tests/rosetta/transpiler/Python/boolean-values.py,
survived,"def calkinWilf(n):
    seq = []
    seq = seq + [bigrat(1, 1)]
    i = 1
    while i < n:
        prev = seq[i - 1]
        a = prev.numerator
        b = prev.denominator
        f = a // b
        t = bigrat(f, 1)
        t = t * (Fraction(2))
        t = t - prev
        t = t + (Fraction(1))
        t = (Fraction(1)) // t
        seq = seq + [t]
        i = i + 1
    return seq
",tests/rosetta/transpiler/Python/calkin-wilf-sequence.py,
survived,"def indexOf(s, ch):
    i = 0
    while i < len(s):
        if s[i:i + 1] == ch:
            return i
        i = i + 1
    return -1
",tests/rosetta/transpiler/Python/caesar-cipher-1.py,
survived,"def commatize(n):
    s = str(n)
    out = """"
    i = 0
    cnt = 0
    neg = False
    if s[0:1] == ""-"":
        neg = True
        s = s[1:]
    i = len(s) - 1
    while i >= 0:
        out = """".join(s[i:i + 1]) + out
        cnt = cnt + 1
        if cnt == 3 and i != 0:
            out = "","" + out
            cnt = 0
        i = i - 1
    if neg:
        out = ""-"" + out
    return out
",tests/rosetta/transpiler/Python/calkin-wilf-sequence.py,
survived,"def main():
    i = 1
    print(""initial: "" + str(i))
    tmp = zeroval(i)
    print(""zeroval: "" + str(i))
    box = [i]
    zeroptr(box)
    i = box[0]
    print(""zeroptr: "" + str(i))
    print(""pointer: 0"")
",tests/rosetta/transpiler/Python/call-a-function-11.py,
survived,"def sortInts(xs):
    res = []
    tmp = xs
    while len(tmp) > 0:
        min = tmp[0]
        idx = 0
        i = 1
        while i < len(tmp):
            if tmp[i] < min:
                min = tmp[i]
                idx = i
            i = i + 1
        res = res + [min]
        out = []
        j = 0
        while j < len(tmp):
            if j != idx:
                out = out + [tmp[j]]
            j = j + 1
        tmp = out
    return res
",tests/rosetta/transpiler/Python/brilliant-numbers.py,
survived,"def examineAndModify(f):
    print("" v: {"" + str(f.Exported) + "" "" + str(f.unexported) + ""} = {"" + str(f.Exported) + "" "" + str(f.unexported) + ""}"")
    print(""    Idx Name       Type CanSet"")
    print(""     0: Exported   int  true"")
    print(""     1: unexported int  false"")
    f = dataclasses.replace(f, Exported=16)
    f = dataclasses.replace(f, unexported=44)
    print(""  modified unexported field via unsafe"")
    return f
",tests/rosetta/transpiler/Python/break-oo-privacy.py,
survived,"def ord(ch):
    upper = ""ABCDEFGHIJKLMNOPQRSTUVWXYZ""
    lower = ""abcdefghijklmnopqrstuvwxyz""
    idx = indexOf(upper, ch)
    if idx >= 0:
        return 65 + idx
    idx = indexOf(lower, ch)
    if idx >= 0:
        return 97 + idx
    return 0
",tests/rosetta/transpiler/Python/caesar-cipher-2.py,
survived,"def termNumber(cf):
    b = """"
    d = ""1""
    for n in cf:
        b = repeat(d, n) + b
        if d == ""1"":
            d = ""0""
        else:
            d = ""1""
    return parseIntStr(b, 2)
",tests/rosetta/transpiler/Python/calkin-wilf-sequence.py,
survived,"def import_cmd():
    """"""Import compiled data into a graph database.""""""
",pygs/graphserver/cli.py,
survived,"def cli():
    """"""Graphserver command line utility.""""""
",pygs/graphserver/cli.py,
survived,"def osm(args, tolerant, dryrun):
    """"""Compile one or more OSM files into an OSM database.""""""
    if len(args) < 2:
        raise click.UsageError(""OSM file(s) and destination database required"")
    *osm_files, osmdb_filename = args
    osm_to_osmdb(osm_files, osmdb_filename, tolerant, dryrun)
",pygs/graphserver/cli.py,
survived,"    def admit(self, diff: str, parent: str, repo_dir: str | Path | None = None) -> bool:
        """"""Validate and store ``diff`` with its parent hash.""""""

        repo = Path(repo_dir) if repo_dir else REPO_ROOT
        try:
            run_preflight(repo)
        except Exception:
            return False
        if not _tool_roundtrip():
            return False

        h = hashlib.sha1(diff.encode()).hexdigest()
        entry = json.dumps({""diff"": diff, ""parent"": parent})
        self.db.set_state(f""patch:{h}"", entry)
        self.db.add(
            ArchiveEntry(hash=h, parent=parent, score=0.0, novelty=0.0, is_live=True, ts=time.time())
        )
        return True",src/archive/manager.py,PatchManager
survived,"    def __init__(self, db_path: str | Path) -> None:
        self.db = ArchiveDB(db_path)
",src/archive/manager.py,PatchManager
survived,"def _fitness(g: float) -> float:
    if g > 2:
        return 10.0 - (g - 5.0) ** 2
    return 5.0 - g * g
",experiments/ablate_selector.py,
survived,"def _select_softmax(pop: list[_Candidate]) -> _Candidate:
    return select_parent(pop, beta=1.0, gamma=0.0)
",experiments/ablate_selector.py,
survived,"def get_global_setting(key, default=None):
    conn = get_db()
    c = conn.cursor()
    c.execute('SELECT value FROM global_settings WHERE key=?', (key,))
    row = c.fetchone()
    conn.close()
    if row:
        try:
            return json.loads(row['value'])
        except Exception:
            return row['value']
    return default
",users_db.py,
survived,"def problem_response(exc: HTTPException) -> JSONResponse:
    """"""Return an RFC 7807 compliant response for ``exc``.""""""

    try:
        title = HTTPStatus(exc.status_code).phrase
    except Exception:  # pragma: no cover - unknown status code
        title = str(exc.status_code)

    detail = (
        exc.detail if isinstance(exc.detail, str) else str(exc.detail) if exc.detail else """"
    )

    body: dict[str, Any] = {""type"": ""about:blank"", ""title"": title, ""status"": exc.status_code}
    if detail:
        body[""detail""] = detail

    return JSONResponse(status_code=exc.status_code, content=body)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/problem_json.py,
survived,"def test_governance_sim_cli() -> None:
    """"""Verify the console script prints a result.""""""
    result = subprocess.run(
        [""governance-sim"", ""-N"", ""10"", ""-r"", ""20""],
        check=True,
        capture_output=True,
        text=True,
    )
    assert ""mean cooperation"" in result.stdout.lower()",tests/test_governance_sim_cli.py,
survived,"def indexOf(s, ch):
    i = 0
    while i < len(s):
        if s[i:i + 1] == ch:
            sys.exit(i)
        i = i + 1
    sys.exit(0 - 1)
",tests/rosetta/transpiler/Python/fibonacci-word.py,
survived,"def cstr(a):
    s = ""("" + str(a.re)
    if a.im >= 0:
        s = s + ""+"" + str(a.im) + ""i)""
    else:
        s = s + str(a.im) + ""i)""
    sys.exit(s)
",tests/rosetta/transpiler/Python/eulers-identity.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/euclid-mullin-sequence.py,
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    k = 0.07
    tempRoom = 20.0
    tempObject = 100.0
    fcr = newCoolingRateDy(k, tempRoom)
    analytic = newTempFunc(k, tempRoom, tempObject)
    for step in [2.0, 5.0, 10.0]:
        print(""Step size = "" + fmtF(step, 0, 1))
        print("" Time Euler's Analytic"")
        temp = tempObject
        time = 0.0
        while time <= 100.0:
            line = fmtF(time, 5, 1) + "" "" + fmtF(temp, 7, 3) + "" "" + fmtF(analytic(time), 7, 3)
            print(line)
            temp = eulerStep(fcr, time, temp, step)
            time = time + step
        print("""")
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/euler-method.py,
survived,"def cis(x):
    sys.exit(Complex(re=cosApprox(x), im=sinApprox(x)))
",tests/rosetta/transpiler/Python/eulers-identity.py,
survived,"def fib(n):
    a = 0
    b = 1
    res = []
    i = 0
    while i < n:
        res = res + [a]
        tmp = a + b
        a = b
        i = i + 1
        b = tmp
    sys.exit(res)
",tests/rosetta/transpiler/Python/fibonacci-sequence-4.py,
survived,"def floorf(x):
    y = int(x)
    sys.exit(float(y))
",tests/rosetta/transpiler/Python/feigenbaum-constant-calculation.py,
survived,"def copyFile(out, inp):
    fs[out] = fs.get(inp)
",tests/rosetta/transpiler/Python/file-input-output-2.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/ethiopian-multiplication.py,
survived,"def expf(x):
    if x < 0.0:
        sys.exit(1.0 / expf(-x))
    term = 1.0
    sum = 1.0
    i = 1
    while i < 20:
        term = term * x / (float(i))
        sum = sum + term
        i = i + 1
    sys.exit(sum)
",tests/rosetta/transpiler/Python/euler-method.py,
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    print(""validating "" + str(len(testSet)) + "" test cases"")
    failures = False
    i = 0
    while i < len(testSet):
        tc = testSet[i]
        res = interpret(tc.get(""ruleSet""), tc.get(""sample""))
        if not res.get(""ok""):
            print(""test "" + str(i + 1) + "" invalid ruleset"")
            failures = True
        else:
            if res.get(""out"") != tc.get(""output""):
                print(""test "" + str(i + 1) + "": got "" + res.get(""out"") + "", want "" + tc.get(""output""))
                failures = True
        i = i + 1
    if not failures:
        print(""no failures"")
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/execute-a-markov-algorithm.py,
survived,"def uabs(a, b):
    if a > b:
        sys.exit(a - b)
    sys.exit(b - a)
",tests/rosetta/transpiler/Python/esthetic-numbers.py,
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    copyFile(""output.txt"", ""input.txt"")
    print(fs.get(""output.txt""))
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/file-input-output-2.py,
survived,"def isEsthetic(n, b):
    if n == 0:
        sys.exit(False)
    i = n % b
    n = n // b
    while n > 0:
        j = n % b
        if uabs(i, j) != 1:
            sys.exit(False)
        n = n // b
        i = j
    sys.exit(True)
",tests/rosetta/transpiler/Python/esthetic-numbers.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/events.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/file-input-output-1.py,
survived,"def test_create_sse_app_sets_state():
    server = FastMCP(name=""StateTest"")
    app = create_sse_app(server, message_path=""/message"", sse_path=""/sse"")
    assert app.state.fastmcp_server is server",tests/server/test_app_state.py,
survived,"    def close(self) -> None:  # pragma: no cover - stub
        pass
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_codegen_safety.py,DummyLedger
survived,"    def record_event(
        self,
        category: ""TelemetryCollector.Category"",
        message: str,
        severity: ""TelemetryCollector.Severity"" = Severity.ERROR,
    ) -> None:
        """"""Record an informational or error event.""""""
        self.events.append(
            TelemetryCollector.Event(
                category=category,
                severity=severity,
                message=message,
            )
        )
        log = self.logger.info
        if severity in (self.Severity.ERROR, self.Severity.CRITICAL):
            log = self.logger.error
        elif severity is self.Severity.WARNING:
            log = self.logger.warning
        log(message)
",src/meta_agent/telemetry.py,TelemetryCollector
survived,"def test_math_env_rollout(openai_mock, monkeypatch):  # type: ignore[valid-type]
    """"""Ensure MathEnv produces a correctly graded rollout group.""""""

    # ------------------------------------------------------------------
    # Prepare mock dataset (train & test identical for simplicity)
    # ------------------------------------------------------------------
    example = {
        ""problem"": (
            ""A board game spinner is divided into three parts labeled $A$, $B$  and $C$. ""
            ""The probability of the spinner landing on $A$ is \\frac{1}{3} and the probability ""
            ""of the spinner landing on $B$ is \\frac{5}{12}.  What is the probability of the ""
            ""spinner landing on $C$? Express your answer as a common fraction.""
        ),
        ""level"": ""Level 1"",
        ""type"": ""Counting & Probability"",
        ""solution"": (
            ""The spinner is guaranteed to land on exactly one of the three regions, so we know that ""
            ""the sum of the probabilities of it landing in each region will be 1. If we let the probability ""
            ""of it landing in region $C$ be $x$, we then have the equation $1 = \\frac{5}{12}+\\frac{1}{3}+x$, ""
            ""from which we have $x=\\boxed{\\frac{1}{4}}$.""
        ),
    }
    fake_dataset = {""train"": [example], ""test"": [example]}

    # Monkeypatch datasets.load_dataset to return our fake dataset.
    def _fake_load_dataset(name, *_, **__):
        assert name == ""mock""
        return fake_dataset

    monkeypatch.setattr(datasets, ""load_dataset"", _fake_load_dataset)

    # ------------------------------------------------------------------
    # Prepare mocked OpenAI response (correct answer inside <answer> tags)
    # ------------------------------------------------------------------
    openai_mock.chat.completions.create.response = {
        ""choices"": [
            {
                ""index"": 0,
                ""finish_reason"": ""stop"",
                ""message"": {
                    ""content"": ""Sure! <think>some reasoning</think> <answer>\\frac{1}{4}</answer>"",
                    ""role"": ""assistant"",
                },
            }
        ],
    }

    # ------------------------------------------------------------------
    # Collect rollouts emitted by the environment
    # ------------------------------------------------------------------
    collected: deque[RolloutGroup] = deque()

    def sink(groups):  # type: ignore[override]
        collected.extend(groups)

    env = MathEnv(
        inference=InferenceEndpoint(""https://api.openai.com/v1""),
        rollout_sink=sink,  # type: ignore[arg-type]
        data_source=""mock"",
        split=""train"",
        max_iters=1,
        api_key=""sk-fake"",
        seed=123,
    )

    asyncio.run(env.run())

    # ------------------------------------------------------------------
    # Assertions
    # ------------------------------------------------------------------
    assert len(collected) == 1
    group = collected.pop()
    assert group.metadata[""correct""] is True
    assert group.rollouts[0].turns[1].reward == 1.0

    # The mocked endpoint should have been called exactly once
    assert openai_mock.chat.completions.create.route.call_count == 1",tests/rl/test_math_env.py,
survived,"    async def shutdown(self) -> None:
        pass
",marin/rl/envs/openai_echo.py,ChatEchoEnv
survived,"    async def shutdown(self) -> None:  # pragma: no cover
        pass
",marin/rl/envs/math_env.py,MathEnv
survived,"def _read_first_row(path: Path) -> Dict[str, str] | None:
    """"""Return the first row of a CSV as a mapping or ``None`` if empty.""""""
    if pd is not None:  # use pandas when available for convenience
        try:
            df = pd.read_csv(path)
        except FileNotFoundError:
            raise
        except Exception:  # pragma: no cover - handle corrupt CSV gracefully
            pass
        else:
            if not df.empty:
                return df.iloc[0].to_dict()

    try:
        with open(path, newline="""") as fh:
            reader = csv.DictReader(fh)
            return next(reader, None)
    except FileNotFoundError:
        raise

    return None
",alpha_factory_v1/demos/era_of_experience/alpha_detection.py,
survived,"    async def step(self) -> None:
        await self.publish(""alpha.compliance"", {""status"": ""ok""})
",alpha_factory_v1/demos/alpha_agi_business_v1/alpha_agi_business_v1.py,AlphaComplianceAgent
survived,"async def trigger_market_analysis() -> str:
    resp = requests.post(f""{HOST}/agent/market_analysis/trigger"", timeout=5)
    resp.raise_for_status()
    return ""market_analysis queued""
",alpha_factory_v1/demos/alpha_agi_business_v1/openai_agents_bridge.py,
survived,"async def fetch_logs() -> list[str]:
    """"""Retrieve the latest orchestrator logs via the REST API.""""""
    resp = requests.get(f""{HOST}/api/logs"", timeout=5)
    resp.raise_for_status()
    return resp.json()
",alpha_factory_v1/demos/alpha_agi_business_v1/openai_agents_bridge.py,
survived,"def _parse_args(argv: list[str] | None = None) -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description=""Call BusinessAgent via OpenAI Agents runtime""
    )
    parser.add_argument(
        ""--host"",
        default=os.getenv(""AGENTS_HOST"", ""http://localhost:5001""),
        help=""Base URL for the Agents runtime (default: http://localhost:5001)"",
    )
    parser.add_argument(
        ""--action"",
        default=""recent_alpha"",
        help=""Action to invoke (default: recent_alpha)"",
    )
    parser.add_argument(
        ""--job"",
        help=""Optional JSON file with a custom job payload"",
    )
    return parser.parse_args(argv)
",alpha_factory_v1/demos/alpha_agi_business_v1/examples/openai_agent_client.py,
survived,"    def _wait_and_open() -> None:
        deadline = time.monotonic() + timeout
        while time.monotonic() < deadline:
            try:
                import requests  # type: ignore

                if requests.get(f""{url.rstrip('/')}/healthz"", timeout=1).status_code == 200:
                    webbrowser.open(url, new=1)
                    return
            except Exception:
                time.sleep(0.2)
        # fallback: open anyway
        webbrowser.open(url, new=1)
",alpha_factory_v1/demos/alpha_agi_business_v1/run_business_v1_local.py,
survived,"def _open_browser_when_ready(url: str, timeout: float = 5.0) -> None:
    """"""Open *url* in the default browser once the orchestrator responds.""""""

    def _wait_and_open() -> None:
        deadline = time.monotonic() + timeout
        while time.monotonic() < deadline:
            try:
                import requests  # type: ignore

                if requests.get(f""{url.rstrip('/')}/healthz"", timeout=1).status_code == 200:
                    webbrowser.open(url, new=1)
                    return
            except Exception:
                time.sleep(0.2)
        # fallback: open anyway
        webbrowser.open(url, new=1)

    threading.Thread(target=_wait_and_open, daemon=True).start()
",alpha_factory_v1/demos/alpha_agi_business_v1/run_business_v1_local.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/bitmap-b-zier-curves-quadratic.py,
survived,"def padStart(s, width, pad):
    out = s
    while len(out) < width:
        out = pad + out
    return out
",tests/rosetta/transpiler/Python/bernoulli-numbers.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/compound-data-type.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/conditional-structures-9.py,
survived,"def test_start_stop_logging(caplog: Any) -> None:
    """"""Bus start and stop should emit informative log messages.""""""
    bus = messaging.A2ABus(config.Settings(bus_port=0, broker_url=""kafka:9092""))

    async def run() -> None:
        await bus.start()
        await bus.stop()

    with caplog.at_level(logging.INFO):
        asyncio.run(run())

    messages = [record.getMessage() for record in caplog.records]
    assert any(""A2ABus.start()"" in m for m in messages)
    assert any(""A2ABus.stop()"" in m for m in messages)",tests/test_messaging.py,
survived,"def test_build_tree(tmp_path: Path) -> None:
    db = tmp_path / ""a.db""
    arch = Archive(db)
    arch.add({""diff"": ""root.patch""}, 1.0)
    arch.add({""parent"": 1, ""diff"": ""child.patch""}, 0.6)
    df = ld.load_df(db)
    fig = ld.build_tree(df)
    assert isinstance(fig, go.Figure)
    data = fig.data[0]
    assert len(data.ids) == 2
    assert ""child.patch"" in data.hovertemplate
",tests/test_lineage_dashboard.py,
survived,"    def is_available(cls) -> bool:
        try:
            import importlib

            importlib.import_module(""adk"")
            return True
        except Exception:
            return False
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/adk_adapter.py,ADKAdapter
survived,"def test_rejects_malformed_patch() -> None:
    diff = _read(""malformed_patch.diff"")
    assert not is_patch_valid(diff)",tests/test_patch_validation.py,
survived,"def main() -> None:
    PAGES.mkdir(parents=True, exist_ok=True)
    links = []
    for pdf in sorted(SRC.glob(""*.pdf"")):
        slug = slugify(pdf.stem)
        target = PAGES / pdf.name
        if not target.exists():
            shutil.copy2(pdf, target)
        page = PAGES / f""{slug}.md""
        page.write_text(
            f""# {pdf.stem}\n\n""
            f'<embed src=""{pdf.name}"" type=""application/pdf"" '
            f'width=""100%"" height=""600px"">\n',
            encoding=""utf-8"",
        )
        links.append(f""- [{pdf.stem}](research/{slug}.html)"")
    INDEX.write_text(
        ""# Post-Labor Economics Research\n\n"" + ""\n"".join(links),
        encoding=""utf-8"",
    )
",generate_pdf_pages.py,
survived,"def test_list_profiles_returns_all_names(tmp_path):
    data = """"""\
[default]
username = 'a'
password = 'b'

[second]
username = 'c'
password = 'd'
""""""
    cred_file = tmp_path / ""credentials""
    cred_file.write_text(data, encoding=""UTF-8"")

    profiles = CredentialsProvider.list_profiles(path=str(cred_file))

    assert set(profiles) == {""default"", ""second""}
",tests/dhapi/port/test_credentials_provider.py,
survived,"        def execute_endpoint(payload: Dict[str, Any]) -> Any:
            input_obj = cls.InputSchema(**payload)
            instance = cls()
            result = instance.execute(input_obj.dict())
            return OutputModel(**result)
",servers/server_clear_thought/core/base_tool.py,BaseTool
survived,"def test_seven_seekers_orchestrator():
    client = get_client()
    resp = client.post(
        ""/seven-seekers-orchestrator/execute"",
        json={""query"": ""q""},
    )
    assert resp.status_code == 200
    data = resp.json()
    assert set(data.keys()) == {""seeker_results"", ""resonance_map"", ""synthesis""}
",servers/server_clear_thought/tests/test_new_tools.py,
survived,"def test_existing_tool_example():
    app = create_app()
    client = TestClient(app)
    resp = client.post(""/existing-tool-example/execute"", json={""text"": ""hi""})
    assert resp.status_code == 200
    assert resp.json() == {""echoed"": ""hi""}",servers/server_clear_thought/tests/test_existing_tools.py,
survived,"def load_tools() -> List[Type[BaseTool]]:
    tools: List[Type[BaseTool]] = []
    pkg_dir = Path(__file__).parent / ""tools""
    for module_info in pkgutil.iter_modules([str(pkg_dir)]):
        module = importlib.import_module(f""{__package__}.tools.{module_info.name}"")
        for attr in module.__dict__.values():
            if isinstance(attr, type) and issubclass(attr, BaseTool) and attr is not BaseTool:
                tools.append(attr)
    return tools
",servers/server_clear_thought/app.py,
survived,"def test_value_of_information():
    client = get_client()
    resp = client.post(
        ""/value-of-information/execute"",
        json={""decision_options"": [""a""], ""uncertainties"": [""u""], ""payoffs"": [1.0]},
    )
    assert resp.status_code == 200
    data = resp.json()
    assert set(data.keys()) == {""voi_score"", ""high_impact_questions""}
",servers/server_clear_thought/tests/test_new_tools.py,
survived,"def create_app() -> FastAPI:
    app = FastAPI()
    for tool_cls in load_tools():
        router = tool_cls.get_router()
        app.include_router(router, prefix=tool_cls.endpoint_path, tags=[tool_cls.slug])
    return app",servers/server_clear_thought/app.py,
survived,"    def execute(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        k = payload.get(""k"") or 3
        analogies = [
            {""domain"": d, ""analogy"": f""{payload['problem']} ~ {d}""}
            for d in (payload.get(""seed_domains"") or [""math"", ""biology"", ""art""])[:k]
        ]
        prompts = [f""How would {a['domain']} approach it?"" for a in analogies]
        return {
            ""analogies"": analogies,
            ""suggested_prompts"": prompts,
        }",servers/server_clear_thought/tools/analogical_mapper.py,AnalogicalMapper
survived,"    def execute(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        raise NotImplementedError",servers/server_clear_thought/core/base_tool.py,BaseTool
survived,"    def execute(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        steps = [
            f""Practice {payload['skill']} at level {lvl}""
            for lvl in range(payload[""current_level""], payload[""target_level""] + 1)
        ]
        measures = [""Take breaks"", ""Monitor progress""]
        return {
            ""scaffold_steps"": steps,
            ""safety_measures"": measures,
            ""review_intervals"": ""weekly"",
        }",servers/server_clear_thought/tools/safe_struggle_designer.py,SafeStruggleDesigner
survived,"def load_tools() -> List[Type[BaseTool]]:
    tools: List[Type[BaseTool]] = []
    pkg_dir = Path(__file__).parent / ""tools""
    for module_info in pkgutil.iter_modules([str(pkg_dir)]):
        module = importlib.import_module(f""{__package__}.tools.{module_info.name}"")
        for attr in module.__dict__.values():
            if isinstance(attr, type) and issubclass(attr, BaseTool) and attr is not BaseTool:
                tools.append(attr)
    return tools
",servers/server_clear_thought/app.py,
survived,"def test_codegen_agent_sandbox_blocks_import(monkeypatch) -> None:
    from alpha_factory_v1.demos.alpha_agi_insight_v1.src.utils import config, messaging
    from alpha_factory_v1.demos.alpha_agi_insight_v1.src.agents import codegen_agent

    class DummyLedger:
        def __init__(self, *_a, **_kw) -> None:
            self.records: list[messaging.Envelope] = []

        def log(self, env) -> None:  # type: ignore[override]
            self.records.append(env)

        def start_merkle_task(self, *_a, **_kw) -> None:
            pass

        async def stop_merkle_task(self) -> None:
            pass

        def close(self) -> None:
            pass

    settings = config.Settings(bus_port=0, openai_api_key=""k"")
    bus = messaging.A2ABus(settings)
    ledger = DummyLedger()
    agent = codegen_agent.CodeGenAgent(bus, ledger)

    agent.execute_in_sandbox(""import os\nprint('hi')"")
    errs = [r.payload.get(""stderr"", """") for r in ledger.records if ""stderr"" in r.payload]
    assert errs and ""ImportError"" in errs[-1]",tests/test_agents.py,
survived,"    def test_main_uses_env_loglevel(self, edge_parse, run_parse, apply_env, run):
        args = self._args()
        args.loglevel = None
        edge_parse.return_value = args
        run_parse.return_value = argparse.Namespace()
        os.environ.pop(""PGHOST"", None)

        edge_runner.main()

        run_parse.assert_called_once_with([
            ""--dev"",
            ""--port"",
            ""123"",
            ""--metrics-port"",
            ""456"",
            ""--a2a-port"",
            ""789"",
            ""--enabled"",
            ""A,B"",
            ""--cycle"",
            ""5"",
        ])
        apply_env.assert_called_once_with(run_parse.return_value)
",alpha_factory_v1/tests/test_edge_runner_main.py,EdgeRunnerMainInvokesRun
survived,"    async def send(self, name: str, payload: Dict[str, Any]) -> Dict[str, Any]:
        """"""Post ``payload`` to the endpoint identified by ``name``.""""""
        if name not in self.endpoints:
            raise ValueError(f""Unknown endpoint '{name}'"")
        cfg = self.endpoints[name]
        async with self._sem:
            async with self._session.post(
                cfg.url,
                json=payload,
                headers=cfg.headers,
                timeout=self.timeout,
            ) as resp:
                if resp.status != 200:
                    text = await resp.text()
                    raise ValueError(f""API error: {resp.status} - {text}"")
                return await resp.json()
",src/meta_agent/services/telemetry_client.py,TelemetryAPIClient
survived,"    async def close(self) -> None:
        pass",src/aiohttp/__init__.py,ClientSession
survived,"    async def close(self) -> None:
        """"""Close the underlying HTTP session.""""""
        await self._session.close()
",src/meta_agent/services/telemetry_client.py,TelemetryAPIClient
survived,"async def test_send_success(telemetry_client):
    result = await telemetry_client.send(""trace"", {""data"": 1})
    assert result == {""ok"": True}
",tests/unit/test_telemetry_client.py,
survived,"    def __post_init__(self) -> None:
        if self.auth_token:
            self.headers[""Authorization""] = f""Bearer {self.auth_token}""
        self.headers.setdefault(""Content-Type"", ""application/json"")
",src/meta_agent/services/telemetry_client.py,EndpointConfig
survived,"    def record_event(
        self,
        category: ""TelemetryCollector.Category"",
        message: str,
        severity: ""TelemetryCollector.Severity"" = Severity.ERROR,
    ) -> None:
        """"""Record an informational or error event.""""""
        self.events.append(
            TelemetryCollector.Event(
                category=category,
                severity=severity,
                message=message,
            )
        )
        log = self.logger.info
        if severity in (self.Severity.ERROR, self.Severity.CRITICAL):
            log = self.logger.error
        elif severity is self.Severity.WARNING:
            log = self.logger.warning
        log(message)
",src/meta_agent/telemetry.py,TelemetryCollector
survived,"async def test_send_retry_success():
    with patch(""aiohttp.ClientSession"") as mock_session:
        resp1 = AsyncMock()
        resp1.status = 500
        resp1.text = AsyncMock(return_value=""bad"")
        cm1 = AsyncMock()
        cm1.__aenter__.return_value = resp1

        resp2 = AsyncMock()
        resp2.status = 200
        resp2.json = AsyncMock(return_value={""ok"": True})
        cm2 = AsyncMock()
        cm2.__aenter__.return_value = resp2

        mock_session.return_value.post.side_effect = [cm1, cm2]
        mock_session.return_value.close = AsyncMock()

        client = TelemetryAPIClient(
            {""trace"": EndpointConfig(""http://example.com"")}, retries=1, backoff=0
        )
        result = await client.send(""trace"", {""d"": 1})
        assert result == {""ok"": True}
        assert mock_session.return_value.post.call_count == 2
        await client.close()
",tests/unit/test_telemetry_client.py,
survived,"    def record(
        self, tokens: int, cost: float, latency: float, guardrail_hits: int
    ) -> None:
        cur = self.conn.cursor()
        cur.execute(
            ""INSERT INTO telemetry (timestamp, tokens, cost, latency, guardrail_hits) VALUES (?, ?, ?, ?, ?)"",
            (datetime.utcnow().isoformat(), tokens, cost, latency, guardrail_hits),
        )
        self.conn.commit()
        self.purge_old()
",src/meta_agent/telemetry_db.py,TelemetryDB
survived,"    def archive(self, path: Optional[str] = None) -> str:
        """"""Export all telemetry records to a gzipped JSON file.""""""
        data = self.fetch_all()
        if path is None:
            name = datetime.utcnow().isoformat().replace("":"", """").replace(""."", """")
            path = f""telemetry_{name}.json.gz""
        with gzip.open(path, ""wt"", encoding=""utf-8"") as f:
            json.dump(data, f)
        return path
",src/meta_agent/telemetry_db.py,TelemetryDB
survived,"    def archive(self, path: Optional[str] = None) -> str:
        """"""Export all telemetry records to a gzipped JSON file.""""""
        data = self.fetch_all()
        if path is None:
            name = datetime.utcnow().isoformat().replace("":"", """").replace(""."", """")
            path = f""telemetry_{name}.json.gz""
        with gzip.open(path, ""wt"", encoding=""utf-8"") as f:
            json.dump(data, f)
        return path
",src/meta_agent/telemetry_db.py,TelemetryDB
survived,"    def increment_guardrail_hits(self) -> None:
        """"""Increment guardrail hit counter and record an event.""""""
        self.guardrail_hits += 1
        self.record_event(
            self.Category.GUARDRAIL,
            ""guardrail violation"",
            severity=self.Severity.WARNING,
        )
",src/meta_agent/telemetry.py,TelemetryCollector
survived,"    def increment_guardrail_hits(self) -> None:
        """"""Increment guardrail hit counter and record an event.""""""
        self.guardrail_hits += 1
        self.record_event(
            self.Category.GUARDRAIL,
            ""guardrail violation"",
            severity=self.Severity.WARNING,
        )
",src/meta_agent/telemetry.py,TelemetryCollector
survived,"def test_archive(tmp_path):
    db = TelemetryDB(tmp_path / ""tele.db"")
    db.record(5, 0.02, 0.3, 1)
    archive_path = db.archive(tmp_path / ""out.gz"")
    with gzip.open(archive_path, ""rt"", encoding=""utf-8"") as f:
        data = json.load(f)
    assert data[0][""guardrail_hits""] == 1
    db.close()
",tests/unit/test_telemetry_db.py,
survived,"def test_record_and_fetch(tmp_path):
    db_path = tmp_path / ""tele.db""
    db = TelemetryDB(db_path, retention_days=1)
    db.record(10, 0.1, 0.5, 0)
    rows = db.fetch_all()
    assert len(rows) == 1
    assert rows[0][""tokens""] == 10
    assert db.verify()
    db.close()
",tests/unit/test_telemetry_db.py,
survived,"def binEval(op, l, r):
    lv = exprEval(l)
    rv = exprEval(r)
    if op == OP_ADD:
        return Rational(num=lv.num * rv.denom + lv.denom * rv.num, denom=lv.denom * rv.denom)
    if op == OP_SUB:
        return Rational(num=lv.num * rv.denom - lv.denom * rv.num, denom=lv.denom * rv.denom)
    if op == OP_MUL:
        return Rational(num=lv.num * rv.num, denom=lv.denom * rv.denom)
    return Rational(num=lv.num * rv.denom, denom=lv.denom * rv.num)
",tests/rosetta/transpiler/Python/24-game-solve.py,
survived,"def test_missing_locale_warning_and_english_fallback() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri()

    try:
        with sync_playwright() as p:
            browser = p.chromium.launch()
            page = browser.new_page()
            warnings: list[str] = []
            page.on(""console"", lambda msg: warnings.append(msg.text) if msg.type == ""warning"" else None)
            page.add_init_script(""localStorage.setItem('lang','xx')"")
            page.goto(url)
            page.wait_for_selector(""#controls"")
            label_text = page.locator(""#controls label"").first.inner_text()
            assert ""Seed"" in label_text
            assert warnings, ""Expected a console warning for missing locale""
            browser.close()
    except PlaywrightError as exc:
        pytest.skip(f""Playwright browser not installed: {exc}"")",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_missing_locale_fallback.py,
survived,"    def post_whisper_transcription(self, file_obj, model=""whisper-1"", language=None):
        """"""Whisper API request - Speech to Text""""""
        headers = {""Authorization"": self.headers.get(""Authorization"")}
        files = {""file"": (file_obj.filename, file_obj.stream, file_obj.mimetype)}
        data = {""model"": model}
        if language:
            data[""language""] = language

        response = requests.post(
            ""https://api.openai.com/v1/audio/transcriptions"",
            headers=headers,
            files=files,
            data=data,
        )
        return response
",src/openai_request.py,OpenAI_Request
survived,"    def post_tts_request(self, text, voice=""alloy"", model=""tts-1""):
        """"""OpenAI TTS API request - Text to Speech""""""
        headers = self.headers.copy()
        headers[""Content-Type""] = ""application/json""
        data = {
            ""model"": model,
            ""input"": text,
            ""voice"": voice,
            ""response_format"": ""mp3"",
        }
        response = requests.post(
            ""https://api.openai.com/v1/audio/speech"",
            headers=headers,
            data=json.dumps(data),
        )
        return response
",src/openai_request.py,OpenAI_Request
survived,"def test_joins_octal_escape():
    s_in = """"""'\\40'.join(['a', 'b'])""""""
    expected_out = '""a\\40b""'
    out, count = code_editor.fstringify_static_joins(s_in, State())
    assert count > 0
    assert out == expected_out",test/test_edits.py,
survived,"async def trigger_best_alpha() -> str:
    """"""Read the bundled alpha opportunities and enqueue the best one.""""""
    try:
        path = Path(__file__).with_name(""examples"") / ""alpha_opportunities.json""
        data = json.loads(path.read_text(encoding=""utf-8""))
        best = max(data, key=lambda x: x.get(""score"", 0))
    except Exception as exc:  # pragma: no cover - file may be missing
        raise RuntimeError(f""failed to load alpha opportunities: {exc}"") from exc
    resp = requests.post(
        f""{HOST}/agent/alpha_execution/trigger"",
        json=best,
        timeout=5,
    )
    resp.raise_for_status()
    return ""best alpha queued""
",alpha_factory_v1/demos/alpha_agi_business_v1/openai_agents_bridge.py,
survived,"    def backprop(self, node: Node) -> None:
        reward = node.reward
        while node is not None:
            node.visits += 1
            node.reward += reward
            node = node.parent
",alpha_factory_v1/demos/meta_agentic_tree_search_v0/mats/tree.py,Tree
survived,"    def __init__(self, root: Node, exploration: float = 1.4) -> None:
        self.root = root
        self.exploration = exploration
",alpha_factory_v1/demos/meta_agentic_tree_search_v0/mats/tree.py,Tree
survived,"            async def improve_policy(policy: list[int]) -> list[int]:
                return [p + 1 for p in policy]
",alpha_factory_v1/demos/meta_agentic_tree_search_v0/mats/meta_rewrite.py,
survived,"            async def _run() -> list[int]:
                result = await agent.policy({""policy"": agents}, {})
                if have_adk:
                    _ = agent2agent  # pragma: no cover - placeholder use
                return list(result)
",alpha_factory_v1/demos/meta_agentic_tree_search_v0/mats/meta_rewrite.py,
survived,"def violates_exfil_policy(text: str) -> bool:
    """"""Return ``True`` if ``text`` matches exfiltration patterns.""""""
    for pat in _EXFIL_RE:
        if pat.search(text):
            return True
    return False",src/utils/opa_policy.py,
survived,"    def __enter__(self) -> ""Ledger"":
        """"""Return ``self`` for context manager support.""""""
        return self
",alpha_factory_v1/common/utils/logging.py,Ledger
survived,"    def wrapper_sync(*args: P.args, **kwargs: P.kwargs) -> Any:
        for attempt in range(max_tries):
            try:
                return cast(Callable[P, T], func)(*args, **kwargs)
            except Exception as exc:  # pragma: no cover - runtime errors
                if attempt + 1 >= max_tries:
                    raise
                _log_retry(
                    {
                        ""tries"": attempt + 1,
                        ""exception"": exc,
                        ""target"": func,
                    }
                )
                time.sleep(2**attempt * 0.1)
        raise AssertionError(""unreachable"")
",alpha_factory_v1/common/utils/retry.py,
survived,"            def call_ctrans(prompt: str, s: Settings) -> str:
                return cast(str, cast(Any, _MODEL)(prompt, temperature=s.temperature))
",alpha_factory_v1/common/utils/local_llm.py,
survived,"    def __init__(self, **data: Any) -> None:  # pragma: no cover - exercised in tests
        super().__init__(**data)
        raw = os.getenv(""AGI_ISLAND_BACKENDS"")
        if raw and not data.get(""island_backends""):
            mapping = {}
            for part in raw.split("",""):
                if ""="" in part:
                    k, v = part.split(""="", 1)
                    mapping[k.strip()] = v.strip()
            if mapping:
                self.island_backends = mapping
        if not self.openai_api_key:
            _log.warning(""OPENAI_API_KEY missing â€“ offline mode enabled"")
            self.offline = True
        if self.offline:
            self.broadcast = False
        if not self.solana_wallet and self.solana_wallet_file:
            try:
                self.solana_wallet = Path(self.solana_wallet_file).read_text(encoding=""utf-8"").strip()
            except Exception as exc:  # pragma: no cover - optional
                _log.warning(""Failed to load wallet file %s: %s"", self.solana_wallet_file, exc)
        if self.bus_cert and self.bus_key:
            if not self.bus_token or self.bus_token == ""change_this_token"":
                raise ValueError(
                    ""AGI_INSIGHT_BUS_TOKEN must be set and cannot be 'change_this_token' when TLS is enabled""
                )
",alpha_factory_v1/common/utils/config.py,Settings
survived,"    def _log_retry(details: dict[str, Any]) -> None:
        _log.warning(
            ""Retry %d/%d for %s due to %s"",
            details[""tries""],
            max_tries,
            getattr(details.get(""target""), ""__name__"", ""call""),
            details.get(""exception""),
        )
",alpha_factory_v1/common/utils/retry.py,
survived,"    def start(self) -> None:
        init_metrics(self._port)
",alpha_factory_v1/backend/services/metrics_service.py,MetricsExporter
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-h/compiler/py/q1.py,Lineitem
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-h/compiler/py/q9.py,Auto2
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-h/compiler/py/q15.py,_Group
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-h/compiler/py/q13.py,Auto1
survived,"            def run(self) -> None:
                logger.info(""OpenAI Agents bridge disabled."")
",alpha_factory_v1/demos/cross_industry_alpha_factory/openai_agents_bridge.py,AgentRuntime
survived,"    def test_version_flag(self) -> None:
        result = subprocess.run(
            [sys.executable, ""-m"", ""alpha_factory_v1.edge_runner"", ""--version""],
            capture_output=True,
            text=True,
        )
        self.assertEqual(result.returncode, 0)
        self.assertEqual(result.stdout.strip(), edge_runner.__version__)
",tests/test_edge_runner_parse.py,TestParseArgs
survived,"    def test_env_defaults(self) -> None:
        env = {""PORT"": ""1234"", ""CYCLE"": ""5"", ""METRICS_PORT"": ""9000"", ""A2A_PORT"": ""7000""}
        with patch.dict(os.environ, env, clear=True):
            args = edge_runner.parse_args([])
        self.assertEqual(args.port, 1234)
        self.assertEqual(args.cycle, 5)
        self.assertEqual(args.metrics_port, 9000)
        self.assertEqual(args.a2a_port, 7000)
",tests/test_edge_runner_parse.py,TestParseArgs
survived,"    def test_ping_agent_skipped_when_env_set(self):
        code = ""import alpha_factory_v1.backend.agents as mod; print('ping' in mod.AGENT_REGISTRY)""
        env = os.environ.copy()
        env[""AF_DISABLE_PING_AGENT""] = ""true""
        result = subprocess.run([sys.executable, ""-c"", code], capture_output=True, text=True, env=env)
        self.assertEqual(result.stdout.strip(), ""False"")
",tests/test_agents_registry.py,TestPingAgentDisabled
survived,"            async def step(self):
                return None
",tests/test_agents_registry.py,TestAgentRegistryFunctions.DummyAgent
survived,"    def test_stub_after_errors(self):
        from alpha_factory_v1.backend.agents import _HEALTH_Q, StubAgent, _ERR_THRESHOLD

        class FailingAgent(AgentBase):
            NAME = ""fail""

            async def step(self):
                raise RuntimeError(""boom"")

        meta = AgentMetadata(name=""fail"", cls=FailingAgent, version=""0"", capabilities=[])  # type: ignore[list-item]
        register_agent(meta)
        # Pre-set error count to threshold -1
        object.__setattr__(AGENT_REGISTRY[""fail""], ""err_count"", _ERR_THRESHOLD - 1)
        _HEALTH_Q.put((""fail"", 0.0, False))
        # give the background thread a moment
        import time
        time.sleep(0.05)
        self.assertIs(AGENT_REGISTRY[""fail""].cls, StubAgent)
",tests/test_agents_registry.py,TestHealthQuarantine
survived,"    def test_condition_false(self):
        from alpha_factory_v1.backend.agents import register, _agent_base
        Base = _agent_base()

        @register(condition=False)
        class SkipAgent(Base):
            NAME = ""skip""

            async def step(self):
                return None

        self.assertNotIn(""skip"", AGENT_REGISTRY)
",tests/test_agents_registry.py,TestRegisterDecorator
survived,"    def test_capabilities_nonempty(self):
        for name, meta in AGENT_REGISTRY.items():
            if not meta.capabilities:
                continue
            self.assertTrue(meta.capabilities)
",tests/test_agents_integrity.py,TestAgentsIntegrity
survived,"    async def step(self) -> None:
        self.calls += 1
        raise RuntimeError(""boom"")
",tests/test_agent_base.py,DummyAgent
survived,"    def __init__(self):
        self.published = []
",tests/test_ping_agent.py,DummyOrch
survived,"                def tolist(self):
                    return list(self)
",tests/test_embedder_fallback.py,TestEmbedderFallback._Vec
survived,"    async def step(prompt, **kwargs):
        counter[""i""] += 1
        return counter[""i""]
",tests/test_workflow.py,
survived,"    async def runner(prompt, user_id=None, session_id=None, llm=None, sdk_context=None):
        called['params'] = (user_id, session_id, llm, sdk_context)
        return prompt + ""-done""
",tests/test_workflow.py,
survived,"    async def _execute_runner(
        self,
        runner: Any,
        prompt: Any,
        user_id: str,
        session_id: str,
        llm: Optional[LLM],
        sdk_context: SDKContext,
    ) -> Any:
        if hasattr(runner, ""chat""):
            result = runner.chat(prompt, user_id=user_id, session_id=session_id, llm=llm, sdk_context=sdk_context)
        else:
            result = runner(prompt, user_id=user_id, session_id=session_id, llm=llm, sdk_context=sdk_context)
        if asyncio.iscoroutine(result):
            return await result
        return result
",swarmzero/workflow.py,Workflow
survived,"async def test_example_runs(example):
    example_path = Path(__file__).resolve().parents[1] / ""examples"" / example
    db_path = example_path.parent / ""shop.db""
    if db_path.exists():
        db_path.unlink()

    params = StdioServerParameters(command=sys.executable, args=[str(example_path)])
    async with ClientSessionGroup() as group:
        session = await group.connect_to_server(params)
        await session.list_tools()

    # Clean up database file if created by shop_api_sqlite example
    if db_path.exists():
        db_path.unlink()",tests/test_examples.py,
survived,"    def test_apply_patch_rejects_unknown_file(self) -> None:
        with tempfile.TemporaryDirectory() as repo:
            open(os.path.join(repo, ""file.py""), ""w"").close()
            bad_patch = """"""--- a/missing.py
+++ b/missing.py
@@
-print('x')
+print('y')
""""""
            with self.assertRaises(ValueError):
                patcher_core.apply_patch(bad_patch, repo_path=repo)
",tests/test_self_healing_patcher.py,TestPatcherCore
survived,"    def decode_step(self, state, decode_fn):
        """"""Decode one token for the sequence at ``state.tail``.""""""
        import jax.numpy as jnp
        from jax import lax

        idx = state.tail
        tokens = state.token_ids[idx]
        length = state.lengths[idx]
        prev = tokens[length - 1]
        new_tok = decode_fn(prev)
        state.token_ids = state.token_ids.at[idx, length].set(new_tok)
        state.lengths = state.lengths.at[idx].set(length + 1)

        finished = jnp.logical_or(new_tok == self.eos, length + 1 >= self.max_len)

        def _finish(st):
            st.active = st.active.at[idx].set(False)
            st.tail = (st.tail + 1) % self.max_seqs
            return st

        state = lax.cond(finished, _finish, lambda s: s, state)
        return state
",src/levanter/inference/scheduler.py,JittedScheduler
survived,"    def schedule(self) -> tuple[List[Sequence], bool]:
        if self.waiting:
            seq = self.waiting.popleft()
            self.running.append(seq)
            return [seq], True
        seqs = [s for s in self.running if not s.is_finished]
        return seqs, False
",src/levanter/inference/scheduler.py,Scheduler
survived,"    def is_finished(self) -> bool:
        return not self.waiting and all(s.is_finished for s in self.running)
",src/levanter/inference/scheduler.py,Scheduler
survived,"    def _decode(self, seq: Sequence, cache, page_table, step: int):
        prev_token = jnp.array([seq.last_token], dtype=jnp.int32)
        seq_named = hax.named([seq.seq_id], ""seq"")
        temps = hax.full((), seq.sampling_params.temperature, dtype=jnp.float32)
        key = jrandom.PRNGKey(step)
        start = jnp.array(step, dtype=jnp.int32)
        tok, page_table, cache = do_generate(
            self.model, cache, page_table, prev_token, self.sampler, seq_named, start, temps, key
        )
        return int(tok.array), cache, page_table
",src/levanter/inference/llm_engine.py,LLMEngine
survived,"    def add(self, seq: Sequence) -> None:
        self.waiting.append(seq)
",src/levanter/inference/scheduler.py,Scheduler
survived,"    def __repr__(self):
        # printable version of self

        return str(self.tiles[0])+'\n'+str(self.tiles[1])+'\n'+str(self.tiles[2])+'\n'+str(self.tiles[3])+'\n'
",tests/rosetta/x/Python/15-puzzle-solver/15-puzzle-solver-2.py,Position
survived,"def slide_solved_state(n):
    return tuple(i % (n*n) for i in range(1, n*n+1))
",tests/rosetta/x/Python/15-puzzle-solver/15-puzzle-solver-1.py,
survived,"def slide_wd(n, goal):
    wd = gen_wd_table(n)
    goals = {i : goal.index(i) for i in goal}
    b = n.bit_length()

    def h(p):
        ht = 0 # Walking distance between rows.
        vt = 0 # Walking distance between columns.
        d = 0
        for i, c in enumerate(p):
            if c == 0: continue
            g = goals[c]
            xi, yi = i % n, i // n
            xg, yg = g % n, g // n
            ht += 1 << (b*(n*yi+yg))
            vt += 1 << (b*(n*xi+xg))

            if yg == yi:
                for k in range(i + 1, i - i%n + n): # Until end of row.
                    if p[k] and goals[p[k]] // n == yi and goals[p[k]] < g:
                        d += 2

            if xg == xi:
                for k in range(i + n, n * n, n): # Until end of column.
                    if p[k] and goals[p[k]] % n == xi and goals[p[k]] < g:
                        d += 2

        d += wd[ht] + wd[vt]

        return d
    return h
",tests/rosetta/x/Python/15-puzzle-solver/15-puzzle-solver-1.py,
survived,"    def neighbors(self):
        """"""
        returns a list of neighbors
        returns a list position objects with their
        directiontomoveto set to the direction that the
        empty square moved.

        tiles is 4x4 tuple of tuples with
        0,0 as top left.

        tiles[y][x]

        """"""

        # find 0 - blank square

        x0 = None
        y0 = None

        for i in range(4):
            for j in range(4):
                if self.tiles[i][j] == 0:
                    y0 = i
                    x0 = j

        if x0 == None or y0 == None:
            return []

        neighbor_list = []

        # move 0 to the right
        if x0 < 3:
            new_tiles = self.copy_tiles()
            temp = new_tiles[y0][x0+1]
            new_tiles[y0][x0+1] = 0
            new_tiles[y0][x0] = temp
            new_pos = new_position(new_tiles)
            neighbor_list.append(new_pos)
        # move 0 to the left
        if x0 > 0:
            new_tiles = self.copy_tiles()
            temp = new_tiles[y0][x0-1]
            new_tiles[y0][x0-1] = 0
            new_tiles[y0][x0] = temp
            new_pos = new_position(new_tiles)
            neighbor_list.append(new_pos)
        # move 0 up
        if y0 > 0:
            new_tiles = self.copy_tiles()
            temp = new_tiles[y0-1][x0]
            new_tiles[y0-1][x0] = 0
            new_tiles[y0][x0] = temp
            new_pos = new_position(new_tiles)
            neighbor_list.append(new_pos)
        # move 0 down
        if y0 < 3:
            new_tiles = self.copy_tiles()
            temp = new_tiles[y0+1][x0]
            new_tiles[y0+1][x0] = 0
            new_tiles[y0][x0] = temp
            new_pos = new_position(new_tiles)
            neighbor_list.append(new_pos)

        return neighbor_list
",tests/rosetta/x/Python/15-puzzle-solver/15-puzzle-solver-2.py,Position
survived,"def reconstruct_path(current):
    """"""
    Uses the cameFrom members to follow the chain of moves backwards
    and then reverses the list to get the path in the correct order.
    """"""
    total_path = [current]

    while current.cameFrom != None:
        current = current.cameFrom
        total_path.append(current)

    total_path.reverse()

    return total_path
",tests/rosetta/x/Python/15-puzzle-solver/15-puzzle-solver-2.py,
survived,"    def run(self):
        if isdir(""queries""):
            dest = join(self.build_lib, ""tree_sitter_racket"", ""queries"")
            self.copy_tree(""queries"", dest)
        super().run()
",third_party/tree-sitter-racket/setup.py,Build
survived,"    def Init(logger:logging.Logger, moonrakerConfigFilePath:Optional[str], isCompanionMode:bool):
        MoonrakerCredentialManager._Instance = MoonrakerCredentialManager(logger, moonrakerConfigFilePath, isCompanionMode)
",moonraker_octoeverywhere/moonrakercredentialmanager.py,MoonrakerCredentialManager
survived,"    def TryToGetApiKey(self) -> Optional[str]:
        # If this is an companion plugin, we dont' have the moonraker config file nor can we access the UNIX socket.
        if self.IsCompanionMode:
            return None

        # First, we need to find the unix socket to connect to
        moonrakerSocketFilePath = self._TryToFindUnixSocket()
        if moonrakerSocketFilePath is None:
            self.Logger.warning(""No moonraker unix socket file could be found."")
            return None

        try:
            # Try to open the socket.
            # pylint: disable=no-member # Only exists on linux
            sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
            sock.connect(moonrakerSocketFilePath)

            # Create the db request query.
            msgId = random.randint(100000, 99999999)
            obj = {
                ""jsonrpc"": ""2.0"",
                ""method"": ""access.get_api_key"",
                ""id"": msgId
            }
            jsonStr = json.dumps(obj, default=str)
            # Add the End Of Text ascii value of 3 to the string to indicate the end of message.
            jsonStr += b'\x03'.decode()

            # Send it on the socket.
            sock.sendall(jsonStr.encode(encoding=""utf-8""))

            # Moonraker sends state messages along with responses, so we need to eat them until we find what we need.
            startTime = time.time()
            msgCount = 0
            while True:
                jsonMsg = self._ReadSingleJsonObject(sock)
                if jsonMsg is None:
                    return None

                msgCount += 1
                jsonRpcResponse = json.loads(jsonMsg)
                # Only messages with the ID field are responses, so we don't care about the others.
                if ""id"" not in jsonRpcResponse:
                    if time.time() - startTime > 20.0:
                        self.Logger.warning(""TryToGetCredentials timeout waiting for db query response after ""+str(msgCount)+"" messages."")
                        return None
                    continue

                # Make sure this is us.
                if jsonRpcResponse[""id""] != msgId:
                    self.Logger.info(""TryToGetCredentials got a response for a different id? got:""+str(jsonRpcResponse[""id""]) + "" expected:""+str(msgId))
                    continue
                # Check for error.
                if ""error"" in jsonRpcResponse:
                    self.Logger.warning(""TryToGetCredentials got a response but it had an error. ""+str(jsonRpcResponse[""error""]))
                    return None

                # Look for the result string.
                if ""result"" not in jsonRpcResponse:
                    self.Logger.warning(""TryToGetCredentials got a response but with no result object."")
                    return None
                result  = jsonRpcResponse[""result""]
                if isinstance(result, str) is False:
                    self.Logger.warning(""TryToGetCredentials got a response but result is not a str. ""+str(result))
                    return None

                # We got it!
                self.Logger.info(""MoonrakerCredentialManager successfully found the API key."")
                return result

        except Exception as e:
            Sentry.OnException(""TryToGetCredentials failed to open the unix socket."", e)
            return None
",moonraker_octoeverywhere/moonrakercredentialmanager.py,MoonrakerCredentialManager
survived,"    def _GetParentDirectory(self, path:str) -> str:
        return os.path.abspath(os.path.join(path, os.pardir))
",moonraker_octoeverywhere/moonrakercredentialmanager.py,MoonrakerCredentialManager
survived,"def test_visualize_shardings_model_axis(capsys):
    devices = jax.devices()
    mesh = jax.sharding.Mesh(np.array(devices).reshape(-1, 2), (ResourceAxis.DATA, ResourceAxis.MODEL))
    with axis_mapping({""dim1"": ResourceAxis.DATA, ""dim2"": ResourceAxis.MODEL}), mesh:
        arr = hax.ones((Dim1, Dim2))
        visualize_shardings(arr)

    out = capsys.readouterr().out
    assert ""dim2"" in out",tests/test_visualize_sharding.py,
survived,"def main() -> None:
    alpha = discover_alpha()
    print(""Discovered alpha:"")
    print(json.dumps(alpha, indent=2))
    print(f""Logged to {LEDGER}"")
",alpha_factory_v1/demos/omni_factory_demo/alpha_discovery_stub.py,
survived,"    def test_apply_patch_failure_rollback(self):
        with tempfile.TemporaryDirectory() as repo:
            file_path = os.path.join(repo, ""hello.txt"")
            with open(file_path, ""w"") as fh:
                fh.write(""hello\n"")
            bad_patch = ""invalid diff""
            with self.assertRaises(RuntimeError):
                patcher_core.apply_patch(bad_patch, repo_path=repo)
            with open(file_path) as fh:
                self.assertEqual(fh.read(), ""hello\n"")
",tests/test_self_healing_patcher.py,TestPatcherCore
survived,"    def test_bridge_compiles(self):
        path = Path('alpha_factory_v1/demos/alpha_asi_world_model/openai_agents_bridge.py')
        py_compile.compile(path, doraise=True)
",tests/test_openai_bridge.py,TestOpenAIBridge
survived,"    def test_sampling(self) -> None:
        with tempfile.TemporaryDirectory() as tmp:
            ledger = Path(tmp) / 'log.json'
            result = subprocess.run(
                [sys.executable, STUB, '-n', '2', '--seed', '1', '--ledger', str(ledger)],
                capture_output=True,
                text=True,
            )
            self.assertEqual(result.returncode, 0, result.stderr)
            self.assertTrue(ledger.exists())
            logged = json.loads(ledger.read_text())
            self.assertIsInstance(logged, list)
            self.assertEqual(len(logged), 2)
",tests/test_cross_alpha_discovery.py,TestCrossAlphaDiscoveryStub
survived,"    def test_aiga_bridge_compiles(self):
        """"""Ensure the AI-GA demo bridge compiles.""""""
        path = Path('alpha_factory_v1/demos/aiga_meta_evolution/openai_agents_bridge.py')
        py_compile.compile(path, doraise=True)
",tests/test_openai_bridge.py,TestOpenAIBridge
survived,"    def __repr__(self):
        return f""Person(name={self.name!r}, age={self.age}, status={self.status!r})""
",tests/machine/x/python/update_stmt.py,Person
survived,"def classify(n: int) -> str:
    if n == 0:
        return ""zero""
    elif n == 1:
        return ""one""
    else:
        return ""many""
",tests/machine/x/python/match_full.py,
survived,"def boom(a: int, b: int) -> bool:
    print(""boom"")
    return True
",tests/machine/x/python/short_circuit.py,
survived,"def test_grpc_bus_tls_bad_token(tmp_path: Path) -> None:
    from alpha_factory_v1.demos.alpha_agi_insight_v1.src.utils import config, messaging

    port = _free_port()
    cert, key, ca = _make_cert(tmp_path)
    cfg = config.Settings(bus_port=port, bus_cert=cert, bus_key=key, bus_token=""tok"")
    bus = messaging.A2ABus(cfg)

    async def run() -> None:
        await bus.start()
        try:
            creds = grpc.ssl_channel_credentials(root_certificates=ca)
            async with grpc.aio.secure_channel(f""localhost:{port}"", creds) as ch:
                stub = ch.unary_unary(""/bus.Bus/Send"")
                payload = {
                    ""sender"": ""a"",
                    ""recipient"": ""b"",
                    ""payload"": {},
                    ""ts"": 0.0,
                    ""token"": ""bad"",
                }
                with pytest.raises(grpc.aio.AioRpcError):
                    await stub(json.dumps(payload).encode())
        finally:
            await bus.stop()

    asyncio.run(run())",tests/test_agents.py,
survived,"def sum_tree(t):
    return (0 if t == Leaf else (sum_tree(t.left) + t.value + sum_tree(t.right) if t != None else None))
",tests/transpiler/x/py/tree_sum.py,
survived,"def test_read_and_clear() -> None:
    bus = EventBus(None, True, max_queue_size=2)
    bus.publish(""x"", {""v"": 1})
    bus.publish(""x"", {""v"": 2})
    events = bus.read_and_clear(""x"")
    assert events == {""x"": [{""v"": 1}, {""v"": 2}]}
    assert bus.read_and_clear(""x"") == {}
",tests/test_eventbus.py,
survived,"    def max_seqs(self) -> int:
        return self.page_indices.axis_size(""seq"")
",src/levanter/layers/page_table.py,PageTable
survived,"    async def input_guardrail(prompt: str):
        order.append(f""in:{prompt}"")
",tests/test_guardrail_router.py,
survived,"    def __init__(self, llm_service: LLMService) -> None:
        self.llm_service = llm_service
",src/meta_agent/services/guardrail_router.py,LLMModelAdapter
survived,"def test_openai_agents_installed_from_wheelhouse(tmp_path: Path, monkeypatch: pytest.MonkeyPatch) -> None:
    wheelhouse = tmp_path / ""wheels""
    wheelhouse.mkdir()
    _make_wheel(wheelhouse, ""openai-agents"", ""0.0.15"")

    monkeypatch.setattr(check_env, ""CORE"", [])
    monkeypatch.setattr(check_env, ""REQUIRED"", [])
    monkeypatch.setattr(check_env, ""OPTIONAL"", [""openai_agents""])
    monkeypatch.setattr(check_env, ""warn_missing_core"", lambda: [])
    monkeypatch.setattr(check_env, ""has_network"", lambda: False)
    monkeypatch.delitem(sys.modules, ""openai_agents"", raising=False)

    rc = check_env.main([""--auto-install"", ""--wheelhouse"", str(wheelhouse)])
    assert rc == 0
    mod = importlib.import_module(""openai_agents"")
    assert getattr(mod, ""__version__"", """") == ""0.0.15""",tests/test_aiga_offline_setup.py,
survived,"def download(cid: str, path: Path) -> None:
    url = f""{GATEWAY}/{cid}""
    path.parent.mkdir(parents=True, exist_ok=True)
    with _session().get(url, timeout=60) as resp:
        resp.raise_for_status()
        path.write_bytes(resp.content)
",scripts/fetch_assets.py,
survived,"def test_offline_queue_flushes_on_reconnect() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri()

    with sync_playwright() as p:
        browser = p.chromium.launch()
        page = browser.new_page()
        page.goto(url)
        page.evaluate(
            ""window.OTEL_ENDPOINT='https://example.com';""
            ""window.confirm=() => true;""
            ""Object.defineProperty(navigator,'onLine',{get:()=>false,configurable:true});""
            ""navigator.sendBeacon=()=>false;""
        )
        page.reload()
        page.wait_for_selector(""#controls"")
        page.click(""text=Share"")
        page.evaluate(""window.dispatchEvent(new Event('beforeunload'))"")
        assert page.evaluate(""JSON.parse(localStorage.getItem('telemetryQueue')).length > 0"")
        page.evaluate(
            ""navigator.sendBeacon=(...a)=>{(window.sent=window.sent||[]).push(a);return true;}""
            ""Object.defineProperty(navigator,'onLine',{get:()=>true});""
            ""window.dispatchEvent(new Event('online'));""
        )
        page.wait_for_function(""window.sent && window.sent.length > 0"")
        assert page.evaluate(""localStorage.getItem('telemetryQueue')"") == ""[]""
        browser.close()",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_telemetry.py,
survived,"    def test_csv_gz_load(dest_uri):
        """"""When the source URI is a gzipped CSV file, the data should be ingested.""""""
        with (
            patch(target_fs) as target_fs_mock,
            patch(""ingestr.src.filesystem.glob_files"", wraps=glob_files_override),
        ):
            target_fs_mock.return_value = test_fs
            schema_rand_prefix = f""testschema_fs_{get_random_string(5)}""
            dest_table = f""{schema_rand_prefix}.fs_{get_random_string(5)}""
            result = invoke_ingest_command(
                f""{protocol}://bucket?{auth}"",
                ""/data.csv.gz"",
                dest_uri,
                dest_table,
            )
            assert result.exit_code == 0
            assert_rows(dest_uri, dest_table, 5)
",ingestr/main_test.py,
survived,"def test_firejail_used_when_available(monkeypatch) -> None:
    calls: dict[str, list] = {}

    def fake_run(cmd, **kwargs):
        calls[""cmd""] = cmd
        calls[""preexec_fn""] = kwargs.get(""preexec_fn"")

        class P:
            stdout = ""{}""
            stderr = """"

        return P()

    monkeypatch.setattr(codegen_agent.shutil, ""which"", lambda n: ""/usr/bin/firejail"")
    monkeypatch.setattr(codegen_agent.subprocess, ""run"", fake_run)

    agent = _make_agent()
    agent.execute_in_sandbox(""print('hi')"")

    assert calls[""cmd""][0] == ""/usr/bin/firejail""
    assert ""--net=none"" in calls[""cmd""]
    assert calls[""preexec_fn""] is None",tests/test_codegen_agent.py,
survived,"    def start_merkle_task(self, *_a: object, **_kw: object) -> None:  # pragma: no cover - test helper
        pass
",tests/test_agent_runner.py,_Ledger
survived,"def test_settings_secret_fallback(monkeypatch: pytest.MonkeyPatch) -> None:
    monkeypatch.delenv(""OPENAI_API_KEY"", raising=False)
    monkeypatch.delenv(""AGI_INSIGHT_SECRET_BACKEND"", raising=False)
    importlib.reload(cfg)
    monkeypatch.setattr(cfg, ""get_secret"", lambda name, default=None: ""backend"")
    settings = cfg.Settings()
    assert settings.openai_api_key == ""backend""
    assert not settings.offline",tests/test_config_utils.py,
survived,"    def scan_via(self, fn: Callable[..., tuple[CarryT, OutputT_co]]):
        """"""Return a function that scans over the sequence using ``fn``.

        ``fn`` should take a block and a carry and return ``(carry, output)``.
        Semantics match :func:`haliax.scan` over the block axis.
        """"""

        def do_scan(init: CarryT) -> tuple[CarryT, OutputT_co]:
            out = []
            carry = init
            for block in self.blocks:
                carry, extra = fn(block, carry)
                carry = tree_checkpoint_name(carry, self._carry_ckpt_name)
                extra = tree_checkpoint_name(extra, self._output_ckpt_name)
                out.append(extra)

            stacked_out = haliax.tree_util.tree_map(lambda *x: haliax.stack(self.Block, x), *out)
            return carry, stacked_out

        return do_scan
",src/haliax/nn/scan.py,BlockSeq
survived,"    def fold_via(self, fn: Callable[..., CarryT]) -> Callable[[CarryT], CarryT]:
        ...
",src/haliax/nn/scan.py,BlockFoldable
survived,"def import_logs(log_dir: str | Path, *, db_path: str | Path = DEFAULT_ARCHIVE) -> int:
    """"""Load DGM logs from ``log_dir`` into ``db_path``.

    Args:
        log_dir: Directory containing ``*.json`` log files.
        db_path: Archive database path.

    Returns:
        Number of imported records.
    """"""
    db = ArchiveDB(db_path)
    count = 0
    for file in sorted(Path(log_dir).glob(""*.json"")):
        for entry in _parse_file(file):
            db.add(entry)
            count += 1
    return count
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/tools/dgm_import.py,
survived,"def test_curriculum_switch(tmp_path: Path) -> None:
    db_path = tmp_path / ""archive.db""
    switcher = CurriculumSwitcher(db_path, window=10)

    # Start on mini dataset
    assert switcher.dataset == ""swe_mini""

    rates = [0.2, 0.5, 0.6]
    for r in rates:
        metrics = compute_fitness(_results(switcher.dataset, r))
        switcher.update(metrics)
    assert switcher.dataset == ""swebench_verified_mini""

    rates = [0.6, 0.6, 0.6, 0.6]
    for r in rates:
        metrics = compute_fitness(_results(switcher.dataset, r))
        switcher.update(metrics)
    assert switcher.dataset == ""polyglot_lite""

    # state persisted
    db = ArchiveDB(db_path)
    assert db.get_state(""dataset"") == ""polyglot_lite""",tests/test_curriculum_switcher.py,
survived,"def compose_stack() -> None:
    subprocess.run([
        ""docker"",
        ""compose"",
        ""-f"",
        str(COMPOSE_FILE),
        ""up"",
        ""-d"",
        ""agents"",
    ], check=True)
    try:
        yield
    finally:
        subprocess.run([
            ""docker"",
            ""compose"",
            ""-f"",
            str(COMPOSE_FILE),
            ""down"",
            ""-v"",
        ], check=False)
",tests/test_no_network.py,
survived,"def test_pareto_front_after_five_generations() -> None:
    def fn(genome: list[float]) -> tuple[float, float]:
        x, y = genome
        return x**2, y**2

    pop = mats.run_evolution(
        fn,
        2,
        population_size=20,
        generations=5,
        seed=42,
        scenario_hash=""test"",
    )
    front = mats.pareto_front(pop)
    assert len(front) >= 10",tests/test_mats.py,
survived,"def _read_logs(paths: Iterable[Path]) -> List[Dict[str, Any]]:
    records: List[Dict[str, Any]] = []
    for p in paths:
        with p.open(encoding=""utf-8"") as fp:
            for line in fp:
                line = line.strip()
                if not line:
                    continue
                try:
                    records.append(json.loads(line))
                except json.JSONDecodeError:
                    continue
    return records
",alpha_factory_v1/demos/alpha_agi_insight_v1/tools/export_tree.py,
survived,"def test_business_bridge_offline(monkeypatch, capsys):
    # Stub google_adk so adk_bridge imports succeed without network
    dummy = types.ModuleType(""google_adk"")
    dummy.Agent = object

    class _Router:
        def __init__(self):
            self.app = types.SimpleNamespace(middleware=lambda *_a, **_k: lambda f: f)

        def register_agent(self, _agent):
            pass

    dummy.Router = _Router
    dummy.AgentException = Exception
    monkeypatch.setitem(sys.modules, ""google_adk"", dummy)

    # Ensure OPENAI_API_KEY unset and openai_agents import fails
    monkeypatch.delenv(""OPENAI_API_KEY"", raising=False)
    monkeypatch.setattr(
        check_env, ""main"", lambda *_a, **_k: (_ for _ in ()).throw(requests.exceptions.ConnectionError(""offline""))
    )
    sys.modules.pop(""openai_agents"", None)
    orig_import = builtins.__import__

    def fake_import(name, globals=None, locals=None, fromlist=(), level=0):
        if name == ""openai_agents"":
            raise ModuleNotFoundError(name)
        return orig_import(name, globals, locals, fromlist, level)

    monkeypatch.setattr(builtins, ""__import__"", fake_import)

    bridge = importlib.reload(
        importlib.import_module(""alpha_factory_v1.demos.alpha_agi_business_v1.openai_agents_bridge"")
    )

    assert bridge._require_openai_agents() is False

    bridge.main()
    captured = capsys.readouterr()
    assert ""OpenAI Agents SDK not available; bridge inactive."" in captured.out",tests/test_business_bridge_offline.py,
survived,"    def rebuild(self) -> None:
        """"""Rebuild the index from all registered templates.""""""
        self._index = []
        for entry in self.registry.list_templates():
            slug = entry[""slug""]
            for version_info in entry.get(""versions"", []):
                version = version_info[""version""]
                path = self.registry.templates_dir / version_info[""path""]
                metadata_path = path.parent / METADATA_FILE_NAME
                try:
                    content = path.read_text(encoding=""utf-8"")
                except OSError:  # pragma: no cover - file missing
                    continue
                checksum = sha256(content.encode(""utf-8"")).hexdigest()
                try:
                    with open(metadata_path, ""r"", encoding=""utf-8"") as f:
                        metadata = json.load(f)
                except (OSError, json.JSONDecodeError):
                    metadata = {}
                self._index.append(
                    {
                        ""slug"": slug,
                        ""version"": version,
                        ""path"": str(path.relative_to(self.registry.templates_dir)),
                        ""checksum"": checksum,
                        ""metadata"": metadata,
                        ""content"": content,
                    }
                )
        self.save()
",src/meta_agent/template_index.py,TemplateIndex
survived,"def test_auto_rebuild_on_drift(tmp_path) -> None:
    reg = TemplateRegistry(base_dir=tmp_path)
    reg.register(_meta(""foo""), ""hello foo"")

    index = TemplateIndex(reg)
    index.rebuild()

    # modify template to trigger checksum mismatch
    tpl_path = reg.templates_dir / ""foo"" / ""v0_1_0"" / ""template.yaml""
    tpl_path.write_text(""hi foo"", encoding=""utf-8"")

    index.ensure_up_to_date()
    results = index.search(""hi foo"")
    assert results and results[0][""slug""] == ""foo""",tests/test_template_index.py,
survived,"def test_build_and_search(tmp_path) -> None:
    reg = TemplateRegistry(base_dir=tmp_path)
    reg.register(_meta(""foo""), ""hello foo"")
    reg.register(_meta(""bar""), ""hello bar"")

    index = TemplateIndex(reg)
    index.rebuild()

    results = index.search(""hello foo"")
    assert results and results[0][""slug""] == ""foo""
",tests/test_template_index.py,
survived,"        def _worker(js: str):
            g = Genome.from_json(js)
            module = import_module(__name__)
            return module.MetaEvolver._simulate(module.MetaEvolver, g)
",alpha_factory_v1/demos/aiga_meta_evolution/meta_evolver.py,MetaEvolver
survived,"    def mutate(self) -> ""Genome"":
        g = copy.deepcopy(self)
        if random.random() < 0.4:
            idx = random.randrange(len(g.layers))
            delta = random.randint(-8, 8)
            new_size = max(4, min(128, g.layers[idx] + delta))
            layers = list(g.layers)
            layers[idx] = new_size
            if random.random() < 0.2 and len(layers) < 4:
                layers.insert(idx, random.choice([16, 32, 64]))
            g.layers = tuple(layers)
        if random.random() < 0.2:
            g.activation = random.choice(list(_ACT))
        if random.random() < 0.1:
            g.hebbian = not g.hebbian
        if random.random() < 0.15:
            g.novelty_weight = round(min(1.0, max(0.0, g.novelty_weight + random.uniform(-0.15, 0.15))), 2)
        return g
",alpha_factory_v1/demos/aiga_meta_evolution/meta_evolver.py,Genome
survived,"    def _select(self, scores, k=3):
        idx = max(random.sample(range(self.pop_size), k), key=lambda i: scores[i])
        return self.population[idx]
",alpha_factory_v1/demos/aiga_meta_evolution/meta_evolver.py,MetaEvolver
survived,"    def run_forever(self) -> None:
        """"""Start the orchestrator and block until interrupted.""""""
        asyncio.run(_main())
",alpha_factory_v1/backend/orchestrator.py,Orchestrator
survived,"def ensure_dir(path: Path) -> None:
    if not path.exists():
        path.mkdir(parents=True, exist_ok=True)
        banner(f""Created {path}"", 'YELLOW')
    else:
        banner(f""Using {path}"", 'GREEN')
",alpha_factory_v1/scripts/preflight.py,
survived,"def test_pbm(h, f):
    """"""Verify if the image is a PBM (portable bitmap).""""""
    if len(h) >= 3 and \
        h[0] == ord(b'P') and h[1] in b'14' and h[2] in b' \t\n\r':
        return 'pbm'
",metaflow/_vendor/imghdr/__init__.py,
survived,"def test_xbm(h, f):
    """"""Verify if the image is a X bitmap (X10 or X11).""""""
    if h.startswith(b'#define '):
        return 'xbm'
",metaflow/_vendor/imghdr/__init__.py,
survived,"def test_umap_fallback_random_coordinates() -> None:
    dist = Path(__file__).resolve().parents[1] / (
        ""alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/dist/index.html""
    )
    url = dist.as_uri()
    try:
        with sync_playwright() as p:
            browser = p.chromium.launch()
            page = browser.new_page()
            page.route(""**/pyodide.js"", lambda route: route.abort())
            page.goto(url)
            page.wait_for_selector(""#controls"")
            page.wait_for_selector(""#simulator-panel"")
            first = _run_sim(page)
            second = _run_sim(page)
            browser.close()
    except PlaywrightError as exc:
        pytest.skip(f""Playwright browser not installed: {exc}"")
    assert first != second
    assert all(len(pt) == 2 for pt in first)
",tests/test_umap_fallback.py,
survived,"    def lookup_artist(name: str) -> str | None:
        url = f""https://api.lidarr.audio/api/v0.4/search?type=artist&query=\""{urllib.parse.quote_plus(name)}\""""
        resp = session.get(url, headers=headers)
        if resp.status_code == 200 and resp.text not in ("""", ""[]""):
            data = resp.json()
            if isinstance(data, list):
                return data[0].get(""id"")
            return data.get(""id"")
        return None
",arr_gui.py,
survived,"def lidarr_import(csv_path: str, cfg: configparser.ConfigParser) -> None:
    baseurl = cfg[""lidarr""][""baseurl""]
    api_key = cfg[""lidarr""][""api_key""]
    root = cfg[""lidarr""][""rootfolderpath""]

    headers = {""Content-type"": ""application/json"", ""X-Api-Key"": api_key}
    session = requests.Session()

    def lookup_artist(name: str) -> str | None:
        url = f""https://api.lidarr.audio/api/v0.4/search?type=artist&query=\""{urllib.parse.quote_plus(name)}\""""
        resp = session.get(url, headers=headers)
        if resp.status_code == 200 and resp.text not in ("""", ""[]""):
            data = resp.json()
            if isinstance(data, list):
                return data[0].get(""id"")
            return data.get(""id"")
        return None

    with open(csv_path, encoding=""utf-8"") as f:
        reader = csv.DictReader(f)
        for row in reader:
            artist = row.get(""artist"")
            mbid = row.get(""foreignArtistId"")
            if not mbid:
                mbid = lookup_artist(artist)
            if not mbid:
                messagebox.showwarning(""Lidarr"", f""{artist} not found"")
                continue
            payload = {
                ""artistName"": artist,
                ""foreignArtistId"": mbid,
                ""QualityProfileId"": 1,
                ""MetadataProfileId"": 1,
                ""Path"": os.path.join(root, artist),
                ""RootFolderPath"": root,
                ""monitored"": True,
                ""addOptions"": {""searchForMissingAlbums"": False},
            }
            add_url = f""{baseurl}/api/v1/artist""
            session.post(add_url, headers=headers, json=payload)
",arr_gui.py,
survived,"def load_defaults():
    config = load_config()
    csv_path = """"
    if config.has_section(""gui""):
        csv_path = config.get(""gui"", ""default_csv"", fallback="""")
    return csv_path
",arr_gui.py,
survived,"    def gen_trace_id(self) -> str:
        """"""Generate a new trace ID.""""""
        return f""trace_{uuid.uuid4().hex}""
",src/agents/tracing/setup.py,TraceProvider
survived,"def test_load_model_warning(monkeypatch, caplog):
    caplog.set_level(logging.WARNING)
    monkeypatch.setattr(local_llm, ""_MODEL"", None)
    monkeypatch.setattr(local_llm, ""_CALL"", None)
    monkeypatch.setattr(local_llm, ""Llama"", mock.Mock(side_effect=RuntimeError(""boom"")))
    monkeypatch.setattr(local_llm, ""AutoModelForCausalLM"", None)

    local_llm._load_model()

    assert any(""boom"" in r.message for r in caplog.records)",tests/test_local_llm_logging.py,
survived,"    def __call__(self, text: str) -> str:
        words = text.split()
        if not words:
            return text
        idx = self.rng.randrange(len(words))
        w = words[idx].lower()
        words[idx] = self.synonyms.get(w, words[idx])
        return "" "".join(words)
",src/simulation/mats_ops.py,PromptRewrite
survived,"def test_macro_launcher_no_offline(monkeypatch: pytest.MonkeyPatch) -> None:
    """"""`OPENAI_API_KEY` disables the offline profile.""""""
    compose_calls: list[list[str]] = []

    def fake_run(cmd: list[str], *a, **k) -> subprocess.CompletedProcess[str]:
        if cmd[:2] == [""docker"", ""compose""]:
            compose_calls.append(cmd)
        return subprocess.CompletedProcess(cmd, 0, """", """")

    monkeypatch.setattr(subprocess, ""run"", fake_run)
    monkeypatch.setenv(""OPENAI_API_KEY"", ""dummy-key"")

    mod = __import__(
        ""alpha_factory_v1.demos.macro_sentinel.macro_launcher"", fromlist=[""main""]
    )
    mod.main([])

    cmd_str = "" "".join("" "".join(c) for c in compose_calls)
    assert ""--profile offline"" not in cmd_str
",tests/test_macro_launcher.py,
survived,"    async def handler(env: messaging.Envelope) -> None:
        events.append(env)
",tests/test_message_bus.py,
survived,"def test_background_tasks_lifecycle() -> None:
    settings = config.Settings(bus_port=0)
    with mock.patch.object(orchestrator.Orchestrator, ""_init_agents"", lambda self: [DummyAgent(self.bus, self.ledger)]):
        orch = orchestrator.Orchestrator(settings)

    async def run() -> None:
        with (
            mock.patch.object(orch.bus, ""start"", mock.AsyncMock()) as bus_start,
            mock.patch.object(orch.bus, ""stop"", mock.AsyncMock()) as bus_stop,
            mock.patch.object(orch.ledger, ""start_merkle_task"") as merkle_start,
            mock.patch.object(orch.ledger, ""stop_merkle_task"", mock.AsyncMock()) as merkle_stop,
        ):
            task = asyncio.create_task(orch.run_forever())
            await asyncio.sleep(0.05)
            assert orch._monitor_task is not None and not orch._monitor_task.done()
            runner = orch.runners[""dummy""]
            assert runner.task is not None and not runner.task.done()
            merkle_start.assert_called_once()
            bus_start.assert_awaited_once()
            task.cancel()
            with contextlib.suppress(asyncio.CancelledError):
                await task
            assert orch._monitor_task is not None and orch._monitor_task.cancelled()
            assert runner.task is not None and runner.task.cancelled()
            bus_stop.assert_awaited_once()
            merkle_stop.assert_awaited_once()

    asyncio.run(run())",tests/test_orchestrator.py,
survived,"        async def run() -> None:
            async with bus:
                env = messaging.Envelope(""a"", ""x"", {""ok"": True}, 0.0)
                bus.publish(""x"", env)
                await asyncio.sleep(0)
",tests/test_message_bus.py,
survived,"def test_insight_missing_ids() -> None:
    _setup_simulations()
    client = _make_client()
    headers = {""Authorization"": ""Bearer test-token""}
    resp = client.post(""/insight"", json={""ids"": [""missing""]}, headers=headers)
    assert resp.status_code == 404",tests/test_insight_endpoint.py,
survived,"  def deserialize(cls, data: dict):
    return cls(port=data[""port""])",pylabrobot/storage/cytomat/heraeus_cytomat_backend.py,HeraeusCytomatBackend
survived,"  def racks(self) -> List[PlateCarrier]:
    return self._racks
",pylabrobot/storage/incubator.py,Incubator
survived,"  async def get_action_register(self) -> ActionRegisterState:
    hex_value = await self.send_command(""ch"", ""ba"", """")
    binary_repr = hex_to_binary(hex_value)
    target, action = binary_repr[:3], binary_repr[3:]

    target_enum = None
    for action_type_member in ActionType:
      if int(target, 2) == int(action_type_member.value, 16):
        target_enum = action_type_member
        break
    assert target_enum is not None, f""Unknown target value: {target}""

    action_enum = None
    for action_register_member in ActionRegister:
      if int(action, base=2) == int(action_register_member.value, base=16):
        action_enum = action_register_member
        break
    assert action_enum is not None, f""Unknown HIGH_LEVEL_COMMANDment value: {action}""

    return ActionRegisterState(target=target_enum, action=action_enum)
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend
survived,"  async def action_storage_to_exposed(self, site: PlateHolder) -> OverviewRegisterState:
    """"""Move from wait to storage, load MTP, transport to exposed""""""
    return await self.send_action(""mv"", ""sh"", self._site_to_firmware_string(site))
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend
survived,"  async def action_transfer_to_wait(self) -> OverviewRegisterState:
    """"""Open door, retrieve from transfer, return to wait, close door""""""
    return await self.send_action(""mv"", ""tw"", """")
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend
survived,"  async def stop_shaking(self):
    if self.model == CytomatType.C5C:
      raise NotImplementedError(""Shaking is not supported on this model"")
    return hex_to_binary(await self.send_command(""ll"", ""vd"", """"))
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend
survived,"def cytomat_rack_57mm_9(name: str):
  return _cytomat_rack(name=name, site_height=57, num_sites=9, model=""cytomat_rack_57mm_9"")
",pylabrobot/storage/cytomat/racks.py,
survived,"  async def get_swap_register(self) -> SwapStationState:
    value = await self.send_command(""ch"", ""sw"", """")
    return SwapStationState(
      position=SwapStationPosition(int(value[0])),
      load_status_front_of_gate=LoadStatusFrontOfGate(int(value[1])),
      load_status_at_processor=LoadStatusAtProcessor(int(value[2])),
    )
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend
survived,"def _cytomat_rack(name: str, site_height: float, num_sites: int, model: str):
  start = 17.6  # roughly measured, not important right now
  return PlateCarrier(
    name=name,
    size_x=109,  # roughly measured, not important right now
    size_y=142,  # roughly measured, not important right now
    size_z=541,  # roughly measured, not important right now
    sites={
      i: PlateHolder(
        size_x=85.48,
        size_y=127.27,
        # the last site is always 50mm or taller.
        size_z=max(site_height, 50) if i == num_sites - 1 else site_height,
        name=f""{name}-{i + 1}"",
        pedestal_size_z=0,
      ).at(
        Coordinate(
          x=11.76,  # estimate
          y=0,  # estimate
          z=start + site_height * i,
        )
      )
      for i in range(num_sites)
    },
    model=model,
  )
",pylabrobot/storage/cytomat/racks.py,
survived,"  async def send_command(self, command_type: str, command: str, params: str) -> str:
    async def _send_command(command_str) -> str:
      logging.debug(command_str.encode(self.serial_message_encoding))
      await self.io.write(command_str.encode(self.serial_message_encoding))
      resp = (await self.io.read(128)).decode(self.serial_message_encoding)
      if len(resp) == 0:
        raise RuntimeError(""Cytomat did not respond to command, is it turned on?"")
      key, *values = resp.split()
      value = "" "".join(values)

      if key == CytomatActionResponse.OK.value or key == command:
        # actions return an OK response, while checks return the command at the start of the response
        return value
      if key == CytomatActionResponse.ERROR.value:
        logger.error(""Command %s failed with: '%s'"", command_str, resp)
        if value == ""03"":
          error_register = await self.get_error_register()
          await self.reset_error_register()
          raise CytomatTelegramStructureError(f""Telegram structure error: {error_register}"")
        if int(value, base=16) in error_map:
          await self.reset_error_register()
          raise error_map[int(value, base=16)]
        await self.reset_error_register()
        raise Exception(f""Unknown cytomat error code in response: {resp}"")

      logging.error(""Command %s recieved an unknown response: '%s'"", command_str, resp)
      await self.reset_error_register()
      raise Exception(f""Unknown response from cytomat: {resp}"")

    # Cytomats sometimes return a busy or command not recognized error even when the overview
    # register says the machine is not busy, or if the command is known. We will retry a few times,
    # which costs 1s if there is a true error, but is necessary to avoid false negatives.
    command_str = self._assemble_command(command_type=command_type, command=command, params=params)
    n_retries = 10
    exc: Optional[BaseException] = None
    for _ in range(n_retries):
      try:
        return await _send_command(command_str)
      except (CytomatCommandUnknownError, CytomatBusyError) as e:
        exc = e
        await asyncio.sleep(0.1)
        continue
    assert exc is not None
    await self.reset_error_register()
    raise exc
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend
survived,"def test_template_validator_missing_variable() -> None:
    validator = TemplateValidator()
    case = TemplateTestCase(context={""name"": ""Alice""})
    result = validator.validate(""Hello {{ name }} from {{ city }}"", [case])
    assert not result.success
    assert any(""missing variables"" in e for e in result.errors)
",tests/test_template_validator.py,
survived,"    def parse(self, source: str) -> None:
        """"""Naive validation that braces are balanced.""""""
        if source.count(""{{"") != source.count(""}}""):  # pragma: no cover - simple
            raise TemplateSyntaxError(""unbalanced variable braces"")
        if source.count(""{%"") != source.count(""%}""):
            raise TemplateSyntaxError(""unbalanced block braces"")
        if ""{% for"" in source and ""endfor"" not in source:
            raise TemplateSyntaxError(""for block not closed"")
        if ""{% if"" in source and ""endif"" not in source:
            raise TemplateSyntaxError(""if block not closed"")
        return source
",src/jinja2/__init__.py,Environment
survived,"    def __repr__(self) -> str:  # pragma: no cover - trivial
        data = self.model_dump()
        for k in tuple(data):
            if any(s in k.lower() for s in (""token"", ""key"", ""password"")) and data[k]:
                data[k] = ""***""
        return f""{self.__class__.__name__}({data})""",alpha_factory_v1/utils/config_common.py,SettingsBase
survived,"    def _load_ratings(self) -> Dict[str, List[int]]:
        try:
            with open(self.ratings_path, ""r"", encoding=""utf-8"") as f:
                return json.load(f)
        except (OSError, json.JSONDecodeError):
            return {}
",src/meta_agent/template_sharing.py,TemplateSharingManager
survived,"        async def dispatch(
            self, request: Request, call_next: RequestResponseEndpoint
        ) -> Response:
            ip = request.client.host
            now = time.time()
            async with self.lock:
                count, start = self.counters.get(ip, (0, now))
                if now - start > self.window:
                    count = 0
                    start = now
                count += 1
                self.counters[ip] = (count, start)
                if count > self.limit:
                    return Response(""Too Many Requests"", status_code=429)
            return await call_next(request)
",src/interface/api_server.py,SimpleRateLimiter
survived,"    def __exit__(self, exc_type, exc, tb):
        pass
",tests/test_selfheal_import_stubs.py,DummyBlocks
survived,"        def token_stream() -> Generator[str, None, None]:
            for t in [""a"", ""b"", ""c""]:
                yield t
",python/tests/unit_tests/test_run_helpers.py,
survived,"def test_first_token_event_only(mock_client: Client) -> None:
    collected_run: Optional[RunTree] = None

    def on_end(run: RunTree) -> None:
        nonlocal collected_run
        collected_run = run

    with tracing_context(enabled=True):

        @traceable(client=mock_client)
        def token_stream() -> Generator[str, None, None]:
            for t in [""a"", ""b"", ""c""]:
                yield t

        list(token_stream(langsmith_extra={""on_end"": on_end}))

    assert collected_run is not None
    events = [ev for ev in collected_run.events if ev.get(""name"") == ""new_token""]
    assert len(events) == 1
",python/tests/unit_tests/test_run_helpers.py,
survived,"def _wait_running(url: str, headers: dict[str, str]) -> None:
    for _ in range(50):
        try:
            r = httpx.get(f""{url}/runs"", headers=headers)
            if r.status_code == 200:
                return
        except Exception:
            time.sleep(0.1)
    raise AssertionError(""server did not start"")
",tests/test_api_server_subprocess.py,
survived,"def unique_counts(
    array: NamedArray,
    Unique: Axis,
    *,
    axis: AxisSelector | None = None,
    fill_value: ArrayLike | None = None,
) -> tuple[NamedArray, NamedArray]:
    """"""Shortcut for :func:`unique` that also returns counts.""""""

    values, counts = typing.cast(
        tuple[NamedArray, NamedArray],
        unique(
            array,
            Unique,
            return_counts=True,
            axis=axis,
            fill_value=fill_value,
        ),
    )
    return values, counts
",src/haliax/ops.py,
survived,"def test_unique_shortcuts():
    Height = Axis(""Height"", 3)
    Width = Axis(""Width"", 2)

    arr2d = hax.named([[1, 2], [2, 3], [1, 2]], (Height, Width))
    U = Axis(""U"", 3)

    # unique_values
    uv = hax.unique_values(arr2d, U)
    uv_expected = hax.unique(arr2d, U)
    assert jnp.all(uv.array == uv_expected.array)

    # unique_counts
    vc, cc = hax.unique_counts(arr2d, U)
    vc_exp, cc_exp = hax.unique(arr2d, U, return_counts=True)
    assert jnp.all(vc.array == vc_exp.array)
    assert jnp.all(cc.array == cc_exp.array)

    # unique_inverse
    Height1 = Axis(""Height1"", 5)
    arr1d = hax.named([3, 4, 1, 3, 1], (Height1,))
    U2 = Axis(""U2"", 3)
    vi, ii = hax.unique_inverse(arr1d, U2)
    vi_exp, ii_exp = hax.unique(arr1d, U2, return_inverse=True)
    assert jnp.all(vi.array == vi_exp.array)
    assert jnp.all(ii.array == ii_exp.array)

    # unique_all
    U3 = Axis(""U3"", 2)
    va, ia, ina, ca = hax.unique_all(arr2d, U3, axis=Height)
    va_exp, ia_exp, ina_exp, ca_exp = typing.cast(
        tuple[NamedArray, NamedArray, NamedArray, NamedArray],
        hax.unique(
            arr2d,
            U3,
            axis=Height,
            return_index=True,
            return_inverse=True,
            return_counts=True,
        ),
    )
    assert jnp.all(va.array == va_exp.array)
    assert jnp.all(ia.array == ia_exp.array)
    assert jnp.all(ina.array == ina_exp.array)
    assert jnp.all(ca.array == ca_exp.array)",tests/test_ops.py,
survived,"def test_detect_bottleneck_selects_largest_gap(tmp_path: Path) -> None:
    repo = _make_repo(tmp_path)
    agent = MetaRefinementAgent(repo, tmp_path / ""logs"")
    entries = [
        {""module"": ""a"", ""ts"": 0},
        {""module"": ""b"", ""ts"": 2},
        {""module"": ""c"", ""ts"": 8},
    ]
    assert agent._detect_bottleneck(entries) == ""c""
",tests/test_meta_refinement_agent.py,
survived,"def test_init_sets_default_stake(tmp_path: Path) -> None:
    repo = _make_repo(tmp_path)
    logs = tmp_path / ""logs""
    logs.mkdir()
    reg = StakeRegistry()
    assert ""meta"" not in reg.stakes
    MetaRefinementAgent(repo, logs, reg)
    assert reg.stakes[""meta""] == 1.0",tests/test_meta_refinement_agent.py,
survived,"        def _render_source(source: str) -> str:
            # handle extends directive
            match = re.search(r""{%\s*extends\s+'([^']+)'\s*%}"", source)
            if match:
                parent_slug = match.group(1)
                parent = self.registry.load_template(parent_slug, version) or """"
                source = source.replace(match.group(0), """")
                base = _render_source(parent)
                block_re = re.compile(
                    r""{%\s*block\s+(\w+)\s*%}(.*?){%\s*endblock\s*%}"", re.S
                )
                parent_blocks = {n: c for n, c in block_re.findall(base)}
                child_blocks = {n: c for n, c in block_re.findall(source)}
                for name, content in parent_blocks.items():
                    if name in child_blocks:
                        child = child_blocks[name].replace(""{{ super() }}"", content)
                        pattern = (
                            r""{%\s*block\s+""
                            + re.escape(name)
                            + r""\s*%}.*?{%\s*endblock\s*%}""
                        )
                        base = re.sub(pattern, child, base, flags=re.S)
                source = base
            # handle include directive
            include_re = re.compile(r""{%\s*include\s+'([^']+)'\s*%}"")

            def _replace_include(m: re.Match[str]) -> str:
                inc = self.registry.load_template(m.group(1), version) or """"
                return _render_source(inc)

            source = include_re.sub(_replace_include, source)
            return source
",src/meta_agent/template_mixer.py,TemplateMixer
survived,"    def open_logs():
        try:
            open_logs_folder()
            return {""message"": ""opened""}
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))",app/desktop/studio_server/settings_api.py,
survived,"def test_update_settings_thread_safety(config_with_yaml):
    config = config_with_yaml

    exceptions = []

    def update(val):
        try:
            config.update_settings({""int_property"": val})
        except Exception as e:
            exceptions.append(e)

    threads = [threading.Thread(target=update, args=(i,)) for i in range(5)]

    for t in threads:
        t.start()
    for t in threads:
        t.join()

    assert not exceptions
    assert config.int_property in range(5)",libs/core/kiln_ai/utils/test_config.py,
survived,"def test_relationship_not_set_on_instance():
    """"""Relationship defaults should be removed after initialization.""""""
    user = User(id=1, name=""John Doe"", email=""john@example.com"")

    # Relationship field should not be stored in the instance dict
    assert ""address"" not in user.__dict__

    # Attribute shouldn't exist on the instance
    assert not hasattr(user, ""address"")
    with pytest.raises(AttributeError):
        _ = user.address",tests/test_entity.py,
survived,"def _lambda10():
    draw.get(200)()
    draw.get(600)()
",tests/rosetta/transpiler/Python/cistercian-numerals.py,
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    r = add4(True, False, True, False, True, False, False, True)
    print(str(b2i(r.v)) + "" "" + str(b2i(r.s3)) + "" "" + str(b2i(r.s2)) + "" "" + str(b2i(r.s1)) + "" "" + str(b2i(r.s0)))
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/four-bit-adder-1.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/french-republican-calendar.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/formatted-numeric-output.py,
survived,"def drawPoint(g, x, y):
    if x >= 0 and x < width and y >= 0 and y < height:
        row = g[y]
        row[x] = ""#""
        g[y] = row
",tests/rosetta/transpiler/Python/fractal-tree.py,
survived,"def padLeft(s, w):
    res = """"
    n = w - len(s)
    while n > 0:
        res = res + "" ""
        n = n - 1
    return res + s
",tests/rosetta/transpiler/Python/functional-coverage-tree.py,
survived,"def greLeap(year):
    a = int((year % 4))
    b = int((year % 100))
    c = int((year % 400))
    return a == 0 and (b != 0 or c == 0)
",tests/rosetta/transpiler/Python/french-republican-calendar.py,
survived,"def firstFusc(n):
    arr = []
    i = 0
    while i < n:
        arr = arr + [fuscVal(i)]
        i = i + 1
    return arr
",tests/rosetta/transpiler/Python/fusc-sequence.py,
survived,"def _lambda4(n):
    if n == 0:
        return 0.0
    return extract(cos, n - 1) / (float(n))
",tests/rosetta/transpiler/Python/formal-power-series.py,
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/four-is-the-number-of-letters-in-the-....py,
survived,"def c(nums):
    pass
",tests/rosetta/transpiler/Python/function-prototype.py,
survived,"def wordLen(w):
    global idx, words
    while len(words) < w:
        idx = idx + 1
        n = countLetters(words[idx])
        parts = say(n).split("" "")
        j = 0
        while j < len(parts):
            words = words + [parts[j]]
            j = j + 1
        words = words + [""in""]
        words = words + [""the""]
        parts = sayOrdinal(idx + 1) + "","".split("" "")
        j = 0
        while j < len(parts):
            words = words + [parts[j]]
            j = j + 1
    word = words[w - 1]
    return [word, countLetters(word)]
",tests/rosetta/transpiler/Python/four-is-the-number-of-letters-in-the-....py,
survived,"def say(n):
    if n < 20:
        return small[n]
    if n < 100:
        res = tens[n // 10]
        m = n % 10
        if m != 0:
            res = res + ""-"" + small[m]
        return res
    if n < 1000:
        res = say(n // 100) + "" hundred""
        m = n % 100
        if m != 0:
            res = res + "" "" + say(m)
        return res
    if n < 1000000:
        res = say(n // 1000) + "" thousand""
        m = n % 1000
        if m != 0:
            res = res + "" "" + say(m)
        return res
    res = say(n // 1000000) + "" million""
    m = n % 1000000
    if m != 0:
        res = res + "" "" + say(m)
    return res
",tests/rosetta/transpiler/Python/four-is-the-number-of-letters-in-the-....py,
survived,"def pad(n, width):
    s = str(n)
    while len(s) < width:
        s = "" "" + s
    return s
",tests/rosetta/transpiler/Python/four-is-the-number-of-letters-in-the-....py,
survived,"def sayOrdinal(n):
    if n < 20:
        return smallOrd[n]
    if n < 100:
        if n % 10 == 0:
            return tensOrd[n // 10]
        return say(n - n % 10) + ""-"" + smallOrd[n % 10]
    if n < 1000:
        if n % 100 == 0:
            return say(n // 100) + "" hundredth""
        return say(n // 100) + "" hundred "" + sayOrdinal(n % 100)
    if n < 1000000:
        if n % 1000 == 0:
            return say(n // 1000) + "" thousandth""
        return say(n // 1000) + "" thousand "" + sayOrdinal(n % 1000)
    if n % 1000000 == 0:
        return say(n // 1000000) + "" millionth""
    return say(n // 1000000) + "" million "" + sayOrdinal(n % 1000000)
",tests/rosetta/transpiler/Python/four-is-the-number-of-letters-in-the-....py,
survived,"def padLeftZeros(s, width):
    out = s
    while len(out) < width:
        out = ""0"" + out
    return out
",tests/rosetta/transpiler/Python/formatted-numeric-output.py,
survived,"def fourIsMagic(n):
    s = say(n)
    s = capitalize(s)
    t = s
    while n != 4:
        n = len(s)
        s = say(n)
        t = t + "" is "" + s + "", "" + s
    t = t + "" is magic.""
    return t
",tests/rosetta/transpiler/Python/four-is-magic.py,
survived,"def formatFloat(f, prec):
    scale = pow10(prec)
    scaled = (f * scale) + 0.5
    n = (int(scaled))
    digits = str(n)
    while len(digits) <= prec:
        digits = ""0"" + digits
    intPart = digits[0:len(digits) - prec]
    fracPart = digits[len(digits) - prec:len(digits)]
    return intPart + ""."" + fracPart
",tests/rosetta/transpiler/Python/formatted-numeric-output.py,
survived,"def newNode(name, weight, coverage):
    return {""name"": name, ""weight"": weight, ""coverage"": coverage, ""children"": []}
",tests/rosetta/transpiler/Python/functional-coverage-tree.py,
survived,"def render(g):
    out = """"
    y = 0
    while y < height:
        line = """"
        x = 0
        while x < width:
            line = line + g[y][x]
            x = x + 1
        out = out + line
        if y < height - 1:
            out = out + ""\n""
        y = y + 1
    return out
",tests/rosetta/transpiler/Python/fractal-tree.py,
survived,"def _reset_demo_globals() -> Iterator[None]:
    """"""Reset global state altered by the demo.""""""
    yield
    if MODULE in sys.modules:
        sys.modules[MODULE]._A2A = None
",tests/test_alpha_agi_business_3_v1.py,
survived,"    def test_nested_prefix_handling(self) -> None:
        with tempfile.TemporaryDirectory() as repo:
            os.makedirs(os.path.join(repo, ""alpha""), exist_ok=True)
            file_path = os.path.join(repo, ""alpha"", ""test.py"")
            with open(file_path, ""w"") as fh:
                fh.write(""x = 1\n"")
            patch = """"""--- a/alpha/test.py
+++ b/alpha/test.py
@@
-x = 1
+x = 2
""""""
            # Should not raise for valid nested path
            patcher_core._sanity_check_patch(patch, pathlib.Path(repo))
            patcher_core.apply_patch(patch, repo_path=repo)
            with open(file_path) as fh:
                data = fh.read()
            self.assertIn(""x = 2"", data)
",tests/test_self_healing_patcher.py,TestPatcherCore
survived,"    def test_auto_select_model_precedence(self) -> None:
        env = {
            ""OPENAI_MODEL"": ""foo"",
            ""OPENAI_API_KEY"": ""x"",
            ""ANTHROPIC_API_KEY"": ""y"",
            ""LLAMA_MODEL_PATH"": ""/tmp/model.bin"",
        }
        with mock.patch.dict(os.environ, env, clear=True):
            self.assertEqual(self.af._auto_select_model(), ""foo"")
",tests/test_agent_factory.py,TestAgentFactory
survived,"    def test_get_default_tools_with_api_and_local(self) -> None:
        with mock.patch.dict(
            os.environ,
            {""OPENAI_API_KEY"": ""x"", ""ALPHA_FACTORY_ALLOW_LOCAL_CODE"": ""1""},
            clear=True,
        ):
            with mock.patch.object(self.af, ""SDK_AVAILABLE"", True):
                tools = self.af.get_default_tools()
        self.assertTrue(any(isinstance(t, self.af.ComputerTool) for t in tools))
        self.assertTrue(any(isinstance(t, self.af.PythonTool) for t in tools))
",tests/test_agent_factory.py,TestAgentFactory
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/join_multi.py,
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/min_max_builtin.py,
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/cross_join_triple.py,
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/cast_struct.py,
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/string_prefix_slice.py,
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/map_nested_assign.py,
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/count_builtin.py,
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/cross_join.py,
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/list_assign.py,
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/unary_neg.py,
survived,"def add(a: int, b: int) -> int:
    return a + b
",tests/human/x/python/partial_application.py,
survived,"def test_tree_visualization(tmp_path: Path) -> None:
    browser_dir = Path(__file__).resolve().parents[1]
    target = tmp_path / ""browser""
    shutil.copytree(browser_dir, target)
    subprocess.check_call([""npm"", ""run"", ""build""], cwd=target)

    url = (target / ""dist"" / ""index.html"").as_uri()
    tree_path = Path(__file__).resolve().parents[4] / ""docs"" / ""alpha_agi_insight_v1"" / ""tree.json""
    tree = json.loads(tree_path.read_text())

    def count_nodes(node: Mapping[str, Any]) -> int:
        return 1 + sum(count_nodes(c) for c in node.get(""children"", []))

    node_count = count_nodes(tree)
    best_path = tree.get(""bestPath"", [])

    with sync_playwright() as p:
        browser = p.chromium.launch()
        context = browser.new_context()
        page = context.new_page()
        page.goto(url)
        page.wait_for_selector(""#tree-container"")
        page.wait_for_selector(""#tree-container .node"")

        count_initial = page.eval_on_selector_all(""#tree-container .node"", ""els => els.length"")
        page.wait_for_timeout(1000)
        count_later = page.eval_on_selector_all(""#tree-container .node"", ""els => els.length"")
        assert count_later > count_initial

        context.route(""**"", lambda route: route.abort())
        page.wait_for_function(f""document.querySelectorAll('#tree-container .node').length >= {node_count}"")
        page.wait_for_timeout(len(best_path) * 800 + 500)
        highlighted = page.evaluate(
            ""Array.from(document.querySelectorAll('#tree-container circle[fill='#d62728']'))""
            "".map(n => n.parentNode.querySelector('text').textContent)""
        )
        assert highlighted == best_path
        browser.close()",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_tree_visualization.py,
survived,"    def test_batch_add_invalid_relation(self):
        with self.assertRaises(ValueError):
            self.g.batch_add([(""A"", ""bad rel"", ""B"")])
",tests/test_memory_graph_rel.py,TestGraphMemoryRelationValidation
survived,"    def test_batch_add_valid_relation(self):
        self.g.batch_add([(""A"", ""REL1"", ""B""), (""B"", ""REL2"", ""C"")])
        self.assertIn(""B"", self.g.neighbours(""A"", rel=""REL1""))
        self.assertIn(""C"", self.g.neighbours(""B"", rel=""REL2""))
",tests/test_memory_graph_rel.py,TestGraphMemoryRelationValidation
survived,"def test_serialize_deserialize_special_floats():
  assert deserialize(serialize(float(""inf""))) == math.inf
  assert deserialize(serialize(float(""-inf""))) == -math.inf
  result = deserialize(serialize(float(""nan"")))
  assert math.isnan(result)",pylabrobot/tests/serializer_tests.py,
survived,"    def log(self, env: messaging.Envelope) -> None:  # type: ignore[override]
        self.logged.append(env)
",tests/test_adk_agent.py,DummyLedger
survived,"        def start_merkle_task(self, *_a, **_kw) -> None:
            pass
",tests/test_orchestrator_backoff.py,DummyLedger
survived,"        def close(self) -> None:
            pass
",tests/test_orchestrator_backoff.py,DummyLedger
survived,"    def __init__(self, bus: orchestrator.messaging.A2ABus, ledger: orchestrator.Ledger) -> None:
        super().__init__(""fail"", bus, ledger)
",tests/test_orchestrator_backoff.py,FailingAgent
survived,"def test_restart_backoff(monkeypatch):
    monkeypatch.setenv(""AGENT_ERR_THRESHOLD"", ""1"")
    monkeypatch.setenv(""AGENT_BACKOFF_EXP_AFTER"", ""1"")

    delays = []
    orig_sleep = asyncio.sleep

    async def fake_sleep(sec: float):
        delays.append(sec)
        await orig_sleep(0)

    monkeypatch.setattr(orchestrator.asyncio, ""sleep"", fake_sleep)
    monkeypatch.setattr(orchestrator.random, ""uniform"", lambda a, b: 1.0)

    events: list[str] = []

    class DummyLedger:
        def __init__(self, *_a, **_kw) -> None:
            pass

        def log(self, env) -> None:
            if env.payload.get(""event""):
                events.append(env.payload[""event""])

        def start_merkle_task(self, *_a, **_kw) -> None:
            pass

        async def stop_merkle_task(self) -> None:
            pass

        def close(self) -> None:
            pass

    settings = config.Settings(bus_port=0)
    monkeypatch.setattr(orchestrator, ""Ledger"", DummyLedger)
    monkeypatch.setattr(
        orchestrator.Orchestrator,
        ""_init_agents"",
        lambda self: [FailingAgent(self.bus, self.ledger)],
    )
    orch = orchestrator.Orchestrator(settings)
    runner = orch.runners[""fail""]

    async def run() -> None:
        async with orch.bus:
            runner.start(orch.bus, orch.ledger)
            monitor = asyncio.create_task(orch._monitor())
            for _ in range(6):
                await orig_sleep(0)
            monitor.cancel()
            with contextlib.suppress(asyncio.CancelledError):
                await monitor
            if runner.task:
                runner.task.cancel()
                with contextlib.suppress(asyncio.CancelledError):
                    await runner.task

    asyncio.run(run())

    restart_delays = [d for d in delays if d not in (0, 2)]
    assert restart_delays[:2] == [1.0, 2.0]
    assert events.count(""restart"") >= 2
",tests/test_orchestrator_backoff.py,
survived,"    async def insight(req: InsightRequest, _: None = Depends(verify_token)) -> InsightResponse | JSONResponse:
        """"""Return aggregated forecast data across runs.""""""

        try:
            ids = req.ids or list(_simulations.keys())
            forecasts = [_simulations[i].forecast for i in ids if i in _simulations]
            if not forecasts:
                raise HTTPException(status_code=404)

            year_map: dict[int, list[float]] = {}
            for fc in forecasts:
                for point in fc:
                    year_map.setdefault(point.year, []).append(point.capability)
            agg = [
                InsightPoint(year=year, capability=sum(vals) / len(vals))
                for year, vals in sorted(year_map.items())
            ]
            return InsightResponse(forecast=agg)
        except HTTPException as exc:
            return problem_response(exc)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/api_server.py,
survived,"    async def skill_test(self, payload: dict) -> dict:
        return {""ok"": True}
",tests/test_skill_test_route.py,SimpleAgent
survived,"def button_down_template(button_name):
    return f""""""
  - set-control:
      part-id: {button_name}
      control: pressed
      value: 1
  - delay: {hold_time}ms
  """"""
",.scripts/prepare_workflow.py,
survived,"    def from_file(cls, path: Path | str) -> Self:
        """"""Create an attachment from a file path. The attachment is persisted to
        its permanent location when the model is saved.
        """"""
        if isinstance(path, str):
            path = Path(path)
        return cls(input_path=path)
",libs/core/kiln_ai/datamodel/basemodel.py,KilnAttachmentModel
survived,"def reload_devicons():
    from ranger_devicons import devicons
    importlib.reload(devicons)
    return devicons
",tests/test_xdg.py,
survived,"    def _job() -> None:  # pragma: no cover - Rocketry callback
        publish_root(db_path=db_path, out_file=out_file)
",src/archive/cron.py,
survived,"def propose_diff(file_path: str, goal: str) -> str:
    """"""Return a diff appending a placeholder comment with ``goal``.""""""
    p = Path(file_path)
    original = p.read_text(encoding=""utf-8"").splitlines()
    updated = original + [f""# TODO: {goal}""]
    rel = p.name
    diff = difflib.unified_diff(
        original,
        updated,
        fromfile=f""a/{rel}"",
        tofile=f""b/{rel}"",
        lineterm="""",
    )
    return ""\n"".join(diff) + ""\n""",src/tools/diff_mutation.py,
survived,"def aggregate_proof(transcript_path: str | Path, items: Sequence[tuple[str, Sequence[float]]]) -> str:
    """"""Return aggregated proof for ``items`` using ``generate_proof``.""""""
    proofs = [generate_proof(transcript_path, h, s) for h, s in items]
    blob = "","".join(sorted(proofs)).encode()
    return hashlib.sha256(blob).hexdigest()
",src/utils/snark.py,
survived,"    def visit_Break(self, node):
        self.emit(""break"")
",tools/any2mochi/py_simple.py,Conv
survived,"    async def _trigger(name: str) -> Dict[str, bool]:  # noqa: D401
        if name not in runners:
            raise HTTPException(404, ""Agent not found"")
        runners[name].next_ts = 0
        return {""queued"": True}
",alpha_factory_v1/backend/api_server.py,
survived,"async def regression_guard(runners: Dict[str, AgentRunner]) -> None:
    history: deque[float] = deque(maxlen=3)
    while True:
        await asyncio.sleep(1)
        try:
            sample = metrics.dgm_best_score.collect()[0].samples[0]
            score = float(sample.value)
        except Exception:  # pragma: no cover - metrics optional
            continue
        history.append(score)
        if len(history) == 3 and history[1] <= history[0] * 0.8 and history[2] <= history[1] * 0.8:
            runner = runners.get(""aiga_evolver"")
            if runner and runner.task:
                runner.task.cancel()
                with contextlib.suppress(asyncio.CancelledError):
                    await runner.task
            alerts.send_alert(""Evolution paused due to metric regression"")
            history.clear()",alpha_factory_v1/backend/agent_manager.py,
survived,"    def publish(self, topic: str, msg: Dict[str, Any]) -> None:
        if self._producer:
            self._producer.send(topic, msg)
        else:
            assert self._queues is not None
            self._queues.setdefault(topic, asyncio.Queue()).put_nowait(msg)
",alpha_factory_v1/backend/agent_manager.py,EventBus
survived,"        def set(self, *_a: Any) -> None:
            ...
",alpha_factory_v1/backend/telemetry.py,_Metric
survived,"    async def start(self) -> None:
        """"""Launch heartbeat and regression guard tasks.""""""

        self._hb_task = asyncio.create_task(hb_watch(self.runners))
        self._reg_task = asyncio.create_task(regression_guard(self.runners))
",alpha_factory_v1/backend/agent_manager.py,AgentManager
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/group_by_multi_join_sort.py,Lineitem
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/cross_join.py,Customer
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/cross_join.py,Order
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/dataset_sort_take_limit.py,Product
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/left_join_multi.py,Customer
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/join_multi.py,Order
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/group_by_left_join.py,Order
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/right_join.py,Order
survived,"    def get_agent(name: str) -> object:  # noqa: D401
        agent = DummyAgent() if name == ""dummy"" else FailingAgent()

        if hasattr(agent, ""step"") and inspect.iscoroutinefunction(agent.step):
            orig = agent.step

            async def _wrapped(*a: object, **kw: object) -> object:
                t0 = time.perf_counter()
                ok = True
                try:
                    return await orig(*a, **kw)
                except Exception:
                    ok = False
                    raise
                finally:
                    _HEALTH_Q.put((name, (time.perf_counter() - t0) * 1000, ok))

            agent.step = _wrapped
        return agent
",tests/test_backend_orchestrator_dev.py,
survived,"    def __hash__(self):
        return hash(self.minutes)
",hl7/datatypes.py,_UTCOffset
survived,"    def transform(self, X: Any) -> np.ndarray:  # noqa: D401
        if not hasattr(self, ""model_""):
            raise RuntimeError(""Estimator has not been fitted"")
        n_docs = len(self.model_.document_leaves)
        assignments = np.zeros(n_docs, dtype=int)
        for d in range(n_docs):
            leaf = self.model_.document_leaves[d]
            assignments[d] = leaf.node_id
        return assignments",src/hlda/sklearn_wrapper.py,HierarchicalLDAEstimator
survived,"def test_execute_in_sandbox_stdout() -> None:
    agent = _make_agent()
    out, err = agent.execute_in_sandbox(""print('x')"")
    assert out == ""x\n""
    assert err == """"
",tests/test_codegen_agent.py,
survived,"def test_bus_tls_with_script(tmp_path: Path) -> None:
    port = _free_port()
    cert, key, ca, token = _gen_certs(tmp_path)
    cfg = config.Settings(bus_port=port, bus_cert=cert, bus_key=key, bus_token=token)
    bus = messaging.A2ABus(cfg)
    received: list[messaging.Envelope] = []

    async def run() -> None:
        bus.subscribe(""b"", lambda e: received.append(e))
        await bus.start()
        try:
            creds = grpc.ssl_channel_credentials(root_certificates=ca)
            async with grpc.aio.secure_channel(f""localhost:{port}"", creds) as ch:
                stub = ch.unary_unary(""/bus.Bus/Send"")
                payload = {
                    ""sender"": ""a"",
                    ""recipient"": ""b"",
                    ""payload"": {""v"": 1},
                    ""ts"": 0.0,
                    ""token"": token,
                }
                await stub(json.dumps(payload).encode())
            await asyncio.sleep(0.05)
        finally:
            await bus.stop()
            shutil.rmtree(tmp_path / ""certs"", ignore_errors=True)

    asyncio.run(run())
    assert received and received[0].payload[""v""] == 1",tests/test_bus_ssl_gen.py,
survived,"    def fake_run(*args, **kwargs):
        if kwargs.get(""preexec_fn""):
            kwargs[""preexec_fn""]()

        class P:
            stdout = ""{}""
            stderr = """"

        return P()
",tests/test_codegen_agent.py,
survived,"def _free_port() -> int:
    s = socket.socket()
    s.bind((""localhost"", 0))
    port = s.getsockname()[1]
    s.close()
    return port
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_bus_secure.py,
survived,"def test_simulate_export_formats(export_fmt: str) -> None:
    """"""Ensure simulate exports JSON and CSV correctly.""""""
    runner = CliRunner()
    with patch.object(cli, ""asyncio""):
        with patch.object(cli.orchestrator, ""Orchestrator""):
            res = runner.invoke(
                cli.main,
                [
                    ""simulate"",
                    ""--horizon"",
                    ""1"",
                    ""--offline"",
                    ""--sectors"",
                    ""1"",
                    ""--pop-size"",
                    ""1"",
                    ""--generations"",
                    ""1"",
                    ""--export"",
                    export_fmt,
                ],
            )

    assert res.exit_code == 0
    if export_fmt == ""json"":
        assert res.output.startswith(""["")
    else:
        lines = res.output.splitlines()
        assert lines[0] == ""year,capability,affected""
        assert "","" in lines[1]
",tests/test_demo_cli.py,
survived,"def test_parse_diff_rejects_oversized(tmp_path: Path) -> None:
    repo_src = Path(""alpha_factory_v1/demos/self_healing_repo/sample_broken_calc"")
    repo = tmp_path / ""repo""
    shutil.copytree(repo_src, repo)

    long_lines = [""--- a/calc.py"", ""+++ b/calc.py"", ""@@""] + [""+x"" for _ in range(diff_utils.MAX_DIFF_LINES + 1)]
    big_diff = ""\n"".join(long_lines) + ""\n""

    assert diff_utils.parse_and_validate_diff(big_diff, repo_dir=str(repo)) is None",tests/test_diff_utils_apply.py,
survived,"    def binary_path(self, target_dir: str) -> str:
        dep = self.single_for_current_platform()
        if not dep.binary_name:
            return target_dir
        return os.path.join(target_dir, dep.binary_name)
",src/solidlsp/language_servers/common.py,RuntimeDependencyCollection
survived,"def test_skip_net_check(monkeypatch: pytest.MonkeyPatch) -> None:
    """"""Ensure --skip-net-check avoids connectivity checks.""""""
    _no_missing(monkeypatch)

    def _fail_net() -> bool:
        raise AssertionError(""has_network called"")

    monkeypatch.setattr(check_env, ""has_network"", _fail_net)
    rc = check_env.main([""--auto-install"", ""--skip-net-check""])
    assert rc == 0",tests/test_check_env_network.py,
survived,"    def _extract_license(self, dist: metadata.Distribution) -> str:
        """"""Return the license string for a distribution.""""""
        meta = cast(Mapping[str, str], dist.metadata)
        license_header = meta.get(""License"")
        if license_header:
            return license_header.strip()
        for classifier in dist.metadata.get_all(""Classifier"") or []:
            if ""License"" in classifier:
                part = classifier.split(""::"")[-1].strip()
                return part.removesuffix(""License"").strip()
        return """"
",src/meta_agent/dependency_manager.py,DependencyManager
survived,"    def _collect_recursive(
        self,
        package: str,
        pinned: Dict[str, str],
        licenses: Dict[str, str],
        visited: set[str],
        include_hashes: bool,
        hashes: Optional[Dict[str, str]],
    ) -> None:
        if package in visited:
            return
        visited.add(package)
        try:
            dist = metadata.distribution(package)
        except metadata.PackageNotFoundError:
            return

        name = dist.metadata.get(""Name"", package)
        version = dist.version
        pinned[name] = version
        licenses[name] = dist.metadata.get(""License"", """")
        if include_hashes and hashes is not None:
            # Use hash of RECORD contents if available, else hash of version
            record = dist.read_text(""RECORD"")
            if record is not None:
                digest = hashlib.sha256(record.encode(""utf-8"")).hexdigest()
            else:
                digest = hashlib.sha256(version.encode(""utf-8"")).hexdigest()
            hashes[name] = digest

        for req in dist.requires or []:
            req_name = req.split("";"")[0].strip().split()[0]
            req_name = req_name.split(""["")[0]
            if req_name:
                self._collect_recursive(
                    req_name, pinned, licenses, visited, include_hashes, hashes
                )
",src/meta_agent/dependency_manager.py,DependencyManager
survived,"    def __init__(self, repo_dir: str | Path) -> None:
        self.repo_dir = Path(repo_dir)
",src/meta_agent/git_utils.py,GitManager
survived,"def test_git_manager_init_and_commit(tmp_path: Path) -> None:
    gm = GitManager(tmp_path)
    gm.init()
    (tmp_path / ""foo.txt"").write_text(""hi"")
    sha = gm.commit_all(""init"")

    assert (tmp_path / "".git"").exists()
    out = subprocess.check_output(
        [""git"", ""-C"", str(tmp_path), ""rev-parse"", ""HEAD""], text=True
    ).strip()
    assert out == sha
",tests/test_git_utils.py,
survived,"    def _run(
        self, *args: str, env: dict | None = None
    ) -> subprocess.CompletedProcess[str]:
        if not self.git_available():
            raise RuntimeError(""git executable not found"")
        return subprocess.run(
            [""git"", *args],
            cwd=self.repo_dir,
            text=True,
            check=True,
            capture_output=True,
            env=env,
        )
",src/meta_agent/git_utils.py,GitManager
survived,"    def init(self) -> None:
        """"""Initialize a new repository if one does not already exist.""""""
        if (self.repo_dir / "".git"").exists():
            return
        self.repo_dir.mkdir(parents=True, exist_ok=True)
        self._run(""init"")
        self._run(""config"", ""user.name"", ""meta-agent"")
        self._run(""config"", ""user.email"", ""meta-agent@example.com"")
        self._run(""branch"", ""-M"", ""main"")
",src/meta_agent/git_utils.py,GitManager
survived,"    def push(self, remote: str = ""origin"", branch: str = ""main"") -> None:
        self._run(""push"", remote, f""HEAD:{branch}"")",src/meta_agent/git_utils.py,GitManager
survived,"    def commit_all(self, message: str = ""Initial commit"") -> str:
        """"""Add all files and create a commit.

        Returns the commit SHA.
        """"""
        env = os.environ.copy()
        # Deterministic commit timestamp
        env.setdefault(""GIT_AUTHOR_DATE"", ""1970-01-01T00:00:00+0000"")
        env.setdefault(""GIT_COMMITTER_DATE"", ""1970-01-01T00:00:00+0000"")
        self._run(""add"", ""-A"", env=env)
        self._run(""commit"", ""-m"", message, env=env)
        result = self._run(""rev-parse"", ""HEAD"", env=env)
        return result.stdout.strip()
",src/meta_agent/git_utils.py,GitManager
survived,"def test_git_manager_push(tmp_path: Path) -> None:
    remote = tmp_path / ""remote.git""
    subprocess.run([""git"", ""init"", ""--bare"", str(remote)], check=True)

    repo = tmp_path / ""repo""
    gm = GitManager(repo)
    gm.init()
    (repo / ""bar.txt"").write_text(""bar"")
    gm.commit_all(""first"")
    gm.add_remote(""origin"", str(remote))
    gm.push(""origin"", ""main"")

    log = subprocess.check_output(
        [""git"", ""-C"", str(remote), ""log"", ""--oneline""], text=True
    )
    assert ""first"" in log",tests/test_git_utils.py,
survived,"    def _run_tests(self, errors: List[str]) -> None:
        result = subprocess.run(
            [""pytest"", ""-x""],
            cwd=self.bundle_dir,
            capture_output=True,
            text=True,
        )
        if result.returncode != 0:
            errors.append(""tests failed"")
",src/meta_agent/bundle_validator.py,BundleValidator
survived,"    def _run_tests(self, errors: List[str]) -> None:
        result = subprocess.run(
            [""pytest"", ""-x""],
            cwd=self.bundle_dir,
            capture_output=True,
            text=True,
        )
        if result.returncode != 0:
            errors.append(""tests failed"")
",src/meta_agent/bundle_validator.py,BundleValidator
survived,"def test_apply_diff_missing_patch(monkeypatch: pytest.MonkeyPatch) -> None:
    diff = """"""--- a/file.txt\n+++ b/file.txt\n@@\n-\n+ok\n""""""
    with tempfile.TemporaryDirectory() as repo:
        open(os.path.join(repo, ""file.txt""), ""w"").close()
        monkeypatch.setattr(_shutil, ""which"", lambda _cmd: None)
        success, output = diff_utils.apply_diff(diff, repo_dir=repo)
        assert not success
        assert output == ""patch command not found""
",tests/test_diff_utils_apply.py,
survived,"def compose(f, g):
    return lambda x: f(g(x))
",tests/rosetta/transpiler/Python/church-numerals-2.py,
survived,"def plus(m, n):
    return lambda f: compose(m(f), n(f))
",tests/rosetta/transpiler/Python/church-numerals-2.py,
survived,"def primeFactors(n):
    factors = []
    x = n
    while x % 2 == 0:
        factors = factors + [2]
        x = int((x // 2))
    p = 3
    while p * p <= x:
        while x % p == 0:
            factors = factors + [p]
            x = int((x // p))
        p = p + 2
    if x > 1:
        factors = factors + [x]
    return factors
",tests/rosetta/transpiler/Python/composite-numbers-k-with-no-single-digit-factors-whose-factors-are-all-substrings-of-k.py,
survived,"def unescape(s):
    out = """"
    i = 0
    while i < len(s):
        if s[i:i + 1] == ""\\"" and i + 1 < len(s):
            c = s[i + 1:i + 2]
            if c == ""n"":
                out = out + ""\n""
                i = i + 2
                continue
            else:
                if c == ""\\"":
                    out = out + ""\\""
                    i = i + 2
                    continue
        out = out + """".join(s[i:i + 1])
        i = i + 1
    return out
",tests/rosetta/transpiler/Python/compiler-virtual-machine-interpreter.py,
survived,"def convexHull(ps):
    ps = sortPoints(ps)
    h = []
    for pt in ps:
        while len(h) >= 2 and ccw(h[len(h) - 2], h[len(h) - 1], pt) == False:
            h = h[:len(h) - 1]
        h = h + [pt]
    i = len(ps) - 2
    t = len(h) + 1
    while i >= 0:
        pt = ps[i]
        while len(h) >= t and ccw(h[len(h) - 2], h[len(h) - 1], pt) == False:
            h = h[:len(h) - 1]
        h = h + [pt]
        i = i - 1
    return h[:len(h) - 1]
",tests/rosetta/transpiler/Python/convex-hull.py,
survived,"def test_menu_empty_options():
    inter = Interactive()
    with pytest.raises(InteractiveError):
        inter.menu(""Pick"", [])
",tests/ux/test_interactive.py,
survived,"def test_notify_levels(capsys):
    fb = UserFeedback()
    fb.notify(""ok"", NotificationSeverity.SUCCESS)
    out, _ = capsys.readouterr()
    assert ""ok"" in click.unstyle(out)
",tests/ux/test_user_feedback.py,
survived,"    def list_packages(self) -> list[str]:
        """"""Return remote package names from the ADK mesh.""""""
        list_fn = getattr(self._client, ""list_remote_packages"", None)
        if not callable(list_fn):
            raise AttributeError(""list_remote_packages not available"")
        return [pkg.name for pkg in list_fn()]",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/adk_adapter.py,ADKAdapter
survived,"    async def invoke_tool(self, name: str, args: dict[str, object] | None = None) -> object:
        """"""Invoke a tool by name using :class:`mcp.ClientSessionGroup`.""""""
        args = args or {}
        return await self._group.call_tool(name, args)",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/mcp_adapter.py,MCPAdapter
survived,"        def subscribe(self, _t: str, _h):
            pass
",tests/test_adapters.py,DummyBus
survived,"        def close(self) -> None:
            pass
",tests/test_adapters.py,DummyLedger
survived,"        def __init__(self) -> None:
            self.logged: list[messaging.Envelope] = []
",tests/test_adapters.py,DummyLedger
survived,"def _dummy_classes():
    captured: dict[str, str] = {}

    class DummyClient:
        def __init__(self, url: str) -> None:
            captured[""url""] = url

        async def send_transaction(self, tx: object, *args: object) -> None:
            captured[""data""] = tx.instructions[0].data.decode()

        async def close(self) -> None:  # pragma: no cover - dummy
            pass

    class DummyTx:
        def __init__(self) -> None:
            self.instructions: list[object] = []

        def add(self, instr: object) -> ""DummyTx"":
            self.instructions.append(instr)
            return self

    class DummyInstr:
        def __init__(self, program_id: object, data: bytes, keys: list[object]):
            self.data = data

    class DummyPk:
        def __init__(self, val: str) -> None:  # pragma: no cover - dummy
            pass

    return captured, DummyClient, DummyTx, DummyInstr, DummyPk
",tests/test_safety_guardian_property.py,
survived,"def pad(
    array: NamedArray,
    pad_width: Mapping[AxisSelector, tuple[int, int]],
    *,
    mode: str = ""constant"",
    constant_values: NamedOrNumeric = 0,
    **kwargs,
) -> NamedArray:
    """"""Version of ``jax.numpy.pad`` that works with ``NamedArray``.

    ``pad_width`` should be a mapping from axis (or axis name) to a ``(before, after)``
    tuple specifying how much padding to add on each side of that axis. Any axis
    not present in ``pad_width`` will not be padded.
    """"""

    padding = []
    new_axes = []
    for ax in array.axes:
        left_right = pad_width.get(ax)
        if left_right is None:
            left_right = pad_width.get(axis_name(ax))  # type: ignore[arg-type]
        if left_right is None:
            left_right = (0, 0)
        left, right = left_right
        padding.append((left, right))
        new_axes.append(ax.resize(ax.size + left + right))

    result = jnp.pad(
        array.array,
        padding,
        mode=mode,
        constant_values=raw_array_or_scalar(constant_values),
        **kwargs,
    )

    return NamedArray(result, tuple(new_axes))
",src/haliax/ops.py,
survived,"            async def __call__(self, text: str) -> str:
                return ""ok""
",alpha_factory_v1/demos/aiga_meta_evolution/utils.py,OpenAIAgent
survived,"def load_examples(path: str | Path | None = None) -> List[str]:
    """"""Return example innovations from ``path`` or the default file.""""""
    p = Path(path) if path is not None else _DATA_FILE
    try:
        text = p.read_text(encoding=""utf-8"")
    except Exception:
        return []
    return [line.strip() for line in text.splitlines() if line.strip()]
",src/evaluators/logic_critic.py,
survived,"    def score(self, genome: str | Iterable[float]) -> float:
        key = str(genome).lower()
        pos = self.index.get(key, -1)
        base = (pos + 1) / (self.scale + 1) if pos >= 0 else 0.0
        noise = self.rng.random() * 0.001
        val = base + noise
        return float(min(1.0, max(0.0, val)))",src/evaluators/logic_critic.py,LogicCritic
survived,"    def score(self, genome: str | Iterable[float]) -> float:
        tokens = str(genome).lower().split()
        best = 0.0
        for ex in self.examples:
            sim = self._jaccard(tokens, ex.lower().split())
            if sim > best:
                best = sim
        noise = self.rng.random() * 0.001
        val = best + noise
        return float(min(1.0, max(0.0, val)))",src/evaluators/feasibility_critic.py,FeasibilityCritic
survived,"async def test_auto_resources_and_resolvers():
    app, lifespan = create_app()
    async with lifespan(app) as ctx:
        session_factory = ctx[""session_factory""]
        mock_ctx = Mock(spec=EnrichContext)
        mock_ctx.request_context = Mock()
        mock_ctx.request_context.lifespan_context = {""session_factory"": session_factory}

        list_users = app.resources[""list_users""]
        result = await list_users(ctx=mock_ctx)
        assert result.total_items == 1
        assert result.items[0].name == ""Alice""

        get_user = app.resources[""get_user""]
        single = await get_user(user_id=1, ctx=mock_ctx)
        assert single.name == ""Alice""

        # Relationship resolver
        get_orders = app.resources[""get_user_orders""]
        rel = await get_orders(user_id=1, ctx=mock_ctx)
        assert len(rel) == 1
        assert rel[0].id == 1",tests/test_sqlalchemy_autogen.py,
survived,"def _register_relationship_resolvers(
    app: EnrichMCP,
    sa_model: type,
    enrich_model: type,
    models: dict[str, type],
    session_key: str,
) -> None:
    mapper = inspect(sa_model)
    for rel in mapper.relationships:
        if rel.info.get(""exclude""):
            continue
        field_name = rel.key
        if field_name not in enrich_model.model_fields:
            continue
        relationship = enrich_model.model_fields[field_name].default
        target_model = models[rel.mapper.class_.__name__]
        description = rel.info.get(""description"", f""Get {field_name} for {sa_model.__name__}"")

        if rel.uselist:

            def _create_resolver(f_name=field_name, model=sa_model, target=target_model):
                async def func(entity_id: int, ctx: EnrichContext) -> list[Any]:
                    session_factory = ctx.request_context.lifespan_context[session_key]
                    async with session_factory() as session:  # type: AsyncSession
                        obj = await session.get(model, entity_id)
                        if not obj:
                            return []
                        await session.refresh(obj, [f_name])
                        values = getattr(obj, f_name)
                        return [_sa_to_enrich(v, target) for v in values]

                return func

            resolver = _create_resolver()
        else:

            def _create_resolver(f_name=field_name, model=sa_model, target=target_model):
                async def func(entity_id: int, ctx: EnrichContext) -> Any | None:
                    session_factory = ctx.request_context.lifespan_context[session_key]
                    async with session_factory() as session:  # type: AsyncSession
                        obj = await session.get(model, entity_id)
                        if not obj:
                            return None
                        await session.refresh(obj, [f_name])
                        value = getattr(obj, f_name)
                        return _sa_to_enrich(value, target) if value else None

                return func

            resolver = _create_resolver()

        resolver.__name__ = f""get_{sa_model.__name__.lower()}_{field_name}""
        resolver.__doc__ = description
        relationship.resolver(name=""get"")(resolver)
",src/enrichmcp/sqlalchemy/auto.py,
survived,"def _build_incremental_case(rng, seq_lens, k_lens):
    """"""Like ``_build_random_case`` but query only contains the last ``k`` tokens.

    ``seq_lens`` gives the total tokens already in the KV cache for each
    sequence. ``k_lens`` is how many query tokens each sequence has. The KV
    cache still contains ``seq_lens`` tokens for every sequence.
    """"""
    q_full, kv_pages, kv_lens, page_indices, full_cu_q_lens, num_seqs = _build_random_case(rng, seq_lens)

    assert len(seq_lens) == len(k_lens)

    chunks = []
    new_offsets = [0]
    for sid, (total_len, k) in enumerate(zip(seq_lens, k_lens)):
        start = int(full_cu_q_lens[sid]) + total_len - k
        chunks.append(q_full[""tok"", hax.ds(start, k)])
        new_offsets.append(new_offsets[-1] + k)

    q = hax.concatenate(""tok"", chunks)
    cu_q_lens = jnp.asarray(new_offsets, dtype=jnp.int32)

    return q, kv_pages, kv_lens, page_indices, cu_q_lens, num_seqs
",tests/test_paged_attention.py,
survived,"    def agents(self) -> list[str]:
        """"""Return the list of registered agents.""""""
        url = f""{self.base_url}/agents""
        resp = requests.get(url)
        resp.raise_for_status()
        return resp.json()
",alpha_factory_v1/demos/alpha_agi_marketplace_v1/marketplace.py,MarketplaceClient
survived,"    def __init__(self, target: int = 5, market_data: List[int] | None = None) -> None:
        super().__init__(target=target)
        self.market_data = list(market_data) if market_data else []
",alpha_factory_v1/demos/meta_agentic_tree_search_v0/mats/env.py,LiveBrokerEnv
survived,"    def test_run_demo_anthropic_rewriter(self) -> None:
        result = subprocess.run(
            [
                sys.executable,
                ""-m"",
                ""alpha_factory_v1.demos.meta_agentic_tree_search_v0.run_demo"",
                ""--episodes"",
                ""2"",
                ""--rewriter"",
                ""anthropic"",
            ],
            capture_output=True,
            text=True,
        )
        self.assertEqual(result.returncode, 0, result.stderr)
        self.assertIn(""Best agents"", result.stdout)
",tests/test_meta_agentic_tree_search_demo.py,TestMetaAgenticTreeSearchDemo
survived,"def test_chinese_labels() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri()

    with sync_playwright() as p:
        browser = p.chromium.launch()
        context = browser.new_context(locale=""zh-CN"")
        page = context.new_page()
        page.goto(url)
        page.wait_for_selector(""#controls"")
        label_text = page.locator(""#controls label"").first.inner_text()
        assert ""ç§å­"" in label_text
        browser.close()
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_chinese_locale.py,
survived,"def health() -> dict[str, str]:
    return {""status"": ""ok""}",backend/main.py,
survived,"def test_expand_cidr_single_ip():
    assert expand_cidr('192.168.1.1') == ['192.168.1.1']
",tests/test_whois_perms.py,
survived,"  def supports_active_cooling(self) -> bool:
    return False
",pylabrobot/heating_shaking/inheco_backend.py,InhecoThermoShakeBackend
survived,"  def supports_active_cooling(self) -> bool:
    return True
",pylabrobot/temperature_controlling/temperature_controller_tests.py,_FakeBackend
survived,"def test_simulate_dry_run_mut_rate() -> None:
    """"""Running simulate with --dry-run and custom mutation rate should succeed.""""""
    runner = CliRunner()
    with patch.object(cli, ""asyncio""):
        with patch.object(cli.orchestrator, ""Orchestrator""):
            res = runner.invoke(
                cli.main,
                [""simulate"", ""--dry-run"", ""--mut-rate"", ""0.2""],
            )
    assert res.exit_code == 0",tests/test_demo_cli.py,
survived,"def fake_dataset_class(monkeypatch):
    import np_ocr.data as data

    def fake_from_list(lst):
        return FakeDataset(lst)

    monkeypatch.setattr(data, ""Dataset"", types.SimpleNamespace(from_list=staticmethod(fake_from_list)))
    return data
",no-ocr-api/tests/test_ingest_search.py,
survived,"def test_pdfs_to_hf_dataset(monkeypatch, tmp_path, fake_dataset_class):
    from importlib import reload

    data = fake_dataset_class
    reload(data)

    def fake_convert_from_path(*args, **kwargs):
        return [Image.new(""RGB"", (10, 10)), Image.new(""RGB"", (10, 10))]

    class FakePage:
        def __init__(self, text):
            self.text = text

        def extract_text(self):
            return self.text

    class FakeReader:
        def __init__(self, _):
            self.pages = [FakePage(""a""), FakePage(""b"")]

    monkeypatch.setattr(data, ""convert_from_path"", fake_convert_from_path)
    monkeypatch.setattr(data, ""PdfReader"", FakeReader)

    (tmp_path / ""doc1.pdf"").write_bytes(b""%PDF-1.4"")
    (tmp_path / ""doc2.pdf"").write_bytes(b""%PDF-1.4"")

    dataset = data.pdfs_to_hf_dataset(tmp_path)
    assert len(dataset) == 4
    assert dataset[0][""pdf_name""] == ""doc1.pdf""
    assert dataset[0][""pdf_page""] == 1
",no-ocr-api/tests/test_ingest_search.py,
survived,"        def search(self, *_):
            class Limiter:
                def limit(self, *_):
                    class Selector:
                        def select(self, *_):
                            return self

                        def to_list(self):
                            return [{""_distance"": 0.1, ""index"": 0, ""pdf_name"": ""x.pdf"", ""pdf_page"": 1}]

                    return Selector()

            return Limiter()
",no-ocr-api/tests/test_ingest_search.py,FakeTable
survived,"                def limit(self, *_):
                    class Selector:
                        def select(self, *_):
                            return self

                        def to_list(self):
                            return [{""_distance"": 0.1, ""index"": 0, ""pdf_name"": ""x.pdf"", ""pdf_page"": 1}]

                    return Selector()
",no-ocr-api/tests/test_ingest_search.py,FakeTable.Limiter
survived,"def stub_adk(monkeypatch: pytest.MonkeyPatch):
    mod = types.ModuleType(""adk"")

    class Client:
        def generate(self, prompt: str) -> str:
            resp = httpx.post(""https://adk.example/generate"", json={""prompt"": prompt})
            resp.raise_for_status()
            return resp.json()[""text""]

    mod.Client = Client
    monkeypatch.setitem(sys.modules, ""adk"", mod)
    monkeypatch.setitem(sys.modules, ""google.adk"", mod)
    yield mod
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_adapters.py,
survived,"def copy_assets(manifest: dict, repo_root: Path, dist_dir: Path) -> None:
    for rel in manifest[""files""]:
        src_path = ROOT / rel
        if src_path.exists():
            target = dist_dir / rel
            target.parent.mkdir(parents=True, exist_ok=True)
            target.write_bytes(src_path.read_bytes())

    quickstart_pdf = repo_root / manifest[""quickstart_pdf""]
    if quickstart_pdf.exists():
        (dist_dir / quickstart_pdf.name).write_bytes(quickstart_pdf.read_bytes())

    translations = ROOT / manifest[""dirs""][""translations""]
    if translations.exists():
        for f in translations.iterdir():
            if f.is_file():
                target = dist_dir / manifest[""dirs""][""translations""] / f.name
                target.parent.mkdir(parents=True, exist_ok=True)
                target.write_bytes(f.read_bytes())

    critics_src = repo_root / manifest[""dirs""][""critics""]
    critics_dst = dist_dir / manifest[""dirs""][""critics""]
    if critics_src.exists():
        critics_dst.mkdir(parents=True, exist_ok=True)
        for f in critics_src.iterdir():
            (critics_dst / f.name).write_bytes(f.read_bytes())

    for key in (""wasm"", ""wasm_llm""):
        d = ROOT / manifest[""dirs""][key]
        if d.exists():
            target_dir = dist_dir / manifest[""dirs""][key]
            target_dir.mkdir(exist_ok=True)
            for f in d.iterdir():
                (target_dir / f.name).write_bytes(f.read_bytes())
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/manual_build.py,
survived,"def scenario_2020_mrna() -> replay.Scenario:
    return replay.load_scenario(""2020_mrna"")
",tests/conftest.py,
survived,"        def wait(self, timeout: float | None = None) -> None:
            pass
",tests/test_start_alpha_business.py,DummyProc
survived,"    def fake_post(url: str, json: dict, timeout: int) -> Resp:
        post_calls.append((url, json, timeout))
        return Resp()
",tests/test_start_alpha_business.py,
survived,"    def test_trigger_best_alpha(self):
        """"""trigger_best_alpha should POST the highest scoring entry.""""""
        data = [
            {""alpha"": ""x"", ""score"": 1},
            {""alpha"": ""y"", ""score"": 5},
        ]
        with patch.object(bridge.Path, ""read_text"", return_value=json.dumps(data)):
            with patch.object(bridge, ""AsyncClient"") as client_cls:
                client = AsyncMock()
                client.__aenter__.return_value = client
                client.post.return_value = DummyResponse()
                client_cls.return_value = client
                result = asyncio.run(bridge.trigger_best_alpha())
        client.post.assert_awaited_once_with(
            f""{bridge.HOST}/agent/alpha_execution/trigger"",
            json={""alpha"": ""y"", ""score"": 5},
            headers=bridge.HEADERS,
            timeout=5,
        )
        self.assertEqual(result, ""best alpha queued"")
",tests/test_openai_bridge_integration.py,TestBusinessAgentIntegration
survived,"    def text(self) -> str:
        try:
            return self.content.decode()
        except UnicodeDecodeError:
            return self.content.decode(""latin1"", errors=""replace"")
",alpha_factory_v1/af_requests.py,Response
survived,"    def __init__(self, status_code: int, content: bytes, headers: dict | None = None, url: str = """") -> None:
        self.status_code = status_code
        self.content = content
        self.headers = headers or {}
        self.url = url
",alpha_factory_v1/af_requests.py,Response
survived,"    def _save_manifest(self, manifest: Dict[str, Any]) -> None:
        try:
            with open(self.manifest_path, ""w"", encoding=""utf-8"") as f:
                json.dump(manifest, f, indent=2)
        except IOError as e:
            logger.error(f""Failed to write template registry manifest: {e}"")
",src/meta_agent/template_registry.py,TemplateRegistry
survived,"    def diff(self, slug: str, old_version: str, new_version: str) -> str:
        old = self.load_template(slug, old_version) or """"
        new = self.load_template(slug, new_version) or """"
        return ""\n"".join(
            difflib.unified_diff(
                old.splitlines(),
                new.splitlines(),
                fromfile=old_version,
                tofile=new_version,
                lineterm="""",
            )
        )
",src/meta_agent/template_registry.py,TemplateRegistry
survived,"    def build_index(self) -> None:
        """"""Build an in-memory index of template metadata and content.""""""
        self._index.clear()
        for entry in self.registry.list_templates():
            slug = entry[""slug""]
            version = entry.get(""current_version"")
            if not version:
                continue
            content = self.registry.load_template(slug, version) or """"
            metadata_path = (
                self.registry.templates_dir
                / slug.replace("" "", ""_"").lower()
                / f""v{version.replace('.', '_')}""
                / METADATA_FILE_NAME
            )
            try:
                with open(metadata_path, ""r"", encoding=""utf-8"") as f:
                    metadata = json.load(f)
            except (OSError, json.JSONDecodeError):
                metadata = {}
            self._index.append(
                {
                    ""slug"": slug,
                    ""version"": version,
                    ""metadata"": metadata,
                    ""content"": content,
                }
            )
",src/meta_agent/template_search.py,TemplateSearchEngine
survived,"def test_a2a_port_invalid(monkeypatch):
    """"""Invalid ``A2A_PORT`` values should not crash the import.""""""
    dummy = types.ModuleType(""a2a"")

    class DummySocket:
        def __init__(self, *args, **kwargs) -> None:  # pragma: no cover - dummy
            raise AssertionError(""should not be instantiated"")

    dummy.A2ASocket = DummySocket
    monkeypatch.setitem(sys.modules, ""a2a"", dummy)
    monkeypatch.setenv(""A2A_PORT"", ""abc"")
    if MODULE in sys.modules:
        del sys.modules[MODULE]
    mod = importlib.import_module(MODULE)
    assert mod._A2A is None
",tests/test_alpha_agi_business_3_v1.py,
survived,"    def _target(q: _mp.Queue) -> None:
        _apply_limits()
        try:
            proc = subprocess.Popen(
                [sys.executable, script],
                stdin=subprocess.PIPE,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
            )
            try:
                out, err = proc.communicate(inp_json, timeout=SOFT_T)
            except subprocess.TimeoutExpired:
                proc.kill()
                out, err = proc.communicate()
            q.put((out, err))
        except Exception as exc:  # pragma: no cover
            q.put(("""", str(exc)))
",alpha_factory_v1/demos/meta_agentic_agi_v3/curriculum/azr_engine.py,
survived,"    def _add(self, t: Triplet) -> None:
        self.buffer.append(t)
        if len(self.buffer) > self.buffer_max:
            self.buffer.pop(0)
",alpha_factory_v1/demos/meta_agentic_agi_v3/curriculum/azr_engine.py,AZREngine
survived,"    def _build_prompt(self, n: int) -> str:
        examples = (
            ""\n\n"".join(
                f""```python\n{t.program}```\n```json\n{t.inp}```\n```json\n{t.out}```""
                for t in self._rng.sample(self.buffer, k=min(3, len(self.buffer)))
            )
            or ""(buffer empty)""
        )

        return self._PROMPT.format(
            n=n,
            max_loc=MAX_PROG_LOC,
            buf=len(self.buffer),
            examples=examples,
        )
",alpha_factory_v1/demos/meta_agentic_agi_v3/curriculum/azr_engine.py,AZREngine
survived,"    def setUp(self) -> None:
        self.settings = config.Settings(bus_port=0)
        self.bus = messaging.A2ABus(self.settings)
",tests/test_insight_orchestrator_features.py,TestMessaging
survived,"    def test_publish_subscribe(self) -> None:
        received = []

        async def handler(env: messaging.Envelope) -> None:
            received.append(env)

        self.bus.subscribe(""x"", handler)
        env = messaging.Envelope(""a"", ""x"", {""v"": 1}, 0.0)
        self.bus.publish(""x"", env)
        asyncio.run(asyncio.sleep(0.01))
        self.assertEqual(received[0].payload[""v""], 1)
",tests/test_insight_orchestrator_features.py,TestMessaging
survived,"    def test_registration_records(self) -> None:
        count = self.orch.ledger.conn.execute(""SELECT COUNT(*) FROM messages"").fetchone()[0]
        self.assertEqual(count, len(self.orch.runners))
",tests/test_insight_orchestrator_features.py,TestInsightOrchestrator
survived,"def exponential_curve(t: float, k: float = 3.0) -> float:
    scale = math.exp(k) - 1.0
    return min(1.0, (math.exp(k * t) - 1.0) / scale)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/simulation/forecast.py,
survived,"def timeline_df(traj: list[Any]) -> pd.DataFrame:
    """"""Return a DataFrame summarising sector performance.""""""

    rows = []
    for point in traj:
        for sec in point.sectors:
            rows.append(
                {
                    ""year"": point.year,
                    ""sector"": sec.name,
                    ""energy"": sec.energy,
                    ""disrupted"": sec.disrupted,
                }
            )
    return pd.DataFrame(rows)
",src/interface/web_app.py,
survived,"def _timeline_df(traj: list[Any]) -> ""pd.DataFrame"":
    """"""Convert trajectory data into a DataFrame.""""""

    import pandas as pd

    rows = []
    for point in traj:
        for sec in point.sectors:
            rows.append(
                {
                    ""year"": point.year,
                    ""sector"": sec.name,
                    ""energy"": sec.energy,
                    ""disrupted"": sec.disrupted,
                }
            )
    return pd.DataFrame(rows)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/web_app.py,
survived,"    def baz(x: Float[""b""]):  # type: ignore  # noqa: F722
        pass
",tests/test_dtype_typing.py,
survived,"    def __init__(self):
        self.app = types.SimpleNamespace(middleware=lambda *_a, **_k: lambda f: f)
",tests/test_openai_bridge_integration.py,_Router
survived,"def _to_mochi(v: Any) -> str:
    if v is None:
        return ""null""
    if isinstance(v, bool):
        return ""true"" if v else ""false""
    if isinstance(v, (int, float)):
        return str(v)
    if isinstance(v, str):
        return ""\"""" + v.replace(""\\"", ""\\\\"").replace(""\"""", ""\\\"""") + ""\""""
    if isinstance(v, Sequence) and not isinstance(v, (str, bytes, bytearray)):
        return ""["" + "", "".join(_to_mochi(x) for x in v) + ""]""
    if isinstance(v, dict):
        items = "", "".join(f'{_to_mochi(k)}: {_to_mochi(val)}' for k, val in v.items())
        return ""{"" + items + ""}""
    raise TypeError(f""unsupported value type: {type(v).__name__}"")",tools/libmochi/python/libmochi.py,
survived,"def call(code: str, func: str, *args: Any, mochi_bin: str = ""mochi"") -> Any:
    """"""Call ``func`` defined in ``code`` with ``args`` and return the result.

    ``code`` should contain the Mochi function definition. The result is
    obtained by wrapping the call with the ``json`` builtin and decoding the
    output.
    """"""
    args_literal = "", "".join(_to_mochi(a) for a in args)
    snippet = f""{code}\njson({func}({args_literal}))\n""
    out = _run(snippet, mochi_bin)
    return json.loads(out.strip())
",tools/libmochi/python/libmochi.py,
survived,"def test_first_time_event_score_is_one() -> None:
    """"""First occurrence should return ``1.0``.""""""
    _reset_cache()
    value = cr.reward({}, None, {""event"": 1})
    assert value == 1.0
",tests/test_curiosity_reward.py,
survived,"def test_llama_paged_decode_matches_full_prefill():
    """"""Ensure llama paged decode matches full forward when prefilling entire sequences.""""""
    Pos = Axis(""position"", 16)
    Embed = Axis(""embed"", 8)
    Vocab = Axis(""vocab"", 64)

    cfg = LlamaConfig(
        seq_len=Pos.size,
        hidden_dim=Embed.size,
        intermediate_dim=16,
        num_layers=2,
        num_heads=2,
        num_kv_heads=2,
        rope=None,
        gradient_checkpointing=False,
        scan_layers=True,
        attn_backend=AttentionBackend.VANILLA,
    )

    model_key, input_key = jrandom.split(jrandom.PRNGKey(0))
    model = LlamaLMHeadModel.init(Vocab=Vocab, config=cfg, key=model_key)

    input_ids = hax.random.randint(input_key, Pos, 0, Vocab.size)

    pt = PageTable.init(max_pages=4, max_seqs=2, page_size=4, max_pages_per_seq=4)
    pt, seq1 = pt.assign_seq_id_to_seq()
    pt, seq2 = pt.assign_seq_id_to_seq()

    seq_ids = hax.named([seq1, seq2, -1, -1, -1, -1, -1, -1], ""seq"")
    new_token_counts = hax.named([4, 3, 0, 0, 0, 0, 0, 0], ""seq"")
    seg_ids = hax.named([0] * 4 + [1] * 3 + [-1] * 9, ""position"")
    pt, binfo = pt.allocate_for_seqs(updated_seqs=seq_ids, new_counts=new_token_counts, tokens=seg_ids)

    mask = AttentionMask.causal().with_segment_ids(seg_ids)
    full_out = model.activations(input_ids, attn_mask=mask, key=jrandom.PRNGKey(1))

    layer_caches = model.transformer.initial_cache(pt, dtype=jnp.float32)
    page_state = KvPageState.from_batch(binfo, layer_caches)
    pos_ids = hax.arange(Pos, dtype=jnp.int32)
    x = model.embeddings.embed(input_ids)
    decode_out, _ = _jit_paged_decode(model.transformer, x, pos_ids, page_state)

    full_out = full_out[""position"", hax.dslice(0, 7)]
    decode_out = decode_out[""position"", hax.dslice(0, 7)]
    assert_trees_all_close(full_out.array, decode_out.array, atol=1e-4, rtol=1e-4)
",tests/test_llama_decode.py,
survived,"def sample_json_file(tmp_path, valid_spec_dict):
    file_path = tmp_path / ""spec.json""
    with open(file_path, ""w"") as f:
        json.dump(valid_spec_dict, f)
    return file_path
",tests/integration/test_telemetry_integration.py,
survived,"        def __init__(self, endpoint: str | None = None, *args: Any, **_kw: Any) -> None:  # noqa: D401 - simple init
            called.append(endpoint or """")
",tests/test_metrics.py,DummyExporter
survived,"    def fake_apply(diff_text: str, repo_path: str) -> None:
        applied.append(diff_text)
        diff_utils.apply_diff(diff_text, repo_dir=repo_path)
",tests/test_self_healer_sandbox.py,
survived,"def test_agent_creates_default_router(monkeypatch):
    monkeypatch.setenv(""OPENAI_API_KEY"", ""x"")
    agent = GuardrailDesignerAgent()
    assert isinstance(agent.model_router, GuardrailModelRouter)
    assert agent.default_model == agent.model_router.default_model",tests/test_guardrail_designer_agent.py,
survived,"    async def restart_no_error(self: orchestrator.AgentRunner, bus, ledger) -> None:
        if self.task:
            self.task.cancel()
            with contextlib.suppress(Exception):
                await self.task
        self.agent = self.cls(bus, ledger)
        self.start(bus, ledger)
        self.last_beat = orchestrator.time.time()
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_orchestrator.py,
survived,"def _sort_key(k):
    if isinstance(k, (list, tuple, dict)):
        return str(k)
    return k
",tests/machine/x/python/q2.py,
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/machine/x/python/q1.py,_Group
survived,"def _avg(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""avg() expects list or group"")
    if not v:
        return 0
    s = 0.0
    for it in v:
        if isinstance(it, (int, float)):
            s += float(it)
        else:
            raise Exception(""avg() expects numbers"")
    return s / len(v)
",tests/machine/x/python/q1.py,
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/q1.py,Lineitem
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/machine/x/python/q1.py,
survived,"def _get(obj, name):
    if obj is None:
        return None
    if isinstance(obj, dict):
        if name in obj:
            return obj[name]
    if hasattr(obj, name):
        return getattr(obj, name)
    if name == ""items"" and hasattr(obj, ""Items""):
        return getattr(obj, ""Items"")
    if isinstance(obj, (list, tuple)):
        for it in obj:
            try:
                return _get(it, name)
            except Exception:
                pass
    raise Exception(""field not found: "" + name)
",tests/machine/x/python/q1.py,
survived,"def bincount(
    x: NamedArray,
    Counts: Axis,
    *,
    weights: NamedArray | ArrayLike | None = None,
    minlength: int = 0,
) -> NamedArray:
    """"""Named version of `jax.numpy.bincount`.

    The output axis is specified by ``Counts``.
    """"""

    if x.ndim != 1:
        raise ValueError(""bincount only supports 1D arrays"")

    w_array = None
    if weights is not None:
        if isinstance(weights, NamedArray):
            weights = haliax.broadcast_to(weights, x.axes)
            w_array = weights.array
        else:
            w_array = jnp.asarray(weights)

    result = jnp.bincount(x.array, weights=w_array, minlength=minlength, length=Counts.size)
    return NamedArray(result, (Counts,))
",src/haliax/ops.py,
survived,"        async def create_item() -> bool:
            return True
",tests/test_tooldef.py,
survived,"    def fake_run(models, top_n):
        called[""models""] = models
        called[""top_n""] = top_n
",tests/test_transfer_test.py,
survived,"    def __init__(self, steps: int = 2, rng: random.Random | None = None) -> None:
        self.steps = steps
        self.rng = rng or random.Random()
        self._op = PromptRewrite(rng=self.rng)
",src/simulation/mats_ops.py,SelfRewriteOperator
survived,"def run() -> None:
    n = 21
    total = sum(range(n))
    expected = n*(n-1)//2
    assert total == expected",benchmarks/swe_mini/task_021.py,
survived,"def run() -> None:
    n = 7
    total = sum(range(n))
    expected = n*(n-1)//2
    assert total == expected",benchmarks/swe_mini/task_007.py,
survived,"def run() -> None:
    parts = [""poly"", ""task"", ""15""]
    joined = ""-"".join(parts)
    assert joined.split(""-"")[2] == str(15)",benchmarks/poly_mini/task_015.py,
survived,"def run() -> None:
    n = 4
    total = sum(range(n))
    expected = n*(n-1)//2
    assert total == expected",benchmarks/swe_mini/task_004.py,
survived,"def run() -> None:
    parts = [""poly"", ""task"", ""11""]
    joined = ""-"".join(parts)
    assert joined.split(""-"")[2] == str(11)",benchmarks/poly_mini/task_011.py,
survived,"    def _ensure_pydantic_methods(cls: type[BaseModel]) -> None:
        """"""Ensure ``model_dump`` and ``model_dump_json`` exist on ``cls``.""""""

        if not hasattr(cls, ""model_dump""):

            def _model_dump(self: BaseModel, *args: Any, **kwargs: Any) -> Any:
                return self.dict(*args, **kwargs)

            cls.model_dump = _model_dump  # type: ignore[attr-defined]

        if not hasattr(cls, ""model_dump_json""):

            def _model_dump_json(self: BaseModel, *args: Any, **kwargs: Any) -> str:
                return self.json(*args, **kwargs)

            cls.model_dump_json = _model_dump_json  # type: ignore[attr-defined]
",src/meta_agent/__init__.py,
survived,"    def test_new_env_tool(self):
        with patch.object(
            bridge.requests,
            ""post"",
            return_value=DummyResponse({""ok"": True}),
        ) as post:
            result = asyncio.run(bridge.new_env())
        post.assert_called_once_with(
            ""http://localhost:7860/command"",
            json={""cmd"": ""new_env""},
            timeout=5,
        )
        self.assertEqual(result, {""ok"": True})
",tests/test_inspector_bridge.py,TestInspectorAgent
survived,"def _tool(*_a, **_k):
    def _decorator(func):
        return func
    return _decorator
",tests/test_inspector_bridge.py,
survived,"    def test_list_agents_tool(self):
        with patch.object(bridge.requests, ""get"", return_value=DummyResponse([""a""])) as get:
            result = asyncio.run(bridge.list_agents())
        get.assert_called_once_with(""http://localhost:7860/agents"", timeout=5)
        self.assertEqual(result, [""a""])
",tests/test_inspector_bridge.py,TestInspectorAgent
survived,"    def optimise(self, sequence: str) -> Dict[str, Any]:  # noqa: D401
        loop = asyncio.get_event_loop()
        return loop.run_until_complete(self._optimise_async(sequence))
",alpha_factory_v1/backend/agents/biotech_agent.py,BiotechAgent
survived,"    def test_rsi(self):
        uptrend = list(range(1, 20))
        self.assertGreater(am.rsi(uptrend, period=5), 70)
        downtrend = list(range(20, 1, -1))
        self.assertLess(am.rsi(downtrend, period=5), 30)
",alpha_factory_v1/tests/test_alpha_model.py,AlphaModelTest
survived,"    def as_dict(self) -> Dict[str, float]:
        """"""Return a ``dict`` representation suitable for ``toy_fitness``.""""""

        return {
            ""temperature"": float(self.temperature),
            ""top_p"": float(self.top_p),
            ""max_tokens"": int(self.max_tokens),
        }
",alpha_factory_v1/backend/genetic_tests.py,GeneConfig
survived,"    async def close(self) -> None:
        if hasattr(self._backend, ""close""):
            await self._backend.close()
",alpha_factory_v1/backend/market_data.py,MarketData
survived,"    async def __aenter__(self) -> ""PolygonMarketData"":
        await self._client()
        return self
",alpha_factory_v1/backend/market_data.py,PolygonMarketData
survived,"    async def close(self) -> None:
        await self.__aexit__(None, None, None)
",alpha_factory_v1/backend/market_data.py,PolygonMarketData
survived,"    def setUp(self):
        self.tmpdir = tempfile.TemporaryDirectory()
        self.memory = Memory(self.tmpdir.name)
        self.gov = DummyGov()
",alpha_factory_v1/tests/test_planner_agent.py,PlannerAgentTest
survived,"def main() -> None:
    ap = argparse.ArgumentParser(description=""Run Meta-Agentic Î±-AGI demo"")
    ap.add_argument(""--gens"", type=int, default=6, help=""number of generations"")
    ap.add_argument(
        ""--provider"",
        default=os.getenv(""LLM_PROVIDER"", ""mistral:7b-instruct.gguf""),
        help=""openai:gpt-4o | anthropic:claude-3-sonnet | mistral:7b-instruct.gguf"",
    )
    ap.add_argument(
        ""--ui"",
        action=""store_true"",
        help=""launch Streamlit lineage UI after the search loop"",
    )
    ap.add_argument(
        ""--db"",
        type=Path,
        default=DB,
        help=""path to lineage SQLite DB"",
    )
    args = ap.parse_args()

    os.environ[""METAAGI_DB""] = str(args.db)

    try:
        asyncio.run(meta_loop(args.gens, args.provider))
    except KeyboardInterrupt:
        return

    if args.ui:
        ui_path = Path(__file__).parent / ""ui"" / ""lineage_app.py""
        print(f""\nStarting Streamlit UI â†’ {ui_path}\n"")
        subprocess.call([""streamlit"", ""run"", str(ui_path)])
",alpha_factory_v1/demos/meta_agentic_agi/app.py,
survived,"async def _startup():
    global orch
    orch=Orchestrator()
    threading.Thread(target=orch.loop,daemon=True).start()
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,
survived,"    def handle(self,msg):
        if ""loss"" in msg and (np.isnan(msg[""loss""]) or msg[""loss""]>1e3):
            LOG.warning(""[SAFETY] triggered â€“ halting learner"")
            self.emit(""orch"",{""cmd"":""stop""})
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,BasicSafetyAgent
survived,"    def _obs(self):
        vec = np.zeros(self.size*self.size, dtype=np.float32)
        vec[self.agent[0]*self.size+self.agent[1]] = 1.0
        return vec
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,MiniWorld
survived,"    def _on_cmd(self,msg):
        if msg.get(""cmd"")==""new_env"":
            idx=random.randrange(len(self.envs))
            self.envs[idx]=self.gen.propose()
            self.learners[idx]=Learner(self.envs[idx])
            LOG.info(""Replaced env #%d"", idx)
        elif msg.get(""cmd"")==""stop"": self.stop=True
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,Orchestrator
survived,"    def _clip(self,v): return max(0, min(self.size-1, v))
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,MiniWorld
survived,"    async def submit_order(self, symbol: str, qty: float, side: str, type: str = ""market"") -> str:
        qty = float(qty)
        pos = self.positions.get(symbol.upper(), 0.0)
        if side.lower() == ""buy"":
            pos += qty
        else:
            pos -= qty
        self.positions[symbol.upper()] = pos
        oid = next(self._ids)
        _LOG.info(""Simulated order %s %s %s@%s"", oid, side, qty, symbol)
        return str(oid)
",alpha_factory_v1/backend/broker/broker_sim.py,SimulatedBroker
survived,"    async def __aenter__(self) -> ""SimulatedBroker"":
        return self
",alpha_factory_v1/backend/broker/broker_sim.py,SimulatedBroker
survived,"def _positive_int(name: str) -> callable:
    """"""Return a parser for positive integers.""""""

    def parser(value: str) -> int:
        try:
            iv = int(value)
        except ValueError as exc:  # pragma: no cover - argparse handles message
            raise argparse.ArgumentTypeError(f""{name} must be an integer"") from exc
        if iv <= 0:
            raise argparse.ArgumentTypeError(f""{name} must be > 0"")
        return iv

    return parser
",alpha_factory_v1/edge_runner.py,
survived,"    def _mark_invite_used(inv: Invitation, user: User) -> None:
        inv.used = True if not inv.unlimited else inv.used
        inv.used_at = datetime.datetime.now()
        inv.used_by = user
        db.session.commit()
",app/services/media/jellyfin.py,JellyfinClient
survived,"    async def run() -> None:
        client, _ = await make_client()
        async with client:
            headers = {
                ""Authorization"": ""Bearer test-token"",
                ""Origin"": ""http://example.com"",
            }
            r = await client.get(""/runs"", headers=headers)
            assert r.status_code == 200
            assert r.headers.get(""access-control-allow-origin"") == ""http://example.com""
",tests/test_api_server_cors.py,
survived,"def test_cors_headers() -> None:
    async def run() -> None:
        client, _ = await make_client()
        async with client:
            headers = {
                ""Authorization"": ""Bearer test-token"",
                ""Origin"": ""http://example.com"",
            }
            r = await client.get(""/runs"", headers=headers)
            assert r.status_code == 200
            assert r.headers.get(""access-control-allow-origin"") == ""http://example.com""

    asyncio.run(run())",tests/test_api_server_cors.py,
survived,"    def __init__(self):
        self.called = False
",tests/test_core/test_decorators/test_guard.py,SimpleGuard
survived,"    async def optimize_autovacuum(self, rollback: bool = False) -> None:
        """"""Apply or revert autovacuum settings.""""""
        if rollback:
            query = self.qbe.build_optimize_autovacuum_rollback_query()
        else:
            query = self.qbe.build_optimize_autovacuum_query()

        await self.driver.execute(query)
",pgqueuer/queries.py,Queries
survived,"def test_patcher_core_cli(tmp_path: Path, monkeypatch: pytest.MonkeyPatch) -> None:
    repo = tmp_path / ""repo""
    tests_dir = repo / ""tests""
    tests_dir.mkdir(parents=True)

    # buggy source file
    (repo / ""calc.py"").write_text(""def add(a, b):\n    return a - b\n"", encoding=""utf-8"")

    # failing test
    (tests_dir / ""test_calc.py"").write_text(
        ""from calc import add\n\ndef test_add():\n    assert add(1, 2) == 3\n"",
        encoding=""utf-8"",
    )

    # patch to fix the bug
    patch_file = tmp_path / ""fix.diff""
    patch_file.write_text(
        """"""--- a/calc.py
+++ b/calc.py
@@ -1,2 +1,2 @@
 def add(a, b):
-    return a - b
+    return a + b
\ No newline at end of file
"""""",
        encoding=""utf-8"",
    )

    import openai_agents

    class StubAgent:
        def __init__(self, *a, **k):
            self.patch_file = os.environ.get(""PATCH_FILE"")

        def __call__(self, _prompt: str) -> str:
            return Path(self.patch_file).read_text() if self.patch_file else """"

    monkeypatch.setattr(openai_agents, ""OpenAIAgent"", StubAgent)

    env = os.environ.copy()
    env[""PATCH_FILE""] = str(patch_file)

    result = subprocess.run(
        [
            sys.executable,
            ""-m"",
            ""alpha_factory_v1.demos.self_healing_repo.patcher_core"",
            ""--repo"",
            str(repo),
        ],
        capture_output=True,
        text=True,
        env=env,
    )

    assert result.returncode == 0, result.stdout + result.stderr
    combined = result.stdout + result.stderr
    assert ""Patch fixed the tests"" in combined",tests/test_patcher_core_cli.py,
survived,"def boom(a, b):
    print(""boom"")
    return True
",tests/transpiler/x/py/short_circuit.py,
survived,"def twoSum(nums, target):
    n = len(nums)
    for i in range(0, n):
        for j in range((i + 1), n):
            if ((nums[i] + nums[j]) == target):
                return [i, j]
    return [-1, -1]
",tests/transpiler/x/py/two-sum.py,
survived,"def test_docs_service_worker_present() -> None:
    html = (DOCS_DIR / ""index.html"").read_text()
    assert (DOCS_DIR / ""service-worker.js"").is_file()
    assert re.search(r""service-worker.js"", html)
    assert ""serviceWorker"" in html",tests/test_docs_service_worker_present.py,
survived,"def boom():
    print(""boom"")
    return True
",tests/human/py/bool_chain.py,
survived,"def test_max_sim_tasks(tmp_path: Path, monkeypatch: pytest.MonkeyPatch) -> None:
    monkeypatch.setenv(""SIM_RESULTS_DIR"", str(tmp_path))
    monkeypatch.setenv(""MAX_SIM_TASKS"", ""1"")
    from src.interface import api_server as api

    api = importlib.reload(api)

    cfg = api.SimRequest(horizon=1, pop_size=2, generations=1)
    counter = {""current"": 0, ""max"": 0}

    async def stub(sim_id: str, _cfg: api.SimRequest) -> None:
        counter[""current""] += 1
        counter[""max""] = max(counter[""max""], counter[""current""])
        await asyncio.sleep(0.05)
        counter[""current""] -= 1

    monkeypatch.setattr(api, ""_background_run"", stub)

    asyncio.run(asyncio.gather(api._bounded_run(""a"", cfg), api._bounded_run(""b"", cfg)))

    assert counter[""max""] == 1",tests/test_max_sim_tasks.py,
survived,"    def _load_results() -> None:
        entries: list[tuple[float, ResultsResponse]] = []
        latest_time = 0.0
        latest_id: str | None = None
        for f in _results_dir.glob(""*.json""):
            try:
                data = json.loads(f.read_text())
                res = ResultsResponse(**data)
            except Exception:
                continue
            mtime = f.stat().st_mtime
            entries.append((mtime, res))
            if mtime > latest_time:
                latest_time = mtime
                latest_id = res.id
        _simulations.clear()
        for _, res in sorted(entries, key=lambda t: t[0]):
            _simulations[res.id] = res
        while len(_simulations) > _max_results:
            old_id, _ = _simulations.popitem(last=False)
            with contextlib.suppress(FileNotFoundError):
                (_results_dir / f""{old_id}.json"").unlink()
        global _latest_id
        _latest_id = latest_id
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/api_server.py,
survived,"    async def get_results(sim_id: str, _: None = Depends(verify_token)) -> ResultsResponse:
        result = _simulations.get(sim_id)
        if result is None:
            raise HTTPException(status_code=404)
        return result
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/api_server.py,
survived,"    async def status(_: None = Depends(verify_token)) -> StatusResponse:
        orch = getattr(app_f.state, ""orchestrator"", None)
        agents: dict[str, StatusAgent] = {}
        if orch is not None:
            agents = {name: StatusAgent(last_beat=r.last_beat, restarts=r.restarts) for name, r in orch.runners.items()}
        return StatusResponse(agents=agents)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/api_server.py,
survived,"        def eval_fn(genome: list[float]) -> tuple[float, float, float]:
            x, y = genome
            return x**2, y**2, (x + y) ** 2
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/api_server.py,
survived,"    def getExpressionIds(self):
        exprs = list(map(str, self.importer.flux_ids))
        exprs += [str(k) for k in self.importer.symbols.get(SymbolId.EXPRESSION, {}).keys()]
        return exprs
",tests/testSBMLSuiteJax.py,DummyModel
survived,"    def __len__(self):
        return len(self.Items)
",tests/machine/x/python/group_by_multi_join.py,_Group
survived,"def apply_diff(diff_text: str, repo_dir: str) -> tuple[bool, str]:
    """"""Apply the unified diff to repo_dir. Returns (success, output).""""""
    try:
        process = subprocess.run([""patch"", ""-p1""], input=diff_text, text=True, cwd=repo_dir, timeout=60, capture_output=True)
        output = (process.stdout or """") + (process.stderr or """")
        if process.returncode != 0:
            logger.error(""Patch command failed with code %s: %s"", process.returncode, output)
            return False, output
        return True, output
    except Exception as e:
        logger.exception(""Exception while applying patch: %s"", e)
        return False, str(e)",alpha_factory_v1/demos/self_healing_repo/agent_core/diff_utils.py,
survived,"def test_moe_linear_out_first_property():
    E, In, Out = hax.make_axes(E=2, In=4, Out=3)
    moe = MoELinear.init(E, In, Out, key=jrandom.PRNGKey(0), out_first=True)
    assert moe.out_first
    assert moe.weight.axes[:3] == (E, Out, In)

    moe2 = MoELinear.init(E, In, Out, key=jrandom.PRNGKey(1), out_first=False)
    assert not moe2.out_first
    assert moe2.weight.axes[:3] == (E, In, Out)
",tests/test_moe_linear.py,
survived,"    def _run_search_helper(episodes: int, target: int) -> str:
        """"""Execute the search loop and return a summary string.""""""
        run(episodes=episodes, target=target)
        return f""completed {episodes} episodes toward target {target}""
",alpha_factory_v1/demos/meta_agentic_tree_search_v0/openai_agents_bridge.py,
survived,"        def __init__(self, *a: object, **k: object) -> None:
            pass
",tests/test_llm_client_offline.py,DummyAgent
survived,"def run(cmd: list[str]) -> None:
    subprocess.run(cmd, check=False)
",scripts/setup_wizard.py,
survived,"    def get_agent(name: str) -> DummyAgent:
        assert name == ""dummy""
        return DummyAgent()
",tests/test_agent_manager_consumer.py,
survived,"        async def start_consumer(self) -> None:
            nonlocal started
            started = True
",tests/test_agent_manager_consumer.py,DummyBus
survived,"def agents_status() -> None:
    """"""List registered agents.""""""
    orch = orchestrator.Orchestrator()
    for agent in orch.agents:
        click.echo(agent.__class__.__name__)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/cli.py,
survived,"def _write_executable(path: Path, content: str) -> None:
    path.write_text(content)
    path.chmod(0o755)
",tests/test_finance_demo_cli.py,
survived,"    def from_response(
        self,
        response: Any,
        mode: Mode,
        validation_context: Optional[Any] = None,
        strict: Optional[bool] = None,
    ) -> Generator[BaseModel, None, None]:
        assert mode == Mode.ANTHROPIC_PARALLEL_TOOLS, (
            ""Mode must be ANTHROPIC_PARALLEL_TOOLS""
        )

        if not response or not hasattr(response, ""content""):
            return

        for content in response.content:
            if getattr(content, ""type"", None) == ""tool_use"":
                name = content.name
                arguments = content.input
                if name in self.registry:
                    json_str = json.dumps(arguments)
                    yield self.registry[name].model_validate_json(
                        json_str, context=validation_context, strict=strict
                    )
",instructor/dsl/parallel.py,AnthropicParallelBase
survived,"def compile_code(code: str, timeout: int):
    signal.alarm(timeout)
    try:
        tmp_sol = ModuleType(""tmp_sol"", """")
        exec(code, tmp_sol.__dict__)
        if ""class Solution"" in code:
            # leetcode wraps solutions in `Solution`
            # this is a hack to check if it is leetcode solution or not
            # currently livecodebench only supports LeetCode but
            # else condition allows future extensibility to other platforms
            compiled_sol = tmp_sol.Solution()
        else:
            # do nothing in the other case since function is accesible
            compiled_sol = tmp_sol

        assert compiled_sol is not None
    finally:
        signal.alarm(0)

    return compiled_sol
",scripts/utils/lcb_runner.py,
survived,"    def __getattr__(self, name):
        # Delegate other attributes to StringIO
        return getattr(self._stringio, name)
",scripts/utils/lcb_runner.py,MockStdinWithBuffer
survived,"    def sample(self, k: int, *, lam: float = 10.0, alpha0: float = 0.5) -> List[Agent]:
        agents = self.all()
        if not agents:
            return []
        weights = [1.0 / (1.0 + math.exp(-lam * (a.score - alpha0))) for a in agents]
        chosen = random.choices(agents, weights=weights, k=min(k, len(agents)))
        return chosen",src/archive.py,Archive
survived,"def explore(jobs_file: str, token_quota: int | None, time_quota: int | None) -> None:
    """"""Run self-improvement jobs under quota limits.""""""

    data = json.loads(Path(jobs_file).read_text())
    jobs = [scheduler.Job(**item) for item in data]
    sched = scheduler.SelfImprovementScheduler(jobs, tokens_quota=token_quota, time_quota=time_quota)
    asyncio.run(sched.serve())
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/cli.py,
survived,"    async def accept(self, cand: Candidate) -> None:
        self._items.append(cand)
",src/evolve.py,InMemoryArchive
survived,"def main(argv: Sequence[str] | None = None) -> None:
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument(""--max-cost"", type=float, default=1.0, help=""Cost budget"")
    parser.add_argument(
        ""--wallclock"",
        type=float,
        default=None,
        help=""Wallclock limit in seconds"",
    )
    args = parser.parse_args(argv)

    archive = InMemoryArchive()
    asyncio.run(
        evolve(
            lambda g: g,
            _dummy_evaluate,
            archive,
            max_cost=args.max_cost,
            wallclock=args.wallclock,
        )
    )
",src/evolve.py,
survived,"async def _eval(_genome):
    return 0.0, 0.05
",tests/test_evolve.py,
survived,"    def __init__(self, gid: str) -> None:
        super().__init__(gid)
        reflex_comm_map[gid] = self
",pygwalker/communications/reflex_comm.py,ReflexCommunication
survived,"    def setup(self):
        self.set(""model_version"", f'{self.__class__.__name__}-v0.0.1')
",label_studio_ml/examples/timeseries_segmenter/model.py,TimeSeriesSegmenter
survived,"def parse_feature_sections(text):
    sections = []
    parts = text.split(""##### "")
    for part in parts[1:]:
        if not part.strip():
            continue
        header, *rest = part.split(""\n"", 1)
        body = rest[0] if rest else """"
        sections.append((header.strip(), body.strip()))
    return sections
",convert_missing.py,
survived,"def route(rule: str, **options: Any) -> Callable[[Handler], Handler]:
    """"""Typed wrapper around :meth:`Flask.route`.""""""
    return cast(Callable[[Handler], Handler], app.route(rule, **options))
",alpha_factory_v1/ui/app.py,
survived,"def test_reference_logs_exist():
    for name in (
        ""positions_step0.txt"",
        ""velocities_step0.txt"",
        ""density_step0.txt"",
        ""pressure_step0.txt"",
    ):
        assert os.path.exists(os.path.join(DATA_DIR, name))
",tests/test_solver_logs.py,
survived,"    def purge_old(self) -> None:
        """"""Remove records older than ``retention_days``.""""""
        if self.retention_days <= 0:
            return
        cutoff = datetime.utcnow() - timedelta(days=self.retention_days)
        cur = self.conn.cursor()
        cur.execute(""DELETE FROM telemetry WHERE timestamp < ?"", (cutoff.isoformat(),))
        self.conn.commit()
",src/meta_agent/telemetry_db.py,TelemetryDB
survived,"    async def run(self, *_args, **_kwargs):
        return {""status"": ""success""}
",src/agents/__init__.py,Agent
survived,"def test_record_and_fetch(tmp_path):
    db_path = tmp_path / ""tele.db""
    db = TelemetryDB(db_path, retention_days=1)
    db.record(10, 0.1, 0.5, 0)
    rows = db.fetch_all()
    assert len(rows) == 1
    assert rows[0][""tokens""] == 10
    assert db.verify()
    db.close()
",tests/unit/test_telemetry_db.py,
survived,"def test_cli_export_csv(runner, tmp_path):
    db_path = tmp_path / ""tele.db""
    db = TelemetryDB(db_path)
    db.record(5, 0.1, 0.2, 1)
    db.close()
    out = tmp_path / ""export.csv""
    result = runner.invoke(
        cli,
        [
            ""export"",
            ""--db-path"",
            str(db_path),
            ""--output"",
            str(out),
            ""--format"",
            ""csv"",
            ""--metric"",
            ""tokens"",
        ],
    )
    assert result.exit_code == 0
    assert out.exists()",tests/test_cli.py,
survived,"    def fake_download(url: str, dest: Path) -> None:
        calls.append((url, dest))
        dest.write_text(""stub"")
",tests/test_download_openai_gpt2.py,
survived,"def test_no_placeholder() -> None:
    files = asset_files()
    assert files, ""no wasm assets found""
    for path in files:
        data = path.read_bytes()
        assert b""placeholder"" not in data.lower(), f""placeholder found in {path}""",tests/test_integrity.py,
survived,"    def main(cfg: TextLogitsConfig) -> None:  # pragma: no cover - CLI entrypoint
        compute_logits(cfg)
",marin/generation/logits.py,
survived,"def boom(a, b):
    print(""boom"")
    return True
",tests/transpiler/x/py/short_circuit.py,
survived,"def add(a, b):
    return a + b
",tests/transpiler/x/py/partial_application.py,
survived,"def test_bridge_online_mode(monkeypatch) -> None:
    pytest.importorskip(""openai_agents"")
    monkeypatch.setenv(""OPENAI_API_KEY"", ""dummy"")
    result = subprocess.run(
        [
            sys.executable,
            ""-m"",
            ""alpha_factory_v1.demos.meta_agentic_tree_search_v0.openai_agents_bridge"",
            ""--episodes"",
            ""1"",
            ""--rewriter"",
            ""openai"",
        ],
        capture_output=True,
        text=True,
    )
    assert result.returncode == 0, result.stderr
    assert ""Best agents"" in result.stdout
",tests/test_meta_agentic_tree_search_demo.py,
survived,"    def test_summary_auth_error(self) -> None:
        import openai

        with patch.dict(os.environ, {""OPENAI_API_KEY"": ""sk-test""}):
            with patch(""openai.OpenAI"") as mock_client:
                mock_client.return_value.chat.completions.create.side_effect = openai.AuthenticationError(""bad key"")
                text = summarise_with_agent(
                    0.5,
                    agents=2,
                    rounds=10,
                    delta=0.9,
                    stake=1.0,
                )
        self.assertIn(""OPENAI_API_KEY not set"", text)
        self.assertIn(""offline summary"", text)
",tests/test_governance_sim.py,TestGovernanceSim
survived,"    def rebuild(self) -> None:
        """"""Rebuild the index from all registered templates.""""""
        self._index = []
        for entry in self.registry.list_templates():
            slug = entry[""slug""]
            for version_info in entry.get(""versions"", []):
                version = version_info[""version""]
                path = self.registry.templates_dir / version_info[""path""]
                metadata_path = path.parent / METADATA_FILE_NAME
                try:
                    content = path.read_text(encoding=""utf-8"")
                except OSError:  # pragma: no cover - file missing
                    continue
                checksum = sha256(content.encode(""utf-8"")).hexdigest()
                try:
                    with open(metadata_path, ""r"", encoding=""utf-8"") as f:
                        metadata = json.load(f)
                except (OSError, json.JSONDecodeError):
                    metadata = {}
                self._index.append(
                    {
                        ""slug"": slug,
                        ""version"": version,
                        ""path"": str(path.relative_to(self.registry.templates_dir)),
                        ""checksum"": checksum,
                        ""metadata"": metadata,
                        ""content"": content,
                    }
                )
        self.save()
",src/meta_agent/template_index.py,TemplateIndex
survived,"    def rebuild(self) -> None:
        """"""Rebuild the index from all registered templates.""""""
        self._index = []
        for entry in self.registry.list_templates():
            slug = entry[""slug""]
            for version_info in entry.get(""versions"", []):
                version = version_info[""version""]
                path = self.registry.templates_dir / version_info[""path""]
                metadata_path = path.parent / METADATA_FILE_NAME
                try:
                    content = path.read_text(encoding=""utf-8"")
                except OSError:  # pragma: no cover - file missing
                    continue
                checksum = sha256(content.encode(""utf-8"")).hexdigest()
                try:
                    with open(metadata_path, ""r"", encoding=""utf-8"") as f:
                        metadata = json.load(f)
                except (OSError, json.JSONDecodeError):
                    metadata = {}
                self._index.append(
                    {
                        ""slug"": slug,
                        ""version"": version,
                        ""path"": str(path.relative_to(self.registry.templates_dir)),
                        ""checksum"": checksum,
                        ""metadata"": metadata,
                        ""content"": content,
                    }
                )
        self.save()
",src/meta_agent/template_index.py,TemplateIndex
survived,"    def __init__(self, registry: Optional[TemplateRegistry] = None) -> None:
        self.registry = registry or TemplateRegistry()
        self.index_path = self.registry.templates_dir / self.INDEX_FILE_NAME
        self._index: List[Dict[str, Any]] = []
",src/meta_agent/template_index.py,TemplateIndex
survived,"    def load(self) -> None:
        if self.index_path.exists():
            try:
                with open(self.index_path, ""r"", encoding=""utf-8"") as f:
                    self._index = json.load(f)
            except (OSError, json.JSONDecodeError):  # pragma: no cover - corrupt file
                self._index = []
        else:
            self._index = []
",src/meta_agent/template_index.py,TemplateIndex
survived,"def test_load_translations_unknown(monkeypatch):
    monkeypatch.delenv('DEVICONS_LANG', raising=False)
    assert devicons.load_translations('unknown') == {}",tests/test_translations.py,
survived,"        async def _spawn():  # pragma: no cover - Rocketry callback
            await self._spawn_jobs()
",src/scheduler/__init__.py,SelfImprovementScheduler
survived,"        def add(self, instr: object) -> ""DummyTx"":
            self.instructions.append(instr)
            return self
",tests/test_archive.py,DummyTx
survived,"        def __init__(self, val: str) -> None:  # pragma: no cover - dummy
            pass
",tests/test_archive.py,DummyPk
survived,"    def _worker() -> None:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        task = loop.create_task(_call())
        try:
            result.append(loop.run_until_complete(task))
        finally:
            loop.close()
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/mutators/code_diff.py,
survived,"def _free_port() -> int:
    s = socket.socket()
    s.bind((""localhost"", 0))
    port = s.getsockname()[1]
    s.close()
    return port
",tests/test_critics.py,
survived,"    def run() -> None:
        service.score(""alpha"", ""alpha"")
",tests/test_critics.py,
survived,"def test_grpc_scoring() -> None:
    service = DualCriticService([""Rome is the capital of Italy.""])
    port = _free_port()

    async def run() -> None:
        await service.start_grpc(port)
        async with grpc.aio.insecure_channel(f""localhost:{port}"") as ch:
            stub = ch.unary_unary(""/critics.Critic/Score"")
            payload = {
                ""context"": ""Rome is the capital of Italy."",
                ""response"": ""Rome is the capital of Italy."",
            }
            reply = await stub(json.dumps(payload).encode())
            data = json.loads(reply.decode())
            assert data[""logic""] == 1.0
        await service.stop_grpc()

    asyncio.run(run())
",tests/test_critics.py,
survived,"    def search(self, query: str, k: int = 3) -> List[Tuple[str, float]]:
        results = [(d, self._score(query, d)) for d in self.docs]
        results.sort(key=lambda x: x[1], reverse=True)
        return results[:k]
",src/critics/dual_critic_service.py,VectorDB
survived,"def test_adversarial_cases_detected() -> None:
    service = DualCriticService([""The sky is blue.""])
    monkey = ChaosMonkey(service)
    fraction = monkey.detected_fraction(""The sky is blue."", ""The sky is blue."")
    assert fraction >= 0.8",tests/test_chaos_monkey.py,
survived,"def test_simulate_does_not_modify_global_cfg() -> None:
    """"""CLI options should not persist on the global config.""""""
    runner = CliRunner()
    original = cli.config.CFG.model_dump()

    with patch.object(cli, ""asyncio""), patch.object(cli.orchestrator, ""Orchestrator""):
        res = runner.invoke(
            cli.main,
            [
                ""simulate"",
                ""--horizon"",
                ""1"",
                ""--offline"",
                ""--sectors"",
                ""1"",
                ""--pop-size"",
                ""1"",
                ""--generations"",
                ""1"",
                ""--model"",
                ""other"",
                ""--temperature"",
                ""0.9"",
                ""--context-window"",
                ""1024"",
            ],
        )

    assert res.exit_code == 0
    assert cli.config.CFG.model_dump() == original",tests/test_cli.py,
survived,"    def raise_for_status(self) -> None:
        """"""Raise :class:`RuntimeError` if the status code signals an error.""""""
        if self.status_code >= 400:
            raise RuntimeError(f""HTTP {self.status_code}"")
",alpha_factory_v1/requests.py,Response
survived,"        def skipif(self, *_, **__):
            def wrapper(func):
                return func
            return wrapper
",alpha_factory_v1/tests/test_smoke.py,_DummyMark
survived,"            def add(self, instr: object) -> ""DummyTx"":
                self.instructions.append(instr)
                return self
",tests/test_insight_orchestrator_features.py,TestLedger.DummyTx
survived,"def test_get_kill_after_minutes_default(tmp_path, monkeypatch):
    monkeypatch.setenv(""DAGSTER_HOME"", str(tmp_path))
    assert get_kill_after_minutes() == 60
    monkeypatch.delenv(""DAGSTER_HOME"")",tests/test_timeout_sensor.py,
survived,"def test_generate_state_same_key():
    st.session_state.clear()
    s1 = _generate_state(key=""a"")
    s2 = _generate_state(key=""a"")
    assert s1 == s2
",tests/test_internal.py,
survived,"        def observe(self, *_a: Any) -> None:
            ...
",alpha_factory_v1/core/utils/tracing.py,_N
survived,"def free_energy(sector: Sector, capability: float) -> float:
    return sector.energy - capability * sector.entropy
",alpha_factory_v1/core/simulation/forecast.py,
survived,"    def _init_agents(self) -> List[BaseAgent]:
        agents: List[BaseAgent] = []
        for island, backend in self.settings.island_backends.items():
            agents.extend(
                [
                    planning_agent.PlanningAgent(self.bus, self.ledger, backend=backend, island=island),
                    research_agent.ResearchAgent(self.bus, self.ledger, backend=backend, island=island),
                    adk_summariser_agent.ADKSummariserAgent(self.bus, self.ledger, backend=backend, island=island),
                    strategy_agent.StrategyAgent(self.bus, self.ledger, backend=backend, island=island),
                    market_agent.MarketAgent(self.bus, self.ledger, backend=backend, island=island),
                    codegen_agent.CodeGenAgent(self.bus, self.ledger, backend=backend, island=island),
                    safety_agent.SafetyGuardianAgent(self.bus, self.ledger, backend=backend, island=island),
                    memory_agent.MemoryAgent(
                        self.bus,
                        self.ledger,
                        self.settings.memory_path,
                        backend=backend,
                        island=island,
                    ),
                ]
            )
        if os.getenv(""AGI_SELF_IMPROVE"") == ""1"":
            patch = os.getenv(""AGI_SELF_IMPROVE_PATCH"")
            repo = os.getenv(""AGI_SELF_IMPROVE_REPO"", str(Path.cwd()))
            allow = [p.strip() for p in os.getenv(""AGI_SELF_IMPROVE_ALLOW"", ""**"").split("","") if p.strip()]
            if patch:
                agents.append(
                    SelfImproverAgent(
                        self.bus,
                        self.ledger,
                        repo,
                        patch,
                        allowed=allow or [""**""],
                    )
                )
        return agents
",alpha_factory_v1/core/orchestrator.py,Orchestrator
survived,"def load_sectors(path: str | os.PathLike[str], *, energy: float = 1.0, entropy: float = 1.0) -> list[Sector]:
    """"""Load sector definitions from a JSON file.

    The file may contain a list of strings representing sector names or a list
    of objects with ``name`` and optional ``energy``, ``entropy`` and ``growth``
    fields. The ``energy`` and ``entropy`` arguments provide defaults when these
    values are omitted.
    """"""
    with open(path, ""r"", encoding=""utf-8"") as f:
        data = json.load(f)

    sectors: list[Sector] = []
    for entry in data:
        if isinstance(entry, str):
            sectors.append(Sector(entry, energy, entropy))
        elif isinstance(entry, dict):
            sectors.append(
                Sector(
                    entry.get(""name"", """"),
                    float(entry.get(""energy"", energy)),
                    float(entry.get(""entropy"", entropy)),
                    float(entry.get(""growth"", 0.05)),
                    bool(entry.get(""disrupted"", False)),
                )
            )
        else:
            raise ValueError(f""Invalid sector entry: {entry!r}"")
    return sectors",alpha_factory_v1/core/simulation/sector.py,
survived,"def improve_repo(
    repo_url: str,
    patch_file: str,
    metric_file: str,
    log_file: str,
    cleanup: bool = True,
) -> Tuple[float, Path]:
    """"""Clone ``repo_url``, apply ``patch_file`` and log score delta.

    Parameters
    ----------
    repo_url:
        Repository to clone.
    patch_file:
        Unified diff to apply.
    metric_file:
        File containing the numeric metric used for scoring.
    log_file:
        JSON file updated with the score delta.
    cleanup:
        When ``True`` the temporary clone is removed before returning.

    Returns
    -------
    tuple[float, Path]
        Score delta and path to the cloned repository (if ``cleanup`` is
        ``False``).
    """"""
    if git is None:
        raise RuntimeError(""GitPython is required"")
    repo_dir = Path(tempfile.mkdtemp(prefix=""selfimprover-""))
    repo = git.Repo.clone_from(repo_url, repo_dir)
    baseline = _evaluate(repo_dir, metric_file)

    diff = Path(patch_file).read_text()
    if not is_patch_valid(diff):
        raise ValueError(""Invalid or unsafe patch"")

    repo.git.apply(patch_file)
    repo.index.add([metric_file])
    repo.index.commit(""apply patch"")
    # run basic checks before scoring
    run_preflight(repo_dir)
    new_score = _evaluate(repo_dir, metric_file)
    delta = new_score - baseline
    _log_delta(delta, Path(log_file))
    if cleanup:
        shutil.rmtree(repo_dir, ignore_errors=True)
    return delta, repo_dir",alpha_factory_v1/core/self_evolution/self_improver.py,
survived,"    def update(self, cost: float, gain: float) -> bool:
        """"""Update stats and return ``True`` if training should stop.""""""
        self.cost += cost
        if gain > 0:
            self.gain += gain
            self.success += 1
            metrics.dgm_fitness_gain_total.inc(gain)
        else:
            self.fail += 1
        metrics.dgm_gpu_hours_total.inc(cost / 3600)
        if self.gain > 0:
            metrics.dgm_gpu_hours_per_gain.set(self.cost / 3600 / self.gain)
            metrics.dgm_gpu_seconds_per_gain.set(self.cost / self.gain)
        prob = random.betavariate(self.success, self.fail)
        expected_gain = self.gain + prob
        ratio = self.cost / expected_gain if expected_gain else float(""inf"")
        return ratio > self.threshold
",alpha_factory_v1/core/simulation/loop.py,BanditEarlyStopper
survived,"def thermodynamic_trigger(sector: Sector, capability: float) -> bool:
    return free_energy(sector, capability) < 0
",alpha_factory_v1/core/simulation/forecast.py,
survived,"def _reset() -> None:
    hc._last_seen.clear()
",tests/test_habit_consistency_reward.py,
survived,"def _reset_ledger() -> None:
    eb._ledger.clear()
",tests/test_energy_balance_reward.py,
survived,"def test_non_dict_returns_zero() -> None:
    assert er.reward(None, None, 123) == 0.0",tests/test_efficiency_reward.py,
survived,"def test_terraform_validate() -> None:
    env = os.environ.copy()
    subprocess.run(
        [""terraform"", ""init"", ""-backend=false"", ""-input=false""],
        cwd=TERRAFORM_DIR,
        check=True,
        env=env,
    )
    subprocess.run(
        [""terraform"", ""validate"", ""-no-color""],
        cwd=TERRAFORM_DIR,
        check=True,
        env=env,
    )",tests/test_terraform.py,
survived,"    def close(self) -> None:  # pragma: no cover - dummy
        pass
",tests/test_safety_guardian_property.py,DummyLedger
survived,"def add(a: int, b: int) -> int:
    """"""Return the sum of a and b, intentionally broken.""""""
    return a - b",alpha_factory_v1/demos/self_healing_repo/sample_broken_calc/calc.py,
survived,"def main() -> None:  # pragma: no cover - entry point
    """"""Launch the minimal dashboard or print results.""""""
    if st is None:
        print(""Streamlit not installed"")
        traj = _simulate(5, ""logistic"", 6, 3)
        for record in _disruption_df(traj).to_dict(orient=""records""):
            print(f""{record['sector']}: year {record['year']}"")
        return

    st.title(""Disruption Forecast"")
    horizon = st.sidebar.slider(""Horizon"", 1, 20, 5)
    curve = st.sidebar.selectbox(""Curve"", [""logistic"", ""linear"", ""exponential""], index=0)
    pop_size = st.sidebar.slider(""Population size"", 2, 20, 6)
    generations = st.sidebar.slider(""Generations"", 1, 20, 3)

    if st.sidebar.button(""Run""):
        traj = _simulate(horizon, curve, pop_size, generations)
        df = _timeline_df(traj)
        pivot = df.pivot(index=""year"", columns=""sector"", values=""energy"")
        st.line_chart(pivot)
        st.table(_disruption_df(traj))
",src/interface/minimal_ui.py,
survived,"    def _fake_run(*_a, **_k):
        return subprocess.CompletedProcess([], 0, """", """")
",tests/test_check_env_network.py,
survived,"def test_get_explorer_hostname_env(monkeypatch):
    monkeypatch.setenv('MYHOST', 'example.com')
    cfg = {'explorer_hostname_env_var': 'MYHOST'}
    assert get_explorer_hostname(cfg) == 'example.com'
",tests/test_explorer_utils.py,
survived,"def test_format_str_call(state: State):
    s_in = """"""'{}'.format(str(var))""""""
    s_expected = """"""f'{var!s}'""""""

    s_out, count = code_editor.fstringify_code_by_line(s_in, state)
    assert s_out == s_expected
",test/test_edits.py,
survived,"def test_format_repr_call(state: State):
    s_in = """"""'{}'.format(repr(var))""""""
    s_expected = """"""f'{var!r}'""""""

    s_out, count = code_editor.fstringify_code_by_line(s_in, state)
    assert s_out == s_expected
",test/test_edits.py,
survived,"    async def step(self) -> None:  # noqa: D401
        """"""Delegate step execution to :meth:`run_cycle`.""""""
        await self.run_cycle()
",alpha_factory_v1/backend/agents/retail_demand_agent.py,RetailDemandAgent
survived,"    async def run_cycle(self) -> None:
        pass
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/memory_agent.py,MemoryAgent
survived,"    def __init__(self, bus, ledger) -> None:
        super().__init__(""codegen"", bus, ledger)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/codegen_agent.py,CodeGenAgent
survived,"    async def run_cycle(self) -> None:
        pass
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/safety_agent.py,SafetyGuardianAgent
survived,"    def __init__(self, bus, ledger) -> None:
        super().__init__(""strategy"", bus, ledger)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/strategy_agent.py,StrategyAgent
survived,"    async def run_cycle(self) -> None:
        await self.emit(""research"", {""plan"": ""collect data""})
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/planning_agent.py,PlanningAgent
survived,"def nsga2_step(pop: Population, fn: Callable[[List[float]], Tuple[float, float]], mu: int = 20) -> Population:
    evaluate(pop, fn)
    offspring: Population = []
    while len(offspring) < mu:
        a, b = random.sample(pop, 2)
        cut = random.randint(1, len(a.genome) - 1)
        child_genome = a.genome[:cut] + b.genome[cut:]
        if random.random() < 0.1:
            idx = random.randrange(len(child_genome))
            child_genome[idx] += random.uniform(-1, 1)
        offspring.append(Individual(child_genome))
    evaluate(offspring, fn)
    union = pop + offspring
    fronts = _non_dominated_sort(union)
    new_pop: Population = []
    for front in fronts:
        _crowding(front)
        front.sort(key=lambda x: (-x.rank, -x.crowd))
        for ind in front:
            if len(new_pop) < mu:
                new_pop.append(ind)
    return new_pop",alpha_factory_v1/demos/alpha_agi_insight_v1/src/simulation/mats.py,
survived,"    def __init__(self, settings: config.Settings | None = None) -> None:
        self.settings = settings or config.Settings()
        logging.setup()
        self.bus = messaging.A2ABus(self.settings)
        self.ledger = Ledger(self.settings.ledger_path)
        self.agents = self._init_agents()
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/orchestrator.py,Orchestrator
survived,"    def __init__(self, bus, ledger) -> None:
        super().__init__(""market"", bus, ledger)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/market_agent.py,MarketAgent
survived,"    async def handle(self, env):
        pass",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/codegen_agent.py,CodeGenAgent
survived,"def test_jax_llh(benchmark_problem):
    jax.config.update(""jax_enable_x64"", True)
    from beartype import beartype

    problem_id, flat_petab_problem, petab_problem, amici_model = (
        benchmark_problem
    )

    amici_solver = amici_model.getSolver()
    cur_settings = settings[problem_id]
    amici_solver.setAbsoluteTolerance(1e-8)
    amici_solver.setRelativeTolerance(1e-8)
    amici_solver.setMaxSteps(10_000)

    simulate_amici = partial(
        simulate_petab,
        petab_problem=flat_petab_problem,
        amici_model=amici_model,
        solver=amici_solver,
        scaled_parameters=True,
        scaled_gradients=True,
        log_level=logging.DEBUG,
    )

    np.random.seed(cur_settings.rng_seed)

    problem_parameters = None
    if problem_id in problems_for_gradient_check:
        point = flat_petab_problem.x_nominal_free_scaled
        for _ in range(20):
            amici_solver.setSensitivityMethod(amici.SensitivityMethod.adjoint)
            amici_solver.setSensitivityOrder(amici.SensitivityOrder.first)
            amici_model.setSteadyStateSensitivityMode(
                cur_settings.ss_sensitivity_mode
            )
            point_noise = (
                np.random.randn(len(point)) * cur_settings.noise_level
            )
            point += point_noise  # avoid small gradients at nominal value

            problem_parameters = dict(
                zip(flat_petab_problem.x_free_ids, point)
            )

            r_amici = simulate_amici(
                problem_parameters=problem_parameters,
            )
            if np.isfinite(r_amici[LLH]):
                break
        else:
            raise RuntimeError(""Could not compute expected derivative."")
    else:
        r_amici = simulate_amici()
    llh_amici = r_amici[LLH]

    jax_model = import_petab_problem(
        petab_problem,
        model_output_dir=benchmark_outdir / (problem_id + ""_jax""),
        jax=True,
    )
    jax_problem = JAXProblem(jax_model, petab_problem)
    if problem_parameters:
        jax_problem = eqx.tree_at(
            lambda x: x.parameters,
            jax_problem,
            jnp.array(
                [problem_parameters[pid] for pid in jax_problem.parameter_ids]
            ),
        )

    if problem_id in problems_for_gradient_check:
        beartype(run_simulations)(jax_problem)
        (llh_jax, _), sllh_jax = eqx.filter_value_and_grad(
            run_simulations, has_aux=True
        )(jax_problem)
    else:
        llh_jax, _ = beartype(run_simulations)(jax_problem)

    np.testing.assert_allclose(
        llh_jax,
        llh_amici,
        rtol=1e-3,
        atol=1e-3,
        err_msg=f""LLH mismatch for {problem_id}"",
    )

    if problem_id in problems_for_gradient_check:
        sllh_amici = r_amici[SLLH]
        np.testing.assert_allclose(
            sllh_jax.parameters,
            np.array([sllh_amici[pid] for pid in jax_problem.parameter_ids]),
            rtol=1e-2,
            atol=1e-2,
            err_msg=f""SLLH mismatch for {problem_id}, {dict(zip(jax_problem.parameter_ids, sllh_jax.parameters))}"",
        )",tests/benchmark-models/test_petab_benchmark_jax.py,
survived,"    def __init__(self) -> None:
        self._clients: List[GeminiClientWrapper] = []
        self._id_map: Dict[str, GeminiClientWrapper] = {}
        self._round_robin = deque()

        for c in g_config.gemini.clients:
            client = GeminiClientWrapper(
                client_id=c.id,
                secure_1psid=c.secure_1psid,
                secure_1psidts=c.secure_1psidts,
            )
            self._clients.append(client)
            self._id_map[c.id] = client
            self._round_robin.append(client)
",app/services/pool.py,GeminiClientPool
survived,"    def is_player_stuck(self):
        """"""
        Detect if the player is stuck (not moving).
        If stuck for more than WATCH_DOG_TIMEOUT seconds, performs a random action.
        """"""
        dx = abs(self.loc_player_global[0] - self.loc_watch_dog[0])
        dy = abs(self.loc_player_global[1] - self.loc_watch_dog[1])

        current_time = time.time()
        if dx + dy > self.cfg.watch_dog_range:
            # Player moved, reset watchdog timer
            self.loc_watch_dog = self.loc_player_global
            self.t_watch_dog = current_time
            return False

        dt = current_time - self.t_watch_dog
        if dt > self.cfg.watch_dog_timeout:
            # watch dog idle for too long, player stuck
            self.loc_watch_dog = self.loc_player_global
            self.t_watch_dog = current_time
            logger.warning(f""[is_player_stuck] Player stuck for {dt} seconds."")
            return True
        return False
",src/legacy/mapleStoryAutoLevelUp_legacy.py,MapleStoryBot
survived,"    def start_capture(self):
        '''
        é–‹å§‹èž¢å¹•æ“·å–ï¼Œä¸¦ä¸æ–·æ›´æ–° frameã€‚
        '''
        while not self.is_terminated:
            # Update self.region
            self.update_window_region()

            # Update self.frame
            self.capture_frame()

            # Limit FPS to save systme resources
            self.limit_fps()
",src/input/GameWindowCapturorForMac.py,GameWindowCapturor
survived,"    def get_frame(self):
        '''
        å®‰å…¨åœ°ç²å–æœ€æ–°çš„èž¢å¹•ç•«é¢
        '''
        with self.lock:
            if self.frame is None:
                return None
            # cv2.imwrite(""debug_frame.png"", self.frame)
            return cv2.cvtColor(self.frame, cv2.COLOR_BGRA2BGR)
",src/input/GameWindowCapturorForMac.py,GameWindowCapturor
survived,"    def on_closed(self):
        '''
        æ•æ‰çµæŸå¾Œçš„å›žèª¿
        '''
        logger.warning(""Capture session closed."")
        cv2.destroyAllWindows()
",src/input/GameWindowCapturorForMac.py,GameWindowCapturor
survived,"    def get_player_location(self):
        '''
        get player location by detecting player's nametag
        '''
        img_roi = self.img_frame_gray[self.cfg.camera_ceiling:self.cfg.camera_floor, :]

        # Pad search region to avoid edge cut-off issue (full template size)
        (pad_y, pad_x) = self.img_nametag.shape[:2]
        img_roi_padded = cv2.copyMakeBorder(
            img_roi,
            pad_y, pad_y, pad_x, pad_x,
            borderType=cv2.BORDER_REPLICATE  # replicate border for safe matching
        )

        # Adjust previous location
        if self.is_first_frame:
            last_result = None
        else:
            last_result = (
                self.loc_nametag[0] + pad_x,
                self.loc_nametag[1] - self.cfg.camera_ceiling + pad_y
            )

        # Split nametag into left and right half, detect seperately and pick highest socre
        # This localization method is more robust for occluded nametag
        h, w = self.img_nametag_gray.shape
        mask_full = get_mask(self.img_nametag, (0, 255, 0))
        nametag_variants = {
            ""left"": {
                ""img_pattern"": self.img_nametag_gray[:, :w // 2],
                ""mask"": mask_full[:, :w // 2],
                ""last_result"": last_result,
                ""score_penalty"": 0.0
            },
            ""right"": {
                ""img_pattern"": self.img_nametag_gray[:, w // 2:],
                ""mask"": mask_full[:, w // 2:],
                ""last_result"": (last_result[0] + w // 2, last_result[1]) if last_result else None,
                ""score_penalty"": 0.0
            }
        }

        # Match template for each split nametag
        matches = []
        for tag_type, data in nametag_variants.items():
            loc, score, is_cached = find_pattern_sqdiff(
                img_roi_padded,
                data[""img_pattern""],
                last_result=data[""last_result""],
                mask=data[""mask""],
                global_threshold=0.3
            )
            w_match = data[""img_pattern""].shape[1]
            h_match = data[""img_pattern""].shape[0]
            score += data[""score_penalty""]
            matches.append((tag_type, loc, score, w_match, h_match, is_cached))

        # Choose the best match
        matches.sort(key=lambda x: (not x[5], x[2]))
        tag_type, loc_nametag, score, w_match, h_match, is_cached = matches[0]
        if tag_type == ""right"":
            loc_nametag = (loc_nametag[0] - w_match, loc_nametag[1])

        # Convert back to original (unpadded) coordinates
        loc_nametag = (
            loc_nametag[0] - pad_x,
            loc_nametag[1] - pad_y + self.cfg.camera_ceiling
        )

        # Update name tag location if confidence is good
        if score < self.cfg.nametag_diff_thres:
            self.loc_nametag = loc_nametag
        loc_player = (
            self.loc_nametag[0] - self.cfg.nametag_offset[0],
            self.loc_nametag[1] - self.cfg.nametag_offset[1]
        )

        # Draw name tag detection box for debug
        draw_rectangle(
            self.img_frame_debug, self.loc_nametag, self.img_nametag.shape,
            (0, 255, 0), """")
        text = f""NameTag,{round(score, 2)},"" + \
                f""{'cached' if is_cached else 'missed'},"" + \
                f""{tag_type}""
        cv2.putText(self.img_frame_debug, text,
                    (self.loc_nametag[0], self.loc_nametag[1] + self.img_nametag.shape[0] + 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

        # Draw player center
        cv2.circle(self.img_frame_debug,
                loc_player, radius=3,
                color=(0, 0, 255), thickness=-1)

        return loc_player
",src/legacy/mapleStoryAutoLevelUp_legacy.py,MapleStoryBot
survived,"def test_new_async_manager_includes_tags() -> None:
    config = {""callbacks"": None}
    manager = get_async_callback_manager_for_config(config, tags=[""x"", ""y""])
    assert isinstance(manager, AsyncCallbackManager)
    assert manager.inheritable_tags == [""x"", ""y""]
",libs/langgraph/tests/test_config_async.py,
survived,"def _demo_url(demo: str) -> str:
    env = os.environ.get(""AF_GALLERY_URL"")
    if env:
        return f""{env.rstrip('/')}/alpha_factory_v1/demos/{demo}/index.html""
    remote = subprocess.check_output([""git"", ""config"", ""--get"", ""remote.origin.url""], text=True).strip()
    repo_path = remote.split(""github.com"")[-1].lstrip("":/"").removesuffix("".git"")
    org, repo = repo_path.split(""/"", 1)
    return f""https://{org}.github.io/{repo}/alpha_factory_v1/demos/{demo}/index.html""
",scripts/open_subdir_demo.py,
survived,"        def __init__(self, *a, **k):
            pass
",tests/test_aiga_openai_bridge_offline.py,_DummyEvolver
survived,"        def register(self, agent: object) -> None:
            self.registered.append(agent)
",tests/test_aiga_openai_bridge_offline.py,AgentRuntime
survived,"        def __init__(self, *a, base_url: str | None = None, **_k) -> None:
            self.base_url = base_url.rstrip(""/"") if base_url else None
",tests/test_aiga_openai_bridge_offline.py,OpenAIAgent
survived,"        def latest_log(self) -> str:
            return self.llm(""hi"") if self.llm else ""done""
",tests/test_aiga_openai_bridge_offline.py,DummyEvolver
survived,"    def fake_import(name, globals=None, locals=None, fromlist=(), level=0):
        if name == ""openai_agents"":
            raise ModuleNotFoundError(name)
        return orig_import(name, globals, locals, fromlist, level)
",tests/test_patcher_core_cli_offline.py,
survived,"    def replace_str_task(self, *, path: str, old: str, new: str) -> dict[str, int]:
        return {""count"": replace_str(path, old, new)}
",src/self_edit/tools.py,FileToolsADK
survived,"    def add_tarball(self, tarball: str | Path) -> str:
        path = Path(tarball)
        cid = self._ipfs_add(path)
        with sqlite3.connect(self.db_path) as cx:
            cx.execute(
                ""INSERT INTO tarballs(path, cid, pinned, ts) VALUES(?,?,?,?)"",
                (str(path), cid, 1, time.time()),
            )
        return cid
",src/archive/hash_archive.py,HashArchive
survived,"    def __init__(self, db_path: str | Path) -> None:
        self.db_path = Path(db_path)
        _ensure_db(self.db_path)
",src/archive/hash_archive.py,HashArchive
survived,"def test_snark_roundtrip(tmp_path: Path) -> None:
    transcript = tmp_path / ""eval.json""
    entry = {""hash"": ""a1b2"", ""score"": [0.5, 1.2]}
    transcript.write_text(json.dumps([entry]), encoding=""utf-8"")

    db = ArchiveDB(tmp_path / ""arch.db"")
    db.add(ArchiveEntry(""a1b2"", None, 0.5, 0.0, True, 1.0))

    cid = publish_proof(transcript, entry[""hash""], entry[""score""], db)
    assert db.get_proof_cid(entry[""hash""]) == cid

    proof = transcript.with_suffix("".proof"").read_text()
    assert verify_proof(transcript, entry[""hash""], entry[""score""], proof)

    expected_cid = hashlib.sha256(proof.encode()).hexdigest()
    assert cid == expected_cid",tests/test_snark.py,
survived,"def test_js_serializer_malformed_json(tmp_path: Path) -> None:
    script = tmp_path / ""run.mjs""
    script.write_text(
        f""import {{load}} from '{SERIALIZER.resolve().as_posix()}';\n""
        ""try {\n""
        ""  load(process.argv[2]);\n""
        ""} catch (err) {\n""
        ""  console.error(err.message);\n""
        ""  process.exit(1);\n""
        ""}\n""
    )
    result = subprocess.run([""node"", script, ""{invalid""], capture_output=True, text=True)
    assert result.returncode == 1",tests/test_serializer.py,
survived,"def _create_html_repo(tmpdir: Path, content: str) -> Path:
    docs = tmpdir / ""docs""
    docs.mkdir()
    (docs / ""DISCLAIMER_SNIPPET.md"").write_text(SNIPPET_TEXT)
    (tmpdir / ""index.html"").write_text(content)
    return tmpdir
",tests/test_verify_disclaimer_snippet.py,
survived,"    def count_links_in_html(html_path: Path) -> int:
        content = html_path.read_text(encoding=""utf-8"", errors=""ignore"")
        return content.count(""See docs/DISCLAIMER_SNIPPET.md"")
",scripts/verify_disclaimer_snippet.py,
survived,"    def search(
        self,
        query: str,
        *,
        category: str | None = None,
        tags: Optional[List[str]] = None,
        limit: int = 5,
    ) -> List[Dict[str, Any]]:
        """"""Search the index using a simple token overlap ranking.""""""
        if not self._index:
            self.ensure_up_to_date()
        tokens = [t.lower() for t in query.split() if t]
        results = []
        for item in self._index:
            meta = item.get(""metadata"", {})
            if category and meta.get(""category"") != category:
                continue
            if tags and not all(t in meta.get(""tags"", []) for t in tags):
                continue
            haystack = "" "".join(
                [
                    item.get(""content"", """"),
                    meta.get(""title"", """"),
                    meta.get(""description"", """"),
                    meta.get(""slug"", """"),
                    "" "".join(meta.get(""tags"", [])),
                ]
            ).lower()
            score = sum(1 for tok in tokens if tok in haystack)
            if score:
                results.append({**item, ""score"": float(score)})
        results.sort(key=lambda r: r[""score""], reverse=True)
        return results[:limit]",src/meta_agent/template_index.py,TemplateIndex
survived,"    def save(self) -> None:
        with open(self.index_path, ""w"", encoding=""utf-8"") as f:
            json.dump(self._index, f, indent=2)
",src/meta_agent/template_index.py,TemplateIndex
survived,"    def load(self) -> None:
        if self.index_path.exists():
            try:
                with open(self.index_path, ""r"", encoding=""utf-8"") as f:
                    self._index = json.load(f)
            except (OSError, json.JSONDecodeError):  # pragma: no cover - corrupt file
                self._index = []
        else:
            self._index = []
",src/meta_agent/template_index.py,TemplateIndex
survived,"def _get_llm() -> Callable[[str, Optional[str]], str]:
    """"""Return the LLM callable according to environment settings.""""""
    provider = os.getenv(""SELF_IMPROVE_PROVIDER"")
    if provider == ""local"" or LLMProvider is None:
        return lambda prompt, _sys: local_llm.chat(prompt, CFG)

    def call(prompt: str, system_prompt: Optional[str]) -> str:
        llm = LLMProvider()
        return llm.chat(prompt, system_prompt=system_prompt)

    return call
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/self_edit/prompting.py,
survived,"    def execute_and_collect(self, path: Path, timeout: int = 60) -> CollectionResult:
        """"""Run tests via the execution module and gather outputs.""""""
        start = time.perf_counter()
        result = self.execution_module.run_tests(path, timeout)
        end = time.perf_counter()
        return CollectionResult(
            exit_code=result.exit_code,
            stdout=result.stdout,
            stderr=result.stderr,
            duration=end - start,
        )",src/meta_agent/evaluation/result_collection.py,ResultCollectionModule
survived,"def test_execute_and_collect_success(monkeypatch, tmp_path):
    fake_exec = MagicMock()
    fake_exec.run_tests.return_value = ExecutionResult(0, ""out"", ""err"")
    module = ResultCollectionModule(fake_exec)
    result = module.execute_and_collect(tmp_path, timeout=5)
    assert isinstance(result, CollectionResult)
    assert result.exit_code == 0
    assert result.stdout == ""out""
    assert result.stderr == ""err""
    assert result.duration >= 0
    fake_exec.run_tests.assert_called_with(tmp_path, timeout=5)
",tests/unit/test_result_collection_module.py,
survived,"def test_execute_and_collect_success(monkeypatch, tmp_path):
    fake_exec = MagicMock()
    fake_exec.run_tests.return_value = ExecutionResult(0, ""out"", ""err"")
    module = ResultCollectionModule(fake_exec)
    result = module.execute_and_collect(tmp_path, timeout=5)
    assert isinstance(result, CollectionResult)
    assert result.exit_code == 0
    assert result.stdout == ""out""
    assert result.stderr == ""err""
    assert result.duration >= 0
    fake_exec.run_tests.assert_called_with(tmp_path, timeout=5)
",tests/unit/test_result_collection_module.py,
survived,"    def to_html(self, report: SummaryReport) -> str:
        """"""Return a simple HTML representation of the report.""""""
        return (
            ""<html><body>""
            ""<h2>Evaluation Report</h2>""
            f""<p>Status: {'PASSED' if report.passed else 'FAILED'}</p>""
            f""<p>Exit Code: {report.exit_code}</p>""
            f""<p>Duration: {report.duration:.2f}s</p>""
            f""<h3>stdout</h3><pre>{html.escape(report.stdout)}</pre>""
            f""<h3>stderr</h3><pre>{html.escape(report.stderr)}</pre>""
            ""</body></html>""
        )
",src/meta_agent/evaluation/reporting.py,ReportingModule
survived,"    def __init__(self) -> None:
        self.logger = logging.getLogger(__name__)
",src/meta_agent/evaluation/reporting.py,ReportingModule
survived,"    def _validate_inputs(
        self,
        code_directory: Path,
        command: list[str],
        mem_limit: str,
        cpu_shares: int,
    ) -> None:
        """"""Validate inputs and resource limits for sandbox execution.""""""

        if not command or any(
            not isinstance(c, str) or any(x in c for x in ["";"", ""&"", ""|"", ""`"", ""\n""])
            for c in command
        ):
            raise ValueError(""Invalid command passed to sandbox"")

        if cpu_shares <= 0 or cpu_shares > MAX_CPU_SHARES:
            raise ValueError(""cpu_shares out of allowed range"")

        if mem_limit[-1].lower() not in {""m"", ""g""} or not mem_limit[:-1].isdigit():
            raise ValueError(""mem_limit must be like '256m' or '1g'"")
",src/meta_agent/sandbox/sandbox_manager.py,SandboxManager
survived,"def test_invalid_command(monkeypatch, tmp_path):
    fake_client = MagicMock()
    fake_client.ping.return_value = None
    monkeypatch.setattr(sm.docker, ""from_env"", lambda: fake_client)
    manager = SandboxManager()
    code_dir = tmp_path / ""code""
    code_dir.mkdir()
    with pytest.raises(ValueError):
        manager.run_code_in_sandbox(code_dir, [""python; rm -rf /""])
",tests/unit/test_sandbox_manager.py,
survived,"def div(a, b):
    return a // b
",tests/rosetta/transpiler/Python/element-wise-operations.py,
survived,"def padLeft(s, w):
    res = """"
    n = w - len(s)
    while n > 0:
        res = res + "" ""
        n = n - 1
    return res + s
",tests/rosetta/transpiler/Python/element-wise-operations.py,
survived,"    async def simulate(req: SimRequest, _: None = Depends(verify_token)) -> SimStartResponse | JSONResponse:
        try:
            sim_id = secrets.token_hex(8)
            asyncio.create_task(_background_run(sim_id, req))
            return SimStartResponse(id=sim_id)
        except HTTPException as exc:
            return problem_response(exc)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/api_server.py,
survived,"        def __init__(self, app: FastAPI, limit: int = 60, window: int = 60) -> None:
            super().__init__(app)
            self.limit = int(os.getenv(""API_RATE_LIMIT"", str(limit)))
            self.window = window
            # Use TTLCache so inactive IP entries expire automatically.
            self.counters: TTLCache[str, deque[float]] = TTLCache(maxsize=1024, ttl=window)
            self.lock = asyncio.Lock()
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/api_server.py,SimpleRateLimiter
survived,"    async def policy(self, obs, ctx):  # type: ignore[override]
        domain = obs.get(""domain"", ""finance"") if isinstance(obs, dict) else ""finance""
        return await identify_alpha(domain)
",alpha_factory_v1/demos/aiga_meta_evolution/alpha_opportunity_stub.py,AlphaDiscoveryAgent
survived,"def test_broadcast_merkle_root_logs_on_error() -> None:
    with tempfile.TemporaryDirectory() as tmp:
        ledger = Ledger(os.path.join(tmp, ""l.db""), rpc_url=""http://rpc.test"", broadcast=True)
        env = messaging.Envelope(sender=""a"", recipient=""b"", payload={""v"": 1}, ts=0.0)
        ledger.log(env)
        root = ledger.compute_merkle_root()

        captured: dict[str, Any] = {}

        class DummyClient:
            def __init__(self, url: str) -> None:
                captured[""url""] = url

            async def send_transaction(self, tx: Any, *args: Any) -> None:
                captured[""root""] = tx.instructions[0].data.decode()
                raise RuntimeError(""fail"")

            async def close(self) -> None:
                pass

        class DummyTx:
            def __init__(self) -> None:
                self.instructions: list[Any] = []

            def add(self, instr: Any) -> ""DummyTx"":
                self.instructions.append(instr)
                return self

        class DummyInstr:
            def __init__(self, program_id: Any, data: bytes, keys: list[Any]):
                self.data = data

        class DummyPk:
            def __init__(self, val: str) -> None:
                pass

        with (
            mock.patch.dict(
                sys.modules,
                {
                    ""solana"": ModuleType(""solana""),
                    ""solana.rpc"": ModuleType(""solana.rpc""),
                    ""solana.rpc.async_api"": ModuleType(""solana.rpc.async_api""),
                },
            ),
            mock.patch(""solana.rpc.async_api.AsyncClient"", DummyClient, create=True),
            mock.patch.object(insight_logging, ""AsyncClient"", DummyClient, create=True),
            mock.patch.object(insight_logging, ""Transaction"", DummyTx, create=True),
            mock.patch.object(insight_logging, ""TransactionInstruction"", DummyInstr, create=True),
            mock.patch.object(insight_logging, ""PublicKey"", DummyPk, create=True),
            mock.patch.object(insight_logging, ""_log"") as log,
        ):
            asyncio.run(ledger.broadcast_merkle_root())

        assert captured[""root""] == root
        log.warning.assert_called()",tests/test_ledger_broadcast.py,
survived,"            async def send_transaction(self, tx: Any, *args: Any) -> None:
                calls.append((""sent"", tx.instructions[0].data.decode()))
",tests/test_ledger_client_close.py,DummyClient
survived,"            async def close(self) -> None:
                calls.append((""closed"", True))
",tests/test_ledger_client_close.py,DummyClient
survived,"    def _should_store(self, value: Any) -> bool:
        if self.entry_size_limit is None:
            return True
        try:
            return self._estimate_size(value) <= self.entry_size_limit
        except Exception:
            return True
",src/cachier/cores/base.py,_BaseCore
survived,"    def _verify_checksum(self, mnemonic_ids):
        from shamir_mnemonic.share import Share
        try:
            Share.from_mnemonic("" "".join(self.id_to_word(i) for i in mnemonic_ids))
            return True
        except Exception:
            return False
",btcrecover/btcrseed.py,WalletSLIP39Seed
survived,"    def mochi(self, line, cell):
        """"""Run Mochi code contained in the cell.""""""
        with tempfile.NamedTemporaryFile(""w"", suffix="".mochi"", delete=False) as f:
            f.write(cell)
            fname = f.name
        try:
            cmd = [""mochi"", ""run"", fname]
            proc = subprocess.run(cmd, capture_output=True, text=True)
            if proc.stdout:
                sys.stdout.write(proc.stdout)
            if proc.stderr:
                sys.stderr.write(proc.stderr)
            if proc.returncode != 0:
                raise RuntimeError(f""mochi exited with status {proc.returncode}"")
        finally:
            os.unlink(fname)
",tools/notebook/mochi_magic.py,MochiMagics
survived,"    def visit_Module(self, node):
        for stmt in node.body:
            self.visit(stmt)
",tools/any2mochi/py_simple.py,Conv
survived,"async def test_as_proxy_with_server(fastmcp_server):
    """"""FastMCP.as_proxy should accept a FastMCP instance.""""""
    proxy = FastMCP.as_proxy(fastmcp_server)
    result = await proxy._mcp_call_tool(""greet"", {""name"": ""Test""})
    assert isinstance(result[0], mcp.types.TextContent)
    assert result[0].text == ""Hello, Test!""
",tests/server/test_proxy.py,
survived,"async def test_crud_decorators_register_resources():
    app = EnrichMCP(""API"", description=""desc"")

    @app.entity
    class Item(EnrichModel):
        """"""Item entity.""""""

        id: int = Field(description=""id"")
        name: str = Field(description=""name"", mutable=True)

    @app.create
    async def create_item(name: str) -> Item:
        """"""Create item.""""""
        return Item(id=1, name=name)

    @app.update
    async def update_item(item_id: int, patch: Item.PatchModel) -> Item:
        """"""Update item.""""""
        return Item(id=item_id, name=patch.name or ""n"")

    @app.delete
    async def delete_item(item_id: int) -> bool:
        """"""Delete item.""""""
        return True

    assert ""create_item"" in app.resources
    assert ""update_item"" in app.resources
    assert ""delete_item"" in app.resources

    item = await create_item(name=""x"")
    assert item.name == ""x""
    item = await update_item(1, Item.PatchModel(name=""y""))
    assert item.name == ""y""
    assert await delete_item(1) is True",tests/test_mutability.py,
survived,"async def test_patch_model_generation_and_mutable_fields():
    app = EnrichMCP(""Test API"", description=""desc"")

    @app.entity
    class Customer(EnrichModel):
        """"""Customer entity.""""""

        id: int = Field(description=""id"")
        email: str = Field(description=""email"", mutable=True)
        status: str = Field(description=""status"", mutable=True)

    # mutable fields detected
    assert Customer.mutable_fields() == {""email"", ""status""}
    assert hasattr(Customer, ""PatchModel"")
    patch_fields = set(Customer.PatchModel.model_fields.keys())
    assert patch_fields == {""email"", ""status""}
",tests/test_mutability.py,
survived,"        def _is_mutable(f: Any) -> bool:
            extra = getattr(f, ""json_schema_extra"", None)
            if extra is None:
                info = getattr(f, ""field_info"", None)
                extra = getattr(info, ""extra"", {}) if info is not None else {}
            return extra.get(""mutable"") is True
",src/enrichmcp/entity.py,EnrichModel
survived,"    def load(self, project: str, note_id: str) -> MemoryNote | None:
        """"""Retrieve a note by ``note_id`` or ``None`` if it does not exist.""""""
",examples/basic_memory/memory.py,MemoryStore
survived,"    def list_notes(self, page: int = 1, page_size: int = 10) -> list[MemoryNoteSummary]:
        return self.store.list(self.name, page, page_size)
",examples/basic_memory/memory.py,MemoryProject
survived,"    def get_note(self, note_id: str) -> MemoryNote | None:
        return self.store.load(self.name, note_id)
",examples/basic_memory/memory.py,MemoryProject
survived,"        def load_censor_words(self) -> None:
            pass
",alpha_factory_v1/backend/governance.py,_StubProfanity
survived,"def test_template_validator_shell_detection() -> None:
    validator = TemplateValidator()
    result = validator.validate(""{{ os.system('ls') }}"")
    assert not result.success
    assert any(""shell command"" in e for e in result.errors)
",tests/test_template_validator.py,
survived,"def warn_missing_core() -> None:
    missing = [pkg for pkg in CORE if importlib.util.find_spec(pkg) is None]
    if missing:
        print(""WARNING: Missing core packages:"", "", "".join(missing))
",check_env.py,
survived,"def test_f1_scores_above_threshold(tmp_path) -> None:
    csv_path = tmp_path / ""metrics.csv""
    for name in sorted(EXPECTED):
        scn = replay.load_scenario(name)
        traj = replay.run_scenario(scn)
        metrics = replay.score_trajectory(name, traj, csv_path=csv_path)
        assert metrics[""f1""] > 0.6
    with open(csv_path, newline="""") as fh:
        rows = list(csv.reader(fh))
    assert rows[0] == [""scenario"", ""f1"", ""auroc"", ""lead_time""]
    assert len(rows) == len(EXPECTED) + 1",tests/test_replay_metrics.py,
survived,"    def run_hash_particles(self):
        """"""Assign a grid cell index to each particle.""""""
        pos = self.position[:, :3]
        offset = torch.tensor(
            [self.config[""xmin""], self.config[""ymin""], self.config[""zmin""]],
            device=self.device,
        )
        idx = torch.floor(
            (pos - offset) * self.config[""hash_grid_cell_size_inv""]
        ).long()
        cell_id = (
            idx[:, 0]
            + idx[:, 1] * self.config[""grid_cells_x""]
            + idx[:, 2] * self.config[""grid_cells_x""] * self.config[""grid_cells_y""]
        )
        ids = torch.arange(pos.shape[0], device=self.device)
        self.particle_index = torch.stack([cell_id, ids], dim=1)
",pytorch_solver.py,PytorchSolver
survived,"def convert_backgrounds(v1_path, out_dir, doc_slug):
    bgs = load_json(v1_path)
    out_bg = []
    out_bgb = []
    for bg in bgs:
        f = bg[""fields""]
        slug = bg[""pk""]
        pk = f""{doc_slug}_{slug}""
        out_bg.append({
            ""model"": ""api_v2.background"",
            ""pk"": pk,
            ""fields"": {""name"": f[""name""], ""desc"": f[""desc""], ""document"": doc_slug},
        })
        mapping = [
            (""skill_proficiencies"", ""Skill Proficiencies"", ""skill_proficiency""),
            (""tool_proficiencies"", ""Tool Proficiencies"", ""tool_proficiency""),
            (""languages"", ""Languages"", ""language""),
            (""equipment"", ""Equipment"", ""equipment""),
        ]
        for key, name, typ in mapping:
            val = f.get(key)
            if val:
                out_bgb.append({
                    ""model"": ""api_v2.backgroundbenefit"",
                    ""pk"": f""{pk}_{slugify(name)}"",
                    ""fields"": {""name"": name, ""desc"": val, ""type"": typ, ""parent"": pk},
                })
        if f.get(""feature"") or f.get(""feature_desc""):
            out_bgb.append({
                ""model"": ""api_v2.backgroundbenefit"",
                ""pk"": f""{pk}_{slugify(f.get('feature','feature'))}"",
                ""fields"": {""name"": f.get(""feature"", ""Feature""), ""desc"": f.get(""feature_desc"", """"), ""type"": ""feature"", ""parent"": pk},
            })
        if f.get(""suggested_characteristics""):
            out_bgb.append({
                ""model"": ""api_v2.backgroundbenefit"",
                ""pk"": f""{pk}_suggested-characteristics"",
                ""fields"": {""name"": ""Suggested Characteristics"", ""desc"": f[""suggested_characteristics""], ""type"": ""suggested_characteristics"", ""parent"": pk},
            })
    if out_bg:
        save_json(out_bg, os.path.join(out_dir, ""Background.json""))
    if out_bgb:
        save_json(out_bgb, os.path.join(out_dir, ""BackgroundBenefit.json""))
",convert_missing.py,
survived,"    async def healthz() -> str:
        """"""Simple liveness probe.""""""

        return ""ok""
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/api_server.py,
survived,"    async def healthz() -> str:
        """"""Simple liveness probe.""""""

        return ""ok""
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/api_server.py,
survived,"    def __init__(self) -> None:
        self.logged: list[messaging.Envelope] = []
",tests/test_agent_handle_methods.py,DummyLedger
survived,"def test_bundle_metadata_defaults():
    meta = BundleMetadata()
    assert meta.schema_version == BUNDLE_SCHEMA_VERSION
    assert isinstance(meta.created_at, datetime)
    assert meta.custom == {}
",tests/test_bundle_metadata.py,
survived,"def test_bus_tls_reject_bad_token(tmp_path: Path) -> None:
    """"""Invalid token causes rejection.""""""
    port = _free_port()
    cert, key, ca = _make_cert(tmp_path)
    cfg = config.Settings(bus_port=port, bus_cert=cert, bus_key=key, bus_token=""tok"")
    bus = messaging.A2ABus(cfg)

    async def run() -> None:
        await bus.start()
        try:
            creds = grpc.ssl_channel_credentials(root_certificates=ca)
            async with grpc.aio.secure_channel(f""localhost:{port}"", creds) as ch:
                stub = ch.unary_unary(""/bus.Bus/Send"")
                payload = {
                    ""sender"": ""a"",
                    ""recipient"": ""b"",
                    ""payload"": {},
                    ""ts"": 0.0,
                    ""token"": ""bad"",
                }
                with pytest.raises(grpc.aio.AioRpcError):
                    await stub(json.dumps(payload).encode())
        finally:
            await bus.stop()

    asyncio.run(run())
",tests/test_bus_tls.py,
survived,"    async def run() -> None:
        await bus.start()
        try:
            creds = grpc.ssl_channel_credentials(root_certificates=ca)
            async with grpc.aio.secure_channel(f""localhost:{port}"", creds) as ch:
                stub = ch.unary_unary(""/bus.Bus/Send"")
                payload = {
                    ""sender"": ""a"",
                    ""recipient"": ""b"",
                    ""payload"": {},
                    ""ts"": 0.0,
                    ""token"": ""bad"",
                }
                with pytest.raises(grpc.aio.AioRpcError):
                    await stub(json.dumps(payload).encode())
        finally:
            await bus.stop()
",tests/test_bus_tls.py,
survived,"    def __init__(self, bundle_dir: str | Path) -> None:
        self.bundle_dir = Path(bundle_dir)
",src/meta_agent/bundle_generator.py,BundleGenerator
survived,"def test_capability_growth_dispatch() -> None:
    """"""Capability growth should dispatch to the appropriate curve.""""""
    t = 0.3
    assert forecast.capability_growth(t, curve=""linear"") == pytest.approx(forecast.linear_curve(t))
    assert forecast.capability_growth(t, curve=""exponential"") == pytest.approx(forecast.exponential_curve(t))
    assert forecast.capability_growth(t, curve=""logistic"") == pytest.approx(forecast.logistic_curve(10 * t))
    assert forecast.capability_growth(t) == pytest.approx(forecast.logistic_curve(10 * t))",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_capability_growth.py,
survived,"def test_resolve_pins_versions():
    manager = DependencyManager()
    reqs, licenses, _ = manager.resolve([""pydantic"", ""click""])
    assert any(r.startswith(""pydantic=="") for r in reqs)
    assert any(r.startswith(""click=="") for r in reqs)
    assert licenses.get(""pydantic"") == ""MIT""
    assert ""click"" in licenses
",tests/test_dependency_manager.py,
survived,"    def test_run_demo_seed_repeat(self) -> None:
        """"""Running the demo twice with the same seed yields identical results.""""""
        cmd = [
            sys.executable,
            ""-m"",
            ""alpha_factory_v1.demos.meta_agentic_tree_search_v0.run_demo"",
            ""--episodes"",
            ""2"",
            ""--seed"",
            ""321"",
        ]

        first = subprocess.run(cmd, capture_output=True, text=True)
        second = subprocess.run(cmd, capture_output=True, text=True)

        self.assertEqual(first.returncode, 0, first.stderr)
        self.assertEqual(second.returncode, 0, second.stderr)

        first_line = [l for l in first.stderr.splitlines() if ""Best agents"" in l][-1]
        second_line = [l for l in second.stderr.splitlines() if ""Best agents"" in l][-1]

        self.assertEqual(first_line, second_line)
",tests/test_meta_agentic_tree_search_demo.py,TestMetaAgenticTreeSearchDemo
survived,"    async def test_get_run_includes_metadata(
        self,
        test_api_client: AsyncClient,
        returned_run: AgentRun,
        mock_storage: Mock,
    ):
        """"""Test that metadata is included in the get_run response""""""
        returned_run.metadata = {""environment"": ""production"", ""user_id"": ""456"", ""custom_data"": ""test_value""}

        response = await test_api_client.get(f""/v1/_/agents/test_task/runs/{returned_run.id}"")
        assert response.status_code == 200

        response_data = response.json()
        assert response_data[""id""] == returned_run.id
        assert response_data[""metadata""] == {
            ""environment"": ""production"",
            ""user_id"": ""456"",
            ""custom_data"": ""test_value"",
        }

        mock_storage.task_runs.fetch_task_run_resource.assert_called_once_with(
            (""bla"", 2),
            returned_run.id,
            exclude={""llm_completions""},
            include=None,
        )",api/api/routers/runs_v1_test.py,TestGetRunByID
survived,"    def ingest(
        self,
        new_packages: list[Package],
        new_urls: list[URL],
        new_package_urls: list[PackageURL],
        updated_packages: list[dict[str, UUID | str | datetime]],
        updated_package_urls: list[dict[str, UUID | datetime]],
        new_deps: list[LegacyDependency],
        removed_deps: list[LegacyDependency],
    ) -> None:
        """"""
        Ingest the diffs by first adding all new entities, then updating existing ones.

        Inputs:
          - All the differential changes computed by the diff module

        Outputs:
          - None
        """"""
        self.logger.log(""-"" * 100)
        self.logger.log(""Going to load pkgx data"")
        self.logger.log(f""New packages: {len(new_packages)}"")
        self.logger.log(f""New URLs: {len(new_urls)}"")
        self.logger.log(f""New package URLs: {len(new_package_urls)}"")
        self.logger.log(f""Updated packages: {len(updated_packages)}"")
        self.logger.log(f""Updated package URLs: {len(updated_package_urls)}"")
        self.logger.log(f""New dependencies: {len(new_deps)}"")
        self.logger.log(f""Removed dependencies: {len(removed_deps)}"")
        self.logger.log(""-"" * 100)

        with self.session() as session:
            try:
                # 1. Add all new objects with granular flushes
                if new_packages:
                    session.add_all(new_packages)
                    session.flush()

                if new_urls:
                    session.add_all(new_urls)
                    session.flush()

                if new_package_urls:
                    session.add_all(new_package_urls)
                    session.flush()

                # remove deps first to avoid constraint issues
                if removed_deps:
                    for dep in removed_deps:
                        session.delete(dep)
                    session.flush()

                if new_deps:
                    session.add_all(new_deps)
                    session.flush()

                # 2. Perform updates (these will now operate on a flushed state)
                if updated_packages:
                    session.execute(update(Package), updated_packages)

                if updated_package_urls:
                    session.execute(update(PackageURL), updated_package_urls)

                # 3. Commit all changes
                session.commit()
                self.logger.log(""âœ… Successfully ingested pkgx data"")

            except Exception as e:
                self.logger.error(f""Error during pkgx batched ingest: {e}"")
                session.rollback()
                raise e",package_managers/pkgx/db.py,PkgxDB
survived,"    def test_sort_by_speed_index_desc(self):
        """"""Test sorting by speed index (highest first).""""""
        models: list[ConciseModelResponse | ConciseLatestModelResponse] = [
            create_test_model(""model1"", speed_index=300),
            create_test_model(""model2"", speed_index=800),
            create_test_model(""model3"", speed_index=600),
        ]

        sorted_models = sort_models(models, ""speed_index"", ""desc"")

        assert [m.id for m in sorted_models] == [""model2"", ""model3"", ""model1""]
",api/api/routers/mcp/_utils/model_sorting_test.py,TestSortModels
survived,"    def test_perplexity_reasoning_effort_mock_completion(self, model):
        """"""
        Test that reasoning_effort is correctly passed in actual completion call (mocked)
        """"""
        from openai import OpenAI
        from openai.types.chat.chat_completion import ChatCompletion
        
        litellm.set_verbose = True
        
        # Mock successful response with reasoning content
        response_object = {
            ""id"": ""cmpl-test"",
            ""object"": ""chat.completion"",
            ""created"": 1677652288,
            ""model"": model.split(""/"")[1],
            ""choices"": [
                {
                    ""index"": 0,
                    ""message"": {
                        ""role"": ""assistant"",
                        ""content"": ""This is a test response from the reasoning model."",
                        ""reasoning_content"": ""Let me think about this step by step..."",
                    },
                    ""finish_reason"": ""stop"",
                }
            ],
            ""usage"": {
                ""prompt_tokens"": 9,
                ""completion_tokens"": 20,
                ""total_tokens"": 29,
                ""completion_tokens_details"": {
                    ""reasoning_tokens"": 15
                }
            },
        }

        pydantic_obj = ChatCompletion(**response_object)

        def _return_pydantic_obj(*args, **kwargs):
            new_response = MagicMock()
            new_response.headers = {""content-type"": ""application/json""}
            new_response.parse.return_value = pydantic_obj
            return new_response

        openai_client = OpenAI(api_key=""fake-api-key"")

        with patch.object(
            openai_client.chat.completions.with_raw_response, ""create"", side_effect=_return_pydantic_obj
        ) as mock_client:
            
            response = completion(
                model=model,
                messages=[{""role"": ""user"", ""content"": ""Hello, please think about this carefully.""}],
                reasoning_effort=""high"",
                client=openai_client,
            )
            
            # Verify the call was made
            assert mock_client.called
            
            # Get the request data from the mock call
            call_args = mock_client.call_args
            request_data = call_args.kwargs
            
            # Verify reasoning_effort was included in the request
            assert ""reasoning_effort"" in request_data
            assert request_data[""reasoning_effort""] == ""high""
            
            # Verify response structure
            assert response.choices[0].message.content is not None
            assert response.choices[0].message.content == ""This is a test response from the reasoning model.""
",tests/llm_translation/test_perplexity_reasoning.py,TestPerplexityReasoning
survived,"def test_semantic_unnest_keep_empty():
    """"""Test semantic unnest operation with keep_empty option.""""""
    df = pd.DataFrame({
        ""id"": [1, 2, 3],
        ""tags"": [[""a"", ""b""], [], [""c""]]
    })
    
    result = df.semantic.unnest(
        unnest_key=""tags"",
        keep_empty=True
    )
    
    assert isinstance(result, pd.DataFrame)
    assert len(result) == 4  # 2 + 1 (empty) + 1 tags
    
    # Check that empty list row is preserved
    empty_rows = result[result[""tags""].isna()]
    assert len(empty_rows) == 1
    assert empty_rows.iloc[0][""id""] == 2
",tests/test_pandas_accessors.py,
survived,"    def gather(
        self,
        content_key: str,
        doc_id_key: str,
        order_key: str,
        peripheral_chunks: Optional[Dict[str, Any]] = None,
        **kwargs
    ) -> pd.DataFrame:
        """"""
        Gather contextual information from surrounding chunks to enhance each chunk.

        Documentation: https://ucbepic.github.io/docetl/operators/gather/

        Args:
            content_key: The column containing the main content to be enhanced
            doc_id_key: The column containing document identifiers to group chunks
            order_key: The column containing chunk order numbers within documents
            peripheral_chunks: Configuration for surrounding context:
                - previous: {""head"": {""count"": int}, ""tail"": {""count"": int}, ""middle"": {}}
                - next: {""head"": {""count"": int}, ""tail"": {""count"": int}, ""middle"": {}}
            **kwargs: Additional configuration options:
                - main_chunk_start: Start marker for main chunk (default: ""--- Begin Main Chunk ---"")
                - main_chunk_end: End marker for main chunk (default: ""--- End Main Chunk ---"")
                - doc_header_key: Column containing document headers (optional)

        Returns:
            pd.DataFrame: DataFrame with enhanced content including:
                - {content_key}_rendered: The main content with surrounding context

        Examples:
            >>> # Basic gathering with surrounding context
            >>> df.semantic.gather(
            ...     content_key=""chunk_content"",
            ...     doc_id_key=""document_id"",
            ...     order_key=""chunk_number"",
            ...     peripheral_chunks={
            ...         ""previous"": {""head"": {""count"": 2}, ""tail"": {""count"": 1}},
            ...         ""next"": {""head"": {""count"": 1}, ""tail"": {""count"": 2}}
            ...     }
            ... )

            >>> # Simple gathering without peripheral chunks
            >>> df.semantic.gather(
            ...     content_key=""content"",
            ...     doc_id_key=""doc_id"",
            ...     order_key=""order""
            ... )
        """"""
        # Convert DataFrame to list of dicts
        input_data = self._df.to_dict(""records"")

        # Create gather operation config
        gather_config = {
            ""type"": ""gather"",
            ""name"": f""semantic_gather_{len(self._history)}"",
            ""content_key"": content_key,
            ""doc_id_key"": doc_id_key,
            ""order_key"": order_key,
            **kwargs,
        }

        # Add peripheral_chunks config if provided
        if peripheral_chunks is not None:
            gather_config[""peripheral_chunks""] = peripheral_chunks

        # Create and execute gather operation
        gather_op = GatherOperation(
            runner=self.runner,
            config=gather_config,
            default_model=self.runner.config[""default_model""],
            max_threads=self.runner.max_threads,
            console=self.runner.console,
            status=self.runner.status,
        )
        results, cost = gather_op.execute(input_data)

        return self._record_operation(results, ""gather"", gather_config, cost)
",docetl/apis/pd_accessors.py,SemanticAccessor
survived,"    def test_cost_report_none_days(self):
        """"""Test cost_report with None days parameter.""""""
        with mock.patch('sky.global_user_state.get_clusters_from_history') as mock_get_history:
            mock_get_history.return_value = []
            
            result = core.cost_report(days=None)
            
            # Should call with default 30 days when None is passed
            mock_get_history.assert_called_once_with(days=30)
            self.assertEqual(result, [])
",tests/unit_tests/test_sky_cost_report.py,TestCostReportCore
survived,"def test_complex_severity_expressions(
    db_session, workflow_manager, create_workflow, create_alert
):
    """"""Test complex CEL expressions involving severity comparisons""""""
    workflow = create_workflow(
        ""test-complex-severity"",
        ""(severity >= 'warning' && source.contains('prometheus')) || (severity == 'critical' && source.contains('grafana'))""
    )

    # Should match: prometheus with warning+, grafana with critical
    prometheus_critical = create_alert(
        severity=AlertSeverity.CRITICAL, source=[""prometheus""], fingerprint=""fp1""
    )
    prometheus_high = create_alert(
        severity=AlertSeverity.HIGH, source=[""prometheus""], fingerprint=""fp2""
    )
    prometheus_warning = create_alert(
        severity=AlertSeverity.WARNING, source=[""prometheus""], fingerprint=""fp3""
    )
    grafana_critical = create_alert(
        severity=AlertSeverity.CRITICAL, source=[""grafana""], fingerprint=""fp4""
    )

    # Should NOT match: prometheus with info/low, grafana with non-critical
    prometheus_info = create_alert(
        severity=AlertSeverity.INFO, source=[""prometheus""], fingerprint=""fp5""
    )
    grafana_high = create_alert(
        severity=AlertSeverity.HIGH, source=[""grafana""], fingerprint=""fp6""
    )

    # Test matching alerts
    for alert in [prometheus_critical, prometheus_high, prometheus_warning, grafana_critical]:
        workflows_to_run_before = len(workflow_manager.scheduler.workflows_to_run)
        workflow_manager.insert_events(SINGLE_TENANT_UUID, [alert])
        assert len(workflow_manager.scheduler.workflows_to_run) == workflows_to_run_before + 1

    # Test non-matching alerts
    for alert in [prometheus_info, grafana_high]:
        workflows_to_run_before = len(workflow_manager.scheduler.workflows_to_run)
        workflow_manager.insert_events(SINGLE_TENANT_UUID, [alert])
        assert len(workflow_manager.scheduler.workflows_to_run) == workflows_to_run_before
",tests/test_workflow_severity_comparisons.py,
survived,"def test_severity_preprocessing_cel_utils_integration(
    db_session, workflow_manager, create_workflow, create_alert
):
    """"""
    Test that the cel_utils.preprocess_cel_expression function is properly integrated
    into the workflow manager to fix the lexicographic comparison bug
    """"""
    
    # This test specifically validates that lexicographic issues are resolved
    # Before fix: 'high' < 'info' lexicographically (h comes before i in alphabet)
    # After fix: high (4) > info (2) numerically
    
    workflow = create_workflow(
        ""test-preprocessing-integration"", 
        ""severity > 'info'""
    )

    # Create a 'high' severity alert - this is the key test case
    # that would fail with lexicographic comparison but should pass with numeric
    high_alert = create_alert(
        severity=AlertSeverity.HIGH,
        source=[""test""], 
        fingerprint=""fp-high-severity""
    )

    workflows_to_run_before = len(workflow_manager.scheduler.workflows_to_run)
    workflow_manager.insert_events(SINGLE_TENANT_UUID, [high_alert])
    
    # This assertion would fail before the fix, but should pass after
    assert len(workflow_manager.scheduler.workflows_to_run) == workflows_to_run_before + 1, \
        ""HIGH severity alert should match 'severity > info' expression after preprocessing fix""
    assert workflow_manager.scheduler.workflows_to_run[-1][""workflow_id""] == workflow.id",tests/test_workflow_severity_comparisons.py,
survived,"def create_alert():
    """"""Fixture to create an alert DTO with specified properties""""""

    def _create_alert(**properties):
        alert_data = {
            ""id"": ""test-alert-1"",
            ""source"": [""prometheus""],
            ""name"": ""test-alert"",
            ""status"": AlertStatus.FIRING,
            ""severity"": AlertSeverity.INFO,
            ""lastReceived"": datetime.datetime.now().isoformat(),
            ""fingerprint"": f""test-fingerprint-{datetime.datetime.now().timestamp()}"",
        }
        alert_data.update(properties)
        return AlertDto(**alert_data)

    return _create_alert
",tests/test_workflow_severity_comparisons.py,
survived,"    def diff_url(
        self, import_id: str, debian_data: DebianData, new_urls: dict[URLKey, URL]
    ) -> dict[UUID, UUID]:
        """"""Given a package's URLs, returns the resolved URL for this specific package""""""
        resolved_urls: dict[UUID, UUID] = {}

        # Generate the URLs for this package
        urls = self._generate_chai_urls(debian_data)

        # Process each URL
        for url_key in urls:
            # guard: _generate_chai_urls could be None for a url type
            if url_key is None:
                continue

            resolved_url_id: UUID

            if url_key in new_urls:
                resolved_url_id = new_urls[url_key].id
            elif url_key in self.caches.url_map:
                resolved_url_id = self.caches.url_map[url_key].id
            else:
                self.logger.debug(
                    f""URL {url_key.url} as {url_key.url_type_id} is entirely new""
                )
                new_url = URL(
                    id=uuid4(),
                    url=url_key.url,
                    url_type_id=url_key.url_type_id,
                    created_at=self.now,
                    updated_at=self.now,
                )
                resolved_url_id = new_url.id
                new_urls[url_key] = new_url

            resolved_urls[url_key.url_type_id] = resolved_url_id

        return resolved_urls
",package_managers/debian/diff.py,DebianDiff
survived,"        def process_deps(dependencies: list[Depends], dep_type: UUID) -> None:
            """"""Helper to process dependencies of a given type with priority""""""
            for dep in dependencies:
                dep_name = f""debian/{dep.package}""  # bc the map is by import_id

                # Get the dependency package from cache
                dependency = self.caches.package_map.get(dep_name)

                # try debian/dependency
                if not dependency:
                    self.logger.debug(f""{dep_name} not loaded, will catch next time"")
                    continue

                # If this dependency already exists in our map, choose higher priority
                if dep_name in dependency_map:
                    existing_priority = priority_order.get(
                        dependency_map[dep_name], 999
                    )
                    new_priority = priority_order.get(dep_type, 999)

                    if new_priority < existing_priority:  # Lower is better!
                        old_type_id = dependency_map[dep_name]
                        dependency_map[dep_name] = dep_type
                        self.logger.debug(
                            f""Updated dependency type for {dep_name} from ""
                            f""{old_type_id} to {dep_type} (higher priority)""
                        )
                else:
                    dependency_map[dep_name] = dep_type
",package_managers/debian/diff.py,DebianDiff
survived,"    def test_completely_new_package(self, mock_config, mock_logger, mock_db):
        """"""Tests the addition of completely new packages & new URLs""""""

        # Create empty cache (no existing packages)
        cache = Cache(package_map={}, url_map={}, package_urls={}, dependencies={})

        # Create new package data
        new_pkg_data = create_debian_package(
            package=""new-pkg"",
            description=""A new package"",
            homepage=""https://github.com/example/new-pkg"",
            depends=[""some-dep""],
            build_depends=[""build-tool""],
        )

        # Test the diff
        diff = DebianDiff(mock_config, cache, mock_db, mock_logger)
        pkg_id, pkg_obj, update_payload = diff.diff_pkg(""debian/new-pkg"", new_pkg_data)

        # Assertions
        assert pkg_obj is not None  # New package should be created
        assert pkg_obj.derived_id == ""debian/new-pkg""
        assert pkg_obj.name == ""new-pkg""
        assert pkg_obj.import_id == ""debian/new-pkg""
        assert pkg_obj.package_manager_id == mock_config.pm_config.pm_id
        assert pkg_obj.readme == ""A new package""
        assert update_payload == {}  # No updates for new package

        # Test URL creation
        new_urls = {}
        resolved_urls = diff.diff_url(""new-pkg"", new_pkg_data, new_urls)
        new_links, updated_links = diff.diff_pkg_url(pkg_id, resolved_urls)

        # Should create URL for homepage
        assert len(new_urls) >= 1  # At least homepage
        assert len(new_links) >= 1  # At least homepage link
        assert len(updated_links) == 0  # No existing links to update

        # Check that homepage URL was created
        homepage_url_found = False
        for url_key, _url in new_urls.items():
            if url_key.url_type_id == mock_config.url_types.homepage:
                assert url_key.url == ""https://github.com/example/new-pkg""
                homepage_url_found = True
                break
        assert homepage_url_found
",tests/package_managers/debian/test_debian_diff.py,TestDebianDifferentialLoading
survived,"def simple_source():
    return """"""Package: 0ad
Binary: 0ad, 0ad-dbg, 0ad-data, 0ad-data-common
Version: 0.0.26-1
Maintainer: Debian Games Team <pkg-games-devel@lists.alioth.debian.org>
Uploaders: Vincent Cheng <vcheng@debian.org>, Euan Kemp <euank@euank.com>
Build-Depends: debhelper-compat (= 13), cmake, dpkg-dev (>= 1.15.5), libboost-dev, libenet-dev (>= 1.3), libopenal-dev, libpng-dev, libsdl2-dev, libtiff5-dev, libvorbis-dev, libxcursor-dev, pkg-config, zlib1g-dev, libcurl4-gnutls-dev, libgloox-dev, libjsoncpp-dev, libminiupnpc-dev, libnspr4-dev, libnss3-dev, libsodium-dev, libwxgtk3.0-gtk3-dev | libwxgtk3.0-dev, python3, python3-dev, libxml2-dev, rust-gdb [amd64 i386 ppc64el]
Architecture: any all
Standards-Version: 4.5.1
Format: 3.0 (quilt)
Files:
 2fc0f38b8a4cf56fea7040fcf5f79ca3 2414 0ad_0.0.26-1.dsc
 35ca57e781448c69ba31323313e972af 31463733 0ad_0.0.26.orig.tar.xz
 f78de44c8a9c32e6be3ae99f2747c330 71948 0ad_0.0.26-1.debian.tar.xz
Vcs-Browser: https://salsa.debian.org/games-team/0ad
Vcs-Git: https://salsa.debian.org/games-team/0ad.git
Directory: pool/main/0/0ad
Priority: optional
Section: games
Testsuite: autopkgtest
Testsuite-Triggers: g++, pyrex


""""""
",tests/package_managers/debian/test_debian_parser.py,
survived,"    def test_multiline_binary(self, multiline_binary):
        """"""Test handling of multiline binaries.""""""
        parser = DebianParser(multiline_binary)
        sources = list(parser.parse())
        assert len(sources) == 1
        source = sources[0]
        assert source.package == ""binutils""
        assert source.binary == [
            ""binutils-for-host"",
            ""binutils-for-build"",
            ""binutils-ia64-linux-gnu-dbg"",
            ""binutils-m68k-linux-gnu"",
            ""binutils-mips64el-linux-gnuabin32-dbg"",
            ""binutils-mipsisa64r6-linux-gnuabin32"",
            ""binutils-mipsisa64r6el-linux-gnuabi64-dbg"",
        ]
",tests/package_managers/debian/test_debian_parser.py,TestDebianParser
survived,"    def test_dependency_type_priority_no_change(
        self, mock_config, mock_logger, mock_db
    ):
        """"""
        Scenario:
          - p1 has runtime dependency to p2 in cache
          - p1 depends on p2 as both runtime and build in parsed data

        Expect no change (runtime has priority).
        """"""

        # Setup existing package and dependencies
        p1_id = uuid4()
        p2_id = uuid4()

        p1_pkg = Package(id=p1_id, derived_id=""debian/p1"", name=""p1"", import_id=""p1"")
        p2_pkg = Package(id=p2_id, derived_id=""debian/p2"", name=""p2"", import_id=""p2"")

        # Existing runtime dependency in cache
        existing_runtime_dep = LegacyDependency(
            package_id=p1_id,
            dependency_id=p2_id,
            dependency_type_id=mock_config.dependency_types.runtime,
        )

        cache = Cache(
            package_map={""debian/p1"": p1_pkg, ""debian/p2"": p2_pkg},
            url_map={},
            package_urls={},
            dependencies={p1_id: {existing_runtime_dep}},
        )

        # Parsed data has p2 as both runtime and build dependency
        new_pkg_data = create_debian_package(
            package=""p1"",
            depends=[""p2""],  # runtime
            build_depends=[""p2""],  # build
        )

        diff = DebianDiff(mock_config, cache, mock_db, mock_logger)
        new_deps, removed_deps = diff.diff_deps(""debian/p1"", new_pkg_data)

        # Should have no changes - runtime priority means no change needed
        assert len(new_deps) == 0
        assert len(removed_deps) == 0
",tests/package_managers/debian/test_debian_diff.py,TestDebianDifferentialLoading
survived,"    def test_package_description_update(self, mock_config, mock_logger, mock_db):
        """"""Test scenario where package exists but description has changed""""""

        # Setup existing package
        existing_pkg_id = uuid4()
        existing_package = Package(
            id=existing_pkg_id,
            derived_id=""debian/desc-pkg"",
            name=""desc-pkg"",
            package_manager_id=mock_config.pm_config.pm_id,
            import_id=""desc-pkg"",
            readme=""Old description"",
        )

        cache = Cache(
            package_map={""desc-pkg"": existing_package},
            url_map={},
            package_urls={},
            dependencies={},
        )

        # Create package data with new description
        pkg_data = create_debian_package(
            package=""desc-pkg"", description=""New description""
        )

        # Test the diff
        diff = DebianDiff(mock_config, cache, mock_db, mock_logger)
        pkg_id, pkg_obj, update_payload = diff.diff_pkg(""desc-pkg"", pkg_data)

        # Assertions
        assert pkg_id == existing_pkg_id
        assert pkg_obj is None  # No new package
        assert update_payload is not None  # Should have changes
        assert update_payload[""id""] == existing_pkg_id
        assert update_payload[""readme""] == ""New description""
",tests/package_managers/debian/test_debian_diff.py,TestDebianDifferentialLoading
survived,"    def __init__(self, logger_name: str, config: Config):
        super().__init__(logger_name)
        self.config = config
",package_managers/debian/db.py,DebianDB
survived,"def validate_github_token():
    """"""Validate GitHub token and check permissions""""""
    try:
        data = request.get_json()
        github_token = data.get('github_token')
        repo_url = data.get('repo_url', '')
        
        if not github_token:
            return jsonify({'error': 'github_token is required'}), 400
        
        # Create GitHub client
        g = Github(github_token)
        
        # Test basic authentication
        user = g.get_user()
        logger.info(f""ðŸ” Token belongs to user: {user.login}"")
        
        # Test token scopes
        rate_limit = g.get_rate_limit()
        logger.info(f""ðŸ“Š Rate limit info: {rate_limit.core.remaining}/{rate_limit.core.limit}"")
        
        # If repo URL provided, test repo access
        repo_info = {}
        if repo_url:
            try:
                repo_parts = repo_url.replace('https://github.com/', '').replace('.git', '')
                repo = g.get_repo(repo_parts)
                
                # Test various permissions
                permissions = {
                    'read': True,  # If we got here, we can read
                    'write': False,
                    'admin': False
                }
                
                try:
                    # Test if we can read branches
                    branches = list(repo.get_branches())
                    permissions['read_branches'] = True
                    logger.info(f""âœ… Can read branches ({len(branches)} found)"")
                    
                    # Test if we can create branches (this is what's actually failing)
                    test_branch_name = f""test-permissions-{int(time.time())}""
                    try:
                        # Try to create a test branch
                        main_branch = repo.get_branch(repo.default_branch)
                        test_ref = repo.create_git_ref(f""refs/heads/{test_branch_name}"", main_branch.commit.sha)
                        permissions['create_branches'] = True
                        logger.info(f""âœ… Can create branches - test successful"")
                        
                        # Clean up test branch immediately
                        test_ref.delete()
                        logger.info(f""ðŸ§¹ Cleaned up test branch"")
                        
                    except Exception as branch_error:
                        permissions['create_branches'] = False
                        logger.warning(f""âŒ Cannot create branches: {branch_error}"")
                        
                except Exception as e:
                    permissions['read_branches'] = False
                    permissions['create_branches'] = False
                    logger.warning(f""âŒ Cannot read branches: {e}"")
                
                try:
                    # Check if we can write (without actually writing)
                    repo_perms = repo.permissions
                    permissions['write'] = repo_perms.push
                    permissions['admin'] = repo_perms.admin
                    logger.info(f""ðŸ“‹ Repo permissions: push={repo_perms.push}, admin={repo_perms.admin}"")
                except Exception as e:
                    logger.warning(f""âš ï¸ Could not check repo permissions: {e}"")
                
                repo_info = {
                    'name': repo.full_name,
                    'private': repo.private,
                    'permissions': permissions,
                    'default_branch': repo.default_branch
                }
                
            except Exception as repo_error:
                return jsonify({
                    'error': f'Cannot access repository: {str(repo_error)}',
                    'user': user.login
                }), 403
        
        return jsonify({
            'status': 'success',
            'user': user.login,
            'repo': repo_info,
            'message': 'Token is valid and has repository access'
        })
        
    except Exception as e:
        logger.error(f""Token validation error: {str(e)}"")
        return jsonify({'error': f'Token validation failed: {str(e)}'}), 401
",server/github_integration.py,
survived,"def apply_diff_to_content(original_content, diff_lines, filename):
    """"""Apply diff changes to original content - simplified implementation""""""
    try:
        # For now, let's use a simple approach: reconstruct from + lines
        # This is not a complete diff parser, but works for basic cases
        
        result_lines = []
        original_lines = original_content.split('\n') if original_content else []
        
        # Find the actual diff content starting from @@ line
        diff_start = 0
        for i, line in enumerate(diff_lines):
            if line.startswith('@@'):
                diff_start = i + 1
                break
        
        # Simple reconstruction: take context and + lines, skip - lines
        for line in diff_lines[diff_start:]:
            if line.startswith('+++') or line.startswith('---'):
                continue
            elif line.startswith('+') and not line.startswith('+++'):
                result_lines.append(line[1:])  # Remove the +
            elif line.startswith(' '):  # Context line
                result_lines.append(line[1:])  # Remove the space
            elif line.startswith('-'):
                continue  # Skip removed lines
            elif line.strip() == '':
                continue  # Skip empty lines in diff
            else:
                # Check if we've reached the next file
                if line.startswith('diff --git') or line.startswith('--- a/'):
                    break
        
        # If we got content, return it, otherwise fall back to using the git diff directly
        if result_lines:
            return '\n'.join(result_lines)
        else:
            # Fallback: return original content (no changes applied)
            logger.warning(f""âš ï¸ Could not parse diff for {filename}, keeping original"")
            return original_content
            
    except Exception as e:
        logger.error(f""âŒ Error applying diff to {filename}: {str(e)}"")
        return None",server/github_integration.py,
survived,"def migrate_legacy_tasks():
    """"""Migrate tasks from legacy JSON storage to Supabase""""""
    try:
        user_id = request.headers.get('X-User-ID')
        if not user_id:
            return jsonify({'error': 'User ID required'}), 400
        
        # This would be called manually to migrate existing tasks
        # Load legacy tasks from file if it exists
        import json
        import os
        
        legacy_file = 'tasks_backup.json'
        if not os.path.exists(legacy_file):
            return jsonify({
                'status': 'success',
                'message': 'No legacy tasks file found',
                'migrated': 0
            })
        
        with open(legacy_file, 'r') as f:
            legacy_tasks = json.load(f)
        
        migrated_count = 0
        for task_id, task_data in legacy_tasks.items():
            try:
                # Check if already migrated
                existing = DatabaseOperations.get_task_by_legacy_id(task_id)
                if existing:
                    continue
                
                # Migrate task
                DatabaseOperations.migrate_legacy_task(task_data, user_id)
                migrated_count += 1
            except Exception as e:
                logger.warning(f""Failed to migrate task {task_id}: {e}"")
        
        return jsonify({
            'status': 'success',
            'message': f'Migrated {migrated_count} tasks',
            'migrated': migrated_count
        })
        
    except Exception as e:
        logger.error(f""Error migrating legacy tasks: {str(e)}"")
        return jsonify({'error': str(e)}), 500",server/tasks.py,
survived,"def get_project_tasks(project_id):
    """"""Get all tasks for a specific project""""""
    try:
        user_id = request.headers.get('X-User-ID')
        if not user_id:
            return jsonify({'error': 'User ID required'}), 400
        
        # Verify project exists and belongs to user
        project = DatabaseOperations.get_project_by_id(project_id, user_id)
        if not project:
            return jsonify({'error': 'Project not found'}), 404
        
        tasks = DatabaseOperations.get_user_tasks(user_id, project_id)
        return jsonify({
            'status': 'success',
            'tasks': tasks
        })
        
    except Exception as e:
        logger.error(f""Error fetching tasks for project {project_id}: {str(e)}"")
        return jsonify({'error': str(e)}), 500",server/projects.py,
survived,"    def delete_project(project_id: int, user_id: str) -> bool:
        """"""Delete a project""""""
        try:
            result = supabase.table('projects').delete().eq('id', project_id).eq('user_id', user_id).execute()
            return len(result.data) > 0
        except Exception as e:
            logger.error(f""Error deleting project {project_id}: {e}"")
            raise
",server/database.py,DatabaseOperations
survived,"def save_combined_file(data: Dict, output_path: str) -> None:
    """"""
    Save combined metadata to a JSON file.
    
    Args:
        data: Dictionary to save
        output_path: Path where to save the file
    """"""
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)
    
    print(f""Saved combined metadata to {output_path}"")
",combine_metadata.py,
survived,"def find_metadata_files(decrypted_dir: str) -> Dict[str, Any]:
    """"""
    Find all metadata.json files and categorize them by type.
    
    Args:
        decrypted_dir: Path to the decrypted_overrides directory
        
    Returns:
        Dictionary with categories as keys and lists of file paths as values
    """"""
    files = {
        ""global"": [],
        ""regions"": defaultdict(list),
        ""locales"": defaultdict(list)
    }
    
    # Walk through all directories
    for root, dirs, filenames in os.walk(decrypted_dir):
        if ""metadata.json"" in filenames:
            metadata_path = os.path.join(root, ""metadata.json"")
            
            # Check if this is a region-specific file
            if ""/region/"" in metadata_path:
                region_match = re.search(r'/region/([^/]+)/', metadata_path)
                if region_match:
                    region = region_match.group(1)
                    files[""regions""][region].append(metadata_path)
            
            # Check if this is a locale-specific file  
            elif ""/locale/"" in metadata_path:
                locale_match = re.search(r'/locale/([^/]+)/', metadata_path)
                if locale_match:
                    locale = locale_match.group(1)
                    files[""locales""][locale].append(metadata_path)
            
            # Check if this is a global file (directly in AssetData/)
            elif metadata_path.endswith(""/AssetData/metadata.json""):
                files[""global""].append(metadata_path)
    
    return files
",combine_metadata.py,
survived,"def main():
    """"""Main function to process all metadata files.""""""
    decrypted_dir = ""decrypted_overrides""
    output_dir = ""combined_metadata""
    
    if not os.path.exists(decrypted_dir):
        print(f""Error: Directory {decrypted_dir} does not exist."")
        return
    
    print(f""Processing metadata files in {decrypted_dir}..."")
    
    # Find all metadata files
    files = find_metadata_files(decrypted_dir)
    
    # Process global files
    print(f""Found {len(files['global'])} global metadata files"")
    if files['global']:
        global_data = combine_files(files['global'])
        save_combined_file(global_data, f""{output_dir}/global_metadata.json"")
        print(f""  - Global: {len(global_data['reject'])} reject, {len(global_data['regexReject'])} regexReject entries"")
    
    # Process region-specific files
    print(f""Found {len(files['regions'])} regions"")
    for region, file_list in files['regions'].items():
        print(f""  Processing region {region}: {len(file_list)} files"")
        region_data = combine_files(file_list)
        save_combined_file(region_data, f""{output_dir}/region_{region}_metadata.json"")
        print(f""    - Region {region}: {len(region_data['reject'])} reject, {len(region_data['regexReject'])} regexReject entries"")
    
    # Process locale-specific files
    print(f""Found {len(files['locales'])} locales"")
    for locale, file_list in files['locales'].items():
        print(f""  Processing locale {locale}: {len(file_list)} files"")
        locale_data = combine_files(file_list)
        save_combined_file(locale_data, f""{output_dir}/locale_{locale}_metadata.json"")
        print(f""    - Locale {locale}: {len(locale_data['reject'])} reject, {len(locale_data['regexReject'])} regexReject entries"")
    
    print(f""\nCombined metadata files saved to {output_dir}/"")
    print(""These files provide a convenient way to review all safety filters by region/locale."")
",combine_metadata.py,
deleted,"    def troubleshooting_guide() -> str:
        """"""Get troubleshooting help for flow execution issues.""""""
        return """"""
# Langflow MCP Troubleshooting Guide

## Common Issues:

### Flow Execution Errors:
- Check that required inputs are provided
- Verify input format matches flow expectations
- Review flow configuration and dependencies

### Tool Discovery:
- Use MCP client's tool listing functionality
- Check resource ""flow://flows"" for available flows
- Verify MCP server connection

### Input Formatting:
- Provide input_value as string
- Use tweaks object for parameter overrides
- Check flow schema via ""flow://flows/{flow_id}/schema""

### Performance:
- Large flows may take time to execute
- Check execution_time in response
- Consider flow optimization for better performance
""""""
",src/backend/base/langflow/cli/mcp_server.py,
survived,"    def test_run_mcp_server_websocket(self, mock_fastmcp):
        """"""Test running MCP server with websocket transport.""""""
        mock_mcp_instance = MagicMock()
        mock_mcp_instance.run = MagicMock()

        run_mcp_server(
            mcp_server=mock_mcp_instance,
            transport=""websocket"",
            host=""127.0.0.1"",
            port=9000
        )

        # Should call run() with transport, host, and port
        mock_mcp_instance.run.assert_called_once_with(
            transport=""websocket"",
            host=""127.0.0.1"",
            port=9000
        )
",src/backend/tests/unit/test_mcp_server.py,TestMCPServerRuntime
survived,"    def test_create_mcp_server_with_none_meta(self, mock_fastmcp):
        """"""Test MCP server creation when meta is None.""""""
        mock_graph = MagicMock()
        mock_mcp_instance = MagicMock()
        mock_fastmcp.return_value = mock_mcp_instance

        graphs = {""test_flow"": mock_graph}
        metas = {""test_flow"": None}  # None meta

        server = create_mcp_server(
            graphs=graphs,
            metas=metas,
            server_name=""None Meta Test""
        )

        # Should handle None meta gracefully
        assert server == mock_mcp_instance
        mock_fastmcp.assert_called_once_with(""None Meta Test"")
",src/backend/tests/unit/test_mcp_server.py,TestMCPServerErrorHandling
survived,"    def test_create_mcp_server_with_root_dir(self, mock_fastmcp, sample_graphs_and_metas, tmp_path):
        """"""Test MCP server creation with root directory.""""""
        graphs, metas = sample_graphs_and_metas
        mock_mcp_instance = MagicMock()
        mock_fastmcp.return_value = mock_mcp_instance

        server = create_mcp_server(
            graphs=graphs,
            metas=metas,
            server_name=""Test Server"",
            root_dir=tmp_path
        )

        assert server == mock_mcp_instance
        mock_fastmcp.assert_called_once_with(""Test Server"")
",src/backend/tests/unit/test_mcp_server.py,TestMCPServerCreation
deleted,"    def test_transform_request_handles_tool_choice_required(self):
        """"""Test that tool_choice 'required' is removed""""""
        config = MoonshotChatConfig()
        
        optional_params = {
            ""tool_choice"": ""required"",
            ""tools"": [{""type"": ""function"", ""function"": {""name"": ""test""}}],
            ""temperature"": 0.7
        }
        
        result = config.transform_request(
            model=""moonshot-v1-8k"",
            messages=[{""role"": ""user"", ""content"": ""test""}],
            optional_params=optional_params,
            litellm_params={},
            headers={}
        )
        
        # tool_choice should be removed when it's ""required""
        assert ""tool_choice"" not in result
        # Tools should remain
        assert result.get(""tools"") is not None
        assert result.get(""temperature"") == 0.7
",tests/test_litellm/llms/moonshot/test_moonshot_chat_transformation.py,TestMoonshotConfig
deleted,"    def test_transform_request_removes_functions(self):
        """"""Test that functions parameter is removed from optional_params""""""
        config = MoonshotChatConfig()
        
        optional_params = {
            ""functions"": [{""name"": ""test_function"", ""description"": ""Test function""}],
            ""temperature"": 0.7,
            ""max_tokens"": 1000
        }
        
        result = config.transform_request(
            model=""moonshot-v1-8k"",
            messages=[{""role"": ""user"", ""content"": ""test""}],
            optional_params=optional_params,
            litellm_params={},
            headers={}
        )
        
        # Functions should be removed
        assert ""functions"" not in result
        # Other params should remain
        assert result.get(""temperature"") == 0.7
        assert result.get(""max_tokens"") == 1000
",tests/test_litellm/llms/moonshot/test_moonshot_chat_transformation.py,TestMoonshotConfig
deleted,"    def test_transform_request_temperature_n_not_limited_high_temp(self):
        """"""Test that n is not limited when temperature is high""""""
        config = MoonshotChatConfig()
        
        optional_params = {
            ""temperature"": 0.8,  # High temperature
            ""n"": 3  # Multiple results requested
        }
        
        result = config.transform_request(
            model=""moonshot-v1-8k"",
            messages=[{""role"": ""user"", ""content"": ""test""}],
            optional_params=optional_params,
            litellm_params={},
            headers={}
        )
        
        # n should remain as 3 when temperature is high
        assert result.get(""n"") == 3
        assert result.get(""temperature"") == 0.8
",tests/test_litellm/llms/moonshot/test_moonshot_chat_transformation.py,TestMoonshotConfig
survived,"    def test_csharp_generics_and_complex_types(self):
        patch = """"""
@@ -152,10 +152,6 @@ public List<T> GetItems<T>()

@@ -152,10 +152,6 @@ public Dictionary<string, int> GetDictionary()

@@ -152,10 +152,6 @@ public async Task<List<string>> GetStringsAsync()

@@ -152,10 +152,6 @@ public T[] GetArray<T>(int size)

@@ -152,10 +152,6 @@ public void ProcessItems(List<Dictionary<string, object>> items)

@@ -152,10 +152,6 @@ public Func<int, bool> GetPredicate()

@@ -152,10 +152,6 @@ public Action<string> GetAction()

@@ -152,10 +152,6 @@ public int? GetNullableInt()

""""""

        assert CSharpParser.extract_functions_from_patch(patch) == {
            ""GetItems"",
            ""GetDictionary"",
            ""GetStringsAsync"",
            ""GetArray"",
            ""ProcessItems"",
            ""GetPredicate"",
            ""GetAction"",
            ""GetNullableInt"",
        }
",tests/sentry/integrations/source_code_management/test_language_parsers.py,CSharpParserTestCase
deleted,"		def current_state_property(self) -> AgentBrain:
			""""""For backward compatibility - returns an AgentBrain with the flattened properties""""""
			return AgentBrain(
				thinking=None,
				evaluation_previous_goal=self.evaluation_previous_goal,
				memory=self.memory,
				next_goal=self.next_goal,
			)
",browser_use/agent/views.py,AgentOutput
survived,"    def test_env_response_method(self, mock_singleturn_env):
        """"""Test the env_response method (which should never be called in practice).""""""
        messages = [{""role"": ""user"", ""content"": ""Hello""}]
        state = {}
        
        response, new_state = mock_singleturn_env.env_response(messages, state)
        
        # Should return minimal response
        assert response[""role""] == ""user""
        assert response[""content""] == """"
        assert new_state == state
",tests/test_singleturn_env.py,TestSingleTurnEnv
survived,"            def __init__(self, **kwargs):
                super().__init__(message_type=""completion"", **kwargs)
",tests/test_multiturn_env.py,TestMultiTurnEnv.CompletionMultiTurnEnv
survived,"    def test_parse_chat_completion_tokens(self, mock_openai_client, sample_dataset):
        """"""Test parsing tokens from a vLLM chat completion.""""""
        env = SimpleEnvironment(
            client=mock_openai_client,
            model=""test-model"",
            dataset=sample_dataset,
            parser=Parser(),
            rubric=Rubric()
        )
        
        # Create mock chat completion with tokens
        mock_completion = Mock()
        mock_completion.choices = [Mock()]
        mock_completion.choices[0].logprobs = Mock()
        mock_completion.choices[0].logprobs.content = [
            Mock(token=""id:1234""),
            Mock(token=""id:5678""),
            Mock(token=""id:9012"")
        ]
        
        tokens = env.parse_chat_completion_tokens(mock_completion)
        assert tokens == [1234, 5678, 9012]
",tests/test_environment.py,TestEnvironmentBase
survived,"    def test_process_completion_format(self, mock_openai_client, sample_dataset):
        """"""Test processing completion format text.""""""
        env = SimpleEnvironment(
            client=mock_openai_client,
            model=""test-model"",
            dataset=sample_dataset,
            parser=Parser(),
            rubric=Rubric()
        )
        
        # Create a mock tokenizer
        mock_tokenizer = Mock()
        mock_tokenizer.encode = Mock(side_effect=lambda text: list(range(len(text))))
        
        prompt = ""Complete this: 2+2=""
        completion = ""4""
        
        prompt_ids, prompt_mask, completion_ids, completion_mask = env.process_completion_format(
            prompt, completion, mock_tokenizer
        )
        
        assert isinstance(prompt_ids, list)
        assert isinstance(prompt_mask, list)
        assert isinstance(completion_ids, list)
        assert isinstance(completion_mask, list)
        assert len(prompt_ids) == len(prompt)
        assert len(completion_ids) == len(completion)
        assert all(m == 0 for m in prompt_mask)
        assert all(m == 1 for m in completion_mask)
",tests/test_environment.py,TestEnvironmentBase
survived,"    def test_get_env_for_task(self, mock_openai_client):
        """"""Test getting environment for a specific task.""""""
        env1 = SingleTurnEnv(
            client=mock_openai_client,
            model=""test-model"",
            dataset=Dataset.from_dict({""question"": [""q1""], ""answer"": [""a1""]}),
            rubric=Rubric()
        )
        
        env2 = SingleTurnEnv(
            client=mock_openai_client,
            model=""test-model"",
            dataset=Dataset.from_dict({""question"": [""q2""], ""answer"": [""a2""]}),
            rubric=Rubric()
        )
        
        env_group = EnvGroup(envs=[env1, env2], env_names=[""math"", ""code""])
        
        assert env_group.get_env_for_task(""math"") == env1
        assert env_group.get_env_for_task(""code"") == env2
        # Unknown task returns first environment as fallback
        assert env_group.get_env_for_task(""unknown"") == env1
",tests/test_env_group.py,TestEnvGroup
survived,"    def test_process_env_results_with_truncation(self, mock_openai_client, sample_dataset):
        """"""Test processing environment results with sequence length truncation.""""""
        env = SimpleEnvironment(
            client=mock_openai_client,
            model=""test-model"",
            dataset=sample_dataset,
            parser=Parser(),
            rubric=Rubric()
        )
        
        # Create a mock tokenizer
        mock_tokenizer = Mock()
        
        # Track the conversation state
        def mock_apply_chat_template(conversation, tokenize=False, add_generation_prompt=True):
            # Convert messages to a string representation
            text = """"
            for msg in conversation:
                text += f""{msg['role']}: {msg['content']} ""
            return text.strip()
        
        def mock_encode(text, **kwargs):
            # Return tokens based on the text content
            if ""assistant: Hi there!"" in text:
                # Prompt + completion: return extended tokens
                return [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
            elif ""user: Hello"" in text:
                # Just prompt: return base tokens
                return [1, 2, 3, 4, 5]
            else:
                # Default case
                return [1, 2, 3]
        
        mock_tokenizer.apply_chat_template = Mock(side_effect=mock_apply_chat_template)
        mock_tokenizer.encode = Mock(side_effect=mock_encode)
        
        prompts = [[{""role"": ""user"", ""content"": ""Hello""}]]
        completions = [[{""role"": ""assistant"", ""content"": ""Hi there!""}]]
        states = [{}]
        rewards = [1.0]
        
        results = env.process_env_results(
            prompts, completions, states, rewards, mock_tokenizer,
            max_seq_len=8,  # Force truncation
            mask_truncated_completions=True
        )
        
        # Check that total length respects max_seq_len
        total_len = len(results[""prompt_ids""][0]) + len(results[""completion_ids""][0])
        assert total_len <= 8
        # Check that truncated completion is masked
        assert all(m == 0 for m in results[""completion_mask""][0])
",tests/test_environment.py,TestEnvironmentBase
survived,"    async def create_project(
        self,
        info: Info[Context, None],
        input: CreateProjectInput,
    ) -> ProjectMutationPayload:
        name = input.name
        description = input.description if input.description is not UNSET else None
        gradient_start_color = (
            input.gradient_start_color if input.gradient_start_color is not UNSET else None
        )
        gradient_end_color = (
            input.gradient_end_color if input.gradient_end_color is not UNSET else None
        )

        # Build the values dict, only including non-None values to use database defaults
        values = {""name"": name}
        if description is not None:
            values[""description""] = description
        if gradient_start_color is not None:
            values[""gradient_start_color""] = gradient_start_color
        if gradient_end_color is not None:
            values[""gradient_end_color""] = gradient_end_color

        async with info.context.db() as session:
            project = await session.scalar(
                insert(models.Project)
                .values(**values)
                .returning(models.Project)
            )
            assert project is not None
        
        info.context.event_queue.put(ProjectInsertEvent((project.id,)))
        return ProjectMutationPayload(project=to_gql_project(project), query=Query())
",src/phoenix/server/api/mutations/project_mutations.py,ProjectMutationMixin
survived,"    def test_mcp_json_cache_control(self):
        with override_settings(SENTRY_MODE=""saas""):
            response = self.client.get(""/.well-known/mcp.json"")

        assert response.status_code == 200
        assert ""max-age=3600"" in response[""Cache-Control""]
        assert ""public"" in response[""Cache-Control""]",tests/sentry/web/test_api.py,McpJsonTest
deleted,"    def _parse_custom_tools(self, tool_calls: List[ChatCompletionMessageToolCall], tools: List[Dict[str, str]]) -> List[Dict[str, Any]]:
        """"""Parse responses from custom tools.""""""
        results = []
        for tool_call in tool_calls:
            for tool in tools:
                if tool_call.function.name == tool[""function""][""name""]:
                    try:
                        function_args = (
                            json.loads(tool_call.function.arguments)
                            if isinstance(tool_call.function.arguments, str)
                            else tool_call.function.arguments
                        )
                    except json.JSONDecodeError:
                        return [{}]
                    
                    # Execute the function defined in the tool's code
                    local_scope = {}
                    exec(tool[""code""].strip(), globals(), local_scope)
                    function_result = local_scope[tool[""function""][""name""]](**function_args)
                    function_args.update(function_result)
                    results.append(function_args)
        return results
",docetl/operations/utils/api.py,ResponseParser
deleted,"    def _build_send_output_tool(self, output_schema: Dict[str, Any], scratchpad: Optional[str], model: str) -> tuple:
        """"""Build the send_output tool configuration.""""""
        parameters = OutputSchemaBuilder.build_tool_schema(output_schema, scratchpad, model)
        
        if is_snowflake(model):
            tools = [
                {
                    ""tool_spec"": {
                        ""type"": ""generic"",
                        ""name"": ""send_output"",
                        ""description"": ""Send output back to the user"",
                        ""input_schema"": parameters,
                    }
                }
            ]
        else:
            tools = [
                {
                    ""type"": ""function"",
                    ""function"": {
                        ""name"": ""send_output"",
                        ""description"": ""Send output back to the user"",
                        ""parameters"": parameters,
                    },
                }
            ]
            
        if ""claude"" not in model:
            tools[0][""additionalProperties""] = False
            tools[0][""strict""] = True

        tool_choice = {""type"": ""function"", ""function"": {""name"": ""send_output""}}
        
        return tools, tool_choice
",docetl/operations/utils/api.py,LLMCallHandler
deleted,"    def _build_custom_tools(self, tools: str) -> tuple:
        """"""Build custom tools configuration.""""""
        tools_list = json.loads(tools)
        tool_choice = ""required"" if any(tool.get(""required"", False) for tool in tools_list) else ""auto""
        tools_config = [
            {""type"": ""function"", ""function"": tool[""function""]} for tool in tools_list
        ]
        return tools_config, tool_choice
",docetl/operations/utils/api.py,LLMCallHandler
survived,"    async def test_score_rollouts_empty(self):
        """"""Test scoring empty list of rollouts.""""""
        rubric = Rubric(funcs=[], weights=[])
        
        # The Rubric class has a bug with empty rollouts - it tries to access rewards[0]
        # Let's test that it handles this case gracefully or raises an appropriate error
        with pytest.raises(IndexError):
            await rubric.score_rollouts(
                prompts=[],
                completions=[],
                answers=[],
                states=[],
                tasks=[],
                infos=[]
            )
",tests/test_rubric.py,TestRubric
survived,"    def test_parse_answer_string_integration(self, think_parser):
        """"""Test parse_answer with string input.""""""
        text = ""<think>Calculating...</think>Result: 42""
        result = think_parser.parse_answer(text)
        assert result == ""Result: 42""",tests/test_think_parser.py,TestThinkParser
survived,"    async def test_rollout_chat_format(self, mock_singleturn_env):
        """"""Test rollout with chat format.""""""
        prompt = [{""role"": ""user"", ""content"": ""What is 2+2?""}]
        answer = ""4""
        
        completion, state = await mock_singleturn_env.rollout(
            client=mock_singleturn_env.client,
            model=""test-model"",
            prompt=prompt,
            answer=answer
        )
        
        # Should return list format for chat
        assert isinstance(completion, list)
        assert len(completion) == 1
        assert completion[0][""role""] == ""assistant""
        assert completion[0][""content""] == ""This is a test response""
        assert state == {}
        
        # Verify the client was called
        mock_singleturn_env.client.chat.completions.create.assert_called_once()
",tests/test_singleturn_env.py,TestSingleTurnEnv
survived,"    async def test_get_model_response_exception_handling(self, mock_openai_client):
        """"""Test exception handling in get_model_response.""""""
        # Mock an exception with context length error
        mock_openai_client.chat.completions.create = AsyncMock(
            side_effect=Exception(""Request longer than the maximum context length"")
        )
        
        env = TestEnvironment(
            client=mock_openai_client,
            model=""test-model"",
            eval_dataset=Dataset.from_dict({""question"": [""test""], ""answer"": [""test""]}),
            parser=Parser(),
            rubric=Rubric()
        )
        
        prompt = [{""role"": ""user"", ""content"": ""Hello""}]
        response = await env.get_model_response(
            prompt=prompt,
            client=mock_openai_client,
            model=""test-model""
        )
        
        assert response == ""[ERROR] prompt_too_long""
",tests/test_environment.py,TestEnvironmentBase
survived,"            def is_completed(self, messages, state, **kwargs):
                return state.get(""turn_count"", 0) >= 2
",tests/test_multiturn_env.py,TestMultiTurnEnv.StatefulMultiTurnEnv
survived,"    async def test_rollout_completion_format(self, mock_singleturn_env_completion):
        """"""Test rollout with completion format.""""""
        prompt = ""Calculate 2+2:""
        answer = ""4""
        
        completion, state = await mock_singleturn_env_completion.rollout(
            client=mock_singleturn_env_completion.client,
            model=""test-model"",
            prompt=prompt,
            answer=answer
        )
        
        # Should return string format for completion
        assert isinstance(completion, str)
        assert completion == ""This is a test completion""
        assert state == {}
        
        # Verify the client was called
        mock_singleturn_env_completion.client.completions.create.assert_called_once()
",tests/test_singleturn_env.py,TestSingleTurnEnv
survived,"    def test_format_method_with_alternatives(self, xml_parser_with_alternatives):
        """"""Test format method with alternative field names.""""""
        # Using canonical name
        formatted1 = xml_parser_with_alternatives.format(reasoning=""test"", code=""print('hello')"")
        assert ""<code>\nprint('hello')\n</code>"" in formatted1
        
        # Using alternative name
        formatted2 = xml_parser_with_alternatives.format(reasoning=""test"", answer=""print('hello')"")
        assert ""<code>\nprint('hello')\n</code>"" in formatted2  # Should use canonical tag
",tests/test_xml_parser.py,TestXMLParser
survived,"    def test_parse_xml_with_alternatives(self, xml_parser_with_alternatives):
        """"""Test parsing XML with alternative field names.""""""
        xml_text = """"""
        <reasoning>
        First, I need to understand the problem.
        </reasoning>
        <code>
        def solve(): return 42
        </code>
        """"""
        result = xml_parser_with_alternatives.parse(xml_text)
        assert result.reasoning == ""First, I need to understand the problem.""
        assert result.code == ""def solve(): return 42""
        # Both alternatives should be accessible
        assert hasattr(result, 'answer')
        assert result.answer is None
",tests/test_xml_parser.py,TestXMLParser
survived,"    def test_sanitize_sampling_args_remote_server(self, mock_openai_client):
        """"""Test sampling args sanitization for remote servers.""""""
        mock_openai_client.base_url = ""https://api.openai.com/v1/""
        
        env = TestEnvironment(
            client=mock_openai_client,
            model=""test-model"",
            eval_dataset=Dataset.from_dict({""question"": [""test""], ""answer"": [""test""]}),
            parser=Parser(),
            rubric=Rubric()
        )
        
        sampling_args = {
            ""temperature"": 0.7,
            ""extra_body"": {""skip_special_tokens"": True}
        }
        
        sanitized = env.sanitize_sampling_args(mock_openai_client, sampling_args)
        
        assert ""temperature"" in sanitized
        assert ""extra_body"" not in sanitized
",tests/test_environment.py,TestEnvironmentBase
survived,"    async def test_call_reward_func_with_subset_args(self):
        """"""Test calling reward function that only uses some arguments.""""""
        def simple_func(completion, answer, **kwargs):
            return 1.0 if completion == answer else 0.0
        
        rubric = Rubric(funcs=[], weights=[])
        
        result = await rubric.call_reward_func(
            func=simple_func,
            prompt=""irrelevant"",
            completion=""same"",
            answer=""same"",
            state={},
            task=""irrelevant"",
            info={}
        )
        
        assert result == 1.0
",tests/test_rubric.py,TestRubric
survived,"    async def test_call_reward_func_with_all_args(self):
        """"""Test calling reward function with all possible arguments.""""""
        def comprehensive_func(prompt, completion, answer, state, task, info, **kwargs):
            return len(completion) + len(answer) + len(task)
        
        rubric = Rubric(funcs=[], weights=[])
        
        result = await rubric.call_reward_func(
            func=comprehensive_func,
            prompt=""test prompt"",
            completion=""test completion"",
            answer=""test answer"",
            state={""key"": ""value""},
            task=""test task"",
            info={""info_key"": ""info_value""}
        )
        
        # len(""test completion"") + len(""test answer"") + len(""test task"")
        expected = len(""test completion"") + len(""test answer"") + len(""test task"")
        assert result == expected
",tests/test_rubric.py,TestRubric
survived,"    def test_parse_with_custom_extractor(self, think_parser_with_extractor):
        """"""Test parsing with custom extraction function.""""""
        text = """"""<think>
        I need to solve this step by step.
        </think>
        The answer is \\boxed{42}.""""""
        
        result = think_parser_with_extractor.parse(text)
        assert result == ""42""
",tests/test_think_parser.py,TestThinkParser
survived,"    def test_parse_answer_with_string(self, basic_parser):
        """"""Test parse_answer with string input.""""""
        text = ""This is an answer""
        result = basic_parser.parse_answer(text)
        assert result == text
",tests/test_parser.py,TestParser
survived,"    def test_rubric_group_initialization_empty_fails(self):
        """"""Test that RubricGroup initialization fails with empty rubrics list.""""""
        with pytest.raises(AssertionError, match=""RubricGroup must have at least one rubric""):
            RubricGroup(rubrics=[])
",tests/test_rubric_group.py,TestRubricGroup
survived,"        def length_func(completion, **kwargs):
            return len(str(completion))
",tests/test_rubric.py,TestRubric
survived,"    def test_parse_missing_fields(self, xml_parser):
        """"""Test parsing XML with missing fields.""""""
        xml_text = ""<reasoning>Only reasoning here</reasoning>""
        result = xml_parser.parse(xml_text)
        assert result.reasoning == ""Only reasoning here""
        assert result.answer is None
",tests/test_xml_parser.py,TestXMLParser
survived,"    def test_think_parser_with_custom_extractor(self, think_parser_with_extractor):
        """"""Test ThinkParser with custom extraction function.""""""
        assert isinstance(think_parser_with_extractor, ThinkParser)
",tests/test_think_parser.py,TestThinkParser
survived,"def mock_url_types():
    """"""
    Mock URL types with consistent UUIDs for testing.

    Returns a mock URLTypes object that returns consistent URL type objects
    for common URL type names.
    """"""
    url_types = MagicMock(spec=URLTypes)

    # Set up URL type attributes directly
    url_types.homepage = Mock(id=uuid.UUID(""00000000-0000-0000-0000-000000000001""))
    url_types.repository = Mock(id=uuid.UUID(""00000000-0000-0000-0000-000000000002""))
    url_types.documentation = Mock(id=uuid.UUID(""00000000-0000-0000-0000-000000000003""))
    url_types.source = Mock(id=uuid.UUID(""00000000-0000-0000-0000-000000000004""))

    return url_types
",tests/conftest.py,
survived,"def test_packages(ids):
    """"""Fixture providing test package objects.""""""
    return {
        ""package1"": Package(
            id=ids[""pkg1""],
            name=""package1"",
            package_manager_id=ids[""package_manager""],
            import_id=""pkg1"",
            derived_id=""npm/package1"",
            created_at=datetime.now(),
            updated_at=datetime.now(),
        ),
        ""package2"": Package(
            id=ids[""pkg2""],
            name=""package2"",
            package_manager_id=ids[""package_manager""],
            import_id=""pkg2"",
            derived_id=""npm/package2"",
            created_at=datetime.now(),
            updated_at=datetime.now(),
        ),
        ""package3"": Package(
            id=ids[""pkg3""],
            name=""package3"",
            package_manager_id=ids[""package_manager""],
            import_id=""pkg3"",
            derived_id=""npm/package3"",
            created_at=datetime.now(),
            updated_at=datetime.now(),
        ),
    }
",tests/ranker/test_dedupe.py,
survived,"def sample_package_data():
    """"""
    Provides sample package data for testing transformers and parsers.

    Returns a dict with sample data for different package managers.
    """"""
    return {
        ""crates"": {
            ""name"": ""serde"",
            ""version"": ""1.0.130"",
            ""description"": ""A generic serialization/deserialization framework"",
            ""homepage"": ""https://serde.rs"",
            ""repository"": ""https://github.com/serde-rs/serde"",
            ""dependencies"": {
                ""serde_derive"": ""1.0.130"",
            },
        },
        ""homebrew"": {
            ""name"": ""wget"",
            ""version"": ""1.21.2"",
            ""description"": ""Internet file retriever"",
            ""homepage"": ""https://www.gnu.org/software/wget/"",
            ""dependencies"": [""gettext"", ""libidn2"", ""openssl@1.1""],
        },
        ""debian"": {
            ""package"": ""curl"",
            ""version"": ""7.74.0-1.3+deb11u1"",
            ""maintainer"": ""Alessandro Ghedini <ghedo@debian.org>"",
            ""depends"": [""libc6"", ""libcurl4"", ""zlib1g""],
        },
        ""pkgx"": {
            ""full_name"": ""gnu.org/wget"",
            ""version"": ""1.21.2"",
            ""homepage"": ""https://www.gnu.org/software/wget/"",
            ""dependencies"": {
                ""gnu.org/gettext"": ""^0.21"",
                ""openssl.org"": ""^1.1"",
            },
        },
    }
",tests/conftest.py,
survived,"def mock_pm_config(mock_package_managers):
    """"""
    Mock PMConf (Package Manager Configuration) for testing.

    Returns a mock PMConf object with a default package manager ID.
    """"""
    pm_config = MagicMock(spec=PMConf)
    pm_config.pm_id = mock_package_managers.crates.id
    return pm_config
",tests/conftest.py,
survived,"    def test_go_interface_methods(self):
        # Note: Interface method regex is intentionally last in the list
        # because it's more general and could match other patterns
        patch = """"""
@@ -152,10 +152,6 @@ Read(p []byte) (n int, err error)

@@ -152,10 +152,6 @@ Write(p []byte) (n int, err error)

@@ -152,10 +152,6 @@ Close() error

@@ -152,10 +152,6 @@ String() string

@@ -152,10 +152,6 @@ ServeHTTP(ResponseWriter, *Request)

@@ -152,10 +152,6 @@ Validate() bool

""""""

        assert GoParser.extract_functions_from_patch(patch) == {
            ""Read"",
            ""Write"",
            ""Close"",
            ""String"",
            ""ServeHTTP"",
            ""Validate"",
        }
",tests/sentry/integrations/source_code_management/test_language_parsers.py,GoParserTestCase
survived,"def workflow_share(
        workflow_share: schemas.WorkflowShare,
        _: schemas.TokenPayload = Depends(get_current_active_user)) -> Any:
    """"""
    åˆ†äº«å·¥ä½œæµ
    """"""
    if not workflow_share.id or not workflow_share.share_title or not workflow_share.share_user:
        return schemas.Response(success=False, message=""è¯·å¡«å†™å·¥ä½œæµIDã€åˆ†äº«æ ‡é¢˜å’Œåˆ†äº«äºº"")
    
    state, errmsg = WorkflowHelper().workflow_share(workflow_id=workflow_share.id,
                                                    share_title=workflow_share.share_title or """",
                                                    share_comment=workflow_share.share_comment or """",
                                                    share_user=workflow_share.share_user or """")
    return schemas.Response(success=state, message=errmsg)
",app/api/endpoints/workflow.py,
survived,"    def get_shares(self, name: Optional[str] = None, page: Optional[int] = 1, count: Optional[int] = 30) -> List[dict]:
        """"""
        èŽ·å–å·¥ä½œæµåˆ†äº«æ•°æ®
        """"""
        if not settings.WORKFLOW_STATISTIC_SHARE:  # ä½¿ç”¨ç‹¬ç«‹çš„å·¥ä½œæµåˆ†äº«å¼€å…³
            return []
        
        res = RequestUtils(proxies=settings.PROXY or {}, timeout=15).get_res(self._workflow_shares, params={
            ""name"": name,
            ""page"": page,
            ""count"": count
        })
        if res and res.status_code == 200:
            return res.json()
        return []
",app/helper/workflow.py,WorkflowHelper
survived,"def test_top_level_start_session_with_mode(sentry_init, capture_envelopes):
    """"""Test that top-level start_session accepts session_mode parameter.""""""
    sentry_init(release=""test-release"", environment=""test-env"")
    envelopes = capture_envelopes()

    # Start a session with request mode
    sentry_sdk.start_session(session_mode=""request"")
    sentry_sdk.end_session()
    sentry_sdk.flush()

    # Request mode sessions are aggregated
    assert len(envelopes) == 1
    sess = envelopes[0]
    assert len(sess.items) == 1
    sess_event = sess.items[0].payload.json

    assert sess_event[""attrs""] == {
        ""release"": ""test-release"",
        ""environment"": ""test-env"",
    }
    # Request sessions show up as aggregates
    assert ""aggregates"" in sess_event",tests/test_sessions.py,
survived,"    def calculate_cost(
        cls,
        provider: str,
        model: str,
        token_usage_input: int,
        token_usage_output: int,
    ) -> float:
        """"""
        ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‹ã‚‰æŽ¨å®šã‚³ã‚¹ãƒˆã‚’è¨ˆç®—ã™ã‚‹

        Args:
            provider: LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼å
            model: ãƒ¢ãƒ‡ãƒ«å
            token_usage_input: å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡
            token_usage_output: å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡

        Returns:
            float: æŽ¨å®šã‚³ã‚¹ãƒˆï¼ˆUSDï¼‰
        """"""
        if provider not in cls.PRICING:
            return cls._calculate_with_price(
                cls.DEFAULT_PRICE, token_usage_input, token_usage_output
            )

        if model not in cls.PRICING[provider]:
            return cls._calculate_with_price(
                cls.DEFAULT_PRICE, token_usage_input, token_usage_output
            )

        price = cls.PRICING[provider][model]
        return cls._calculate_with_price(price, token_usage_input, token_usage_output)
",server/src/services/llm_pricing.py,LLMPricing
survived,"    def __init__(self, options: DexscreenerPluginOptions):
        super().__init__(""dexscreener"", [DexscreenerService()])
",python/src/plugins/dexscreener/goat_plugins/dexscreener/__init__.py,DexscreenerPlugin
survived,"    def supports_chain(self, chain) -> bool:
        return True
",python/src/plugins/nansen/goat_plugins/nansen/__init__.py,NansenPlugin
survived,"    def __init__(self, api_key: str, base_url: str = ""https://api.neynar.com/v2/farcaster""):
        self.api_key = api_key
        self.base_url = base_url
",python/src/plugins/farcaster/goat_plugins/farcaster/service.py,FarcasterService
survived,"    async def search_casts(self, parameters: dict):
        url = f""{self.base_url}/cast/search""
        return await self._make_request(""GET"", url, params={
            ""q"": parameters['query'],
            ""limit"": parameters.get('limit', 20)
        })
",python/src/plugins/farcaster/goat_plugins/farcaster/service.py,FarcasterService
survived,"    def is_small_company(self) -> bool:
        """"""Check if company has 5 or fewer employees.""""""
        return self.num_employees in [""1"", ""2-5""]
",pcweb/pages/pricing/header.py,QuoteFormState
survived,"def run_final_polars_code(reasoning: str, csv_path: str, polars_python_code: str, output_file: Optional[str] = None) -> str:
    """"""Executes the final Polars code and returns results to user.

    This is the last tool call the agent should make after validating the code.
    The code should be fully tested and ready for production use.
    Results will be displayed to the user and optionally saved to a file.

    Args:
        reasoning: Final explanation of how this code satisfies user request
        csv_path: Path to the CSV file
        polars_python_code: The validated Polars Python code to run. Should use pl.scan_csv() for lazy evaluation.
        output_file: Optional path to save results to. Use .csv or .json extension.

    Returns:
        Code execution results as a string

    Example:
        result = run_final_polars_code(
            ""Calculating average user age"",
            ""data.csv"",
            '''
            # Calculate average age using lazy evaluation
            result = df.select(pl.col(""age"").mean().alias(""avg_age"")).collect()
            print(""Average age:"", float(result[0, ""avg_age""]))
            ''',
            ""results.csv""
        )
    """"""
    try:
        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
            # Ensure code is properly indented
            indented_code = ""\n"".join(""    "" + line if line.strip() else line 
                                    for line in polars_python_code.splitlines())
            
            script = '''import polars as pl
import sys

try:
    # Read the CSV file using lazy evaluation
    df = pl.scan_csv(""{csv_path}"")
    
    # Execute the user's code
{code}
    
    # If no result was explicitly printed, try to collect and display
    if 'result' not in locals():
        if any(var for var in locals().values() if isinstance(var, (pl.LazyFrame, pl.DataFrame))):
            result = next(var for var in reversed(list(locals().values())) 
                      if isinstance(var, (pl.LazyFrame, pl.DataFrame)))
            if isinstance(result, pl.LazyFrame):
                result = result.collect()
        else:
            result = df.collect()
    
    # Handle output file if specified
    output_file = {output_file}
    if output_file:
        if isinstance(result, pl.DataFrame):
            if output_file.endswith('.csv'):
                result.write_csv(output_file)
            elif output_file.endswith('.json'):
                result.write_json(output_file)
            else:
                result.write_csv(output_file + '.csv')  # Default to CSV
        else:
            # For non-DataFrame results, create a single column DataFrame
            pl.DataFrame({{""result"": [str(result)]}}).write_csv(output_file)
        print(""Results written to "" + str(output_file))
    
    # Convert result to string for display
    if isinstance(result, pl.DataFrame):
        print(result.select(pl.all()).write_csv(None))
    else:
        print(str(result))
except Exception as e:
    print(""Error: "" + str(e), file=sys.stderr)
    sys.exit(1)
'''
            script_content = script.format(
                csv_path=csv_path,
                code=indented_code,
                output_file=repr(output_file) if output_file else 'None'
            )
            f.write(script_content)
            temp_file = f.name
            temp_file = f.name

        result = subprocess.run(['uv', 'run', '--with', 'polars', temp_file],
                              capture_output=True, text=True)
        os.unlink(temp_file)

        if result.returncode != 0:
            return f""Error: {result.stderr}""

        console.log(
            Panel(
                f""[green]Final Code Tool[/green]\nReasoning: {reasoning}\nCode:\n{polars_python_code}""
            )
        )
        return result.stdout
    except Exception as e:
        console.log(f""[red]Error running final code: {str(e)}[/red]"")
        return str(e)
",sfa_polars_csv_agent_openai_v2.py,
survived,"def get_pose_params_from_mat(mat_path):
    mat = sio.loadmat(mat_path)
    pre_pose_params = mat['Pose_Para'][0]
    pose_params = pre_pose_params[:5]
    return pose_params
",face_recognition/6d_repnet_360/utils_6d_repnet_360/utils.py,
survived,"def compute_rotation_matrix_from_ortho6d(poses, use_gpu=False):
    x_raw = poses[:, 0:3]
    y_raw = poses[:, 3:6]

    x = normalize_vector(x_raw, use_gpu)
    z = cross_product(x, y_raw)
    z = normalize_vector(z, use_gpu)
    y = cross_product(z, x)

    x = x.view(-1, 3, 1)
    y = y.view(-1, 3, 1)
    z = z.view(-1, 3, 1)
    matrix = torch.cat((x, y, z), 2)
    return matrix
",face_recognition/6d_repnet_360/utils_6d_repnet_360/utils.py,
survived,"def transform(img, mean, std):
    img = np.array(img)
    img = img.transpose(2, 0, 1)
    img = img / 255
    output = []
    for im, me, st in zip(img, mean, std):
        out = (im - me) / st
        output.append(out)
    return np.array(output)
",face_recognition/6d_repnet_360/utils_6d_repnet_360/utils.py,
survived,"def normalize_vector(v, use_gpu=True):
    batch = v.shape[0]
    v_mag = torch.sqrt(v.pow(2).sum(1))
    if use_gpu:
        v_mag = torch.max(v_mag, torch.autograd.Variable(torch.FloatTensor([1e-8])))
    else:
        v_mag = torch.max(v_mag, torch.autograd.Variable(torch.FloatTensor([1e-8])))
    v_mag = v_mag.view(batch, 1).expand(batch, v.shape[1])
    v = v / v_mag
    return v
",face_recognition/6d_repnet_360/utils_6d_repnet_360/utils.py,
survived,"def test_mistral_integration():
    """"""Integration test demonstrating all four Mistral call patterns:
    1. Sync (non-streaming)
    2. Sync (streaming)
    3. Async (non-streaming)
    4. Async (streaming)

    Verifies that AgentOps correctly tracks all LLM calls via analytics.
    """"""
    # Initialize AgentOps without auto-starting session
    agentops.init(auto_start_session=False)
    session = agentops.start_session()

    # Initialize client and provider
    client = MistralClient(api_key=os.getenv(""MISTRAL_API_KEY""))
    from agentops.llms.providers.mistral import MistralProvider
    provider = MistralProvider(client)
    provider.override()
    
    # Pass session to provider
    provider.client = session

    def sync_no_stream():
        client.chat(
            model=""mistral-tiny"",
            messages=[ChatMessage(role=""user"", content=""Hello from sync no stream"")]
        )

    async def sync_stream():
        stream_response = await client.chat_stream(
            model=""mistral-tiny"",
            messages=[ChatMessage(role=""user"", content=""Hello from sync streaming"")]
        )
        async for chunk in stream_response:
            _ = chunk.delta.content if hasattr(chunk.delta, 'content') else ''

    async def async_no_stream():
        # Mistral doesn't have async methods, use sync
        client.chat(
            model=""mistral-tiny"",
            messages=[ChatMessage(role=""user"", content=""Hello from async no stream"")]
        )

    async def async_stream():
        stream_response = await client.chat_stream(
            model=""mistral-tiny"",
            messages=[ChatMessage(role=""user"", content=""Hello from async streaming"")]
        )
        async for chunk in stream_response:
            _ = chunk.delta.content if hasattr(chunk.delta, 'content') else ''

    async def run_async_tests():
        await async_no_stream()
        await async_stream()

    # Call each function with proper error handling
    try:
        sync_no_stream()
        asyncio.run(sync_stream())
        asyncio.run(run_async_tests())
    except Exception as e:
        print(f""Error during Mistral test: {str(e)}"")
        raise

    session.end_session(""Success"")
    analytics = session.get_analytics()
    print(analytics)
    # Verify that all LLM calls were tracked
    assert analytics[""LLM calls""] >= 4, f""Expected at least 4 LLM calls, but got {analytics['LLM calls']}""
",tests/core_manual_tests/providers/mistral_canary.py,
survived,"    async def async_no_stream():
        # Mistral doesn't have async methods, use sync
        client.chat(
            model=""mistral-tiny"",
            messages=[ChatMessage(role=""user"", content=""Hello from async no stream"")]
        )
",tests/core_manual_tests/providers/mistral_canary.py,
survived,"def main(_):
  """"""Main function to run the tests.""""""
  print(""Running single-threaded test..."")
  single_thread_data = test_dataset_creation(threads=1)

  print(""\nRunning parallel test..."")
  parallel_data = test_parallel_dataset_creation()

  assert len(single_thread_data) == len(parallel_data), (
    f""Single-threaded ({len(single_thread_data)} entries) and ""
    f""parallel ({len(parallel_data)} entries) results differ""
  )

  print(""\nAll tests passed!"")
  return 0
",tests/dataset_creation_test.py,
survived,"def determine_if_file_is_relevant(prompt: str, file_path: str, client: Anthropic) -> Dict[str, Any]:
    """"""Determines if a single file is relevant to the prompt.
    
    Args:
        prompt: The user prompt
        file_path: Path to the file to check
        client: Anthropic client
        
    Returns:
        Dictionary with reasoning and is_relevant flag
    """"""
    result = {
        ""reasoning"": ""Error: Could not process file"",
        ""file_path"": file_path,
        ""is_relevant"": False
    }
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            file_content = f.read()
        
        # Truncate file content if it's too long
        if len(file_content) > 10000:
            file_content = file_content[:10000] + ""... [content truncated]""
        
        file_prompt = f""""""
        <purpose>
        You are a codebase context builder. Your task is to determine if a file is relevant to a user query.
        </purpose>
        
        <instructions>
        <instruction>Analyze the file content and determine if it's relevant to the user query.</instruction>
        <instruction>Provide clear reasoning for your decision.</instruction>
        <instruction>Return a structured output with your reasoning and a boolean indicating relevance.</instruction>
        </instructions>
        
        <user-query>
        {prompt}
        </user-query>
        
        <file-path>
        {file_path}
        </file-path>
        
        <file-content>
        {file_content}
        </file-content>
        """"""
        
        for attempt in range(MAX_RETRIES):
            try:
                response = client.messages.create(
                    model=""claude-3-7-sonnet-20250219"",
                    max_tokens=3000,  # Increased to be greater than thinking.budget_tokens
                    thinking={
                        ""type"": ""enabled"",
                        ""budget_tokens"": THINKING_BUDGET_TOKENS_PER_FILE
                    },
                    messages=[{""role"": ""user"", ""content"": file_prompt}],
                    system=""Determine if the file is relevant to the user query. Return a JSON object with 'reasoning' and 'is_relevant' fields.""
                )
                
                # Parse the response
                response_text = response.content[0].text
                result = json.loads(response_text)
                
                return {
                    ""reasoning"": result.get(""reasoning"", ""No reasoning provided""),
                    ""file_path"": file_path,
                    ""is_relevant"": result.get(""is_relevant"", False)
                }
            except Exception as e:
                if attempt < MAX_RETRIES - 1:
                    console.log(f""[yellow]Retry {attempt + 1}/{MAX_RETRIES} for {file_path}: {str(e)}[/yellow]"")
                    time.sleep(RETRY_WAIT)
                else:
                    console.log(f""[red]Failed to determine relevance for {file_path}: {str(e)}[/red]"")
                    return {
                        ""reasoning"": f""Error: {str(e)}"",
                        ""file_path"": file_path,
                        ""is_relevant"": False
                    }
    except Exception as e:
        console.log(f""[red]Error processing file {file_path}: {str(e)}[/red]"")
        return {
            ""reasoning"": f""Error: {str(e)}"",
            ""file_path"": file_path,
            ""is_relevant"": False
        }
",sfa_codebase_context_agent_v3.py,
survived,"    def supports_chain(self, chain) -> bool:
        return chain['type'] == 'solana'
",python/src/plugins/jupiter/goat_plugins/jupiter/__init__.py,JupiterPlugin
survived,"def jupiter(options: JupiterPluginOptions) -> JupiterPlugin:
    return JupiterPlugin(options)",python/src/plugins/jupiter/goat_plugins/jupiter/__init__.py,
survived,"    async def _run(self) -> StepResult:
        connector = self.context.connector
        manifest_path = connector.manifest_path
        python_path = connector.python_source_dir_path
        if connector.language not in [
            ConnectorLanguage.PYTHON,
            ConnectorLanguage.LOW_CODE,
            ConnectorLanguage.MANIFEST_ONLY,
        ]:
            return StepResult(
                step=self,
                status=StepStatus.SKIPPED,
                stderr=""The connector is not a Python connector."",
            )
        if connector.connector_type != ""source"":
            return StepResult(
                step=self,
                status=StepStatus.SKIPPED,
                stderr=""The connector is not a source connector."",
            )

        if not manifest_path.is_file():
            return StepResult(
                step=self,
                status=StepStatus.SKIPPED,
                stderr=""The connector does not have a manifest file."",
            )

        schemas_dir = python_path / SCHEMAS_DIR_NAME
        if not schemas_dir.is_dir():
            return StepResult(
                step=self,
                status=StepStatus.SKIPPED,
                stderr=""The connector does not have a schemas directory."",
            )

        # TODO: does this help or not?
        # if _has_subdirectory(schemas_dir):
        #     return StepResult(step=self, status=StepStatus.SKIPPED, stderr=""This has subdirectories. It's probably complicated."")

        return StepResult(
            step=self,
            status=StepStatus.SUCCESS,
        )
",airbyte-ci/connectors/pipelines/pipelines/airbyte_ci/connectors/migrate_to_inline_schemas/pipeline.py,CheckIsInlineCandidate
survived,"    def pause_live_updates(self) -> None:
        """"""Pause Live session updates to allow for human input without interference.""""""
        if not self._live_paused:
            if self._live:
                self._live.stop()
                self._live = None
            self._live_paused = True
",src/crewai/utilities/events/utils/console_formatter.py,ConsoleFormatter
survived,"    def test_pause_live_updates_with_no_session(self):
        """"""Test pausing when no Live session exists.""""""
        formatter = ConsoleFormatter()
        
        formatter._live = None
        formatter._live_paused = False
        
        formatter.pause_live_updates()
        
        assert formatter._live_paused
",tests/utilities/test_console_formatter_pause_resume.py,TestConsoleFormatterPauseResume
survived,"def test_convert_with_yes_flag(tmp_path: Path) -> None:
    """"""Test convert command with -y flag to automatically overwrite files.""""""
    # Create a notebook file
    notebook_path = tmp_path / ""test_notebook.ipynb""
    notebook_content = """"""
    {
     ""cells"": [
      {
       ""cell_type"": ""code"",
       ""execution_count"": null,
       ""metadata"": {},
       ""outputs"": [],
       ""source"": [
        ""print('Hello, World!')""
       ]
      }
     ],
     ""metadata"": {},
     ""nbformat"": 4,
     ""nbformat_minor"": 4
    }
    """"""
    notebook_path.write_text(notebook_content)
    
    # Create an existing output file
    output_path = tmp_path / ""output.py""
    output_path.write_text(""existing content"")
    
    # Use the -y flag to verify that the file can be overwritten without prompting
    result = subprocess.run(
        [
            ""marimo"",
            ""-y"",
            ""convert"",
            str(notebook_path),
            ""-o"",
            str(output_path),
        ],
        capture_output=True,
        text=True,
    )
    
    # Check that the command completed successfully
    assert result.returncode == 0
    
    # Verify the file was overwritten with -y flag
    assert output_path.read_text() != ""existing content""
    
    # Verify there was no prompt in the output
    assert ""Warning: The file"" not in result.stdout
    assert ""Overwrite?"" not in result.stdout",tests/_cli/test_file_overwrite.py,
survived,"    def to_dict(self) -> Dict[str, Any]:
        """"""
        Convert the security config to a dictionary.

        Returns:
            Dict[str, Any]: Dictionary representation of the security config
        """"""
        result = {
            ""fingerprint"": self.fingerprint.to_dict()
        }
        return result
",src/crewai/security/security_config.py,SecurityConfig
survived,"def create_sink_connection(config: Mapping[str, Any]) -> PipelineDataSink:
    pipeline_id = config.get(""pipeline_id"")
    pipeline_access_token = config.get(""pipeline_access_token"")

    return PipelineDataSink(pipeline_id=pipeline_id, pipeline_access_token=pipeline_access_token)
",airbyte-integrations/connectors/destination-glassflow/destination_glassflow/destination.py,
survived,"def _record(stream: str, data: Dict[str, Any]) -> AirbyteMessage:
    return AirbyteMessage(type=Type.RECORD, record=AirbyteRecordMessage(stream=stream, data=data, emitted_at=0))
",airbyte-integrations/connectors/destination-glassflow/unit_tests/unit_test.py,
survived,"def _configured_catalog() -> ConfiguredAirbyteCatalog:
    stream_schema = {""type"": ""object"", ""properties"": {}}
    append_stream = ConfiguredAirbyteStream(
        stream=AirbyteStream(name=""test"", json_schema=stream_schema, supported_sync_modes=[SyncMode.full_refresh]),
        sync_mode=SyncMode.full_refresh,
        destination_sync_mode=DestinationSyncMode.append,
    )
    return ConfiguredAirbyteCatalog(streams=[append_stream])
",airbyte-integrations/connectors/destination-glassflow/unit_tests/unit_test.py,
survived,"def test_check_fails(client):
    pipeline = _init_mocks(client)
    pipeline.validate_credentials.side_effect = errors.PipelineAccessTokenInvalidError(mock.Mock())
    destination = DestinationGlassflow()
    status = destination.check(logger=Mock(), config=config)
    assert status.status == Status.FAILED
",airbyte-integrations/connectors/destination-glassflow/unit_tests/unit_test.py,
survived,"def test_rename_with_special_chars(app_file_manager: AppFileManager) -> None:
    """"""Test that renaming files with special characters works on Windows.""""""
    # Create a temporary file
    temp_dir = tempfile.mkdtemp()
    try:
        initial_path = os.path.join(temp_dir, ""test.py"")
        with open(initial_path, ""w"") as f:
            f.write(""import marimo"")
        app_file_manager.filename = initial_path
        
        # Try to rename to path with special characters
        new_path = os.path.join(temp_dir, ""test & space.py"")
        app_file_manager.rename(new_path)
        assert app_file_manager.filename == new_path
        assert os.path.exists(new_path)
    finally:
        shutil.rmtree(temp_dir)",tests/_server/test_file_manager.py,
survived,"def test_default_unlimited_usage():
    """"""Test that tools have unlimited usage by default.""""""
    @tool(""Default Tool"")
    def default_tool(input_text: str) -> str:
        """"""A default tool.""""""
        return f""Result: {input_text}""
    
    assert default_tool.max_usage_count is None
    assert default_tool.current_usage_count == 0",tests/tools/test_tool_usage_limit.py,
survived,"    def test_init_with_max_size_zero(self) -> None:
        """"""Test initialization with max_size=0.""""""
        loader = MemoryLoader(""test"", max_size=0)
        assert loader.max_size == 0
        assert loader.is_lru is False
        assert not isinstance(loader._cache, OrderedDict)
        assert loader._cache_lock is None
",tests/_save/loaders/test_memory_loader.py,TestMemoryLoader
survived,"    def cache_hit(self, hashed_context: str, cache_type: str) -> bool:
        key = f""{cache_type}_{hashed_context}""
        return key in self.saved_caches
",tests/_save/loaders/test_loader.py,MockLoader
survived,"    def test_call(self) -> None:
        """"""Test calling the partial to create a loader.""""""
        partial = LoaderPartial(MockLoader, config_value=""custom"")
        loader = partial(""test_name"")
        
        assert isinstance(loader, MockLoader)
        assert loader.name == ""test_name""
        assert loader.config_value == ""custom""
",tests/_save/loaders/test_loader.py,TestLoaderPartial
survived,"    def _get_current_schema(self) -> list:
        """"""Get the current schema of the runs table from the database.

        Returns:
            list: List of tuples containing column information.
                  Each tuple contains (cid, name, type, notnull, dflt_value, pk)
        """"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            cursor.execute(""PRAGMA table_info(runs)"")
            schema_info = cursor.fetchall()
        return schema_info
",src/bespokelabs/curator/db.py,MetadataDB
survived,"def create_init_file(goat_plugins_dir: Path, plugin_name: str, is_evm: bool) -> None:
    """"""Create the __init__.py file with plugin class.""""""
    class_name = f""{plugin_name.title()}Service""
    plugin_class = f""{plugin_name.title()}Plugin""
    options_class = f""{plugin_name.title()}PluginOptions""
    
    init_content = '''from dataclasses import dataclass
from goat.classes.plugin_base import PluginBase
from .service import {class_name}


@dataclass
class {options_class}:
    """"""Options for the {plugin_class}.""""""
    api_key: str  # API key for external service integration


class {plugin_class}(PluginBase):
    def __init__(self, options: {options_class}):
        super().__init__(""{plugin_name}"", [{class_name}(options.api_key)])

    def supports_chain(self, chain) -> bool:
        return {supports_chain}


def {plugin_name}(options: {options_class}) -> {plugin_class}:
    return {plugin_class}(options)
'''.format(
        class_name=class_name,
        plugin_class=plugin_class,
        options_class=options_class,
        plugin_name=plugin_name,
        supports_chain=""chain['type'] == 'evm'"" if is_evm else ""True""
    )

    with open(goat_plugins_dir / ""__init__.py"", ""w"") as f:
        f.write(init_content)
",python/create_plugin.py,
survived,"def create_service_file(goat_plugins_dir: Path, plugin_name: str, is_evm: bool) -> None:
    """"""Create the service.py file with an empty tool.""""""
    # Start with common imports
    service_content = '''from goat.decorators.tool import Tool
from .parameters import ExampleQueryParameters, ExampleActionParameters
'''

    # Add EVM-specific imports if needed
    if is_evm:
        service_content += '''from goat_wallets.evm import EVMWalletClient

'''

    # Create the service class
    class_name = f""{plugin_name.title()}Service""
    service_content += f'''
class {class_name}:
    def __init__(self, api_key: str):
        self.api_key = api_key

    @Tool({{
        ""description"": ""Example query tool that demonstrates parameter usage"",
        ""parameters_schema"": ExampleQueryParameters
    }})
    async def example_query(self{"", wallet_client: EVMWalletClient"" if is_evm else """"}, parameters: dict):
        """"""An example query method that shows how to use parameters.""""""
        try:
            # Example implementation
            query = parameters[""query""]
            limit = parameters.get(""limit"")
            include_metadata = parameters.get(""include_metadata"", False)
            
            # Placeholder for actual implementation
            return {{""status"": ""success"", ""query"": query, ""limit"": limit, ""metadata_included"": include_metadata}}
        except Exception as error:
            raise Exception(f""Failed to execute query: {{error}}"")

    @Tool({{
        ""description"": ""Example action tool that demonstrates parameter usage"",
        ""parameters_schema"": ExampleActionParameters
    }})
    async def example_action(self{"", wallet_client: EVMWalletClient"" if is_evm else """"}, parameters: dict):
        """"""An example action method that shows how to use parameters.""""""
        try:
            # Example implementation
            target_id = parameters[""target_id""]
            action_type = parameters[""action_type""]
            action_params = parameters.get(""parameters"", {{}})
            
            # Placeholder for actual implementation
            return {{""status"": ""success"", ""action"": action_type, ""target"": target_id, ""params"": action_params}}
        except Exception as error:
            raise Exception(f""Failed to execute action: {{error}}"")
'''

    with open(goat_plugins_dir / ""service.py"", ""w"") as f:
        f.write(service_content)
",python/create_plugin.py,
survived,"    def __init__(self, **data):
        """"""Initialize a Fingerprint with auto-generated uuid_str and created_at.""""""
        # Remove uuid_str and created_at from data to ensure they're auto-generated
        if 'uuid_str' in data:
            data.pop('uuid_str')
        if 'created_at' in data:
            data.pop('created_at')

        # Call the parent constructor with the modified data
        super().__init__(**data)
",src/crewai/security/fingerprint.py,Fingerprint
survived,"    def uuid(self) -> uuid.UUID:
        """"""Get the UUID object for this fingerprint.""""""
        return uuid.UUID(self.uuid_str)
",src/crewai/security/fingerprint.py,Fingerprint
survived,"def test_telemetry_disable_after_singleton_creation():
    """"""Test that telemetry operations are disabled when env var is set after singleton creation.""""""
    Telemetry._instance = None
    
    with patch.dict(os.environ, {}, clear=True):
        with patch(""crewai.telemetry.telemetry.TracerProvider""):
            telemetry = Telemetry()
            assert telemetry.ready is True
            
            mock_operation = MagicMock()
            telemetry._safe_telemetry_operation(mock_operation)
            mock_operation.assert_called_once()
            
            mock_operation.reset_mock()
            
            os.environ['CREWAI_DISABLE_TELEMETRY'] = 'true'
            
            telemetry._safe_telemetry_operation(mock_operation)
            mock_operation.assert_not_called()
",tests/telemetry/test_telemetry_disable.py,
survived,"    def _start_subprocess(self):
        """"""Start the reflex app using subprocess instead of threads.""""""
        backend_port = reflex.utils.processes.handle_port(
            ""backend"", 8000, auto_increment=True
        )
        frontend_port = reflex.utils.processes.handle_port(
            ""frontend"", 3000, auto_increment=True
        )

        self.reflex_process = reflex.utils.processes.new_process(
            [
                sys.executable,
                ""-m"",
                ""reflex"",
                ""run"",
                ""--backend-port"",
                str(backend_port),
                ""--frontend-port"",
                str(frontend_port),
                ""--env"",
                ""dev"",
            ],
            cwd=self.app_path,
            env={""NO_COLOR"": ""1""},
        )

        self.backend_port = backend_port
        self.frontend_port = frontend_port

        self._wait_for_servers()
",reflex/testing.py,AppHarness
survived,"    def test_require_api_key_config(self, mock_get_context: MagicMock) -> None:
        """"""Test _require_api_key with config.""""""
        mock_context = MagicMock()
        mock_context.marimo_config = {""ai"": {""open_ai"": {""api_key"": ""config-key""}}}
        mock_get_context.return_value = mock_context

        model = openai(""gpt-4"")
        assert model._require_api_key == ""config-key""
",tests/_ai/llm/_impl.py,TestOpenAI
survived,"    def test_require_api_key_missing(self, mock_get_context: MagicMock) -> None:
        """"""Test _require_api_key with missing key.""""""
        mock_context = MagicMock()
        mock_context.marimo_config = {""ai"": {""anthropic"": {""api_key"": """"}}}
        mock_get_context.return_value = mock_context

        model = anthropic(""claude-3-opus-20240229"")
        with pytest.raises(ValueError):
            _ = model._require_api_key",tests/_ai/llm/_impl.py,TestAnthropic
survived,"    def test_require_api_key_missing(self, mock_get_context: MagicMock) -> None:
        """"""Test _require_api_key with missing key.""""""
        mock_context = MagicMock()
        mock_context.marimo_config = {""ai"": {""google"": {""api_key"": """"}}}
        mock_get_context.return_value = mock_context

        model = google(""gemini-pro"")
        with pytest.raises(ValueError):
            _ = model._require_api_key
",tests/_ai/llm/_impl.py,TestGoogle
deleted,"    def test_unknown_error(self) -> None:
        error = UnknownError(msg=""Something went wrong"")

        # Test properties
        assert error.type == ""unknown""
        assert error.describe() == ""Something went wrong""
",tests/_messaging/test_errors.py,TestErrorClasses
survived,"    def test_stdout_write(self) -> None:
        stdout = self.MockStdout()

        # Test write method
        result = stdout.write(""Hello, world!"")

        # Should return the length of the string
        assert result == 13

        # Should call _write_with_mimetype with text/plain mimetype
        assert len(stdout.written_data) == 1
        assert stdout.written_data[0] == (""Hello, world!"", ""text/plain"")
",tests/_messaging/test_types.py,TestStdoutStderr
deleted,"    def test_cycle_error(self) -> None:
        # Create a cycle error with mock edges
        # EdgeWithVar is a tuple of (start_cell_id, variables, end_cell_id)
        edge1 = (""cell1"", [""var1""], ""cell2"")
        edge2 = (""cell2"", [""var2""], ""cell1"")

        error = CycleError(edges_with_vars=(edge1, edge2))

        # Test properties
        assert error.type == ""cycle""
        assert ""cycle"" in error.describe().lower()
        assert isinstance(error.describe(), str)
",tests/_messaging/test_errors.py,TestErrorClasses
deleted,"    def test_marimo_ancestor_prevented_error(self) -> None:
        error = MarimoAncestorPreventedError(
            msg=""Execution prevented by ancestor"",
            raising_cell=""cell1"",
            blamed_cell=""cell2"",
        )

        # Test properties
        assert error.type == ""ancestor-prevented""
        assert error.describe() == ""Execution prevented by ancestor""
        assert error.raising_cell == ""cell1""
        assert error.blamed_cell == ""cell2""
",tests/_messaging/test_errors.py,TestErrorClasses
survived,"    def test_mime_bundle_or_tuple(self) -> None:
        # Test that MimeBundleOrTuple can be used as a type annotation
        def accepts_mime_bundle_or_tuple(
            bundle_or_tuple: MimeBundleOrTuple
        ) -> MimeBundleOrTuple:
            return bundle_or_tuple

        # Test with a bundle
        bundle: MimeBundle = {""text/plain"": ""Hello, world!""}
        assert accepts_mime_bundle_or_tuple(bundle) == bundle

        # Test with a tuple
        metadata = {""key"": ""value""}
        bundle_tuple: tuple[MimeBundle, Any] = (bundle, metadata)
        assert accepts_mime_bundle_or_tuple(bundle_tuple) == bundle_tuple",tests/_messaging/test_mimetypes.py,TestMimeTypes
survived,"    def test_stdout_name(self) -> None:
        stdout = self.MockStdout()
        assert stdout.name == ""stdout""
",tests/_messaging/test_types.py,TestStdoutStderr
deleted,"    def test_is_unexpected_error(self) -> None:
        # These errors are expected/intentional
        assert not is_unexpected_error(MarimoAncestorPreventedError(
            msg="""", raising_cell=""cell1"", blamed_cell=None
        ))
        assert not is_unexpected_error(MarimoAncestorStoppedError(
            msg="""", raising_cell=""cell1""
        ))
        assert not is_unexpected_error(MarimoInterruptionError())

        # These errors are unexpected
        assert is_unexpected_error(MarimoExceptionRaisedError(
            msg="""", exception_type="""", raising_cell=None
        ))
        assert is_unexpected_error(MarimoSyntaxError(msg=""""))
        assert is_unexpected_error(UnknownError(msg=""""))
",tests/_messaging/test_errors.py,TestErrorUtilityFunctions
survived,"def test_utf8() -> None:
    """"""Test the _utf8 function.""""""
    # Test with UTF8 supported
    with patch(""marimo._server.print.UTF8_SUPPORTED"", True):
        assert _utf8(""ðŸŒŠðŸƒ"") == ""ðŸŒŠðŸƒ""
    
    # Test with UTF8 not supported
    with patch(""marimo._server.print.UTF8_SUPPORTED"", False):
        assert _utf8(""ðŸŒŠðŸƒ"") == """"
",tests/_server/test_print.py,
survived,"    async def swap_tokens(self, wallet_client: EVMWalletClient, parameters: dict):
        """"""Execute a token swap on Uniswap.""""""
        try:
            quote = await self.get_quote(wallet_client, parameters)
            
            response = await self.make_request(""swap"", {
                ""quote"": quote[""quote""]
            })
            
            swap = response[""swap""]
            transaction = await wallet_client.send_transaction({
                ""to"": swap[""to""],
                ""value"": swap[""value""],
                ""data"": swap[""data""]
            })

            return {
                ""txHash"": transaction[""hash""]
            }
        except Exception as error:
            raise Exception(f""Failed to execute swap: {error}"")",python/src/plugins/uniswap/goat_plugins/uniswap/service.py,UniswapService
survived,"    def __init__(self, api_key: str, base_url: str = ""https://api.uniswap.org/v2""):
        self.api_key = api_key
        self.base_url = base_url
",python/src/plugins/uniswap/goat_plugins/uniswap/service.py,UniswapService
deleted,"def test_multiple_tasks_with_conditional():
    """"""Test that having multiple tasks before a conditional task works correctly.""""""
    task1 = Task(
        description=""Research task 1"",
        expected_output=""Research output"",
        agent=researcher,
    )
    task2 = Task(
        description=""Research task 2"",
        expected_output=""Research output"",
        agent=researcher,
    )
    
    def condition_func(task_output: TaskOutput) -> bool:
        return ""success"" in task_output.raw.lower()
    
    task3 = ConditionalTask(
        description=""Conditional task that runs if previous task succeeded"",
        expected_output=""Conditional output"",
        agent=writer,
        condition=condition_func,
    )

    crew = Crew(
        agents=[researcher, writer],
        tasks=[task1, task2, task3],
    )

    # Mock task outputs
    mock_success = TaskOutput(
        description=""Mock success"",
        raw=""Success output"",
        agent=researcher.role,
    )
    
    # Set up mocks for task execution
    with patch.object(Task, ""execute_sync"", return_value=mock_success) as mock_execute:
        result = crew.kickoff()
        # Verify all tasks were executed (no IndexError)
        assert mock_execute.call_count == 3
        assert len(result.tasks_output) == 3
",tests/crew_test.py,
survived,"    def condition2(task_output: TaskOutput) -> bool:
        return ""proceed"" in task_output.raw.lower()
",tests/crew_test.py,
survived,"def test_custodial_wallet_invalid_options(custodial_api, invalid_options, solana_connection):
    """"""Test error handling with invalid options.""""""
    with pytest.raises(Exception) as exc:
        custodial_api.create_custodial_wallet(list(invalid_options.values())[0])
    assert ""error"" in str(exc.value).lower() or ""invalid"" in str(exc.value).lower()
",python/src/wallets/crossmint/tests/test_custodial_wallet.py,
survived,"def test_error_handling_not_found(custodial_api):
    """"""Test error handling for non-existent wallet.""""""
    with pytest.raises(Exception) as exc:
        custodial_api.get_wallet(""invalid:wallet:id"")
    assert ""Error"" in str(exc.value)
    assert ""404"" in str(exc.value)
",python/src/wallets/crossmint/tests/test_api_client.py,
survived,"def test_email():
    """"""Fixture providing test email for wallet creation.""""""
    return ""test@example.com""
",python/src/wallets/crossmint/tests/conftest.py,
survived,"def get_generic_json_schema() -> Dict:
    generic_schema = """"""
        {
        ""$schema"": ""http://json-schema.org/draft-07/schema#"",
        ""type"": ""object"",
        ""properties"": {
            ""type"": {
            ""type"": ""string""
            },
            ""id"": {
            ""type"": ""string""
            },
            ""file_version"": {
            ""type"": ""object"",
            ""properties"": {
                ""type"": {
                ""type"": ""string""
                },
                ""id"": {
                ""type"": ""string""
                },
                ""sha1"": {
                ""type"": ""string""
                }
            },
            ""required"": [""type"", ""id"", ""sha1""]
            },
            ""sequence_id"": {
            ""type"": ""string""
            },
            ""etag"": {
            ""type"": ""string""
            },
            ""sha1"": {
            ""type"": ""string""
            },
            ""name"": {
            ""type"": ""string""
            },
            ""description"": {
            ""type"": ""string""
            },
            ""size"": {
            ""type"": ""integer""
            },
            ""path_collection"": {
            ""type"": ""object"",
            ""properties"": {
                ""total_count"": {
                ""type"": ""integer""
                },
                ""entries"": {
                ""type"": ""array"",
                ""items"": [
                    {
                    ""type"": ""object"",
                    ""properties"": {
                        ""type"": {
                        ""type"": ""string""
                        },
                        ""id"": {
                        ""type"": ""string""
                        },
                        ""sequence_id"": {
                        ""type"": ""null""
                        },
                        ""etag"": {
                        ""type"": ""null""
                        },
                        ""name"": {
                        ""type"": ""string""
                        }
                    },
                    ""required"": [""type"", ""id"", ""sequence_id"", ""etag"", ""name""]
                    },
                    {
                    ""type"": ""object"",
                    ""properties"": {
                        ""type"": {
                        ""type"": ""string""
                        },
                        ""id"": {
                        ""type"": ""string""
                        },
                        ""sequence_id"": {
                        ""type"": ""string""
                        },
                        ""etag"": {
                        ""type"": ""string""
                        },
                        ""name"": {
                        ""type"": ""string""
                        }
                    },
                    ""required"": [""type"", ""id"", ""sequence_id"", ""etag"", ""name""]
                    },
                    {
                    ""type"": ""object"",
                    ""properties"": {
                        ""type"": {
                        ""type"": ""string""
                        },
                        ""id"": {
                        ""type"": ""string""
                        },
                        ""sequence_id"": {
                        ""type"": ""string""
                        },
                        ""etag"": {
                        ""type"": ""string""
                        },
                        ""name"": {
                        ""type"": ""string""
                        }
                    },
                    ""required"": [""type"", ""id"", ""sequence_id"", ""etag"", ""name""]
                    }
                ]
                }
            },
            ""required"": [""total_count"", ""entries""]
            },
            ""created_at"": {
            ""type"": ""string""
            },
            ""modified_at"": {
            ""type"": ""string""
            },
            ""trashed_at"": {
            ""type"": ""null""
            },
            ""purged_at"": {
            ""type"": ""null""
            },
            ""content_created_at"": {
            ""type"": ""string""
            },
            ""content_modified_at"": {
            ""type"": ""string""
            },
            ""created_by"": {
            ""type"": ""object"",
            ""properties"": {
                ""type"": {
                ""type"": ""string""
                },
                ""id"": {
                ""type"": ""string""
                },
                ""name"": {
                ""type"": ""string""
                },
                ""login"": {
                ""type"": ""string""
                }
            },
            ""required"": [""type"", ""id"", ""name"", ""login""]
            },
            ""modified_by"": {
            ""type"": ""object"",
            ""properties"": {
                ""type"": {
                ""type"": ""string""
                },
                ""id"": {
                ""type"": ""string""
                },
                ""name"": {
                ""type"": ""string""
                },
                ""login"": {
                ""type"": ""string""
                }
            },
            ""required"": [""type"", ""id"", ""name"", ""login""]
            },
            ""owned_by"": {
            ""type"": ""object"",
            ""properties"": {
                ""type"": {
                ""type"": ""string""
                },
                ""id"": {
                ""type"": ""string""
                },
                ""name"": {
                ""type"": ""string""
                },
                ""login"": {
                ""type"": ""string""
                }
            },
            ""required"": [""type"", ""id"", ""name"", ""login""]
            },
            ""shared_link"": {
            ""type"": ""null""
            },
            ""parent"": {
            ""type"": ""object"",
            ""properties"": {
                ""type"": {
                ""type"": ""string""
                },
                ""id"": {
                ""type"": ""string""
                },
                ""sequence_id"": {
                ""type"": ""string""
                },
                ""etag"": {
                ""type"": ""string""
                },
                ""name"": {
                ""type"": ""string""
                }
            },
            ""required"": [""type"", ""id"", ""sequence_id"", ""etag"", ""name""]
            },
            ""item_status"": {
            ""type"": ""string""
            },
            ""text_representation"": {
            ""type"": ""string""
            }
        }
        }

        """"""
    return json.loads(generic_schema)",airbyte-integrations/connectors/source-box-data-extract/source_box_data_extract/schemas.py,
survived,"def test_create_specialist_agents():
    """"""Test that specialist agents are created with the correct configuration.""""""
    science_agent = create_science_agent()
    tech_agent = create_tech_agent()
    
    assert science_agent.name == ""ScienceSpecialist""
    assert tech_agent.name == ""TechSpecialist""
    assert ""science specialist"" in science_agent.instructions.lower()
    assert ""technology specialist"" in tech_agent.instructions.lower()
",openai-agents-examples/02_multi_agent.py,
survived,"def test_run_custom_tool_agent():
    """"""Test that the agent can use custom tools and produce a response.""""""
    import pytest
    
    # Skip this test if no API key is available
    if not os.environ.get(""OPENAI_API_KEY""):
        pytest.skip(""OPENAI_API_KEY not set"")
    
    # Run a test query that should use the currency conversion tool
    response = asyncio.run(run_custom_tool_agent(""Convert 50 USD to EUR""))
    
    # Verify we got a non-empty response that mentions the currencies
    assert response
    assert len(response) > 0
    assert ""USD"" in response
    assert ""EUR"" in response
",openai-agents-examples/06_agent_with_custom_tools.py,
survived,"def create_content_agent() -> Agent:
    """"""
    Create a content agent that writes engaging content.
    
    Returns:
        An Agent instance specialized in content writing.
    """"""
    instructions = """"""
    You are a content writing specialist who excels at creating engaging, informative content.
    Your task is to write high-quality content based on the provided outline and research.
    Use a conversational, engaging tone while maintaining accuracy and clarity.
    Include an attention-grabbing introduction, well-developed body paragraphs, and a compelling conclusion.
    Incorporate the research seamlessly into the content while maintaining a consistent voice.
    """"""
    
    return Agent(
        name=""ContentSpecialist"",
        instructions=instructions,
        model=""gpt-4o-mini"",
        handoff_description=""Use this agent to write engaging content based on an outline and research.""
    )
",openai-agents-examples/11_agent_orchestration.py,
survived,"async def run_multi_agent_system(prompt: str) -> str:
    """"""
    Run the multi-agent system with the given prompt.
    
    Args:
        prompt: The user's query or prompt
        
    Returns:
        The final response from the appropriate specialist agent
    """"""
    # Create specialist agents
    science_agent = create_science_agent()
    tech_agent = create_tech_agent()
    
    # Create coordinator agent with specialists
    coordinator = create_coordinator_agent([science_agent, tech_agent])
    
    # Run the coordinator agent with the prompt
    result = await Runner.run(coordinator, prompt)
    
    # Return the final response
    return result.final_output
",openai-agents-examples/02_multi_agent.py,
survived,"def simulate_conversation(initial_prompt: str, follow_up_prompts: List[str]) -> List[str]:
    """"""
    Simulate a multi-turn conversation with context management.
    
    Args:
        initial_prompt: The first user prompt
        follow_up_prompts: List of follow-up prompts
        
    Returns:
        List of agent responses
    """"""
    responses = []
    context = None
    
    # Run the initial prompt
    response, context = asyncio.run(run_conversation_with_context(initial_prompt, context))
    responses.append(result.final_output)
    
    # Run each follow-up prompt with the updated context
    for prompt in follow_up_prompts:
        response, context = asyncio.run(run_conversation_with_context(prompt, context))
        responses.append(result.final_output)
    
    return responses
",openai-agents-examples/09_agent_with_context_management.py,
survived,"    def __init__(self, min_length: int = 5, max_length: int = 500):
        """"""
        Initialize the format validation guardrail.
        
        Args:
            min_length: Minimum allowed input length
            max_length: Maximum allowed input length
        """"""
        self.min_length = min_length
        self.max_length = max_length
",openai-agents-examples/10_agent_with_guardrails.py,FormatValidationGuardrail
survived,"def main():
    """"""Main function to parse arguments and run the blog writer system.""""""
    parser = argparse.ArgumentParser(description=""Agent with Agent as Tool Example"")
    parser.add_argument(""--prompt"", ""-p"", type=str, required=True, 
                        help=""The topic or request for a blog post"")
    
    args = parser.parse_args()
    
    # Ensure API key is available
    if not os.environ.get(""OPENAI_API_KEY""):
        console.print(Panel(""[bold red]Error: OPENAI_API_KEY environment variable not set[/bold red]""))
        sys.exit(1)
    
    try:
        # Run the blog writer system and get the blog post
        blog_post = asyncio.run(run_blog_writer_system(args.prompt))
        
        # Display the blog post
        console.print(Panel(blog_post, title=""Blog Post"", border_style=""green""))
    
    except Exception as e:
        console.print(Panel(f""[bold red]Error: {str(e)}[/bold red]""))
        sys.exit(1)
",openai-agents-examples/08_agent_with_agent_as_tool.py,
survived,"    def filter(self, input_str: str) -> Optional[str]:
        """"""
        Filter the input string based on format requirements.
        
        Args:
            input_str: The input string to filter
            
        Returns:
            The input string if it passes, or None if it should be rejected
        """"""
        # Check length constraints
        if len(input_str) < self.min_length:
            return None  # Too short
        
        if len(input_str) > self.max_length:
            return None  # Too long
        
        return input_str  # Accept the input
",openai-agents-examples/10_agent_with_guardrails.py,FormatValidationGuardrail
survived,"def test_create_specialist_agents():
    """"""Test that specialist agents are created with the correct configuration.""""""
    research_agent = create_research_agent()
    outline_agent = create_outline_agent()
    content_agent = create_content_agent()
    editor_agent = create_editor_agent()
    
    assert research_agent.name == ""ResearchSpecialist""
    assert outline_agent.name == ""OutlineSpecialist""
    assert content_agent.name == ""ContentSpecialist""
    assert editor_agent.name == ""EditingSpecialist""
    
    assert ""research specialist"" in research_agent.instructions.lower()
    assert ""outline specialist"" in outline_agent.instructions.lower()
    assert ""content writing specialist"" in content_agent.instructions.lower()
    assert ""editing specialist"" in editor_agent.instructions.lower()
",openai-agents-examples/11_agent_orchestration.py,
survived,"async def run_basic_agent(prompt: str, agent: Optional[Agent] = None) -> str:
    """"""
    Run the basic agent with the given prompt.
    
    Args:
        prompt: The user's query or prompt
        agent: Optional pre-configured agent. If None, a default agent is created.
        
    Returns:
        The agent's response as a string
    """"""
    # Create agent if not provided
    if agent is None:
        agent = create_basic_agent()
    
    # Run the agent with the prompt
    result = await Runner.run(agent, prompt)
    
    # Extract and return the text response
    return result.final_output
",openai-agents-examples/01_basic_agent.py,
survived,"def main():
    """"""Main function to parse arguments and run the Anthropic agent.""""""
    parser = argparse.ArgumentParser(description=""Anthropic Agent Example"")
    parser.add_argument(""--prompt"", ""-p"", type=str, required=True, 
                        help=""The prompt to send to the agent"")
    
    args = parser.parse_args()
    
    # Ensure API key is available
    if not os.environ.get(""ANTHROPIC_API_KEY""):
        console.print(Panel(""[bold red]Error: ANTHROPIC_API_KEY environment variable not set[/bold red]""))
        sys.exit(1)
    
    try:
        # Run the Anthropic agent and get response
        response = asyncio.run(run_anthropic_agent(args.prompt))
        
        # Display the response
        console.print(Panel(response, title=""Claude Response"", border_style=""green""))
    
    except Exception as e:
        console.print(Panel(f""[bold red]Error: {str(e)}[/bold red]""))
        sys.exit(1)
",openai-agents-examples/12_anthropic_agent.py,
survived,"    def register_listener(
        self,
        event_type: typing.Type[platform_events.Event],
        func: typing.Callable[[platform_events.Event, msadapter.MessagePlatformAdapter], typing.Awaitable[None]],
    ):
        """"""æ³¨å†Œäº‹ä»¶ç›‘å¬å™¨""""""
        pass
",pkg/platform/sources/webchat.py,WebChatAdapter
survived,"    def __init__(self, config: dict, ap: app.Application, logger: logging.Logger):
        self.ap = ap
        self.logger = logger
        self.config = config
        self.debug_messages = {}
        self.debug_sessions = {}
        
        self.debug_sessions['webchatperson'] = {
            'type': 'person',
            'id': 'webchatperson',
            'name': 'è°ƒè¯•ç§èŠ'
        }
        self.debug_sessions['webchatgroup'] = {
            'type': 'group', 
            'id': 'webchatgroup',
            'name': 'è°ƒè¯•ç¾¤èŠ'
        }
        
        self.debug_messages['webchatperson'] = []
        self.debug_messages['webchatgroup'] = []
",pkg/platform/sources/webchat.py,WebChatAdapter
survived,"    def reset_debug_session(self, session_type: str):
        """"""é‡ç½®è°ƒè¯•ä¼šè¯""""""
        session_key = f'webchat{session_type}'
        self.debug_messages[session_key] = []",pkg/platform/sources/webchat.py,WebChatAdapter
survived,"    def process_file(self, file_path: Path, docs_root: Path) -> Optional[Dict[str, Any]]:
        """"""Process a single markdown file.""""""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                post = frontmatter.load(f)
            
            metadata = post.metadata
            content = post.content
            
            rel_path = file_path.relative_to(docs_root)
            path_parts = list(rel_path.parts[:-1])  # Remove filename
            
            url_path = '/' + '/'.join(['docs'] + path_parts)
            if file_path.name != 'index.md':
                url_path += '/' + file_path.stem
            
            if url_path != '/' and url_path.endswith('/'):
                url_path = url_path.rstrip('/')
            
            title = metadata.get('title', '')
            if not title:
                headings = self.extract_headings(content)
                title = headings[0] if headings else file_path.stem.replace('-', ' ').replace('_', ' ').title()
            
            components = metadata.get('components', [])
            if isinstance(components, str):
                components = [components]
            
            headings = self.extract_headings(content)
            
            clean_content = self.clean_content(content)
            
            section = path_parts[0] if path_parts else 'docs'
            subsection = path_parts[1] if len(path_parts) > 1 else None
            
            document = {
                'title': title,
                'content': clean_content,
                'headings': headings,
                'path': str(rel_path),
                'url': url_path,
                'section': section,
            }
            
            if components:
                document['components'] = components
            
            if subsection:
                document['subsection'] = subsection
            
            return document
            
        except Exception as e:
            logger.error(f""Error processing {file_path}: {e}"")
            return None
",scripts/typesense_indexer.py,MarkdownProcessor
survived,"    async def search_docs(self, query: str):
        """"""Search the documentation using Typesense.""""""
        self.search_query = query
        if not query.strip():
            self.search_results = []
            self.show_results = False
            return
        
        self.is_searching = True
        
        try:
            import typesense
            
            import os
            
            client = typesense.Client({
                'nodes': [{
                    'host': 'z2mi3hyewokc16a4p-1.a1.typesense.net',
                    'port': '443',
                    'protocol': 'https'
                }],
                'api_key': os.getenv('TYPESENSE_SEARCH_API_KEY'),
                'connection_timeout_seconds': 10
            })
            
            search_parameters = {
                'q': query,
                'query_by': 'title,content,headings',
                'per_page': 8,
                'highlight_full_fields': 'title,content',
                'snippet_threshold': 30,
                'num_typos': 2
            }
            
            result = client.collections['docs'].documents.search(search_parameters)
            
            self.search_results = [
                {
                    'title': hit['document']['title'],
                    'content': hit['document']['content'][:150] + '...' if len(hit['document']['content']) > 150 else hit['document']['content'],
                    'url': hit['document']['url'],
                    'path': hit['document']['path']
                }
                for hit in result['hits']
            ]
            self.show_results = True
            
        except Exception as e:
            print(f""Search error: {e}"")
            self.search_results = []
            self.show_results = False
        
        self.is_searching = False
",pcweb/components/docpage/navbar/typesense.py,TypesenseSearchState
survived,"def test_solana_smart_wallet_creation(smart_api):
    """"""Test Solana smart wallet creation and retrieval.""""""
    wallet = smart_api.create_wallet(
        wallet_type=WalletType.SOLANA_SMART_WALLET,
        linked_user=""email:test@example.com""
    )
    assert wallet[""type""] == ""solana-smart-wallet""
    
    # Get wallet and verify only the address matches since other fields might differ
    retrieved = smart_api.get_wallet(wallet[""address""])
    assert retrieved[""address""] == wallet[""address""]
",python/src/wallets/crossmint/tests/test_solana_smart_wallet.py,
survived,"def main():
    """"""Run the pipeline architecture example.""""""
    print(""\n===== Pipeline Architecture Example ====="")
    
    # Create sample data
    data_file = create_sample_data()
    
    # Create pipeline stages
    input_stage = InputStage()
    processing_stage = ProcessingStage()
    output_stage = OutputStage()
    
    # Create and configure pipeline
    pipeline = DataProcessingPipeline(""Sales Data Analysis Pipeline"")
    
    # Add stages
    pipeline.add_stage(""input"", input_stage)
    pipeline.add_stage(""processing"", processing_stage)
    pipeline.add_stage(""output"", output_stage)
    
    # Configure input
    pipeline.configure_input(
        source=data_file,
        source_type=""json"",
        required_fields=[""id"", ""product"", ""price"", ""quantity""]
    )
    
    # Configure processing
    pipeline.configure_processing({
        ""calculate_statistics"": True,
        ""numeric_fields"": [""price"", ""quantity"", ""discount""],
        ""filters"": [
            {
                ""filter_func"": lambda item: item[""price""] * item[""quantity""] > 1000,
                ""description"": ""High-value sales (>$1000)""
            }
        ],
        ""transformations"": {
            ""price"": lambda price: format_currency(price),
            ""discount"": lambda discount: format_percentage(discount)
        },
        ""transformation_description"": ""Format price as currency and discount as percentage""
    })
    
    # Configure output
    pipeline.configure_output({
        ""format_summary"": True,
        ""format_detailed"": True,
        ""print_results"": True,
        ""print_output_type"": ""summary"",
        ""save_to_file"": [
            {
                ""format"": ""json"",
                ""dir"": ""./output"",
                ""filename"": ""sales_analysis.json""
            }
        ]
    })
    
    # Run the pipeline
    result = pipeline.run()
    
    print(""\n===== Pipeline Execution Complete ====="")
    print(f""Pipeline status: {result['metadata']['status']}"")
    print(f""Execution time: {result['metadata']['execution_time_seconds']:.2f} seconds"")
    
    # Show output file location if saved
    if ""stages"" in result and len(result[""stages""]) > 0:
        output_stage_name = result[""stages""][-1][""name""]
        if output_stage_name in pipeline.results:
            output_result = pipeline.results[output_stage_name]
            if ""metadata"" in output_result and ""output_files"" in output_result[""metadata""]:
                print(""\nOutput files:"")
                for output_file in output_result[""metadata""][""output_files""]:
                    print(f""- {output_file['path']} ({output_file['format']})"")
",codebase-architectures/pipeline-architecture/main.py,
survived,"def create_sample_data():
    """"""Create sample sales data for the pipeline example.""""""
    # Create output directory if it doesn't exist
    os.makedirs(""./data"", exist_ok=True)
    
    # Sample sales data
    sales_data = [
        {
            ""id"": ""S001"",
            ""product"": ""Laptop"",
            ""category"": ""Electronics"",
            ""price"": 1299.99,
            ""quantity"": 5,
            ""date"": ""2025-01-15"",
            ""customer"": ""ABC Corp"",
            ""discount"": 0.1
        },
        {
            ""id"": ""S002"",
            ""product"": ""Smartphone"",
            ""category"": ""Electronics"",
            ""price"": 899.99,
            ""quantity"": 10,
            ""date"": ""2025-01-20"",
            ""customer"": ""XYZ Ltd"",
            ""discount"": 0.05
        },
        {
            ""id"": ""S003"",
            ""product"": ""Office Chair"",
            ""category"": ""Furniture"",
            ""price"": 249.99,
            ""quantity"": 8,
            ""date"": ""2025-01-22"",
            ""customer"": ""123 Industries"",
            ""discount"": 0.0
        },
        {
            ""id"": ""S004"",
            ""product"": ""Desk"",
            ""category"": ""Furniture"",
            ""price"": 349.99,
            ""quantity"": 4,
            ""date"": ""2025-01-25"",
            ""customer"": ""ABC Corp"",
            ""discount"": 0.15
        },
        {
            ""id"": ""S005"",
            ""product"": ""Monitor"",
            ""category"": ""Electronics"",
            ""price"": 499.99,
            ""quantity"": 12,
            ""date"": ""2025-01-30"",
            ""customer"": ""XYZ Ltd"",
            ""discount"": 0.1
        },
        {
            ""id"": ""S006"",
            ""product"": ""Printer"",
            ""category"": ""Electronics"",
            ""price"": 299.99,
            ""quantity"": 3,
            ""date"": ""2025-02-05"",
            ""customer"": ""123 Industries"",
            ""discount"": 0.0
        },
        {
            ""id"": ""S007"",
            ""product"": ""Bookshelf"",
            ""category"": ""Furniture"",
            ""price"": 199.99,
            ""quantity"": 6,
            ""date"": ""2025-02-10"",
            ""customer"": ""ABC Corp"",
            ""discount"": 0.05
        }
    ]
    
    # Save to file
    with open(""./data/sales_data.json"", ""w"") as file:
        json.dump(sales_data, file, indent=2)
    
    print(f""Created sample data file: ./data/sales_data.json"")
    return ""./data/sales_data.json""
",codebase-architectures/pipeline-architecture/main.py,
survived,"    def update_task(task_id, task_data):
        """"""Update a task.""""""
        existing_task = db.get(""tasks"", task_id)
        if not existing_task:
            return None
        
        # Update fields
        for key, value in task_data.items():
            if key not in [""id"", ""created_at""]:
                existing_task[key] = value
        
        # Update timestamp
        existing_task[""updated_at""] = get_timestamp()
        
        # Save to database
        db.update(""tasks"", task_id, existing_task)
        return existing_task
",codebase-architectures/vertical-slice-architecture/features/tasks/service.py,TaskService
survived,"def display_header(text):
    """"""Display a header with the given text.""""""
    print(""\n"" + ""="" * 50)
    print(f"" {text}"")
    print(""="" * 50)
",codebase-architectures/layered-architecture/main.py,
survived,"    def delete_user(user_id):
        """"""Delete a user.""""""
        return db.delete(""users"", user_id)",codebase-architectures/vertical-slice-architecture/features/users/service.py,UserService
survived,"    def get_alerts(token: str, unread_only: bool = False, level: Optional[str] = None) -> Dict:
        """"""
        Get alerts for a user.
        
        Args:
            token: Authentication token
            unread_only: Whether to return only unread alerts
            level: Optional filter by alert level
            
        Returns:
            Response with success status and alerts or error message
        """"""
        # Validate token
        success, user_data = validate_user_token(token)
        if not success:
            return {
                ""status"": ""error"",
                ""message"": ""Invalid or expired token"",
                ""data"": None
            }
        
        # Get alerts
        alerts = get_user_alerts(
            user_id=user_data[""id""],
            unread_only=unread_only,
            level=level
        )
        
        return {
            ""status"": ""success"",
            ""message"": f""Retrieved {len(alerts)} alerts"",
            ""data"": {""alerts"": alerts}
        }
",codebase-architectures/atomic-composable-architecture/endpoints/alerts_api.py,AlertsAPI
survived,"    def prepare(self, processing_result):
        """"""
        Prepare the output stage with data from the processing stage.
        
        Args:
            processing_result: Result from the processing stage
        
        Returns:
            dict: Stage result with data and metadata
        """"""
        # Check if processing stage had errors
        if processing_result[""metadata""][""status""] in [""error"", ""skipped""]:
            self.metadata[""status""] = ""skipped""
            self.metadata[""errors""].append(""Processing stage had errors, output skipped"")
            return self._create_result()
        
        # Get data and metadata from processing stage
        self.data = processing_result[""data""]
        self.metadata[""input_metadata""] = processing_result[""metadata""][""input_metadata""]
        self.metadata[""processing_metadata""] = processing_result[""metadata""]
        
        # Get analysis if available
        if ""analysis"" in processing_result:
            self.analysis = processing_result[""analysis""]
        
        # Initialize output
        self.metadata[""status""] = ""preparing""
        self.metadata[""started_at""] = datetime.now().isoformat()
        
        return self._create_result()
",codebase-architectures/pipeline-architecture/pipeline/output_stage.py,OutputStage
survived,"    def finalize(self):
        """"""
        Finalize the output stage.
        
        Returns:
            dict: Stage result with data and metadata
        """"""
        if self.metadata[""status""] not in [""error"", ""skipped""]:
            self.metadata[""status""] = ""completed""
            self.metadata[""completed_at""] = datetime.now().isoformat()
            
            # Calculate processing time if we have start time
            if ""started_at"" in self.metadata:
                start_time = datetime.fromisoformat(self.metadata[""started_at""])
                end_time = datetime.fromisoformat(self.metadata[""completed_at""])
                processing_time = (end_time - start_time).total_seconds()
                self.metadata[""processing_time_seconds""] = processing_time
        
        return self._create_result()
",codebase-architectures/pipeline-architecture/pipeline/output_stage.py,OutputStage
survived,"def display_header(text):
    """"""Display a header with the given text.""""""
    print(""\n"" + ""="" * 50)
    print(f"" {text}"")
    print(""="" * 50)
",codebase-architectures/vertical-slice-architecture/main.py,
survived,"    def update_category(category_id, name=None, description=None):
        """"""Update a category.""""""
        try:
            # Get existing category
            category_data = db.get(""categories"", category_id)
            if not category_data:
                Logger.warning(app_logger, f""Cannot update: Category not found: {category_id}"")
                return None
            
            # Check if new name already exists
            if name and name != category_data[""name""]:
                existing_categories = db.query(""categories"", lambda c: c[""name""].lower() == name.lower() and c[""id""] != category_id)
                if existing_categories:
                    raise ValueError(f""Category with name '{name}' already exists"")
            
            # Update fields
            if name:
                category_data[""name""] = name
            if description is not None:
                category_data[""description""] = description
            
            # Update timestamp
            category_data[""updated_at""] = datetime.now().isoformat()
            
            # Save to database
            updated_category = db.update(""categories"", category_id, category_data)
            Logger.info(app_logger, f""Updated category: {category_id}"")
            return updated_category
        except Exception as e:
            Logger.error(app_logger, f""Error updating category: {str(e)}"", exc_info=True)
            raise
",codebase-architectures/layered-architecture/services/category_service.py,CategoryService
survived,"    def to_dict(self):
        """"""Convert task to dictionary.""""""
        return {
            ""id"": self.id,
            ""title"": self.title,
            ""description"": self.description,
            ""user_id"": self.user_id,
            ""status"": self.status,
            ""created_at"": self.created_at,
            ""updated_at"": self.updated_at
        }
",codebase-architectures/vertical-slice-architecture/features/tasks/model.py,Task
survived,"def format_percentage(value):
    """"""Format a number as percentage.""""""
    try:
        return f""{float(value) * 100:.1f}%""
    except (ValueError, TypeError):
        return ""N/A""
",codebase-architectures/pipeline-architecture/shared/utilities.py,
survived,"def main():
    """"""Run the application.""""""
    display_header(""Atomic/Composable Architecture Example"")
    
    # Register users
    display_header(""Registering Users"")
    
    register_response = UserAPI.register(
        username=""johndoe"",
        password=""Password123!"",
        email=""john@example.com""
    )
    display_response(register_response)
    
    register_response2 = UserAPI.register(
        username=""janedoe"",
        password=""Secure456@"",
        email=""jane@example.com""
    )
    display_response(register_response2)
    
    # Try to register with invalid data
    invalid_register = UserAPI.register(
        username=""user"",
        password=""weak"",
        email=""invalid-email""
    )
    display_response(invalid_register)
    
    # Login
    display_header(""User Login"")
    
    login_response = UserAPI.login(
        username=""johndoe"",
        password=""Password123!""
    )
    display_response(login_response)
    
    # Store token for later use
    if login_response[""status""] == ""success"" and login_response[""data""]:
        token = login_response[""data""][""token""]
        
        # Get user profile
        display_header(""User Profile"")
        
        profile_response = UserAPI.get_profile(token)
        display_response(profile_response)
        
        # Update profile
        display_header(""Updating Profile"")
        
        update_response = UserAPI.update_profile(
            token=token,
            profile_data={""name"": ""John Doe"", ""location"": ""New York""}
        )
        display_response(update_response)
        
        # Send alerts
        display_header(""Sending Alerts"")
        
        info_alert = AlertsAPI.send_alert(
            token=token,
            message=""This is an informational alert"",
            level=""info""
        )
        display_response(info_alert)
        
        warning_alert = AlertsAPI.send_alert(
            token=token,
            message=""This is a warning alert"",
            level=""warning"",
            email=""john@example.com""
        )
        display_response(warning_alert)
        
        error_alert = AlertsAPI.send_alert(
            token=token,
            message=""This is an error alert"",
            level=""error"",
            additional_data={""error_code"": ""E123"", ""source"": ""system""}
        )
        display_response(error_alert)
        
        # Get alerts
        display_header(""Getting Alerts"")
        
        alerts_response = AlertsAPI.get_alerts(token)
        display_response(alerts_response)
        
        # Filter alerts by level
        display_header(""Filtering Alerts by Level"")
        
        warning_alerts = AlertsAPI.get_alerts(token, level=""warning"")
        display_response(warning_alerts)
        
        # Mark an alert as read
        if alerts_response[""status""] == ""success"" and alerts_response[""data""]:
            alerts = alerts_response[""data""][""alerts""]
            if alerts:
                alert_id = alerts[0][""id""]
                
                display_header(""Marking Alert as Read"")
                
                mark_response = AlertsAPI.mark_as_read(token, alert_id)
                display_response(mark_response)
                
                # Get unread alerts
                display_header(""Getting Unread Alerts"")
                
                unread_response = AlertsAPI.get_alerts(token, unread_only=True)
                display_response(unread_response)
                
                # Mark all as read
                display_header(""Marking All Alerts as Read"")
                
                mark_all_response = AlertsAPI.mark_all_as_read(token)
                display_response(mark_all_response)
                
                # Delete an alert
                display_header(""Deleting an Alert"")
                
                delete_response = AlertsAPI.delete_alert(token, alert_id)
                display_response(delete_response)
        
        # Send system notification
        display_header(""Sending System Notification"")
        
        system_response = AlertsAPI.send_system_alert(
            token=token,
            user_id=profile_response[""data""][""user""][""id""],
            notification_type=""welcome"",
            data={""username"": ""johndoe""},
            email=""john@example.com""
        )
        display_response(system_response)
        
        # Logout
        display_header(""User Logout"")
        
        logout_response = UserAPI.logout(token)
        display_response(logout_response)
        
        # Try to use expired token
        display_header(""Using Expired Token"")
        
        expired_response = UserAPI.get_profile(token)
        display_response(expired_response)
",codebase-architectures/atomic-composable-architecture/main.py,
survived,"    def _create_result(self):
        """"""Create a result dictionary with data and metadata.""""""
        result = {
            ""data"": self.data,
            ""metadata"": self.metadata
        }
        
        # Add analysis if available
        if self.analysis:
            result[""analysis""] = self.analysis
        
        # Add formatted outputs if available
        if hasattr(self, ""summary""):
            result[""summary""] = self.summary
        
        if hasattr(self, ""detailed_report""):
            result[""detailed_report""] = self.detailed_report
        
        return result",codebase-architectures/pipeline-architecture/pipeline/output_stage.py,OutputStage
survived,"    def delete_task(task_id):
        """"""Delete a task.""""""
        success = TaskService.delete_task(task_id)
        if not success:
            return {""error"": f""Task with ID {task_id} not found""}
        return {""message"": f""Task with ID {task_id} deleted successfully""}",codebase-architectures/vertical-slice-architecture/features/tasks/api.py,TaskAPI
survived,"    def _view_file(self, path: str, view_range=None) -> FileOperationResult:
        """"""
        View the contents of a file.

        Args:
            path: The path to the file to view
            view_range: Optional start and end lines to view [start, end]

        Returns:
            FileOperationResult with content or error message
        """"""
        try:
            # Normalize the path
            path = normalize_path(path)

            if not os.path.exists(path):
                error_msg = f""File {path} does not exist""
                console.log(f""[view_file] Error: {error_msg}"")
                return FileOperationResult(False, error_msg)

            with open(path, ""r"") as f:
                lines = f.readlines()

            if view_range:
                start, end = view_range
                # Convert to 0-indexed for Python
                start = max(0, start - 1)
                if end == -1:
                    end = len(lines)
                else:
                    end = min(len(lines), end)
                lines = lines[start:end]

            content = """".join(lines)

            # Display the file content (only for console, not returned to Claude)
            display_file_content(path, content)

            return FileOperationResult(True, f""Successfully viewed file {path}"", content)
        except Exception as e:
            error_msg = f""Error viewing file: {str(e)}""
            console.print(f""[red]{error_msg}[/red]"")
            console.log(f""[view_file] Error: {str(e)}"")
            console.log(traceback.format_exc())
            return FileOperationResult(False, error_msg)
",example-agent-codebase-arch/pipeline-architecture/steps/processing_stage.py,ProcessingStage
survived,"    def from_dict(cls, data: Dict[str, Any]) -> 'ToolUseRequest':
        """"""
        Create a tool use request from a dictionary.
        
        Args:
            data: Dictionary containing the tool use request
            
        Returns:
            A ToolUseRequest instance
        """"""
        command = data.get(""command"")
        path = data.get(""path"")
        
        # Extract all other keys as kwargs
        kwargs = {k: v for k, v in data.items() if k not in [""command"", ""path""]}
        
        return cls(command, path, **kwargs)",example-agent-codebase-arch/pipeline-architecture/shared/utilities.py,ToolUseRequest
survived,"    def _validate_request(self, request: ToolUseRequest) -> FileOperationResult:
        """"""
        Validate the tool use request.
        
        Args:
            request: The tool use request to validate
            
        Returns:
            FileOperationResult with validation result
        """"""
        if not request.command:
            return FileOperationResult(False, ""No command specified in tool use request"")

        if not request.path and request.command != ""undo_edit"":  # undo_edit might not need a path
            return FileOperationResult(False, ""No path specified in tool use request"")
            
        # Validate command-specific parameters
        if request.command == ""view"":
            # View command is valid with just a path
            pass
            
        elif request.command == ""str_replace"":
            # Validate str_replace parameters
            old_str = request.kwargs.get(""old_str"")
            new_str = request.kwargs.get(""new_str"")
            
            if old_str is None:
                return FileOperationResult(False, ""Missing 'old_str' parameter for str_replace command"")
                
            if new_str is None:
                return FileOperationResult(False, ""Missing 'new_str' parameter for str_replace command"")
                
        elif request.command == ""create"":
            # Validate create parameters
            file_text = request.kwargs.get(""file_text"")
            # file_text can be None or empty, so no validation needed
            
        elif request.command == ""insert"":
            # Validate insert parameters
            insert_line = request.kwargs.get(""insert_line"")
            new_str = request.kwargs.get(""new_str"")
            
            if insert_line is None:
                return FileOperationResult(False, ""Missing 'insert_line' parameter for insert command"")
                
            if new_str is None:
                return FileOperationResult(False, ""Missing 'new_str' parameter for insert command"")
                
        elif request.command == ""undo_edit"":
            # undo_edit is valid with just a path
            pass
            
        else:
            return FileOperationResult(False, f""Unknown command: {request.command}"")
            
        return FileOperationResult(True, ""Request validation successful"")",example-agent-codebase-arch/pipeline-architecture/steps/input_stage.py,InputStage
survived,"    def _undo_edit(self, path: str) -> FileOperationResult:
        """"""
        Placeholder for undo_edit functionality.
        In a real implementation, you would need to track edit history.

        Args:
            path: The path to the file whose last edit should be undone

        Returns:
            FileOperationResult with message about undo functionality
        """"""
        try:
            if not path or not path.strip():
                error_msg = ""Invalid file path provided: path is empty.""
                console.log(f""[undo_edit] Error: {error_msg}"")
                return FileOperationResult(False, error_msg)

            # Normalize the path
            path = normalize_path(path)

            message = ""Undo functionality is not implemented in this version.""
            console.print(f""[yellow]{message}[/yellow]"")
            console.log(f""[undo_edit] {message}"")
            return FileOperationResult(True, message)
        except Exception as e:
            error_msg = f""Error in undo_edit: {str(e)}""
            console.print(f""[red]{error_msg}[/red]"")
            console.log(f""[undo_edit] Error: {str(e)}"")
            console.log(traceback.format_exc())
            return FileOperationResult(False, error_msg)",example-agent-codebase-arch/pipeline-architecture/steps/processing_stage.py,ProcessingStage
survived,"    def from_dict(cls, data: Dict[str, Any]) -> 'ToolUseRequest':
        """"""
        Create a tool use request from a dictionary.
        
        Args:
            data: Dictionary containing the tool use request
            
        Returns:
            A ToolUseRequest instance
        """"""
        command = data.get(""command"")
        path = data.get(""path"")
        
        # Extract all other keys as kwargs
        kwargs = {k: v for k, v in data.items() if k not in [""command"", ""path""]}
        
        return cls(command, path, **kwargs)",example-agent-codebase-arch/vertical-slice-architecture/features/file_operations/model.py,ToolUseRequest
survived,"    def warning(logger_name: str, message: str) -> None:
        """"""
        Log a warning message.
        
        Args:
            logger_name: Name of the logger
            message: Message to log
        """"""
        console.log(f""[{logger_name}] [warning] {message}"")
",example-agent-codebase-arch/layered-architecture/utils/logger.py,Logger
survived,"    def to_dict(self) -> Dict[str, Any]:
        """"""
        Convert the result to a dictionary.
        
        Returns:
            Dictionary representation of the result
        """"""
        return {
            ""success"": self.success,
            ""message"": self.message,
            ""data"": self.data
        }
",example-agent-codebase-arch/vertical-slice-architecture/features/file_operations/model.py,FileOperationResult
deleted,"def get_file_extension(path: str) -> str:
    """"""
    Get the file extension from a path.

    Args:
        path: The path to get the extension from

    Returns:
        The file extension without the dot
    """"""
    return os.path.splitext(path)[1][1:]
",example-agent-codebase-arch/atomic-composable-architecture/atom/path_utils.py,
survived,"    def from_dict(cls, data: Dict[str, Any]) -> 'ToolUseRequest':
        """"""
        Create a tool use request from a dictionary.
        
        Args:
            data: Dictionary containing the tool use request
            
        Returns:
            A ToolUseRequest instance
        """"""
        command = data.get(""command"")
        path = data.get(""path"")
        
        # Extract all other keys as kwargs
        kwargs = {k: v for k, v in data.items() if k not in [""command"", ""path""]}
        
        return cls(command, path, **kwargs)
",example-agent-codebase-arch/layered-architecture/models/tool_models.py,ToolUseRequest
survived,"    def str_replace(path: str, old_str: str, new_str: str) -> FileOperationResult:
        """"""
        Replace a specific string in a file.

        Args:
            path: The path to the file to modify
            old_str: The text to replace
            new_str: The new text to insert

        Returns:
            FileOperationResult with result or error message
        """"""
        try:
            # Normalize the path
            path = normalize_path(path)

            if not os.path.exists(path):
                error_msg = f""File {path} does not exist""
                Logger.error(app_logger, f""[str_replace] {error_msg}"")
                return FileOperationResult(False, error_msg)

            with open(path, ""r"") as f:
                content = f.read()

            if old_str not in content:
                error_msg = f""The specified string was not found in the file {path}""
                Logger.error(app_logger, f""[str_replace] {error_msg}"")
                return FileOperationResult(False, error_msg)

            new_content = content.replace(old_str, new_str, 1)

            with open(path, ""w"") as f:
                f.write(new_content)

            Logger.info(app_logger, f""[str_replace] Successfully replaced text in {path}"")
            return FileOperationResult(True, f""Successfully replaced text in {path}"")
        except Exception as e:
            error_msg = f""Error replacing text: {str(e)}""
            Logger.error(app_logger, f""[str_replace] {error_msg}"", exc_info=True)
            return FileOperationResult(False, error_msg)
",example-agent-codebase-arch/layered-architecture/services/file_service.py,FileService
survived,"    def run_agent(
        client: Anthropic,
        prompt: str,
        handle_tool_use_func,
        max_thinking_tokens: int = DEFAULT_THINKING_TOKENS,
        max_loops: int = 10,
        use_token_efficiency: bool = False,
    ) -> Tuple[str, int, int]:
        """"""
        Run the Claude agent with file editing capabilities.

        Args:
            client: The Anthropic client
            prompt: The user's prompt
            handle_tool_use_func: Function to handle tool use requests
            max_thinking_tokens: Maximum tokens for thinking
            max_loops: Maximum number of tool use loops
            use_token_efficiency: Whether to use token-efficient tool use beta feature

        Returns:
            Tuple containing:
            - Final response from Claude (str)
            - Total input tokens used (int)
            - Total output tokens used (int)
        """"""
        # Track token usage
        input_tokens_total = 0
        output_tokens_total = 0
        system_prompt = """"""You are a helpful AI assistant with text editing capabilities.
You have access to a text editor tool that can view, edit, and create files.
Always think step by step about what you need to do before taking any action.
Be careful when making edits to files, as they can permanently change the user's files.
Follow these steps when handling file operations:
1. First, view files to understand their content before making changes
2. For edits, ensure you have the correct context and are making the right changes
3. When creating files, make sure they're in the right location with proper formatting
""""""

        # Define text editor tool
        text_editor_tool = {""name"": ""str_replace_editor"", ""type"": ""text_editor_20250124""}

        messages = [
            {
                ""role"": ""user"",
                ""content"": f""""""I need help with editing files. Here's what I want to do:

{prompt}

Please use the text editor tool to help me with this. First, think through what you need to do, then use the appropriate tool.
"""""",
            }
        ]

        loop_count = 0
        tool_use_count = 0
        thinking_start_time = time.time()

        while loop_count < max_loops:
            loop_count += 1

            console.rule(f""[yellow]Agent Loop {loop_count}/{max_loops}[/yellow]"")
            Logger.info(app_logger, f""Starting agent loop {loop_count}/{max_loops}"")

            # Create message with text editor tool
            message_args = {
                ""model"": MODEL,
                ""max_tokens"": 4096,
                ""tools"": [text_editor_tool],
                ""messages"": messages,
                ""system"": system_prompt,
                ""thinking"": {""type"": ""enabled"", ""budget_tokens"": max_thinking_tokens},
            }

            # Use the beta.messages with betas parameter if token efficiency is enabled
            if use_token_efficiency:
                # Using token-efficient tools beta feature
                message_args[""betas""] = [""token-efficient-tools-2025-02-19""]
                response = client.beta.messages.create(**message_args)
            else:
                # Standard approach
                response = client.messages.create(**message_args)

            # Track token usage
            if hasattr(response, ""usage""):
                input_tokens = getattr(response.usage, ""input_tokens"", 0)
                output_tokens = getattr(response.usage, ""output_tokens"", 0)

                input_tokens_total += input_tokens
                output_tokens_total += output_tokens

                console.print(
                    f""[dim]Loop {loop_count} tokens: Input={input_tokens}, Output={output_tokens}[/dim]""
                )
                Logger.info(
                    app_logger, 
                    f""Loop {loop_count} tokens: Input={input_tokens}, Output={output_tokens}""
                )

            # Process response content
            thinking_block = None
            tool_use_block = None
            text_block = None

            for content_block in response.content:
                if content_block.type == ""thinking"":
                    thinking_block = content_block
                    # Access the thinking attribute which contains the actual thinking text
                    if hasattr(thinking_block, ""thinking""):
                        console.print(
                            Panel(
                                thinking_block.thinking,
                                title=f""Claude's Thinking (Loop {loop_count})"",
                                border_style=""blue"",
                            )
                        )
                    else:
                        console.print(
                            Panel(
                                ""Claude is thinking..."",
                                title=f""Claude's Thinking (Loop {loop_count})"",
                                border_style=""blue"",
                            )
                        )
                elif content_block.type == ""tool_use"":
                    tool_use_block = content_block
                    tool_use_count += 1
                elif content_block.type == ""text"":
                    text_block = content_block

            # If we got a final text response with no tool use, we're done
            if text_block and not tool_use_block:
                thinking_end_time = time.time()
                thinking_duration = thinking_end_time - thinking_start_time

                console.print(
                    f""\n[bold green]Completed in {thinking_duration:.2f} seconds after {loop_count} loops and {tool_use_count} tool uses[/bold green]""
                )
                Logger.info(
                    app_logger,
                    f""Completed in {thinking_duration:.2f} seconds after {loop_count} loops and {tool_use_count} tool uses""
                )

                # Add the response to messages
                messages.append(
                    {
                        ""role"": ""assistant"",
                        ""content"": [
                            *([thinking_block] if thinking_block else []),
                            {""type"": ""text"", ""text"": text_block.text},
                        ],
                    }
                )

                return text_block.text, input_tokens_total, output_tokens_total

            # Handle tool use
            if tool_use_block:
                # Add the assistant's response to messages before handling tool calls
                messages.append({""role"": ""assistant"", ""content"": response.content})

                console.print(
                    f""\n[bold blue]Tool Call:[/bold blue] {tool_use_block.name}""
                )
                Logger.info(app_logger, f""Tool Call: {tool_use_block.name}"")

                # Handle the tool use
                tool_result = handle_tool_use_func(tool_use_block.input)

                # Log tool result
                result_text = tool_result.get(""error"") or tool_result.get(""result"", """")
                Logger.info(app_logger, f""Tool Result: {result_text[:100]}..."")

                # Format tool result for Claude
                tool_result_message = {
                    ""role"": ""user"",
                    ""content"": [
                        {
                            ""type"": ""tool_result"",
                            ""tool_use_id"": tool_use_block.id,
                            ""content"": result_text,
                        }
                    ],
                }
                messages.append(tool_result_message)

        # If we reach here, we hit the max loops
        console.print(
            f""\n[bold red]Warning: Reached maximum loops ({max_loops}) without completing the task[/bold red]""
        )
        Logger.warning(
            app_logger,
            f""Reached maximum loops ({max_loops}) without completing the task""
        )
        return (
            ""I wasn't able to complete the task within the allowed number of thinking steps. Please try a more specific prompt or increase the loop limit."",
            input_tokens_total,
            output_tokens_total,
        )",example-agent-codebase-arch/layered-architecture/services/agent_service.py,AgentService
survived,"    def __init__(self, name: str):
        """"""
        Initialize a pipeline.
        
        Args:
            name: The name of the pipeline
        """"""
        self.name = name
        self.stages: Dict[str, PipelineStage] = {}
        self.stage_order: List[str] = []
        console.log(f""[pipeline] Initialized pipeline: {name}"")
",example-agent-codebase-arch/pipeline-architecture/pipeline_manager/pipeline_manager.py,Pipeline
survived,"def test_create_folder_structure_handles_spaces_and_dashes_with_slash():
    with tempfile.TemporaryDirectory() as temp_dir:
        os.chdir(temp_dir)
        folder_path, folder_name, class_name = create_folder_structure(""My Cool-Project/"")
        
        assert folder_name == ""my_cool_project""
        assert class_name == ""MyCoolProject""
        assert folder_path.name == ""my_cool_project""
        assert folder_path.exists()
",tests/cli/test_create_crew.py,
survived,"    def load_state(self, flow_uuid: str) -> Optional[Dict[str, Any]]:
        """"""Load the most recent state for a given flow UUID.
        
        Args:
            flow_uuid: Unique identifier for the flow instance
            
        Returns:
            The most recent state as a dictionary, or None if no state exists
        """"""
        pass",src/crewai/flow/persistence/base.py,FlowPersistence
survived,"    def init_db(self) -> None:
        """"""Create the necessary tables if they don't exist.""""""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute(""""""
            CREATE TABLE IF NOT EXISTS flow_states (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                flow_uuid TEXT NOT NULL,
                method_name TEXT NOT NULL,
                timestamp DATETIME NOT NULL,
                state_json TEXT NOT NULL
            )
            """""")
            # Add index for faster UUID lookups
            conn.execute(""""""
            CREATE INDEX IF NOT EXISTS idx_flow_states_uuid 
            ON flow_states(flow_uuid)
            """""")
",src/crewai/flow/persistence/sqlite.py,SQLiteFlowPersistence
survived,"def persist(persistence: FlowPersistence):
    """"""Decorator to persist flow state after method execution.
    
    This decorator supports both synchronous and asynchronous methods. It will
    persist the flow state after the method completes successfully. For async
    methods, it ensures the state is persisted before returning the result.
    
    Args:
        persistence: FlowPersistence implementation to use for storing state
    
    Returns:
        A decorator function that wraps flow methods and handles state persistence
    
    Raises:
        ValueError: If the flow state doesn't have an 'id' field
        RuntimeError: If state persistence fails
    """"""
    def _persist_state(flow_instance: Any, method_name: str) -> None:
        """"""Helper to persist state with error handling.""""""
        try:
            # Get flow UUID from state
            state = getattr(flow_instance, 'state', None)
            if state is None:
                raise ValueError(""Flow instance has no state"")
                
            flow_uuid: Optional[str] = None
            if isinstance(state, dict):
                flow_uuid = state.get('id')
            elif isinstance(state, BaseModel):
                flow_uuid = getattr(state, 'id', None)
                
            if not flow_uuid:
                raise ValueError(
                    ""Flow state must have an 'id' field for persistence""
                )
                
            # Persist the state
            persistence.save_state(
                flow_uuid=flow_uuid,
                method_name=method_name,
                state_data=state,
            )
        except Exception as e:
            logger.error(
                f""Failed to persist state for method {method_name}: {str(e)}""
            )
            raise RuntimeError(f""State persistence failed: {str(e)}"") from e
    
    def decorator(method: Callable[..., T]) -> Callable[..., T]:
        """"""Decorator that handles both sync and async methods.""""""
        if asyncio.iscoroutinefunction(method):
            @functools.wraps(method)
            async def async_wrapper(flow_instance: Any, *args: Any, **kwargs: Any) -> T:
                # Execute the original async method
                result = await method(flow_instance, *args, **kwargs)
                # Persist state after method completion
                _persist_state(flow_instance, method.__name__)
                return result
            return cast(Callable[..., T], async_wrapper)
        else:
            @functools.wraps(method)
            def sync_wrapper(flow_instance: Any, *args: Any, **kwargs: Any) -> T:
                # Execute the original sync method
                result = method(flow_instance, *args, **kwargs)
                # Persist state after method completion
                _persist_state(flow_instance, method.__name__)
                return result
            return cast(Callable[..., T], sync_wrapper)
            
    return decorator",src/crewai/flow/persistence/decorators.py,
survived,"    def load_state(self, flow_uuid: str) -> Optional[Dict[str, Any]]:
        """"""Load the most recent state for a given flow UUID.
        
        Args:
            flow_uuid: Unique identifier for the flow instance
            
        Returns:
            The most recent state as a dictionary, or None if no state exists
        """"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute(""""""
            SELECT state_json
            FROM flow_states
            WHERE flow_uuid = ?
            ORDER BY id DESC
            LIMIT 1
            """""", (flow_uuid,))
            row = cursor.fetchone()
            
        if row:
            return json.loads(row[0])
        return None",src/crewai/flow/persistence/sqlite.py,SQLiteFlowPersistence
survived,"    def get_flowrate(self, wallet_client: EVMWalletClient, parameters: dict):
        result = wallet_client.read(
            {
                ""address"": self.CFA_FORWARDER_ADDRESS,
                ""abi"": CFA_FORWARDER_ABI,
                ""functionName"": ""getFlowrate"",
                ""args"": [parameters[""token""], parameters[""sender""], parameters[""receiver""]],
            }
        )
        return result[""value""]
",python/src/plugins/superfluid/goat_plugins/superfluid/service.py,SuperfluidService
survived,"    def __init__(self, options: JSONRpcPluginOptions):
        super().__init__(""jsonrpc"", [JSONRpcService(options.endpoint)])
",python/src/plugins/jsonrpc/goat_plugins/jsonrpc/__init__.py,JSONRpcPlugin
survived,"def test_xai_raw_response_sync(model, mode):
    """"""Test that _raw_response is attached to sync XAI responses""""""
    client = instructor.from_provider(f""xai/{model}"", mode=mode)
    
    user = client.chat.completions.create(
        response_model=User,
        messages=[
            {
                ""role"": ""system"",
                ""content"": ""You are a helpful assistant that extracts information."",
            },
            {
                ""role"": ""user"",
                ""content"": ""Extract: Jason is 25 years old."",
            },
        ],
    )
    
    assert isinstance(user, User)
    assert user.name.lower() == ""jason""
    assert user.age == 25
    assert hasattr(user, ""_raw_response""), (
        ""The raw response should be available from XAI""
    )
    assert user._raw_response is not None
",tests/llm/test_xai/test_raw_response.py,
deleted,"    def should_include_file(file_path):
        """"""Check if a file should be included based on patterns and exclusions.""""""
        path_parts = Path(file_path).parts
        
        if any(part in excluded_names for part in path_parts):
            return False
            
        if file_path.endswith(('.md', '.mdx')):
            return True
            
        return False
",docs/compile_llms_txt.py,
survived,"    def supports_function_calling(self) -> bool:
        """"""Check if the LLM supports function calling.
        
        Returns:
            True if the LLM supports function calling, False otherwise.
        """"""
        pass
",src/crewai/llm.py,BaseLLM
