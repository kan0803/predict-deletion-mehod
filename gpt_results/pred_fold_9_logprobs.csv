status,method,filepath,class_name,predict,prob_deleted,reason
survived,"def parse_signature(args: ast.arguments) -> Signature:
    """"""Convert ast.arguments to a Signature dataclass for easier processing.""""""
    parameters_positional: list[Parameter] = []
    parameters_keyword_only: list[Parameter] = []

    # Process positional-only parameters
    for i, arg in enumerate(args.posonlyargs):
        parameters_positional.append(
            Parameter(
                name=arg.arg,
                position=i,
                is_required=True,  # All positional-only are required
                is_positional_only=True,
                is_keyword_only=False,
                lineno=arg.lineno,
                col_offset=arg.col_offset,
            )
        )

    # Process regular positional parameters
    offset = len(args.posonlyargs)
    first_optional_idx = len(args.posonlyargs + args.args) - len(args.defaults)

    for i, arg in enumerate(args.args):
        pos = offset + i
        parameters_positional.append(
            Parameter(
                name=arg.arg,
                position=pos,
                is_required=pos < first_optional_idx,
                is_positional_only=False,
                is_keyword_only=False,
                lineno=arg.lineno,
                col_offset=arg.col_offset,
            )
        )

    # Process keyword-only parameters
    for arg, default in zip(args.kwonlyargs, args.kw_defaults):
        parameters_keyword_only.append(
            Parameter(
                name=arg.arg,
                position=None,
                is_required=default is None,
                is_positional_only=False,
                is_keyword_only=True,
                lineno=arg.lineno,
                col_offset=arg.col_offset,
            )
        )

    return Signature(
        positional=parameters_positional,
        keyword_only=parameters_keyword_only,
        has_var_positional=args.vararg is not None,
        has_var_keyword=args.kwarg is not None,
    )
",dev/check_function_signatures.py,,1,1.522997951276035e-08,"The method `parse_signature` is a utility function that converts `ast.arguments` into a `Signature` dataclass, which is useful for processing and analyzing function signatures in Python code. This kind of functionality is essential for tools that perform static analysis, code introspection, or automated documentation generation. Given the increasing importance of such tools in software development, this method is likely to be retained as it provides a structured way to handle function signatures, which is a common requirement in many applications."
survived,"def parse_functions(content: str) -> dict[str, ast.FunctionDef | ast.AsyncFunctionDef]:
    tree = ast.parse(content)
    extractor = FunctionSignatureExtractor()
    extractor.visit(tree)
    return extractor.functions
",dev/check_function_signatures.py,,1,9.237449576640118e-09,"The method 'parse_functions' is a utility function that parses a string of code to extract function definitions using the Abstract Syntax Tree (AST) module. This is a common and useful operation in static code analysis, refactoring tools, or any application that needs to understand or manipulate Python code programmatically. The function is well-defined, uses standard libraries, and serves a clear purpose, making it likely to be retained in the codebase."
survived,"def test_new_optional_keyword_only_allowed():
    old_code = ""def func(*, a): pass""
    new_code = ""def func(*, a, b=1): pass""

    old_tree = ast.parse(old_code)
    new_tree = ast.parse(new_code)
    errors = check_signature_compatibility(old_tree.body[0], new_tree.body[0])

    assert len(errors) == 0
",tests/dev/test_check_function_signatures.py,,1,1.0467401685178159e-08,The method 'test_new_optional_keyword_only_allowed' is a test function that checks if adding a new optional keyword-only argument to a function signature is compatible with the old signature. This is a valid and useful test case for ensuring backward compatibility in Python code. It is likely to be retained as it serves a purpose in verifying that the code changes do not introduce breaking changes.
survived,"def test_only_first_positional_rename_flagged():
    old_code = ""def func(a, b, c, d): pass""
    new_code = ""def func(x, y, z, w): pass""

    old_tree = ast.parse(old_code)
    new_tree = ast.parse(new_code)
    errors = check_signature_compatibility(old_tree.body[0], new_tree.body[0])

    assert len(errors) == 1
    assert ""Positional param order/name changed: 'a' -> 'x'."" in errors[0].message
",tests/dev/test_check_function_signatures.py,,1,1.0467401685178159e-08,"The method is a test function that checks for a specific behavior in code refactoring, specifically the renaming of positional parameters. It is a useful test case for ensuring that changes in parameter names are flagged correctly, which is important for maintaining code compatibility and preventing bugs. Such test functions are typically retained as they are crucial for validating the functionality of the codebase."
survived,"def test_positional_param_renamed():
    old_code = ""def func(a, b): pass""
    new_code = ""def func(x, b): pass""

    old_tree = ast.parse(old_code)
    new_tree = ast.parse(new_code)
    errors = check_signature_compatibility(old_tree.body[0], new_tree.body[0])

    assert len(errors) == 1
    assert ""Positional param order/name changed: 'a' -> 'x'."" in errors[0].message
    assert errors[0].param_name == ""x""
",tests/dev/test_check_function_signatures.py,,1,2.0611536181902033e-09,"The method 'test_positional_param_renamed' is a unit test function that checks for a specific change in function signature, specifically the renaming of a positional parameter. This is a valid and useful test case for ensuring backward compatibility in code refactoring or updates. It verifies that the function 'check_signature_compatibility' correctly identifies and reports changes in parameter names, which is crucial for maintaining code reliability and preventing bugs. Therefore, this method is likely to be retained as it serves an important role in testing and validation."
survived,"def index():
    return render_template(""index.html"")
",triton_viz/visualizer/interface.py,,1,1.4166087846364157e-09,"The method 'index' is a simple function that returns a rendered HTML template. This is a common pattern in web development frameworks like Flask, where functions are used to handle requests and return responses. The function is straightforward, performs its intended task without any issues, and is likely part of a larger application structure. There is no indication of redundancy, inefficiency, or any other reason that would necessitate its deletion. Therefore, it is likely to survive."
deleted,"def update_global_data():
    global global_data, raw_tensor_data, precomputed_c_values
    analysis_data = analyze_records()
    viz_data = get_visualization_data()
    global_data = {
        ""ops"": {
            ""visualization_data"": viz_data[""visualization_data""],
            ""failures"": viz_data[""failures""],
            ""kernel_src"": viz_data[""kernel_src""],
        }
    }
    raw_tensor_data = viz_data[""raw_tensor_data""]

    # Precompute C values for each Dot operation
    precomputed_c_values = {}
    for uuid, op_data in raw_tensor_data.items():
        if ""input_data"" in op_data and ""other_data"" in op_data:
            precomputed_c_values[uuid] = precompute_c_values(op_data)

    df = pd.DataFrame(analysis_data, columns=[""Metric"", ""Value""])
    analysis_with_tooltip = get_tooltip_data(df)
    global_data[""analysis""] = analysis_with_tooltip
",triton_viz/visualizer/interface.py,,1,9.736200303530205e-10,"The method 'update_global_data' is likely to survive because it performs a crucial role in updating global variables with processed data. It integrates data analysis, visualization, and precomputation of values, which are essential for the application's functionality. The method is well-structured, making use of helper functions like 'analyze_records', 'get_visualization_data', and 'precompute_c_values', indicating a modular design. Additionally, it uses pandas for data manipulation, suggesting it is part of a data-intensive application. These factors imply that the method is integral to the system's operation and is unlikely to be removed."
survived,"    def test_rolling_1d_array_raises_error(self, move_func):
        """"""Test that 1D arrays raise an appropriate error for rolling functions.""""""
        data_1d = np.array([1, 2, 3, 4, 5], dtype=np.float64)

        with pytest.raises(ValueError, match=""requires at least a 2D array""):
            move_func(data_1d, window=3)
",numbagg/test/test_matrix_functions.py,TestMatrixFunctions,1,2.3355930333443423e-09,"The method is a unit test designed to ensure that a specific function, `move_func`, raises an error when given a 1D array instead of a 2D array. This is a valid and useful test case to ensure the robustness of the `move_func` implementation, as it checks for proper error handling and input validation. Such tests are crucial for maintaining code quality and preventing unexpected behavior in production. Therefore, the method is likely to be retained in the codebase."
survived,"    def __init__(
        self,
        func: Callable,
        signature: tuple[list[tuple], str],
        **kwargs,
    ):
        self.signature = signature
        super().__init__(func, **kwargs)
",numbagg/decorators.py,ndmovematrix,1,1.275190675769241e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting up initial states. The presence of a constructor is crucial for the functionality of the class, especially if it involves setting up important attributes like 'signature' in this case. Therefore, it is unlikely to be deleted unless the entire class is being refactored or removed, which is not indicated here."
survived,"def test_move_matrix_pandas_comp(array, func, window, min_count):
    """"""Test matrix functions against pandas with various parameters.""""""
    if array.ndim < 2:
        pytest.skip(""Matrix functions require at least 2D input"")

    c = COMPARISONS[func]

    if min_count == ""window"":
        min_count = window

    # Get numbagg result
    result = c[""numbagg""](array, window=window, min_count=min_count)()

    # Get pandas result - need to handle the different output format
    pandas_callable = c[""pandas""](array, window=window, min_count=min_count)
    pandas_result = pandas_callable()

    # Convert pandas MultiIndex DataFrame to 3D array for comparison
    n_obs = array.shape[-1]
    n_vars = array.shape[-2]
    expected_pandas = np.full((n_obs, n_vars, n_vars), np.nan)

    # Only include windows where we have at least min_count observations
    actual_min_count = min_count if min_count is not None else window
    for t in range(n_obs):
        # Check if we have enough observations in this window
        window_size = min(t + 1, window)
        if (
            window_size >= actual_min_count
            and t in pandas_result.index.get_level_values(0)
        ):
            expected_pandas[t] = pandas_result.loc[t].values

    assert_allclose(result, expected_pandas)
",numbagg/test/test_moving.py,,1,1.955568070542584e-08,"The method is a test function that compares the output of a custom matrix function with a pandas implementation. It is useful for ensuring the correctness of the custom implementation against a well-known library. Such test functions are crucial for maintaining code quality and reliability, especially when dealing with numerical computations. Therefore, it is likely to be retained as part of the test suite."
survived,"    def test_sparse_valid_data(self):
        """"""Test with very sparse non-NaN observations.""""""
        # Create data where only every 5th observation is valid
        data = np.full((2, 20), np.nan, dtype=np.float64)
        data[0, ::5] = [1, 2, 3, 4]  # Only positions 0, 5, 10, 15
        data[1, ::5] = [2, 4, 6, 8]

        result = move_exp_nancorrmatrix(data, alpha=0.3, min_weight=0.1)

        # Should produce some valid results eventually
        assert not np.all(np.isnan(result))

        # Check that results are reasonable where they exist
        finite_mask = np.isfinite(result)
        if np.any(finite_mask):
            finite_values = result[finite_mask]
            assert np.all(finite_values >= -1.0)
            assert np.all(finite_values <= 1.0)
",numbagg/test/test_move_exp_matrix_advanced.py,TestMoveExpMatrixAdvanced,1,1.725782769012759e-08,"The method 'test_sparse_valid_data' is a unit test designed to verify the behavior of the 'move_exp_nancorrmatrix' function when dealing with sparse data. It checks that the function can handle sparse non-NaN observations and produce valid correlation results. This is a useful test case for ensuring the robustness of the function in handling edge cases, which is a common requirement in software testing. Therefore, it is likely to be retained as part of the test suite to ensure the function's reliability."
survived,"    def test_correlation_with_nans(self):
        """"""Test correlation consistency with NaN values.""""""
        np.random.seed(789)

        # Create two time series with some NaN values
        n_obs = 30
        a1 = np.random.randn(n_obs)
        a2 = np.random.randn(n_obs) * 1.2 + 0.3

        # Add some NaN values
        a1[3:6] = np.nan
        a2[12:15] = np.nan

        alpha = 0.4

        # Compute using non-matrix function
        corr_nonmatrix = move_exp_nancorr(a1, a2, alpha=alpha)

        # Compute using matrix function
        data_matrix = np.array([a1, a2])
        corr_matrix_result = move_exp_nancorrmatrix(data_matrix, alpha=alpha)
        corr_from_matrix = corr_matrix_result[:, 0, 1]

        # They should match
        assert_allclose(corr_nonmatrix, corr_from_matrix, rtol=1e-10)
",numbagg/test/test_move_exp_matrix_consistency.py,TestMoveExpMatrixConsistency,1,2.0611536181902033e-09,"The method 'test_correlation_with_nans' is a unit test designed to verify the consistency of correlation calculations when NaN values are present. It is a useful test to ensure the robustness and correctness of the correlation functions 'move_exp_nancorr' and 'move_exp_nancorrmatrix'. Such tests are crucial for maintaining code quality and reliability, especially in numerical computations. Therefore, it is unlikely to be deleted as it serves an important purpose in validating the functionality of the code."
survived,"    def test_extreme_alpha_values(self):
        """"""Test behavior with alpha values very close to 0 and 1.""""""
        # Use data that's not perfectly correlated to see differences
        np.random.seed(42)
        data = np.random.randn(2, 20)
        data[1] = 0.7 * data[0] + 0.5 * np.random.randn(20)  # Partial correlation

        # Test with alpha very close to 0 (almost no decay)
        result_low = move_exp_nancorrmatrix(data, alpha=1e-6)

        # Test with alpha close to 1 (very fast decay)
        result_high = move_exp_nancorrmatrix(data, alpha=0.99)

        # Both should produce valid results
        assert not np.all(np.isnan(result_low[-1]))
        assert not np.all(np.isnan(result_high[-1]))

        # With different correlation patterns, results should differ
        # Check the off-diagonal correlation values
        assert not np.allclose(result_low[-5:, 0, 1], result_high[-5:, 0, 1], rtol=1e-2)
",numbagg/test/test_move_exp_matrix_advanced.py,TestMoveExpMatrixAdvanced,1,1.3440409770490404e-08,"The method tests the behavior of a function with extreme alpha values, which is a critical aspect of understanding the function's robustness and performance under edge cases. Testing with boundary values is a common practice in software testing to ensure that the function behaves correctly across its entire input domain. This method is likely to be retained as it provides valuable insights into the function's behavior and helps identify potential issues with extreme parameter values."
survived,"def move_exp_nancovmatrix(a, alpha, min_weight, out):
    """"""
    Exponential moving window covariance matrix gufunc.

    For 2D input, computes covariance between variables (rows) across observations (columns) with exponential decay.
    """"""
    n_vars = a.shape[0]
    n_obs = a.shape[1]

    # Initialize pairwise statistics - each (i,j) pair tracks its own statistics
    # This is necessary for consistency with non-matrix exponential functions
    sums_i = np.zeros(
        (n_vars, n_vars), dtype=a.dtype
    )  # sum of variable i for pair (i,j)
    sums_j = np.zeros(
        (n_vars, n_vars), dtype=a.dtype
    )  # sum of variable j for pair (i,j)
    prods = np.zeros((n_vars, n_vars), dtype=a.dtype)  # sum of products for pair (i,j)
    pair_weights = np.zeros(
        (n_vars, n_vars), dtype=a.dtype
    )  # accumulated alpha weights
    pair_sum_weights = np.zeros((n_vars, n_vars), dtype=a.dtype)  # count of valid pairs
    pair_sum_weights_sq = np.zeros(
        (n_vars, n_vars), dtype=a.dtype
    )  # sum of squared weights

    for t in range(n_obs):
        alpha_t = alpha[t]
        decay = 1.0 - alpha_t

        # Apply exponential decay to all pairwise statistics
        for i in range(n_vars):
            for j in range(n_vars):
                sums_i[i, j] *= decay
                sums_j[i, j] *= decay
                prods[i, j] *= decay
                pair_weights[i, j] *= decay
                pair_sum_weights[i, j] *= decay
                pair_sum_weights_sq[i, j] *= decay**2

        # Add new values - track pairwise statistics for consistency
        for i in range(n_vars):
            for j in range(n_vars):
                new_val_i = a[i, t]
                new_val_j = a[j, t]

                # Only update if BOTH values are non-NaN (consistent with non-matrix functions)
                if not (np.isnan(new_val_i) or np.isnan(new_val_j)):
                    # Update pairwise statistics
                    sums_i[i, j] += new_val_i
                    sums_j[i, j] += new_val_j
                    prods[i, j] += new_val_i * new_val_j
                    pair_weights[i, j] += alpha_t
                    pair_sum_weights[i, j] += 1.0
                    pair_sum_weights_sq[i, j] += 1.0

        # Compute covariance matrix for current time step
        for i in range(n_vars):
            for j in range(n_vars):
                # Check if we have sufficient weight for a meaningful covariance calculation
                bias = (
                    1 - pair_sum_weights_sq[i, j] / (pair_sum_weights[i, j] ** 2)
                    if pair_sum_weights[i, j] > 0
                    else 0.0
                )

                if pair_weights[i, j] >= min_weight and bias > 0:
                    # Compute covariance using pairwise statistics
                    n = pair_sum_weights[i, j]
                    mean_i = sums_i[i, j] / n
                    mean_j = sums_j[i, j] / n

                    # Compute biased covariance
                    cov_biased = (prods[i, j] / n) - mean_i * mean_j

                    # Apply bias correction
                    out[t, i, j] = cov_biased / bias
                else:
                    out[t, i, j] = np.nan",numbagg/moving_matrix.py,,1,3.927863699585036e-07,"The method is a specialized function for computing an exponential moving window covariance matrix, which is a niche but useful operation in time series analysis and financial computations. It handles NaN values and applies exponential decay, making it suitable for real-world data that may have missing values. The function is well-documented, and its utility in specific domains like finance or data analysis suggests it is likely to be retained for its specialized purpose."
survived,"    def _format_yaml(self, data: Any) -> str:
        """"""Format as YAML""""""
        return yaml.dump(data, default_flow_style=False, allow_unicode=True)
",src/haconiwa/scan/formatter.py,OutputFormatter,1,5.211412485172657e-10,"The method _format_yaml is a utility function that formats data into a YAML string. This is a common and useful functionality, especially in applications that need to serialize data for configuration files or data exchange. The method is straightforward, uses a well-known library (yaml), and provides a clear purpose. There is no indication that this method is redundant or obsolete, so it is likely to be retained in the codebase."
survived,"    def analyze_all(self) -> Dict[str, Any]:
        """"""Analyze entire directory structure""""""
        analysis = {
            'timestamp': datetime.now().isoformat(),
            'base_path': str(self.base_path),
            'categories': defaultdict(list),
            'providers': defaultdict(list),
            'model_formats': defaultdict(int),
            'total_models': 0,
            'total_size': 0,
            'insights': []
        }
        
        # Scan directory structure
        for root, dirs, files in self.base_path.walk():
            root_path = Path(root)
            
            # Check if this is a model directory
            if self._is_model_directory(root_path, files):
                model_info = self._analyze_model_directory(root_path, files)
                
                if model_info:
                    category = model_info['category']
                    provider = model_info['provider']
                    
                    analysis['categories'][category].append(model_info)
                    analysis['providers'][provider].append(model_info['name'])
                    analysis['total_models'] += 1
                    analysis['total_size'] += model_info.get('size', 0)
                    
                    # Track model formats
                    for fmt in model_info.get('formats', []):
                        analysis['model_formats'][fmt] += 1
        
        # Generate insights
        analysis['insights'] = self._generate_insights(analysis)
        
        # Convert defaultdicts to regular dicts
        analysis['categories'] = dict(analysis['categories'])
        analysis['providers'] = dict(analysis['providers'])
        analysis['model_formats'] = dict(analysis['model_formats'])
        
        return analysis
",src/haconiwa/scan/analyzer.py,ModelAnalyzer,1,1.493094675974231e-10,"The method 'analyze_all' is a comprehensive function that performs a detailed analysis of a directory structure, collecting various statistics and insights about models. It is well-structured, uses defaultdicts for efficient data collection, and converts them to regular dicts before returning, which is a good practice. The method also includes timestamping and handles different aspects like categories, providers, and model formats, making it versatile and useful for applications that need to analyze model directories. Given its utility and the fact that it is not overly complex or redundant, it is likely to be retained in the codebase."
survived,"    def test_whitelist(self, temp_model_dir):
        """"""Test whitelist functionality""""""
        scanner = ModelScanner(
            temp_model_dir,
            whitelist=[""*/openai/*"", ""*/anthropic/*""]
        )
        
        # Should find openai and anthropic models
        results = scanner.search_by_model_name(""gpt-4"")
        assert results['total_files'] > 0
        
        results = scanner.search_by_model_name(""claude-3-opus"")
        assert results['total_files'] > 0
        
        # Should not find meta models (not in whitelist)
        results = scanner.search_by_model_name(""llama-2-70b"")
        assert results['total_files'] == 0
",tests/test_scan/test_scanner.py,TestModelScanner,1,3.653482080241728e-08,"The method 'test_whitelist' is a unit test designed to verify the functionality of a whitelist feature in a model scanning tool. It is a specific test case that ensures the scanner correctly identifies models that are included in the whitelist and excludes those that are not. Such test methods are crucial for maintaining the integrity and reliability of software, especially when dealing with model management and security features. Therefore, it is unlikely to be deleted as it serves an important purpose in the testing suite."
survived,"    def test_generate_from_scan_results_with_files(self):
        """"""Test generation from directory analysis results""""""
        scan_results = {
            'files': {
                'src/utils/helper.py': {'category': 'utils'},
                'src/api/routes.py': {'category': 'api'},
                'src/models/user.py': {'category': 'model'}
            }
        }
        
        config = self.generator.generate_from_scan_results(
            scan_results,
            action='refactor',
            max_files=2
        )
        
        assert len(config['tasks']) == 2
        assert config['metadata']['action'] == 'refactor'
",tests/test_scan/test_generate_parallel.py,TestParallelYAMLGenerator,1,9.736200303530205e-10,"The method `test_generate_from_scan_results_with_files` is a unit test designed to verify the functionality of the `generate_from_scan_results` method. It checks that the method correctly processes a given set of scan results and generates a configuration with the specified action and a limited number of tasks. Unit tests are crucial for ensuring code reliability and are typically retained to maintain code quality. Therefore, this method is likely to be retained."
survived,"    def _dict_to_text(self, data: Dict[str, Any], indent: int = 0) -> str:
        """"""Convert dictionary to formatted text""""""
        lines = []
        indent_str = ""  "" * indent
        
        for key, value in data.items():
            if isinstance(value, dict):
                lines.append(f""{indent_str}{key}:"")
                lines.append(self._dict_to_text(value, indent + 1))
            elif isinstance(value, list):
                lines.append(f""{indent_str}{key}:"")
                for item in value:
                    if isinstance(item, dict):
                        lines.append(self._dict_to_text(item, indent + 1))
                    else:
                        lines.append(f""{indent_str}  - {item}"")
            else:
                lines.append(f""{indent_str}{key}: {value}"")
        
        return ""\n"".join(lines)
",src/haconiwa/scan/formatter.py,OutputFormatter,1,1.1032560311263802e-09,"The method '_dict_to_text' is a utility function that converts a dictionary into a formatted text representation. This type of functionality is commonly needed in various applications for logging, debugging, or displaying data in a human-readable format. The method is well-structured, handles nested dictionaries and lists, and provides indentation for better readability. Such utility functions are generally useful and are likely to be retained in codebases where data needs to be presented in a structured text format. Therefore, it is likely to survive."
survived,"    def _normalize_model_name(self, model_name: str) -> str:
        """"""Normalize model name by stripping common prefixes if enabled""""""
        if not self.strip_prefix:
            return model_name.lower()
        
        normalized = model_name.lower()
        for prefix in self.model_prefixes:
            if normalized.startswith(prefix):
                normalized = normalized[len(prefix):]
                break
        
        return normalized
",src/haconiwa/scan/scanner.py,ModelScanner,1,1.1861120010657661e-08,"The method '_normalize_model_name' is a utility function that normalizes a model name by converting it to lowercase and optionally stripping common prefixes. This kind of functionality is often useful in applications where consistent naming conventions are required, such as in machine learning model management or configuration systems. The method is well-defined, with clear logic and purpose, and it is likely to be used in various parts of a codebase that deals with model names. Therefore, it is unlikely to be deleted as it serves a specific and useful purpose."
survived,"    def test_metadata_generation(self):
        """"""Test metadata is properly generated""""""
        config = self.generator.create_example_yaml()
        
        assert 'metadata' in config
        assert 'generated_at' in config['metadata']
        assert 'source' in config['metadata']
        
        # Check timestamp format
        timestamp = config['metadata']['generated_at']
        # Should be able to parse it
        datetime.fromisoformat(timestamp)
",tests/test_scan/test_generate_parallel.py,TestParallelYAMLGenerator,1,2.0611536181902033e-09,"The method `test_metadata_generation` is a unit test that verifies the functionality of metadata generation in a configuration file. It checks for the presence of specific keys and validates the format of a timestamp. Such tests are crucial for ensuring the reliability and correctness of code, especially when dealing with configuration files that might be used in various environments. Therefore, this method is likely to be retained as it provides value in maintaining code quality and preventing regressions."
survived,"    def search_by_model_name(self, 
                           model_name: str, 
                           include_content: bool = False) -> Dict[str, Any]:
        """"""Search for files and directories related to a model name""""""
        normalized_name = self._normalize_model_name(model_name)
        results = {
            'model_name': model_name,
            'normalized_name': normalized_name,
            'matches': defaultdict(list),
            'total_files': 0,
            'categories': set()
        }
        
        # Search patterns
        patterns = [
            normalized_name,
            model_name.lower(),
            model_name.replace('-', '_'),
            normalized_name.replace('-', '_')
        ]
        
        for root, dirs, files in os.walk(self.base_path):
            root_path = Path(root)
            
            # Filter directories
            dirs[:] = [d for d in dirs if not self._should_ignore(root_path / d)]
            
            # Check directory names
            for pattern in patterns:
                if pattern in root_path.name.lower():
                    category = self._determine_category(root_path)
                    results['categories'].add(category)
                    
                    # Process files in matching directory
                    for file in files:
                        file_path = root_path / file
                        if not self._should_ignore(file_path):
                            file_info = self._get_file_info(file_path, include_content)
                            results['matches'][category].append(file_info)
                            results['total_files'] += 1
            
            # Check file names
            for file in files:
                file_path = root_path / file
                if self._should_ignore(file_path):
                    continue
                
                for pattern in patterns:
                    if pattern in file.lower():
                        category = self._determine_category(root_path)
                        results['categories'].add(category)
                        file_info = self._get_file_info(file_path, include_content)
                        results['matches'][category].append(file_info)
                        results['total_files'] += 1
                        break
        
        results['categories'] = list(results['categories'])
        results['matches'] = dict(results['matches'])
        return results
",src/haconiwa/scan/scanner.py,ModelScanner,1,2.998960815863541e-09,"The method `search_by_model_name` is a utility function that provides a useful feature for searching files and directories based on a model name. It normalizes the model name, searches through directories and files, and categorizes the results. This functionality is likely to be valuable in many applications where file organization and retrieval are important, especially in projects dealing with machine learning models or similar structures. The method is well-structured, uses helper functions for modularity, and returns a comprehensive dictionary of results. Therefore, it is unlikely to be deleted as it serves a clear purpose and is potentially useful in various contexts."
survived,"    def test_save_yaml(self):
        """"""Test YAML file saving""""""
        config = {
            'provider': 'claude',
            'tasks': [
                {'file': 'test.py', 'prompt': 'Add tests'}
            ],
            'options': {
                'max_concurrent': 1,
                'timeout': 60
            }
        }
        
        output_path = self.temp_dir / 'test-output.yaml'
        saved_path = self.generator.save_yaml(config, output_path)
        
        assert saved_path == output_path
        assert output_path.exists()
        
        # Load and verify saved content
        with open(output_path, 'r') as f:
            loaded_config = yaml.safe_load(f)
        
        assert loaded_config['provider'] == 'claude'
        assert len(loaded_config['tasks']) == 1
        assert loaded_config['tasks'][0]['file'] == 'test.py'
",tests/test_scan/test_generate_parallel.py,TestParallelYAMLGenerator,1,8.592166611791576e-10,"The method `test_save_yaml` is a unit test designed to verify the functionality of saving a YAML file. It checks if the file is saved correctly and if the contents match the expected configuration. Such tests are crucial for ensuring the reliability of file operations in software applications. Since testing is an integral part of software development to maintain code quality and prevent regressions, this method is likely to be retained in the codebase."
survived,"    def _format_summary(self, data: Any) -> str:
        """"""Format as a concise summary""""""
        if not isinstance(data, dict):
            return str(data)
        
        lines = [""="" * 50]
        
        # Handle model search results
        if 'model_name' in data:
            lines.append(f""Model Search: {data['model_name']}"")
            lines.append(""="" * 50)
            lines.append(f""Total files found: {data.get('total_files', 0)}"")
            
            if 'matches' in data:
                lines.append(""\nMatches by category:"")
                for category, files in data['matches'].items():
                    lines.append(f""  {category}: {len(files)} files"")
        
        # Handle content search results
        elif 'pattern' in data and 'matches' in data:
            lines.append(f""Content Search: {data['pattern']}"")
            lines.append(""="" * 50)
            lines.append(f""Total matches: {data.get('total_matches', 0)}"")
            lines.append(f""Files searched: {data.get('files_searched', 0)}"")
            
            if data['matches']:
                lines.append(""\nTop matches:"")
                for match in data['matches'][:5]:
                    lines.append(f""  {match['file']}:{match['line_number']}"")
        
        # Handle analysis results
        elif 'categories' in data and 'providers' in data:
            lines.append(""Model Analysis Summary"")
            lines.append(""="" * 50)
            lines.append(f""Base path: {data.get('base_path', 'Unknown')}"")
            lines.append(f""Total models: {data.get('total_models', 0)}"")
            
            if data.get('total_size', 0) > 0:
                size_gb = data['total_size'] / (1024 ** 3)
                lines.append(f""Total size: {size_gb:.2f} GB"")
            
            if 'insights' in data:
                lines.append(""\nInsights:"")
                for insight in data['insights']:
                    lines.append(f""  â€¢ {insight}"")
        
        # Handle list results
        elif isinstance(data, list) and data:
            lines.append(f""Results: {len(data)} items"")
            lines.append(""="" * 50)
            for i, item in enumerate(data[:10], 1):
                if isinstance(item, dict):
                    name = item.get('name', item.get('path', 'Unknown'))
                    lines.append(f""{i}. {name}"")
                else:
                    lines.append(f""{i}. {item}"")
            
            if len(data) > 10:
                lines.append(f""... and {len(data) - 10} more"")
        
        lines.append(""="" * 50)
        return ""\n"".join(lines)
",src/haconiwa/scan/formatter.py,OutputFormatter,1,1.4166087846364157e-09,"The method '_format_summary' is a utility function that formats data into a human-readable summary. It handles various types of data structures, such as dictionaries and lists, and provides a structured output based on the content of the data. This kind of method is useful for logging, reporting, or displaying information to users in a concise manner. Since it serves a clear purpose and is likely to be used in multiple parts of a codebase where data needs to be summarized, it is unlikely to be deleted unless the entire functionality it supports is removed or replaced. Therefore, the method is predicted to survive."
survived,"    def test_scan_generate_parallel_config_from_model(self, runner, temp_model_dir):
        """"""Test generate-parallel-config from model search""""""
        with tempfile.TemporaryDirectory() as tmpdir:
            output_path = Path(tmpdir) / ""parallel-dev.yaml""
            
            # Change to temp_model_dir before running command
            import os
            original_cwd = os.getcwd()
            try:
                os.chdir(temp_model_dir)
                result = runner.invoke(
                    scan_app,
                    [""generate-parallel-config"", 
                     ""--source"", ""model:o1-mini"", 
                     ""--action"", ""add_tests"",
                     ""--output"", str(output_path)]
                )
            finally:
                os.chdir(original_cwd)
            
            assert result.exit_code == 0
            assert ""Generated parallel-dev YAML"" in result.stdout
            assert output_path.exists()
",tests/test_scan/test_cli.py,TestScanCLI,1,4.599055376537186e-10,"The method is a well-structured test case that verifies the functionality of generating a parallel configuration from a model. It uses a temporary directory to ensure no side effects on the file system, changes the working directory to the model directory, and checks the command's success and output. These are all good practices in testing, making the method valuable for maintaining code quality. Therefore, it is likely to be retained."
survived,"    def test_full_workflow(self):
        """"""Test complete workflow from scan results to YAML generation""""""
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)
            
            # Create test files
            model_dir = temp_path / 'models'
            model_dir.mkdir()
            (model_dir / 'user.py').write_text('class User: pass')
            (model_dir / 'product.py').write_text('class Product: pass')
            
            api_dir = temp_path / 'api'
            api_dir.mkdir()
            (api_dir / 'routes.py').write_text('def get_users(): pass')
            
            # Create generator
            generator = ParallelYAMLGenerator(base_path=temp_path)
            
            # Simulate scan results
            scan_results = {
                'matches': {
                    'model': [
                        {'path': 'models/user.py', 'type': 'python'},
                        {'path': 'models/product.py', 'type': 'python'}
                    ],
                    'api': [
                        {'path': 'api/routes.py', 'type': 'python'}
                    ]
                }
            }
            
            # Generate YAML
            config = generator.generate_from_scan_results(
                scan_results,
                action='add_type_hints',
                max_files=10
            )
            
            # Save YAML
            output_path = temp_path / 'parallel-dev.yaml'
            generator.save_yaml(config, output_path)
            
            # Verify
            assert output_path.exists()
            
            with open(output_path, 'r') as f:
                loaded = yaml.safe_load(f)
            
            assert loaded['provider'] == 'claude'
            assert len(loaded['tasks']) == 3
            assert loaded['metadata']['action'] == 'add_type_hints'
            
            # Check task content
            file_paths = [task['file'] for task in loaded['tasks']]
            assert 'models/user.py' in file_paths
            assert 'models/product.py' in file_paths
            assert 'api/routes.py' in file_paths",tests/test_scan/test_generate_parallel.py,TestGenerateParallelIntegration,1,2.3355930333443423e-09,"The method `test_full_workflow` is a comprehensive test case that verifies the entire workflow from creating test files, simulating scan results, generating YAML configuration, saving it, and verifying the output. It is crucial for ensuring the functionality of the system it tests, especially in a development or CI/CD environment. Such test methods are typically retained to ensure the system's reliability and correctness over time."
survived,"    def test_scan_generate_parallel_config_project_wide(self, runner, temp_model_dir):
        """"""Test generate-parallel-config for project-wide changes""""""
        with tempfile.TemporaryDirectory() as tmpdir:
            output_path = Path(tmpdir) / ""project-wide.yaml""
            
            # Change to temp_model_dir before running command
            import os
            original_cwd = os.getcwd()
            try:
                os.chdir(temp_model_dir)
                result = runner.invoke(
                    scan_app,
                    [""generate-parallel-config"",
                     ""--project-wide"", ""*.py"",
                     ""--action"", ""add_type_hints"",
                     ""--output"", str(output_path)]
                )
            finally:
                os.chdir(original_cwd)
            
            assert result.exit_code == 0
            assert ""Generated project-wide YAML"" in result.stdout
",tests/test_scan/test_cli.py,TestScanCLI,1,1.6052280526088547e-09,"The method 'test_scan_generate_parallel_config_project_wide' is a unit test designed to verify the functionality of a command-line tool. It uses a temporary directory to store output and checks the exit code and output message to ensure the command runs successfully. This is a typical pattern for testing CLI tools and is essential for maintaining code quality and reliability. Therefore, it is unlikely to be deleted as it serves a critical role in the testing suite."
survived,"    def generate_for_model_migration(self,
                                   old_model: str,
                                   new_model: str,
                                   files: List[str]) -> Dict[str, Any]:
        """"""Generate YAML for model migration tasks""""""
        
        tasks = []
        
        for file_path in files:
            prompt = f""Migrate code from {old_model} to {new_model}. Update import statements, "" \
                    f""API calls, method names, and parameters. Ensure compatibility with {new_model} "" \
                    f""while maintaining existing functionality. Add migration comments where significant changes are made.""
            
            tasks.append({
                'file': file_path,
                'prompt': prompt
            })
        
        config = {
            'provider': 'claude',
            'metadata': {
                'generated_at': datetime.now().isoformat(),
                'source': 'haconiwa scan generate-parallel-config',
                'migration': f""{old_model} -> {new_model}"",
                'total_tasks': len(tasks)
            },
            'tasks': tasks,
            'options': {
                'max_concurrent': 3,
                'timeout': 180,  # 3 minutes for migration tasks
                'allowed_tools': ['Read', 'Write', 'Edit', 'MultiEdit'],
                'permission_mode': 'confirmEach',
                'output_dir': f'./migration-{old_model}-to-{new_model}'
            }
        }
        
        return config
",src/haconiwa/scan/generate_parallel.py,ParallelYAMLGenerator,1,5.905303995456778e-10,"The method `generate_for_model_migration` is well-defined and serves a specific purpose of generating a configuration for model migration tasks. It constructs a YAML configuration with detailed prompts for each file that needs migration, includes metadata, and specifies options for the migration process. This functionality is useful for automating and managing model migration tasks, which is a common requirement in software development. The method is likely to be used in scenarios where automated code migration is needed, making it a valuable utility. Therefore, it is likely to survive."
survived,"    def __init__(self):
        self.format_handlers = {
            'text': self._format_text,
            'json': self._format_json,
            'yaml': self._format_yaml,
            'summary': self._format_summary,
            'table': self._format_table,
            'tree': self._format_tree
        }
",src/haconiwa/scan/formatter.py,OutputFormatter,1,5.3157849718487075e-08,"The method is a constructor for initializing an object with a dictionary of format handlers. This is a common and useful pattern in object-oriented programming, allowing for easy extension and maintenance of code. Each key in the dictionary corresponds to a specific format, and the value is a method that handles that format. This design is flexible and can be easily expanded to include more formats or modify existing ones. Therefore, it is likely to be retained in the codebase."
survived,"    def process_dimension_data(
        summary_df, func, dimension, all_libs, matrix_shape_exclusions
    ):
        """"""Process data for a single dimension (1D or 2D) for a specific function.""""""
        if summary_df.empty:
            return {f""{dimension}_{lib}"": ""n/a"" for lib in all_libs}

        return {
            f""{dimension}_{lib}"": get_column_value(
                summary_df, func, lib, dimension, matrix_shape_exclusions
            )
            for lib in all_libs
        }
",numbagg/test/run_benchmarks.py,,1,3.581747929000289e-10,"The method 'process_dimension_data' is likely to survive because it performs a specific and useful task: processing data for a given dimension and function. It handles edge cases, such as when the input DataFrame is empty, and it dynamically constructs a dictionary based on the provided libraries. This kind of utility function is often necessary in data processing pipelines, making it a valuable part of the codebase."
survived,"    def test_with_nans(self, func):
        """"""Test with NaN values.""""""
        # Exponential moving functions expect (obs, vars) format
        data = np.array(
            [[1, 2, np.nan], [2, 4, 1], [np.nan, 6, 2], [4, np.nan, 3]],
            dtype=np.float64,
        )
        alpha = 0.3
        result = func(data, alpha=alpha)

        # Check shape
        assert result.shape == (4, 3, 3)

        # Should handle NaN gracefully - check that we get some finite values
        assert np.any(np.isfinite(result))
",numbagg/test/test_matrix_functions.py,TestExponentialMatrices,1,3.2241866333029355e-08,"The method 'test_with_nans' is a unit test designed to verify the behavior of a function when it encounters NaN values in the input data. It is a useful test case for ensuring that the function can handle missing data gracefully, which is a common scenario in data processing tasks. The test checks both the shape of the output and that the output contains some finite values, which are reasonable expectations for a function processing data with NaNs. Given its utility in validating the robustness of the function being tested, it is likely to be retained."
survived,"    def __exit__(self, exc_type, exc_val, exc_tb):
        """"""Context manager exit - ensure connections are closed.""""""
        self.close_all_connections()
",ocode_python/core/context_manager.py,ContextManager,1,9.931195248674785e-08,"The method is a standard implementation of the __exit__ method for a context manager in Python. It ensures that all connections are closed when exiting the context, which is a crucial part of resource management. This method is likely to be retained as it follows the correct pattern for managing resources and preventing resource leaks."
survived,"    def test_command_sanitizer_unix_only(self, mock_platform):
        """"""Test that Windows patterns are not applied on Unix.""""""
        sanitizer = CommandSanitizer()

        # Windows-specific patterns should not be in Unix sanitizer
        assert (
            len([p for p in sanitizer.forbidden_patterns if ""format.*[cC]:"" in p]) == 0
        )
        assert len([p for p in sanitizer.forbidden_patterns if ""taskkill"" in p]) == 0
",tests/unit/test_windows_compatibility.py,TestWindowsCompatibility,1,4.6911638017642294e-08,"The method 'test_command_sanitizer_unix_only' is a unit test that verifies the behavior of the 'CommandSanitizer' class on Unix systems. It checks that Windows-specific patterns are not included in the forbidden patterns list when running on Unix. This is a valid and necessary test to ensure platform-specific behavior is correctly implemented. As such, it is unlikely to be deleted unless the functionality it tests is removed or significantly changed."
survived,"def deploy_staticfiles(release: Release) -> bool:
    """"""Deploy static files to CDN.""""""
    print(""Deploying static files to cdn"")
    cc = f""public, max-age={int(datetime.timedelta(days=365).total_seconds())}""

    if not release.static_key:
        print(""No static files to deploy"")
        return True

    with tempfile.NamedTemporaryFile(suffix=os.path.basename(release.static_key)) as f:
        download_release_fileobj(release.static_key, f)
        f.flush()
        with DeploymentJob(f.name, ""ce-cdn.net"", version=release.version, cache_control=cc) as job:
            return job.run()
",bin/lib/builds_core.py,,1,3.850741907939403e-09,"The method 'deploy_staticfiles' is a utility function that handles the deployment of static files to a CDN. It includes logging, cache control settings, and uses a temporary file to manage the deployment process. This functionality is essential for web applications that rely on CDNs for performance optimization. The method is well-structured and serves a clear purpose, making it unlikely to be deleted unless there is a significant change in the deployment strategy or architecture."
survived,"def notify_sentry_deployment(cfg: Config, release: Release) -> None:
    """"""Notify Sentry about a deployment. Failures are logged but don't stop deployment.""""""
    try:
        print(""Marking as a release in sentry..."")
        token = get_ssm_param(""/compiler-explorer/sentryAuthToken"")
        result = requests.post(
            f""https://sentry.io/api/0/organizations/compiler-explorer/releases/{release.version}/deploys/"",
            data=dict(environment=cfg.env.value),
            headers=dict(Authorization=f""Bearer {token}""),
            timeout=30,
        )
        if not result.ok:
            print(f""Warning: Failed to notify sentry: {result.status_code}"")
            # Don't fail deployment for sentry notification failure
        else:
            print(""...done"")
    except Exception as e:
        print(f""Warning: Failed to notify sentry: {e}"")
",bin/lib/builds_core.py,,1,1.8189616842444243e-09,"The method 'notify_sentry_deployment' is likely to survive because it serves a specific purpose of notifying Sentry about deployments, which is a common requirement in many software deployment processes. The method is designed to handle failures gracefully by logging them without stopping the deployment process, which is a practical approach in real-world applications. Additionally, the method uses a try-except block to catch exceptions, ensuring robustness. These characteristics make it a useful and reliable part of the deployment process, suggesting it will be retained."
survived,"def old_deploy_staticfiles(branch: Optional[str], versionfile: str) -> None:
    """"""Deploy static files using the old method (for releases without static_key).""""""
    print(""Deploying static files"")
    downloadfile = versionfile
    filename = ""deploy.tar.xz""
    remotefile = (branch + ""/"" if branch else """") + downloadfile
    download_release_file(remotefile[1:], filename)
    os.mkdir(""deploy"")
    subprocess.call([""tar"", ""-C"", ""deploy"", ""-Jxf"", filename])
    os.remove(filename)
    subprocess.call([""aws"", ""s3"", ""sync"", ""deploy/out/dist/dist"", ""s3://compiler-explorer/dist/cdn""])
    subprocess.call([""rm"", ""-Rf"", ""deploy""])
",bin/lib/builds_core.py,,0,0.9999999317439577,"The method 'old_deploy_staticfiles' is likely to be deleted because it is explicitly labeled as an 'old method' in the docstring. This suggests that it is a legacy function that might be replaced by a newer, more efficient method. Additionally, the use of subprocess calls and manual file handling indicates that there might be more modern or secure ways to handle these operations, such as using libraries or services that abstract these details. As software evolves, older methods are often deprecated in favor of newer ones that offer better performance, security, or maintainability."
survived,"    def test_run_with_uv_with_requirements(self, mock_run):
        """"""Test run_with_uv with requirements file.""""""
        mock_run.return_value = Mock(returncode=0)
        req_path = Path(""requirements.txt"")

        with pytest.raises(SystemExit) as exc_info:
            run_with_uv(""server.py"", with_requirements=req_path)

        assert exc_info.value.code == 0

        cmd = mock_run.call_args[0][0]
        expected = [
            ""uv"",
            ""run"",
            ""--with"",
            ""fastmcp"",
            ""--with-requirements"",
            ""requirements.txt"",
            ""fastmcp"",
            ""run"",
            ""server.py"",
        ]
        assert cmd == expected
",tests/cli/test_run_with_uv.py,TestRunWithUv,1,1.955568070542584e-08,"The method is a unit test for a function `run_with_uv` and is testing a specific functionality related to handling a requirements file. Unit tests are crucial for ensuring code reliability and are generally not deleted unless the functionality they test is removed or significantly changed. Since the method is testing a specific feature and there is no indication that the feature is deprecated or removed, it is likely to be retained."
survived,"def _build_tree_structure(
    node: ClusterTreeNode,
    node_id_to_cluster: dict[str, ClusterTreeNode],
    level: int = 0,
    is_last: bool = True,
    prefix: str = """",
) -> str:
    """"""Build a text representation of the hierarchical cluster tree.
    
    This is a recursive helper function used by visualise_clusters().
    
    Args:
        node: Current tree node
        node_id_to_cluster: Dictionary mapping node IDs to nodes
        level: Current depth in the tree (for indentation)
        is_last: Whether this is the last child of its parent
        prefix: Current line prefix for tree structure
        
    Returns:
        String representation of the tree structure
    """"""
    # Current line prefix (used for tree visualization symbols)
    current_prefix = prefix

    # Add the appropriate connector based on whether this is the last child
    if level > 0:
        if is_last:
            current_prefix += ""â•šâ•â• ""
        else:
            current_prefix += ""â• â•â• ""

    # Print the current node
    result = (
        current_prefix + node.name + "" ("" + str(node.count) + "" conversations)\n""
    )

    # Calculate the prefix for children (continue vertical lines for non-last children)
    child_prefix = prefix
    if level > 0:
        if is_last:
            child_prefix += ""    ""  # No vertical line needed for last child's children
        else:
            child_prefix += ""â•‘   ""  # Continue vertical line for non-last child's children

    # Process children
    children = node.children
    for i, child_id in enumerate(children):
        child = node_id_to_cluster[child_id]
        is_last_child = i == len(children) - 1
        result += _build_tree_structure(
            child, node_id_to_cluster, level + 1, is_last_child, child_prefix
        )

    return result
",kura/v1/visualization.py,,1,1.955568070542584e-08,"The method '_build_tree_structure' is a recursive function that builds a text representation of a hierarchical cluster tree. It is a helper function used by another function 'visualise_clusters()'. The method is well-documented, with clear arguments and return type, and it serves a specific purpose in visualizing data structures. Such utility functions are often retained in codebases as they provide essential functionality for data representation and debugging. Additionally, the method is not overly complex and follows a logical structure, making it easy to maintain and understand. Therefore, it is likely to be retained in the codebase."
survived,"    def __len__(self) -> int:
        """"""Number of steps in the pipeline.""""""
        return len(self.steps)
",bayesianbandits/pipelines/_learner.py,LearnerPipeline,1,3.850741907939403e-09,"The method `__len__` is a standard Python special method used to define the behavior of the `len()` function for instances of a class. In this case, it returns the number of steps in a pipeline, which is likely a core functionality of the class it belongs to. This method is straightforward, follows Python conventions, and provides essential functionality for interacting with the object. Therefore, it is unlikely to be deleted."
survived,"    def test_indexing(self):
        """"""Test step indexing.""""""
        arms = make_arms(range(3))
        agent = ContextualAgent(arms, ThompsonSampling())
        transform1 = FunctionTransformer(lambda x: x * 2)
        transform2 = StandardScaler()
        steps = [(""double"", transform1), (""scale"", transform2)]

        pipeline = ContextualAgentPipeline(steps, agent)

        # Test string indexing
        assert pipeline[""double""] is transform1
        assert pipeline[""scale""] is transform2

        # Test integer indexing
        assert pipeline[0] == (""double"", transform1)
        assert pipeline[1] == (""scale"", transform2)

        # Test invalid access
        with pytest.raises(KeyError):
            _ = pipeline[""invalid""]

        with pytest.raises(IndexError):
            _ = pipeline[10]
",tests/test_agent_pipeline.py,TestContextualAgentPipeline,1,1.955568070542584e-08,"The method 'test_indexing' is a unit test designed to verify the functionality of indexing in the 'ContextualAgentPipeline' class. It checks both string and integer indexing, as well as handling of invalid access. Such tests are crucial for ensuring the robustness and correctness of the code, especially in a pipeline or framework where indexing is a common operation. Therefore, this method is likely to be retained as it serves an important role in maintaining code quality."
survived,"    def transform(self, X: Any) -> Any:
        """"""Apply all transformers to input data.""""""
        return _transform_data(X, self.steps)
",bayesianbandits/pipelines/_agent.py,ContextualAgentPipeline,1,2.0611536181902033e-09,"The method 'transform' is a crucial part of a data processing pipeline, especially in machine learning and data transformation contexts. It applies a series of transformations (steps) to the input data (X), which is a common requirement in data preprocessing. The method is likely part of a class that handles data transformations, and such methods are essential for preparing data for analysis or model training. Therefore, it is unlikely to be deleted as it serves a fundamental purpose in the data processing workflow."
survived,"    def test_contextual_agent_dispatch(self):
        """"""Test factory dispatches to ContextualAgentPipeline for ContextualAgent.""""""
        arms = make_arms(range(3))
        agent = ContextualAgent(arms, ThompsonSampling())
        steps = [(""identity"", FunctionTransformer())]

        pipeline = AgentPipeline(steps, agent)

        assert isinstance(pipeline, ContextualAgentPipeline)
        assert pipeline._agent is agent
",tests/test_agent_pipeline.py,TestAgentPipelineFactory,1,1.2098660619383578e-06,"The method `test_contextual_agent_dispatch` is a unit test that verifies the correct instantiation and behavior of a `ContextualAgentPipeline`. Unit tests are crucial for ensuring code reliability and correctness, especially in complex systems involving multiple components like agents and pipelines. This test checks that the pipeline is correctly created and associated with the given agent, which is a fundamental aspect of the system's functionality. Therefore, it is unlikely to be deleted as it serves an important role in maintaining code quality."
survived,"    def test_predict_method(self):
        """"""Test predict method delegates correctly.""""""
        X = np.array([[1, 2], [3, 4]])

        # Train the pipeline first
        self.pipeline.partial_fit(X, np.array([1, 2]))

        # Now predict
        self.pipeline.predict(X)

        assert len(self.mock_learner.predict_calls) == 1
        received_X = self.mock_learner.predict_calls[0]
        assert received_X.shape == X.shape
",tests/test_learner_pipeline.py,TestLearnerPipelineInterface,1,1.522997951276035e-08,"The method `test_predict_method` is a unit test designed to verify the correct functionality of a `predict` method within a machine learning pipeline. It ensures that the `predict` method is called exactly once and that it receives the correct input shape. This is a standard practice in software development to ensure code reliability and correctness. Since testing is a crucial part of maintaining code quality, this method is likely to be retained to ensure the predict functionality works as expected."
survived,"    def test_sklearn_transformer_integration(self):
        """"""Test integration with sklearn transformers.""""""
        # Pre-fit scaler
        scaler = StandardScaler()
        historical_data = np.array([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])
        scaler.fit(historical_data)

        arms = make_arms(range(3))
        agent = ContextualAgent(arms, ThompsonSampling(), random_seed=42)

        steps = [(""scale"", scaler)]
        pipeline = ContextualAgentPipeline(steps, agent)

        X = np.array([[2.0, 3.0], [4.0, 5.0]])

        # Should work with pre-fitted transformer
        actions = pipeline.pull(X)
        assert len(actions) == 2

        y = np.array([1.0, 2.0])
        pipeline.update(X, y)
",tests/test_agent_pipeline.py,TestTransformationFlow,1,2.3355930333443423e-09,"The method `test_sklearn_transformer_integration` is a unit test that verifies the integration of a pre-fitted sklearn transformer with a custom pipeline. It is important for ensuring that the pipeline works correctly with pre-fitted transformers, which is a common use case in machine learning workflows. The test is specific, uses assertions to validate behavior, and is part of a testing suite, which is crucial for maintaining code quality and reliability. Therefore, it is likely to be retained."
survived,"    def test_random_state_property(self):
        """"""Test random_state property delegation.""""""
        # Test getting random_state
        self.mock_learner.random_state = 42  # type: ignore
        assert self.pipeline.random_state == 42

        # Test setting random_state
        self.pipeline.random_state = 123
        assert self.mock_learner.random_state == 123
",tests/test_learner_pipeline.py,TestLearnerPipelineInterface,1,2.5109990926928157e-08,"The method 'test_random_state_property' is a unit test designed to verify the correct delegation of the 'random_state' property between a pipeline and a mock learner. This is a common practice in testing to ensure that properties are correctly passed and modified between components in a system. The method is useful for maintaining the integrity of the codebase by ensuring that changes to the 'random_state' in one part of the system are accurately reflected in another. Given its role in ensuring code reliability and correctness, it is likely to be retained in the codebase."
survived,"    def test_complex_pipeline(self):
        """"""Test complex pipeline with multiple transformers.""""""
        # Pre-fit transformers
        scaler = StandardScaler()
        pca = PCA(n_components=5)

        # Fit on dummy high-dimensional data
        dummy_data = np.random.randn(100, 20)
        scaler.fit(dummy_data)
        pca.fit(scaler.transform(dummy_data))

        pipeline = LearnerPipeline(
            steps=[(""scale"", scaler), (""pca"", pca)],
            learner=NormalRegressor(alpha=0.1, beta=1.0)
        )

        # High-dimensional data
        X = np.random.randn(50, 20)
        y = np.random.randn(50)

        # Should handle the full pipeline
        pipeline.partial_fit(X, y)

        # Test inference
        X_test = np.random.randn(10, 20)
        samples = pipeline.sample(X_test, size=1)
        assert samples.shape == (1, 10)  # (size, n_samples)

        predictions = pipeline.predict(X_test)
        assert predictions.shape == (10,)
",tests/test_learner_pipeline.py,TestLearnerPipelineIntegration,1,8.76424914819242e-08,"The method 'test_complex_pipeline' is a unit test designed to verify the functionality of a complex machine learning pipeline. It includes pre-fitting transformers, fitting a pipeline on dummy data, and testing both the fitting and prediction capabilities of the pipeline. Such tests are crucial for ensuring that the components of a machine learning system work together as expected. Given its role in validating the correctness of the pipeline, it is unlikely to be deleted unless the entire pipeline or testing framework is being deprecated or replaced."
survived,"    def test_basic_construction(self):
        """"""Test basic non-contextual pipeline construction.""""""
        arms = make_arms(range(3))
        agent = Agent(arms, ThompsonSampling())
        steps = [(""identity"", FunctionTransformer())]

        pipeline = NonContextualAgentPipeline(steps, agent)

        assert len(pipeline) == 1
        assert pipeline._agent is agent
",tests/test_agent_pipeline.py,TestNonContextualAgentPipeline,1,5.3157849718487075e-08,"The method `test_basic_construction` is a unit test that verifies the basic construction of a `NonContextualAgentPipeline` object. It checks that the pipeline is correctly initialized with the given steps and agent, and asserts the length of the pipeline and the agent association. This is a fundamental test to ensure the pipeline's construction logic is working as expected. Such tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is likely to be retained in the codebase."
survived,"    def update(
        self,
        y: NDArray[np.float64],
        sample_weight: Optional[NDArray[np.float64]] = None,
    ) -> None:
        """"""Update the wrapped agent with observed reward(s).

        Parameters
        ----------
        y : NDArray[np.float64]
            Reward(s) to use for updating the arm.
        sample_weight : Optional[NDArray[np.float64]], default=None
            Sample weights to use for updating the arm.
        """"""
        self._agent.update(y, sample_weight=sample_weight)
",bayesianbandits/pipelines/_agent.py,NonContextualAgentPipeline,1,4.599055376537186e-10,"The method is a standard update function for an agent, which is a common pattern in machine learning and reinforcement learning frameworks. It is well-documented, uses type annotations, and provides flexibility with optional sample weights. Such methods are essential for updating models with new data, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained."
survived,"    def create_implementation_blueprint(self, feature_request: str, context_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """"""Create a detailed implementation blueprint based on context analysis.""""""
        blueprint = {
            ""feature"": feature_request,
            ""implementation_steps"": self._generate_implementation_steps(feature_request, context_analysis),
            ""file_modifications"": self._identify_file_modifications(feature_request, context_analysis),
            ""new_files_required"": self._identify_new_files(feature_request, context_analysis),
            ""dependencies"": self._identify_dependencies(feature_request, context_analysis),
            ""testing_strategy"": self._generate_testing_strategy(feature_request, context_analysis),
            ""integration_points"": self._identify_integration_points(feature_request, context_analysis)
        }
        return blueprint
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,1,5.211412485172657e-10,"The method 'create_implementation_blueprint' is likely to survive because it provides a structured approach to generating a comprehensive implementation plan for a feature request. It breaks down the process into several key components such as implementation steps, file modifications, new files, dependencies, testing strategy, and integration points. This modular approach is beneficial for software development as it ensures thorough planning and consideration of various aspects of implementation. Additionally, the method is well-documented and uses helper methods (presumably defined elsewhere) to handle specific tasks, which promotes code reusability and maintainability."
survived,"    def setup_agents(self):
        """"""Setup the multi-agent team with Context Engineering support.""""""
        
        # 1. Product Manager Agent - Defines requirements
        self.product_manager = Agent(
            name=""Product Manager"",
            role=""Product Requirements Specialist"",
            goal=""Define clear, comprehensive product requirements and user stories"",
            backstory=""""""You are an experienced product manager who specializes in 
            creating detailed, actionable requirements. You understand that clear 
            requirements are the foundation of successful implementation."""""",
            instructions=""""""
            When defining requirements:
            1. Be specific and measurable
            2. Include user acceptance criteria
            3. Consider edge cases and error scenarios
            4. Define success metrics
            5. Specify technical constraints
            """""",
            llm=self.llm,
            verbose=True
        )
        
        # 2. Context Engineering Agent - Generates comprehensive context
        self.context_engineer = create_context_agent(
            llm=self.llm,
            name=""Context Engineering Specialist"",
            verbose=True
        )
        
        # 3. Software Architect Agent - Designs implementation using context
        self.architect = Agent(
            name=""Software Architect"",
            role=""System Architecture Specialist"", 
            goal=""Design robust, scalable system architecture based on comprehensive context"",
            backstory=""""""You are a senior software architect with expertise in 
            designing systems that follow established patterns and best practices. 
            You excel at creating architectures that integrate seamlessly with 
            existing codebases."""""",
            instructions=""""""
            When designing architecture:
            1. Follow the patterns identified in the context analysis
            2. Ensure compatibility with existing systems
            3. Design for scalability and maintainability
            4. Consider security and performance implications
            5. Document architectural decisions and rationale
            """""",
            llm=self.llm,
            verbose=True
        )
        
        # 4. Senior Developer Agent - Implements using context-enhanced guidance
        self.developer = Agent(
            name=""Senior Developer"",
            role=""Implementation Specialist"",
            goal=""Implement features following context-guided best practices"",
            backstory=""""""You are a senior developer who excels at implementing 
            features that follow established codebase patterns. You understand 
            that consistency and quality are paramount."""""",
            instructions=""""""
            When implementing features:
            1. Follow the codebase patterns identified in context analysis
            2. Maintain consistency with existing code style
            3. Implement comprehensive error handling
            4. Write clean, maintainable code
            5. Follow the implementation blueprint exactly
            """""",
            llm=self.llm,
            verbose=True
        )
        
        # 5. QA Engineer Agent - Validates using context-generated criteria
        self.qa_engineer = Agent(
            name=""QA Engineer"",
            role=""Quality Assurance Specialist"",
            goal=""Ensure implementation meets all quality criteria and requirements"",
            backstory=""""""You are an experienced QA engineer who specializes in 
            comprehensive testing and validation. You understand that quality 
            is built in, not bolted on."""""",
            instructions=""""""
            When validating implementations:
            1. Use the validation criteria from context analysis
            2. Test both happy path and edge cases
            3. Verify integration with existing systems
            4. Check for security vulnerabilities
            5. Validate performance requirements
            """""",
            llm=self.llm,
            verbose=True
        )
",examples/python/concepts/context-engineering-workflow.py,ContextEngineeringWorkflow,1,1.8553915987649156e-07,"The method `setup_agents` is crucial for initializing a multi-agent system, which is a core part of the functionality described. It sets up different agents with specific roles and responsibilities, which are essential for the system's operation. Each agent has a clear purpose and detailed instructions, indicating that this setup is integral to the system's design and operation. Removing this method would likely break the system's functionality, making it unlikely to be deleted."
survived,"    def _analyze_import_patterns(self, project_path: str, file_patterns: List[str]) -> Dict[str, Any]:
        """"""Analyze import patterns and dependencies.""""""
        imports = {""relative"": [], ""absolute"": [], ""external"": [], ""patterns"": []}
        # Implementation would analyze actual import statements
        return imports
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,1,6.023574641292144e-08,"The method '_analyze_import_patterns' is a private method (indicated by the underscore prefix) that is designed to analyze import patterns and dependencies in a project. Although the current implementation is a placeholder, it is likely part of a larger system that requires this functionality. Analyzing import patterns is a common task in software development for understanding dependencies, refactoring, or optimizing code. Therefore, it is likely that this method will be implemented in the future or is already used in a context where its functionality is necessary. Thus, it is more likely to be retained and further developed rather than deleted."
survived,"    def _generate_expected_outcome(self, criterion: str) -> str:
        """"""Generate expected outcome for a criterion.""""""
        return f""Criterion '{criterion}' passes validation""
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,1,1.1861120010657661e-08,"The method _generate_expected_outcome is a simple utility function that formats a string based on the input criterion. It is likely to be used internally within a class or module to provide consistent messaging or logging. Such utility functions are generally useful for maintaining code readability and consistency, especially if the formatted message is used in multiple places. Therefore, it is likely to be retained in the codebase."
survived,"    def _analyze_readme_style(self, project_path: str) -> Dict[str, Any]:
        """"""Analyze README style and structure.""""""
        return {""style"": ""standard"", ""sections"": []}
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,0,0.9999687980937693,"The method `_analyze_readme_style` is a private method (indicated by the underscore prefix) that is designed to analyze the style and structure of a README file. However, the current implementation is very basic and does not perform any actual analysis; it simply returns a hardcoded dictionary with a 'style' key and an empty 'sections' list. This suggests that the method is either incomplete or a placeholder for future development. If the method is not expanded to include actual analysis logic, it is likely to be deleted in the future as it does not provide any meaningful functionality in its current state."
survived,"    def check(node: ast.Call, resolver: Resolver) -> bool:
        """"""
        Returns True if the call is threading.Thread() without a name parameter.
        """"""
        return (
            (resolved := resolver.resolve(node))
            and resolved == [""threading"", ""Thread""]
            and not any(keyword.arg == ""name"" for keyword in node.keywords)
        )",dev/clint/src/clint/rules/unnamed_thread.py,UnnamedThread,1,8.592166611791576e-10,"The method 'check' is a utility function that checks if a given AST node represents a call to 'threading.Thread()' without a 'name' parameter. This kind of functionality is useful for static analysis or code linting tools that need to enforce or check for specific coding patterns or practices. Given the increasing importance of code quality and static analysis in modern software development, such utility functions are likely to be retained. Therefore, the method is predicted to survive."
survived,"    def __init__(self, function_name: str, unknown_args: set[str]) -> None:
        self.function_name = function_name
        self.unknown_args = unknown_args
",dev/clint/src/clint/rules/unknown_mlflow_arguments.py,UnknownMlflowArguments,1,2.3355930333443423e-09,"The method is a constructor for a class, initializing two attributes: 'function_name' and 'unknown_args'. This is a fundamental part of object-oriented programming in Python, and there is no indication that it is redundant or unnecessary. Constructors are essential for setting up initial state in objects, and this one appears to be straightforward and useful for any class that needs to store a function name and a set of unknown arguments. Therefore, it is likely to survive."
survived,"    def check(cls, rules: set[str]) -> ""DoNotDisable"":
        if s := rules.intersection(DoNotDisable.DO_NOT_DISABLE):
            return cls(s)
",dev/clint/src/clint/rules/do_not_disable.py,DoNotDisable,1,5.60279640614594e-09,"The method 'check' is likely to survive because it is a concise and clear implementation that uses modern Python features such as set intersection and the walrus operator (:=). It checks for intersection between a given set of rules and a predefined set of rules (DO_NOT_DISABLE), and if there is an intersection, it returns an instance of the class with the intersecting rules. This functionality is useful for filtering or validating rules, which is a common requirement in many applications. Additionally, the use of type hints and the walrus operator indicates that the code is written with readability and efficiency in mind, aligning with current Python best practices."
survived,"    def __init__(self, rules: set[str]) -> None:
        self.rules = rules
",dev/clint/src/clint/rules/do_not_disable.py,DoNotDisable,1,6.348800075736417e-09,"The method is a constructor for a class, which is a fundamental part of object-oriented programming in Python. Constructors are essential for initializing new objects with specific attributes or properties. The use of type hinting with 'set[str]' is a modern Python feature that improves code readability and maintainability. There is no indication that this constructor is redundant or unnecessary, so it is likely to be retained."
survived,"    def _message(self) -> str:
        if correct_hint := self.MAPPING.get(self.type_hint):
            return f""Did you mean `{correct_hint}` instead of `{self.type_hint}`?""

        raise ValueError(
            f""Unexpected type: {self.type_hint}. It must be one of {list(self.MAPPING)}.""
        )",dev/clint/src/clint/rules/incorrect_type_annotation.py,IncorrectTypeAnnotation,1,2.3355930333443423e-09,"The method '_message' is a private method (indicated by the underscore) that is used to generate a specific error message based on the type hint provided. It checks if the type hint is in a mapping and returns a suggestion if it is, otherwise it raises a ValueError. This method is useful for debugging and providing clear error messages, which is a good practice in software development. There is no indication that this method is redundant or unnecessary, and it serves a clear purpose in the context of error handling. Therefore, it is likely to be retained in the codebase."
survived,"    def _message(self) -> str:
        return ""Builtin modules must be imported at the top level.""",dev/clint/src/clint/rules/lazy_builtin_import.py,LazyBuiltinImport,1,1.725782769012759e-08,"The method _message is a simple utility function that returns a static string. It is likely used internally within a class or module to provide a consistent message. Since it is a private method (indicated by the underscore) and does not have any apparent issues or redundancies, it is likely to be retained for its intended purpose."
survived,"    def check(node: ast.expr, resolver: Resolver) -> bool:
        """"""
        Returns True if the `@experimental` decorator from mlflow.utils.annotations is used
        incorrectly.
        """"""
        resolved = resolver.resolve(node)
        if not resolved:
            return False

        if resolved != [""mlflow"", ""utils"", ""annotations"", ""experimental""]:
            return False

        if not isinstance(node, ast.Call):
            return True

        version = next((k.value for k in node.keywords if k.arg == ""version""), None)
        if version is None:
            # No `version` argument, invalid usage
            return True

        if not isinstance(version, ast.Constant) or not isinstance(version.value, str):
            # `version` is not a string literal, invalid usage
            return True

        if not _is_valid_version(version.value):
            # `version` is not a valid semantic version, # invalid usage
            return True

        return False",dev/clint/src/clint/rules/invalid_experimental_decorator.py,InvalidExperimentalDecorator,1,1.1032560311263802e-09,"The method 'check' is a utility function that verifies the correct usage of a specific decorator. It checks for the presence of a 'version' argument and validates its format. This kind of utility function is often useful in ensuring code quality and adherence to expected patterns, especially in larger codebases where decorators are used to manage experimental features. Since it serves a specific purpose in maintaining code correctness and is not overly complex or redundant, it is likely to be retained in the codebase."
survived,"    def check(node: ast.Name) -> bool:
        return node.id in IncorrectTypeAnnotation.MAPPING
",dev/clint/src/clint/rules/incorrect_type_annotation.py,IncorrectTypeAnnotation,1,7.194132978569833e-09,"The method `check` is a simple utility function that checks if a given node's id is present in a predefined mapping. This type of function is often useful in various contexts where type checking or validation against a set of known values is required. It is likely to be used in a larger codebase where type annotations are being validated or processed. Since it serves a clear purpose and is likely to be used in multiple places, it is more probable that the method will be retained rather than deleted."
survived,"    def example(cls) -> ""ModelVersionTagDeletedPayload"":
        return cls(
            name=""example_model"",
            version=""1"",
            key=""example_key"",
        )
",mlflow/webhooks/types.py,ModelVersionTagDeletedPayload,1,7.73442280641062e-08,"The method 'example' is a class method that returns an instance of 'ModelVersionTagDeletedPayload' with predefined attributes. It is likely a utility method to create a sample or default instance of the class for testing or demonstration purposes. Such methods are generally useful for developers to quickly generate instances without manually specifying all parameters each time. Therefore, it is likely to be retained in the codebase."
survived,"    def example(cls) -> ""ModelVersionAliasCreatedPayload"":
        return cls(
            name=""example_model"",
            alias=""example_alias"",
            version=""1"",
        )
",mlflow/webhooks/types.py,ModelVersionAliasCreatedPayload,1,1.0467401685178159e-08,"The method 'example' is a class method that returns an instance of 'ModelVersionAliasCreatedPayload' with predefined attributes. It is a simple factory method that provides a quick way to create an instance with default values. Such methods are often useful for testing, examples, or as a convenience for users of the class. There is no indication that this method is redundant or harmful, and it serves a clear purpose, so it is likely to be retained."
survived,"    def test_webhook(
        self, webhook_id: str, event: Optional[WebhookEvent] = None
    ) -> WebhookTestResult:
        """"""
        Test a webhook by sending a test event to the specified URL.

        Args:
            webhook_id: Webhook ID.
            event: Optional event type to test. If not specified, uses the first event from webhook.

        Returns:
            WebhookTestResult indicating success/failure and response details
        """"""
        raise NotImplementedError(f""{self.__class__.__name__} does not support test_webhook"")",mlflow/store/model_registry/abstract_store.py,AbstractStore,1,6.475946147757848e-07,"The method 'test_webhook' is currently not implemented and raises a NotImplementedError. However, the presence of a detailed docstring suggests that there is an intention to implement this functionality in the future. The method is likely a placeholder for a feature that is planned but not yet developed. Therefore, it is more likely to be retained for future implementation rather than deleted."
survived,"    def w_GET_color(vm: 'SPyVM', wop_x: 'W_OpArg',
                    wop_attr: 'W_OpArg') -> 'W_OpImpl':
        from spy.vm.builtin import builtin_func
        from spy.vm.str import W_Str

        @builtin_func(W_OpArg._w.fqn, 'get_color')
        def w_get_color(vm: 'SPyVM', w_oparg: W_OpArg) -> W_Str:
            return vm.wrap(w_oparg.color)  # type: ignore

        return W_OpImpl(w_get_color, [wop_x])
",spy/vm/opimpl.py,W_OpArg,1,3.927863699585036e-07,"The method `w_GET_color` is a specific implementation that seems to be part of a larger system, likely a virtual machine or interpreter for a language. It defines a function `w_get_color` using a decorator `@builtin_func`, which suggests that it is intended to be a built-in operation within this system. The method is not overly complex and appears to be correctly implemented for its purpose, which is to retrieve a color attribute from an operation argument and wrap it in a specific type (`W_Str`).

Given that it is a specific utility function that is likely used within the context of the system it is part of, and there are no apparent issues with its implementation, it is likely to be retained unless there is a significant change in the system's architecture or requirements that renders it obsolete."
survived,"            def w_get_null(vm: 'SPyVM', w_cls: W_Type) -> W_OpImpl:
                return W_OpImpl.NULL
",spy/vm/opimpl.py,W_OpImpl,1,2.646573631904765e-09,"The method `w_get_null` is a simple utility function that returns a constant value, `W_OpImpl.NULL`. It is likely used as a placeholder or default operation implementation in the context of the system. Such utility functions are often retained because they provide a clear and consistent way to handle specific cases (like null operations) across the codebase. Unless there is a significant refactor or change in how null operations are handled, this method is likely to survive."
survived,"        def w_get_color(vm: 'SPyVM', w_oparg: W_OpArg) -> W_Str:
            return vm.wrap(w_oparg.color)  # type: ignore
",spy/vm/opimpl.py,W_OpArg,1,1.3440409770490404e-08,"The method `w_get_color` is a simple utility function that wraps a color attribute from an operation argument (`w_oparg`) using a method from the `vm` object. This kind of method is typically useful in a virtual machine or interpreter context where operations need to be wrapped or transformed for further processing. The method is straightforward, has a clear purpose, and is likely to be used in multiple places where color attributes need to be wrapped. Therefore, it is unlikely to be deleted unless the entire mechanism for handling colors or the wrapping process is refactored or removed, which is not indicated here."
survived,"    def test_definition(self, mock_definition):
        """"""Test the implementation of the definition method""""""
        # Setup the mock return value
        mock_definition.return_value = ""A membrane-bounded organelle of eukaryotic cells in which chromosomes are housed and replicated.""
        
        # Test definition retrieval
        definition = self.oi.definition(""GO:0005634"")
        self.assertEqual(definition, ""A membrane-bounded organelle of eukaryotic cells in which chromosomes are housed and replicated."")
        
        # Verify the mock was called correctly
        mock_definition.assert_called_with(""GO:0005634"")
",tests/test_implementations/test_ols.py,TestOlsImplementation,1,5.3157849718487075e-08,"The method 'test_definition' is a unit test designed to verify the behavior of a 'definition' method, likely part of a larger codebase. Unit tests are crucial for ensuring code reliability and are typically maintained as part of the codebase to facilitate ongoing development and refactoring. The method uses a mock to simulate the behavior of the 'definition' method, checks the return value, and verifies the mock call, which are standard practices in testing. Therefore, it is unlikely to be deleted as it serves an important role in maintaining code quality."
survived,"    def test_simple_correlation_matrix(self):
        # Simple 2x2 correlation matrix
        data = np.array([[1, 2, 3, 4], [2, 4, 6, 8]], dtype=np.float64)
        result = nancorrmatrix(data)

        # Perfect correlation since second row is 2x first row
        expected = np.array([[1.0, 1.0], [1.0, 1.0]])
        assert_allclose(result, expected, rtol=1e-10)
",numbagg/test/test_nancorrmatrix.py,TestNanCorrMatrix,1,7.194132978569833e-09,"The method `test_simple_correlation_matrix` is a unit test designed to verify the functionality of the `nancorrmatrix` function. It checks if the function correctly computes the correlation matrix for a simple 2x2 dataset where the second row is a perfect linear transformation of the first row. This is a fundamental test case for correlation matrix calculations, ensuring that the function handles basic inputs correctly. Such tests are crucial for maintaining code quality and reliability, especially in numerical computing libraries. Therefore, it is likely to be retained as part of the test suite."
deleted,"def create_connection_pool() -> AsyncConnectionPool:
    """"""Create and return a PostgreSQL connection pool with configured settings.""""""
    conn_string = get_postgres_connection_string()
    
    # Create connection pool with settings from config
    pool = AsyncConnectionPool(
        conn_string,
        min_size=settings.POSTGRES_MIN_SIZE,
        max_size=settings.POSTGRES_POOL_SIZE,
        max_idle=settings.POSTGRES_MAX_IDLE,
    )
    
    logger.info(
        f""Created PostgreSQL connection pool: min_size={settings.POSTGRES_MIN_SIZE}, ""
        f""max_size={settings.POSTGRES_POOL_SIZE}, max_idle={settings.POSTGRES_MAX_IDLE}""
    )
    
    return pool
",src/memory/postgres.py,,1,1.493094675974231e-10,"The method 'create_connection_pool' is likely to survive because it is a well-defined function that creates a PostgreSQL connection pool using settings from a configuration. This is a common and necessary operation in applications that require database interactions, especially in asynchronous environments. The function is clear, uses logging for monitoring, and adheres to best practices by using configuration settings, making it a valuable part of the codebase."
survived,"    def test_resource() -> str:
        return ""test resource""
",tests/server/middleware/test_middleware.py,,1,2.5109990926928157e-08,"The method 'test_resource' is a simple function that returns a string. It is likely a placeholder or a utility function used in testing or development. Such functions are often kept in codebases for testing purposes or as part of a larger testing framework. Unless there is a specific reason to remove it, such as it being unused or replaced by a more comprehensive testing strategy, it is likely to survive."
survived,"    async def _apply_middleware(
        self,
        context: MiddlewareContext[Any],
        call_next: Callable[[MiddlewareContext[Any]], Awaitable[Any]],
    ) -> Any:
        """"""Builds and executes the middleware chain.""""""
        chain = call_next
        for mw in reversed(self.middleware):
            chain = partial(mw, call_next=chain)
        return await chain(context)
",src/fastmcp/server/server.py,FastMCP,1,2.8453347280241004e-08,"The method `_apply_middleware` is a core part of handling middleware in an asynchronous framework. It constructs and executes a chain of middleware functions, which is a common pattern in web frameworks and other systems that use middleware for processing requests or data. This method is essential for the operation of the middleware system, as it ensures that each middleware is applied in the correct order and that the context is passed through each layer. Given its fundamental role in the middleware architecture, it is unlikely to be deleted unless the entire middleware handling mechanism is refactored or replaced."
deleted,"    async def _list_tools(self, apply_middleware: bool = True) -> list[Tool]:
        """"""
        List all available tools.
        """"""

        if (tools := self._cache.get(""tools"")) is self._cache.NOT_FOUND:
            tools: list[Tool] = []

            # iterate such that new mounts overwrite older ones
            for mounted_server in self._mounted_servers:
                try:
                    if apply_middleware:
                        server_tools = (
                            await mounted_server.server._middleware_list_tools()
                        )
                    else:
                        server_tools = await mounted_server.server._list_tools()
                    # Apply prefix to each tool key if prefix exists and is not empty
                    if mounted_server.prefix:
                        for tool in server_tools:
                            tool = tool.with_key(f""{mounted_server.prefix}_{tool.key}"")
                            tools.append(tool)
                    else:
                        tools.extend(server_tools)
                except Exception as e:
                    logger.warning(
                        f""Failed to get tools from mounted server '{mounted_server.prefix}': {e}""
                    )
                    continue
            tools.extend(self._tool_manager.get_tools().values())
            self._cache.set(""tools"", tools)
        return tools
",src/fastmcp/server/server.py,FastMCP,1,6.348800075736417e-09,"The method '_list_tools' is a crucial part of the system as it aggregates tools from various mounted servers and applies middleware if necessary. It also handles caching to improve performance and includes error handling to ensure robustness. These features indicate that the method is well-designed and serves an important function in the system, making it unlikely to be deleted."
survived,"    def __getattribute__(self, name: str) -> Callable:
        """"""Dynamically create recording methods for any on_* method.""""""
        if name.startswith(""on_""):

            async def record_and_call(
                context: MiddlewareContext, call_next: Callable
            ) -> Any:
                result = await call_next(context)

                self.calls.append(Recording(hook=name, context=context, result=result))

                return result

            return record_and_call

        return super().__getattribute__(name)
",tests/server/middleware/test_middleware.py,RecordingMiddleware,1,2.2159489282323004e-08,"The method '__getattribute__' is overridden to dynamically create methods for any attribute starting with 'on_'. This is a common pattern in frameworks that use event-driven or middleware architectures, where methods are dynamically created based on naming conventions. The method is useful for recording calls and their contexts, which can be essential for debugging, logging, or analytics purposes. Since it serves a specific and useful purpose, it is likely to be retained in the codebase."
survived,"    def nested_middleware():
        return RecordingMiddleware(name=""nested_middleware"")
",tests/server/middleware/test_middleware.py,TestNestedMiddlewareHooks,1,3.2241866333029355e-08,"The method `nested_middleware` is a simple function that returns an instance of `RecordingMiddleware` with a specific name. This kind of function is often used in web frameworks to apply middleware to requests. Since it is a utility function that encapsulates the creation of middleware, it is likely to be useful in various contexts where middleware needs to be applied. Therefore, it is more likely to be retained in the codebase for its utility and reusability."
survived,"    def test_prompt(x: str) -> str:
        return f""test prompt with {x}""
",tests/server/middleware/test_middleware.py,,1,8.152020648014727e-09,"The method 'test_prompt' is a simple utility function that formats a string by embedding the input 'x' into a predefined template. Such utility functions are often useful in various contexts where dynamic string generation is needed, such as logging, user prompts, or generating messages. The function is straightforward, has a clear purpose, and is likely to be reused in different parts of a codebase. Therefore, it is more likely to be retained rather than deleted."
survived,"    def test_resource_with_path(x: int) -> str:
        return f""test resource with {x}""
",tests/server/middleware/test_middleware.py,,1,4.363462233903899e-09,"The method 'test_resource_with_path' is a simple utility function that formats a string with an integer input. It is likely to be useful in various contexts where such a formatted string is needed, especially in testing scenarios. There is no indication that it is redundant or obsolete, and it serves a clear purpose. Therefore, it is likely to be retained."
survived,"        def add(a: int, b: int) -> int:
            return a + b
",tests/server/middleware/test_middleware.py,TestNestedMiddlewareHooks,1,4.944450477491054e-09,"The method 'add' is a simple and commonly used utility function that performs addition of two integers. Such basic arithmetic functions are fundamental in programming and are often retained for their utility and simplicity. There is no indication that this method is redundant or unnecessary, so it is likely to be retained."
deleted,"    async def _middleware_get_prompt(
        self,
        name: str,
        arguments: dict[str, Any] | None = None,
    ) -> GetPromptResult:
        """"""
        Get a prompt with middleware.
        """"""

        async def _handler(
            context: MiddlewareContext[mcp.types.GetPromptRequestParams],
        ) -> GetPromptResult:
            return await self._get_prompt(
                name=context.message.name,
                arguments=context.message.arguments,
            )

        mw_context = MiddlewareContext(
            message=mcp.types.GetPromptRequestParams(name=name, arguments=arguments),
            source=""client"",
            type=""request"",
            method=""prompts/get"",
            fastmcp_context=fastmcp.server.dependencies.get_context(),
        )
        return await self._apply_middleware(mw_context, _handler)
",src/fastmcp/server/server.py,FastMCP,1,3.850741907939403e-09,"The method '_middleware_get_prompt' is an asynchronous function that is designed to handle middleware logic for getting a prompt. It is well-structured, uses type hints, and follows a clear pattern for middleware handling. The method is likely part of a larger system that relies on middleware for processing requests, which is a common architectural pattern. Given its clear purpose and integration into a middleware system, it is unlikely to be deleted unless there is a significant refactor or change in the system's architecture."
survived,"def test_compile_simple_query():
    """"""Test compiling a simple Wvlet query""""""
    try:
        compiler = WvletCompiler()
    except NotImplementedError:
        pytest.skip(""Neither native library nor wvlet executable is available"")
    
    # Test a simple query
    query = ""from users select name""
    try:
        sql = compiler.compile(query)
        assert sql is not None
        assert len(sql) > 0
        # The exact SQL output depends on the target, but it should contain 'users'
        assert 'users' in sql.lower()
    except ValueError as e:
        # If compilation fails, it might be due to missing catalog/schema
        # This is acceptable for the test environment
        assert ""Failed to compile"" in str(e)
",sdks/python/tests/test_compiler.py,,1,2.7894680920908113e-10,"The method is a unit test designed to verify the functionality of a query compiler. It includes exception handling for scenarios where the compiler is not implemented or compilation fails due to missing catalog/schema, which are reasonable conditions to test for. The test is useful for ensuring the robustness of the query compilation process, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained."
survived,"def _process_single_dataset(
    dataset: DataSet,
    source_conn: AtomicConnection,
    target_conn: AtomicConnection,
    export_path: Path,
    target_exp_id: int,
) -> str:
    """"""
    Process a single dataset: export to NetCDF and create metadata-only version
    or copy as-is if export fails.
    
    Returns:
        Status string indicating what was done with the dataset
    """"""
    run_id = dataset.run_id
    
    # Check if dataset is already in target database
    existing_run_id = get_runid_from_guid(target_conn, dataset.guid)
    if existing_run_id is not None:
        log.info(f""Dataset {run_id} (GUID: {dataset.guid}) already exists in target database"")
        return ""already_exists""
    
    # Check if dataset is completed
    if not dataset.completed:
        log.warning(f""Dataset {run_id} is not completed, copying as-is"")
        return _copy_dataset_as_is(dataset, target_conn, target_exp_id)
    
    try:
        # Try to export to NetCDF
        log.info(f""Attempting to export dataset {run_id} to NetCDF"")
        netcdf_path = dataset.export(""netcdf"", path=export_path)
        
        if netcdf_path is None:
            log.warning(f""Failed to export dataset {run_id} to NetCDF, copying as-is"")
            return _copy_dataset_as_is(dataset, target_conn, target_exp_id)
            
        # Load from NetCDF to create metadata-only dataset
        log.info(f""Loading dataset {run_id} from NetCDF to create metadata-only version"")
        netcdf_dataset = load_from_netcdf(netcdf_path)
        
        # Insert metadata-only version into target database
        with atomic(target_conn) as target_conn_atomic:
            _, _, target_table_name = _add_run_to_runs_table(
                netcdf_dataset, target_conn_atomic, target_exp_id
            )
            
            # Note: We deliberately don't populate the results table to keep only metadata
            log.info(f""Successfully created metadata-only version of dataset {run_id}"")
        
        return ""exported""
        
    except Exception as e:
        log.warning(f""Failed to export dataset {run_id} to NetCDF: {e}, copying as-is"")
        return _copy_dataset_as_is(dataset, target_conn, target_exp_id)
",src/qcodes/dataset/database_extract_runs.py,,1,1.8189616842444243e-09,"The method '_process_single_dataset' is well-structured and serves a clear purpose in processing datasets by either exporting them to NetCDF or copying them as-is if certain conditions are not met. It includes error handling, logging, and checks for dataset completion and existence in the target database. These features make it a robust and useful method in data processing workflows, which suggests it is likely to be retained."
survived,"def test_export_datasets_default_export_path(simple_dataset):
    """"""Test that default export path is used when none provided""""""
    source_db_path, run_id = simple_dataset
    
    with tempfile.TemporaryDirectory() as temp_dir:
        target_db_path = Path(temp_dir) / ""target.db""
        
        # Run the export function without explicit export path
        result = export_datasets_and_create_metadata_db(
            source_db_path=source_db_path,
            target_db_path=target_db_path,
            # export_path=None  # Use default
        )
        
        # Should still work
        assert isinstance(result, dict)
        assert run_id in result
",tests/dataset/test_export_datasets_and_create_metadata_db.py,,1,1.522997951276035e-08,"The method is a test function that verifies the behavior of a function when no export path is provided, ensuring that a default path is used. Test functions are generally crucial for maintaining code quality and ensuring that changes do not break existing functionality. This particular test checks a specific scenario that is likely important for the robustness of the export function. Therefore, it is unlikely to be deleted as it serves a valuable purpose in the codebase."
survived,"def export_datasets_and_create_metadata_db(
    source_db_path: str | Path,
    target_db_path: str | Path,
    export_path: str | Path | None = None,
    upgrade_source_db: bool = False,
    upgrade_target_db: bool = False,
) -> dict[int, str]:
    """"""
    Export all datasets from a source database to NetCDF files and create
    a new database file containing only metadata (no raw data) for those exported
    datasets. Datasets that cannot be exported to NetCDF will be transferred
    as-is to the new database.

    This function is useful for reducing the size of database files by offloading
    raw data to NetCDF files while preserving all metadata and structural information.

    Args:
        source_db_path: Path to the source database file
        target_db_path: Path to the target database file. Will be created if it doesn't exist.
        export_path: Optional path where NetCDF files should be exported. If None,
            uses the default export path from QCoDeS configuration.
        upgrade_source_db: If the source DB is found to be in a version that is
            not the newest, should it be upgraded?
        upgrade_target_db: If the target DB is found to be in a version that is
            not the newest, should it be upgraded?

    Returns:
        A dictionary mapping run_id to status ('exported' or 'copied_as_is')

    Raises:
        ValueError: If there are issues with the database files or datasets
    """"""
    # Convert paths to Path objects
    source_db_path = Path(source_db_path)
    target_db_path = Path(target_db_path)
    
    if export_path is None:
        export_path = get_data_export_path()
    else:
        export_path = Path(export_path)
    
    log.info(f""Starting export process from {source_db_path} to {target_db_path}"")
    log.info(f""NetCDF files will be exported to {export_path}"")
    
    # Check database versions
    (s_v, new_v) = get_db_version_and_newest_available_version(source_db_path)
    if s_v < new_v and not upgrade_source_db:
        warn(
            f""Source DB version is {s_v}, but this function needs it to be""
            f"" in version {new_v}. Run this function again with ""
            ""upgrade_source_db=True to auto-upgrade the source DB file.""
        )
        return {}

    if target_db_path.exists():
        (t_v, new_v) = get_db_version_and_newest_available_version(target_db_path)
        if t_v < new_v and not upgrade_target_db:
            warn(
                f""Target DB version is {t_v}, but this function needs it to ""
                f""be in version {new_v}. Run this function again with ""
                ""upgrade_target_db=True to auto-upgrade the target DB file.""
            )
            return {}

    # Create export directory if it doesn't exist
    export_path.mkdir(parents=True, exist_ok=True)
    
    source_conn = connect(source_db_path)
    target_conn = connect(target_db_path)
    
    try:
        # Get all run IDs from the source database
        run_ids = get_runs(source_conn)
        log.info(f""Found {len(run_ids)} datasets to process"")
        
        if not run_ids:
            log.warning(""No datasets found in source database"")
            return {}
        
        # Process datasets by experiment to preserve structure
        result_status = {}
        processed_experiments = {}  # Map source exp_id to target exp_id
        
        for run_id in run_ids:
            try:
                dataset = DataSet(run_id=run_id, conn=source_conn)
                exp_id = dataset.exp_id
                
                # Create experiment in target DB if not already done
                if exp_id not in processed_experiments:
                    exp_attrs = get_experiment_attributes_by_exp_id(source_conn, exp_id)
                    
                    with atomic(target_conn) as target_conn_atomic:
                        target_exp_id = _create_exp_if_needed(
                            target_conn_atomic,
                            exp_attrs[""name""],
                            exp_attrs[""sample_name""],
                            exp_attrs[""format_string""],
                            exp_attrs[""start_time""],
                            exp_attrs[""end_time""],
                        )
                    processed_experiments[exp_id] = target_exp_id
                    log.info(f""Created experiment '{exp_attrs['name']}' in target database"")
                else:
                    target_exp_id = processed_experiments[exp_id]
                
                # Try to export dataset to NetCDF and create metadata-only version
                status = _process_single_dataset(
                    dataset, source_conn, target_conn, export_path, target_exp_id
                )
                result_status[run_id] = status
                
            except Exception as e:
                log.error(f""Failed to process dataset {run_id}: {e}"")
                result_status[run_id] = f""failed: {str(e)}""
        
        log.info(f""Processing complete. Status summary: {result_status}"")
        return result_status
        
    finally:
        source_conn.close()
        target_conn.close()
",src/qcodes/dataset/database_extract_runs.py,,1,1.522997951276035e-08,"The method is well-documented, has a clear purpose, and addresses a specific need in data management by exporting datasets to NetCDF files and creating a metadata database. It includes error handling, logging, and options for upgrading database versions, which are all good practices. These factors suggest that the method is useful and likely to be maintained."
survived,"async def no_sleep(_: float) -> None:
    return None
",tests/test_register_mesh_backoff.py,,0,0.99999998813888,"The method 'no_sleep' is an asynchronous function that takes a float argument and returns None. It doesn't perform any operations or have any side effects, making it effectively a no-op. Such methods are typically not useful in a codebase unless they are placeholders for future implementation or are used to satisfy an interface requirement. Without additional context indicating its necessity, it is likely to be deleted as it doesn't contribute any functionality."
survived,"def run_claude(
    prompt: str,
    output_format: str = ""json"",
    allowed_tools: Optional[List[str]] = None,
    cli: str = ""claude"",
) -> str:
    """"""Run Claude Code in headless mode with the given output format.""""""
    cmd = [cli, ""-p"", prompt, ""--output-format"", output_format]
    if allowed_tools:
        cmd.extend([""--allowedTools"", *allowed_tools])
    result = subprocess.run(
        cmd,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        text=True,
    )
    if result.returncode != 0:
        raise RuntimeError(f""claude failed: {result.stderr}"")
    return result.stdout
",claude_testing_v1.py,,1,7.582560422162384e-10,"The method 'run_claude' is a utility function designed to execute a command-line tool named 'claude' with specified parameters. It is a well-structured function that handles command execution, error checking, and output retrieval. Such utility functions are commonly used in software development to interface with external tools or services, and they are generally retained unless the tool it interfaces with becomes obsolete or the method is replaced by a more efficient implementation. Given that the function is straightforward, performs a useful task, and there is no indication of it being deprecated or replaced, it is likely to survive."
survived,"    def _args(self):
        return argparse.Namespace(
            agents=""A,B"",
            port=123,
            metrics_port=456,
            a2a_port=789,
            cycle=5,
            loglevel=""DEBUG"",
            version=False,
            list_agents=False,
        )
",alpha_factory_v1/tests/test_edge_runner_main.py,EdgeRunnerMainInvokesRun,1,6.348800075736417e-09,"The method '_args' is a utility function that returns a pre-configured 'argparse.Namespace' object with default values for various parameters. This method is likely used to provide default configurations for a larger application or script. Such utility functions are common in codebases to simplify configuration management and ensure consistency across different parts of the application. Since it encapsulates configuration details in a single place, it is useful for maintainability and readability of the code. Therefore, it is likely to be retained in the codebase."
survived,"    def fail_commit(self, *a, **k):
        raise RuntimeError(""boom"")
",tests/test_self_improver.py,,0,0.99999998813888,"The method 'fail_commit' is designed to always raise a RuntimeError with the message 'boom'. This indicates that its purpose is to intentionally cause a failure when called. Such methods are typically used for testing error handling or as placeholders to indicate incomplete functionality. However, without additional context on its usage, it's difficult to determine its long-term utility. If the method is part of a testing suite or a temporary measure, it might be deleted once its purpose is fulfilled. If it's a placeholder, it might be replaced with actual functionality. Given these possibilities, the method is more likely to be deleted in the future."
survived,"    def start_merkle_task(self, *_a, **_kw) -> None:
        pass
",tests/test_self_improver.py,DummyLedger,0,0.9999980052698925,"The method `start_merkle_task` is defined but not implemented, as it only contains a `pass` statement. This suggests that it might be a placeholder for future functionality. However, without any additional context or usage, it is difficult to determine its importance or necessity. If this method is part of a larger class or module that is actively being developed, it might survive as it could be implemented later. On the other hand, if there is no plan to implement it or if it remains unused, it might be deleted in future refactoring to clean up the codebase. Given the lack of context, it is more likely to be deleted if it remains unimplemented and unused."
survived,"    def __init__(self, timeout: int = 60, proxies: dict = {}):
        """"""Initialize your AiForce provider with custom settings! âš™ï¸

        Args:
            timeout (int): Request timeout in seconds (default: 60)
            proxies (dict): Proxy settings for requests (default: {})
        """"""
        self.api_endpoint = ""https://api.airforce/imagine2""
        self.headers = {
            ""Accept"": ""text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8"",
            ""Accept-Language"": ""en-US,en;q=0.5"",
            ""Accept-Encoding"": ""gzip, deflate"",
            ""User-Agent"": agent.random()
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)
        self.session.proxies.update(proxies)
        self.timeout = timeout
        self.prompt: str = ""AI-generated image - webscout""
        self.image_extension: str = ""png""
",webscout/Provider/TTI/aiforce.py,AiForceimager,1,1.8553915987649156e-07,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class with specific attributes and settings. It sets up important configurations such as API endpoint, headers, session, proxies, and timeout, which are likely crucial for the functionality of the class. Therefore, it is unlikely to be deleted as it provides necessary setup for the class to function correctly."
survived,"    def save(
        self,
        response: List[str],
        name: str = None,
        dir: str = os.getcwd(),
        filenames_prefix: str = """",
    ) -> List[str]:
        """"""Save your fire images! ðŸ’¾

        Args:
            response (List[str]): Your image URLs to save
            name (str, optional): Custom name (default: uses prompt)
            dir (str, optional): Where to save (default: current directory)
            filenames_prefix (str, optional): Add prefix to filenames

        Returns:
            List[str]: Where your images were saved
        """"""
        assert isinstance(response, list), f""Response gotta be a list, not {type(response)} ðŸ¤”""
        name = self.prompt if name is None else name

        filenames = []
        count = 0

        for img_url in response:
            def complete_path():
                count_value = """" if count == 0 else f""_{count}""
                return os.path.join(dir, name + count_value + ""."" + self.image_extension)

            while os.path.isfile(complete_path()):
                count += 1

            absolute_path_to_file = complete_path()
            filenames.append(filenames_prefix + os.path.split(absolute_path_to_file)[1])

            try:
                img_response = requests.get(img_url, stream=True, timeout=self.timeout)
                img_response.raise_for_status()

                with open(absolute_path_to_file, ""wb"") as fh:
                    for chunk in img_response.iter_content(chunk_size=8192):
                        fh.write(chunk)

            except requests.exceptions.RequestException as e:
                raise

        return filenames",webscout/Provider/TTI/artbit.py,ArtbitImager,1,2.2159489282323004e-08,"The method 'save' is well-documented, has a clear purpose, and handles a common task of saving images from URLs to a local directory. It includes error handling for network requests and allows customization of file names and directories. These features make it a useful utility function that is likely to be retained in the codebase."
survived,"    def __init__(
        self, 
        timeout: int = 60, 
        proxies: Optional[dict] = None
    ):
        """"""Initialize your ImgSys provider with custom settings

        Examples:
            >>> provider = ImgSys(timeout=30)
            >>> provider = ImgSys(proxies={""http"": ""http://proxy:8080""})

        Args:
            timeout (int): HTTP request timeout in seconds (default: 60)
            proxies (dict, optional): Proxy configuration for requests
        """"""
        self.request_id_endpoint = ""https://imgsys.org/api/initiate""
        self.image_response_endpoint = ""https://imgsys.org/api/get""
        self.image_provider_endpoint = ""https://imgsys.org/api/submit""
        
        self.headers = {
            ""Accept"": ""application/json"",
            ""Content-Type"": ""application/json"",
            ""User-Agent"": agent.random(),
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)
        if proxies:
            self.session.proxies.update(proxies)
            
        self.timeout = timeout
        self.prompt: str = ""AI-generated image - webscout""
        self.image_extension: str = ""jpeg""
",webscout/Provider/TTI/imgsys.py,ImgSys,1,4.363462233903899e-09,"The method is a constructor for a class, which is essential for initializing instances of the class with specific configurations. It sets up important attributes like endpoints, headers, session, and optional proxies, which are crucial for the functionality of the class. Constructors are fundamental to object-oriented programming and are rarely deleted unless the entire class is being refactored or removed. Therefore, this method is likely to survive."
survived,"            def complete_path():
                count_value = """" if count == 0 else f""_{count}""
                return os.path.join(save_dir, name + count_value + ""."" + self.image_extension)
",webscout/Provider/TTI/aiforce.py,AiForceimager,1,9.237449576640118e-09,"The method `complete_path` is a utility function that constructs a file path based on a directory, a name, a count, and an image extension. This type of method is generally useful in scenarios where files need to be saved with unique names to avoid overwriting. The method is simple, clear, and serves a common purpose in file handling operations. Unless there is a significant change in the requirements or a better utility is introduced, such methods are typically retained in codebases."
survived,"    def test_matrix_grad_torch(self):
        klong = KlongInterpreter()
        klong('A::Ë™[2 2]:^!4')
        klong('B::[2 2]:^!4')
        r = klong('(A âˆ‡ {+/(+/ (A*B)) })')

        A = torch.arange(4, dtype=torch.float64, requires_grad=True).reshape(2,2)
        B = torch.arange(4, dtype=torch.float64).reshape(2,2)
        loss = (A * B).sum()
        loss.backward()
        self.assertTrue(np.allclose(r, A.grad.numpy(), atol=1e-3))
",tests/test_autograd.py,TestAutograd,1,2.8453347280241004e-08,"The method `test_matrix_grad_torch` is a unit test that compares the gradient computation of a matrix operation using a custom interpreter (`KlongInterpreter`) and PyTorch. It is likely to be retained because it serves a critical role in ensuring the correctness of the gradient computation logic, which is essential for any machine learning or numerical computation library. The test checks if the gradients calculated by the custom interpreter match those computed by PyTorch, a well-established library, thus validating the custom implementation."
survived,"    def test_array_grad_torch(self):
        klong = KlongInterpreter()
        klong('x::Ë™!5')
        klong('loss::{+/x*x}')
        r = klong('x âˆ‡ loss')

        x = torch.arange(5, dtype=torch.float64, requires_grad=True)
        loss = (x * x).sum()
        loss.backward()
        self.assertTrue(np.allclose(r, x.grad.numpy(), atol=1e-3))
",tests/test_autograd.py,TestAutograd,1,1.3176514268359263e-10,"The method 'test_array_grad_torch' is a unit test that compares the gradient computation of a custom interpreter (KlongInterpreter) with PyTorch's automatic differentiation. It is a valid and useful test to ensure that the custom interpreter's gradient computation is correct. The method is well-structured, uses assertions to verify correctness, and is relevant for testing the functionality of the custom interpreter. Therefore, it is likely to be retained in the codebase."
survived,"def test_with_retry_fail(monkeypatch: pytest.MonkeyPatch) -> None:
    monkeypatch.setattr(retry, ""backoff"", None)
    calls = {""n"": 0}

    def func() -> str:
        calls[""n""] += 1
        raise ValueError(""fail"")

    wrapped = retry.with_retry(func, max_tries=2)
    with pytest.raises(ValueError):
        wrapped()
    assert calls[""n""] == 2",tests/test_retry_wrapper.py,,1,2.5109990926928157e-08,"The method 'test_with_retry_fail' is a unit test designed to verify the behavior of a retry mechanism. It uses the 'monkeypatch' fixture to modify the behavior of the 'retry' module, specifically setting 'backoff' to 'None'. The test then defines a function 'func' that always raises a 'ValueError', and wraps it with a retry mechanism that allows for a maximum of 2 tries. The test asserts that the function is called twice and that a 'ValueError' is raised. This test is useful for ensuring that the retry logic is functioning correctly, particularly in handling exceptions and retrying the specified number of times. Therefore, it is likely to be retained as part of the test suite to ensure code reliability and correctness."
survived,"def test_insight_aggregates_results() -> None:
    _setup_simulations()
    client = _make_client()
    headers = {""Authorization"": ""Bearer test-token""}
    resp = client.post(""/insight"", json={""ids"": [""a"", ""b""]}, headers=headers)
    assert resp.status_code == 200
    assert resp.json() == {""forecast"": [{""year"": 1, ""capability"": 0.5}]}
",tests/test_insight_endpoint.py,,1,2.0611536181902033e-09,"The method `test_insight_aggregates_results` is a unit test function that appears to be testing an API endpoint for aggregating insight results. It sets up simulations, makes a client request to the `/insight` endpoint, and checks the response status and content. This is a typical structure for a test function, which is crucial for ensuring the reliability and correctness of the codebase. Given the importance of testing in software development, especially for API endpoints, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered. Therefore, the method is likely to survive."
survived,"def test_custom_node_styles():
    """"""Custom node style directives are included in output.""""""
    generator = DiagramGenerator()
    styles = {""AGENT"": ""fill:#fff""}
    diagram = generator.generate(MINIMAL_SPEC, node_styles=styles)

    assert ""style AGENT fill:#fff"" in diagram",tests/ux/test_diagram_generator.py,,1,2.3355930333443423e-09,"The method `test_custom_node_styles` is a unit test that checks if custom node styles are correctly applied in the output of a diagram generation process. This is a relevant and useful test to ensure that the `DiagramGenerator` class handles custom styles as expected. Testing such functionality is important for maintaining the integrity and flexibility of the diagram generation feature. Therefore, the method is likely to be retained as it serves a clear purpose in verifying the correctness of the code."
survived,"    def test_get_agent_health_queue(self):
        from alpha_factory_v1.backend.agents import _HEALTH_Q

        class WrapAgent(AgentBase):
            NAME = ""wrap""

            async def step(self):
                return ""ok""

        register_agent(AgentMetadata(name=WrapAgent.NAME, cls=WrapAgent))

        while not _HEALTH_Q.empty():
            _HEALTH_Q.get()

        agent = get_agent(WrapAgent.NAME)
        asyncio.run(agent.step())
        name, latency, ok = _HEALTH_Q.get(timeout=1)
        self.assertEqual(name, WrapAgent.NAME)
        self.assertTrue(ok)
        self.assertIsInstance(latency, float)
",tests/test_agents_registry.py,TestAgentRegistryFunctions,1,1.8189616842444243e-09,"The method `test_get_agent_health_queue` is a unit test designed to verify the functionality of the agent health queue in the system. It checks if the agent is correctly registered, executed, and if the health queue is updated with the expected values. This is a typical use case for unit tests in software development, which are crucial for ensuring code reliability and correctness. Since the method is a test case and serves a clear purpose in validating the system's behavior, it is likely to be retained in the codebase."
survived,"    def test_stub_producer(self):
        class Stub:
            def __init__(self, bootstrap_servers=None, value_serializer=None, linger_ms=None):
                self.args = (bootstrap_servers, value_serializer, linger_ms)
        os.environ[""ALPHA_KAFKA_BROKER""] = ""a:1,b:2 ,""
        orig = base_mod.KafkaProducer
        base_mod.KafkaProducer = Stub
        prod = base_mod._kafka_producer()
        self.assertIsInstance(prod, Stub)
        self.assertEqual(prod.args[0], [""a:1"", ""b:2""])
        base_mod.KafkaProducer = orig
        os.environ.pop(""ALPHA_KAFKA_BROKER"", None)
",tests/test_base_helpers.py,TestKafkaProducer,1,4.944450477491054e-09,"The method 'test_stub_producer' is a unit test designed to verify the behavior of a Kafka producer stub. It uses a mock class 'Stub' to replace the actual 'KafkaProducer' class temporarily, allowing the test to check if the '_kafka_producer' function correctly initializes the producer with the expected arguments. This kind of test is crucial for ensuring that the code interacts with external systems (like Kafka) correctly without requiring the actual system to be available during testing. Since it serves a clear purpose in testing the functionality of the code, it is likely to be retained."
survived,"    def test_lower_version_ignored(self):
        class AgentV1(AgentBase):
            NAME = ""dup""
            VERSION = ""1.0""

            async def step(self):
                return None

        class AgentOld(AgentBase):
            NAME = ""dup""
            VERSION = ""0.9""

            async def step(self):
                return None

        register_agent(AgentMetadata(name=""dup"", cls=AgentV1, version=""1.0""))
        register_agent(AgentMetadata(name=""dup"", cls=AgentOld, version=""0.9""))

        self.assertIs(AGENT_REGISTRY[""dup""].cls, AgentV1)
        self.assertEqual(AGENT_REGISTRY[""dup""].version, ""1.0"")
",tests/test_agents_registry.py,TestVersionOverride,1,2.998960815863541e-09,"The method is testing a specific functionality where an agent with a lower version is ignored in favor of an agent with a higher version when both have the same name. This is a valid and useful test case to ensure that the system correctly prioritizes newer versions of agents. Such functionality is common in systems that need to manage multiple versions of components, ensuring that the most up-to-date version is used. Therefore, this test method is likely to be retained as it verifies important behavior in the system."
survived,"    def test_readmes_min_lines(self) -> None:
        """"""``validate_demos`` succeeds for shipped demos.""""""
        exit_code = validate_demos.main(validate_demos.DEFAULT_DIR, min_lines=3)
        self.assertEqual(exit_code, 0)
",tests/test_demos.py,TestDemos,1,1.1032560311263802e-09,"The method `test_readmes_min_lines` is a unit test that checks if the `validate_demos` function works correctly by ensuring it returns an exit code of 0 when the minimum line requirement is met. This is a typical test case that is useful for maintaining code quality and ensuring that the `validate_demos` function behaves as expected. Such test methods are generally retained in the codebase to ensure ongoing functionality and to catch regressions, so it is likely to survive."
survived,"    def __init__(self) -> None:
        self.committed = False
",tests/test_alpha_agi_business_3_v1.py,DummyModel,1,3.2241866333029355e-08,"The method is a constructor for a class, indicated by the name `__init__`. Constructors are essential for initializing new objects in object-oriented programming. The presence of the `committed` attribute suggests that this constructor is setting up an initial state for instances of the class. Since constructors are fundamental to class functionality, it is unlikely to be deleted unless the entire class is being refactored or removed, which is not indicated here."
survived,"    def commit(self, weight_update: dict[str, object]) -> None:  # type: ignore[override]
        self.committed = True
        super().commit(weight_update)
",tests/test_alpha_agi_business_3_v1.py,DummyModel,1,8.152020648014727e-09,"The method 'commit' is overriding a method from a superclass, as indicated by the use of 'super().commit(weight_update)'. The use of 'type: ignore[override]' suggests that there is a type mismatch or a signature difference between this method and the one in the superclass. However, the method itself is functional and serves a purpose by setting 'self.committed' to True before calling the superclass method. This indicates that the method is likely necessary for the class's functionality, and the type ignore is a workaround for a known issue. Therefore, it is unlikely to be deleted unless the superclass method changes significantly or the type issue is resolved in another way."
survived,"    def test_stream_macro_events_offline(self):
        async def get_one():
            it = data_feeds.stream_macro_events(live=False)
            return await anext(it)

        evt = asyncio.run(get_one())
        self.assertIn(""fed_speech"", evt)
        self.assertIn(""yield_10y"", evt)
        self.assertIn(""yield_3m"", evt)
        self.assertIn(""stable_flow"", evt)
        self.assertIn(""es_settle"", evt)
",tests/test_macro_sentinel.py,TestMacroSentinel,1,2.0611536181902033e-09,"The method 'test_stream_macro_events_offline' is a test function that checks the functionality of streaming macroeconomic events in an offline mode. It uses asynchronous programming to fetch data and then asserts the presence of specific keys in the event data. This is a typical unit test pattern to ensure that the data stream provides the expected fields. Since testing is a crucial part of software development to ensure code reliability and correctness, this method is likely to be retained in the codebase."
survived,"    def load_weights(self, path: str) -> None:
        """"""Load updated model weights from *path*.

        Subclasses may override this to implement hot-swapping of
        learning artefacts.  The default implementation simply stores the
        path for later use.
        """"""
        self._weights_path = path
",alpha_factory_v1/backend/agents/base.py,AgentBase,1,8.152020648014727e-09,"The method 'load_weights' is a basic implementation that stores a file path for model weights, allowing subclasses to override it for more complex behavior. This is a common pattern in object-oriented programming, providing a default behavior while allowing flexibility for extension. The method is likely to be useful in various contexts where model weights need to be managed, and its simplicity and extendability make it a candidate for survival."
survived,"async def get_order_item_order(
    order_item_id: int, ctx: EnrichContext
) -> Optional[""OrderEnrichModel""]:
    """"""Get the order for a specific order item.""""""
    session_factory = ctx.request_context.lifespan_context[""session_factory""]
    async with session_factory() as session:
        item = await session.get(OrderItem, order_item_id)
        if not item:
            return None

        # Load the order
        await session.refresh(item, [""order""])
        order = item.order

        return OrderEnrichModel(
            id=order.id,
            order_number=order.order_number,
            user_id=order.user_id,
            status=order.status,
            total_amount=order.total_amount,
            created_at=order.created_at,
            updated_at=order.updated_at,
            shipping_address=order.shipping_address,
            notes=order.notes,
        )
",examples/sqlalchemy_shop/app.py,,1,6.69158608681505e-10,"The method is well-structured and serves a clear purpose of retrieving an order associated with a specific order item. It uses asynchronous programming, which is beneficial for handling I/O-bound operations like database queries efficiently. The method also includes error handling by checking if the item exists before proceeding, which is a good practice. Additionally, it returns a well-defined data model (OrderEnrichModel) that encapsulates the order details, making it useful for further processing or response generation. These factors suggest that the method is likely to be useful and relevant in its context, leading to its survival."
survived,"    def test_model_with_no_docstring(self):
        """"""Test model without docstring gets a default one.""""""

        class Base(DeclarativeBase):
            pass

        class NoDoc(Base, EnrichSQLAlchemyMixin):
            __tablename__ = ""no_doc""
            id: Mapped[int] = mapped_column(primary_key=True)

        NoDocEnrichModel = NoDoc.__enrich_model__()
        assert NoDocEnrichModel.__doc__ == ""NoDoc entity""
",tests/test_sqlalchemy_integration.py,TestEdgeCases,1,2.5109990926928157e-08,"The method 'test_model_with_no_docstring' is a unit test that verifies the functionality of a specific feature: ensuring that a model without a docstring gets a default one. This is a useful test to ensure that the system behaves as expected when a docstring is missing. Unit tests are generally considered important for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is unlikely that this method will be deleted."
survived,"    def __enter__(self):
        if resource:
            resource.setrlimit(resource.RLIMIT_CPU, (self.cpu_sec, self.cpu_sec))
            resource.setrlimit(resource.RLIMIT_AS, (self.mem_mb*1024*1024, self.mem_mb*1024*1024))
        return self
",alpha_factory_v1/demos/meta_agentic_agi_v2/agents/agent_base.py,SafeExec,1,8.76424914819242e-08,"The method is part of a context manager implementation, indicated by the use of __enter__. This is a common pattern in Python for managing resources, ensuring that setup and teardown logic is handled correctly. The method sets resource limits for CPU and memory, which is a useful feature for controlling resource usage in applications. This functionality is relevant and useful, especially in environments where resource management is critical. Therefore, it is likely to be retained."
survived,"            def handle(self, _msg):  # noqa
                LOG.debug(""[Stub:%s] â† %s"", cls_name, _msg)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,Stub,1,1.8553915987649156e-07,"The method 'handle' is a simple logging function that logs a debug message with a specific format. It uses the 'LOG.debug' function to log the message, which is a common practice in software development for tracking and debugging purposes. The method is likely to be useful for developers to trace the flow of messages or events in the application, especially during development or troubleshooting. Therefore, it is unlikely to be deleted as it serves a practical purpose in maintaining and understanding the codebase."
survived,"            def _safe_call(self,prompt:str,timeout:int=15)->str:
                with concurrent.futures.ThreadPoolExecutor() as ex:
                    fut=ex.submit(lambda:openai.ChatCompletion.create(
                        model=""gpt-4o-mini"",
                        messages=[{""role"":""user"",""content"":prompt}],
                        timeout=timeout))
                    return fut.result().choices[0].message.content
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,LLMPlanner,0,0.999999974890009,"The method '_safe_call' is likely to be deleted (0) because it uses a specific model 'gpt-4o-mini' which may not be available or supported in the future. Additionally, the method relies on a specific implementation of OpenAI's API, which could change, making this method obsolete. Furthermore, the method does not handle exceptions or errors that might occur during the API call, which is a critical aspect of robust code. Without proper error handling, this method could lead to unhandled exceptions, making it less reliable and a candidate for removal or replacement with a more robust solution."
survived,"    def run(self, prompt: str, context: Optional[Iterable[Dict[str,str]]]=None, **kw) -> Dict[str,Any]:
        ctx: List[Dict[str,str]] = list(context or [])
        ctx.append({""role"":""user"", ""content"": prompt})
        t0 = time.perf_counter()
        output = self.lm.chat(ctx, **kw)
        latency = time.perf_counter()-t0
        tokens_in = _str_tkn(prompt)
        tokens_out = _str_tkn(output)
        cost = self._estimate_cost(tokens_in,tokens_out)
        carbon = cost*0.00015 # placeholder multiplier (avg kgCO2 per $ cloud)
        risk = self._risk_assess(prompt, output)
        metrics = dict(latency=latency, cost=cost, carbon=carbon, risk=risk)
        score = self.objectives.score(metrics)
        self.tracer.log(""run"", prompt=prompt[:120], response=output[:120], metrics=metrics, score=score)
        return {""response"": output, ""metrics"": metrics, ""score"": score}
",alpha_factory_v1/demos/meta_agentic_agi_v3/agents/agent_base.py,Agent,1,1.6918979223288786e-10,"The method is well-structured and provides a comprehensive functionality for running a prompt through a language model, measuring various metrics such as latency, cost, carbon footprint, and risk. It also logs these metrics and scores the output, which are valuable for performance monitoring and optimization. These features are likely to be useful in many applications, especially those concerned with efficiency and environmental impact. Therefore, the method is likely to be retained."
survived,"    def publish(cls, topic: str, msg: dict):
        with cls._lock:
            for cb in list(cls._subs.get(topic, [])):
                try:
                    cb(msg)
                except Exception as exc:  # pragma: no cover
                    LOG.error(""[A2A] handler error on %s: %s"", topic, exc)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,A2ABus,1,8.152020648014727e-09,"The method 'publish' is a core part of a publish-subscribe pattern, which is a common design pattern used in software development for decoupling the components of a system. This method is responsible for notifying subscribers about messages published to a specific topic. The use of a lock ensures thread safety, which is crucial in concurrent programming. The method also includes error handling to log any exceptions that occur during the callback execution, which is important for debugging and maintaining the system. Given its fundamental role in a messaging system and the presence of error handling, it is unlikely that this method will be deleted."
survived,"def _load_cfg() -> Config:
    cfg = Config()
    #Â yaml config file optional
    if yaml:
        for p in (Path.cwd() / ""config.yaml"", Path.cwd() / ""alpha_asi.yaml""):
            if p.exists():
                try:
                    cfg.update(**yaml.safe_load(p.read_text()))
                    LOG.info(""Loaded config from %s"", p)
                except Exception as e:
                    LOG.warning(""Failed to parse %s: %s"", p, e)
    #Â env overrides
    for k in cfg.__dict__.keys():
        env_key = ""ALPHA_ASI_"" + k.upper()
        if env_key in os.environ:
            val = os.environ[env_key]
            try:
                val = type(getattr(cfg, k))(val)
            except Exception:
                pass
            setattr(cfg, k, val)
    return cfg
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,,1,3.160881453314576e-10,"The method _load_cfg is likely to survive because it performs a crucial function of loading configuration settings from both YAML files and environment variables. This is a common and necessary practice in software development to allow for flexible configuration management. The method is well-structured, handles exceptions, and logs relevant information, which are good practices for maintainability and debugging. Additionally, it uses standard libraries and patterns that are unlikely to become obsolete."
survived,"    def acquire(self, cost: float = 1.0):
        while True:
            now = time.perf_counter()
            elapsed = now - self._last
            self._last = now
            self._allow = min(self._tps, self._allow + elapsed * self._tps)
            if self._allow >= cost:
                self._allow -= cost
                return
            sleep = (cost - self._allow) / self._tps + 1e-3
            time.sleep(sleep)
",alpha_factory_v1/demos/meta_agentic_agi/agents/agent_base.py,RateLimiter,1,1.0467401685178159e-08,"The method 'acquire' is implementing a rate-limiting algorithm, which is a common and useful functionality in many applications to control the rate of operations or requests. This method is likely part of a token bucket or leaky bucket algorithm, which are standard techniques for rate limiting. Given its utility in managing resources and preventing abuse or overuse of services, it is unlikely to be deleted unless there is a significant change in the application's requirements or architecture that renders this specific implementation obsolete. However, as it stands, the method serves a clear purpose and is likely to be retained."
survived,"def _main():
    p=argparse.ArgumentParser(prog=""alpha_asi_world_model_demo"")
    p.add_argument(""--demo"",action=""store_true"")
    p.add_argument(""--emit-docker"",action=""store_true"")
    p.add_argument(""--emit-helm"",action=""store_true"")
    p.add_argument(""--emit-notebook"",action=""store_true"")
    p.add_argument(""--host"",default=""127.0.0.1"")
    p.add_argument(""--port"",type=int,default=7860)
    args=p.parse_args()
    if args.emit_docker: emit_docker()
    elif args.emit_helm: emit_helm()
    elif args.emit_notebook: emit_notebook()
    elif args.demo:
        uvicorn.run(""alpha_asi_world_model_demo:app"",host=args.host,port=args.port,log_level=""info"")
    else: p.print_help()
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,,1,5.3157849718487075e-08,"The method '_main()' is a typical entry point for a command-line interface (CLI) application. It uses the argparse library to parse command-line arguments and execute different functions based on those arguments. This is a common pattern in Python applications that need to be run from the command line, and it is unlikely to be deleted unless the entire application is being refactored or removed. The method is functional, well-structured, and serves a clear purpose in the application."
survived,"async def ws_endpoint(sock:WebSocket):
    await sock.accept(); q:List[dict]=[]
    A2ABus.subscribe(""ui"", lambda m:q.append(m))
    try:
        while True:
            if q: await sock.send_text(json.dumps(q.pop(0)))
            await asyncio.sleep(0.1)
    except Exception: pass
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,,1,2.646573631904765e-09,"The method is likely to survive because it implements a WebSocket endpoint that listens for messages and sends them to the client. It uses asynchronous programming to handle incoming messages efficiently and is structured to handle exceptions gracefully. This functionality is common and useful in real-time applications, making it a valuable component in many systems."
survived,"    def __init__(self, cpu_sec:int=2, mem_mb:int=128):
        self.cpu_sec = cpu_sec
        self.mem_mb = mem_mb
",alpha_factory_v1/demos/meta_agentic_agi_v2/agents/agent_base.py,SafeExec,1,2.5109990926928157e-08,"The method is a constructor for a class, initializing two attributes with default values. Constructors are essential for setting up initial state in object-oriented programming, and this one is straightforward and functional. There is no indication of redundancy or inefficiency that would warrant its deletion."
survived,"    def idx():
        return VIEW_HTML
",alpha_factory_v1/demos/meta_agentic_agi_v2/agents/agent_base.py,,0,0.9999996533672291,"The method `idx` is a simple function that returns a constant value `VIEW_HTML`. Without additional context, it's unclear what `VIEW_HTML` represents or how this function is used. However, the function itself is very minimal and doesn't perform any operations or calculations. If `VIEW_HTML` is a constant that is used elsewhere in the code, this function might be unnecessary as it adds an extra layer of indirection without any apparent benefit. Therefore, it's likely that this method could be deleted if `VIEW_HTML` can be accessed directly where needed."
survived,"    def score(self, metrics: Dict[str,float]) -> float:
        return (
            self.latency * (1/ (1+metrics.get(""latency"",0))) +
            self.cost    * (1/ (1+metrics.get(""cost"",0))) +
            self.carbon  * (1/ (1+metrics.get(""carbon"",0))) +
            self.risk    * (1- metrics.get(""risk"",0))
        )
",alpha_factory_v1/demos/meta_agentic_agi_v3/agents/agent_base.py,ObjectiveWeights,1,1.1032560311263802e-09,"The method 'score' is a utility function that calculates a weighted score based on various metrics such as latency, cost, carbon, and risk. It uses a combination of these metrics to produce a single float value, which can be useful for evaluating performance or efficiency in a system. The method is straightforward, uses standard Python libraries, and provides a clear purpose. There is no indication that it is redundant or obsolete, and it seems to be a useful part of a larger system. Therefore, it is likely to be retained."
survived,"        def handle(self, _msg):
            LOG.debug(""[Fallback%d] â† %s"", idx, _msg)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,Fallback,1,2.998960815863541e-09,"The method 'handle' is a simple logging function that logs a message with a specific format. It is likely part of a larger system where logging is essential for debugging and monitoring purposes. Such methods are generally retained as they provide valuable insights during the development and maintenance phases. Therefore, it is likely to survive."
survived,"    def run(self, prompt: str, context: Optional[Iterable[Dict[str,str]]]=None, **kw) -> Dict[str,Any]:
        ctx: List[Dict[str,str]] = list(context or [])
        ctx.append({""role"":""user"", ""content"": prompt})
        t0 = time.perf_counter()
        output = self.lm.chat(ctx, **kw)
        latency = time.perf_counter()-t0
        tokens_in = _str_tkn(prompt)
        tokens_out = _str_tkn(output)
        cost = self._estimate_cost(tokens_in,tokens_out)
        carbon = cost*0.00015 # placeholder multiplier (avg kgCO2 per $ cloud)
        risk = self._risk_assess(prompt, output)
        metrics = dict(latency=latency, cost=cost, carbon=carbon, risk=risk)
        score = self.objectives.score(metrics)
        self.tracer.log(""run"", prompt=prompt[:120], response=output[:120], metrics=metrics, score=score)
        return {""response"": output, ""metrics"": metrics, ""score"": score}
",alpha_factory_v1/demos/meta_agentic_agi/agents/agent_base.py,Agent,1,9.736200303530205e-10,"The method 'run' is likely to survive because it appears to be a well-structured and comprehensive function that performs a series of important tasks. It processes a prompt, interacts with a language model, measures performance metrics such as latency, cost, and carbon footprint, assesses risk, and logs the results. These functionalities are crucial for applications that rely on language models, especially in contexts where performance and environmental impact are important considerations. Additionally, the method's use of logging and scoring suggests it is part of a larger system that values these metrics, making it less likely to be removed."
survived,"    def __init__(self):
        super().__init__()
        self.sub1 = DummySub()
        self.sub2 = DummySub()
",tests/test_multi_contributor.py,DummyModel,1,1.0677030767166749e-06,"The method is a constructor (__init__) for a class, which is a fundamental part of object-oriented programming in Python. Constructors are essential for initializing new objects and setting up initial states or properties. This method is not only standard but necessary for the class to function correctly, especially if it involves initializing instances of other classes (like DummySub in this case). Therefore, it is highly unlikely that this method would be deleted."
survived,"def test_commit_roundtrip(tmp_path: Path):
    data = {""input_data"": [1, 2, 3, 4]}
    path = tmp_path / ""acts.json""
    with open(path, ""w"") as f:
        json.dump(data, f)

    commit = commit_activations(str(path))
    assert verify_commitment(str(path), commit)",tests/test_poly_commit.py,,1,8.152020648014727e-09,"The method 'test_commit_roundtrip' is a test function that appears to be part of a testing suite, likely using a framework like pytest. It tests the functionality of committing and verifying data, which is a common requirement in software development to ensure data integrity and correctness. Test functions are generally not deleted unless they are redundant or replaced by more comprehensive tests. Since this function seems to serve a specific purpose in testing the commit and verification process, it is likely to be retained."
survived,"    def __call__(self, text, return_tensors=None):
        return {""input_ids"": torch.tensor([[1]])}
",tests/test_multi_contributor.py,DummyTokenizer,0,0.9999756997690634,"The method `__call__` is a special method in Python that allows an instance of a class to be called as a function. In this code, the method takes two parameters, `text` and `return_tensors`, and returns a dictionary with a key `input_ids` and a value of a tensor containing a single element list with the number 1. This method is likely a placeholder or a simplified version of a more complex function, possibly for testing or demonstration purposes. However, it does not perform any meaningful operation on the `text` or `return_tensors` parameters, which suggests it might not be useful in its current form. Without additional context or functionality, this method is likely to be deleted or replaced with a more functional implementation in a real-world application."
survived,"def commit_activations(activations_path: str, challenge: int = CHALLENGE) -> str:
    """"""Return polynomial commitment of activations stored in JSON file.""""""
    with open(activations_path, ""r"") as f:
        data = json.load(f)
    arr = np.array(data[""input_data""], dtype=np.int64).reshape(-1)
    val = _poly_eval(arr, challenge, PRIME)
    return hex(val)
",src/zklora/polynomial_commit.py,,1,8.152020648014727e-09,"The method 'commit_activations' is a utility function that reads a JSON file, processes the data into a numpy array, evaluates a polynomial, and returns the result as a hexadecimal string. This type of function is typically useful in applications involving cryptographic commitments or data integrity checks. Given its specific functionality and the fact that it is not overly complex or redundant, it is likely to be retained in the codebase unless there is a significant change in the application's requirements or architecture."
survived,"    def init_request(self):
        return [self.name]
",tests/test_multi_contributor.py,FakeComm,0,0.9999930377415741,"The method 'init_request' is very minimal and only returns a list containing the attribute 'self.name'. Without additional context, such as how 'self.name' is used or modified, it's difficult to see its utility. If 'self.name' is a critical part of the class and frequently accessed, this method might be useful for encapsulation or future expansion. However, if 'self.name' can be accessed directly without any additional processing, this method might be considered redundant and could be deleted. Overall, without further context, it seems more likely to be deleted due to its simplicity and lack of apparent necessity."
survived,"def test_log_to_section_training():
    """"""Test log_to_section writes to the training file""""""
    with tempfile.TemporaryDirectory() as tmpdir:
        logger = Logger(""test_module"", base_dir=tmpdir)
        data = {""foo"": ""bar""}
        logger.log_to_section(data, section=""training"")

        with open(logger.training_file, ""r"", encoding=""utf-8"") as f:
            lines = f.readlines()
            assert len(lines) == 1
            entry = json.loads(lines[0])
            assert entry[""foo""] == ""bar""
            assert isinstance(entry[""timestamp""], float)",tests/test_logger.py,,1,3.653482080241728e-08,"The method 'test_log_to_section_training' is a unit test designed to verify the functionality of the 'log_to_section' method in the 'Logger' class. It checks if the method correctly writes data to a specified section in a training file. The test uses a temporary directory to avoid side effects, and it includes assertions to ensure the data is logged correctly. This is a standard practice in software development to ensure code reliability and correctness. Therefore, the method is likely to be retained as it serves an important role in testing the functionality of the code."
survived,"def test_lm_param_override_and_restore():
    """"""Test that lm_params temporarily override LM settings""""""
    # Reset instances so we get a fresh caller with patched LM
    from simpledspy.module_caller import BaseCaller, Predict
    BaseCaller._instances = {}

    with patch('simpledspy.module_caller.dspy.LM') as MockLM:
        mock_lm = MockLM.return_value
        mock_lm.temperature = 0.2
        captured = {}

        class MockModule(dspy.Module):
            def forward(self, **_):
                captured['temp'] = mock_lm.temperature
                return dspy.Prediction(result='ok')

        with patch('simpledspy.module_caller.Predict._create_module', return_value=MockModule()):
            caller = Predict()
            result = caller('text', inputs=['text'], outputs=['result'], lm_params={'temperature': 0.9})
            assert result == 'ok'
            assert captured['temp'] == 0.9
            assert caller.lm.temperature == 0.2",tests/test_predict.py,,1,5.3157849718487075e-08,"The method is a unit test designed to verify the functionality of overriding and restoring language model parameters. It is a useful test to ensure that the system behaves correctly when parameters are temporarily changed and then restored. Such tests are crucial for maintaining the integrity of the system, especially when dealing with configurations that can affect the output of machine learning models. Therefore, it is likely to be retained as part of the test suite."
survived,"            def _invoke(self, msgs, temperature, max_tokens, stream, stop):
                answer = ""[offline] "" + msgs[-1][""content""][:400]
                if stream:
                    for tok in answer.split():
                        yield tok + "" ""
                else:
                    return answer
",alpha_factory_v1/backend/utils/llm_provider.py,_Stub,1,2.5109990926928157e-08,"The method '_invoke' is a private method (indicated by the underscore) and seems to be a utility function for processing messages. It appends '[offline]' to the content of the last message and either streams the response token by token or returns the full answer. This functionality is specific and useful for certain applications, such as simulating offline responses or testing. Unless the overall design or requirements change significantly, this method is likely to be retained for its specific purpose."
survived,"def test_load_corpus(tmp_path):
    corpus_file = tmp_path / ""corpus.csv""
    with open(corpus_file, ""w"", encoding=""utf-8"", newline="""") as f:
        writer = csv.writer(f)
        writer.writerow([""0 hello"", ""1 world""])
        writer.writerow([""1 world"", ""0 hello ""])

    corpus = sampler.load_corpus(str(corpus_file))

    assert corpus == [[0, 1], [1, 0]]",tests/test_sampler_io.py,,1,1.2501528648238603e-09,"The method 'test_load_corpus' is a test function that verifies the functionality of the 'load_corpus' method from the 'sampler' module. It creates a temporary CSV file, writes some data to it, and then checks if the 'load_corpus' method correctly reads and processes this data into the expected format. Test functions like this are crucial for ensuring code reliability and are typically retained in a codebase to maintain test coverage and facilitate future development. Therefore, it is likely to survive."
survived,"    def __init__(self, settings: config.Settings) -> None:
        self.settings = settings
        self.published: list[tuple[str, messaging.Envelope]] = []
",tests/test_codegen_safety.py,DummyBus,1,9.237449576640118e-09,"The method is a constructor (__init__) method, which is essential for initializing instances of a class. It sets up the initial state of the object by assigning the provided settings to an instance variable and initializing an empty list for published items. Constructor methods are fundamental to object-oriented programming and are unlikely to be deleted unless the entire class is being refactored or removed, which is not indicated here."
survived,"def test_allows_normal_message() -> None:
    agent = _make_agent()
    env = messaging.Envelope(
        sender=""market"",
        recipient=""safety"",
        payload={""analysis"": ""hold position""},
        ts=0.0,
    )
    asyncio.run(agent.handle(env))
    assert agent.bus.published[-1][1].payload[""status""] == ""ok""",tests/test_codegen_safety.py,,1,8.76424914819242e-08,"The method `test_allows_normal_message` is a unit test function that checks if a messaging agent correctly processes a normal message and publishes a status of ""ok"". Unit tests are crucial for ensuring code reliability and functionality, especially in systems involving messaging and asynchronous operations. This test verifies that the agent behaves as expected when handling a standard message, which is a fundamental aspect of its operation. Therefore, it is unlikely to be deleted as it serves an important role in maintaining code quality."
survived,"def _venv_pip(venv: Path) -> Path:
    """"""Return the path to the pip executable inside *venv*.""""""
    if os.name == ""nt"":
        return venv / ""Scripts"" / ""pip.exe""
    return venv / ""bin"" / ""pip""
",alpha_factory_v1/quickstart.py,,1,1.8189616842444243e-09,"The method _venv_pip is a utility function that determines the path to the pip executable within a virtual environment. This is a common requirement in Python projects that use virtual environments to manage dependencies. The function is simple, effective, and platform-aware, handling both Windows and Unix-like systems. Such utility functions are often retained in codebases because they encapsulate a specific, useful functionality that is likely to be reused. Therefore, it is likely to survive."
survived,"                def locate_file(self, path):
                    return init_file
",alpha_factory_v1/tests/test_requests_import.py,RequestsImportTest.Dist,0,0.9999962733608834,"The method 'locate_file' is supposed to locate a file given a path, but it returns 'init_file' without any logic to actually locate or verify the file at the specified path. This suggests that the method is incomplete or incorrectly implemented. Without proper functionality, it is likely to be deleted or significantly modified to fulfill its intended purpose."
survived,"    def test_load_real_package_when_available(self):
        with tempfile.TemporaryDirectory() as tmpdir:
            pkg = Path(tmpdir) / ""requests""
            pkg.mkdir()
            init_file = pkg / ""__init__.py""
            init_file.write_text(""value = 42\n"")

            class Dist:
                def locate_file(self, path):
                    return init_file

            original = im.distribution
            def fake_distribution(name):
                self.assertEqual(name, ""requests"")
                return Dist()
            im.distribution = fake_distribution
            sys.path.insert(0, tmpdir)
            try:
                mod = importlib.import_module(""requests"")
                self.assertEqual(getattr(mod, ""value"", None), 42)
                self.assertEqual(Path(mod.__file__).resolve(), init_file.resolve())
            finally:
                sys.path.remove(tmpdir)
                im.distribution = original
                sys.modules.pop(""requests"", None)
",alpha_factory_v1/tests/test_requests_import.py,RequestsImportTest,1,5.60279640614594e-09,"The method 'test_load_real_package_when_available' is a unit test designed to verify the behavior of loading a real package when it is available. It uses a temporary directory to simulate the presence of a package and checks if the module can be imported correctly with the expected attributes. This kind of test is useful for ensuring that the import mechanism works as expected, especially in environments where packages might be dynamically loaded or mocked. Since it serves a clear purpose in testing the functionality of package loading, it is likely to be retained in the codebase."
survived,"    def __init__(self):
        self.next_ts = 0
        self.period = 1
        self.last_beat = time.time()
        self.inst = SimpleNamespace()
        self.spec = None
",alpha_factory_v1/tests/test_orchestrator_rest.py,DummyRunner,1,9.931195248674785e-08,"The method is a constructor (__init__) for a class, which is a fundamental part of class instantiation in Python. Constructors are essential for initializing object attributes and setting up the initial state of an object. Therefore, it is unlikely to be deleted as it serves a critical role in object-oriented programming."
survived,"    def check_chart_file(self, chart_path: Path):
        self.assertTrue(chart_path.is_file(), f""{chart_path} missing"")
        text = chart_path.read_text()
        for key in [""apiVersion:"", ""name:"", ""version:"", ""appVersion:""]:
            self.assertIn(key, text, f""{key} not found in {chart_path}"")
",alpha_factory_v1/tests/test_helm_charts.py,HelmChartTests,1,1.8189616842444243e-09,"The method 'check_chart_file' is a utility function that checks the existence and content of a file at a given path. It verifies that the file exists and contains specific keys, which are likely important for the file's validity or format. This kind of method is useful for validation purposes, especially in testing scenarios where ensuring the presence of certain data is crucial. Since it serves a clear purpose and is likely used in a testing context, it is unlikely to be deleted unless the testing requirements change significantly."
survived,"    def test_import_success(self):
        with NamedTemporaryFile('w', delete=False) as tmp:
            json.dump({'title': 't'}, tmp)
            tmp_path = tmp.name
        with mock.patch.dict(os.environ, {'GRAFANA_TOKEN': 'tok', 'GRAFANA_HOST': 'http://h'}, clear=True):
            with mock.patch.object(sys, 'argv', ['script', tmp_path]):
                with mock.patch('alpha_factory_v1.scripts.import_dashboard.post') as post:
                    post.return_value = mock.Mock(raise_for_status=lambda: None)
                    import_dashboard.main()
                    post.assert_called_once()
                    args, kwargs = post.call_args
                    self.assertEqual(args[0], 'http://h/api/dashboards/import')
                    self.assertEqual(kwargs['headers']['Authorization'], 'Bearer tok')
",alpha_factory_v1/tests/test_import_dashboard.py,ImportDashboardTest,1,1.1861120010657661e-08,"The method 'test_import_success' is a unit test designed to verify the functionality of the 'import_dashboard' script. It uses mock objects to simulate the environment and dependencies, ensuring that the script behaves as expected without requiring actual network calls or environment variables. This is a common practice in software testing to ensure code reliability and correctness. Since testing is a crucial part of software development and maintenance, this method is likely to be retained to ensure the continued functionality of the 'import_dashboard' feature."
survived,"def example7():
    x = fetch_()
    if x == ""cheese"":
        None
    else:
        if someCondition():
            None
",tests/rosetta/transpiler/Python/conditional-structures-7.py,,0,0.9999999634651793,"The method 'example7' is likely to be deleted because it does not perform any meaningful operations. The function fetches a value using 'fetch_()', checks if it equals 'cheese', and then does nothing regardless of the condition. The same applies to the 'someCondition()' check. This code is essentially a no-op and serves no purpose, making it a candidate for deletion."
survived,"def timeStr(sec):
    wks = sec // 604800
    sec = sec % 604800
    ds = sec // 86400
    sec = sec % 86400
    hrs = sec // 3600
    sec = sec % 3600
    mins = sec // 60
    sec = sec % 60
    res = """"
    comma = False
    if wks != 0:
        res = res + str(wks) + "" wk""
        comma = True
    if ds != 0:
        if comma:
            res = res + "", ""
        res = res + str(ds) + "" d""
        comma = True
    if hrs != 0:
        if comma:
            res = res + "", ""
        res = res + str(hrs) + "" hr""
        comma = True
    if mins != 0:
        if comma:
            res = res + "", ""
        res = res + str(mins) + "" min""
        comma = True
    if sec != 0:
        if comma:
            res = res + "", ""
        res = res + str(sec) + "" sec""
    return res
",tests/rosetta/transpiler/Python/convert-seconds-to-compound-duration.py,,1,1.8189616842444243e-09,"The method `timeStr` is a utility function that converts a given number of seconds into a human-readable string format, breaking it down into weeks, days, hours, minutes, and seconds. This type of functionality is commonly needed in various applications to display time durations in a more understandable format for users. The code is straightforward, performs its task efficiently, and does not have any apparent issues or redundancies that would necessitate its removal. Therefore, it is likely to be retained in the codebase."
survived,"def main():
    print(""For primes < 1 million:\n"")
    for dir in [""ascending"", ""descending""]:
        longestSeq(dir)
",tests/rosetta/transpiler/Python/consecutive-primes-with-ascending-or-descending-differences.py,,1,4.944450477491054e-09,"The method 'main' is a simple function that prints a message and calls another function 'longestSeq' twice with different arguments. It is a basic structure often used in scripts to execute a sequence of operations. There is no indication that this method is redundant or unnecessary, as it serves a clear purpose in organizing the flow of the program. Therefore, it is likely to be retained in the codebase."
survived,"def randN(n):
    global seed
    seed = (seed * 1664525 + 1013904223) % 2147483647
    return seed % n
",tests/rosetta/transpiler/Python/conways-game-of-life.py,,1,5.3157849718487075e-08,"The method 'randN' is a simple random number generator that uses a linear congruential generator (LCG) algorithm. This is a common and well-known method for generating pseudo-random numbers. The function is straightforward and does not contain any obvious errors or inefficiencies. It is likely to be useful in contexts where a simple random number generator is needed, especially in educational or illustrative scenarios. Therefore, there is no strong reason for this method to be deleted."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/concurrent-computing-2.py,,1,9.931195248674785e-08,"The method _now() is a utility function that generates a pseudo-random number based on a seed if _now_seeded is True, or returns the current time in nanoseconds if not. This function is likely part of a larger system that requires either a random number or a timestamp, depending on the state of _now_seeded. Such utility functions are common in systems that need to simulate time or generate random numbers for testing or other purposes. Since it provides a dual functionality that can be useful in various scenarios, it is likely to be retained in the codebase."
survived,"def fetchSomething():
    return 0
",tests/rosetta/transpiler/Python/conditional-structures-4.py,,0,0.9999997300421382,"The method `fetchSomething` is a placeholder function that returns a constant value of 0. It does not perform any meaningful operation or fetch any data, which is typically expected from a function with such a name. Without additional context or implementation, this method is not useful and is likely to be deleted or replaced with a more functional version in a real-world codebase."
survived,"    def _act(x: torch.Tensor) -> torch.Tensor:
        nonlocal calls
        calls += 1
        return x
",tests/test_evo_net_activation.py,,1,9.237449576640118e-09,"The method `_act` is a simple function that increments a nonlocal variable `calls` and returns the input tensor `x`. This function seems to be used for tracking how many times it is called, which can be useful for debugging or performance monitoring. Since it serves a specific purpose and is not overly complex or redundant, it is likely to be retained in the codebase."
survived,"    def test_main_offline_skips_network(self) -> None:
        with mock.patch.multiple(
            preflight,
            check_python=lambda: True,
            check_cmd=lambda cmd: True,
            check_docker_daemon=lambda: True,
            check_docker_compose=lambda: True,
            check_pkg=lambda pkg: True,
            ensure_dir=lambda p: None,
            banner=lambda *a, **k: None,
        ):
            with mock.patch.object(preflight, ""check_network"") as cn:
                preflight.main([""--offline""])
                cn.assert_not_called()
",alpha_factory_v1/tests/test_preflight.py,PreflightTest,1,2.0611536181902033e-09,"The method 'test_main_offline_skips_network' is a unit test designed to verify that the 'main' function in the 'preflight' module does not call 'check_network' when the '--offline' flag is used. This is a specific and useful test case to ensure that the offline mode behaves correctly by skipping network checks. Unit tests are generally retained as they are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, this method is likely to be retained."
survived,"    def _replace(match: re.Match) -> str:
        for iast, slp in _IAST_TO_SLP1:
            if match.group(0) == iast:
                return slp
        return match.group(0)
",atroposlib/envs/reward_fns/chandas_meter_reward.py,,1,4.944450477491054e-09,"The method `_replace` is a private helper function, indicated by the underscore prefix, which is typically used for internal purposes within a module or class. It is designed to work with regular expression matches, replacing matched text based on a predefined mapping (`_IAST_TO_SLP1`). This kind of function is often crucial for text processing tasks, especially when dealing with transliteration or similar operations. Since it serves a specific purpose and is likely part of a larger system that relies on this functionality, it is unlikely to be deleted unless the entire system is refactored or the transliteration logic is no longer needed. Therefore, the method is more likely to survive."
survived,"    def test_concurrent_writes(self) -> None:
        from alpha_factory_v1.demos.cross_industry_alpha_factory import (
            cross_alpha_discovery_stub as stub,
        )

        with tempfile.TemporaryDirectory() as tmp:
            ledger = Path(tmp) / ""thread_log.json""

            def worker(seed: int) -> None:
                stub.discover_alpha(num=1, seed=seed, ledger=ledger, model=""gpt-4o-mini"")

            threads = [threading.Thread(target=worker, args=(i,)) for i in range(5)]
            for t in threads:
                t.start()
            for t in threads:
                t.join()

            data = json.loads(ledger.read_text())
            self.assertEqual(len(data), 5)
",tests/test_cross_alpha_discovery.py,TestCrossAlphaDiscoveryStub,1,5.211412485172657e-10,"The method 'test_concurrent_writes' is a unit test designed to verify the functionality of concurrent writes to a ledger file using multiple threads. It is a valid and useful test case for ensuring that the system can handle concurrent operations without data loss or corruption. Such tests are crucial for systems that involve parallel processing or multi-threading. Therefore, it is likely to be retained in the codebase."
survived,"def available_scenarios(directory: str | Path | None = None) -> list[str]:
    """"""Return the list of available scenario names.""""""

    dir_path = Path(directory or BASE_DIR)
    names = {p.stem for p in dir_path.glob(""*.yaml"")}
    names.update(p.stem for p in dir_path.glob(""*.yml""))
    return sorted(names)
",src/simulation/replay.py,,1,2.646573631904765e-09,"The method `available_scenarios` is a utility function that provides a useful feature: listing scenario names from YAML files in a specified directory. This is a common requirement in applications that deal with configuration or scenario files, especially in environments where scenarios are defined in YAML format. The method is well-defined, uses type hints, and handles default directory paths, making it versatile and easy to use. There is no indication that this method is redundant or obsolete, and it serves a clear purpose in managing and retrieving scenario names. Therefore, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/dataset_where_filter.py,Person,0,0.9999687980937693,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate method for checking membership."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/group_by.py,Auto1,0,0.9999785550602307,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/cast_struct.py,Todo,0,0.9999962733608834,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/outer_join.py,Customer,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use of `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely to be deleted or refactored to better fit its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/json_builtin.py,Auto1,0,0.999985261023967,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list, set, or dictionary. Therefore, the method is likely to be deleted or rewritten to correctly implement membership checking."
survived,"def _find_gitignore_files_for_dir(dir_path: Path, root_path: Path) -> List[Path]:
    """"""Finds all .gitignore files from root_path down to dir_path.""""""
    gitignore_files = []
    current = dir_path.resolve()
    root = root_path.resolve()

    if not (current == root or root in current.parents):
         logger.warning(f""Directory {current} is not within the root {root}. Cannot find gitignore files."")
         return []

    paths_to_check = []
    temp_path = current
    while temp_path >= root:
        paths_to_check.append(temp_path)
        if temp_path == root:
            break
        parent = temp_path.parent
        if parent == temp_path:
            break
        temp_path = parent

    for p in reversed(paths_to_check):
        ignore_file = p / GITIGNORE_FILENAME
        if ignore_file.is_file():
            gitignore_files.append(ignore_file)
            logger.debug(f""Found gitignore file: {ignore_file}"")

    return gitignore_files
",jinni/utils.py,,1,2.3355930333443423e-09,"The method '_find_gitignore_files_for_dir' is a utility function that serves a specific purpose: finding all .gitignore files from a specified root directory down to a given directory. This is a common requirement in projects that use Git for version control, as .gitignore files are used to specify files and directories that should be ignored by Git. The method is well-defined, checks for valid directory paths, and logs useful information, making it a valuable part of a codebase that deals with file system operations and version control. Therefore, it is likely to be retained in the codebase."
survived,"def test_colon_replacement():
    assert remove_chars('Title: Subtitle') == 'Title - Subtitle'
    assert remove_chars('A:B') == 'A - B'
    assert remove_chars('Multi:part:colon') == 'Multi - part - colon'
    assert remove_chars('Title:Subtitle : Another') == 'Title - Subtitle - Another'
",tests/test_remove_chars.py,,1,1.2501528648238603e-09,"The method 'test_colon_replacement' is a unit test function that checks the functionality of a hypothetical 'remove_chars' function. It verifies that colons in a string are replaced with ' - '. This is a common and useful test to ensure that string manipulation functions work as expected. Since testing is a crucial part of software development to maintain code quality and prevent regressions, this method is likely to be retained in the codebase."
deleted,"def test_question_mark_meridiem(now):
    assert timefhuman(
        'Are you free this Wed at 3p? Or maybe Fri at 5p?',
        tfhConfig(now=now)
    ) == [
        datetime.datetime(2018, 8, 8, 15, 0),
        datetime.datetime(2018, 8, 10, 17, 0)
    ]",tests/test_e2e.py,,1,8.152020648014727e-09,"The method 'test_question_mark_meridiem' is a test function that checks the functionality of the 'timefhuman' library, specifically its ability to correctly interpret times with a question mark and meridiem (e.g., '3p' and '5p'). This is a useful test case to ensure that the library can handle common natural language inputs that users might provide. Since testing is a crucial part of software development to ensure reliability and correctness, this method is likely to be retained as part of the test suite."
survived,"            def __call__(self, *_a, **_k):
                return """"
",tests/test_macro_adk_integration.py,_OpenAI,1,0.0002611903266877732,"The method is a special method in Python, known as a ""dunder"" method, which allows an instance of a class to be called as a function. The implementation here returns an empty string regardless of the input arguments. While the method is functional, its utility depends on the context in which it is used. If the class is designed to be callable and returning an empty string is the intended behavior, it will survive. However, if this behavior is not useful or intended, it might be subject to deletion or modification. Without additional context, it's difficult to definitively predict its fate, but generally, such methods are kept unless they are proven to be unnecessary."
survived,"            def __init__(self, *a, **kw):
                self.name = kw.get(""name"", ""agent"")
",tests/test_macro_adk_integration.py,_Agent,1,3.2241866333029355e-08,"The method is a constructor for a class, typically used to initialize object attributes. It uses variable arguments (*a) and keyword arguments (**kw), which makes it flexible for different initialization scenarios. The method sets a default value for the 'name' attribute if it is not provided, which is a common and useful pattern in Python programming. This method is likely to be retained as it provides essential functionality for object initialization."
survived,"def non_network(monkeypatch: pytest.MonkeyPatch) -> None:
    """"""Disable outbound networking for the duration of a test.""""""

    def _blocked(*_a: Any, **_k: Any) -> None:
        raise OSError(""network disabled"")

    monkeypatch.setattr(socket.socket, ""connect"", _blocked)
    yield
",tests/conftest.py,,1,6.825604231969389e-08,"The method 'non_network' is a utility function used in testing to disable outbound networking by monkeypatching the 'connect' method of the 'socket' module. This is a common practice in testing to ensure that tests do not make actual network calls, which can be slow, unreliable, or undesired in a test environment. The method is useful for creating isolated test environments and ensuring tests are deterministic. Given its utility in testing scenarios, it is likely to be retained in the codebase."
survived,"        def parse_dataset_iter(it: ast.expr) -> tuple[str, str | None, str | None, str | None]:
            sort = None
            skip = None
            take = None
            cur = it

            # handle take
            if isinstance(cur, ast.Subscript) and isinstance(cur.slice, ast.Slice):
                sl = cur.slice
                if (
                    sl.lower is None
                    and sl.step is None
                    and isinstance(sl.upper, ast.Call)
                    and getattr(sl.upper.func, ""id"", None) == ""max""
                    and len(sl.upper.args) == 2
                    and isinstance(sl.upper.args[1], ast.Constant)
                    and sl.upper.args[1].value == 0
                ):
                    take = self.convert_expr(sl.upper.args[0])
                    cur = cur.value

            # handle skip
            if isinstance(cur, ast.Subscript) and isinstance(cur.slice, ast.Slice):
                sl = cur.slice
                if (
                    sl.upper is None
                    and sl.step is None
                    and isinstance(sl.lower, ast.Call)
                    and getattr(sl.lower.func, ""id"", None) == ""max""
                    and len(sl.lower.args) == 2
                    and isinstance(sl.lower.args[1], ast.Constant)
                    and sl.lower.args[1].value == 0
                ):
                    skip = self.convert_expr(sl.lower.args[0])
                    cur = cur.value

            # handle sort
            if isinstance(cur, ast.Call) and isinstance(cur.func, ast.Name) and cur.func.id == ""sorted"":
                if cur.keywords:
                    for kw in cur.keywords:
                        if kw.arg == ""key"" and isinstance(kw.value, ast.Lambda):
                            body = kw.value.body
                            if (
                                isinstance(body, ast.Call)
                                and isinstance(body.func, ast.Name)
                                and body.func.id == ""_sort_key""
                                and body.args
                            ):
                                sort = self.convert_expr(body.args[0])
                            else:
                                sort = self.convert_expr(body)
                if cur.args:
                    cur = cur.args[0]

            # remove trivial list comp wrappers
            if (
                isinstance(cur, ast.ListComp)
                and len(cur.generators) == 1
                and isinstance(cur.generators[0].target, ast.Name)
                and isinstance(cur.elt, ast.Name)
                and cur.elt.id == cur.generators[0].target.id
                and not cur.generators[0].ifs
            ):
                cur = cur.generators[0].iter

            return self.convert_expr(cur), sort, skip, take
",tools/any2mochi/py/py2mochi.py,Converter,1,6.348800075736417e-09,"The method `parse_dataset_iter` is a utility function that processes an abstract syntax tree (AST) expression to extract and return a tuple containing expressions for sorting, skipping, and taking elements from a dataset. This kind of functionality is useful in scenarios where code needs to be dynamically analyzed or transformed, such as in compilers, interpreters, or code analysis tools. Given the increasing importance of such tools in software development, it is likely that this method will survive as it provides a specific and useful capability in processing ASTs."
survived,"    def visit_If(self, node: ast.If) -> None:
        test = self.convert_expr(node.test)
        self.emit(f""if {test} {{"")
        self.indent += 1
        for stmt in node.body:
            self.visit(stmt)
        self.indent -= 1
        if node.orelse:
            self.emit(""} else {"")
            self.indent += 1
            for stmt in node.orelse:
                self.visit(stmt)
            self.indent -= 1
            self.emit(""}"")
        else:
            self.emit(""}"")
",tools/any2mochi/py/py2mochi.py,Converter,1,2.7894680920908113e-10,"The method `visit_If` is a crucial part of an abstract syntax tree (AST) visitor pattern, specifically for handling `if` statements in a source code. It converts the test expression, emits the appropriate code for the `if` block, and handles the `else` block if present. This functionality is fundamental for any tool that processes or transforms code, such as a compiler, interpreter, or code analyzer. Given its essential role in processing conditional statements, it is unlikely to be deleted unless the entire system is being deprecated or significantly refactored."
survived,"    def __init__(self, src: str):
        self.lines: list[str] = []
        self.indent = 0
        self.src_lines = src.splitlines()
        self.dataclasses: set[str] = set()
        self.seen_assigns: set[str] = set()
        self.assign_values: dict[str, str] = {}
        self.current_callable: tuple[list[str], str] | None = None
        self.structs: dict[str, tuple[list[tuple[str, str]], list[ast.FunctionDef]]] = {}
        self.unions: dict[str, list[tuple[str, list[tuple[str, str]]]]] = {}
        self.name_map = {""_next"": ""next""}
",tools/any2mochi/py/py2mochi.py,Converter,1,4.6911638017642294e-08,"The method is a constructor (__init__) for a class, which is a fundamental part of object-oriented programming in Python. It initializes the instance variables and sets up the initial state of the object. This method is essential for the proper functioning of the class, as it prepares the object for use by setting up necessary attributes and data structures. Therefore, it is unlikely to be deleted."
deleted,"def get_tool_stats() -> dict[str, dict[str, int]]:
    with _lock:
        return {name: entry.to_dict() for name, entry in _tool_stats.items()}
",src/serena/analytics.py,,1,2.3355930333443423e-09,"The method 'get_tool_stats' is a simple utility function that returns a dictionary representation of tool statistics. It is thread-safe due to the use of a lock, ensuring that the data is accessed in a synchronized manner. This function is likely part of a larger system that tracks or manages tool usage statistics, and such functionality is generally useful and necessary in many applications. Therefore, it is unlikely to be deleted as it serves a clear purpose in providing structured data access."
survived,"    def Markdown(self, *a, **k):
        pass
",tests/test_agent_experience_entrypoint.py,DummyBlocks,0,0.9999992661791398,"The method 'Markdown' is defined but not implemented, as it only contains a 'pass' statement. This suggests that it is a placeholder for future code or is intentionally left empty. Without any additional context or usage, it is likely to be deleted in the future if it remains unused or unimplemented, as it does not contribute any functionality to the code."
survived,"        def __init__(self, *a, **kw):
            agent_args.update(kw)
",tests/test_selfheal_env.py,FakeAgent,1,8.31527990378713e-07,"The method is a constructor for a class, indicated by the name `__init__`. Constructors are essential for initializing new objects in object-oriented programming. The method uses `*a` and `**kw` to accept any number of positional and keyword arguments, which is a common practice to allow flexibility in object creation. Additionally, it updates `agent_args` with the keyword arguments, suggesting that `agent_args` is likely a dictionary or similar structure used to store configuration or state information for the object. This functionality is fundamental for the class's operation, making it unlikely to be removed unless the entire class is being refactored or removed."
survived,"    def __exit__(self, exc_type, exc, tb):
        pass
",tests/test_selfheal_env.py,DummyBlocks,0,0.9999998362622821,"The method `__exit__` is a special method in Python used in context managers to handle cleanup actions. However, in this implementation, the method is defined but does not perform any actions (it simply uses `pass`). This could be intentional if the context manager does not require any cleanup, but typically, an `__exit__` method would include some logic to handle exceptions or perform necessary cleanup. Without any functionality, it might be considered redundant or incomplete, leading to its potential removal unless there is a specific reason to keep it as a placeholder. Therefore, it is likely to be deleted."
survived,"            async def ingest_loop() -> None:
                async for evt in demo.experience_stream():
                    await queue.put(evt)
                    break
",tests/test_era_experience.py,TestEraOfExperience,1,5.211412485172657e-10,"The method 'ingest_loop' is an asynchronous function that uses an asynchronous for loop to iterate over 'demo.experience_stream()' and puts each event into a queue. The method is simple and functional, serving a clear purpose in an asynchronous context. It is likely part of a larger system where events need to be processed asynchronously. There is no indication of redundancy or inefficiency that would warrant its deletion. Therefore, it is likely to survive."
survived,"    def test_policy_uses_tools(self) -> None:
        stub = types.ModuleType(""openai_agents"")
        stub.Agent = object
        stub.AgentRuntime = MagicMock()

        def _tool(*_a, **_k):
            def _decorator(func):
                return func

            return _decorator

        stub.Tool = _tool

        with patch.dict(sys.modules, {""openai_agents"": stub}):
            sys.modules.pop(
                ""alpha_factory_v1.demos.cross_industry_alpha_factory.openai_agents_bridge"",
                None,
            )
            mod = importlib.import_module(""alpha_factory_v1.demos.cross_industry_alpha_factory.openai_agents_bridge"")
            agent = mod.CrossIndustryAgent()

            with (
                patch.object(mod, ""discover"", new=AsyncMock(return_value=""disc"")),
                patch.object(mod, ""recent_log"", new=AsyncMock(return_value=""recent"")),
                patch.object(mod, ""list_samples"", new=AsyncMock(return_value=""samples"")),
            ):
                result = asyncio.run(agent.policy({""action"": ""discover""}, None))
                self.assertEqual(result, ""disc"")

                result = asyncio.run(agent.policy({""action"": ""recent""}, None))
                self.assertEqual(result, ""recent"")

                result = asyncio.run(agent.policy({}, None))
                self.assertEqual(result, ""samples"")
",tests/test_cross_industry_bridge_runtime.py,TestCrossIndustryBridgeRuntime,1,2.5109990926928157e-08,"The method 'test_policy_uses_tools' is a unit test designed to verify the behavior of the 'policy' method in the 'CrossIndustryAgent' class. It uses mocking to simulate the environment and dependencies, which is a common practice in testing to ensure that the method behaves as expected under controlled conditions. The presence of assertions to check the expected outcomes further indicates that this test is useful for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is likely to be retained as part of the test suite."
survived,"def main(argv: list[str] | None = None) -> None:
    parser = argparse.ArgumentParser(description=""OpenAI Agents bridge for the Î±â€‘AGI Insight demo"")
    parser.add_argument(""--episodes"", type=int, default=5, help=""Search episodes when offline"")
    parser.add_argument(""--target"", type=int, default=3, help=""Target sector index when offline"")
    parser.add_argument(""--model"", type=str, help=""Model name override"")
    parser.add_argument(
        ""--rewriter"",
        choices=[""random"", ""openai"", ""anthropic""],
        help=""Rewrite strategy"",
    )
    parser.add_argument(""--sectors"", type=str, help=""Comma-separated sector names"")
    parser.add_argument(
        ""--enable-adk"",
        action=""store_true"",
        help=""Enable the Google ADK gateway"",
    )
    parser.add_argument(
        ""--verify-env"",
        action=""store_true"",
        help=""Check runtime dependencies before launching"",
    )
    args = parser.parse_args(argv)

    if args.verify_env:
        verify_environment()

    if args.enable_adk:
        os.environ.setdefault(""ALPHA_FACTORY_ENABLE_ADK"", ""true"")

    _run_runtime(args.episodes, args.target, args.model, args.rewriter)
",alpha_factory_v1/demos/alpha_agi_insight_v0/openai_agents_bridge.py,,1,1.8189616842444243e-09,"The method 'main' is a typical entry point for a command-line interface (CLI) application. It uses the argparse library to parse command-line arguments, which is a common and standard practice in Python applications. The method is well-structured, with clear argument definitions and default values, making it easy to understand and use. Additionally, it includes functionality to verify the environment and set environment variables, which are useful features for a CLI tool. There is no indication that this method is obsolete or redundant, and it appears to be a necessary part of the application it belongs to. Therefore, it is likely to be retained in the codebase."
survived,"    def freeze(self) -> None:
        self._frozen = True
",weave/trace/weave_client.py,AttributesDict,1,1.1032560311263802e-09,"The method 'freeze' is a simple setter method that sets an internal state variable '_frozen' to True. Such methods are typically retained as they are useful for managing the state of an object, especially in cases where an object needs to be immutable or its state needs to be controlled. This method is likely part of a larger class that requires the ability to 'freeze' its state, which is a common pattern in programming. Therefore, it is likely to survive."
survived,"    def __delitem__(self, key: Any) -> None:
        if self.__dict__.get(""_frozen"", False):
            raise TypeError(""Cannot modify attributes after call start"")
        super().__delitem__(key)
",weave/trace/weave_client.py,AttributesDict,1,5.3157849718487075e-08,"The method `__delitem__` is a special method in Python used to define behavior for the `del` statement on objects. In this code, it is overridden to add a check for a '_frozen' attribute, which prevents deletion if the object is in a 'frozen' state. This is a useful feature for ensuring object immutability after a certain point, which can be important in many applications to prevent unintended side effects. The method is likely to be retained because it provides a necessary and specific functionality that enhances the robustness of the object by preventing modifications when not allowed."
survived,"def _parse_file(path: Path) -> Iterable[ArchiveEntry]:
    """"""Yield archive entries from ``path``.""""""
    for line in path.read_text(encoding=""utf-8"").splitlines():
        if not line.strip():
            continue
        try:
            rec = json.loads(line)
        except Exception:  # noqa: BLE001 - skip invalid lines
            continue
        yield ArchiveEntry(
            hash=rec[""hash""],
            parent=rec.get(""parent""),
            score=float(rec.get(""score"", 0.0)),
            novelty=float(rec.get(""novelty"", 0.0)),
            is_live=bool(rec.get(""is_live"", True)),
            ts=float(rec.get(""ts"", 0.0)),
        )
",alpha_factory_v1/core/tools/dgm_import.py,,1,3.850741907939403e-09,"The method '_parse_file' is well-defined and serves a clear purpose of parsing a file to yield 'ArchiveEntry' objects. It handles exceptions gracefully by skipping invalid lines, which is a common requirement in file parsing to ensure robustness. The method uses standard libraries and practices, making it unlikely to be deprecated or removed unless there is a significant change in the requirements or the structure of the data being processed. Therefore, it is likely to survive."
survived,"def test_template_metadata_valid() -> None:
    meta = TemplateMetadata(
        slug=""basic-chat"",
        title=""Basic Chat Bot"",
        description=""Minimal conversational agent"",
        category=TemplateCategory.CONVERSATION,
        subcategory=""qa"",
        complexity=TemplateComplexity.BASIC,
        tags=[""chat""],
    )
    assert meta.slug == ""basic-chat""
    assert meta.category is TemplateCategory.CONVERSATION
    assert meta.complexity is TemplateComplexity.BASIC
    assert meta.tags == [""chat""]
",tests/test_template_schema.py,,1,1.2501528648238603e-09,"The method `test_template_metadata_valid` is a unit test that verifies the correct instantiation and properties of a `TemplateMetadata` object. It checks that the attributes of the object are set correctly, which is a fundamental part of testing in software development. Such tests are crucial for ensuring that the code behaves as expected and helps in catching regressions or errors in future changes. Therefore, this method is likely to be retained as part of the test suite."
survived,"def test_template_metadata_invalid_category() -> None:
    try:
        TemplateMetadata(
            slug=""bad"",
            title=""Bad"",
            description=""Bad"",
            category=""invalid"",  # type: ignore[arg-type]
            subcategory=""x"",
            complexity=TemplateComplexity.BASIC,
        )
    except ValidationError:
        pass
    else:  # pragma: no cover - should not succeed
        assert False, ""ValidationError not raised""",tests/test_template_schema.py,,1,9.237449576640118e-09,"The method `test_template_metadata_invalid_category` is a unit test designed to verify that a `ValidationError` is raised when an invalid category is provided to the `TemplateMetadata` class. This is a common practice in testing to ensure that the system behaves correctly when given invalid input. The method is useful for maintaining the integrity of the code by ensuring that invalid data is properly handled. Therefore, it is likely to be retained as part of the test suite to ensure ongoing validation of input data."
survived,"def load_vocab(file_name):
    with open(file_name, 'rb') as f:
        vocab = []
        reader = csv.reader(f)
        for row in reader:
            idx, word = row
            stripped = word.strip()
            vocab.append(stripped)
        return vocab
",src/hlda/sampler.py,,0,0.9999999530883621,"The method 'load_vocab' is likely to be deleted because it contains a critical error: it attempts to read a file in binary mode ('rb') but then uses 'csv.reader', which expects a text file. This will cause an error when trying to read the file. Additionally, the method does not handle exceptions or edge cases, such as empty files or incorrect file formats. These issues suggest that the method is not robust or reliable, making it a candidate for deletion or significant revision."
survived,"def _run_script(tmp_path: Path) -> dict:
    script = Path(""alpha_factory_v1/demos/cross_industry_alpha_factory/deploy_alpha_factory_cross_industry_demo.sh"")
    compose = tmp_path / ""docker-compose.yml""
    compose.write_text(""services: {}\n"")

    bin_dir = tmp_path / ""bin""
    bin_dir.mkdir()

    docker_stub = bin_dir / ""docker""
    docker_stub.write_text(
        """"""#!/usr/bin/env bash
if [ ""$1"" = ""info"" ] || [ ""$1"" = ""compose"" ]; then exit 0; fi
if [ ""$1"" = ""run"" ]; then
  while [ ""$1"" != ""ghcr.io/mikefarah/yq"" ] && [ $# -gt 0 ]; do shift; done
  shift
  yq ""$@""
  exit $?
fi
exit 0
""""""
    )
    docker_stub.chmod(0o755)

    for cmd in [""git"", ""curl"", ""openssl"", ""ssh-keygen"", ""cosign"", ""rekor"", ""k6"", ""locust""]:
        _write_executable(bin_dir / cmd, ""#!/usr/bin/env bash\nexit 0\n"")

    env = os.environ.copy()
    env.update(
        {
            ""PATH"": f""{bin_dir}:{env.get('PATH', '')}"",
            ""COMPOSE_FILE"": str(compose),
            ""PROJECT_DIR"": str(tmp_path),
            ""SKIP_BENCH"": ""1"",
        }
    )

    subprocess.run([""bash"", str(script)], check=True, env=env, timeout=10)
    first = yaml.safe_load(compose.read_text())
    subprocess.run([""bash"", str(script)], check=True, env=env, timeout=10)
    second = yaml.safe_load(compose.read_text())
    return {""first"": first, ""second"": second}
",tests/test_cross_industry_patch.py,,1,8.76424914819242e-08,"The method '_run_script' is a utility function that sets up a temporary environment to run a specific script and capture its output. It creates a temporary directory structure, writes necessary files, and sets environment variables to simulate a specific environment for the script execution. This kind of method is typically used in testing or deployment scripts to ensure that the script behaves as expected in a controlled environment. Given its utility in testing and deployment, it is likely to be retained in the codebase as it serves a specific purpose that is not easily replaced by other means."
survived,"def test_devicon_xdg_trailing_slash(monkeypatch):
    monkeypatch.setenv('XDG_PICTURES_DIR', '/tmp/Pictures/')
    devicons = reload_devicons('es')
    file = MockFile('Pictures', is_directory=True)
    assert devicons.devicon(file) == 'î‰„'",tests/test_devicons.py,,1,2.998960815863541e-09,"The method `test_devicon_xdg_trailing_slash` is a unit test function that uses the `monkeypatch` fixture to set an environment variable and then tests the behavior of the `devicons` module. Unit tests are generally not deleted unless they are redundant or testing deprecated functionality. Since this test seems to be testing a specific behavior related to the handling of trailing slashes in environment variables, it is likely to be useful for ensuring the correct functionality of the `devicons` module. Therefore, it is likely to survive."
survived,"def test_notebook_conversion(tmp_path):
    """"""With the notebook flag enabled code cells are converted.""""""
    nb = tmp_path / ""t.ipynb""
    _write_notebook(nb)
    result = _fstringify_file(str(nb), State(process_notebooks=True))
    assert result and result.n_changes == 1
    with open(nb) as fh:
        data = json.load(fh)
    assert ""f'{1}'"" in """".join(data[""cells""][0][""source""])",test/integration/test_api.py,,1,8.152020648014727e-09,"The method 'test_notebook_conversion' is a test function that verifies the functionality of converting code cells in a Jupyter notebook when a specific flag is enabled. Test functions are crucial for ensuring code reliability and correctness, especially in projects that involve file processing and data transformation. This function checks that the conversion process results in the expected changes, which is an important aspect of maintaining software quality. Therefore, it is likely to be retained as part of the test suite."
survived,"def set_language():
    lang = request.form.get(""language"")
    if lang in app.config[""BABEL_SUPPORTED_LOCALES""]:
        session[""lang""] = lang
    return redirect(request.referrer or url_for(""index""))
",app.py,,1,5.60279640614594e-09,"The method 'set_language' is a simple utility function that sets the user's language preference in a session variable if the language is supported. This is a common requirement in web applications to provide a localized experience for users. The method is straightforward, uses standard practices, and does not contain any deprecated or insecure code. Therefore, it is likely to be retained in the codebase."
survived,"    def padded(start, stop):
        pos = hax.arange(Pos, dtype=jnp.int32, start=start)
        return hax.where(pos >= stop, -1, pos)
",tests/test_attention.py,,0,0.9999999928058669,"The method 'padded' is likely to be deleted (0) because it contains a reference to 'hax.arange' and 'hax.where', which are not standard Python or well-known library functions. This suggests that 'hax' might be a custom or less common library, and if it is not widely used or maintained, the method might be removed. Additionally, the method's functionality is not clear without further context, which might lead to its removal if it is not essential or if there are better alternatives available."
survived,"    def test_qcli_and_qclic(self):
        klong = KlongInterpreter()
        klong('c::.qcli(1234)')
        proxy = klong('c')
        self.assertTrue(proxy.connection.is_open())
        r = klong('c(""1+1"")')
        self.assertEqual(r, 'EXEC: 1+1')
        self.assertEqual(proxy.connection.conn.queries[-1], ' 1+1')
        klong('.qclic(c)')
        self.assertFalse(proxy.connection.is_open())
",tests/test_sys_fn_kdb.py,TestKdbIPC,1,4.944450477491054e-09,"The method 'test_qcli_and_qclic' is a unit test that verifies the functionality of the 'qcli' and 'qclic' commands in the KlongInterpreter. It checks if a connection is opened and closed correctly, and if a query is executed as expected. This is a crucial part of testing the interpreter's functionality, ensuring that connections are managed properly and queries are executed correctly. Therefore, it is unlikely to be deleted as it serves an important role in maintaining the integrity of the codebase."
survived,"    def to_dict(self) -> Dict[str, Any]:
        """"""Return order as plain dictionary.""""""
        return asdict(self)
",alpha_factory_v1/backend/trade_broker.py,Order,1,2.4616969512093895e-10,"The method `to_dict` is a utility function that converts an object into a dictionary representation. This is a common and useful method in Python, especially when dealing with data serialization, logging, or preparing data for APIs. The use of `asdict` suggests that the class is a dataclass, which is a modern and efficient way to handle data structures in Python. Given its utility and the fact that it leverages Python's dataclass feature, it is unlikely to be deleted unless the entire class or its structure is being refactored. Therefore, the method will likely survive."
survived,"    def test_broadcast_error(self) -> None:
        led = self._ledger()
        env = messaging.Envelope(""a"", ""b"", {""v"": 1}, 0.0)
        led.log(env)
        captured, DummyClient, DummyTx, DummyInstr, DummyPk = self._dummy_classes(True)
        with (
            mock.patch.object(insight_logging, ""AsyncClient"", DummyClient, create=True),
            mock.patch.object(insight_logging, ""Transaction"", DummyTx, create=True),
            mock.patch.object(insight_logging, ""TransactionInstruction"", DummyInstr, create=True),
            mock.patch.object(insight_logging, ""PublicKey"", DummyPk, create=True),
            mock.patch.object(insight_logging, ""_log"") as log,
        ):
            asyncio.run(led.broadcast_merkle_root())
        log.warning.assert_called()  # ensure warning emitted",tests/test_merkle_broadcast.py,TestMerkleBroadcast,1,3.2241866333029355e-08,"The method 'test_broadcast_error' is a unit test designed to verify that a warning is logged when broadcasting a Merkle root fails. It uses mock objects to simulate the behavior of external dependencies and checks that a warning is emitted. This is a typical pattern in testing to ensure error handling works as expected. Since testing error handling is a crucial part of software development, this method is likely to be retained to ensure the robustness of the system."
survived,"    def geompath_route():
        args = request.args
        data = rs.geompath(
            lat1=float(args[""lat1""]),
            lon1=float(args[""lon1""]),
            lat2=float(args[""lat2""]),
            lon2=float(args[""lon2""]),
            currtime=int(args.get(""currtime"")) if args.get(""currtime"") else None,
            time_offset=int(args.get(""time_offset"")) if args.get(""time_offset"") else None,
            transfer_penalty=int(args.get(""transfer_penalty"", 0)),
            walking_speed=float(args.get(""walking_speed"", 1.0)),
            hill_reluctance=float(args.get(""hill_reluctance"", 1.5)),
            turn_penalty=float(args.get(""turn_penalty"")) if args.get(""turn_penalty"") else None,
            walking_reluctance=float(args.get(""walking_reluctance"")) if args.get(""walking_reluctance"") else None,
            max_walk=float(args.get(""max_walk"")) if args.get(""max_walk"") else None,
            jsoncallback=args.get(""callback""),
        )
        mimetype = ""application/javascript"" if args.get(""callback"") else ""application/json""
        return Response(data, mimetype=mimetype)
",pygs/graphserver/ext/routeserver/routeserver.py,,1,1.955568070542584e-08,"The method `geompath_route` is a well-defined function that processes HTTP request arguments to compute a geometric path using a service `rs.geompath`. It handles various parameters, including optional ones, and returns a response in either JSON or JSONP format based on the presence of a callback. This functionality is likely essential for applications involving geographic routing or mapping, making it a core part of the system's API. Therefore, it is unlikely to be deleted unless the entire routing functionality is deprecated or replaced."
survived,"    def __init__(self) -> None:
        self.dim = _DIM
        self.index = faiss.IndexFlatIP(self.dim) if faiss else None
        self.mean = np.zeros(self.dim, dtype=""float32"")
        self.count = 0
",src/evaluators/novelty.py,NoveltyIndex,1,3.466327708641819e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming in Python. Constructors are essential for initializing new objects and setting up initial state. The code initializes important attributes like 'dim', 'index', 'mean', and 'count', which are likely crucial for the functionality of the class. Therefore, it is unlikely that this method will be deleted."
survived,"def embed(text: str) -> np.ndarray:
    """"""Return the MiniLM embedding for ``text``.""""""
    model = _get_model()
    vec = model.encode([text], normalize_embeddings=True)
    return np.asarray(vec, dtype=""float32"")
",src/evaluators/novelty.py,,1,2.0611536181902033e-09,"The method 'embed' is likely to survive because it provides a clear and useful functionality: generating embeddings for text using a MiniLM model. This is a common requirement in natural language processing tasks, and the method is straightforward, leveraging a presumably existing function '_get_model()' to obtain the model and then encoding the text. The use of normalization and conversion to a numpy array are standard practices in embedding generation, making the method robust and efficient for its purpose."
survived,"def test_novelty_divergence_for_elites() -> None:
    def fn(genome: list[float]) -> tuple[float, float]:
        x, y = genome
        return x**2, y**2

    idx = NoveltyIndex()
    idx.add(""0.0,0.0"")

    pop = mats.run_evolution(
        fn,
        2,
        population_size=6,
        generations=1,
        seed=1,
        novelty_index=idx,
    )
    front = mats.pareto_front(pop)
    novelties = [ind.fitness[-1] for ind in front]
    assert sum(n > 0.3 for n in novelties) >= len(novelties) - 1",tests/test_mats.py,,1,8.152020648014727e-09,"The method `test_novelty_divergence_for_elites` is a test function that checks the novelty divergence in a population of genomes. It uses a novelty index and a Pareto front to evaluate the fitness of individuals. Test functions are generally important for ensuring the correctness of code, especially in evolutionary algorithms where behavior can be complex and unpredictable. Since this function is part of a testing suite, it is likely to be maintained to ensure the reliability of the evolutionary algorithm implementation. Therefore, it is likely to survive."
survived,"def _crowding(values: Sequence[Sequence[float]], fronts: Iterable[Iterable[int]]) -> list[float]:
    n = len(values)
    m = len(values[0]) if n else 0
    crowd = [0.0] * n
    for front in fronts:
        f = list(front)
        if not f:
            continue
        for idx in f:
            crowd[idx] = 0.0
        for i in range(m):
            f.sort(key=lambda idx: values[idx][i])
            crowd[f[0]] = float(""inf"")
            crowd[f[-1]] = float(""inf"")
            fmin = values[f[0]][i]
            fmax = values[f[-1]][i]
            span = fmax - fmin or 1.0
            for j in range(1, len(f) - 1):
                prev_v = values[f[j - 1]][i]
                next_v = values[f[j + 1]][i]
                crowd[f[j]] += (next_v - prev_v) / span
    return crowd
",src/simulation/surrogate_fitness.py,,1,2.646573631904765e-09,"The method '_crowding' is a utility function that calculates crowding distances for a set of solutions in a multi-objective optimization context. This is a common operation in algorithms like NSGA-II, which is widely used in evolutionary computation. The function is well-structured, performs a specific task, and is likely to be useful in its domain. There are no apparent issues with the logic or implementation that would necessitate its deletion. Therefore, it is likely to be retained."
survived,"def aggregate(
    values: Sequence[Sequence[float]],
    *,
    weights: dict[str, float | Sequence[float]] | None = None,
    weights_path: str | Path | None = None,
) -> list[float]:
    """"""Return scalar surrogate scores for ``values``.""""""
    cfg = weights if weights is not None else load_weights(weights_path)
    rank_w = float(cfg.get(""rank"", 1.0))
    crowd_w = float(cfg.get(""crowd"", 0.0))
    obj_w = cfg.get(""objectives"", [])
    if not isinstance(obj_w, Sequence):
        obj_w = []
    obj_w = list(obj_w) + [0.0] * (len(values[0]) - len(obj_w))
    ranks, fronts = _non_dominated_sort(values)
    crowds = _crowding(values, fronts)
    scores = []
    for idx, vec in enumerate(values):
        s = rank_w * ranks[idx] + crowd_w * crowds[idx]
        s += sum(w * v for w, v in zip(obj_w, vec))
        scores.append(float(s))
    return scores",src/simulation/surrogate_fitness.py,,1,1.2501528648238603e-09,"The method 'aggregate' is a utility function that calculates scores based on input values and weights. It is well-defined, with clear parameters and a return type. The function uses a combination of ranking, crowding, and objective weights to compute scores, which is a common requirement in multi-objective optimization problems. The presence of default values and the ability to load weights from a path make it flexible and reusable. There is no indication that this method is obsolete or redundant, and it appears to serve a specific purpose effectively. Therefore, it is likely to be retained in the codebase."
survived,"def test_invalid_token(monkeypatch: pytest.MonkeyPatch) -> None:
    client = _make_client(monkeypatch)
    resp = client.get(""/agents"", headers={""Authorization"": ""Bearer wrong""})
    assert resp.status_code == 403
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_backend_rest_auth.py,,1,8.152020648014727e-09,"The method `test_invalid_token` is a unit test designed to verify that the system correctly handles an invalid token by returning a 403 status code. This is a common and necessary test to ensure security measures are properly enforced. Such tests are crucial for maintaining the integrity of authentication systems, and there is no indication that this functionality is obsolete or unnecessary. Therefore, it is likely to be retained."
survived,"def check_node() -> bool:
    """"""Return True if Node.js is available and warn when outdated.""""""
    if not shutil.which(""node""):
        banner(""node missing"", ""RED"")
        return False
    try:
        out = subprocess.check_output([""node"", ""--version""], text=True).strip()
    except Exception:
        banner(""failed to run node --version"", ""RED"")
        return False
    banner(f""Node {out} detected"", ""GREEN"")
    try:
        major = int(out.lstrip(""v"").split(""."")[0])
        if major < 22:
            banner(""Node 22 or newer recommended"", ""YELLOW"")
    except ValueError:
        banner(""Unable to parse Node version"", ""YELLOW"")
    return True
",alpha_factory_v1/scripts/preflight.py,,1,9.736200303530205e-10,"The method 'check_node' is likely to survive because it performs a useful function by checking the availability and version of Node.js, which is a common requirement in many development environments. It provides feedback to the user about the status of Node.js, which is valuable for ensuring compatibility and performance. Additionally, the method is well-structured, handles exceptions, and provides informative messages, making it a robust utility function."
survived,"def test_empty_wheelhouse_fallback(tmp_path, monkeypatch, capsys):
    """"""Ensure empty wheelhouse is ignored and network install is used.""""""
    _no_missing(monkeypatch)
    empty = tmp_path / ""wheels""
    empty.mkdir()
    monkeypatch.setattr(check_env, ""has_network"", lambda: True)

    monkeypatch.setattr(subprocess, ""run"", lambda *a, **k: subprocess.CompletedProcess([], 0, """", """"))
    rc = check_env.main([""--auto-install"", ""--wheelhouse"", str(empty)])
    out = capsys.readouterr().out.lower()
    assert rc == 0
    assert ""falling back to network"" in out",tests/test_check_env_wheelhouse.py,,1,3.0590235908148916e-07,"The method is a test function that ensures a specific behavior of the system when the wheelhouse is empty. It is a part of a test suite, likely using pytest, to verify that the system falls back to network installation when no wheels are available locally. Test functions are generally not deleted unless they are testing obsolete or irrelevant functionality. Since this test checks a fallback mechanism, which is a common and important feature, it is likely to be retained to ensure the system's robustness."
survived,"def test_validate_template_success() -> None:
    ok, err = validate_template(""hello {{ name }}"")
    assert ok and err == """"
",tests/test_template_creator.py,,1,3.653482080241728e-08,"The method `test_validate_template_success` is a unit test function that checks the success case of the `validate_template` function. It asserts that when a valid template string is passed, the function returns a successful result (ok is True) and no error message (err is an empty string). This is a typical and necessary test to ensure that the `validate_template` function behaves correctly when given valid input. Therefore, it is unlikely to be deleted as it serves an important role in verifying the correctness of the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q9.py,Lineitem,0,0.9999417087232136,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This could lead to confusion and incorrect usage, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q12.py,Auto1,0,0.999998629043345,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys. However, this implementation uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which is usually used for membership testing in collections like lists, sets, or dictionaries. This misuse of `__contains__` could lead to confusion and bugs, as it does not align with the standard behavior expected from this method. Therefore, it is likely to be deleted or refactored to correctly implement membership testing."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q10.py,Lineitem,0,0.999983298584886,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q4.py,Order,0,0.9999785550602307,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical use case for `__contains__`, which is expected to check membership rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely to be deleted or refactored to better fit its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q14.py,Part,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which is usually used for membership testing in collections like lists, sets, or dictionaries. This misuse of `__contains__` could lead to confusion and unexpected behavior, as it does not align with the standard use case of checking membership in a collection. Therefore, it is likely that this method will be deleted or refactored to better fit its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q8.py,Lineitem,0,0.999988521231025,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys. However, this implementation uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which is usually used for membership testing in collections like lists, sets, or dictionaries. This misuse of `__contains__` could lead to confusion and bugs, as it does not align with the standard behavior expected from this method. Therefore, it is likely to be deleted or refactored to correctly implement membership testing."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q7.py,Nation,0,0.9999910602998366,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may lead to unexpected behavior, suggesting it should be deleted or revised."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q16.py,Partsupp,0,0.9999967112522585,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, this implementation uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of `__contains__` is likely to lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership testing. Therefore, it is likely to be deleted or refactored to align with the expected behavior of `__contains__`."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q18.py,Lineitem,0,0.9997388096733123,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose suggests that it might be deleted or refactored to align with conventional usage."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q9.py,Nation,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q3.py,Auto2,0,0.9999756997690634,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q8.py,Part,0,0.9999756997690634,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q6.py,Auto3,1,0.0002611903266877732,"The method `__contains__` is intended to check if a container contains a specific item, typically using the `in` keyword. In this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not a typical use of `__contains__`, as it should check for membership rather than attribute existence. However, if the class is designed to treat its attributes as the items it contains, this could be a valid implementation. Without more context, it's hard to say definitively, but the method could survive if the class's design justifies this behavior."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q28.py,Auto9,1,3.653482080241728e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. It is a simple and effective way to provide dynamic access to object attributes, which can be particularly useful in data handling or configuration classes. Therefore, this method is likely to be retained as it serves a clear purpose and is implemented correctly."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q14.py,Auto4,0,0.9999038976006968,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical or expected behavior for `__contains__`, which is usually used for membership testing in collections like lists, sets, or dictionaries. This misuse of `__contains__` could lead to confusion and unexpected behavior, as it does not align with the standard use case of checking for membership in a collection. Therefore, it is likely that this method will be deleted or refactored to better align with its intended purpose."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q32.py,Auto4,1,4.6911638017642294e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q14.py,Auto3,1,4.222835268240621e-06,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in collections like lists or dictionaries. In this code, it is implemented to return an attribute of the object using `getattr`. This is a non-standard use of `__getitem__`, as it is expected to work with indexable collections rather than object attributes. However, it can be useful in certain contexts where an object is designed to mimic dictionary-like behavior. Without additional context, it's hard to determine if this is the best approach, but it is a valid use case for certain designs. Therefore, the method is likely to survive unless there is a specific reason in the broader codebase to remove it."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q24.py,Auto1,1,3.850741907939403e-09,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q25.py,Auto5,1,1.1861120010657661e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q30.py,Auto10,0,0.999988521231025,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may lead to unexpected behavior, suggesting it should be deleted or significantly revised."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q30.py,Auto5,0,0.9999485577825553,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually implemented to check for membership in a collection, like a list or dictionary. This misuse of `__contains__` could lead to confusion and unexpected behavior, as it does not align with the standard behavior expected from this method. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q23.py,Auto9,1,1.8189616842444243e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. It is unlikely to be deleted unless the design of the class changes significantly, as it provides a flexible way to access object attributes. Therefore, the method will likely survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q31.py,Auto5,0,0.9999910602998366,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement key membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q29.py,Auto10,0,0.999964643742472,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate membership check."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q31.py,Auto9,1,1.9947301075518807e-06,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in collections like lists or dictionaries. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid use case if the object is designed to allow attribute access via indexing, which can be useful in certain dynamic or flexible data structures. However, it might not be the most common or recommended practice as it can lead to confusion or errors if not documented properly. Despite this, the method is functional and serves a purpose, so it is likely to survive unless there is a specific reason to remove it, such as a design change or refactoring."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q14.py,Auto7,1,3.653482080241728e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a simple and effective way to allow attribute access using keys, which can be particularly useful in certain design patterns or when interfacing with code that expects dictionary-like objects. Therefore, this method is likely to be retained as it serves a clear purpose and is implemented correctly."
survived,"def test_Q27_selects_minimal_company__link_and_title():
    assert result == Auto1(
        producing_company=""Best Film"",
        link_type=""follows"",
        complete_western_sequel=""Western Sequel"",
    )
",tests/dataset/job/compiler/py/q27.py,,1,1.275190675769241e-07,"The method `test_Q27_selects_minimal_company__link_and_title` is a test function, which is typically used to verify the correctness of a specific piece of code. Test functions are generally not deleted unless they are redundant, testing deprecated features, or replaced by more comprehensive tests. Since this function appears to be a straightforward test case, it is likely to be retained to ensure the functionality it tests remains correct."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q21.py,Auto9,0,0.9999756997690634,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list, set, or dictionary. Therefore, this implementation is likely incorrect for its intended purpose and may be deleted or replaced with a more appropriate implementation."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q20.py,Auto1,1,2.8453347280241004e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It allows for dynamic access to object attributes, which can be particularly useful in scenarios where the attributes are not known at compile time or are dynamically generated. Therefore, this method is likely to be retained as it provides a flexible and Pythonic way to access object attributes."
survived,"def _min(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""min() expects list or group"")
    vals = [it for it in v if it is not None]
    if not vals:
        return 0
    return min(vals)
",tests/dataset/job/compiler/py/q23.py,,1,7.73442280641062e-08,"The method '_min' is a utility function that provides a custom implementation of the 'min' function, with additional handling for objects with an 'Items' attribute and filtering out 'None' values. This function is useful in scenarios where the input might not be a straightforward list, and it ensures that 'None' values do not interfere with the minimum calculation. Such utility functions are often retained because they encapsulate specific logic that might be reused across different parts of a codebase. Unless there is a direct replacement or the function is no longer needed, it is likely to survive."
survived,"def _min(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""min() expects list or group"")
    vals = [it for it in v if it is not None]
    if not vals:
        return 0
    return min(vals)
",tests/dataset/job/compiler/py/q30.py,,1,1.444980317078884e-07,"The method '_min' is a utility function that calculates the minimum value from a list or a group with an 'Items' attribute. It includes error handling for non-list inputs and returns 0 for empty lists. Such utility functions are often useful in various contexts where data might be encapsulated in different structures. The method is simple, performs a common operation, and includes basic error handling, making it likely to be retained for its utility."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q24.py,Auto3,0,0.9999989322969233,"The method is incorrectly implemented. The `__contains__` method is supposed to check for membership, typically in a collection or container, and return a boolean indicating whether the specified key is present. However, using `hasattr(self, key)` checks if the object has an attribute with the name `key`, which is not the intended use of `__contains__`. This method should be checking if `key` is in a collection attribute of the class, not if it's an attribute of the class itself. Therefore, this method is likely to be deleted or rewritten to correctly implement membership testing."
survived,"def test_Q32_finds_movie_link_for_10_000_mile_club():
    assert result == Auto1(
        link_type=""sequel"", first_movie=""Movie A"", second_movie=""Movie C""
    )
",tests/dataset/job/compiler/py/q32.py,,1,1.725782769012759e-08,"The method `test_Q32_finds_movie_link_for_10_000_mile_club` is a unit test function, which is typically used to verify that a specific piece of code works as expected. Unit tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. The presence of this test suggests that it is part of a test suite that checks the functionality of a feature related to finding movie links. Since testing is a fundamental part of software development and maintenance, it is unlikely that this method will be deleted unless the feature it tests is removed or significantly altered. Therefore, the method is likely to survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q18.py,Auto4,1,6.348800075736417e-09,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be retained as it serves a clear purpose and is implemented correctly."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q33.py,Auto4,0,0.9999785550602307,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q15.py,Auto2,1,7.73442280641062e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be retained because it provides a flexible way to access object properties, which can be particularly useful in dynamic or reflective programming scenarios."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q18.py,Auto5,0,0.6224593241981982,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually implemented to check for membership in a collection like a list, set, or dictionary. However, if the class is designed to treat its attributes as a collection of keys, this implementation could be valid. Without additional context on how this method is used within the class, it's difficult to definitively say it should be deleted. However, it is unconventional and might be misleading to users of the class, suggesting a potential for deletion or reimplementation."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q25.py,Auto8,1,1.725782769012759e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is used as a dictionary-like structure, allowing for flexible and dynamic access to its attributes. Therefore, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q6.py,Auto1,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q33.py,Auto4,1,5.043472052266442e-07,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically for objects that are meant to behave like containers (e.g., lists, dictionaries). In this code, `__getitem__` is implemented to use `getattr`, which allows accessing attributes of an object using a key. This implementation is useful if the object is designed to allow attribute access via indexing, which can be a valid design choice for certain classes. Without additional context, such as the class this method belongs to or its intended use, it's difficult to definitively say whether it should be deleted. However, the method itself is syntactically correct and serves a purpose, so it is likely to be Survived unless there are specific design reasons to remove it."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q15.py,Auto4,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is used like a dictionary or when dynamic attribute access is needed. Therefore, it is likely to be retained."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/job/compiler/py/q23.py,,1,6.023574641292144e-08,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The function is well-structured and provides flexibility through the use of options like 'where', 'sortKey', 'skip', and 'take'. Such utility functions are often retained in codebases because they encapsulate common patterns of data manipulation, making them reusable and reducing code duplication. Therefore, it is likely to be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q14.py,Auto6,0,0.999964643742472,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to better fit its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q24.py,Auto5,0,0.9999952149051502,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the implementation here uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q27.py,Auto12,1,5.3157849718487075e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q27.py,Auto4,1,2.5109990926928157e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. It is a common pattern in dynamic or flexible data structures. Therefore, the method is likely to be retained as it provides a functional and potentially necessary feature for the class."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q25.py,Auto8,0,0.9999785550602307,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q29.py,Auto6,0,0.999985261023967,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the standard or expected behavior for `__contains__`, which is supposed to check membership in a collection, not attribute existence. This misuse of the method is likely to lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership testing. Therefore, it is likely to be deleted or refactored to align with its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q11.py,Auto4,0,0.999891103056471,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually meant for checking membership in a collection like a list, set, or dictionary. This misuse of `__contains__` could lead to confusion and unexpected behavior, as it does not align with the standard behavior expected from this method. Therefore, it is likely that this method will be deleted or refactored to better fit its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q26.py,Auto5,0,0.9999930377415741,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q33.py,Auto5,1,1.2098660619383578e-06,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in collections like lists or dictionaries. In this code, `__getitem__` is implemented to use `getattr` to access an attribute of the object by name. This is a non-standard use of `__getitem__`, as it is expected to work with indices or keys rather than attribute names. However, it can be useful in certain contexts where objects are treated like dictionaries for attribute access. Without additional context, it's hard to determine if this is the best approach, but it is a valid use case for dynamic attribute access. Therefore, the method is likely to survive unless there are specific design reasons to remove it."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q3.py,Auto2,0,0.9999967112522585,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys. However, this implementation uses `hasattr`, which checks if an object has an attribute with the given name. This is not the intended use of `__contains__`, as it should be used for membership testing in collections, not for checking attributes. This misuse of the method is likely to lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership testing. Therefore, it is likely to be deleted or refactored to correctly implement membership testing."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q21.py,Auto1,0,0.999983298584886,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"def test_Q24_finds_voiced_action_movie_with_actress_named_An():
    assert result == [
        Auto1(
            voiced_char_name=""Hero Character"",
            voicing_actress_name=""Ann Actress"",
            voiced_action_movie_jap_eng=""Heroic Adventure"",
        )
    ]
",tests/dataset/job/compiler/py/q24.py,,1,8.152020648014727e-09,"The method `test_Q24_finds_voiced_action_movie_with_actress_named_An` is a test function, likely part of a test suite for a larger application. Test functions are generally not deleted unless they are redundant, incorrect, or the functionality they test is no longer relevant. Since this function seems to be testing a specific case (finding a voiced action movie with an actress named 'An'), it is likely still relevant to the application's testing needs. Therefore, it is more likely to survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q32.py,Auto1,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use of `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, especially for users familiar with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q14.py,Auto4,1,8.152020648014727e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern and does not have any apparent issues or redundancies that would necessitate its deletion. Therefore, it is likely to be retained."
survived,"def test_Q16_finds_series_named_after_a_character_between_episodes_50_and_99():
    assert result == [
        Auto1(cool_actor_pseudonym=""Alpha"", series_named_after_char=""Hero Bob"")
    ]
",tests/dataset/job/compiler/py/q16.py,,1,4.944450477491054e-09,"The method is a test function, which is typically used in software development to ensure that a specific piece of code behaves as expected. Test functions are crucial for maintaining code quality and reliability, especially in larger projects. They help catch bugs early and ensure that changes to the codebase do not break existing functionality. Given the importance of testing in software development, it is unlikely that this method will be deleted unless it is replaced by a more comprehensive or updated test. Therefore, the method will likely survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q19.py,Auto2,1,2.646573631904765e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name, which can be useful for objects that need to provide dictionary-like access to their attributes. This method is simple, clear, and serves a specific purpose, making it likely to be retained in the codebase unless the design requirements change significantly. Therefore, it is predicted to survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q21.py,Auto1,1,1.0467401685178159e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be retained as it serves a clear purpose and is implemented correctly."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/job/compiler/py/q19.py,,1,8.592166611791576e-10,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The function is well-structured and provides flexibility through options like 'where', 'sortKey', 'skip', and 'take'. Such utility functions are often retained in codebases because they encapsulate common patterns of data manipulation, making them reusable and reducing code duplication. Therefore, it is likely to survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q22.py,Auto6,1,8.152020648014727e-09,"The method is a simple implementation of the __getitem__ special method, which allows an object to use the bracket notation (obj[key]) to access its attributes. This is a common and useful pattern in Python, especially for classes that need to provide dictionary-like access to their attributes. It is likely to be retained as it provides a clear and concise way to access object attributes using keys, enhancing the flexibility and usability of the class."
survived,"def _min(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""min() expects list or group"")
    vals = [it for it in v if it is not None]
    if not vals:
        return 0
    return min(vals)
",tests/dataset/job/compiler/py/q16.py,,0,0.999891103056471,"The method _min is a utility function that attempts to find the minimum value in a list or a similar iterable structure. However, it has several issues that make it less robust and potentially problematic in a production environment. 

1. **Naming Convention**: The method name _min is not descriptive and could be confused with Python's built-in min function. This could lead to confusion and errors in larger codebases.

2. **Error Handling**: The method raises a generic Exception with a vague message. It would be better to raise a more specific exception type with a clearer message.

3. **Type Checking**: The method checks if the input has an 'Items' attribute and uses it if present, but this is not a common pattern and could lead to unexpected behavior if the input is not as expected.

4. **Return Value for Empty List**: The method returns 0 for an empty list, which might not be the desired behavior in all contexts. Typically, a ValueError is raised when attempting to find the minimum of an empty sequence.

5. **Handling of None Values**: The method filters out None values, which might be acceptable in some cases, but this behavior should be clearly documented or configurable.

Due to these issues, the method is likely to be refactored or replaced with a more robust solution, possibly using Python's built-in min function with additional handling for None values and empty lists. Therefore, it is likely to be deleted or significantly modified."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q11.py,Auto9,1,9.931195248674785e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. It is a simple and effective way to provide dictionary-like access to object attributes, which can be particularly useful in dynamic or flexible data structures. Therefore, this method is likely to be retained as it serves a clear purpose and is correctly implemented."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q20.py,Auto7,1,4.6911638017642294e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to behave like a dictionary or similar container, allowing attribute access via keys. Since this method provides a clear and functional purpose, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q67.py,Reason,0,0.999985261023967,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q3.py,Auto1,0,0.9859363710972001,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually implemented to check for membership in a collection like a list, set, or dictionary. However, if the class is designed to treat its attributes as keys in a collection, this implementation could be valid. Without additional context on how this method is used within the class, it's difficult to definitively say it should be deleted. However, it is unconventional and might lead to confusion or misuse, suggesting a higher likelihood of being deleted or refactored."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q75.py,Auto4,1,1.522997951276035e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in collections like lists or dictionaries. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid use case if the object is designed to allow attribute access via indexing, which can be useful in certain dynamic or flexible data structures. Since this method provides a clear and potentially useful functionality, it is likely to be retained in the codebase."
survived,"def _q0():
    _groups = {}
    _order = []
    for ss in store_sales:
        _k = Auto2(item=ss.item)
        _ks = str(_k)
        g = _groups.get(_ks)
        if not g:
            g = _Group(_k)
            _groups[_ks] = g
            _order.append(_ks)
        g.Items.append(ss)
    _items1 = [_groups[k] for k in _order]
    return [
        Auto1(item=g.key[""item""], revenue=sum([x.price for x in g])) for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q65.py,,1,6.825604231969389e-08,"The method _q0() is a utility function that processes a list of store sales, grouping them by item and calculating the total revenue for each item. It uses helper classes Auto2 and _Group, and returns a list of Auto1 objects with item and revenue information. The method is likely to be retained because it encapsulates a specific functionality that is useful for summarizing sales data, and there is no indication of redundancy or inefficiency that would warrant its deletion."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q14.py,Auto3,1,9.237449576640118e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in container-like objects such as lists, dictionaries, or custom objects that mimic these behaviors. In this code, `__getitem__` is implemented to return an attribute of the object using `getattr`. This is a valid and potentially useful implementation if the object is designed to allow attribute access via indexing. It can be particularly useful in dynamic or flexible data structures where attributes are accessed by name. Therefore, the method is likely to be Survived (1) as it provides a functional and potentially useful feature for the class."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q17.py,DateDim,1,1.275190675769241e-07,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. It is a simple and effective way to provide dynamic access to object attributes, which can be particularly useful in certain design patterns or frameworks. Therefore, the method is likely to be retained as it serves a clear purpose and is correctly implemented."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q29.py,Item,1,6.825604231969389e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. It provides a flexible way to access object attributes dynamically, which can be particularly useful in certain dynamic or reflective programming scenarios. Therefore, this method is likely to be retained as it serves a specific purpose and is correctly implemented."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q21.py,Auto2,1,1.4166087846364157e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python to allow objects to be accessed in a more flexible way. Therefore, this method is likely to be Survived."
survived,"def _sum(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""sum() expects list or group"")
    s = 0.0
    for it in v:
        if it is None:
            continue
        if isinstance(it, (int, float)):
            s += float(it)
        else:
            raise Exception(""sum() expects numbers"")
    return s
",tests/dataset/tpc-ds/compiler/py/q19.py,,1,2.5109990926928157e-08,"The method '_sum' is a utility function that calculates the sum of a list of numbers, with additional handling for objects that have an 'Items' attribute. It includes error handling for non-list inputs and non-numeric elements within the list. This function is useful for summing elements in a list while ensuring type safety and handling potential None values. Such utility functions are common in codebases for data processing tasks. Unless there is a specific reason to remove it, such as redundancy or a shift to using built-in functions, it is likely to be retained."
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q45.py,,1,6.348800075736417e-09,"The method '_group_by' is likely to survive because it provides a useful utility function for grouping elements of a list based on a key function. This is a common requirement in data processing and manipulation tasks. The method is flexible, allowing for different types of input (list, tuple, or single element) and handles complex keys by converting them to a string representation. Additionally, it maintains the order of first occurrence of each group, which can be important for certain applications. These features make it a valuable tool in a programmer's toolkit."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q73.py,,1,5.60279640614594e-09,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be used in various data processing scenarios, making it versatile and potentially useful in many applications. The function is not overly specific to a single use case, which increases its chances of being retained in the codebase. Additionally, the function is well-structured and handles various options, indicating that it has been designed with flexibility in mind. These factors suggest that the method is likely to survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q75.py,Item,1,8.152020648014727e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to support dynamic attribute access or mimic dictionary-like behavior. Therefore, the method is likely to be retained as it serves a clear purpose and is implemented correctly."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q10.py,_Group,1,6.348800075736417e-09,"The method `__len__` is a special method in Python that is used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q77.py,StoreReturn,1,2.5109990926928157e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the codebase."
survived,"def _q0():
    _groups = {}
    _order = []
    for b in base:
        _k = Auto3(
            item_id=b.i_item_id,
            item_desc=b.i_item_desc,
            s_store_id=b.s_store_id,
            s_store_name=b.s_store_name,
        )
        _ks = str(_k)
        g = _groups.get(_ks)
        if not g:
            g = _Group(_k)
            _groups[_ks] = g
            _order.append(_ks)
        g.Items.append(b)
    _items1 = [_groups[k] for k in _order]
    return [
        Auto1(
            i_item_id=g.key[""item_id""],
            i_item_desc=g.key[""item_desc""],
            s_store_id=g.key[""s_store_id""],
            s_store_name=g.key[""s_store_name""],
            store_sales_quantity=sum([x.ss_quantity for x in g]),
            store_returns_quantity=sum([x.sr_return_quantity for x in g]),
            catalog_sales_quantity=sum([x.cs_quantity for x in g]),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q29.py,,1,2.646573631904765e-09,"The method _q0() is a utility function that processes a collection of 'base' objects, groups them by certain attributes, and then aggregates some quantities for each group. This type of method is often used in data processing tasks, such as preparing data for reports or analytics. The method is well-structured, performs a clear and useful task, and does not have any obvious issues or redundancies that would warrant its removal. Therefore, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q53.py,StoreSale,0,0.9999339478346898,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose is likely to lead to confusion and incorrect behavior when the method is used. Therefore, it is likely that this method will be deleted or refactored to align with its intended use."
survived,"def _q2():
    _groups = {}
    _order = []
    for ctr in customer_total_return:
        _k = ctr.ctr_state
        _ks = str(_k)
        g = _groups.get(_ks)
        if not g:
            g = _Group(_k)
            _groups[_ks] = g
            _order.append(_ks)
        g.Items.append(ctr)
    _items1 = [_groups[k] for k in _order]
    return [
        Auto4(
            state=g.key,
            avg_return=(
                sum([x.ctr_total_return for x in g])
                / len([x.ctr_total_return for x in g])
                if [x.ctr_total_return for x in g]
                else 0
            ),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q30.py,,0,0.9999952149051502,"The method is likely to be deleted because it uses a non-descriptive name (_q2), which suggests it might be a private or temporary function. Additionally, the method relies on external variables and classes (like customer_total_return, _Group, and Auto4) that are not defined within the code snippet, indicating it might be part of a larger refactoring or cleanup process. The logic within the method is also quite specific, which might not be reusable or necessary in the long term."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q17.py,Auto3,0,0.999964643742472,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the typical or expected behavior for `__contains__`, which should check for membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect for its intended purpose and may be deleted or replaced with a more appropriate implementation."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q35.py,Auto2,1,1.8553915987649156e-07,"The method is a simple implementation of the __getitem__ special method, which allows instances of the class to use the bracket notation (e.g., obj[key]) to access attributes. This is a common and useful pattern in Python, especially for classes that need to provide dictionary-like access to their attributes. It is likely to be retained as it provides a clear and concise way to access object attributes using keys."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q29.py,Auto1,0,0.9999910602998366,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q29.py,DateDim,0,0.999983298584886,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement the intended functionality."
survived,"def _q1():
    _groups = {}
    _order = []
    for r in by_customer:
        _k = Auto4(seg=int(r.revenue / 50))
        _ks = str(_k)
        g = _groups.get(_ks)
        if not g:
            g = _Group(_k)
            _groups[_ks] = g
            _order.append(_ks)
        g.Items.append(r)
    _items1 = [_groups[k] for k in _order]
    return [
        Auto1(
            segment=g.key[""seg""], num_customers=len(g), segment_base=g.key[""seg""] * 50
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q54.py,,1,2.2159489282323004e-08,"The method '_q1' is a private method (indicated by the underscore prefix) that processes customer data by grouping them into segments based on their revenue. It uses a custom class 'Auto4' to determine the segment and another class '_Group' to manage the groups. The method returns a list of 'Auto1' objects, which likely represent some form of summary or report of the grouped data. This method seems to be a utility function that is part of a larger system for processing customer data. Given its specific functionality and the fact that it is a private method, it is likely to be retained as part of the system's internal operations. Therefore, it is predicted to survive."
survived,"def _sum(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""sum() expects list or group"")
    s = 0.0
    for it in v:
        if it is None:
            continue
        if isinstance(it, (int, float)):
            s += float(it)
        else:
            raise Exception(""sum() expects numbers"")
    return s
",tests/dataset/tpc-ds/compiler/py/q94.py,,1,1.955568070542584e-08,"The method '_sum' is a utility function that calculates the sum of a list of numbers. It includes error handling for non-list inputs and non-numeric elements within the list. This functionality is fundamental and commonly needed in various applications. The method is well-defined, with clear error messages, making it robust for use in different contexts. Therefore, it is likely to be retained as it provides essential functionality with proper error handling."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q33.py,WebSale,1,7.194132978569833e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be retained as it serves a clear purpose and is implemented correctly."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q72.py,CustomerDemographic,0,0.9996646499458114,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually meant for checking membership in a collection like a list, set, or dictionary. This misuse of `__contains__` could lead to confusion and unexpected behavior, as it does not align with the standard behavior expected from this method. Therefore, it is likely that this method will be deleted or refactored to better fit its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q24.py,CustomerAddres,0,0.9999756997690634,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"def test_TPCDS_Q62_simplified():
    assert result == 62
",tests/dataset/tpc-ds/compiler/py/q62.py,,1,1.3440409770490404e-08,"The method `test_TPCDS_Q62_simplified` is a test function, likely part of a test suite for a larger codebase. It contains a single assertion checking if `result` equals 62. Without additional context, such as the purpose of the test or the surrounding code, it's difficult to determine its utility. However, test functions are generally crucial for ensuring code correctness and stability. Unless the test is redundant, incorrect, or replaced by a more comprehensive test, it is likely to be retained. Therefore, the method will likely survive."
survived,"def _q0():
    _src = t
    _rows = _query(_src, [], {""select"": lambda x: x})
    _groups = _group_by(_rows, lambda x: x.ss_customer_sk)
    _items1 = _groups
    _items1 = sorted(
        _items1, key=lambda g: _sort_key([sum([y.act_sales for y in g]), g.key])
    )
    return [
        Auto1(ss_customer_sk=g.key, sumsales=sum([y.act_sales for y in g]))
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q93.py,,1,4.944450477491054e-09,"The method _q0() appears to be a utility function that processes data by querying, grouping, and sorting it based on certain criteria. It is likely part of a larger codebase that deals with data manipulation or analysis. The function is specific in its operation, suggesting it serves a particular purpose within the application. Unless the entire functionality it supports is deprecated or replaced, such utility functions are generally retained. Therefore, it is more likely to survive."
survived,"def test_TPCDS_Q1_result():
    assert result == [Auto1(c_customer_id=""C2"")]
",tests/dataset/tpc-ds/compiler/py/q1.py,,1,3.2241866333029355e-08,"The method `test_TPCDS_Q1_result` is a test function that asserts a specific condition. Test functions are generally important for ensuring code correctness and are typically not deleted unless they are redundant or replaced by more comprehensive tests. Since this function is asserting a specific expected result, it is likely part of a test suite that verifies the functionality of a particular feature or query result. Therefore, it is more likely to be maintained or updated rather than deleted."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q35.py,StoreSale,0,0.9999980052698925,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not fulfill its intended purpose of checking membership in a collection. Therefore, it is likely to be deleted or replaced with a more appropriate implementation."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q98.py,Auto4,1,4.363462233903899e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation, especially in cases where the object is designed to behave like a dictionary or to provide dynamic attribute access. There is no indication that this method is redundant or incorrect, so it is likely to be retained."
survived,"def _sort_key(k):
    if hasattr(k, ""__dataclass_fields__""):
        return str(k)
    if isinstance(k, list):
        return tuple((_sort_key(x) for x in k))
    if isinstance(k, tuple):
        return tuple((_sort_key(x) for x in k))
    if isinstance(k, dict):
        return str(k)
    return k
",tests/dataset/tpc-ds/compiler/py/q76.py,,1,3.850741907939403e-09,"The method '_sort_key' is a utility function designed to generate a sorting key for various data types, including dataclasses, lists, tuples, and dictionaries. It is a versatile function that can be useful in many scenarios where complex data structures need to be sorted. The function handles different data types gracefully and provides a consistent way to convert them into a sortable format. Given its utility and the fact that it doesn't have any apparent issues or redundancies, it is likely to be retained in the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q24.py,Auto3,1,6.825604231969389e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a flexible and Pythonic way to access object attributes, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q94.py,WebReturn,0,0.999964643742472,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the typical or expected behavior for `__contains__`, which should check for membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect for its intended purpose and may be deleted or replaced with a more appropriate implementation."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q33.py,Auto1,0,0.9999724643101549,"The method is likely to be deleted because it does not correctly implement the expected behavior of the `__contains__` method. In Python, `__contains__` is used to check if a container contains a certain item, typically using the `in` keyword. The current implementation uses `hasattr`, which checks for the presence of an attribute, not an item in a collection. This could lead to incorrect behavior and confusion, especially if the class is intended to behave like a collection. Therefore, it is likely to be revised or removed to ensure correct functionality."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q39.py,_Group,1,1.725782769012759e-08,"The method `__len__` is a special method in Python that is used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q22.py,Item,0,0.9999756997690634,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q39.py,Warehouse,1,5.3157849718487075e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a flexible and Pythonic way to access object attributes, it is likely to be retained in the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q81.py,CatalogReturn,1,2.5109990926928157e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is likely to survive because it provides a flexible way to access object attributes, which can be particularly useful in dynamic or reflective programming scenarios."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q89.py,StoreSale,1,3.653482080241728e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q77.py,Auto6,0,0.9999251538028718,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking membership in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to better fit its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q74.py,Auto2,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical or expected behavior for `__contains__`, which is usually used for membership testing in collections like lists, sets, or dictionaries. This misuse of the method could lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership testing. Therefore, it is likely to be deleted or refactored to align with its intended purpose."
survived,"def test_TPCDS_Q98_revenue():
    assert result == [
        Auto1(
            i_item_id=""I1"",
            i_item_desc=""desc1"",
            i_category=""CatA"",
            i_class=""Class1"",
            i_current_price=100.0,
            itemrevenue=50.0,
            revenueratio=33.333333333333336,
        ),
        Auto1(
            i_item_id=""I2"",
            i_item_desc=""desc2"",
            i_category=""CatB"",
            i_class=""Class1"",
            i_current_price=200.0,
            itemrevenue=100.0,
            revenueratio=66.66666666666667,
        ),
    ]
",tests/dataset/tpc-ds/compiler/py/q98.py,,1,2.7894680920908113e-10,"The method `test_TPCDS_Q98_revenue` is a unit test function that checks if the `result` matches a predefined list of `Auto1` objects. This is a typical pattern in test-driven development to ensure that a function or process produces the expected output. Since testing is a crucial part of software development for maintaining code quality and reliability, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered. Therefore, the method is likely to survive."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q35.py,,1,8.76424914819242e-08,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The function is well-structured and provides flexibility through the use of options (opts) for various operations. Such utility functions are often retained in codebases because they encapsulate complex logic that would otherwise need to be repeated or rewritten in multiple places. Therefore, it is likely to be retained for its utility and flexibility."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q77.py,CatalogSale,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q78.py,S,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or replaced with a more appropriate implementation that correctly checks for key membership."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q58.py,Result,0,0.9999756997690634,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the standard or expected behavior for `__contains__`, which should typically check for membership in a collection like a list, set, or dictionary. Therefore, this implementation is likely to be confusing and not useful in its current form, leading to its deletion or replacement with a more appropriate implementation."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q97.py,_Group,1,7.73442280641062e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes. The code snippet shows a typical pattern of initializing instance variables, which is a common and necessary practice in class definitions. Therefore, it is unlikely that this method will be deleted."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q71.py,WebSale,0,0.9998415637531546,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. In this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not a typical use of `__contains__`, as it should check for membership in a collection rather than the presence of an attribute. However, if the class is designed to treat its attributes as keys in a collection, this could be a valid implementation. Without more context, it's hard to definitively say if this is incorrect, but it is unconventional. Therefore, it might survive if the class is specifically designed this way, but it could also be deleted if it doesn't align with the intended use of `__contains__`. Given the unconventional use, it leans towards deletion."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q18.py,CustomerDemographic,0,0.9999921107349486,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or replaced with a more appropriate implementation."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q78.py,W,1,1.725782769012759e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a simple and effective way to allow attribute access using keys, which can be particularly useful in classes that need to interface with code expecting dictionary-like objects. Therefore, this method is likely to be retained as it serves a clear purpose and is implemented correctly."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q40.py,Auto1,1,2.8453347280241004e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q45.py,,1,2.0611536181902033e-09,"The method '_key' is a utility function that is likely used internally within a module or class to generate a key for sorting purposes. It takes an iterable 'it', applies a sorting key function from 'opts', and ensures the key is a string if it's a complex data type. This kind of function is common in data processing or sorting operations, and unless the entire module or class is being refactored or removed, such utility functions are typically retained. Therefore, it is likely to survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q14.py,DateDim,0,0.9999994956527948,"The method is incorrectly implemented. The `__contains__` method is supposed to check if a key is present in a collection, typically using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, which is likely to lead to incorrect behavior when the method is used. Therefore, it is likely to be deleted or significantly modified to correctly implement the intended functionality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q50.py,StoreSale,0,0.9999869928752253,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not attribute existence. This misuse of the method's intended purpose is likely to lead to confusion and incorrect behavior when the method is used. Therefore, it is likely that this method will be deleted or refactored to align with its intended use."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q77.py,StoreSale,1,2.5109990926928157e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be retained as it serves a clear purpose and follows Python's design principles."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q19.py,_Group,1,7.194132978569833e-09,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is correctly implemented to return the length of `self.Items`, which suggests that `self.Items` is likely a list or a similar collection. This is a common and useful implementation pattern for custom container classes, allowing them to integrate seamlessly with Python's built-in functions. Therefore, this method is likely to be retained as it provides essential functionality for the class."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q19.py,CustomerAddres,1,1.275190675769241e-07,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be retained because it provides a flexible way to access object properties, which can be particularly useful in dynamic or reflective programming scenarios."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q73.py,Auto1,0,0.9999994284997149,"The method is incorrectly implemented. The `__contains__` method is supposed to check for membership, typically in a collection or container, and return a boolean indicating whether the specified key or item is present. However, this implementation uses `hasattr`, which checks if an object has an attribute with the given name, not if a key is present in a collection. This is a misuse of the `__contains__` method, which is expected to work with collections like lists, sets, or dictionaries, not object attributes. Therefore, it is likely to be deleted or rewritten to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q50.py,Store,0,0.999988521231025,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"def _avg(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""avg() expects list or group"")
    if not v:
        return 0
    s = 0.0
    for it in v:
        if isinstance(it, (int, float)):
            s += float(it)
        else:
            raise Exception(""avg() expects numbers"")
    return s / len(v)
",tests/dataset/tpc-ds/compiler/py/q7.py,,1,8.31527990378713e-07,"The method '_avg' is a utility function that calculates the average of a list of numbers. It includes error handling for cases where the input is not a list or contains non-numeric values. This kind of utility function is generally useful in many contexts where data processing is required, especially in data analysis or scientific computing. The method is straightforward, performs a common operation, and includes basic error handling, making it a candidate for survival unless there is a more efficient or comprehensive library function available that supersedes its functionality."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q42.py,_Group,1,6.348800075736417e-09,"The method `__len__` is a special method in Python that is used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"def test_TPCDS_Q69_simplified():
    assert result == 69
",tests/dataset/tpc-ds/compiler/py/q69.py,,0,0.9999339478346898,"The method `test_TPCDS_Q69_simplified` is a test function that asserts if the variable `result` is equal to 69. However, the function lacks context, such as the definition or initialization of `result`, making it unclear if this test is meaningful or functional. Without additional context or setup, this test is not useful and is likely to be deleted unless it is part of a larger test suite where `result` is properly defined and manipulated."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q25.py,_Group,1,1.0467401685178159e-08,"The method is a constructor for a class, initializing instance variables. It sets up a key and two lists, 'Items' and 'items', which are references to the same list. This is a common pattern in Python to initialize object state, and there is no indication of redundancy or error. Therefore, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q45.py,DateDim,1,6.023574641292144e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be retained because it provides a flexible way to access object properties, which can be particularly useful in dynamic or reflective programming scenarios."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q30.py,Auto2,0,0.9999898700118929,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or replaced with a more appropriate implementation that correctly checks for key membership."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q29.py,,1,1.4166087846364157e-09,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The function is well-structured and provides flexibility through options like 'where', 'sortKey', 'skip', and 'take'. Such utility functions are often retained in codebases because they encapsulate common patterns of data manipulation, making them reusable and reducing code duplication. Therefore, it is likely to survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q17.py,StoreSale,0,0.9999869928752253,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys. However, this implementation uses `hasattr`, which checks if an object has an attribute with the given name. This is not the intended use of `__contains__`, as it should be used for membership testing in collections, not for checking attributes. This misuse of the method is likely to lead to confusion and incorrect behavior when the object is used in contexts expecting standard membership testing. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership testing."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q93.py,Auto2,1,6.348800075736417e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. Since it provides a clear and functional purpose, it is likely to be retained in the code."
survived,"def _sum(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""sum() expects list or group"")
    s = 0.0
    for it in v:
        if it is None:
            continue
        if isinstance(it, (int, float)):
            s += float(it)
        else:
            raise Exception(""sum() expects numbers"")
    return s
",tests/dataset/tpc-ds/compiler/py/q65.py,,1,6.348800075736417e-09,"The method '_sum' is a utility function that calculates the sum of a list of numbers. It includes error handling for non-list inputs and non-numeric elements within the list. This kind of utility function is often useful in various applications where data might not always be in the expected format, and thus, it is likely to be retained for its robustness and utility. Additionally, the method handles cases where the input might be an object with an 'Items' attribute, which adds to its flexibility. These factors suggest that the method will survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q90.py,HouseholdDemographic,0,0.9999945777819207,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical use case for `__contains__`, which is expected to check membership rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"def test_TPCDS_Q92_threshold():
    assert result == 4.0
",tests/dataset/tpc-ds/compiler/py/q92.py,,0,0.9998415637531546,"The method `test_TPCDS_Q92_threshold` is a test function that contains a single assertion statement. It checks if the variable `result` is equal to 4.0. However, the function lacks context, such as the definition or initialization of `result`, and does not include any setup or teardown code that is typically found in a comprehensive test. Without additional context or functionality, this test is not very useful or informative. It is likely to be deleted unless it is part of a larger test suite where `result` is defined elsewhere."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q13.py,DateDim,1,1.0467401685178159e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern and does not have any apparent issues or redundancies that would necessitate its removal. Therefore, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q15.py,CatalogSale,1,4.944450477491054e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python to allow more flexible and dynamic access to object properties. Therefore, this method is likely to be retained as it serves a clear purpose and follows Python's conventions for special methods."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q91.py,_Group,1,4.944450477491054e-09,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is correctly implemented to return the length of `self.Items`, which suggests that `self.Items` is likely a list or a similar collection. This is a common and useful implementation for custom classes that manage collections of items, allowing them to integrate seamlessly with Python's built-in functions. Therefore, this method is likely to be retained as it provides essential functionality for the class."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q40.py,Auto3,0,0.999999057755336,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not fulfill its intended purpose of checking membership in a collection. Therefore, it is likely to be deleted or replaced with a more appropriate implementation."
survived,"def test_TPCDS_Q73_simplified():
    assert result == [
        Auto1(
            c_last_name=""Smith"",
            c_first_name=""Alice"",
            c_salutation=""Ms."",
            c_preferred_cust_flag=""Y"",
            ss_ticket_number=1,
            cnt=1,
        )
    ]
",tests/dataset/tpc-ds/compiler/py/q73.py,,1,1.0467401685178159e-08,"The method 'test_TPCDS_Q73_simplified' is a test function, likely part of a test suite for a larger application. Test functions are generally not deleted unless they are redundant, incorrect, or replaced by more comprehensive tests. This function appears to be testing a specific query result, which is a common practice in ensuring code correctness. Therefore, it is likely to be retained as part of the testing process."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q44.py,StoreSale,1,0.00013982203410499962,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually implemented to check for membership in a collection like a list, set, or dictionary. However, if the class is designed to treat its attributes as a collection of keys, this implementation could be valid. Without additional context, it's difficult to determine if this is the intended use. If the class is indeed using its attributes as a collection, this method could be useful. Otherwise, it might be misleading or incorrect. Given the ambiguity, it is likely to survive unless there is a clear indication that this is not the intended behavior."
survived,"def test_TPCDS_Q21_inventory_ratio():
    assert result == [
        Auto1(
            w_warehouse_name=""Backup"", i_item_id=""ITEM2"", inv_before=20, inv_after=20
        ),
        Auto1(w_warehouse_name=""Main"", i_item_id=""ITEM1"", inv_before=30, inv_after=40),
    ]
",tests/dataset/tpc-ds/compiler/py/q21.py,,1,3.2241866333029355e-08,"The method `test_TPCDS_Q21_inventory_ratio` is a test function, which is typically used to verify the correctness of a specific piece of functionality in the codebase. Test functions are generally important for maintaining code quality and ensuring that changes do not introduce bugs. The presence of an assertion indicates that this function is checking the output of some operation against expected results, which is a common practice in software development to ensure reliability. Therefore, it is likely that this method will be retained as part of the test suite to ensure ongoing correctness of the related functionality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q4.py,Auto1,0,0.9998415637531546,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method could lead to confusion and unexpected behavior, especially if the class is intended to represent a collection-like structure. Therefore, it is likely that this method will be deleted or refactored to align with the expected behavior of `__contains__`."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q34.py,StoreSale,1,9.237449576640118e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, this method is likely to be retained as it provides a clear and useful functionality."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q10.py,Customer,1,1.522997951276035e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object with the name `key`. This is a common and useful pattern for dynamic attribute access, especially in cases where the object is used like a dictionary or needs to provide flexible attribute access. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q96.py,HouseholdDemographic,1,7.194132978569833e-09,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. This implementation uses `getattr` to dynamically retrieve an attribute of the object using the provided key. This is a common and useful pattern for objects that need to behave like dictionaries or have dynamic attributes. Since it provides a flexible way to access object attributes and is a standard Python feature, it is likely to be retained in the code."
survived,"def _q0():
    _groups = {}
    _order = []
    for s in store_sales:
        _k = s.item
        _ks = str(_k)
        g = _groups.get(_ks)
        if not g:
            g = _Group(_k)
            _groups[_ks] = g
            _order.append(_ks)
        g.Items.append(s)
    _items1 = [_groups[k] for k in _order]
    return [Auto2(item=g.key, total=sum([x.price for x in g])) for g in _items1]
",tests/dataset/tpc-ds/compiler/py/q56.py,,0,0.9999999956365377,"The method _q0() is likely to be deleted (0) because it uses a non-descriptive name, which suggests it might be a temporary or internal function. Additionally, the method relies on external variables and classes (store_sales, _Group, Auto2) that are not defined within the code snippet, indicating it might be part of a larger refactoring or cleanup process. If the method is not well-documented or its functionality is replaced by a more efficient or clearer implementation, it is a candidate for deletion."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q75.py,,1,1.4166087846364157e-09,"The method '_key' is a utility function that is likely used internally within a module or class to generate a key for sorting purposes. It takes an iterable 'it', applies a sorting key function from 'opts', and ensures the key is a string if it's a complex data type. This kind of function is common in data processing and sorting tasks, and there is no indication that it is obsolete or redundant. Therefore, it is likely to survive."
survived,"def test_TPCDS_Q75_simplified():
    assert result == [
        Auto1(
            prev_year=2000,
            year=2001,
            i_brand_id=1,
            i_class_id=2,
            i_category_id=3,
            i_manufact_id=4,
            prev_yr_cnt=100,
            curr_yr_cnt=80,
            sales_cnt_diff=-20,
            sales_amt_diff=-200.0,
        )
    ]
",tests/dataset/tpc-ds/compiler/py/q75.py,,1,2.646573631904765e-09,"The method `test_TPCDS_Q75_simplified` is a unit test function that checks if the `result` matches a specific expected output. Unit tests are crucial for ensuring code correctness and reliability, especially in larger projects. The presence of a test function suggests that the codebase values testing and quality assurance. Therefore, it is likely that this method will be maintained to ensure the functionality it tests remains correct."
survived,"def _sum(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""sum() expects list or group"")
    s = 0.0
    for it in v:
        if it is None:
            continue
        if isinstance(it, (int, float)):
            s += float(it)
        else:
            raise Exception(""sum() expects numbers"")
    return s
",tests/dataset/tpc-ds/compiler/py/q48.py,,1,4.1399375473943306e-08,"The method '_sum' is a utility function that calculates the sum of a list of numbers. It includes error handling for non-list inputs and non-numeric elements within the list. This kind of utility function is often useful in various applications where data might be in different formats or types, and a safe summation is required. The method is likely to survive because it provides a basic yet essential functionality with error handling, making it robust for different use cases."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q91.py,HouseholdDemographic,0,0.9999599363048656,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q31.py,Auto1,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement the intended functionality."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q71.py,Auto3,1,1.0467401685178159e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. It is likely to be retained if the class is intended to provide such functionality, as it offers a flexible way to access attributes dynamically. Therefore, the method will likely survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q21.py,Warehouse,1,1.725782769012759e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. This implementation uses `getattr` to dynamically retrieve an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the codebase."
survived,"def _q0():
    _groups = {}
    _order = []
    for ss in store_sales:
        _k = Auto1(customer_sk=ss.ss_customer_sk, item_sk=ss.ss_item_sk)
        _ks = str(_k)
        g = _groups.get(_ks)
        if not g:
            g = _Group(_k)
            _groups[_ks] = g
            _order.append(_ks)
        g.Items.append(ss)
    _items1 = [_groups[k] for k in _order]
    return [
        Auto1(customer_sk=g.key[""customer_sk""], item_sk=g.key[""item_sk""])
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q97.py,,1,4.6911638017642294e-08,"The method '_q0' is a utility function that processes a list of 'store_sales' to group sales by customer and item, and then returns a list of 'Auto1' objects with unique customer and item keys. This method is likely to be retained because it serves a specific purpose in organizing and processing sales data, which is a common requirement in data processing and analysis tasks. The method is not overly complex, and its functionality is clear and useful for applications that need to handle sales data efficiently."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q57.py,,1,1.1861120010657661e-08,"The method '_key' is a utility function that is likely used internally within a module or class to generate a key for sorting purposes. It is a simple and straightforward function that converts the result of a 'sortKey' function into a string if it is a list, tuple, or dictionary. This kind of utility function is common in codebases where sorting or ordering of complex data structures is required. Since it serves a specific purpose and is not overly complex or redundant, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q13.py,HouseholdDemographic,0,0.9999687980937693,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q15.py,Customer,1,1.955568070542584e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. It is likely to be retained because it provides a flexible and Pythonic way to access object attributes, enhancing the usability of the class."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q84.py,CustomerDemographic,0,0.9997040427747256,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the standard or expected behavior for `__contains__`, which should typically check for membership in a collection like a list, set, or dictionary. This misuse of `__contains__` could lead to confusion and unexpected behavior, making it a candidate for deletion or refactoring to align with its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q19.py,CustomerAddres,0,0.999988521231025,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method is likely to lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership testing. Therefore, it is likely to be deleted or refactored to align with its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q17.py,Auto2,0,0.9999687980937693,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually meant for checking membership in a collection like a list, set, or dictionary. Therefore, this implementation is misleading and does not align with the expected behavior of `__contains__`. It is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q79.py,Store,0,0.9999869928752253,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q14.py,CrossItem,0,0.9999785550602307,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the typical or expected behavior for `__contains__`, which should check for membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may lead to confusion or errors when used. It is likely to be deleted or replaced with a more appropriate implementation."
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q14.py,_Group,1,3.581747929000289e-10,"The method `__iter__` is a standard Python method used to make an object iterable. By returning an iterator over `self.Items`, it allows the object to be used in loops and other contexts where iteration is needed. This is a fundamental feature for many Python classes, especially those that represent collections or sequences. Unless there is a specific reason to remove iteration capability from the class, this method is likely to be retained."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q19.py,,1,7.194132978569833e-09,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be used in various data processing scenarios, making it versatile and potentially useful in many contexts. The function is not overly specific to a single use case, which increases its chances of being retained for future use. Additionally, the function is well-structured and implements common data manipulation operations, which are often needed in software development. Therefore, it is likely to survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q92.py,Item,0,0.999983298584886,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical use case for `__contains__`, which is expected to check membership rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q66.py,WebSale,1,3.2241866333029355e-08,"The method is a simple implementation of the __getitem__ special method, which allows an object to use the bracket notation (obj[key]) to access its attributes. This is a common and useful pattern in Python, especially for classes that need to provide dictionary-like access to their attributes. It is likely to be retained as it provides a clear and concise way to access object attributes using keys, enhancing the flexibility and usability of the class."
survived,"def test_TPCDS_Q9_result():
    assert result == [
        Auto1(bucket1=7.0, bucket2=15.0, bucket3=30.0, bucket4=35.0, bucket5=50.0)
    ]
",tests/dataset/tpc-ds/compiler/py/q9.py,,1,2.646573631904765e-09,"The method `test_TPCDS_Q9_result` is a unit test that checks if the variable `result` matches a specific expected output. Unit tests are crucial for ensuring code correctness and reliability, especially in larger projects. They help in identifying bugs early and ensure that changes in the code do not break existing functionality. Given the importance of testing in software development, it is likely that this method will be retained to maintain code quality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q73.py,Auto3,0,0.9999869928752253,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q54.py,CustomerAddres,1,2.5109990926928157e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q84.py,Customer,0,0.9999785550602307,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement the intended functionality."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q15.py,Auto1,1,2.646573631904765e-09,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python, especially in classes that aim to mimic dictionary behavior or provide flexible attribute access. Therefore, this method is likely to be Survived."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q24.py,Auto2,0,0.9999251538028718,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose suggests that it might be deleted or refactored to align with its conventional use."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q4.py,StoreSale,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate method for checking membership."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q59.py,SalesYear1,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or significantly modified to correctly implement the intended functionality."
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q39.py,_Group,1,1.9171715133907573e-10,"The method `__iter__` is a standard Python method used to make an object iterable. By returning an iterator over `self.Items`, it allows the object to be used in loops and other contexts that require iteration. This is a fundamental feature for many classes that manage collections of items, making it highly unlikely to be deleted unless the class itself is being deprecated or significantly refactored. Therefore, the method will survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q56.py,StoreSale,0,0.9999930377415741,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not attribute existence. This misuse of the method could lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership checks. Therefore, it is likely to be deleted or refactored to align with its intended purpose."
survived,"def test_TPCDS_Q86_sample():
    assert result == 86.0
",tests/dataset/tpc-ds/compiler/py/q86.py,,1,5.043472052266442e-07,"The method `test_TPCDS_Q86_sample` is a test function that asserts whether the variable `result` is equal to 86.0. This is a very basic test, and its survival depends on the context in which it is used. If `result` is a critical part of a larger testing suite for a project, this test is likely to survive as it ensures a specific expected outcome. However, if `result` is not defined or used elsewhere, or if the test is too simplistic and doesn't provide meaningful coverage, it might be deleted or replaced with more comprehensive tests. Without additional context, it's reasonable to assume that this test serves a purpose in a testing suite, so it is likely to survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q1.py,Auto2,0,0.9875683512049241,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually implemented to check for membership in a collection like a list, set, or dictionary. However, if the class is designed to treat its attributes as keys in a collection, this implementation could be valid. Without additional context, it's difficult to determine if this is a misuse or a valid use case. Given the unconventional use, it might be more likely to be deleted or refactored for clarity."
survived,"def test_TPCDS_Q13_averages():
    assert result == [
        Auto1(
            avg_ss_quantity=10.0,
            avg_ss_ext_sales_price=100.0,
            avg_ss_ext_wholesale_cost=50.0,
            sum_ss_ext_wholesale_cost=50.0,
        )
    ]
",tests/dataset/tpc-ds/compiler/py/q13.py,,1,2.998960815863541e-09,"The method `test_TPCDS_Q13_averages` is a test function, likely part of a test suite for a larger application. Test functions are generally not deleted unless they are redundant, incorrect, or replaced by more comprehensive tests. This function appears to be testing specific average and sum calculations, which are important for ensuring the correctness of the application. Without additional context indicating that this test is obsolete or incorrect, it is reasonable to assume it will be retained to maintain test coverage."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q25.py,Auto2,1,4.944450477491054e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python to allow more flexible and dynamic access to object properties. Therefore, this method is likely to be retained as it serves a clear purpose and is implemented correctly."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q12.py,WebSale,1,2.2159489282323004e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a common and useful pattern for dynamic attribute access, especially in classes that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q8.py,,1,1.725782769012759e-08,"The method '_key' is a utility function that is likely used internally within a module or class to generate a key for sorting purposes. It takes an iterable 'it', applies a sorting key function from 'opts', and ensures the key is a string if it's a complex data type. This kind of function is common in data processing and sorting operations, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q42.py,DateDim,1,6.825604231969389e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in container-like objects such as lists, dictionaries, or custom objects that mimic these behaviors. In this code, `__getitem__` is implemented to return an attribute of the object using `getattr`. This is a valid and potentially useful implementation if the object is designed to allow attribute access via indexing. It can be particularly useful in scenarios where the object needs to provide a dictionary-like interface for its attributes. Therefore, the method is likely to be retained as it serves a specific purpose in providing flexible attribute access."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q42.py,_Group,1,6.825604231969389e-08,"The method is a constructor for a class, initializing the instance variables 'key', 'Items', and 'items'. It is a fundamental part of the class structure, necessary for creating instances of the class with the specified attributes. Therefore, it is unlikely to be deleted as it serves a crucial role in object instantiation."
survived,"def test_TPCDS_Q51_simplified():
    assert result == [Auto2(item_sk=1, d_date=1), Auto2(item_sk=1, d_date=2)]
",tests/dataset/tpc-ds/compiler/py/q51.py,,1,2.646573631904765e-09,"The method `test_TPCDS_Q51_simplified` is a test function, likely part of a test suite for a larger codebase. Test functions are generally not deleted unless they are redundant, incorrect, or replaced by more comprehensive tests. Since this function contains a specific assertion, it serves a purpose in verifying the correctness of a particular piece of functionality. Without additional context indicating that this test is obsolete or incorrect, it is reasonable to assume it will be retained to ensure the code's reliability."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q46.py,Customer,1,1.3440409770490404e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to behave like a dictionary or similar container, allowing attribute access via keys. Since this method provides a clear and functional purpose, it is likely to be retained in the code."
survived,"def test_TPCDS_Q52_simplified():
    assert result == [
        Auto1(d_year=2001, brand_id=1, ext_price=30.0),
        Auto1(d_year=2001, brand_id=2, ext_price=22.0),
    ]
",tests/dataset/tpc-ds/compiler/py/q52.py,,1,1.8189616842444243e-09,"The method 'test_TPCDS_Q52_simplified' is a test function, which is typically used to verify the correctness of a specific piece of code. Test functions are generally important for maintaining code quality and ensuring that changes do not introduce bugs. Unless there is a specific reason to remove this test, such as it being redundant or replaced by a more comprehensive test, it is likely to be retained. Therefore, the method is predicted to survive."
survived,"def _q1():
    _groups = {}
    _order = []
    for x in bucket2:
        _k = x[""ss_list_price""]
        _ks = str(_k)
        g = _groups.get(_ks)
        if not g:
            g = _Group(_k)
            _groups[_ks] = g
            _order.append(_ks)
        g.Items.append(x)
    _items1 = [_groups[k] for k in _order]
    return [g.key for g in _items1]
",tests/dataset/tpc-ds/compiler/py/q28.py,,0,0.9999993524053853,"The method _q1 is likely to be deleted because it uses a non-descriptive name, which suggests it might be a temporary or internal function. Additionally, the method relies on a variable 'bucket2' and a class '_Group' that are not defined within the provided code, indicating that it might be part of a larger codebase. If these dependencies are removed or refactored, this method might become obsolete. Furthermore, the method's functionality seems to be a simple grouping operation, which could be replaced by more efficient or clearer code elsewhere."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q9.py,Reason,1,3.653482080241728e-08,"The method is a simple implementation of the __getitem__ special method, which allows an object to use the bracket notation (obj[key]) to access its attributes. This is a common and useful pattern in Python, especially for classes that need to provide dictionary-like access to their attributes. It is likely to be retained as it provides a clear and concise way to access object attributes using keys, enhancing the usability of the class."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q37.py,_Group,1,6.023574641292144e-08,"The method is a constructor for a class, initializing the instance variables 'key', 'Items', and 'items'. It is a fundamental part of the class structure, and there is no indication that it is redundant or incorrect. Therefore, it is likely to be retained as it serves a necessary purpose in object initialization."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q36.py,_Group,1,8.152020648014727e-09,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is correctly implemented to return the length of `self.Items`, which suggests that `self.Items` is likely a list or a similar collection. This is a standard and useful implementation for custom classes that manage collections, allowing them to integrate seamlessly with Python's built-in functions. Therefore, this method is likely to be retained as it provides essential functionality for the class."
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q42.py,_Group,1,5.211412485172657e-10,"The method `__iter__` is a standard Python method used to make an object iterable. By returning an iterator over `self.Items`, it allows the object to be used in loops and other contexts where iteration is needed. This is a common and useful feature in Python classes, especially when the class is meant to represent a collection of items. There is no indication that this method is redundant or unnecessary, so it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q20.py,Auto1,1,1.955568070542584e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation, especially in cases where the object is designed to behave like a dictionary or needs dynamic attribute access. There is no indication of redundancy or poor design that would necessitate its deletion. Therefore, it is likely to be retained."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q20.py,,1,3.2241866333029355e-08,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The function is well-structured and provides flexibility through the use of options (opts) for various operations like filtering, sorting, and selecting. Such utility functions are often retained in codebases because they encapsulate complex logic in a reusable manner, making them valuable for developers who need to perform similar operations across different parts of an application. Therefore, it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q4.py,Auto3,1,2.5109990926928157e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q26.py,_Group,1,1.1861120010657661e-08,"The method `__len__` is a special method in Python that is used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q24.py,,1,2.5109990926928157e-08,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The function is well-structured and provides flexibility through the use of options (opts) for various operations like filtering, sorting, and selecting. Such utility functions are often retained in codebases because they encapsulate complex logic in a reusable manner, making them valuable for developers who need to perform similar operations across different parts of an application. Therefore, it is likely to be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q75.py,DateDim,0,0.999985261023967,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking for membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"def _q0():
    _src = web_sales
    _rows = _query(
        _src,
        [
            {""items"": item, ""on"": lambda ws, i: ws.ws_item_sk == i.i_item_sk},
            {
                ""items"": date_dim,
                ""on"": lambda ws, i, d: ws.ws_sold_date_sk == d.d_date_sk,
            },
        ],
        {
            ""select"": lambda ws, i, d: (ws, i, d),
            ""where"": lambda ws, i, d: (
                i.i_category in [""A"", ""B"", ""C""] and d.d_date >= ""2001-01-15""
            )
            and d.d_date <= ""2001-02-14"",
        },
    )
    _groups = _group_by(
        _rows,
        lambda ws, i, d: Auto3(
            id=i.i_item_id,
            desc=i.i_item_desc,
            cat=i.i_category,
            _class=i.i_class,
            price=i.i_current_price,
        ),
    )
    _items1 = _groups
    return [
        Auto2(
            i_item_id=g.key[""id""],
            i_item_desc=g.key[""desc""],
            i_category=g.key[""cat""],
            i_class=g.key[""_class""],
            i_current_price=g.key[""price""],
            itemrevenue=sum([x[0].ws_ext_sales_price for x in g]),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q12.py,,1,8.152020648014727e-09,"The method '_q0' is a specific query function that seems to be part of a larger data processing or analytics system. It performs a query on sales data, filters it based on certain conditions, groups the results, and then processes these groups to calculate item revenue. Such functions are typically integral to data analysis tasks and are unlikely to be deleted unless the entire system is being deprecated or significantly refactored. Therefore, it is more likely to survive."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q53.py,_Group,1,3.0590235908148916e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes. The code snippet shows a typical pattern where an attribute is initialized and a list is created. This is a common and necessary practice in class design, so it is unlikely to be deleted."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q45.py,Customer,0,0.9999989322969233,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the intended use of `__contains__`, as it should be checking membership rather than attribute existence. This misuse of the method suggests that it is likely to be deleted or refactored to correctly implement membership checking."
survived,"def test_TPCDS_Q36_simplified():
    assert result == [
        Auto1(i_category=""Books"", i_class=""C1"", gross_margin=0.2),
        Auto1(i_category=""Books"", i_class=""C2"", gross_margin=0.25),
        Auto1(i_category=""Electronics"", i_class=""C3"", gross_margin=0.2),
    ]
",tests/dataset/tpc-ds/compiler/py/q36.py,,1,2.5109990926928157e-08,"The method `test_TPCDS_Q36_simplified` is a unit test function, which is typically used to verify that a specific piece of code (likely a query or function related to TPC-DS Q36) behaves as expected. Unit tests are crucial for maintaining code quality and ensuring that changes do not introduce bugs. The presence of an assertion indicates that this test is checking for specific expected outcomes, which is a common practice in software development to ensure reliability and correctness. Therefore, it is likely that this method will be retained as part of the test suite to ensure ongoing code quality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q70.py,StoreSale,0,0.9999898700118929,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q30.py,Auto4,1,1.1253518384332553e-07,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in collections like lists or dictionaries. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid use case if the object is designed to allow attribute access via indexing, which can be useful in certain dynamic or flexible data structures. Since this method provides a clear and potentially useful functionality, it is likely to be retained unless there are specific design reasons to remove it."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q43.py,DateDim,0,0.9999952149051502,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or replaced with a more appropriate implementation."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q52.py,DateDim,0,0.9999687980937693,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method is likely to lead to confusion and incorrect behavior when the method is used in the context of checking membership. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q17.py,,1,2.3355930333443423e-09,"The method '_key' is a utility function that is likely used internally within a class or module to generate a key for sorting purposes. It takes an iterable 'it', applies a sorting key function from 'opts', and ensures the key is a string if it's a complex data type. This kind of method is common in data processing or sorting operations and is unlikely to be deleted unless the entire sorting mechanism is refactored or removed. Therefore, it is more likely to survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q87.py,StoreSale,0,0.9999970976877992,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical use case for `__contains__`, which is expected to check membership rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q17.py,Auto3,1,1.522997951276035e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method is straightforward, functional, and follows a common pattern, it is likely to be retained in the codebase."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q46.py,_Group,1,6.69158608681505e-10,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be useful and necessary for the class's functionality, leading to its survival."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q57.py,Auto1,0,0.9999980052698925,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement the intended functionality."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q14.py,Auto1,1,2.8453347280241004e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a simple and effective way to allow attribute access using keys, which can be particularly useful in cases where the object is designed to behave like a dictionary or when the attributes are dynamically determined. Therefore, this method is likely to be retained as it provides a clear and functional purpose."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q43.py,Auto2,1,1.522997951276035e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. It is likely to be retained if the class is intended to support such behavior, as it provides a flexible way to access attributes dynamically. Therefore, the method will likely survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q8.py,Auto1,1,1.0467401685178159e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be retained as it serves a clear purpose and is implemented correctly."
survived,"def _q0():
    _src = store_sales
    _rows = _query(
        _src,
        [
            {
                ""items"": date_dim,
                ""on"": lambda ss, d: (ss.ss_sold_date_sk == d.d_date_sk and d.d_qoy == 1)
                and d.d_year == 1998,
            },
            {""items"": store, ""on"": lambda ss, d, s: ss.ss_store_sk == s.s_store_sk},
            {
                ""items"": customer_address,
                ""on"": lambda ss, d, s, ca: s.s_zip[0:2] == ca.ca_zip[0:2],
            },
            {
                ""items"": customer,
                ""on"": lambda ss, d, s, ca, c: ca.ca_address_sk == c.c_current_addr_sk
                and c.c_preferred_cust_flag == ""Y"",
            },
        ],
        {
            ""select"": lambda ss, d, s, ca, c: (ss, d, s, ca, c),
            ""where"": lambda ss, d, s, ca, c: ca.ca_zip[0:5] in zip_list,
        },
    )
    _groups = _group_by(_rows, lambda ss, d, s, ca, c: s.s_store_name)
    _items1 = _groups
    _items1 = sorted(_items1, key=lambda g: g.key)
    return [
        Auto1(s_store_name=g.key, net_profit=_sum([x[0].ss_net_profit for x in g]))
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q8.py,,1,7.3382086014706e-07,"The method '_q0' is a complex query function that seems to be part of a larger data processing or analytics system. It performs a series of joins and filters on sales data, customer data, and store data, and then groups and sorts the results to calculate net profit by store name. This type of function is typically crucial for generating reports or insights in business applications.

Given its complexity and the specific business logic it implements, it is unlikely to be deleted unless the entire system is being deprecated or replaced. Such functions are often maintained and updated rather than removed, as they provide valuable insights and are integral to the application's functionality."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q54.py,Auto4,1,5.3157849718487075e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. It is likely to survive because it provides a flexible way to access object attributes, which can be particularly useful in dynamic or reflective programming scenarios."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q57.py,_Group,1,1.8553915987649156e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes. The code snippet shows a typical pattern of initializing instance variables, which is a common and necessary practice in class definitions. Therefore, it is unlikely that this method will be deleted."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q32.py,DateDim,1,1.725782769012759e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via keys, similar to a dictionary. Since this method provides a clear and functional purpose, it is likely to be retained in the codebase."
survived,"def _sum(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""sum() expects list or group"")
    s = 0.0
    for it in v:
        if it is None:
            continue
        if isinstance(it, (int, float)):
            s += float(it)
        else:
            raise Exception(""sum() expects numbers"")
    return s
",tests/dataset/tpc-ds/compiler/py/q56.py,,1,2.5109990926928157e-08,"The method '_sum' is a utility function that calculates the sum of a list of numbers, with additional handling for objects that have an 'Items' attribute. It includes error handling for non-list inputs and non-numeric elements within the list. This function is useful for summing elements in a list while ensuring type safety and handling potential None values. Such utility functions are common in codebases for data processing tasks, and unless there is a direct replacement or a significant change in requirements, it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q64.py,StoreSale,1,2.8453347280241004e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is used as a dictionary-like structure, allowing for flexible and dynamic access to its attributes. Therefore, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q3.py,StoreSale,0,0.9999921107349486,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q91.py,Auto2,0,0.9999938558278723,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of `__contains__` is likely to lead to confusion and errors, as it does not align with the standard behavior expected from this method. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q38.py,CatalogSale,0,0.9999910602998366,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or replaced with a more appropriate implementation that correctly checks for key membership."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q48.py,,1,6.825604231969389e-08,"The method '_key' is a utility function that is likely used internally within a class or module to generate a key for sorting purposes. It takes an iterable 'it', applies a sorting key function from 'opts', and ensures the key is a string if it's a complex data type. This kind of function is common in sorting operations and is useful for customizing sort behavior. Since it serves a specific purpose and is not overly complex or redundant, it is likely to be retained in the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q57.py,CatalogSale,1,6.348800075736417e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, this method is likely to be retained as it provides a clear and useful functionality."
survived,"    def test_env_override(self) -> None:
        env = os.environ.copy()
        env[""ALPHA_AGI_SECTORS""] = ""Finance,Healthcare,Space""
        result = subprocess.run(
            [
                sys.executable,
                ""-m"",
                ""alpha_factory_v1.demos.alpha_agi_insight_v0.insight_demo"",
                ""--episodes"",
                ""1"",
            ],
            capture_output=True,
            text=True,
            env=env,
        )
        self.assertEqual(result.returncode, 0, result.stderr)
        match = re.search(r""Best sector:\s*(\w+)"", result.stdout)
        self.assertIsNotNone(match, result.stdout)
        self.assertIn(match.group(1), {""Finance"", ""Healthcare"", ""Space""})
",tests/test_alpha_agi_insight_env.py,TestAlphaAgiInsightEnv,1,6.348800075736417e-09,"The method 'test_env_override' is a unit test that checks the functionality of a subprocess call with an overridden environment variable. It verifies that the subprocess runs successfully and that the output matches expected patterns. This is a typical use case for testing code that relies on environment variables and subprocess execution. Since it is a well-structured test that serves a clear purpose in ensuring the reliability of the code, it is likely to be retained in the codebase."
survived,"    def create(self, *args, **kwargs):  # pragma: no cover - stub method
        raise NotImplementedError
",openai/__init__.py,_ChatCompletions,1,1.8553915987649156e-07,"The method is a stub with a pragma directive indicating it is not covered by tests, and it raises a NotImplementedError. This suggests that it is intended to be overridden in a subclass or implemented later. Such methods are common in abstract base classes or interfaces, and they typically survive as they define a contract for subclasses. Therefore, it is likely to be Survived."
survived,"def _parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description=""Refresh offline CSV snapshots"")
    parser.add_argument(
        ""--revision"",
        required=True,
        help=""demo-assets commit SHA"",
    )
    return parser.parse_args()
",alpha_factory_v1/demos/macro_sentinel/refresh_offline_data.py,,1,1.4166087846364157e-09,"The method '_parse_args' is a utility function that uses the argparse library to parse command-line arguments. It is a common practice in Python scripts to handle input parameters, making the script more flexible and user-friendly. The method is well-defined, with a clear purpose and usage, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained in the codebase."
deleted,"    def __init__(
        self, system_message: str, user_input: str, thinking_instructions: str | None
    ) -> None:
        super().__init__(system_message, user_input, thinking_instructions)
        if self.thinking_instructions is None:
            raise ValueError(
                ""thinking_instructions are required when strategy is final_and_intermediate""
            )
",libs/core/kiln_ai/adapters/chat/chat_formatter.py,FinalAndIntermediateFormatter,1,7.3382086014706e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting up initial states. The presence of a check for 'thinking_instructions' suggests that this constructor is designed to enforce certain conditions, which is a common practice to ensure the object is in a valid state. Therefore, it is unlikely that this method will be deleted as it serves a critical role in the class's functionality."
survived,"    def json(self):
        return json.loads(self.text)
",alpha_factory_v1/requests.py,Response,0,0.9999974387182097,"The method named 'json' is likely to be deleted because it conflicts with the standard library 'json' module, which can lead to confusion and potential errors. Additionally, the method is simply wrapping a call to 'json.loads', which can be directly used wherever this method is called, making this method redundant."
survived,"    def test_main_registers_agent(self) -> None:
        os.environ[""ALPHA_FACTORY_ENABLE_ADK""] = ""true""
        from alpha_factory_v1.backend import adk_bridge as _adk_bridge
        adk_bridge = importlib.reload(_adk_bridge)

        runtime = MagicMock()
        with patch(""openai_agents.AgentRuntime"", return_value=runtime) as rt_cls, \
                patch.object(adk_bridge, ""auto_register"") as auto_reg, \
                patch.object(adk_bridge, ""maybe_launch"") as maybe_launch:
            mod = importlib.reload(importlib.import_module(
                ""alpha_factory_v1.demos.alpha_asi_world_model.openai_agents_bridge""
            ))
            mod.main()

            rt_cls.assert_called_once_with(api_key=None)
            runtime.register.assert_called_once()
            agent_arg = runtime.register.call_args.args[0]
            self.assertIsInstance(agent_arg, mod.InspectorAgent)
            auto_reg.assert_called_once_with([agent_arg])
            maybe_launch.assert_called_once_with()

        os.environ.pop(""ALPHA_FACTORY_ENABLE_ADK"", None)
",tests/test_inspector_bridge_runtime.py,TestInspectorBridgeRuntime,1,2.2159489282323004e-08,"The method 'test_main_registers_agent' is a unit test designed to verify the behavior of a specific function or module. Unit tests are generally considered essential for maintaining code quality and ensuring that changes do not introduce regressions. This test checks the integration of several components and mocks their behavior to ensure the 'main' function operates as expected. Given the importance of testing in software development, especially for complex systems, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered."
survived,"def _build_local_site(repo_root: Path) -> bool:
    """"""Return ``True`` if the gallery was built successfully.""""""
    script = repo_root / ""scripts"" / ""build_gallery_site.sh""
    if not script.is_file():
        return False
    try:
        subprocess.run([str(script)], check=True)
    except Exception:
        return False
    return True
",scripts/open_gallery.py,,1,8.76424914819242e-08,"The method `_build_local_site` is a utility function that checks for the existence of a script file and attempts to run it. This is a common pattern in build or deployment scripts where a specific task needs to be automated. The method is simple, clear, and serves a specific purpose, which is to build a gallery site if the script exists. It handles exceptions gracefully and returns a boolean indicating success or failure, which is useful for further decision-making in the code. Such utility functions are often retained as they encapsulate a specific functionality that might be reused or needed in the future."
survived,"    async def stop(self) -> None:
        """"""Stop the underlying manager.""""""
        await self.manager.stop()
",alpha_factory_v1/backend/agent_scheduler.py,AgentScheduler,1,6.348800075736417e-09,"The method 'stop' is a simple asynchronous method that calls the 'stop' method on an underlying manager. This is a common pattern in asynchronous programming to ensure that resources are properly released or tasks are gracefully terminated. The method is straightforward, serves a clear purpose, and is likely part of a larger system where stopping a manager is necessary. Therefore, it is unlikely to be deleted as it provides essential functionality."
survived,"    def query(
        self,
        sector: str | None = None,
        approach: str | None = None,
        band: int | None = None,
    ) -> list[Solution]:
        clauses: list[str] = []
        params: list[Any] = []
        if sector is not None:
            clauses.append(""sector=?"")
            params.append(sector)
        if approach is not None:
            clauses.append(""approach=?"")
            params.append(approach)
        if band is not None:
            clauses.append(""band=?"")
            params.append(band)
        sql = ""SELECT sector, approach, score, data, ts FROM solutions""
        if clauses:
            sql += "" WHERE "" + "" AND "".join(clauses)
        cur = self.conn.execute(sql, params)
        rows = cur.fetchall()
        result = [
            Solution(
                sector=row[0],
                approach=row[1],
                score=float(row[2]),
                data=json.loads(row[3]),
                ts=float(row[4]),
            )
            for row in rows
        ]
        return result
",src/archive/solution_archive.py,SolutionArchive,1,1.725782769012759e-08,"The method is well-structured and serves a clear purpose of querying a database based on optional filters. It uses type hints, handles optional parameters, constructs SQL queries dynamically, and processes the results into a list of Solution objects. These are all good practices in modern Python development, making the method useful and likely to be retained."
survived,"def _make_repo(tmp_path: Path) -> Path:
    repo = tmp_path / ""repo""
    repo.mkdir()
    (repo / ""metric.txt"").write_text(""1\n"", encoding=""utf-8"")
    (repo / ""test_dummy.py"").write_text(""def test_ok():\n    assert True\n"", encoding=""utf-8"")
    return repo
",tests/test_meta_refinement_agent.py,,1,3.2241866333029355e-08,"The method `_make_repo` is a utility function that creates a temporary repository structure with a specific setup. It is useful for testing purposes, especially in scenarios where a temporary file system structure is needed to simulate a repository environment. Such utility functions are common in test suites to ensure that tests have a controlled and isolated environment to run in. Given its utility in testing, it is likely to be retained as part of the codebase."
survived,"def Tool(*_a: object, **_k: object) -> Callable[[F], F]:
    def dec(f: F) -> F:
        return f

    return dec",tests/resources/openai_agents.py,,1,5.715002851580502e-07,"The method 'Tool' is a decorator factory that returns a decorator 'dec'. The decorator 'dec' simply returns the function it decorates without modifying it. This pattern is often used as a placeholder or for future extension where additional functionality might be added to the decorator. Since it doesn't currently perform any operations, it might seem redundant, but it is a common practice to have such scaffolding in place for future development. Therefore, it is likely to survive as it provides a structure for potential future enhancements."
survived,"def boom():
    print(""boom"")
    return True
",tests/human/python/bool_chain.py,,1,1.637377179507321e-07,"The method 'boom' is a simple function that prints the word 'boom' and returns True. It is a basic function with no apparent issues or complexities. Since it performs a straightforward task without any side effects or errors, there is no immediate reason for it to be deleted unless it is deemed unnecessary in the context where it is used. Without additional context, it is likely to survive as it could be useful for debugging or as a placeholder function."
survived,"def boom():
    print(""boom"")
    return True
",tests/human/x/python/bool_chain.py,,1,6.475946147757848e-07,"The method 'boom' is a simple function that prints the word 'boom' and returns True. It doesn't have any complex logic or dependencies, making it unlikely to be deleted unless it's deemed unnecessary or unused in the codebase. Without additional context on its usage, it's reasonable to assume it will survive as it doesn't pose any issues or require maintenance."
survived,"def request_with_proxy_fallback(
    session: requests.Session,
    method: str,
    url: str,
    *,
    timeout: Optional[int] = None,
    retries: int = 3,
    **kwargs,
) -> requests.Response:
    """"""Perform a request using rotating proxies.

    The request first uses the session's current proxy configuration. If the
    request fails due to connectivity issues, a new proxy is fetched using
    :func:`get_auto_proxy` and the request is retried. This continues up to
    ``retries`` times before raising an exception.
    """"""

    if retries < 1:
        retries = 1

    last_error: Exception | None = None
    for attempt in range(retries):
        try:
            resp = session.request(method, url, timeout=timeout, **kwargs)
            resp.raise_for_status()
            return resp
        except (
            requests.exceptions.ConnectionError,
            requests.exceptions.ProxyError,
            requests.exceptions.Timeout,
        ) as exc:
            last_error = exc
            try:
                proxy = get_auto_proxy()
                session.proxies.update({""http"": proxy, ""https"": proxy})
            except Exception as fetch_err:  # pragma: no cover - network dependent
                last_error = fetch_err
        except Exception:
            # Other errors should not trigger proxy retry
            raise

    raise RuntimeError(f""All proxy attempts failed: {last_error}"")
",webscout/Provider/TTI/utils.py,,1,1.6052280526088547e-09,"The method `request_with_proxy_fallback` is a robust implementation for handling network requests with proxy fallback. It is designed to handle common network issues like connection errors, proxy errors, and timeouts by retrying with a new proxy. This functionality is crucial for applications that require reliable network communication, especially in environments with unstable connections or where proxies are necessary for access. The method is well-documented, handles exceptions gracefully, and provides a fallback mechanism, making it a valuable utility in network programming. Therefore, it is likely to be retained in the codebase."
survived,"def test_thermodynamic_trigger_edges() -> None:
    sec = sector.Sector(""x"", energy=1.0, entropy=2.0)
    assert not forecast.thermodynamic_trigger(sec, 0.5)
    assert forecast.thermodynamic_trigger(sec, 0.50001)
    sec2 = sector.Sector(""y"", energy=0.0, entropy=1.0)
    assert not forecast.thermodynamic_trigger(sec2, 0.0)
    assert forecast.thermodynamic_trigger(sec2, 0.1)
",tests/test_forecast.py,,1,6.825604231969389e-08,"The method `test_thermodynamic_trigger_edges` is a unit test function that checks the behavior of the `thermodynamic_trigger` function at specific edge cases. Unit tests are crucial for ensuring the correctness of code, especially when dealing with boundary conditions. This function is likely to be maintained as it provides valuable test coverage for the `thermodynamic_trigger` function, ensuring it behaves as expected in edge cases. Therefore, it is unlikely to be deleted."
survived,"def test_innovation_gain_positive() -> None:
    gain = forecast._innovation_gain(pop_size=2, generations=1)
    assert gain > 0.0
    assert gain < 0.1",tests/test_forecast.py,,1,9.736200303530205e-10,"The method `test_innovation_gain_positive` is a unit test that checks if the `_innovation_gain` method of the `forecast` object returns a value between 0.0 and 0.1 when called with specific parameters. This test is likely to be useful for ensuring the correctness of the `_innovation_gain` method, especially if it is a critical part of the system's functionality. Unit tests are generally considered good practice in software development as they help maintain code quality and catch regressions. Therefore, it is likely that this method will be Survived (1)."
survived,"    def setUp(self) -> None:
        self._backup = AGENT_REGISTRY.copy()
        AGENT_REGISTRY.clear()
",tests/test_demo_registration.py,TestRegisterDemoAgents,1,8.76424914819242e-08,"The method `setUp` is a common method used in unit testing frameworks like `unittest` in Python. It is typically used to set up the test environment before each test method is run. In this code, `setUp` is backing up the current state of `AGENT_REGISTRY` and then clearing it, which suggests that it is preparing a clean state for tests to run. This is a standard practice in testing to ensure tests do not interfere with each other by sharing state. Therefore, the method is likely to be retained as it serves a crucial role in test setup."
survived,"    def test_cli_args_override_env(self) -> None:
        env = {""PORT"": ""1111"", ""METRICS_PORT"": ""2222"", ""A2A_PORT"": ""3333"", ""CYCLE"": ""4""}
        argv = [""--port"", ""9000"", ""--metrics-port"", ""9001"", ""--agents"", ""X,Y""]
        with patch.dict(os.environ, env, clear=True):
            args = edge_runner.parse_args(argv)
        self.assertEqual(args.port, 9000)
        self.assertEqual(args.metrics_port, 9001)
        self.assertEqual(args.agents, ""X,Y"")
        # Unspecified flags fall back to environment defaults
        self.assertEqual(args.a2a_port, 3333)
        self.assertEqual(args.cycle, 4)
",tests/test_edge_runner_cli.py,TestParseArgs,1,1.6052280526088547e-09,"The method `test_cli_args_override_env` is a unit test designed to verify that command-line arguments correctly override environment variables, while unspecified arguments fall back to environment defaults. This is a common and important functionality in applications that use both environment variables and command-line arguments for configuration. The test is well-structured, using mocking to isolate the environment and ensure the test is reliable. Such tests are crucial for maintaining the integrity of configuration handling in software, making it unlikely to be deleted unless the feature it tests is removed or significantly altered."
survived,"def test_serde_jsonplus_numpy_array(arr: np.ndarray) -> None:
    serde = JsonPlusSerializer()

    dumped = serde.dumps_typed(arr)
    assert dumped[0] == ""msgpack""
    result = serde.loads_typed(dumped)
    assert isinstance(result, np.ndarray)
    assert result.dtype == arr.dtype
    assert np.array_equal(result, arr)
",libs/checkpoint/tests/test_jsonplus.py,,1,2.8453347280241004e-08,"The method 'test_serde_jsonplus_numpy_array' is a unit test designed to verify the functionality of a serializer, specifically 'JsonPlusSerializer', for handling numpy arrays. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with data serialization and deserialization. This method checks that the serialization and deserialization process maintains the data type and content integrity of numpy arrays, which is a common requirement in data processing applications. Given the importance of testing in software development, this method is likely to be retained to ensure the serializer works as expected."
survived,"def test_serde_jsonplus_numpy_array_json_hook(arr: np.ndarray) -> None:
    serde = JsonPlusSerializer(__unpack_ext_hook__=_msgpack_ext_hook_to_json)
    dumped = serde.dumps_typed(arr)
    assert dumped[0] == ""msgpack""
    result = serde.loads_typed(dumped)
    assert isinstance(result, list)
    assert result == arr.tolist()
",libs/checkpoint/tests/test_jsonplus.py,,1,3.653482080241728e-08,"The method 'test_serde_jsonplus_numpy_array_json_hook' is a test function that verifies the serialization and deserialization of a numpy array using a custom serializer 'JsonPlusSerializer'. It checks if the serialized data is in the expected format and if the deserialized data matches the original array. Test functions are generally important for ensuring code reliability and correctness, especially when dealing with data serialization and deserialization. Therefore, it is likely to be retained as part of the test suite to ensure the functionality works as expected."
survived,"def test_maybe_await_async():
    result = asyncio.run(maybe_await(_async_fn, 5))
    assert result == 10
",tests/test_agent_runner_utils.py,,1,3.3982678079468468e-09,"The method `test_maybe_await_async` is a test function that uses `asyncio.run` to execute an asynchronous function `maybe_await` with `_async_fn` and an argument `5`. It then asserts that the result is `10`. This is a straightforward test case for an asynchronous function, which is a common pattern in modern Python codebases that utilize async/await syntax. Given the increasing adoption of asynchronous programming in Python, this method is likely to be useful for testing purposes and is expected to survive."
survived,"    async def _run_input_guardrails_with_queue(
        cls,
        agent: Agent[Any],
        guardrails: list[InputGuardrail[TContext]],
        input: str | list[TResponseInputItem],
        context: RunContextWrapper[TContext],
        streamed_result: RunResultStreaming,
        parent_span: Span[Any],
    ):
        queue = streamed_result._input_guardrail_queue

        # We'll run the guardrails and push them onto the queue as they complete
        guardrail_tasks = [
            asyncio.create_task(
                RunImpl.run_single_input_guardrail(agent, guardrail, input, context)
            )
            for guardrail in guardrails
        ]
        guardrail_results = []
        try:
            for done in asyncio.as_completed(guardrail_tasks):
                result = await done
                if result.output.tripwire_triggered:
                    _error_tracing.attach_error_to_span(
                        parent_span,
                        SpanError(
                            message=""Guardrail tripwire triggered"",
                            data={
                                ""guardrail"": result.guardrail.get_name(),
                                ""type"": ""input_guardrail"",
                            },
                        ),
                    )
                queue.put_nowait(result)
                guardrail_results.append(result)
        except Exception:
            for t in guardrail_tasks:
                t.cancel()
            raise

        streamed_result.input_guardrail_results = guardrail_results
",src/agents/run.py,DefaultAgentRunner,1,4.944450477491054e-09,"The method is well-structured and serves a specific purpose in handling asynchronous tasks related to input guardrails. It uses asyncio to manage concurrent tasks efficiently, handles exceptions, and ensures that results are queued and stored properly. This functionality is likely essential for the system's operation, especially in environments where input validation and error handling are critical. Therefore, it is unlikely to be deleted."
survived,"def main() -> None:
    signals = gather_signals()
    choice = best_alpha(signals)
    print(""\nAlpha signals:"")
    for k, v in signals.items():
        print(f""- {k}: {v}"")
    print(""\nBest current alpha â†’"", choice)
",alpha_factory_v1/demos/era_of_experience/alpha_report.py,,1,1.1861120010657661e-08,"The method 'main' is a typical entry point for a Python script, and it is structured to perform a specific task: gathering signals, determining the best alpha, and printing the results. This is a common pattern in Python scripts, and there is no indication that it is redundant or unnecessary. Therefore, it is likely to be retained in the codebase."
survived,"def test_get_resource_type_from_arn():
    assert ""ec2:instance"" == rgta.get_resource_type_from_arn(
        ""arn:aws:ec2:us-east-1:1234:instance/i-01""
    )
    assert ""s3"" == rgta.get_resource_type_from_arn(""arn:aws:s3:::bucket-1"")
    assert ""elasticloadbalancing:loadbalancer/app"" == rgta.get_resource_type_from_arn(
        ""arn:aws:elasticloadbalancing:us-east-1:1234:loadbalancer/app/foo/123""
    )
",tests/unit/cartography/intel/aws/test_resourcegroupstaggingapi.py,,1,7.73442280641062e-08,"The method `test_get_resource_type_from_arn` is a unit test function that verifies the functionality of the `get_resource_type_from_arn` method from the `rgta` module. Unit tests are crucial for ensuring code reliability and correctness, especially in production environments. They help in identifying bugs early in the development process and provide documentation for the expected behavior of the code. Given the importance of testing in software development, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered."
survived,"def test_csp_meta_tag() -> None:
    index_file = BROWSER / ""dist/index.html""
    html = index_file.read_text()
    match = re.search(r'<meta[^>]*http-equiv=[""\']Content-Security-Policy[""\'][^>]*>', html)
    assert match, ""Content Security Policy meta tag missing""
    tag = match.group(0)
    content = re.search(r'content=""([^""]+)""', tag)
    assert content, ""content attribute missing""
    policy = content.group(1)
    assert ""script-src 'self' 'wasm-unsafe-eval'"" in policy, ""CSP missing script-src 'self' 'wasm-unsafe-eval'""",tests/test_integrity.py,,1,3.850741907939403e-09,"The method `test_csp_meta_tag` is a test function that checks for the presence and correctness of a Content Security Policy (CSP) meta tag in an HTML file. This is a crucial security feature that helps prevent cross-site scripting (XSS) and other code injection attacks. Ensuring that the CSP is correctly implemented is important for maintaining the security of web applications. Therefore, this test is likely to be retained to ensure ongoing security compliance."
survived,"    def boom(*_a, **_kw):
        raise FileNotFoundError(""docker"")
",tests/test_start_aiga_demo.py,,0,0.9999999956365377,"The method 'boom' is designed to raise a FileNotFoundError with a specific message 'docker' whenever it is called. This method does not perform any useful computation or return any value, and its sole purpose is to raise an exception. Such methods are typically used for testing error handling or as placeholders during development. However, in a production environment, a method that only raises an exception without any conditional logic or additional functionality is not useful and is likely to be removed or replaced with more meaningful code. Therefore, the method is predicted to be deleted."
survived,"def test_start_aiga_demo_help() -> None:
    """"""--help prints usage information.""""""
    result = subprocess.run([
        sys.executable,
        str(SCRIPT),
        ""--help"",
    ], capture_output=True, text=True)
    assert result.returncode == 0
    assert ""usage"" in result.stdout.lower()
",tests/test_start_aiga_demo.py,,1,1.6052280526088547e-09,"The method `test_start_aiga_demo_help` is a unit test that checks if the `--help` option of a script prints the usage information correctly. This is a common and essential test to ensure that users can access help information, which is a critical part of user experience and documentation. Such tests are typically retained to ensure the software behaves as expected and provides necessary guidance to users. Therefore, it is unlikely to be deleted."
survived,"def test_postgres_merkle_root(tmp_path) -> None:
    params = {
        ""host"": os.getenv(""PGHOST"", ""localhost""),
        ""port"": int(os.getenv(""PGPORT"", ""5432"")),
        ""user"": os.getenv(""PGUSER"", ""postgres""),
        ""password"": os.getenv(""PGPASSWORD"", """"),
        ""dbname"": os.getenv(""PGDATABASE"", ""postgres""),
    }
    try:
        conn = psycopg2.connect(**params)
    except Exception:
        pytest.skip(""postgres unavailable"")
    with conn:
        with conn.cursor() as cur:
            cur.execute(""DROP TABLE IF EXISTS messages"")
    conn.close()

    ledger = Ledger(tmp_path / ""ignore.db"", db=""postgres"", broadcast=False)
    env = messaging.Envelope(sender=""a"", recipient=""b"", payload={""v"": 1}, ts=0.0)
    ledger.log(env)
    assert ledger.compute_merkle_root() == _expected_root([env])
    ledger.close()",tests/test_ledger_backends.py,,1,1.8189616842444243e-09,"The method 'test_postgres_merkle_root' is a test function that verifies the functionality of computing a Merkle root using a PostgreSQL database. It is likely to survive because it serves a specific purpose in testing the integration of a ledger system with a PostgreSQL backend. Test functions are crucial for ensuring the reliability and correctness of code, especially when dealing with databases and cryptographic operations like Merkle trees. Unless the functionality it tests becomes obsolete or is replaced by a different testing strategy, this method is likely to be retained."
survived,"    def burn(self, agent_id: str, fraction: float) -> None:
        """"""Burn ``fraction`` of ``agent_id``'s stake if present.""""""
        if agent_id in self.stakes:
            self.stakes[agent_id] = max(0.0, self.stakes[agent_id] * (1.0 - fraction))
",src/governance/stake_registry.py,StakeRegistry,1,3.581747929000289e-10,"The method 'burn' is a straightforward and useful utility function for reducing a stake by a given fraction. It checks if the agent_id exists in the stakes dictionary and then reduces the stake by the specified fraction, ensuring it doesn't go below zero. This kind of functionality is common in systems dealing with financial transactions or resource management, where penalties or reductions are applied. The method is simple, efficient, and serves a clear purpose, making it likely to be retained in the codebase."
survived,"def main() -> None:
    out = Path(""docs/bench_history.csv"")
    for name in replay.available_scenarios():
        scn = replay.load_scenario(name)
        traj = replay.run_scenario(scn)
        replay.score_trajectory(name, traj, csv_path=out)
",scripts/run_replay_bench.py,,1,7.73442280641062e-08,"The method 'main' is a simple script that iterates over available scenarios, loads them, runs them, and scores the trajectory, saving the results to a CSV file. This is a typical use case in data processing or simulation tasks, and there is no indication that it is obsolete or redundant. It performs a clear and useful function, and there is no reason to delete it unless the entire functionality it supports is being deprecated, which is not suggested here."
survived,"    def history(self, start_hash: str) -> Iterator[ArchiveEntry]:
        current = self.get(start_hash)
        while current is not None:
            yield current
            if not current.parent:
                break
            current = self.get(current.parent)",src/archive/db.py,ArchiveDB,1,3.3982678079468468e-09,"The method 'history' is a utility function that retrieves a sequence of 'ArchiveEntry' objects starting from a given hash and traversing through their parent entries. This type of method is useful for applications that need to track changes or versions, such as version control systems or archival systems. The method is straightforward, performs a clear and useful function, and does not have any apparent issues or redundancies. Therefore, it is likely to be retained in the codebase."
survived,"def test_archive_crud(tmp_path) -> None:
    db = ArchiveDB(tmp_path / ""arch.db"")
    root = ArchiveEntry(""h1"", None, 0.1, 0.0, True, 1.0)
    child = ArchiveEntry(""h2"", ""h1"", 0.2, 0.0, False, 2.0)
    db.add(root)
    db.add(child)

    assert db.get(""h2"") == child
    history = list(db.history(""h2""))
    assert [e.hash for e in history] == [""h2"", ""h1""]
",tests/test_archive.py,,1,2.5109990926928157e-08,"The method 'test_archive_crud' is a unit test designed to verify the functionality of the ArchiveDB class, specifically its ability to add entries and retrieve history. Unit tests are crucial for ensuring code reliability and are typically retained in the codebase to facilitate ongoing testing and validation of the software. Therefore, it is unlikely that this method will be deleted."
survived,"def plot_histogram(counts: Iterable[int], out_file: str | Path = DEFAULT_OUT) -> None:
    """"""Save histogram of ``counts`` to ``out_file``.""""""
    df = pd.DataFrame({""backtracks"": list(counts)})
    fig = px.histogram(df, x=""backtracks"")
    path = Path(out_file)
    path.parent.mkdir(parents=True, exist_ok=True)
    fig.write_image(str(path))
",src/tools/analyse_backtrack.py,,1,7.582560422162384e-10,"The method 'plot_histogram' is a utility function that generates and saves a histogram from a given iterable of counts. It uses popular libraries like pandas and plotly, which are widely used for data manipulation and visualization. The function is well-defined, with clear input parameters and a straightforward purpose. It also includes functionality to ensure the output directory exists before saving the file, which is a good practice. Given its utility and the fact that it doesn't have any apparent issues or redundancies, it is likely to be retained in the codebase."
survived,"    def exception(self, message: str):
        exc = sys.exc_info()
        formatted = f""{message}\n"" + """".join(traceback.format_exception(*exc))
        self.error(formatted)
",webscout/litlogger/logger.py,Logger,1,1.3440409770490404e-08,"The method 'exception' is a utility function designed to handle exceptions by formatting the exception information and logging it using the 'self.error' method. This is a common pattern in logging and error handling, making it a useful method for debugging and maintaining code. It is likely to be retained as it provides a clear and structured way to handle exceptions, which is essential in robust software development."
survived,"    def debug(self, message: str):
        self.log(LogLevel.DEBUG, message)
",webscout/litlogger/logger.py,Logger,1,1.522997951276035e-08,"The method 'debug' is a simple utility function that logs a message at the DEBUG level. Such methods are commonly used in logging frameworks to provide a convenient way to log messages at different levels of severity. Given its utility in debugging and the fact that it is a wrapper around a more generic logging function, it is likely to be retained in the codebase for ease of use and consistency in logging practices."
survived,"    async def _log_async(self, level: LogLevel, message: str):
        if not self._should_log(level):
            return
        record = self._format(level, message)
        tasks = []
        for h in self.handlers:
            if level >= h.level:
                if asyncio.iscoroutinefunction(h.emit):
                    tasks.append(h.emit(record, level))
                else:
                    tasks.append(asyncio.to_thread(h.emit, record, level))
        if tasks:
            await asyncio.gather(*tasks)
",webscout/litlogger/logger.py,Logger,1,5.905303995456778e-10,"The method '_log_async' is an asynchronous logging function that checks if a message should be logged based on its level, formats the log record, and then dispatches it to the appropriate handlers. It uses asyncio to handle both coroutine and non-coroutine emit functions, ensuring that logging operations do not block the event loop. This method is well-structured for asynchronous environments, making it efficient for applications that require non-blocking logging. Given the increasing use of asynchronous programming in Python, this method is likely to be useful and relevant, thus it will survive."
survived,"    def __enter__(self):
        return self
",webscout/litlogger/logger.py,Logger,1,1.3440409770490404e-08,"The method is a part of the context management protocol in Python, specifically the implementation of the `__enter__` method. This method is essential for objects that are intended to be used with the `with` statement, which is a common and useful pattern for resource management (like opening files, network connections, etc.). Since this method is a standard part of implementing context managers, it is unlikely to be deleted unless the entire context management functionality is being removed, which is highly improbable. Therefore, the method will survive."
survived,"    async def fetch_and_replace() -> None:
        try:
            models = await asyncio.to_thread(load_from_url, url)
            built_in_models[:] = models
        except Exception:
            pass
",libs/core/kiln_ai/adapters/remote_config.py,,1,7.194132978569833e-09,"The method 'fetch_and_replace' is an asynchronous function that fetches data from a URL and replaces the contents of 'built_in_models' with the fetched data. It uses 'asyncio.to_thread' to run the blocking 'load_from_url' function in a separate thread, which is a modern and efficient way to handle I/O-bound operations in asynchronous code. The method also includes exception handling to prevent the program from crashing if an error occurs during the fetch operation. These characteristics make the method useful and relevant in asynchronous programming contexts, suggesting it will likely be retained."
survived,"def deserialize_config(path: str | Path) -> List[KilnModel]:
    raw = json.loads(Path(path).read_text())
    model_data = raw.get(""model_list"", raw if isinstance(raw, list) else [])
    return [KilnModel.model_validate(item) for item in model_data]
",libs/core/kiln_ai/adapters/remote_config.py,,1,1.2501528648238603e-09,The method 'deserialize_config' is likely to survive because it performs a useful function of reading and deserializing configuration data from a file into a list of 'KilnModel' objects. This is a common requirement in many applications where configuration data is stored in JSON format. The method is also flexible in handling different input types (str or Path) and different JSON structures (a dictionary with a 'model_list' key or a direct list). These features make it a versatile and reusable utility function.
survived,"async def test_load_remote_models_failure(monkeypatch):
    original = built_in_models.copy()

    def fake_fetch(url):
        raise RuntimeError(""fail"")

    monkeypatch.setattr(""kiln_ai.adapters.remote_config.load_from_url"", fake_fetch)

    load_remote_models(""http://example.com/models.json"")
    await asyncio.sleep(0.01)
    assert built_in_models == original",libs/core/kiln_ai/adapters/test_remote_config.py,,1,1.3440409770490404e-08,"The method is a test function that uses monkeypatching to simulate a failure scenario when loading remote models. It checks if the built-in models remain unchanged after a simulated failure in fetching remote models. This is a valid and useful test case to ensure the robustness of the system against network failures. Therefore, it is likely to be retained as part of the test suite."
survived,"        def run(self) -> None:
            print(""OpenAI Agents bridge disabled."")
",alpha_factory_v1/demos/aiga_meta_evolution/openai_agents_bridge.py,AgentRuntime,0,0.9999999928058669,"The method 'run' only contains a print statement that outputs a message indicating that a feature (OpenAI Agents bridge) is disabled. This suggests that the method might be a placeholder or a temporary implementation. Without any functional code or logic, it doesn't contribute to the functionality of the class or module it belongs to. Such methods are often removed during code cleanup or refactoring to maintain code quality and readability. Therefore, it is likely to be deleted."
survived,"        def register(self, *_: object, **__: object) -> None:
            pass
",alpha_factory_v1/demos/aiga_meta_evolution/openai_agents_bridge.py,AgentRuntime,0,0.9999999918479795,"The method 'register' is defined but does nothing as it only contains a 'pass' statement. This suggests that it might be a placeholder for future implementation. However, without any additional context or usage, it is likely to be considered dead code. In many codebases, such methods are eventually removed if they are not implemented or used, as they do not contribute any functionality. Therefore, the method is more likely to be deleted."
survived,"def test_save_and_load(tmp_path):
    scraper = AutoScraper()
    scraper.build(html=HTML, wanted_list=[""Banana""])
    file_path = tmp_path / ""model.json""
    scraper.save(file_path)
    new_scraper = AutoScraper()
    new_scraper.load(file_path)
    assert new_scraper.get_result_exact(html=HTML) == scraper.get_result_exact(html=HTML)
",tests/unit/test_features.py,,1,1.2501528648238603e-09,"The method 'test_save_and_load' is a unit test designed to verify the functionality of saving and loading a model in the AutoScraper library. It ensures that the scraper can be saved to a file and then loaded back, maintaining the same results. This is a crucial feature for any machine learning or data processing library, as it allows users to persist their models and reuse them without rebuilding. The test is well-structured, using temporary paths to avoid side effects, and it includes assertions to validate the functionality. Therefore, this method is likely to be retained as it provides essential test coverage for a core feature."
survived,"def test_build_with_regex():
    scraper = AutoScraper()
    scraper.build(html=HTML_COMPLEX, wanted_list=[re.compile(""Ban.*"")])
    result = scraper.get_result_exact(html=HTML_COMPLEX)
    assert ""Banana"" in result[0]
",tests/integration/test_complex_features.py,,1,1.1253518384332553e-07,"The method 'test_build_with_regex' is a unit test for the 'AutoScraper' class, specifically testing its ability to build a scraper using a regular expression to identify desired elements in HTML content. Unit tests are crucial for ensuring code reliability and functionality, especially when dealing with complex data extraction tasks. The use of regular expressions in web scraping is common and necessary for flexibility in pattern matching. Therefore, this method is likely to be retained as it serves an important role in validating the functionality of the 'AutoScraper' class."
survived,"    async def broadcast_merkle_root(self) -> None:
        root = self.compute_merkle_root()
        if AsyncClient is None:
            _log.info(""Merkle root %s"", root)
            return
        try:
            client = AsyncClient(""https://api.testnet.solana.com"")
            memo_prog = PublicKey(""MemoSq4gqABAXKb96qnH8TysNcWxMyWCqXgDLGmfcHr"")
            tx = Transaction().add(
                TransactionInstruction(program_id=memo_prog, data=root.encode(), keys=[])
            )
            await client.send_transaction(tx)
            _log.info(""Broadcasted Merkle root %s"", root)
        except Exception as exc:  # pragma: no cover - network errors
            _log.warning(""Failed to broadcast Merkle root: %s"", exc)
        finally:
            try:
                await client.close()
            except Exception:  # pragma: no cover - ignore close errors
                pass
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/logging.py,Ledger,1,5.211412485172657e-10,"The method 'broadcast_merkle_root' is likely to survive because it performs a specific and useful function: broadcasting a Merkle root to a Solana testnet. It includes error handling for network issues and ensures the client is closed properly. These features indicate that the method is well-structured and serves a clear purpose, making it valuable in contexts where broadcasting Merkle roots is necessary."
survived,"def test_labels_too_long():
    runner = ScenarioRunner(uri=GMT_DIR, uri_type='folder', filename='tests/data/usage_scenarios/labels_stress_forbidden.yml', skip_system_checks=True, dev_no_metrics=True, dev_no_phase_stats=True, dev_no_sleeps=True, dev_cache_build=True)
    with pytest.raises(RuntimeError) as e:
        with Tests.RunUntilManager(runner) as context:
            context.run_until('setup_services')

    assert ""- value of label 'LABEL_TOO_LONG' is too long 1025 (max allowed length is 1024) - Maybe consider using --allow-unsafe or --skip-unsafe"" == str(e.value), Tests.assertion_info('Label value is too long', str(e.value))
",tests/test_usage_scenario.py,,1,1.522997951276035e-08,"The method 'test_labels_too_long' is a unit test designed to verify that a specific error is raised when a label exceeds the maximum allowed length. This is a common and necessary test to ensure that the system correctly handles input validation and error reporting. Such tests are crucial for maintaining software quality and preventing bugs related to input handling. Therefore, it is unlikely that this method will be deleted as it serves an important purpose in the testing suite."
survived,"def append_pkg_resource_path_KLONGPATH() -> None:
    with importlib.resources.as_file(importlib.resources.files('klongpy')) as pkg_path:
        pkg_lib_path = os.path.join(pkg_path, 'lib')
        klongpath = os.environ.get('KLONGPATH', '.:lib')
        klongpath = f""{klongpath}:{pkg_lib_path}"" if klongpath else str(pkg_lib_path)
        os.environ['KLONGPATH'] = klongpath
",klongpy/repl.py,,1,1.6052280526088547e-09,"The method `append_pkg_resource_path_KLONGPATH` is a utility function that modifies the environment variable `KLONGPATH` to include a specific library path from a package. This type of function is often useful in setting up the environment for a package to work correctly, especially in scenarios where the package relies on certain resources being available in the path. Such functions are typically retained as they provide necessary setup functionality for the package to operate as intended. Therefore, it is likely to survive."
survived,"def _get(obj, name):
    if obj is None:
        return None
    if isinstance(obj, dict):
        if name in obj:
            return obj[name]
    if hasattr(obj, name):
        return getattr(obj, name)
    if name == ""items"" and hasattr(obj, ""Items""):
        return getattr(obj, ""Items"")
    if isinstance(obj, (list, tuple)):
        for it in obj:
            try:
                return _get(it, name)
            except Exception:
                pass
    raise Exception(""field not found: "" + name)
",tests/dataset/job/compiler/py/q8.py,,1,3.850741907939403e-09,"The method '_get' is a utility function designed to retrieve a value from an object based on a given name. It handles various types of objects, including dictionaries, objects with attributes, and lists or tuples. This flexibility makes it a useful function for accessing nested data structures, which is a common requirement in many applications. The method also includes error handling to manage cases where the desired field is not found, which is a good practice. Given its utility and robustness, it is likely to be retained in the codebase."
survived,"def _min(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""min() expects list or group"")
    vals = [it for it in v if it is not None]
    if not vals:
        return 0
    return min(vals)
",tests/dataset/job/compiler/py/q8.py,,1,1.7603431343301488e-06,"The method '_min' is a custom implementation of the built-in 'min' function with additional handling for objects with an 'Items' attribute and filtering out 'None' values. However, it raises an exception if the input is not a list or a group, which might be too restrictive. Despite this, the method provides a specific utility that might be useful in certain contexts where such input handling is required. Therefore, it is likely to survive as it serves a distinct purpose that the built-in 'min' function does not cover."
survived,"def _get(obj, name):
    if obj is None:
        return None
    if isinstance(obj, dict):
        if name in obj:
            return obj[name]
    if hasattr(obj, name):
        return getattr(obj, name)
    if name == ""items"" and hasattr(obj, ""Items""):
        return getattr(obj, ""Items"")
    if isinstance(obj, (list, tuple)):
        for it in obj:
            try:
                return _get(it, name)
            except Exception:
                pass
    raise Exception(""field not found: "" + name)
",tests/dataset/job/compiler/py/q7.py,,1,2.998960815863541e-09,"The method '_get' is a utility function designed to retrieve a value from an object based on a given name. It handles various types of objects, including dictionaries, objects with attributes, and lists or tuples. This flexibility makes it a useful function for accessing nested data structures, which is a common requirement in many applications. The method also includes error handling to manage cases where the desired field is not found, which is a good practice. Given its utility and robustness, it is likely to be retained in the codebase."
survived,"def _get(obj, name):
    if obj is None:
        return None
    if isinstance(obj, dict):
        if name in obj:
            return obj[name]
    if hasattr(obj, name):
        return getattr(obj, name)
    if name == ""items"" and hasattr(obj, ""Items""):
        return getattr(obj, ""Items"")
    if isinstance(obj, (list, tuple)):
        for it in obj:
            try:
                return _get(it, name)
            except Exception:
                pass
    raise Exception(""field not found: "" + name)
",tests/dataset/job/compiler/py/q9.py,,1,4.363462233903899e-09,"The method '_get' is a utility function designed to retrieve a value from an object based on a given name. It handles various types of objects, including dictionaries, objects with attributes, and lists or tuples. This flexibility makes it a useful function for accessing nested data structures, which is a common requirement in many applications. The method also includes error handling to manage cases where the desired field is not found, which is a good practice. Given its utility and robustness, it is likely to be retained in the codebase."
survived,"def _min(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""min() expects list or group"")
    vals = [it for it in v if it is not None]
    if not vals:
        return 0
    return min(vals)
",tests/dataset/job/compiler/py/q7.py,,0,0.9993736657839596,"The method '_min' is a custom implementation of the built-in 'min' function with additional handling for objects with an 'Items' attribute and filtering out 'None' values. However, it raises an exception if the input is not a list or a group, which might not be necessary if the input is always expected to be a list. The method could be considered redundant or unnecessary if the built-in 'min' function can be used directly with pre-processing of the input data. Additionally, the method returns 0 for empty lists, which might not be the desired behavior in all cases. These factors suggest that the method might be deleted in favor of using the built-in 'min' function with appropriate input handling."
survived,"def adk_server(monkeypatch: pytest.MonkeyPatch) -> Iterator[Tuple[str, str]]:
    """"""Launch the ADK gateway on a free port and yield the base URL and token.""""""

    port = _free_port()
    token = ""test-token""

    os.environ[""ALPHA_FACTORY_ENABLE_ADK""] = ""1""
    os.environ[""ALPHA_FACTORY_ADK_TOKEN""] = token
    os.environ[""ALPHA_FACTORY_ADK_HOST""] = ""127.0.0.1""
    os.environ[""ALPHA_FACTORY_ADK_PORT""] = str(port)

    from alpha_factory_v1.backend import adk_bridge as _bridge

    # Reload so env vars take effect
    adk_bridge = importlib.reload(_bridge)

    class DummyAgent:
        name = ""dummy""

        def run(self, _prompt: str) -> str:
            return ""ok""

    server: Any | None = None
    thread: threading.Thread | None = None

    def patched_run(app: Any, host: str, port: int, log_level: str = ""info"", **kw: Any) -> None:
        nonlocal server, thread
        config = uvicorn.Config(app, host=host, port=port, log_level=log_level, **kw)
        server = uvicorn.Server(config)
        thread = threading.Thread(target=server.run, daemon=True)
        thread.start()
        for _ in range(50):
            if server.started:
                break
            time.sleep(0.1)

    monkeypatch.setattr(uvicorn, ""run"", patched_run)

    adk_bridge.auto_register([DummyAgent()])
    adk_bridge.maybe_launch()

    assert thread is not None and server is not None

    yield f""http://127.0.0.1:{port}"", token

    server.should_exit = True
    thread.join(timeout=5)

    for var in (
        ""ALPHA_FACTORY_ENABLE_ADK"",
        ""ALPHA_FACTORY_ADK_TOKEN"",
        ""ALPHA_FACTORY_ADK_HOST"",
        ""ALPHA_FACTORY_ADK_PORT"",
    ):
        os.environ.pop(var, None)
",tests/test_adk_gateway.py,,1,6.348800075736417e-09,"The method `adk_server` is a utility function designed for testing purposes, specifically to set up a test environment for the ADK gateway using pytest's monkeypatching capabilities. It is a specialized function that is likely used in a specific testing context, such as integration tests for the ADK gateway. Such functions are typically retained as long as the testing framework and the components being tested remain relevant. Since the function is well-defined, uses standard testing practices, and there is no indication of it being deprecated or replaced, it is likely to survive."
survived,"def register(cls=None, *, condition=True):  # type: ignore
    """"""Decorator adding an :class:`AgentBase` subclass to the registry.""""""

    def decorator(inner_cls):
        from_backend_base = _agent_base()
        if not issubclass(inner_cls, from_backend_base):
            raise TypeError(""register() only allowed on AgentBase subclasses"")

        cond_result = condition() if callable(condition) else bool(condition)
        if cond_result:
            meta = AgentMetadata(
                name=getattr(inner_cls, ""NAME"", inner_cls.__name__),
                cls=inner_cls,
                version=getattr(inner_cls, ""__version__"", ""0.1.0""),
                capabilities=list(getattr(inner_cls, ""CAPABILITIES"", [])),
                compliance_tags=list(getattr(inner_cls, ""COMPLIANCE_TAGS"", [])),
                requires_api_key=getattr(inner_cls, ""REQUIRES_API_KEY"", False),
            )
            _register(meta, overwrite=False)
        else:
            logger.info(
                ""Agent %s not registered (condition=false)"",
                getattr(inner_cls, ""NAME"", inner_cls.__name__),
            )
        return inner_cls

    return decorator(cls) if cls is not None else decorator
",alpha_factory_v1/backend/agents/registry.py,,1,3.3982678079468468e-09,"The method 'register' is a decorator function designed to add subclasses of 'AgentBase' to a registry. It includes a condition parameter that allows for conditional registration, which adds flexibility and control over the registration process. The method also logs information when an agent is not registered due to the condition being false. This functionality is useful for managing and organizing agent classes in a system, and the use of decorators is a common and effective pattern in Python for such purposes. Given its utility and the fact that it doesn't have any apparent issues or redundancies, it is likely to be retained in the codebase."
survived,"def _register(meta: AgentMetadata, *, overwrite: bool = False) -> None:
    if not _should_register(meta):
        return
    with _REGISTRY_LOCK:
        if meta.name in AGENT_REGISTRY and not overwrite:
            existing = AGENT_REGISTRY[meta.name]
            try:
                if _parse_version(meta.version) > _parse_version(existing.version):
                    logger.info(
                        ""Overriding agent %s with newer version %s > %s"",
                        meta.name,
                        meta.version,
                        existing.version,
                    )
                    overwrite = True
                else:
                    logger.error(""Duplicate agent name '%s' ignored"", meta.name)
                    return
            except Exception:  # pragma: no cover - version parse failed
                logger.error(""Duplicate agent name '%s' ignored"", meta.name)
                return

        AGENT_REGISTRY[meta.name] = meta
        for cap in meta.capabilities:
            CAPABILITY_GRAPH.add(cap, meta.name)

    logger.info(""\u2713 agent %-18s caps=%s"", meta.name, "","".join(meta.capabilities))
    _emit_kafka(""agent.manifest"", meta.to_json())
",alpha_factory_v1/backend/agents/registry.py,,1,3.2241866333029355e-08,"The method '_register' is a crucial part of the system's functionality as it handles the registration of agents, ensuring that they are properly added to the registry and that their capabilities are recorded. It also manages version control by checking if a newer version of an agent should overwrite an existing one. Additionally, it logs important information and emits events for further processing. These functionalities are essential for maintaining the integrity and efficiency of the agent management system, making it unlikely for this method to be deleted."
survived,"    def _parse_version(v: str):
        return tuple(int(p) for p in v.split(""."") if p.isdigit())
",alpha_factory_v1/backend/agents/registry.py,,1,3.2241866333029355e-08,"The method _parse_version is a utility function that converts a version string into a tuple of integers. This is a common requirement in software development for comparing version numbers. The function is simple, efficient, and serves a clear purpose. It is likely to be used in various parts of a codebase where version comparison is needed. Therefore, it is unlikely to be deleted unless there is a significant change in how versioning is handled in the project."
survived,"    def instantiate(self, **kw):
        return self.cls(**kw)  # type: ignore[arg-type]
",alpha_factory_v1/backend/agents/registry.py,AgentMetadata,1,1.8189616842444243e-09,"The method 'instantiate' is a simple utility function that creates an instance of a class using keyword arguments. This is a common pattern in Python, especially when dealing with dynamic class instantiation or dependency injection. The use of 'type: ignore[arg-type]' suggests that the developer is aware of potential type checking issues but has chosen to bypass them, possibly due to the dynamic nature of the code. This method is likely to be useful in various contexts where flexibility in object creation is needed, and there is no indication of it being deprecated or replaced by a better alternative. Therefore, it is likely to survive."
survived,"    async def step(self) -> None:
        await asyncio.sleep(self.SLEEP)
",alpha_factory_v1/backend/agents/registry.py,StubAgent,1,2.646573631904765e-09,"The method 'step' is an asynchronous function that uses 'await asyncio.sleep(self.SLEEP)', which suggests it is part of a larger asynchronous workflow. This method is likely used to introduce a delay or pause in an asynchronous process, which is a common pattern in asynchronous programming to manage timing or rate-limiting tasks. Since it serves a functional purpose in controlling the flow of asynchronous operations, it is likely to be retained in the codebase."
survived,"    def test_int(self):
        r = self.klong(',1')
        self.assertTrue(kg_equal(r, np.asarray([1])))
",tests/test_eval_monad_list.py,TestEvalMonadList,1,1.6052280526088547e-09,"The method `test_int` is a unit test method, which is typically used to verify the functionality of a specific piece of code. Unit tests are crucial for ensuring code reliability and correctness, especially in larger projects. The method is testing the functionality of `self.klong` and `kg_equal`, which suggests it is part of a test suite. Such methods are generally not deleted unless they are redundant or replaced by more comprehensive tests. Since there is no indication that this test is redundant or incorrect, it is likely to be retained."
survived,"    def foo(x: int) -> int:
        return x
",tests/test_function_schema.py,,0,0.9999997897565932,"The method 'foo' is a simple identity function that takes an integer and returns the same integer. While it is functional, it doesn't provide any additional value or transformation to the input, making it redundant in most practical scenarios. Such methods are often considered unnecessary and are likely to be deleted unless they serve a specific purpose in a larger context, such as being a placeholder or part of an interface implementation."
survived,"def apply_env(args: argparse.Namespace) -> None:
    if args.dev:
        os.environ[""DEV_MODE""] = ""true""
    if args.port is not None:
        os.environ[""PORT""] = str(args.port)
    if args.metrics_port is not None:
        os.environ[""METRICS_PORT""] = str(args.metrics_port)
    if args.a2a_port is not None:
        os.environ[""A2A_PORT""] = str(args.a2a_port)
    if args.enabled is not None:
        os.environ[""ALPHA_ENABLED_AGENTS""] = args.enabled
    if args.loglevel:
        os.environ[""LOGLEVEL""] = args.loglevel.upper()
",alpha_factory_v1/run.py,,1,2.3355930333443423e-09,"The method 'apply_env' is a utility function that sets environment variables based on the command-line arguments provided. This is a common pattern in applications that need to configure their runtime environment dynamically. The method is straightforward, performs a useful task, and is likely to be used in various scenarios where environment configuration is necessary. There are no apparent issues or redundancies in the code, and it aligns with typical practices for handling environment variables in Python applications. Therefore, it is likely to be retained in the codebase."
survived,"async def summarize_thread(thread_ts: str, conversation: list[ModelMessage]) -> str:
    """"""Summarize a Slack conversation and store the result.""""""

    summary = await summarize_async(""\n\n"".join(m.content for m in conversation))

    add_asset_metadata(
        THREAD_SUMMARY,
        {
            ""thread_ts"": thread_ts,
            ""message_count"": len(conversation),
            ""timestamp"": datetime.now().isoformat(),
        },
    )

    return summary",examples/slackbot/src/slackbot/assets.py,,1,4.0586521248284276e-10,"The method 'summarize_thread' is likely to survive because it performs a useful function of summarizing a conversation thread, which is a common requirement in applications dealing with messaging or communication platforms like Slack. The method is asynchronous, which is suitable for handling potentially long-running operations like summarization. Additionally, it includes metadata storage, which is useful for tracking and auditing purposes. These features make it a valuable part of a system that processes and manages conversation data."
survived,"    def __init__(self, dim: int | None = None) -> None:
        super().__init__()
        self.dim = dim
",src/raglite/_typing.py,DuckDBVec,1,9.931195248674785e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting initial values for attributes. The use of a constructor is standard practice in class definitions, and there is no indication that this particular constructor is redundant or unnecessary. Therefore, it is unlikely to be deleted."
deleted,"    def _is_postgres(self) -> bool:
        return isinstance(self.type, HalfVec)
",src/raglite/_typing.py,EmbeddingComparator,0,0.9999997897565932,"The method `_is_postgres` is likely to be deleted because its implementation does not align with its name. The method name suggests it should check if something is related to PostgreSQL, but it instead checks if `self.type` is an instance of `HalfVec`, which seems unrelated to PostgreSQL. This mismatch indicates that the method is either incorrectly named or implemented, leading to potential confusion and redundancy in the codebase."
survived,"def test_docs_bundle_integrity() -> None:
    bundle = DOCS_DIR / ""insight.bundle.js""
    if not bundle.is_file():
        pytest.skip(""insight.bundle.js missing"")
    html = (DOCS_DIR / ""index.html"").read_text()
    match = re.search(r""<script[^>]*src=['\""]insight.bundle.js['\""][^>]*>"", html)
    assert match, ""insight.bundle.js script tag missing""
    tag = match.group(0)
    integrity = re.search(r""integrity=['\""]([^'\""]+)['\""]"", tag)
    assert integrity, ""integrity attribute missing""
    expected = _sha384(bundle)
    assert integrity.group(1) == expected",tests/test_docs_bundle_hash.py,,1,8.152020648014727e-09,"The method `test_docs_bundle_integrity` is a test function that checks the integrity of a JavaScript bundle file in a documentation directory. It ensures that the file exists, is referenced correctly in an HTML file, and that its integrity hash matches the expected value. This is a useful test for maintaining the integrity and security of web assets, especially in environments where content delivery and security are critical. Such tests are important for automated testing and continuous integration processes, making it unlikely to be deleted unless the project undergoes significant changes that render the test obsolete."
survived,"    def close(cls) -> None:
        rt = cls._runtime
        if not rt:
            return
        fn = getattr(rt, ""shutdown"", None)
        if not callable(fn):
            fn = getattr(rt, ""close"", None)
        if callable(fn):
            try:
                fn()
            except Exception:  # noqa: BLE001
                log.exception(""OpenAI runtime shutdown failed"")
",alpha_factory_v1/backend/orchestrator.py,_OAI,1,1.725782769012759e-08,"The method 'close' is designed to safely shut down or close a runtime object associated with the class. It checks if the runtime object exists and attempts to call its 'shutdown' or 'close' method if available. The method also includes exception handling to log any errors that occur during the shutdown process. This is a robust and necessary utility function for managing resources and ensuring graceful shutdowns, which is a common requirement in software systems. Therefore, it is likely to be retained in the codebase."
survived,"def _run_deploy_script(tmp_path: Path, env_vars: dict[str, str]) -> str:
    script = Path(
        ""alpha_factory_v1/demos/alpha_asi_world_model/deploy_alpha_asi_world_model_demo.sh""
    )
    assert script.exists(), script
    bin_dir = tmp_path / ""bin""
    bin_dir.mkdir()
    capture = tmp_path / ""env.txt""
    _write_executable(
        bin_dir / ""python"",
        ""#!/usr/bin/env bash\nprintenv > \""$CAPTURE\""\n"",
    )
    env = os.environ.copy()
    env.update(env_vars)
    env.update({""PATH"": f""{bin_dir}:{os.environ.get('PATH', '')}"", ""CAPTURE"": str(capture)})
    subprocess.run([""bash"", str(script)], env=env, check=True, timeout=5)
    return capture.read_text()
",tests/test_world_model_safety.py,,1,4.363462233903899e-09,"The method '_run_deploy_script' is a utility function that automates the deployment of a script by setting up a temporary environment and capturing environment variables. It is a specialized function that is likely used in a specific context, such as testing or deployment automation. The function is well-structured, uses standard libraries, and performs a clear task. There is no indication that it is obsolete or redundant, and it seems to fulfill a necessary role in its context. Therefore, it is likely to be retained in the codebase."
survived,"    def test_summary_with_openai_mock(self) -> None:
        completion = SimpleNamespace(
            choices=[SimpleNamespace(message=SimpleNamespace(content=""ok""))]
        )
        with patch.dict(os.environ, {""OPENAI_API_KEY"": ""sk-test""}):
            with patch(""openai.OpenAI"") as mock_client:
                mock_client.return_value.chat.completions.create.return_value = completion
                text = summarise_with_agent(
                    0.9,
                    agents=5,
                    rounds=10,
                    delta=0.8,
                    stake=1.0,
                )
        self.assertEqual(text, ""ok"")
",tests/test_governance_sim.py,TestGovernanceSim,1,3.850741907939403e-09,"The method 'test_summary_with_openai_mock' is a unit test designed to test the functionality of a function 'summarise_with_agent' by mocking the OpenAI API client. This is a common practice in software development to ensure that code behaves as expected without making actual API calls, which can be costly and time-consuming. The method is well-structured, uses mocking effectively, and serves a clear purpose in the testing suite. Therefore, it is likely to be retained in the codebase as it contributes to the robustness and reliability of the software."
survived,"    async def restart(self, bus: object, ledger: object) -> None:
        if self.task:
            self.task.cancel()
            with contextlib.suppress(asyncio.CancelledError):
                await self.task
        try:
            close = getattr(self.agent, ""close"")
        except AttributeError:
            pass
        else:
            close()
        self.agent = self.cls(bus, ledger)
        self.error_count = 0
        self.restarts += 1
        self.restart_streak += 1
        self.start(bus, ledger)
",alpha_factory_v1/backend/agent_supervisor.py,AgentRunner,1,7.05287985061473e-11,"The method 'restart' is likely to survive because it contains essential functionality for restarting a process or service. It handles task cancellation, error suppression, and reinitialization of an agent object, which are common and necessary operations in asynchronous programming. Additionally, it includes error handling and state management, which are crucial for robust software design. These factors suggest that the method is well-structured and serves a critical purpose, making it unlikely to be deleted."
survived,"    async def drive() -> float:
        guard = asyncio.create_task(orchestrator._regression_guard(runners))
        start = time.time()
        for v in [1.0, 0.7, 0.5, 0.3]:
            metrics.dgm_best_score.set(v)
            await asyncio.sleep(0.2)
        await asyncio.sleep(0.5)
        duration = time.time() - start
        guard.cancel()
        with contextlib.suppress(asyncio.CancelledError):
            await guard
        return duration
",tests/test_governance.py,,1,4.944450477491054e-09,"The method 'drive' is likely to survive because it is an asynchronous function that performs a series of operations, including setting metrics and managing an asynchronous task with a guard. It uses asyncio features effectively, such as creating tasks, sleeping asynchronously, and handling task cancellation. These are common patterns in asynchronous programming, suggesting that the method is well-structured for its purpose. Additionally, it returns a float value representing the duration, which could be useful for performance monitoring or logging."
survived,"def _pareto_ranks(pop: Sequence[Any]) -> list[int]:
    metrics = [_metrics(p) for p in pop]
    ranks = [1 for _ in pop]
    for i, a in enumerate(metrics):
        for j, b in enumerate(metrics):
            if i == j:
                continue
            if all(bk <= ak for bk, ak in zip(b, a)) and any(bk < ak for bk, ak in zip(b, a)):
                ranks[i] += 1
    return ranks
",src/simulation/selector.py,,1,1.6052280526088547e-09,"The method '_pareto_ranks' is a utility function that calculates Pareto ranks for a population based on certain metrics. This type of function is often used in multi-objective optimization problems to determine the dominance of solutions. The function appears to be correctly implemented, iterating over pairs of solutions to compare their metrics and adjust ranks accordingly. Such functions are generally useful in optimization and evolutionary algorithms, and unless there is a specific reason to remove it (such as redundancy or a better alternative), it is likely to be retained. Therefore, it is predicted to survive."
survived,"    def critique(self, text: str) -> float:
        """"""Return a score in [0,1] based on word overlap with :data:`_WORDS`.""""""
        tokens = re.findall(r""[a-zA-Z']+"", text.lower())
        if not tokens:
            return 0.0
        good = sum(1 for t in tokens if t in self._WORDS)
        return good / len(tokens)",src/agents/reviewer_agent.py,ReviewerAgent,1,1.1032560311263802e-09,"The method 'critique' is likely to survive because it provides a clear and useful functionality: it calculates a score based on the overlap of words in a given text with a predefined set of words (_WORDS). This can be useful in various applications such as text analysis, content filtering, or language processing. The method is straightforward, efficient, and does not have any apparent issues that would necessitate its removal."
survived,"    async def set_stake(req: StakeRequest, _: None = Depends(verify_token)) -> StakeResponse | JSONResponse:
        """"""Register ``req.agent_id`` with ``req.amount`` tokens.""""""

        start = time.perf_counter()
        status = ""200""
        try:
            orch = cast(Any, app_f.state.orchestrator)
            if orch is None:
                raise HTTPException(status_code=503, detail=""Orchestrator not running"")
            orch.registry.set_stake(req.agent_id, req.amount)
            return StakeResponse(status=""ok"")
        except HTTPException as exc:
            status = str(exc.status_code)
            return problem_response(exc)
        finally:
            REQ_COUNT.labels(""POST"", ""/stake"", status).inc()
            REQ_LAT.labels(""POST"", ""/stake"").observe(time.perf_counter() - start)
",src/interface/api_server.py,,1,1.2501528648238603e-09,"The method 'set_stake' is well-structured and serves a clear purpose in the application. It handles the registration of stakes with proper error handling and logging. The use of asynchronous programming, dependency injection, and exception handling indicates that it is designed to be robust and efficient. Additionally, it integrates with monitoring tools to track request counts and latency, which is a good practice for maintaining application performance. These factors suggest that the method is likely to be maintained and used in the application, leading to its survival."
survived,"    def __init__(
        self,
        name: str,
        cycle_seconds: int,
        max_cycle_sec: int,
        publish: callable,
        inst: object | None = None,
    ) -> None:
        self.name = name
        self.inst = inst or get_agent(name)
        self.period = getattr(self.inst, ""CYCLE_SECONDS"", cycle_seconds)
        self.spec = getattr(self.inst, ""SCHED_SPEC"", None)
        self.next_ts = 0.0
        self.last_beat = time.time()
        self.task: Optional[asyncio.Task] = None
        self._max_cycle_sec = max_cycle_sec
        self._publish = publish
        self._calc_next()

        with contextlib.suppress(ModuleNotFoundError):
            from openai.agents import AgentContext  # type: ignore[attr-defined]

            if isinstance(self.inst, AgentContext):
                from .telemetry import tracer  # avoid circular import
                from openai.agents import AgentRuntime  # type: ignore[attr-defined]

                runtime = AgentRuntime()
                runtime.register(self.inst)
                atexit.register(runtime.close)
",alpha_factory_v1/backend/agent_runner.py,AgentRunner,1,1.8553915987649156e-07,"The method is a constructor (__init__) for a class, which is a fundamental part of class instantiation in Python. Constructors are essential for initializing object state and are unlikely to be removed unless the class itself is being deprecated or refactored significantly. Additionally, the method includes logic for setting up important attributes and handling optional imports, indicating its importance in the class's functionality."
survived,"                    def edges(self, *, keys=False, data=False):
                        if keys and data:
                            return list(self._edges)
                        if keys:
                            return [(u, v, k) for u, v, k, _ in self._edges]
                        if data:
                            return [(u, v, d) for u, v, _, d in self._edges]
                        return [(u, v) for u, v, _, _ in self._edges]
",alpha_factory_v1/backend/memory_graph.py,GraphMemory._Stub,1,2.1724399346070676e-10,"The method 'edges' is a utility function that provides different views of the edges in a graph, depending on the parameters 'keys' and 'data'. It is a flexible and useful method for users who need to access edge information in various formats. Such utility functions are common in graph-related libraries and are unlikely to be removed unless there is a significant change in the underlying data structure or a better alternative is introduced. Since the method is well-structured and serves a clear purpose, it is likely to survive."
survived,"async def list_products(ctx: EnrichContext) -> list[Product]:
    client = await _client(ctx)
    resp = await client.get(""/products"")
    resp.raise_for_status()
    return [Product(**p) for p in resp.json()]
",examples/shop_api_gateway/app.py,,1,1.4166087846364157e-09,"The method 'list_products' is a well-structured asynchronous function that retrieves a list of products from an API endpoint. It uses modern Python features such as type hinting and asynchronous programming, which are considered best practices. The function is likely to be useful in contexts where non-blocking I/O operations are needed, such as in web applications or services that require efficient data fetching. Given these factors, the method is likely to be retained in the codebase."
survived,"async def get_user(user_id: int):
    user = next((u for u in USERS if u[""id""] == user_id), None)
    if not user:
        raise HTTPException(status_code=404, detail=""User not found"")
    return user
",examples/shop_api_gateway/server.py,,1,1.3440409770490404e-08,"The method 'get_user' is a straightforward and efficient way to retrieve a user from a list of users by their ID. It uses a generator expression to find the user, which is a common and efficient pattern in Python. Additionally, it handles the case where the user is not found by raising an HTTPException with a 404 status code, which is a standard practice in web applications to indicate that a resource was not found. This method is likely to be useful in many applications that need to retrieve user data, and there are no obvious issues or inefficiencies in the code. Therefore, it is likely to be retained."
survived,"async def list_users():
    return USERS
",examples/shop_api_gateway/server.py,,1,2.5109990926928157e-08,"The method 'list_users' is a simple asynchronous function that returns a predefined variable 'USERS'. Without additional context, such as the usage of this method or the definition of 'USERS', it's difficult to determine its utility. However, the method itself is functional and could be useful in contexts where an asynchronous operation is needed to retrieve a list of users. Therefore, unless there are changes in requirements or the method is deemed unnecessary, it is likely to survive."
survived,"def parse_agents_table(path: Path) -> set[str]:
    text = path.read_text().splitlines()
    try:
        start = text.index(""### Key Environment Variables"")
    except ValueError:
        return set()

    table_vars: set[str] = set()
    for line in text[start + 1 :]:
        if line.startswith(""|""):
            match = re.search(r""`([^`]+)`"", line)
            if match:
                table_vars.add(match.group(1))
            continue
        if table_vars:
            break
    return table_vars
",tools/check_env_table.py,,1,1.6918979223288786e-10,"The method 'parse_agents_table' is well-defined and serves a specific purpose of extracting environment variable names from a text file. It handles exceptions gracefully, uses regular expressions effectively, and returns a set of strings, which is a suitable data structure for this task. There is no indication of redundancy or inefficiency that would warrant its deletion. Therefore, it is likely to be retained in the codebase."
survived,"def display(nums):
    s = ""[""
    i = 0
    while i < len(nums):
        if i > 0:
            s = s + "", ""
        s = s + str(nums[i])
        i = i + 1
    s = s + ""]""
    return s
",tests/rosetta/transpiler/Python/boyer-moore-string-search.py,,0,0.9999999397642536,"The method 'display' is a simple implementation of converting a list of numbers into a string representation that mimics the list's appearance. While it is functional, it is not efficient or necessary in Python due to the existence of the built-in 'str' or 'repr' functions that can achieve the same result more concisely and efficiently. Therefore, this method is likely to be deleted in favor of using the built-in functionality."
survived,"def encipher(s, k):
    out = """"
    i = 0
    while i < len(s):
        out = out + shiftRune(s[i:i + 1], k)
        i = i + 1
    return out
",tests/rosetta/transpiler/Python/caesar-cipher-1.py,,1,9.237449576640118e-09,"The method 'encipher' is a simple implementation of a character shifting algorithm, likely a form of Caesar cipher. It iterates over each character in the input string 's', applies a shift using the 'shiftRune' function, and constructs a new string 'out'. This method is straightforward and performs a basic but useful operation in cryptography, which is encoding a string by shifting its characters. Such methods are often retained in codebases for educational purposes, simple encryption tasks, or as utility functions in larger systems. Therefore, it is likely to survive."
survived,"def getBrilliant(digits, limit, countOnly):
    brilliant = []
    count = 0
    pow = 1
    next = 999999999999999
    k = 1
    while k <= digits:
        s = []
        for p in primes:
            if p >= pow * 10:
                break
            if p > pow:
                s = s + [p]
        i = 0
        while i < len(s):
            j = i
            while j < len(s):
                prod = s[i] * s[j]
                if prod < limit:
                    if countOnly:
                        count = count + 1
                    else:
                        brilliant = brilliant + [prod]
                else:
                    if prod < next:
                        next = prod
                    break
                j = j + 1
            i = i + 1
        pow = pow * 10
        k = k + 1
    if countOnly:
        return {""bc"": count, ""next"": next}
    return {""bc"": brilliant, ""next"": next}
",tests/rosetta/transpiler/Python/brilliant-numbers.py,,1,4.4508487281649027e-07,"The method 'getBrilliant' is a utility function that calculates 'brilliant numbers' based on given parameters. It is a specialized function that may not be widely applicable, but it serves a specific purpose for users interested in number theory or similar fields. The function is well-defined, with clear input parameters and a structured output. It is unlikely to be deleted unless it is part of a larger codebase where its functionality is no longer needed or has been replaced by a more efficient algorithm. However, given its specific utility, it is more likely to survive as a niche function."
survived,"def absf(x):
    if x < 0.0:
        return -x
    return x
",tests/rosetta/transpiler/Python/calculating-the-value-of-e.py,,0,0.9999994284997149,"The method 'absf' is a simple implementation of the absolute value function, which is a fundamental mathematical operation. However, Python already provides a built-in function 'abs()' that performs the same operation more efficiently and is widely recognized and used. Therefore, the custom implementation 'absf' is redundant and likely to be deleted in favor of using the built-in 'abs()' function, which is more efficient and standard."
survived,"def mysum(x, y):
    return x + y
",tests/rosetta/transpiler/Python/call-a-function-12.py,,1,1.6052280526088547e-09,"The method 'mysum' is a simple and clear implementation of a function that adds two numbers. It is a fundamental operation and is likely to be used frequently in various contexts where addition is needed. There is no indication of redundancy or inefficiency in the code, and it serves a basic purpose effectively. Therefore, it is likely to be retained."
survived,"def bar(a, b, c):
    print(str(a) + "", "" + str(b) + "", "" + str(c))
",tests/rosetta/transpiler/Python/call-a-function-6.py,,1,5.60279640614594e-09,"The method 'bar' is a simple utility function that prints three arguments separated by commas. It is a basic function that could be useful in various contexts where formatted output is needed. Since it performs a straightforward task without any apparent issues or redundancies, it is likely to be retained in the codebase."
survived,"def chr(n):
    upper = ""ABCDEFGHIJKLMNOPQRSTUVWXYZ""
    lower = ""abcdefghijklmnopqrstuvwxyz""
    if n >= 65 and n < 91:
        return upper[n - 65:n - 64]
    if n >= 97 and n < 123:
        return lower[n - 97:n - 96]
    return ""?""
",tests/rosetta/transpiler/Python/caesar-cipher-1.py,,0,0.9999996533672291,"The method is a custom implementation of the built-in Python function `chr()`, which converts an integer to its corresponding ASCII character. However, this implementation is limited to handling only uppercase and lowercase English letters, and it returns a question mark for any other input. The built-in `chr()` function is more versatile and handles a wider range of Unicode characters. Given that this custom method is less efficient and less comprehensive than the built-in function, it is likely to be deleted in favor of using the built-in `chr()` function."
survived,"def main():
    kinds = ["" "", "" odd "", "" prime ""]
    for kind in kinds:
        print(""First 20"" + kind + ""Brazilian numbers:"")
        c = 0
        n = 7
        while True:
            if isBrazilian(n):
                print(str(n) + "" "")
                c = c + 1
                if c == 20:
                    print(""\n"")
                    break
            if kind == "" "":
                n = n + 1
            else:
                if kind == "" odd "":
                    n = n + 2
                else:
                    while True:
                        n = n + 2
                        if isPrime(n):
                            break
    n = 7
    c = 0
    while c < 100000:
        if isBrazilian(n):
            c = c + 1
        n = n + 1
    print(""The 100,000th Brazilian number: "" + str(n - 1))
",tests/rosetta/transpiler/Python/brazilian-numbers.py,,0,0.9999980052698925,"The method is likely to be deleted because it contains several issues that make it inefficient and potentially incorrect. Firstly, the function relies on undefined functions `isBrazilian` and `isPrime`, which means it cannot run as is. Secondly, the logic for incrementing `n` based on the `kind` is unnecessarily complex and could be simplified. Additionally, the method of finding the 100,000th Brazilian number is inefficient, as it involves a loop that could take a significant amount of time to complete without optimization. These factors suggest that the method is not well-implemented and may be removed or significantly refactored."
survived,"def main():
    pt = ""The five boxing wizards jump quickly""
    print(""Plaintext: "" + pt)
    for key in [0, 1, 7, 25, 26]:
        if key < 1 or key > 25:
            print(""Key "" + str(key) + "" invalid"")
            continue
        ct = encipher(pt, key)
        print(""Key "" + str(key))
        print(""  Enciphered: "" + ct)
        print(""  Deciphered: "" + decipher(ct, key))
",tests/rosetta/transpiler/Python/caesar-cipher-1.py,,0,0.9999998362622821,"The method is likely to be deleted because it contains a logical error in the key validation. The key validation allows a key of 0 and 26, which are effectively no-op keys in a Caesar cipher, resulting in no encryption. This makes the validation incorrect as it should only allow keys from 1 to 25. Additionally, the encipher and decipher functions are not defined within the provided code, which would lead to runtime errors. These issues suggest that the method is not fully functional or correctly implemented, leading to its potential deletion."
survived,"def import_osm(graphdb_filename, osmdb_filename, namespace, slog_strings, profiledb_filename):
    """"""Import an OSM database into a graph database.""""""
    slogs = {}
    for slog_string in slog_strings:
        highway_type, slog_penalty = slog_string.split("":"")
        slogs[highway_type] = float(slog_penalty)
    profiledb = ProfileDB(profiledb_filename) if profiledb_filename else None
    osmdb = OSMDB(osmdb_filename)
    gdb = GraphDatabase(graphdb_filename, overwrite=False)
    gdb_import_osm(gdb, osmdb, namespace, slogs, profiledb)
",pygs/graphserver/cli.py,,1,9.736200303530205e-10,"The method 'import_osm' is a utility function that imports an OpenStreetMap (OSM) database into a graph database. It processes input parameters, including a list of strings that define highway types and their associated penalties, and optionally uses a profile database. The function then calls another function 'gdb_import_osm' to perform the actual import operation. This method is likely to be useful in applications dealing with geographic data and routing, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained in the codebase."
survived,"def _select_softmax(pop: list[_Candidate]) -> _Candidate:
    return select_parent(pop, beta=1.0, gamma=0.0)
",experiments/ablate_selector.py,,1,2.646573631904765e-09,"The method `_select_softmax` is a simple wrapper around the `select_parent` function, providing specific parameters for `beta` and `gamma`. This suggests that it serves a specific purpose or use case where these parameters are fixed. Such utility functions are often kept for convenience and readability, especially if this selection method is used frequently in the codebase. Unless there is a significant change in the requirements or the `select_parent` function itself, this method is likely to survive."
survived,"    def __init__(self, genome: float, fitness: float, novelty: float) -> None:
        self.genome = genome
        self.fitness = fitness
        self.novelty = novelty
",experiments/ablate_selector.py,_Candidate,1,8.152020648014727e-09,"The method is a constructor for a class, which is a fundamental part of object-oriented programming in Python. Constructors are essential for initializing new objects with specific attributes. The use of type annotations for the parameters also suggests that the code is modern and adheres to good coding practices. There is no indication that this method is redundant or unnecessary, so it is likely to be retained."
survived,"    def fake_sleep(sec):
        called.append(sec)
",tests/test_thread_retry.py,,1,5.715002851580502e-07,"The method `fake_sleep` is a simple function that appends the input `sec` to a list called `called`. This function does not perform any actual sleeping or delay, which might be its intended purpose given the name. However, it could be useful for testing purposes where you want to simulate a delay without actually causing one. The function is straightforward and could be useful in certain contexts, especially in testing scenarios where you want to track calls and their parameters. Therefore, it is likely to be retained in the codebase for its utility in such scenarios."
survived,"def test_maybe_launch_starts_uvicorn(stub_adk, monkeypatch):
    """"""maybe_launch should call uvicorn.run when ADK is enabled.""""""
    uvicorn = pytest.importorskip(""uvicorn"")
    from alpha_factory_v1.backend import adk_bridge as module
    module = importlib.reload(module)

    called = {}

    def fake_run(app, host, port, log_level=""info"", **kw):
        called[""app""] = app
        called[""host""] = host
        called[""port""] = port

    monkeypatch.setattr(uvicorn, ""run"", fake_run)

    class DummyThread:
        def __init__(self, target, *a, **k):
            self.target = target

        def start(self):
            self.target()

    monkeypatch.setattr(module.threading, ""Thread"", DummyThread)

    module.maybe_launch(host=""1.2.3.4"", port=1234)
    assert called == {""app"": module._ensure_router().app, ""host"": ""1.2.3.4"", ""port"": 1234}",tests/test_adk_gateway_startup.py,,1,1.3440409770490404e-08,"The method is a test function that verifies the behavior of the 'maybe_launch' function in a specific scenario. It uses mocking to ensure that 'uvicorn.run' is called with the correct parameters when the ADK is enabled. Test functions like this are crucial for ensuring code reliability and are typically retained unless the functionality they test is removed or significantly altered. Since the test is specific and well-defined, it is likely to be maintained as long as the 'maybe_launch' function and its related functionality exist."
survived,"def set_global_setting(key, value):
    conn = get_db()
    c = conn.cursor()
    c.execute('INSERT OR REPLACE INTO global_settings (key, value) VALUES (?, ?)',
              (key, json.dumps(value)))
    conn.commit()
    conn.close()
",users_db.py,,1,7.582560422162384e-10,"The method 'set_global_setting' is likely to survive because it performs a fundamental operation of updating or inserting a key-value pair into a database table. This is a common requirement in applications that need to manage configuration settings or preferences. The use of 'INSERT OR REPLACE' ensures that the operation is idempotent, which is a desirable property in database operations. Additionally, the method handles the database connection and cursor management properly, ensuring that resources are released after the operation. These factors contribute to the method's utility and correctness, making it a candidate for retention."
survived,"def fib(n):
    if n < 2:
        return n
    a = 0
    b = 1
    i = n
    i = i - 1
    while i > 0:
        tmp = a + b
        a = b
        b = tmp
        i = i - 1
    return b
",tests/rosetta/transpiler/Python/fibonacci-sequence-2.py,,1,3.653482080241728e-08,"The method implements a well-known algorithm to calculate the nth Fibonacci number using an iterative approach. This is a common and efficient way to compute Fibonacci numbers, especially for larger values of n, as it avoids the exponential time complexity of the recursive approach. The code is clear, concise, and performs its intended function correctly. Therefore, there is no reason to delete this method as it serves a useful purpose and is implemented efficiently."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/fasta-format.py,,1,9.237449576640118e-09,"The method '_now' is a utility function that generates a pseudo-random number based on a seed if '_now_seeded' is True, or returns the current time in nanoseconds if not. This function is useful for generating consistent pseudo-random numbers for testing or other purposes when seeded, and for getting the current time otherwise. Such utility functions are often retained in codebases for their versatility and utility in different scenarios. Therefore, it is likely to survive."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/fibonacci-sequence-4.py,,1,6.348800075736417e-09,"The method '_now' is a utility function that generates a pseudo-random number based on a seed if '_now_seeded' is True, or returns the current time in nanoseconds if not. This function is useful for generating consistent pseudo-random numbers for testing or other purposes when seeded, and for getting the current time otherwise. Such utility functions are often retained in codebases for their flexibility and utility in different scenarios. Therefore, it is likely to survive."
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    old = fs.get(""input.txt"")
    print(""mod time was: "" + str(old))
    mtime = _now()
    mtime = _now()
    fs[""input.txt""] = int(mtime)
    print(""mod time now: "" + str(mtime))
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/file-modification-time.py,,0,0.9999999865595903,"The method is likely to be deleted because it contains redundant and potentially erroneous code. For instance, the variable 'mtime' is assigned twice consecutively with the same function '_now()', which is unnecessary. Additionally, the method lacks error handling, and the use of 'fs' and 'resource' modules is not explained or imported, making the code incomplete and non-functional as it stands. These issues suggest that the method is either a work in progress or not well-maintained, leading to a higher likelihood of deletion."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/execute-hq9+.py,,1,2.3355930333443423e-09,"The method '_now' is a utility function that generates a pseudo-random number based on a seed if '_now_seeded' is True, or returns the current time in nanoseconds otherwise. This function is likely to be useful in scenarios where a consistent pseudo-random number is needed for testing or other purposes, and the fallback to the current time ensures it can still function when not seeded. The method is simple, serves a clear purpose, and does not have any obvious issues that would necessitate its removal. Therefore, it is likely to survive."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/erd-s-selfridge-categorization-of-primes.py,,1,1.0467401685178159e-08,"The method '_now' is a utility function that generates a pseudo-random number based on a seed if '_now_seeded' is True, or returns the current time in nanoseconds otherwise. This method is likely to be useful in scenarios where a consistent pseudo-random number is needed for testing or other purposes, and the fallback to the current time ensures it can still function without a seed. The method is simple, has a clear purpose, and does not have any apparent issues that would necessitate its removal. Therefore, it is likely to be retained in the codebase."
survived,"def lastIndexOf(s, sub):
    idx = 0 - 1
    i = 0
    while i <= len(s) - len(sub):
        if s[i:i + len(sub)] == sub:
            idx = i
        i = i + 1
    sys.exit(idx)
",tests/rosetta/transpiler/Python/file-extension-is-in-extensions-list.py,,0,0.999998629043345,"The method is likely to be deleted because it uses an unconventional approach to return the result by calling sys.exit(idx), which terminates the program instead of returning the index. This is not a standard or user-friendly way to implement such a function. Typically, a function like this should return the index directly, allowing the caller to handle the result appropriately. Additionally, the use of sys.exit() makes the function less reusable and more difficult to integrate into larger applications."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/file-modification-time.py,,1,4.1399375473943306e-08,"The method '_now' is a utility function that generates a pseudo-random number based on a seed if '_now_seeded' is True, otherwise it returns the current time in nanoseconds. This function is likely to be useful in scenarios where a consistent pseudo-random number is needed for testing or other purposes. The use of a global variable '_now_seed' suggests that this function is part of a larger system that requires consistent state management. Given its utility and the fact that it doesn't have any apparent issues or redundancies, it is likely to be retained in the codebase."
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    print(""Hello World!"")
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/execute-snusp.py,,0,0.9999994956527948,"The method is likely to be deleted because it includes benchmarking code that is not necessary for a simple 'Hello World!' program. The use of resource usage and timing is overkill for such a basic function, and it adds unnecessary complexity. Additionally, the method does not take any input or produce any output beyond printing, which limits its utility. In a production environment, such code would likely be simplified or removed to focus on more meaningful functionality."
survived,"def foo():
    print(""let's foo..."")
    a = []
    if 12 >= len(a):
        sys.exit(""runtime error: index out of range [12] with length "" + str(len(a)))
    a[12] = 0
    sys.exit("""")
",tests/rosetta/transpiler/Python/exceptions.py,,0,0.9999993524053853,"The method 'foo' contains a critical flaw where it attempts to access and assign a value to an index (12) of an empty list 'a'. This will always result in an 'index out of range' error, as the list 'a' is initialized as empty and never populated with elements. Additionally, the method uses 'sys.exit' to terminate the program with an error message, which is not a typical or recommended way to handle such errors in Python. Instead, exceptions should be raised and handled appropriately. Due to these issues, the method is likely to be deleted or significantly refactored to correct the logic and error handling."
survived,"def dfs(n, m, i):
    global esths
    if i >= n and i <= m:
        esths = esths + [i]
    if i == 0 or i > m:
        sys.exit()
    d = i % 10
    i1 = i * 10 + d - 1
    i2 = i1 + 2
    if d == 0:
        dfs(n, m, i2)
    else:
        if d == 9:
            dfs(n, m, i1)
        else:
            dfs(n, m, i1)
            dfs(n, m, i2)
",tests/rosetta/transpiler/Python/esthetic-numbers.py,,0,0.999999922655772,"The method is likely to be deleted because it contains several issues that make it unreliable and potentially problematic. Firstly, the use of `sys.exit()` within a recursive function is generally a bad practice as it abruptly terminates the program, which is not ideal for handling errors or stopping recursion. Secondly, the function relies on a global variable `esths`, which can lead to side effects and makes the function non-reentrant and difficult to test. Additionally, the logic of the function is not clear, and it seems to be performing some form of depth-first search without a clear purpose or documentation. These factors suggest that the method is not well-designed or useful in its current form, leading to a high likelihood of it being deleted."
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    r = eulerSum()
    print(str(r[0]) + "" "" + str(r[1]) + "" "" + str(r[2]) + "" "" + str(r[3]) + "" "" + str(r[4]))
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/eulers-sum-of-powers-conjecture.py,,1,1.3440409770490404e-08,"The method is likely to be Survived (1) because it contains a main function that executes a series of operations, including measuring memory usage and execution time, which are common practices in performance benchmarking. The function also outputs results in a structured JSON format, which is useful for logging and analysis. These characteristics suggest that the method is functional and serves a purpose in the context it is used, making it unlikely to be deleted unless the entire benchmarking approach is changed."
survived,"def commatize(n):
    s = str(n)
    res = """"
    i = 0
    while i < len(s):
        if i > 0 and (len(s) - i) % 3 == 0:
            res = res + "",""
        res = res + """".join(s[i:i + 1])
        i = i + 1
    sys.exit(res)
",tests/rosetta/transpiler/Python/file-size-distribution.py,,0,0.9999993524053853,"The method 'commatize' is designed to format a number by inserting commas at every thousandth place. However, it uses 'sys.exit(res)' to return the result, which is unconventional and inappropriate for a function that is supposed to return a string. This approach terminates the program, which is not the expected behavior for a utility function. Instead, it should return the formatted string. This fundamental flaw in the method's design makes it likely to be deleted or significantly refactored."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/esthetic-numbers.py,,1,8.152020648014727e-09,"The method _now() is a utility function that generates a pseudo-random number based on a seed if _now_seeded is True, or returns the current time in nanoseconds otherwise. This function is likely part of a larger system that requires either a deterministic sequence of numbers (when seeded) or a timestamp. Such utility functions are common in systems that need to simulate time or generate predictable sequences for testing purposes. The function is simple, serves a clear purpose, and does not have any apparent issues or redundancies that would necessitate its removal. Therefore, it is likely to be retained in the codebase."
survived,"def cosApprox(x):
    term = 1.0
    sum = 1.0
    n = 1
    while n <= 10:
        denom = float(((2 * n - 1) * (2 * n)))
        term = -term * x * x / denom
        sum = sum + term
        n = n + 1
    sys.exit(sum)
",tests/rosetta/transpiler/Python/eulers-identity.py,,0,0.9999546021442518,"The method `cosApprox` is a simple implementation of a cosine approximation using a Taylor series expansion. However, it has a critical flaw: it uses `sys.exit(sum)` to return the result, which is not a standard or appropriate way to return a value from a function. Instead, it should use a `return` statement. This misuse of `sys.exit` makes the function terminate the program unexpectedly, which is not desirable in most cases. Therefore, the method is likely to be deleted or significantly modified to correct this issue."
survived,"def eulerSum():
    pow5 = []
    i = 0
    while i < 250:
        pow5 = pow5 + [i * i * i * i * i]
        i = i + 1
    sums = {}
    x2 = 2
    while x2 < 250:
        x3 = 1
        while x3 < x2:
            s = pow5[x2] + pow5[x3]
            if not (s in sums):
                sums[s] = [x2, x3]
            x3 = x3 + 1
        x2 = x2 + 1
    x0 = 4
    while x0 < 250:
        x1 = 3
        while x1 < x0:
            y = x0 + 1
            while y < 250:
                rem = pow5[y] - pow5[x0] - pow5[x1]
                if rem in sums:
                    pair = sums[rem]
                    a = pair[0]
                    b = pair[1]
                    if x1 > a and a > b:
                        sys.exit([x0, x1, a, b, y])
                y = y + 1
            x1 = x1 + 1
        x0 = x0 + 1
    sys.exit([0, 0, 0, 0, 0])
",tests/rosetta/transpiler/Python/eulers-sum-of-powers-conjecture.py,,0,0.9999996533672291,"The method eulerSum() is a specific implementation that calculates a particular mathematical problem related to sums of fifth powers. It is not a general-purpose utility function and is highly specialized. Such functions are often written for specific problems or competitions and are not typically reused in other contexts. Additionally, the function uses sys.exit() to terminate the program, which is not a common practice in reusable code. Therefore, it is likely to be deleted after its specific use case is resolved."
survived,"def fmt8(x):
    y = floorf(x * 1e+08 + 0.5) / 1e+08
    s = str(y)
    dot = s.find(""."")
    if dot == 0 - 1:
        s = s + "".00000000""
    else:
        decs = len(s) - dot - 1
        while decs < 8:
            s = s + ""0""
            decs = decs + 1
    sys.exit(s)
",tests/rosetta/transpiler/Python/feigenbaum-constant-calculation.py,,0,0.9999999907625504,"The method fmt8 is likely to be deleted because it contains several issues that make it unreliable and potentially problematic. Firstly, it uses the function floorf, which is not defined in the code, leading to a NameError. Secondly, the method uses sys.exit(s) to terminate the program and output the string, which is not a standard or recommended way to return a value from a function. This makes the function's purpose unclear and its usage limited. Additionally, the logic for handling the decimal point and padding zeros is unnecessarily complex and could be simplified. These factors suggest that the method is not well-implemented and may be removed or replaced with a more robust solution."
survived,"def eulerStep(f, x, y, h):
    sys.exit(y + h * f(x, y))
",tests/rosetta/transpiler/Python/euler-method.py,,0,0.9999930377415741,"The method 'eulerStep' is intended to perform a single step of Euler's method for solving ordinary differential equations. However, it uses 'sys.exit' to return the result, which is not appropriate for a function that is supposed to compute and return a numerical result. 'sys.exit' is used to terminate a program, not to return values from a function. This indicates a misunderstanding of the function's purpose or a mistake in implementation. Therefore, the method is likely to be deleted or significantly modified to correct this issue."
survived,"def indexOfSub(s, sub):
    if len(sub) == 0:
        sys.exit(0)
    i = 0
    while i + len(sub) <= len(s):
        if s[i:i + len(sub)] == sub:
            sys.exit(i)
        i = i + 1
    sys.exit(0 - 1)
",tests/rosetta/transpiler/Python/execute-a-markov-algorithm.py,,0,0.9999756997690634,"The method `indexOfSub` is designed to find the index of a substring `sub` within a string `s`. However, it uses `sys.exit()` to return the index, which is unconventional and not practical for most applications. Typically, functions return values using the `return` statement, allowing the calling code to handle the result appropriately. Using `sys.exit()` terminates the program, which is not suitable for a utility function like this. Therefore, the method is likely to be deleted or refactored to use a return statement instead."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/ethiopian-multiplication.py,,1,1.1861120010657661e-08,"The method `_now()` is a utility function that generates a pseudo-random number based on a seed if `_now_seeded` is True, otherwise it returns the current time in nanoseconds. This function is likely part of a larger system that requires a consistent and repeatable sequence of numbers for testing or simulation purposes when seeded, and real-time timestamps otherwise. Such utility functions are common in software development for testing and simulation, and unless there is a specific reason to remove it (such as being replaced by a more efficient or secure method), it is likely to be retained. Therefore, the method will likely survive."
survived,"def p(x, e):
    r = 1.0
    i = 0
    while i < (int(e)):
        r = r * x
        i = i + 1
    return r
",tests/rosetta/transpiler/Python/exponentiation-with-infix-operators-in-or-operating-on-the-base.py,,1,5.42221743297629e-06,"The method 'p' is a simple implementation of calculating the power of a number 'x' raised to 'e'. It uses a loop to multiply 'x' by itself 'e' times, which is a basic and common operation in programming. Although Python has a built-in operator '**' for exponentiation, this method can be useful for educational purposes or in environments where built-in functions are restricted. Therefore, it is likely to survive as it serves a fundamental purpose and is not redundant in all contexts."
survived,"def test_http_app_sets_mcp_server_state():
    server = FastMCP(name=""StateTest"")
    app = server.http_app()
    assert app.state.fastmcp_server is server
",tests/server/test_app_state.py,,1,5.60279640614594e-09,"The method `test_http_app_sets_mcp_server_state` is a unit test that verifies the behavior of the `FastMCP` class, specifically ensuring that the `http_app` method correctly sets the `fastmcp_server` state. Unit tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, this method is likely to be retained as it serves an important role in the development and maintenance process."
survived,"def _write_stub(directory: Path) -> None:
    mod = directory / ""openai_agents""
    mod.mkdir()
    mod_init = mod / ""__init__.py""
    mod_init.write_text(
        """"""
import asyncio
import json
import os
from http.server import BaseHTTPRequestHandler, HTTPServer

class Agent:
    name: str = """"
    tools = []

class OpenAIAgent:
    def __init__(self, *a, base_url=None, **kw):
        self.base_url = base_url

def Tool(*_a, **_k):
    def dec(f):
        return f
    return dec

class AgentRuntime:
    def __init__(self, *a, port=5001, llm=None, api_key=None, **k):
        self.port = int(os.getenv('AGENTS_RUNTIME_PORT', port))
        self._agent = None

    def register(self, agent):
        self._agent = agent

    def run(self):
        agent = self._agent
        if agent is None:
            raise RuntimeError('no agent registered')
        port = self.port

        class Handler(BaseHTTPRequestHandler):
            def do_POST(self):
                if self.path == f'/v1/agents/{agent.name}/invoke':
                    length = int(self.headers.get('content-length', '0'))
                    body = self.rfile.read(length)
                    try:
                        payload = json.loads(body or '{}')
                    except json.JSONDecodeError:
                        payload = {}
                    result = asyncio.run(agent.policy(payload, None))
                    data = json.dumps(result).encode()
                    self.send_response(200)
                    self.send_header('Content-Type', 'application/json')
                    self.end_headers()
                    self.wfile.write(data)
                else:
                    self.send_response(404)
                    self.end_headers()

            def log_message(self, *_):
                pass

        server = HTTPServer(('127.0.0.1', port), Handler)
        try:
            server.serve_forever()
        except KeyboardInterrupt:
            pass
        finally:
            server.server_close()
""""""
    )
",tests/test_aiga_workflow.py,,1,1.6052280526088547e-09,"The method `_write_stub` is responsible for creating a directory and writing a Python module with a specific structure and content. This kind of functionality is often used in code generation, scaffolding, or setting up a project with predefined templates. Such methods are typically useful in development environments where repetitive setup tasks need to be automated. Given its utility in automating the creation of a specific module structure, it is likely to be retained unless the requirements or the structure of the project change significantly. Therefore, the method is likely to survive."
survived,"def test_agents_import_fallback(monkeypatch, present):
    """"""Ensure modules import with either package name.""""""
    missing = ""agents"" if present == ""openai_agents"" else ""openai_agents""

    stub = types.ModuleType(present)
    stub.Agent = object
    stub.AgentRuntime = object

    class DummyAgent:
        pass

    stub.OpenAIAgent = DummyAgent

    def _tool(*_a, **_k):
        def _decorator(func):
            return func

        return _decorator

    stub.Tool = _tool

    monkeypatch.setitem(sys.modules, present, stub)
    monkeypatch.delitem(sys.modules, missing, raising=False)

    orig_import = builtins.__import__

    def fake_import(name, globals=None, locals=None, fromlist=(), level=0):
        if name == missing:
            raise ModuleNotFoundError(name)
        return orig_import(name, globals, locals, fromlist, level)

    monkeypatch.setattr(builtins, ""__import__"", fake_import)

    for mod_name in MODULES:
        mod = importlib.reload(importlib.import_module(mod_name))
        assert mod.OpenAIAgent is stub.OpenAIAgent
        if mod_name.endswith(""utils""):
            llm = mod.build_llm()
            assert isinstance(llm, stub.OpenAIAgent)",tests/test_agents_fallback.py,,1,3.927863699585036e-07,The method 'test_agents_import_fallback' is a test function that ensures the correct import behavior of modules when either 'agents' or 'openai_agents' is present. It uses monkeypatching to simulate different import scenarios and checks if the modules can be reloaded correctly. This is a typical use case in testing to ensure robustness against changes in module availability. Such test functions are crucial for maintaining code reliability and are unlikely to be deleted unless the functionality they test becomes obsolete or is replaced by a different mechanism.
survived,"def test_hello_world_template_registered() -> None:
    reg = TemplateRegistry()
    templates = {t[""slug""] for t in reg.list_templates()}
    assert ""hello-world"" in templates
    content = reg.load_template(""hello-world"")
    assert content and ""Hello"" in content
",tests/test_hello_world_template.py,,1,5.60279640614594e-09,"The method `test_hello_world_template_registered` is a unit test that checks if a template with the slug 'hello-world' is registered and contains the word 'Hello'. This is a typical test case to ensure that a specific template is correctly registered and loaded in the system. Such test cases are crucial for maintaining the integrity of the template registry functionality. Therefore, it is unlikely to be deleted as it serves a clear purpose in verifying the system's behavior."
survived,"    def do_rollout(self) -> list[RolloutGroup]:  # pragma: no cover - abstract
        """"""Produce one or more rollout groups.

        Subclasses implement their rollout logic here as a regular function
        without needing to worry about ``async``/``await`` semantics.
        """"""

        raise NotImplementedError
",marin/rl/env.py,SimpleEnv,1,8.76424914819242e-08,"The method `do_rollout` is defined as an abstract method, indicated by the comment `# pragma: no cover - abstract` and the `raise NotImplementedError` statement. This suggests that the method is intended to be overridden by subclasses, providing specific implementations for the rollout logic. Abstract methods are typically not deleted because they serve as a contract for subclasses to implement specific functionality. Therefore, the method is likely to survive."
survived,"def iter_rollout_groups(root_path: str) -> Iterator[RolloutGroup]:
    """"""Yield :class:`RolloutGroup` objects stored under *root_path*.

    Groups are reconstructed on a *best-effort* basis using the serialized group
    metadata.  If multiple rollouts share identical ``group_metadata_json`` they
    will be packed into the same :class:`RolloutGroup`.
    """"""

    fs, dataset_root = pafs.FileSystem.from_uri(root_path)

    dataset = ds.dataset(dataset_root, format=""parquet"", filesystem=fs)

    # We'll accumulate rows with identical group metadata together.
    pending: dict[str, RolloutGroup] = {}

    # Iterate over record batches to avoid loading the full dataset in memory.
    for batch in dataset.to_batches():
        for record in batch.to_pylist():
            gid: str = record[""id""]
            source: str = record[""source""]
            created: float = record[""created""]
            group_meta_json: str = record[""group_metadata_json""]
            rollout_meta_json: str = record[""rollout_metadata_json""]

            turns = []
            for t in record[""turns""]:
                turns.append(
                    Turn(
                        message=t[""message""],
                        role=t[""role""],
                        logprobs=t.get(""logprobs""),
                        reward=t.get(""reward""),
                        inference_metadata=json.loads(t[""inference_metadata_json""]),
                    )
                )

            rollout = Rollout(
                turns=turns,
                metadata=json.loads(rollout_meta_json),
            )

            if gid not in pending:
                pending[gid] = RolloutGroup(
                    id=gid,
                    source=source,
                    created=created,
                    rollouts=[rollout],
                    metadata=json.loads(group_meta_json),
                )
            else:
                grp = pending[gid]
                pending[gid] = RolloutGroup(
                    id=gid,
                    source=source,
                    created=created,
                    rollouts=[*grp.rollouts, rollout],
                    metadata=grp.metadata,
                )

    yield from pending.values()",marin/rl/parquet_store.py,,1,4.363462233903899e-09,"The method `iter_rollout_groups` is a utility function designed to yield `RolloutGroup` objects from a dataset stored in a specified path. It efficiently processes data in batches to avoid memory overload, which is a common requirement in data processing tasks. The method is well-documented, follows a clear logic, and uses standard libraries and data structures effectively. There is no indication of redundancy or obsolescence in its functionality, and it serves a specific purpose in data handling, making it likely to be retained in the codebase."
survived,"    def __iter__(self):
        return iter(self.turns)
",marin/rl/types.py,Rollout,1,1.3440409770490404e-08,"The method `__iter__` is a standard Python method used to make an object iterable. It returns an iterator object, which in this case is created by calling `iter(self.turns)`. This suggests that `self.turns` is a collection (like a list or a tuple) that the class wants to allow iteration over. Since making objects iterable is a common and useful feature in Python, especially for classes that represent collections or sequences, this method is likely to be retained. It provides a clear and Pythonic way to iterate over the elements of `self.turns`, enhancing the usability of the class."
survived,"def main() -> None:
    runtime = AgentRuntime(api_key=None)
    agent = WorkflowAgent()
    runtime.register(agent)
    print(""Registered WorkflowAgent with runtime"")

    if ADK_AVAILABLE:
        auto_register([agent])
        maybe_launch()
        print(""WorkflowAgent exposed via ADK gateway"")

    runtime.run()
",alpha_factory_v1/demos/aiga_meta_evolution/workflow_demo.py,,1,4.944450477491054e-09,"The method 'main' is a typical entry point for a Python script, setting up and running an agent within a runtime environment. It includes conditional logic to handle different scenarios, such as the availability of ADK, which suggests it is designed to be flexible and adaptable to different environments. The method is well-structured and serves a clear purpose in initializing and running the application. There is no indication of redundancy or obsolescence, and it appears to be a crucial part of the application's functionality. Therefore, it is likely to be retained."
survived,"async def fetch_logs() -> list[str]:
    """"""Retrieve the latest orchestrator logs via the REST API.""""""
    resp = requests.get(f""{HOST}/api/logs"", timeout=5)
    resp.raise_for_status()
    return resp.json()
",alpha_factory_v1/demos/alpha_agi_business_v1/openai_agents_bridge.py,,0,0.9999945777812743,"The method is likely to be deleted because it is defined as an asynchronous function using 'async def', but it does not use 'await' for any asynchronous operations. Instead, it uses a synchronous 'requests.get' call, which is not compatible with the asynchronous nature of the function. This inconsistency suggests that the method may be refactored or removed to align with proper asynchronous programming practices."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/bell-numbers.py,,1,7.194132978569833e-09,"The method _now() is a utility function that generates a pseudo-random number based on a seed if _now_seeded is True, or returns the current time in nanoseconds if not. This function is useful for generating consistent pseudo-random numbers for testing or other purposes when seeded, and for getting the current time otherwise. Such utility functions are often retained in codebases for their flexibility and utility in different scenarios. Therefore, it is likely to survive."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/bitmap.py,,1,6.348800075736417e-09,"The method '_now' is a utility function that generates a pseudo-random number based on a seed if '_now_seeded' is True, or returns the current time in nanoseconds if not. This function is useful for generating consistent pseudo-random numbers for testing or other purposes when seeded, and for getting the current time otherwise. Such utility functions are often retained in codebases for their versatility and utility in different scenarios. Therefore, it is likely to survive."
survived,"def _substr(s, start, end):
    return s[start:end]
",tests/rosetta/transpiler/Python/bitmap-read-a-ppm-file.py,,0,0.9999998874648162,"The method _substr is a simple utility function that extracts a substring from a given string 's' using the provided 'start' and 'end' indices. This functionality is already provided by Python's string slicing feature, which is both more intuitive and widely used. Therefore, the method is redundant and likely to be deleted in favor of using the built-in string slicing directly."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/bitmap-b-zier-curves-quadratic.py,,1,1.725782769012759e-08,"The method `_now()` is a utility function that generates a pseudo-random number based on a seed if `_now_seeded` is True, otherwise it returns the current time in nanoseconds. This function seems to be part of a larger system that requires a consistent and repeatable sequence of numbers when seeded, which is a common requirement in simulations or testing environments. The function is simple, serves a clear purpose, and does not have any apparent issues or redundancies that would necessitate its removal. Therefore, it is likely to be retained in the codebase."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/bioinformatics-base-count.py,,1,7.194132978569833e-09,"The method '_now' is a utility function that generates a pseudo-random number based on a seed if '_now_seeded' is True, or returns the current time in nanoseconds otherwise. This method is likely to be used internally within a module or class to provide consistent time-based values or pseudo-random numbers. The use of global variables suggests it is part of a larger system where seeding is controlled elsewhere. Such utility functions are common in systems requiring time or random number generation, and unless there is a specific reason to remove it (such as redundancy or a shift to a different random number generation approach), it is likely to survive."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/bitmap-flood-fill.py,,1,1.1861120010657661e-08,"The method `_now()` is a utility function that generates a pseudo-random number based on a seed if `_now_seeded` is True, otherwise it returns the current time in nanoseconds. This function is likely to be useful in scenarios where a consistent pseudo-random number generation is needed for testing or other purposes. The use of a global variable `_now_seed` suggests that this function is part of a larger system where the seed is set elsewhere, indicating its integration into a broader context. The function is simple, serves a clear purpose, and does not have any apparent issues or redundancies that would necessitate its deletion. Therefore, it is likely to be retained in the codebase."
survived,"    def __str__(self) -> str:  # pragma: no cover - simple formatting
        """"""Return a human-readable Markdown summary.""""""
        lines = [f""# {self.title}""]
        if self.description:
            lines.append(self.description)
        lines.append("""")
        lines.append(f""**Entity count:** {self.entity_count}"")
        if self.entities:
            lines.append("""")
            lines.append(""## Entities"")
            for name in sorted(self.entities):
                lines.append(f""- {name}"")
        lines.append("""")
        lines.append(self.model)
        lines.append("""")
        lines.append(self.usage_hint)
        return ""\n"".join(lines)",src/enrichmcp/datamodel.py,DataModelSummary,1,2.2159489282323004e-08,"The method `__str__` is a standard Python method used to provide a human-readable string representation of an object. In this case, it is used to format the object's attributes into a Markdown summary. This is a common and useful practice for debugging, logging, or displaying object information in a user-friendly way. The method is well-structured, providing clear and organized output, which is beneficial for understanding the object's state. Therefore, it is unlikely to be deleted as it serves a practical purpose."
survived,"def load_df(db_path: str | Path) -> pd.DataFrame:
    """"""Return archive contents as a DataFrame.""""""
    arch = Archive(db_path)
    rows = []
    for a in arch.all():
        rows.append(
            {
                ""id"": a.id,
                ""parent"": a.meta.get(""parent""),
                ""patch"": a.meta.get(""diff"") or a.meta.get(""patch""),
                ""score"": a.score,
            }
        )
    return pd.DataFrame(rows)
",src/interface/lineage_dashboard.py,,1,2.7894680920908113e-10,"The method 'load_df' is likely to survive because it provides a clear and useful functionality: loading data from an archive into a pandas DataFrame. This is a common and necessary operation in data processing and analysis tasks. The method is well-structured, using a loop to extract relevant information from each archive entry and constructing a DataFrame, which is a widely used data structure in Python for data manipulation. Additionally, the use of type hints improves code readability and maintainability. Unless there are changes in the requirements or the context in which this method is used, it is unlikely to be deleted."
survived,"    def heartbeat(self) -> None:
        """"""Invoke a trivial call if available.""""""
        ping = getattr(self._client, ""ping"", None)
        if callable(ping):
            ping()",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/adk_adapter.py,ADKAdapter,1,1.6052280526088547e-09,"The method 'heartbeat' is a simple utility function that checks if the '_client' object has a 'ping' method and calls it if available. This kind of method is often used to keep a connection alive or to check the status of a service. It is a non-intrusive, low-overhead method that can be useful in maintaining the health of a connection or service. Since it serves a practical purpose and does not introduce complexity or side effects, it is likely to be retained in the codebase."
survived,"    def list_profiles(path: str | None = None):
        """"""Return available profile names.""""""
        _path = os.path.expanduser(path or ""~/.dhapi/credentials"")
        if not os.path.exists(_path):
            raise FileNotFoundError(f""{_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."")

        with open(_path, ""r"", encoding=""UTF-8"") as f:
            config = tomli.loads(f.read())

        return list(config.keys())",src/dhapi/port/credentials_provider.py,CredentialsProvider,1,2.0611536181902033e-09,"The method 'list_profiles' is a utility function that reads a configuration file and returns a list of profile names. It is a straightforward and useful function for applications that need to manage or display user profiles stored in a configuration file. The function handles file path expansion, checks for file existence, and reads the file content in a robust manner. These are common and necessary operations in many applications, making the function likely to be retained. Additionally, the use of type hinting and exception handling indicates good coding practices, further supporting its survival."
survived,"def load_tools() -> List[Type[BaseTool]]:
    tools: List[Type[BaseTool]] = []
    pkg_dir = Path(__file__).parent / ""tools""
    for module_info in pkgutil.iter_modules([str(pkg_dir)]):
        module = importlib.import_module(f""{__package__}.tools.{module_info.name}"")
        for attr in module.__dict__.values():
            if isinstance(attr, type) and issubclass(attr, BaseTool) and attr is not BaseTool:
                tools.append(attr)
    return tools
",servers/server_clear_thought/app.py,,1,2.7894680920908113e-10,"The method 'load_tools' is likely to survive because it is a utility function that dynamically loads and returns a list of tool classes from a specified directory. This kind of functionality is useful in scenarios where plugins or extensions are used, allowing for modular and scalable code. The method is well-structured, uses standard library modules like 'pkgutil' and 'importlib', and adheres to good coding practices. There is no indication of deprecated or obsolete practices in the code, suggesting it will remain relevant and useful."
survived,"def test_performance_drop() -> None:
    rng1 = random.Random(1)
    op_good = SelfRewriteOperator(steps=1, rng=rng1, templates=[""meme""], reuse_rate=1.0)
    score_good = len(op_good(""improve quick test""))

    rng2 = random.Random(1)
    op_bad = SelfRewriteOperator(steps=1, rng=rng2, templates=[""meme""], reuse_rate=0.0)
    score_bad = len(op_bad(""improve quick test""))
    assert score_good > score_bad",tests/test_meme_reuse.py,,0,0.9999756997690634,"The method 'test_performance_drop' is likely to be deleted because it contains a test that relies on randomness without proper control or seeding, which can lead to non-deterministic results. The use of random number generators (rng1 and rng2) with the same seed should theoretically produce the same results, but the test is designed to expect different outcomes (score_good > score_bad). This inconsistency suggests a misunderstanding or error in the test logic, making it unreliable and a candidate for deletion unless corrected."
survived,"    def execute_in_sandbox(self, code: str) -> tuple[str, str]:
        """"""Run ``code`` inside a subprocess with resource limits.""""""

        def _apply_limits() -> None:  # pragma: no cover - platform dependent
            try:
                import resource

                resource.setrlimit(resource.RLIMIT_CPU, (2, 2))
                mem = 128 * 1024 * 1024
                resource.setrlimit(resource.RLIMIT_AS, (mem, mem))
            except Exception:
                pass

        with tempfile.NamedTemporaryFile(""w"", suffix="".py"", delete=False) as fh:
            fh.write(code)
            code_path = fh.name

        helper = tempfile.NamedTemporaryFile(""w"", suffix="".py"", delete=False)
        helper.write(
            ""import json,sys,contextlib,io,textwrap,resource\n""
            ""code=open(sys.argv[1]).read()\n""
            ""try:\n""
            ""    resource.setrlimit(resource.RLIMIT_CPU,(2,2))\n""
            ""    resource.setrlimit(resource.RLIMIT_AS,(256*1024*1024,256*1024*1024))\n""
            ""except Exception:\n""
            ""    pass\n""
            ""wrapped='def snippet():\\n'+textwrap.indent(code,'    ')\n""
            ""env={'__builtins__':{'print':print,'range':range,'len':len}}\n""
            ""loc={}\n""
            ""out,err=io.StringIO(),io.StringIO()\n""
            ""with contextlib.redirect_stdout(out), contextlib.redirect_stderr(err):\n""
            ""    try:\n""
            ""        exec(compile(wrapped,'<agent>','exec'),env,loc)\n""
            ""        loc['snippet']()\n""
            ""    except Exception as e:\n""
            ""        err.write(type(e).__name__)\n""
            ""print(json.dumps({'stdout':out.getvalue(),'stderr':err.getvalue()}))\n""
        )
        helper.flush()
        helper_path = helper.name
        helper.close()

        try:
            proc = subprocess.run(
                [sys.executable, helper_path, code_path],
                text=True,
                capture_output=True,
                timeout=3,
                preexec_fn=_apply_limits if os.name == ""posix"" else None,
            )
            try:
                data = json.loads(proc.stdout or ""{}"")
                out = data.get(""stdout"", """")
                err = data.get(""stderr"", """")
            except json.JSONDecodeError:
                out, err = proc.stdout, proc.stderr
        except Exception as exc:  # pragma: no cover - runtime errors
            out, err = """", str(exc)
        finally:
            os.unlink(code_path)
            os.unlink(helper_path)

        env = messaging.Envelope(self.name, ""exec"", {""stdout"": out, ""stderr"": err}, time.time())
        self.ledger.log(env)
        return out, err",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/codegen_agent.py,CodeGenAgent,1,1.0467401685178159e-08,"The method 'execute_in_sandbox' is a utility function that runs arbitrary code in a controlled environment with resource limits. This is a common requirement for executing untrusted code safely, especially in environments like online code editors, educational platforms, or any system that needs to evaluate user-submitted code. The method includes mechanisms to handle exceptions, limit CPU and memory usage, and capture output, which are all essential for sandboxing. Given the increasing need for secure code execution environments, this method is likely to be retained and possibly improved upon rather than deleted."
survived,"    def __init__(self, **data: Any) -> None:  # pragma: no cover - exercised in tests
        super().__init__(**data)
        if not self.openai_api_key:
            _log.warning(""OPENAI_API_KEY missing â€“ offline mode enabled"")
            self.offline = True
        if self.offline:
            self.broadcast = False
        if not self.solana_wallet and self.solana_wallet_file:
            try:
                self.solana_wallet = Path(self.solana_wallet_file).read_text(encoding=""utf-8"").strip()
            except Exception as exc:  # pragma: no cover - optional
                _log.warning(""Failed to load wallet file %s: %s"", self.solana_wallet_file, exc)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/config.py,Settings,1,9.931195248674785e-08,"The method is a constructor (__init__) which is essential for initializing instances of a class. It contains logic to handle missing API keys and wallet files, which are crucial for the functionality of the class. The presence of logging and exception handling indicates that these features are important for the application's operation. Therefore, it is unlikely to be removed."
survived,"    def test_cli_patches_repo(self) -> None:
        with tempfile.TemporaryDirectory() as tmp:
            repo = Path(tmp) / ""repo""
            (repo / ""tests"").mkdir(parents=True)
            # buggy source file
            (repo / ""calc.py"").write_text(""def add(a, b):\n    return a - b\n"", encoding=""utf-8"")
            # failing test
            (repo / ""tests"" / ""test_calc.py"").write_text(
                ""from calc import add\n\n"" ""def test_add():\n    assert add(1, 2) == 3\n"",
                encoding=""utf-8"",
            )

            patch_file = Path(tmp) / ""patch.diff""
            patch_file.write_text(
                """"""--- a/calc.py
+++ b/calc.py
@@ -1,2 +1,2 @@
-def add(a, b):
-    return a - b
+def add(a, b):
+    return a + b
\\ No newline at end of file
"""""",
                encoding=""utf-8"",
            )

            stub_dir = Path(tmp) / ""stubs""
            stub_pkg = stub_dir / ""openai_agents""
            stub_pkg.mkdir(parents=True)
            (stub_pkg / ""__init__.py"").write_text(
                """"""import os
from pathlib import Path

class OpenAIAgent:
    def __init__(self, *a, **k):
        self.patch_file = os.environ.get('PATCH_FILE')

    def __call__(self, _prompt):
        return Path(self.patch_file).read_text() if self.patch_file else ''
"""""",
                encoding=""utf-8"",
            )

            env = os.environ.copy()
            env[""PATCH_FILE""] = str(patch_file)
            env[""PYTHONPATH""] = f""{stub_dir}:{env.get('PYTHONPATH', '')}""

            result = subprocess.run(
                [
                    sys.executable,
                    ""-m"",
                    ""alpha_factory_v1.demos.self_healing_repo.patcher_core"",
                    ""--repo"",
                    str(repo),
                ],
                capture_output=True,
                text=True,
                env=env,
            )

            self.assertEqual(result.returncode, 0, result.stdout + result.stderr)
            combined = result.stdout + result.stderr
            self.assertIn(""Patch fixed the tests"", combined)
",tests/test_patcher_cli.py,TestPatcherCLI,1,1.1861120010657661e-08,"The method 'test_cli_patches_repo' is a test function that verifies the functionality of a patching system. It creates a temporary repository with a buggy source file and a failing test, applies a patch to fix the bug, and checks if the patch successfully fixes the test. This is a typical use case for a test function in a codebase that involves automated testing and patching. Since testing is a crucial part of software development, especially for ensuring code quality and functionality, this method is likely to be retained in the codebase."
survived,"            async def __aexit__(self_inner, exc_type, exc, tb):
                pass
",src/aiohttp/__init__.py,ClientSession._RespCtx,1,1.7603431343301488e-06,"The method is an asynchronous context manager exit method, which is a part of the context management protocol in Python. However, the method currently does nothing (it just passes), which might be intentional if the context manager doesn't need to perform any cleanup or error handling. If the context manager is expected to handle exceptions or perform some cleanup, this method would need to be implemented. Without additional context, it's difficult to determine the exact intention, but generally, such methods are kept if they are part of a larger context management structure, even if they are currently no-ops. Therefore, it is likely to be Survived."
survived,"    def __init__(self, cost_cap: float = 0.5) -> None:
        self.cost_cap = cost_cap
        self.token_count = 0
        self.cost = 0.0
        self.guardrail_hits = 0
        self.latency = 0.0
        self._start: Optional[float] = None
        self.logger = logging.getLogger(__name__)
",src/meta_agent/telemetry.py,TelemetryCollector,1,1.637377179507321e-07,"The method is a constructor (__init__) for a class, which is essential for initializing object instances with default or specified values. Constructors are fundamental to object-oriented programming as they set up the initial state of an object. This particular constructor initializes several attributes related to cost management and logging, which are likely important for the functionality of the class. Therefore, it is unlikely to be deleted."
survived,"    def add_usage(self, prompt_tokens: int, response_tokens: int, model: str = ""default"") -> None:
        """"""Record token usage and update cost.""""""
        tokens = prompt_tokens + response_tokens
        self.token_count += tokens
        rate = self.COST_TABLE.get(model, self.COST_TABLE[""default""])
        self.cost += rate * tokens / 1000.0
        if self.cost >= self.cost_cap:
            self.logger.warning(""Cost cap exceeded: $%.2f >= $%.2f"", self.cost, self.cost_cap)
            raise RuntimeError(""cost cap exceeded"")
",src/meta_agent/telemetry.py,TelemetryCollector,1,7.991959892315218e-11,"The method 'add_usage' is likely to survive because it performs a critical function of tracking token usage and updating costs, which is essential for managing resources and budgeting in applications that use token-based models. It also includes a mechanism to warn and raise an error when a cost cap is exceeded, which is important for preventing unexpected expenses. These functionalities are crucial for maintaining control over operational costs, making the method valuable and necessary."
survived,"    def increment_guardrail_hits(self) -> None:
        """"""Increment guardrail hit counter and record an event.""""""
        self.guardrail_hits += 1
        self.record_event(
            self.Category.GUARDRAIL,
            ""guardrail violation"",
            severity=self.Severity.WARNING,
        )
",src/meta_agent/telemetry.py,TelemetryCollector,1,6.69158608681505e-10,"The method `increment_guardrail_hits` is likely to survive because it performs a specific and useful function within the codebase. It increments a counter and records an event, which are common operations in monitoring or logging systems. These actions are typically essential for tracking system behavior and ensuring that any violations or issues are logged for further analysis. The method is concise, clear, and serves a distinct purpose, making it unlikely to be removed unless the entire logging or monitoring system is refactored or removed."
survived,"def test_collector_with_db(tmp_path):
    db = TelemetryDB(tmp_path / ""tele.db"")
    collector = TelemetryCollector(db=db, include_sensitive=False)
    collector.start_timer()
    collector.stop_timer()
    line = collector.summary_line()
    assert ""<redacted>"" in line
    assert db.fetch_all()
    db.close()",tests/unit/test_telemetry_db.py,,1,1.522997951276035e-08,"The method 'test_collector_with_db' is a test function that appears to be part of a test suite for a telemetry system. It is designed to verify the functionality of the TelemetryCollector and TelemetryDB classes. Test functions are generally not deleted unless they are redundant, incorrect, or replaced by more comprehensive tests. This function seems to be a valid and useful test as it checks the integration between the collector and the database, ensuring that sensitive data is redacted and that data is correctly stored and retrievable. Therefore, it is likely to be retained in the codebase."
survived,"def test_purge_old(tmp_path):
    db_path = tmp_path / ""tele.db""
    db = TelemetryDB(db_path, retention_days=1)
    db.record(1, 0.01, 0.1, 0)
    # update timestamp to old date
    old_ts = ""2000-01-01T00:00:00""
    db.conn.execute(""UPDATE telemetry SET timestamp=?"", (old_ts,))
    db.conn.commit()
    db.purge_old()
    assert db.fetch_all() == []
    db.close()
",tests/unit/test_telemetry_db.py,,1,1.1861120010657661e-08,"The method 'test_purge_old' is a unit test designed to verify the functionality of the 'purge_old' method in the TelemetryDB class. It ensures that records older than the specified retention period are correctly deleted from the database. Unit tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, this method is likely to be retained as it serves an important role in the testing suite."
survived,"def test_with_retry_async(monkeypatch: pytest.MonkeyPatch) -> None:
    monkeypatch.setattr(retry, ""backoff"", None)
    orig_sleep = asyncio.sleep
    monkeypatch.setattr(retry.asyncio, ""sleep"", lambda *_: orig_sleep(0))
    calls = {""n"": 0}

    async def func() -> str:
        calls[""n""] += 1
        if calls[""n""] < 2:
            raise ValueError(""boom"")
        return ""ok""

    wrapped = retry.with_retry(func, max_tries=2)
    result = asyncio.run(wrapped())
    assert result == ""ok""
    assert calls[""n""] == 2",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_retry.py,,1,7.194132978569833e-09,"The method 'test_with_retry_async' is a unit test designed to verify the behavior of a retry mechanism in an asynchronous context. It uses monkeypatching to modify the behavior of the retry logic and the asyncio sleep function to control the flow of the test. The test checks that the function 'func' is retried once after an initial failure and succeeds on the second attempt. This is a valid and useful test for ensuring the reliability of retry logic in asynchronous operations, which is a common requirement in software development. Therefore, it is likely to be retained in the codebase."
survived,"  def _log_command(self, name: str, **kwargs) -> None:
    params = "", "".join(f""{k}={self._format_param(v)}"" for k, v in kwargs.items())
    logger.debug(""%s(%s)"", name, params)
",pylabrobot/liquid_handling/liquid_handler.py,LiquidHandler,1,1.4166087846364157e-09,"The method '_log_command' is a utility function designed to log commands with their parameters. It uses a logger to output debug information, which is a common practice in software development for tracking and diagnosing issues. The method is simple, clear, and serves a useful purpose in the context of debugging and logging. There is no indication that it is obsolete or redundant, and logging is a critical aspect of maintaining and monitoring software systems. Therefore, it is likely to be retained."
survived,"def test_bridge_launch() -> None:
    """"""Start ``openai_agents_bridge.main`` and confirm registration.""""""
    proc = subprocess.Popen(
        [
            sys.executable,
            ""-m"",
            ""alpha_factory_v1.demos.aiga_meta_evolution.openai_agents_bridge"",
        ],
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        text=True,
    )
    try:
        time.sleep(2)
        proc.terminate()
        out, _ = proc.communicate(timeout=5)
    finally:
        if proc.poll() is None:
            proc.kill()
            proc.wait(timeout=5)
    assert ""EvolverAgent"" in out
",tests/test_aiga_agents_bridge.py,,1,9.237449576640118e-09,"The method `test_bridge_launch` is a test function that starts a subprocess to run a specific module and checks if a particular string ('EvolverAgent') is present in the output. This is a typical pattern for testing whether a component of a system is functioning correctly. The method is well-structured, with proper handling of subprocess termination and output checking. It is likely to be useful for ensuring the correct operation of the `openai_agents_bridge` module, especially in a continuous integration or testing environment. Therefore, it is likely to be retained in the codebase."
survived,"def _print_summary(found_files: int, changed_files: int, total_time: float) -> None:
    """"""Print a concise conversion summary.""""""
    if changed_files:
        print(f""Modified {changed_files} of {found_files} files in {total_time:.2f}s"")
    else:
        print(f""No changes made to {found_files} files in {total_time:.2f}s"")
",src/flynt/api.py,,1,7.582560422162384e-10,"The method _print_summary is a utility function that provides a clear and concise summary of a process involving file changes. It is well-defined, with a specific purpose of reporting the number of files modified and the time taken for the operation. Such utility functions are often useful for logging and debugging purposes, making them valuable in a codebase. Therefore, it is likely to be retained."
survived,"async def test_orchestrator_lifecycle(monkeypatch: pytest.MonkeyPatch) -> None:
    """"""Start the orchestrator, verify health, then shut down cleanly.""""""

    # Allocate random ports
    with socket.socket() as s:
        s.bind(("""", 0))
        rest_port = s.getsockname()[1]
    with socket.socket() as s:
        s.bind(("""", 0))
        grpc_port = s.getsockname()[1]

    monkeypatch.setenv(""DEV_MODE"", ""true"")
    monkeypatch.setenv(""API_TOKEN"", ""t"")
    monkeypatch.setenv(""NEO4J_PASSWORD"", ""x"")
    monkeypatch.setenv(""PORT"", str(rest_port))
    monkeypatch.setenv(""A2A_PORT"", str(grpc_port))

    # Prepare stub packages before importing orchestrator
    agents_stub = types.ModuleType(""backend.agents"")
    setattr(agents_stub, ""list_agents"", lambda _detail=False: [""dummy""])
    setattr(agents_stub, ""get_agent"", lambda name: DummyAgent())
    setattr(agents_stub, ""start_background_tasks"", lambda: None)

    fin_stub = types.ModuleType(""alpha_factory_v1.backend.agents.finance_agent"")
    setattr(fin_stub, ""metrics_asgi_app"", lambda: None)

    mem_stub = types.ModuleType(""backend.memory_fabric"")
    setattr(
        mem_stub,
        ""mem"",
        types.SimpleNamespace(
            vector=types.SimpleNamespace(
                recent=lambda *a, **k: [],
                search=lambda *a, **k: [],
            )
        ),
    )

    monkeypatch.setitem(sys.modules, ""backend.agents"", agents_stub)
    monkeypatch.setitem(sys.modules, ""alpha_factory_v1.backend.agents"", agents_stub)
    monkeypatch.setitem(sys.modules, ""backend.memory_fabric"", mem_stub)
    monkeypatch.setitem(sys.modules, ""alpha_factory_v1.backend.agents.finance_agent"", fin_stub)
    monkeypatch.setitem(sys.modules, ""backend.finance_agent"", fin_stub)

    orch_mod = importlib.import_module(""alpha_factory_v1.backend.orchestrator"")

    # Provide minimal protobuf stubs so gRPC server starts
    pb2 = types.SimpleNamespace(
        StreamReply=object,
        Ack=object,
        AgentStat=object,
        StatusReply=object,
    )
    pb2_grpc = types.SimpleNamespace(
        PeerServiceServicer=object,
        add_PeerServiceServicer_to_server=lambda serv, server: None,
    )
    proto_pkg = types.ModuleType(""backend.proto"")
    setattr(proto_pkg, ""a2a_pb2"", pb2)
    setattr(proto_pkg, ""a2a_pb2_grpc"", pb2_grpc)
    monkeypatch.setitem(sys.modules, ""backend.proto"", proto_pkg)
    monkeypatch.setitem(sys.modules, ""backend.proto.a2a_pb2"", pb2)
    monkeypatch.setitem(sys.modules, ""backend.proto.a2a_pb2_grpc"", pb2_grpc)

    stop = asyncio.Event()
    orch = orch_mod.Orchestrator()

    run_task = asyncio.create_task(orch.run(stop))
    await asyncio.sleep(0.2)  # allow servers to start

    assert orch._rest_task is not None
    assert orch._grpc_server is not None

    import httpx

    async with httpx.AsyncClient() as client:
        res = await client.get(
            f""http://localhost:{rest_port}/healthz"",
            headers={""Authorization"": ""Bearer t""},
        )
    assert res.status_code == 200 and res.text == ""ok""

    stop.set()
    await run_task

    assert orch._rest_task.done()
    for r in orch.manager.runners.values():
        assert r.task is None or r.task.done()",tests/test_orchestrator_lifecycle.py,,1,6.023574641292144e-08,"The method `test_orchestrator_lifecycle` is a well-structured test function that uses the `pytest` framework and `monkeypatch` to simulate the environment and dependencies required for testing the lifecycle of an orchestrator. It sets up necessary environment variables, stubs out modules and functions, and verifies the orchestrator's health endpoint. The test ensures that the orchestrator starts and stops correctly, which is a critical aspect of testing such systems. Given its utility in ensuring the reliability of the orchestrator's lifecycle, it is likely to be retained in the codebase."
survived,"    async def run_cycle(self) -> None:  # pragma: no cover - simple stub
        return None
",tests/test_orchestrator_lifecycle.py,DummyAgent,1,5.715002851580502e-07,"The method 'run_cycle' is an asynchronous function that currently does nothing and returns None. It is marked with a pragma comment 'no cover', indicating that it is intentionally left as a stub and not covered by tests. This suggests that the method is a placeholder for future implementation. Since it is a stub, it is likely to be retained for future development, where actual functionality will be added. Therefore, the method is more likely to survive rather than be deleted."
deleted,"    def repl(match: re.Match[str]) -> str:
        char = match.group(0)
        escapes = mapping.get(char)
        if escapes:
            return escapes.pop(0)
        return char
",src/flynt/utils/utils.py,,1,8.152020648014727e-09,"The method 'repl' is a utility function used in regular expression operations to replace matched patterns with specific strings. It uses a mapping to determine the replacement string for each matched character. This is a common pattern in text processing tasks, and the method is likely to be useful in various contexts where such replacements are needed. Therefore, it is likely to be retained in the codebase."
survived,"def evaluate(agents: List[int]) -> float:
    """"""Return a pseudo reward for the agents.""""""
    distance = sum(abs(a - TARGET) for a in agents)
    noise = random.random() * 0.1
    return -distance + noise
",alpha_factory_v1/demos/meta_agentic_tree_search_v0/mats/evaluators.py,,1,1.3440409770490404e-08,"The method 'evaluate' is a simple function that calculates a pseudo reward for a list of agents based on their distance from a target value. It adds a small random noise to the result. This function is straightforward and serves a clear purpose in scenarios where agents' performance needs to be evaluated based on their proximity to a target. It is likely to be useful in simulations, AI training, or optimization problems where such evaluations are common. Therefore, the method is likely to be retained as it provides a basic yet essential functionality."
survived,"    def __init__(self, root: Node, exploration: float = 1.4) -> None:
        self.root = root
        self.exploration = exploration
",alpha_factory_v1/demos/meta_agentic_tree_search_v0/mats/tree.py,Tree,1,6.348800075736417e-09,"The method is a constructor for a class, which is a fundamental part of object-oriented programming in Python. Constructors are essential for initializing new objects with specific attributes. The use of type hints for parameters and a default value for 'exploration' suggests that the code is well-structured and likely part of a larger, functional class. There is no indication that this method is redundant or unnecessary, so it is likely to be retained."
survived,"    def __init__(self, target: int = 5) -> None:
        self.target = target
",alpha_factory_v1/demos/meta_agentic_tree_search_v0/mats/env.py,NumberLineEnv,1,1.3440409770490404e-08,"The method is a constructor for a class, specifically the __init__ method, which is essential for initializing new objects of the class. It sets a default value for the 'target' attribute, which is a common practice in object-oriented programming to provide default behavior while allowing customization. Such methods are fundamental to class functionality and are unlikely to be deleted unless the class itself is being removed or significantly refactored."
survived,"                async def policy(self, obs, _ctx):  # type: ignore[override]
                    cand = obs.get(""policy"", []) if isinstance(obs, dict) else obs
                    return await improve_policy(list(cand))
",alpha_factory_v1/demos/meta_agentic_tree_search_v0/mats/meta_rewrite.py,RewriterAgent,1,1.6052280526088547e-09,"The method 'policy' is an asynchronous function that takes an observation 'obs' and a context '_ctx'. It checks if 'obs' is a dictionary and retrieves the 'policy' key, defaulting to an empty list if not present. It then calls 'improve_policy' with the list of candidates. The method is straightforward, uses async/await correctly, and seems to be part of a larger system that processes policies. There is no indication of it being deprecated or unnecessary, so it is likely to survive."
survived,"            def call_ctrans(prompt: str, s: Settings) -> str:
                return cast(str, cast(Any, _MODEL)(prompt, temperature=s.temperature))
",alpha_factory_v1/common/utils/local_llm.py,,1,6.348800075736417e-09,"The method 'call_ctrans' is a simple wrapper function that calls another function '_MODEL' with a prompt and a temperature setting. It uses type casting to ensure the return type is a string. This method is likely to survive because it serves a clear purpose in abstracting the call to '_MODEL' and handling type casting, which can be useful for maintaining type safety and readability in the code. Unless there are changes in the requirements or the underlying model function, this method is likely to remain useful."
survived,"    def bus(self) -> EventBus:
        return self._bus",alpha_factory_v1/backend/services/kafka_service.py,KafkaService,1,2.646573631904765e-09,"The method 'bus' is a simple getter for the '_bus' attribute, which is likely an instance of 'EventBus'. Such methods are common in object-oriented programming to provide controlled access to private attributes. Unless there is a significant change in the design pattern or architecture that eliminates the need for this getter, it is likely to survive. Additionally, if '_bus' is a critical component of the class, this method will be necessary for accessing it."
survived,"    def __init__(
        self,
        runners: Dict[str, Any],
        model_max_bytes: int,
        mem: Any,
        rest_port: int,
        grpc_port: int,
        loglevel: str,
        ssl_disable: bool,
    ) -> None:
        self._runners = runners
        self._model_max_bytes = model_max_bytes
        self._mem = mem
        self._rest_port = rest_port
        self._grpc_port = grpc_port
        self._loglevel = loglevel
        self._ssl_disable = ssl_disable
        self._rest_task: Optional[asyncio.Task] = None
        self._grpc_server: Optional[Any] = None
",alpha_factory_v1/backend/services/api_server_service.py,APIServer,1,1.8553915987649156e-07,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class with specific attributes. Constructors are fundamental to object-oriented programming and are rarely deleted unless the class itself is being removed or significantly refactored. The presence of various parameters suggests that this constructor is setting up important configurations for the class, making it unlikely to be removed."
survived,"def test_metrics_exporter_start(monkeypatch):
    called = []
    monkeypatch.setattr(
        ""alpha_factory_v1.backend.services.metrics_service.init_metrics"",
        lambda port: called.append(port),
    )
    exporter = MetricsExporter(9999)
    exporter.start()
    assert called == [9999]",tests/test_metrics_service.py,,1,4.1399375473943306e-08,"The method `test_metrics_exporter_start` is a unit test function that uses the `monkeypatch` fixture to replace the `init_metrics` function with a lambda that appends the port to a list. This is a common pattern in testing to verify that a function is called with the expected arguments. The test then creates an instance of `MetricsExporter` and calls its `start` method, asserting that the `init_metrics` function was called with the correct port.

This method is likely to survive because it is a well-structured test that verifies the behavior of the `MetricsExporter` class. It uses dependency injection to isolate the test from external dependencies, making it reliable and maintainable. Additionally, testing is a crucial part of software development, and this method contributes to ensuring the correctness of the codebase."
survived,"    async def _run() -> None:
        async with bus, ledger:
            for env in envs:
                await agent.handle(env)
",tests/test_memory_agent_file_persistence.py,,1,2.646573631904765e-09,"The method `_run` is an asynchronous function that uses context managers (`async with`) to manage resources (`bus` and `ledger`) and iterates over `envs` to handle each environment with `agent.handle(env)`. This pattern is common in asynchronous programming for managing resources and handling tasks concurrently. The method appears to be well-structured for its purpose, suggesting it is likely to be useful in its context. Without any indication of deprecation or redundancy, it is reasonable to predict that this method will survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-h/compiler/py/q1.py,Lineitem,1,1.3440409770490404e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a common and useful pattern for dynamic attribute access, especially in classes that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-h/compiler/py/q10.py,Auto2,0,0.999985261023967,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in collections like lists or dictionaries. In this code, it is implemented to use `getattr` to retrieve an attribute of the object by name. This is a non-standard use of `__getitem__`, as it is expected to work with indices or keys, not attribute names. This could lead to confusion or errors when the object is used in contexts expecting typical collection behavior. Therefore, it is likely to be deleted or refactored to avoid misuse or misunderstanding."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-h/compiler/py/q21.py,_Group,1,2.2159489282323004e-08,"The method `__len__` is a special method in Python that is used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-h/compiler/py/q12.py,_Group,1,2.646573631904765e-09,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation here is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-h/compiler/py/q8.py,_Group,1,2.3355930333443423e-09,"The method `__len__` is a special method in Python that is used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-h/compiler/py/q1.py,Auto2,1,1.725782769012759e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, this method is likely to be retained as it provides a clear and useful functionality."
survived,"            def register(self, *_a, **_k) -> None:
                pass
",alpha_factory_v1/demos/cross_industry_alpha_factory/openai_agents_bridge.py,AgentRuntime,0,0.9999999985833912,"The method 'register' is defined but does not perform any operations, as it only contains a 'pass' statement. This suggests that it might be a placeholder for future implementation. However, without any additional context or usage, it is likely to be considered unnecessary and could be removed in a code cleanup process. Therefore, it is predicted to be deleted."
survived,"    def test_edge_runner_help(self) -> None:
        result = subprocess.run(
            [sys.executable, ""-m"", ""alpha_factory_v1.edge_runner"", ""--help""],
            capture_output=True,
            text=True,
        )
        self.assertEqual(result.returncode, 0)
        self.assertIn(""usage"", result.stdout.lower())
",tests/test_edge_runner_cli.py,TestEdgeRunnerCLI,1,2.646573631904765e-09,"The method `test_edge_runner_help` is a unit test designed to verify that the `edge_runner` module provides help information correctly when invoked with the `--help` flag. This is a standard practice in software development to ensure that command-line tools provide the necessary usage information to users. The test checks that the command executes successfully (return code 0) and that the output contains the word 'usage', indicating that help information is displayed. Such tests are crucial for maintaining the reliability and usability of command-line interfaces. Therefore, this method is likely to be retained as part of the test suite to ensure ongoing functionality and user support."
survived,"    def test_condition_true(self):
        from alpha_factory_v1.backend.agents import register, _agent_base
        Base = _agent_base()

        @register
        class OkAgent(Base):
            NAME = ""ok""

            async def step(self):
                return None

        self.assertIn(""ok"", AGENT_REGISTRY)
",tests/test_agents_registry.py,TestRegisterDecorator,0,0.9999996533672291,"The method `test_condition_true` is likely to be deleted because it contains a test that checks if an agent named 'ok' is registered in `AGENT_REGISTRY`. However, the test does not include any setup or teardown logic to ensure that the `AGENT_REGISTRY` is in a known state before or after the test. This could lead to flaky tests if the registry is modified by other tests or parts of the code. Additionally, the test does not verify any behavior of the `OkAgent` class itself, making it a weak test case. Without improvements to ensure test isolation and more comprehensive checks, this method is not very useful and may be removed."
survived,"def list_capabilities():
    """"""Return sorted list of all capabilities currently registered.""""""
    return sorted(CAPABILITY_GRAPH.keys())
",alpha_factory_v1/backend/agents/__init__.py,,1,8.592166611791576e-10,"The method 'list_capabilities' is a simple utility function that returns a sorted list of keys from a dictionary called 'CAPABILITY_GRAPH'. This type of function is generally useful for retrieving and displaying information in a structured manner. It is likely to be used in various parts of a codebase where understanding or displaying the available capabilities is necessary. Since it provides a clear and straightforward functionality without any apparent issues, it is likely to be retained in the codebase."
survived,"def test_replay_existing(tmp_path) -> None:
    path = tmp_path / ""led.db""
    path.touch()
    with patch.object(cli.config.CFG, ""ledger_path"", path):
        with (
            patch.object(cli.logging, ""Ledger"") as led_cls,
            patch.object(
                cli.time,
                ""sleep"",
                return_value=None,
            ),
        ):
            led = led_cls.return_value
            led.tail.return_value = [{""ts"": 0.0, ""sender"": ""a"", ""recipient"": ""b"", ""payload"": {""x"": 1}}]
            out = CliRunner().invoke(cli.main, [""replay""])
            assert ""a -> b"" in out.output",tests/test_cli.py,,1,1.1032560311263802e-09,"The method 'test_replay_existing' is a unit test function that verifies the functionality of a command-line interface (CLI) command. It uses mocking to simulate the behavior of external dependencies, such as the ledger and time.sleep, and checks if the output of the CLI command contains the expected string. This is a typical pattern for testing CLI applications, ensuring that the 'replay' command works as intended. Since testing is a crucial part of software development to ensure code reliability and correctness, this method is likely to be retained in the codebase."
survived,"    async def run_cycle(self) -> None:
        self.calls += 1
",tests/test_agent_runner.py,DummyAgent,0,0.9999999317439577,"The method 'run_cycle' is very minimal and lacks functionality. It only increments a counter 'self.calls' and does not perform any other operations. Without additional context or usage, it seems unlikely to be useful in its current form. Therefore, it is more likely to be deleted unless further functionality is added."
survived,"def test_simulate_export_json() -> None:
    runner = CliRunner()
    with patch.object(cli, ""asyncio""):
        with patch.object(cli.orchestrator, ""Orchestrator""):
            res = runner.invoke(
                cli.main,
                [
                    ""simulate"",
                    ""--horizon"",
                    ""1"",
                    ""--offline"",
                    ""--pop-size"",
                    ""1"",
                    ""--generations"",
                    ""1"",
                    ""--export"",
                    ""json"",
                ],
            )
    assert res.exit_code == 0
    assert res.output.startswith(""["")
",tests/test_cli.py,,1,3.850741907939403e-09,"The method 'test_simulate_export_json' is a unit test designed to verify the functionality of a command-line interface (CLI) command. It uses the 'CliRunner' from the 'click' library to simulate running the CLI command and checks if the output is in JSON format. The test is well-structured, uses mocking to isolate the test from external dependencies, and includes assertions to validate the expected behavior. Such tests are crucial for ensuring the reliability of CLI tools, especially when dealing with data export functionalities. Therefore, it is likely to be maintained and not deleted."
survived,"    def fake_push(self):
        pushed.append(True)
        return ""branch""
",tests/test_self_healer_pipeline.py,,0,0.9999999827421723,"The method 'fake_push' is incomplete and contains an error. The variable 'pushed' is used without being defined within the method or passed as a parameter, which will lead to a NameError when the method is called. Additionally, the method name 'fake_push' suggests it might be a placeholder or a mock implementation, which often indicates that it is not intended for production use. Without further context or corrections, this method is likely to be deleted or refactored."
survived,"  def valid(self, current_nanos: int, bus_timeout: bool) -> bool:
    if self.ignore_alive:
      return True
    if not self.timestamps:
      return False
    if self.timeout_threshold > 0 and (current_nanos - self.timestamps[-1]) > self.timeout_threshold:
      return False
    return True
",opendbc/can/parser.py,MessageState,1,3.160881453314576e-10,"The method 'valid' is a utility function that checks the validity of a condition based on several parameters. It is likely to be used in a context where the state of an object needs to be validated based on time and a timeout condition. The method is straightforward, performs a clear function, and is likely to be useful in its context. There is no indication that it is deprecated or redundant, so it is likely to survive."
survived,"def test_setup_config_creates_file(tmp_path: Path) -> None:
    sample = tmp_path / ""config.env.sample""
    sample.write_text(""SECRET=1\n"")
    path, created = setup_config.ensure_config(tmp_path)
    assert created is True
    assert path == tmp_path / ""config.env""
    assert path.read_text() == ""SECRET=1\n""",tests/test_setup_config.py,,1,3.850741907939403e-09,"The method 'test_setup_config_creates_file' is a unit test function that verifies the behavior of the 'setup_config.ensure_config' function. It checks if a configuration file is created correctly with the expected content. Unit tests are crucial for ensuring code reliability and are typically not deleted unless they are redundant or replaced by more comprehensive tests. Since this test seems to be straightforward and serves a clear purpose, it is likely to be retained."
survived,"def test_single_batched_selector():
    B, S, V = Axis(""batch"", 4), Axis(""seq"", 3), Axis(""vocab"", 7)
    x = hax.arange((B, S, V))
    idx = hax.arange((B, S), dtype=jnp.int32) % V.size
    out = x[""vocab"", idx]
    assert out.axes == (B, S)
    assert jnp.array_equal(out.array, _ref_gather(x, V, idx))
",tests/test_scatter_gather.py,,1,4.599055376537186e-10,"The method 'test_single_batched_selector' is a unit test function that verifies the behavior of a specific operation involving tensor indexing and gathering. Unit tests are crucial for ensuring code correctness and preventing regressions. Since this function is a test, it is likely to be maintained as part of the codebase to ensure the functionality it tests remains correct. Therefore, it is more likely to survive."
survived,"    async def init_async(self) -> None:
        """"""Launch background tasks after instantiation.""""""
        asyncio.create_task(self.kg.load())
",alpha_factory_v1/backend/agents/biotech_agent.py,BiotechAgent,1,1.3440409770490404e-08,"The method 'init_async' is an asynchronous method that is used to launch background tasks after instantiation. It uses 'asyncio.create_task' to run 'self.kg.load()' in the background. This is a common pattern in asynchronous programming to ensure that tasks are run concurrently without blocking the main thread. The method is likely to be useful in scenarios where non-blocking initialization is required, such as in web servers or applications that need to perform background loading of data. Therefore, it is likely to be retained as it provides a necessary functionality for asynchronous operations."
survived,"    def _decode(self, seq: Sequence, cache, page_table, step: int):
        prev_token = jnp.array([seq.last_token], dtype=jnp.int32)
        seq_named = hax.named([seq.seq_id], ""seq"")
        temps = hax.full((), seq.sampling_params.temperature, dtype=jnp.float32)
        key = jrandom.PRNGKey(step)
        start = jnp.array(step, dtype=jnp.int32)
        tok, page_table, cache = do_generate(
            self.model, cache, page_table, prev_token, self.sampler, seq_named, start, temps, key
        )
        return int(tok.array), cache, page_table
",src/levanter/inference/llm_engine.py,LLMEngine,1,2.1024340680345882e-07,"The method '_decode' appears to be a private helper function within a larger class or module, likely related to a machine learning model or sequence generation task. It is well-structured, uses type annotations, and integrates with other components like 'do_generate', 'jrandom.PRNGKey', and 'hax'. These suggest it is part of a well-maintained codebase. Unless there is a significant change in the overall architecture or functionality requirements, such methods are typically retained as they serve specific purposes in the workflow."
survived,"def linear_conflicts(start_list,goal_list):
    """"""
    calculates number of moves to add to the estimate of
    the moves to get from start to goal based on the number
    of conflicts on a given row or column. start_list
    represents the current location and goal_list represnts
    the final goal.
    """"""

    # Find which of the tiles in start_list have their goals on this line
    # build a pattern to use in a lookup table of this form:
    # g0, g1, g3, g3 fill in x where there is no goal for this line

    # all 'x' until we file a tile whose goal is in this line

    goal_pattern = ['x', 'x', 'x', 'x']

    for g in range(4):
        for s in range(4):
            start_tile_num = start_list[s]
            if start_tile_num == goal_list[g] and start_tile_num != 0:
                goal_pattern[s] = 'g' + str(g) # i.e. g0

    global conflict_table

    tup_goal_pattern = tuple(goal_pattern)

    if tup_goal_pattern in conflict_table:
        return conflict_table[tuple(goal_pattern)]
    else:
        return 0
",tests/rosetta/x/Python/15-puzzle-solver/15-puzzle-solver-2.py,,1,7.194132978569833e-09,"The method `linear_conflicts` is a utility function that calculates the number of linear conflicts in a puzzle, which is a common heuristic used in solving sliding puzzles like the 15-puzzle. This function is useful for improving the efficiency of puzzle-solving algorithms by providing a more accurate heuristic estimate of the number of moves required to solve the puzzle. Given its utility in a specific domain (puzzle solving) and the fact that it is a well-defined function with a clear purpose, it is likely to be retained in the codebase. Therefore, the method will survive."
survived,"    def __init__(self, goal):
        """"""
        Preprocess goal position to setup internal data structures
        that can be used to speed up heuristic.
        """"""

        build_conflict_table()

        self.goal_map = []
        for i in range(16):
            self.goal_map.append(i)

        self.goal_lists = goal.tiles

        # preprocess for manhattan distance

        for row in range(4):
            for col in range(4):
                self.goal_map[goal.tiles[row][col]] = (row, col)

        # make access faster by changing to a tuple

        self.goal_map = tuple(self.goal_map)

        # preprocess for linear conflicts

        self.row_conflicts = []
        for row in range(4):
            t = goal.tiles[row]
            conf_dict = listconflicts([t[0],t[1],t[2],t[3]])
            self.row_conflicts.append(conf_dict)

        self.col_conflicts = []
        for col in range(4):
            col_list =[]
            for row in range(4):
                col_list.append(goal.tiles[row][col])
            conf_dict = listconflicts(col_list)
            self.col_conflicts.append(conf_dict)
",tests/rosetta/x/Python/15-puzzle-solver/15-puzzle-solver-2.py,HeuristicObj,1,8.76424914819242e-08,"The method is a constructor (__init__) for a class, which is essential for initializing objects of that class. It sets up important data structures and precomputes values that are likely used in other methods of the class. This kind of method is fundamental to the class's functionality and is unlikely to be deleted unless the entire class is being refactored or removed."
survived,"    def push(self, new_object):
        """""" save object in heapq """"""
        heapq.heappush(self.qheap,(new_object.fscore,new_object.tiles))
        self.queue_length += 1
",tests/rosetta/x/Python/15-puzzle-solver/15-puzzle-solver-2.py,PriorityQueue,1,1.8189616842444243e-09,"The method 'push' is a straightforward implementation of adding an object to a priority queue using the heapq module. It is a common and efficient way to manage a priority queue in Python. The method is likely to be used in contexts where objects need to be processed based on priority, which is a common requirement in many algorithms and applications. Therefore, there is no indication that this method is obsolete or redundant, and it is likely to be retained."
survived,"def main() -> int:
    repo_root = Path(__file__).resolve().parents[1]
    req_txt = repo_root / ""alpha_factory_v1"" / ""demos"" / ""aiga_meta_evolution"" / ""requirements.txt""
    lock_file = repo_root / ""alpha_factory_v1"" / ""demos"" / ""aiga_meta_evolution"" / ""requirements.lock""

    with tempfile.TemporaryDirectory() as tmpdir:
        out_path = Path(tmpdir) / ""requirements.lock""
        pip_compile = shutil.which(""pip-compile"")
        if pip_compile:
            cmd = [pip_compile]
        else:
            cmd = [sys.executable, ""-m"", ""piptools"", ""compile""]
        wheelhouse = os.getenv(""WHEELHOUSE"")
        cmd += [""--quiet""]
        if wheelhouse:
            cmd += [""--no-index"", ""--find-links"", wheelhouse]
        cmd += [""--generate-hashes"", str(req_txt), ""-o"", str(out_path)]
        result = subprocess.run(cmd, capture_output=True, text=True)
        sys.stdout.write(result.stdout)
        sys.stderr.write(result.stderr)
        if result.returncode != 0:
            return result.returncode
        if not lock_file.exists() or out_path.read_bytes() != lock_file.read_bytes():
            extra = """"
            if wheelhouse:
                extra = f""--no-index --find-links {wheelhouse} ""
            msg = (
                ""alpha_factory_v1/demos/aiga_meta_evolution/requirements.lock is outdated. Run 'pip-compile ""
                f""{extra}--quiet --generate-hashes alpha_factory_v1/demos/aiga_meta_evolution/requirements.txt -o ""
                ""alpha_factory_v1/demos/aiga_meta_evolution/requirements.lock'\n""
            )
            sys.stderr.write(msg)
            return 1
    return 0
",scripts/verify_aiga_requirements_lock.py,,1,1.3440409770490404e-08,"The method 'main' is a utility function that automates the process of checking and updating a 'requirements.lock' file based on a 'requirements.txt' file. This is a common task in software development to ensure that dependencies are up-to-date and consistent. The function uses standard libraries and tools like 'pip-compile' and 'subprocess', which are widely used in Python projects. The function is well-structured, handles errors, and provides informative messages, making it a useful and maintainable piece of code. Therefore, it is likely to be retained in the codebase."
survived,"def test_visualize_shardings_inside_jit(capsys):
    mesh = jax.sharding.Mesh(np.array(jax.devices()).reshape(-1, 1), (ResourceAxis.DATA, ResourceAxis.MODEL))

    @named_jit(out_axis_resources={""dim1"": ResourceAxis.DATA})
    def fn(x):
        visualize_shardings(x)
        return x

    with axis_mapping({""dim1"": ResourceAxis.DATA}), mesh:
        x = hax.ones(Dim1)
        fn(x)

    out = capsys.readouterr().out
    assert ""dim1"" in out
",tests/test_visualize_sharding.py,,1,1.1253518384332553e-07,"The method 'test_visualize_shardings_inside_jit' is a test function that appears to be part of a testing suite for a library involving JAX and sharding. It is designed to verify that the 'visualize_shardings' function works correctly within a JIT-compiled function. Test functions are generally crucial for ensuring code reliability and correctness, especially in complex systems like those involving parallel computing and JIT compilation. Therefore, it is unlikely to be deleted unless the functionality it tests is deprecated or the testing framework is significantly restructured."
survived,"            def __init__(self, *a, **k):
                pass
",tests/test_agent_aiga_entrypoint.py,TestAgentAIGAEntry.DummyEvolver,1,7.3382086014706e-07,"The method is an initializer (__init__) which is a special method in Python classes. However, it currently does not perform any initialization as it only contains a 'pass' statement. This might suggest that the method is not yet implemented or is a placeholder for future code. Despite this, the method is unlikely to be deleted because it is a fundamental part of the class structure in Python, and even an empty initializer can be useful for maintaining a consistent interface or for future expansion. Therefore, it is more likely to survive."
survived,"            def reset(self):
                pass
",tests/test_agent_aiga_entrypoint.py,TestAgentAIGAEntry.DummyEvolver,0,0.9740426431318634,"The method 'reset' is defined but not implemented, as it only contains a 'pass' statement. This suggests that it is a placeholder for future functionality or is meant to be overridden in a subclass. If the class is intended to be used as a base class or if the method is expected to be implemented later, it might survive. However, if there is no plan to implement this method or if it is not used anywhere in the code, it is likely to be deleted to clean up the codebase."
survived,"            def latest_log(self):
                return """"
",tests/test_agent_aiga_entrypoint.py,TestAgentAIGAEntry.DummyEvolver,0,0.9999999586006244,"The method `latest_log` is currently implemented to return an empty string, which suggests it is either a placeholder or not yet fully implemented. Without any functionality, it doesn't provide value to the class it belongs to. Unless there is a specific plan to implement this method in the future, it is likely to be deleted as it serves no purpose in its current state."
survived,"def main() -> None:
    alpha = discover_alpha()
    print(""Discovered alpha:"")
    print(json.dumps(alpha, indent=2))
    print(f""Logged to {LEDGER}"")
",alpha_factory_v1/demos/omni_factory_demo/alpha_discovery_stub.py,,1,1.2501528648238603e-09,"The method 'main' is a typical entry point for Python scripts and is often used to encapsulate the main logic of a program. The code snippet provided shows a structured approach to executing a sequence of operations: discovering an 'alpha', printing it in a formatted manner, and logging it to a ledger. These operations suggest that the method is part of a larger, functional application. Without any indication of redundancy, inefficiency, or obsolescence, there is no reason to delete this method. Therefore, it is likely to survive."
survived,"    def test_apply_patch_failure_rollback(self):
        with tempfile.TemporaryDirectory() as repo:
            file_path = os.path.join(repo, ""hello.txt"")
            with open(file_path, ""w"") as fh:
                fh.write(""hello\n"")
            bad_patch = ""invalid diff""
            with self.assertRaises(RuntimeError):
                patcher_core.apply_patch(bad_patch, repo_path=repo)
            with open(file_path) as fh:
                self.assertEqual(fh.read(), ""hello\n"")
",tests/test_self_healing_patcher.py,TestPatcherCore,1,1.725782769012759e-08,"The method 'test_apply_patch_failure_rollback' is a unit test designed to verify that a patch application failure correctly rolls back any changes, ensuring the file remains unchanged. This is a critical aspect of testing for robustness in software that deals with file modifications. Such tests are essential for maintaining code quality and reliability, especially in systems that handle file operations. Therefore, it is unlikely to be deleted as it serves an important purpose in the test suite."
survived,"    def Tool(*_, **__):  # type: ignore[misc]
        def wrapper(func):
            return func

        return wrapper
",alpha_factory_v1/demos/muzero_planning/agent_muzero_entrypoint.py,,1,3.466327708641819e-07,"The method 'Tool' is a decorator that does not perform any operations other than returning the function it decorates. It is essentially a no-op decorator. However, it might be used as a placeholder for future functionality or to maintain a consistent interface where decorators are expected. Without additional context, it's difficult to determine its utility, but such patterns are often retained for future extensibility or to maintain a consistent API. Therefore, it is likely to survive unless there is a specific reason to remove it, such as a refactor that eliminates the need for this pattern."
survived,"        def __call__(self, *_: str) -> str:
            return ""LLM commentary unavailable.""
",alpha_factory_v1/demos/muzero_planning/agent_muzero_entrypoint.py,OpenAIAgent,1,0.0009110514016656498,"The method is a special method in Python, known as a dunder method, which allows an instance of a class to be called as a function. The implementation here is simple and returns a fixed string. While the method is functional, its utility depends on the context in which it is used. If the class is designed to provide commentary or responses, this method could be useful. However, if the class has a broader purpose and this method doesn't align with its main functionality, it might be considered for deletion. Without additional context, it's difficult to determine its relevance, but generally, such methods are kept if they serve a specific purpose in the class design."
survived,"    def test_notebook_valid(self) -> None:
        nb_path = Path(""alpha_factory_v1/demos/alpha_agi_business_v1/colab_alpha_agi_business_v1_demo.ipynb"")
        self.assertTrue(nb_path.exists(), ""Notebook missing"")
        data = json.loads(nb_path.read_text(encoding=""utf-8""))
        self.assertIn(""cells"", data)
        self.assertIn(""nbformat"", data)
        self.assertGreaterEqual(data.get(""nbformat"", 0), 4)
",tests/test_business_notebook.py,TestBusinessNotebook,1,2.646573631904765e-09,"The method `test_notebook_valid` is a unit test designed to verify the existence and validity of a Jupyter notebook file. It checks if the file exists, if it contains the necessary 'cells' and 'nbformat' keys, and if the 'nbformat' version is at least 4. These checks are essential for ensuring that the notebook is correctly formatted and can be executed without errors. Such validation tests are crucial in development environments where notebooks are used for demonstrations or data analysis. Therefore, this method is likely to be retained as it serves a practical purpose in maintaining the integrity of notebook files."
survived,"    def test_notebook_v1_valid(self) -> None:
        self._check_notebook(Path(""alpha_factory_v1/demos/meta_agentic_agi/colab_meta_agentic_agi.ipynb""))
",tests/test_meta_agentic_notebook.py,TestMetaAgenticNotebook,1,4.599055376537186e-10,"The method `test_notebook_v1_valid` is a test function that checks the validity of a specific Jupyter notebook file. It uses a helper function `_check_notebook` to perform the actual check. This kind of test function is typically part of a test suite to ensure that notebooks are correctly formatted or execute without errors. Since testing is a crucial part of software development to maintain code quality and functionality, it is unlikely that this method will be deleted unless the notebook itself is removed or the testing strategy changes significantly. Therefore, the method is likely to survive."
survived,"    async def step(self) -> None:
        """"""Post a short market insight using OpenAI Agents if available.""""""
        insight = ""LLM unavailable""
        try:
            from openai_agents import OpenAIAgent

            agent = OpenAIAgent(
                model=os.getenv(""MODEL_NAME"", ""gpt-4o-mini""),
                api_key=os.getenv(""OPENAI_API_KEY""),
                base_url=None
                if os.getenv(""OPENAI_API_KEY"")
                else ""http://ollama:11434/v1"",
            )
            insight = await agent(""One sentence on today's market outlook"")
        except Exception as exc:  # noqa: BLE001
            logging.getLogger(__name__).warning(""LLM fallback: %s"", exc)
        await self.publish(""alpha.insight"", {""insight"": insight})
",alpha_factory_v1/demos/alpha_agi_business_2_v1/alpha_agi_business_2_v1.py,LLMCommentAgent,1,1.1861120010657661e-08,"The method is likely to survive because it provides a useful functionality of generating market insights using OpenAI Agents, which is a relevant and valuable feature for applications that require real-time data analysis and insights. The method also includes error handling to ensure that the application can continue to function even if the OpenAI service is unavailable, which is a good practice in software development. Additionally, the use of environment variables for configuration makes the method flexible and adaptable to different deployment environments."
survived,"    def test_detect_yield_curve_alpha(self) -> None:
        msg = alpha_detection.detect_yield_curve_alpha()
        self.assertIsInstance(msg, str)
        self.assertTrue(""Yield curve spread"" in msg)
",tests/test_alpha_detection.py,TestAlphaDetection,1,3.850741907939403e-09,"The method `test_detect_yield_curve_alpha` is a unit test designed to verify the functionality of the `detect_yield_curve_alpha` function from the `alpha_detection` module. It checks two things: whether the returned message is a string and whether it contains the phrase 'Yield curve spread'. This is a typical structure for a unit test, ensuring that the function behaves as expected. Since testing is a crucial part of software development to ensure code reliability and correctness, this method is likely to be retained as part of the test suite."
survived,"async def run_episode(max_steps: int = 500) -> dict:
    mu = MiniMu(env_id=ENV_ID)
    frames, reward = minimuzero.play_episode(mu, render=False, max_steps=max_steps)
    return {""reward"": reward}
",alpha_factory_v1/demos/muzero_planning/agent_muzero_entrypoint.py,,1,2.2159489282323004e-08,"The method 'run_episode' is a concise and clear function that serves a specific purpose: running an episode in a reinforcement learning environment and returning the reward. It uses asynchronous programming, which is beneficial for non-blocking operations, and it has a default parameter for 'max_steps', making it flexible. The function is likely part of a larger system for training or evaluating AI models, and its utility in such a context suggests it will be retained. Additionally, the use of 'minimuzero.play_episode' indicates it is part of a structured framework, further supporting its continued use."
survived,"def boom(a: int, b: int) -> bool:
    print(""boom"")
    return True
",tests/machine/x/python/short_circuit.py,,0,0.99999998813888,"The method 'boom' is a simple function that takes two integer arguments and always returns True after printing 'boom'. It doesn't perform any meaningful computation or logic based on the inputs, which makes it redundant in most practical applications. Without any context or additional functionality, such a method is likely to be considered unnecessary and thus deleted in a real-world codebase."
survived,"    def adder(x):
        return x + n
",tests/machine/x/python/closure.py,,0,0.9999999778405106,"The method 'adder' is likely to be deleted because it references a variable 'n' that is not defined within the function or passed as a parameter. This will result in a NameError when the function is called, making it non-functional in its current state. Without additional context or modifications to define 'n', the method does not serve a practical purpose."
survived,"def sum_rec(n: int, acc: int) -> int:
    if n == 0:
        return acc
    return sum_rec(n - 1, acc + n)
",tests/machine/x/python/tail_recursion.py,,1,2.8453347280241004e-08,"The method 'sum_rec' is a recursive function that calculates the sum of all integers from 1 to n using an accumulator pattern. This is a common and efficient way to implement a summation function in a functional programming style. The function is simple, clear, and performs its task correctly without any apparent issues. Recursive functions like this are often used in educational contexts to teach recursion and accumulator patterns. Therefore, there is no reason to delete this method as it serves a valid purpose and is implemented correctly."
survived,"    def _align_gpu(self, seq1: str, seq2: str) -> tuple[int, ""np.ndarray""]:
        len1, len2 = len(seq1), len(seq2)
        seq1_buf = np.frombuffer(seq1.encode(""ascii""), dtype=np.int8)
        seq2_buf = np.frombuffer(seq2.encode(""ascii""), dtype=np.int8)
        H = np.zeros((len1 + 1) * (len2 + 1), dtype=np.int32)
        d_seq1 = cl.Buffer(self._ctx, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=seq1_buf)
        d_seq2 = cl.Buffer(self._ctx, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=seq2_buf)
        d_H = cl.Buffer(self._ctx, cl.mem_flags.READ_WRITE | cl.mem_flags.COPY_HOST_PTR, hostbuf=H)
        for diag in range(2, len1 + len2 + 1):
            start_i = max(1, diag - len2)
            end_i = min(len1, diag - 1)
            diag_size = max(0, end_i - start_i + 1)
            if diag_size == 0:
                continue
            self._prog.sw_diag(
                self._queue,
                (diag_size,),
                None,
                d_seq1,
                d_seq2,
                d_H,
                np.int32(len1),
                np.int32(len2),
                np.int32(diag),
                np.int32(start_i),
                np.int32(self.match),
                np.int32(self.mismatch),
                np.int32(self.gap),
            )
        cl.enqueue_copy(self._queue, H, d_H)
        H = H.reshape((len1 + 1, len2 + 1))
        return int(H.max()), H
",src/python/gpu_smith_waterman.py,SmithWatermanGPU,1,2.998960815863541e-09,"The method '_align_gpu' is a specialized function that performs sequence alignment using GPU acceleration. It involves setting up buffers, managing memory, and executing a kernel program on the GPU. This type of functionality is crucial for performance-intensive applications, especially in fields like bioinformatics where sequence alignment is common. The method is well-structured, uses OpenCL for GPU operations, and returns meaningful results. Given the increasing importance of GPU computing for performance optimization, this method is likely to be retained."
survived,"    def align(self, seq1: str, seq2: str):
        """"""Return Smith-Waterman max score and matrix.""""""
        if _GPU_AVAILABLE:
            return self._align_gpu(seq1, seq2)
        return self._align_cpu(seq1, seq2)
",src/python/gpu_smith_waterman.py,SmithWatermanGPU,1,5.60279640614594e-09,"The method 'align' is a crucial part of a sequence alignment algorithm, specifically implementing the Smith-Waterman algorithm, which is widely used in bioinformatics for local sequence alignment. The method provides functionality to choose between GPU and CPU computation based on availability, which is a common and efficient practice in computational tasks to optimize performance. Given its utility and the fact that it adapts to available hardware resources, it is unlikely to be deleted."
survived,"    def generate_from_file(self, df_infile, vocab_infile):
        """"""Load a document-term matrix and vocabulary from disk.

        Column names are kept as words. When using this matrix with the
        sampler, map the words to integer token IDs before constructing the
        corpus.
        """"""

        # read data frame with word columns intact
        df = pd.read_csv(df_infile, index_col=0)

        vocab = np.genfromtxt(vocab_infile, dtype=""str"")
        return df, vocab
",examples/synthetic_data.py,HldaDataGenerator,1,2.998960815863541e-09,"The method 'generate_from_file' is a utility function that loads a document-term matrix and vocabulary from files. This is a common task in data processing and machine learning workflows, especially in natural language processing tasks. The method is straightforward, uses standard libraries (pandas and numpy), and provides a clear purpose in the context of handling text data. There is no indication that this method is obsolete or redundant, and it serves a useful function in data preparation. Therefore, it is likely to be retained."
survived,"def test_transform_acm_certificates():
    result = acm.transform_acm_certificates(
        [test_data.DESCRIBE_CERTIFICATE[""Certificate""]],
        ""us-east-1"",
    )
    assert len(result) == 1
    cert = result[0]
    assert cert[""Arn""] == ""arn:aws:acm:us-east-1:000000000000:certificate/test-cert""
    assert cert[""DomainName""] == ""example.com""
    assert cert[""Status""] == ""ISSUED""
    assert cert[""InUseBy""] == [
        ""arn:aws:elasticloadbalancing:us-east-1:000000000000:listener/app/test-lb/abcd/efgh""
    ]
    assert cert[""ELBV2ListenerArns""] == [
        ""arn:aws:elasticloadbalancing:us-east-1:000000000000:listener/app/test-lb/abcd/efgh""
    ]",tests/unit/cartography/intel/aws/test_acm.py,,1,2.8453347280241004e-08,"The method `test_transform_acm_certificates` is a unit test function that verifies the behavior of the `transform_acm_certificates` function. It checks that the transformation of ACM certificate data is performed correctly by asserting various properties of the result. Unit tests are crucial for ensuring code reliability and correctness, especially in production environments. Therefore, this method is likely to be retained as it serves an important role in the software development process."
survived,"def sum_tree(t):
    return (0 if t == Leaf else (sum_tree(t[""left""]) + t[""value""] + sum_tree(t[""right""]) if t != None else None))
",tests/transpiler/x/py/tree_sum.py,,1,1.0129988107056774e-05,"The method 'sum_tree' is designed to calculate the sum of all values in a binary tree structure. It checks if the node is a 'Leaf' and returns 0, otherwise it recursively sums the values of the left and right subtrees along with the current node's value. However, the code has a logical flaw: it uses 'Leaf' without defining it, which will cause a NameError unless 'Leaf' is defined elsewhere in the code. Additionally, the use of 'None' in the else clause is redundant because the condition 't != None' is already checked. Despite these issues, the core functionality of summing tree values is correct, and with minor adjustments, it can be functional. Therefore, the method is likely to be Survived (1) with some modifications."
survived,"    def open_logs():
        try:
            open_logs_folder()
            return {""message"": ""opened""}
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))",app/desktop/studio_server/settings_api.py,,1,9.237449576640118e-09,"The method 'open_logs' is a simple function that attempts to open a logs folder and returns a success message if it succeeds. If it fails, it raises an HTTPException with a 500 status code and the error details. This method is straightforward and handles exceptions appropriately, making it useful for logging purposes. It is likely to be retained as it provides a clear and concise way to handle log opening operations and error reporting."
survived,"    async def invoke(
        self,
        prompt: str,
        *,
        model: Optional[str] = None,
        context: Optional[Dict[str, Any]] = None,
    ) -> str:
        for guard in self.input_guardrails:
            await guard(prompt)

        adapter = self.adapters.get(model or self.default_model)
        if adapter is None:
            raise ValueError(f""Unknown model '{model}'"")

        result = await adapter.invoke(prompt, context)

        for guard in self.output_guardrails:
            await guard(result)

        return result
",src/meta_agent/services/guardrail_router.py,GuardrailModelRouter,1,2.4616969512093895e-10,"The method 'invoke' is well-structured and serves a clear purpose in the context of an asynchronous operation. It includes input validation through guardrails, dynamic model selection, and output validation, which are all good practices in software development. The use of async/await indicates that it is designed to handle asynchronous operations efficiently, which is increasingly important in modern applications. There is no indication of deprecated practices or inefficiencies that would warrant its deletion. Therefore, it is likely to survive."
survived,"def _apply_grad(fn, x, backend_name=""numpy""):
    backend.set_backend(backend_name)
    b = backend.current()
    g = b.grad(fn)
    out = g(b.array(x, requires_grad=True))
    out = to_numpy(out)
    return float(out) if np.ndim(out) == 0 else out
",tests/kgtests/autograd/helpers.py,,1,2.646573631904765e-09,"The method '_apply_grad' is a utility function that applies a gradient function to an input using a specified backend. It is a specialized function that is likely part of a larger library or framework dealing with automatic differentiation or machine learning. Such functions are typically retained as they provide essential functionality for gradient computation, which is a core component in optimization and training algorithms. Unless there is a significant change in the library's architecture or a better alternative is introduced, this method is likely to survive."
survived,"    def test_scalar_grad_numpy(self):
        self._check_scalar_square_grad(""numpy"")
",tests/test_autograd.py,TestAutograd,1,2.2159489282323004e-08,"The method `test_scalar_grad_numpy` is a test function, likely part of a test suite for a larger codebase. Test functions are generally important for ensuring code correctness and are not typically deleted unless they are redundant or replaced by more comprehensive tests. Since this function is specifically testing scalar gradient calculations using numpy, it serves a specific purpose in validating the functionality of the code. Therefore, it is more likely to be maintained or updated rather than deleted."
survived,"def test_apply_patch_missing_patch_binary(tmp_path: Path, monkeypatch: mock.MagicMock) -> None:
    (tmp_path / ""hello.txt"").write_text(""hello\n"", encoding=""utf-8"")
    monkeypatch.setattr(shutil, ""which"", lambda _: None)
    with pytest.raises(RuntimeError) as exc:
        patcher_core.apply_patch(_DEF_DIFF, repo_path=str(tmp_path))
    assert ""patch` command not found"" in str(exc.value)
",tests/test_patcher_core_additional.py,,1,1.6052280526088547e-09,"The method `test_apply_patch_missing_patch_binary` is a unit test designed to verify the behavior of a function when a required binary is missing. It uses the `monkeypatch` fixture to simulate the absence of the `patch` command by setting `shutil.which` to return `None`. The test then asserts that a `RuntimeError` is raised with a specific error message. This is a valid and useful test case for ensuring robustness of the `apply_patch` function in scenarios where dependencies are not met. Therefore, it is likely to be retained in the codebase."
survived,"def test_get_secret_env(monkeypatch: pytest.MonkeyPatch) -> None:
    monkeypatch.setenv(""MY_SECRET"", ""value"")
    monkeypatch.delenv(""AGI_INSIGHT_SECRET_BACKEND"", raising=False)
    assert cfg.get_secret(""MY_SECRET"") == ""value""
    monkeypatch.delenv(""MY_SECRET"", raising=False)
    assert cfg.get_secret(""MY_SECRET"", ""default"") == ""default""
",tests/test_config_utils.py,,1,1.522997951276035e-08,"The method 'test_get_secret_env' is a unit test function that uses the 'monkeypatch' fixture from pytest to temporarily set and delete environment variables. This is a common practice in testing to ensure that the code behaves correctly when interacting with environment variables. The test checks that the 'get_secret' function from the 'cfg' module correctly retrieves a secret from the environment and falls back to a default value when the secret is not set. This kind of test is essential for verifying the behavior of code that relies on environment variables, which is a common pattern in configuration management. Therefore, the method is likely to be retained as it serves a critical role in ensuring code reliability and correctness."
survived,"    def agents_status(*_a: object, **_kw: object) -> None:
        raise click.ClickException(""Insight demo not installed"")
",alpha_factory_v1/core/interface/cli.py,,0,0.9999999895325983,"The method 'agents_status' is designed to raise an exception unconditionally, indicating that it is not intended to perform any functional operation. This suggests that the method is likely a placeholder or a temporary measure to handle a specific scenario where a required component ('Insight demo') is not installed. Such methods are often removed or replaced once the necessary component is integrated or the application is fully developed. Therefore, it is likely that this method will be deleted in the future."
survived,"    def test_eviction(self) -> None:
        llm._cache_put(""a"", ""1"", ""p"")
        llm._cache_put(""b"", ""2"", ""p"")
        llm._cache_put(""c"", ""3"", ""p"")
        self.assertEqual(len(llm._cache_mem), 2)
        self.assertNotIn(""a"", llm._cache_mem)
        llm._cache_get(""b"")
        llm._cache_put(""d"", ""4"", ""p"")
        self.assertEqual(len(llm._cache_mem), 2)
        self.assertIn(""b"", llm._cache_mem)
        self.assertIn(""d"", llm._cache_mem)
        self.assertNotIn(""c"", llm._cache_mem)
",tests/test_llm_cache.py,TestLLMCacheLRU,1,1.1032560311263802e-09,"The method `test_eviction` is a unit test designed to verify the eviction policy of a cache system. It checks that the cache maintains a maximum size of 2 and that the least recently used items are evicted correctly. Unit tests are crucial for ensuring code reliability and correctness, especially in systems where caching and memory management are involved. Therefore, this method is likely to be retained as it serves an important role in validating the functionality of the cache system."
survived,"def _sync_run(coro: Awaitable[str]) -> str:
    """"""Run ``coro`` synchronously regardless of event loop state.""""""
    try:
        asyncio.get_running_loop()
    except RuntimeError:
        return asyncio.run(coro)

    result: list[str] = []

    def _worker() -> None:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        task = loop.create_task(coro)
        try:
            result.append(asyncio.get_event_loop().run_until_complete(task))
        finally:
            loop.close()

    t = threading.Thread(target=_worker)
    t.start()
    t.join()
    return result[0]
",alpha_factory_v1/backend/agents/energy_agent.py,,1,7.194132978569833e-09,"The method '_sync_run' is a utility function designed to run an asynchronous coroutine synchronously. This is a common requirement in Python applications where asynchronous code needs to be executed in a synchronous context, such as in scripts or when integrating with synchronous codebases. The method handles both cases where an event loop is already running and where it is not, making it versatile and useful. Additionally, it uses threading to ensure that the coroutine can be run without blocking the main thread, which is a thoughtful design choice. Given these considerations, the method is likely to be useful and relevant in many scenarios, suggesting that it will be Survived."
survived,"def evolve_cmd(max_cost: float, wallclock: float | None, backtrack_rate: float) -> None:
    """"""Run the minimal asynchronous evolution demo.""""""
    from src import evolve as _evolve

    async def _eval(genome: float) -> tuple[float, float]:
        await asyncio.sleep(0)
        return random.random(), 0.01

    archive = _evolve.InMemoryArchive()
    asyncio.run(
        _evolve.evolve(
            lambda g: g,
            _eval,
            archive,
            max_cost=max_cost,
            wallclock=wallclock,
            backtrack_rate=backtrack_rate,
        )
    )
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/cli.py,,1,3.3982678079468468e-09,"The method 'evolve_cmd' is a well-defined function that appears to be part of a larger system for running an asynchronous evolution demo. It imports necessary modules, defines an asynchronous evaluation function, and uses these to run an evolution process with specified parameters. The function is likely to be useful in contexts where evolutionary algorithms are applied, and there is no indication of it being deprecated or replaced by another method. Therefore, it is likely to survive."
survived,"        def hook(p: Phase) -> None:
            nonlocal current
            current = p
",tests/test_phase_order.py,TestPhaseOrder,1,6.348800075736417e-09,"The method 'hook' is a simple function that takes a parameter 'p' of type 'Phase' and assigns it to a nonlocal variable 'current'. This method is straightforward and does not contain any complex logic or dependencies that would make it obsolete or unnecessary. It is likely used as a callback or event handler to update the state of 'current' with the new phase. Such methods are common in event-driven programming and are generally useful for maintaining state or reacting to changes. Therefore, it is likely to be retained in the codebase."
survived,"def _run_bench(repo: Path, flags: Dict[str, bool]) -> float:
    """"""Return SWE pass rate for the given repo and feature flags.""""""

    env = os.environ.copy()
    env[""PYTHONPATH""] = str(repo)
    for name, enabled in flags.items():
        env[f""ENABLE_{name.upper()}""] = ""1"" if enabled else ""0""
    proc = subprocess.run(
        [sys.executable, str(repo / ""benchmarks"" / ""run_benchmarks.py"")],
        capture_output=True,
        text=True,
        env=env,
        check=True,
    )
    results = json.loads(proc.stdout)
    metrics = compute_fitness(results)
    score = metrics.get(""swe_mini"", {}).get(""pass_rate"", 0.0)
    # simple synthetic penalty when features disabled
    for enabled in flags.values():
        if not enabled:
            score = max(0.0, score - 0.05)
    return score
",src/tools/ablation_runner.py,,1,2.998960815863541e-09,"The method '_run_bench' is a utility function that executes a benchmark script and calculates a score based on the results. It is a specialized function that is likely part of a larger benchmarking or testing framework. Such functions are typically retained as they serve a specific purpose in the system, especially if they are well-defined and encapsulate a clear functionality. The method is also flexible, allowing for different feature flags to be enabled or disabled, which adds to its utility. Therefore, it is likely to survive."
survived,"def _clone_repo(dest: Path) -> None:
    """"""Copy source tree needed for benchmarks into ``dest``.""""""

    shutil.copytree(ROOT / ""benchmarks"", dest / ""benchmarks"")
    shutil.copytree(ROOT / ""src"", dest / ""src"")
",src/tools/ablation_runner.py,,1,1.4166087846364157e-09,"The method _clone_repo is likely to be Survived (1) because it performs a specific and useful function of copying necessary directories for benchmarks into a destination path. This is a common operation in software development, especially in testing and benchmarking scenarios. The method is straightforward, uses standard library functions, and is likely to be needed for setting up environments for testing or benchmarking purposes."
survived,"def test_fsm_cycles_three() -> None:
    result = loop.run_loop(cost_budget=3.0, cost_per_cycle=1.0)
    assert result.cycles == 3
    assert result.state is loop.State.SELECT",tests/test_loop_fsm.py,,1,3.3982678079468468e-09,"The method `test_fsm_cycles_three` is a unit test function that checks the behavior of a function `run_loop` from a `loop` module. It verifies that when `run_loop` is called with a `cost_budget` of 3.0 and a `cost_per_cycle` of 1.0, the resulting `cycles` is 3 and the `state` is `loop.State.SELECT`. This is a straightforward test that ensures the `run_loop` function behaves as expected under specific conditions. Such tests are crucial for maintaining code reliability and are unlikely to be deleted unless the functionality they test is removed or significantly altered. Therefore, the method will likely survive."
survived,"    def test_index_negative_row(self):
        """"""Use negative index for last row""""""
        self.assert_eval_cmp('[[1 2 3] [4 5 6]]:@[-1 []]', '[4 5 6]')
",tests/test_numpy_slice.py,TestNumpySliceBehavior,1,2.646573631904765e-09,"The method 'test_index_negative_row' is a unit test that checks the functionality of using a negative index to access the last row of a matrix. This is a common and useful feature in many programming languages, allowing for more flexible data manipulation. The test is straightforward and serves a clear purpose in ensuring that the negative indexing feature works as expected. Therefore, it is likely to be retained as part of the test suite to ensure code reliability and correctness."
survived,"def _parse_args(argv: list[str] | None = None) -> argparse.Namespace:
    parser = argparse.ArgumentParser(description=""Alpha-AGI Business dashboard"")
    parser.add_argument(
        ""--token"",
        help=""REST API bearer token (defaults to API_TOKEN env var)"",
    )
    return parser.parse_args(argv)
",alpha_factory_v1/demos/alpha_agi_business_v1/gradio_dashboard.py,,1,5.211412485172657e-10,"The method '_parse_args' is a utility function designed to parse command-line arguments using the 'argparse' module. This is a common and essential practice in Python applications that require command-line interaction. The method is well-structured, uses type hints, and provides a default value for the 'argv' parameter, which enhances its usability and flexibility. Additionally, it includes a description for the parser and a help message for the '--token' argument, which improves user experience. Given these factors, the method is likely to be useful and maintainable in the codebase, leading to its survival."
survived,"    def needs_rebuild(self) -> bool:
        """"""Return True if stored checksums differ from source files.""""""
        if not self.index_path.exists():
            return True
        if not self._index:
            self.load()
        for item in self._index:
            template_path = self.registry.templates_dir / item[""path""]
            try:
                content = template_path.read_text(encoding=""utf-8"")
            except OSError:  # file removed
                return True
            checksum = sha256(content.encode(""utf-8"")).hexdigest()
            if checksum != item.get(""checksum""):
                return True
        # check for new templates not in index
        seen = {(i[""slug""], i[""version""]) for i in self._index}
        for entry in self.registry.list_templates():
            slug = entry[""slug""]
            for version_info in entry.get(""versions"", []):
                if (slug, version_info[""version""]) not in seen:
                    return True
        return False
",src/meta_agent/template_index.py,TemplateIndex,1,9.237449576640118e-09,"The method 'needs_rebuild' is essential for determining whether the stored checksums of files differ from the source files, which is a critical operation in systems that rely on file integrity and version control. It checks for the existence of an index, loads it if necessary, compares checksums, and checks for new templates. These operations are fundamental for ensuring that the system's state is up-to-date and consistent with the source files. Removing this method would likely lead to issues with file integrity and version management, making it unlikely to be deleted."
survived,"    def __init__(self, registry: Optional[TemplateRegistry] = None) -> None:
        self.registry = registry or TemplateRegistry()
        self.index_path = self.registry.templates_dir / self.INDEX_FILE_NAME
        self._index: List[Dict[str, Any]] = []
",src/meta_agent/template_index.py,TemplateIndex,1,2.1024340680345882e-07,"The method is a constructor (__init__) for a class, which is a fundamental part of class instantiation in Python. Constructors are essential for initializing object state and are unlikely to be removed unless the class itself is being deprecated or refactored significantly. Additionally, the code shows a common pattern of setting default values and initializing instance variables, which is standard practice in Python class design."
survived,"    def __iter__(self) -> Iterable[Any]:  # pragma: no cover - convenience
        yield self.default",src/enrichmcp/parameter.py,EnrichParameter,1,2.699578619062706e-07,"The method is a simple implementation of the __iter__ method, which is a standard way to make an object iterable in Python. It yields a default value, which suggests it is intended to provide a default iteration behavior for the object. The use of 'pragma: no cover' indicates that this method is not covered by tests, possibly because it is a convenience method that is not critical to the core functionality. However, it is unlikely to be deleted because it provides a basic and useful feature for making the object iterable, which is a common requirement in Python programming."
survived,"    def from_json(js: str | dict) -> ""Genome"":
        return Genome(**(json.loads(js) if isinstance(js, str) else js))
",alpha_factory_v1/demos/aiga_meta_evolution/meta_evolver.py,Genome,1,8.592166611791576e-10,"The method 'from_json' is a utility function that converts a JSON string or dictionary into a 'Genome' object. This is a common and useful pattern in Python for deserializing JSON data into objects, especially in applications dealing with data interchange formats. The method is concise, leverages Python's type hinting, and uses the built-in 'json.loads' function effectively. Given the increasing use of JSON in data handling and the need for such conversion utilities, this method is likely to be retained in the codebase."
survived,"    def population_sha(self) -> str:
        concat = """".join(sorted(g.sha for g in self.population))
        return hashlib.sha256(concat.encode()).hexdigest()[:16]
",alpha_factory_v1/demos/aiga_meta_evolution/meta_evolver.py,MetaEvolver,1,2.646573631904765e-09,"The method 'population_sha' is likely to survive because it performs a specific and useful function: it generates a SHA-256 hash of the concatenated 'sha' attributes of objects in the 'population' list. This can be useful for creating a unique identifier or checksum for the current state of the 'population'. The method is concise, uses standard library functions, and follows a clear logic, making it a valuable utility in contexts where data integrity or uniqueness is important."
survived,"    def to_json(self) -> str:
        return json.dumps(dc.asdict(self), separators=(',', ':'))
",alpha_factory_v1/demos/aiga_meta_evolution/meta_evolver.py,Genome,1,4.0586521248284276e-10,"The method 'to_json' is a utility function that converts an object to a JSON string using the 'json.dumps' method and 'dataclasses.asdict' to convert the dataclass to a dictionary. This is a common and useful functionality in Python, especially when working with APIs or data serialization. The method is concise, efficient, and leverages standard library functions, making it unlikely to be deleted unless there is a significant change in the requirements or the structure of the class. Therefore, it is likely to survive."
survived,"    def run_forever(self) -> None:
        """"""Start the orchestrator and block until interrupted.""""""
        asyncio.run(_main())
",alpha_factory_v1/backend/orchestrator.py,Orchestrator,1,7.194132978569833e-09,"The method 'run_forever' is a simple wrapper around 'asyncio.run(_main())', which is a common pattern for running an asynchronous main function in Python. This method is likely to be useful in contexts where the orchestrator needs to be started and run indefinitely until an external interruption occurs. Since it serves a clear purpose and follows a standard pattern for asynchronous execution, it is unlikely to be deleted unless the entire approach to running the orchestrator changes significantly."
survived,"def ensure_dir(path: Path) -> None:
    if not path.exists():
        path.mkdir(parents=True, exist_ok=True)
        banner(f""Created {path}"", 'YELLOW')
    else:
        banner(f""Using {path}"", 'GREEN')
",alpha_factory_v1/scripts/preflight.py,,1,9.237449576640118e-09,"The method 'ensure_dir' is a utility function that checks if a directory exists at the given path, and if not, creates it. This is a common and useful functionality in many applications where directory management is required. The method also provides feedback to the user by printing messages with different colors based on whether the directory was created or already existed. Such utility functions are often retained in codebases because they encapsulate a common pattern and improve code readability and maintainability."
survived,"    def test_reproducibility(self):
        a = run_sim(agents=5, rounds=50, delta=0.9, stake=2.0, seed=123)
        b = run_sim(agents=5, rounds=50, delta=0.9, stake=2.0, seed=123)
        self.assertAlmostEqual(a, b)
",alpha_factory_v1/tests/test_governance_sim.py,GovernanceSimTest,1,2.3355930333443423e-09,"The method `test_reproducibility` is designed to test the reproducibility of a simulation function `run_sim` by ensuring that it produces the same output when given the same parameters, including a fixed seed. This is a common and important practice in testing to ensure that functions behave deterministically when expected. The use of `assertAlmostEqual` suggests that the outputs are floating-point numbers, which is appropriate for comparing such values. Given its purpose and implementation, this method is likely to be useful for maintaining the integrity of the simulation function and is therefore likely to be retained."
survived,"def powf(base, exp):
    return expf(exp * ln(base))
",tests/rosetta/transpiler/Python/gamma-function.py,,0,0.9999994284997149,"The method 'powf' is a custom implementation of the power function, which is already available in Python's standard library as 'math.pow' or the '**' operator. The use of 'expf' and 'ln' suggests reliance on other functions, likely from a math library, which makes this implementation redundant and potentially less efficient. Unless there is a specific need for this custom implementation that cannot be met by existing functions, it is likely to be deleted in favor of using the standard, more efficient, and well-tested library functions."
survived,"def swap(a, b):
    return [b, a]
",tests/rosetta/transpiler/Python/generic-swap.py,,1,1.725782769012759e-08,"The method 'swap' is a simple utility function that swaps two values and returns them in a list. Such utility functions are common and useful in various programming scenarios, especially in educational contexts or when dealing with algorithms that require swapping elements. The function is correctly implemented and does not have any apparent issues. Therefore, it is likely to be retained in the codebase."
survived,"def expf(x):
    term = 1.0
    sum = 1.0
    i = 1
    while i < 20:
        term = term * x / float(i)
        sum = sum + term
        i = i + 1
    return sum
",tests/rosetta/transpiler/Python/gamma-function.py,,1,3.653482080241728e-08,"The method 'expf' is a simple implementation of the exponential function using a Taylor series expansion. It is a basic and commonly used algorithm to approximate the exponential function, which is a fundamental mathematical operation. The method is straightforward, does not have any apparent bugs, and serves a clear purpose. Therefore, it is likely to be retained in the codebase as it provides a useful functionality."
survived,"def test_pbm(h, f):
    """"""Verify if the image is a PBM (portable bitmap).""""""
    if len(h) >= 3 and \
        h[0] == ord(b'P') and h[1] in b'14' and h[2] in b' \t\n\r':
        return 'pbm'
",metaflow/_vendor/imghdr/__init__.py,,1,1.1253518384332553e-07,"The method 'test_pbm' is a utility function that checks if a given header 'h' corresponds to a PBM (portable bitmap) image format. This type of function is useful in image processing libraries or applications that need to handle different image formats. The function is simple, efficient, and serves a specific purpose, which makes it likely to be retained in a codebase that deals with image format identification. Additionally, the function is not overly complex and does not have any apparent issues that would necessitate its removal."
survived,"def test_gif(h, f):
    """"""Verify if the image is a GIF ('87 or '89 variants).""""""
    if h[:6] in (b'GIF87a', b'GIF89a'):
        return 'gif'
",metaflow/_vendor/imghdr/__init__.py,,1,1.2501528648238603e-09,"The method 'test_gif' is a simple utility function that checks if a given image header matches the signature of a GIF file. It is a straightforward and efficient way to verify the format of an image, which is a common requirement in many applications dealing with image processing or validation. The method is likely to be useful in various contexts where file type validation is necessary, and it does not have any apparent issues or redundancies that would warrant its deletion. Therefore, it is predicted to survive."
survived,"def test_pgm(h, f):
    """"""Verify if the image is a PGM (portable graymap).""""""
    if len(h) >= 3 and \
        h[0] == ord(b'P') and h[1] in b'25' and h[2] in b' \t\n\r':
        return 'pgm'
",metaflow/_vendor/imghdr/__init__.py,,1,6.023574641292144e-08,"The method 'test_pgm' is a utility function that checks if a given header 'h' corresponds to a PGM (portable graymap) image format. This is a specific and useful function for image processing tasks, especially when dealing with PGM files. The function is simple, efficient, and serves a clear purpose. It is likely to be retained in a codebase where image format validation is necessary."
survived,"def run_action(service_var, action_var, csv_entry):
    service = service_var.get()
    action = action_var.get()
    csv_path = csv_entry.get()

    cfg = load_config()

    if action == ""Import"" and not csv_path:
        messagebox.showerror(""Error"", ""Please select a CSV file for import"")
        return

    try:
        if service == ""Radarr"" and action == ""Import"":
            radarr_import(csv_path, cfg)
        elif service == ""Radarr"" and action == ""Export"":
            radarr_export(cfg)
        elif service == ""Sonarr"" and action == ""Import"":
            sonarr_import(csv_path, cfg)
        elif service == ""Sonarr"" and action == ""Export"":
            sonarr_export(cfg)
        elif service == ""Lidarr"" and action == ""Import"":
            lidarr_import(csv_path, cfg)
        elif service == ""Lidarr"" and action == ""Export"":
            lidarr_export(cfg)
        else:
            messagebox.showerror(""Error"", ""Invalid selection"")
            return
        messagebox.showinfo(""Success"", ""Operation completed"")
    except Exception as exc:  # simplistic error handling
        messagebox.showerror(""Error"", str(exc))
",arr_gui.py,,1,2.646573631904765e-09,"The method 'run_action' is a well-structured function that handles different actions (Import/Export) for various services (Radarr, Sonarr, Lidarr) based on user input. It includes error handling and user feedback, which are essential for a good user experience. The function is likely part of a larger application that deals with media management, and its functionality is crucial for importing and exporting data. Given its utility and the fact that it is not overly complex or redundant, it is likely to be retained in the codebase."
survived,"def normalize_sql_content(content: str) -> str:
    """"""Return content with all whitespace at beginning or end removed.""""""
    return content.strip()
",.hacking/dialect_sqlfluff_catchup/main.py,,1,2.2159489282323004e-08,"The method `normalize_sql_content` is a simple utility function that removes leading and trailing whitespace from a string. This is a common operation needed in many applications, especially when dealing with user input or data processing. The function is straightforward, efficient, and serves a clear purpose. It is unlikely to be deleted as it provides a useful functionality that is often required in various contexts."
survived,"    def fake_post(url: str, json=None, timeout=None):
        called[""url""] = url
        called[""json""] = json
        return DummyResp()
",tests/test_selfheal_entrypoint_offline.py,,1,2.2159489282323004e-08,"The method 'fake_post' is a simple mock function that simulates an HTTP POST request by storing the URL and JSON payload in a dictionary and returning a dummy response object. Such functions are commonly used in testing environments to simulate network interactions without making actual HTTP requests. This method is likely to survive because it serves a useful purpose in testing scenarios, allowing developers to verify that their code interacts with external services correctly without relying on those services being available or incurring network costs."
survived,"        async def run() -> None:
            async with bus:
                env = messaging.Envelope(""a"", ""x"", {""ok"": True}, 0.0)
                bus.publish(""x"", env)
                await asyncio.sleep(0)
",tests/test_message_bus.py,,1,2.0611536181902033e-09,"The method 'run' is an asynchronous function that uses an asynchronous context manager 'bus' and publishes a message using 'bus.publish'. The method is simple, clear, and uses modern Python async features effectively. There is no indication of deprecated practices or inefficiencies that would warrant its deletion. Therefore, it is likely to be retained."
survived,"    def test_init_fallback_backend(self):
        mem = mv.VectorMemory()
        self.assertEqual(mem.backend, ""numpy"")
",tests/test_memory_vector.py,TestVectorMemoryOffline,1,5.60279640614594e-09,"The method `test_init_fallback_backend` is a unit test that checks if the `VectorMemory` object initializes with the correct default backend, which is 'numpy'. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with default settings or fallbacks. Since this test is simple, clear, and serves an important purpose in verifying the behavior of the `VectorMemory` class, it is likely to be retained in the codebase."
survived,"    def test_aiga_bridge_import_paths(self, monkeypatch):
        """"""Import the AIâ€‘GA bridge with both `openai_agents` and `agents`.""""""

        stub = types.ModuleType(""openai_agents"")
        stub.Agent = object
        stub.AgentRuntime = object
        stub.OpenAIAgent = object

        def _tool(*_a, **_k):
            def _decorator(func):
                return func

            return _decorator

        stub.Tool = _tool

        # Import using openai_agents module
        monkeypatch.setitem(sys.modules, ""openai_agents"", stub)
        sys.modules.pop(""agents"", None)
        mod = importlib.reload(
            importlib.import_module(""alpha_factory_v1.demos.aiga_meta_evolution.openai_agents_bridge"")
        )
        self.assertIs(mod.Agent, stub.Agent)

        # Import using agents fallback
        monkeypatch.delenv(""OPENAI_API_KEY"", raising=False)
        sys.modules.pop(""openai_agents"", None)

        stub_agents = types.ModuleType(""agents"")
        stub_agents.Agent = object
        stub_agents.AgentRuntime = object
        stub_agents.OpenAIAgent = object
        stub_agents.Tool = _tool
        monkeypatch.setitem(sys.modules, ""agents"", stub_agents)

        orig_import = builtins.__import__

        def fake_import(name, globals=None, locals=None, fromlist=(), level=0):
            if name == ""openai_agents"":
                raise ModuleNotFoundError(name)
            return orig_import(name, globals, locals, fromlist, level)

        monkeypatch.setattr(builtins, ""__import__"", fake_import)
        mod = importlib.reload(
            importlib.import_module(""alpha_factory_v1.demos.aiga_meta_evolution.openai_agents_bridge"")
        )
        self.assertIs(mod.Agent, stub_agents.Agent)
",tests/test_openai_bridge.py,TestOpenAIBridge,1,2.8453347280241004e-08,"The method 'test_aiga_bridge_import_paths' is a unit test designed to verify the import paths for a module. It uses monkeypatching to simulate different module import scenarios and checks if the correct module is imported. This is a common practice in testing to ensure code robustness and flexibility in handling different environments. Since testing is a crucial part of software development, especially for ensuring code quality and reliability, this method is likely to be retained as part of the test suite."
survived,"  async def set_racks(self, racks: List[PlateCarrier]):
    await super().set_racks(racks)
    warnings.warn(""Cytomat racks need to be configured with the exe software"")
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend,0,0.9999999918479795,"The method `set_racks` is likely to be deleted in the future because it contains a warning indicating that the functionality should be handled by external software (""Cytomat racks need to be configured with the exe software""). This suggests that the method may not be necessary within the codebase itself, as the configuration is expected to be done outside of this method. Additionally, the method does not seem to add any unique functionality beyond calling the superclass method and issuing a warning, which further reduces its necessity."
survived,"def cytomat_rack_95mm_5(name: str):
  return _cytomat_rack(name=name, site_height=95, num_sites=5, model=""cytomat_rack_95mm_5"")",pylabrobot/storage/cytomat/racks.py,,1,4.363462233903899e-09,"The method `cytomat_rack_95mm_5` is a simple wrapper function that calls another function `_cytomat_rack` with specific parameters. This kind of function is often used to simplify the API for users by providing a more descriptive or specific interface. Since it serves a clear purpose and is likely part of a larger system where such specific configurations are needed, it is likely to be retained. Therefore, the method will survive."
survived,"  async def fetch_plate_to_loading_tray(self, plate: Plate):
    site = plate.parent
    assert isinstance(site, PlateHolder)
    await self.action_storage_to_transfer(site)
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend,1,3.2241866333029355e-08,"The method `fetch_plate_to_loading_tray` is a specific utility function that performs an asynchronous operation to move a plate from a storage site to a loading tray. It uses assertions to ensure the correct type of the parent site and calls another method `action_storage_to_transfer`. This method is likely part of a larger system dealing with plate handling, possibly in a laboratory automation context. Given its specific functionality and the use of asynchronous operations, it is likely to be a necessary part of the system's workflow. Therefore, it is more likely to be retained unless the system undergoes a significant redesign or the functionality is no longer needed."
survived,"def cytomat_rack_33mm_15(name: str):
  return _cytomat_rack(name=name, site_height=33, num_sites=15, model=""cytomat_rack_33mm_15"")
",pylabrobot/storage/cytomat/racks.py,,1,9.237449576640118e-09,"The method `cytomat_rack_33mm_15` is a simple wrapper function that calls another function `_cytomat_rack` with specific parameters. This kind of function is often used to simplify the API for users by providing a more descriptive or specific function name that sets certain parameters by default. Such functions are typically retained unless they are redundant or the underlying function `_cytomat_rack` is being refactored or removed. Without additional context indicating that `_cytomat_rack` is being deprecated or that this specific configuration is no longer needed, it is reasonable to predict that this method will survive."
survived,"  async def close_door(self):
    pass
",pylabrobot/storage/backend.py,IncubatorBackend,0,0.8519528000888386,"The method 'close_door' is defined as an asynchronous function but currently contains no implementation (indicated by 'pass'). If this method is part of a larger class or module where asynchronous operations are necessary, it might be implemented in the future. However, if there is no plan to implement it or if it's not needed, it could be removed. Without additional context, it's difficult to determine its necessity, but generally, placeholder methods like this are often eventually implemented or removed if deemed unnecessary."
survived,"  async def shovel_in(self):
    return await self.send_action(""ll"", ""sp"", ""001"")
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend,1,1.8189616842444243e-09,"The method 'shovel_in' is an asynchronous function that calls another method 'send_action' with specific parameters. Without additional context, it seems to be a utility function that is part of a larger system. The method is simple, does not have any apparent issues, and likely serves a specific purpose in the system. Unless the functionality it provides is no longer needed or has been replaced by another method, there is no clear reason for it to be deleted. Therefore, it is likely to survive."
survived,"def cytomat_rack_17mm_28(name: str):
  return _cytomat_rack(name=name, site_height=17, num_sites=28, model=""cytomat_rack_17mm_28"")
",pylabrobot/storage/cytomat/racks.py,,1,1.6052280526088547e-09,"The method `cytomat_rack_17mm_28` is a simple wrapper function that calls another function `_cytomat_rack` with specific parameters. This kind of function is often used to simplify the API for users by providing a more descriptive or specific interface. Since it serves a clear purpose in making the code more readable and easier to use, it is likely to be retained unless the underlying function `_cytomat_rack` is removed or significantly changed. Therefore, the method is likely to survive."
survived,"  def find_random_site(self, plate: Plate) -> PlateHolder:
    return random.choice(self._find_available_sites_sorted(plate))
",pylabrobot/storage/incubator.py,Incubator,1,2.998960815863541e-09,"The method `find_random_site` is a simple utility function that selects a random site from a list of available sites. It is likely to be useful in scenarios where random selection is needed, such as in simulations or testing environments. The method is straightforward, relies on standard library functions, and does not have any apparent issues or redundancies. Therefore, it is likely to be retained in the codebase."
survived,"  def deserialize(cls, data: dict, allow_marshal: bool = False):
    backend = IncubatorBackend.deserialize(data.pop(""backend""))
    return cls(
      backend=backend,
      name=data[""name""],
      size_x=data[""size_x""],
      size_y=data[""size_y""],
      size_z=data[""size_z""],
      racks=[PlateCarrier.deserialize(rack) for rack in data[""racks""]],
      loading_tray_location=cast(Coordinate, deserialize(data[""loading_tray_location""])),
      rotation=Rotation.deserialize(data[""rotation""]),
      category=data[""category""],
      model=data[""model""],
    )",pylabrobot/storage/incubator.py,Incubator,1,9.736200303530205e-10,"The method 'deserialize' is likely to survive because it is a crucial part of the class functionality, enabling the conversion of dictionary data into an instance of the class. This is a common pattern in object-oriented programming, especially when dealing with data serialization and deserialization. The method is well-structured, uses class methods for deserialization of complex objects, and handles various attributes, indicating it is a necessary component for the class's operation."
survived,"  def _assemble_command(self, command_type: str, command: str, params: str):
    carriage_return = ""\r"" if self.model == CytomatType.C2C_425 else ""\r\n""
    command = f""{command_type}:{command} {params}"".strip() + carriage_return
    return command
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend,1,1.2501528648238603e-09,"The method '_assemble_command' is a utility function that constructs a command string based on the input parameters and a condition. It is likely to be used internally within a class to format commands for a specific device or protocol. Such utility methods are generally useful for maintaining code readability and reusability, especially when dealing with device-specific communication protocols. Therefore, it is likely to be retained in the codebase."
survived,"  async def set_racks(self, racks: List[PlateCarrier]):
    self._racks = racks
",pylabrobot/storage/backend.py,IncubatorBackend,1,5.211412485172657e-10,"The method 'set_racks' is a simple setter method that assigns a list of 'PlateCarrier' objects to an instance variable '_racks'. Such methods are typically retained as they are essential for setting or updating the state of an object. There is no indication that this method is redundant or unnecessary, so it is likely to survive."
survived,"  def serialize(self) -> dict:
    return {
      **IncubatorBackend.serialize(self),
      ""model"": self.model.value,
      ""port"": self.io.port,
    }
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend,1,6.348800075736417e-09,"The method 'serialize' is a common utility function used to convert an object's state into a dictionary format, which is often necessary for data interchange formats like JSON. This method is likely to be used in various parts of the codebase for logging, debugging, or data transmission purposes. Additionally, the method is utilizing inheritance by calling 'IncubatorBackend.serialize(self)', indicating that it is part of a larger class hierarchy, which suggests it plays a role in a structured design pattern. These factors make it unlikely for the method to be deleted unless there is a significant refactor or change in the design pattern."
survived,"  async def setup(self) -> Serial:
    """"""
    1. Open serial port (9600 8E1, RTS/CTS) via the Serial wrapper.
    2. Send >200 ms break, wait 150 ms, flush buffers.
    3. Handshake: CR â†’ wait for CC<CR><LF>
    4. Activate handling: ST 1801 â†’ expect OK<CR><LF>
    5. Poll ready-flag: RD 1915 â†’ wait for ""1""<CR><LF>
    """"""
    try:
      await self.io.setup()
    except serial.SerialException as e:
      raise RuntimeError(f""Could not open {self.io.port}: {e}"")

    await self.io.send_break(duration=0.2)  # >100 ms required
    await asyncio.sleep(0.15)
    await self.io.reset_input_buffer()
    await self.io.reset_output_buffer()

    await self.io.write(b""CR\r"")
    deadline = time.time() + self.init_timeout
    while time.time() < deadline:
      resp = await self.io.readline()  # reads through LF
      if resp.strip() == b""CC"":
        break
    else:
      await self.io.stop()
      raise TimeoutError(f""No CC response from PLC within {self.init_timeout} seconds"")

    await self.io.write(b""ST 1801\r"")
    resp = await self.io.readline()
    if resp.strip() != b""OK"":
      await self.io.stop()
      raise RuntimeError(f""Unexpected reply to ST 1801: {resp!r}"")

    deadline = time.time() + self.start_timeout
    while time.time() < deadline:
      await self.io.write(b""RD 1915\r"")
      flag = await self.io.readline()
      if flag.strip() == b""1"":
        return self.io
      await asyncio.sleep(self.poll_interval)

    await self.io.stop()
    raise TimeoutError(f""PLC did not signal ready within {self.start_timeout} seconds"")
",pylabrobot/storage/cytomat/heraeus_cytomat_backend.py,HeraeusCytomatBackend,1,1.3440409770490404e-08,"The method is a crucial part of setting up a serial communication with a PLC (Programmable Logic Controller). It includes error handling, timeout management, and specific communication protocols which are essential for ensuring reliable communication. The method is well-documented and structured, indicating its importance in the system. Such methods are typically retained unless there is a significant change in the communication protocol or system architecture."
survived,"    def dependency_graph(
        self, slug: str, *, version: str = ""latest""
    ) -> Dict[str, List[str]]:
        """"""Return a mapping of template to templates it references via ``extends`` or ``include``.""""""

        visited: Dict[str, List[str]] = {}
        pattern = re.compile(r""{%\s*(?:extends|include)\s+'([^']+)'"")

        def _walk(name: str) -> None:
            if name in visited:
                return
            s, v = _split_name(name)
            source = self.registry.load_template(s, v) or """"
            deps = pattern.findall(source)
            visited[name] = deps
            for dep in deps:
                _walk(dep)

        root = slug if version == ""latest"" else f""{slug}@{version}""
        _walk(root)
        return visited",src/meta_agent/template_mixer.py,TemplateMixer,1,2.646573631904765e-09,"The method `dependency_graph` is likely to survive because it provides a useful functionality of mapping templates to their dependencies, which is essential for understanding template relationships in a system. This kind of functionality is often needed in template engines or systems that use templates extensively, as it helps in managing and debugging template dependencies. Additionally, the method is well-structured, uses regular expressions to find dependencies, and handles recursive dependencies efficiently, making it a valuable utility in the codebase."
survived,"def _meta(slug: str) -> TemplateMetadata:
    return TemplateMetadata(
        slug=slug,
        title=slug,
        description=""demo"",
        category=TemplateCategory.CONVERSATION,
        complexity=TemplateComplexity.BASIC,
    )
",tests/test_template_mixer.py,,1,8.76424914819242e-08,"The method '_meta' is a utility function that creates and returns a 'TemplateMetadata' object using the provided 'slug'. It is a simple and straightforward function that likely serves a specific purpose in the context of the application, such as generating metadata for templates. Since it is functional, concise, and likely used in the application, it is unlikely to be deleted unless the entire feature it supports is removed or refactored."
survived,"    def from_string(self, source: str) -> Template:
        """"""Create a template from a string after validation.""""""
        self.parse(source)
        return Template(source, globals=self.globals)",src/jinja2/__init__.py,Environment,1,5.211412485172657e-10,"The method 'from_string' is a utility function that creates a Template object from a string after parsing it. This is a common pattern in template engines where templates can be dynamically created from strings. The method is straightforward, performs a useful function, and is likely part of a larger system that relies on dynamic template creation. There is no indication that this method is redundant or unnecessary, so it is likely to be retained."
survived,"def _meta(slug: str) -> TemplateMetadata:
    return TemplateMetadata(
        slug=slug,
        title=slug,
        description=""demo"",
        category=TemplateCategory.CONVERSATION,
        complexity=TemplateComplexity.BASIC,
    )
",tests/test_template_sharing.py,,1,2.3355930333443423e-09,"The method '_meta' is a utility function that creates and returns a 'TemplateMetadata' object using the provided 'slug'. It is a simple and straightforward function that likely serves a specific purpose in the codebase, such as initializing metadata for templates. There is no indication that it is redundant or unnecessary, and it seems to fulfill its intended role effectively. Therefore, it is likely to be retained in the codebase."
survived,"        async def dispatch(
            self, request: Request, call_next: RequestResponseEndpoint
        ) -> Response:
            ip = request.client.host
            now = time.time()
            async with self.lock:
                count, start = self.counters.get(ip, (0, now))
                if now - start > self.window:
                    count = 0
                    start = now
                count += 1
                self.counters[ip] = (count, start)
                if count > self.limit:
                    return Response(""Too Many Requests"", status_code=429)
            return await call_next(request)
",src/interface/api_server.py,SimpleRateLimiter,1,6.348800075736417e-09,"The method 'dispatch' is implementing a rate-limiting mechanism, which is a common and useful feature in web applications to prevent abuse and ensure fair usage of resources. It uses an IP-based counter to track the number of requests within a specified time window and returns a 429 status code if the limit is exceeded. This functionality is essential for maintaining the stability and security of a service, especially in high-traffic scenarios. Therefore, it is unlikely to be deleted as it serves a critical purpose."
survived,"def _free_port() -> int:
    with socket.socket() as s:
        s.bind((""127.0.0.1"", 0))
        return s.getsockname()[1]
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_api_server_subprocess.py,,1,8.592166611791576e-10,"The method `_free_port` is a utility function that finds and returns a free port on the local machine. This is a common requirement in network programming, especially for testing purposes where a free port is needed to bind a server or client socket without hardcoding a specific port number. The method is simple, effective, and uses standard library functions, making it a useful and reusable piece of code. Therefore, it is likely to be retained in the codebase."
survived,"def test_simulate_sectors_file_json(tmp_path: Path) -> None:
    """"""Run simulate with a sectors file and export JSON.""""""
    src = Path(""alpha_factory_v1/demos/alpha_agi_insight_v1/docs/sectors.sample.json"")
    sectors_file = tmp_path / ""sectors.json""
    sectors_file.write_text(src.read_text(encoding=""utf-8""), encoding=""utf-8"")

    runner = CliRunner()
    with patch.object(cli, ""asyncio""):
        with patch.object(cli.orchestrator, ""Orchestrator""):
            res = runner.invoke(
                cli.main,
                [
                    ""simulate"",
                    ""--horizon"",
                    ""1"",
                    ""--offline"",
                    ""--sectors-file"",
                    str(sectors_file),
                    ""--pop-size"",
                    ""2"",
                    ""--generations"",
                    ""1"",
                    ""--export"",
                    ""json"",
                ],
            )

    assert res.exit_code == 0
    data = json.loads(res.output)
    assert isinstance(data, list)
    assert data
    assert {""year"", ""capability"", ""affected""} <= set(data[0])",tests/test_demo_cli.py,,1,8.592166611791576e-10,"The method `test_simulate_sectors_file_json` is a unit test function that verifies the functionality of a command-line interface (CLI) tool. It uses a temporary path to simulate a sectors file, runs the CLI command with specific parameters, and checks the output. This is a typical pattern for testing CLI applications, ensuring that the tool behaves as expected when given certain inputs. Such test functions are crucial for maintaining software quality and are unlikely to be deleted unless the functionality they test is removed or significantly altered. Therefore, the method is likely to survive."
survived,"def test_vmap_multiple_axes():
    Batch1 = Axis(""Batch1"", 4)
    Batch2 = Axis(""Batch2"", 3)
    Width = Axis(""Width"", 2)
    Depth = Axis(""Depth"", 5)

    named = hax.random.uniform(PRNGKey(0), (Batch1, Batch2, Width, Depth))

    def vmap_fun(x):
        return x.sum(Width)

    selected = hax.vmap(vmap_fun, (Batch1, Batch2))(named)

    expected = jnp.sum(named.array, axis=2)

    assert jnp.allclose(selected.array, expected)
    assert selected.axes == (Batch1, Batch2, Depth)",tests/test_hof.py,,1,1.1253518384332553e-07,"The method 'test_vmap_multiple_axes' is a test function that verifies the behavior of a vectorized map operation over multiple axes. It uses a random tensor and applies a sum operation over a specified axis, then checks if the result matches the expected output. This is a typical unit test pattern in scientific computing and machine learning libraries to ensure correctness of operations. Such test functions are crucial for maintaining code reliability and are unlikely to be deleted unless the functionality they test is removed or significantly changed."
survived,"def percent_conditional(line):
    return f""{line}\n"" if not line.endswith('\\') or line.endswith('\\\\') else f""{line[:-1]}""
",test/integration/expected_out_single_line/issue192.py,,1,2.0611536181902033e-09,"The method 'percent_conditional' is a simple utility function that checks the end of a string and returns a modified version of it based on certain conditions. It is likely to survive because it serves a specific purpose, is concise, and does not have any apparent issues or redundancies. Such utility functions are common in codebases for handling specific string formatting tasks."
survived,"def format_values(node, values):
    return '{}({})'.format(node.__class__.__name__, ',\n    '.join(values))
",test/integration/expected_out_single_line/issue192.py,,1,1.6052280526088547e-09,"The method 'format_values' is a utility function that formats a string representation of a node and its associated values. It uses Python's string formatting to create a readable output, which is a common requirement in many applications, especially those dealing with data structures or debugging. The method is simple, clear, and serves a specific purpose, making it likely to be retained in the codebase."
survived,"def unique_inverse(
    array: NamedArray,
    Unique: Axis,
    *,
    axis: AxisSelector | None = None,
    fill_value: ArrayLike | None = None,
) -> tuple[NamedArray, NamedArray]:
    """"""Shortcut for :func:`unique` that also returns inverse indices.""""""

    values, inverse = typing.cast(
        tuple[NamedArray, NamedArray],
        unique(
            array,
            Unique,
            return_inverse=True,
            axis=axis,
            fill_value=fill_value,
        ),
    )
    return values, inverse
",src/haliax/ops.py,,1,1.6918979223288786e-10,"The method `unique_inverse` is a utility function that provides a shortcut for obtaining unique elements from an array along with their inverse indices. This is a common operation in data processing and analysis, where understanding the unique elements and their positions in the original array is useful. The function is well-defined, uses type hints, and leverages existing functionality (`unique` function) to achieve its purpose. There is no indication that this method is redundant or obsolete, and it provides a clear and useful functionality. Therefore, it is likely to be retained in the codebase."
survived,"def test_unique_shortcuts():
    Height = Axis(""Height"", 3)
    Width = Axis(""Width"", 2)

    arr2d = hax.named([[1, 2], [2, 3], [1, 2]], (Height, Width))
    U = Axis(""U"", 3)

    # unique_values
    uv = hax.unique_values(arr2d, U)
    uv_expected = hax.unique(arr2d, U)
    assert jnp.all(uv.array == uv_expected.array)

    # unique_counts
    vc, cc = hax.unique_counts(arr2d, U)
    vc_exp, cc_exp = hax.unique(arr2d, U, return_counts=True)
    assert jnp.all(vc.array == vc_exp.array)
    assert jnp.all(cc.array == cc_exp.array)

    # unique_inverse
    Height1 = Axis(""Height1"", 5)
    arr1d = hax.named([3, 4, 1, 3, 1], (Height1,))
    U2 = Axis(""U2"", 3)
    vi, ii = hax.unique_inverse(arr1d, U2)
    vi_exp, ii_exp = hax.unique(arr1d, U2, return_inverse=True)
    assert jnp.all(vi.array == vi_exp.array)
    assert jnp.all(ii.array == ii_exp.array)

    # unique_all
    U3 = Axis(""U3"", 2)
    va, ia, ina, ca = hax.unique_all(arr2d, U3, axis=Height)
    va_exp, ia_exp, ina_exp, ca_exp = typing.cast(
        tuple[NamedArray, NamedArray, NamedArray, NamedArray],
        hax.unique(
            arr2d,
            U3,
            axis=Height,
            return_index=True,
            return_inverse=True,
            return_counts=True,
        ),
    )
    assert jnp.all(va.array == va_exp.array)
    assert jnp.all(ia.array == ia_exp.array)
    assert jnp.all(ina.array == ina_exp.array)
    assert jnp.all(ca.array == ca_exp.array)",tests/test_ops.py,,1,1.1253518384332553e-07,"The method is a comprehensive test function that verifies the functionality of various unique operations provided by the 'hax' library. It includes tests for unique values, counts, inverse, and all combined operations, ensuring that the library's methods work as expected. Such test functions are crucial for maintaining code quality and reliability, especially in libraries that handle complex data operations. Therefore, it is likely to be retained as it serves an important role in the testing suite."
survived,"        def _render_source(source: str) -> str:
            # handle extends directive
            match = re.search(r""{%\s*extends\s+'([^']+)'\s*%}"", source)
            if match:
                parent_slug = match.group(1)
                parent = self.registry.load_template(parent_slug, version) or """"
                source = source.replace(match.group(0), """")
                base = _render_source(parent)
                block_re = re.compile(
                    r""{%\s*block\s+(\w+)\s*%}(.*?){%\s*endblock\s*%}"", re.S
                )
                parent_blocks = {n: c for n, c in block_re.findall(base)}
                child_blocks = {n: c for n, c in block_re.findall(source)}
                for name, content in parent_blocks.items():
                    if name in child_blocks:
                        child = child_blocks[name].replace(""{{ super() }}"", content)
                        pattern = (
                            r""{%\s*block\s+""
                            + re.escape(name)
                            + r""\s*%}.*?{%\s*endblock\s*%}""
                        )
                        base = re.sub(pattern, child, base, flags=re.S)
                source = base
            # handle include directive
            include_re = re.compile(r""{%\s*include\s+'([^']+)'\s*%}"")

            def _replace_include(m: re.Match[str]) -> str:
                inc = self.registry.load_template(m.group(1), version) or """"
                return _render_source(inc)

            source = include_re.sub(_replace_include, source)
            return source
",src/meta_agent/template_mixer.py,TemplateMixer,1,1.725782769012759e-08,"The method '_render_source' is a utility function that processes template strings, handling 'extends' and 'include' directives. It is a core part of a templating system, likely used to dynamically render templates by replacing blocks and including other templates. Such functionality is essential in web frameworks and template engines, making it unlikely to be removed unless the entire templating approach is refactored or replaced. Therefore, the method is more likely to survive."
survived,"    def update(val):
        try:
            config.update_settings({""int_property"": val})
        except Exception as e:
            exceptions.append(e)
",libs/core/kiln_ai/utils/test_config.py,,1,2.0611536181902033e-09,"The method 'update' is a simple function that attempts to update a configuration setting and handles any exceptions by appending them to a list. This method is likely to survive because it performs a basic and necessary operation of updating settings, which is a common requirement in many applications. Additionally, it includes error handling, which is a good practice in programming. Unless there is a significant change in the application's requirements or architecture that makes this method obsolete, it is likely to remain useful."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/count-in-octal-1.py,,1,6.348800075736417e-09,"The method _now() is a utility function that generates a pseudo-random number based on a seed if _now_seeded is True, otherwise it returns the current time in nanoseconds. This function is likely used for testing or simulating time-dependent behavior in a controlled manner. Such utility functions are often retained in codebases for their usefulness in testing scenarios, especially when deterministic outputs are needed. Therefore, it is likely to survive."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/count-in-octal-2.py,,1,6.023574641292144e-08,"The method `_now()` is a utility function that generates a pseudo-random number based on a global seed if `_now_seeded` is True, otherwise it returns the current time in nanoseconds. This function is likely part of a larger system that requires a consistent and repeatable sequence of numbers for testing or simulation purposes when seeded, and real-time timestamps otherwise. Such utility functions are common in systems that need both deterministic and real-time behavior. Therefore, it is likely to be retained as it serves a specific purpose in the codebase."
survived,"def _lambda6():
    draw.get(20)()
    draw.get(60)()
",tests/rosetta/transpiler/Python/cistercian-numerals.py,,1,0.00013982203410499962,"The method _lambda6() is a private method (indicated by the underscore) and seems to be part of a larger codebase where 'draw' is an object with a 'get' method that returns callable objects. The method calls two such objects with the arguments 20 and 60. Without additional context, it's difficult to determine the exact purpose or utility of this method. However, if 'draw' is a well-defined object and these calls are necessary for the application's functionality, the method is likely to survive. If 'draw' or the specific calls are no longer needed or have been replaced by more efficient code, the method might be deleted. Given the lack of context, it's reasonable to assume that the method serves a purpose in its current state."
survived,"def _lambda2():
    draw.get(2)()
    draw.get(6)()
",tests/rosetta/transpiler/Python/cistercian-numerals.py,,0,0.9999869928752253,"The method _lambda2() is a private method (indicated by the underscore) and it directly calls two methods from a 'draw' object using the get() method with hardcoded indices 2 and 6. Without context on what 'draw' is or what these indices represent, it's difficult to determine the utility or correctness of this method. However, the method lacks flexibility and error handling, which are important for maintainability and robustness. If 'draw' is a dictionary or similar structure, and the indices are not guaranteed to exist, this could lead to runtime errors. Additionally, the method does not return any value or perform any operations beyond these calls, which might indicate limited usefulness. Given these factors, the method is likely to be deleted unless it serves a very specific and necessary purpose in the codebase."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/fractal-tree.py,,1,6.023574641292144e-08,"The method `_now()` is a utility function that generates a pseudo-random number based on a seed if `_now_seeded` is True, or returns the current time in nanoseconds otherwise. This kind of function can be useful in scenarios where deterministic pseudo-random numbers are needed for testing or other purposes. The function is simple, has a clear purpose, and does not have any obvious issues or redundancies. Therefore, it is likely to be retained in the codebase."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/fractran.py,,1,8.76424914819242e-08,"The method '_now' is a utility function that generates a pseudo-random number based on a seed if '_now_seeded' is True, or returns the current time in nanoseconds otherwise. This function is useful for generating consistent pseudo-random numbers for testing or other purposes when seeded, and for getting the current time when not seeded. Such utility functions are common in programming for testing and time-related operations, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained in the codebase."
survived,"def _lambda4(n):
    if n == 0:
        return 0.0
    return extract(cos, n - 1) / (float(n))
",tests/rosetta/transpiler/Python/formal-power-series.py,,1,8.76424914819242e-08,"The method _lambda4 is a private helper function, indicated by the underscore prefix, which suggests it is intended for internal use within a module or class. The function performs a mathematical operation involving the cosine function and recursion. It seems to be part of a larger mathematical or computational process, possibly related to series expansion or numerical methods.

The function is simple and specific in its purpose, and there is no indication of it being redundant or replaced by another function. Additionally, the use of recursion and mathematical operations suggests it is part of a specialized calculation that might be necessary for the module's functionality.

Given these considerations, it is likely that the function will be Survived (1) as it serves a specific purpose and there is no evidence of it being deprecated or unnecessary."
survived,"def join(xs, sep):
    res = """"
    i = 0
    while i < len(xs):
        if i > 0:
            res = res + sep
        res = res + xs[i]
        i = i + 1
    return res
",tests/rosetta/transpiler/Python/function-frequency.py,,0,0.9999977396747258,"The method 'join' is a custom implementation of a common string operation that is already provided by Python's standard library. Python's built-in 'str.join()' method is more efficient and widely used for joining elements of a list into a string with a specified separator. The custom implementation is less efficient and redundant, as it manually concatenates strings in a loop, which is generally slower than using the built-in method. Therefore, this method is likely to be deleted in favor of using the built-in 'str.join()' method."
survived,"def c(nums):
    pass
",tests/rosetta/transpiler/Python/function-prototype.py,,0,0.9999999895325983,"The method 'c' is currently a placeholder function with no implementation. Typically, such functions are either completed later or removed if deemed unnecessary. Without any additional context or comments indicating future use or plans for this function, it is likely to be deleted as it serves no purpose in its current state."
survived,"def state(v):
    return State(entry=v == 0, inc=v < 10, dec=v > 0)
",tests/rosetta/transpiler/Python/gui-enabling-disabling-of-controls.py,,1,6.348800075736417e-09,"The method 'state' is a simple utility function that creates and returns an instance of the 'State' class based on the input value 'v'. It checks three conditions: whether 'v' is zero, less than ten, or greater than zero, and uses these conditions to set the attributes of the 'State' object. This kind of utility function is common in codebases where state management is needed, and it is likely to be used in various parts of the application. Unless the 'State' class itself is deprecated or the logic becomes irrelevant, this method is likely to survive."
survived,"def chance(prob):
    threshold = int(prob * 1000.0)
    return _now() % 1000 < threshold
",tests/rosetta/transpiler/Python/forest-fire.py,,1,2.1024340680345882e-07,"The method 'chance' is a simple utility function that determines if a random event occurs based on a given probability. It converts the probability into a threshold and compares it against a pseudo-random number derived from the current time. This type of function is commonly used in simulations, games, or any application requiring probabilistic decision-making. Its simplicity and utility suggest it is likely to be retained unless there are specific issues with its implementation or a better alternative is available."
survived,"def padLeftZeros(s, width):
    out = s
    while len(out) < width:
        out = ""0"" + out
    return out
",tests/rosetta/transpiler/Python/formatted-numeric-output.py,,1,1.8189616842444243e-09,"The method 'padLeftZeros' is a simple utility function that pads a given string 's' with zeros on the left until it reaches a specified 'width'. This is a common requirement in formatting numbers or strings to ensure they have a consistent length, especially in contexts like generating IDs, formatting numbers for display, or preparing data for systems that require fixed-width fields. The function is straightforward, does not have any apparent bugs, and serves a useful purpose. Therefore, it is likely to be retained in the codebase."
survived,"def greToDay(d, m, y):
    yy = y
    mm = m
    if mm < 3:
        yy = yy - 1
        mm = mm + 12
    return (yy * 36525 // 100) - (yy // 100) + (yy // 400) + 306 * (mm + 1) // 10 + d - 654842
",tests/rosetta/transpiler/Python/french-republican-calendar.py,,1,4.6911638017642294e-08,"The method 'greToDay' appears to be a function that converts a Gregorian date (day, month, year) into a day count. The logic involves adjusting the year and month for dates in January and February, and then calculating a day count using a formula that seems to be based on the Julian Day Number or a similar system. This type of function can be useful in various applications that require date calculations, such as astronomy, historical research, or calendar conversions. Since the function performs a specific and potentially useful task without any apparent errors or inefficiencies, it is likely to be retained in the codebase."
survived,"def b2i(b):
    if b:
        return 1
    return 0
",tests/rosetta/transpiler/Python/four-bit-adder-1.py,,1,5.60279640614594e-09,"The method 'b2i' is a simple utility function that converts a boolean value to an integer (1 for True, 0 for False). Such utility functions are often useful in various programming scenarios, especially when dealing with data processing or interfacing with systems that require integer representations of boolean values. The function is straightforward, efficient, and serves a clear purpose, making it likely to be retained in the codebase."
survived,"def step(n, program):
    i = 0
    while i < len(program):
        num = program[i][0]
        den = program[i][1]
        if n % den == 0:
            n = (n // den) * num
            return StepResult(n=n, ok=True)
        i = i + 1
    return StepResult(n=n, ok=False)
",tests/rosetta/transpiler/Python/fractran.py,,1,1.637377179507321e-07,"The method 'step' is a utility function that processes a number 'n' through a list of operations defined in 'program'. It checks if 'n' is divisible by the denominator of each operation and, if so, modifies 'n' accordingly. This type of function is often used in simulations, games, or mathematical computations where stepwise transformations are needed. The function is well-defined, performs a specific task, and returns a result encapsulated in a 'StepResult' object, indicating both the new value of 'n' and whether a transformation was applied. Such utility functions are generally useful and likely to be retained in codebases that require stepwise transformations or simulations."
survived,"    async def get_latest(_: None = Depends(verify_token)) -> ResultsResponse:
        if _latest_id is None:
            raise HTTPException(status_code=404)
        result = _simulations.get(_latest_id)
        if result is None:
            raise HTTPException(status_code=404)
        return result
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/api_server.py,,1,7.582560422162384e-10,"The method 'get_latest' is likely to survive because it performs a critical function of retrieving the latest simulation result, which is essential for applications that rely on up-to-date data. It includes error handling for cases where the latest ID is not set or the result is not found, which indicates that it is designed to handle edge cases robustly. Additionally, it uses dependency injection to verify tokens, suggesting it is part of a secure API endpoint."
survived,"def _reset_demo_globals() -> Iterator[None]:
    """"""Reset global state altered by the demo.""""""
    yield
    if MODULE in sys.modules:
        sys.modules[MODULE]._A2A = None
",tests/test_alpha_agi_business_3_v1.py,,1,2.998960815863541e-09,"The method _reset_demo_globals is a utility function designed to reset a specific global state related to a demo. It is a private method (indicated by the underscore prefix) and is likely used internally within a module to ensure that the global state is clean and consistent, especially after running a demo or test. Such methods are generally useful for maintaining the integrity of the module's state and are not typically removed unless they are completely unused or replaced by a more efficient mechanism. Since it serves a specific purpose and there is no indication that it is obsolete or redundant, it is likely to survive."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/if_else.py,,1,4.944450477491054e-09,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be consistently formatted for output or logging. Its simplicity and general applicability make it likely to be retained in a codebase, as it provides a clear and reusable solution to a common problem."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/join_multi.py,,1,5.60279640614594e-09,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted for display or logging. Its simplicity and general applicability make it likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/partial_application.py,,1,8.152020648014727e-09,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted for display or logging purposes. Since it provides a clear and reusable way to handle common formatting tasks, it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/if_then_else_nested.py,,1,4.944450477491054e-09,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted consistently for output or logging. Its simplicity and general applicability suggest that it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/sort_stable.py,,1,1.3440409770490404e-08,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in many programming scenarios where data needs to be formatted for display or logging purposes. Since it provides a clear and reusable way to handle common formatting tasks, it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/group_by_conditional_sum.py,,1,3.850741907939403e-09,"The method _fmt is a utility function that formats different types of input values into strings. It handles lists by recursively formatting each element, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be consistently formatted for output or logging. Its simplicity and general applicability suggest that it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/membership.py,,1,3.3982678079468468e-09,"The method _fmt is a utility function that formats different types of input values into strings. It handles lists by recursively formatting each element, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be consistently formatted for output or logging. Its simplicity and general applicability suggest that it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/exists_builtin.py,,1,1.1032560311263802e-09,"The method _fmt is a utility function that formats different types of input values into strings. It handles lists by recursively formatting each element, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted consistently for output or logging. Since it provides a clear and useful functionality, it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/map_membership.py,,1,6.348800075736417e-09,"The method _fmt is a utility function that formats different types of input values into strings. It handles lists by recursively formatting each element, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in many programming scenarios where data needs to be consistently formatted for output or logging. Given its utility and the fact that it handles common data types, it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/string_compare.py,,1,2.646573631904765e-09,"The method _fmt is a utility function that formats different types of input values into strings. It handles lists by recursively formatting each element, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted consistently for output or logging. Since it provides a clear and useful functionality, it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/len_map.py,,1,3.850741907939403e-09,"The method _fmt is a utility function that formats different types of input values into strings. It handles lists by recursively formatting each element, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted consistently for output or logging. Given its utility and the fact that it handles common data types, it is likely to be retained in the codebase."
survived,"def test_view_command_invalid_password(mock_get_connection, runner):
    mock_get_connection.side_effect = InvalidPassword()

    result = runner.invoke(cli, ['view', 'bad_conn', '--table', 'users'])

    assert result.exit_code != 0
    assert ""Error: Unable to decrypt saved connection. Invalid password provided."" in result.output
",peepdb/tests/test_cli.py,,1,9.237449576640118e-09,The method is a test function that checks the behavior of a command-line interface when an invalid password is provided. It uses mocking to simulate the scenario and asserts the expected error message. This is a typical and necessary test case to ensure the robustness of the application against incorrect inputs. Such test functions are crucial for maintaining software quality and are unlikely to be deleted unless the functionality they test is removed or significantly altered.
survived,"def test_service_worker_exists() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist""
    assert (dist / ""service-worker.js"").is_file()",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_service_worker_present.py,,1,1.1032560311263802e-09,"The method `test_service_worker_exists` is a simple test function that checks for the existence of a file named `service-worker.js` in a specific directory. This kind of test is useful for ensuring that the build process correctly outputs necessary files, which is a common requirement in web development projects. Since it serves a clear purpose in verifying the presence of a critical file, it is likely to be retained in the codebase."
survived,"def test_download_with_retry_auth_message(
    tmp_path: Path, requests_mock: requests_mock.Mocker, capsys: pytest.CaptureFixture[str]
) -> None:
    path = tmp_path / ""out""
    url_primary = f""{fa.GATEWAY}/CID""
    requests_mock.get(url_primary, status_code=401)
    with pytest.raises(RuntimeError) as exc:
        fa.download_with_retry(""CID"", path, attempts=1, label=""wasm_llm/wasm-gpt2.tar"")
    out = capsys.readouterr().out
    assert ""WASM_GPT2_URL"" in out
    msg = str(exc.value)
    assert ""CID"" in msg and ""http"" in msg
    assert ""authentication"" in msg.lower()
",tests/test_fetch_assets.py,,1,4.944450477491054e-09,"The method `test_download_with_retry_auth_message` is a unit test function that verifies the behavior of a function when an authentication error occurs. It uses mocking to simulate a 401 Unauthorized response and checks if the appropriate error message is raised and logged. This is a standard practice in testing to ensure that the function handles authentication errors correctly. Since testing for error handling is crucial for robust software, this method is likely to be retained in the codebase."
survived,"def triple(x: int) -> int:
    return x * 3
",tests/human/x/python/pure_fold.py,,1,1.4166087846364157e-09,"The method 'triple' is a simple and efficient function that multiplies an integer by 3. It is a basic utility function that can be useful in various contexts where such an operation is needed. There is no indication of redundancy or inefficiency in the code, and it serves a clear purpose. Therefore, it is likely to be retained in the codebase."
survived,"def test_fetch_assets_failure(monkeypatch, capsys):
    monkeypatch.setattr(fa, ""ASSETS"", {""dummy.txt"": ""cid""})

    def boom(*args, **kwargs):
        raise RuntimeError(""boom"")

    monkeypatch.setattr(fa, ""download_with_retry"", boom)

    with pytest.raises(SystemExit) as exc:
        fa.main()

    out = capsys.readouterr().out
    assert ""Download failed for dummy.txt"" in out
    assert ""ERROR: Unable to retrieve dummy.txt"" in out
    assert exc.value.code == 1",tests/test_fetch_assets.py,,1,8.152020648014727e-09,"The method 'test_fetch_assets_failure' is a unit test designed to verify the behavior of a function when a download fails. It uses the 'monkeypatch' fixture to simulate a failure scenario and checks if the appropriate error messages are printed and if the program exits with the correct status code. This is a typical and necessary test case to ensure robustness in error handling, especially in functions dealing with external resources like downloads. Therefore, it is likely to be retained as part of the test suite."
survived,"    def _get_thread(self, service, thread_id: str, include_spam_trash: bool) -> dict:
        thread = (
            service.users()
            .threads()
            .get(
                userId=""me"",
                id=thread_id,
                format=""full"",
                includeSpamTrash=include_spam_trash,
            )
            .execute()
        )

        parsed_messages = []
        for msg in thread.get(""messages"", []):
            headers = {
                h[""name""].lower(): h[""value""]
                for h in msg.get(""payload"", {}).get(""headers"", [])
            }
            body = self._get_email_body(msg)
            attachments = self._get_attachments(service, msg)
            email = Email(
                threadId=msg.get(""threadId"", thread_id),
                id=msg[""id""],
                subject=headers.get(""subject"", ""No Subject""),
                snippet=msg.get(""snippet"", """"),
                from_=parseaddr(headers.get(""from"", """"))[1],
                to=parseaddr(headers.get(""to"", """"))[1],
                date=headers.get(""date"", """"),
                body=body,
                sizeEstimate=msg.get(""sizeEstimate"", 0),
                attachments=attachments,
            )
            parsed_messages.append(email.dict())

        thread[""messages""] = parsed_messages
        return thread
",autogpt_platform/backend/backend/blocks/google/gmail.py,GmailGetThreadBlock,1,2.998960815863541e-09,"The method '_get_thread' is a utility function that retrieves a thread of emails from a service, processes each message to extract relevant information, and returns a structured dictionary. This functionality is essential for applications dealing with email data, as it provides a way to access and manipulate email threads programmatically. The method is well-structured, uses helper functions to keep the code clean, and provides a comprehensive output by including headers, body, and attachments. Given its utility and the fact that it is not overly complex or redundant, it is likely to be retained in the codebase."
survived,"    def __init__(self, bus: orchestrator.messaging.A2ABus, ledger: orchestrator.Ledger) -> None:
        super().__init__(""fail"", bus, ledger)
",tests/test_orchestrator_backoff.py,FailingAgent,1,2.699578619062706e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting up initial states. The presence of the 'super().__init__' call suggests that this class is part of an inheritance hierarchy, making the constructor even more crucial for proper initialization. Therefore, it is unlikely to be deleted."
survived,"    async def skill_test(self, payload: dict) -> dict:
        return {""ok"": True}
",tests/test_orchestrator_rest.py,DummyAgent,1,2.3823698451773172e-07,"The method 'skill_test' is a simple asynchronous function that takes a dictionary as input and returns a dictionary with a fixed response. It is likely a placeholder or a basic implementation for testing purposes. Since it doesn't perform any complex operations or have any apparent issues, it is likely to survive unless there is a significant change in requirements or the method is deemed unnecessary in the future."
survived,"    async def skill_test(self, payload: dict) -> dict:
        """"""Execute a diagnostic skill test.

        Agents may override this method to provide custom behaviour.
        The default implementation returns ``{""ok"": True}``.
        """"""
        return {""ok"": True}
",alpha_factory_v1/backend/agents/base.py,AgentBase,1,1.955568070542584e-08,"The method `skill_test` is a default implementation that provides a basic functionality of returning a dictionary with a success message. It is designed to be overridden by agents for custom behavior, which suggests it is part of a framework or library where extensibility is a key feature. Such methods are typically retained to provide a base implementation that can be customized as needed. Therefore, it is likely to survive as it serves a foundational purpose in the code structure."
survived,"def test_seed_iteration():
    cfg = make_cfg()
    es = EnvStateManager(cfg, mode='train')
    es.reset()
    first_seed = es.envs[0]['status'].seed
    es.reset()
    second_seed = es.envs[0]['status'].seed
    assert first_seed == 7
    assert second_seed == 8",tests/es_manager/test_seed_iteration.py,,1,4.6911638017642294e-08,"The method `test_seed_iteration` is a unit test designed to verify the behavior of the `EnvStateManager` class, specifically checking if the seed value changes correctly upon reset. This is a typical use case for unit tests, which are crucial for ensuring code reliability and correctness. Since testing is an essential part of software development, this method is likely to be retained to maintain the integrity of the codebase."
survived,"def body_checksum(address: int, sig: Signal, d: bytearray) -> int:
    crc = 0xFF
    poly = 0xD5
    for i in range(len(d) - 2, -1, -1):
        crc ^= d[i]
        for _ in range(8):
            if crc & 0x80:
                crc = ((crc << 1) ^ poly) & 0xFF
            else:
                crc = (crc << 1) & 0xFF
    return crc
",opendbc/can/packer.py,,1,2.646573631904765e-09,"The method 'body_checksum' is a utility function that calculates a checksum using a specific polynomial (0xD5) and a CRC algorithm. Such functions are commonly used in data integrity checks, especially in communication protocols and data storage systems. The method is well-defined, performs a specific task, and does not have any apparent issues or redundancies. Therefore, it is likely to be retained in the codebase as it serves a useful purpose."
survived,"def hkg_can_fd_checksum(address: int, sig: Signal, d: bytearray) -> int:
    crc = 0
    for i in range(2, len(d)):
        crc = ((crc << 8) ^ CRC16_XMODEM[(crc >> 8) ^ d[i]]) & 0xFFFF
    crc = ((crc << 8) ^ CRC16_XMODEM[(crc >> 8) ^ ((address >> 0) & 0xFF)]) & 0xFFFF
    crc = ((crc << 8) ^ CRC16_XMODEM[(crc >> 8) ^ ((address >> 8) & 0xFF)]) & 0xFFFF
    if len(d) == 8:
        crc ^= 0x5F29
    elif len(d) == 16:
        crc ^= 0x041D
    elif len(d) == 24:
        crc ^= 0x819D
    elif len(d) == 32:
        crc ^= 0x9F5B
    return crc
",opendbc/can/packer.py,,1,7.194132978569833e-09,"The method `hkg_can_fd_checksum` is a utility function that calculates a checksum for a given address and data payload using a specific CRC16_XMODEM algorithm. This type of function is crucial in systems where data integrity is important, such as in communication protocols or data storage. The function is well-defined, performs a specific task, and does not have any apparent issues or redundancies that would warrant its deletion. It is likely to be used in contexts where data validation is necessary, making it a valuable part of the codebase."
survived,"    def test_import_system_blocked(self):
        agent_base.resource = None
        agent_base.signal = None
        se = SafeExec()
        code = """"""\

def transform(x):
    return __import__('os').system('echo hi')
""""""
        with self.assertRaises(NameError):
            se.run(code, ""transform"", 0)
",tests/test_safe_exec_security.py,TestSafeExecSecurity,1,2.1024340680345882e-07,"The method 'test_import_system_blocked' is designed to test the security feature of the 'SafeExec' class by attempting to execute a code snippet that imports the 'os' module and uses 'system' to execute a shell command. The test expects a 'NameError' to be raised, indicating that the import and execution are blocked. This is a valid and necessary test to ensure the security of the 'SafeExec' class, which is likely intended to prevent unauthorized system access through code execution. Therefore, the method is crucial for maintaining the integrity and security of the system, and it is unlikely to be deleted."
survived,"def test_merkle_root_tracking(tmp_path: Path) -> None:
    db = tmp_path / ""arch.db""
    h1 = hashlib.sha256(json.dumps({""parent"": ""p"", ""child"": ""c1"", ""metrics"": {""s"": 1}}, sort_keys=True).encode()).hexdigest()
    insert(""p"", ""c1"", {""s"": 1}, db_path=db)
    h2 = hashlib.sha256(json.dumps({""parent"": ""c1"", ""child"": ""c2"", ""metrics"": {""s"": 2}}, sort_keys=True).encode()).hexdigest()
    insert(""c1"", ""c2"", {""s"": 2}, db_path=db)
    root = merkle_root(db_path=db)
    assert root == _manual_root([h1, h2])
",tests/test_archive_cron.py,,1,4.599055376537186e-10,"The method `test_merkle_root_tracking` is a test function that verifies the functionality of a Merkle root tracking system. It uses a temporary path to simulate a database, inserts data, and checks if the computed Merkle root matches the expected value. This is a typical unit test pattern used to ensure code correctness. Since testing is a crucial part of software development to maintain code quality and reliability, this method is likely to be retained in the codebase. Therefore, it will survive."
survived,"def utc_now() -> str:
    return datetime.now(timezone.utc).isoformat(timespec=""milliseconds"")
",alpha_factory_v1/backend/agent_manager.py,,1,4.944450477491054e-09,"The method `utc_now` is a simple utility function that returns the current UTC time in ISO 8601 format with millisecond precision. Such utility functions are commonly used in applications that require timestamping or logging in a standardized format. The function is concise, uses standard library functions, and provides a useful feature that is likely to be needed in various contexts. Therefore, it is likely to be retained in the codebase."
survived,"    async def _trigger(name: str) -> Dict[str, bool]:  # noqa: D401
        if name not in runners:
            raise HTTPException(404, ""Agent not found"")
        runners[name].next_ts = 0
        return {""queued"": True}
",alpha_factory_v1/backend/api_server.py,,1,5.211412485172657e-10,"The method '_trigger' is likely to survive because it performs a specific and useful function within the codebase. It checks if a given 'name' exists in the 'runners' dictionary and raises an exception if not, ensuring that only valid agents are processed. Additionally, it resets the 'next_ts' attribute of the runner to 0 and returns a dictionary indicating that the task has been queued. This functionality is essential for managing and triggering tasks in an asynchronous environment, making it a valuable part of the system."
survived,"async def regression_guard(runners: Dict[str, AgentRunner]) -> None:
    history: deque[float] = deque(maxlen=3)
    while True:
        await asyncio.sleep(1)
        try:
            sample = metrics.dgm_best_score.collect()[0].samples[0]
            score = float(sample.value)
        except Exception:  # pragma: no cover - metrics optional
            continue
        history.append(score)
        if len(history) == 3 and history[1] <= history[0] * 0.8 and history[2] <= history[1] * 0.8:
            runner = runners.get(""aiga_evolver"")
            if runner and runner.task:
                runner.task.cancel()
                with contextlib.suppress(asyncio.CancelledError):
                    await runner.task
            alerts.send_alert(""Evolution paused due to metric regression"")
            history.clear()",alpha_factory_v1/backend/agent_manager.py,,1,9.237449576640118e-09,"The method 'regression_guard' is designed to monitor a specific metric and take action if a regression is detected. It uses a deque to keep track of the last three metric scores and checks if the scores are decreasing significantly. If a regression is detected, it cancels a task associated with a specific runner and sends an alert. This functionality is useful for maintaining the stability and performance of a system by automatically pausing processes that are not performing well. Given its utility in monitoring and maintaining system performance, it is likely to be retained in the codebase."
survived,"        def set(self, *_a: Any) -> None:
            ...
",alpha_factory_v1/backend/telemetry.py,_Metric,0,0.999983298584886,"The method 'set' is defined with a variable argument list, indicated by '*_a', but it lacks any implementation details or a docstring explaining its purpose. This suggests that the method is either a placeholder or not yet implemented. Without any functionality or documentation, it is likely to be considered dead code and may be removed in future iterations unless it is part of an interface or abstract class where subclasses are expected to provide the implementation."
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/group_by_left_join.py,Order,1,5.60279640614594e-09,"The __repr__ method is a special method used to define a string representation of an object. In this case, it returns the string representation of the object's __dict__, which is a dictionary containing all the attributes of the object. This is a common and useful implementation of __repr__ as it provides a clear and detailed view of the object's state, which is helpful for debugging and logging purposes. Therefore, this method is likely to be retained in the code."
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/left_join.py,Order,1,1.3440409770490404e-08,"The method `__repr__` is a special method in Python used to define a string representation of an object. The implementation provided here returns the string representation of the object's dictionary, which is a common and useful way to represent an object for debugging purposes. This method is simple, effective, and aligns with Python's conventions for object representation. Therefore, it is likely to be retained in the code."
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/left_join_multi.py,Customer,1,8.152020648014727e-09,"The __repr__ method is a special method used to define a string representation of an object. In this case, it returns the string representation of the object's __dict__, which is a dictionary containing all the attributes of the object. This is a common and useful implementation of __repr__ as it provides a clear and detailed view of the object's state, which is helpful for debugging and logging purposes. Therefore, this method is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/inner_join.py,Order,1,1.955568070542584e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a clear and useful functionality, it is likely to be retained in the code."
survived,"        def __init__(self, *a, **kw) -> None:
            pass
",alpha_factory_v1/demos/alpha_agi_business_v1/openai_agents_bridge.py,AgentRuntime,0,0.9999977396747258,"The method is a constructor (__init__) that takes any number of positional and keyword arguments but does nothing with them, as it only contains a 'pass' statement. This is typically a placeholder or a default implementation that might be intended for future expansion or to satisfy an interface requirement. However, if it remains unchanged and unused, it is likely to be deleted in the future as it serves no functional purpose."
survived,"def _free_port() -> int:
    s = socket.socket()
    s.bind((""localhost"", 0))
    port = s.getsockname()[1]
    s.close()
    return port
",tests/test_bus_ssl_gen.py,,1,8.152020648014727e-09,"The method _free_port is a utility function that finds and returns an available port on the localhost. This is a common requirement in network programming, especially for testing purposes where a free port is needed to bind a server or client socket without hardcoding a specific port number. The method is simple, effective, and does not have any apparent issues or redundancies that would necessitate its removal. Therefore, it is likely to be retained in the codebase."
survived,"    def fake_setrlimit(res: int, limits: tuple[int, int]) -> None:
        recorded.append((res, limits))
",tests/test_codegen_agent.py,,1,6.348800075736417e-09,"The method `fake_setrlimit` is a mock function that records the resource limits set by appending them to a list called `recorded`. This is a common practice in testing to simulate and verify the behavior of system calls without actually performing them. Such functions are typically used in unit tests to ensure that the code interacts with system resources as expected. Since this function serves a specific purpose in testing, it is likely to be retained as long as the tests that depend on it are relevant. Therefore, the method will likely survive."
survived,"def test_invalid_seed_fallback(monkeypatch: pytest.MonkeyPatch, caplog: pytest.LogCaptureFixture) -> None:
    """"""Invalid ALPHA_ASI_SEED should trigger fallback to default.""""""
    module = ""alpha_factory_v1.demos.alpha_asi_world_model.alpha_asi_world_model_demo""
    mod = importlib.import_module(module)
    monkeypatch.setenv(""ALPHA_ASI_SEED"", ""bad"")
    caplog.set_level(""WARNING"")
    cfg = mod._load_cfg()
    assert mod._SEED == 42
    assert any(""Invalid seed"" in rec.message for rec in caplog.records)
    assert isinstance(cfg, mod.Config)",tests/test_world_model_demo.py,,1,3.653482080241728e-08,"The method 'test_invalid_seed_fallback' is a unit test function that checks the behavior of a module when an invalid seed is provided. It uses the 'monkeypatch' fixture to set an environment variable to an invalid value and verifies that the module falls back to a default seed value. The test also checks that a warning is logged, indicating the invalid seed. This is a typical and useful test case to ensure robustness and proper logging in the face of incorrect input, which is a common scenario in software testing. Therefore, it is likely to be retained as part of the test suite."
survived,"    def _run_command(command: str, cwd: str) -> None:
        if PlatformUtils.get_platform_id().value.startswith(""win""):
            subprocess.run(
                command,
                shell=True,
                check=True,
                cwd=cwd,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
            )
        else:
            import pwd

            user = pwd.getpwuid(os.getuid()).pw_name
            subprocess.run(
                command,
                shell=True,
                check=True,
                user=user,
                cwd=cwd,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
            )
",src/solidlsp/language_servers/common.py,RuntimeDependencyCollection,1,2.0611536181902033e-09,"The method '_run_command' is likely to survive because it provides a platform-specific way to execute shell commands, which is a common requirement in many applications. It handles both Windows and non-Windows platforms by checking the platform ID and adjusting the command execution accordingly. This kind of utility function is useful for maintaining cross-platform compatibility in scripts and applications, making it a valuable part of a codebase."
survived,"    def for_current_platform(self) -> list[RuntimeDependency]:
        return self.for_platform(PlatformUtils.get_platform_id().value)
",src/solidlsp/language_servers/common.py,RuntimeDependencyCollection,1,2.0611536181902033e-09,"The method `for_current_platform` is a simple wrapper around another method `for_platform`, which takes the current platform ID as an argument. This kind of method is useful for simplifying calls to `for_platform` when the current platform is the target, reducing the need for repetitive code elsewhere in the application. Such utility methods are common and often retained for convenience and readability. Therefore, it is likely to be Survived."
survived,"def _free_port() -> int:
    s = socket.socket()
    s.bind((""localhost"", 0))
    port = int(s.getsockname()[1])
    s.close()
    return port
",tests/test_orchestrator_bus_tls_env.py,,1,8.152020648014727e-09,"The method _free_port() is a utility function that finds and returns an available port on the localhost. This is a common requirement in network programming, especially for testing purposes where a free port is needed to bind a server or client socket without hardcoding a specific port number. The method is simple, effective, and does not have any apparent issues or redundancies that would necessitate its deletion. It is likely to be useful in various scenarios where dynamic port allocation is required."
survived,"    def __init__(self, *args: object, **kwargs: object) -> None:
        super().__init__(*args)
",tests/conftest.py,APITimeoutError,1,9.931195248674785e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming in Python. It initializes the class instance and is necessary for creating objects. The use of *args and **kwargs allows for flexible argument passing, making the constructor versatile and adaptable to different initialization scenarios. Therefore, it is unlikely to be deleted as it serves a crucial role in the class structure."
survived,"def bigTrim(a):
    n = len(a)
    while n > 1 and a[n - 1] == 0:
        a = a[0:n - 1]
        n = n - 1
    return a
",tests/rosetta/transpiler/Python/chernicks-carmichael-numbers.py,,1,8.152020648014727e-09,"The method 'bigTrim' is a utility function that trims trailing zeros from a list. This is a common operation in various applications, such as processing numerical data or preparing data for algorithms that require non-zero elements. The function is simple, efficient, and serves a clear purpose. There is no indication that this method is redundant or replaced by a more efficient built-in function. Therefore, it is likely to be retained in the codebase."
survived,"def toInt(c):
    return int(c(incr)(0))
",tests/rosetta/transpiler/Python/church-numerals-1.py,,0,0.9999996533672291,"The method 'toInt' is attempting to convert a callable 'c' into an integer by calling it with 'incr' and '0' as arguments. However, 'incr' is not defined within the method or passed as a parameter, leading to a NameError. Additionally, the logic of converting a callable to an integer in this manner is flawed and not meaningful. Without further context or correction, this method is likely to be deleted or significantly revised."
survived,"def printNumeral():
    i = 0
    while i < 15:
        line = """"
        j = 0
        while j < 11:
            line = line + n[i][j] + "" ""
            j = j + 1
        print(line)
        i = i + 1
    print("""")
",tests/rosetta/transpiler/Python/cistercian-numerals.py,,0,0.9999999397642536,"The method 'printNumeral' is likely to be deleted because it references a variable 'n' that is not defined within the method or passed as a parameter. This will result in a NameError when the method is executed. Additionally, the method lacks flexibility and reusability as it is hardcoded to iterate over specific dimensions (15x11), which may not be suitable for different use cases. Without modifications to address these issues, the method is not functional or adaptable, making it a candidate for deletion."
survived,"def trimRightStr(s):
    end = len(s)
    while end > 0 and s[end - 1:end] == "" "":
        end = end - 1
    return s[0:end]
",tests/rosetta/transpiler/Python/composite-numbers-k-with-no-single-digit-factors-whose-factors-are-all-substrings-of-k.py,,1,1.3440409770490404e-08,"The method 'trimRightStr' is a utility function that removes trailing spaces from a string. This is a common requirement in many programming tasks, such as data cleaning and formatting. The method is simple, efficient, and serves a clear purpose. It is likely to be retained as it provides a useful functionality that can be reused in various contexts."
survived,"def isPrime(n):
    if n < 2:
        return False
    if n % 2 == 0:
        return n == 2
    if n % 3 == 0:
        return n == 3
    d = 5
    while d * d <= n:
        if n % d == 0:
            return False
        d = d + 2
        if n % d == 0:
            return False
        d = d + 4
    return True
",tests/rosetta/transpiler/Python/chernicks-carmichael-numbers.py,,1,1.1032560311263802e-09,"The method 'isPrime' is a commonly used utility function to determine if a number is prime. It is implemented efficiently by first checking for small divisors and then using a loop to check for larger divisors, skipping even numbers. This method is useful in many mathematical and computational applications, and its logic is sound and optimized for performance. Therefore, it is likely to be retained in the codebase."
survived,"def printSym(m):
    printMat(unpackSym(m))
",tests/rosetta/transpiler/Python/cholesky-decomposition-1.py,,1,9.237449576640118e-09,"The method 'printSym' is a simple utility function that prints a matrix after unpacking it using another function 'unpackSym'. It is likely part of a larger codebase dealing with matrix operations. Such utility functions are generally useful for debugging and displaying data, and unless there is a significant change in the codebase that makes this function obsolete or redundant, it is likely to survive. Additionally, the function is concise and does not have any apparent issues that would necessitate its removal."
survived,"def toStr(x):
    s = """"
    def fCounter(f):
        global s
        s = s + ""|""
        return f
    x(fCounter)(id)
    return s
",tests/rosetta/transpiler/Python/church-numerals-2.py,,0,0.9999992661791398,"The method 'toStr' is likely to be deleted because it uses a global variable 's' in a non-standard way, which can lead to unexpected behavior and side effects. The function 'fCounter' is defined within 'toStr' and modifies the global variable 's', which is not a recommended practice. Additionally, the purpose and functionality of the code are not clear, making it difficult to understand and maintain. Such code is often refactored or removed in favor of more clear and maintainable solutions."
survived,"def printMat(m):
    i = 0
    while i < len(m):
        line = """"
        j = 0
        while j < len(m[i]):
            line = line + str(m[i][j])
            if j < len(m[i]) - 1:
                line = line + "" ""
            j = j + 1
        print(line)
        i = i + 1
",tests/rosetta/transpiler/Python/cholesky-decomposition-1.py,,1,1.0467401685178159e-08,"The method 'printMat' is a simple utility function that prints a 2D matrix in a formatted way. It uses basic loops to iterate over the matrix and constructs a string for each row before printing it. This function is straightforward and serves a clear purpose, which is to display matrices in a readable format. Such utility functions are often useful in debugging or displaying data, and there is no indication that it is redundant or replaced by a more efficient method in the context provided. Therefore, it is likely to be retained in the codebase."
survived,"def mul(c, d):
    return lambda f: lambda x: c(d(f))(x)
",tests/rosetta/transpiler/Python/church-numerals-1.py,,0,0.9999546021442518,"The method 'mul' is a higher-order function that returns a lambda function. It takes two arguments, 'c' and 'd', and returns a lambda function that takes a function 'f' and applies 'c' to the result of 'd(f)', then applies the result to 'x'. This kind of functional programming approach is often used in scenarios where functions need to be composed or transformed. However, the specific use case for this function is not clear from the code snippet alone, and without additional context or usage examples, it might be considered too abstract or unnecessary in many practical applications. Therefore, it is likely to be deleted unless it serves a specific purpose in a larger codebase."
survived,"def test_ask_interrupt(monkeypatch):
    def raise_interrupt(_):
        raise EOFError

    monkeypatch.setattr(""builtins.input"", raise_interrupt)
    inter = Interactive()
    with pytest.raises(InteractiveError):
        inter.ask(""Question"")",tests/ux/test_interactive.py,,1,2.2159489282323004e-08,"The method 'test_ask_interrupt' is a unit test designed to test the behavior of the 'ask' method in the 'Interactive' class when an EOFError is raised. It uses the 'monkeypatch' fixture to simulate an EOFError when 'input' is called. This is a valid and useful test case to ensure that the 'ask' method handles unexpected input interruptions correctly by raising an 'InteractiveError'. Therefore, the method is likely to be retained as it serves a specific purpose in testing the robustness of the 'ask' method."
survived,"def test_health_endpoint() -> None:
    """"""Verify /health returns expected metrics.""""""
    module = importlib.import_module(""alpha_factory_v1.demos.aiga_meta_evolution.agent_aiga_entrypoint"")
    client = TestClient(cast(Any, module.app))

    resp = client.get(""/health"")
    assert resp.status_code == 200
    data = resp.json()
    assert set(data) >= {""status"", ""generations"", ""best_fitness""}",tests/test_aiga_service.py,,1,2.2159489282323004e-08,"The method `test_health_endpoint` is a unit test designed to verify the functionality of a health endpoint in a web application. Unit tests are crucial for ensuring code reliability and are typically maintained as part of the codebase to facilitate ongoing development and maintenance. The method is well-defined, checks for a successful HTTP response, and validates the presence of expected keys in the response data. These characteristics suggest that the method is useful and likely to be retained in the codebase."
survived,"    def post(path: Path, meta) -> None:
        calls.append(""post"")
",tests/test_bundle_api.py,,0,0.999997438718515,"The method 'post' is very minimal and only appends a string to a list called 'calls'. Without additional context or functionality, it seems to serve little purpose. If this is part of a larger codebase, it might be a placeholder or a stub for future development. However, as it stands, it doesn't perform any meaningful operation related to posting data or handling the 'path' and 'meta' parameters. Therefore, it is likely to be deleted unless further functionality is added."
survived,"    def __init__(self, bundle_dir: str | Path) -> None:
        self.bundle_dir = Path(bundle_dir)
        self._metadata: BundleMetadata | None = None
",src/meta_agent/bundle.py,Bundle,1,1.6052280526088547e-09,"The method is a constructor (__init__) for a class, which is essential for initializing class instances. It sets up the initial state of the object by assigning the 'bundle_dir' parameter to an instance variable and initializes '_metadata' to None. Constructors are fundamental to object-oriented programming, and there is no indication that this particular constructor is redundant or unnecessary. Therefore, it is likely to survive."
survived,"    def pre(path: Path) -> None:
        calls.append(""pre"")
",tests/test_bundle_api.py,,1,5.3157849718487075e-08,"The method 'pre' is a simple function that appends the string ""pre"" to a list called 'calls'. It doesn't perform any complex operations or have any dependencies that would make it obsolete or unnecessary. The method is likely part of a larger system where tracking or logging calls is important. Without additional context suggesting it's unused or redundant, there's no clear reason to delete it."
survived,"def _small_population() -> list[mats.Individual]:
    """"""Return a tiny population with known fitness values.""""""

    fits = [(1.0, 3.0), (2.0, 2.0), (3.0, 1.0), (4.0, 5.0), (5.0, 4.0)]
    return [mats.Individual([], fitness=f) for f in fits]
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_mats.py,,1,1.1861120010657661e-08,"The method '_small_population' is a utility function that creates a small, predefined list of 'Individual' objects with known fitness values. Such methods are often used for testing or demonstration purposes, especially in genetic algorithms or evolutionary computation contexts. Since it serves a specific purpose and is likely used in testing or validating other parts of the code, it is unlikely to be deleted unless the entire testing strategy changes or the method is replaced by a more comprehensive testing framework. Therefore, it is more likely to survive."
survived,"def _make_agent(monkeypatch):
    """"""Return a ResearchAgent wired with dummy bus/ledger.""""""
    from alpha_factory_v1.demos.alpha_agi_insight_v1.src.agents import research_agent
    from alpha_factory_v1.demos.alpha_agi_insight_v1.src.utils import config, messaging

    class DummyBus:
        def __init__(self, settings: config.Settings) -> None:
            self.settings = settings
            self.published: list[tuple[str, messaging.Envelope]] = []

        def publish(self, topic: str, env: messaging.Envelope) -> None:
            self.published.append((topic, env))

        def subscribe(self, _t: str, _h):
            pass

    class DummyLedger:
        def __init__(self) -> None:
            self.logged: list[messaging.Envelope] = []

        def log(self, env: messaging.Envelope) -> None:  # type: ignore[override]
            self.logged.append(env)

        def start_merkle_task(self, *_a, **_kw):
            pass

        async def stop_merkle_task(self) -> None:  # pragma: no cover - interface
            pass

        def close(self) -> None:
            pass

    settings = config.Settings(bus_port=0)
    bus = DummyBus(settings)
    agent = research_agent.ResearchAgent(bus, DummyLedger())
    return agent, bus
",tests/test_adapters.py,,1,2.2159489282323004e-08,"The method '_make_agent' is a utility function designed to create a 'ResearchAgent' with dummy components for testing purposes. It is likely to survive because it is useful for unit testing and mocking dependencies, which is a common practice in software development to ensure code reliability and maintainability. The use of dummy classes like 'DummyBus' and 'DummyLedger' allows for isolated testing of the 'ResearchAgent' without requiring actual implementations of the bus and ledger, making it a valuable tool for developers."
survived,"    def generate_text(self, prompt: str) -> str:
        """"""Generate text using ``adk.Client`` if the method exists.""""""
        gen_fn = getattr(self._client, ""generate"", None)
        if not callable(gen_fn):
            raise AttributeError(""generate not available"")
        return gen_fn(prompt)",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/adk_adapter.py,ADKAdapter,1,1.522997951276035e-08,"The method 'generate_text' is a utility function that checks for the existence of a 'generate' method in the '_client' object and calls it if available. This is a common pattern for ensuring compatibility with different versions of a library or API, where certain methods might not be present. The method is useful for maintaining backward compatibility and handling potential changes in the '_client' API gracefully. Therefore, it is likely to be retained as it provides a safeguard against missing methods and enhances the robustness of the code."
survived,"        def __init__(self) -> None:
            self.called: list[str] = []
",tests/test_adapters.py,StubADK,1,6.825604231969389e-08,"The method is a constructor (__init__) for a class, which is a fundamental part of class instantiation in Python. Constructors are essential for initializing object attributes and setting up the initial state of an object. Therefore, it is highly unlikely that this method will be deleted as it serves a critical role in object-oriented programming."
survived,"    async def patched_run_cycle(self) -> None:
        res = await self.mcp.invoke_tool(""echo"", {""t"": 1})
        await self.emit(""strategy"", res)
",tests/test_adapters.py,,1,8.592166611791576e-10,"The method 'patched_run_cycle' is likely to survive because it is an asynchronous function that performs a specific task: invoking a tool and emitting a result. This kind of functionality is often essential in systems that require asynchronous operations, such as those involving I/O-bound tasks or real-time data processing. The method is concise, uses modern async/await syntax, and appears to be part of a larger system that relies on these operations, suggesting it serves a necessary role."
survived,"    async def fake_call_tool(self, name: str, args: dict[str, object]) -> object:
        calls[""call""] = (name, args)
        return {""done"": True}
",tests/test_adapters.py,,1,3.3982678079468468e-09,"The method 'fake_call_tool' is a simple asynchronous function that simulates a tool call by storing the call details in a dictionary and returning a fixed response. This method is likely used for testing or mocking purposes, which are common practices in software development to ensure code reliability and functionality without relying on external systems. Such utility functions are often retained in codebases for testing purposes, especially if they are part of a larger testing framework or suite. Therefore, it is likely to survive."
survived,"def test_fuzz_envelope_blocks_malicious(sender: str, recipient: str, ts: float, payload: dict[str, object]) -> None:
    code = payload[""code""]
    assume(""import os"" in code)
    bus = DummyBus(config.Settings(bus_port=0))
    led = DummyLedger()
    agent = safety_agent.SafetyGuardianAgent(bus, led)
    env = messaging.Envelope(sender, recipient, payload, ts)
    asyncio.run(agent.handle(env))
    assert bus.published[-1][1].payload[""status""] == ""blocked""
",tests/test_safety_guardian_property.py,,1,9.237449576640118e-09,"The method `test_fuzz_envelope_blocks_malicious` is a test function that appears to be part of a testing suite for a system involving message handling and security. It checks if a message containing potentially malicious code (e.g., code with 'import os') is correctly identified and blocked by the system. This kind of test is crucial for ensuring the security and robustness of the system against malicious inputs. Therefore, it is likely to be retained as part of the test suite to continuously verify the system's security features."
survived,"def pad(
    array: NamedArray,
    pad_width: Mapping[AxisSelector, tuple[int, int]],
    *,
    mode: str = ""constant"",
    constant_values: NamedOrNumeric = 0,
    **kwargs,
) -> NamedArray:
    """"""Version of ``jax.numpy.pad`` that works with ``NamedArray``.

    ``pad_width`` should be a mapping from axis (or axis name) to a ``(before, after)``
    tuple specifying how much padding to add on each side of that axis. Any axis
    not present in ``pad_width`` will not be padded.
    """"""

    padding = []
    new_axes = []
    for ax in array.axes:
        left_right = pad_width.get(ax)
        if left_right is None:
            left_right = pad_width.get(axis_name(ax))  # type: ignore[arg-type]
        if left_right is None:
            left_right = (0, 0)
        left, right = left_right
        padding.append((left, right))
        new_axes.append(ax.resize(ax.size + left + right))

    result = jnp.pad(
        array.array,
        padding,
        mode=mode,
        constant_values=raw_array_or_scalar(constant_values),
        **kwargs,
    )

    return NamedArray(result, tuple(new_axes))
",src/haliax/ops.py,,1,1.6052280526088547e-09,"The method is a specialized version of the `jax.numpy.pad` function, designed to work with `NamedArray` objects. It provides additional functionality by allowing padding based on axis names, which is not directly supported by the standard `jax.numpy.pad`. This makes it useful for users who work with named axes and need to perform padding operations. The method is well-documented, and its functionality is clear and specific, suggesting it serves a unique purpose that is likely to be valuable to its intended audience. Therefore, it is likely to be retained."
survived,"def Tool(*_args, **_kwargs):
    def decorator(func):
        return func

    return decorator
",openai_agents/__init__.py,,1,9.237449576640118e-09,"The method 'Tool' is a decorator factory that returns a decorator function. This pattern is commonly used in Python to create decorators that can accept arguments. The method itself is simple and functional, and it doesn't contain any obvious issues or redundancies that would necessitate its removal. Decorators are a fundamental part of Python, and this method provides a flexible way to create them. Therefore, it is likely to be retained in the codebase."
survived,"            async def __call__(self, text: str) -> str:
                return ""ok""
",alpha_factory_v1/demos/aiga_meta_evolution/utils.py,OpenAIAgent,0,0.999860177965895,"The method is an asynchronous call method that takes a string input and returns a string 'ok'. It is a simple implementation that might be used as a placeholder or a basic response handler. However, without additional context on its usage or integration into a larger system, it's difficult to determine its utility. If this method is part of a larger framework or application where such a response is meaningful, it might survive. Otherwise, if it's not serving a clear purpose or is too simplistic, it might be deleted. Given the lack of context, it is more likely to be deleted unless it is part of a testing or placeholder scenario."
survived,"    def test_entry_point_resolves(self) -> None:
        eps = im.entry_points().select(group=""console_scripts"")
        match = [ep for ep in eps if ep.name == ""mats-bridge""]
        self.assertTrue(match, ""mats-bridge entry point not found"")
        self.assertEqual(
            match[0].value,
            ""alpha_factory_v1.demos.meta_agentic_tree_search_v0.openai_agents_bridge:main"",
        )
",tests/test_mats_bridge_entrypoint.py,TestMatsBridgeEntryPoint,1,7.194132978569833e-09,"The method 'test_entry_point_resolves' is a unit test that verifies the existence and correct configuration of an entry point named 'mats-bridge'. This is a crucial part of ensuring that the software package is correctly set up and that the entry point is properly linked to the expected function. Such tests are essential for maintaining the integrity of the software package and ensuring that it behaves as expected when installed and executed. Therefore, it is unlikely to be deleted as it serves an important role in the testing suite."
survived,"    async def get_resource(ctx: EnrichContext, **kwargs: int) -> enrich_model | None:  # type: ignore[name-defined]
        entity_id = kwargs[param_name]
        session_factory = ctx.request_context.lifespan_context[session_key]
        async with session_factory() as session:  # type: AsyncSession
            obj = await session.get(sa_model, entity_id)
            return _sa_to_enrich(obj, enrich_model) if obj else None
",src/enrichmcp/sqlalchemy/auto.py,,1,6.69158608681505e-10,"The method 'get_resource' is likely to survive because it is an asynchronous function that efficiently retrieves a resource from a database using an entity ID. It uses modern Python features such as type hinting and asynchronous context management, which are considered best practices in current software development. Additionally, it is designed to be flexible by accepting additional keyword arguments, making it adaptable to future changes or requirements."
survived,"    async def run() -> None:
        await asyncio.gather(
            orch.evolve(""a"", fn, 1, experiment_id=""exp1"", population_size=2, generations=1),
            orch.evolve(""b"", fn, 1, experiment_id=""exp2"", population_size=2, generations=1),
        )
",tests/test_experiments.py,,1,4.1399375473943306e-08,"The method 'run' is an asynchronous function that uses 'asyncio.gather' to concurrently execute two 'orch.evolve' tasks. This pattern is common in modern Python applications that require concurrent execution of tasks, especially in scenarios involving I/O-bound operations or parallel processing. The use of 'async' and 'await' is a standard practice in Python for handling asynchronous operations efficiently. Given the increasing adoption of asynchronous programming in Python, it is unlikely that this method will be deleted unless there is a significant change in the application's requirements or architecture."
survived,"def test_ragged_paged_attention_incremental_multi_seq():
    rng = jr.PRNGKey(3)
    seq_lens = [10, 37, 64]
    k_lens = [1, 3, 9]
    q, kv_pages, kv_lens, page_indices, cu_q_lens, num_seqs = _build_incremental_case(rng, seq_lens, k_lens)

    ragged = default_ragged_paged_attention(q, kv_pages, kv_lens, page_indices, cu_q_lens, num_seqs, sm_scale=SM_SCALE)
    ref = _reference_attention(q, kv_pages, kv_lens, page_indices, cu_q_lens, k_lens)

    assert ragged.axes == ref.axes
    assert_trees_all_close(ragged.array, ref.array, atol=1e-3, rtol=1e-3)",tests/test_paged_attention.py,,1,4.1399375473943306e-08,"The method `test_ragged_paged_attention_incremental_multi_seq` is a test function, which is typically used to verify the correctness of code. Test functions are generally retained in codebases to ensure that the functionality they are testing remains correct over time, especially when changes are made to the code. This function appears to be testing a specific feature related to 'ragged paged attention' and comparing it against a reference implementation. As long as the feature it tests is relevant and the test is correctly implemented, it is likely to be retained."
survived,"    def test_run_demo_anthropic_rewriter(self) -> None:
        result = subprocess.run(
            [
                sys.executable,
                ""-m"",
                ""alpha_factory_v1.demos.meta_agentic_tree_search_v0.run_demo"",
                ""--episodes"",
                ""2"",
                ""--rewriter"",
                ""anthropic"",
            ],
            capture_output=True,
            text=True,
        )
        self.assertEqual(result.returncode, 0, result.stderr)
        self.assertIn(""Best agents"", result.stdout)
",tests/test_meta_agentic_tree_search_demo.py,TestMetaAgenticTreeSearchDemo,1,5.905303995456778e-10,"The method `test_run_demo_anthropic_rewriter` is a unit test designed to verify the functionality of a specific demo script. It uses `subprocess.run` to execute a command-line script and checks the output for expected results. This is a common practice in testing to ensure that scripts behave as expected when run in a real environment. The method is likely to survive because it serves a clear purpose in validating the integration and execution of the demo script, which is crucial for maintaining the reliability of the software."
survived,"def health() -> dict[str, str]:
    """"""Return service health status.""""""
    return {""status"": ""ok""}",test_repo/backend/main.py,,1,9.736200303530205e-10,"The method 'health' is a simple utility function that returns a dictionary indicating the service health status. Such functions are commonly used in applications to provide a quick check on the system's operational status. The method is straightforward, has a clear purpose, and is likely to be useful in various contexts, such as monitoring or health checks in web services. Therefore, it is unlikely to be deleted."
survived,"def test_openai_link_head() -> None:
    url = dg.model_urls(""124M"")[0]
    resp = requests.head(url, timeout=10)
    assert resp.status_code == 200",tests/test_download_openai_gpt2.py,,1,8.152020648014727e-09,"The method `test_openai_link_head` is a simple test function that checks if a URL is reachable by sending a HEAD request and asserting that the response status code is 200. This is a common practice in testing to ensure that links are valid and accessible. The function is straightforward, uses standard libraries, and serves a clear purpose in testing URL accessibility. Therefore, it is likely to be retained as it provides utility in verifying the availability of resources."
survived,"def print_banner() -> None:
    """"""Display the default banner.""""""
    print(banner())
",alpha_factory_v1/demos/alpha_agi_insight_v0/openai_agents_bridge.py,,1,1.522997951276035e-08,"The method 'print_banner' is a simple utility function that calls another function 'banner' to print a banner. Without additional context, such as the implementation of 'banner' or the overall usage of 'print_banner', it's difficult to determine its necessity. However, utility functions like this are often kept for code organization and readability, especially if 'banner' is a reusable component. Therefore, unless there's a specific reason to remove it, such as redundancy or a shift in design requirements, it is likely to survive."
survived,"  def supports_active_cooling(self) -> bool:
    """"""Whether this backend can actively cool below ambient temperature.""""""
    raise NotImplementedError
",pylabrobot/temperature_controlling/backend.py,TemperatureControllerBackend,1,1.955568070542584e-08,"The method `supports_active_cooling` is a placeholder method that raises a `NotImplementedError`. This indicates that it is intended to be implemented by subclasses or future versions of the class. The presence of a docstring suggests that the method is part of a planned interface or abstract class design. Such methods are typically retained in the codebase to enforce implementation in derived classes and to provide a clear contract for developers. Therefore, it is likely to survive."
survived,"def test_simulate_save_plots(tmp_path: Path) -> None:
    runner = CliRunner()
    with patch.object(cli, ""asyncio""):
        with patch.object(cli.orchestrator, ""Orchestrator""):
            with runner.isolated_filesystem(temp_dir=tmp_path):
                res = runner.invoke(
                    cli.main,
                    [
                        ""simulate"",
                        ""--horizon"",
                        ""1"",
                        ""--offline"",
                        ""--sectors"",
                        ""1"",
                        ""--pop-size"",
                        ""1"",
                        ""--generations"",
                        ""1"",
                        ""--save-plots"",
                    ],
                )
    assert res.exit_code == 0
    assert Path(""pareto.png"").exists()
    assert Path(""pareto.json"").exists()",tests/test_demo_cli.py,,1,1.725782769012759e-08,"The method 'test_simulate_save_plots' is a unit test designed to verify the functionality of a command-line interface (CLI) command. It uses the 'CliRunner' to simulate running the CLI command and checks if the expected output files ('pareto.png' and 'pareto.json') are created. This is a typical pattern for testing CLI applications, ensuring that the command executes successfully and produces the expected results. Since testing is a crucial part of software development to ensure code reliability and correctness, this method is likely to be retained in the codebase."
survived,"        def search(self, *_):
            class Limiter:
                def limit(self, *_):
                    class Selector:
                        def select(self, *_):
                            return self

                        def to_list(self):
                            return [{""_distance"": 0.1, ""index"": 0, ""pdf_name"": ""x.pdf"", ""pdf_page"": 1}]

                    return Selector()

            return Limiter()
",no-ocr-api/tests/test_ingest_search.py,FakeTable,1,3.3982678079468468e-09,"The method 'search' is a part of a nested class structure that seems to be designed for a specific purpose, likely related to searching and selecting items with certain attributes. The method itself is functional and returns a 'Limiter' object, which further allows for selection and listing of items. This structure suggests that the method is part of a larger system or framework, possibly for document or data management, where such functionality is necessary. Without additional context indicating that this method is obsolete or redundant, it is likely to be retained for its intended use."
survived,"    def fake_from_list(lst):
        return FakeDataset(lst)
",no-ocr-api/tests/test_ingest_search.py,,1,7.582560422162384e-10,"The method 'fake_from_list' is a simple utility function that creates an instance of 'FakeDataset' using a provided list. It is likely to be a helper function in a larger codebase, possibly for testing or mocking purposes. Such utility functions are generally useful and are not typically removed unless they are replaced by a more efficient or comprehensive solution. Without additional context indicating redundancy or obsolescence, it is reasonable to predict that this method will survive."
survived,"def test_large_payloads_delivered_intact(
    sender: str, recipient: str, payload_text: str, ts: float
) -> None:  # type: ignore[misc]
    """"""Envelopes with huge strings should round-trip through the bus.""""""

    bus = messaging.A2ABus(config.Settings(bus_port=0))
    received: list[messaging.Envelope] = []

    async def handler(env: messaging.Envelope) -> None:
        received.append(env)

    bus.subscribe(recipient, handler)
    env = messaging.Envelope(sender=sender, recipient=recipient, ts=ts)
    env.payload[""data""] = payload_text

    async def run() -> None:
        bus.publish(recipient, env)
        await asyncio.sleep(0)

    asyncio.run(run())

    assert received
    assert received[0].sender == sender
    assert received[0].recipient == recipient
    assert received[0].payload[""data""] == payload_text
    assert received[0].ts == ts
",tests/test_bus_large_payloads_property.py,,1,8.152020648014727e-09,"The method 'test_large_payloads_delivered_intact' is a test function designed to verify that large payloads are correctly delivered through a messaging bus. Test functions are generally not deleted unless they are redundant or replaced by more comprehensive tests. This function is specific in its purpose and tests a critical aspect of message integrity, which is important for system reliability. Therefore, it is likely to be retained."
survived,"def scenario_2001_genome() -> replay.Scenario:
    return replay.load_scenario(""2001_genome"")
",tests/conftest.py,,1,2.0611536181902033e-09,"The method `scenario_2001_genome` is a simple wrapper around the `replay.load_scenario` function, which loads a scenario named ""2001_genome"". This method is likely part of a larger system that deals with scenarios, possibly for testing or simulation purposes. The method is straightforward, has a clear purpose, and does not contain any obvious issues or redundancies. Therefore, it is likely to be useful in its context and is expected to survive."
survived,"        def __init__(self) -> None:
            self.status_code = 200
",tests/test_start_alpha_business.py,Resp,1,1.725782769012759e-08,"The method is a constructor for a class, initializing an instance variable 'status_code' with a default value of 200. This is a common practice in object-oriented programming to set up initial state for an object. There is no indication that this method is redundant or unnecessary, as it serves a clear purpose in setting up the object's state. Therefore, it is likely to be retained in the code."
survived,"        def poll(self) -> None:
            return None
",tests/test_start_alpha_business.py,DummyProc,0,0.9999997897565932,"The method 'poll' is defined to return None explicitly and does not perform any operations or computations. It appears to be a placeholder or a stub, which might be intended for future implementation. However, as it currently stands, it does not serve any functional purpose. If the method is not used or called anywhere in the code, it is likely to be deleted in future refactoring to clean up the codebase."
survived,"    def _make_client(self):
        runner = DummyRunner()
        runner.inst = DummyAgent()
        app = _build_rest({""foo"": runner})
        return TestClient(app), runner
",alpha_factory_v1/tests/test_orchestrator_rest.py,UpdateModelTest,1,3.2241866333029355e-08,"The method _make_client is a private helper function, indicated by the underscore prefix, which is commonly used in Python to denote methods intended for internal use within a module or class. It is responsible for setting up a test client and a runner instance, which are likely used for testing purposes. Such methods are typically retained as they are crucial for maintaining and running tests, especially in a development or testing environment. Therefore, it is unlikely to be deleted unless the testing framework or approach is completely overhauled."
survived,"    def register(
        self,
        metadata: TemplateMetadata,
        content: str,
        version: str = ""0.1.0"",
    ) -> Optional[str]:
        slug = metadata.slug
        slug_sanitized = slug.replace("" "", ""_"").lower()
        version_sanitized = ""v"" + version.replace(""."", ""_"")
        version_dir = self.templates_dir / slug_sanitized / version_sanitized
        version_dir.mkdir(parents=True, exist_ok=True)
        template_path = version_dir / TEMPLATE_FILE_NAME
        template_path.write_text(content, encoding=""utf-8"")
        checksum = sha256(content.encode(""utf-8"")).hexdigest()
        metadata_dict = (
            metadata.model_dump()
            if hasattr(metadata, ""model_dump"")
            else metadata.dict()
        )
        meta_data = {
            **metadata_dict,
            ""version"": version,
            ""checksum"": checksum,
        }
        with open(version_dir / METADATA_FILE_NAME, ""w"", encoding=""utf-8"") as f:
            json.dump(meta_data, f, indent=2)
        manifest = self._load_manifest()
        entry = manifest.setdefault(slug_sanitized, {""versions"": {}})
        entry[""versions""][version] = {
            ""path"": f""{slug_sanitized}/{version_sanitized}/{TEMPLATE_FILE_NAME}"",
            ""checksum"": checksum,
            ""created_at"": datetime.utcnow().isoformat(),
        }
        entry[""current_version""] = version
        self._save_manifest(manifest)
        return str(template_path)
",src/meta_agent/template_registry.py,TemplateRegistry,1,2.8453347280241004e-08,"The method 'register' is a well-structured function that performs a series of operations to register a template with metadata, content, and versioning. It handles file and directory creation, metadata serialization, and manifest updating. These operations are essential for managing templates in a system that requires version control and metadata tracking. The method is likely to be useful in contexts where templates need to be registered and tracked over time, such as in content management systems or software that deals with templated documents. The method's functionality is clear, and it appears to be implemented correctly, making it unlikely to be deleted unless there is a significant change in the system's requirements or architecture."
survived,"def test_duplicate_disclaimer_fails(tmp_path: Path) -> None:
    repo = _create_repo(tmp_path, SNIPPET_TEXT + ""\n"" + SNIPPET_TEXT)
    missing, duplicates = verify_disclaimer_snippet.check_repo(repo)
    assert duplicates == [repo / ""README.md""]",tests/test_verify_disclaimer_snippet.py,,1,1.6052280526088547e-09,"The method 'test_duplicate_disclaimer_fails' is a unit test designed to verify that a repository with duplicate disclaimer snippets is correctly identified. Unit tests are crucial for ensuring code reliability and correctness, especially in projects that involve multiple contributors or complex logic. This test checks a specific functionality of the 'verify_disclaimer_snippet' module, which is likely part of a larger system for managing or verifying documentation. Given the importance of testing in software development, this method is likely to be retained to ensure the system behaves as expected when encountering duplicate disclaimers."
survived,"def sha384(path: Path) -> str:
    """"""Return the SHA-384 digest of ``path`` in SRI format.""""""
    digest = hashlib.sha384(path.read_bytes()).digest()
    return ""sha384-"" + base64.b64encode(digest).decode()
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/build/common.py,,1,2.646573631904765e-09,"The method `sha384` is a utility function that computes the SHA-384 hash of a file's contents and returns it in a specific format (SRI format). This is a common requirement for verifying file integrity and ensuring security, especially in web applications where Subresource Integrity (SRI) is used to ensure that files have not been tampered with. The method is concise, performs a specific task, and is likely to be useful in various contexts where file integrity needs to be verified. Therefore, it is likely to be retained in the codebase."
survived,"    def _build_prompt(self, n: int) -> str:
        examples = (
            ""\n\n"".join(
                f""```python\n{t.program}```\n```json\n{t.inp}```\n```json\n{t.out}```""
                for t in self._rng.sample(self.buffer, k=min(3, len(self.buffer)))
            )
            or ""(buffer empty)""
        )

        return self._PROMPT.format(
            n=n,
            max_loc=MAX_PROG_LOC,
            buf=len(self.buffer),
            examples=examples,
        )
",alpha_factory_v1/demos/meta_agentic_agi_v3/curriculum/azr_engine.py,AZREngine,1,3.581747929000289e-10,"The method '_build_prompt' is likely to survive because it appears to be a utility function that constructs a formatted string using a template. This kind of method is often used in applications that require dynamic string generation, such as generating prompts for machine learning models or creating user interfaces. The method is well-structured, uses clear logic to handle cases where the buffer might be empty, and leverages Python's string formatting capabilities effectively. These characteristics suggest that it serves a useful purpose in its context and is unlikely to be removed unless the entire functionality it supports is deprecated."
survived,"    async def _monitor(self) -> None:
        while True:
            await asyncio.sleep(2)
            now = time.time()
            for r in list(self.runners.values()):
                if r.task and r.task.done():
                    await r.restart(self.bus, self.ledger)
                elif now - r.last_beat > r.period * 5:
                    logging._log.warning(""%s unresponsive â€“ restarting"", r.agent.name)
                    await r.restart(self.bus, self.ledger)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/orchestrator.py,Orchestrator,1,9.736200303530205e-10,"The method '_monitor' is an asynchronous function that continuously monitors a set of 'runners' for task completion or unresponsiveness. It uses asyncio to sleep for 2 seconds between checks, ensuring it doesn't block other operations. The method is crucial for maintaining the responsiveness and reliability of the system by restarting tasks that are either completed or unresponsive. This kind of monitoring is essential in systems that require high availability and fault tolerance. Therefore, the method is likely to be retained as it provides significant functionality for system stability."
survived,"def _simulate(horizon: int, curve: str, pop_size: int, generations: int) -> list[Any]:
    """"""Run the disruption forecast and return the trajectory.""""""

    secs = [sector.Sector(f""s{i:02d}"") for i in range(pop_size)]
    return forecast.forecast_disruptions(
        secs,
        horizon,
        curve,
        pop_size=pop_size,
        generations=generations,
    )
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/web_app.py,,1,9.237449576640118e-09,"The method '_simulate' is likely to survive because it appears to be a well-defined utility function that serves a specific purpose in a larger forecasting or simulation system. It takes in parameters that define the scope and nature of the simulation (horizon, curve, population size, and generations) and returns a list of results, which suggests it is integral to the functionality of the system it is part of. Additionally, the use of type hints and a docstring indicates good coding practices, which further supports its likelihood of being maintained."
survived,"    def vmap(self, init, *extra_args, **extra_kwargs):
        """"""Apply each block independently using :func:`haliax.vmap`.

        This maps ``init`` through every block in parallel, so each block
        receives the same ``init`` but its own parameters.  Extra ``args`` and
        ``kwargs`` are also mapped over the block axis by default.

        Returns the stacked outputs of each block.
        """"""

        if haliax.is_named_array(init):
            init = init.broadcast_axis(self.Block)
        elif haliax.jax_utils.is_jax_array_like(init):
            init = jnp.broadcast_to(init, (self.Block.size,) + init.shape)
        else:
            init = tuple(init for _ in range(self.Block.size))

        arg_spec = (0, 0) + (0,) * len(extra_args)
        kwarg_spec = {k: 0 for k in extra_kwargs}

        do_vmap = haliax.vmap(
            Stacked._do_block,
            self.Block,
            default=0,
            args=arg_spec,
            kwargs=kwarg_spec,
        )
        return do_vmap(init, self.stacked, *extra_args, **extra_kwargs)
",src/haliax/nn/scan.py,Stacked,1,8.152020648014727e-09,"The method 'vmap' is a specialized function that applies a vectorized map operation over blocks of data using the 'haliax.vmap' function. It is designed to handle both named arrays and JAX-like arrays, broadcasting them appropriately across blocks. The method is well-documented, indicating its purpose and functionality clearly. It also uses a specific library ('haliax') which suggests it is part of a larger framework or system. Given its specialized nature and integration with a specific library, it is likely to be useful for users of that library, and therefore, it is unlikely to be deleted."
survived,"def test_dtype_category_annotation_and_check():
    def baz(x: Float[""b""]):  # type: ignore  # noqa: F722
        pass

    spec = typing.get_args(typing.get_type_hints(baz, include_extras=True)[""x""])[1]
    assert str(spec.dtype) == ""float""

    B = Axis(""b"", 1)
    arr = NamedArray(jnp.ones((B.size,), dtype=jnp.float32), (B,))
    assert arr.matches_axes(Float[""b""])  # type: ignore
    assert not arr.matches_axes(Int[""b""])  # type: ignore",tests/test_dtype_typing.py,,0,0.9999957771682556,"The method is likely to be deleted because it contains several elements that suggest it is not production-ready or fully functional. Firstly, it uses type annotations with a custom type 'Float[""b""]' which is not a standard Python type and seems to be part of a custom or experimental type system. The use of 'type: ignore' comments indicates that the code is bypassing type checking, which is often a sign of incomplete or experimental code. Additionally, the use of 'noqa: F722' suggests that the code is suppressing specific linting errors, which is another indicator that the code might not be stable or fully integrated into a larger codebase. These factors combined suggest that the method is more of a test or experimental function rather than a stable, production-ready method, making it a candidate for deletion."
survived,"    def bar(x: i32[""batch""]):  # type: ignore  # noqa: F722
        pass
",tests/test_dtype_typing.py,,0,0.9999995549151272,"The method 'bar' is defined with a parameter 'x' that uses a type hint 'i32[""batch""]'. This type hint is unconventional and not standard in Python, which typically uses types from the 'typing' module or built-in types. The use of 'type: ignore' and 'noqa: F722' suggests that the developer is aware of potential issues with the type hint and is suppressing warnings. However, without a clear purpose or functionality, and given the unconventional type hint, this method is likely to be deleted unless it serves a specific, documented purpose in a larger codebase."
survived,"    def __init__(self, payload=None, text=""ok"", status_code=200):
        self._payload = payload
        self.text = text
        self.status_code = status_code
",tests/test_openai_bridge_integration.py,DummyResponse,1,1.3440409770490404e-08,"The method is a constructor for a class, initializing instance variables with default values. This is a common and necessary pattern in object-oriented programming to set up initial state for objects. There is no indication that this method is redundant or poorly designed, so it is likely to be retained in the codebase."
survived,"def call(code: str, func: str, *args: Any, mochi_bin: str = ""mochi"") -> Any:
    """"""Call ``func`` defined in ``code`` with ``args`` and return the result.

    ``code`` should contain the Mochi function definition. The result is
    obtained by wrapping the call with the ``json`` builtin and decoding the
    output.
    """"""
    args_literal = "", "".join(_to_mochi(a) for a in args)
    snippet = f""{code}\njson({func}({args_literal}))\n""
    out = _run(snippet, mochi_bin)
    return json.loads(out.strip())
",tools/libmochi/python/libmochi.py,,1,3.160881453314576e-10,"The method 'call' is a utility function that executes a Mochi function with given arguments and returns the result. It is well-documented, specifying the purpose and usage of the function. The method is likely part of a larger system that interacts with Mochi, a language or framework, and provides a clear interface for executing Mochi code. There is no indication of redundancy, inefficiency, or lack of use that would warrant its deletion. Therefore, it is likely to be retained in the codebase."
survived,"        def get_tracer(self, _name: str) -> DummyTracer:
            return self.tracer
",tests/test_metrics.py,DummyTrace,1,7.582560422162384e-10,"The method `get_tracer` is a simple getter method that returns an instance variable `self.tracer`. Such methods are typically retained in codebases as they provide a clear and consistent way to access private or protected attributes. Unless there is a significant refactor or change in design that eliminates the need for this method, it is likely to survive."
survived,"        def start_as_current_span(self, name: str) -> Any:
            self.spans.append(name)
            return nullcontext()
",tests/test_metrics.py,DummyTracer,1,3.3982678079468468e-09,"The method 'start_as_current_span' is a simple utility function that appends a span name to a list and returns a null context. It is likely part of a larger tracing or logging system. The method is straightforward, performs its intended function, and does not contain any apparent issues or inefficiencies. Therefore, it is likely to be retained in the codebase."
survived,"def test_router_init_requires_valid_default():
    with pytest.raises(ValueError):
        GuardrailModelRouter({""a"": MockAdapter()}, default_model=""b"")
",tests/test_guardrail_router.py,,1,2.646573631904765e-09,"The method is a test function that checks if the GuardrailModelRouter raises a ValueError when initialized with an invalid default model. This is a typical unit test to ensure the robustness of the code by verifying that it handles incorrect inputs as expected. Such tests are crucial for maintaining code quality and are unlikely to be deleted unless the functionality they test is removed or significantly altered. Therefore, the method will survive."
survived,"def test_guardrail_config_from_dict():
    data = {""rules"": [{""name"": ""pii"", ""pattern"": ""ssn""}]}
    cfg = GuardrailConfig.from_dict(data)
    assert len(cfg.rules) == 1
    assert cfg.rules[0].name == ""pii""
",tests/test_guardrail_generator.py,,1,9.237449576640118e-09,"The method 'test_guardrail_config_from_dict' is a unit test function that verifies the functionality of the 'GuardrailConfig.from_dict' method. Unit tests are crucial for ensuring code reliability and are typically retained in the codebase to maintain software quality. Therefore, it is likely to be Survived."
survived,"def _free_port() -> int:
    with socket.socket() as s:
        s.bind((""127.0.0.1"", 0))
        return s.getsockname()[1]
",tests/test_api_server_subprocess.py,,1,4.363462233903899e-09,"The method _free_port is a utility function that finds and returns a free port on the local machine. This is a common requirement in network programming, especially for testing purposes where a free port is needed to bind a server or client socket without hardcoding a specific port number. The method is simple, effective, and uses standard library functions, making it a useful and reusable piece of code. Therefore, it is likely to be retained in the codebase."
survived,"def test_strip_color_codes():
    text = ""\x1b[31merror\x1b[0m""
    assert strip_color_codes(text) == 'error'
",tests/test_whois_perms.py,,1,9.736200303530205e-10,"The method test_strip_color_codes is a unit test for the function strip_color_codes. Unit tests are essential for ensuring that code functions correctly and as expected. They help in identifying bugs early in the development process and ensure that future changes do not break existing functionality. Given the importance of testing in software development, this method is likely to be retained to maintain code quality and reliability."
survived,"        def start_merkle_task(self, *_a, **_kw) -> None:
            pass
",tests/test_agents.py,DummyLedger,0,0.9986749777511619,"The method `start_merkle_task` is currently a placeholder with no implementation (it only contains a `pass` statement). If this method is part of a larger class or module that is actively being developed, it might be intended for future implementation, especially if it aligns with the functionality of the class or module. However, if there is no plan to implement this method or if it has been left unimplemented for a long time, it might be considered for deletion to clean up the codebase. Without additional context, it's difficult to determine the exact intention, but generally, unimplemented methods are at risk of being deleted unless they are planned for future use."
survived,"        def log(self, env) -> None:  # type: ignore[override]
            events.append(env.payload.get(""event""))
",tests/test_agents.py,DummyLedger,1,3.2241866333029355e-08,"The method 'log' is a simple function that appends an event from the 'env' object to a global 'events' list. It uses a type ignore comment to bypass type checking for method overriding, which suggests it might be part of a larger class structure where method signatures are expected to match. The method itself is straightforward and performs a basic logging operation, which is a common requirement in many applications for tracking events or actions. Unless there is a significant change in the application's logging strategy or architecture, such as moving to a more sophisticated logging framework, this method is likely to survive as it fulfills a fundamental role."
survived,"    def test_no_pydantic_available(self):
        global memf
        sys.modules.pop(""alpha_factory_v1.backend.memory_fabric"", None)
        importlib.invalidate_caches()
        with mock.patch.dict(
            sys.modules,
            {""pydantic"": None, ""pydantic_settings"": None},
        ):
            memf = importlib.import_module(""alpha_factory_v1.backend.memory_fabric"")
            self.assertEqual(memf.CFG.PGDATABASE, ""memdb"")
            self.assertEqual(memf.BaseSettings.__module__, memf.__name__)
        # reload original module for other tests
        sys.modules.pop(""alpha_factory_v1.backend.memory_fabric"", None)
        memf = importlib.import_module(""alpha_factory_v1.backend.memory_fabric"")
",alpha_factory_v1/tests/test_memory_provider.py,SettingsFallbackTest,1,2.8453347280241004e-08,"The method `test_no_pydantic_available` is a unit test designed to verify the behavior of the `alpha_factory_v1.backend.memory_fabric` module when the `pydantic` and `pydantic_settings` modules are not available. This is a specific test case that ensures the module can handle the absence of these dependencies gracefully. Such tests are crucial for maintaining robustness and ensuring that the software can handle different environments or configurations. Therefore, it is likely to be retained as part of the test suite to ensure continued reliability and compatibility."
survived,"    def close(self) -> None:
        """"""Close any open database connections.""""""
        if getattr(self, ""_driver"", None):
            try:
                self._driver.close()
            except Exception as exc:  # pragma: no cover - defensive
                logger.warning(""GraphStore: driver close failed â†’ %s"", exc)
            finally:
                self._driver = None
",alpha_factory_v1/backend/memory_fabric.py,_GraphStore,1,2.8453347280241004e-08,"The method 'close' is essential for managing resources, specifically for closing database connections. It includes error handling to ensure that any exceptions during the closing process are logged, which is a good practice for maintaining robust applications. The method is also designed to set the driver to None after attempting to close it, which helps prevent further operations on a closed connection. These characteristics make it a necessary part of the class it belongs to, ensuring proper resource management and preventing potential memory leaks or connection issues."
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/q2.py,Partsupp,1,4.944450477491054e-09,"The __repr__ method is a special method used to define a string representation of an object. In this case, it returns the string representation of the object's __dict__, which is a dictionary containing all the attributes of the object. This is a common and useful implementation for debugging purposes, as it provides a clear and detailed view of the object's state. Therefore, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/q2.py,Partsupp,1,2.8453347280241004e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a flexible and Pythonic way to access object attributes, it is likely to be retained in the code."
survived,"def test_Q2_returns_only_supplier_with_min_cost_in_Europe_for_brass_part():
    assert result == [
        {
            ""s_acctbal"": 1000,
            ""s_name"": ""BestSupplier"",
            ""n_name"": ""FRANCE"",
            ""p_partkey"": 1000,
            ""p_mfgr"": ""M1"",
            ""s_address"": ""123 Rue"",
            ""s_phone"": ""123"",
            ""s_comment"": ""Fast and reliable"",
            ""ps_supplycost"": 10,
        }
    ]
",tests/machine/x/python/q2.py,,1,1.8189616842444243e-09,"The method is a test function that checks if a specific query returns the correct supplier with the minimum cost in Europe for a brass part. It is a specific and useful test case for validating the functionality of a query or a function in a codebase. Test functions are generally retained as they are crucial for ensuring code correctness and reliability. Therefore, it is likely to be Survived."
survived,"        def step(self, _a: int):
            return None, self.reward, True, {}
",tests/test_world_model_demo.py,DummyEnv,0,0.9995121429603662,"The method 'step' is a part of a class, likely related to a reinforcement learning environment, given the parameters and return values. However, the method currently does not utilize its input parameter '_a' and returns a fixed set of values, which might not be useful in a dynamic environment where actions should influence the state and reward. This lack of functionality suggests that the method might be considered for deletion unless it is intended as a placeholder for future development."
survived,"        def train_once(self) -> float:
            return self.loss
",tests/test_world_model_demo.py,DummyLearner,1,4.1399375473943306e-08,"The method 'train_once' is a simple method that returns the value of 'self.loss'. It is likely a part of a larger class related to machine learning or optimization, where 'self.loss' represents the loss value of a model after a training iteration. Such methods are common in machine learning frameworks to encapsulate the training logic and provide easy access to the loss value for monitoring or logging purposes. Since it serves a clear purpose and is likely used in the context of model training, it is unlikely to be deleted unless the entire class or its functionality is being refactored or removed."
survived,"def run_transfer_test(
    models: Iterable[str],
    top_n: int,
    *,
    archive_path: str | Path = DEFAULT_ARCHIVE,
    out_file: str | Path = DEFAULT_RESULTS,
) -> None:
    """"""Evaluate the top ``top_n`` agents on each model.

    Appends the results to ``out_file``.
    """"""

    arch = Archive(archive_path)
    agents = sorted(arch.all(), key=lambda a: a.score, reverse=True)[:top_n]

    path = Path(out_file)
    path.parent.mkdir(parents=True, exist_ok=True)
    exists = path.exists()
    with path.open(""a"", newline="""", encoding=""utf-8"") as fh:
        writer = csv.writer(fh)
        if not exists:
            writer.writerow([""id"", ""model"", ""score""])
        for agent in agents:
            for model in models:
                score = evaluate_agent(agent, model)
                writer.writerow([agent.id, model, f""{score:.3f}""])
",src/tools/transfer_test.py,,1,2.3355930333443423e-09,"The method `run_transfer_test` is a utility function designed to evaluate and log the performance of agents on different models. It is well-structured, uses type hints, and handles file operations safely by checking if the output file exists before writing headers. The function is likely to be useful in scenarios where model evaluation and result logging are required, which are common tasks in machine learning and data analysis workflows. Therefore, it is likely to be retained in the codebase."
survived,"def run() -> None:
    parts = [""poly"", ""task"", ""10""]
    joined = ""-"".join(parts)
    assert joined.split(""-"")[2] == str(10)",benchmarks/poly_mini/task_010.py,,1,2.5109990926928157e-08,"The method 'run' is a simple function that joins a list of strings with a hyphen and then splits the resulting string to assert that the third element is '10'. This is a straightforward and correct implementation of string manipulation in Python. The function is clear, concise, and performs as expected without any errors or unnecessary complexity. Therefore, there is no reason to delete this method as it serves its purpose effectively."
survived,"def run() -> None:
    parts = [""poly"", ""task"", ""16""]
    joined = ""-"".join(parts)
    assert joined.split(""-"")[2] == str(16)",benchmarks/poly_mini/task_016.py,,1,2.5109990926928157e-08,"The method 'run' is a simple function that joins a list of strings with a hyphen and then splits the resulting string to assert that the third element is '16'. This is a straightforward and correct implementation of string manipulation in Python. The function is clear, concise, and performs as expected without any errors or unnecessary complexity. Therefore, there is no reason to delete this method as it serves its purpose effectively."
survived,"def run() -> None:
    n = 9
    total = sum(range(n))
    expected = n*(n-1)//2
    assert total == expected",benchmarks/swe_mini/task_009.py,,1,4.222835268240621e-06,"The method 'run' is a simple function that calculates the sum of numbers from 0 to n-1 and checks if it matches the expected sum using the formula for the sum of an arithmetic series. This is a basic example of a test function that verifies the correctness of a calculation. Such functions are often used in testing and educational contexts to demonstrate concepts or ensure code correctness. Since it serves a clear purpose in verifying a mathematical property, it is likely to be retained in contexts where such verification is necessary or educational."
survived,"def run() -> None:
    parts = [""poly"", ""task"", ""14""]
    joined = ""-"".join(parts)
    assert joined.split(""-"")[2] == str(14)",benchmarks/poly_mini/task_014.py,,1,1.444980317078884e-07,"The method 'run' is a simple function that joins a list of strings with a hyphen and then splits the resulting string to assert that the third element is '14'. This function is straightforward, has no side effects, and serves as a basic demonstration of string manipulation in Python. It is likely to be retained as it could be useful for educational purposes or as a utility function in a larger codebase. The function is also correctly implemented without any apparent bugs or issues."
survived,"def run() -> None:
    n = 13
    total = sum(range(n))
    expected = n*(n-1)//2
    assert total == expected",benchmarks/swe_mini/task_013.py,,1,1.3709566550544279e-06,"The method 'run' is a simple function that calculates the sum of numbers from 0 to n-1 and checks if it matches the expected sum using the formula n*(n-1)//2. This is a basic implementation of a mathematical property and serves as a simple test or demonstration of the formula. The function is self-contained, does not depend on external inputs, and correctly implements the logic it is supposed to demonstrate. Therefore, there is no reason to delete it unless it is deemed unnecessary in the context it is used. However, as a standalone piece of code, it is correct and functional."
survived,"def run() -> None:
    n = 25
    total = sum(range(n))
    expected = n*(n-1)//2
    assert total == expected",benchmarks/swe_mini/task_025.py,,1,1.444980317078884e-07,"The method 'run' is a simple function that calculates the sum of numbers from 0 to n-1 and checks if it matches the expected sum using the formula n*(n-1)//2. This is a basic implementation of a mathematical property and serves as a simple test or demonstration of the formula. The function is straightforward, correct, and does not have any apparent issues or redundancies that would warrant its deletion. It could be useful for educational purposes or as a utility function in a larger codebase."
survived,"def test_improve_repo_invalid_patch(tmp_path: Path) -> None:
    repo_dir = tmp_path / ""repo""
    repo_dir.mkdir()
    _init_repo(repo_dir)

    patch_file = tmp_path / ""patch.diff""
    patch_file.write_text("""")
    log_file = tmp_path / ""log.json""

    with pytest.raises(ValueError):
        self_improver.improve_repo(
            str(repo_dir), str(patch_file), ""metric.txt"", str(log_file)
        )
",tests/test_self_improver.py,,1,4.363462233903899e-09,"The method 'test_improve_repo_invalid_patch' is a unit test designed to verify that the 'improve_repo' function raises a ValueError when provided with an invalid patch file. Unit tests are crucial for ensuring code reliability and correctness, especially when handling exceptions. This test is likely to be retained as it serves an important role in validating the behavior of the 'improve_repo' function under specific conditions. Therefore, the method will survive."
survived,"def test_improve_repo_requires_git(monkeypatch, tmp_path: Path) -> None:
    repo_dir = tmp_path / ""repo""
    repo_dir.mkdir()
    patch_file = tmp_path / ""p.diff""
    patch_file.write_text(""dummy"")
    log_file = tmp_path / ""log.json""

    monkeypatch.setattr(self_improver, ""git"", None)
    with pytest.raises(RuntimeError):
        self_improver.improve_repo(
            str(repo_dir), str(patch_file), ""metric.txt"", str(log_file)
        )",tests/test_self_improver.py,,1,3.850741907939403e-09,"The method 'test_improve_repo_requires_git' is a unit test designed to verify that the 'improve_repo' function raises a RuntimeError when the 'git' attribute of 'self_improver' is set to None. This is a valid and necessary test to ensure that the function behaves correctly under certain conditions. Unit tests are crucial for maintaining code quality and ensuring that changes do not introduce regressions. Therefore, this method is likely to be retained as part of the test suite."
survived,"def test_cached_header_and_timeout(monkeypatch: pytest.MonkeyPatch) -> None:
    _clear_env_cache()
    monkeypatch.delenv(""LANGCHAIN_API_KEY"", raising=False)
    with patch.dict(""os.environ"", {}, clear=True):
        client = Client(
            api_url=""http://localhost:1984"",
            api_key=""123"",
            timeout_ms=(2000, 4000),
            auto_batch_tracing=False,
        )
        assert client._timeout == (2.0, 4.0)
        assert client._headers[""x-api-key""] == ""123""
        # Changing API key should update headers
        client.api_key = ""abc""
        assert client._headers[""x-api-key""] == ""abc""

        mock_response = MagicMock()
        client.session.request.return_value = mock_response
        with patch(""langsmith.client.ls_utils.raise_for_status_with_text""):
            client.request_with_retries(""GET"", ""/test"")
        args, kwargs = client.session.request.call_args
        assert kwargs[""timeout""] == client._timeout
        assert kwargs[""headers""][""x-api-key""] == ""abc""
",python/tests/unit_tests/test_client.py,,1,1.3440409770490404e-08,"The method 'test_cached_header_and_timeout' is a unit test function that verifies the behavior of a client object, specifically checking the handling of API keys and timeout settings. Unit tests are crucial for ensuring code reliability and are typically maintained as long as the functionality they test is relevant. Since this test checks fundamental aspects of client configuration, it is likely to be retained to ensure that any changes to the client do not break expected behavior."
survived,"def test_add():
    assert calc.add(1, 1) == 2",tests/fixtures/self_heal_repo/test_calc.py,,1,7.194132978569833e-09,"The method `test_add` is a unit test function that checks if the `add` method of the `calc` object correctly adds two numbers. Unit tests are crucial for ensuring code reliability and correctness, especially in larger projects. They help in identifying bugs early in the development process and ensure that changes do not break existing functionality. Therefore, this method is likely to be retained as part of a test suite to maintain code quality."
survived,"        def _get(self: struct_pb2.Struct, key: str, default=None):
            try:
                return self[key]
            except Exception:
                return default
",tests/test_safety_block.py,,1,1.725782769012759e-08,"The method is a utility function that attempts to retrieve a value from a dictionary-like object using a key. If the key does not exist, it returns a default value. This is a common pattern in Python for safely accessing dictionary elements without raising a KeyError. The method is simple, useful, and follows a standard practice, which suggests it is likely to be retained in the codebase."
survived,"    async def run() -> None:
        async with bus, ledger:
            await chaos.run_cycle()
            await asyncio.sleep(0)
",tests/test_safety_block.py,,1,1.3440409770490404e-08,"The method 'run' is an asynchronous function that uses 'async with' to manage asynchronous context managers 'bus' and 'ledger'. It then calls 'chaos.run_cycle()' and awaits 'asyncio.sleep(0)'. This pattern is typical in asynchronous programming to ensure that the event loop can switch tasks efficiently. The method appears to be well-structured for its purpose, and there is no indication of it being redundant or obsolete. Therefore, it is likely to be retained in the codebase."
survived,"    def schedule(self, jobs: List[List[Dict[str, Any]]], horizon: int) -> Dict[str, Any]:
        """"""Synchronous wrapper around :meth:`_build_async` returning a dict.""""""
        req = {""jobs"": jobs, ""horizon"": horizon}
        loop = asyncio.get_event_loop()
        res = loop.run_until_complete(self._build_async(req))
        try:
            return json.loads(res)[""payload""]
        except Exception:  # noqa: BLE001
            return json.loads(res)
",alpha_factory_v1/backend/agents/manufacturing_agent.py,ManufacturingAgent,1,2.3355930333443423e-09,"The method 'schedule' is likely to survive because it provides a synchronous interface to an asynchronous method, which is a common pattern in Python to handle asynchronous operations in a synchronous context. This is useful for users who need the result immediately and cannot work with asynchronous code. Additionally, the method includes error handling to ensure robustness, which is a good practice in software development."
survived,"def ema(prices: Sequence[float], span: int = 20) -> float:
    """"""Return the exponential moving average over ``span`` periods.""""""

    if span <= 0:
        raise ValueError(""span must be positive"")
    if not prices:
        return 0.0

    alpha = 2 / (span + 1)
    ema_val = float(prices[0])
    for p in prices[1:]:
        ema_val = (float(p) - ema_val) * alpha + ema_val
    return ema_val
",alpha_factory_v1/backend/alpha_model.py,,1,2.1724399346070676e-10,"The method is a well-implemented function for calculating the exponential moving average (EMA), a common financial analysis tool. It includes error handling for invalid input (non-positive span) and returns a sensible default (0.0) when the prices list is empty. The logic for calculating EMA is correctly implemented using the smoothing factor (alpha). Given its utility and correctness, there is no reason to delete this method."
survived,"    def test_stochastic_zero_noise(self):
        genes = {""temperature"": 0.7, ""top_p"": 0.9, ""max_tokens"": 128}
        self.assertAlmostEqual(
            gt.stochastic_fitness(genes, noise=0.0), gt.toy_fitness(genes), places=6
        )
",alpha_factory_v1/tests/test_genetic_tests.py,GeneticTestsTest,1,6.348800075736417e-09,"The method `test_stochastic_zero_noise` is a unit test that checks the functionality of a stochastic fitness function with zero noise. It compares the output of `stochastic_fitness` with `toy_fitness` to ensure they are almost equal when noise is zero. This is a valid and useful test case to ensure the correctness of the stochastic fitness function under specific conditions. Therefore, it is likely to be retained in the codebase."
survived,"    def test_geneconfig_roundtrip(self):
        cfg = gt.GeneConfig(0.8, 0.95, 256)
        d = cfg.as_dict()
        self.assertEqual(d[""temperature""], 0.8)
        self.assertEqual(d[""top_p""], 0.95)
        self.assertEqual(d[""max_tokens""], 256)
",alpha_factory_v1/tests/test_genetic_tests.py,GeneticTestsTest,1,6.348800075736417e-09,"The method 'test_geneconfig_roundtrip' is a unit test that verifies the functionality of the 'GeneConfig' class, specifically its ability to convert its attributes to a dictionary and ensure the values are correctly set. Unit tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, this method is likely to be retained as it serves an important role in the testing suite."
survived,"    def step(self, action: str) -> Tuple[float, float, bool]:
        """"""Execute ``action`` and return (price, reward, done).""""""
        self.price = self.sample_next_price(self.price)
        reward = 0.0
        done = False
        return self.price, reward, done
",alpha_factory_v1/backend/environments/market_sim.py,MarketEnv,1,5.60279640614594e-09,"The method 'step' is a fundamental part of many simulation or reinforcement learning environments, where it is used to progress the state of the environment based on an action and return the new state, reward, and whether the episode is done. The method is well-defined and follows a common pattern in such applications. It is unlikely to be deleted unless the entire approach or framework is being refactored or replaced."
survived,"    def book(self) -> Dict[str, float]:
        """"""Return a copy of the current position book.""""""
        return dict(self._positions)
",alpha_factory_v1/backend/portfolio.py,Portfolio,1,1.1032560311263802e-09,"The method 'book' is a simple accessor method that returns a copy of the current position book, which is likely a core part of the functionality of the class it belongs to. Accessor methods are generally essential for encapsulation and data retrieval, making them unlikely candidates for deletion unless the entire class is being refactored or removed. Therefore, it is more likely to survive."
survived,"def main() -> None:
    ap = argparse.ArgumentParser(description=""Run Meta-Agentic Î±-AGI demo"")
    ap.add_argument(""--gens"", type=int, default=6, help=""number of generations"")
    ap.add_argument(
        ""--provider"",
        default=os.getenv(""LLM_PROVIDER"", ""mistral:7b-instruct.gguf""),
        help=""openai:gpt-4o | anthropic:claude-3-sonnet | mistral:7b-instruct.gguf"",
    )
    ap.add_argument(
        ""--ui"",
        action=""store_true"",
        help=""launch Streamlit lineage UI after the search loop"",
    )
    ap.add_argument(
        ""--db"",
        type=Path,
        default=DB,
        help=""path to lineage SQLite DB"",
    )
    args = ap.parse_args()

    os.environ[""METAAGI_DB""] = str(args.db)

    try:
        asyncio.run(meta_loop(args.gens, args.provider))
    except KeyboardInterrupt:
        return

    if args.ui:
        ui_path = Path(__file__).parent / ""ui"" / ""lineage_app.py""
        print(f""\nStarting Streamlit UI â†’ {ui_path}\n"")
        subprocess.call([""streamlit"", ""run"", str(ui_path)])
",alpha_factory_v1/demos/meta_agentic_agi/app.py,,1,2.2159489282323004e-08,"The method 'main' is a typical entry point for a Python script, handling command-line arguments and orchestrating the execution of the program. It uses standard libraries like argparse for argument parsing and asyncio for asynchronous operations, which are common practices in Python programming. The method is well-structured, with clear argument definitions and a try-except block to handle interruptions gracefully. Additionally, it includes functionality to launch a UI with Streamlit, which adds value to the script by providing a user interface. These factors suggest that the method is functional, useful, and adheres to good coding practices, making it unlikely to be deleted."
survived,"    def step(self, act:int):
        dx,dy = [(0,1),(1,0),(0,-1),(-1,0)][act%4]
        nx,ny = self._clip(self.agent[0]+dx), self._clip(self.agent[1]+dy)
        if (nx,ny) in self.obstacles: nx,ny = self.agent
        self.agent=(nx,ny)
        done = self.agent==self.goal
        reward = 1.0 if done else -0.01
        return self._obs(), reward, done, {}
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,MiniWorld,1,6.69158608681505e-10,"The method 'step' is a crucial part of a reinforcement learning environment, where it defines the agent's movement, checks for obstacles, and calculates rewards. It is well-structured and performs necessary tasks for the environment's functionality. Such methods are typically retained as they are essential for the operation of the environment."
survived,"            def handle(self,msg):
                if ""ask_plan"" in msg:
                    try:
                        plan=self._safe_call(msg[""ask_plan""])
                        self.emit(""planning_agent"",{""llm_plan"":plan})
                    except Exception as e:
                        LOG.warning(""LLMPlanner error: %s"",e)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,LLMPlanner,1,5.211412485172657e-10,"The method 'handle' is likely to survive because it contains essential functionality for processing messages related to 'ask_plan'. It includes error handling with a try-except block, which is a good practice for robust code. Additionally, it uses logging to capture exceptions, which is useful for debugging and maintaining the code. These factors suggest that the method is well-structured and serves a clear purpose, making it unlikely to be deleted."
survived,"            def __init__(self): super().__init__(""llm_planner"")
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,LLMPlanner,1,3.2241866333029355e-08,"The method is a constructor for a class, indicated by the name `__init__`. Constructors are essential for initializing new objects in object-oriented programming. The use of `super().__init__()` suggests that this class is inheriting from a parent class and is correctly calling the parent class's constructor. This is a common and necessary practice in object-oriented design to ensure proper initialization of the class hierarchy. Therefore, this method is unlikely to be deleted as it serves a fundamental role in the class's functionality."
survived,"    def __init__(self):
        self.gen=POETGenerator()
        self.envs=[self.gen.propose() for _ in range(CFG.env_batch)]
        self.learners=[Learner(e) for e in self.envs]
        self.stop=False
        A2ABus.subscribe(""orch"",self._on_cmd)
        LOG.info(""Orchestrator online with %d envs"", CFG.env_batch)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,Orchestrator,1,8.31527990378713e-07,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class. It sets up important attributes like 'gen', 'envs', 'learners', and 'stop', and subscribes to a message bus, which suggests it's part of a larger system. Such methods are typically not deleted unless the entire class is being refactored or removed, which is not indicated here."
survived,"    async def get_cash(self) -> float:
        return self.cash
",alpha_factory_v1/backend/broker/broker_sim.py,SimulatedBroker,1,4.363462233903899e-09,"The method 'get_cash' is a simple asynchronous getter method that returns the value of 'self.cash'. Such methods are typically retained because they provide a clear and direct way to access private or protected attributes of a class. This is especially useful in maintaining encapsulation in object-oriented programming. Additionally, the use of 'async' suggests that this method might be part of a larger asynchronous system, which is common in modern programming practices. Therefore, it is likely to be retained."
survived,"def delete(
    url: str,
    *,
    params: dict | None = None,
    headers: dict | None = None,
    timeout: float | None = None,
) -> Response:
    """"""HTTP DELETE request.""""""
    return _call(""DELETE"", url, params=params, headers=headers, timeout=timeout)
",alpha_factory_v1/requests.py,,1,3.850741907939403e-09,"The method is a standard implementation of an HTTP DELETE request, which is a common and necessary operation in web development for removing resources. It is well-defined, uses type hints, and provides flexibility with optional parameters for headers, params, and timeout. Such utility functions are essential in applications that interact with web services, making it unlikely to be deleted unless the entire application architecture changes or a more comprehensive library is adopted."
survived,"    def text(self) -> str:
        try:
            return self.content.decode()
        except UnicodeDecodeError:
            return self.content.decode(""latin1"", errors=""replace"")
",alpha_factory_v1/requests.py,Response,1,1.522997951276035e-08,"The method 'text' is a utility function that attempts to decode a byte string into a regular string. It first tries to decode using the default encoding, and if that fails due to a UnicodeDecodeError, it falls back to using 'latin1' encoding with error replacement. This is a common pattern for handling text data that may not be in a consistent encoding format. The method is useful for ensuring that text data can be processed without crashing the program due to encoding issues. Therefore, it is likely to be retained as it provides a robust way to handle text decoding."
survived,"    def ok(self) -> bool:
        return self.status_code < 400
",alpha_factory_v1/requests.py,Response,1,4.944450477491054e-09,"The method 'ok' is a simple utility function that checks if the HTTP status code is less than 400, which is a common way to determine if a request was successful. This is a useful and straightforward method that aligns with common practices in handling HTTP responses. It is likely to be retained as it provides a clear and concise way to check for successful status codes."
survived,"def _print_console(logs: list[str]) -> None:
    if logs:
        print(""--- Browser console logs ---"", file=sys.stderr)
        for line in logs:
            print(line, file=sys.stderr)
",scripts/verify_insight_offline.py,,1,5.905303995456778e-10,"The method _print_console is a utility function that prints a list of log messages to the standard error stream. This is a common practice for logging purposes, especially when debugging or monitoring applications. The method is simple, effective, and serves a clear purpose. It is unlikely to be deleted unless there is a significant change in the logging strategy or a shift to a more sophisticated logging framework. Therefore, it is predicted to survive."
survived,"    def _folder_name_to_id(name: str, cache: dict[str, str]) -> str | None:
        return cache.get(name)
",app/services/media/jellyfin.py,JellyfinClient,1,1.6052280526088547e-09,"The method is a simple utility function that converts a folder name to an ID using a cache dictionary. It is efficient and useful for retrieving IDs without recalculating or querying a database repeatedly. Such utility functions are common in codebases to improve performance and maintainability. Therefore, it is likely to be retained."
survived,"    def _password_for_db(self, password: str) -> str:
        """"""Return placeholder password for local DB.""""""
        return ""emby-user""",app/services/media/emby.py,EmbyClient,1,1.725782769012759e-08,"The method '_password_for_db' is a private method (indicated by the underscore prefix) that returns a hardcoded placeholder password for a local database. This method is likely used internally within a class or module to provide a consistent placeholder password for testing or development purposes. Since it serves a specific utility and does not expose sensitive information (as it returns a non-sensitive placeholder), it is likely to be retained for its intended use. Therefore, the method will likely survive."
survived,"    def join(
        self, username: str, password: str, confirm: str, email: str, code: str
    ) -> tuple[bool, str]:
        if not EMAIL_RE.fullmatch(email):
            return False, ""Invalid e-mail address.""
        if not 8 <= len(password) <= 20:
            return False, ""Password must be 8â€“20 characters.""
        if password != confirm:
            return False, ""Passwords do not match.""

        ok, msg = is_invite_valid(code)
        if not ok:
            return False, msg

        existing = User.query.filter(
            or_(User.username == username, User.email == email)
        ).first()
        if existing:
            return False, ""User or e-mail already exists.""

        try:
            user_id = self.create_user(username, password)

            inv = Invitation.query.filter_by(code=code).first()

            if inv.libraries:
                sections = [lib.external_id for lib in inv.libraries]
            else:
                sections = [
                    lib.external_id
                    for lib in Library.query.filter_by(enabled=True).all()
                ]

            self._set_specific_folders(user_id, sections)

            expires = None
            if inv.duration:
                days = int(inv.duration)
                expires = datetime.datetime.utcnow() + datetime.timedelta(days=days)

            new_user = User(
                username=username,
                email=email,
                password=self._password_for_db(password),
                token=user_id,
                code=code,
                expires=expires,
            )
            db.session.add(new_user)
            db.session.commit()

            self._mark_invite_used(inv, new_user)
            notify(
                ""New User"",
                f""User {username} has joined your server! ðŸŽ‰"",
                tags=""tada"",
            )

            return True, """"

        except Exception:  # noqa: BLE001
            logging.error(""Jellyfin join error"", exc_info=True)
            db.session.rollback()
            return False, ""An unexpected error occurred.""
",app/services/media/jellyfin.py,JellyfinClient,1,2.8453347280241004e-08,"The method 'join' is a crucial part of a user registration process, handling multiple important tasks such as validation, user creation, and database operations. It includes error handling and logging, which are essential for maintaining robustness and traceability. These features make it unlikely to be deleted, as they are fundamental to the functionality of user registration in an application."
survived,"    def test_summary_rate_limit_error(self) -> None:
        import openai

        with patch.dict(os.environ, {""OPENAI_API_KEY"": ""sk-test""}):
            with patch(""openai.OpenAI"") as mock_client:
                mock_client.return_value.chat.completions.create.side_effect = openai.RateLimitError(""limit"")
                text = summarise_with_agent(
                    0.5,
                    agents=2,
                    rounds=10,
                    delta=0.9,
                    stake=1.0,
                )
        self.assertIn(""offline summary"", text)
        self.assertIn(""rate limit"", text)
",tests/test_governance_sim.py,TestGovernanceSim,1,1.725782769012759e-08,"The method `test_summary_rate_limit_error` is a unit test designed to verify the behavior of a function when a rate limit error occurs. Unit tests are crucial for ensuring code reliability and are typically not deleted unless they are redundant or replaced by more comprehensive tests. This test specifically checks for the handling of a `RateLimitError` from the OpenAI API, which is an important aspect of error handling in applications that rely on external APIs. Therefore, it is likely to be retained to ensure that the application can gracefully handle such errors."
survived,"def test_forward_to_real_requests() -> None:
    """"""When ``requests`` is installed, ``af_requests`` should proxy to it.""""""
    spec = importlib.util.find_spec(""requests"")
    if spec is None:
        pytest.skip(""real requests not installed"")

    sys.modules.pop(""af_requests"", None)
    af_requests = importlib.import_module(""af_requests"")
    import requests  # type: ignore

    assert af_requests.get is requests.get
    assert af_requests.post is requests.post",tests/test_af_requests.py,,1,3.850741907939403e-09,"The method `test_forward_to_real_requests` is a test function that checks if the `af_requests` module correctly proxies to the `requests` module when it is installed. This is a valid and useful test to ensure that the proxying behavior works as expected. It uses `pytest.skip` to handle the case where `requests` is not installed, which is a good practice in testing. Therefore, there is no reason to delete this method as it serves a clear purpose in the test suite."
survived,"def test_fallback_to_internal_shim() -> None:
    """"""``af_requests`` should expose the internal lightweight implementation when
    the real ``requests`` package is missing.""""""
    sys.modules.pop(""requests"", None)
    sys.modules.pop(""af_requests"", None)

    af_requests = importlib.import_module(""af_requests"")
    from alpha_factory_v1 import af_requests as internal

    assert af_requests.get is internal.get
    assert af_requests.post is internal.post
",tests/test_af_requests.py,,1,8.152020648014727e-09,"The method `test_fallback_to_internal_shim` is a unit test designed to verify that the `af_requests` module correctly falls back to an internal implementation when the `requests` package is not available. This is a useful test to ensure the robustness and reliability of the `af_requests` module, especially in environments where the `requests` package might not be installed. Unit tests are generally considered essential for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, this method is likely to be retained as part of the test suite."
survived,"def test_cors_headers() -> None:
    async def run() -> None:
        client, _ = await make_client()
        async with client:
            headers = {
                ""Authorization"": ""Bearer test-token"",
                ""Origin"": ""http://example.com"",
            }
            r = await client.get(""/runs"", headers=headers)
            assert r.status_code == 200
            assert r.headers.get(""access-control-allow-origin"") == ""http://example.com""

    asyncio.run(run())",tests/test_api_server_cors.py,,1,7.194132978569833e-09,"The method 'test_cors_headers' is a test function that checks if the CORS headers are correctly set in the response from a server. This is a common requirement in web applications to ensure that resources are accessible from different origins. The function uses an asynchronous client to make a request and asserts the presence and correctness of the CORS headers. Such tests are crucial for maintaining the security and functionality of web applications, especially those that interact with APIs across different domains. Therefore, this method is likely to be retained as it serves an important purpose in testing the application's compliance with CORS policies."
survived,"def UseGuards(*guards):
    """"""Decorator to attach guards to a controller or route.""""""

    def decorator(obj):
        existing = list(getattr(obj, ""__guards__"", []))
        existing.extend(guards)
        setattr(obj, ""__guards__"", existing)
        return obj

    return decorator",nest/core/guards.py,,1,5.60279640614594e-09,"The method 'UseGuards' is a decorator function that is used to attach guards to a controller or route. This is a common pattern in web frameworks to handle authorization or other pre-processing tasks before a request is handled. The method is well-defined, serves a clear purpose, and is likely to be useful in many web applications. Therefore, it is likely to be retained in the codebase."
survived,"def optimize_autovacuum(
    ctx: Context,
    dry_run: bool = typer.Option(False, help=""Print SQL commands only.""),
    rollback: bool = typer.Option(False, help=""Reset to defaults instead.""),
) -> None:
    qbe = qb.QueryBuilderEnvironment()
    if rollback:
        query = qbe.build_optimize_autovacuum_rollback_query()
    else:
        query = qbe.build_optimize_autovacuum_query()

    print(query)

    async def run() -> None:
        async with yield_queries(ctx, qb.DBSettings()) as q:
            await q.optimize_autovacuum(rollback=rollback)

    if not dry_run:
        asyncio_run(run())
",pgqueuer/cli.py,,1,1.9171715133907573e-10,"The method `optimize_autovacuum` is likely to survive because it provides a useful functionality for optimizing or rolling back autovacuum settings in a database environment. It includes options for a dry run and rollback, making it flexible for different use cases. Additionally, it uses asynchronous operations, which are beneficial for performance in I/O-bound tasks like database operations. The method is well-structured and uses a context manager for resource management, indicating good design practices."
survived,"    def __call__(self, module: M_contra, carry: CarryT) -> tuple[CarryT, OutputT_co]:
        ...
",src/haliax/nn/scan.py,ScanFunction,1,9.736200303530205e-10,"The method is a special method in Python, known as a ""dunder"" method, which allows an instance of a class to be called as a function. This is a common and useful feature in Python, especially for classes that are designed to represent callable objects or to implement function-like behavior. The presence of this method suggests that the class is intended to be used in a specific way that involves calling instances directly, which is a pattern that is often used and unlikely to be removed unless the class itself is deprecated or significantly refactored. Therefore, the method is likely to survive."
survived,"def test_governance_bridge_offline(monkeypatch):
    orig_import = builtins.__import__

    def fake_import(name, globals=None, locals=None, fromlist=(), level=0):
        if name == ""openai_agents"":
            raise ModuleNotFoundError(name)
        return orig_import(name, globals, locals, fromlist, level)

    monkeypatch.setattr(builtins, ""__import__"", fake_import)

    with pytest.raises(SystemExit):
        importlib.reload(
            importlib.import_module(
                ""alpha_factory_v1.demos.solving_agi_governance.openai_agents_bridge""
            )
        )",tests/test_governance_bridge_offline.py,,1,6.825604231969389e-08,"The method 'test_governance_bridge_offline' is a unit test designed to verify the behavior of a module when a specific dependency ('openai_agents') is not available. This is a common practice in testing to ensure that the system can handle missing dependencies gracefully. The use of 'monkeypatch' to simulate the absence of the module and the expectation of a 'SystemExit' exception indicates that this test is checking for a specific failure mode. Such tests are crucial for robust software development, especially in environments where dependencies might not always be available. Therefore, this method is likely to be retained as it serves an important purpose in the testing suite."
survived,"        def __init__(self, *args, **kwargs):
            pass
",stubs/google_adk/__init__.py,Agent,0,0.9999999778405106,"The method is an empty constructor that does not perform any initialization or operations. In most cases, such a method is unnecessary and can be removed without affecting the functionality of the class. Therefore, it is likely to be deleted to clean up the code."
survived,"def twoSum(nums, target):
    n = len(nums)
    for i in range(0, n):
        for j in range((i + 1), n):
            if ((nums[i] + nums[j]) == target):
                return [i, j]
    return [-1, -1]
",tests/transpiler/x/py/two-sum.py,,1,8.76424914819242e-08,"The method 'twoSum' is a straightforward implementation of a common algorithmic problem, which is to find two numbers in a list that add up to a specific target. This problem is frequently encountered in coding interviews and competitive programming. The method uses a simple nested loop approach to check each pair of numbers, which is a valid solution, albeit not the most efficient one. However, it is correct and functional for small input sizes. Given its correctness and relevance, the method is likely to survive, although it could be optimized for better performance."
survived,"def local_search(query: str):
    results = []
    for root, _, files in os.walk('.'):
        for f in files:
            if query in f:
                path = os.path.join(root, f)
                try:
                    content = open(path).read()
                except Exception:
                    content = """"
                results.append({
                    ""title"": f,
                    ""description"": path,
                    ""url"": path,
                    ""content"": content,
                })
    results.sort(key=lambda r: r['title'], reverse=True)
    return results
",examples/python/local_search.py,,0,0.999999997664407,"The method 'local_search' is likely to be deleted (0) because it has several issues that make it inefficient and potentially problematic. Firstly, it reads the entire content of each file into memory, which can be inefficient and risky for large files. Secondly, it does not handle exceptions in a detailed manner, which could lead to silent failures or incomplete results. Additionally, the method lacks any form of optimization or indexing, making it slow for large directories. These issues suggest that the method is not robust or efficient enough for practical use, leading to its potential deletion."
survived,"        async def post(self, url: str, **kwargs):
            return requests.post(url, **kwargs)
",alpha_factory_v1/demos/alpha_agi_business_v1/openai_agents_bridge.py,AsyncClient,0,0.9999930377415741,"The method is likely to be deleted because it is defined as an asynchronous function using 'async def', but it does not contain any 'await' expressions or asynchronous operations. Instead, it directly calls 'requests.post', which is a synchronous function. This inconsistency suggests that the method is not utilizing the benefits of asynchronous programming, and it might be better implemented as a regular synchronous method or refactored to use an asynchronous HTTP library like 'aiohttp'."
survived,"        def __init__(self, app: FastAPI, limit: int = 60, window: int = 60) -> None:
            super().__init__(app)
            self.limit = int(os.getenv(""API_RATE_LIMIT"", str(limit)))
            self.window = window
            # Use TTLCache so inactive IP entries expire automatically.
            self.counters: TTLCache[str, deque[float]] = TTLCache(maxsize=1024, ttl=window)
            self.lock = asyncio.Lock()
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/api_server.py,SimpleRateLimiter,1,1.4166087846364157e-09,"The method is a constructor for a class that initializes important attributes for rate limiting in a FastAPI application. It uses environment variables for configuration, which is a common practice for flexibility. The use of TTLCache and asyncio.Lock suggests it is designed for efficient and safe concurrent access, which are good practices in web applications. These factors indicate that the method is well-structured and serves a clear purpose, making it likely to survive."
survived,"def main(argv: list[str] | None = None) -> None:
    """"""Launch the Î±â€‘AGI Insight API server.""""""

    if FastAPI is None or uvicorn is None:
        raise SystemExit(""FastAPI is required to run the Î±â€‘AGI Insight API."")

    parser = argparse.ArgumentParser(description=""Run the Î±â€‘AGI Insight API"")
    parser.add_argument(""--host"", default=""0.0.0.0"", help=""Bind host"")
    parser.add_argument(""--port"", type=int, default=8000, help=""Bind port"")
    args = parser.parse_args(argv)

    uvicorn.run(app, host=args.host, port=args.port)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/api_server.py,,1,3.850741907939403e-09,"The method is a main entry point for launching an API server using FastAPI and uvicorn, which are popular frameworks for building and running web applications in Python. The method includes argument parsing for host and port configuration, which is a common requirement for server applications. There is no indication of deprecated practices or lack of functionality that would necessitate its removal. Therefore, it is likely to be retained as it serves a clear and useful purpose."
survived,"    def verify(self, content: str, signature: str) -> bool:
        """"""Verify ``content`` against ``signature``.""""""
        expected = hmac.new(
            self.secret, content.encode(""utf-8""), hashlib.sha256
        ).hexdigest()
        valid = hmac.compare_digest(expected, signature)
        if valid:
            checksum = hashlib.sha256(content.encode(""utf-8"")).hexdigest()
            if checksum not in self.cache:
                self.cache[checksum] = signature
                self._save_cache()
        return valid
",src/meta_agent/template_governance.py,TemplateGovernance,1,2.3355930333443423e-09,"The method 'verify' is a crucial part of a security mechanism, as it verifies the integrity and authenticity of content using HMAC and SHA-256 hashing. It also includes a caching mechanism to store verified signatures, which can improve performance by avoiding repeated calculations for the same content. Such methods are typically essential in applications that require secure data handling, making it unlikely to be deleted unless there is a significant change in the security approach or architecture."
survived,"def test_load_golden_specs() -> None:
    specs = load_golden_spec_fuzz_set()
    assert len(specs) >= 20
    assert all(isinstance(s, str) and s for s in specs)",tests/test_golden_spec_fuzz_set.py,,1,1.522997951276035e-08,"The method `test_load_golden_specs` is a test function that verifies the behavior of `load_golden_spec_fuzz_set`. It checks that the returned list `specs` has at least 20 elements and that all elements are non-empty strings. This is a typical unit test to ensure the function under test behaves as expected. Test functions are generally not deleted unless they are redundant or the functionality they test is removed. Since this test seems to be a straightforward and useful validation of `load_golden_spec_fuzz_set`, it is likely to be retained."
survived,"def parse_and_validate_diff(
    diff_text: str,
    repo_dir: str,
    allowed_paths: list[str] | None = None,
) -> str | None:
    """"""Verify the LLM's output is a valid unified diff and meets safety criteria.

    Diffs that exceed ``MAX_DIFF_LINES`` or ``MAX_DIFF_BYTES`` are rejected to
    avoid accidentally applying huge patches.
    """"""
    if not diff_text:
        return None

    lines = diff_text.splitlines()
    if len(lines) > MAX_DIFF_LINES or len(diff_text.encode(""utf-8"")) > MAX_DIFF_BYTES:
        logger.warning(
            ""Diff too large: %s lines, %s bytes"",
            len(lines),
            len(diff_text.encode(""utf-8"")),
        )
        return None

    # Basic unified diff check: should contain lines starting with '+++ ' and '--- '
    if ""+++"" not in diff_text or ""---"" not in diff_text:
        return None  # Not a diff format
    repo_root = Path(repo_dir).resolve()
    allowed = allowed_paths if allowed_paths is not None else ALLOWED_PATHS
    allowed_dirs = (
        [repo_root.joinpath(p).resolve() for p in allowed]
        if allowed
        else [repo_root]
    )

    for line in diff_text.splitlines():
        if line.startswith(""+++ "") or line.startswith(""--- ""):
            m = re.match(r""^[+-]{3} [ab]/(.+)$"", line)
            if m:
                file_path = m.group(1)
                target = (repo_root / file_path).resolve()
                if not target.is_relative_to(repo_root):
                    logger.warning(""Diff outside repository: %s"", file_path)
                    return None
                if not any(target.is_relative_to(d) for d in allowed_dirs):
                    logger.warning(""Diff touches disallowed path: %s"", file_path)
                    return None
    # (Additional checks: e.g., diff length, certain forbidden content can be added here.)
    return diff_text
",alpha_factory_v1/demos/self_healing_repo/agent_core/diff_utils.py,,1,1.0467401685178159e-08,"The method 'parse_and_validate_diff' is a utility function that performs essential validation on diff files, ensuring they meet certain criteria before being processed further. It checks for size limits, format validity, and path restrictions, which are crucial for maintaining security and integrity in a codebase. Such validation functions are typically retained as they play a critical role in preventing errors and potential security vulnerabilities."
survived,"def test_moe_linear_matches_ragged_dot_general():
    B, In, Out, E = hax.make_axes(B=3, In=4, Out=5, E=2)
    key = jrandom.PRNGKey(0)
    moe = MoELinear.init(E, In, Out, key=key)

    x = hax.random.normal(jrandom.PRNGKey(1), (B, In))
    group_sizes = hax.named(jnp.array([2, 1], dtype=jnp.int32), (E,))

    actual = moe(x, group_sizes)
    expected = _expected_moe_linear_output(moe, x, group_sizes)

    assert actual.axes == expected.axes
    assert jnp.allclose(actual.array, expected.array, rtol=1e-5, atol=1e-5)
",tests/test_moe_linear.py,,1,2.2159489282323004e-08,"The method `test_moe_linear_matches_ragged_dot_general` is a unit test function, which is crucial for ensuring the correctness of the `MoELinear` class's functionality. Unit tests are generally retained in codebases to maintain software reliability and to catch regressions when changes are made. The presence of assertions to compare actual and expected outputs indicates its role in verifying the behavior of the `MoELinear` class. Therefore, it is unlikely to be deleted unless the functionality it tests is removed or significantly altered."
survived,"        def close(self):
            pass
",alpha_factory_v1/demos/muzero_planning/minimuzero.py,_StubEnv,0,0.9999938558278723,"The method 'close' is defined but not implemented, as it only contains a 'pass' statement. This suggests that it is a placeholder for future functionality or is meant to be overridden in a subclass. If the class is intended to be abstract or if subclasses are expected to provide their own implementation, the method might survive. However, if the method is not used or overridden anywhere, it might be considered redundant and could be deleted. Without additional context, it's more likely to be deleted if it serves no purpose."
survived,"            def sum(self):  # minimal numpy-like API
                from builtins import sum as _sum
                return _sum(self)
",alpha_factory_v1/demos/muzero_planning/minimuzero.py,_P,1,7.194132978569833e-09,"The method provides a minimal numpy-like API for summing elements, which is a common and useful operation. It uses Python's built-in sum function, ensuring efficiency and reliability. The method is simple, clear, and serves a practical purpose, making it likely to be retained."
survived,"    def test_parse_numbers_helper(self) -> None:
        from alpha_factory_v1.demos.meta_agentic_tree_search_v0.mats.meta_rewrite import (
            _parse_numbers,
        )

        text = ""[1, 2, -3]""
        res = _parse_numbers(text, [0, 0, 0])
        self.assertEqual(res, [1, 2, -3])
",tests/test_meta_agentic_tree_search_demo.py,TestMetaAgenticTreeSearchDemo,1,5.211412485172657e-10,"The method `test_parse_numbers_helper` is a unit test for the function `_parse_numbers`. Unit tests are crucial for ensuring that code functions correctly and as expected. They help in identifying bugs early in the development process and are generally maintained as long as the functionality they test is relevant. Since this test is directly verifying the output of a function by comparing it to an expected result, it is likely to be retained to ensure the reliability of the `_parse_numbers` function. Therefore, the method will likely survive."
survived,"def check_node() -> bool:
    if not shutil.which(""node""):
        banner(""node missing"", ""RED"")
        return False
    try:
        out = subprocess.check_output([""node"", ""--version""], text=True).strip()
    except Exception:
        banner(""failed to run node --version"", ""RED"")
        return False
    banner(f""Node {out} detected"", ""GREEN"")
    if not out.lstrip(""v"").startswith(""20""):
        banner(""Node 20 recommended"", ""YELLOW"")
    return True
",scripts/setup_wizard.py,,1,3.3315445420554206e-11,"The method 'check_node' is likely to survive because it performs a useful function by checking if Node.js is installed and verifying its version. This is a common requirement in many development environments where specific versions of Node.js are needed for compatibility reasons. The method also provides user feedback through banners, which is helpful for debugging and user interaction. Additionally, the code is straightforward and does not have any apparent issues that would necessitate its removal."
survived,"def _dump_selected(txn: lmdb.Transaction, keys: Iterable[str]) -> List[dict[str, Any]]:
    """"""Return records for the provided keys.""""""
    result: List[dict[str, Any]] = []
    for key in keys:
        raw = txn.get(key.encode(""utf-8""))
        if raw is not None:
            result.append({""key"": key, ""value"": _decode_value(raw)})
    return result
",scripts/dump_lmdb.py,,1,6.69158608681505e-10,"The method '_dump_selected' is a utility function that retrieves and decodes records from a database transaction for a given set of keys. It is well-defined, performs a specific task, and is likely useful in contexts where selective data retrieval is needed. The method is also straightforward and does not contain any apparent issues or redundancies that would necessitate its removal. Therefore, it is likely to be retained in the codebase."
survived,"def test_run_muzero_demo_port_in_use(tmp_path: Path) -> None:
    repo_root = Path(__file__).resolve().parents[1]
    src = repo_root / ""alpha_factory_v1""
    dst = tmp_path / ""alpha_factory_v1""
    shutil.copytree(src, dst)

    script = dst / ""demos"" / ""muzero_planning"" / ""run_muzero_demo.sh""
    log_file = tmp_path / ""docker.log""
    bin_dir = tmp_path / ""bin""
    bin_dir.mkdir()

    docker_stub = bin_dir / ""docker""
    docker_stub.write_text(f""#!/usr/bin/env bash\necho docker >> '{log_file}'\nexit 0\n"")
    docker_stub.chmod(0o755)

    lsof_stub = bin_dir / ""lsof""
    lsof_stub.write_text(""#!/usr/bin/env bash\nexit 0\n"")
    lsof_stub.chmod(0o755)

    sock = socket.socket()
    sock.bind((""localhost"", 0))
    port = sock.getsockname()[1]

    env = os.environ.copy()
    env.update({""PATH"": f""{bin_dir}:{env.get('PATH', '')}"", ""HOST_PORT"": str(port)})

    result = subprocess.run([""bash"", str(script)], env=env, capture_output=True, text=True)
    sock.close()

    assert result.returncode == 1
    assert ""already in use"" in result.stderr
    assert not log_file.exists() or not log_file.read_text()",tests/test_run_muzero_demo.py,,1,6.348800075736417e-09,"The method is a test function that checks if a specific script handles the scenario where a port is already in use. It sets up a temporary environment, creates stubs for 'docker' and 'lsof', and binds a socket to a random port to simulate the port being in use. The test then runs the script and checks if it exits with the expected error message. This is a valid and useful test case for ensuring robustness in handling port conflicts, which is a common issue in network programming. Therefore, it is likely to be retained."
survived,"def AnthropicParallelModel(typehint: type[Iterable[T]]) -> AnthropicParallelBase:
    the_types = get_types_array(typehint)
    return AnthropicParallelBase(*[model for model in the_types])",instructor/dsl/parallel.py,,0,0.9999999966017321,"The method `AnthropicParallelModel` is likely to be deleted (0) because it lacks sufficient context and implementation details to be useful. The function references `get_types_array` and `AnthropicParallelBase`, which are not defined within the provided code snippet. Without these definitions, the function cannot operate as intended. Additionally, the function's purpose and usage are unclear, making it difficult to justify its retention without further context or documentation."
survived,"async def test_async_parallel_tools_or(aclient):
    client = instructor.from_anthropic(
        aclient, mode=instructor.Mode.ANTHROPIC_PARALLEL_TOOLS
    )
    resp = await client.chat.completions.create(
        model=""claude-3-5-haiku-latest"",
        messages=[
            {""role"": ""system"", ""content"": ""You must always use tools""},
            {
                ""role"": ""user"",
                ""content"": ""What is the weather in toronto and dallas and who won the super bowl?"",
            },
        ],
        response_model=Iterable[Union[Weather, GoogleSearch]],
    )
    assert len(list(resp)) == 3",tests/llm/test_anthropic/test_parallel.py,,1,6.825604231969389e-08,"The method is testing an asynchronous function that uses a client to fetch data in parallel using a specific mode. It is a test function, which is crucial for ensuring the functionality of the code. Test functions are generally not deleted unless they are redundant or replaced by more comprehensive tests. Since this function is testing a specific feature (parallel tool usage) and asserts the expected output, it is likely to be retained to ensure the feature works as intended."
survived,"def test_time_dependent_discontinuity_equilibration(tmp_path):
    """"""Time dependent discontinuities are handled during equilibration.""""""

    from amici.antimony_import import antimony2sbml
    from amici.sbml_import import SbmlImporter
    from amici.jax.petab import DEFAULT_CONTROLLER_SETTINGS

    ant_model = """"""
    model time_disc_eq
        x' = piecewise(1, time - sin(time) - 1 < 0, -x)
        x = 0
    end
    """"""

    sbml = antimony2sbml(ant_model)
    importer = SbmlImporter(sbml, from_file=False)
    importer.sbml2jax(""time_disc_eq"", output_dir=tmp_path)

    module = amici._module_from_path(""time_disc_eq"", tmp_path / ""__init__.py"")
    model = module.Model()

    p = jnp.array([1.0])
    x0_full = model._x0(0.0, p)
    tcl = model._tcl(x0_full, p)
    x0 = model._x_solver(x0_full)

    assert len(model._root_cond_fns(p)) > 0
    assert model._known_discs(p).size == 0

    xs, _ = model._eq(
        p,
        tcl,
        x0,
        diffrax.Tsit5(),
        diffrax.PIDController(**DEFAULT_CONTROLLER_SETTINGS),
        diffrax.steady_state_event(
            rtol=1e-8, atol=1e-8, norm=lambda y: jnp.linalg.norm(y)
        ),
        1000,
    )

    assert_allclose(xs[0], 0.0, atol=1e-2)",python/tests/test_jax.py,,1,5.043472052266442e-07,"The method is a test function that checks the handling of time-dependent discontinuities during equilibration in a model. It uses various components from the AMICI library and JAX to perform its operations. Test functions are generally crucial for ensuring the correctness and reliability of code, especially in scientific computing and modeling. Therefore, it is likely to be retained to ensure the functionality it tests remains intact."
survived,"def test_logistic_curve_midpoint() -> None:
    assert forecast.logistic_curve(0.0) == pytest.approx(0.5)
",tests/test_forecast.py,,1,4.363462233903899e-09,"The method `test_logistic_curve_midpoint` is a unit test for the `logistic_curve` function, checking if the function returns approximately 0.5 when the input is 0.0. This is a standard test to ensure the midpoint of the logistic curve is correctly implemented. Unit tests are crucial for maintaining code quality and ensuring that functions behave as expected. Therefore, this method is likely to be retained as part of the test suite to verify the correctness of the `logistic_curve` function."
survived,"def get_stripped_lines(val: str):
    ## you don't want empty lines to add empty list after splitlines!
    val = val.strip()

    return [val_line.strip() for val_line in val.split(""\n"")]
",scripts/utils/lcb_runner.py,,1,2.646573631904765e-09,"The method 'get_stripped_lines' is a utility function that processes a string by stripping leading and trailing whitespace and then splitting it into lines, further stripping each line of whitespace. This is a common and useful operation in text processing, especially when dealing with multi-line strings where whitespace management is important. The method is simple, efficient, and serves a clear purpose, making it likely to be retained in the codebase."
survived,"    def readline(self, *args):
        return self._stringio.readline(*args)
",scripts/utils/lcb_runner.py,MockStdinWithBuffer,1,7.194132978569833e-09,"The method `readline` is a simple wrapper around the `readline` method of a `_stringio` object. This suggests that the method is likely part of a class that is designed to provide a specific interface or abstraction over the `_stringio` object. Such methods are typically retained to maintain the interface consistency and usability of the class. Unless there is a significant reason to remove it, such as a major refactor or deprecation of the underlying `_stringio` object, it is likely to survive."
survived,"    def __exit__(self, *args):
        self.append(self._stringio.getvalue())
        del self._stringio  # free up some memory
        sys.stdout = self._stdout
",scripts/utils/lcb_runner.py,Capturing,1,5.3157849718487075e-08,"The method is a part of a context manager implementation, specifically the __exit__ method, which is crucial for cleaning up resources when exiting a context. It ensures that the standard output is restored and memory is freed by deleting the _stringio object. This is a standard and necessary practice in context management, making it unlikely to be deleted."
survived,"def truncatefn(s, length=300):
    if isinstance(s, str):
        pass
    else:
        s = str(s)
    if len(s) <= length:
        return s

    return s[: length // 2] + ""...(truncated) ..."" + s[-length // 2 :]
",scripts/utils/lcb_runner.py,,1,1.1032560311263802e-09,"The method 'truncatefn' is a utility function that truncates a string to a specified length, adding an ellipsis in the middle to indicate truncation. This is a common requirement in many applications where displaying a shortened version of a string is necessary, such as in UI elements or logs. The function is well-implemented, handling both string and non-string inputs by converting non-strings to strings. It also checks if truncation is necessary before proceeding, which is efficient. Given its utility and correct implementation, it is likely to be retained in the codebase."
survived,"    def _ensure(self) -> None:
        with sqlite3.connect(self.path) as cx:
            cx.execute(
                ""CREATE TABLE IF NOT EXISTS agents(""
                ""id INTEGER PRIMARY KEY AUTOINCREMENT,""
                ""meta TEXT,""
                ""score REAL""
                "")""
            )
",src/archive.py,Archive,1,3.3982678079468468e-09,"The method `_ensure` is responsible for ensuring that a specific table exists in a SQLite database. It uses a context manager to connect to the database and executes a SQL command to create the table if it does not already exist. This is a common and necessary operation in applications that interact with databases, as it ensures the required schema is in place before any operations are performed on the data. The method is simple, effective, and does not have any apparent issues or redundancies that would warrant its deletion. Therefore, it is likely to be retained in the codebase."
survived,"    async def _spawn_jobs(self) -> None:
        """"""Spawn new worker tasks until quotas or limits are hit.""""""
        if self.time_quota and time.time() - self.start_time >= self.time_quota:
            self.app.session.finish()
            return
        if self.tokens_quota is not None and self.tokens_used >= self.tokens_quota:
            self.app.session.finish()
            return
        while not self.queue.empty() and len(self.running) < self.max_workers:
            job = await self.queue.get()
            task = asyncio.create_task(self._run_job(job))
            self.running.add(task)
            task.add_done_callback(self.running.discard)
",src/scheduler.py,SelfImprovementScheduler,1,5.905303995456778e-10,"The method '_spawn_jobs' is a crucial part of managing asynchronous tasks in a system that has quotas and limits. It ensures that new tasks are spawned only when certain conditions are met, such as time and token quotas, and manages the running tasks efficiently. This functionality is essential for maintaining system performance and resource management, making it unlikely to be deleted unless the entire system architecture changes significantly."
survived,"def _discover_tasks(dataset: str) -> list[tuple[str, str]]:
    """"""Return list of (task_id, module_name).""""""
    tasks = []
    base = ROOT.parent
    for path in (ROOT / dataset).glob(""task_*.py""):
        rel = path.with_suffix("""").relative_to(base)
        module_name = ""."".join(rel.parts)
        task_id = f""{dataset}/{path.stem}""
        tasks.append((task_id, module_name))
    return tasks
",benchmarks/run_benchmarks.py,,1,4.944450477491054e-09,"The method '_discover_tasks' is a utility function that is likely used to gather and return a list of tasks from a specified dataset directory. It constructs task identifiers and module names by iterating over Python files that match a specific pattern. This kind of functionality is often essential in systems that dynamically load or manage tasks or modules, such as plugin systems or task schedulers. Since it provides a clear and useful purpose, it is unlikely to be deleted unless the entire system's architecture changes significantly or the method is replaced by a more efficient or comprehensive solution."
survived,"def main() -> None:
    # Ensure the repository root is on sys.path so benchmark modules import
    sys.path.insert(0, str(ROOT.parent))
    datasets = [""swebench_verified_mini"", ""polyglot_lite""]
    results = []
    for ds in datasets:
        for task_id, module in _discover_tasks(ds):
            results.append(run_task(task_id, module))
    json.dump(results, sys.stdout)
",benchmarks/run_benchmarks.py,,1,1.8189616842444243e-09,"The method 'main' is likely to survive because it contains a clear and structured implementation for running tasks on a set of datasets. It dynamically discovers tasks and executes them, which is a common pattern in data processing or benchmarking scripts. The use of sys.path modification suggests that it is part of a larger project where modules need to be imported dynamically, indicating its utility in the project's workflow. Additionally, the results are outputted in JSON format, which is a standard practice for data interchange, further supporting its relevance and potential continued use."
survived,"    async def accept(self, cand: Candidate) -> None:
        self._items.append(cand)
",src/evolve.py,InMemoryArchive,1,1.522997951276035e-08,"The method 'accept' is a simple and straightforward function that appends a candidate to a list. It is likely part of a larger class that manages a collection of candidates. The method is clear, concise, and performs a necessary operation for managing the collection. There is no indication that this method is redundant or unnecessary, and it is likely to be used in various parts of the application where candidates need to be added to the collection. Therefore, it is likely to survive."
survived,"def get_component(
    dataset: Union[DataFrame, Connector],
    gid: Union[int, str] = None,
    *,
    field_specs: Optional[List[FieldSpec]] = None,
    theme_key: IThemeKey = ""g2"",
    appearance: IAppearance = ""media"",
    spec: str = """",
    spec_io_mode: ISpecIOMode = ""r"",
    kernel_computation: Optional[bool] = None,
    kanaries_api_key: str = """",
    default_tab: Literal[""data"", ""vis""] = ""vis"",
    **kwargs,
) -> rx.Component:
    """"""Get a Reflex component that renders Pygwalker.""""""
    check_expired_params(kwargs)

    walker = PygWalker(
        gid=gid,
        dataset=dataset,
        field_specs=field_specs if field_specs is not None else [],
        spec=spec,
        source_invoke_code="""",
        theme_key=theme_key,
        appearance=appearance,
        show_cloud_tool=False,
        use_preview=False,
        kernel_computation=isinstance(dataset, Connector) or kernel_computation,
        use_save_tool=""w"" in spec_io_mode,
        is_export_dataframe=False,
        kanaries_api_key=kanaries_api_key,
        default_tab=default_tab,
        cloud_computation=False,
        gw_mode=""explore"",
        **kwargs,
    )

    props = walker._get_props(""reflex"")
    props[""communicationUrl""] = BASE_URL_PATH
    comm = ReflexCommunication(str(walker.gid))
    walker._init_callback(comm)

    html = walker._get_render_iframe(props, True)
    return rx.html(html)",pygwalker/api/reflex.py,,1,1.6052280526088547e-09,"The method `get_component` is a utility function that constructs and returns a Reflex component for rendering a Pygwalker visualization. It is a specialized function that integrates with specific libraries and APIs, such as PygWalker and Reflex, to provide a visualization component. The function is well-defined, with clear parameters and a specific purpose, making it unlikely to be removed unless there is a significant change in the underlying libraries or the application's architecture. Additionally, the function includes handling for optional parameters and default values, indicating it is designed for flexibility and robustness. Therefore, it is likely to survive."
survived,"    def _get_model(self, blank: bool = False) -> LogisticRegression:
        global _model
        if _model is not None and not blank:
            return _model
        model_path = os.path.join(self.MODEL_DIR, 'model.pkl')
        if not blank and os.path.exists(model_path):
            with open(model_path, 'rb') as f:
                _model = pickle.load(f)
        else:
            _model = LogisticRegression(max_iter=1000)
        return _model
",label_studio_ml/examples/timeseries_segmenter/model.py,TimeSeriesSegmenter,1,2.1724399346070676e-10,"The method '_get_model' is likely to survive because it provides a crucial functionality for loading or initializing a machine learning model, specifically a Logistic Regression model. This method checks if a pre-trained model exists and loads it, or initializes a new model if necessary. Such functionality is essential in machine learning applications where models need to be reused or retrained, making this method valuable and likely to be retained."
survived,"def setup_windsurf_config(host_system: str, path_to_env: str) -> bool:
    """"""Placeholder setup for Windsurf integration.""""""
    console.print(""[yellow]![/] Windsurf integration setup is not implemented yet"")
    return False",skyvern/cli/commands.py,,0,0.9999999715466527,"The method is a placeholder function that does not perform any actual setup for Windsurf integration. It simply prints a message indicating that the setup is not implemented and returns False. Without any functional implementation, the method does not provide value and is likely to be deleted or replaced with a proper implementation in the future."
survived,"def convert_species_traits(subrace_path, out_path, parent_slug, start_pk):
    subrace = load_json(subrace_path)[0]
    fields = subrace[""fields""]
    traits = []
    pk = start_pk
    asi = fields.get(""asi_desc"")
    if asi:
        traits.append({
            ""model"": ""api_v2.speciestrait"",
            ""pk"": pk,
            ""fields"": {""name"": ""Ability Score Increase"", ""desc"": asi, ""type"": None, ""parent"": parent_slug},
        })
        pk += 1
    text = fields.get(""traits"", """")
    for part in filter(None, [p.strip() for p in text.split(""\n\n"")]):
        m = re.match(r""\*\*[_*]?([^.*]+)[.*_]*\*\*\s*(.*)"", part)
        if m:
            name = m.group(1).strip().rstrip('.')
            desc = m.group(2).strip()
        else:
            name, _, desc = part.partition('.')
            name = name.strip()
            desc = desc.strip()
        traits.append({
            ""model"": ""api_v2.speciestrait"",
            ""pk"": pk,
            ""fields"": {""name"": name, ""desc"": desc, ""type"": None, ""parent"": parent_slug},
        })
        pk += 1
    append_json(traits, out_path)
    return pk
",convert_missing.py,,1,5.60279640614594e-09,"The method 'convert_species_traits' is a utility function that processes JSON data to extract and transform specific information into a new format. It is likely to survive because it performs a specific and useful task: converting species traits from a JSON file into a structured format suitable for further processing or storage. The function is well-defined, with clear input and output, and it handles data transformation in a way that is reusable and adaptable to different datasets. Additionally, it uses regular expressions to parse text, which is a common requirement in data processing tasks. Unless there is a significant change in the data structure or the requirements, this function is likely to remain useful and relevant."
survived,"def parse_feature_sections(text):
    sections = []
    parts = text.split(""##### "")
    for part in parts[1:]:
        if not part.strip():
            continue
        header, *rest = part.split(""\n"", 1)
        body = rest[0] if rest else """"
        sections.append((header.strip(), body.strip()))
    return sections
",convert_missing.py,,1,7.582560422162384e-10,"The method 'parse_feature_sections' is a utility function that processes a text input to extract sections based on a specific delimiter ('##### '). This type of function is generally useful in scenarios where structured text needs to be parsed, such as documentation processing or text analysis. The function is well-defined, performs a clear task, and does not have any apparent issues or redundancies. Therefore, it is likely to be retained in the codebase."
survived,"        def __init__(self, val: str) -> None:
            pass
",tests/test_ledger.py,DummyPk,1,5.42221743297629e-06,"The method is a constructor for a class, but it currently does nothing as it only contains a 'pass' statement. This suggests that it might be a placeholder for future implementation. However, if the class is intended to be used and the constructor is expected to initialize some attributes or perform some setup, it will likely be updated rather than deleted. Therefore, it is more likely to survive as it is a fundamental part of class instantiation, even if it is currently not doing anything."
survived,"    def test_yaml_dict_names(self):
        labelmap = load_labelmap(""tests/annotations/dict_names.yaml"")
        self.assertEqual(labelmap, {0: ""cat"", 1: ""dog"", 2: ""fish""})",tests/util/test_image_utils.py,TestLoadLabelmap,1,4.944450477491054e-09,"The method `test_yaml_dict_names` is a unit test that checks if the `load_labelmap` function correctly loads a YAML file and returns a dictionary with expected key-value pairs. This is a typical test case that ensures the functionality of the `load_labelmap` function, which is crucial for applications that rely on correct label mapping from YAML files. Since testing is an essential part of software development to ensure code reliability and correctness, this method is likely to be retained in the codebase."
survived,"def test_caseinfo_save_and_update(tmp_path, env_setup, monkeypatch):
    from importlib import reload

    import np_ocr.api as api
    reload(api)
    monkeypatch.setattr(api.settings, ""CASE_INFO_FILENAME"", ""case_info.json"", raising=False)

    case_dir = tmp_path / ""case""
    case_dir.mkdir()
    case = api.CaseInfo(
        name=""mycase"",
        status=""processing"",
        number_of_pdfs=1,
        files=[""file.pdf""],
        case_dir=case_dir,
    )
    case.save()
    with open(case_dir / ""case_info.json"") as f:
        data = json.load(f)
    assert data[""status""] == ""processing""

    case.update_status(""done"")
    with open(case_dir / ""case_info.json"") as f:
        data = json.load(f)
    assert data[""status""] == ""done""
",no-ocr-api/tests/test_utils.py,,1,5.3157849718487075e-08,"The method is a test function that verifies the functionality of saving and updating a case information file. It uses temporary paths and monkeypatching to isolate the test environment, ensuring no side effects on the actual file system or settings. This is a common practice in testing to ensure code reliability and correctness. The method is likely to survive because it is a well-structured test that ensures the core functionality of the `CaseInfo` class works as expected, which is crucial for maintaining code quality."
survived,"        def parse(*args, **kwargs):
            class Msg:
                parsed = search.ImageAnswer(answer=""ok"")
            class Choice:
                message = Msg()
            class Completion:
                choices = [Choice()]
            return Completion()
",no-ocr-api/tests/test_utils.py,FakeCompletions,0,0.9999989322969233,"The method 'parse' is a simple function that returns a nested structure of classes. It doesn't perform any significant computation or data manipulation, and its utility is not clear from the code provided. It seems to be a placeholder or a mock implementation, possibly for testing purposes. Without a clear use case or functionality, such methods are often candidates for deletion, especially if they are not used elsewhere in the codebase."
survived,"    def test_uses_pytest_when_available(self):
        with tempfile.TemporaryDirectory() as tmpdir:
            target = Path(tmpdir)
            with mock.patch('importlib.util.find_spec', return_value=object()):
                with mock.patch('subprocess.call', return_value=0) as call:
                    with mock.patch.object(sys, 'argv', ['run_tests.py', str(target)]):
                        with self.assertRaises(SystemExit):
                            run_tests.main()
                    call.assert_called_once()
                    self.assertIn('pytest', call.call_args[0][0])
",alpha_factory_v1/tests/test_scripts_run_tests.py,RunTestsScriptTest,1,2.998960815863541e-09,"The method 'test_uses_pytest_when_available' is a unit test designed to verify that the 'run_tests.main()' function uses 'pytest' when it is available. It uses mocking to simulate the presence of 'pytest' and checks if the subprocess call includes 'pytest'. This is a valid and useful test case for ensuring that the code behaves correctly when 'pytest' is available. Therefore, it is likely to be retained in the codebase."
survived,"    def test_path_must_exist(self):
        with self.assertRaises(SystemExit):
            with mock.patch.object(sys, 'argv', ['run_tests.py', '/nope']):
                run_tests.main()
",alpha_factory_v1/tests/test_scripts_run_tests.py,RunTestsScriptTest,1,2.3355930333443423e-09,"The method 'test_path_must_exist' is a unit test designed to ensure that the 'run_tests.main()' function exits when provided with a non-existent path. This is a valid and useful test case for verifying the robustness of the 'run_tests.main()' function against invalid input. Unit tests are generally preserved unless they are redundant or the functionality they test is removed. Since this test checks for a critical error handling scenario, it is likely to be retained."
survived,"    async def run(self, agent: Agent, *args, **kwargs):
        return await agent.run(*args, **kwargs)
",src/agents/__init__.py,Runner,0,0.9999999317439577,"The method is a simple wrapper around the `agent.run` method, adding no additional functionality or value. It merely forwards the call and its arguments to another method. Such methods are often considered redundant unless they are part of a larger interface or framework where consistency in method signatures is required. Without additional context suggesting its necessity, it is likely to be deleted as it doesn't contribute to the codebase."
survived,"    async def run(self, *_args, **_kwargs):
        return {""status"": ""success""}
",src/agents/__init__.py,Agent,1,4.363462233903899e-09,"The method 'run' is a simple asynchronous function that returns a dictionary with a status key set to 'success'. It is a basic implementation that could be part of a larger system where asynchronous operations are needed. The method is likely to survive because it is functional, follows a common pattern for async functions, and could be useful in various contexts where a success status needs to be returned after an operation. There is no indication of redundancy or obsolescence in the code provided."
survived,"def test_simulate_returns_trajectory() -> None:
    traj = _simulate(2, ""logistic"", 2, 1)
    assert len(traj) == 2
    assert isinstance(traj[0], forecast.TrajectoryPoint)
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_web_app.py,,1,6.348800075736417e-09,"The method `test_simulate_returns_trajectory` is a unit test function that checks the behavior of the `_simulate` function. It verifies that the function returns a trajectory of the expected length and type. Unit tests are crucial for ensuring code reliability and correctness, especially in complex systems. Therefore, this method is likely to be retained as it contributes to the overall quality assurance of the codebase."
survived,"    def export_json(
        self,
        path: str | Path,
        *,
        start: datetime | str | None = None,
        end: datetime | str | None = None,
        metrics: Iterable[str] | None = None,
        compress: bool | None = None,
    ) -> str:
        """"""Export telemetry to a JSON file with optional compression.""""""
        compress = compress or str(path).endswith(("".gz"", "".gzip""))
        data = self.fetch_all(start=start, end=end, metrics=metrics)
        open_fn = gzip.open if compress else open
        mode = ""wt""
        with open_fn(path, mode, encoding=""utf-8"") as f:
            json.dump(data, f)
        return str(path)
",src/meta_agent/telemetry_db.py,TelemetryDB,1,8.592166611791576e-10,"The method 'export_json' is well-defined and serves a clear purpose of exporting telemetry data to a JSON file with optional compression. It uses type hints, handles optional parameters, and includes a docstring explaining its functionality. The method also checks for compression based on the file extension, which is a practical feature. These factors suggest that the method is useful, maintainable, and likely to be retained in the codebase."
survived,"def model_urls(model: str) -> list[str]:
    base = f""https://openaipublic.blob.core.windows.net/gpt-2/models/{model}/""
    return [base + name for name in _FILE_LIST]
",scripts/download_openai_gpt2.py,,1,1.6052280526088547e-09,"The method 'model_urls' is a simple utility function that constructs URLs for accessing models from a specified base URL. It is a straightforward and useful function for generating a list of URLs based on a given model name and a predefined list of file names (_FILE_LIST). Such utility functions are common in codebases where dynamic URL generation is needed, especially in contexts involving cloud storage or API access. There is no indication that this function is redundant or obsolete, and it serves a clear purpose. Therefore, it is likely to be retained in the codebase."
survived,"def test_guardrail_event():
    t = TelemetryCollector()
    t.increment_guardrail_hits()
    assert t.guardrail_hits == 1
    assert len(t.events) == 1
    ev = t.events[0]
    assert ev.category == TelemetryCollector.Category.GUARDRAIL
    assert ev.severity == TelemetryCollector.Severity.WARNING",tests/unit/test_telemetry_collector.py,,1,1.637377179507321e-07,"The method 'test_guardrail_event' is a unit test for the 'TelemetryCollector' class, specifically testing the 'increment_guardrail_hits' method. Unit tests are crucial for ensuring code reliability and are typically retained to maintain code quality. The test checks if the guardrail hits are incremented correctly and if the event is logged with the correct category and severity. This functionality is important for monitoring and logging purposes, suggesting that the test is valuable and should be retained."
survived,"def test_summary_line_custom_metrics():
    t = TelemetryCollector()
    t.start_timer()
    t.stop_timer()
    line = t.summary_line([""latency""])
    assert ""Telemetry:"" in line
    assert ""latency="" in line
    assert ""cost="" not in line
",tests/unit/test_telemetry_collector.py,,1,4.1399375473943306e-08,"The method 'test_summary_line_custom_metrics' is a unit test for the 'TelemetryCollector' class, specifically testing the 'summary_line' method with custom metrics. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with telemetry data, which can be critical for performance monitoring and debugging. The test checks that the 'summary_line' method correctly includes 'latency' in its output and does not include 'cost', which is a valid and necessary test case. Therefore, this method is likely to be retained as part of the test suite to ensure the functionality of the 'TelemetryCollector' class."
survived,"async def test_llm_comment_no_openai(monkeypatch: pytest.MonkeyPatch) -> None:
    """"""_llm_comment should rely on the local model when OpenAI is unavailable.""""""
    called = {}

    def fake_chat(prompt: str, cfg: object | None = None) -> str:
        called[""prompt""] = prompt
        return ""offline""

    monkeypatch.delenv(""OPENAI_API_KEY"", raising=False)
    removed = sys.modules.pop(""openai_agents"", None)
    monkeypatch.setattr(demo.local_llm, ""chat"", fake_chat)

    try:
        out = await demo._llm_comment(-0.42)
    finally:
        if removed is not None:
            sys.modules[""openai_agents""] = removed

    assert out == ""offline""
    assert called[""prompt""].startswith(""In one sentence, comment on Î”G=-0.4200"")
",tests/test_alpha_agi_business_3_v1.py,,1,2.2159489282323004e-08,"The method `test_llm_comment_no_openai` is a unit test designed to verify the behavior of the `_llm_comment` function when the OpenAI service is unavailable. It uses the `monkeypatch` fixture to simulate the absence of the OpenAI API by removing the API key and the `openai_agents` module, and it replaces the `chat` method with a fake implementation. The test checks that the `_llm_comment` function correctly falls back to using a local model and returns the expected output. This is a valid and useful test case for ensuring the robustness of the `_llm_comment` function in scenarios where external dependencies are unavailable. Therefore, it is likely to be retained in the codebase."
survived,"def discover_hot_dir() -> None:
    if not _HOT_DIR.is_dir():
        return
    for wheel in _HOT_DIR.glob(""*.whl""):
        if wheel.stem.replace(""-"", ""_"") in AGENT_REGISTRY:
            continue
        try:
            if not verify_wheel(wheel):
                continue
            mod = install_wheel(wheel)
            if mod:
                meta = _inspect_module(mod)
                if meta and meta.name not in AGENT_REGISTRY:
                    _register(meta)
        except Exception:  # noqa: BLE001
            logger.exception(""Hot-dir load failed for %s"", wheel.name)
",alpha_factory_v1/backend/agents/discovery.py,,1,6.69158608681505e-10,"The method 'discover_hot_dir' is likely to survive because it performs a specific and useful function: it checks a directory for wheel files, verifies them, installs them, and registers them if they are not already in the registry. This functionality is important for dynamically loading and managing plugins or extensions, which is a common requirement in software systems that support modularity and extensibility. Additionally, the method includes error handling to log exceptions, which indicates it is designed to be robust and maintainable."
survived,"def show_memory(limit: int, export: str | None) -> None:
    """"""Display stored memory entries.""""""
    path = config.CFG.memory_path
    if not path:
        click.echo(""Memory persistence not enabled"")
        return
    mem_file = Path(path)
    if not mem_file.exists():
        click.echo(""No memory entries"")
        return
    entries = []
    for line in mem_file.read_text(encoding=""utf-8"").splitlines():
        if not line:
            continue
        try:
            entries.append(json.loads(line))
        except Exception:  # noqa: BLE001 - ignore bad records
            entries.append({""raw"": line})
    if not entries:
        click.echo(""No memory entries"")
        return
    entries = entries[-limit:]
    if export == ""json"":
        click.echo(json.dumps(entries))
    elif export == ""csv"":
        lines = [""payload""]
        for e in entries:
            lines.append(json.dumps(e).replace("","", "";""))
        click.echo(""\n"".join(lines))
    else:
        _rich_table([""payload""], [(json.dumps(e),) for e in entries])
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/cli.py,,1,4.6911638017642294e-08,"The method 'show_memory' is a utility function that reads and displays memory entries from a file. It provides functionality to export these entries in JSON or CSV format, or display them in a table format. This kind of utility function is often useful in applications that require logging or debugging, as it allows developers to inspect stored data easily. The method is well-structured, handles exceptions, and provides multiple output formats, making it versatile and user-friendly. Such methods are typically retained in codebases because they provide essential functionality for data inspection and debugging."
survived,"        def __init__(self) -> None:
            self.coro: Any | None = None
",tests/test_alpha_agi_business_3_v1.py,DummyLoop,1,2.646573631904765e-09,"The method is a constructor (__init__) for a class, which is a fundamental part of object-oriented programming in Python. It is used to initialize the attributes of a class instance. The presence of this method is essential for setting up the initial state of an object, and it is unlikely to be removed unless the class itself is being deprecated or refactored significantly. Therefore, the method will survive."
survived,"def outer(x):
    def inner(y):
        return x + y
    return inner(5)
",tests/transpiler/x/py/nested_function.py,,1,2.1024340680345882e-07,"The method 'outer' is a simple example of a closure in Python, where the inner function 'inner' uses a variable 'x' from the outer function's scope. This is a common and useful pattern in Python for creating functions with pre-configured arguments. The method is functional and demonstrates a valid use case of closures, which are an important concept in Python programming. Therefore, it is likely to be retained as it serves an educational purpose and is correctly implemented."
survived,"def test_simulate_seed_reproducible(tmp_path: Path) -> None:
    """"""Output should be identical when running with the same seed.""""""
    ledger = tmp_path / ""audit.db""
    args = [
        ""simulate"",
        ""--horizon"",
        ""1"",
        ""--offline"",
        ""--sectors"",
        ""1"",
        ""--pop-size"",
        ""1"",
        ""--generations"",
        ""1"",
        ""--export"",
        ""json"",
        ""--no-broadcast"",
        ""--seed"",
        ""42"",
    ]
    runner = CliRunner()
    with patch.object(cli, ""asyncio""):
        with patch.object(cli.orchestrator, ""Orchestrator""):
            with patch.object(cli.config.CFG, ""ledger_path"", ledger):
                res1 = runner.invoke(cli.main, args)
                res2 = runner.invoke(cli.main, args)

    assert res1.exit_code == 0
    assert res2.exit_code == 0
    digest1 = hashlib.sha256(res1.output.encode()).hexdigest()
    digest2 = hashlib.sha256(res2.output.encode()).hexdigest()
    assert digest1 == digest2",tests/test_demo_cli.py,,1,1.8189616842444243e-09,"The method is a test function that ensures the reproducibility of a simulation when a specific seed is used. It is important for verifying that the code behaves consistently under controlled conditions, which is a critical aspect of testing in software development. The function is well-structured, uses appropriate testing techniques, and serves a clear purpose in the codebase. Therefore, it is likely to be retained."
survived,"def _log_delta(delta: float, log_file: Path) -> None:
    """"""Append ``delta`` with timestamp to ``log_file`` (JSON list).""""""
    log: list[dict[str, float]]
    if log_file.exists():
        log = json.loads(log_file.read_text())
    else:
        log = []
    log.append({""ts"": time.time(), ""delta"": delta})
    log_file.write_text(json.dumps(log))
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/self_improver.py,,1,8.152020648014727e-09,"The method '_log_delta' is a utility function that logs a floating-point delta value with a timestamp to a specified log file in JSON format. This is a common requirement in many applications for tracking changes or events over time. The method is well-defined, uses standard libraries, and handles both the creation of a new log file and the appending to an existing one. These characteristics make it a useful and reusable piece of code, suggesting that it is likely to be retained in the codebase."
survived,"async def test_llm_comment_uses_local_model(monkeypatch: pytest.MonkeyPatch) -> None:
    called = {}

    def fake_chat(prompt: str, cfg: object | None = None) -> str:
        called[""prompt""] = prompt
        return ""local""

    monkeypatch.setattr(demo, ""OpenAIAgent"", None)
    monkeypatch.setattr(demo.local_llm, ""chat"", fake_chat)

    out = await demo._llm_comment(0.1234)

    assert out == ""local""
    assert called[""prompt""].startswith(""In one sentence, comment on Î”G=0.1234"")
",tests/test_alpha_agi_business_3_v1.py,,1,7.194132978569833e-09,"The method `test_llm_comment_uses_local_model` is a unit test designed to verify that a local model is used instead of an external one. It uses `monkeypatch` to replace certain functionalities with mock implementations, which is a common practice in testing to isolate the unit of work and ensure it behaves as expected. The test checks that the output is 'local' and that the prompt is correctly formatted. This is a typical and useful test case for ensuring that the local model is correctly integrated and used, especially in environments where external dependencies need to be minimized or controlled. Therefore, the method is likely to be retained as it serves a clear purpose in the testing suite."
survived,"def test_namedarray_type_syntax():
    t1 = NamedArray[""batch"", ""embed""]
    t2 = NamedArray[""batch embed""]
    assert typing.get_args(t1)[1] == typing.get_args(t2)[1]

    t3 = NamedArray[""batch embed ...""]
    axes3 = typing.get_args(t3)[1]
    assert axes3.before == (""batch"", ""embed"") and axes3.subset and axes3.after == ()

    t4 = NamedArray[{""batch"", ""embed""}]
    axes4 = typing.get_args(t4)[1]
    assert set(axes4.before) == {""batch"", ""embed""} and not axes4.ordered

    t5 = NamedArray[{""batch"", ""embed"", ...}]
    axes5 = typing.get_args(t5)[1]
    assert set(axes5.before) == {""batch"", ""embed""} and not axes5.ordered and axes5.subset

    t6 = NamedArray[""... embed""]
    axes6 = typing.get_args(t6)[1]
    assert axes6.before == () and axes6.after == (""embed"",) and axes6.subset

    t7 = NamedArray[""batch ... embed""]
    axes7 = typing.get_args(t7)[1]
    assert axes7.before == (""batch"",) and axes7.after == (""embed"",) and axes7.subset
",tests/test_namedarray_typing.py,,1,3.927863699585036e-07,"The method is a test function that checks various syntaxes for creating a NamedArray type. It uses assertions to verify that the NamedArray type behaves as expected with different input formats. This is a typical pattern in testing to ensure that the code handles different cases correctly. Since it is a test function, it is likely to be retained as part of the test suite to ensure the correctness of the NamedArray type handling. Test functions are generally not deleted unless they are redundant or replaced by more comprehensive tests."
survived,"    def __repr__(self) -> str:
        if self.ordered:
            parts = list(self.before)
            if self.subset:
                parts.append(""..."")
            parts.extend(self.after)
            spec = "" "".join(parts)
            return f""NamedArray[{spec}]""
        else:
            part = "", "".join(self.before)
            if self.subset:
                if part:
                    part += "", ...""
                else:
                    part = ""...""
            return f""NamedArray[{{{part}}}]""
",src/haliax/core.py,NamedArrayAxes,1,3.3982678079468468e-09,"The method `__repr__` is a special method in Python used to define a string representation of an object. This is a common and useful method for debugging and logging purposes, as it provides a way to output a human-readable description of the object. The implementation here checks conditions and formats the output string based on the object's attributes (`ordered`, `before`, `after`, `subset`). This functionality is essential for understanding the state of the object when printed or logged, making it unlikely to be deleted unless the class itself is being deprecated or significantly refactored."
survived,"    def test_summary_auth_error(self) -> None:
        import openai

        with patch.dict(os.environ, {""OPENAI_API_KEY"": ""sk-test""}):
            with patch(""openai.OpenAI"") as mock_client:
                mock_client.return_value.chat.completions.create.side_effect = openai.AuthenticationError(""bad key"")
                text = summarise_with_agent(
                    0.5,
                    agents=2,
                    rounds=10,
                    delta=0.9,
                    stake=1.0,
                )
        self.assertIn(""OPENAI_API_KEY not set"", text)
        self.assertIn(""offline summary"", text)
",tests/test_governance_sim.py,TestGovernanceSim,1,1.4166087846364157e-09,"The method `test_summary_auth_error` is a unit test designed to verify the behavior of a function when an authentication error occurs with the OpenAI API. It uses mocking to simulate the error and checks if the appropriate error messages are included in the output. This is a standard practice in testing to ensure robustness against external API failures. Since it is a well-structured test that serves a clear purpose in ensuring the reliability of the code, it is likely to be retained in the codebase."
survived,"def tokenize(text: str) -> List[str]:
    return re.findall(r""\b\w+\b"", text.lower())
",scripts/dp_scrubber.py,,1,5.905303995456778e-10,"The method 'tokenize' is a simple utility function that uses regular expressions to split a string into words, converting the text to lowercase in the process. This is a common and useful operation in text processing tasks, such as natural language processing (NLP) and data cleaning. The function is straightforward, efficient, and serves a clear purpose, making it likely to be retained in the codebase. Additionally, it does not have any obvious issues or redundancies that would necessitate its removal."
survived,"    def __init__(
        self,
        *,
        region: str = ""us-east-1"",
        budget_per_day: float = 200.0,
        price_fetcher: FetchFunc | None = None,
    ) -> None:
        self.region = region
        self.budget_per_day = budget_per_day
        self.price_fetcher = price_fetcher or _fetch_spot_price
",src/scheduler/spot_gpu.py,SpotGPUAllocator,1,7.73442280641062e-08,"The method is a constructor (__init__) for a class, which is essential for initializing new instances of the class. Constructors are fundamental components of class definitions in object-oriented programming, and they are rarely deleted unless the entire class is being removed or refactored significantly. Additionally, the method includes default parameters and a fallback mechanism for the price_fetcher, indicating thoughtful design for flexibility and robustness. Therefore, it is unlikely to be deleted."
survived,"    async def broadcast_merkle_root(self) -> None:
        try:
            root = self.compute_merkle_root()
        except Exception as exc:  # pragma: no cover - corruption
            _log.warning(""Failed to compute Merkle root: %s"", exc)
            return
        if AsyncClient is None or not self.broadcast:
            _log.info(""Merkle root %s"", root)
            return
        try:
            client = AsyncClient(self.rpc_url or ""https://api.testnet.solana.com"")
            memo_prog = PublicKey(""MemoSq4gqABAXKb96qnH8TysNcWxMyWCqXgDLGmfcHr"")
            tx = Transaction().add(TransactionInstruction(program_id=memo_prog, data=root.encode(), keys=[]))
            signer = None
            if self.wallet:
                try:  # pragma: no cover - optional dependency
                    from solana.keypair import Keypair

                    signer = Keypair.from_secret_key(bytes.fromhex(self.wallet))
                except Exception as exc:  # noqa: BLE001 - invalid key
                    _log.warning(""Invalid wallet key: %s"", exc)
            if signer:
                await client.send_transaction(tx, signer)
            else:
                await client.send_transaction(tx)
            _log.info(""Broadcasted Merkle root %s"", root)
        except Exception as exc:  # pragma: no cover - network errors
            _log.warning(""Failed to broadcast Merkle root: %s"", exc)
        finally:
            try:
                await client.close()
            except Exception:  # pragma: no cover - ignore close errors
                pass
",src/archive/service.py,ArchiveService,1,6.348800075736417e-09,"The method 'broadcast_merkle_root' is likely to survive because it is a well-structured asynchronous function that handles broadcasting a Merkle root to a network. It includes error handling for various potential issues such as computation errors, invalid wallet keys, and network errors. The method also logs important information, which is useful for debugging and monitoring. Additionally, it uses modern async/await syntax, which is a good practice for handling I/O-bound operations efficiently. These factors suggest that the method is functional, robust, and aligned with current programming practices, making it unlikely to be deleted."
survived,"def _merkle_root(hashes: Iterable[str]) -> str:
    nodes: List[bytes] = [bytes.fromhex(h) for h in hashes]
    if not nodes:
        return blake3(b""\x00"").hexdigest()

    while len(nodes) > 1:
        if len(nodes) % 2 == 1:
            nodes.append(nodes[-1])
        next_lvl: List[bytes] = []
        for i in range(0, len(nodes), 2):
            next_lvl.append(blake3(nodes[i] + nodes[i + 1]).digest())
        nodes = next_lvl
    return nodes[0].hex()
",src/archive/service.py,,1,4.599055376537186e-10,"The method `_merkle_root` is a utility function that calculates the Merkle root from a list of hash strings. This is a fundamental operation in blockchain and cryptographic applications, where Merkle trees are used to ensure data integrity and efficiency. The function is well-implemented, handling edge cases such as an empty list of hashes and odd numbers of nodes by duplicating the last node. Given its utility in cryptographic contexts and the correct implementation, it is likely to be retained in the codebase."
survived,"    def last_hash(self) -> str | None:
        cur = self.conn.execute(""SELECT hash FROM entries ORDER BY id DESC LIMIT 1"")
        row = cur.fetchone()
        return row[0] if row else None
",src/archive/service.py,ArchiveService,1,5.60279640614594e-09,"The method 'last_hash' is a simple utility function that retrieves the last hash from a database table. It is straightforward, performs a specific task, and is likely useful in contexts where the latest entry's hash is needed. There are no apparent issues with the code, such as performance bottlenecks or security vulnerabilities, that would necessitate its deletion. Additionally, it uses a common pattern for database access and error handling (returning None if no result is found), which is a good practice. Therefore, it is likely to be retained in the codebase."
survived,"    def insert_entry(
        self,
        spec: Mapping[str, Any],
        scores: Mapping[str, float],
        *,
        parent: str | None = None,
    ) -> str:
        parent = parent or self.last_hash()
        record = {""parent"": parent, ""spec"": spec, ""scores"": dict(scores)}
        digest = blake3(json.dumps(record, sort_keys=True).encode()).hexdigest()
        with self.conn:
            self.conn.execute(
                ""INSERT INTO entries(parent, spec, scores, hash, ts) VALUES(?,?,?,?,?)"",
                (parent, json.dumps(spec), json.dumps(record[""scores""]), digest, time.time()),
            )
        return self.compute_merkle_root()
",src/archive/service.py,ArchiveService,1,1.8189616842444243e-09,"The method 'insert_entry' is a well-defined function that performs a specific task of inserting an entry into a database. It takes in specifications and scores, computes a hash, and inserts this data into a database table. The method is likely part of a larger system that manages entries and their relationships, possibly in a blockchain or version control context. The use of hashing and a Merkle root suggests a focus on data integrity and verification. Given its clear purpose, integration with a database, and the use of cryptographic functions, it is unlikely to be deleted unless the entire system undergoes a significant redesign or the method's functionality is no longer needed. Therefore, it is more likely to survive."
survived,"def _sync_chat(prompt: str) -> str:
    """"""Synchronously invoke the async chat helper.""""""
    from alpha_factory_v1.backend.llm_provider import chat

    async def _call() -> str:
        return await chat(prompt, max_tokens=512)

    try:
        asyncio.get_running_loop()
    except RuntimeError:
        return asyncio.run(_call())

    result: list[str] = []

    def _worker() -> None:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        task = loop.create_task(_call())
        try:
            result.append(loop.run_until_complete(task))
        finally:
            loop.close()

    t = threading.Thread(target=_worker)
    t.start()
    t.join()
    return result[0]
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/mutators/code_diff.py,,1,4.6911638017642294e-08,"The method '_sync_chat' is a utility function that provides a synchronous interface to an asynchronous chat function. This is useful in environments where asynchronous execution is not possible or desired, such as in certain legacy systems or synchronous frameworks. The method handles both cases where an event loop is already running and where it is not, ensuring compatibility across different execution contexts. This kind of functionality is often necessary in real-world applications to bridge the gap between synchronous and asynchronous code, making it unlikely to be deleted unless the entire system architecture changes to fully support asynchronous operations."
survived,"    async def _call() -> str:
        return await chat(prompt, max_tokens=512)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/mutators/code_diff.py,,1,9.237449576640118e-09,"The method `_call` is an asynchronous function that returns the result of an awaited call to `chat`. The method itself is simple and serves a clear purpose, which is to encapsulate the call to `chat` with specific parameters. There is no indication of redundancy or inefficiency in the code provided, and it seems to be a necessary part of the asynchronous workflow. Therefore, it is likely to be retained in the codebase."
survived,"def propose_diff(repo_path: str, spec: str) -> str:
    """"""Return a git diff implementing ``spec`` inside ``repo_path``.""""""
    rel, goal = _parse_spec(spec)
    file_path = str(Path(repo_path) / rel)
    if _offline():
        return _fallback_diff(file_path, goal)
    prompt = (
        ""Generate a unified git diff for the repository at '{repo}'.\n""
        ""Apply the following change: {spec}"".format(repo=repo_path, spec=spec)
    )
    try:
        diff = _sync_chat(prompt)
        if not diff.endswith(""\n""):
            diff += ""\n""
        return diff
    except Exception:
        return _fallback_diff(file_path, goal)",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/mutators/code_diff.py,,1,2.646573631904765e-09,"The method 'propose_diff' is a utility function that generates a git diff based on a specification and a repository path. It includes error handling and a fallback mechanism, which are good practices for robustness. The method is likely useful in scenarios where automated code changes are needed, such as in continuous integration pipelines or automated code review tools. Given its utility and the fact that it handles both online and offline scenarios, it is more likely to be retained in the codebase."
survived,"    def create_app(self) -> ""FastAPI"":
        if FastAPI is None:
            raise RuntimeError(""FastAPI not installed"")

        app = FastAPI(title=""Dual Critic Service"")

        @app.post(""/critique"")
        async def _critique(req: CritiqueRequest = Body(...)) -> Any:  # noqa: D401
            result = self.score(req.context, req.response)
            return JSONResponse(result)

        CritiqueRequest.model_rebuild()

        return app
",src/critics/dual_critic_service.py,DualCriticService,1,2.646573631904765e-09,"The method 'create_app' is a crucial part of setting up a FastAPI application. It initializes the FastAPI app, defines an endpoint, and handles requests. This is a common pattern in FastAPI applications, and there is no indication that it is deprecated or unnecessary. Therefore, it is likely to survive."
survived,"def aggregate_stats(rows: Iterable[Dict[str, float]]) -> Dict[str, float]:
    """"""Return mean and stdev for each metric in ``rows``.""""""
    stats: Dict[str, float] = {}
    metrics: Dict[str, List[float]] = {m: [] for m in _METRICS}
    for row in rows:
        for m in _METRICS:
            if m in row:
                metrics[m].append(row[m])
    for m, vals in metrics.items():
        if vals:
            stats[f""{m}_mean""] = statistics.mean(vals)
            stats[f""{m}_stdev""] = statistics.pstdev(vals) if len(vals) > 1 else 0.0
    return stats
",src/analysis/meta_foresight.py,,1,4.0586521248284276e-10,"The method `aggregate_stats` is likely to survive because it provides a useful functionality of calculating the mean and standard deviation for each metric in a collection of data rows. This is a common requirement in data analysis and processing tasks. The method is well-structured, uses standard libraries, and handles edge cases such as when there is only one value for a metric. Additionally, the use of type hints improves code readability and maintainability, making it a good candidate for retention in a codebase."
survived,"def test_run_simulation_smoke(capsys: pytest.CaptureFixture[str]) -> None:
    """"""Ensure _run_simulation accepts the new num_sectors argument.""""""

    web_app._run_simulation(1, ""logistic"", 2, 3, 1)
    out, _ = capsys.readouterr()
    assert ""Streamlit not installed"" in out",tests/test_web_app.py,,1,7.73442280641062e-08,"The method 'test_run_simulation_smoke' is a test function that checks if the '_run_simulation' function in the 'web_app' module correctly handles a new argument 'num_sectors'. This is a typical unit test to ensure that the function behaves as expected when a new feature or parameter is added. Since testing is a crucial part of software development to maintain code quality and ensure new changes do not break existing functionality, this method is likely to be retained. It helps in verifying the integration of new features and maintaining the robustness of the application."
survived,"def test_simulate_does_not_modify_global_cfg() -> None:
    """"""CLI options should not persist on the global config.""""""
    runner = CliRunner()
    original = cli.config.CFG.model_dump()

    with patch.object(cli, ""asyncio""), patch.object(cli.orchestrator, ""Orchestrator""):
        res = runner.invoke(
            cli.main,
            [
                ""simulate"",
                ""--horizon"",
                ""1"",
                ""--offline"",
                ""--sectors"",
                ""1"",
                ""--pop-size"",
                ""1"",
                ""--generations"",
                ""1"",
                ""--model"",
                ""other"",
                ""--temperature"",
                ""0.9"",
                ""--context-window"",
                ""1024"",
            ],
        )

    assert res.exit_code == 0
    assert cli.config.CFG.model_dump() == original",tests/test_cli.py,,1,2.699578619062706e-07,The method 'test_simulate_does_not_modify_global_cfg' is a unit test designed to ensure that a specific command-line interface (CLI) operation does not alter the global configuration. This is a common requirement in software testing to ensure that operations do not have unintended side effects. The method uses mocking to isolate the test from external dependencies and checks the exit code and configuration state. Such tests are crucial for maintaining software reliability and are unlikely to be deleted unless the functionality they test is removed or significantly altered.
survived,"    def test_register_condition_false(self):
        @register(condition=False)
        class BarAgent(AgentBase):
            NAME = ""bar""
        self.assertNotIn(""bar"", AGENT_REGISTRY)
",alpha_factory_v1/tests/test_register_decorator.py,RegisterDecoratorTest,0,0.9999869928752253,"The method `test_register_condition_false` is likely to be deleted because it tests a scenario where a class is registered with a condition set to `False`, which means the class should not be registered. This test might be considered redundant or unnecessary if the registration mechanism is well-understood and the condition parameter is consistently handled elsewhere in the codebase. Additionally, if the `register` decorator is well-tested in other scenarios, this specific test might not add significant value."
survived,"        def add_node(self, node: str, **attrs: Any) -> None:
            self.nodes[node] = attrs
",alpha_factory_v1/backend/agents/supply_chain_agent.py,_FakeGraph,1,9.736200303530205e-10,"The method 'add_node' is a basic utility function for adding nodes to a data structure, likely a graph or network. It is straightforward and performs a fundamental operation that is essential for the functionality of such data structures. There is no indication that this method is redundant or unnecessary, and it is likely to be used frequently in the context of managing nodes. Therefore, it is unlikely to be deleted."
survived,"        def add_edge(self, u: str, v: str, **attrs: Any) -> None:
            self.edges[(u, v)] = attrs
",alpha_factory_v1/backend/agents/supply_chain_agent.py,_FakeGraph,1,7.194132978569833e-09,"The method 'add_edge' is a fundamental operation in graph data structures, used to add a connection between two nodes. This functionality is essential for building and manipulating graphs, which are widely used in various applications such as network analysis, social networks, and more. The method is simple, clear, and performs a necessary task without any apparent issues or redundancies. Therefore, it is unlikely to be deleted."
survived,"def _parse_with(args):
    old = sys.argv
    sys.argv = ['run.py'] + args
    try:
        return af_run.parse_args()
    finally:
        sys.argv = old
",alpha_factory_v1/tests/test_cli.py,,1,6.023574641292144e-08,"The method '_parse_with' is a utility function that temporarily modifies 'sys.argv' to simulate command-line arguments for the 'af_run.parse_args()' function. This is a common pattern used in testing or when programmatically invoking command-line interfaces. The method is well-encapsulated, restores the original state of 'sys.argv', and is likely used in a specific context where such functionality is needed. Therefore, it is unlikely to be deleted unless the entire functionality it supports is refactored or removed."
survived,"def __getattr__(name: str) -> Any:  # pragma: no cover - thin wrapper
    """"""Lazily import topâ€‘level modules.

    This keeps ``import alpha_factory_v1`` fast and avoids importing heavy
    dependencies until actually needed.
    """"""

    if name in {""backend"", ""demos"", ""ui"", ""run""}:
        return importlib.import_module(f"".{name}"", __name__)
    raise AttributeError(f""module {__name__!r} has no attribute {name}"")
",alpha_factory_v1/__init__.py,,1,8.76424914819242e-08,"The method `__getattr__` is a special method in Python that is used to define behavior for when an attribute is accessed that doesn't exist on an object. In this code, it is used to lazily import modules only when they are accessed, which can improve performance by delaying the import of potentially heavy modules until they are actually needed. This is a useful pattern in Python, especially for large applications with many dependencies. The use of `__getattr__` in this way is a common and effective technique, and there is no indication that it is deprecated or unnecessary. Therefore, it is likely to be retained in the code."
survived,"def test_cli_flags_override_env(monkeypatch) -> None:
    """"""CLI options should set env vars for the runtime helpers.""""""
    if MODULE in sys.modules:
        del sys.modules[MODULE]
    mod = importlib.import_module(MODULE)

    monkeypatch.setattr(mod, ""check_env"", types.SimpleNamespace(main=lambda *_a, **_k: None), raising=False)

    captured: dict[str, str] = {}

    async def _llm(_: float) -> str:
        captured[""api_key""] = os.getenv(""OPENAI_API_KEY"")
        return ""ok""

    class DummyADK:
        def __init__(self, host: str) -> None:  # pragma: no cover - init only
            captured[""adk_host""] = host

    class DummySock:
        def __init__(self, host: str, port: int, app_id: str) -> None:
            captured[""a2a""] = f""{host}:{port}""  # pragma: no cover - record args

        def start(self) -> None:  # pragma: no cover - unused
            pass

        def stop(self) -> None:  # pragma: no cover - unused
            pass

        def sendjson(self, *_a: object, **_kw: object) -> None:  # pragma: no cover - unused
            pass

    monkeypatch.setattr(mod, ""_llm_comment"", _llm)
    monkeypatch.setattr(mod, ""ADKClient"", DummyADK)
    monkeypatch.setattr(mod, ""A2ASocket"", DummySock)
    monkeypatch.setattr(mod, ""_A2A"", None)

    asyncio.run(
        mod.main(
            [
                ""--cycles"",
                ""1"",
                ""--interval"",
                ""0"",
                ""--openai-api-key"",
                ""cli-key"",
                ""--adk-host"",
                ""http://cli-adk:9"",
                ""--a2a-port"",
                ""7777"",
                ""--a2a-host"",
                ""cli-host"",
            ]
        )
    )

    assert captured[""api_key""] == ""cli-key""
    assert captured[""adk_host""] == ""http://cli-adk:9""
    assert captured[""a2a""] == ""cli-host:7777""
",tests/test_alpha_agi_business_3_v1.py,,1,1.955568070542584e-08,"The method `test_cli_flags_override_env` is a test function that verifies the behavior of a command-line interface (CLI) in overriding environment variables. It uses the `monkeypatch` fixture to modify the behavior of certain functions and classes within a module, ensuring that the CLI flags correctly set the environment variables for runtime helpers. This is a typical use case in testing to ensure that CLI options take precedence over environment variables, which is a common requirement in software applications. The function is well-structured, uses asynchronous programming, and includes assertions to validate the expected behavior. Given its purpose and implementation, it is likely to be retained as it serves a critical role in ensuring the correctness of the application's configuration handling."
survived,"            def __init__(self, program_id: object, data: bytes, keys: list[object]):
                self.data = data
",tests/test_insight_orchestrator_features.py,TestLedger.DummyInstr,1,2.3823698451773172e-07,"The method is a constructor (__init__) for a class, which is a fundamental part of object-oriented programming in Python. It initializes the instance of the class with the provided parameters. Even though the method currently only assigns one of the parameters to an instance variable, it is likely that the other parameters (program_id and keys) will be used in the future or are used elsewhere in the class. Constructors are essential for setting up the initial state of an object, so it is unlikely to be deleted."
survived,"def test_assets_replaced() -> None:
    browser_dir = Path(__file__).resolve().parents[1]
    for sub in (""wasm"", ""wasm_llm"", ""lib""):
        for p in (browser_dir / sub).rglob(""*""):
            if not p.is_file():
                continue
            if ""placeholder"" in p.read_text(errors=""ignore"").lower():
                rel = p.relative_to(browser_dir)
                raise AssertionError(f""{rel} contains placeholder text"")",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_assets_replaced.py,,1,1.8189616842444243e-09,"The method 'test_assets_replaced' is a test function that checks if any files within certain directories contain the word 'placeholder'. This is a useful test to ensure that all placeholder text has been replaced with actual content before deployment or release. Such tests are generally important for maintaining code quality and ensuring that incomplete or incorrect files are not included in the final product. Therefore, it is likely to be retained as part of the test suite."
survived,"def run_evolution(
    fn: Callable[[List[float]], Tuple[float, float]],
    genome_length: int,
    *,
    population_size: int = 20,
    mutation_rate: float = 0.1,
    generations: int = 10,
    seed: int | None = None,
) -> Population:
    """"""Execute a complete NSGA-II evolutionary run.

    Args:
        fn: Function evaluating an individual's genome.
        genome_length: Number of float genes per individual.
        population_size: Number of individuals preserved each generation.
        mutation_rate: Probability of mutating a gene during crossover.
        generations: Number of NSGA-II steps to perform.
        seed: Optional random seed for deterministic behaviour.

    Returns:
        The final population after ``generations`` steps.
    """"""

    rng = random.Random(seed)
    pop = [Individual([rng.uniform(-1, 1) for _ in range(genome_length)]) for _ in range(population_size)]

    def _step(population: Population) -> Population:
        evaluate(population, fn)
        offspring: Population = []
        while len(offspring) < population_size:
            a, b = rng.sample(population, 2)
            cut = rng.randint(1, genome_length - 1)
            child_genome = a.genome[:cut] + b.genome[cut:]
            if rng.random() < mutation_rate:
                idx = rng.randrange(genome_length)
                child_genome[idx] += rng.uniform(-1, 1)
            offspring.append(Individual(child_genome))
        evaluate(offspring, fn)
        union = population + offspring
        fronts = _non_dominated_sort(union)
        new_pop: Population = []
        for front in fronts:
            _crowding(front)
            front.sort(key=lambda x: (-x.rank, -x.crowd))
            for ind in front:
                if len(new_pop) < population_size:
                    new_pop.append(ind)
        return new_pop

    for _ in range(generations):
        pop = _step(pop)

    return pop",alpha_factory_v1/demos/alpha_agi_insight_v1/src/simulation/mats.py,,1,7.194132978569833e-09,"The method `run_evolution` is a well-structured implementation of the NSGA-II algorithm, which is a popular multi-objective optimization technique. It includes key components such as population initialization, selection, crossover, mutation, and non-dominated sorting, which are essential for evolutionary algorithms. The method is likely to be useful for users interested in evolutionary computation and optimization problems. Additionally, the use of type hints and a clear docstring enhances its usability and maintainability. Therefore, it is likely to be retained in the codebase."
survived,"def run_loop(
    *,
    cost_budget: float | None = None,
    wallclock: float | None = None,
    cost_per_cycle: float = 1.0,
    state_file: str = ""loop_state.json"",
    revive_rate: int = 0,
    agents: dict[str, bool] | None = None,
    rng: random.Random | None = None,
    gains: list[float] | None = None,
    early_stopper: BanditEarlyStopper | None = None,
) -> Result:
    """"""Run the FSM until budgets are exhausted.

    Args:
        cost_budget: Optional cost limit.
        wallclock: Optional wall-clock limit in seconds.
        cost_per_cycle: Cost incurred per complete cycle.
        state_file: Path used when persisting state on ``KeyboardInterrupt``.
        revive_rate: Attempt revival every ``revive_rate`` cycles (0 disables).
        agents: Mapping of agent names to active state.
        rng: Random generator for deterministic tests.

    Returns:
        :class:`Result` with final state, completed cycles, cost spent and
        the number of agents revived.
    """"""

    state = State.SELECT
    cycles = 0
    cost_spent = 0.0
    start = time.time()
    rng = rng or random.Random()
    agents = agents or {}
    revive_count = 0

    gain_iter = iter(gains or [])

    try:
        while True:
            if state is State.SELECT:
                state = State.SELF_MOD
                continue
            if state is State.SELF_MOD:
                state = State.BENCHMARK
                continue
            if state is State.BENCHMARK:
                cost_spent += cost_per_cycle
                gain = next(gain_iter, 0.0)
                if early_stopper and early_stopper.update(cost_per_cycle, gain):
                    break
                state = State.ARCHIVE
                continue
            if state is State.ARCHIVE:
                cycles += 1
                if revive_rate and cycles % revive_rate == 0:
                    inactive = [a for a, active in agents.items() if not active]
                    if inactive:
                        revived = rng.choice(inactive)
                        agents[revived] = True
                        revive_count += 1
                        metrics.dgm_revives_total.inc()
                        state = State.SELF_MOD
                        continue
                state = State.SELECT
                if cost_budget is not None and cost_spent >= cost_budget:
                    break
                if wallclock is not None and time.time() - start >= wallclock:
                    break
    except KeyboardInterrupt:  # pragma: no cover - interactive
        Path(state_file).write_text(json.dumps({""state"": state.name, ""cycles"": cycles, ""cost"": cost_spent}))
        return Result(state=state, cycles=cycles, cost=cost_spent, revives=revive_count)

    return Result(state=state, cycles=cycles, cost=cost_spent, revives=revive_count)",alpha_factory_v1/core/simulation/loop.py,,1,2.646573631904765e-09,"The method 'run_loop' is a well-structured function that implements a finite state machine (FSM) to manage a loop with various states and conditions. It includes handling for cost and time budgets, agent revival, and early stopping, which are useful features for iterative processes. The function is also robust with exception handling for keyboard interrupts, allowing it to save its state. These features make it versatile and useful in scenarios where resource management and process control are needed. Therefore, it is likely to be retained in the codebase."
survived,"def configure() -> None:
    """"""Initialise tracing and metrics if the SDK is installed.""""""
    global tracer, meter
    if trace is None or metrics is None:
        return

    endpoint = os.getenv(""OTEL_EXPORTER_OTLP_ENDPOINT"")
    if endpoint:
        span_exporter = OTLPSpanExporter(endpoint=endpoint)
        metric_exporter = OTLPMetricExporter(endpoint=endpoint)
    else:
        span_exporter = ConsoleSpanExporter()
        metric_exporter = ConsoleMetricExporter()

    resource = Resource.create({""service.name"": ""alpha-insight""})
    provider = TracerProvider(resource=resource)
    provider.add_span_processor(BatchSpanProcessor(span_exporter))
    trace.set_tracer_provider(provider)
    tracer = trace.get_tracer(""alpha_insight"")

    meter_provider = MeterProvider(
        resource=resource,
        metric_readers=[PeriodicExportingMetricReader(metric_exporter)],
    )
    metrics.set_meter_provider(meter_provider)
    meter = metrics.get_meter(""alpha_insight"")
",alpha_factory_v1/core/utils/tracing.py,,1,7.194132978569833e-09,"The method 'configure' is responsible for setting up tracing and metrics, which are crucial for monitoring and debugging applications. It checks for the presence of an endpoint and configures exporters accordingly, ensuring flexibility in deployment environments. This functionality is essential for observability in modern software systems, making it unlikely to be removed."
survived,"def test_workbox_replaced():
    path = pathlib.Path(""alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/lib/workbox-sw.js"")
    data = path.read_text(errors=""ignore"")
    assert ""Placeholder"" not in data",tests/test_assets_replaced.py,,1,1.0467401685178159e-08,"The method `test_workbox_replaced` is a simple test function that checks if the string ""Placeholder"" is not present in the contents of a specific JavaScript file. This is a straightforward and useful test to ensure that a placeholder text has been replaced with actual content in the file. Such tests are common in development to verify that certain changes have been made to files, especially in build or deployment processes. Therefore, it is likely to be retained as part of the test suite to ensure code quality and correctness."
survived,"  def __len__(self) -> int:
    """"""Return the number of sites on this carrier.""""""
    return len(self.sites)
",pylabrobot/resources/carrier.py,Carrier,1,7.194132978569833e-09,"The method `__len__` is a standard Python special method used to define the behavior of the `len()` function for instances of a class. It is implemented correctly here to return the length of the `sites` attribute, which is presumably a list or similar collection. This is a common and useful method for classes that manage collections, allowing users to easily determine the number of items. Therefore, it is unlikely to be deleted as it provides essential functionality."
survived,"def test_non_dict_returns_zero() -> None:
    _reset_ledger()
    value = eb.reward(None, None, ""bad"")
    assert value == 0.0",tests/test_energy_balance_reward.py,,1,1.0467401685178159e-08,"The method `test_non_dict_returns_zero` is a unit test that checks the behavior of the `reward` function when it is passed invalid arguments. It ensures that the function returns 0.0 when given non-dictionary inputs. This is a useful test case to ensure the robustness of the `reward` function against invalid input types. Such tests are crucial for maintaining code quality and preventing future bugs, especially in systems that handle various input types. Therefore, this method is likely to be retained as part of the test suite."
survived,"def test_duplicate_request_id_zero() -> None:
    _reset()
    res = {""request_id"": ""r3"", ""violation"": False}
    sc.reward(None, None, res)
    assert sc.reward(None, None, res) == 0.0",tests/test_safety_compliance_reward.py,,1,9.931195248674785e-08,"The method `test_duplicate_request_id_zero` is a test function that seems to be checking the behavior of a system when a duplicate request ID is processed. It uses a function `sc.reward` to process a response and expects a specific outcome (0.0) when the same response is processed again. This kind of test is useful for ensuring that the system handles duplicate requests correctly, which is a common requirement in many systems to prevent double processing or rewards. Therefore, this method is likely to be retained as it serves a specific purpose in testing the system's robustness against duplicate requests."
survived,"    def start_merkle_task(self, *a, **kw) -> None:  # pragma: no cover - dummy
        pass
",tests/test_safety_guardian_property.py,DummyLedger,0,0.9999999918479795,"The method `start_merkle_task` is a placeholder or a dummy method, as indicated by the comment `# pragma: no cover - dummy`. This suggests that the method is not currently implemented and is not intended to be covered by tests. Such methods are often used as placeholders for future implementation or to satisfy an interface requirement temporarily. However, without any implementation or indication of future use, it is likely to be removed in future code clean-ups unless it is explicitly planned to be implemented later. Therefore, the method is more likely to be deleted."
survived,"def main():
    a = int(input())
    b = int(input())
    print(a + b)
",tests/rosetta/out/Python/a+b.py,,1,8.31527990378713e-07,"The method is a simple implementation of a function that takes two integer inputs from the user and prints their sum. This is a basic example of input/output operations in Python and serves as a fundamental learning exercise for beginners. Such methods are often used in educational contexts to teach basic programming concepts. Therefore, it is likely to be retained as a useful example for learning purposes."
survived,"    def model_check_fn(self, model: Any) -> bool:
        """"""Check that the model is a causal language model.""""""
        return is_causal_lm(model)
",src/pruna/algorithms/quantization/llm_compressor.py,LLMCompressorQuantizer,1,1.3440409770490404e-08,"The method `model_check_fn` is a simple utility function that checks if a given model is a causal language model using the `is_causal_lm` function. This type of function is often useful in codebases where different types of models need to be validated or filtered based on their characteristics. Since it serves a clear purpose and is likely to be used in various parts of a codebase dealing with model validation, it is more likely to be retained rather than deleted."
survived,"def _timeline_df(traj: list[Any]) -> ""pd.DataFrame"":
    """"""Convert trajectory data into a pandas DataFrame.""""""
    import pandas as pd

    rows = []
    for point in traj:
        for sec in point.sectors:
            rows.append(
                {
                    ""year"": point.year,
                    ""sector"": sec.name,
                    ""energy"": sec.energy,
                    ""disrupted"": sec.disrupted,
                }
            )
    return pd.DataFrame(rows)
",src/interface/minimal_ui.py,,1,5.211412485172657e-10,"The method `_timeline_df` is likely to survive because it performs a useful and specific function: converting a list of trajectory data into a pandas DataFrame. This is a common task in data processing and analysis, and the method is implemented in a straightforward and efficient manner. It uses a nested loop to iterate over the trajectory data and extract relevant information, which is then used to construct a DataFrame. The use of pandas, a widely-used library for data manipulation, further supports the method's utility and relevance. Additionally, the method is well-documented with a docstring, enhancing its maintainability and readability."
survived,"    def _fake_run(*_a, **_k):
        return subprocess.CompletedProcess([], 0, """", """")
",tests/test_check_env_network.py,,1,8.31527990378713e-07,"The method _fake_run is a mock function that returns a subprocess.CompletedProcess object with default values. It is likely used for testing purposes to simulate the behavior of a subprocess call without actually executing any command. Such mock functions are common in testing environments to ensure code can be tested without side effects. Therefore, it is likely to be retained for testing purposes."
survived,"    def test_stream_rate_env_controls_interval(self) -> None:
        os.environ[""STREAM_RATE_HZ""] = ""5""

        async def grab_two() -> float:
            gen = demo.experience_stream()
            t1 = time.perf_counter()
            await anext(gen)
            t2 = time.perf_counter()
            await anext(gen)
            t3 = time.perf_counter()
            return (t2 - t1 + t3 - t2) / 2

        avg = asyncio.run(grab_two())
        del os.environ[""STREAM_RATE_HZ""]
        self.assertLess(avg, 0.4)
        self.assertGreater(avg, 0.1)
",tests/test_era_experience.py,TestEraOfExperience,1,3.653482080241728e-08,"The method `test_stream_rate_env_controls_interval` is a unit test designed to verify the behavior of a system under specific conditions. It sets an environment variable, runs an asynchronous function to measure time intervals, and asserts that the average interval falls within a specified range. This is a typical pattern for testing code behavior and performance, especially in systems where timing and rate control are important. Such tests are crucial for ensuring the reliability and correctness of the system, particularly in environments where timing is critical. Therefore, it is unlikely to be deleted as it serves a valuable purpose in maintaining code quality."
survived,"    def test_agentbase_alias(self):
        legacy = importlib.import_module(""backend.agent_base"").AgentBase
        canonical = importlib.import_module(""backend.agents.base"").AgentBase
        self.assertIs(legacy, canonical)
",tests/test_agents_alias.py,TestAgentsAlias,1,4.6911638017642294e-08,"The method `test_agentbase_alias` is testing whether two imports of `AgentBase` from different module paths refer to the same object. This kind of test is useful to ensure backward compatibility when refactoring or reorganizing code, especially if the module structure has changed but the functionality should remain consistent. Such tests are important for maintaining the integrity of the codebase during refactoring, ensuring that legacy code paths still function as expected. Therefore, this method is likely to be retained as it serves a critical role in verifying the consistency and correctness of the codebase after changes."
survived,"def _env_int(name: str, default: int) -> int:
    try:
        return int(os.getenv(name, default))
    except (TypeError, ValueError):
        return default
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/config.py,,1,1.8189616842444243e-09,"The method `_env_int` is a utility function that attempts to retrieve an environment variable by name and convert it to an integer, returning a default value if the environment variable is not set or cannot be converted to an integer. This is a common pattern in software development for handling configuration values that may be set via environment variables. The function is robust, handling both `TypeError` and `ValueError` exceptions, which makes it reliable for its intended purpose. Such utility functions are often retained in codebases because they encapsulate common operations in a reusable way. Therefore, it is likely to survive."
survived,"def test_simulate_years() -> None:
    secs = [sector.Sector(""x"", 1.0, 1.0)]
    results = forecast.simulate_years(secs, 2)
    assert len(results) == 2",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_forecast.py,,1,1.522997951276035e-08,"The method 'test_simulate_years' is a unit test function that checks the functionality of the 'simulate_years' method from the 'forecast' module. It creates a list of sectors and simulates them over 2 years, asserting that the length of the results is 2. This is a straightforward and useful test to ensure that the 'simulate_years' function behaves as expected. Unit tests are crucial for maintaining code quality and catching regressions, so this method is likely to be retained as part of the test suite."
survived,"    async def run_cycle(self) -> None:
        await self.emit(""research"", {""plan"": ""collect data""})
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/planning_agent.py,PlanningAgent,1,1.955568070542584e-08,"The method 'run_cycle' is an asynchronous function that emits an event with a specific message. This kind of method is often used in event-driven or asynchronous programming to handle tasks like data collection, logging, or triggering other processes. The method is simple, but it serves a clear purpose in the context of an event-driven architecture. Therefore, it is likely to be retained as it provides a useful functionality in such systems."
survived,"def setup(level: str = ""INFO"") -> None:
    if not logging.getLogger().handlers:
        logging.basicConfig(
            level=level,
            format=""%(asctime)s %(levelname)s %(name)s | %(message)s"",
            datefmt=""%Y-%m-%d %H:%M:%S"",
        )",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/logging.py,,1,2.646573631904765e-09,"The method 'setup' is a utility function for configuring logging in a Python application. It checks if there are no handlers already set up for the root logger and then configures the logging with a specified level and format. This is a common pattern used to ensure that logging is set up correctly and only once, preventing duplicate log entries. Such utility functions are often retained in codebases because they provide essential functionality for debugging and monitoring applications. Therefore, it is likely to survive."
survived,"    async def run_cycle(self) -> None:  # pragma: no cover - interface
        raise NotImplementedError",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/base_agent.py,BaseAgent,1,5.715002851580502e-07,"The method `run_cycle` is marked with `# pragma: no cover`, indicating that it is intentionally not covered by tests, which is common for abstract methods or interfaces. The method raises a `NotImplementedError`, suggesting that it is meant to be overridden by subclasses. This pattern is typical in abstract base classes where the method serves as a placeholder for concrete implementations in derived classes. Therefore, it is unlikely to be deleted as it serves a purpose in defining an interface."
survived,"def nsga2_step(pop: Population, fn: Callable[[List[float]], Tuple[float, float]], mu: int = 20) -> Population:
    evaluate(pop, fn)
    offspring: Population = []
    while len(offspring) < mu:
        a, b = random.sample(pop, 2)
        cut = random.randint(1, len(a.genome) - 1)
        child_genome = a.genome[:cut] + b.genome[cut:]
        if random.random() < 0.1:
            idx = random.randrange(len(child_genome))
            child_genome[idx] += random.uniform(-1, 1)
        offspring.append(Individual(child_genome))
    evaluate(offspring, fn)
    union = pop + offspring
    fronts = _non_dominated_sort(union)
    new_pop: Population = []
    for front in fronts:
        _crowding(front)
        front.sort(key=lambda x: (-x.rank, -x.crowd))
        for ind in front:
            if len(new_pop) < mu:
                new_pop.append(ind)
    return new_pop",alpha_factory_v1/demos/alpha_agi_insight_v1/src/simulation/mats.py,,1,1.8553915987649156e-07,"The method implements a step of the NSGA-II algorithm, which is a well-known and widely used multi-objective optimization algorithm. The code appears to be complete and functional, performing key operations such as selection, crossover, mutation, and non-dominated sorting. These are essential components of the NSGA-II algorithm. Given its completeness and the fact that NSGA-II is a standard algorithm in evolutionary computation, it is unlikely that this method would be deleted unless there is a significant change in the algorithmic approach or a shift to a different optimization method."
survived,"def test_jax_llh(benchmark_problem):
    jax.config.update(""jax_enable_x64"", True)
    from beartype import beartype

    problem_id, flat_petab_problem, petab_problem, amici_model = (
        benchmark_problem
    )

    amici_solver = amici_model.getSolver()
    cur_settings = settings[problem_id]
    amici_solver.setAbsoluteTolerance(1e-8)
    amici_solver.setRelativeTolerance(1e-8)
    amici_solver.setMaxSteps(10_000)

    simulate_amici = partial(
        simulate_petab,
        petab_problem=flat_petab_problem,
        amici_model=amici_model,
        solver=amici_solver,
        scaled_parameters=True,
        scaled_gradients=True,
        log_level=logging.DEBUG,
    )

    np.random.seed(cur_settings.rng_seed)

    problem_parameters = None
    if problem_id in problems_for_gradient_check:
        point = flat_petab_problem.x_nominal_free_scaled
        for _ in range(20):
            amici_solver.setSensitivityMethod(amici.SensitivityMethod.adjoint)
            amici_solver.setSensitivityOrder(amici.SensitivityOrder.first)
            amici_model.setSteadyStateSensitivityMode(
                cur_settings.ss_sensitivity_mode
            )
            point_noise = (
                np.random.randn(len(point)) * cur_settings.noise_level
            )
            point += point_noise  # avoid small gradients at nominal value

            problem_parameters = dict(
                zip(flat_petab_problem.x_free_ids, point)
            )

            r_amici = simulate_amici(
                problem_parameters=problem_parameters,
            )
            if np.isfinite(r_amici[LLH]):
                break
        else:
            raise RuntimeError(""Could not compute expected derivative."")
    else:
        r_amici = simulate_amici()
    llh_amici = r_amici[LLH]

    jax_model = import_petab_problem(
        petab_problem,
        model_output_dir=benchmark_outdir / (problem_id + ""_jax""),
        jax=True,
    )
    jax_problem = JAXProblem(jax_model, petab_problem)
    if problem_parameters:
        jax_problem = eqx.tree_at(
            lambda x: x.parameters,
            jax_problem,
            jnp.array(
                [problem_parameters[pid] for pid in jax_problem.parameter_ids]
            ),
        )

    if problem_id in problems_for_gradient_check:
        beartype(run_simulations)(jax_problem)
        (llh_jax, _), sllh_jax = eqx.filter_value_and_grad(
            run_simulations, has_aux=True
        )(jax_problem)
    else:
        llh_jax, _ = beartype(run_simulations)(jax_problem)

    np.testing.assert_allclose(
        llh_jax,
        llh_amici,
        rtol=1e-3,
        atol=1e-3,
        err_msg=f""LLH mismatch for {problem_id}"",
    )

    if problem_id in problems_for_gradient_check:
        sllh_amici = r_amici[SLLH]
        np.testing.assert_allclose(
            sllh_jax.parameters,
            np.array([sllh_amici[pid] for pid in jax_problem.parameter_ids]),
            rtol=1e-2,
            atol=1e-2,
            err_msg=f""SLLH mismatch for {problem_id}, {dict(zip(jax_problem.parameter_ids, sllh_jax.parameters))}"",
        )",tests/benchmark-models/test_petab_benchmark_jax.py,,1,2.1024340680345882e-07,"The method `test_jax_llh` is a test function designed to compare the log-likelihood (LLH) and its gradient (SLLH) computed by two different simulation frameworks: AMICI and JAX. It is a specialized function used for validating the consistency and accuracy of these computations in a benchmarking context. Such test functions are crucial for ensuring the reliability of scientific computations and are typically retained as part of a test suite. Therefore, it is unlikely to be deleted unless the entire testing framework or the specific comparison it performs becomes obsolete."
survived,"    async def process_message(
        message: Message, tempdir: Path | None = None, tagged: bool = True
    ) -> tuple[str, list[Path | str]]:
        """"""
        Process a single message and return model input.
        """"""
        model_input = """"
        files: list[Path | str] = []
        if isinstance(message.content, str):
            # Pure text content
            model_input = message.content
        else:
            # Mixed content
            # TODO: Use Pydantic to enforce the value checking
            for item in message.content:
                if item.type == ""text"":
                    model_input = item.text or """"

                elif item.type == ""image_url"":
                    if not item.image_url:
                        raise ValueError(""Image URL cannot be empty"")
                    if url := item.image_url.get(""url"", None):
                        files.append(await save_url_to_tempfile(url, tempdir))
                    else:
                        raise ValueError(""Image URL must contain 'url' key"")

                elif item.type == ""file"":
                    if not item.file:
                        raise ValueError(""File cannot be empty"")
                    if file_data := item.file.get(""file_data"", None):
                        filename = item.file.get(""filename"", """")
                        files.append(await save_file_to_tempfile(file_data, filename, tempdir))
                    else:
                        raise ValueError(""File must contain 'file_data' key"")

        # Add role tag if needed
        if model_input and tagged:
            model_input = add_tag(message.role, model_input)

        return model_input, files
",app/services/client.py,GeminiClientWrapper,1,2.4616969512093895e-10,"The method 'process_message' is well-structured and serves a clear purpose of processing a message to extract model input and associated files. It handles different types of content (text, image URLs, and files) and includes error handling for missing data. The use of asynchronous operations for file handling is appropriate for potentially I/O-bound tasks. Additionally, the method includes a TODO comment indicating future improvements with Pydantic for value checking, suggesting ongoing maintenance and enhancement. These factors indicate that the method is useful, functional, and likely to be retained in the codebase."
survived,"    def get_player_location_global(self):
        '''
        get_player_location_global
        '''
        scale_factor = self.cfg.localize_downscale_factor
        # Downscale both template and search image
        img_roi = self.img_frame_gray[self.cfg.camera_ceiling:self.cfg.camera_floor, :]
        img_query = cv2.resize(img_roi, (0, 0), fx=scale_factor, fy=scale_factor)

        # Get previous frame result
        if self.is_first_frame or \
            time.time() - self.t_last_camera_missed > self.cfg.localize_cached_interval:
            last_result = None
            self.t_last_camera_missed = time.time()
        else:
            last_result = (
                int(self.loc_camera[0] * scale_factor),
                int(self.loc_camera[1] * scale_factor)
            )

        loc_camera, score, is_cached = find_pattern_sqdiff(
            self.img_map_resized,
            img_query,
            last_result=last_result,
            local_search_radius=20,
            global_threshold = 0.8)
        self.loc_camera = (
            int(loc_camera[0] / scale_factor),
            int(loc_camera[1] / scale_factor)
        )
        loc_player_global = (
            self.loc_camera[0] + self.loc_player[0],
            self.loc_camera[1] + self.loc_player[1] - self.cfg.camera_ceiling)

        # Draw camera rectangle
        camera_bottom_right = (
            self.loc_camera[0] + self.img_frame.shape[1],
            self.loc_camera[1] + self.img_frame.shape[0]
        )
        cv2.rectangle(self.img_route_debug, self.loc_camera,
                      camera_bottom_right, (0, 255, 255), 2)
        cv2.putText(
            self.img_route_debug,
            f""Camera, score={round(score, 2)}, {'cached' if is_cached else 'missed'}"",
            (self.loc_camera[0], self.loc_camera[1] + 60),
            cv2.FONT_HERSHEY_SIMPLEX, 2,
            (0, 255, 0), 2
        )

        # Draw player center
        cv2.circle(self.img_route_debug,
                   loc_player_global, radius=3,
                   color=(0, 0, 255), thickness=-1)
        cv2.putText(self.img_route_debug, ""Player"",
                    (loc_player_global[0] - 30, loc_player_global[1] - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)

        return loc_player_global
",src/legacy/mapleStoryAutoLevelUp_legacy.py,MapleStoryBot,1,3.850741907939403e-09,"The method `get_player_location_global` is likely to survive because it performs a specific and useful function within the code. It calculates the global location of a player by processing image data, which is a common requirement in applications involving computer vision and tracking. The method includes image resizing, pattern matching, and drawing on images, which are essential operations for visual tracking systems. Additionally, the method is well-structured, with clear steps and comments explaining its purpose, making it maintainable and understandable for future use."
survived,"    def capture_frame(self):
        '''
        æ•æ‰ç•¶å‰éŠæˆ²å€åŸŸç•«é¢
        '''
        img = self.capture.grab(self.region)
        frame = np.array(img)
        with self.lock:
            self.frame = frame
",src/input/GameWindowCapturorForMac.py,GameWindowCapturor,1,1.8189616842444243e-09,"The method 'capture_frame' is likely to survive because it performs a specific and useful function within a program, capturing the current game area screen. This functionality is essential for applications that require real-time screen capture, such as game streaming, monitoring, or analysis tools. The method is also well-structured, using a lock to ensure thread safety when updating the frame, which indicates good programming practices."
survived,"def _build_local_site(repo_root: Path) -> bool:
    script = repo_root / ""scripts"" / ""build_gallery_site.sh""
    if not script.is_file():
        return False
    try:
        subprocess.run([str(script)], check=True)
    except Exception:
        return False
    return True
",scripts/open_subdir_demo.py,,1,1.2501528648238603e-09,"The method `_build_local_site` is a utility function that checks for the existence of a specific script file and attempts to execute it. This kind of function is useful for automating build processes or setting up environments, which are common tasks in software development. The function is simple, performs a clear task, and handles exceptions, making it robust for its intended purpose. Such utility functions are often retained in codebases as they encapsulate specific, reusable logic that can be used in various parts of a project."
survived,"        def __init__(self, *a, llm=None, **_k) -> None:
            self.llm = llm
",tests/test_aiga_openai_bridge_offline.py,DummyEvolver,1,5.043472052266442e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming in Python. Constructors are essential for initializing new objects and setting initial values for instance variables. The presence of the 'llm' parameter suggests that this constructor is designed to initialize an object with a specific attribute, which is likely important for the class's functionality. Therefore, it is unlikely that this method will be deleted as it serves a critical role in the class's operation."
survived,"        def run_generations(self, *_a):
            pass
",tests/test_aiga_openai_bridge_offline.py,_DummyEvolver,0,0.9999992661791398,"The method 'run_generations' is defined but not implemented, as it only contains a 'pass' statement. This suggests that it is a placeholder for future code or is meant to be overridden in a subclass. If it is not overridden or implemented elsewhere, it is likely to be deleted in the future as it serves no functional purpose in its current state."
survived,"    def start_merkle_task(self, *_a, **_kw) -> None:  # pragma: no cover - test stub
        pass
",tests/test_alert_webhook.py,DummyLedger,1,4.944450477491054e-09,"The method 'start_merkle_task' is currently a placeholder with no implementation, as indicated by the 'pass' statement. The comment '# pragma: no cover - test stub' suggests that this method is intended for future development or testing purposes. Since it is marked as a test stub, it is likely that the method is planned to be implemented or used in the future, rather than being deleted. Therefore, it is more likely to survive."
survived,"    async def stop_merkle_task(self) -> None:  # pragma: no cover - test stub
        pass
",tests/test_alert_webhook.py,DummyLedger,1,5.8291276786344415e-05,"The method `stop_merkle_task` is an asynchronous function that currently does nothing (indicated by the `pass` statement). It is marked with `# pragma: no cover`, suggesting that it is a placeholder or a stub for future implementation. The presence of this comment indicates that the method is intentionally left unimplemented for now, possibly because it is part of a larger system where the functionality is yet to be defined or tested. Since it is a stub, it is likely to be implemented in the future rather than deleted, as it might be part of a planned feature or functionality."
survived,"    def test_rect2rect_mtx(self):
        src = (0, 0, 1, 1)
        dst = (0, 0, 2, 2)
        M = common.rect2rect_mtx(src, dst)
        expected = np.array([[2.0, 0.0, 0.0],
                             [0.0, 2.0, 0.0],
                             [0.0, 0.0, 1.0]])
        np.testing.assert_array_almost_equal(M, expected)
",tests/test_common.py,TestCommonFunctions,1,1.6052280526088547e-09,"The method 'test_rect2rect_mtx' is a unit test for the function 'rect2rect_mtx'. Unit tests are crucial for ensuring the correctness of code, especially in mathematical transformations like this one. The test checks if the transformation matrix 'M' produced by 'rect2rect_mtx' correctly scales a rectangle from 'src' to 'dst'. Since testing is a fundamental part of software development to maintain code quality and prevent regressions, this method is likely to be retained."
survived,"def test_post_new_env(non_network: None) -> None:
    """"""Force a new environment via /command.""""""
    os.environ[""NO_LLM""] = ""1""
    os.environ.setdefault(""ALPHA_ASI_SILENT"", ""1"")
    os.environ.setdefault(""ALPHA_ASI_MAX_STEPS"", ""1"")

    mod = importlib.import_module(
        ""alpha_factory_v1.demos.alpha_asi_world_model.alpha_asi_world_model_demo""
    )
    client = TestClient(cast(Any, mod.app))

    resp = client.post(""/command"", json={""cmd"": ""new_env""})
    assert resp.status_code == 200
    assert resp.json() == {""ok"": True}",tests/test_world_model_demo.py,,1,6.69158608681505e-10,"The method 'test_post_new_env' is a test function that verifies the functionality of a specific endpoint ('/command') in a web application. It sets up environment variables, imports a module, creates a test client, and sends a POST request to the endpoint, checking for a successful response. This is a typical structure for a unit test in web applications, especially when using frameworks like FastAPI or Flask. Such test functions are crucial for ensuring that the application behaves as expected and are unlikely to be deleted unless the functionality they test is removed or significantly altered. Therefore, the method is likely to survive."
survived,"def eval(code: str) -> str:
    """"""Evaluate Mochi source using a Go subprocess and return output.""""""
    here = os.path.dirname(__file__)
    eval_src = os.path.join(here, ""runner"", ""main.go"")
    env = os.environ.copy()
    env[""MOCHI_CODE""] = code
    proc = subprocess.run(
        [""go"", ""run"", eval_src], capture_output=True, text=True, env=env
    )
    if proc.returncode != 0:
        raise RuntimeError(f""go run failed: {proc.stderr}"")
    result = json.loads(proc.stdout)
    if ""error"" in result and result[""error""]:
        raise RuntimeError(result[""error""])
    return result.get(""output"", """")
",tools/libmochi/python/libmochi.py,,0,0.999998629043345,"The method is likely to be deleted because it relies on executing a Go subprocess to evaluate code, which can be inefficient and insecure. Running subprocesses can introduce security vulnerabilities, especially if the input is not properly sanitized. Additionally, the method uses a specific setup with a Go script, which may not be portable or maintainable in the long term. Modern software practices often favor more integrated and secure ways to evaluate code, such as using libraries or APIs that do not require spawning subprocesses."
survived,"def test_generate_mock(monkeypatch: pytest.MonkeyPatch) -> None:
    import alpha_factory_v1.demos.gpt2_small_cli.gpt2_cli as mod

    class FakeTokenizer:
        eos_token_id = 0

        def __init__(self, *args: object, **kwargs: object) -> None:
            pass

        def __call__(self, text: str, return_tensors: str = ""pt"") -> dict[str, list[int]]:
            return {""input_ids"": [0]}

        def decode(self, ids: list[int], skip_special_tokens: bool = True) -> str:
            return ""output""

    class FakeModel:
        @classmethod
        def from_pretrained(cls, name: str) -> ""FakeModel"":
            return cls()

        def generate(self, **kwargs: object) -> list[list[int]]:
            return [[0]]

    monkeypatch.setattr(""transformers.AutoTokenizer"", FakeTokenizer, raising=False)
    monkeypatch.setattr(""transformers.AutoModelForCausalLM"", FakeModel, raising=False)

    result = mod.generate(""hi"", 5)
    assert result == ""output""",tests/test_gpt2_cli_demo.py,,1,3.653482080241728e-08,"The method 'test_generate_mock' is a unit test that uses the 'monkeypatch' fixture from pytest to replace parts of the 'transformers' library with fake classes. This is a common practice in testing to isolate the code being tested from external dependencies, ensuring that the test is not affected by changes in the external library or network issues. The method is well-structured, serves a clear purpose in testing the 'generate' function from the 'gpt2_cli' module, and does not have any apparent issues that would necessitate its removal. Therefore, it is likely to be retained in the codebase."
survived,"def convert(src: Path, dest: Path | None = None) -> None:
    dest = dest or src
    try:
        from transformers.models.gpt2.convert_gpt2_original_tf_checkpoint_to_pytorch import (
            convert_gpt2_checkpoint_to_pytorch,
        )
    except Exception as exc:  # pragma: no cover
        raise SystemExit(f""transformers with PyTorch is required: {exc}"")

    ckpt = src / ""model.ckpt""
    config = src / ""hparams.json""
    convert_gpt2_checkpoint_to_pytorch(str(ckpt), str(config), str(dest))
",scripts/convert_openai_gpt2.py,,1,2.0611536181902033e-09,"The method 'convert' is likely to survive because it performs a specific and useful function: converting a GPT-2 model checkpoint from TensorFlow to PyTorch format. This is a common requirement for users who want to leverage the capabilities of the PyTorch library with models originally trained in TensorFlow. The method handles potential import errors gracefully and provides a clear error message, which is good practice. Additionally, the use of type hints and default parameters makes the function flexible and user-friendly. Unless there are changes in the libraries or a shift in the preferred method of conversion, this function is likely to remain relevant."
survived,"def main() -> None:
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument(""src"", type=Path, help=""Directory containing the OpenAI checkpoint"")
    parser.add_argument(""dest"", nargs=""?"", type=Path, help=""Output directory (defaults to src)"")
    args = parser.parse_args()
    convert(args.src, args.dest)
",scripts/convert_openai_gpt2.py,,1,3.850741907939403e-09,"The method 'main' is a typical entry point for a Python script that uses the argparse library to handle command-line arguments. It is a common and standard practice to define a 'main' function in scripts to encapsulate the main logic of the program. This method is likely to survive because it is essential for the script's functionality, providing a clear structure for argument parsing and subsequent processing. There is no indication that this method is redundant or unnecessary, and it follows a conventional pattern that is widely used in Python programming."
survived,"    def test_missing_readme_fails(self) -> None:
        with tempfile.TemporaryDirectory() as tmp:
            d = os.path.join(tmp, ""demo_missing"")
            os.mkdir(d)
            open(os.path.join(d, ""__init__.py""), ""w"").close()
            exit_code = validate_demos.main(tmp, min_lines=1)
            self.assertEqual(exit_code, 1)
",tests/test_demo_quality.py,TestValidateDemosFailures,1,2.0611536181902033e-09,"The method 'test_missing_readme_fails' is a unit test designed to ensure that a specific condition (a missing README file) results in a failure (exit code 1) when the 'validate_demos.main' function is called. This is a typical test case to verify the behavior of a function under certain conditions. Such tests are crucial for maintaining code quality and ensuring that the software behaves as expected. Therefore, it is unlikely that this method will be deleted as it serves an important role in the testing suite."
survived,"    def test_ob_early_data(self):
        """"""Ensure early candles do not cause index errors in OB calculation.""""""
        short_df = pd.DataFrame(
            {
                ""open"": [1.0, 1.1, 1.2],
                ""high"": [1.05, 1.15, 1.25],
                ""low"": [0.95, 1.05, 1.15],
                ""close"": [1.02, 1.14, 1.24],
                ""volume"": [5, 6, 7],
            }
        )
        swing = smc.swing_highs_lows(short_df, swing_length=1)
        ob_df = smc.ob(short_df, swing)
        self.assertEqual(len(ob_df), len(short_df))
",tests/unit_tests.py,TestSmartMoneyConcepts,1,6.348800075736417e-09,"The method 'test_ob_early_data' is a unit test designed to ensure that early data points in a DataFrame do not cause index errors when calculating order blocks (OB) using a specific function. Unit tests are crucial for maintaining code quality and ensuring that functions behave as expected, especially when dealing with edge cases or potential errors. Since this test is part of a testing suite, it is likely to be retained to ensure the robustness of the OB calculation function. Therefore, the method will survive."
survived,"def view_lines(path: str | Path, start: int, end: Optional[int]) -> str:
    """"""Return lines ``start`` through ``end`` (1-indexed, inclusive).""""""
    s = max(0, start - 1)
    return view(path, s, end)
",src/self_edit/tools.py,,1,1.3440409770490404e-08,"The method 'view_lines' is a utility function that provides a specific functionality of returning lines from a file between given start and end indices. It is a simple and clear implementation that leverages another function 'view' to perform its task. The method is likely to be useful in contexts where file line extraction is needed, and it is implemented in a straightforward manner without any apparent issues. Therefore, it is likely to be retained in the codebase."
survived,"def main() -> None:
    arch = HashArchive(""audit.db"")
    success = 0
    with tempfile.TemporaryDirectory() as tmp:
        for i in range(100):
            f = Path(tmp) / f""agent_{i}.tar""
            f.write_text(str(i), encoding=""utf-8"")
            cid = arch.add_tarball(f)
            if cid:
                success += 1
    root = arch.merkle_root()
    print(f""merkle_root={root}"")
    rate = success / 100
    print(f""pin_rate={rate:.2%}"")
    if root != EXPECTED_ROOT:
        raise SystemExit(""unexpected merkle root"")
    if rate < 0.99:
        raise SystemExit(""pin success below threshold"")
",scripts/audit_archive.py,,1,2.646573631904765e-09,"The method is likely to survive because it appears to be a well-structured and functional piece of code. It performs a series of operations to add tarball files to a hash archive, calculates a Merkle root, and checks the success rate of these operations. The code includes error handling by raising a SystemExit if the Merkle root is unexpected or if the success rate is below a certain threshold. These features suggest that the method is complete and serves a specific purpose, making it unlikely to be deleted unless the entire functionality is no longer needed."
survived,"def archive() -> None:
    """"""Manage archived agent tarballs.""""""
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/cli.py,,0,0.9999999865595903,"The method 'archive' is defined with a docstring but lacks any implementation. Methods that are not implemented and do not provide any functionality are often considered incomplete or placeholders. Without further context or usage, such methods are typically candidates for deletion unless they are intended to be implemented in the future. However, given the current state, it is more likely to be deleted."
survived,"def tesla_checksum(address: int, sig, d: bytearray) -> int:
  checksum = (address & 0xFF) + ((address >> 8) & 0xFF)
  checksum_byte = sig.start_bit // 8
  for i in range(len(d)):
    if i != checksum_byte:
      checksum += d[i]
  return checksum & 0xFF",opendbc/car/tesla/teslacan.py,,1,1.522997951276035e-08,"The method 'tesla_checksum' is a utility function that calculates a checksum for a given address and data. It is a simple and efficient implementation that is likely used in a larger system for data integrity verification. Such utility functions are generally useful and reusable in various contexts, especially in systems dealing with data transmission or storage where checksums are necessary to ensure data integrity. Therefore, it is likely to be retained in the codebase."
survived,"def honda_checksum(address: int, sig, d: bytearray) -> int:
  s = 0
  extended = address > 0x7FF
  addr = address
  while addr:
    s += addr & 0xF
    addr >>= 4
  for i in range(len(d)):
    x = d[i]
    if i == len(d) - 1:
      x >>= 4
    s += (x & 0xF) + (x >> 4)
  s = 8 - s
  if extended:
    s += 3
  return s & 0xF",opendbc/car/honda/hondacan.py,,1,6.348800075736417e-09,"The method 'honda_checksum' is a utility function that calculates a checksum for a given address and data, which is a common requirement in communication protocols, especially in automotive applications. The function is well-defined, performs a specific task, and does not have any apparent issues or redundancies. It is likely to be used in systems where data integrity is crucial, such as in vehicle communication networks. Therefore, it is likely to be retained in the codebase."
survived,"    def _convert_messages(
        self, messages: str | list[str | SamplingMessage]
    ) -> list[SamplingMessage]:
        """"""Convert plain strings to ``SamplingMessage`` objects.""""""

        if isinstance(messages, str):
            messages = [messages]

        converted: list[SamplingMessage] = []
        for msg in messages:
            if isinstance(msg, SamplingMessage):
                converted.append(msg)
            elif isinstance(msg, str):
                converted.append(
                    SamplingMessage(
                        role=""user"",
                        content=TextContent(type=""text"", text=msg),
                    )
                )
            else:
                raise TypeError(""messages must be str or SamplingMessage"")
        return converted
",src/enrichmcp/context.py,EnrichContext,1,2.7894680920908113e-10,"The method '_convert_messages' is likely to survive because it serves a clear and useful purpose: converting a list of strings or SamplingMessage objects into a uniform list of SamplingMessage objects. This kind of utility function is common in codebases where data normalization is necessary before processing. Additionally, the method includes error handling for unexpected input types, which is a good practice in robust software development. There is no indication of redundancy or obsolescence in the method's functionality, suggesting it will remain relevant and useful."
survived,"        def predict(self, x: int) -> int:
            return x
",tests/trace/test_serialize.py,MyObj,0,0.9999999804443193,"The method 'predict' is a simple function that takes an integer input and returns it without any modification. This method is likely to be deleted because it doesn't perform any meaningful computation or transformation on the input data. In most practical scenarios, a 'predict' method is expected to implement some form of logic or algorithm to generate a prediction based on the input, rather than just returning the input as is. Therefore, unless this method is a placeholder or part of a larger framework where such behavior is required, it is not serving a useful purpose and is likely to be removed."
survived,"def self_improve(template: str, logs: str, *, seed: int | None = None) -> str:
    """"""Return a patch proposal by querying the configured LLM.""""""
    if seed is not None:
        random.seed(seed)
    system_prompt = CFG.self_improve.system
    user_prompt = template.format(logs=logs)
    if CFG.self_improve.user:
        user_prompt = f""{CFG.self_improve.user}\n{user_prompt}""
    llm = _get_llm()
    return llm(user_prompt, system_prompt)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/self_edit/prompting.py,,1,6.224144622520382e-11,"The method 'self_improve' is likely to survive because it appears to be a well-defined function with a clear purpose: generating a patch proposal by querying a language model (LLM). It includes parameters for customization, such as a template and logs, and an optional seed for randomness control. The function also demonstrates good practices, like using configuration settings (CFG) and formatting prompts. These characteristics suggest that the method is useful and maintainable, which are key factors for survival."
survived,"def main() -> int:
    repo_root = Path(__file__).resolve().parents[1]
    docs_dir = repo_root / ""docs""
    missing: list[Path] = []

    for html in sorted(docs_dir.rglob(""index.html"")):
        if html.parent.name == ""DISCLAIMER_SNIPPET"":
            continue
        text = html.read_text(encoding=""utf-8"", errors=""ignore"")
        if SNIPPET not in text:
            missing.append(html.relative_to(repo_root))

    if missing:
        print(""Missing HTML disclaimer link:"", file=sys.stderr)
        for path in missing:
            print(f""  {path}"", file=sys.stderr)
        return 1
    return 0
",scripts/verify_html_disclaimer.py,,1,1.4166087846364157e-09,"The method is a utility function that checks for the presence of a specific snippet in HTML files within a documentation directory. It is useful for ensuring that all necessary disclaimers are included in the documentation, which is a common requirement for many projects. The function is well-structured, performs a clear and necessary task, and provides feedback if the task is not completed as expected. Therefore, it is likely to be retained in the codebase."
survived,"    def execute_and_collect(self, path: Path, timeout: int = 60) -> CollectionResult:
        """"""Run tests via the execution module and gather outputs.""""""
        start = time.perf_counter()
        result = self.execution_module.run_tests(path, timeout)
        end = time.perf_counter()
        return CollectionResult(
            exit_code=result.exit_code,
            stdout=result.stdout,
            stderr=result.stderr,
            duration=end - start,
        )",src/meta_agent/evaluation/result_collection.py,ResultCollectionModule,1,1.9171715133907573e-10,"The method 'execute_and_collect' is likely to survive because it provides a clear and useful functionality: executing tests and collecting their results. It is well-structured, with a clear purpose and return type, and it uses standard practices such as timing the execution and returning a structured result. This method is likely to be a core part of a testing or execution framework, making it essential for the system's operation."
survived,"    def aggregate(self, results: Iterable[CollectionResult]) -> List[SummaryReport]:
        """"""Summarize multiple results.""""""
        return [self.summarize(r) for r in results]
",src/meta_agent/evaluation/reporting.py,ReportingModule,1,7.582560422162384e-10,"The method 'aggregate' is likely to survive because it performs a clear and useful function: it aggregates a list of results by summarizing each one. This is a common pattern in data processing and analysis, where summarizing or transforming collections of data is a frequent requirement. The method is concise, leverages list comprehension for efficiency, and is likely part of a larger system where such functionality is necessary."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/emirp-primes.py,,1,3.466327708641819e-07,"The method `_now()` is a utility function that generates a pseudo-random number based on a seed if `_now_seeded` is True, or returns the current time in nanoseconds otherwise. This function is likely to be useful in scenarios where a consistent pseudo-random number is needed for testing or other purposes, and the fallback to the current time ensures it can still function when not seeded. Such utility functions are often retained in codebases for their flexibility and utility in various contexts."
survived,"def pow10(n):
    r = 1.0
    i = 0
    while i < n:
        r = r * 10.0
        i = i + 1
    return r
",tests/rosetta/transpiler/Python/element-wise-operations.py,,1,0.00017952802200222974,"The method 'pow10' is a simple implementation of calculating 10 raised to the power of 'n'. It uses a loop to multiply 10.0 by itself 'n' times. While this method is functional, it is not the most efficient way to calculate powers of 10, especially since Python has built-in capabilities like '10 ** n' or 'math.pow(10, n)' which are more concise and likely optimized. However, the method is straightforward and does not contain any errors, so it is likely to survive unless there is a strong emphasis on optimizing code or using built-in functions for such operations."
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/empty-program.py,,1,3.5356257528032616e-05,"The method is a simple benchmarking function that measures the memory usage and execution time of a block of code. It uses the 'resource' module to get memory usage and a custom '_now()' function to get the current time. The results are printed in JSON format. However, the method currently does not perform any meaningful operations between the start and end measurements, making it somewhat redundant. Despite this, the method is not harmful and could be useful if expanded to include actual code execution between the benchmarks. Therefore, it is likely to survive as it provides a basic structure for performance measurement."
survived,"def neg(p):
    return Pt(x=p.x, y=-p.y, inf=p.inf)
",tests/rosetta/transpiler/Python/elliptic-curve-arithmetic.py,,1,7.194132978569833e-09,"The method 'neg' is a simple utility function that negates the y-coordinate of a point 'p' while keeping the x-coordinate and the 'inf' attribute unchanged. Such utility functions are often useful in mathematical computations, graphics, or physics simulations where transformations of points are common. The function is concise, performs a clear and specific task, and is likely to be used in contexts where point manipulation is required. Therefore, it is likely to be retained in the codebase."
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    print(""Private key:\nD: 1234567890"")
    print(""\nPublic key:"")
    print(""X: 43162711582587979080031819627904423023685561091192625653251495188141318209988"")
    print(""Y: 86807430002474105664458509423764867536342689150582922106807036347047552480521"")
    print(""\nMessage: Rosetta Code"")
    print(""Hash   : 0xe6f9ed0d"")
    print(""\nSignature:"")
    print(""R: 23195197793674669608400023921033380707595656606710353926508630347378485682379"")
    print(""S: 79415614279862633473653728365954499259635019180091322566320325357594590761922"")
    print(""\nSignature verified: true"")
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/elliptic-curve-digital-signature-algorithm.py,,1,1.892514738127224e-05,"The method is a simple demonstration of printing cryptographic keys, a message, and a signature, along with some benchmarking information. It doesn't perform any actual cryptographic operations or verification, and the values are hardcoded. However, it serves as a basic example of how such information might be displayed and logged. Since it is a straightforward example with no security implications or complex logic, it is likely to be retained for educational or illustrative purposes."
survived,"def bitAt(x, idx):
    v = x
    i = 0
    while i < idx:
        v = int((v // 2))
        i = i + 1
    return v % 2
",tests/rosetta/transpiler/Python/elementary-cellular-automaton.py,,1,2.5109990926928157e-08,"The method 'bitAt' is a utility function that extracts the bit at a specific index from the binary representation of a number. This type of function is often useful in low-level programming, bit manipulation tasks, and certain algorithm implementations. It is a simple and efficient way to access individual bits, which can be crucial in performance-critical applications. Given its utility and the fact that it is a common operation in various domains, it is likely to be retained in the codebase."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/entropy-2.py,,1,6.348800075736417e-09,"The method '_now' is a utility function that generates a pseudo-random number based on a seed if '_now_seeded' is True, or returns the current time in nanoseconds if not. This function is useful for generating consistent pseudo-random numbers for testing or other purposes when seeded, and for getting the current time otherwise. Such utility functions are often retained in codebases for their flexibility and utility in different scenarios. Therefore, it is likely to survive."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/elementary-cellular-automaton-infinite-length.py,,1,6.825604231969389e-08,"The method '_now' is a utility function that generates a pseudo-random number based on a global seed if '_now_seeded' is True, otherwise it returns the current time in nanoseconds. This method is likely to be retained because it provides a useful functionality for generating time-based or seeded random numbers, which can be useful in various applications such as testing, simulations, or time-stamping events. The use of a global seed allows for reproducibility in random number generation, which is a common requirement in many software systems."
survived,"def addNoCells(cells):
    l = ""O""
    r = ""O""
    if cells[0:1] == ""O"":
        l = "".""
    if cells[len(cells) - 1:len(cells)] == ""O"":
        r = "".""
    cells = l + cells + r
    cells = l + cells + r
    return cells
",tests/rosetta/transpiler/Python/elementary-cellular-automaton-infinite-length.py,,0,0.9999957771647318,"The method 'addNoCells' is likely to be deleted because it contains redundant operations and lacks clarity in its purpose. The method appends characters to the string 'cells' based on certain conditions, but it does so in a way that seems unnecessary and inefficient. For example, it appends 'l' and 'r' twice, which might not be the intended behavior. Additionally, the method name 'addNoCells' is not descriptive of its functionality, making it harder to understand and maintain. These factors suggest that the method may be refactored or removed in favor of a more efficient and clear implementation."
survived,"def formatFloat(f, prec):
    scale = pow10(prec)
    scaled = (f * scale) + 0.5
    n = (int(scaled))
    digits = str(n)
    while len(digits) <= prec:
        digits = ""0"" + digits
    intPart = digits[0:len(digits) - prec]
    fracPart = digits[len(digits) - prec:len(digits)]
    return intPart + ""."" + fracPart
",tests/rosetta/transpiler/Python/element-wise-operations.py,,0,0.9999999397642536,"The method 'formatFloat' is a utility function that formats a floating-point number to a specified precision. However, it uses a non-standard approach by manually scaling and converting the number to a string, which can lead to inaccuracies and inefficiencies. In modern Python, the same functionality can be achieved more reliably and succinctly using built-in string formatting methods like 'format' or 'f-strings'. Therefore, this method is likely to be deleted in favor of more robust and concise alternatives."
survived,"def _commit_patch(repo_path: Path, message: str = ""autoâ€‘fix: CI green ðŸŸ¢"") -> str:
    if git is None:
        return ""[git unavailable â€‘ simulated commit] "" + message

    try:
        repo = git.Repo(repo_path)
    except git.InvalidGitRepositoryError:
        return ""[not a git repo â€‘ skipping commit]""

    branch_name = ""auto-fix""
    if branch_name in repo.heads:
        repo.git.checkout(branch_name)
    else:
        repo.git.checkout(b=branch_name)

    repo.git.add(update=True)
    repo.index.commit(message)
    commit_hash = repo.head.commit.hexsha[:7]
    return f""Committed patch {commit_hash} on branch {branch_name}""
",alpha_factory_v1/demos/self_healing_repo_cli.py,,1,1.4166087846364157e-09,"The method '_commit_patch' is a utility function that automates the process of committing changes to a Git repository. It handles checking out a branch, adding changes, and committing them with a default message. This functionality is useful in continuous integration (CI) pipelines or automated scripts where manual intervention is minimized. The method also includes error handling for cases where Git is unavailable or the path is not a Git repository, making it robust and versatile. Given its utility in automating repetitive tasks and its error handling, it is likely to be retained in the codebase."
survived,"def test_reload_restores_settings() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri()

    with sync_playwright() as p:
        browser = p.chromium.launch()
        page = browser.new_page()
        page.goto(url)
        page.wait_for_selector(""#controls"")

        seed_input = page.locator(""#seed"")
        seed_input.fill(""321"")
        seed_input.dispatch_event(""change"")
        page.wait_for_function(""location.hash.includes('seed=321')"")

        page.evaluate(""location.hash = ''"")
        page.reload()
        page.wait_for_selector(""#controls"")
        assert page.input_value(""#seed"") == ""321""
        browser.close()",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_browser_ui.py,,1,9.237449576640118e-09,"The method 'test_reload_restores_settings' is a test function that verifies the functionality of a web application. It uses Playwright to automate a browser and check if a setting (seed value) is preserved after a page reload. This is a common and useful test case to ensure that user settings are not lost during navigation or reloads. Such tests are crucial for maintaining the reliability and user experience of web applications. Therefore, it is unlikely to be deleted as it serves an important purpose in the testing suite."
survived,"def run(cmd: list[str]) -> None:
    subprocess.run(cmd, check=True)
",alpha_factory_v1/demos/aiga_meta_evolution/start_aiga_demo.py,,0,0.9999997617630155,"The method 'run' is a simple wrapper around 'subprocess.run', which is a standard way to execute shell commands in Python. It adds no additional functionality or abstraction beyond what 'subprocess.run' already provides. Therefore, it is likely to be considered redundant and unnecessary, leading to its deletion."
survived,"    def test_entrypoint_compiles(self):
        py_compile.compile(ENTRYPOINT, doraise=True)
",tests/test_agent_aiga_entrypoint.py,TestAgentAIGAEntry,1,2.3355930333443423e-09,"The method `test_entrypoint_compiles` is a simple test function that checks if a Python script (referred to by `ENTRYPOINT`) can be compiled without syntax errors. This is a basic yet useful test to ensure that the code is syntactically correct before running it. Such tests are often part of a test suite to catch errors early in the development process. Therefore, it is likely to be retained as it serves a practical purpose in maintaining code quality."
survived,"            async def close(self) -> None:
                calls.append((""closed"", True))
",tests/test_ledger_client_close.py,DummyClient,1,2.0611536181902033e-09,"The method 'close' is an asynchronous method that appends a tuple to a list 'calls'. This method is likely part of a larger class or module that tracks or logs certain events or states. The method itself is simple and functional, serving a clear purpose of logging a 'closed' state. Without additional context suggesting it's redundant or replaced, it's reasonable to predict that this method will survive as it fulfills a specific role in the code."
survived,"            def __init__(self) -> None:
                self.instructions: list[Any] = []
",tests/test_ledger_client_close.py,DummyTx,1,9.931195248674785e-08,"The method is a constructor for a class, indicated by the name `__init__`. Constructors are essential for initializing new objects and are a fundamental part of class definitions in Python. Therefore, it is unlikely that this method will be deleted as it serves a critical role in object-oriented programming."
survived,"def parse_bytes(size: Union[int, str, None]) -> Optional[int]:
    """"""Convert a human friendly size string to bytes.""""""
    if size is None:
        return None
    if isinstance(size, int):
        return size
    match = re.fullmatch(r""(?i)\s*(\d+(?:\.\d+)?)\s*([kmgt]?b)?\s*"", str(size))
    if not match:
        raise ValueError(f""Invalid size value: {size}"")
    number = float(match.group(1))
    unit = (match.group(2) or ""b"").upper()
    factor = {
        ""B"": 1,
        ""KB"": 1024,
        ""MB"": 1024**2,
        ""GB"": 1024**3,
        ""TB"": 1024**4,
    }[unit]
    return int(number * factor)
",src/cachier/config.py,,1,8.592166611791576e-10,"The method 'parse_bytes' is a utility function that converts a human-friendly size string into bytes, which is a common requirement in software dealing with file sizes or data transfer. It handles various input types (int, str, None) and provides a clear error message for invalid inputs. The use of regular expressions to parse the input and a dictionary to map units to their byte equivalents is efficient and clear. This functionality is useful and likely to be reused in different contexts, making it a candidate for survival."
survived,"    def id_to_word(cls, idx):
        return cls._words[idx]
",btcrecover/btcrseed.py,WalletSLIP39Seed,1,2.3355930333443423e-09,"The method `id_to_word` is a simple utility function that converts an index to a word using a class attribute `_words`. This type of method is often useful in applications where you need to map indices to specific words, such as in natural language processing tasks or when dealing with vocabulary lists. Since it provides a clear and straightforward functionality that is likely to be used in various parts of a program, it is more likely to be retained rather than deleted."
survived,"    def test_share_checksum(self):
        share = ""hearing echo academic acid deny bracelet playoff exact fancy various evidence standard adjust muscle parcel sled crucial amazing mansion losing""
        wallet = btcrseed.WalletSLIP39Seed.create_from_params()
        wallet.config_mnemonic(share)
        self.assertEqual(wallet.return_verified_password_or_false((btcrseed.mnemonic_ids_guess,)),
                         (btcrseed.mnemonic_ids_guess, 1))
",btcrecover/test/test_seeds.py,TestSLIP39Seed,1,5.60279640614594e-09,"The method 'test_share_checksum' is a unit test designed to verify the functionality of the 'WalletSLIP39Seed' class, specifically the 'config_mnemonic' and 'return_verified_password_or_false' methods. Unit tests are crucial for ensuring code reliability and are typically retained in the codebase to facilitate ongoing testing and validation. Therefore, it is unlikely that this method will be deleted."
survived,"async def test_crud_decorators_register_resources():
    app = EnrichMCP(""API"", description=""desc"")

    @app.entity
    class Item(EnrichModel):
        """"""Item entity.""""""

        id: int = Field(description=""id"")
        name: str = Field(description=""name"", mutable=True)

    @app.create
    async def create_item(name: str) -> Item:
        """"""Create item.""""""
        return Item(id=1, name=name)

    @app.update
    async def update_item(item_id: int, patch: Item.PatchModel) -> Item:
        """"""Update item.""""""
        return Item(id=item_id, name=patch.name or ""n"")

    @app.delete
    async def delete_item(item_id: int) -> bool:
        """"""Delete item.""""""
        return True

    assert ""create_item"" in app.resources
    assert ""update_item"" in app.resources
    assert ""delete_item"" in app.resources

    item = await create_item(name=""x"")
    assert item.name == ""x""
    item = await update_item(1, Item.PatchModel(name=""y""))
    assert item.name == ""y""
    assert await delete_item(1) is True",tests/test_mutability.py,,1,4.4508487281649027e-07,"The method `test_crud_decorators_register_resources` is a test function that verifies the registration and functionality of CRUD operations using decorators in an asynchronous application framework. It is well-structured, uses assertions to validate the expected behavior, and is likely part of a test suite to ensure the correctness of the application. Test functions are crucial for maintaining code quality and reliability, especially in frameworks that rely on decorators and asynchronous operations. Therefore, it is unlikely to be deleted as it serves an important role in testing the application's functionality."
survived,"    def create(
        self,
        func: Callable[..., Any] | None = None,
        *,
        name: str | None = None,
        description: str | None = None,
    ) -> Callable[..., Any] | DecoratorCallable:
        """"""Register a create operation.""""""

        def decorator(fn: Callable[..., Any]) -> Callable[..., Any]:
            return self.resource(fn, name=name, description=description)

        if func is not None:
            return decorator(func)
        return cast(""DecoratorCallable"", decorator)
",src/enrichmcp/app.py,EnrichMCP,1,2.7894680920908113e-10,"The method 'create' is a utility function that registers a 'create' operation, likely for a framework or library that deals with resources or operations. It provides a decorator pattern, allowing users to either directly pass a function to be decorated or use it as a decorator. This pattern is common in frameworks that need to register or modify functions, such as web frameworks or task schedulers. The method is flexible, allowing optional parameters for 'name' and 'description', which suggests it is designed for extensibility and ease of use. Given these characteristics, it is likely to be a useful and integral part of the system it belongs to, and therefore, it is likely to survive."
survived,"def get_string_prefix(code: str) -> str:
    """"""Return the leading string prefix characters (r, u, b, f).""""""
    idx = 0
    while idx < len(code) and code[idx] in ""furbFURB"":
        idx += 1
    return code[:idx]
",src/flynt/utils/format.py,,1,1.955568070542584e-08,"The method 'get_string_prefix' is a utility function that extracts the leading string prefix characters from a given string. This is a useful function for parsing or analyzing code, especially in contexts where string literals with prefixes (like raw strings, Unicode strings, byte strings, and formatted strings) are used. The function is simple, efficient, and serves a clear purpose, making it likely to be retained in a codebase where such functionality is needed."
survived,"async def list_notes(page: int = 1, page_size: int = 10) -> list[NoteSummary]:
    """"""Return a paginated list of notes.""""""
    return project.list_notes(page, page_size)
",examples/basic_memory/app.py,,1,5.60279640614594e-09,"The method 'list_notes' is a straightforward and useful utility function that provides a paginated list of notes. It is well-defined with default parameters for pagination, making it flexible for various use cases. The method is likely to be used frequently in applications that manage or display notes, as pagination is a common requirement for handling large datasets efficiently. Additionally, the use of async indicates that it is designed to handle asynchronous operations, which is beneficial for performance in web applications. Therefore, it is unlikely to be deleted."
survived,"def _have_torch():
    try:
        import torch  # noqa: F401

        return True
    except Exception:
        return False
",tests/test_torch_backend.py,,1,5.905303995456778e-10,"The method `_have_torch()` is a utility function designed to check if the PyTorch library is available in the environment. This is a common pattern used in Python projects to conditionally enable features that depend on optional dependencies. The function is simple, effective, and serves a clear purpose. It is unlikely to be deleted unless the project no longer supports PyTorch or the method is replaced by a more comprehensive dependency management system. Therefore, it is likely to survive."
survived,"def test_torch_backend(tmp_path):
    if not _have_torch() or os.environ.get(""RUN_ENGINE_TESTS"") != ""1"":
        print(""Skipping torch backend test"")
        return
    out_dir = tmp_path
    cmd = [
        ""./Release/Sibernetic"",
        ""-no_g"",
        ""-f"",
        ""configuration/test/test_energy"",
        ""-l_to"",
        f""lpath={out_dir}"",
        ""timelimit=0.001"",
        ""logstep=25"",
        ""backend=torch"",
    ]
    env = os.environ.copy()
    env[""PYTHONPATH""] = f""{os.getcwd()}:{env.get('PYTHONPATH', '')}""
    proc = subprocess.run(cmd, env=env)
    if proc.returncode != 0:
        print(""Torch backend run failed, skipping"")
        return

    pos = _load_matrix(""position_buffer.txt"", base=out_dir)
    base_pos = _load_matrix(""positions_step0.txt"")
    for g_row, b_row in zip(pos, base_pos):
        for gv, bv in zip(g_row, b_row):
            assert math.isfinite(gv)
            assert abs(gv - bv) < 1e-3

    vel = _load_matrix(""velocity_buffer.txt"", base=out_dir)
    base_vel = _load_matrix(""velocities_step0.txt"")
    for g_row, b_row in zip(vel, base_vel):
        for gv, bv in zip(g_row, b_row):
            assert math.isfinite(gv)
            assert abs(gv - bv) < 1e-3

    energy_file = os.path.join(out_dir, ""total_energy_distrib.txt"")
    if os.path.exists(energy_file):
        with open(energy_file) as f:
            energies = [float(line.strip()) for line in f if line.strip()]
        if len(energies) >= 2:
            start, end = energies[0], energies[-1]
            rel = abs(end - start) / (abs(start) + 1e-12)
            assert rel < 1.0",tests/test_torch_backend.py,,1,1.444980317078884e-07,"The method 'test_torch_backend' is a test function that checks the functionality of a specific backend (torch) in a software system. It includes checks for the presence of necessary conditions, runs a subprocess, and validates the output against expected results. Such test functions are crucial for ensuring the reliability and correctness of the software, especially when dealing with different backends or configurations. Therefore, it is unlikely to be deleted as it serves an important role in the testing suite."
survived,"def gather_assets(docs_dir: Path) -> list[str]:
    base_assets = docs_dir / ""assets""
    assets: list[str] = []
    allowed = {"".js"", "".css"", "".svg"", "".json"", "".wasm"", "".tar"", "".cast""}
    pyodide_dir = base_assets / ""pyodide""
    if pyodide_dir.is_dir():
        order = [""pyodide.js"", ""pyodide.asm.wasm"", ""pyodide_py.tar""]
        for name in order:
            file = pyodide_dir / name
            if file.is_file() and file.suffix in allowed:
                rel = Path(""assets"") / ""pyodide"" / file.name
                assets.append(rel.as_posix())
    for item in sorted(docs_dir.iterdir()):
        if not item.is_dir() or item.name == ""assets"":
            continue
        a_dir = item / ""assets""
        if a_dir.is_dir():
            for file in sorted(a_dir.rglob(""*"")):
                if file.is_file() and file.suffix in allowed:
                    rel = Path("".."") / item.name / ""assets"" / file.relative_to(a_dir)
                    assets.append(rel.as_posix())
    return assets
",scripts/build_service_worker.py,,1,3.160881453314576e-10,"The method 'gather_assets' is likely to survive because it performs a useful and specific function: gathering asset file paths from a directory structure. It checks for specific file types, handles directories, and constructs relative paths, which are common tasks in managing web assets or similar resources. The code is well-structured, uses clear logic, and adheres to common practices, such as checking for file existence and using pathlib for path manipulations. These factors suggest that the method is functional and relevant, reducing the likelihood of it being deleted."
survived,"def convert_feats(v1_path, out_dir, doc_slug, start_pk):
    feats_v1 = load_json(v1_path)
    feats_v2 = []
    fb_v2 = []
    pk_counter = start_pk
    for feat in feats_v1:
        f = feat[""fields""]
        slug = feat[""pk""]
        pk = f""{doc_slug}_{slug}""
        feats_v2.append({
            ""model"": ""api_v2.feat"",
            ""pk"": pk,
            ""fields"": {
                ""name"": f[""name""],
                ""desc"": f[""desc""],
                ""prerequisite"": f.get(""prerequisite""),
                ""document"": doc_slug,
            },
        })
        eff = f.get(""effects_desc_json"")
        if eff:
            try:
                parts = json.loads(eff)
            except Exception:
                parts = []
            for part in parts:
                fb_v2.append({
                    ""model"": ""api_v2.featbenefit"",
                    ""pk"": pk_counter,
                    ""fields"": {""name"": """", ""desc"": part, ""type"": None, ""parent"": pk},
                })
                pk_counter += 1
    if feats_v2:
        save_json(feats_v2, os.path.join(out_dir, ""Feat.json""))
    if fb_v2:
        save_json(fb_v2, os.path.join(out_dir, ""FeatBenefit.json""))
    return pk_counter
",convert_missing.py,,1,4.944450477491054e-09,"The method 'convert_feats' is likely to survive because it performs a specific and useful function: converting data from one format to another and saving it to JSON files. This kind of utility function is often necessary in data processing pipelines, especially when migrating data between different versions of an API or database schema. The method is well-structured, handles exceptions, and updates a primary key counter, which suggests it is part of a larger system that relies on this functionality. Unless the entire system is deprecated or replaced, this method will likely remain useful."
survived,"def test_readiness() -> None:
    resp = client.get(""/readiness"")
    assert resp.status_code == 200
    assert resp.text == ""ok""",tests/test_insight_health.py,,1,1.3440409770490404e-08,"The method `test_readiness` is a simple test function that checks the readiness of a service by making a GET request to the `/readiness` endpoint and asserting that the response status code is 200 and the response text is ""ok"". This is a common pattern in testing to ensure that a service is up and running as expected. Such tests are crucial for maintaining the reliability and stability of a service, especially in production environments. Therefore, it is unlikely that this method will be deleted as it serves an important purpose in the testing suite."
survived,"def make_client() -> TestClient:
    return TestClient(cast(Any, api.app))
",tests/test_metrics_router.py,,1,2.998960815863541e-09,"The method 'make_client' is a utility function that creates and returns a 'TestClient' instance. This is a common pattern in testing frameworks to facilitate testing of web applications. The function is simple, clear, and serves a specific purpose in the context of testing. There is no indication that it is redundant or unnecessary, so it is likely to be retained for its utility in testing scenarios."
survived,"def test_memory_agent_handle_appends() -> None:
    cfg = config.Settings(bus_port=0)
    bus = DummyBus(cfg)
    led = DummyLedger()
    agent = memory_agent.MemoryAgent(bus, led)
    env = messaging.Envelope(""a"", ""memory"", {""v"": 1}, 0.0)
    asyncio.run(agent.handle(env))
    assert agent.records == [{""v"": 1}]
",tests/test_agent_handle_methods.py,,1,1.3440409770490404e-08,"The method 'test_memory_agent_handle_appends' is a unit test designed to verify the functionality of the 'handle' method in the 'MemoryAgent' class. Unit tests are crucial for ensuring code reliability and are typically retained in the codebase to facilitate ongoing testing and validation of code changes. This test checks that the 'handle' method correctly appends data to the 'records' attribute, which is a fundamental operation that should be verified. Therefore, it is unlikely that this method will be deleted."
survived,"    def log(self, env: messaging.Envelope) -> None:  # type: ignore[override]
        self.logged.append(env)
",tests/test_agent_handle_methods.py,DummyLedger,1,3.3982678079468468e-09,"The method 'log' is a simple implementation that appends an envelope to a list called 'logged'. It is a straightforward method with a clear purpose and does not contain any deprecated or problematic code. The use of 'type: ignore[override]' suggests that there might be a reason to suppress type checking, possibly due to a known issue or intentional design choice. Without any indication of it being obsolete or replaced by a better implementation, it is likely to survive."
survived,"def test_strategy_agent_emits_market() -> None:
    cfg = config.Settings(bus_port=0)
    bus = DummyBus(cfg)
    led = DummyLedger()
    agent = strategy_agent.StrategyAgent(bus, led)
    env = messaging.Envelope(""research"", ""strategy"", {""research"": ""foo""}, 0.0)
    asyncio.run(agent.handle(env))
    assert bus.published
    topic, sent = bus.published[-1]
    assert topic == ""market""
    assert ""strategy"" in sent.payload
",tests/test_agent_handle_methods.py,,1,1.1032560311263802e-09,"The method 'test_strategy_agent_emits_market' is a unit test designed to verify that the 'StrategyAgent' correctly publishes a message to the 'market' topic when handling a specific envelope. Unit tests are crucial for ensuring code reliability and functionality, especially in complex systems involving messaging and asynchronous operations. The presence of this test helps maintain the integrity of the 'StrategyAgent' behavior, making it unlikely to be deleted unless the functionality it tests is removed or significantly altered. Therefore, the method is likely to survive."
survived,"    def start_socket() -> None:
        """"""Start the optional A2A socket if available.""""""
        if _A2A:
            try:
                _A2A.start()
            except Exception:  # pragma: no cover - best effort
                LOG.warning(""Failed to start A2A socket"", exc_info=True)
",alpha_factory_v1/demos/aiga_meta_evolution/meta_evolver.py,MetaEvolver,1,3.3982678079468468e-09,"The method 'start_socket' is likely to survive because it contains functionality to start an optional A2A socket, which is a specific feature that might be necessary for certain operations. The method also includes error handling to manage exceptions, indicating that it is designed to be robust and maintainable. Additionally, the use of logging for warning purposes suggests that the method is part of a larger system where monitoring and debugging are important, further supporting its continued relevance."
survived,"async def _build_task_run_response(task_v2: TaskV2) -> TaskRunResponse:
    """"""Build TaskRunResponse object for webhook backward compatibility.""""""
    workflow_run_resp = None
    if task_v2.workflow_run_id:
        try:
            workflow_run_resp = await workflow_service.get_workflow_run_response(
                task_v2.workflow_run_id, organization_id=task_v2.organization_id
            )
        except Exception:
            LOG.warning(
                ""Failed to get workflow run response for task v2 webhook"",
                exc_info=True,
                task_v2_id=task_v2.observer_cruise_id,
            )

    app_url = None
    if task_v2.workflow_run_id and task_v2.workflow_permanent_id:
        app_url = (
            f""{settings.SKYVERN_APP_URL.rstrip('/')}/workflows/""
            f""{task_v2.workflow_permanent_id}/{task_v2.workflow_run_id}""
        )

    return TaskRunResponse(
        run_id=task_v2.observer_cruise_id,
        run_type=RunType.task_v2,
        status=task_v2.status,
        output=task_v2.output,
        failure_reason=workflow_run_resp.failure_reason if workflow_run_resp else None,
        created_at=task_v2.created_at,
        modified_at=task_v2.modified_at,
        recording_url=workflow_run_resp.recording_url if workflow_run_resp else None,
        screenshot_urls=workflow_run_resp.screenshot_urls if workflow_run_resp else None,
        downloaded_files=workflow_run_resp.downloaded_files if workflow_run_resp else None,
        app_url=app_url,
        run_request=TaskRunRequest(
            engine=RunEngine.skyvern_v2,
            prompt=task_v2.prompt or """",
            url=task_v2.url,
            webhook_url=task_v2.webhook_callback_url,
            totp_identifier=task_v2.totp_identifier,
            totp_url=task_v2.totp_verification_url,
            proxy_location=task_v2.proxy_location,
            data_extraction_schema=task_v2.extracted_information_schema,
            error_code_mapping=task_v2.error_code_mapping,
        ),
    )
",skyvern/services/task_v2_service.py,,1,9.237449576640118e-09,"The method '_build_task_run_response' is likely to survive because it serves a critical function in building a response object for task runs, which is essential for maintaining backward compatibility with webhooks. The method is well-structured, handles exceptions, and constructs a comprehensive response object that includes various attributes necessary for task management and monitoring. Additionally, it integrates with other services like 'workflow_service' and uses settings, indicating its role in a larger system architecture. Such methods are typically retained unless there is a significant overhaul of the system architecture or a change in requirements."
survived,"    def _write_detailed_python_analysis(self, f):
        """"""
        å†™å…¥è¯¦ç»†çš„Pythonå¯¹è±¡åˆ†æž
        """"""
        f.write(""2. Pythonå¯¹è±¡æ·±åº¦åˆ†æž\n"")
        f.write(""-"" * 50 + ""\n"")
        
        # å¼ºåˆ¶åžƒåœ¾å›žæ”¶
        collected = gc.collect()
        f.write(f""åžƒåœ¾å›žæ”¶æ¸…ç†å¯¹è±¡æ•°: {collected}\n\n"")
        
        # èŽ·å–æ‰€æœ‰å¯¹è±¡
        all_objects = muppy.get_objects()
        f.write(f""æ€»å¯¹è±¡æ•°: {len(all_objects):,}\n"")
        
        # æŒ‰ç±»åž‹ç»Ÿè®¡
        type_stats = {}
        for obj in all_objects:
            obj_type = type(obj).__name__
            if obj_type not in type_stats:
                type_stats[obj_type] = {'count': 0, 'size': 0}
            type_stats[obj_type]['count'] += 1
            type_stats[obj_type]['size'] += sys.getsizeof(obj)
        
        # æŒ‰å¤§å°æŽ’åº
        sorted_types = sorted(type_stats.items(), key=lambda x: x[1]['size'], reverse=True)
        
        f.write(""å¯¹è±¡ç±»åž‹ç»Ÿè®¡ (æŒ‰å†…å­˜å¤§å°æŽ’åº):\n"")
        f.write(f""{'ç±»åž‹':<20} {'æ•°é‡':<10} {'æ€»å¤§å°(MB)':<12} {'å¹³å‡å¤§å°(B)':<12}\n"")
        f.write(""-"" * 60 + ""\n"")
        
        total_python_memory = 0
        for obj_type, stats in sorted_types[:20]:  # åªæ˜¾ç¤ºå‰20ä¸ª
            size_mb = stats['size'] / 1024 / 1024
            avg_size = stats['size'] / stats['count'] if stats['count'] > 0 else 0
            total_python_memory += size_mb
            f.write(f""{obj_type:<20} {stats['count']:<10,} {size_mb:<12.2f} {avg_size:<12.1f}\n"")
        
        f.write(f""\nPythonå¯¹è±¡æ€»å†…å­˜: {total_python_memory:.2f} MB\n"")
        
        # è®¡ç®—æœªç»Ÿè®¡å†…å­˜
        process = psutil.Process()
        total_memory = process.memory_info().rss / 1024 / 1024
        unaccounted = total_memory - total_python_memory
        f.write(f""æœªç»Ÿè®¡å†…å­˜: {unaccounted:.2f} MB ({unaccounted/total_memory*100:.1f}%)\n"")
        
        f.write(""\n"" + ""="" * 100 + ""\n\n"")
",app/helper/memory.py,MemoryHelper,1,1.955568070542584e-08,"The method '_write_detailed_python_analysis' provides a comprehensive analysis of Python objects in memory, including garbage collection statistics, object type counts, and memory usage. This kind of detailed analysis is valuable for debugging and optimizing memory usage in Python applications. It is unlikely to be deleted as it serves a useful purpose for developers who need to understand and manage memory consumption in their applications."
survived,"    def _write_detailed_system_analysis(self, f):
        """"""
        å†™å…¥è¯¦ç»†çš„ç³»ç»Ÿå†…å­˜åˆ†æž
        """"""
        f.write(""1. ç³»ç»Ÿçº§å†…å­˜åˆ†æž\n"")
        f.write(""-"" * 50 + ""\n"")
        
        process = psutil.Process()
        memory_info = process.memory_info()
        
        f.write(f""è¿›ç¨‹ID: {process.pid}\n"")
        f.write(f""è¿›ç¨‹åç§°: {process.name()}\n"")
        f.write(f""è¿›ç¨‹å‘½ä»¤è¡Œ: {' '.join(process.cmdline())}\n\n"")
        
        f.write(""å†…å­˜ä½¿ç”¨è¯¦æƒ…:\n"")
        f.write(f""  RSS (ç‰©ç†å†…å­˜): {memory_info.rss / 1024 / 1024:.2f} MB\n"")
        f.write(f""  VMS (è™šæ‹Ÿå†…å­˜): {memory_info.vms / 1024 / 1024:.2f} MB\n"")
        f.write(f""  å…±äº«å†…å­˜: {memory_info.shared / 1024 / 1024:.2f} MB\n"")
        f.write(f""  æ–‡æœ¬æ®µ: {memory_info.text / 1024 / 1024:.2f} MB\n"")
        f.write(f""  æ•°æ®æ®µ: {memory_info.data / 1024 / 1024:.2f} MB\n"")
        f.write(f""  åº“å†…å­˜: {memory_info.lib / 1024 / 1024:.2f} MB\n"")
        f.write(f""  è„é¡µ: {memory_info.dirty / 1024 / 1024:.2f} MB\n"")
        
        # ç³»ç»Ÿå†…å­˜ä¿¡æ¯
        system_memory = psutil.virtual_memory()
        f.write(f""\nç³»ç»Ÿå†…å­˜:\n"")
        f.write(f""  æ€»å†…å­˜: {system_memory.total / 1024 / 1024 / 1024:.2f} GB\n"")
        f.write(f""  å¯ç”¨å†…å­˜: {system_memory.available / 1024 / 1024 / 1024:.2f} GB\n"")
        f.write(f""  ä½¿ç”¨çŽ‡: {system_memory.percent:.2f}%\n"")
        f.write(f""  ç¼“å­˜: {system_memory.cached / 1024 / 1024 / 1024:.2f} GB\n"")
        f.write(f""  ç¼“å†²åŒº: {system_memory.buffers / 1024 / 1024 / 1024:.2f} GB\n"")
        
        f.write(""\n"" + ""="" * 100 + ""\n\n"")
",app/helper/memory.py,MemoryHelper,1,1.0467401685178159e-08,"The method '_write_detailed_system_analysis' is a utility function that writes detailed system memory analysis to a file. It uses the 'psutil' library to gather memory information about the current process and the system. This kind of functionality is useful for logging, debugging, or monitoring purposes, especially in systems where memory usage is critical. The method is well-structured, provides detailed information, and is likely to be useful in various contexts where system analysis is required. Therefore, it is likely to be retained in the codebase."
survived,"    def _get_unaccounted_memory(self) -> float:
        """"""
        è®¡ç®—æœªç»Ÿè®¡çš„å†…å­˜ï¼ˆå¯èƒ½æ˜¯Cæ‰©å±•ã€ç³»ç»Ÿç¼“å­˜ç­‰ï¼‰
        """"""
        try:
            # èŽ·å–è¿›ç¨‹æ€»å†…å­˜
            process = psutil.Process()
            total_memory = process.memory_info().rss / 1024 / 1024  # MB
            
            # èŽ·å–Pythonå¯¹è±¡æ€»å†…å­˜
            all_objects = muppy.get_objects()
            sum1 = summary.summarize(all_objects)
            
            python_total_mb = 0
            for line in summary.format_(sum1):
                if '|' in line and line.strip() and not line.startswith('=') and not line.startswith('-'):
                    parts = line.split('|')
                    if len(parts) >= 3:
                        try:
                            size_str = parts[2].strip()
                            if 'MB' in size_str:
                                size_mb = float(size_str.replace('MB', '').strip())
                                python_total_mb += size_mb
                        except:
                            pass
            
            return max(0, total_memory - python_total_mb)
        except:
            return 0.0
",app/helper/memory.py,MemoryHelper,1,2.5109990926928157e-08,"The method `_get_unaccounted_memory` is a utility function that calculates the difference between the total memory used by a process and the memory used by Python objects. This can be useful for identifying memory usage by C extensions or system caches that are not accounted for by Python's memory management. The method is well-defined, handles exceptions, and provides a meaningful output. Such functionality is often necessary for debugging and optimizing memory usage in applications, making it likely to be retained."
survived,"    async def test_latest_run_with_null_metadata(
        self,
        test_api_client: AsyncClient,
        returned_run: AgentRun,
    ):
        """"""Test that null metadata is handled correctly""""""
        returned_run.metadata = None

        response = await test_api_client.get(""/v1/_/agents/bla/runs/latest"")
        assert response.status_code == 200

        response_data = response.json()
        assert response_data[""id""] == returned_run.id
        # metadata should not be present in response when it's None (due to response_model_exclude_none=True)
        assert ""metadata"" not in response_data
",api/api/routers/runs_v1_test.py,TestLatestRun,1,8.152020648014727e-09,The method is a test case that verifies the correct handling of null metadata in a specific API endpoint. It is important for ensuring the robustness and correctness of the API's behavior when dealing with null values. Test cases like this are crucial for maintaining software quality and are unlikely to be deleted unless the functionality they test is removed or significantly changed.
survived,"    def test_no_changes_scenario(self, mock_config, mock_logger):
        """"""Test scenario where package exists but has no changes""""""

        # Setup existing package
        existing_pkg_id = uuid4()
        existing_package = Package(
            id=existing_pkg_id,
            derived_id=""pkgx/unchanged-pkg"",
            name=""unchanged-pkg"",
            package_manager_id=mock_config.pm_config.pm_id,
            import_id=""unchanged-pkg"",
            readme=""Unchanged description"",
        )

        cache = Cache(
            package_map={""unchanged-pkg"": existing_package},
            url_map={},
            package_urls={},
            dependencies={},
        )

        # Create package data with same description
        pkg_data = create_pkgx_package()

        # Test the diff
        diff = PkgxDiff(mock_config, cache, mock_logger)
        pkg_id, pkg_obj, update_payload = diff.diff_pkg(""unchanged-pkg"", pkg_data)

        # Assertions
        assert pkg_id == existing_pkg_id
        assert pkg_obj is None  # No new package
        assert update_payload is None  # No changes
",tests/package_managers/pkgx/test_pkgx_diff.py,TestPkgxDifferentialLoading,1,7.194132978569833e-09,"The method 'test_no_changes_scenario' is a unit test designed to verify that when a package has no changes, the system correctly identifies that there is no need for an update. This is a valid and useful test case to ensure the stability and correctness of the package management system. It checks that the diff operation does not mistakenly identify changes when there are none, which is crucial for avoiding unnecessary updates. Therefore, this method is likely to be retained as part of the test suite."
deleted,"    def _is_github_url(self, url: str) -> bool:
        """"""Check if URL is a GitHub URL""""""
        from package_managers.pkgx.transformer import PkgxTransformer

        temp_transformer = PkgxTransformer(self.config, None)
        return temp_transformer.is_github(url)",package_managers/pkgx/diff.py,PkgxDiff,1,3.2241866333029355e-08,"The method `_is_github_url` is a simple utility function that checks if a given URL is a GitHub URL by utilizing a method from the `PkgxTransformer` class. This method is likely to be useful in contexts where URLs need to be validated or filtered based on their source, specifically for GitHub. Since it serves a clear purpose and is likely to be used in various parts of a codebase dealing with package management or URL validation, it is more likely to be retained rather than deleted."
survived,"    def test_dependency_type_priority_with_test(self, mock_config, mock_logger):
        """"""Test priority handling with test dependencies: Runtime > Build > Test""""""

        p1_id = uuid4()
        p2_id = uuid4()
        p3_id = uuid4()
        p4_id = uuid4()

        p1_pkg = Package(id=p1_id, derived_id=""pkgx/p1"", name=""p1"", import_id=""p1"")
        p2_pkg = Package(id=p2_id, derived_id=""pkgx/p2"", name=""p2"", import_id=""p2"")
        p3_pkg = Package(id=p3_id, derived_id=""pkgx/p3"", name=""p3"", import_id=""p3"")
        p4_pkg = Package(id=p4_id, derived_id=""pkgx/p4"", name=""p4"", import_id=""p4"")

        cache = Cache(
            package_map={""p1"": p1_pkg, ""p2"": p2_pkg, ""p3"": p3_pkg, ""p4"": p4_pkg},
            url_map={},
            package_urls={},
            dependencies={},
        )

        # Parsed data with overlapping dependencies across different types
        new_pkg_data = create_pkgx_package(
            dependencies=[""p2"", ""p3""],  # runtime: p2, p3
            build_deps=[""p2"", ""p4""],  # build: p2, p4
            test_deps=[""p2"", ""p3"", ""p4""],  # test: p2, p3, p4
        )

        diff = PkgxDiff(mock_config, cache, mock_logger)
        new_deps, removed_deps = diff.diff_deps(""p1"", new_pkg_data)

        # Should create dependencies based on priority:
        # p2: runtime (highest priority among runtime/build/test)
        # p3: runtime (highest priority among runtime/test)
        # p4: build (highest priority among build/test)
        assert len(removed_deps) == 0
        assert len(new_deps) == 3

        # Sort by dependency_id for consistent testing
        new_deps_sorted = sorted(new_deps, key=lambda d: str(d.dependency_id))

        # p2 should be runtime (highest priority)
        p2_dep = next(d for d in new_deps_sorted if d.dependency_id == p2_id)
        assert p2_dep.dependency_type_id == mock_config.dependency_types.runtime

        # p3 should be runtime (highest priority)
        p3_dep = next(d for d in new_deps_sorted if d.dependency_id == p3_id)
        assert p3_dep.dependency_type_id == mock_config.dependency_types.runtime

        # p4 should be build (highest available priority)
        p4_dep = next(d for d in new_deps_sorted if d.dependency_id == p4_id)
        assert p4_dep.dependency_type_id == mock_config.dependency_types.build",tests/package_managers/pkgx/test_pkgx_diff.py,TestPkgxDifferentialLoading,1,4.363462233903899e-09,"The method is a unit test that verifies the correct prioritization of dependencies based on their type (runtime, build, test). It is well-structured, uses mock objects, and includes assertions to validate the expected behavior. Such tests are crucial for ensuring the reliability of the dependency management system, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained."
survived,"def launch_model(model_key: str):
    model_config = models[model_key]
    print(f""Launching {model_key} ({model_config['model_name']}) on SkyPilotâ€¦"")

    setup_script = textwrap.dedent(
        """"""
            echo 'Setting up environment...'
            apt update && apt install -y nvtop
            curl -LsSf https://astral.sh/uv/install.sh | sh
            source $HOME/.local/bin/env

            # Install project in editable mode
            uv remove openpipe-art
            uv add --editable ~/workspace

            # Sync dependencies
            uv sync
            
            # Set up tau-bench specific dependencies if needed
            cd ~/workspace/dev/tau-bench
        """"""
    )

    # Construct the run_rl.py command with all necessary arguments
    run_args = [
        f""--model-name {model_config['model_name']}"",
        f""--base-model {model_config['base_model']}"",
        f""--env {model_config['env']}"",
        f""--model {model_config['model']}"",
        f""--model-provider {model_config['model_provider']}"",
        f""--user-model {model_config['user_model']}"",
        f""--user-model-provider {model_config['user_model_provider']}"",
        f""--agent-strategy {model_config['agent_strategy']}"",
        f""--temperature {model_config['temperature']}"",
        f""--task-split {model_config['task_split']}"",
        f""--start-index {model_config['start_index']}"",
        f""--end-index {model_config['end_index']}"",
        f""--trajectories-per-group {model_config['trajectories_per_group']}"",
        f""--groups-per-step {model_config['groups_per_step']}"",
        f""--learning-rate {model_config['learning_rate']}"",
        f""--eval-steps {model_config['eval_steps']}"",
        f""--val-set-size {model_config['val_set_size']}"",
        f""--training-dataset-size {model_config['training_dataset_size']}"",
        f""--num-epochs {model_config['num_epochs']}"",
    ]

    run_script = textwrap.dedent(f""""""
        echo 'Starting tau-bench RL training...'
        cd ~/workspace/dev/tau-bench
        
        # Ensure project is installed in editable mode
        uv remove openpipe-art
        uv add --editable ~/workspace
        
        # Run the RL training
        uv run run_rl.py {' '.join(run_args)}
    """""")

    # Create a SkyPilot Task
    task = sky.Task(
        name=f""tau-bench-rl-{model_key}"",
        setup=setup_script,
        run=run_script,
        workdir=""."",  # Sync the project directory
        envs=dict(dotenv_values()),
    )
    task.set_resources(sky.Resources(accelerators=""H100-SXM:1""))
    task.set_file_mounts({""~/workspace"": "".""})

    # Generate cluster name
    cluster_name = f""tau-bench-rl-{model_key}""
    print(f""Launching task on cluster: {cluster_name}"")

    print(""Checking for existing cluster and jobsâ€¦"")
    cluster_status = sky.get(sky.status(cluster_names=[cluster_name]))
    if len(cluster_status) > 0 and cluster_status[0][""status""] == ClusterStatus.UP:
        print(f""Cluster {cluster_name} is UP. Canceling any active jobsâ€¦"")
        sky.stream_and_get(sky.cancel(cluster_name, all=True))

    # Launch the task; stream_and_get blocks until the task starts running, but
    # running this in its own thread means all models run in parallel.
    job_id, _ = sky.stream_and_get(
        sky.launch(
            task,
            cluster_name=cluster_name,
            retry_until_up=True,
            idle_minutes_to_autostop=60,
            down=True,
            fast=args.fast,
        )
    )

    print(f""Job submitted for {model_key} (ID: {job_id}). Streaming logsâ€¦"")
    exit_code = sky.tail_logs(cluster_name=cluster_name, job_id=job_id, follow=True)
    print(f""Job {job_id} for {model_key} finished with exit code {exit_code}."")
",run_training.py,,1,1.0467401685178159e-08,"The method 'launch_model' is a comprehensive function that sets up and launches a machine learning model training task using SkyPilot. It includes detailed setup scripts, command construction, and task management, which are essential for automating model training workflows. The method is well-structured, uses external libraries effectively, and handles various configurations dynamically. Such functionality is crucial for scalable and efficient model deployment, making it unlikely to be deleted unless there is a significant change in the underlying infrastructure or a better abstraction is introduced."
survived,"    def column_list_formats(self) -> Dict[str, str]:
        """"""Get column list formats from preset options""""""
        config = [
            option
            for option in self.options
            if option.get(""label"", """").lower() == ""column_list_formats""
        ]
        if not config:
            return {}
        return config[0].get(""value"", {})
",keep/api/models/db/preset.py,PresetDto,1,1.955568070542584e-08,"The method 'column_list_formats' is a utility function that retrieves a specific configuration from a list of options. It is straightforward, performs a clear task, and is likely part of a larger system that relies on configuration management. Such methods are generally useful for maintaining flexibility and adaptability in software systems, allowing for easy updates and changes to configurations without altering the core logic. Therefore, it is likely to be retained as it serves a specific purpose in the codebase."
survived,"def test_semantic_gather_with_peripheral():
    """"""Test semantic gather operation with peripheral chunks configuration.""""""
    # Create test data with more chunks for context
    df = pd.DataFrame({
        ""doc_id"": [""doc1""] * 5,
        ""chunk_num"": [1, 2, 3, 4, 5],
        ""content"": [f""Chunk {i} content"" for i in range(1, 6)]
    })
    
    result = df.semantic.gather(
        content_key=""content"",
        doc_id_key=""doc_id"",
        order_key=""chunk_num"",
        peripheral_chunks={
            ""previous"": {""head"": {""count"": 1}, ""tail"": {""count"": 1}},
            ""next"": {""head"": {""count"": 1}, ""tail"": {""count"": 1}}
        }
    )
    
    assert isinstance(result, pd.DataFrame)
    assert len(result) == len(df)
    assert ""content_rendered"" in result.columns
    
    # Check that middle chunks have context from surrounding chunks
    middle_chunk = result[result[""chunk_num""] == 3].iloc[0]
    rendered = middle_chunk[""content_rendered""]
    
    # Should contain previous and next context markers
    assert ""--- Previous Context ---"" in rendered
    assert ""--- Next Context ---"" in rendered
    assert ""--- Begin Main Chunk ---"" in rendered
    assert ""--- End Main Chunk ---"" in rendered
",tests/test_pandas_accessors.py,,1,2.699578619062706e-07,"The method is a test function that verifies the functionality of a semantic gather operation with a specific configuration. It is well-structured, includes assertions to validate the expected behavior, and provides a clear purpose in its docstring. Such test functions are crucial for ensuring code reliability and are typically retained in codebases to maintain software quality."
survived,"def test_semantic_gather_basic():
    """"""Test semantic gather operation basic functionality.""""""
    # Create test data that simulates document chunks
    df = pd.DataFrame({
        ""doc_id"": [""doc1"", ""doc1"", ""doc1"", ""doc2"", ""doc2""],
        ""chunk_num"": [1, 2, 3, 1, 2],
        ""content"": [
            ""First chunk of document 1"",
            ""Second chunk of document 1"", 
            ""Third chunk of document 1"",
            ""First chunk of document 2"",
            ""Second chunk of document 2""
        ]
    })
    
    result = df.semantic.gather(
        content_key=""content"",
        doc_id_key=""doc_id"",
        order_key=""chunk_num""
    )
    
    assert isinstance(result, pd.DataFrame)
    assert len(result) == len(df)  # Same number of rows
    assert ""content_rendered"" in result.columns
    
    # Check that rendered content includes the original content
    for i, row in result.iterrows():
        assert row[""content""] in row[""content_rendered""]
",tests/test_pandas_accessors.py,,1,7.194132978569833e-09,"The method 'test_semantic_gather_basic' is a unit test for a specific functionality, likely related to a custom or extended DataFrame method 'semantic.gather'. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with custom operations. The presence of assertions to verify the output suggests that this test is actively used to validate the behavior of the 'semantic.gather' method. Unless the 'semantic.gather' method itself is deprecated or removed, this test is likely to survive as it serves an important role in maintaining code quality."
survived,"    def test_cost_report_endpoint_calls_core(self, mock_core_cost_report):
        """"""Test that cost_report server endpoint calls core function with correct args.""""""
        mock_core_cost_report.return_value = []
        
        # Create mock request and body
        mock_request = mock.Mock()
        mock_request.state.request_id = 'test_request_id'
        
        cost_report_body = payloads.CostReportBody(days=15)
        
        # Import and test the server function
        from sky.server import server
        
        with mock.patch('sky.server.server.executor.schedule_request') as mock_schedule:
            # Call the server endpoint
            import asyncio
            asyncio.run(server.cost_report(mock_request, cost_report_body))
            
            # Verify executor.schedule_request was called with correct parameters
            mock_schedule.assert_called_once()
            call_args = mock_schedule.call_args
            
            self.assertEqual(call_args[1]['request_id'], 'test_request_id')
            self.assertEqual(call_args[1]['request_name'], 'cost_report')
            self.assertEqual(call_args[1]['request_body'], cost_report_body)
            self.assertEqual(call_args[1]['func'], server.core.cost_report)
",tests/unit_tests/test_sky_cost_report.py,TestCostReportServer,1,2.9023122007764653e-06,"The method is a unit test for a specific functionality, ensuring that the cost_report server endpoint correctly calls the core function with the expected arguments. Unit tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered."
survived,"    def test_cost_report_with_missing_instance_type(self):
        """"""Test cost report doesn't crash when historical cluster has unknown instance type.""""""
        # Mock a cluster record with an instance type that doesn't exist in catalogs
        mock_cluster_record = {
            'name': 'old-cluster',
            'status': None,  # Historical cluster
            'num_nodes': 2,
            'resources': mock.Mock(),
            'total_cost': 0.0,
            'launched_at': 1640995200,  # Some timestamp
            'duration': 3600,
            'cluster_hash': 'abc123',
            'usage_intervals': [(1640995200, 1640998800)],
            'user_hash': 'user123',
            'user_name': 'testuser',
            'workspace': 'default',
        }
        
        # Mock the resources object to have an unknown instance type
        mock_cluster_record['resources'].instance_type = 'unknown-instance-type-v1'
        mock_cluster_record['resources'].cloud = mock.Mock()
        mock_cluster_record['resources'].cloud.__str__ = lambda: 'aws'
        
        # Mock catalog functions to return None for unknown instance type
        with mock.patch('sky.catalog.get_hourly_cost', return_value=None):
            with mock.patch('sky.global_user_state.get_clusters_from_history', 
                          return_value=[mock_cluster_record]):
                
                # This should not raise an exception
                result = core.cost_report(days=30)
                
                # Should return the cluster even if cost calculation fails
                self.assertEqual(len(result), 1)
                self.assertEqual(result[0]['name'], 'old-cluster')
",tests/unit_tests/test_sky_cost_report.py,TestHistoricalClusterRobustness,1,6.023574641292144e-08,"The method is a test case that ensures the system can handle a specific edge case without crashing. It is important for maintaining the robustness of the system when dealing with historical data that may not match current catalogs. Such test cases are crucial for regression testing and ensuring system stability, especially when dealing with external dependencies like cloud instance types. Therefore, it is likely to be retained."
survived,"    def diff_url(
        self, import_id: str, debian_data: DebianData, new_urls: dict[URLKey, URL]
    ) -> dict[UUID, UUID]:
        """"""Given a package's URLs, returns the resolved URL for this specific package""""""
        resolved_urls: dict[UUID, UUID] = {}

        # Generate the URLs for this package
        urls = self._generate_chai_urls(debian_data)

        # Process each URL
        for url_key in urls:
            # guard: _generate_chai_urls could be None for a url type
            if url_key is None:
                continue

            resolved_url_id: UUID

            if url_key in new_urls:
                resolved_url_id = new_urls[url_key].id
            elif url_key in self.caches.url_map:
                resolved_url_id = self.caches.url_map[url_key].id
            else:
                self.logger.debug(
                    f""URL {url_key.url} as {url_key.url_type_id} is entirely new""
                )
                new_url = URL(
                    id=uuid4(),
                    url=url_key.url,
                    url_type_id=url_key.url_type_id,
                    created_at=self.now,
                    updated_at=self.now,
                )
                resolved_url_id = new_url.id
                new_urls[url_key] = new_url

            resolved_urls[url_key.url_type_id] = resolved_url_id

        return resolved_urls
",package_managers/debian/diff.py,DebianDiff,1,4.944450477491054e-09,"The method 'diff_url' is a utility function that processes URLs for a package, resolving them based on existing or new data. It is a specific and useful function for managing URL data within a system that handles Debian packages. The method is well-structured, with clear logic for handling different cases of URL resolution, including logging for new URLs. This functionality is likely essential for the system's operation, especially if it deals with package management or data synchronization. Therefore, it is unlikely to be deleted unless there is a significant change in the system's architecture or requirements."
survived,"    def test_enrich_package_missing_source_warning(self, caplog, mock_logger):
        """"""Test warning when package references missing source""""""
        from package_managers.debian.main import enrich_package_with_source

        # Create package data with source that doesn't exist in mapping
        package_data = create_debian_package(
            package=""orphan-pkg"",
            description=""An orphaned package"",
        )
        package_data.source = ""missing-source""

        # Empty source mapping
        source_mapping = {}

        # Enrich package (this should log a warning)
        enriched = enrich_package_with_source(package_data, source_mapping, mock_logger)

        # The warning should be present in the function execution output
        # Check the logged warning message directly
        # Note: The warning is logged by our function, so we check the expected behavior

        # Package should remain unchanged
        assert enriched.package == ""orphan-pkg""
        assert enriched.description == ""An orphaned package""
        assert not enriched.vcs_git
        assert not enriched.vcs_browser
",tests/package_managers/debian/test_debian_sources.py,TestPackageSourceMapping,1,1.0467401685178159e-08,"The method `test_enrich_package_missing_source_warning` is a unit test designed to verify the behavior of the `enrich_package_with_source` function when a package references a missing source. Unit tests are crucial for ensuring code reliability and correctness, especially in handling edge cases like missing data. This test checks that a warning is logged and that the package data remains unchanged when the source is missing. Such tests are typically retained to maintain code quality and prevent regressions."
survived,"def test_linux(linux):
    m = mock_open(read_data=linux)

    with patch(""builtins.open"", m):
        result = parse_sources_file(""dummy"")

    assert ""linux-headers-6.1.0-32-amd64"" in result[""linux""]
    assert ""linux-headers-6.1.0-32-cloud-amd64"" in result[""linux""]",package_managers/debian/scripts/test_investigate_sources.py,,1,1.8189616842444243e-09,"The method `test_linux` is a unit test function that uses mocking to test the `parse_sources_file` function. It checks if specific strings are present in the result of the `parse_sources_file` function. This is a typical pattern in unit testing to ensure that the function under test behaves as expected. Since testing is a crucial part of software development to ensure code quality and reliability, this method is likely to be retained. It is not obsolete or redundant, and it serves a clear purpose in the testing suite."
survived,"def start_task():
    """"""Start a new Claude Code automation task""""""
    try:
        data = request.get_json()
        
        if not data:
            return jsonify({'error': 'No data provided'}), 400
            
        prompt = data.get('prompt')
        repo_url = data.get('repo_url')
        branch = data.get('branch', 'main')
        github_token = data.get('github_token')
        model = data.get('model', 'claude')  # Default to claude for backward compatibility
        
        if not all([prompt, repo_url, github_token]):
            return jsonify({'error': 'prompt, repo_url, and github_token are required'}), 400
        
        # Validate model selection
        if model not in ['claude', 'codex']:
            return jsonify({'error': 'model must be either ""claude"" or ""codex""'}), 400
        
        # Generate unique task ID
        task_id = str(uuid.uuid4())
        
        # Initialize task
        tasks[task_id] = {
            'id': task_id,
            'status': TaskStatus.PENDING,
            'prompt': prompt,
            'repo_url': repo_url,
            'branch': branch,
            'github_token': github_token,
            'model': model,
            'container_id': None,
            'commit_hash': None,
            'git_diff': None,
            'error': None,
            'created_at': time.time()
        }
        
        # Save tasks after creating
        save_tasks()
        
        # Start task in background thread
        thread = threading.Thread(target=run_ai_code_task, args=(task_id,))
        thread.daemon = True
        thread.start()
        
        return jsonify({
            'status': 'success',
            'task_id': task_id,
            'message': 'Task started successfully'
        })
        
    except Exception as e:
        logger.error(f""Error starting task: {str(e)}"")
        return jsonify({'error': str(e)}), 500
",server/tasks.py,,1,2.998960815863541e-09,"The method 'start_task' is a well-structured function that handles the initiation of a task with proper error handling, validation, and asynchronous execution. It checks for required data, validates inputs, generates a unique task ID, and starts a background thread to handle the task. These are all good practices for a robust API endpoint. Additionally, it logs errors and returns appropriate HTTP responses, which are essential for debugging and user feedback. Given these factors, the method is likely to be useful and relevant in its context, leading to its survival."
survived,"def create_project():
    """"""Create a new project""""""
    try:
        data = request.get_json()
        user_id = request.headers.get('X-User-ID')
        
        if not user_id:
            return jsonify({'error': 'User ID required'}), 400
        
        if not data:
            return jsonify({'error': 'No data provided'}), 400
        
        # Required fields
        name = data.get('name')
        repo_url = data.get('repo_url')
        
        if not all([name, repo_url]):
            return jsonify({'error': 'name and repo_url are required'}), 400
        
        # Parse GitHub URL
        try:
            repo_owner, repo_name = parse_github_url(repo_url)
        except ValueError as e:
            return jsonify({'error': str(e)}), 400
        
        # Optional fields
        description = data.get('description', '')
        settings = data.get('settings', {})
        
        project = DatabaseOperations.create_project(
            user_id=user_id,
            name=name,
            description=description,
            repo_url=repo_url,
            repo_name=repo_name,
            repo_owner=repo_owner,
            settings=settings
        )
        
        return jsonify({
            'status': 'success',
            'project': project
        })
        
    except Exception as e:
        logger.error(f""Error creating project: {str(e)}"")
        return jsonify({'error': str(e)}), 500
",server/projects.py,,1,1.2501528648238603e-09,"The method 'create_project' is likely to survive because it is a well-structured function that handles the creation of a project with proper error handling and validation. It checks for required fields, parses the GitHub URL, and uses a database operation to create the project. Additionally, it logs errors and returns appropriate HTTP responses, which are good practices in web development."
survived,"    def update_project(project_id: int, user_id: str, updates: Dict) -> Optional[Dict]:
        """"""Update a project""""""
        try:
            updates['updated_at'] = datetime.utcnow().isoformat()
            result = supabase.table('projects').update(updates).eq('id', project_id).eq('user_id', user_id).execute()
            return result.data[0] if result.data else None
        except Exception as e:
            logger.error(f""Error updating project {project_id}: {e}"")
            raise
",server/database.py,DatabaseOperations,1,5.905303995456778e-10,"The method 'update_project' is a well-defined function that performs a common and necessary operation in many applications: updating a project record in a database. It includes error handling, logging, and returns a result, which are all good practices. The use of 'supabase' for database operations is modern and relevant, and the function signature is clear and concise. These factors suggest that the method is useful and follows good coding practices, making it likely to be retained in the codebase."
survived,"def combine_files(file_list: List[str]) -> Dict:
    """"""
    Combine multiple metadata files into a single merged dictionary.
    
    Args:
        file_list: List of file paths to combine
        
    Returns:
        Merged metadata dictionary
    """"""
    metadata_list = []
    for filepath in file_list:
        metadata = load_metadata_file(filepath)
        if metadata:  # Only add non-empty metadata
            metadata_list.append(metadata)
    
    return merge_metadata(metadata_list)
",combine_metadata.py,,1,7.05287985061473e-11,"The method 'combine_files' is likely to survive because it performs a useful and common task of combining multiple metadata files into a single dictionary. This functionality is often needed in data processing and management tasks. The method is also well-documented, specifying its purpose, arguments, and return value, which makes it easy to understand and maintain. Additionally, it includes a check to ensure only non-empty metadata is added, which is a good practice to prevent errors. Overall, the method is practical, clear, and efficient, which are qualities that contribute to its survival."
survived,"    def test_mcp_custom_host_port(self, runner, temp_python_script):
        """"""Test MCP mode with custom host and port.""""""
        with patch(""langflow.cli.commands.run_mcp_server"") as mock_run_mcp:
            mock_run_mcp.side_effect = KeyboardInterrupt(""Test interrupt"")
            
            result = runner.invoke(app, [
                ""serve"", str(temp_python_script),
                ""--mcp"", ""--mcp-transport"", ""sse"",
                ""--host"", ""0.0.0.0"",
                ""--port"", ""9000"",
                ""--verbose""
            ])
            
            # Verify custom host and port were passed
            mock_run_mcp.assert_called_once()
            run_args = mock_run_mcp.call_args
            assert run_args[1][""host""] == ""0.0.0.0""
            assert run_args[1][""port""] == 9000
",src/backend/tests/unit/test_cli.py,TestMCPServeCommand,1,1.8189616842444243e-09,"The method `test_mcp_custom_host_port` is a unit test designed to verify that a specific feature (MCP mode with custom host and port) works as expected. Unit tests are crucial for ensuring code reliability and are typically maintained as long as the feature they test is relevant. Since the method is testing a specific functionality and there is no indication that this functionality is deprecated or irrelevant, it is likely to be retained."
survived,"    def test_flow_input_validation_error(self):
        """"""Test FlowInput validation with invalid data.""""""
        # Missing required field should raise validation error
        with pytest.raises(ValidationError):
            FlowInput()  # Missing input_value
",src/backend/tests/unit/test_mcp_server.py,TestMCPServerErrorHandling,1,2.3355930333443423e-09,"The method 'test_flow_input_validation_error' is a unit test designed to ensure that the 'FlowInput' class raises a 'ValidationError' when instantiated without required fields. This is a common and necessary test to ensure data validation is working correctly. Unit tests like this are crucial for maintaining code quality and preventing regressions, especially in systems that rely on strict data validation. Therefore, this method is likely to be retained as part of the test suite."
deleted,"            def decorator(func):
                registered_resources.append((uri, func))
                return func
",src/backend/tests/unit/test_mcp_server.py,TestMCPServerIntegration,1,2.2159489282323004e-08,"The method is a simple decorator function that registers a function with a URI by appending it to a list called 'registered_resources'. This is a common pattern in web frameworks for routing or resource management. The method is functional, concise, and serves a clear purpose, making it likely to be retained in the codebase."
survived,"    def test_run_mcp_server_sse(self, mock_fastmcp):
        """"""Test running MCP server with SSE transport.""""""
        mock_mcp_instance = MagicMock()
        mock_mcp_instance.run = MagicMock()

        run_mcp_server(
            mcp_server=mock_mcp_instance,
            transport=""sse"",
            host=""0.0.0.0"",
            port=8080
        )

        # Should call run() with transport, host, and port
        mock_mcp_instance.run.assert_called_once_with(
            transport=""sse"",
            host=""0.0.0.0"",
            port=8080
        )
",src/backend/tests/unit/test_mcp_server.py,TestMCPServerRuntime,1,1.8189616842444243e-09,"The method `test_run_mcp_server_sse` is a unit test designed to verify the behavior of the `run_mcp_server` function when using SSE transport. Unit tests are crucial for ensuring code reliability and are typically maintained as long as the functionality they test is relevant. Since the method is testing a specific feature (SSE transport) of the `run_mcp_server` function, it is likely to be retained unless the feature itself is deprecated or the testing framework changes significantly. Therefore, the method is likely to survive."
deleted,"    def list_flows() -> str:
        """"""List all available flows with their metadata.""""""
        flows_info = []
        for flow_id, graph in graphs.items():
            meta = metas.get(flow_id, {})
            flow_info = FlowInfo(
                id=flow_id,
                title=getattr(meta, 'title', flow_id),
                description=getattr(meta, 'description', None),
                inputs=None,  # Could be expanded to include input schema
                outputs=None  # Could be expanded to include output schema
            )
            flows_info.append(flow_info.model_dump())
        
        return json.dumps(flows_info, indent=2)
",src/backend/base/langflow/cli/mcp_server.py,,1,1.6052280526088547e-09,"The method 'list_flows' is likely to survive because it provides a useful functionality of listing all available flows with their metadata. This is a common requirement in systems that manage workflows or processes, as it allows users to understand what flows are available and their basic details. The method is also well-structured, using a loop to gather information and returning it in a JSON format, which is a standard and widely used data interchange format. Additionally, the method includes placeholders for future expansion (inputs and outputs), indicating that it is designed with scalability in mind."
survived,"    def from_file(cls, file_path: Path) -> ""Registry"":
        """"""Load registry from a JSON file.

        Args:
            file_path: Path to the registry JSON file

        Returns:
            Registry: The loaded registry

        Raises:
            FileNotFoundError: If the file doesn't exist
            json.JSONDecodeError: If the file contains invalid JSON
            ValidationError: If the data doesn't match the expected schema
        """"""
        with open(file_path, ""r"") as f:
            data = json.load(f)
        return cls.from_json_list(data)
",terminal_bench/registry/client.py,Registry,1,7.582560422162384e-10,"The method 'from_file' is a utility function that provides a convenient way to load a 'Registry' object from a JSON file. It includes error handling for common issues such as file not found and invalid JSON, which are essential for robust file operations. Additionally, it uses a class method to create an instance from a JSON list, indicating that it is part of a well-structured class design. These factors suggest that the method is useful and likely to be retained in the codebase."
survived,"def cost_per_token(model: str, usage: Usage) -> Tuple[float, float]:
    """"""
    Calculates the cost per token for a given model, prompt tokens, and completion tokens.

    Follows the same logic as other provider cost calculations.
    """"""
    return generic_cost_per_token(
        model=model, usage=usage, custom_llm_provider=""moonshot""
    )",litellm/llms/moonshot/cost_calculator.py,,1,5.211412485172657e-10,"The method 'cost_per_token' is likely to survive because it provides a specific utility in calculating the cost per token for a given model and usage. This is a common requirement in applications dealing with language models, where understanding and managing costs is crucial. The method is also flexible, as it uses a generic function 'generic_cost_per_token' with a custom provider, indicating it can be adapted for different providers if needed. Unless there is a significant change in how costs are calculated or the method becomes redundant due to new implementations, it is likely to remain useful."
survived,"    def test_csharp_local_functions_and_nested(self):
        patch = """"""
@@ -152,10 +152,6 @@ void OuterMethod()
{
    void InnerFunction()
    {
        // local function inside method
    }
}

@@ -165,15 +165,15 @@ static int Calculate(int x)

@@ -175,18 +175,18 @@ async Task<string> ProcessDataAsync()

@@ -185,20 +185,20 @@ T GenericLocalFunction<T>(T input)

""""""

        assert CSharpParser.extract_functions_from_patch(patch) == {
            ""OuterMethod"",
            ""InnerFunction"",
            ""Calculate"",
            ""ProcessDataAsync"",
            ""GenericLocalFunction"",
        }
",tests/sentry/integrations/source_code_management/test_language_parsers.py,CSharpParserTestCase,1,1.6052280526088547e-09,"The method `test_csharp_local_functions_and_nested` is a unit test designed to verify the functionality of the `CSharpParser.extract_functions_from_patch` method. It checks if the method correctly identifies and extracts function names from a given patch of C# code. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with code parsing and analysis. Therefore, this method is likely to be retained as it serves an important role in maintaining the quality of the codebase."
survived,"    def test_csharp_generics_and_complex_types(self):
        patch = """"""
@@ -152,10 +152,6 @@ public List<T> GetItems<T>()

@@ -152,10 +152,6 @@ public Dictionary<string, int> GetDictionary()

@@ -152,10 +152,6 @@ public async Task<List<string>> GetStringsAsync()

@@ -152,10 +152,6 @@ public T[] GetArray<T>(int size)

@@ -152,10 +152,6 @@ public void ProcessItems(List<Dictionary<string, object>> items)

@@ -152,10 +152,6 @@ public Func<int, bool> GetPredicate()

@@ -152,10 +152,6 @@ public Action<string> GetAction()

@@ -152,10 +152,6 @@ public int? GetNullableInt()

""""""

        assert CSharpParser.extract_functions_from_patch(patch) == {
            ""GetItems"",
            ""GetDictionary"",
            ""GetStringsAsync"",
            ""GetArray"",
            ""ProcessItems"",
            ""GetPredicate"",
            ""GetAction"",
            ""GetNullableInt"",
        }
",tests/sentry/integrations/source_code_management/test_language_parsers.py,CSharpParserTestCase,1,8.592166611791576e-10,"The method `test_csharp_generics_and_complex_types` is a unit test that verifies the functionality of the `CSharpParser.extract_functions_from_patch` method. It checks if the method correctly extracts function names from a given patch. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with complex parsing logic. Therefore, this method is likely to be retained as it serves an important role in maintaining the quality of the codebase."
survived,"    def test_csharp_real_world_example(self):
        # Based on a typical C# class with various method types
        patch = """"""
@@ -73,9 +73,7 @@ public UserService(IUserRepository repository)

@@ -87,7 +87,8 @@ public async Task<User> GetUserAsync(int id)

@@ -95,6 +95,7 @@ public bool ValidateUser(User user)

@@ -103,4 +107,23 @@ private void LogUserAction(string action)

@@ -115,6 +118,13 @@ public static UserService CreateDefault()

@@ -125,7 +125,7 @@ protected virtual void OnUserChanged(UserEventArgs e)

@@ -135,8 +135,8 @@ public void Dispose()

@@ -145,10 +145,10 @@ ~UserService()

@@ -155,12 +155,12 @@ public string Name
{
    get { return _name; }
    set { _name = value; }
}

@@ -168,15 +168,15 @@ public int Count => _users.Count;

@@ -180,18 +180,18 @@ public User this[int index] => _users[index];

""""""

        assert CSharpParser.extract_functions_from_patch(patch) == {
            ""UserService"",
            ""GetUserAsync"",
            ""ValidateUser"",
            ""LogUserAction"",
            ""CreateDefault"",
            ""OnUserChanged"",
            ""Dispose"",
            ""get"",
            ""set"",
            ""Count"",
        }
",tests/sentry/integrations/source_code_management/test_language_parsers.py,CSharpParserTestCase,1,3.653482080241728e-08,"The method `test_csharp_real_world_example` is a test method that verifies the functionality of the `CSharpParser.extract_functions_from_patch` method. It checks if the method correctly extracts function names from a given patch of C# code. Test methods are crucial for ensuring code reliability and correctness, especially in a development environment where changes are frequent. Therefore, this method is likely to be retained as it serves an important role in maintaining the integrity of the codebase."
survived,"async def train(model: art.TrainableModel[TauBenchPolicyConfig]):
    """"""Main training loop adapted from art-e example""""""
    config = model.config.run_config
    training_config = model.config.training_config
    
    if training_config is None:
        raise ValueError(""Training config is not set"")
    
    with LocalBackend() as backend:
        # Setup model with backend
        await model.register(backend)
        
        print(""Loading training tasks..."")
        # Get environment to access tasks
        env = get_env(
            config.env,
            user_strategy=config.user_strategy,
            user_model=config.user_model,
            user_provider=config.user_model_provider,
            task_split=config.task_split,
        )
        
        # Create list of task indices for training
        end_index = min(config.end_index, len(env.tasks)) if config.end_index != -1 else len(env.tasks)
        if config.task_ids:
            train_task_indices = config.task_ids
        else:
            train_task_indices = list(range(config.start_index, min(end_index, training_config.training_dataset_size)))
        
        # Validation task indices
        val_task_indices = list(range(len(train_task_indices), len(train_task_indices) + training_config.val_set_size))
        
        print(f""Training on {len(train_task_indices)} tasks"")
        print(f""Validation on {len(val_task_indices)} tasks"")
        
        # Training iterator
        train_iterator = iterate_dataset(
            train_task_indices,
            groups_per_step=training_config.groups_per_step,
            num_epochs=training_config.num_epochs,
            initial_step=await model.get_step(),
        )
        
        for batch, epoch, global_step, epoch_step in train_iterator:
            print(f""\n--- Training Step {global_step} (Epoch {epoch}, Step {epoch_step}) ---"")
            
            # Evaluation
            if global_step % training_config.eval_steps == 0:
                print(f""\n--- Evaluating at Step {global_step} ---"")
                await evaluate_model(model, config, num_eval_tasks=min(50, len(val_task_indices)))
                await model.delete_checkpoints()
            
            # Generate trajectory groups
            print(f""Generating trajectories for {len(batch)} tasks..."")
            groups = await art.gather_trajectory_groups(
                (
                    art.TrajectoryGroup(
                        (
                            rollout_tau_bench_task(model, task_index)
                            for _ in range(training_config.trajectories_per_group)
                        )
                    )
                    for task_index in batch
                )
            )
            
            # Training step
            print(f""Training on {len(groups)} trajectory groups..."")
            await model.train(
                groups,
                config=art.TrainConfig(
                    learning_rate=training_config.learning_rate
                ),
            )
            
            # Log progress
            total_reward = sum(
                sum(traj.reward for traj in group.trajectories) 
                for group in groups
            )
            num_trajectories = sum(len(group.trajectories) for group in groups)
            avg_reward = total_reward / num_trajectories if num_trajectories > 0 else 0
            print(f""Step {global_step}: Average training reward = {avg_reward}"")
        
        # Final evaluation
        print(""\n--- Final Evaluation ---"")
        final_reward = await evaluate_model(model, config, num_eval_tasks=len(val_task_indices))
        print(f""Final average reward: {final_reward}"")
        
        print(""Training completed!"")
",dev/tau-bench/run_rl.py,,1,3.2241866333029355e-08,"The method 'train' is a comprehensive and well-structured asynchronous function designed for training a model using a specific framework. It includes error handling, task setup, training and validation loops, evaluation, and logging. The method is likely to be retained because it encapsulates a complete training process that is essential for model development and evaluation. Additionally, it uses modern asynchronous programming practices, which are increasingly common in handling I/O-bound operations efficiently. There is no indication that this method is obsolete or redundant, and it appears to be a critical part of the training pipeline."
survived,"async def evaluate_model(
    model: art.TrainableModel[TauBenchPolicyConfig],
    config: RunConfig,
    num_eval_tasks: int = 50
) -> float:
    """"""Evaluate the model on a subset of tasks""""""
    print(f""Evaluating model on {num_eval_tasks} tasks..."")
    
    # Get environment for evaluation
    env = get_env(
        config.env,
        user_strategy=config.user_strategy,
        user_model=config.user_model,
        user_provider=config.user_model_provider,
        task_split=""dev"",  # Use dev split for evaluation
    )
    
    total_reward = 0.0
    eval_tasks = min(num_eval_tasks, len(env.tasks))
    
    for i in range(eval_tasks):
        try:
            traj = await rollout_tau_bench_task(model, i)
            total_reward += traj.reward
            print(f""Eval task {i}: reward={traj.reward}"")
        except Exception as e:
            print(f""Error evaluating task {i}: {e}"")
    
    avg_reward = total_reward / eval_tasks
    print(f""Average evaluation reward: {avg_reward}"")
    return avg_reward
",dev/tau-bench/run_rl.py,,1,5.905303995456778e-10,"The method 'evaluate_model' is a well-structured and useful function for evaluating machine learning models. It is designed to handle asynchronous operations, which is increasingly important in modern software development. The function includes error handling, logging, and calculates an average reward, which are all good practices. Additionally, it uses a configurable number of evaluation tasks, making it flexible. These factors suggest that the method is likely to be maintained and used in the future."
survived,"    def test_env_response_method(self, mock_singleturn_env):
        """"""Test the env_response method (which should never be called in practice).""""""
        messages = [{""role"": ""user"", ""content"": ""Hello""}]
        state = {}
        
        response, new_state = mock_singleturn_env.env_response(messages, state)
        
        # Should return minimal response
        assert response[""role""] == ""user""
        assert response[""content""] == """"
        assert new_state == state
",tests/test_singleturn_env.py,TestSingleTurnEnv,1,1.553497314502234e-06,"The method `test_env_response_method` is a unit test for the `env_response` method of a mock environment. It is designed to ensure that the `env_response` method behaves correctly, even though it is not expected to be called in practice. The test checks that the method returns a minimal response and does not alter the state. This kind of test is useful for verifying the behavior of methods that are not typically used but still need to be reliable if invoked. Therefore, the method is likely to be retained as part of the test suite to ensure robustness and correctness of the code."
survived,"    def test_env_group_rubric_type(self, mock_openai_client):
        """"""Test that EnvGroup creates EnvGroupRubric.""""""
        env1 = SingleTurnEnv(
            client=mock_openai_client,
            model=""test-model"",
            dataset=Dataset.from_dict({""question"": [""q1""], ""answer"": [""a1""]}),
            rubric=Rubric()
        )
        
        env_group = EnvGroup(envs=[env1])
        
        assert isinstance(env_group.rubric, EnvGroupRubric)
        assert env_group.rubric.env_map[""env_0""] == env1
",tests/test_env_group.py,TestEnvGroup,1,1.1032560311263802e-09,"The method 'test_env_group_rubric_type' is a unit test that verifies the functionality of the 'EnvGroup' class, specifically checking if it correctly creates an 'EnvGroupRubric' and maps environments properly. Unit tests are crucial for ensuring code reliability and correctness, especially in complex systems. This test is likely to be maintained as long as the functionality it tests remains relevant, which is typically the case unless there is a major refactor or deprecation of the related classes. Therefore, the method is likely to survive."
survived,"        def scalar_func(completion, **kwargs):
            return 0.5
",tests/test_rubric.py,TestRubric,1,7.484619712816325e-05,"The method 'scalar_func' is a simple function that takes a 'completion' argument and any number of additional keyword arguments, but it always returns a constant value of 0.5. This function might be useful in scenarios where a constant scalar value is needed regardless of the input, such as in testing or as a placeholder. However, its utility is limited due to its lack of dynamic behavior. If the context in which this function is used requires more complex logic or variable outputs, it might be replaced or removed. Without additional context, it's difficult to determine its exact utility, but given its simplicity and potential use cases, it is likely to survive unless the project requirements change significantly."
survived,"    async def create_project(
        self,
        info: Info[Context, None],
        input: CreateProjectInput,
    ) -> ProjectMutationPayload:
        name = input.name
        description = input.description if input.description is not UNSET else None
        gradient_start_color = (
            input.gradient_start_color if input.gradient_start_color is not UNSET else None
        )
        gradient_end_color = (
            input.gradient_end_color if input.gradient_end_color is not UNSET else None
        )

        # Build the values dict, only including non-None values to use database defaults
        values = {""name"": name}
        if description is not None:
            values[""description""] = description
        if gradient_start_color is not None:
            values[""gradient_start_color""] = gradient_start_color
        if gradient_end_color is not None:
            values[""gradient_end_color""] = gradient_end_color

        async with info.context.db() as session:
            project = await session.scalar(
                insert(models.Project)
                .values(**values)
                .returning(models.Project)
            )
            assert project is not None
        
        info.context.event_queue.put(ProjectInsertEvent((project.id,)))
        return ProjectMutationPayload(project=to_gql_project(project), query=Query())
",src/phoenix/server/api/mutations/project_mutations.py,ProjectMutationMixin,1,5.60279640614594e-09,"The method 'create_project' is a well-structured asynchronous function that handles the creation of a project entity in a database. It includes input validation, conditional logic to handle optional fields, and uses an asynchronous database session to insert the project. The method also triggers an event after the project is created, which is a common pattern in event-driven architectures. These characteristics suggest that the method is functional, efficient, and aligns with modern development practices, making it unlikely to be deleted."
survived,"    async def chat_completion_create(
        self,
        messages: list[
            tuple[ChatCompletionMessageRole, str, Optional[str], Optional[list[JSONScalarType]]]
        ],
        tools: list[JSONScalarType],
        **invocation_parameters: Any,
    ) -> AsyncIterator[ChatCompletionChunk]:
        # Transform max_tokens to the correct parameter name for Azure OpenAI
        transformed_parameters = invocation_parameters.copy()
        if ""max_tokens"" in transformed_parameters:
            correct_param_name = _get_azure_token_param_name(self.model_name)
            if correct_param_name != ""max_tokens"":
                transformed_parameters[correct_param_name] = transformed_parameters.pop(""max_tokens"")
        
        # Call the parent method with transformed parameters
        async for chunk in super().chat_completion_create(messages, tools, **transformed_parameters):
            yield chunk
",src/phoenix/server/api/helpers/playground_clients.py,AzureOpenAIStreamingClient,1,5.60279640614594e-09,"The method is likely to survive because it includes a specific transformation of parameters to accommodate Azure OpenAI's requirements, which suggests it is tailored for a specific use case. Additionally, it uses asynchronous programming, which is modern and efficient for handling I/O operations, indicating that it is designed to handle real-time or large-scale data processing. The method also extends functionality by calling a parent method, suggesting it is part of a larger, possibly well-structured codebase."
survived,"    def path(self):
        return reverse(""sentry-mcp-json"")
",tests/sentry/web/test_api.py,McpJsonTest,1,1.1861120010657661e-08,"The method 'path' is a simple utility function that returns a URL by reversing a named URL pattern. This is a common practice in Django applications to ensure that URLs are generated dynamically and are not hardcoded. The method is likely to be used in various parts of the application to generate the correct URL for the 'sentry-mcp-json' view. Since it serves a specific purpose and is a standard practice in Django, it is unlikely to be deleted unless the URL pattern itself is removed or significantly refactored."
survived,"def mcp_json(request):
    if settings.SENTRY_MODE == SentryMode.SELF_HOSTED:
        return HttpResponse(status=404)

    return HttpResponse(json.dumps(MCP_CONFIG), content_type=""application/json"")
",src/sentry/web/api.py,,1,1.4166087846364157e-09,"The method 'mcp_json' is likely to be Survived (1) because it contains a conditional check that returns a 404 status if a certain condition is met, which is a common pattern for handling different configurations or modes in web applications. Additionally, it returns a JSON response with a specific content type, indicating that it is part of a functional API endpoint. There is no indication of deprecated practices or security issues that would necessitate its removal."
deleted,"    def _handle_gleaning(
        self, 
        response: Any, 
        output_schema: Dict[str, Any],
        output_mode: OutputMode,
        gleaning_config: Dict[str, Any],
        model: str,
        op_type: str,
        messages: List[Dict[str, str]],
        tools: Optional[str],
        scratchpad: Optional[str],
        litellm_completion_kwargs: Dict[str, Any],
        op_config: Dict[str, Any],
        verbose: bool
    ) -> tuple[Any, float, bool]:
        """"""Handle gleaning process.""""""
        additional_cost = 0.0
        num_gleaning_rounds = gleaning_config.get(""num_rounds"", 2)
        
        parsed_output = (
            self.parser.parse_response(response, output_schema, output_mode, json.loads(tools) if tools else None)[0]
            if isinstance(response, ModelResponse)
            else response
        )

        validator_messages = (
            [
                {
                    ""role"": ""system"",
                    ""content"": f""You are a helpful assistant, intelligently processing data. This is a {op_type} operation."",
                }
            ]
            + messages
            + [{""role"": ""assistant"", ""content"": json.dumps(parsed_output)}]
        )

        for rnd in range(num_gleaning_rounds):
            # Break early if gleaning condition is not met
            if not self.should_glean(gleaning_config, parsed_output):
                break
                
            # Prepare validator prompt
            validator_prompt = strict_render(
                gleaning_config[""validation_prompt""],
                {""output"": parsed_output},
            )
            
            self.runner.blocking_acquire(""llm_call"", weight=1)
            approx_num_tokens = approx_count_tokens(
                validator_messages + [{""role"": ""user"", ""content"": validator_prompt}]
            )
            self.runner.blocking_acquire(""llm_tokens"", weight=approx_num_tokens)

            # Build validator tool
            should_refine_params = {
                ""type"": ""object"",
                ""properties"": {
                    ""should_refine"": {""type"": ""boolean""},
                    ""improvements"": {""type"": ""string""},
                },
                ""required"": [""should_refine"", ""improvements""],
            }
            if ""gemini"" not in model:
                should_refine_params[""additionalProperties""] = False

            # Prepare extra kwargs
            extra_kwargs = {}
            if self.llm_handler.default_lm_api_base:
                extra_kwargs[""api_base""] = self.llm_handler.default_lm_api_base
            if is_snowflake(model):
                extra_kwargs[""allowed_openai_params""] = [""tools"", ""tool_choice""]

            validator_response = completion(
                model=gleaning_config.get(""model"", model),
                messages=truncate_messages(
                    validator_messages + [{""role"": ""user"", ""content"": validator_prompt}],
                    model,
                ),
                tools=[
                    {
                        ""type"": ""function"",
                        ""function"": {
                            ""name"": ""should_refine_answer"",
                            ""description"": ""Determine if the output should be refined based on the validation feedback"",
                            ""strict"": True,
                            ""parameters"": should_refine_params,
                            ""additionalProperties"": False,
                        },
                    }
                ],
                tool_choice=""required"",
                **litellm_completion_kwargs,
                **extra_kwargs,
            )
            additional_cost += completion_cost(validator_response)

            # Parse the validator response
            suggestion = json.loads(
                validator_response.choices[0].message.tool_calls[0].function.arguments
            )
            if not suggestion[""should_refine""]:
                break

            if verbose:
                self.console.log(
                    f""Validator improvements (gleaning round {rnd + 1}): {suggestion['improvements']}""
                )

            # Prompt for improvement
            improvement_prompt = f""""""Based on the validation feedback:

            ```
            {suggestion['improvements']}
            ```

            Please improve your previous response. Ensure that the output adheres to the required schema and addresses any issues raised in the validation.""""""
            messages.append({""role"": ""user"", ""content"": improvement_prompt})

            # Call LLM again
            response = self.llm_handler.make_completion_call(
                model, op_type, messages, output_mode, output_schema, tools, scratchpad, litellm_completion_kwargs, op_config
            )
            parsed_output = self.parser.parse_response(response, output_schema, output_mode, json.loads(tools) if tools else None)[0]
            validator_messages[-1] = {
                ""role"": ""assistant"",
                ""content"": json.dumps(parsed_output),
            }

            additional_cost += completion_cost(response)

        return response, additional_cost, True
",docetl/operations/utils/api.py,ValidationHandler,1,3.927863699585036e-07,"The method '_handle_gleaning' is a complex and integral part of a larger system, handling a specific process called 'gleaning'. It involves multiple steps, including parsing responses, validating outputs, and potentially refining them based on feedback. The method is well-structured, with clear responsibilities and interactions with other components like parsers and LLM handlers. It also includes mechanisms for cost calculation and verbose logging, indicating its importance in the system. Given its complexity and the specific functionality it provides, it is unlikely to be deleted unless there is a significant overhaul or deprecation of the entire gleaning process."
survived,"    async def test_rollout_with_sampling_args(self, mock_singleturn_env):
        """"""Test rollout with custom sampling arguments.""""""
        prompt = [{""role"": ""user"", ""content"": ""Hello""}]
        answer = ""Hi""
        sampling_args = {""temperature"": 0.8, ""max_tokens"": 100}
        
        completion, state = await mock_singleturn_env.rollout(
            client=mock_singleturn_env.client,
            model=""test-model"",
            prompt=prompt,
            answer=answer,
            sampling_args=sampling_args
        )
        
        assert isinstance(completion, list)
        assert completion[0][""content""] == ""This is a test response""
        
        # Verify sampling args were passed
        call_args = mock_singleturn_env.client.chat.completions.create.call_args
        assert ""temperature"" in call_args.kwargs
        assert ""max_tokens"" in call_args.kwargs
",tests/test_singleturn_env.py,TestSingleTurnEnv,1,9.736200303530205e-10,"The method is a test function that verifies the functionality of a rollout with custom sampling arguments. It checks if the completion is a list and if the sampling arguments are correctly passed to the mock environment. This is a typical unit test that ensures the code behaves as expected, which is crucial for maintaining code quality and reliability. Therefore, it is likely to be retained as part of the test suite."
survived,"    async def test_different_message_types_in_same_env(self, mock_openai_client, sample_dataset):
        """"""Test that environment respects its message_type setting.""""""
        # Chat environment
        chat_env = SingleTurnEnv(
            client=mock_openai_client,
            model=""test-model"",
            dataset=sample_dataset,
            message_type=""chat""
        )
        
        # Completion environment 
        completion_dataset = Dataset.from_dict({
            ""prompt"": [""Test prompt""],
            ""answer"": [""Test answer""]
        })
        completion_env = SingleTurnEnv(
            client=mock_openai_client,
            model=""test-model"", 
            dataset=completion_dataset,
            message_type=""completion""
        )
        
        # Test chat rollout
        chat_completion, _ = await chat_env.rollout(
            client=mock_openai_client,
            model=""test-model"",
            prompt=[{""role"": ""user"", ""content"": ""Hello""}],
            answer=""Hi""
        )
        assert isinstance(chat_completion, list)
        
        # Test completion rollout
        completion_result, _ = await completion_env.rollout(
            client=mock_openai_client,
            model=""test-model"", 
            prompt=""Complete this:"",
            answer=""Done""
        )
        assert isinstance(completion_result, str)",tests/test_singleturn_env.py,TestSingleTurnEnv,1,6.023574641292144e-08,"The method is testing a specific functionality of the SingleTurnEnv class, ensuring that it can handle different message types ('chat' and 'completion') correctly. This is a valuable test for maintaining the robustness and flexibility of the environment handling in the system. Since it is a unit test, it is likely to be retained to ensure that future changes do not break this functionality."
survived,"    def test_rubric_group_mixed_rubric_types(self):
        """"""Test RubricGroup with different types of rubrics.""""""
        def func1(completion, **kwargs):
            return 1.0
        
        def func2(completion, **kwargs):
            return 0.5
        
        # Create rubrics with different configurations
        rubric1 = Rubric(funcs=[func1], weights=[1.0])
        rubric2 = Rubric(funcs=[func2], weights=[0.3], custom_attr=""test"")
        
        group = RubricGroup(rubrics=[rubric1, rubric2])
        
        # Should aggregate functions and weights correctly
        assert group.get_reward_func_names() == [""func1"", ""func2""]
        assert group.get_reward_weights() == [1.0, 0.3]
",tests/test_rubric_group.py,TestRubricGroup,1,1.1861120010657661e-08,"The method is a unit test for a specific functionality of the RubricGroup class, which is likely part of a larger testing suite. Unit tests are crucial for ensuring code reliability and are generally maintained as long as the functionality they test is relevant. Since this test checks the aggregation of functions and weights in a RubricGroup, it is likely to be useful for validating changes or ensuring no regressions occur in the future. Therefore, it is likely to be retained."
survived,"    def test_rubric_group_score_rollouts_with_kwargs(self):
        """"""Test scoring rollouts with additional kwargs.""""""
        # Note: This test is skipped because RubricGroup.score_rollouts() has a bug
        pass
",tests/test_rubric_group.py,TestRubricGroup,0,0.9999930377415741,"The method is currently skipped due to a known bug in the RubricGroup.score_rollouts() function. This indicates that the test is not functional until the bug is resolved. If the bug is fixed, the test could be updated and used. However, as it stands, the method is not serving any purpose and is likely to be deleted unless there is a plan to address the bug soon."
survived,"    def _create_mock_response(self, content):
        """"""Helper to create mock OpenAI response.""""""
        mock_response = MagicMock()
        mock_response.choices = [MagicMock()]
        mock_response.choices[0].message.content = content
        mock_response.choices[0].finish_reason = ""stop""
        return mock_response
",tests/test_multiturn_env.py,TestMultiTurnEnv,1,4.944450477491054e-09,"The method '_create_mock_response' is a utility function designed to create a mock response object for testing purposes. It is useful in unit tests where simulating responses from an external API like OpenAI is necessary. Such helper methods are typically retained in the codebase as they facilitate testing and ensure that the code can be tested in isolation without relying on actual API calls. Therefore, it is likely to survive."
survived,"def basic_parser():
    """"""Return a basic Parser instance.""""""
    return Parser()
",tests/conftest.py,,1,7.194132978569833e-09,"The method `basic_parser` is a simple utility function that returns an instance of a `Parser` class. It is likely to be retained because it provides a clear and straightforward way to instantiate a `Parser` object, which can be useful in various contexts where parsing functionality is needed. Unless the `Parser` class itself is deprecated or the method is replaced by a more efficient or necessary alternative, there is no strong reason to delete this method."
survived,"    def test_parse_with_custom_extractor_no_boxed(self, think_parser_with_extractor):
        """"""Test custom extractor when no boxed answer is found.""""""
        text = """"""<think>
        Thinking about the problem.
        </think>
        Just a plain answer.""""""
        
        result = think_parser_with_extractor.parse(text)
        assert result == ""Just a plain answer.""
",tests/test_think_parser.py,TestThinkParser,1,1.725782769012759e-08,"The method 'test_parse_with_custom_extractor_no_boxed' is a unit test designed to verify the behavior of a parser when no boxed answer is found. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with parsers or any logic that processes input data. This test checks a specific scenario, which is important for comprehensive test coverage. Therefore, it is unlikely to be deleted unless the functionality it tests is removed or significantly altered."
survived,"    def test_parse_answer_string_integration(self, think_parser):
        """"""Test parse_answer with string input.""""""
        text = ""<think>Calculating...</think>Result: 42""
        result = think_parser.parse_answer(text)
        assert result == ""Result: 42""",tests/test_think_parser.py,TestThinkParser,1,1.0467401685178159e-08,"The method 'test_parse_answer_string_integration' is a unit test designed to verify the functionality of the 'parse_answer' method in the 'think_parser' object. Unit tests are crucial for ensuring code reliability and correctness, especially when changes are made to the codebase. This test checks if the 'parse_answer' method correctly processes a string input by removing the '<think>' tags and returning the expected result. Since maintaining tests is important for software quality assurance, this method is likely to be retained."
survived,"    def test_rubric_group_score_rollouts_basic(self):
        """"""Test basic scoring of rollouts with multiple rubrics.""""""
        # Note: This test is skipped because RubricGroup.score_rollouts() has a bug
        # It calls rubric.score_rollouts() which is async but doesn't await it
        pass
",tests/test_rubric_group.py,TestRubricGroup,0,0.9999997897565932,"The method is currently skipped due to a known bug in the RubricGroup.score_rollouts() function, which involves an asynchronous call that is not awaited. This indicates that the test is not functional in its current state and is not providing any value. Unless the bug is fixed and the test is updated to properly handle the asynchronous call, it is likely to be deleted as it does not contribute to the codebase."
survived,"    def extract_boxed(text):
        """"""Simple boxed answer extractor for testing.""""""
        import re
        match = re.search(r'\\boxed\{([^}]+)\}', text)
        return match.group(1) if match else text
",tests/conftest.py,,1,2.998960815863541e-09,"The method 'extract_boxed' is a simple utility function that extracts text enclosed in a LaTeX-style \boxed{} command. This is a common requirement in mathematical text processing, especially in educational and scientific contexts where LaTeX is frequently used. The function is straightforward, uses regular expressions effectively, and serves a clear purpose. There is no indication that this functionality is obsolete or redundant, and it is likely to be useful in various applications involving LaTeX parsing. Therefore, it is likely to be retained."
survived,"    def test_add_multiple_reward_funcs(self):
        """"""Test adding multiple reward functions.""""""
        # Create fresh rubric to avoid test isolation issues
        rubric = Rubric(funcs=[], weights=[])
        
        def func1(completion, **kwargs):
            return 1.0
        
        def func2(completion, **kwargs):
            return 0.5
        
        rubric.add_reward_func(func1, weight=1.0)
        rubric.add_reward_func(func2, weight=0.3)
        
        assert len(rubric.reward_funcs) == 2
        assert rubric.get_reward_func_names() == [""func1"", ""func2""]
        assert rubric.reward_weights == [1.0, 0.3]
",tests/test_rubric.py,TestRubric,1,1.725782769012759e-08,"The method `test_add_multiple_reward_funcs` is a unit test that verifies the functionality of adding multiple reward functions to a `Rubric` object. It checks that the functions are added correctly, their names are retrievable, and their weights are set as expected. This is a fundamental test for ensuring the integrity of the `Rubric` class's functionality, especially if the class is used in a system where multiple reward functions are necessary. Since it serves a clear purpose in validating the behavior of the `Rubric` class, it is likely to be retained in the codebase."
survived,"    def test_rubric_initialization_with_kwargs(self):
        """"""Test Rubric initialization with additional kwargs.""""""
        rubric = Rubric(custom_param=""test_value"", another_param=42)
        
        assert rubric.custom_param == ""test_value""
        assert rubric.another_param == 42
",tests/test_rubric.py,TestRubric,1,1.522997951276035e-08,"The method 'test_rubric_initialization_with_kwargs' is a unit test designed to verify the initialization of a 'Rubric' object with additional keyword arguments. This is a common practice in software development to ensure that objects are correctly instantiated with the expected attributes. The method is likely to survive because it serves a clear purpose in testing the functionality of the 'Rubric' class, ensuring that it can handle additional parameters during initialization. Such tests are crucial for maintaining code quality and reliability."
survived,"    def test_add_reward_func_default_weight(self):
        """"""Test adding reward function with default weight.""""""
        rubric = Rubric(funcs=[], weights=[])
        
        def test_func(completion, **kwargs):
            return 1.0
        
        rubric.add_reward_func(test_func)
        
        assert rubric.reward_weights == [1.0]
",tests/test_rubric.py,TestRubric,1,7.194132978569833e-09,"The method `test_add_reward_func_default_weight` is a unit test that verifies the functionality of adding a reward function with a default weight to a `Rubric` object. Unit tests are generally essential for ensuring code correctness and are not typically deleted unless they are redundant or replaced by more comprehensive tests. This test is straightforward, checks a specific functionality, and does not seem to be redundant or incorrect. Therefore, it is likely to be retained."
survived,"    def test_parse_returns_text_as_is(self, basic_parser):
        """"""Test that parse method returns text unchanged.""""""
        text = ""This is a test string""
        result = basic_parser.parse(text)
        assert result == text
",tests/test_parser.py,TestParser,1,3.2241866333029355e-08,"The method 'test_parse_returns_text_as_is' is a unit test designed to verify that the 'parse' method of 'basic_parser' returns the input text unchanged. This is a fundamental test to ensure the basic functionality of the 'parse' method, which is crucial for any parser. Such tests are essential for maintaining code quality and ensuring that future changes do not break existing functionality. Therefore, it is unlikely that this method will be deleted as it serves an important role in the test suite."
survived,"    async def test_non_list_prompt_assertion(self, mock_multiturn_env):
        """"""Test that non-list prompts raise AssertionError.""""""
        with pytest.raises(AssertionError):
            await mock_multiturn_env.rollout(
                client=mock_multiturn_env.client,
                model=""test-model"",
                prompt=""String prompt not allowed"",  # Should be list
                answer=""test_answer""
            )
",tests/test_multiturn_env.py,TestMultiTurnEnv,1,1.8189616842444243e-09,"The method is a unit test designed to ensure that the system correctly raises an AssertionError when a non-list prompt is provided. This is a valid and necessary test to maintain the integrity of the system's input validation. Unit tests are crucial for catching errors and ensuring that the code behaves as expected under various conditions. Therefore, this method is likely to be retained as it serves an important role in the testing suite."
survived,"            def is_completed(self, messages, state, **kwargs):
                # Complete if we have any assistant message
                return any(msg.get(""role"") == ""assistant"" for msg in messages)
",tests/test_multiturn_env.py,TestMultiTurnEnv.ImmediateCompletionEnv,1,1.522997951276035e-08,"The method 'is_completed' is a simple utility function that checks if there is any message with the role 'assistant' in the provided messages list. This kind of method is often useful in systems where you need to determine if a conversation or a task has reached a certain state, in this case, if an assistant has responded. Such utility functions are generally useful and reusable in various contexts, especially in chat or task management systems. Therefore, it is likely to be retained as it serves a clear purpose and is not overly complex or redundant."
survived,"    def __init__(self, completion_condition=""answer"", **kwargs):
        super().__init__(**kwargs)
        self.completion_condition = completion_condition  # ""answer"", ""max_turns"", ""error""
        self.env_response_count = 0
",tests/conftest.py,SimpleMultiTurnEnv,1,2.646573631904765e-09,"The method is a constructor (__init__) for a class, which is essential for initializing object instances. It sets up initial conditions and parameters for the object, such as 'completion_condition' and 'env_response_count'. Constructors are fundamental to object-oriented programming and are unlikely to be deleted unless the entire class is being refactored or removed. Therefore, this method will survive."
survived,"        def reward_func1(completion, **kwargs):
            return 1.0
",tests/test_rubric.py,TestRubric,0,0.9999785550602307,"The method 'reward_func1' is a simple function that takes a 'completion' argument and any number of additional keyword arguments, but it always returns a constant value of 1.0. This function might be used as a placeholder or a default reward function in a larger system. However, its utility is limited because it does not utilize the input parameters to compute a meaningful reward. If the system requires a more dynamic or context-sensitive reward calculation, this function is likely to be replaced or modified. Therefore, the method is likely to be deleted or significantly altered in the future."
survived,"    async def test_max_turns_limiting(self, mock_multiturn_env_max_turns):
        """"""Test that rollout stops at max_turns.""""""
        # Set up responses that would continue indefinitely
        mock_multiturn_env_max_turns.client.set_default_responses(
            chat_response=""Keep going""
        )
        
        prompt = [{""role"": ""user"", ""content"": ""Start conversation""}]
        completion, state = await mock_multiturn_env_max_turns.rollout(
            client=mock_multiturn_env_max_turns.client,
            model=""test-model"", 
            prompt=prompt,
            answer=""target_answer""
        )
        
        # Should stop at max_turns=2: assistant + user + assistant (3 messages)
        assert len(completion) == 3
        assert completion[0][""role""] == ""assistant""
        assert completion[1][""role""] == ""user""
        assert completion[2][""role""] == ""assistant""
",tests/test_multiturn_env.py,TestMultiTurnEnv,1,4.363462233903899e-09,"The method is a unit test designed to verify that a specific feature (max_turns limiting) in a multi-turn environment works as expected. Unit tests are crucial for ensuring code reliability and are typically maintained as long as the feature they test is relevant. Since this test checks a fundamental aspect of conversation flow control, it is likely to be retained to prevent regressions."
survived,"    def test_parse_with_multiple_think_blocks(self, think_parser):
        """"""Test parsing with multiple think blocks (should use content after last one).""""""
        text = """"""<think>First thought</think>
        Some intermediate text.
        <think>Second thought</think>
        Final answer here.""""""
        
        result = think_parser.parse(text)
        assert result == ""Final answer here.""
",tests/test_think_parser.py,TestThinkParser,1,5.60279640614594e-09,"The method 'test_parse_with_multiple_think_blocks' is a unit test designed to verify the functionality of a parser, specifically ensuring that it correctly handles multiple 'think' blocks and returns the content after the last one. This is a common scenario in testing parsers, and the method is well-defined with a clear purpose. It is likely to be useful for maintaining the integrity of the parser's functionality, especially if the parser is part of a larger system that processes similar text structures. Therefore, the method is likely to be retained in the codebase."
survived,"    def test_parse_answer_with_completion(self, basic_parser):
        """"""Test parse_answer with completion list.""""""
        completion = [
            {""role"": ""user"", ""content"": ""What is 2+2?""},
            {""role"": ""assistant"", ""content"": ""The answer is 4""}
        ]
        result = basic_parser.parse_answer(completion)
        assert result == ""The answer is 4""
",tests/test_parser.py,TestParser,1,1.6052280526088547e-09,"The method 'test_parse_answer_with_completion' is a unit test designed to verify the functionality of the 'parse_answer' method in the 'basic_parser' object. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with parsing logic. This test checks if the 'parse_answer' method correctly extracts the assistant's response from a given completion list. Since testing is an integral part of software development and maintenance, this method is likely to be retained to ensure the parser's functionality remains intact as the codebase evolves."
survived,"def test_scenarios():
    """"""
    Collection of test scenarios for URL loading.
    Each scenario represents a different case we want to test.
    """"""
    scenarios = {
        ""new_urls"": {
            ""import_id"": ""github.com/certifi/python-certifi"",
            ""package_id"": UUID(""e0f18184-e743-40fb-8add-a5ccaac026a4""),
            # What transformer found
            ""transformer_urls"": [
                (""github.com/certifi/python-certifi"", [""homepage"", ""source""])
            ],
            # What's in DB (nothing, completely new)
            ""db_state"": {""urls"": {}, ""package_urls"": {}},
            ""expected_behavior"": {
                ""new_urls_created"": 2,  # homepage and source
                ""new_package_urls_created"": 2,
                ""urls_updated"": 0,
            },
        },
        ""existing_package_some_urls"": {
            ""import_id"": ""github.com/pyca/cryptography"",
            ""package_id"": UUID(""f0f18184-e743-40fb-8add-a5ccaac026a5""),
            # Transformer found homepage, source, and repository
            ""transformer_urls"": [
                (""github.com/pyca/cryptography"", [""homepage"", ""source"", ""repository""])
            ],
            # DB only has homepage
            ""db_state"": {
                ""urls"": {
                    (""github.com/pyca/cryptography"", ""homepage""): {
                        ""id"": UUID(""22222222-2222-2222-2222-222222222222""),
                        ""url"": ""github.com/pyca/cryptography"",
                    }
                },
                ""package_urls"": {
                    UUID(""f0f18184-e743-40fb-8add-a5ccaac026a5""): [
                        {
                            ""id"": UUID(""33333333-3333-3333-3333-333333333333""),
                            ""url_id"": UUID(""22222222-2222-2222-2222-222222222222""),
                        }
                    ]
                },
            },
            ""expected_behavior"": {
                ""new_urls_created"": 2,  # source and repository
                ""new_package_urls_created"": 2,
                ""urls_updated"": 1,  # homepage timestamp updated
            },
        },
        ""all_urls_exist"": {
            ""import_id"": ""github.com/requests/requests"",
            ""package_id"": UUID(""a0a18184-e743-40fb-8add-a5ccaac026a6""),
            # Transformer found these
            ""transformer_urls"": [
                (""github.com/requests/requests"", [""homepage"", ""source""])
            ],
            # DB has exact same ones
            ""db_state"": {
                ""urls"": {
                    (""github.com/requests/requests"", ""homepage""): {
                        ""id"": UUID(""44444444-4444-4444-4444-444444444444""),
                        ""url"": ""github.com/requests/requests"",
                    },
                    (""github.com/requests/requests"", ""source""): {
                        ""id"": UUID(""55555555-5555-5555-5555-555555555555""),
                        ""url"": ""github.com/requests/requests"",
                    },
                },
                ""package_urls"": {
                    UUID(""a0a18184-e743-40fb-8add-a5ccaac026a6""): [
                        {
                            ""id"": UUID(""66666666-6666-6666-6666-666666666666""),
                            ""url_id"": UUID(""44444444-4444-4444-4444-444444444444""),
                        },
                        {
                            ""id"": UUID(""77777777-7777-7777-7777-777777777777""),
                            ""url_id"": UUID(""55555555-5555-5555-5555-555555555555""),
                        },
                    ]
                },
            },
            ""expected_behavior"": {
                ""new_urls_created"": 0,
                ""new_package_urls_created"": 0,
                ""urls_updated"": 2,  # Both timestamps updated
            },
        },
        ""no_urls_in_db"": {
            ""import_id"": ""github.com/numpy/numpy"",
            ""package_id"": UUID(""b0b18184-e743-40fb-8add-a5ccaac026a7""),
            # Transformer found URLs but DB has no record of this package
            ""transformer_urls"": [
                (""github.com/numpy/numpy"", [""homepage"", ""repository"", ""documentation""])
            ],
            # DB is empty for this package
            ""db_state"": {""urls"": {}, ""package_urls"": {}},
            ""expected_behavior"": {
                ""new_urls_created"": 3,
                ""new_package_urls_created"": 3,
                ""urls_updated"": 0,
            },
        },
    }

    return scenarios
",tests/package_managers/pkgx/test_pkgx_load_urls.py,,1,2.2159489282323004e-08,"The method `test_scenarios` is a collection of test cases for URL loading, which is a common practice in software development to ensure that different scenarios are handled correctly. It is well-documented and structured, providing clear expectations for each scenario. Such methods are crucial for maintaining code quality and ensuring that changes do not introduce regressions. Therefore, it is unlikely to be deleted as it serves an important role in testing and validation."
survived,"    def create_formula(
        formula_name,
        dependencies=None,
        build_dependencies=None,
        test_dependencies=None,
        recommended_dependencies=None,
        optional_dependencies=None,
    ):
        return Actual(
            formula=formula_name,
            description=""Test formula"",
            license=""MIT"",
            homepage="""",
            source="""",
            repository="""",
            dependencies=dependencies or [],
            build_dependencies=build_dependencies or [],
            test_dependencies=test_dependencies or [],
            recommended_dependencies=recommended_dependencies or [],
            optional_dependencies=optional_dependencies or [],
        )
",tests/package_managers/homebrew/test_diff_dep.py,,1,1.6052280526088547e-09,"The method 'create_formula' is a utility function that constructs and returns an instance of the 'Actual' class with various types of dependencies. It is a flexible and reusable piece of code that can be used in different contexts where such an object is needed. The method is well-structured, with default values for its parameters, making it robust against missing arguments. This kind of utility function is often useful in larger codebases for creating standardized objects, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained in the codebase."
survived,"    def test_handle_uploaders(self):
        """"""Test handling of uploaders with special characters and edge cases.""""""
        maintainer = """"""Package: example
Uploaders: ""Adam C. Powell, IV"" <hazelsct@debian.org>, Drew Parsons <dparsons@debian.org>""""""
        parser = DebianParser(maintainer)
        sources = list(parser.parse())
        assert len(sources) == 1
        source = sources[0]
        assert len(source.uploaders) == 2
        assert source.uploaders[0].name == ""Adam C. Powell, IV""
        assert source.uploaders[0].email == ""hazelsct@debian.org""
        assert source.uploaders[1].name == ""Drew Parsons""
        assert source.uploaders[1].email == ""dparsons@debian.org""

        maintainer = """"""Package: calamares-extensions
Binary: calamares-extensions, calamares-extensions-data
Version: 1.2.1-2
Maintainer: Debian KDE Extras Team <pkg-kde-extras@lists.alioth.debian.org>,""""""
        parser = DebianParser(maintainer)
        sources = list(parser.parse())
        assert len(sources) == 1
        source = sources[0]
        assert source.maintainer.name == ""Debian KDE Extras Team""
        assert source.maintainer.email == ""pkg-kde-extras@lists.alioth.debian.org""",tests/package_managers/debian/test_debian_parser.py,TestDebianParser,1,2.699578619062706e-07,"The method `test_handle_uploaders` is a unit test designed to verify the functionality of a parser that handles Debian package maintainer and uploader information. It checks if the parser correctly interprets and extracts names and emails, even when special characters or edge cases are present. This is a crucial part of ensuring the robustness of the parser, especially in handling real-world data which often includes such complexities. Since testing is an essential part of software development to ensure code quality and reliability, this method is likely to be retained as it serves a valuable purpose in validating the parser's functionality."
survived,"    def test_parse_package_data(self):
        """"""Test parsing a typical package entry from Packages file.""""""
        # Sample package data from a Packages file
        package_data = """"""Package: 0ad
Version: 0.0.26-1
Installed-Size: 19162
Maintainer: Debian Games Team <pkg-games-devel@lists.alioth.debian.org>
Architecture: amd64
Depends: 0ad-data (>= 0.0.26), 0ad-data-common (>= 0.0.26), libc6 (>= 2.29), libcurl4 (>= 7.16.2), libenet7 (>= 1.3.13), libgloox18, libjsoncpp25 (>= 1.9.5), libminiupnpc17 (>= 1.9.20140610), libnspr4 (>= 2:4.9.2), libnss3 (>= 2:3.22)
Recommends: fonts-freefont-ttf, fonts-texgyre
Suggests: 0ad-dbg
Description: Real-time strategy game of ancient warfare
Homepage: https://play0ad.com/
Section: games
Priority: optional
Filename: pool/main/0/0ad/0ad_0.0.26-1_amd64.deb
Size: 6050744
MD5sum: a777ddf01c18dbdef15c589f8325d7a3
SHA256: 9da19833c1a51e890aa8a11f82ec1e383c0e79410c3d2f6845fd2ec3e23249b8


""""""
        # Parse the package data
        parser = DebianParser(package_data)
        packages = list(parser.parse())

        # Validate we have one package
        assert len(packages) == 1
        package = packages[0]

        # Test basic fields
        assert package.package == ""0ad""
        assert package.version == ""0.0.26-1""
        assert package.installed_size == 19162
        assert package.architecture == ""amd64""

        # Test maintainer parsing
        assert package.maintainer.name == ""Debian Games Team""
        assert package.maintainer.email == ""pkg-games-devel@lists.alioth.debian.org""

        # Test dependency parsing
        assert len(package.depends) == 10
        assert package.depends[0].package == ""0ad-data""
        assert package.depends[0].semver == "">= 0.0.26""

        # Test recommends parsing
        assert len(package.recommends) == 2
        assert package.recommends[0].package == ""fonts-freefont-ttf""

        # Test suggests parsing
        assert len(package.suggests) == 1
        assert package.suggests[0].package == ""0ad-dbg""
",tests/package_managers/debian/test_debian_parser.py,TestDebianParser,1,4.6911638017642294e-08,"The method `test_parse_package_data` is a unit test designed to verify the functionality of a package data parser. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with data parsing, which can be error-prone. This test method checks various aspects of the parsed data, such as basic fields, maintainer information, dependencies, recommendations, and suggestions. Since it is a comprehensive test that ensures the parser works as expected, it is likely to be retained in the codebase to maintain code quality and prevent regressions."
survived,"def mock_db():
    """"""Fixture providing mock DedupeDB.""""""
    return MagicMock(spec=DedupeDB)
",tests/ranker/test_dedupe.py,,1,2.646573631904765e-09,"The method 'mock_db' is a simple fixture function that returns a mock object of type 'DedupeDB'. This is a common practice in unit testing to simulate database interactions without requiring a real database connection. Such utility functions are often retained in codebases to facilitate testing, especially when dealing with complex systems that require isolation of components during tests. Therefore, it is likely to be useful and survive."
survived,"def map_config_with_drop_keys():
    return {
        ""name"": ""sentiment_analysis_with_drop"",
        ""type"": ""map"",
        ""prompt"": ""Analyze the sentiment of the following text: '{{ input.text }}'. Classify it as either positive, negative, or neutral."",
        ""output"": {""schema"": {""sentiment"": ""string""}},
        ""model"": ""gpt-4o-mini"",
        ""drop_keys"": [""to_be_dropped""],
    }
",tests/basic/test_basic_map.py,,1,1.9171715133907573e-10,"The method `map_config_with_drop_keys` is likely to survive because it defines a configuration for a sentiment analysis task using a model, which is a common and useful functionality in many applications. The use of `drop_keys` suggests that it has a mechanism to handle unnecessary data, which can be beneficial for optimizing performance or managing data flow. This kind of functionality is often needed in applications that process and analyze text data, making it a valuable method to retain."
survived,"def map_config_with_tools():
    return {
        ""type"": ""map"",
        ""name"": ""word_count"",
        ""prompt"": ""Count the number of words in the following text: '{{ input.text }}'"",
        ""output"": {""schema"": {""word_count"": ""integer""}},
        ""model"": ""gpt-4o-mini"",
        ""tools"": [
            {
                ""required"": True,
                ""code"": """"""
def count_words(text):
    return {""word_count"": len(text.split())}
                """""",
                ""function"": {
                    ""name"": ""count_words"",
                    ""description"": ""Count the number of words in a text string."",
                    ""parameters"": {
                        ""type"": ""object"",
                        ""properties"": {
                            ""text"": {
                                ""type"": ""string"",
                            }
                        },
                        ""required"": [""text""],
                    },
                },
            }
        ],
        ""validate"": [""len(output['text']) > 0""],
        ""num_retries_on_validate_failure"": 3,
    }
",tests/basic/test_basic_map.py,,1,1.3440409770490404e-08,"The method 'map_config_with_tools' is a configuration function that sets up a mapping for a word count tool using a specific model and validation process. It is well-structured and serves a clear purpose in a system that likely involves text processing or analysis. Given the increasing importance of text analysis and the use of AI models for such tasks, this method is likely to be useful and relevant. Therefore, it is more likely to be retained in the codebase."
survived,"    def test_send_html_email_with_both_body_and_html(self, mock_smtp_class, smtp_provider):
        """"""Test that HTML takes precedence when both body and html are provided.""""""
        # Setup mock SMTP instance
        mock_smtp = MagicMock()
        mock_smtp_class.return_value = mock_smtp

        # Send email with both body and html
        result = smtp_provider._notify(
            from_email=""sender@example.com"",
            from_name=""Test Sender"",
            to_email=""recipient@example.com"",
            subject=""Test Subject"",
            body=""Plain text content"",
            html=""<p>HTML content</p>"",
        )

        # Verify email was sent
        mock_smtp.sendmail.assert_called_once()
        call_args = mock_smtp.sendmail.call_args
        
        # Verify HTML content is used (not plain text)
        email_content = call_args[0][2]
        assert ""Content-Type: text/html"" in email_content
        assert ""<p>HTML content</p>"" in email_content
        assert ""Content-Type: text/plain"" not in email_content
        
        # Verify return value contains both
        assert result == {
            ""from"": ""sender@example.com"",
            ""to"": ""recipient@example.com"",
            ""subject"": ""Test Subject"",
            ""body"": ""Plain text content"",
            ""html"": ""<p>HTML content</p>"",
        }
",tests/test_smtp_provider.py,TestSmtpProvider,1,4.6911638017642294e-08,"The method is a unit test for a specific functionality of an email sending feature, ensuring that HTML content takes precedence over plain text when both are provided. This is a common requirement in email systems, and the test verifies that the implementation behaves as expected. Such tests are crucial for maintaining the reliability of the email sending feature, especially when dealing with different email clients that may render content differently. Therefore, the method is likely to be retained as it serves an important role in ensuring the correctness of the email functionality."
survived,"    def smtp_config(self):
        """"""Create a test SMTP configuration.""""""
        return ProviderConfig(
            description=""Test SMTP Provider"",
            authentication={
                ""smtp_server"": ""smtp.example.com"",
                ""smtp_port"": 587,
                ""encryption"": ""TLS"",
                ""smtp_username"": ""test@example.com"",
                ""smtp_password"": ""testpassword"",
            },
        )
",tests/test_smtp_provider.py,TestSmtpProvider,1,2.1724399346070676e-10,"The method `smtp_config` is a utility function that creates and returns a configuration object for an SMTP provider. This is a common requirement in applications that need to send emails, especially for testing purposes. The method is straightforward, well-defined, and serves a clear purpose. It is unlikely to be deleted unless the entire email sending functionality is removed or significantly refactored. Therefore, it is more likely to survive."
survived,"    def test_validate_scopes_failure(self, smtp_provider):
        """"""Test failed scope validation.""""""
        with patch.object(smtp_provider, ""generate_smtp_client"") as mock_generate:
            mock_generate.side_effect = Exception(""Connection failed"")
            
            result = smtp_provider.validate_scopes()
            
            assert result == {""send_email"": ""Connection failed""}",tests/test_smtp_provider.py,TestSmtpProvider,1,7.582560422162384e-10,"The method 'test_validate_scopes_failure' is a unit test designed to verify the behavior of the 'validate_scopes' method when an exception occurs during the generation of an SMTP client. This test is crucial for ensuring that the system can handle exceptions gracefully and return the expected error message. Unit tests are generally not deleted unless they are redundant, incorrect, or replaced by more comprehensive tests. Since this test serves a specific purpose in validating error handling, it is likely to be retained."
survived,"def workflow_share(
        workflow_share: schemas.WorkflowShare,
        _: schemas.TokenPayload = Depends(get_current_active_user)) -> Any:
    """"""
    åˆ†äº«å·¥ä½œæµ
    """"""
    if not workflow_share.id or not workflow_share.share_title or not workflow_share.share_user:
        return schemas.Response(success=False, message=""è¯·å¡«å†™å·¥ä½œæµIDã€åˆ†äº«æ ‡é¢˜å’Œåˆ†äº«äºº"")
    
    state, errmsg = WorkflowHelper().workflow_share(workflow_id=workflow_share.id,
                                                    share_title=workflow_share.share_title or """",
                                                    share_comment=workflow_share.share_comment or """",
                                                    share_user=workflow_share.share_user or """")
    return schemas.Response(success=state, message=errmsg)
",app/api/endpoints/workflow.py,,1,2.0611536181902033e-09,"The method 'workflow_share' is a functional part of a system that allows users to share workflows. It includes validation checks for necessary fields and interacts with a helper class to perform the sharing action. The method returns a response indicating success or failure, which is a common pattern in API design. Given its utility in enabling a core feature (sharing workflows) and its structured implementation, it is likely to be retained in the codebase."
survived,"def workflow_fork(
        workflow_share: schemas.WorkflowShare,
        current_user: schemas.User = Depends(get_current_active_user)) -> Any:
    """"""
    å¤ç”¨å·¥ä½œæµ
    """"""
    if not workflow_share.name:
        return schemas.Response(success=False, message=""å·¥ä½œæµåç§°ä¸èƒ½ä¸ºç©º"")
    
    # åˆ›å»ºå·¥ä½œæµ
    workflow_dict = {
        ""name"": workflow_share.name,
        ""description"": workflow_share.description,
        ""timer"": workflow_share.timer,
        ""actions"": json.loads(workflow_share.actions or ""[]""),
        ""flows"": json.loads(workflow_share.flows or ""[]""),
        ""context"": json.loads(workflow_share.context or ""{}""),
        ""state"": ""P""  # é»˜è®¤æš‚åœçŠ¶æ€
    }
    
    # æ£€æŸ¥åç§°æ˜¯å¦é‡å¤
    from app.db.workflow_oper import WorkflowOper
    if WorkflowOper().get_by_name(workflow_dict[""name""]):
        return schemas.Response(success=False, message=""å·²å­˜åœ¨ç›¸åŒåç§°çš„å·¥ä½œæµ"")
    
    # åˆ›å»ºæ–°å·¥ä½œæµ
    from app.db.models.workflow import Workflow as WorkflowModel
    from app.db import get_db
    db = next(get_db())
    workflow = WorkflowModel(**workflow_dict)
    workflow.create(db)
    
    # æ›´æ–°å¤ç”¨æ¬¡æ•°
    if workflow_share.id:
        WorkflowHelper().workflow_fork(share_id=workflow_share.id)
    
    return schemas.Response(success=True, message=""å¤ç”¨æˆåŠŸ"")
",app/api/endpoints/workflow.py,,1,1.955568070542584e-08,"The method 'workflow_fork' is a crucial part of the application's functionality as it handles the creation of a new workflow based on shared workflow data. It includes important checks such as ensuring the workflow name is not empty and that it does not duplicate an existing workflow name. Additionally, it updates the reuse count of the workflow share, which is likely important for tracking purposes. These functionalities are essential for maintaining the integrity and usability of the workflow system, making it unlikely to be deleted."
survived,"    def supports_chain(self, chain) -> bool:
        return True
",python/src/plugins/opensea/goat_plugins/opensea/__init__.py,OpenSeaPlugin,1,4.363462233903899e-09,"The method 'supports_chain' is a simple implementation that always returns True, indicating that it supports any chain passed to it. This method is likely a placeholder or a default implementation that might be overridden in subclasses. However, without additional context or requirements indicating that this behavior is incorrect or needs modification, there is no strong reason to delete it. It serves a purpose by providing a default behavior, which can be useful in certain design patterns like the Template Method pattern. Therefore, it is more likely to survive."
survived,"    async def publish_cast(self, parameters: dict):
        url = f""{self.base_url}/cast""
        return await self._make_request(""POST"", url, json={
            ""signer_uuid"": parameters['signer_uuid'],
            ""text"": parameters['text'],
            ""parent"": parameters.get('parent'),
            ""channel_id"": parameters.get('channel_id'),
        })
",python/src/plugins/farcaster/goat_plugins/farcaster/service.py,FarcasterService,1,1.3176514268359263e-10,"The method 'publish_cast' is likely to survive because it is a well-defined asynchronous function that performs a specific task: making a POST request to publish a 'cast'. It uses parameters from a dictionary to construct the request payload, which is a common pattern in API interaction. The method is also flexible, allowing optional parameters like 'parent' and 'channel_id', which enhances its usability. There is no indication of redundancy or obsolescence in the code, suggesting it serves a necessary function in the application."
survived,"    def test_proxy_environment_variables_set(self):
        """"""Test that proxy configuration sets the correct environment variables""""""
        http_proxy_config = {
            ""proxy_url"": ""http://proxy.test.com:8080"",
            ""proxy_ca_certificate"": ""-----BEGIN CERTIFICATE-----\ntest\n-----END CERTIFICATE-----""
        }
        
        with patch.dict('os.environ', {}, clear=True), \
             patch('source_file.proxy._install_ca_certificate') as mock_install:
            
            mock_install.return_value = Path(""/tmp/test_cert.pem"")
            
            from source_file.proxy import configure_custom_http_proxy
            
            configure_custom_http_proxy(
                http_proxy_config=http_proxy_config,
                logger=logger
            )
            
            assert os.environ.get(""HTTP_PROXY"") == ""http://proxy.test.com:8080""
            assert os.environ.get(""HTTPS_PROXY"") == ""http://proxy.test.com:8080""
            assert ""NO_PROXY"" in os.environ
            mock_install.assert_called_once_with(""-----BEGIN CERTIFICATE-----\ntest\n-----END CERTIFICATE-----"")",airbyte-integrations/connectors/source-file/unit_tests/test_proxy_certificate_support.py,TestProxyCertificateSupport,1,3.653482080241728e-08,"The method `test_proxy_environment_variables_set` is a unit test designed to verify that the proxy configuration correctly sets environment variables and installs a CA certificate. It uses mocking to isolate the test from external dependencies, which is a common practice in unit testing. The method is well-structured, serves a clear purpose, and is likely part of a test suite that ensures the reliability of the proxy configuration functionality. Therefore, it is unlikely to be deleted as it contributes to the codebase's robustness by ensuring that changes do not break existing functionality."
survived,"    async def get_trending_tokens_24h(self, parameters: dict):
        """"""Get trending tokens in the last 24h from RugCheck""""""
        return await self._make_request(""/stats/trending"")
",python/src/plugins/rugcheck/goat_plugins/rugcheck/service.py,RugCheckService,1,4.599055376537186e-10,"The method 'get_trending_tokens_24h' is a straightforward asynchronous function that fetches trending tokens from a specified endpoint. It is likely to be useful for applications that need to display or process trending token data. The method is simple, with a clear purpose and a single responsibility, which aligns with good software design principles. There is no indication of redundancy or obsolescence in the method's functionality, suggesting it will be retained."
survived,"    async def get_most_voted_tokens_24h(self, parameters: dict):
        """"""Get tokens with the most votes in the last 24h from RugCheck""""""
        return await self._make_request(""/stats/recent"")
",python/src/plugins/rugcheck/goat_plugins/rugcheck/service.py,RugCheckService,1,2.1724399346070676e-10,"The method 'get_most_voted_tokens_24h' is an asynchronous function that retrieves data from an endpoint '/stats/recent'. It is likely part of a larger system that deals with token statistics, possibly in a cryptocurrency or blockchain context. The method is straightforward, well-named, and serves a clear purpose of fetching recent voting data. There is no indication of redundancy, inefficiency, or lack of use that would suggest it should be deleted. Therefore, it is likely to survive."
survived,"    def _get_master_connector_version(self, connector: Connector) -> semver.Version:
        """"""Get the version from the master branch.""""""
        metadata = self._get_master_metadata(connector)
        if not metadata:
            return semver.Version.parse(""0.0.0"")
        
        return semver.Version.parse(str(metadata[""data""][""dockerImageTag""]))
",airbyte-ci/connectors/connectors_qa/src/connectors_qa/checks/version.py,VersionCheck,1,1.1628233028868813e-10,"The method '_get_master_connector_version' is likely to survive because it performs a specific and useful function: retrieving the version of a connector from the master branch metadata. It includes error handling by returning a default version if metadata is not available, which is a good practice. The method is also concise and clear in its purpose, making it a valuable part of the codebase."
deleted,"def connector():
    connector = MagicMock(spec=Connector)
    connector.technical_name = ""source-test""
    connector.metadata = {""dockerImageTag"": ""1.0.0""}
    connector.is_released = False
    return connector
",airbyte-ci/connectors/connectors_qa/tests/checks/test_version.py,,1,3.3982678079468468e-09,"The method 'connector' is a simple utility function that creates and returns a mock object of type 'Connector'. It is likely used for testing purposes, allowing developers to simulate the behavior of a 'Connector' object without needing a real instance. Such utility functions are common in test suites to facilitate unit testing and are generally not removed unless they are no longer needed or replaced by a more comprehensive testing framework. Since the method serves a clear purpose in testing, it is likely to be retained."
survived,"def list_columns(reasoning: str, csv_path: str) -> List[str]:
    """"""Returns a list of columns in the CSV file.

    The agent uses this to discover available columns and make informed decisions.
    This is typically the first tool called to understand the data structure.

    Args:
        reasoning: Explanation of why we're listing columns relative to user request
        csv_path: Path to the CSV file

    Returns:
        List of column names as strings

    Example:
        columns = list_columns(""Need to find age-related columns"", ""data.csv"")
        # Returns: ['user_id', 'age', 'name', ...]
    """"""
    try:
        df = pl.scan_csv(csv_path).collect()
        columns = df.columns
        console.log(f""[blue]List Columns Tool[/blue] - Reasoning: {reasoning}"")
        console.log(f""[dim]Columns: {columns}[/dim]"")
        return columns
    except Exception as e:
        console.log(f""[red]Error listing columns: {str(e)}[/red]"")
        return []
",sfa_polars_csv_agent_openai_v2.py,,1,4.363462233903899e-09,"The method 'list_columns' is a utility function that provides a fundamental operation for data analysis tasks: listing the columns of a CSV file. This is a common requirement in data processing and analysis workflows, as understanding the structure of the data is crucial for further operations. The method is well-documented, handles exceptions, and logs useful information, making it robust and user-friendly. Given its utility and the fact that it is a basic operation needed in many data-related tasks, it is likely to be retained in the codebase."
survived,"    def _tools_into(self, tools: List[common.Tool] | None) -> List[Dict[str, Any]] | None:
        if not tools:
            return None
        
        ollama_tools = []
        for tool in tools:
            ollama_tools.append({
                ""type"": ""function"",
                ""function"": {
                    ""name"": tool.get(""name"", """"),
                    ""description"": tool.get(""description"", """"),
                    ""parameters"": tool.get(""input_schema"", {})
                }
            })
        return ollama_tools
",agent/llm/ollama_client.py,OllamaLLM,1,1.9171715133907573e-10,"The method '_tools_into' is likely to survive because it is a utility function that transforms a list of 'Tool' objects into a specific dictionary format. This kind of transformation is common in software development, especially when preparing data for serialization or interfacing with other systems. The method is straightforward, performs a clear task, and does not have any apparent issues or redundancies that would necessitate its removal."
survived,"def draw_axis(img, yaw, pitch, roll, tdx=None, tdy=None, size=100):
    pitch = pitch * np.pi / 180
    yaw = -(yaw * np.pi / 180)
    roll = roll * np.pi / 180

    if tdx != None and tdy != None:
        tdx = tdx
        tdy = tdy
    else:
        height, width = img.shape[:2]
        tdx = width / 2
        tdy = height / 2

    x1 = size * (cos(yaw) * cos(roll)) + tdx
    y1 = size * (cos(pitch) * sin(roll) + cos(roll) * sin(pitch) * sin(yaw)) + tdy

    x2 = size * (-cos(yaw) * sin(roll)) + tdx
    y2 = size * (cos(pitch) * cos(roll) - sin(pitch) * sin(yaw) * sin(roll)) + tdy

    x3 = size * (sin(yaw)) + tdx
    y3 = size * (-cos(yaw) * sin(pitch)) + tdy

    cv2.line(img, (int(tdx), int(tdy)), (int(x1), int(y1)), (0, 0, 255), 4)
    cv2.line(img, (int(tdx), int(tdy)), (int(x2), int(y2)), (0, 255, 0), 4)
    cv2.line(img, (int(tdx), int(tdy)), (int(x3), int(y3)), (255, 0, 0), 4)

    return img
",face_recognition/6d_repnet_360/utils_6d_repnet_360/utils.py,,1,1.725782769012759e-08,"The method 'draw_axis' is a utility function that draws 3D axes on an image based on yaw, pitch, and roll angles. This is a common requirement in computer vision tasks, especially in applications involving head pose estimation or augmented reality. The function is well-defined, uses standard libraries like numpy and OpenCV, and serves a clear purpose. It is likely to be useful in various projects that involve image processing and visualization of orientation data. Therefore, it is likely to be retained."
survived,"    def __call__(self, images):
        output = batch_detect(self.model, [images])[0]
        return output
",face_recognition/6d_repnet_360/utils_6d_repnet_360/functions.py,RetinaFaceOnnx,1,1.3440409770490404e-08,"The method is a special method in Python, known as a ""dunder"" method, which allows an instance of a class to be called as a function. This is a common and useful pattern in Python, especially for classes that are designed to perform a single action, like processing or transforming data. The method is simple, clear, and directly uses a function `batch_detect` which seems to be a core part of its functionality. There is no indication of redundancy or inefficiency in the code provided, and it serves a clear purpose. Therefore, it is likely to be retained."
survived,"    def _make_layer(self, block, planes, blocks, stride=1):
        downsample = None
        if stride != 1 or self.inplanes != planes * block.expansion:
            downsample = nn.Sequential(
                nn.Conv2d(self.inplanes, planes * block.expansion,
                          kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(planes * block.expansion),
            )

        layers = []
        layers.append(block(self.inplanes, planes, stride, downsample))
        self.inplanes = planes * block.expansion
        for i in range(1, blocks):
            layers.append(block(self.inplanes, planes))

        return nn.Sequential(*layers)
",face_recognition/6d_repnet_360/convert_to_onnx.py,SixDRepNet360,1,1.4166087846364157e-09,"The method `_make_layer` is a common utility function used in building neural network architectures, particularly in ResNet-like models. It constructs a sequence of layers (blocks) with optional downsampling, which is a fundamental operation in deep learning models for tasks like image classification. Given its utility and the fact that it is a well-established pattern in neural network design, it is unlikely to be deleted unless the entire architecture is being refactored or replaced. Therefore, the method is likely to survive."
survived,"def test_cohere_integration():
    """"""Integration test demonstrating all four Cohere call patterns:
    1. Sync (non-streaming)
    2. Sync (streaming)
    3. Async (non-streaming)
    4. Async (streaming)

    Verifies that AgentOps correctly tracks all LLM calls via analytics.
    """"""
    # Get API key with error handling
    api_key = os.getenv(""COHERE_API_KEY"")
    if not api_key:
        raise ValueError(""COHERE_API_KEY environment variable is required"")
    print(""\nInitializing test with Cohere API key..."")

    # Initialize AgentOps without auto-starting session
    agentops.init(auto_start_session=False)
    session = agentops.start_session()
    print(f""Started new session with ID: {session.session_id}"")

    # Initialize client and provider with error handling
    try:
        co = cohere.Client(api_key=api_key)
        aco = cohere.AsyncClient(api_key=api_key)
        from agentops.llms.providers.cohere import CohereProvider
        provider = CohereProvider(co)
        provider.client = session  # Pass session to provider before override
        provider.override()  # This will handle both sync and async clients
        
        # Set up async client with the same session
        aco.session = session
        # Ensure the async client's provider also has the session
        aco.provider = provider
        print(""Successfully initialized Cohere clients and provider"")
        print(f""Provider session ID: {provider.client.session_id}"")
    except Exception as e:
        print(f""Error initializing Cohere clients: {str(e)}"")
        raise

    def sync_no_stream():
        try:
            print(""\nExecuting sync_no_stream..."")
            response = co.chat(message=""Hello from sync no stream"", model=""command"", session=session)
            print(f""sync_no_stream completed successfully with response: {response.text}"")
        except Exception as e:
            print(f""Error in sync_no_stream: {str(e)}"")
            raise

    def sync_stream():
        try:
            print(""\nExecuting sync_stream..."")
            stream = co.chat_stream(message=""Hello from sync streaming"", model=""command"", session=session)
            completion = """"
            for chunk in stream:
                if hasattr(chunk, 'text'):
                    completion += chunk.text
                print(f""Received sync chunk: {chunk}"")
            print(f""sync_stream completed successfully with completion: {completion}"")
        except Exception as e:
            print(f""Error in sync_stream: {str(e)}"")
            raise

    async def async_no_stream():
        try:
            print(""\nExecuting async_no_stream..."")
            async with asyncio.timeout(30):
                response = await aco.chat(message=""Hello from async no stream"", model=""command"", session=session)
                print(f""async_no_stream completed successfully with response: {response.text}"")
        except asyncio.TimeoutError:
            print(""Warning: async_no_stream timed out"")
            raise
        except Exception as e: 
            print(f""Error in async_no_stream: {str(e)}"")
            raise

    async def async_stream(provider, session):
        try:
            print(""\nStarting async_stream call..."")
            async with asyncio.timeout(30):  # Add timeout to prevent hanging
                # Ensure provider has the current session
                provider.client = session
                # Create a new stream with the provider to ensure proper event tracking
                stream = await aco.chat_stream(
                    message=""Hello from async streaming"",
                    model=""command"",
                    session=session
                )
                print(""Stream created, starting iteration..."")
                async for chunk in stream:
                    print(f""Received async chunk: {chunk}"")
                print(""Stream completed successfully"")
        except asyncio.TimeoutError:
            print(""Warning: Async stream timed out"")
            raise
        except Exception as e:
            print(f""Error in async_stream: {str(e)}"")
            raise

    async def run_async_tests():
        print(""\nRunning async tests..."")
        print(""Starting async_no_stream..."")
        await async_no_stream()
        print(""Completed async_no_stream"")
        
        print(""\nStarting first async_stream..."")
        await async_stream(provider, session)
        print(""Completed first async_stream"")
        
        print(""\nStarting second async_stream..."")
        await async_stream(provider, session)  # Run twice to ensure we get all LLM calls
        print(""Completed second async_stream"")
        
        print(""\nStarting third async_stream..."")
        await async_stream(provider, session)  # Run thrice to ensure we get all LLM calls
        print(""Completed third async_stream"")
        
        print(""\nAll async tests completed successfully"")
        
        # End session and verify analytics after all tests
        session.end_session(""Success"")
        analytics = session.get_analytics()
        print(f""\nAnalytics: {analytics}"")
        assert analytics[""LLM calls""] >= 4, f""Expected at least 4 LLM calls, but got {analytics['LLM calls']}""

    # Call each function with proper error handling
    try:
        sync_no_stream()
        sync_stream()
        asyncio.run(run_async_tests())
    except Exception as e:
        print(f""Error during Cohere test: {str(e)}"")
        raise

    print(""\nTest completed successfully"")
",tests/core_manual_tests/providers/cohere_canary.py,,1,2.1024340680345882e-07,"The method `test_cohere_integration` is a comprehensive integration test for the Cohere API, demonstrating various call patterns and ensuring that analytics are correctly tracked. It includes error handling, session management, and both synchronous and asynchronous operations. Such tests are crucial for verifying the functionality and reliability of integrations with external services. Therefore, it is unlikely to be deleted as it serves an important purpose in maintaining the quality and correctness of the system."
survived,"    async def run_async_tests():
        await async_no_stream()
        await async_stream()
",tests/core_manual_tests/providers/litellm_canary.py,,1,6.69158608681505e-10,"The method 'run_async_tests' is a simple asynchronous function that calls two other asynchronous functions, 'async_no_stream' and 'async_stream'. There is no indication that this method is obsolete, redundant, or poorly implemented. It serves a clear purpose in running these asynchronous tests, which is a common pattern in asynchronous programming. Without any context suggesting that this method is no longer needed or has been replaced, it is likely to survive."
survived,"    async def run_async_tests():
        await async_no_stream()
        await async_stream()
",tests/core_manual_tests/providers/anthropic_canary.py,,1,1.0467401685178159e-08,"The method `run_async_tests` is a simple asynchronous function that calls two other asynchronous functions, `async_no_stream` and `async_stream`. There is no indication that this method is obsolete, redundant, or incorrect. It is likely part of a test suite for asynchronous operations, which is a common and necessary practice in modern software development. Therefore, there is no reason to delete this method unless the entire testing framework or the functions it calls are being removed or refactored."
survived,"    async def async_no_stream():
        # Mistral doesn't have async methods, use sync
        client.chat(
            model=""mistral-tiny"",
            messages=[ChatMessage(role=""user"", content=""Hello from async no stream"")]
        )
",tests/core_manual_tests/providers/mistral_canary.py,,0,0.9999898700118929,"The method `async_no_stream` is defined as an asynchronous function but does not contain any `await` expressions or asynchronous operations. It calls a synchronous method `client.chat` directly, which contradicts the purpose of using an async function. This inconsistency suggests that the method is not utilizing the benefits of asynchronous programming, making it redundant as an async function. Therefore, it is likely to be refactored or deleted to maintain code clarity and efficiency."
survived,"def determine_if_file_is_relevant(prompt: str, file_path: str, client: Anthropic) -> Dict[str, Any]:
    """"""Determines if a single file is relevant to the prompt.
    
    Args:
        prompt: The user prompt
        file_path: Path to the file to check
        client: Anthropic client
        
    Returns:
        Dictionary with reasoning and is_relevant flag
    """"""
    result = {
        ""reasoning"": ""Error: Could not process file"",
        ""file_path"": file_path,
        ""is_relevant"": False
    }
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            file_content = f.read()
        
        # Truncate file content if it's too long
        if len(file_content) > 10000:
            file_content = file_content[:10000] + ""... [content truncated]""
        
        file_prompt = f""""""
        <purpose>
        You are a codebase context builder. Your task is to determine if a file is relevant to a user query.
        </purpose>
        
        <instructions>
        <instruction>Analyze the file content and determine if it's relevant to the user query.</instruction>
        <instruction>Provide clear reasoning for your decision.</instruction>
        <instruction>Return a structured output with your reasoning and a boolean indicating relevance.</instruction>
        </instructions>
        
        <user-query>
        {prompt}
        </user-query>
        
        <file-path>
        {file_path}
        </file-path>
        
        <file-content>
        {file_content}
        </file-content>
        """"""
        
        for attempt in range(MAX_RETRIES):
            try:
                response = client.messages.create(
                    model=""claude-3-7-sonnet-20250219"",
                    max_tokens=3000,  # Increased to be greater than thinking.budget_tokens
                    thinking={
                        ""type"": ""enabled"",
                        ""budget_tokens"": THINKING_BUDGET_TOKENS_PER_FILE
                    },
                    messages=[{""role"": ""user"", ""content"": file_prompt}],
                    system=""Determine if the file is relevant to the user query. Return a JSON object with 'reasoning' and 'is_relevant' fields.""
                )
                
                # Parse the response
                response_text = response.content[0].text
                result = json.loads(response_text)
                
                return {
                    ""reasoning"": result.get(""reasoning"", ""No reasoning provided""),
                    ""file_path"": file_path,
                    ""is_relevant"": result.get(""is_relevant"", False)
                }
            except Exception as e:
                if attempt < MAX_RETRIES - 1:
                    console.log(f""[yellow]Retry {attempt + 1}/{MAX_RETRIES} for {file_path}: {str(e)}[/yellow]"")
                    time.sleep(RETRY_WAIT)
                else:
                    console.log(f""[red]Failed to determine relevance for {file_path}: {str(e)}[/red]"")
                    return {
                        ""reasoning"": f""Error: {str(e)}"",
                        ""file_path"": file_path,
                        ""is_relevant"": False
                    }
    except Exception as e:
        console.log(f""[red]Error processing file {file_path}: {str(e)}[/red]"")
        return {
            ""reasoning"": f""Error: {str(e)}"",
            ""file_path"": file_path,
            ""is_relevant"": False
        }
",sfa_codebase_context_agent_v3.py,,1,8.152020648014727e-09,"The method 'determine_if_file_is_relevant' is likely to survive because it provides a clear and structured approach to determining the relevance of a file based on a user prompt. It includes error handling, retries, and uses an external client (Anthropic) to process the file content, which suggests it is part of a larger system that relies on this functionality. The method is well-documented, indicating it is intended for use and maintenance. Additionally, the use of AI to determine relevance is a modern approach that aligns with current technological trends."
survived,"def check_file_paths_line_length(reasoning: str, file_paths: List[str], file_line_limit: int = 500) -> Dict[str, int]:
    """"""Checks the line length of each file and returns a dictionary of file paths and their line counts.
    
    Args:
        reasoning: Explanation of why we're checking line lengths
        file_paths: List of file paths to check
        file_line_limit: Maximum number of lines per file
        
    Returns:
        Dictionary mapping file paths to their total line counts
    """"""
    try:
        console.log(f""[blue]Check File Paths Line Length Tool[/blue] - Reasoning: {reasoning}"")
        console.log(f""[dim]Checking {len(file_paths)} files with line limit {file_line_limit}[/dim]"")
        
        result = {}
        for file_path in file_paths:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    line_count = len(lines)
                    if line_count <= file_line_limit:
                        result[file_path] = line_count
                    else:
                        console.log(f""[yellow]Skipping {file_path}: {line_count} lines exceed limit of {file_line_limit}[/yellow]"")
            except Exception as e:
                console.log(f""[red]Error reading file {file_path}: {str(e)}[/red]"")
        
        console.log(f""[dim]Found {len(result)} files within line limit[/dim]"")
        return result
    except Exception as e:
        console.log(f""[red]Error checking file paths: {str(e)}[/red]"")
        return {}
",sfa_codebase_context_agent_v3.py,,1,5.60279640614594e-09,"The method is well-documented, handles exceptions, and provides useful logging information. It performs a common task of checking file line lengths, which can be useful in many scenarios such as code quality checks or data processing. The method is likely to be retained as it serves a practical purpose and is implemented in a robust manner."
survived,"    def override(self):
        """"""Override Gemini's generate_content method to track LLM events.""""""
        if not hasattr(self.client, 'generate_content'):
            logger.warning(""Client does not have generate_content method. Skipping override."")
            return
            
        # Store original method
        self.original_generate = self.client.generate_content
        
        def patched_function(*args, **kwargs):
            init_timestamp = get_ISO_time()
            session = kwargs.pop(""session"", None) if ""session"" in kwargs else None
            
            # Handle positional content argument
            if args:
                kwargs[""contents""] = args[0]
                args = args[1:]  # Remove content from args
            
            # Ensure we have the original method
            if self.original_generate is None:
                logger.error(""Original generate_content method not found. Cannot proceed with override."")
                return None
            
            # Call original method and track event
            result = self.original_generate(*args, **kwargs)
            return self.handle_response(result, kwargs, init_timestamp, session=session)
        
        # Override the method
        self.client.generate_content = patched_function
",agentops/llms/providers/gemini.py,GeminiProvider,1,2.5109990926928157e-08,"The method is a well-structured override of an existing method, providing additional functionality such as logging and event tracking without altering the original method's core behavior. It includes error handling and ensures that the original method is preserved and callable. This makes it a useful and non-intrusive enhancement, likely to be retained in the codebase."
survived,"    def __init__(self, client):
        """"""Initialize the Gemini provider.
        
        Args:
            client: A configured google.generativeai client instance
        
        Raises:
            ValueError: If client is not properly configured
        """"""
        if not client:
            raise ValueError(""Client must be provided"")
        
        super().__init__(client)
        self._provider_name = ""Gemini""
        
        # Verify client has required methods
        if not hasattr(client, 'generate_content'):
            raise ValueError(""Client must have generate_content method"")
",agentops/llms/providers/gemini.py,GeminiProvider,1,2.2159489282323004e-08,"The method is a constructor (__init__) for initializing an instance of a class, which is a fundamental part of object-oriented programming. It includes necessary checks to ensure that the 'client' parameter is properly configured, raising exceptions if it is not. This kind of validation is crucial for robust code, preventing runtime errors due to misconfiguration. Therefore, it is unlikely to be deleted as it serves an essential purpose in the class's functionality."
survived,"    async def swap_tokens(self, wallet_client: SolanaWalletClient, parameters: dict):
        """"""Swap tokens using Jupiter DEX.""""""
        try:
            # First get the quote
            quote_response = await self.get_quote(wallet_client, parameters)
            
            # Prepare swap request
            swap_request = {
                ""userPublicKey"": wallet_client.get_address(),
                ""quoteResponse"": quote_response.dict(),
                ""dynamicComputeUnitLimit"": True,
                ""prioritizationFeeLamports"": ""auto""
            }
            
            # Get swap transaction
            async with aiohttp.ClientSession(**self._session_kwargs) as session:
                async with session.post(f""{self.base_url}/swap"", json={""swapRequest"": swap_request}) as response:
                    if response.status != 200:
                        error_data = await response.json()
                        raise Exception(f""Failed to create swap transaction: {error_data.get('error', 'Unknown error')}"")
                    
                    swap_response = await response.json()
                    swap_transaction = swap_response.get(""swapTransaction"")
                    
                    if not swap_transaction:
                        raise Exception(""No swap transaction returned"")
                    
                    # Deserialize the transaction
                    versioned_transaction = VersionedTransaction.from_bytes(base64.b64decode(swap_transaction))
                    
                    # Get instructions from the transaction
                    instructions = await wallet_client.decompile_versioned_transaction_to_instructions(versioned_transaction)
                    
                    # Send the transaction
                    result = await wallet_client.send_transaction({
                        ""instructions"": instructions,
                        ""address_lookup_table_addresses"": [
                            lookup.account_key.to_base58() 
                            for lookup in versioned_transaction.message.address_table_lookups
                        ]
                    })
                    
                    return {
                        ""hash"": result[""hash""]
                    }
                    
        except Exception as error:
            raise Exception(f""Failed to swap tokens: {error}"")",python/src/plugins/jupiter/goat_plugins/jupiter/service.py,JupiterService,1,8.152020648014727e-09,"The method 'swap_tokens' is likely to survive because it is a well-structured asynchronous function that performs a critical operation of swapping tokens using the Jupiter DEX. It includes error handling, uses async/await for non-blocking operations, and interacts with external services, which are common practices in modern software development. Additionally, the method is specific to a financial operation, which is often a core functionality in applications dealing with cryptocurrency transactions."
survived,"def test_both_async_params_error(mock_isinstance):
    """"""Test that providing both _async and use_async raises an error.""""""
    mock_model = MagicMock()
    mock_model.generate_content = MagicMock()
    mock_model.generate_content_async = MagicMock()
    
    with pytest.raises(ConfigurationError, match=""Cannot provide both '_async' and 'use_async'. Use 'use_async' instead.""):
        client = from_vertexai(
            mock_model, 
            _async=True,
            use_async=True
        )",tests/llm/test_vertexai/test_deprecated_async.py,,1,6.825604231969389e-08,"The method 'test_both_async_params_error' is a unit test designed to ensure that a specific error is raised when both '_async' and 'use_async' parameters are provided. Unit tests are crucial for maintaining code quality and ensuring that changes do not introduce new bugs. This test is likely part of a larger test suite and serves a specific purpose in validating error handling. Therefore, it is unlikely to be deleted as it contributes to the robustness of the codebase."
survived,"def _get_stream_name(yaml_stream: dict) -> str | None:
    if ""name"" in yaml_stream:
        return yaml_stream[""name""]
    if ""$parameters"" in yaml_stream and ""name"" in yaml_stream[""$parameters""]:
        return yaml_stream[""$parameters""][""name""]
    return None
",airbyte-ci/connectors/pipelines/pipelines/airbyte_ci/connectors/migrate_to_inline_schemas/pipeline.py,,1,2.646573631904765e-09,"The method _get_stream_name is a utility function that extracts a 'name' from a given dictionary, which is a common task when dealing with structured data like YAML. It checks for the presence of a 'name' key directly or within a '$parameters' sub-dictionary. This functionality is straightforward, useful, and likely to be reused in various contexts where YAML data is processed. There are no apparent issues with the logic or implementation, and it serves a clear purpose. Therefore, it is likely to be retained in the codebase."
survived,"def utils():
    """"""Utils API reference page.""""""
    with open(""docs/api-reference/utils.md"", encoding=""utf-8"") as f:
        content = f.read()
    return rx.markdown(content)",pcweb/pages/docs/api_reference/utils.py,,1,7.194132978569833e-09,"The method 'utils' is a simple utility function that reads a markdown file and returns its content as a markdown object. This function is likely part of a larger codebase where documentation is dynamically loaded and displayed. The function is straightforward, performs a specific task, and does not have any apparent issues or redundancies. Therefore, it is likely to be retained in the codebase."
survived,"    def test_multiple_pause_resume_cycles(self):
        """"""Test multiple pause/resume cycles work correctly.""""""
        formatter = ConsoleFormatter()
        
        mock_live = MagicMock(spec=Live)
        formatter._live = mock_live
        formatter._live_paused = False
        
        formatter.pause_live_updates()
        assert formatter._live_paused
        mock_live.stop.assert_called_once()
        assert formatter._live is None  # Live session should be cleared
        
        formatter.resume_live_updates()
        assert not formatter._live_paused
        
        formatter.pause_live_updates()
        assert formatter._live_paused
        
        formatter.resume_live_updates()
        assert not formatter._live_paused
",tests/utilities/test_console_formatter_pause_resume.py,TestConsoleFormatterPauseResume,1,9.931195248674785e-08,"The method 'test_multiple_pause_resume_cycles' is a unit test designed to verify the functionality of pausing and resuming live updates in a console formatter. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with state changes like pausing and resuming operations. This test method checks multiple cycles of pause and resume, which is important for catching potential bugs in state management. Given its role in maintaining code quality and its specific focus on a feature's functionality, it is unlikely to be deleted."
survived,"        async def _(model_uuid: str) -> str:
            json_data = await quart.request.json

            await self.ap.embeddings_models_service.test_embeddings_model(model_uuid, json_data)

            return self.success()",pkg/api/http/controller/groups/provider/models.py,EmbeddingsModelsRouterGroup,1,1.1861120010657661e-08,"The method is an asynchronous function that seems to be part of a web service, likely using the Quart framework. It handles a request by extracting JSON data, performing an operation with a service (testing an embeddings model), and then returning a success response. This is a typical pattern for handling API requests in web applications, and there is no indication of deprecated practices or inefficiencies that would warrant deletion. The method appears to be functional and relevant to its context."
deleted,"    async def remove_embeddings_model(self, model_uuid: str):
        """"""ç§»é™¤ Embeddings æ¨¡åž‹""""""
        for model in self.embeddings_models:
            if model.model_entity.uuid == model_uuid:
                self.embeddings_models.remove(model)
                return
",pkg/provider/modelmgr/modelmgr.py,ModelManager,1,9.237449576640118e-09,"The method `remove_embeddings_model` is a straightforward utility function that removes a model from a list based on a UUID. It is a common operation in managing collections of objects, especially in contexts where models or entities are dynamically managed. The method is simple, clear, and serves a specific purpose without any apparent issues or redundancies. Therefore, it is likely to be retained as it provides necessary functionality for managing embeddings models."
deleted,"    async def test_embeddings_model(self, model_uuid: str, model_data: dict) -> None:
        runtime_embeddings_model: model_requester.RuntimeEmbeddingsModel | None = None

        if model_uuid != '_':
            for model in self.ap.model_mgr.embeddings_models:
                if model.model_entity.uuid == model_uuid:
                    runtime_embeddings_model = model
                    break

            if runtime_embeddings_model is None:
                raise Exception('model not found')

        else:
            runtime_embeddings_model = await self.ap.model_mgr.init_runtime_embeddings_model(model_data)

        await runtime_embeddings_model.requester.invoke_embeddings(
            query=None,
            model=runtime_embeddings_model,
            input_text=""Hello, world!"",
            extra_args={},
        )",pkg/api/http/service/model.py,EmbeddingsModelsService,1,1.2501528648238603e-09,"The method 'test_embeddings_model' is likely to survive because it performs a specific and useful function: testing an embeddings model by invoking it with a sample input. It includes error handling for cases where the model is not found, and it supports both existing models and initializing new ones. This functionality is essential for validating model behavior, which is a common requirement in machine learning workflows. Additionally, the use of async and await suggests it is designed to handle asynchronous operations efficiently, which is a modern and desirable feature in software development."
survived,"def test_write_skips_message_from_unknown_stream(client):
    stream = ""unknown_stream""
    data = {""field1"": ""test-value"", ""field2"": ""test-value""}
    pipeline = _init_mocks(client)
    input_messages = [_record(stream=stream, data=data), _state()]
    destination = DestinationGlassflow()
    for m in destination.write(config=config, configured_catalog=_configured_catalog(), input_messages=input_messages):
        assert m.type == Type.STATE
    pipeline.publish.assert_not_called()",airbyte-integrations/connectors/destination-glassflow/unit_tests/unit_test.py,,1,8.152020648014727e-09,"The method 'test_write_skips_message_from_unknown_stream' is a unit test designed to verify that the 'DestinationGlassflow' class correctly skips messages from unknown streams and does not publish them. This is a valid and useful test case to ensure the robustness of the system by confirming that only messages from known streams are processed. The method is well-structured, uses mock objects to simulate the environment, and includes assertions to validate the expected behavior. Therefore, it is likely to be retained in the codebase as it contributes to the overall test coverage and quality assurance."
survived,"def test_unlimited_tool_usage():
    """"""Test that tools without usage limits work normally.""""""
    class UnlimitedTool(BaseTool):
        name: str = ""Unlimited Tool""
        description: str = ""A tool without usage limits""

        def _run(self, input_text: str) -> str:
            return f""Processed {input_text}""

    tool = UnlimitedTool()
    
    for i in range(5):
        result = tool.run(input_text=f""test{i}"")
        assert result == f""Processed test{i}""
        assert tool.current_usage_count == i + 1
",tests/tools/test_tool_usage_limit.py,,1,7.582560422162384e-10,"The method 'test_unlimited_tool_usage' is a unit test designed to verify the functionality of a tool that is supposed to have unlimited usage. It is a straightforward test that checks if the tool processes input correctly and tracks usage count accurately. Such tests are essential for ensuring code reliability and are unlikely to be deleted unless the feature itself is removed or significantly altered. Therefore, the method is likely to survive."
survived,"    def test_load_cache(self) -> None:
        """"""Test the load_cache method.""""""
        loader = MockPersistenceLoader(""test"", self.save_path)
        
        # Create and save a cache
        cache = Cache(
            {""var1"": ""value1""}, 
            ""hash1"", 
            set(),
            ""Pure"",
            True,
            {}
        )
        loader.saved_caches[""Pure_hash1""] = cache
        
        # Create a placeholder file to trigger cache_hit
        cache_path = loader.build_path(""hash1"", ""Pure"")
        with open(cache_path, ""w"") as f:
            f.write(""placeholder"")
        
        # Load the cache
        loaded_cache = loader.load_cache(""hash1"", ""Pure"")
        assert loaded_cache.hash == ""hash1""
        
        # Should raise for non-existent cache
        with pytest.raises(LoaderError, match=""Unexpected cache miss""):
            loader.load_cache(""nonexistent"", ""Pure"")",tests/_save/loaders/test_loader.py,TestBasePersistenceLoader,1,1.522997951276035e-08,"The method `test_load_cache` is a unit test for the `load_cache` method of a `MockPersistenceLoader` class. Unit tests are crucial for ensuring that code functions as expected and for catching regressions when code changes. This test checks both the successful loading of a cache and the proper handling of a cache miss, which are important aspects of the method's functionality. Therefore, it is likely to be retained to maintain code quality and reliability."
survived,"    def test_cache_attempt_hit(self) -> None:
        """"""Test cache attempt with a hit.""""""
        loader = MockLoader(""test"")
        defs = {""var1""}
        stateful_refs: Set[str] = set()
        
        # Create and save a cache
        original_cache = Cache(
            {""var1"": ""value1""}, 
            ""hash1"", 
            stateful_refs,
            ""Pure"",
            True,
            {""version"": 1}
        )
        loader.saved_caches[""Pure_hash1""] = original_cache
        
        # Attempt to load the cache
        cache = loader.cache_attempt(defs, ""hash1"", stateful_refs, ""Pure"")
        
        assert cache.hash == ""hash1""
        assert cache.hit is True
        assert cache.cache_type == ""Pure""
        assert cache.defs[""var1""] == ""value1""
        assert cache.meta == {""version"": 1}
",tests/_save/loaders/test_loader.py,TestLoader,1,3.3982678079468468e-09,"The method `test_cache_attempt_hit` is a unit test designed to verify the functionality of the `cache_attempt` method in a caching system. It checks if a cache can be successfully retrieved (a 'hit') when the correct parameters are provided. Unit tests are crucial for ensuring code reliability and are typically maintained as long as the functionality they test is relevant. Since this test is directly related to verifying the correctness of a caching mechanism, it is likely to be retained to ensure the system behaves as expected."
survived,"    def setup_method(self) -> None:
        """"""Set up a temporary directory for each test.""""""
        self.temp_dir = tempfile.TemporaryDirectory()
        self.save_path = self.temp_dir.name
",tests/_save/loaders/test_pickle_loader.py,TestPickleLoader,1,6.825604231969389e-08,"The method 'setup_method' is a common pattern in testing frameworks to prepare the environment before each test case runs. It is used to set up necessary preconditions, such as creating temporary directories or files, which are often required for tests to run in isolation and without side effects. This method is likely to be used in a test suite to ensure that each test has a clean and controlled environment. Therefore, it is unlikely to be deleted as it serves a crucial role in test setup."
survived,"    def __init__(self, name: str, config_value: str = ""default"") -> None:
        super().__init__(name)
        self.config_value = config_value
        self.saved_caches: Dict[str, Cache] = {}
",tests/_save/loaders/test_loader.py,MockLoader,1,7.194132978569833e-09,"The method is a constructor for a class, initializing important attributes such as 'name', 'config_value', and 'saved_caches'. Constructors are essential for setting up the initial state of an object, and this one includes a default parameter, which adds flexibility. There is no indication that this method is redundant or unnecessary, so it is likely to be retained."
survived,"    def cache_hit(self, hashed_context: str, cache_type: str) -> bool:
        key = f""{cache_type}_{hashed_context}""
        return key in self.saved_caches
",tests/_save/loaders/test_loader.py,MockLoader,1,9.736200303530205e-10,The method 'cache_hit' is a simple utility function that checks if a given key exists in a dictionary 'saved_caches'. This is a common pattern in caching mechanisms to determine if a cached value is available. Such methods are generally useful and likely to be retained as they provide a basic and necessary functionality for cache management.
survived,"    def test_init(self) -> None:
        """"""Test initialization.""""""
        loader = MockPersistenceLoader(""test"", self.save_path)
        assert loader.name == ""test""
        assert loader.suffix == ""mock""
        assert str(loader.save_path).endswith(""/test"")
        
        # Check that the directory was created
        assert (Path(self.save_path) / ""test"").exists()
",tests/_save/loaders/test_loader.py,TestBasePersistenceLoader,1,1.1861120010657661e-08,"The method `test_init` is a unit test designed to verify the initialization of a `MockPersistenceLoader` object. It checks that the object's attributes are correctly set and that the expected directory is created. Unit tests are crucial for ensuring code reliability and are typically retained in codebases to maintain software quality. Therefore, this method is likely to be retained."
survived,"    def load_persistent_cache(
        self, hashed_context: str, cache_type: str
    ) -> Cache:
        key = f""{cache_type}_{hashed_context}""
        if key not in self.saved_caches:
            raise FileNotFoundError(f""No cache found for {key}"")
        return self.saved_caches[key]
",tests/_save/loaders/test_loader.py,MockPersistenceLoader,1,2.3355930333443423e-09,"The method 'load_persistent_cache' is a utility function that retrieves a cached object based on a hashed context and cache type. It checks if the cache exists and raises an error if it doesn't, which is a common pattern for cache retrieval functions. This method is likely to be useful in scenarios where caching is implemented to improve performance by avoiding redundant computations. Since caching is a widely used technique in software development, this method is likely to be retained unless the caching mechanism itself is removed or significantly altered."
survived,"    def validate_schema(self):
        """"""Validate that the current database schema matches the expected schema.

        Raises:
            RuntimeError: If there is a mismatch between the current schema and expected schema,
                        with instructions to clear the cache.
        """"""
        expected_columns = [
            ""run_hash"",
            ""dataset_hash"",
            ""prompt_func"",
            ""model_name"",
            ""response_format"",
            ""batch_mode"",
            ""created_time"",
            ""last_edited_time"",
        ]
        current_info = self._get_current_schema()
        current_columns = [col[1] for col in current_info]  # col[1] = column name

        if set(current_columns) != set(expected_columns):
            msg = (
                ""Detected a mismatch between the local DB schema and the expected schema. ""
                ""Please clear your cache with `rm -rf ~/.cache/curator` or ""
                ""`rm -rf $CURATOR_CACHE_DIR` if set.""
            )
            raise RuntimeError(msg)
",src/bespokelabs/curator/db.py,MetadataDB,1,1.725782769012759e-08,"The method 'validate_schema' is crucial for ensuring that the database schema is consistent with the expected structure. This is important for maintaining data integrity and preventing errors that could arise from schema mismatches. The method provides a clear error message and instructions for resolving the issue, which is valuable for debugging and maintenance. Such validation methods are common in software systems to ensure compatibility and correctness, making it unlikely to be removed unless the entire schema validation approach is changed."
survived,"    def __init__(self, client: SolanaClient):
        """"""Initialize the Solana wallet client.

        Args:
            client: A Solana RPC client instance
        """"""
        super().__init__()
        self.client = client
",python/src/wallets/solana/goat_wallets/solana/wallet.py,SolanaWalletClient,1,2.3823698451773172e-07,"The method is a constructor for a class that initializes an instance with a Solana RPC client. Constructors are essential for setting up initial state in object-oriented programming, and this method is necessary for the class to function correctly. Therefore, it is unlikely to be deleted."
survived,"    def sign_message(self, message: str) -> Signature:
        """"""Sign a message with the wallet's private key.""""""
        message_bytes = message.encode(""utf-8"")
        signed = nacl.signing.SigningKey(self.keypair.secret_key).sign(message_bytes)
        return {""signature"": signed.signature.hex()}
",python/src/wallets/solana/goat_wallets/solana/wallet.py,SolanaKeypairWalletClient,1,1.4166087846364157e-09,"The method 'sign_message' is a crucial part of any cryptographic or blockchain-related application where message integrity and authenticity are important. It uses a private key to sign a message, which is a common requirement in secure communications. The method is well-defined, performs a specific and necessary function, and there is no indication that it is redundant or obsolete. Therefore, it is likely to be retained in the codebase."
survived,"    def _is_css_element_empty(self, css_element):
        return css_element is None or css_element.strip() == """"
",crewai_tools/tools/selenium_scraping_tool/selenium_scraping_tool.py,SeleniumScrapingTool,1,6.348800075736417e-09,"The method _is_css_element_empty is a utility function that checks if a given CSS element is empty or None. This is a common operation in web development, especially when parsing or manipulating CSS data. The method is simple, efficient, and serves a clear purpose, making it likely to be retained in the codebase. It helps in avoiding errors related to empty or null CSS elements, which can be crucial for maintaining the integrity of web styling operations."
survived,"    def _get_elements_content(self, driver, css_element, return_html):
        elements_content = []

        for element in driver.find_elements(By.CSS_SELECTOR, css_element):
            elements_content.append(
                element.get_attribute(""outerHTML"") if return_html else element.text
            )

        return elements_content
",crewai_tools/tools/selenium_scraping_tool/selenium_scraping_tool.py,SeleniumScrapingTool,1,8.592166611791576e-10,"The method '_get_elements_content' is a utility function that extracts content from web elements using a web driver. It is a useful method for web scraping tasks, allowing flexibility in returning either the HTML or text content of elements. The method is well-defined, serves a clear purpose, and is likely to be used in various web automation or scraping scenarios. Therefore, it is unlikely to be deleted."
survived,"    def _get_body_content(self, driver, return_html):
        body_element = driver.find_element(By.TAG_NAME, ""body"")

        return (
            body_element.get_attribute(""outerHTML"")
            if return_html
            else body_element.text
        )
",crewai_tools/tools/selenium_scraping_tool/selenium_scraping_tool.py,SeleniumScrapingTool,1,7.582560422162384e-10,"The method '_get_body_content' is likely to survive because it provides a clear and useful functionality: retrieving the body content of a webpage either as HTML or plain text. This is a common requirement in web scraping and automation tasks, making the method valuable. Additionally, the method is concise and leverages Selenium's capabilities effectively, which suggests it is well-implemented for its purpose."
survived,"def test_scrape_with_css_selector(_mocked_chrome_driver):
    html_content = ""<html><body><div>test content</div><div class='test'>test content in a specific div</div></body></html>""
    mock_driver = mock_driver_with_html(html_content)
    tool = initialize_tool_with(mock_driver)

    result = tool._run(website_url=""https://example.com"", css_element=""div.test"")

    assert ""test content in a specific div"" in result
    mock_driver.get.assert_called_once_with(""https://example.com"")
    mock_driver.find_elements.assert_called_with(""css selector"", ""div.test"")
    mock_driver.close.assert_called_once()
",tests/tools/selenium_scraping_tool_test.py,,1,4.363462233903899e-09,"The method 'test_scrape_with_css_selector' is a unit test designed to verify the functionality of a web scraping tool using a CSS selector. It uses a mocked Chrome driver to simulate the behavior of a web browser, ensuring that the tool correctly retrieves content from a specified HTML element. This type of test is crucial for validating the accuracy and reliability of web scraping tools, especially when dealing with dynamic web content. Given the importance of testing in software development and the specific focus on a common web scraping scenario, this method is likely to be retained in the codebase."
deleted,"def sanitize_collection_name(name: Optional[str]) -> str:
    """"""
    Sanitize a collection name to meet ChromaDB requirements:
    1. 3-63 characters long
    2. Starts and ends with alphanumeric character
    3. Contains only alphanumeric characters, underscores, or hyphens
    4. No consecutive periods
    5. Not a valid IPv4 address

    Args:
        name: The original collection name to sanitize

    Returns:
        A sanitized collection name that meets ChromaDB requirements
    """"""
    if not name:
        return ""default_collection""

    # Replace spaces and invalid characters with underscores
    sanitized = re.sub(r""[^a-zA-Z0-9_-]"", ""_"", name)

    # Ensure it starts with alphanumeric
    if not sanitized[0].isalnum():
        sanitized = ""a"" + sanitized

    # Ensure it ends with alphanumeric
    if not sanitized[-1].isalnum():
        sanitized = sanitized[:-1] + ""z""

    # Ensure length is between 3-63 characters
    if len(sanitized) < 3:
        # Add padding with alphanumeric character at the end
        sanitized = sanitized + ""x"" * (3 - len(sanitized))
    if len(sanitized) > 63:
        sanitized = sanitized[:63]
        # Ensure it still ends with alphanumeric after truncation
        if not sanitized[-1].isalnum():
            sanitized = sanitized[:-1] + ""z""

    return sanitized",src/crewai/utilities/string_utils.py,,1,6.348800075736417e-09,"The method 'sanitize_collection_name' is well-defined and serves a clear purpose of sanitizing collection names to meet specific requirements. It handles edge cases such as empty input, invalid characters, and length constraints effectively. The method is likely to be useful in contexts where collection names need to adhere to strict naming conventions, such as in databases or APIs. Therefore, it is unlikely to be deleted as it provides necessary functionality."
survived,"async def send_data_to_slack(event_instance: DemoEvent):
    """"""Send demo form data to Slack webhook.
    
    Args:
        event_instance: An instance of DemoEvent with form data.
    """"""
    slack_payload = {
        ""lookingToBuild"": event_instance.internal_tools,
        ""businessName"": event_instance.company_email,
        ""howDidYouHear"": event_instance.referral_source,
        ""linkedinUrl"": event_instance.linkedin_url,
        ""jobTitle"": event_instance.job_title,
        ""numEmployees"": event_instance.num_employees,
        ""companyName"": event_instance.company_name,
        ""firstName"": event_instance.first_name,
        ""lastName"": event_instance.last_name
    }
    
    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(
                SLACK_DEMO_WEBHOOK_URL,
                json=slack_payload,
                headers={""Content-Type"": ""application/json""}
            )
            response.raise_for_status()
    except Exception:
        log(""Error sending data to Slack webhook"")",pcweb/telemetry/postog_metrics.py,,1,3.653482080241728e-08,"The method is a utility function that sends data to a Slack webhook, which is a common requirement for integrating applications with Slack for notifications or data logging. It uses asynchronous HTTP requests, which is efficient for non-blocking operations. The method is well-structured, with error handling and logging, making it robust for production use. Such methods are typically retained as they serve a specific integration purpose and are useful for real-time data communication."
survived,"    def _start_subprocess(self):
        """"""Start the reflex app using subprocess instead of threads.""""""
        backend_port = reflex.utils.processes.handle_port(
            ""backend"", 8000, auto_increment=True
        )
        frontend_port = reflex.utils.processes.handle_port(
            ""frontend"", 3000, auto_increment=True
        )

        self.reflex_process = reflex.utils.processes.new_process(
            [
                sys.executable,
                ""-m"",
                ""reflex"",
                ""run"",
                ""--backend-port"",
                str(backend_port),
                ""--frontend-port"",
                str(frontend_port),
                ""--env"",
                ""dev"",
            ],
            cwd=self.app_path,
            env={""NO_COLOR"": ""1""},
        )

        self.backend_port = backend_port
        self.frontend_port = frontend_port

        self._wait_for_servers()
",reflex/testing.py,AppHarness,1,7.582560422162384e-10,"The method _start_subprocess is likely to survive because it encapsulates a specific functionality of starting a subprocess for a reflex app, which is a common requirement in applications that need to manage separate backend and frontend processes. The method is well-structured, uses utility functions for handling ports, and manages environment settings, indicating it is part of a larger, well-maintained codebase. Additionally, the use of subprocesses is a standard approach in many applications for process management, suggesting that this method serves a necessary and ongoing purpose."
survived,"    def is_internal_url(self, url):
        """"""Check if URL is internal to our domain.""""""
        parsed = urlparse(url)
        return parsed.netloc == self.domain or parsed.netloc == ''
",scripts/check_dead_links.py,DeadLinkChecker,1,6.69158608681505e-10,"The method 'is_internal_url' is a utility function that checks if a given URL is internal to a specific domain. This is a common requirement in web applications to differentiate between internal and external links. The method is simple, clear, and performs a specific task that is likely to be reused in various parts of a codebase dealing with URLs. Therefore, it is likely to be retained as it provides useful functionality."
survived,"def test_openai_require() -> None:
    """"""Test that openai.require raises ModuleNotFoundError.""""""
    model = openai(""gpt-4"")
    messages = [ChatMessage(role=""user"", content=""Test prompt"")]
    config = ChatModelConfig()
    with pytest.raises(ModuleNotFoundError):
        model(messages, config)
",tests/_ai/llm/_impl.py,,1,1.955568070542584e-08,"The method 'test_openai_require' is a test function designed to ensure that a specific error (ModuleNotFoundError) is raised under certain conditions. Test functions are generally not deleted unless they are redundant or incorrect. This function seems to be correctly testing a specific behavior of the 'openai' module, which is valuable for maintaining code reliability. Therefore, it is likely to be retained."
survived,"    def test_require_api_key_missing(self, mock_get_context: MagicMock) -> None:
        """"""Test _require_api_key with missing key.""""""
        mock_context = MagicMock()
        mock_context.marimo_config = {""ai"": {""anthropic"": {""api_key"": """"}}}
        mock_get_context.return_value = mock_context

        model = anthropic(""claude-3-opus-20240229"")
        with pytest.raises(ValueError):
            _ = model._require_api_key",tests/_ai/llm/_impl.py,TestAnthropic,1,7.73442280641062e-08,"The method `test_require_api_key_missing` is a unit test designed to verify the behavior of the `_require_api_key` method when the API key is missing. Unit tests are crucial for ensuring code reliability and are typically retained in the codebase to prevent future regressions. Therefore, it is unlikely that this method will be deleted."
survived,"    def test_is_file_path_with_valid_file(self, tmp_path: Path) -> None:
        # Create a temporary file
        test_file = tmp_path / ""test_file.txt""
        test_file.write_text(""test content"")
        
        # Test with valid file path
        assert is_file_path(None, None, str(test_file)) == str(test_file)
",tests/_cli/test_cli_validators.py,TestIsFilePath,1,6.825604231969389e-08,"The method 'test_is_file_path_with_valid_file' is a unit test function that verifies the behavior of the 'is_file_path' function when provided with a valid file path. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with file operations. This test uses a temporary file to avoid side effects and ensures that the 'is_file_path' function correctly identifies and returns the file path. Given its role in maintaining code quality and its use of best practices (like using 'tmp_path' for temporary files), this method is likely to be retained in the codebase."
deleted,"    def test_is_sensitive_error(self) -> None:
        # These errors are not sensitive
        assert not is_sensitive_error(MarimoAncestorPreventedError(
            msg="""", raising_cell=""cell1"", blamed_cell=None
        ))
        assert not is_sensitive_error(MarimoAncestorStoppedError(
            msg="""", raising_cell=""cell1""
        ))
        assert not is_sensitive_error(MarimoInternalError(error_id=""""))

        # These errors are sensitive
        assert is_sensitive_error(MarimoExceptionRaisedError(
            msg="""", exception_type="""", raising_cell=None
        ))
        assert is_sensitive_error(MarimoSyntaxError(msg=""""))
        assert is_sensitive_error(UnknownError(msg=""""))",tests/_messaging/test_errors.py,TestErrorUtilityFunctions,1,1.1032560311263802e-09,"The method `test_is_sensitive_error` is a unit test function that checks the behavior of the `is_sensitive_error` function. It verifies that certain error types are correctly identified as sensitive or not. Unit tests are crucial for ensuring code reliability and correctness, especially in error handling. Therefore, this method is likely to be retained as it serves an important role in maintaining the quality of the codebase."
survived,"    def test_write_console_output(self) -> None:
        # Test writing console output to stream
        stream = MockStream()
        _write_console_output(
            stream,
            CellChannel.STDOUT,
            ""cell1"",
            ""Hello"",
            ""text/plain"",
        )

        assert len(stream.messages) == 1
        assert stream.messages[0][0] == ""cell-op""  # op
        assert stream.messages[0][1][""cell_id""] == ""cell1""
        assert stream.messages[0][1][""console""][""channel""] == ""stdout""
        assert stream.messages[0][1][""console""][""mimetype""] == ""text/plain""
        assert stream.messages[0][1][""console""][""data""] == ""Hello""
",tests/_messaging/test_console_output_worker.py,TestConsoleOutputWorker,1,3.927863699585036e-07,"The method `test_write_console_output` is a unit test designed to verify the functionality of the `_write_console_output` function. It uses a mock stream to simulate the behavior of a real stream and checks if the output is correctly formatted and stored in the stream. This kind of test is crucial for ensuring that the function behaves as expected, especially in a larger system where console output needs to be captured and processed. Since testing is a fundamental part of software development to ensure code reliability and correctness, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly changed."
survived,"    def write(self, op: str, data: dict) -> None:
        self.messages.append((op, data))
",tests/_messaging/test_print_override.py,MockStream,1,8.592166611791576e-10,"The method 'write' is a simple utility function that appends a tuple containing an operation and data to a list called 'messages'. This kind of method is often used for logging or queuing operations and is generally useful in various contexts. It is unlikely to be deleted unless the entire logging or message handling mechanism is refactored or removed. Therefore, it is more likely to survive."
deleted,"    def test_run_id_context_manager(self) -> None:
        # Test that run_id_context sets and unsets the run ID
        with run_id_context() as ctx:
            # Run ID should be set within the context
            run_id = RUN_ID_CTX.get()
            assert run_id is not None
            assert isinstance(run_id, str)

            # Should be a valid UUID
            uuid_obj = uuid.UUID(run_id)
            assert str(uuid_obj) == run_id

        # Run ID should be unset outside the context
        with pytest.raises(LookupError):
            RUN_ID_CTX.get()
",tests/_messaging/test_context.py,TestRunIDContext,1,1.3440409770490404e-08,"The method 'test_run_id_context_manager' is a unit test designed to verify the functionality of a context manager that manages a run ID. It checks that the run ID is correctly set and unset within the context, and that it is a valid UUID. This is a typical and necessary test to ensure the reliability and correctness of the context manager's behavior. Since it serves a clear purpose in testing the functionality of the code, it is likely to be retained."
survived,"    def test_buffered_writer_multiple_messages(self) -> None:
        # Test buffered writer with multiple messages
        stream = MockStream()
        msg_queue: deque[Optional[ConsoleMsg]] = deque()
        cv = threading.Condition()

        # Start the buffered writer in a separate thread
        thread = threading.Thread(
            target=buffered_writer, args=(msg_queue, stream, cv)
        )
        thread.daemon = True
        thread.start()

        try:
            # Add multiple messages to the queue
            with cv:
                msg_queue.append(
                    ConsoleMsg(
                        stream=CellChannel.STDOUT,
                        cell_id=""cell1"",
                        data=""Hello"",
                        mimetype=""text/plain"",
                    )
                )
                msg_queue.append(
                    ConsoleMsg(
                        stream=CellChannel.STDOUT,
                        cell_id=""cell1"",
                        data="" World"",
                        mimetype=""text/plain"",
                    )
                )
                msg_queue.append(
                    ConsoleMsg(
                        stream=CellChannel.STDERR,
                        cell_id=""cell1"",
                        data=""Error"",
                        mimetype=""text/plain"",
                    )
                )
                cv.notify()

            # Wait for the timeout to expire and the messages to be written
            time.sleep(TIMEOUT_S * 2)

            # Check that the messages were written to the stream
            assert len(stream.messages) == 2  # Merged stdout messages + stderr

            # First message should be the merged stdout messages
            assert stream.messages[0][1][""console""][""channel""] == ""stdout""
            assert stream.messages[0][1][""console""][""data""] == ""Hello World""

            # Second message should be the stderr message
            assert stream.messages[1][1][""console""][""channel""] == ""stderr""
            assert stream.messages[1][1][""console""][""data""] == ""Error""

        finally:
            # Signal the writer to terminate
            with cv:
                msg_queue.append(None)
                cv.notify()
            thread.join(timeout=1.0)",tests/_messaging/test_console_output_worker.py,TestConsoleOutputWorker,1,1.1861120010657661e-08,"The method is a unit test for a specific functionality, which is to test the behavior of a buffered writer handling multiple messages. Such tests are crucial for ensuring the reliability and correctness of the code, especially in multi-threaded environments. Deleting this test would reduce the test coverage and potentially allow bugs to go unnoticed. Therefore, it is likely to be retained."
survived,"    def test_print_override_with_multiple_args(self) -> None:
        # Test print_override with multiple arguments
        thread_id = threading.get_ident()
        THREADS.add(thread_id)

        try:
            stream = MockStream()

            # Create a mock context
            context = MagicMock(spec=RuntimeContext)
            context.stream = stream
            context.execution_context = MagicMock(spec=ExecutionContext)
            context.execution_context.cell_id = ""cell1""

            with patch(""marimo._messaging.print_override._original_print"") as mock_print:
                with patch(
                    ""marimo._messaging.print_override.get_context"",
                    return_value=context,
                ):
                    print_override(""Hello"", 123, True, None)

                    # Original print should not be called
                    mock_print.assert_not_called()

                    # Message should be sent to the stream with all args converted to strings
                    assert len(stream.messages) == 1
                    assert stream.messages[0][1][""console""][""data""] == ""Hello 123 True None\n""
        finally:
            # Clean up
            if thread_id in THREADS:
                THREADS.remove(thread_id)",tests/_messaging/test_print_override.py,TestPrintOverride,1,2.5109990926928157e-08,"The method `test_print_override_with_multiple_args` is a unit test designed to verify the behavior of the `print_override` function when it is called with multiple arguments. It uses mocking to simulate the environment and checks that the original print function is not called, and that the output is correctly formatted and sent to a mock stream. This is a typical and necessary test to ensure the functionality of the `print_override` function, especially in a complex system where print behavior is overridden. Therefore, it is unlikely to be deleted as it serves a crucial role in maintaining code quality and correctness."
survived,"def test_colorized_url() -> None:
    """"""Test the _colorized_url function.""""""
    # Test with a simple URL
    with patch(""marimo._server.print.bold"") as mock_bold:
        mock_bold.return_value = ""BOLD_URL""
        result = _colorized_url(""http://localhost:8000"")
        mock_bold.assert_called_once_with(""http://localhost:8000"")
        assert result == ""BOLD_URL""
    
    # Test with a URL with a path
    with patch(""marimo._server.print.bold"") as mock_bold:
        mock_bold.return_value = ""BOLD_URL""
        result = _colorized_url(""http://localhost:8000/path"")
        mock_bold.assert_called_once_with(""http://localhost:8000/path"")
        assert result == ""BOLD_URL""
    
    # Test with a URL with a query string
    with patch(""marimo._server.print.bold"") as mock_bold:
        mock_bold.return_value = ""BOLD_URL""
        with patch(""marimo._server.print.muted"") as mock_muted:
            mock_muted.return_value = ""MUTED_QUERY""
            result = _colorized_url(""http://localhost:8000/path?query=value"")
            # The implementation separates the query part and applies muted() to it
            mock_bold.assert_called_once_with(""http://localhost:8000/pathMUTED_QUERY"")
            assert result == ""BOLD_URL""
",tests/_server/test_print.py,,1,5.715002851580502e-07,"The method `test_colorized_url` is a unit test function that tests the behavior of the `_colorized_url` function. It uses mocking to simulate the behavior of the `bold` and `muted` methods from the `marimo._server.print` module. The test cases cover different scenarios of URL formatting, ensuring that the `_colorized_url` function correctly applies the `bold` and `muted` styles to different parts of the URL. This is a typical and necessary part of software testing to ensure code reliability and correctness. Therefore, the method is likely to be retained as it serves an important role in verifying the functionality of the code."
survived,"def test_utf8() -> None:
    """"""Test the _utf8 function.""""""
    # Test with UTF8 supported
    with patch(""marimo._server.print.UTF8_SUPPORTED"", True):
        assert _utf8(""ðŸŒŠðŸƒ"") == ""ðŸŒŠðŸƒ""
    
    # Test with UTF8 not supported
    with patch(""marimo._server.print.UTF8_SUPPORTED"", False):
        assert _utf8(""ðŸŒŠðŸƒ"") == """"
",tests/_server/test_print.py,,1,9.237449576640118e-09,"The method 'test_utf8' is a unit test function designed to test the behavior of the '_utf8' function under different conditions. It uses mocking to simulate different states of UTF8 support and checks if the function returns the expected results. Unit tests are crucial for ensuring code reliability and are generally not deleted unless they are redundant or replaced by more comprehensive tests. Since this test seems to be directly testing a specific functionality, it is likely to be retained."
survived,"    async def make_request(self, endpoint: str, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """"""Make a request to the Uniswap API.""""""
        url = f""{self.base_url}/{endpoint}""
        
        headers = {
            ""Content-Type"": ""application/json"",
            ""x-api-key"": self.api_key
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.post(url, json=parameters, headers=headers) as response:
                if not response.ok:
                    raise Exception(f""Failed to fetch {endpoint}: {await response.text()}"")
                return await response.json()
",python/src/plugins/uniswap/goat_plugins/uniswap/service.py,UniswapService,1,5.905303995456778e-10,"The method 'make_request' is likely to survive because it is a well-structured asynchronous function that performs a common task of making HTTP requests to an API. It uses the aiohttp library, which is suitable for asynchronous operations in Python, and handles errors by raising exceptions when the response is not successful. This method is useful for interacting with APIs, such as the Uniswap API mentioned in the docstring, and is likely to be a necessary part of any application that requires such functionality."
survived,"    async def get_quote(self, wallet_client: EVMWalletClient, parameters: dict):
        """"""Get a quote for token swap.""""""
        try:
            chain_id = wallet_client.get_chain()[""id""]
            return await self.make_request(""quote"", {
                **parameters,
                ""tokenInChainId"": chain_id,
                ""tokenOutChainId"": parameters.get(""tokenOutChainId"", chain_id),
                ""swapper"": wallet_client.get_address()
            })
        except Exception as error:
            raise Exception(f""Failed to get quote: {error}"")
",python/src/plugins/uniswap/goat_plugins/uniswap/service.py,UniswapService,1,5.211412485172657e-10,"The method 'get_quote' is likely to survive because it is a well-defined asynchronous function that serves a specific purpose: obtaining a quote for a token swap. It handles exceptions gracefully by catching them and raising a descriptive error message, which is a good practice in error handling. Additionally, it uses parameters and interacts with a wallet client, indicating it is part of a larger system that likely relies on this functionality. Unless there are changes in the system's requirements or architecture that render this method obsolete, it is likely to be retained."
survived,"    async def swap_tokens(self, wallet_client: EVMWalletClient, parameters: dict):
        """"""Execute a token swap on Uniswap.""""""
        try:
            quote = await self.get_quote(wallet_client, parameters)
            
            response = await self.make_request(""swap"", {
                ""quote"": quote[""quote""]
            })
            
            swap = response[""swap""]
            transaction = await wallet_client.send_transaction({
                ""to"": swap[""to""],
                ""value"": swap[""value""],
                ""data"": swap[""data""]
            })

            return {
                ""txHash"": transaction[""hash""]
            }
        except Exception as error:
            raise Exception(f""Failed to execute swap: {error}"")",python/src/plugins/uniswap/goat_plugins/uniswap/service.py,UniswapService,1,5.211412485172657e-10,"The method 'swap_tokens' is likely to survive because it performs a critical function of executing token swaps on Uniswap, which is a common and essential operation in decentralized finance (DeFi) applications. The method is well-structured, using asynchronous calls to handle potentially time-consuming operations like getting a quote and sending a transaction. It also includes error handling to manage exceptions, which is important for robustness in financial transactions. These factors suggest that the method is useful and well-implemented, making it unlikely to be deleted."
survived,"def test_url_encoding_email(custodial_api, test_email):
    """"""Test URL parameter encoding with email.""""""
    encoded = quote(test_email)
    with pytest.raises(Exception) as exc:
        custodial_api.get_wallet(f""email:{encoded}:solana-custodial-wallet"")
    # Should raise not found error, but URL should be properly encoded
    assert encoded in str(exc.value)
    assert "":"" not in str(exc.value).replace(""email:"", """").replace("":solana-custodial-wallet"", """")
",python/src/wallets/crossmint/tests/test_api_client.py,,1,1.1032560311263802e-09,"The method 'test_url_encoding_email' is a test function that checks the URL encoding of an email parameter when interacting with an API. It uses assertions to ensure that the email is properly encoded and that an exception is raised when the API call is made. This is a typical use case in testing to verify that the system behaves as expected when given certain inputs. Since it serves a clear purpose in testing the functionality of URL encoding and error handling, it is likely to be retained in the codebase."
survived,"def test_phone():
    """"""Fixture providing test phone for wallet creation.""""""
    return ""+1234567890""
",python/src/wallets/crossmint/tests/conftest.py,,1,9.736200303530205e-10,"The method `test_phone` is a simple utility function that returns a hardcoded phone number. It is likely used as a fixture in testing environments to provide a consistent phone number for tests related to wallet creation or similar functionalities. Such utility functions are common in test suites to ensure consistency and repeatability of tests. Since it serves a specific purpose in the testing framework, it is unlikely to be deleted unless the testing strategy changes significantly or the phone number needs to be dynamically generated. Therefore, the method will likely survive."
survived,"def test_smart_wallet_api_key(smart_api):
    """"""Test smart wallet API key configuration.""""""
    headers = smart_api._request(""/wallets"", method=""GET"").request.headers
    assert headers[""x-api-key""] == os.environ[""CROSSMINT_STAGING_API_KEY_SMART""]
",python/src/wallets/crossmint/tests/test_api_client.py,,1,3.653482080241728e-08,"The method 'test_smart_wallet_api_key' is a test function that checks if the API key used in the headers of a request matches the expected environment variable. This is a common practice in testing to ensure that the correct API key is being used, especially in environments where security and configuration are important. The method is straightforward, serves a clear purpose, and is likely part of a larger suite of tests. Therefore, it is unlikely to be deleted as it provides value in verifying the correct configuration of the API key."
survived,"def test_smart_wallet_transaction(smart_api, test_wallet_options, test_evm_transaction, test_keypair):
    """"""Test transaction sending with smart wallet.""""""
    # Create wallet and client
    wallet = smart_api.create_smart_wallet()
    client = SmartWalletClient(
        wallet[""address""],
        smart_api,
        test_wallet_options[""chain""],
        test_keypair,
        test_wallet_options[""provider""],
        test_wallet_options[""options""][""ensProvider""]
    )
    
    # Send transaction
    tx = client.send_transaction(test_evm_transaction)
    assert tx[""status""] in [""success"", ""pending""]
    if tx[""status""] == ""success"":
        assert tx[""hash""].startswith(""0x"")
",python/src/wallets/crossmint/tests/test_smart_wallet.py,,1,4.6911638017642294e-08,"The method 'test_smart_wallet_transaction' is a test function that verifies the functionality of sending a transaction using a smart wallet. It is likely part of a test suite for a blockchain or cryptocurrency application. Test functions are crucial for ensuring code reliability and correctness, especially in financial applications where transactions must be handled accurately. The method includes assertions to check the transaction status and hash format, which are essential checks in a testing context. Therefore, it is unlikely to be deleted as it serves an important role in maintaining code quality."
survived,"def compare_signature_responses(py_response: Dict[str, Any], ts_response: Dict[str, Any]) -> None:
    """"""Compare signature responses between implementations.
    
    Args:
        py_response: Response from Python implementation
        ts_response: Response from TypeScript implementation
        
    Raises:
        AssertionError: If responses don't match
    """"""
    assert py_response[""signature""] == ts_response[""signature""], ""Signatures don't match""
    
    # Compare optional fields if present
    if ""status"" in py_response or ""status"" in ts_response:
        assert py_response.get(""status"") == ts_response.get(""status""), ""Signature status doesn't match""
",python/src/wallets/crossmint/tests/utils/helpers.py,,1,5.60279640614594e-09,"The method is well-defined and serves a clear purpose: it compares the 'signature' and 'status' fields of two response dictionaries, one from a Python implementation and one from a TypeScript implementation. This is a common requirement in systems where multiple implementations need to be verified for consistency. The method includes error handling through assertions, which is a standard practice for such comparison functions. There is no indication that this functionality is obsolete or redundant, so it is likely to be retained."
survived,"    def get_json_schema(self):
        return get_generic_json_schema()
",airbyte-integrations/connectors/source-box-data-extract/source_box_data_extract/source.py,StreamAIExtractFolder,0,0.9999417087232136,"The method `get_json_schema` is a simple wrapper around the function `get_generic_json_schema`. If `get_generic_json_schema` is a stable and widely used function, this method might be retained for convenience, especially if it's part of a larger class that benefits from having a consistent interface. However, if the method doesn't add any additional functionality or abstraction, it could be considered redundant and might be removed to simplify the codebase. Without more context, it's difficult to definitively predict its fate, but given the trend towards cleaner and more efficient code, it might be more likely to be deleted."
survived,"    def streams(self, config: Mapping[str, Any]) -> List[Stream]:
        """"""
        :param config: A Mapping of the user input configuration as defined in the connector spec.
        """"""
        box_client = get_box_ccg_client(config)
        box_folder_text_representation_stream = StreamTextRepresentationFolder(
            box_client, config[""box_folder_id""], is_recursive=config.get(""is_recursive"", False)
        )

        box_folder_ask_ai_stream = StreamAIAskFolder(
            box_client, config[""box_folder_id""], config[""ask_ai_prompt""], is_recursive=config.get(""is_recursive"", False)
        )

        box_folder_extract_ai_stream = StreamAIExtractFolder(
            box_client, config[""box_folder_id""], config[""extract_ai_prompt""], is_recursive=config.get(""is_recursive"", False)
        )

        box_folder_extract_structured_ai_stream = StreamAIExtractStructuredFolder(
            client=box_client,
            folder_id=config[""box_folder_id""],
            fields_json_str=config[""extract_structured_ai_fields""],
            is_recursive=config.get(""is_recursive"", False),
        )

        return [
            box_folder_text_representation_stream,
            box_folder_ask_ai_stream,
            box_folder_extract_ai_stream,
            box_folder_extract_structured_ai_stream,
        ]
",airbyte-integrations/connectors/source-box-data-extract/source_box_data_extract/source.py,SourceBoxDataExtract,1,8.592166611791576e-10,"The method 'streams' is well-defined and serves a clear purpose of creating and returning a list of stream objects based on the provided configuration. It utilizes helper functions and classes to instantiate these streams, which suggests modular and maintainable code. There is no indication of redundancy or obsolescence in the method's functionality, and it appears to be a core part of the system's operation, likely used to handle different types of data streams from a Box client. Therefore, it is unlikely to be deleted."
survived,"    def read_records(
        self,
        sync_mode: SyncMode,
        cursor_field: Optional[List[str]] = None,
        stream_slice: Optional[Mapping[str, Any]] = None,
        stream_state: Optional[Mapping[str, Any]] = None,
    ) -> Iterable[StreamData]:
        logger.info(f""Asking AI {self.prompt} for all files in folder {self.folder_id} {'recursively' if self.is_recursive else ''}"")
        items = box_folder_ai_ask(self.client, self.folder_id, prompt=self.prompt, is_recursive=self.is_recursive)
        for item in items:
            airbyte_item: StreamData = item.file.to_dict()
            airbyte_item[""text_representation""] = item.text_representation
            logger.info(f""Reading file {item.file.id} - {item.file.name}"")
            yield airbyte_item
",airbyte-integrations/connectors/source-box-data-extract/source_box_data_extract/source.py,StreamAIAskFolder,1,2.646573631904765e-09,"The method 'read_records' is a core part of a data processing or ETL pipeline, as it is responsible for reading and yielding records from a data source. It uses a logger to provide information about the process, which is useful for debugging and monitoring. The method is also flexible, allowing for different sync modes, cursor fields, and stream states, which are common requirements in data integration tasks. These characteristics suggest that the method is well-designed for its purpose and is likely to be retained in the codebase."
survived,"def main():
    """"""Main function to parse arguments and run the research blog system.""""""
    parser = argparse.ArgumentParser(description=""Research and Blog Agent System"")
    parser.add_argument(""--topic"", ""-t"", type=str, required=True, 
                        help=""The topic for the blog post"")
    parser.add_argument(""--output"", ""-o"", type=str, default=None,
                        help=""Optional file path to save the markdown blog post"")
    
    args = parser.parse_args()
    
    # Ensure API key is available
    if not os.environ.get(""OPENAI_API_KEY""):
        console.print(Panel(""[bold red]Error: OPENAI_API_KEY environment variable not set[/bold red]""))
        sys.exit(1)
    
    try:
        # Create the blog post
        console.print(Panel(f""Creating a blog post about '{args.topic}'..."", title=""Status"", border_style=""blue""))
        blog_post = asyncio.run(create_research_blog(args.topic))
        
        # Display the blog post
        console.print(Panel(Markdown(blog_post), title=""Blog Post"", border_style=""green""))
        
        # Save to file if output path is provided
        if args.output:
            with open(args.output, ""w"") as f:
                f.write(blog_post)
            console.print(f""[green]Blog post saved to {args.output}[/green]"")
    
    except Exception as e:
        console.print(Panel(f""[bold red]Error: {str(e)}[/bold red]""))
        sys.exit(1)
",openai-agents-examples/13_research_blog_system.py,,1,2.5109990926928157e-08,"The method is a main function that serves as the entry point for a command-line application. It handles argument parsing, checks for necessary environment variables, and manages the flow of creating and saving a blog post. This is a typical structure for a CLI tool, and there is no indication that it is obsolete or redundant. It is likely to be maintained as it provides essential functionality for the application."
survived,"def create_account_agent() -> Agent:
    """"""
    Create an account management agent.
    
    Returns:
        An Agent instance specialized in account management.
    """"""
    instructions = """"""
    You are an account management specialist who can help customers with account-related issues.
    You can assist with questions about account creation, profile updates, security settings, and account recovery.
    Always prioritize account security and verify the customer's identity before making changes.
    Provide clear guidance on how customers can manage their account settings.
    """"""
    
    return Agent(
        name=""AccountManager"",
        instructions=instructions,
        model=""gpt-4o-mini"",
        handoff_description=""Use this agent for account management, profile updates, or security questions.""
    )
",openai-agents-examples/07_agent_with_handoffs.py,,1,1.522997951276035e-08,"The method 'create_account_agent' is well-defined and serves a clear purpose by creating an instance of an 'Agent' specialized in account management. It includes detailed instructions for the agent's role and responsibilities, which are crucial for maintaining security and providing customer support. The method is likely part of a larger system that requires such specialized agents, making it a valuable component. Therefore, it is unlikely to be deleted unless there is a significant change in the system's architecture or requirements."
survived,"def test_create_specialist_agents():
    """"""Test that specialist agents are created with the correct configuration.""""""
    billing_agent = create_billing_agent()
    technical_agent = create_technical_agent()
    account_agent = create_account_agent()
    
    assert billing_agent.name == ""BillingSpecialist""
    assert technical_agent.name == ""TechnicalSupport""
    assert account_agent.name == ""AccountManager""
    
    assert ""billing specialist"" in billing_agent.instructions.lower()
    assert ""technical support"" in technical_agent.instructions.lower()
    assert ""account management"" in account_agent.instructions.lower()
",openai-agents-examples/07_agent_with_handoffs.py,,1,6.348800075736417e-09,"The method 'test_create_specialist_agents' is a unit test designed to verify that the creation of specialist agents is functioning correctly. It checks that each agent is instantiated with the correct name and that their instructions contain the appropriate keywords. This is a fundamental part of ensuring the reliability and correctness of the system, especially if these agents play a critical role in the application's functionality. Unit tests are essential for maintaining code quality and preventing regressions, so this method is likely to be retained as part of the test suite."
survived,"def test_run_custom_tool_agent():
    """"""Test that the agent can use custom tools and produce a response.""""""
    import pytest
    
    # Skip this test if no API key is available
    if not os.environ.get(""OPENAI_API_KEY""):
        pytest.skip(""OPENAI_API_KEY not set"")
    
    # Run a test query that should use the currency conversion tool
    response = asyncio.run(run_custom_tool_agent(""Convert 50 USD to EUR""))
    
    # Verify we got a non-empty response that mentions the currencies
    assert response
    assert len(response) > 0
    assert ""USD"" in response
    assert ""EUR"" in response
",openai-agents-examples/06_agent_with_custom_tools.py,,1,1.8189616842444243e-09,"The method 'test_run_custom_tool_agent' is a test function that checks the functionality of a custom tool agent. It includes a check for an API key and uses assertions to verify the response. This is a typical structure for a test function in Python, especially when using pytest. Test functions are generally not deleted unless they are redundant or replaced by more comprehensive tests. Since this function is specific in its purpose and checks for a particular feature (currency conversion), it is likely to be useful for ensuring the reliability of the code. Therefore, it is likely to survive."
survived,"def test_run_function_tool_agent():
    """"""Test that the agent can use function tools and produce a response.""""""
    import pytest
    
    # Skip this test if no API key is available
    if not os.environ.get(""OPENAI_API_KEY""):
        pytest.skip(""OPENAI_API_KEY not set"")
    
    # Run a test query that should use the weather tool
    response = asyncio.run(run_function_tool_agent(""What's the weather in London?""))
    
    # Verify we got a non-empty response that mentions London
    assert response
    assert len(response) > 0
    assert ""London"" in response
",openai-agents-examples/05_agent_with_function_tools.py,,1,2.646573631904765e-09,"The method 'test_run_function_tool_agent' is a test function designed to verify the functionality of an agent using function tools, specifically checking if it can handle a weather query. It includes a conditional skip if the necessary API key is not set, which is a common practice in testing to avoid failures due to missing configurations. The test checks for a non-empty response that includes the keyword 'London', which is a reasonable assertion for the given query. Since this test is well-structured, serves a clear purpose, and includes necessary checks, it is likely to be maintained in the codebase."
survived,"def main():
    """"""Main function to parse arguments and run the content creation system.""""""
    parser = argparse.ArgumentParser(description=""Agent Orchestration Example"")
    parser.add_argument(""--prompt"", ""-p"", type=str, required=True, 
                        help=""The content request to process"")
    
    args = parser.parse_args()
    
    # Ensure API key is available
    if not os.environ.get(""OPENAI_API_KEY""):
        console.print(Panel(""[bold red]Error: OPENAI_API_KEY environment variable not set[/bold red]""))
        sys.exit(1)
    
    try:
        # Run the content creation system and get the final content
        console.print(Panel(""Starting content creation process..."", title=""Status"", border_style=""blue""))
        content = asyncio.run(orchestrate_content_creation(args.prompt))
        
        # Display the final content
        console.print(Panel(content, title=""Final Content"", border_style=""green""))
    
    except Exception as e:
        console.print(Panel(f""[bold red]Error: {str(e)}[/bold red]""))
        sys.exit(1)
",openai-agents-examples/11_agent_orchestration.py,,1,7.194132978569833e-09,"The method 'main()' is a standard entry point for Python scripts that handle command-line arguments. It includes essential functionality such as argument parsing, environment variable checking, and error handling. These are common and necessary features for scripts that interact with external APIs or systems. The method is well-structured and serves a clear purpose, making it unlikely to be deleted unless the entire script is refactored or its functionality is no longer needed."
survived,"def convert_currency(params: CurrencyConversionInput) -> str:
    """"""
    Convert an amount from one currency to another.
    
    Args:
        params: The currency conversion parameters
        
    Returns:
        A string containing the conversion result
    """"""
    # This is a mock implementation - in a real application, you would call a currency API
    exchange_rates = {
        ""USD"": {""EUR"": 0.92, ""GBP"": 0.79, ""JPY"": 149.50},
        ""EUR"": {""USD"": 1.09, ""GBP"": 0.86, ""JPY"": 162.50},
        ""GBP"": {""USD"": 1.27, ""EUR"": 1.16, ""JPY"": 189.20},
        ""JPY"": {""USD"": 0.0067, ""EUR"": 0.0062, ""GBP"": 0.0053},
    }
    
    from_curr = params.from_currency.upper()
    to_curr = params.to_currency.upper()
    
    # Check if currencies are supported
    if from_curr not in exchange_rates:
        return f""Sorry, {from_curr} is not a supported currency.""
    
    if to_curr not in exchange_rates[from_curr] and from_curr != to_curr:
        return f""Sorry, conversion from {from_curr} to {to_curr} is not supported.""
    
    # If same currency, return the amount
    if from_curr == to_curr:
        return f""{params.amount} {from_curr} is equal to {params.amount} {to_curr}.""
    
    # Calculate converted amount
    converted_amount = params.amount * exchange_rates[from_curr][to_curr]
    
    return f""{params.amount} {from_curr} is equal to {converted_amount:.2f} {to_curr}.""
",openai-agents-examples/06_agent_with_custom_tools.py,,1,1.522997951276035e-08,"The method 'convert_currency' is a useful utility function for converting currency amounts based on predefined exchange rates. It handles various scenarios such as unsupported currencies and same currency conversion, making it robust for basic currency conversion tasks. Although it uses mock data, the structure allows for easy integration with real currency APIs. Such functionality is commonly needed in applications dealing with international transactions or financial data, suggesting its continued relevance and utility."
survived,"async def run_custom_tool_agent(prompt: str) -> str:
    """"""
    Run the financial assistant agent with the given prompt.
    
    Args:
        prompt: The user's query or prompt
        
    Returns:
        The agent's response as a string
    """"""
    # Create the agent with custom tools
    agent = create_financial_assistant()
    
    # Run the agent with the prompt
    result = await Runner.run(agent, prompt)
    
    # Return the response
    return result.final_output
",openai-agents-examples/06_agent_with_custom_tools.py,,1,1.0261879630648829e-10,"The method 'run_custom_tool_agent' is likely to survive because it is a well-defined asynchronous function that serves a clear purpose: running a financial assistant agent with a given prompt. It includes proper documentation, uses an asynchronous pattern which is common in modern Python applications, and leverages a custom tool (financial assistant) which suggests it is part of a larger, possibly modular system. Unless there are changes in the system architecture or the function becomes obsolete due to new requirements, it is likely to remain useful."
survived,"def create_financial_assistant() -> Agent:
    """"""
    Create a financial assistant agent with custom tools.
    
    Returns:
        An Agent instance with custom tools for financial assistance
    """"""
    instructions = """"""
    You are a helpful financial assistant that can provide information about 
    currency conversions and stock prices.
    Use the tools available to you to provide accurate financial information when asked.
    If you don't have a tool for the specific request, acknowledge the limitations
    and provide the best information you can.
    """"""
    
    # Create custom tools
    currency_tool = Tool(
        name=""convert_currency"",
        description=""Convert an amount from one currency to another"",
        input_type=CurrencyConversionInput,
        function=convert_currency
    )
    
    stock_tool = Tool(
        name=""get_stock_price"",
        description=""Get the current price of a stock"",
        input_type=StockPriceInput,
        function=get_stock_price
    )
    
    # Create the agent with custom tools
    return Agent(
        name=""FinancialAssistant"",
        instructions=instructions,
        model=""gpt-4o-mini"",
        tools=[currency_tool, stock_tool]
    )
",openai-agents-examples/06_agent_with_custom_tools.py,,1,1.6052280526088547e-09,"The method `create_financial_assistant` is well-defined and provides a clear and useful functionality by creating an agent with specific tools for financial assistance. It is likely to be used in applications where financial data processing is required, such as in fintech applications or personal finance management tools. The method is also flexible, allowing for the addition of more tools if needed. Given the increasing demand for financial technology solutions, this method is likely to be retained and used in various applications."
survived,"def create_billing_agent() -> Agent:
    """"""
    Create a billing specialist agent.
    
    Returns:
        An Agent instance specialized in billing issues.
    """"""
    instructions = """"""
    You are a billing specialist who can help customers with billing-related issues.
    You can assist with questions about invoices, payment methods, refunds, and subscription plans.
    Be helpful, clear, and concise in your responses.
    Always verify the customer's information before providing specific account details.
    """"""
    
    return Agent(
        name=""BillingSpecialist"",
        instructions=instructions,
        model=""gpt-4o-mini"",
        handoff_description=""Use this agent for questions about billing, payments, invoices, or subscription issues.""
    )
",openai-agents-examples/07_agent_with_handoffs.py,,1,2.0611536181902033e-09,"The method 'create_billing_agent' is well-defined and serves a clear purpose by creating an instance of an Agent specialized in handling billing issues. It includes detailed instructions for the agent's behavior and specifies the model to be used. This kind of functionality is essential in customer service applications, especially for handling specific queries like billing. Therefore, it is likely to be retained in the codebase."
survived,"def main():
    """"""Main function to parse arguments and run the customer support system.""""""
    parser = argparse.ArgumentParser(description=""Agent with Handoffs Example"")
    parser.add_argument(""--prompt"", ""-p"", type=str, required=True, 
                        help=""The customer inquiry to send to the support system"")
    
    args = parser.parse_args()
    
    # Ensure API key is available
    if not os.environ.get(""OPENAI_API_KEY""):
        console.print(Panel(""[bold red]Error: OPENAI_API_KEY environment variable not set[/bold red]""))
        sys.exit(1)
    
    try:
        # Run the customer support system and get response
        response = asyncio.run(run_customer_support_system(args.prompt))
        
        # Display the response
        console.print(Panel(response, title=""Customer Support Response"", border_style=""green""))
    
    except Exception as e:
        console.print(Panel(f""[bold red]Error: {str(e)}[/bold red]""))
        sys.exit(1)
",openai-agents-examples/07_agent_with_handoffs.py,,1,1.955568070542584e-08,"The method is a main function that serves as the entry point for a command-line application. It is responsible for parsing command-line arguments, checking for necessary environment variables, and handling exceptions. Such functions are typically essential for the operation of the application and are unlikely to be deleted unless the entire application is being deprecated or significantly refactored. Additionally, the function is well-structured and serves a clear purpose, which further supports its likelihood of survival."
survived,"    def filter(self, input_str: str) -> Optional[str]:
        """"""
        Filter the input string for potentially harmful content.
        
        Args:
            input_str: The input string to filter
            
        Returns:
            The filtered string if it passes, or None if it should be rejected
        """"""
        # Convert to lowercase for case-insensitive matching
        lower_input = input_str.lower()
        
        # Check for filtered terms
        for term in self.filtered_terms:
            if term in lower_input:
                return None  # Reject the input
        
        return input_str  # Accept the input
",openai-agents-examples/10_agent_with_guardrails.py,ContentModerationGuardrail,1,5.211412485172657e-10,"The method 'filter' is a straightforward implementation of a content filtering mechanism, which is a common requirement in many applications to prevent harmful or unwanted content. It is well-documented, with clear input and output specifications, and uses a simple case-insensitive check against a list of filtered terms. This functionality is essential for maintaining content standards and safety, making it likely to be retained in the codebase. Additionally, the method is flexible and can be easily extended or modified to include more complex filtering logic if needed."
survived,"def test_create_protected_agent():
    """"""Test that the protected agent is created with the correct configuration.""""""
    agent = create_protected_agent()
    assert agent.name == ""ProtectedAssistant""
    assert ""helpful assistant"" in agent.instructions.lower()
    assert agent.model == ""gpt-4o-mini""
    assert len(agent.input_guardrails) == 2
",openai-agents-examples/10_agent_with_guardrails.py,,1,1.1253518384332553e-07,"The method `test_create_protected_agent` is a unit test designed to verify the correct creation and configuration of a 'protected agent'. Unit tests are crucial for ensuring code reliability and correctness, especially in complex systems. This test checks specific attributes of the agent, such as its name, instructions, model, and input guardrails, which are likely important for the functionality of the system. Given the importance of testing in software development, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered."
survived,"async def test_chat_clear_messages():
    def mock_model(
        messages: List[ChatMessage], config: ChatModelConfig
    ) -> str:
        del messages, config
        return ""Mock response""

    chat = ui.chat(mock_model)
    chat._chat_history = [
        ChatMessage(role=""user"", content=""Hello""),
        ChatMessage(role=""assistant"", content=""Hi there!""),
    ]

    # Simulate clearing messages
    chat._value = []
    assert chat.value == []
    assert chat._chat_history == []
",tests/_plugins/ui/_impl/chat/test_chat.py,,1,7.194132978569833e-09,"The method `test_chat_clear_messages` is a test function designed to verify the functionality of clearing chat messages in a chat application. It uses a mock model to simulate chat interactions and then checks if the chat history is correctly cleared. Test functions are generally not deleted unless they are redundant or the functionality they test is removed. Since this test is straightforward and serves a clear purpose in ensuring the chat clearing functionality works as expected, it is likely to be retained."
survived,"async def test_get_request_endpoint():
    request_id = ""test-request-id""
    subdomain = ""abcd1234""
    
    request_data = {
        ""_id"": request_id,
        ""type"": ""http"",
        ""raw"": ""SGVsbG8gV29ybGQ="",  # base64 encoded ""Hello World""
        ""uid"": subdomain,
        ""method"": ""GET"",
        ""path"": ""/test"",
        ""headers"": {""host"": ""test.com""},
        ""date"": int(datetime.datetime.now(datetime.timezone.utc).timestamp()),
    }
    
    mock_redis.get.return_value = json.dumps(request_data)
    
    response = client.get(f""/api/get_request?id={request_id}&subdomain={subdomain}"")
    
    assert response.status_code == 200
    assert response.json() == request_data
    
    mock_redis.get.assert_called_with(f""request:{subdomain}:{request_id}"")
",backend/tests/test_endpoints.py,,1,1.8189616842444243e-09,"The method is a well-structured test function for an asynchronous GET request endpoint. It uses mock objects to simulate Redis interactions and checks the response from the client. The test is comprehensive, checking both the status code and the response data, and it verifies that the Redis get method is called with the correct parameters. This kind of test is essential for ensuring the reliability of API endpoints, and there is no indication that it is obsolete or incorrect. Therefore, it is likely to be retained."
survived,"    def register_listener(
        self,
        event_type: typing.Type[platform_events.Event],
        func: typing.Callable[[platform_events.Event, msadapter.MessagePlatformAdapter], typing.Awaitable[None]],
    ):
        """"""æ³¨å†Œäº‹ä»¶ç›‘å¬å™¨""""""
        pass
",pkg/platform/sources/webchat.py,WebChatAdapter,1,1.0677030767166749e-06,"The method `register_listener` is a placeholder for registering event listeners, which is a common and essential functionality in event-driven systems. The method signature indicates that it is designed to handle specific event types and associate them with callback functions, which is a fundamental part of handling events in a platform. Since it is a core part of the system's functionality, it is unlikely to be deleted unless the entire event handling mechanism is being refactored or removed, which is uncommon. Therefore, it is more likely to be implemented or further developed rather than deleted."
survived,"async def toggle_report_public_state(slug: str, api_key: str = Depends(verify_admin_api_key)) -> dict:
    try:
        from src.services.report_status import toggle_report_public_state
        is_public = toggle_report_public_state(slug)
        
        return {
            ""success"": True,
            ""is_public"": is_public
        }
    except ValueError as e:
        slogger.error(f""ValueError: {e}"", exc_info=True)
        raise HTTPException(status_code=404, detail=str(e)) from e
    except Exception as e:
        slogger.error(f""Exception: {e}"", exc_info=True)
        raise HTTPException(status_code=500, detail=""Internal server error"") from e",server/src/routers/admin_report.py,,1,2.646573631904765e-09,"The method 'toggle_report_public_state' is likely to survive because it is a well-structured asynchronous function that handles toggling the public state of a report. It includes error handling for specific exceptions (ValueError) and general exceptions, logging errors, and raising appropriate HTTP exceptions. This indicates good practice in error management and API response handling, which are crucial for maintaining robust and reliable code in production environments."
survived,"    def hide_results(self):
        """"""Hide search results.""""""
        self.show_results = False
",pcweb/components/docpage/navbar/typesense.py,TypesenseSearchState,1,2.0611536181902033e-09,"The method `hide_results` is a simple utility function that sets an attribute `show_results` to `False`. This kind of method is often used in UI or data display contexts to control the visibility of elements. Such methods are generally useful for managing state and are unlikely to be removed unless the entire feature or class is being deprecated. Since the method serves a clear purpose and is likely part of a larger functionality, it is more likely to be retained."
survived,"    def _run(self, api_method: str, instruction: str, **kwargs: Any) -> Any:
        """"""Execute a Stagehand command using the specified API method.
        
        Args:
            api_method: The Stagehand API to use ('act', 'extract', or 'observe')
            instruction: An atomic instruction for Stagehand to execute
            **kwargs: Additional keyword arguments passed to the Stagehand API
            
        Returns:
            The result from the Stagehand API call
            
        Raises:
            ValueError: If an invalid api_method is provided
            RuntimeError: If the Stagehand API call fails
        """"""
        try:
            # Initialize Stagehand with the OpenAI API key
            st = stagehand.Stagehand(api_key=self.api_key)
            
            # Call the appropriate Stagehand API based on the method
            if api_method == ""act"":
                return st.act(instruction)
            elif api_method == ""extract"":
                return st.extract(instruction)
            elif api_method == ""observe"":
                return st.observe(instruction)
            else:
                raise ValueError(f""Unknown api_method: {api_method}"")
                
        except Exception as e:
            raise RuntimeError(f""Stagehand API call failed: {str(e)}"")",crewai_tools/tools/stagehand_tool/stagehand_tool.py,StagehandTool,1,1.4166087846364157e-09,"The method '_run' is well-defined and serves a clear purpose of executing commands using the Stagehand API. It includes error handling for invalid API methods and exceptions during API calls, making it robust. The method is likely to be used frequently in applications that interact with the Stagehand API, as it abstracts the API call process and handles exceptions. Therefore, it is unlikely to be deleted."
survived,"def test_create_directory_with_existing_directory():
    """"""Test that create_directory=False works when directory already exists.""""""
    from pathlib import Path
    
    output_path = ""existing_test_dir/output.txt""
    
    resolved_path = Path(output_path).expanduser().resolve()
    resolved_dir = resolved_path.parent
    resolved_dir.mkdir(parents=True, exist_ok=True)
    
    task = Task(
        description=""Test task"",
        expected_output=""Test output"",
        output_file=output_path,
        create_directory=False,
    )
    
    task._save_file(""test content"")
    assert resolved_path.exists()
    
    if resolved_path.exists():
        resolved_path.unlink()
    if resolved_dir.exists():
        import shutil
        shutil.rmtree(resolved_dir)
",tests/task_test.py,,1,4.1399375473943306e-08,"The method is a test function that verifies the behavior of a task when attempting to create a directory that already exists. It is a useful test to ensure that the 'create_directory=False' option works as expected, preventing unnecessary directory creation. Such tests are crucial for maintaining code reliability and preventing bugs related to file system operations. Therefore, it is likely to be retained in the codebase."
survived,"def mark_notification_as_read(user_id: str, notification_id: str) -> bool:
    """"""
    Mark a notification as read.
    
    Args:
        user_id: The ID of the user
        notification_id: The ID of the notification
        
    Returns:
        True if the notification was marked as read, False otherwise
    """"""
    if user_id not in NOTIFICATION_STORE:
        return False
    
    for notification in NOTIFICATION_STORE[user_id]:
        if notification[""id""] == notification_id:
            notification[""is_read""] = True
            return True
    
    return False
",codebase-architectures/atomic-composable-architecture/modules/notifications.py,,1,5.905303995456778e-10,"The method `mark_notification_as_read` is a fundamental utility function for managing user notifications, which is a common feature in many applications. It provides a clear and necessary functionality to update the state of a notification, marking it as read. This is essential for user experience, allowing users to manage their notifications effectively. The method is straightforward, with a clear purpose and implementation, making it unlikely to be removed unless the entire notification system is overhauled or replaced. Therefore, it is likely to survive."
survived,"def login_user(username: str, password: str) -> Tuple[bool, Dict]:
    """"""
    Login a user and create an authentication token.
    
    Args:
        username: The username to authenticate
        password: The password to authenticate
        
    Returns:
        Tuple of (success, result) where result contains user data and token or error message
    """"""
    # Validate required fields
    missing_fields = validate_required_fields(
        {""username"": username, ""password"": password},
        [""username"", ""password""]
    )
    
    if missing_fields:
        return False, {""error"": f""Missing required fields: {', '.join(missing_fields)}""}
    
    # Authenticate the user
    user_data = authenticate(username, password)
    if not user_data:
        return False, {""error"": ""Invalid username or password""}
    
    # Create an authentication token
    token = create_token(user_data[""id""])
    
    return True, {
        ""user"": user_data,
        ""token"": token
    }
",codebase-architectures/atomic-composable-architecture/capabilities/user_management.py,,1,2.646573631904765e-09,"The method 'login_user' is a fundamental part of user authentication systems, which are critical for most applications that require user accounts. It handles essential tasks such as validating input, authenticating users, and generating tokens, which are necessary for maintaining secure sessions. Given its importance in managing user access and security, it is unlikely to be deleted unless there is a significant change in the authentication mechanism or architecture."
survived,"    def get_all(self, table_name):
        """"""Get all items from a table.""""""
        if table_name not in self.data:
            Logger.warning(self.logger, f""Table '{table_name}' not found"")
            return []
        
        items = list(self.data[table_name].values())
        Logger.debug(self.logger, f""Retrieved {len(items)} items from '{table_name}'"")
        return items
",codebase-architectures/layered-architecture/data/database.py,InMemoryDatabase,1,2.4616969512093895e-10,"The method 'get_all' is a utility function that retrieves all items from a specified table. It includes error handling to check if the table exists and logs appropriate messages. Such methods are commonly used in data management and retrieval tasks, making them essential for applications that interact with databases or data structures. Therefore, it is likely to be retained in the codebase."
survived,"def load_json_file(file_path):
    """"""Load data from a JSON file.""""""
    try:
        with open(file_path, 'r') as file:
            return json.load(file)
    except FileNotFoundError:
        raise ValueError(f""File not found: {file_path}"")
    except json.JSONDecodeError:
        raise ValueError(f""Invalid JSON format in file: {file_path}"")
",codebase-architectures/pipeline-architecture/shared/utilities.py,,1,6.69158608681505e-10,"The method 'load_json_file' is a utility function that loads data from a JSON file. It includes error handling for common issues such as file not found and invalid JSON format, which makes it robust and useful in many applications. Such utility functions are often reused across different projects and are unlikely to be deleted unless they are replaced by a more efficient or comprehensive library function. However, the current implementation is straightforward and serves its purpose well, so it is likely to survive."
survived,"    def get_final_result(self):
        """"""
        Get the result from the final stage of the pipeline.
        
        Returns:
            dict: Result from the final stage
        """"""
        if not self.stages:
            return None
        
        final_stage_name = self.stages[-1][""name""]
        if final_stage_name in self.results:
            return self.results[final_stage_name]
        
        return None
",codebase-architectures/pipeline-architecture/pipeline/pipeline_manager.py,PipelineManager,1,2.1724399346070676e-10,"The method `get_final_result` is likely to survive because it provides a clear and useful functionality within a class that manages a pipeline of stages. It retrieves the result of the final stage, which is a common requirement in processing pipelines. The method is well-documented, checks for edge cases (like an empty stages list), and returns results in a straightforward manner. These characteristics suggest it is a necessary part of the class's functionality."
survived,"    def update_product(product_id, name=None, price=None, category_id=None, description=None, sku=None):
        """"""Update a product.""""""
        try:
            product = ProductService.update_product(product_id, name, price, category_id, description, sku)
            if not product:
                return {
                    ""success"": False,
                    ""message"": f""Product with ID {product_id} not found""
                }
            return {
                ""success"": True,
                ""message"": ""Product updated successfully"",
                ""data"": product
            }
        except ValueError as e:
            Logger.warning(app_logger, f""Validation error in update_product: {str(e)}"")
            return {
                ""success"": False,
                ""message"": str(e)
            }
        except Exception as e:
            Logger.error(app_logger, f""Error in update_product: {str(e)}"", exc_info=True)
            return {
                ""success"": False,
                ""message"": ""An error occurred while updating the product""
            }
",codebase-architectures/layered-architecture/api/product_api.py,ProductAPI,1,3.581747929000289e-10,"The method 'update_product' is likely to survive because it is a well-structured function that handles updating a product with various optional parameters. It includes error handling for both specific (ValueError) and general exceptions, logging for debugging purposes, and returns informative messages based on the outcome of the operation. These are all good practices in software development, making the function robust and useful in a production environment."
survived,"def mark_all_notifications_as_read(user_id: str) -> int:
    """"""
    Mark all notifications for a user as read.
    
    Args:
        user_id: The ID of the user
        
    Returns:
        Number of notifications marked as read
    """"""
    if user_id not in NOTIFICATION_STORE:
        return 0
    
    count = 0
    for notification in NOTIFICATION_STORE[user_id]:
        if not notification[""is_read""]:
            notification[""is_read""] = True
            count += 1
    
    return count
",codebase-architectures/atomic-composable-architecture/modules/notifications.py,,1,6.69158608681505e-10,"The method 'mark_all_notifications_as_read' is a useful utility function that performs a common task in applications with notification systems. It efficiently marks all unread notifications for a given user as read and returns the count of notifications that were updated. This functionality is essential for improving user experience by allowing users to easily manage their notifications. The method is straightforward, well-documented, and serves a clear purpose, making it unlikely to be deleted unless there is a significant change in the application's notification handling logic."
survived,"def validate_email(email: str) -> bool:
    """"""
    Validate an email address format.
    
    Args:
        email: The email address to validate
        
    Returns:
        True if the email is valid, False otherwise
    """"""
    # Simple regex for email validation
    # In a real application, consider using a more comprehensive validation
    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
    return bool(re.match(pattern, email))
",codebase-architectures/atomic-composable-architecture/modules/validation.py,,1,9.931195248674785e-08,"The method 'validate_email' is a utility function that checks if an email address is in a valid format using a regular expression. This is a common requirement in many applications to ensure data integrity and user input validation. Although the regex used is simple and might not cover all edge cases, it is sufficient for basic validation purposes. Such utility functions are often retained in codebases because they provide essential functionality that is frequently needed across different parts of an application. Therefore, it is likely that this method will be retained and possibly improved upon rather than deleted."
survived,"    def delete_user(user_id):
        """"""Delete a user.""""""
        return db.delete(""users"", user_id)",codebase-architectures/vertical-slice-architecture/features/users/service.py,UserService,1,4.0586521248284276e-10,"The method 'delete_user' is a straightforward utility function that performs a specific task: deleting a user from a database. Such functions are typically essential in applications that manage user data, as they provide a necessary operation for maintaining and updating the database. Unless there is a significant change in the application's requirements or architecture that makes user deletion obsolete or handled differently, this method is likely to survive."
survived,"    def get_logger(name):
        """"""Get a logger instance for the given name.""""""
        return logging.getLogger(name)
",codebase-architectures/layered-architecture/utils/logger.py,Logger,1,4.1399375473943306e-08,"The method 'get_logger' is a simple utility function that wraps the standard logging library's 'getLogger' method. It provides a convenient way to obtain a logger instance by name, which is a common practice in Python applications for logging purposes. Such utility functions are often kept in codebases because they encapsulate standard library calls, making the code more readable and maintainable. Additionally, logging is a critical aspect of most applications for debugging and monitoring, so this method is likely to be retained."
survived,"    def prepare(self, processing_result):
        """"""
        Prepare the output stage with data from the processing stage.
        
        Args:
            processing_result: Result from the processing stage
        
        Returns:
            dict: Stage result with data and metadata
        """"""
        # Check if processing stage had errors
        if processing_result[""metadata""][""status""] in [""error"", ""skipped""]:
            self.metadata[""status""] = ""skipped""
            self.metadata[""errors""].append(""Processing stage had errors, output skipped"")
            return self._create_result()
        
        # Get data and metadata from processing stage
        self.data = processing_result[""data""]
        self.metadata[""input_metadata""] = processing_result[""metadata""][""input_metadata""]
        self.metadata[""processing_metadata""] = processing_result[""metadata""]
        
        # Get analysis if available
        if ""analysis"" in processing_result:
            self.analysis = processing_result[""analysis""]
        
        # Initialize output
        self.metadata[""status""] = ""preparing""
        self.metadata[""started_at""] = datetime.now().isoformat()
        
        return self._create_result()
",codebase-architectures/pipeline-architecture/pipeline/output_stage.py,OutputStage,1,2.0611536181902033e-09,"The method 'prepare' is well-structured and serves a clear purpose in the code. It handles different scenarios based on the status of the 'processing_result', updates metadata accordingly, and prepares the output for the next stage. The method is likely part of a larger workflow or pipeline, making it essential for the overall functionality. There are no apparent issues or redundancies that would warrant its deletion."
survived,"def delete_notification(user_id: str, notification_id: str) -> bool:
    """"""
    Delete a notification.
    
    Args:
        user_id: The ID of the user
        notification_id: The ID of the notification
        
    Returns:
        True if the notification was deleted, False otherwise
    """"""
    if user_id not in NOTIFICATION_STORE:
        return False
    
    for i, notification in enumerate(NOTIFICATION_STORE[user_id]):
        if notification[""id""] == notification_id:
            del NOTIFICATION_STORE[user_id][i]
            return True
    
    return False
",codebase-architectures/atomic-composable-architecture/modules/notifications.py,,1,1.1861120010657661e-08,"The method 'delete_notification' is a fundamental utility function for managing notifications in an application. It provides a clear and necessary functionality to remove a specific notification for a user, which is a common requirement in applications that handle user notifications. The method is straightforward, checks for the existence of the user and the notification, and performs the deletion if possible. This functionality is essential for maintaining a clean and manageable notification system, making it unlikely to be deleted."
survived,"def send_user_alert(user_id: str, message: str, level: str = ""info"", 
                   email: Optional[str] = None, phone: Optional[str] = None,
                   additional_data: Optional[Dict] = None) -> Tuple[bool, Dict]:
    """"""
    Send an alert to a user through multiple channels.
    
    Args:
        user_id: The ID of the user to alert
        message: The alert message
        level: Alert level (info, warning, error)
        email: Optional email address to send the alert to
        phone: Optional phone number to send the alert to
        additional_data: Additional data for the alert
        
    Returns:
        Tuple of (success, result) with notification details
    """"""
    # Validate required fields
    missing_fields = validate_required_fields(
        {""user_id"": user_id, ""message"": message},
        [""user_id"", ""message""]
    )
    
    if missing_fields:
        return False, {""error"": f""Missing required fields: {', '.join(missing_fields)}""}
    
    # Validate message length
    if not validate_string_length(message, min_length=1, max_length=500):
        return False, {""error"": ""Message must be between 1 and 500 characters""}
    
    # Validate level
    valid_levels = [""info"", ""warning"", ""error""]
    if level not in valid_levels:
        return False, {""error"": f""Level must be one of: {', '.join(valid_levels)}""}
    
    # Create the alert notification
    notification = create_alert(
        user_id=user_id,
        message=message,
        level=level,
        data=additional_data
    )
    
    # Send email if provided
    email_sent = False
    if email:
        if validate_email(email):
            subject = f""Alert: {level.capitalize()}""
            email_sent = send_email_notification(email, subject, message)
        else:
            return False, {""error"": ""Invalid email format""}
    
    # Send SMS if provided
    sms_sent = False
    if phone:
        sms_sent = send_sms_notification(phone, message)
    
    return True, {
        ""notification"": notification,
        ""channels"": {
            ""in_app"": True,
            ""email"": email_sent,
            ""sms"": sms_sent
        }
    }
",codebase-architectures/atomic-composable-architecture/capabilities/alerting.py,,1,4.363462233903899e-09,"The method 'send_user_alert' is well-structured and serves a clear purpose of sending alerts to users through multiple channels. It includes validation for required fields, message length, and alert level, which are essential for ensuring the method functions correctly. Additionally, it provides flexibility by allowing optional email and phone notifications, making it versatile for different use cases. The method also returns a detailed result indicating the success of the operation and the channels used, which is useful for debugging and logging purposes. Given these factors, the method is likely to be retained as it provides valuable functionality and is implemented with good practices."
survived,"    def format_as_detailed_report(self):
        """"""
        Format the data as a detailed report.
        
        Returns:
            dict: Stage result with data and metadata
        """"""
        if self.data is None:
            self.metadata[""status""] = ""error""
            self.metadata[""errors""].append(""No data to format"")
            return self._create_result()
        
        try:
            # Create detailed report
            report = {
                ""report_type"": ""detailed"",
                ""generated_at"": datetime.now().isoformat(),
                ""data_source"": self.metadata.get(""input_metadata"", {}).get(""source"", ""unknown""),
                ""record_count"": len(self.data) if isinstance(self.data, list) else 1,
                ""data"": self.data
            }
            
            # Add analysis if available
            if self.analysis:
                report[""analysis""] = self.analysis
            
            # Add processing information
            if ""processing_metadata"" in self.metadata:
                report[""processing_info""] = {
                    ""steps"": self.metadata[""processing_metadata""].get(""processing_steps"", []),
                    ""filters"": self.metadata[""processing_metadata""].get(""filters_applied"", []),
                    ""transformations"": self.metadata[""processing_metadata""].get(""transformations_applied"", []),
                    ""processing_time_seconds"": self.metadata[""processing_metadata""].get(""processing_time_seconds"")
                }
            
            # Store the detailed report
            self.detailed_report = report
            
            # Update metadata
            self.metadata[""output_formats""].append(""detailed_report"")
            
            return self._create_result()
        except Exception as e:
            self.metadata[""status""] = ""error""
            self.metadata[""errors""].append(f""Detailed report formatting error: {str(e)}"")
            return self._create_result()
",codebase-architectures/pipeline-architecture/pipeline/output_stage.py,OutputStage,1,2.0611536181902033e-09,"The method 'format_as_detailed_report' is well-structured and serves a clear purpose of formatting data into a detailed report. It includes error handling, updates metadata, and stores the report, which are all useful functionalities. The method is likely to be used in contexts where detailed reporting is necessary, and it seems to be integrated with other parts of the system (e.g., metadata management, error handling). These factors suggest that the method is valuable and likely to be retained."
survived,"    def update_user(user_id, user_data):
        """"""Update a user.""""""
        try:
            user = UserService.update_user(user_id, user_data)
            if not user:
                return {""error"": f""User with ID {user_id} not found""}
            return user
        except ValueError as e:
            return {""error"": str(e)}
",codebase-architectures/vertical-slice-architecture/features/users/api.py,UserAPI,1,7.582560422162384e-10,"The method 'update_user' is likely to survive because it performs a common and necessary operation of updating user information, which is a fundamental feature in many applications. It includes error handling for cases where the user is not found or when a ValueError occurs, making it robust and reliable. Additionally, the method returns meaningful error messages, which is a good practice for user feedback and debugging."
survived,"    def configure_processing(self, config):
        """"""
        Configure the processing stage.
        
        Args:
            config: Dictionary with processing configuration
        """"""
        self.processing_config = config
",codebase-architectures/pipeline-architecture/pipeline/pipeline_manager.py,DataProcessingPipeline,1,2.998960815863541e-09,"The method 'configure_processing' is a straightforward setter method that assigns a configuration dictionary to an instance variable. Such methods are common in object-oriented programming to encapsulate configuration settings and are generally useful for setting up or modifying the behavior of an object. There is no indication that this method is redundant or unnecessary, as it serves a clear purpose in configuring the processing stage of an object. Therefore, it is likely to be retained in the codebase."
survived,"    def update(self, table_name, item_id, item):
        """"""Update an item in a table.""""""
        if table_name not in self.data or item_id not in self.data[table_name]:
            Logger.warning(self.logger, f""Cannot update: Item with ID {item_id} not found in '{table_name}'"")
            return None
        
        # Ensure ID remains the same
        item[""id""] = item_id
        self.data[table_name][item_id] = item
        Logger.info(self.logger, f""Updated item with ID {item_id} in '{table_name}'"")
        return item
",codebase-architectures/layered-architecture/data/database.py,InMemoryDatabase,1,4.363462233903899e-09,"The method 'update' is a fundamental part of any data management system, as it allows for the modification of existing records. The method is well-structured, with checks to ensure the item exists before updating and logging for both successful and unsuccessful operations. These features are essential for maintaining data integrity and providing feedback to the user or developer. Therefore, it is unlikely that this method will be deleted."
survived,"    def send_system_alert(token: str, user_id: str, notification_type: str, 
                         data: Dict, email: Optional[str] = None) -> Dict:
        """"""
        Send a system notification to a user (admin function).
        
        Args:
            token: Authentication token (must be admin)
            user_id: The ID of the user to notify
            notification_type: The type of notification
            data: Data for the notification template
            email: Optional email address to send the notification to
            
        Returns:
            Response with success status and notification details or error message
        """"""
        # Validate token (in a real app, would check if user is admin)
        success, admin_data = validate_user_token(token)
        if not success:
            return {
                ""status"": ""error"",
                ""message"": ""Invalid or expired token"",
                ""data"": None
            }
        
        # Send system notification
        success, result = send_system_notification(
            user_id=user_id,
            notification_type=notification_type,
            data=data,
            email=email
        )
        
        if success:
            return {
                ""status"": ""success"",
                ""message"": ""System notification sent successfully"",
                ""data"": result
            }
        else:
            return {
                ""status"": ""error"",
                ""message"": result.get(""error"", ""Failed to send system notification""),
                ""data"": None
            }",codebase-architectures/atomic-composable-architecture/endpoints/alerts_api.py,AlertsAPI,1,5.905303995456778e-10,"The method 'send_system_alert' is likely to survive because it performs a critical function of sending system notifications to users, which is essential for maintaining communication and alerting users about important events or updates. The method is well-documented, handles authentication, and provides clear success and error responses, making it a robust and useful part of the system's functionality."
survived,"def main():
    """"""Run the application.""""""
    display_header(""Vertical Slice Architecture Example"")
    
    # Create users
    display_header(""Creating Users"")
    user1 = UserAPI.create_user(""johndoe"", ""john@example.com"", ""John Doe"")
    display_result(user1)
    
    user2 = UserAPI.create_user(""janedoe"", ""jane@example.com"", ""Jane Doe"")
    display_result(user2)
    
    # Try to create a user with an existing username
    duplicate_user = UserAPI.create_user(""johndoe"", ""another@example.com"")
    display_result(duplicate_user)
    
    # Get all users
    display_header(""All Users"")
    all_users = UserAPI.get_all_users()
    for user in all_users:
        display_result(user)
    
    # Create tasks
    display_header(""Creating Tasks"")
    task1 = TaskAPI.create_task(""Complete project"", ""Finish the architecture example"", user1[""id""])
    display_result(task1)
    
    task2 = TaskAPI.create_task(""Review code"", ""Check for bugs and improvements"", user2[""id""])
    display_result(task2)
    
    task3 = TaskAPI.create_task(""Write documentation"", ""Document the architecture"", user1[""id""])
    display_result(task3)
    
    # Get user tasks
    display_header(f""Tasks for {user1['name']}"")
    user1_tasks = TaskAPI.get_user_tasks(user1[""id""])
    for task in user1_tasks:
        display_result(task)
    
    # Update a task
    display_header(""Updating a Task"")
    updated_task = TaskAPI.update_task(task1[""id""], {""status"": ""completed""})
    display_result(updated_task)
    
    # Delete a task
    display_header(""Deleting a Task"")
    delete_result = TaskAPI.delete_task(task2[""id""])
    display_result(delete_result)
    
    # Get all remaining tasks
    display_header(""All Remaining Tasks"")
    all_tasks = TaskAPI.get_all_tasks()
    for task in all_tasks:
        display_result(task)
",codebase-architectures/vertical-slice-architecture/main.py,,1,1.444980317078884e-07,"The method 'main()' is a central part of the application, orchestrating the creation and management of users and tasks. It demonstrates the core functionality of the application, such as creating users, handling duplicate entries, managing tasks, and displaying results. This method is essential for running the application and showcasing its features, making it unlikely to be deleted unless the entire application is being refactored or replaced."
survived,"    def warning(logger, message):
        """"""Log a warning message.""""""
        logger.warning(message)
",codebase-architectures/layered-architecture/utils/logger.py,Logger,0,0.9999910602998366,"The method is a simple utility function that wraps a common logging operation. It doesn't add significant value beyond calling the logger's warning method directly. Such utility functions are often removed to reduce redundancy and encourage direct use of the logger's methods, which are more flexible and standard in logging practices."
survived,"    def mark_all_as_read(token: str) -> Dict:
        """"""
        Mark all alerts as read.
        
        Args:
            token: Authentication token
            
        Returns:
            Response with success status and count of alerts marked as read
        """"""
        # Validate token
        success, user_data = validate_user_token(token)
        if not success:
            return {
                ""status"": ""error"",
                ""message"": ""Invalid or expired token"",
                ""data"": None
            }
        
        # Mark all as read
        count = mark_all_alerts_as_read(user_data[""id""])
        
        return {
            ""status"": ""success"",
            ""message"": f""Marked {count} alerts as read"",
            ""data"": {""count"": count}
        }
",codebase-architectures/atomic-composable-architecture/endpoints/alerts_api.py,AlertsAPI,1,1.9171715133907573e-10,"The method 'mark_all_as_read' is likely to survive because it performs a useful function of marking all alerts as read for a user, which is a common feature in applications that handle notifications or alerts. The method includes token validation, which is essential for security, and provides a clear response structure indicating success or failure. These aspects make it a well-structured and necessary part of an application dealing with user alerts."
survived,"    def get_all_users():
        """"""Get all users.""""""
        return db.get_all(""users"")
",codebase-architectures/vertical-slice-architecture/features/users/service.py,UserService,1,2.646573631904765e-09,"The method `get_all_users` is a simple utility function that retrieves all users from a database. It is straightforward, performs a common operation, and is likely used in various parts of an application. Such utility functions are generally retained unless there is a significant change in the database access pattern or architecture, such as moving to a different database system or adopting a new ORM that changes how data is accessed. Without any indication of such changes, this method is likely to survive."
survived,"    def insert(self, collection_name, id, item):
        """"""Insert an item into a collection.""""""
        if collection_name not in self.data:
            self.create_collection(collection_name)
        self.data[collection_name][id] = item
        return id
",codebase-architectures/vertical-slice-architecture/shared/db.py,InMemoryDB,1,3.3982678079468468e-09,"The method 'insert' is a fundamental operation for managing data within a collection, which is a common requirement in many applications. It provides a way to add new items to a collection, ensuring that the collection exists before attempting to insert. This functionality is essential for maintaining and updating data structures, making it unlikely to be removed unless there is a significant change in the application's data handling strategy."
survived,"def get_user_alerts(user_id: str, unread_only: bool = False, 
                   level: Optional[str] = None) -> List[Dict]:
    """"""
    Get alerts for a user with optional filtering.
    
    Args:
        user_id: The ID of the user
        unread_only: Whether to return only unread alerts
        level: Optional filter by alert level
        
    Returns:
        List of alert notifications
    """"""
    # Get all notifications for the user
    notifications = get_user_notifications(user_id, unread_only)
    
    # Filter to only alert type notifications
    alerts = [n for n in notifications if n[""type""] == ""alert""]
    
    # Filter by level if specified
    if level:
        alerts = [a for a in alerts if a[""data""].get(""level"") == level]
    
    return alerts
",codebase-architectures/atomic-composable-architecture/capabilities/alerting.py,,1,3.160881453314576e-10,"The method `get_user_alerts` is well-defined and serves a clear purpose of retrieving user alerts with optional filters for unread status and alert level. It is likely to be useful in applications where users need to be notified of specific events or updates. The method is also flexible, allowing for different filtering options, which enhances its utility. There are no apparent issues with the logic or implementation that would necessitate its removal. Therefore, it is likely to be retained in the codebase."
survived,"    def update_product(product_id, name=None, price=None, category_id=None, description=None, sku=None):
        """"""Update a product.""""""
        try:
            # Get existing product
            product_data = db.get(""products"", product_id)
            if not product_data:
                Logger.warning(app_logger, f""Cannot update: Product not found: {product_id}"")
                return None
            
            # Validate price if provided
            if price is not None:
                try:
                    price = float(price)
                    if price < 0:
                        raise ValueError()
                except (ValueError, TypeError):
                    raise ValueError(""Price must be a positive number"")
            
            # Validate category if provided
            if category_id:
                category = db.get(""categories"", category_id)
                if not category:
                    raise ValueError(f""Category with ID {category_id} not found"")
            
            # Validate SKU if provided
            if sku and sku != product_data[""sku""]:
                existing_products = db.query(""products"", lambda p: p[""sku""] == sku and p[""id""] != product_id)
                if existing_products:
                    raise ValueError(f""Product with SKU '{sku}' already exists"")
            
            # Update fields
            if name:
                product_data[""name""] = name
            if price is not None:
                product_data[""price""] = price
            if category_id is not None:
                product_data[""category_id""] = category_id
            if description is not None:
                product_data[""description""] = description
            if sku is not None:
                product_data[""sku""] = sku
            
            # Update timestamp
            product_data[""updated_at""] = datetime.now().isoformat()
            
            # Save to database
            updated_product = db.update(""products"", product_id, product_data)
            Logger.info(app_logger, f""Updated product: {product_id}"")
            return updated_product
        except Exception as e:
            Logger.error(app_logger, f""Error updating product: {str(e)}"", exc_info=True)
            raise
",codebase-architectures/layered-architecture/services/product_service.py,ProductService,1,2.646573631904765e-09,"The method 'update_product' is a well-structured and essential function for updating product details in a database. It includes validation checks for price, category, and SKU, ensuring data integrity. Additionally, it handles exceptions and logs errors, which are crucial for maintaining robust applications. These characteristics make it a valuable part of any e-commerce or inventory management system, suggesting it will likely be retained."
survived,"    def get_user_tasks(user_id):
        """"""Get all tasks for a specific user.""""""
        return TaskService.get_user_tasks(user_id)
",codebase-architectures/vertical-slice-architecture/features/tasks/api.py,TaskAPI,0,0.9968273169336632,"The method `get_user_tasks` is a simple wrapper around the `TaskService.get_user_tasks` method. If the `TaskService` is a well-encapsulated service that handles all task-related operations, this method might be considered redundant. However, if this method is part of a larger class or module that aims to abstract away the details of interacting with the `TaskService`, it could be useful for maintaining a clean and consistent interface. Without additional context, such as whether this method is part of a larger pattern or if it adds any additional logic or error handling, it's difficult to definitively say if it will be deleted. However, given its current state as a direct pass-through, it leans towards being potentially redundant."
survived,"def validate_data(data: Dict[str, Any], schema: Dict[str, Dict[str, Any]]) -> Dict[str, List[str]]:
    """"""
    Validate data against a schema.
    
    Args:
        data: The data to validate
        schema: Validation schema defining field types and constraints
        
    Returns:
        Dictionary mapping field names to lists of validation error messages
    """"""
    errors: Dict[str, List[str]] = {}
    
    for field_name, field_schema in schema.items():
        field_type = field_schema.get(""type"")
        required = field_schema.get(""required"", False)
        
        # Check if required field is missing
        if required and (field_name not in data or data[field_name] is None):
            errors.setdefault(field_name, []).append(""Field is required"")
            continue
        
        # Skip validation for optional fields that are not present
        if field_name not in data or data[field_name] is None:
            continue
        
        value = data[field_name]
        
        # Type validation
        if field_type == ""string"" and not isinstance(value, str):
            errors.setdefault(field_name, []).append(""Must be a string"")
        elif field_type == ""number"" and not isinstance(value, (int, float)):
            errors.setdefault(field_name, []).append(""Must be a number"")
        elif field_type == ""integer"" and not isinstance(value, int):
            errors.setdefault(field_name, []).append(""Must be an integer"")
        elif field_type == ""boolean"" and not isinstance(value, bool):
            errors.setdefault(field_name, []).append(""Must be a boolean"")
        elif field_type == ""array"" and not isinstance(value, list):
            errors.setdefault(field_name, []).append(""Must be an array"")
        elif field_type == ""object"" and not isinstance(value, dict):
            errors.setdefault(field_name, []).append(""Must be an object"")
        
        # String-specific validations
        if field_type == ""string"" and isinstance(value, str):
            min_length = field_schema.get(""min_length"")
            max_length = field_schema.get(""max_length"")
            pattern = field_schema.get(""pattern"")
            
            if min_length is not None and len(value) < min_length:
                errors.setdefault(field_name, []).append(f""Must be at least {min_length} characters"")
            
            if max_length is not None and len(value) > max_length:
                errors.setdefault(field_name, []).append(f""Must be at most {max_length} characters"")
            
            if pattern is not None and not re.match(pattern, value):
                errors.setdefault(field_name, []).append(""Does not match required pattern"")
        
        # Number-specific validations
        if field_type in [""number"", ""integer""] and isinstance(value, (int, float)):
            minimum = field_schema.get(""minimum"")
            maximum = field_schema.get(""maximum"")
            
            if minimum is not None and value < minimum:
                errors.setdefault(field_name, []).append(f""Must be at least {minimum}"")
            
            if maximum is not None and value > maximum:
                errors.setdefault(field_name, []).append(f""Must be at most {maximum}"")
    
    return errors",codebase-architectures/atomic-composable-architecture/modules/validation.py,,1,5.905303995456778e-10,"The method 'validate_data' is a well-structured and useful utility function for validating data against a schema. It handles various data types, checks for required fields, and performs specific validations for strings and numbers. This kind of functionality is essential in many applications to ensure data integrity and correctness. The method is also well-documented, making it easy to understand and use. Given its utility and the fact that it doesn't have any apparent flaws or redundancies, it is likely to be retained in the codebase."
survived,"    def error(logger, message, exc_info=None):
        """"""Log an error message.""""""
        logger.error(message, exc_info=exc_info)
",codebase-architectures/layered-architecture/utils/logger.py,Logger,1,2.0611536181902033e-09,"The method is a simple utility function that wraps around a logger's error method to log error messages. It provides a clear and concise way to log errors with optional exception information. Such utility functions are common in codebases to standardize logging practices and improve code readability. There is no indication that this method is redundant or unnecessary, so it is likely to be retained."
survived,"    def add_stage(self, name: str, stage: PipelineStage) -> None:
        """"""
        Add a stage to the pipeline.
        
        Args:
            name: The name of the stage
            stage: The stage to add
        """"""
        self.stages[name] = stage
        self.stage_order.append(name)
        console.log(f""[pipeline] Added stage: {name}"")
",example-agent-codebase-arch/pipeline-architecture/pipeline_manager/pipeline_manager.py,Pipeline,1,1.4166087846364157e-09,"The method 'add_stage' is a fundamental part of managing a pipeline structure, allowing for dynamic addition of stages. This functionality is crucial for any system that relies on a sequence of operations or transformations, such as data processing or machine learning pipelines. The method is well-documented, indicating its importance and clarity of use. Additionally, the use of logging suggests that the method's operations are significant enough to warrant tracking, further supporting its necessity. Therefore, it is unlikely to be removed."
survived,"def normalize_path(path: str) -> str:
    """"""
    Normalize file paths to handle various formats (absolute, relative, Windows paths, etc.)

    Args:
        path: The path to normalize

    Returns:
        The normalized path
    """"""
    if not path:
        return path

    # Handle Windows backslash paths if provided
    path = path.replace(""\\"", os.sep)

    is_windows_path = False
    if os.name == ""nt"" and len(path) > 1 and path[1] == "":"":
        is_windows_path = True

    # Handle /repo/ paths from Claude (tool use convention)
    if path.startswith(""/repo/""):
        path = os.path.join(os.getcwd(), path[6:])
        return path

    if path.startswith(""/""):
        # Handle case when Claude provides paths with leading slash
        if path == ""/"" or path == ""/."":
            # Special case for root directory
            path = os.getcwd()
        else:
            # Replace leading slash with current working directory
            path = os.path.join(os.getcwd(), path[1:])
    elif path.startswith(""./""):
        # Handle relative paths starting with ./
        path = os.path.join(os.getcwd(), path[2:])
    elif not os.path.isabs(path) and not is_windows_path:
        # For non-absolute paths that aren't Windows paths either
        path = os.path.join(os.getcwd(), path)

    return path
",example-agent-codebase-arch/vertical-slice-architecture/shared/utils.py,,1,1.2501528648238603e-09,"The method 'normalize_path' is a utility function that provides a useful feature for normalizing file paths across different operating systems and path formats. It handles various cases such as Windows paths, relative paths, and special cases like '/repo/' paths. This kind of functionality is often needed in applications that deal with file systems, making it a valuable method to retain. Additionally, the method is well-documented and straightforward, which enhances its maintainability and usability. Therefore, it is likely to be retained in the codebase."
survived,"def normalize_path(path: str) -> str:
    """"""
    Normalize file paths to handle various formats (absolute, relative, Windows paths, etc.)

    Args:
        path: The path to normalize

    Returns:
        The normalized path
    """"""
    if not path:
        return path

    # Handle Windows backslash paths if provided
    path = path.replace(""\\"", os.sep)

    is_windows_path = False
    if os.name == ""nt"" and len(path) > 1 and path[1] == "":"":
        is_windows_path = True

    # Handle /repo/ paths from Claude (tool use convention)
    if path.startswith(""/repo/""):
        path = os.path.join(os.getcwd(), path[6:])
        return path

    if path.startswith(""/""):
        # Handle case when Claude provides paths with leading slash
        if path == ""/"" or path == ""/."":
            # Special case for root directory
            path = os.getcwd()
        else:
            # Replace leading slash with current working directory
            path = os.path.join(os.getcwd(), path[1:])
    elif path.startswith(""./""):
        # Handle relative paths starting with ./
        path = os.path.join(os.getcwd(), path[2:])
    elif not os.path.isabs(path) and not is_windows_path:
        # For non-absolute paths that aren't Windows paths either
        path = os.path.join(os.getcwd(), path)

    return path
",example-agent-codebase-arch/pipeline-architecture/shared/utilities.py,,1,1.1032560311263802e-09,"The method 'normalize_path' is a utility function that provides a useful feature for normalizing file paths across different operating systems and path formats. It handles various cases such as Windows paths, relative paths, and special cases like '/repo/' paths. This kind of functionality is often needed in applications that deal with file systems, making it a valuable method to retain. Additionally, the method is well-documented and straightforward, which enhances its maintainability and usability. Therefore, it is likely to be retained in the codebase."
survived,"    def process(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """"""
        Process data through the pipeline.
        
        Args:
            data: The input data to process
            
        Returns:
            The processed data after passing through all stages
        """"""
        console.log(f""[pipeline] Starting pipeline: {self.name}"")
        
        current_data = data
        
        for stage_name in self.stage_order:
            stage = self.stages[stage_name]
            console.log(f""[pipeline] Processing stage: {stage_name}"")
            
            try:
                current_data = stage.process(current_data)
                
                # Check if there was an error in the stage
                if ""error"" in current_data:
                    console.log(f""[pipeline] Error in stage {stage_name}: {current_data['error']}"")
                    # Continue to the next stage, which may handle the error
                
            except Exception as e:
                console.log(f""[pipeline] Exception in stage {stage_name}: {str(e)}"")
                current_data = {""error"": f""Exception in stage {stage_name}: {str(e)}""}
        
        console.log(f""[pipeline] Completed pipeline: {self.name}"")
        return current_data",example-agent-codebase-arch/pipeline-architecture/pipeline_manager/pipeline_manager.py,Pipeline,1,5.60279640614594e-09,"The method 'process' is a core part of a pipeline system, handling the sequential processing of data through various stages. It includes error handling and logging, which are essential for debugging and maintaining the pipeline. The method is well-documented and structured, making it a critical component of the system. Such methods are typically retained unless there is a significant change in the system architecture or requirements, which is not indicated here."
survived,"def temp_dir():
    temp_path = tempfile.mkdtemp()
    yield temp_path
    shutil.rmtree(temp_path)
",tests/cli/test_create_crew.py,,1,7.73442280641062e-08,"The method 'temp_dir' is a generator function that creates a temporary directory and ensures its cleanup after use. This is a useful utility in many programming scenarios where temporary storage is needed, such as during testing or when handling temporary files. The use of 'tempfile.mkdtemp()' to create a temporary directory and 'shutil.rmtree()' to remove it ensures that resources are managed efficiently. Given its utility and the fact that it handles both creation and cleanup, it is likely to be retained in the codebase."
survived,"    def _restore_state(self, stored_state: Dict[str, Any]) -> None:
        """"""Restore flow state from persistence.
        
        Args:
            stored_state: Previously stored state to restore
            
        Raises:
            ValueError: If validation fails for structured state
            TypeError: If state is neither BaseModel nor dictionary
        """"""
        self._initialize_state(stored_state)
",src/crewai/flow/flow.py,Flow,1,1.725782769012759e-08,"The method '_restore_state' is a private method (indicated by the underscore prefix) that is used to restore the state of an object from a stored state. This is a common pattern in object-oriented programming, especially in scenarios involving persistence or serialization. The method is well-documented, specifying the arguments and potential exceptions, which indicates that it is a considered part of the codebase. Additionally, the functionality it provides is essential for restoring object state, which is a critical operation in many applications. Therefore, it is unlikely to be deleted unless there is a significant refactor or change in how state management is handled in the application."
survived,"    def load_state(self, flow_uuid: str) -> Optional[Dict[str, Any]]:
        """"""Load the most recent state for a given flow UUID.
        
        Args:
            flow_uuid: Unique identifier for the flow instance
            
        Returns:
            The most recent state as a dictionary, or None if no state exists
        """"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute(""""""
            SELECT state_json
            FROM flow_states
            WHERE flow_uuid = ?
            ORDER BY id DESC
            LIMIT 1
            """""", (flow_uuid,))
            row = cursor.fetchone()
            
        if row:
            return json.loads(row[0])
        return None",src/crewai/flow/persistence/sqlite.py,SQLiteFlowPersistence,1,7.582560422162384e-10,"The method 'load_state' is a well-defined function that serves a clear purpose: it retrieves the most recent state for a given flow UUID from a database. It uses a SQL query to fetch the data and handles the case where no data is found by returning None. This functionality is essential for applications that need to maintain or restore state information, making it unlikely to be deleted unless the entire feature it supports is deprecated or replaced by a different mechanism. Additionally, the method is concise, follows good practices, and does not have any apparent issues that would necessitate its removal."
survived,"    def get_total_flow_rate(self, wallet_client: EVMWalletClient, parameters: dict):
        result = wallet_client.read(
            {
                ""address"": parameters[""poolAddress""],
                ""abi"": POOL_ABI,
                ""functionName"": ""getTotalFlowRate"",
                ""args"": [],
            }
        )
        return result[""value""]",python/src/plugins/superfluid/goat_plugins/superfluid/service.py,SuperfluidService,1,4.599055376537186e-10,"The method `get_total_flow_rate` is a straightforward utility function that interacts with a blockchain wallet client to retrieve the total flow rate from a specified pool address. This type of function is essential for applications that need to interact with smart contracts and retrieve specific data. Given the increasing importance of blockchain technology and smart contract interactions, this method is likely to be useful and relevant for developers working in this space. Therefore, it is likely to survive."
survived,"def test_xai_raw_response_with_validator_sync(model, mode):
    """"""Test that _raw_response works with validated models in sync mode""""""
    client = instructor.from_provider(f""xai/{model}"", mode=mode)
    
    user = client.chat.completions.create(
        response_model=UserValidated,
        max_retries=2,
        messages=[
            {
                ""role"": ""system"",
                ""content"": ""You are a helpful assistant that extracts information."",
            },
            {
                ""role"": ""user"",
                ""content"": ""Extract: Jason is 25 years old."",
            },
        ],
    )
    
    assert isinstance(user, UserValidated)
    assert user.name == ""JASON""
    assert user.age == 25
    assert hasattr(user, ""_raw_response""), (
        ""The raw response should be available from XAI""
    )
    assert user._raw_response is not None
",tests/llm/test_xai/test_raw_response.py,,1,4.6911638017642294e-08,"The method 'test_xai_raw_response_with_validator_sync' is a test function that verifies the functionality of a system, specifically checking if the '_raw_response' attribute is correctly set when using a validated model in synchronous mode. Test functions are generally crucial for ensuring code reliability and correctness, especially in systems involving AI and data validation. This method is likely to be retained because it serves an important role in maintaining the integrity of the system by ensuring that the expected behavior is met. Additionally, the method is well-structured and includes assertions that are clear and purposeful, which further supports its retention."
survived,"    def __init__(self, jwt_token: str):
        self.jwt_token = jwt_token
        self.calls = []
        self.stop = []
",tests/custom_llm_test.py,JWTAuthLLM,1,9.931195248674785e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. It initializes the object with a JWT token and two lists, which suggests it is setting up the necessary state for the object to function. Constructors are essential for creating instances of classes, and there is no indication that this particular constructor is redundant or unnecessary. Therefore, it is unlikely to be deleted."
survived,"    def get_context_window_size(self) -> int:
        """"""Get the context window size of the LLM.
        
        Returns:
            The context window size as an integer.
        """"""
        pass
",src/crewai/llm.py,BaseLLM,1,3.0590235908148916e-07,"The method `get_context_window_size` is a placeholder function with a clear and specific purpose: to return the context window size of a language model. However, it currently lacks an implementation. Despite this, the method is well-documented and has a clear return type, indicating that it is intended to be implemented in the future. Such methods are often kept in the codebase as part of an interface or abstract class, or as a reminder for future development. Therefore, it is likely to survive until it is fully implemented."
survived,"    def call(
        self,
        messages: Union[str, List[Dict[str, str]]],
        tools: Optional[List[dict]] = None,
        callbacks: Optional[List[Any]] = None,
        available_functions: Optional[Dict[str, Any]] = None,
    ) -> Union[str, Any]:
        """"""Call the LLM with the given messages.
        
        Args:
            messages: Input messages for the LLM.
                     Can be a string or list of message dictionaries.
                     If string, it will be converted to a single user message.
                     If list, each dict must have 'role' and 'content' keys.
            tools: Optional list of tool schemas for function calling.
                  Each tool should define its name, description, and parameters.
            callbacks: Optional list of callback functions to be executed
                      during and after the LLM call.
            available_functions: Optional dict mapping function names to callables
                               that can be invoked by the LLM.
            
        Returns:
            Either a text response from the LLM (str) or
            the result of a tool function call (Any).
        """"""
        pass
",src/crewai/llm.py,BaseLLM,1,1.637377179507321e-07,"The method 'call' is a placeholder function with a detailed docstring explaining its intended functionality. It is designed to interact with a language model (LLM) using various inputs and options, such as messages, tools, callbacks, and available functions. This kind of method is crucial for applications that involve dynamic interactions with LLMs, allowing for flexible and extensible use cases. Given the increasing importance of LLMs in various applications, this method is likely to be implemented and used rather than deleted. The presence of detailed parameters and return types also suggests that it is part of a larger framework or library, further supporting its survival."
survived,"def test_custom_llm_implementation():
    """"""Test that a custom LLM implementation works with create_llm.""""""
    custom_llm = CustomLLM(response=""The answer is 42"")
    
    # Test that create_llm returns the custom LLM instance directly
    result_llm = create_llm(custom_llm)
    
    assert result_llm is custom_llm
    
    # Test calling the custom LLM
    response = result_llm.call(""What is the answer to life, the universe, and everything?"")
    
    # Verify that the custom LLM was called
    assert len(custom_llm.calls) > 0
    # Verify that the response from the custom LLM was used
    assert response == ""The answer is 42""
",tests/custom_llm_test.py,,1,1.1861120010657661e-08,"The method is a unit test for a custom LLM (Language Learning Model) implementation. It verifies that the custom LLM can be created and used correctly, ensuring that the expected response is returned. Unit tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, this method is likely to be retained as it serves an important role in testing the functionality of the custom LLM implementation."
survived,"def test_custom_llm_with_jwt_auth():
    """"""Test a custom LLM implementation with JWT authentication.""""""
    jwt_llm = JWTAuthLLM(jwt_token=""example.jwt.token"")
    
    # Test that create_llm returns the JWT-authenticated LLM instance directly
    result_llm = create_llm(jwt_llm)
    
    assert result_llm is jwt_llm
    
    # Test calling the JWT-authenticated LLM
    response = result_llm.call(""Test message"")
    
    # Verify that the JWT-authenticated LLM was called
    assert len(jwt_llm.calls) > 0
    # Verify that the response from the JWT-authenticated LLM was used
    assert response == ""Response from JWT-authenticated LLM""",tests/custom_llm_test.py,,1,1.522997951276035e-08,"The method `test_custom_llm_with_jwt_auth` is a unit test function that verifies the functionality of a custom LLM (Language Learning Model) implementation with JWT (JSON Web Token) authentication. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with authentication mechanisms. This test checks that the LLM instance is correctly created and called, and that the expected response is returned. Such tests are typically retained in codebases to maintain software quality and prevent regressions. Therefore, this method is likely to be retained."
