status,method,filepath,class_name,predict,prob_deleted,reason
survived,"def test_new_required_keyword_only_param():
    old_code = ""def func(*, a): pass""
    new_code = ""def func(*, a, b): pass""

    old_tree = ast.parse(old_code)
    new_tree = ast.parse(new_code)
    errors = check_signature_compatibility(old_tree.body[0], new_tree.body[0])

    assert len(errors) == 1
    assert errors[0].message == ""New required keyword-only param 'b' added.""
    assert errors[0].param_name == ""b""
",tests/dev/test_check_function_signatures.py,,1,2.998960815863541e-09,"The method 'test_new_required_keyword_only_param' is a unit test designed to verify that adding a new required keyword-only parameter to a function signature is correctly identified as an error. This is a common scenario in software development where backward compatibility of function signatures is crucial. The test is well-structured, checking for the specific error message and parameter name, which indicates its importance in maintaining code quality and compatibility. Therefore, it is likely to be retained as part of the test suite to ensure that such changes are properly flagged."
survived,"def test_new_required_positional_param():
    old_code = ""def func(a): pass""
    new_code = ""def func(a, b): pass""

    old_tree = ast.parse(old_code)
    new_tree = ast.parse(new_code)
    errors = check_signature_compatibility(old_tree.body[0], new_tree.body[0])

    assert len(errors) == 1
    assert errors[0].message == ""New required positional param 'b' added.""
    assert errors[0].param_name == ""b""
",tests/dev/test_check_function_signatures.py,,1,4.0586521248284276e-10,"The method 'test_new_required_positional_param' is a test function that checks for compatibility issues when a new required positional parameter is added to a function signature. This is a useful test case for ensuring backward compatibility in code changes. Test functions like this are generally retained as they help in maintaining code quality and preventing regressions. Therefore, it is likely to survive."
survived,"def add_3d_slices(input1, input2, output):
    # Get tensor shapes
    slice_z, slice_y, slice_x = input1.shape

    # Compute strides
    stride_z, stride_y, stride_x = input1.stride()

    # Determine grid size
    grid = (
        triton.cdiv(slice_x, BLOCK_SIZE_X),
        triton.cdiv(slice_y, BLOCK_SIZE_Y),
        triton.cdiv(slice_z, BLOCK_SIZE_Z),
    )

    # Launch kernel
    add_3d_slices_kernel[grid](
        input1,
        input2,
        output,
        stride_x,
        stride_y,
        stride_z,
        slice_x,
        slice_y,
        slice_z,
        BLOCK_SIZE_X=BLOCK_SIZE_X,
        BLOCK_SIZE_Y=BLOCK_SIZE_Y,
        BLOCK_SIZE_Z=BLOCK_SIZE_Z,
    )
",examples/3dims.py,,1,1.725782769012759e-08,"The method 'add_3d_slices' is a specialized function that appears to be part of a larger system for performing operations on 3D tensors using Triton, a library for writing custom GPU kernels. This function is likely to be useful in contexts where high-performance computing is required, such as in machine learning or scientific computing applications. Given the increasing importance of such applications and the need for efficient computation, it is likely that this method will be retained and possibly further optimized rather than deleted."
survived,"    def test_rolling_simple(self, move_func, static_func, window):
        """"""Test rolling functions with simple data.""""""
        data = np.array([[1, 2, 3, 4, 5, 6], [2, 4, 6, 8, 10, 12]], dtype=np.float64)
        result = move_func(data, window=window, min_count=2)

        # Shape should be (n_obs, n_vars, n_vars)
        assert result.shape == (6, 2, 2)

        # Check symmetry for each time point
        for t in range(6):
            assert_allclose(result[t], result[t].T, equal_nan=True)

        # For perfect linear relationship, correlation should be 1
        if move_func == move_nancorrmatrix:
            for i in range(1, 6):  # From second window onwards (min_count=2)
                assert_allclose(result[i], [[1.0, 1.0], [1.0, 1.0]], rtol=1e-10)
",numbagg/test/test_matrix_functions.py,TestMatrixFunctions,1,1.725782769012759e-08,"The method `test_rolling_simple` is a unit test function designed to test the behavior of rolling functions with simple data. It checks the shape of the result, symmetry, and correlation values, which are essential for validating the correctness of the rolling functions. Such test functions are crucial for ensuring code reliability and are typically retained in codebases to prevent regressions and verify functionality. Therefore, it is likely to be retained."
survived,"    def test_constant_variables(self, func):
        """"""Test with constant (zero variance) variables.""""""
        data = np.array([[1, 1, 1, 1], [2, 2, 2, 2], [1, 2, 3, 4]], dtype=np.float64)
        result = func(data)

        if func == nancorrmatrix:
            # Correlation with constant variables should be NaN
            assert np.isnan(result[0, 1])  # Two constants
            assert np.isnan(result[0, 2])  # Constant with non-constant
            assert result[2, 2] == 1.0  # Variable with itself
        else:
            # Covariance of constants should be 0
            assert result[0, 0] == 0.0
            assert result[1, 1] == 0.0
            assert result[0, 1] == 0.0
",numbagg/test/test_matrix_functions.py,TestMatrixFunctions,1,1.522997951276035e-08,"The method `test_constant_variables` is a unit test designed to verify the behavior of a function when dealing with constant variables. It checks both correlation and covariance scenarios, ensuring that the function handles these edge cases correctly. Such tests are crucial for validating the robustness and correctness of statistical functions, especially in handling edge cases like constant variables. Therefore, this method is likely to be retained as it serves an important role in testing and ensuring the reliability of the code."
survived,"def pandas_matrix_setup(a):
    """"""Setup for matrix functions (corr/cov) that need transposed DataFrame.""""""
    # Transpose so variables are columns (pandas expects this)
    df = pd.DataFrame(a.T)
    return df
",numbagg/test/conftest.py,,1,1.522997951276035e-08,"The method 'pandas_matrix_setup' is a utility function that transposes a given matrix and converts it into a pandas DataFrame. This is a common requirement when working with pandas' matrix functions like correlation or covariance, which expect variables to be in columns. The function is simple, clear, and serves a specific purpose that is likely to be useful in data analysis tasks. Therefore, it is likely to be retained as it provides a necessary transformation for data preparation in pandas."
survived,"    def test_array_alpha_consistency(self):
        """"""Test consistency when alpha is an array.""""""
        np.random.seed(999)

        # Create two time series
        n_obs = 20
        a1 = np.random.randn(n_obs)
        a2 = np.random.randn(n_obs) * 0.8 + 0.2

        # Create varying alpha
        alpha_array = np.linspace(0.1, 0.9, n_obs)

        # Compute using non-matrix functions
        cov_nonmatrix = move_exp_nancov(a1, a2, alpha=alpha_array)
        corr_nonmatrix = move_exp_nancorr(a1, a2, alpha=alpha_array)

        # Compute using matrix functions
        data_matrix = np.array([a1, a2])
        cov_matrix_result = move_exp_nancovmatrix(data_matrix, alpha=alpha_array)
        corr_matrix_result = move_exp_nancorrmatrix(data_matrix, alpha=alpha_array)

        # Extract off-diagonal elements
        cov_from_matrix = cov_matrix_result[:, 0, 1]
        corr_from_matrix = corr_matrix_result[:, 0, 1]

        # They should match
        assert_allclose(cov_nonmatrix, cov_from_matrix, rtol=1e-10)
        assert_allclose(corr_nonmatrix, corr_from_matrix, rtol=1e-10)
",numbagg/test/test_move_exp_matrix_consistency.py,TestMoveExpMatrixConsistency,1,8.76424914819242e-08,"The method `test_array_alpha_consistency` is a unit test designed to verify the consistency of results between two different implementations of moving exponential covariance and correlation calculations. It uses assertions to ensure that the results from non-matrix functions match those from matrix functions. This kind of test is crucial for validating the correctness of numerical computations, especially when dealing with varying parameters like `alpha`. Since it serves an important role in ensuring the reliability of the code, it is unlikely to be deleted unless the functionality it tests is removed or significantly altered."
survived,"    def test_single_series_diagonal_consistency(self):
        """"""Test that diagonal elements match what we'd expect for a single series.""""""
        np.random.seed(333)

        # Create a single time series
        n_obs = 20
        a1 = np.random.randn(n_obs)

        alpha = 0.4

        # For correlation, diagonal should always be 1.0 (after enough data)
        data_matrix = np.array([a1])
        corr_matrix_result = move_exp_nancorrmatrix(data_matrix, alpha=alpha)

        # Diagonal elements should be 1.0 where finite
        diagonal_values = corr_matrix_result[:, 0, 0]
        finite_mask = np.isfinite(diagonal_values)
        assert_allclose(diagonal_values[finite_mask], 1.0, rtol=1e-10)
",numbagg/test/test_move_exp_matrix_consistency.py,TestMoveExpMatrixConsistency,1,7.194132978569833e-09,"The method `test_single_series_diagonal_consistency` is a unit test designed to verify the consistency of diagonal elements in a correlation matrix for a single time series. It uses a random time series and checks that the diagonal elements of the correlation matrix are 1.0, which is a fundamental property of correlation matrices. This test is crucial for ensuring the correctness of the `move_exp_nancorrmatrix` function, especially in handling single series data. Since it serves an important role in validating the functionality of the code, it is likely to be retained."
survived,"    def test_init(self):
        """"""Test generator initialization""""""
        assert self.generator.base_path == self.temp_dir
        assert isinstance(self.generator.default_prompts, dict)
        assert isinstance(self.generator.task_templates, dict)
        assert 'model' in self.generator.default_prompts
        assert 'add_type_hints' in self.generator.task_templates
",tests/test_scan/test_generate_parallel.py,TestParallelYAMLGenerator,1,5.905303995456778e-10,"The method 'test_init' is a unit test designed to verify the initialization of a generator object. It checks that the generator's base path is set correctly and that certain attributes are of the expected types and contain specific keys. Unit tests are crucial for ensuring code reliability and are typically retained in codebases to maintain software quality. Therefore, this method is likely to survive."
survived,"    def test_generate_for_model_migration(self):
        """"""Test model migration YAML generation""""""
        files = [
            'src/models/old_model.py',
            'src/api/old_api.py',
            'tests/test_old.py'
        ]
        
        config = self.generator.generate_for_model_migration(
            'gpt-3.5',
            'gpt-4',
            files
        )
        
        assert config['provider'] == 'claude'
        assert config['metadata']['migration'] == 'gpt-3.5 -> gpt-4'
        assert len(config['tasks']) == 3
        
        # Check migration prompts
        for task in config['tasks']:
            assert 'Migrate code from gpt-3.5 to gpt-4' in task['prompt']
            assert task['file'] in files
        
        assert config['options']['timeout'] == 180  # Longer timeout for migration
        assert config['options']['output_dir'] == './migration-gpt-3.5-to-gpt-4'
",tests/test_scan/test_generate_parallel.py,TestParallelYAMLGenerator,1,6.348800075736417e-09,"The method `test_generate_for_model_migration` is a unit test designed to verify the functionality of a model migration YAML generation process. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with complex processes like model migrations. The test checks various aspects of the configuration, such as provider, metadata, tasks, and options, which are essential for validating the migration process. Since testing is a fundamental part of software development and maintenance, this method is likely to be retained to ensure the migration functionality works as expected."
survived,"    def get_directory_structure(self) -> Dict[str, Any]:
        """"""Get hierarchical directory structure""""""
        structure = {}
        
        def build_tree(path: Path, tree: Dict[str, Any]):
            """"""Recursively build directory tree""""""
            try:
                for item in sorted(path.iterdir()):
                    if item.is_dir() and not item.name.startswith('.'):
                        tree[item.name] = {}
                        build_tree(item, tree[item.name])
                    elif item.is_file() and self._is_model_file(item):
                        if '__files__' not in tree:
                            tree['__files__'] = []
                        tree['__files__'].append({
                            'name': item.name,
                            'size': item.stat().st_size,
                            'type': self.model_extensions.get(item.suffix, 'other')
                        })
            except PermissionError:
                pass
        
        build_tree(self.base_path, structure)
        return structure
",src/haconiwa/scan/analyzer.py,ModelAnalyzer,1,1.8189616842444243e-09,"The method `get_directory_structure` is a utility function that provides a hierarchical view of a directory structure, which is a common requirement in many applications dealing with file systems. It is well-structured, handles exceptions like `PermissionError`, and filters files based on certain criteria (e.g., model files). Such functionality is often needed for organizing, displaying, or processing directory contents, making it a useful and reusable component in various contexts. Therefore, it is likely to be retained in the codebase."
survived,"    def test_generate_project_wide(self):
        """"""Test project-wide YAML generation""""""
        # Create test files in temp directory
        src_dir = self.temp_dir / 'src'
        src_dir.mkdir()
        models_dir = src_dir / 'models'
        models_dir.mkdir()
        tests_dir = self.temp_dir / 'tests'
        tests_dir.mkdir()
        
        # Create test files
        (src_dir / 'main.py').write_text('def main(): pass')
        (src_dir / 'utils.py').write_text('def helper(): pass')
        (models_dir / 'user.py').write_text('class User: pass')
        (tests_dir / 'test_main.py').write_text('def test_main(): pass')
        
        config = self.generator.generate_project_wide(
            action='add_type_hints',
            file_pattern='*.py',
            exclude_patterns=['tests/']
        )
        
        assert config['provider'] == 'claude'
        assert config['metadata']['action'] == 'add_type_hints'
        assert config['metadata']['file_pattern'] == '*.py'
        
        # Should exclude test files
        file_names = [task['file'] for task in config['tasks']]
        assert 'tests/test_main.py' not in file_names
        for task in config['tasks']:
            assert 'tests/' not in task['file']
            assert task['prompt'] == 'Add comprehensive type hints to all functions and methods'
",tests/test_scan/test_generate_parallel.py,TestParallelYAMLGenerator,1,1.1253518384332553e-07,"The method 'test_generate_project_wide' is a unit test designed to verify the functionality of a project-wide YAML generation feature. It sets up a temporary directory structure, creates test files, and then calls a method to generate a configuration. The test includes assertions to ensure the configuration is generated correctly and that certain files are excluded based on the specified patterns. This is a typical and necessary part of software testing to ensure code reliability and correctness. Therefore, it is unlikely to be deleted as it serves an important purpose in maintaining the quality of the codebase."
survived,"        def build_tree(node: Dict[str, Any], prefix: str = """", is_last: bool = True):
            """"""Recursively build tree representation""""""
            items = [(k, v) for k, v in node.items() if k != '__files__']
            files = node.get('__files__', [])
            
            # Add directories
            for i, (key, value) in enumerate(items):
                is_last_item = i == len(items) - 1 and not files
                
                connector = ""‚îî‚îÄ‚îÄ "" if is_last_item else ""‚îú‚îÄ‚îÄ ""
                lines.append(f""{prefix}{connector}{key}/"")
                
                if isinstance(value, dict):
                    extension = ""    "" if is_last_item else ""‚îÇ   ""
                    build_tree(value, prefix + extension, is_last_item)
            
            # Add files
            for i, file_info in enumerate(files):
                is_last_file = i == len(files) - 1
                connector = ""‚îî‚îÄ‚îÄ "" if is_last_file else ""‚îú‚îÄ‚îÄ ""
                
                if isinstance(file_info, dict):
                    name = file_info.get('name', 'Unknown')
                    size = file_info.get('size', 0)
                    size_str = self._format_size(size)
                    lines.append(f""{prefix}{connector}{name} ({size_str})"")
                else:
                    lines.append(f""{prefix}{connector}{file_info}"")
",src/haconiwa/scan/formatter.py,OutputFormatter,1,7.194132978569833e-09,"The method 'build_tree' is a utility function that recursively builds a tree representation of a directory structure. It is a common and useful function for visualizing hierarchical data, especially in file systems. The method is well-structured, uses recursion effectively, and handles both directories and files. It also includes formatting for file sizes, which adds to its utility. Such methods are often retained in codebases because they provide a clear and useful representation of data structures, which is a common requirement in many applications."
survived,"def help():
    """"""Show detailed help for scan command""""""
    help_text = """"""
üîç Haconiwa Scan Command - AI Model Search & Analysis

The scan command provides comprehensive search and analysis capabilities for AI model
directories, supporting model name searching, file content searching, and various 
output formats.

COMMANDS:
  model         Search by model name (with automatic prefix stripping)
  content       Search file contents with regex
  list          List all available AI models
  analyze       Analyze directory structure and categorization
  compare       Compare multiple AI models
  guide         Generate development guide for specific model
  generate-parallel-config  Generate parallel development configuration YAML

EXAMPLES:
  # Search for a model
  haconiwa scan model gpt-4
  
  # Search with prefix
  haconiwa scan model claude-3-opus --no-strip-prefix
  
  # Search content
  haconiwa scan content ""model.forward"" --type .py --context 5
  
  # List models by provider
  haconiwa scan list --provider openai --format json
  
  # Analyze directory
  haconiwa scan analyze --show-structure
  
  # Compare models
  haconiwa scan compare gpt-4 claude-3-opus
  
  # Generate guide
  haconiwa scan guide gpt-4 --type quickstart --output guide.md
  
  # Generate parallel development configuration YAML
  haconiwa scan generate-parallel-config --source model:gpt-4 --action add_tests
  haconiwa scan generate-parallel-config --example
  haconiwa scan generate-parallel-config --migration gpt-3.5:gpt-4 --max-files 20
  haconiwa scan generate-parallel-config --project-wide ""*.py"" --action add_type_hints

For more information on a specific command, use:
  haconiwa scan <command> --help
    """"""
    typer.echo(help_text)",src/haconiwa/scan/cli.py,,1,6.023574641292144e-08,"The method provides a detailed help text for a command-line tool, which is a common and useful feature in software applications. It is well-documented and serves an important purpose for users who need guidance on how to use the tool effectively. Such methods are typically retained as they enhance user experience and are essential for understanding the functionality of the software."
survived,"    def _get_file_info(self, file_path: Path, include_content: bool = False) -> Dict[str, Any]:
        """"""Get information about a file""""""
        info = {
            'path': str(file_path.relative_to(self.base_path)),
            'name': file_path.name,
            'type': self.file_type_mappings.get(file_path.suffix, 'other'),
            'size': file_path.stat().st_size
        }
        
        if include_content and info['size'] < 1024 * 1024:  # Max 1MB
            try:
                info['content'] = file_path.read_text(encoding='utf-8', errors='ignore')
            except:
                info['content'] = None
        
        return info
",src/haconiwa/scan/scanner.py,ModelScanner,1,5.905303995456778e-10,"The method '_get_file_info' is a utility function that provides useful metadata about a file, such as its path, name, type, and size. Additionally, it can include the file's content if it's below a certain size threshold. This functionality is generally useful in many applications that need to handle files, making it a candidate for survival. The method is well-structured, handles exceptions when reading file content, and uses a clear and concise approach to gather file information, which are all good practices in coding."
survived,"    def test_search_content(self, temp_model_dir):
        """"""Test content searching""""""
        scanner = ModelScanner(temp_model_dir)
        
        # Search for pattern in files
        results = scanner.search_content(""openai"", file_types=["".py""])
        assert results['total_matches'] > 0
        assert results['files_searched'] > 0
        assert len(results['matches']) > 0
        
        # Verify match details
        first_match = results['matches'][0]
        assert 'file' in first_match
        assert 'line_number' in first_match
        assert 'line' in first_match
        assert 'context' in first_match
",tests/test_scan/test_scanner.py,TestModelScanner,1,1.8189616842444243e-09,"The method `test_search_content` is a unit test designed to verify the functionality of a `ModelScanner` class, specifically its ability to search for content within files. Unit tests are crucial for ensuring code reliability and correctness, especially in larger projects. This test checks for multiple conditions, such as the presence of matches, the number of files searched, and the details of the matches, which are all important aspects of validating the search functionality. Given its role in maintaining code quality and the absence of any indication that this functionality is obsolete or redundant, it is likely to be retained."
survived,"    def generate_from_scan_results(self, 
                                 scan_results: Dict[str, Any],
                                 action: str = 'refactor',
                                 max_files: int = 10,
                                 custom_prompts: Optional[Dict[str, str]] = None) -> Dict[str, Any]:
        """"""Generate parallel-dev.yaml from scan results""""""
        
        tasks = []
        
        # Extract files from scan results
        if 'matches' in scan_results:  # Model search results
            files = self._extract_files_from_matches(scan_results['matches'], max_files)
        elif 'files' in scan_results:  # Directory analysis results
            files = list(scan_results['files'].keys())[:max_files]
        else:
            files = []
        
        # Generate tasks for each file
        for file_path in files:
            prompt = self._generate_prompt_for_file(file_path, action, custom_prompts)
            tasks.append({
                'file': file_path,
                'prompt': prompt
            })
        
        # Generate YAML configuration
        config = {
            'provider': 'claude',
            'metadata': {
                'generated_at': datetime.now().isoformat(),
                'source': 'haconiwa scan generate-parallel-config',
                'action': action,
                'total_tasks': len(tasks)
            },
            'tasks': tasks,
            'options': {
                'max_concurrent': min(5, max(1, len(tasks) // 2)),  # Dynamic concurrency
                'timeout': 120,  # 2 minutes per task
                'allowed_tools': ['Read', 'Write', 'Edit', 'MultiEdit'],
                'permission_mode': 'confirmEach',
                'output_dir': './parallel-dev-results'
            }
        }
        
        return config
",src/haconiwa/scan/generate_parallel.py,ParallelYAMLGenerator,1,4.363462233903899e-09,"The method 'generate_from_scan_results' is a utility function that processes scan results to generate a YAML configuration. It is well-structured, with clear input parameters and a defined output. The method is likely part of a larger system that automates configuration generation based on scan results, which is a common requirement in software development and deployment pipelines. Given its utility and the fact that it handles dynamic input to produce a structured output, it is likely to be retained in the codebase."
survived,"    def test_scan_guide_types(self, runner, temp_model_dir):
        """"""Test different guide types""""""
        guide_types = [""development"", ""usage"", ""integration"", ""quickstart""]
        
        for guide_type in guide_types:
            result = runner.invoke(
                scan_app,
                [""guide"", ""o1-mini"", ""--path"", str(temp_model_dir), ""--type"", guide_type]
            )
            
            assert result.exit_code == 0
            assert ""o1-mini"" in result.stdout
",tests/test_scan/test_cli.py,TestScanCLI,1,1.6052280526088547e-09,"The method 'test_scan_guide_types' is a test function that verifies the functionality of a command-line application by checking if it correctly handles different guide types. It uses assertions to ensure the application runs without errors and produces the expected output. Test functions like this are crucial for maintaining software quality and ensuring that changes do not introduce regressions. Therefore, it is likely to be retained as part of the test suite."
survived,"    def _is_model_directory(self, path: Path, files: List[str]) -> bool:
        """"""Check if directory contains model files""""""
        # Check for config files
        has_config = any(f in files for f in self.config_files)
        
        # Check for model files
        has_model = any(
            any(f.endswith(ext) for ext in self.model_extensions.keys())
            for f in files
        )
        
        # Check directory name patterns
        model_patterns = ['model', 'checkpoint', 'weights', 'ckpt']
        has_pattern = any(pattern in path.name.lower() for pattern in model_patterns)
        
        return has_config or has_model or has_pattern
",src/haconiwa/scan/analyzer.py,ModelAnalyzer,1,2.646573631904765e-09,"The method `_is_model_directory` is likely to survive because it serves a clear and useful purpose: determining if a given directory contains model-related files. This is a common requirement in machine learning and data science workflows where directories need to be scanned for specific types of files, such as configuration files, model files, or directories named with certain patterns. The method is well-structured, checking for the presence of configuration files, model files with specific extensions, and directory name patterns, making it versatile and applicable in various scenarios. Additionally, the method is private (indicated by the underscore prefix), suggesting it is intended for internal use within a class, which is a common practice for utility functions."
survived,"    def _compare_size(self, model_data: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
        """"""Compare model sizes""""""
        sizes = {}
        
        for model, data in model_data.items():
            size_bytes = data.get('size', 0)
            size_gb = size_bytes / (1024 ** 3)
            
            sizes[model] = {
                'bytes': size_bytes,
                'gb': round(size_gb, 2),
                'category': self._categorize_size(size_gb)
            }
        
        return sizes
",src/haconiwa/scan/comparator.py,ModelComparator,1,1.3176514268359263e-10,"The method '_compare_size' is likely to survive because it provides a useful functionality of comparing model sizes in a structured way. It converts sizes from bytes to gigabytes, categorizes them, and returns a dictionary with detailed information. This kind of utility function is often needed in data processing and analysis tasks, making it valuable for maintaining and understanding model data."
survived,"    def _format_table(self, data: Any) -> str:
        """"""Format as ASCII table""""""
        if not isinstance(data, (list, dict)):
            return str(data)
        
        # Convert dict to list of items
        if isinstance(data, dict) and 'matches' not in data:
            data = [{'key': k, 'value': v} for k, v in data.items()]
        
        # Handle different data structures
        if isinstance(data, dict) and 'matches' in data:
            # Model search results
            rows = []
            for category, files in data['matches'].items():
                for file in files:
                    rows.append({
                        'Category': category,
                        'File': file['name'],
                        'Path': file['path'],
                        'Type': file['type']
                    })
            return self._create_table(rows)
        
        elif isinstance(data, list) and data:
            # List of models or other items
            if isinstance(data[0], dict):
                return self._create_table(data)
            else:
                # Simple list
                return ""\n"".join(f""‚Ä¢ {item}"" for item in data)
        
        return str(data)
",src/haconiwa/scan/formatter.py,OutputFormatter,1,5.905303995456778e-10,"The method '_format_table' is a utility function that formats data into an ASCII table or a simple list format. It handles different data structures like dictionaries and lists, making it versatile for various input types. Such utility functions are often useful in applications that require data presentation in a readable format, especially in command-line interfaces or logging. The method is well-structured, with clear handling of different cases, and does not seem to have any major issues or redundancies that would warrant its removal. Therefore, it is likely to be retained in the codebase."
survived,"    def search_content(self, 
                      pattern: str, 
                      file_types: Optional[List[str]] = None,
                      context_lines: int = 2) -> Dict[str, Any]:
        """"""Search for pattern in file contents""""""
        results = {
            'pattern': pattern,
            'matches': [],
            'total_matches': 0,
            'files_searched': 0
        }
        
        regex = re.compile(pattern, re.IGNORECASE | re.MULTILINE)
        
        for file_path in self._iter_files(file_types):
            if self._should_ignore(file_path):
                continue
            
            results['files_searched'] += 1
            
            try:
                content = file_path.read_text(encoding='utf-8', errors='ignore')
                lines = content.splitlines()
                
                for i, line in enumerate(lines):
                    if regex.search(line):
                        match_info = {
                            'file': str(file_path.relative_to(self.base_path)),
                            'line_number': i + 1,
                            'line': line.strip(),
                            'context': self._get_context(lines, i, context_lines)
                        }
                        results['matches'].append(match_info)
                        results['total_matches'] += 1
            
            except Exception as e:
                # Skip files that can't be read
                continue
        
        return results
",src/haconiwa/scan/scanner.py,ModelScanner,1,3.160881453314576e-10,"The method `search_content` is a utility function that provides a useful feature for searching patterns within files, which is a common requirement in many applications. It is well-structured, handles exceptions, and provides detailed results including context lines, which enhances its usability. These characteristics make it a valuable method that is likely to be retained in the codebase."
survived,"    def test_scan_content_command(self, runner, temp_model_dir):
        """"""Test the scan content command""""""
        result = runner.invoke(
            scan_app,
            [""content"", ""Hello"", ""--path"", str(temp_model_dir), ""--type"", "".py""]
        )
        
        assert result.exit_code == 0
        assert ""Hello from o1-mini"" in result.stdout
",tests/test_scan/test_cli.py,TestScanCLI,1,1.0467401685178159e-08,"The method 'test_scan_content_command' is a test function that is likely part of a test suite for a command-line application. Test functions are generally not deleted unless they are redundant, testing deprecated features, or replaced by more comprehensive tests. This function appears to be testing a specific command with assertions to verify expected behavior, which is a common practice in maintaining software quality. Therefore, it is likely to be retained as part of the test suite."
survived,"    def test_scan_generate_parallel_config_pattern_fix(self, runner):
        """"""Test generate-parallel-config for pattern fix""""""
        with tempfile.TemporaryDirectory() as tmpdir:
            output_path = Path(tmpdir) / ""pattern-fix.yaml""
            
            result = runner.invoke(
                scan_app,
                [""generate-parallel-config"",
                 ""--pattern-fix"", ""old_func:replace with new_func"",
                 ""--output"", str(output_path)]
            )
            
            assert result.exit_code == 0
            assert ""Generated pattern fix YAML"" in result.stdout
",tests/test_scan/test_cli.py,TestScanCLI,1,9.736200303530205e-10,"The method 'test_scan_generate_parallel_config_pattern_fix' is a unit test for a specific functionality of a command-line application. It uses a temporary directory to safely test the generation of a configuration file without affecting the actual file system. The test checks if the command executes successfully and verifies the expected output message. Such tests are crucial for ensuring the reliability and correctness of software, especially in command-line tools. Therefore, it is likely to be maintained as part of the test suite."
survived,"    def test_fixed_dimensional_conventions(self):
        """"""Test fixed dimensional conventions: (..., vars, obs) -> (..., vars, vars).""""""
        np.random.seed(42)

        # Basic test: (vars, obs) -> (vars, vars)
        data = np.random.randn(3, 100)  # (vars, obs)
        corr_result = nancorrmatrix(data)
        cov_result = nancovmatrix(data)

        assert corr_result.shape == (3, 3)
        assert cov_result.shape == (3, 3)

        # Broadcasting test: (batch, vars, obs) -> (batch, vars, vars)
        data_3d = np.random.randn(2, 3, 100)  # (batch, vars, obs)
        corr_3d = nancorrmatrix(data_3d)
        cov_3d = nancovmatrix(data_3d)

        assert corr_3d.shape == (2, 3, 3)
        assert cov_3d.shape == (2, 3, 3)
",numbagg/test/test_matrix_functions.py,TestCorrelationCovarianceMatrices,1,8.152020648014727e-09,"The method `test_fixed_dimensional_conventions` is a unit test designed to verify the behavior of the `nancorrmatrix` and `nancovmatrix` functions. It checks that these functions correctly handle input data of different shapes and return results with the expected dimensions. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with mathematical operations like correlation and covariance calculations. Therefore, this method is likely to be retained as it serves an important role in validating the functionality of the code."
survived,"    def test_correlation_matrix_properties(self):
        """"""Test mathematical properties of correlation matrices.""""""
        np.random.seed(123)
        # Exponential moving functions expect (obs, vars) format
        data = np.random.randn(30, 3)

        result = move_exp_nancorrmatrix(data, alpha=0.4)

        for t in range(result.shape[0]):
            corr_matrix = result[t]
            if not np.any(np.isnan(corr_matrix)):
                # 1. Diagonal should be 1.0
                assert_allclose(np.diag(corr_matrix), 1.0, rtol=1e-12)

                # 2. Matrix should be symmetric
                assert_allclose(corr_matrix, corr_matrix.T, rtol=1e-12)

                # 3. All values should be very close to [-1, 1] (allowing for floating-point precision)
                assert np.all(corr_matrix >= -1.0 - 1e-10)
                assert np.all(corr_matrix <= 1.0 + 1e-10)

                # 4. Should be positive semi-definite
                eigenvals = np.linalg.eigvals(corr_matrix)
                assert np.all(eigenvals >= -1e-10), (
                    f""Correlation matrix not PSD at time {t}""
                )
",numbagg/test/test_matrix_functions.py,TestExponentialMatrices,1,5.3157849718487075e-08,"The method is a well-structured test function that checks the mathematical properties of correlation matrices. It includes checks for diagonal values, symmetry, value range, and positive semi-definiteness, which are all essential properties of a valid correlation matrix. These checks are crucial for ensuring the correctness of the correlation matrix computation, making the method valuable for maintaining code quality. Therefore, it is likely to be retained in the codebase."
survived,"    def test_positive_semidefinite_covariance(self):
        """"""Test that covariance matrices are positive semi-definite.""""""
        np.random.seed(42)
        # Exponential moving functions expect (obs, vars) format
        data = np.random.randn(50, 4)

        result = move_exp_nancovmatrix(data, alpha=0.3)

        # Check that all finite covariance matrices are positive semi-definite
        for t in range(result.shape[0]):
            cov_matrix = result[t]
            if not np.any(np.isnan(cov_matrix)):
                # Compute eigenvalues
                eigenvals = np.linalg.eigvals(cov_matrix)
                # All eigenvalues should be non-negative (allowing small numerical errors)
                assert np.all(eigenvals >= -1e-10), (
                    f""Negative eigenvalue found at time {t}: {eigenvals.min()}""
                )
",numbagg/test/test_matrix_functions.py,TestExponentialMatrices,1,1.275190675769241e-07,"The method `test_positive_semidefinite_covariance` is a unit test designed to verify that the covariance matrices produced by the `move_exp_nancovmatrix` function are positive semi-definite. This is a crucial property for covariance matrices in statistical analysis and machine learning. The test uses random data to generate covariance matrices and checks their eigenvalues to ensure they are non-negative, which is a standard approach to verify positive semi-definiteness. Such tests are essential for ensuring the correctness and reliability of mathematical functions in a codebase, especially in scientific computing. Therefore, this method is likely to be retained as it serves an important role in validating the functionality of the code."
survived,"    def test_with_nans(self, func):
        """"""Test with NaN values.""""""
        data = np.array(
            [[1, 2, np.nan, 4], [2, 4, 6, np.nan], [np.nan, 1, 2, 3]], dtype=np.float64
        )
        result = func(data)

        # Check shape and symmetry
        assert result.shape == (3, 3)
        assert_allclose(result, result.T, equal_nan=True)

        # For correlation, check diagonal is 1 where not NaN
        if func == nancorrmatrix:
            assert_allclose(np.diag(result), [1.0, 1.0, 1.0])
",numbagg/test/test_matrix_functions.py,TestCorrelationCovarianceMatrices,1,1.955568070542584e-08,"The method `test_with_nans` is a unit test designed to verify the behavior of a function when handling NaN values. It checks the shape, symmetry, and specific properties of the result, which are crucial for ensuring the correctness of functions dealing with NaN values, such as correlation matrices. Given the importance of testing edge cases like NaN handling in data processing, this method is likely to be retained as it provides valuable validation for the function being tested."
survived,"    async def test_windows_script_execution_no_chmod(
        self, mock_chmod, mock_tempfile, mock_platform
    ):
        """"""Test that chmod is not called on Windows for script files.""""""
        mock_file = MagicMock()
        mock_file.name = ""C:\\temp\\script.sh""
        mock_file.__enter__.return_value = mock_file
        mock_tempfile.return_value = mock_file

        bash_tool = BashTool()

        # This would normally trigger script execution, but we'll just test the setup
        with patch.object(bash_tool, ""execute"") as mock_execute:
            mock_execute.return_value = MagicMock(success=True)

            # The actual script execution path includes chmod logic
            # We're testing that on Windows, chmod should not be called
            # This is tested indirectly through the platform check in the code

        # On Windows, chmod should not be called
        mock_chmod.assert_not_called()
",tests/unit/test_windows_compatibility.py,TestWindowsCompatibility,1,2.2159489282323004e-08,The method is a unit test designed to verify that the 'chmod' function is not called on Windows systems when executing scripts. This is a valid and useful test case to ensure platform-specific behavior is correctly implemented. It is likely to be retained as it helps maintain the integrity of the code across different operating systems.
survived,"def deploy_staticfiles_windows(release: Release) -> bool:
    """"""Deploy static files to CDN for Windows.""""""
    print(""Deploying static files to cdn (Windows)"")
    cc = f""public, max-age={int(datetime.timedelta(days=365).total_seconds())}""

    if not release.static_key:
        print(""No static files to deploy"")
        return True

    with tempfile.NamedTemporaryFile(suffix=os.path.basename(release.static_key)) as f:
        download_release_fileobj(release.static_key, f)
        f.flush()
        with DeploymentJob(
            f.name, ""ce-cdn.net"", version=release.version, cache_control=cc, bucket_path=""windows""
        ) as job:
            return job.run()
",bin/lib/builds_core.py,,1,9.237449576640118e-09,"The method 'deploy_staticfiles_windows' is a specialized function for deploying static files to a CDN specifically for Windows. It includes logging, cache control settings, and uses a temporary file to handle the deployment process. The method is likely part of a larger deployment system and is tailored for a specific platform (Windows), which suggests it serves a unique purpose. Unless there is a significant change in the deployment strategy or platform support, this method is likely to be retained as it fulfills a specific need."
survived,"    def test_build_uv_command_with_all_options(self):
        """"""Test building uv command with all options.""""""
        cmd = _build_uv_command(
            ""server.py"",
            python_version=""3.10"",
            project=Path(""/my/project""),
            with_packages=[""pandas"", ""numpy""],
            with_requirements=Path(""reqs.txt""),
            with_editable=Path(""/local/pkg""),
            no_banner=True,
        )
        expected = [
            ""uv"",
            ""run"",
            ""--python"",
            ""3.10"",
            ""--project"",
            ""/my/project"",
            ""--with"",
            ""fastmcp"",
            ""--with-editable"",
            ""/local/pkg"",
            ""--with"",
            ""pandas"",
            ""--with"",
            ""numpy"",
            ""--with-requirements"",
            ""reqs.txt"",
            ""fastmcp"",
            ""run"",
            ""server.py"",
            ""--no-banner"",
        ]
        assert cmd == expected
",tests/cli/test_cli.py,TestMainCLI,1,6.348800075736417e-09,"The method is a unit test for a function that builds a command with various options. Unit tests are crucial for ensuring code correctness and reliability, especially when dealing with command-line operations that can have many parameters and configurations. This test checks if the command is constructed correctly with all possible options, which is important for maintaining the integrity of the function it tests. Therefore, it is likely to be retained as part of the test suite."
survived,"    def test_run_with_uv_transport_options(self, mock_run):
        """"""Test run_with_uv with transport-related options.""""""
        mock_run.return_value = Mock(returncode=0)

        with pytest.raises(SystemExit) as exc_info:
            run_with_uv(
                ""server.py"",
                transport=""http"",
                host=""localhost"",
                port=8080,
                path=""/api"",
                log_level=""DEBUG"",
                show_banner=False,
            )

        assert exc_info.value.code == 0

        cmd = mock_run.call_args[0][0]
        expected = [
            ""uv"",
            ""run"",
            ""--with"",
            ""fastmcp"",
            ""fastmcp"",
            ""run"",
            ""server.py"",
            ""--transport"",
            ""http"",
            ""--host"",
            ""localhost"",
            ""--port"",
            ""8080"",
            ""--path"",
            ""/api"",
            ""--log-level"",
            ""DEBUG"",
            ""--no-banner"",
        ]
        assert cmd == expected
",tests/cli/test_run_with_uv.py,TestRunWithUv,1,2.3355930333443423e-09,"The method `test_run_with_uv_transport_options` is a unit test designed to verify the behavior of the `run_with_uv` function when specific transport-related options are provided. It uses mocking to simulate the function's execution and checks that the command constructed matches the expected command. This is a typical and necessary part of testing in software development, ensuring that the function behaves as expected under certain conditions. There is no indication that this test is obsolete or redundant, and it serves a clear purpose in validating the functionality of the code. Therefore, it is likely to be retained."
survived,"    def test_build_uv_command_with_requirements(self):
        """"""Test building uv command with requirements file.""""""
        req_path = Path(""requirements.txt"")
        cmd = _build_uv_command(""server.py"", with_requirements=req_path)
        expected = [
            ""uv"",
            ""run"",
            ""--with"",
            ""fastmcp"",
            ""--with-requirements"",
            ""requirements.txt"",
            ""fastmcp"",
            ""run"",
            ""server.py"",
        ]
        assert cmd == expected
",tests/cli/test_cli.py,TestMainCLI,1,6.348800075736417e-09,"The method 'test_build_uv_command_with_requirements' is a unit test designed to verify the functionality of the '_build_uv_command' function. Unit tests are crucial for ensuring code reliability and are typically retained in the codebase to maintain software quality. This test checks if the command is built correctly when a requirements file is provided, which is a common scenario in software development. Therefore, it is likely to be retained."
survived,"def visualise_clusters_rich(
    clusters: Optional[List[Cluster]] = None,
    *,
    checkpoint_path: Optional[Union[str, Path]] = None,
    console: Optional[Console] = None
) -> None:
    """"""Print a rich-formatted hierarchical visualization using Rich library.
    
    This function provides the most visually appealing output with colors, 
    interactive-style formatting, and comprehensive statistics when Rich is available.
    Falls back to enhanced visualization if Rich is not available.
    
    Args:
        clusters: List of clusters to visualize. If None, loads from checkpoint_path
        checkpoint_path: Path to checkpoint file to load clusters from
        console: Rich Console instance. If None, creates a new one or falls back
        
    Raises:
        ValueError: If neither clusters nor checkpoint_path is provided
        FileNotFoundError: If checkpoint file doesn't exist
    """"""
    if not RICH_AVAILABLE:
        logger.warning(""Rich library not available. Using enhanced visualization..."")
        visualise_clusters_enhanced(clusters, checkpoint_path=checkpoint_path)
        return

    # Create console if not provided
    if console is None and Console is not None:
        console = Console()
    
    if console is None:
        logger.warning(""Console not available. Using enhanced visualization..."")
        visualise_clusters_enhanced(clusters, checkpoint_path=checkpoint_path)
        return

    # Load clusters
    if clusters is None:
        if checkpoint_path is None:
            raise ValueError(""Either clusters or checkpoint_path must be provided"")
        clusters = _load_clusters_from_checkpoint(checkpoint_path)
    
    logger.info(f""Rich visualization of {len(clusters)} clusters"")

    # Build cluster tree structure
    node_id_to_cluster = _build_cluster_tree(clusters)
    
    # Calculate total conversations from root clusters only
    root_clusters = [cluster for cluster in clusters if not cluster.parent_id]
    total_conversations = sum(len(cluster.chat_ids) for cluster in root_clusters)

    # Create Rich Tree
    if Tree is None:
        logger.warning(""Rich Tree component not available. Using enhanced visualization..."")
        visualise_clusters_enhanced(clusters, checkpoint_path=checkpoint_path)
        return
        
    tree = Tree(
        f""[bold bright_cyan]üìö All Clusters ({total_conversations:,} conversations)[/]"",
        style=""bold bright_cyan""
    )

    # Add root clusters to tree
    root_nodes = [
        node_id_to_cluster[cluster.id] for cluster in root_clusters
    ]

    def add_node_to_tree(rich_tree, cluster_node, level=0):
        """"""Recursively add nodes to Rich tree with formatting.""""""
        # Color scheme based on level
        colors = [""bright_green"", ""bright_yellow"", ""bright_magenta"", ""bright_blue"", ""bright_red""]
        color = colors[level % len(colors)]
        
        # Calculate percentage
        percentage = (cluster_node.count / total_conversations * 100) if total_conversations > 0 else 0
        
        # Create progress bar representation
        bar_width = 15
        filled_width = int((cluster_node.count / total_conversations) * bar_width) if total_conversations > 0 else 0
        progress_bar = ""‚ñà"" * filled_width + ""‚ñë"" * (bar_width - filled_width)
        
        # Create node label with rich formatting
        label = f""[bold {color}]{cluster_node.name}[/] [dim]({cluster_node.count:,} conversations, {percentage:.1f}%)[/]""
        if hasattr(cluster_node, 'description') and cluster_node.description:
            short_desc = cluster_node.description[:80] + ""..."" if len(cluster_node.description) > 80 else cluster_node.description
            label += f""\n[italic dim]{short_desc}[/]""
        label += f""\n[dim]Progress: [{progress_bar}][/]""
        
        node = rich_tree.add(label)
        
        # Add children
        for child_id in cluster_node.children:
            child = node_id_to_cluster[child_id]
            add_node_to_tree(node, child, level + 1)

    # Add all root nodes to the tree
    for root_node in sorted(root_nodes, key=lambda x: x.count, reverse=True):
        add_node_to_tree(tree, root_node)

    # Only create tables if Rich components are available
    if Table is None or ROUNDED is None:
        console.print(tree)
        return

    # Create statistics table
    stats_table = Table(title=""üìà Cluster Statistics"", box=ROUNDED, title_style=""bold bright_cyan"")
    stats_table.add_column(""Metric"", style=""bold bright_yellow"")
    stats_table.add_column(""Value"", style=""bright_green"")
    
    stats_table.add_row(""üìä Total Clusters"", f""{len(clusters):,}"")
    stats_table.add_row(""üå≥ Root Clusters"", f""{len(root_nodes):,}"")
    stats_table.add_row(""üí¨ Total Conversations"", f""{total_conversations:,}"")
    stats_table.add_row(""üìè Avg per Root Cluster"", f""{total_conversations/len(root_nodes):.1f}"")
    
    # Create cluster size distribution table
    size_table = Table(title=""üìä Cluster Size Distribution"", box=ROUNDED, title_style=""bold bright_magenta"")
    size_table.add_column(""Size Range"", style=""bold bright_yellow"")
    size_table.add_column(""Count"", style=""bright_green"")
    size_table.add_column(""Percentage"", style=""bright_blue"")
    
    # Calculate size distribution for root clusters
    root_sizes = [node.count for node in root_nodes]
    size_ranges = [
        (""üî• Large (>100)"", lambda x: x > 100),
        (""üìà Medium (21-100)"", lambda x: 21 <= x <= 100),
        (""üìä Small (6-20)"", lambda x: 6 <= x <= 20),
        (""üîç Tiny (1-5)"", lambda x: 1 <= x <= 5),
    ]
    
    for range_name, condition in size_ranges:
        count = sum(1 for size in root_sizes if condition(size))
        percentage = (count / len(root_sizes) * 100) if root_sizes else 0
        size_table.add_row(range_name, f""{count}"", f""{percentage:.1f}%"")

    # Display everything
    console.print(""\n"")
    
    # Only use Panel and Align if they're available
    if Panel is not None and Align is not None and Text is not None:
        console.print(Panel(
            Align.center(Text(""üéØ RICH CLUSTER VISUALIZATION"", style=""bold bright_cyan"")),
            box=ROUNDED,
            style=""bright_cyan""
        ))
    else:
        console.print(""[bold bright_cyan]üéØ RICH CLUSTER VISUALIZATION[/]"")
        
    console.print(""\n"")
    console.print(tree)
    console.print(""\n"")
    
    # Display tables side by side if Table.grid is available
    if hasattr(Table, 'grid'):
        layout = Table.grid(padding=2)
        layout.add_column()
        layout.add_column()
        layout.add_row(stats_table, size_table)
        console.print(layout)
    else:
        # Fallback to printing tables separately
        console.print(stats_table)
        console.print(size_table)
        
    console.print(""\n"")
",kura/v1/visualization.py,,1,1.522997951276035e-08,"The method `visualise_clusters_rich` is a comprehensive function designed to visualize clusters using the Rich library. It includes detailed error handling, fallback mechanisms, and rich formatting features. The method is well-documented, indicating its importance and utility. It provides a visually appealing output and handles various scenarios, such as the absence of the Rich library or console. Given its functionality and the fact that it enhances user experience significantly, it is likely to be retained in the codebase."
survived,"    def test_duplicate_step_names_error(self):
        """"""Test that duplicate step names raise ValueError.""""""
        mock_learner = MockLearner()
        with pytest.raises(ValueError, match=""Step names must be unique""):
            LearnerPipeline(
                steps=[(""dup"", StandardScaler()), (""dup"", StandardScaler())],
                learner=mock_learner
            )
",tests/test_learner_pipeline.py,TestLearnerPipelineInit,1,1.6052280526088547e-09,"The method 'test_duplicate_step_names_error' is a unit test designed to ensure that the LearnerPipeline class raises a ValueError when duplicate step names are provided. This is a valid and necessary test to ensure the robustness and correctness of the LearnerPipeline class. Unit tests are crucial for maintaining code quality and preventing regressions, so this method is likely to be retained as part of the test suite."
survived,"        def numeric_arm_featurizer(X, action_tokens):
            """"""Add numeric arm features instead of string tokens.""""""
            n_contexts, n_features = X.shape
            n_arms = len(action_tokens)

            # Create 3D array: (n_contexts, n_features + 1, n_arms)
            result = np.zeros((n_contexts, n_features + 1, n_arms))

            for i, token in enumerate(action_tokens):
                result[:, :-1, i] = X  # Original features
                result[:, -1, i] = int(token.split(""_"")[1])  # Numeric arm ID

            return result
",tests/test_learner_pipeline.py,TestLearnerPipelineIntegration,1,6.69158608681505e-10,"The method 'numeric_arm_featurizer' is likely to survive because it provides a clear and useful functionality: transforming input data into a 3D array with additional numeric features based on action tokens. This transformation is essential for certain machine learning models that require numeric input features. The method is well-defined, with a clear purpose and implementation, making it a valuable utility in data preprocessing for machine learning tasks."
survived,"    def pull(
        self, X: Any, *, top_k: Optional[int] = None
    ) -> Union[List[TokenType], List[List[TokenType]]]:
        """"""Choose arm(s) and pull based on the context(s).

        Parameters
        ----------
        X : Any
            Input data to transform and use for choosing arms.
            Will be transformed through the pipeline steps to ContextType.
        top_k : int, optional
            Number of arms to select per context. If None (default),
            selects single best arm per context.

        Returns
        -------
        List[TokenType] or List[List[TokenType]]
            If top_k is None: List of action tokens (one per context)
            If top_k is int: List of lists of action tokens
        """"""
        X_transformed = self.transform(X)
        if top_k is None:
            return self._agent.pull(X_transformed)
        else:
            return self._agent.pull(X_transformed, top_k=top_k)
",bayesianbandits/pipelines/_agent.py,ContextualAgentPipeline,1,1.1032560311263802e-09,"The method 'pull' is well-documented and provides a clear functionality for selecting arms based on context. It includes parameters for input data and an optional parameter for selecting multiple arms, which adds flexibility. The method also handles different return types based on the 'top_k' parameter, making it versatile. There is no indication of redundancy or obsolescence, and it seems to be a core part of a decision-making or recommendation system. Therefore, it is likely to be retained."
survived,"    def test_basic_construction(self):
        """"""Test basic contextual pipeline construction.""""""
        arms = make_arms(range(3))
        agent = ContextualAgent(arms, ThompsonSampling())
        steps = [(""double"", FunctionTransformer(lambda x: x * 2))]

        pipeline = ContextualAgentPipeline(steps, agent)

        assert len(pipeline) == 1
        assert pipeline.named_steps[""double""] is not None
        assert pipeline._agent is agent
",tests/test_agent_pipeline.py,TestContextualAgentPipeline,1,4.363462233903899e-09,"The method 'test_basic_construction' is a unit test for the 'ContextualAgentPipeline' class, ensuring that the pipeline is constructed correctly with the given steps and agent. Unit tests are crucial for verifying the functionality of code and are typically retained to ensure code reliability and correctness. Therefore, it is likely to be retained."
survived,"    def test_validate_duplicate_names(self):
        """"""Test validation with duplicate step names.""""""
        steps = [
            (""transform"", FunctionTransformer()),
            (""transform"", FunctionTransformer()),  # Duplicate
        ]
        with pytest.raises(ValueError, match=""Step names must be unique""):
            _validate_steps(steps)
",tests/test_agent_pipeline.py,TestValidateSteps,1,1.522997951276035e-08,"The method 'test_validate_duplicate_names' is a unit test designed to ensure that the '_validate_steps' function correctly raises a ValueError when duplicate step names are provided. This is a common and necessary test to ensure the robustness of the '_validate_steps' function, which likely plays a critical role in a larger system by ensuring that each step in a process has a unique identifier. Such tests are essential for maintaining code quality and preventing bugs related to duplicate identifiers in workflows or pipelines. Therefore, this method is likely to be retained as it serves an important purpose in the codebase."
survived,"    def test_steps_property(self):
        """"""Test steps property.""""""
        scaler = StandardScaler()
        learner = MockLearner()
        pipeline = LearnerPipeline(steps=[(""scale"", scaler)], learner=learner)

        steps = pipeline.steps
        assert len(steps) == 1  # Only transformer steps
        assert steps[0] == (""scale"", scaler)
",tests/test_learner_pipeline.py,TestLearnerPipelineProperties,1,1.955568070542584e-08,"The method 'test_steps_property' is a unit test designed to verify the functionality of the 'steps' property in a 'LearnerPipeline' class. Unit tests are crucial for ensuring code reliability and correctness, especially in complex systems involving machine learning pipelines. This test checks that the 'steps' property correctly returns the list of steps in the pipeline, which is fundamental for debugging and understanding the pipeline's structure. Therefore, this method is likely to be retained as it serves an important role in maintaining code quality."
survived,"    def rng(self):
        """"""Get the random generator from the wrapped agent.""""""
        return self._agent.rng
",bayesianbandits/pipelines/_agent.py,ContextualAgentPipeline,1,2.4616969512093895e-10,"The method 'rng' is a simple getter method that returns the random generator from a wrapped agent. Such methods are typically retained because they provide a clear and encapsulated way to access internal components of an object, promoting good object-oriented design practices. Unless there is a significant refactor or change in design that makes this method redundant, it is likely to survive."
survived,"    def __getitem__(self, ind: Union[int, str]) -> Any:
        """"""Get a step by index or name.""""""
        if isinstance(ind, str):
            return self.named_steps[ind]
        return self.steps[ind]",bayesianbandits/pipelines/_learner.py,LearnerPipeline,1,1.522997951276035e-08,"The method `__getitem__` is a common and useful method in Python classes that allows instances of the class to use the indexing operator `[]`. This method is particularly useful in classes that represent collections or sequences, as it provides a way to access elements by index or key. The implementation here supports both integer and string indices, making it versatile for accessing elements by position or by name. This functionality is often essential in custom data structures or classes that mimic the behavior of lists or dictionaries. Therefore, it is unlikely to be deleted as it provides important functionality."
survived,"    def arm(self, token: TokenType):
        """"""Get an arm by its action token.""""""
        return self._agent.arm(token)
",bayesianbandits/pipelines/_agent.py,NonContextualAgentPipeline,0,0.9953904270578577,"The method 'arm' is a simple wrapper around another method call, 'self._agent.arm(token)'. It doesn't add any additional functionality or logic, which might make it redundant if 'self._agent.arm' is directly accessible. However, if 'self._agent.arm' is not directly accessible or if this method is part of a larger interface that requires this method signature, it might be necessary. Without more context, it's difficult to definitively say, but such simple pass-through methods are often candidates for deletion unless they serve a specific purpose in the code structure."
survived,"    def named_steps(self) -> Dict[str, Any]:
        """"""Access pipeline steps by name.""""""
        return dict(self.steps)
",bayesianbandits/pipelines/_agent.py,ContextualAgentPipeline,1,3.3982678079468468e-09,"The method 'named_steps' is a simple utility function that converts the 'steps' attribute of a pipeline into a dictionary, allowing access to each step by its name. This is a useful feature for users who want to interact with or modify specific steps in a pipeline. Given its utility and simplicity, it is likely to be retained in the codebase."
survived,"    def __getitem__(self, ind: Union[int, str]) -> Any:
        """"""Get a step by index or name.""""""
        if isinstance(ind, str):
            return self.named_steps[ind]
        return self.steps[ind]
",bayesianbandits/pipelines/_agent.py,ContextualAgentPipeline,1,4.363462233903899e-09,"The method `__getitem__` is a standard way to allow objects to use the indexing syntax (e.g., obj[index]) in Python. This method is useful for classes that represent collections or sequences, as it allows users to access elements by index or key. The implementation here supports both integer and string indices, which makes it versatile for accessing elements by position or by name. This kind of functionality is commonly needed and appreciated in custom classes that manage collections of items. Therefore, it is likely to be retained."
survived,"    def test_decay(self):
        """"""Test decay method.""""""
        arms = make_arms(range(3))
        agent = Agent(arms, ThompsonSampling())
        steps = []

        pipeline = NonContextualAgentPipeline(steps, agent)

        # Should not raise
        pipeline.decay(decay_rate=0.5)
",tests/test_agent_pipeline.py,TestNonContextualAgentPipeline,1,1.444980317078884e-07,"The method 'test_decay' is a unit test for the 'decay' method of the 'NonContextualAgentPipeline' class. It is a simple test that ensures the 'decay' method can be called without raising an exception. This kind of test is useful for verifying that the method can handle basic input without errors, which is a fundamental aspect of testing. Since it serves a purpose in ensuring the stability and correctness of the 'decay' method, it is likely to be retained in the codebase."
survived,"    def arm(self, token: TokenType):
        """"""Get an arm by its action token.""""""
        return self._agent.arm(token)
",bayesianbandits/pipelines/_agent.py,ContextualAgentPipeline,1,1.6052280526088547e-09,"The method 'arm' is a simple wrapper around another method call, 'self._agent.arm(token)'. It is likely part of a larger class that interacts with an agent object. The method is concise, has a clear purpose, and is likely used to encapsulate the interaction with the '_agent' object, which is a common practice in object-oriented programming to maintain encapsulation and abstraction. Unless there is a significant change in the design that makes this method redundant or unnecessary, it is likely to survive."
survived,"    def _generate_testing_strategy(self, feature_request: str, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """"""Generate testing strategy for the feature.""""""
        return {""unit_tests"": True, ""integration_tests"": True, ""coverage_target"": ""90%""}
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,1,9.736200303530205e-10,"The method '_generate_testing_strategy' is likely to survive because it provides a clear and useful functionality by generating a testing strategy for a given feature request. It returns a dictionary with key testing components such as unit tests, integration tests, and a coverage target, which are essential for ensuring software quality. The method is straightforward, has a clear purpose, and aligns with common software development practices, making it a valuable part of the codebase."
survived,"    def _generate_implementation_steps(self, feature_request: str, analysis: Dict[str, Any]) -> List[str]:
        """"""Generate step-by-step implementation plan.""""""
        return [f""Step 1: Analyze {feature_request}"", ""Step 2: Implement"", ""Step 3: Test""]
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,1,7.194132978569833e-09,"The method '_generate_implementation_steps' is likely to survive because it provides a clear and structured way to generate implementation steps for a feature request. It takes in a feature request and an analysis dictionary, which suggests it is designed to be flexible and adaptable to different inputs. The method returns a list of steps, which is a common and useful pattern in software development for planning and execution. Additionally, the method is simple and straightforward, making it easy to understand and maintain."
survived,"    def _analyze_api_docs(self, project_path: str) -> Dict[str, Any]:
        """"""Analyze API documentation patterns.""""""
        return {""format"": ""openapi"", ""coverage"": ""partial""}
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,1,0.0013250222488381364,"The method `_analyze_api_docs` is a private method (indicated by the underscore prefix) that seems to be part of a larger system for analyzing API documentation. It returns a dictionary with hardcoded values, which suggests it might be a placeholder or a simple utility function. However, without more context on its usage or the overall system, it's difficult to determine its criticality. If the system evolves to require more dynamic analysis or if this functionality is deemed unnecessary, it might be refactored or removed. However, given its current state, it seems to serve a basic purpose and could be retained for simplicity or as a starting point for further development."
survived,"    def _analyze_test_naming(self, project_path: str) -> Dict[str, Any]:
        """"""Analyze test naming conventions.""""""
        return {""pattern"": ""test_*"", ""style"": ""descriptive""}
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,1,6.69158608681505e-10,"The method `_analyze_test_naming` is a utility function that analyzes test naming conventions in a project. It returns a dictionary with a pattern and style, which can be useful for ensuring consistency in test naming across a project. This kind of functionality is often needed in software development to maintain code quality and readability. Since it provides a specific utility that can be reused and is not overly complex, it is likely to be retained in the codebase."
survived,"    def __init__(self, project_path: str, llm: str = ""gpt-4o-mini""):
        self.project_path = project_path
        self.llm = llm
        self.context_data = {}
        self.setup_agents()
",examples/python/concepts/context-engineering-workflow.py,ContextEngineeringWorkflow,1,7.73442280641062e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes and setting up necessary configurations. The presence of parameters like 'project_path' and 'llm' suggests that this constructor is designed to initialize an object with specific settings, which is a common and necessary practice in software development. Therefore, it is unlikely that this method will be deleted as it serves a critical role in the class's functionality."
survived,"    def _format_implementation_patterns(self, code_patterns: Dict[str, Any]) -> str:
        """"""Format implementation patterns for context document.""""""
        return ""Follow existing class and function patterns identified in codebase analysis.""
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,1,2.646573631904765e-09,"The method '_format_implementation_patterns' is a private method (indicated by the underscore prefix) that formats implementation patterns for a context document. It takes a dictionary as input and returns a string. The method is simple and serves a specific purpose, which is likely useful in the context of the codebase it belongs to. There is no indication that it is redundant or unnecessary, so it is likely to be retained."
survived,"def test_basic_instantiation():
    """"""Test basic ContextAgent instantiation.""""""
    print(""\nüß™ Testing ContextAgent Instantiation..."")
    
    try:
        from praisonaiagents import ContextAgent, create_context_agent
        
        # Test direct instantiation
        context_agent = ContextAgent()
        print(""‚úÖ Successfully created ContextAgent with default parameters"")
        
        # Test with custom parameters
        custom_agent = ContextAgent(
            name=""Test Context Engineer"",
            role=""Test Role"",
            goal=""Test Goal"",
            llm=""gpt-4o-mini""
        )
        print(""‚úÖ Successfully created ContextAgent with custom parameters"")
        
        # Test factory function
        factory_agent = create_context_agent(llm=""gpt-4o-mini"")
        print(""‚úÖ Successfully created ContextAgent using factory function"")
        
        return True, [context_agent, custom_agent, factory_agent]
        
    except Exception as e:
        print(f""‚ùå Instantiation failed: {e}"")
        return False, []
",test_context_agent.py,,1,2.8453347280241004e-08,"The method `test_basic_instantiation` is a unit test function that verifies the instantiation of the `ContextAgent` class and its factory function. It is a crucial part of testing to ensure that objects can be created correctly with both default and custom parameters. This kind of test is fundamental for maintaining code quality and reliability, especially in a library or framework that provides agent-based functionalities. Since it serves an important purpose in the development and testing process, it is likely to be retained."
survived,"    def _determine_validation_method(self, criterion: str) -> str:
        """"""Determine appropriate validation method for a criterion.""""""
        return ""automated_test""
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,0,0.9999756997690634,"The method `_determine_validation_method` is a simple utility function that returns a hardcoded string ""automated_test"" based on the input criterion. It is likely part of a larger system where different criteria might require different validation methods. However, since it currently returns a constant value, it might be considered for deletion if it doesn't add any dynamic functionality or if the system doesn't plan to expand this logic. If the system is expected to evolve to handle multiple criteria with different validation methods, the method might be retained for future extensibility. Without additional context, it seems more likely to be deleted due to its current lack of dynamic behavior."
survived,"    def __init__(
        self,
        name: Optional[str] = None,
        role: Optional[str] = None,
        goal: Optional[str] = None,
        backstory: Optional[str] = None,
        instructions: Optional[str] = None,
        llm: Optional[Union[str, Any]] = None,
        tools: Optional[List[Any]] = None,
        **kwargs
    ):
        # Set Context Engineering defaults if not provided
        if name is None:
            name = ""Context Engineer""
        if role is None:
            role = ""Context Engineering Specialist""
        if goal is None:
            goal = ""Generate comprehensive context for AI coding assistants to enable first-try implementation success""
        if backstory is None:
            backstory = """"""You are an expert in Context Engineering - the discipline of engineering context 
            for AI coding assistants. You understand that context is 10x better than prompt engineering 
            and 100x better than vibe coding. Your expertise lies in analyzing codebases, extracting patterns, 
            and creating comprehensive context that enables AI assistants to implement features correctly 
            on the first attempt.""""""
        if instructions is None:
            instructions = """"""As a Context Engineering specialist, your primary responsibilities are:
            
            1. ANALYZE: Examine codebases to understand patterns, conventions, and architecture
            2. EXTRACT: Identify key patterns, best practices, and implementation approaches
            3. CONTEXTUALIZE: Generate comprehensive context documents with all necessary information
            4. VALIDATE: Create executable validation criteria and success metrics
            5. ENHANCE: Enrich prompts with comprehensive contextual information
            
            Always focus on providing complete context rather than clever wording. Include documentation,
            examples, patterns, constraints, and validation criteria in your context generation.""""""

        # Add Context Engineering specific tools if none provided
        if tools is None:
            tools = self._get_default_context_tools()

        # Initialize parent Agent class
        super().__init__(
            name=name,
            role=role,
            goal=goal,
            backstory=backstory,
            instructions=instructions,
            llm=llm,
            tools=tools,
            **kwargs
        )
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,1,7.3382086014706e-07,"The method is a constructor (__init__) for a class, which is a fundamental part of object-oriented programming. It is responsible for initializing the attributes of an instance of the class. The method sets default values for several parameters if they are not provided, ensuring that the object is always initialized with a complete set of attributes. This is a common and necessary pattern in class design, especially when dealing with optional parameters and defaults. Therefore, it is unlikely to be deleted as it is essential for the proper functioning of the class."
survived,"def run_example_workflow():
    """"""Run an example Context Engineering workflow.""""""
    
    # Setup workflow with current project
    project_path = str(project_root)
    workflow = ContextEngineeringWorkflow(
        project_path=project_path,
        llm=""gpt-4o-mini""
    )
    
    # Example feature request
    feature_request = """"""
    Implement a real-time notification system that:
    - Sends notifications via WebSocket connections
    - Supports different notification types (info, warning, error)
    - Persists notifications in database for offline users
    - Includes user preference management for notification settings
    - Provides REST API for notification management
    """"""
    
    print(""üéØ Running Example Context Engineering Workflow"")
    print(""="" * 60)
    
    try:
        # Execute the complete workflow
        results = workflow.run_context_engineering_workflow(feature_request)
        
        print(""\nüéâ Context Engineering Workflow Completed Successfully!"")
        print(""="" * 60)
        
        print(f""\nüìä Workflow Summary:"")
        print(f""   ‚Ä¢ Feature: Real-time notification system"")
        print(f""   ‚Ä¢ Context generated: ‚úÖ Complete"")
        print(f""   ‚Ä¢ Architecture designed: ‚úÖ With context"")
        print(f""   ‚Ä¢ Implementation: ‚úÖ Context-guided"")
        print(f""   ‚Ä¢ Quality validation: ‚úÖ Context-criteria"")
        
        print(f""\nüîß Context Engineering Data:"")
        context_data = results[""context_engineering""]
        print(f""   ‚Ä¢ Codebase analysis: {len(str(context_data['codebase_analysis']))} chars"")
        print(f""   ‚Ä¢ Context document: {len(context_data['context_document'])} chars"") 
        print(f""   ‚Ä¢ Validation framework: {len(context_data['validation_framework']['validation_steps'])} steps"")
        print(f""   ‚Ä¢ Implementation blueprint: {len(context_data['implementation_blueprint']['implementation_steps'])} steps"")
        print(f""   ‚Ä¢ PRP: {len(context_data['prp'])} chars"")
        
        return results
        
    except Exception as e:
        print(f""\n‚ùå Error in workflow execution: {e}"")
        print(""   Note: This is a demonstration - actual execution requires proper environment setup"")
        return None
",examples/python/concepts/context-engineering-workflow.py,,1,1.8553915987649156e-07,"The method `run_example_workflow` is a demonstration of a Context Engineering workflow, which is a specific and potentially useful example for users to understand how to implement a real-time notification system using a particular framework. It includes detailed steps and error handling, making it a valuable resource for learning and reference. Such example methods are often retained in codebases to aid developers in understanding and utilizing the framework effectively."
survived,"    async def test_ai_text_summarizer_real_llm_call_stats(self):
        """"""Test AITextSummarizer with real LLM call mocking to verify llm_call_count.""""""
        from unittest.mock import AsyncMock, MagicMock, patch

        import backend.blocks.llm as llm

        block = llm.AITextSummarizerBlock()

        # Mock the actual LLM call instead of the llm_call method
        call_count = 0

        async def mock_create(*args, **kwargs):
            nonlocal call_count
            call_count += 1

            mock_response = MagicMock()
            # Return different responses for chunk summary vs final summary
            if call_count == 1:
                mock_response.choices = [
                    MagicMock(
                        message=MagicMock(
                            content='{""summary"": ""Test chunk summary""}', tool_calls=None
                        )
                    )
                ]
            else:
                mock_response.choices = [
                    MagicMock(
                        message=MagicMock(
                            content='{""final_summary"": ""Test final summary""}',
                            tool_calls=None,
                        )
                    )
                ]
            mock_response.usage = MagicMock(prompt_tokens=50, completion_tokens=30)
            return mock_response

        with patch(""openai.AsyncOpenAI"") as mock_openai:
            mock_client = AsyncMock()
            mock_openai.return_value = mock_client
            mock_client.chat.completions.create = mock_create

            # Test with very short text (should only need 1 chunk + 1 final summary)
            input_data = llm.AITextSummarizerBlock.Input(
                text=""This is a short text."",
                model=llm.LlmModel.GPT4O,
                credentials=llm.TEST_CREDENTIALS_INPUT,  # type: ignore
                max_tokens=1000,  # Large enough to avoid chunking
            )

            outputs = {}
            async for output_name, output_data in block.run(
                input_data, credentials=llm.TEST_CREDENTIALS
            ):
                outputs[output_name] = output_data

            print(f""Actual calls made: {call_count}"")
            print(f""Block stats: {block.execution_stats}"")
            print(f""LLM call count: {block.execution_stats.llm_call_count}"")

            # Should have made 2 calls: 1 for chunk summary + 1 for final summary
            assert block.execution_stats.llm_call_count >= 1
            assert block.execution_stats.input_token_count > 0
            assert block.execution_stats.output_token_count > 0
",autogpt_platform/backend/backend/blocks/test/test_llm.py,TestLLMStatsTracking,1,1.1253518384332553e-07,"The method is a test function for verifying the behavior of an AI text summarizer block. It uses mocking to simulate interactions with an external API, which is a common practice in unit testing to ensure that the code behaves as expected without making actual API calls. This kind of test is crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is unlikely to be deleted as it serves an important role in the development and maintenance process."
survived,"    async def test_ai_list_generator_with_retries(self):
        """"""Test that AIListGeneratorBlock correctly tracks stats with retries.""""""
        import backend.blocks.llm as llm

        block = llm.AIListGeneratorBlock()

        # Counter to track calls
        call_count = 0

        async def mock_llm_call(input_data, credentials):
            nonlocal call_count
            call_count += 1

            # Update stats
            if hasattr(block, ""execution_stats"") and block.execution_stats:
                block.execution_stats.input_token_count += 40
                block.execution_stats.output_token_count += 20
                block.execution_stats.llm_call_count += 1
            else:
                block.execution_stats = NodeExecutionStats(
                    input_token_count=40,
                    output_token_count=20,
                    llm_call_count=1,
                )

            if call_count == 1:
                # First call returns invalid format
                return {""response"": ""not a valid list""}
            else:
                # Second call returns valid list
                return {""response"": ""['item1', 'item2', 'item3']""}

        block.llm_call = mock_llm_call  # type: ignore

        # Run the block
        input_data = llm.AIListGeneratorBlock.Input(
            focus=""test items"",
            model=llm.LlmModel.GPT4O,
            credentials=llm.TEST_CREDENTIALS_INPUT,  # type: ignore
            max_retries=3,
        )

        outputs = {}
        async for output_name, output_data in block.run(
            input_data, credentials=llm.TEST_CREDENTIALS
        ):
            outputs[output_name] = output_data

        # Check stats - should have 2 calls
        assert call_count == 2
        assert block.execution_stats.input_token_count == 80  # 40 * 2
        assert block.execution_stats.output_token_count == 40  # 20 * 2
        assert block.execution_stats.llm_call_count == 2

        # Check output
        assert outputs[""generated_list""] == [""item1"", ""item2"", ""item3""]
",autogpt_platform/backend/backend/blocks/test/test_llm.py,TestLLMStatsTracking,1,1.8189616842444243e-09,"The method is a well-structured test function that verifies the behavior of the AIListGeneratorBlock with retries. It includes a mock function to simulate LLM calls, checks for correct statistics tracking, and validates the output. This kind of test is crucial for ensuring the reliability and correctness of the AIListGeneratorBlock, especially in handling retries and updating execution statistics. Therefore, it is likely to be retained as part of the test suite."
survived,"    async def test_stats_initialization(self):
        """"""Test that blocks properly initialize stats when not present.""""""
        import backend.blocks.llm as llm

        block = llm.AIStructuredResponseGeneratorBlock()

        # Initially stats should be initialized with zeros
        assert hasattr(block, ""execution_stats"")
        assert block.execution_stats.llm_call_count == 0

        # Mock llm_call
        async def mock_llm_call(*args, **kwargs):
            return llm.LLMResponse(
                raw_response="""",
                prompt=[],
                response='{""result"": ""test""}',
                tool_calls=None,
                prompt_tokens=10,
                completion_tokens=20,
                reasoning=None,
            )

        block.llm_call = mock_llm_call  # type: ignore

        # Run the block
        input_data = llm.AIStructuredResponseGeneratorBlock.Input(
            prompt=""Test"",
            expected_format={""result"": ""desc""},
            model=llm.LlmModel.GPT4O,
            credentials=llm.TEST_CREDENTIALS_INPUT,  # type: ignore
        )

        # Run the block
        outputs = {}
        async for output_name, output_data in block.run(
            input_data, credentials=llm.TEST_CREDENTIALS
        ):
            outputs[output_name] = output_data

        # Block finished - now grab and assert stats
        assert block.execution_stats is not None
        assert block.execution_stats.input_token_count == 10
        assert block.execution_stats.output_token_count == 20
        assert block.execution_stats.llm_call_count == 1  # Should have exactly 1 call

        # Check output
        assert ""response"" in outputs
        assert outputs[""response""] == {""result"": ""test""}",autogpt_platform/backend/backend/blocks/test/test_llm.py,TestLLMStatsTracking,1,1.8553915987649156e-07,"The method is a well-structured test case for verifying the initialization and updating of execution statistics in a block. It includes assertions to ensure the block's behavior is as expected, which is crucial for maintaining code quality and reliability. Test methods like this are typically retained to ensure ongoing functionality and to catch regressions in future code changes."
survived,"    def _message(self) -> str:
        return f""Missing parameters in docstring: {self.params}""",dev/clint/src/clint/rules/missing_docstring_param.py,MissingDocstringParam,1,3.581747929000289e-10,"The method '_message' is a private method (indicated by the underscore) that returns a formatted string. It is likely used internally within a class to generate a specific error or log message when parameters are missing in a docstring. Such utility methods are common in codebases to maintain clean and reusable code. Since it serves a specific purpose and is not exposed as part of the public API, it is unlikely to be deleted unless the functionality it supports is no longer needed. Therefore, it is predicted to survive."
survived,"    def check(node: ast.Call, resolver: Resolver) -> bool:
        """"""
        Returns True if the call is ThreadPoolExecutor() without a thread_name_prefix parameter.
        """"""
        return (
            (resolved := resolver.resolve(node))
            and resolved == [""concurrent"", ""futures"", ""ThreadPoolExecutor""]
            and not any(keyword.arg == ""thread_name_prefix"" for keyword in node.keywords)
        )",dev/clint/src/clint/rules/thread_pool_executor_without_thread_name_prefix.py,ThreadPoolExecutorWithoutThreadNamePrefix,1,4.363462233903899e-09,"The method 'check' is a utility function that checks if a specific condition is met in an abstract syntax tree (AST) node. It is a concise and clear implementation that serves a specific purpose: identifying calls to 'ThreadPoolExecutor' without a 'thread_name_prefix' parameter. Such utility functions are often useful in static analysis tools, linters, or code quality checks. Given its clear purpose and utility, it is likely to be retained in the codebase unless the requirements change significantly or the method is refactored for broader functionality."
survived,"    def __init__(self, *, full_name: str, allowlist: list[str]) -> None:
        self.full_name = full_name
        self.allowlist = allowlist
",dev/clint/src/clint/rules/typing_extensions.py,TypingExtensions,1,1.6052280526088547e-09,"The method is a constructor for a class, which is a fundamental part of object-oriented programming in Python. It initializes the instance variables 'full_name' and 'allowlist', which are likely essential for the functionality of the class. Constructors are rarely deleted unless the class itself is being removed or significantly refactored, which is not indicated here. Therefore, it is likely to survive."
survived,"    def __init_subclass__(cls, **kwargs):
        super().__init_subclass__(**kwargs)
        # Only generate ID for concrete classes
        if not inspect.isabstract(cls):
            id_ = next(cls._id_counter)
            cls._generated_id = f""MLF{id_:04d}""
",dev/clint/src/clint/rules/base.py,Rule,1,2.1024340680345882e-07,"The method `__init_subclass__` is a special method in Python that is used to customize the behavior of class creation. It is particularly useful for metaprogramming, where you want to automatically modify or add attributes to subclasses when they are defined. In this code, the method is used to generate a unique ID for each concrete subclass, which can be a valuable feature for tracking or identifying instances of subclasses. This kind of functionality is often useful in frameworks or libraries that deal with a hierarchy of classes, such as in machine learning frameworks or ORM systems. Therefore, the method is likely to be retained as it provides a useful and specific functionality that enhances the class creation process."
survived,"    def _is_optional(ann: ast.AST) -> bool:
        """"""
        Returns True if `ann` looks like `Optional[...]`.
        """"""
        return (
            isinstance(ann, ast.Subscript)
            and isinstance(ann.value, ast.Name)
            and ann.value.id == ""Optional""
        )
",dev/clint/src/clint/rules/implicit_optional.py,ImplicitOptional,1,5.60279640614594e-09,"The method `_is_optional` is a utility function that checks if a given AST node represents an `Optional` type. This is a common requirement when analyzing or transforming Python code using the AST module, especially in the context of type hinting and static analysis. The function is simple, clear, and serves a specific purpose, making it likely to be useful in various scenarios where type annotations are processed. Therefore, it is likely to be retained in the codebase."
survived,"    def message(self) -> str:
        return self._message()
",dev/clint/src/clint/rules/base.py,Rule,1,3.3982678079468468e-09,"The method 'message' is a simple wrapper around another method '_message'. Without additional context, it's difficult to determine its utility. However, such methods are often used to provide a public interface to a private method or to allow for future extensions or modifications without changing the interface. This pattern is common and generally considered good practice for encapsulation. Therefore, unless there is a specific reason to remove it, such as redundancy or a change in design, it is likely to survive."
survived,"    def _message(self) -> str:
        return (
            ""Invalid usage of `@experimental` decorator. It must be used with a `version` ""
            ""argument that is a valid semantic version string.""
        )
",dev/clint/src/clint/rules/invalid_experimental_decorator.py,InvalidExperimentalDecorator,1,2.5109990926928157e-08,"The method '_message' is a private method (indicated by the underscore prefix) that returns a specific error message related to the usage of an '@experimental' decorator. This method is likely part of a larger class or module that deals with experimental features and their versioning. Such methods are typically kept to provide clear error messages and improve code maintainability by centralizing message strings. Therefore, it is unlikely to be deleted unless the entire functionality it supports is removed or refactored."
survived,"    def _message(self) -> str:
        return ""Do not delete `os.environ` in test directly. Use `monkeypatch.delenv` (https://docs.pytest.org/en/stable/reference/reference.html#pytest.MonkeyPatch.delenv).""
",dev/clint/src/clint/rules/os_environ_delete_in_test.py,OsEnvironDeleteInTest,1,2.5109990926928157e-08,"The method _message is a private method (indicated by the underscore) that returns a string message. This message provides guidance on best practices for testing, specifically advising against directly deleting environment variables and suggesting the use of a specific pytest utility instead. This kind of method is useful for maintaining code quality and ensuring that developers follow recommended practices. Since it serves an educational purpose and helps prevent common mistakes, it is likely to be retained in the codebase."
survived,"    def _message(self) -> str:
        return (
            ""@pytest.mark.repeat decorator should not be committed. ""
            ""This decorator is meant for local testing only to check for flaky tests.""
        )
",dev/clint/src/clint/rules/pytest_mark_repeat.py,PytestMarkRepeat,1,3.3982678079468468e-09,"The method _message is a private method (indicated by the underscore) that returns a string message. It is likely used internally within a class to provide a specific warning or information about the use of the @pytest.mark.repeat decorator. Since it serves a clear purpose of conveying a specific message and does not have any apparent issues or redundancies, it is likely to be retained in the codebase."
survived,"    def test_OpImpl_with_args(self):
        mod = self.compile(
        """"""
        from operator import OpImpl, OpArg

        def bar(x: i32) -> i32:
            return x * 2

        @blue
        def foo() -> OpImpl:
            # Create an OpImpl with an argument list
            arg = OpArg('blue', i32, 42)
            return OpImpl(bar, [arg])
        """""")
        w_opimpl = mod.foo(unwrap=False)
        assert isinstance(w_opimpl, W_OpImpl)
        assert not w_opimpl.is_simple()
        assert w_opimpl._args_wop is not None
        assert len(w_opimpl._args_wop) == 1

        # Check the OpArg stored in the arguments list
        wop = w_opimpl._args_wop[0]
        assert isinstance(wop, W_OpArg)
        assert wop.color == 'blue'
        assert wop.w_static_type is B.w_i32
        assert wop.is_blue()
        assert wop._w_val is not None
        assert self.vm.unwrap_i32(wop._w_val) == 42
",spy/tests/compiler/test_opimpl.py,TestOpImpl,1,1.3440409770490404e-08,"The method `test_OpImpl_with_args` is a unit test that verifies the functionality of creating an `OpImpl` object with arguments and checks various properties of the created object. Unit tests are crucial for ensuring code correctness and are typically retained in the codebase to prevent regressions. The method is well-structured, with clear assertions that validate the expected behavior of the `OpImpl` and `OpArg` classes. There is no indication that this test is redundant or obsolete, and it serves a clear purpose in the testing suite."
survived,"    def w_meta_GETATTR(vm: 'SPyVM', wop_cls: W_OpArg, wop_attr: W_OpArg) -> 'W_OpImpl':
        """"""
        Handle class attribute lookups on OpImpl, like OpImpl.NULL
        """"""
        from spy.vm.str import W_Str

        attr_name = wop_attr.blue_unwrap_str(vm)

        if attr_name == 'NULL':
            # Return the NULL instance directly
            @builtin_func(W_OpImpl._w.fqn, 'get_null')
            def w_get_null(vm: 'SPyVM', w_cls: W_Type) -> W_OpImpl:
                return W_OpImpl.NULL

            return W_OpImpl(w_get_null, [wop_cls])

        return W_OpImpl.NULL
",spy/vm/opimpl.py,W_OpImpl,1,1.1253518384332553e-07,"The method `w_meta_GETATTR` is a specialized function for handling class attribute lookups, specifically for the `OpImpl` class. It includes a mechanism to return a special `NULL` instance when the attribute name is 'NULL'. This kind of functionality is often crucial in systems that require dynamic attribute handling or have special cases for certain attributes. The method is well-defined, has a clear purpose, and is likely part of a larger framework or system that relies on this behavior. Therefore, it is unlikely to be deleted as it serves a specific and necessary role."
survived,"def make_oparg_list(args_wop: list[W_OpArg]) -> W_OpArgList:
   return W_List(w_oparglist_type, args_wop)  # type: ignore",spy/vm/list.py,,1,4.6911638017642294e-08,"The method 'make_oparg_list' is a simple utility function that converts a list of 'W_OpArg' objects into a 'W_OpArgList'. It is likely part of a larger codebase dealing with operations or arguments in a specific context. The function is straightforward and serves a clear purpose, making it unlikely to be deleted unless the entire system or approach it supports is refactored or deprecated. Additionally, the use of 'type: ignore' suggests that the developer is aware of a type-checking issue but has chosen to bypass it, indicating the function's importance despite the type warning."
survived,"    def label(self, curie: CURIE, lang: Optional[LANGUAGE_TAG] = None) -> Optional[str]:
        """"""
        Fetch the label for a CURIE from OLS.
        
        :param curie: The CURIE to fetch the label for
        :param lang: Optional language tag (not currently supported by this implementation)
        :return: The label for the CURIE, or None if not found
        """"""
        if curie in self.label_cache:
            return self.label_cache[curie]
        
        try:
            ontology = self.focus_ontology
            iri = self.curie_to_uri(curie)
            term = self.client.get_term(ontology=ontology, iri=iri)
            if term and ""label"" in term:
                self.label_cache[curie] = term[""label""]
                return term[""label""]
        except Exception as e:
            pass
        
        return None
",src/oaklib/implementations/ols/ols_implementation.py,BaseOlsImplementation,1,1.6052280526088547e-09,"The method 'label' is likely to survive because it performs a specific and useful function: fetching a label for a CURIE from an ontology service (OLS). It includes caching for efficiency, error handling, and is part of a larger system that interacts with ontologies. The method is well-documented, indicating it is maintained and understood by developers. Additionally, it provides a clear interface for fetching labels, which is a common requirement in systems dealing with ontologies and semantic data."
survived,"    def __init__(
        self,
        func: Callable,
        signature: tuple[list[tuple], str],
        **kwargs,
    ):
        self.signature = signature
        super().__init__(func, **kwargs)
",numbagg/decorators.py,ndmatrix,1,8.76424914819242e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting up initial state. The presence of a constructor is crucial for the functionality of the class, especially when it involves setting up important attributes like 'signature' in this case. Therefore, it is unlikely to be deleted unless the entire class is being refactored or removed, which is not indicated here."
survived,"    def test_anticorrelation(self):
        # Test negative correlation
        data = np.array([[1, 2, 3, 4], [4, 3, 2, 1]], dtype=np.float64)
        result = nancorrmatrix(data)

        # Perfect negative correlation
        expected = np.array([[1.0, -1.0], [-1.0, 1.0]])
        assert_allclose(result, expected, rtol=1e-10)
",numbagg/test/test_nancorrmatrix.py,TestNanCorrMatrix,1,1.9171715133907573e-10,"The method 'test_anticorrelation' is a unit test designed to verify the functionality of the 'nancorrmatrix' function, specifically checking for perfect negative correlation. Unit tests are crucial for ensuring code reliability and correctness, especially in mathematical computations. The presence of this test helps maintain the integrity of the correlation matrix calculations, making it unlikely to be deleted unless the 'nancorrmatrix' function itself is removed or significantly altered. Therefore, the method is likely to survive."
survived,"    def gufunc(self, *, target):
        vectorize = numba.guvectorize(
            *self.signature,
            nopython=True,
            target=target,
            cache=self.cache,
            fastmath=_FASTMATH,
        )
        return vectorize(self.func)
",numbagg/decorators.py,ndmatrix,1,1.493094675974231e-10,"The method 'gufunc' is a utility function that wraps the 'numba.guvectorize' function to create a generalized universal function (gufunc) with specific parameters. It is a specialized function that is likely used in a context where performance optimization is critical, such as numerical computations. The method is concise, uses a well-known library (Numba), and provides a clear purpose by allowing the user to specify a target for the vectorization. Given these factors, it is likely to be useful and relevant in its context, suggesting it will survive."
survived,"    def test_zero_variance(self):
        # Test with zero variance (constant) variables
        data = np.array([[1, 1, 1, 1], [2, 2, 2, 2], [1, 2, 3, 4]], dtype=np.float64)
        result = nancorrmatrix(data)

        # Correlation with constant variables should be NaN
        assert result[2, 2] == 1.0  # Variable with itself
        assert np.isnan(result[0, 1])  # Two constants
        assert np.isnan(result[0, 2])  # Constant with non-constant
        assert np.isnan(result[1, 2])  # Constant with non-constant
",numbagg/test/test_nancorrmatrix.py,TestNanCorrMatrix,1,5.60279640614594e-09,"The method 'test_zero_variance' is a unit test designed to verify the behavior of the 'nancorrmatrix' function when dealing with zero variance (constant) variables. This is a common edge case in statistical computations, and ensuring that the function handles it correctly is important for robustness. The test checks that the correlation of constant variables with any other variable results in NaN, which is the expected behavior. Since this test is crucial for validating the correctness of the 'nancorrmatrix' function, it is likely to be retained."
survived,"                def make(*args, **kwargs):
                    from ._core import FactorGraph

                    if ""factors"" in kwargs:
                        kwargs[""costs""] = kwargs.pop(""factors"")

                    warnings.warn(
                        ""`jaxls.FactorGraph` has been renamed `jaxls.FactorGraph`"",
                        DeprecationWarning,
                        stacklevel=2,
                    )

                    return FactorGraph(*args, **kwargs)
",src/jaxls/__init__.py,_FactorGraphDescriptor.FactorGraph,1,0.14804719615221756,"The method is using a deprecated warning to inform users about a name change, which suggests that the method is being maintained for backward compatibility. This is a common practice to ensure that existing codebases do not break immediately after a change. The presence of the deprecation warning indicates that the method is likely to be removed in the future, but it is currently being kept to allow users time to transition to the new method name. Therefore, the method is likely to be deleted eventually, but it has survived for now to provide a smooth transition."
survived,"    async def log_tool(context: Context) -> None:
        await context.info(message=""test log"")
",tests/server/middleware/test_middleware.py,,1,5.60279640614594e-09,"The method 'log_tool' is a simple asynchronous function that logs a message using the 'context.info' method. It is a utility function that can be useful for logging purposes in an asynchronous environment. Since logging is a common requirement in many applications for debugging and monitoring, this method is likely to be retained for its utility in providing a standardized way to log messages asynchronously."
survived,"def mcp_server(recording_middleware):
    mcp = FastMCP()

    @mcp.tool
    def add(a: int, b: int) -> int:
        return a + b

    @mcp.resource(""resource://test"")
    def test_resource() -> str:
        return ""test resource""

    @mcp.resource(""resource://test-template/{x}"")
    def test_resource_with_path(x: int) -> str:
        return f""test resource with {x}""

    @mcp.prompt
    def test_prompt(x: str) -> str:
        return f""test prompt with {x}""

    @mcp.tool
    async def progress_tool(context: Context) -> None:
        await context.report_progress(progress=1, total=10, message=""test"")

    @mcp.tool
    async def log_tool(context: Context) -> None:
        await context.info(message=""test log"")

    @mcp.tool
    async def sample_tool(context: Context) -> None:
        await context.sample(""hello"")

    mcp.add_middleware(recording_middleware)

    # Register progress handler
    @mcp._mcp_server.progress_notification()
    async def handle_progress(
        progress_token: str | int,
        progress: float,
        total: float | None,
        message: str | None,
    ):
        print(""HI"")

    return mcp
",tests/server/middleware/test_middleware.py,,1,1.725782769012759e-08,"The method 'mcp_server' is likely to survive because it demonstrates a well-structured and functional implementation of a server using the FastMCP framework. It includes various tools, resources, and prompts that are registered with the MCP instance, showcasing its utility in handling different types of operations. Additionally, the use of middleware and a progress handler indicates a comprehensive approach to managing server tasks, making it a valuable component in a larger system."
deleted,"    async def _middleware_list_resources(self) -> list[Resource]:
        """"""
        List all available resources, in the format expected by the low-level MCP
        server.

        """"""

        async def _handler(
            context: MiddlewareContext[dict[str, Any]],
        ) -> list[Resource]:
            resources = await self._list_resources()

            mcp_resources: list[Resource] = []
            for resource in resources:
                if self._should_enable_component(resource):
                    mcp_resources.append(resource)

            return mcp_resources

        with fastmcp.server.context.Context(fastmcp=self) as fastmcp_ctx:
            # Create the middleware context.
            mw_context = MiddlewareContext(
                message={},  # List resources doesn't have parameters
                source=""client"",
                type=""request"",
                method=""resources/list"",
                fastmcp_context=fastmcp_ctx,
            )

            # Apply the middleware chain.
            return await self._apply_middleware(mw_context, _handler)
",src/fastmcp/server/server.py,FastMCP,1,4.1399375473943306e-08,"The method '_middleware_list_resources' is an asynchronous function that lists resources in a specific format for a server. It uses a handler to filter resources based on a condition and applies middleware to process the request. The method is well-structured, uses context management, and is likely part of a larger system that relies on middleware for processing requests. Given its utility in managing resources and its integration with middleware, it is likely to be a crucial part of the system's functionality. Therefore, it is more likely to be retained rather than deleted."
survived,"    async def test_list_tools(
        self, mcp_server: FastMCP, recording_middleware: RecordingMiddleware
    ):
        async with Client(mcp_server) as client:
            await client.list_tools()

        assert recording_middleware.assert_called(times=3)
        assert recording_middleware.assert_called(method=""tools/list"", times=3)
        assert recording_middleware.assert_called(hook=""on_message"", times=1)
        assert recording_middleware.assert_called(hook=""on_request"", times=1)
        assert recording_middleware.assert_called(hook=""on_list_tools"", times=1)
",tests/server/middleware/test_middleware.py,TestMiddlewareHooks,1,9.736200303530205e-10,"The method 'test_list_tools' is a test function that verifies the behavior of the 'list_tools' functionality in an asynchronous context. It uses assertions to ensure that the 'recording_middleware' is called the expected number of times with the correct parameters. This kind of test is crucial for maintaining the integrity of the codebase, especially in systems that rely on middleware for handling requests and responses. Since testing is a fundamental part of software development and this test seems to be well-structured and purposeful, it is likely to be retained in the codebase."
survived,"def test_export_datasets_with_incomplete_dataset():
    """"""Test behavior when source database contains incomplete datasets""""""
    with tempfile.TemporaryDirectory() as temp_dir:
        source_db_path = Path(temp_dir) / ""source.db""
        target_db_path = Path(temp_dir) / ""target.db""
        export_path = Path(temp_dir) / ""exports""
        
        # Create source database
        source_conn = connect(source_db_path)
        exp = load_or_create_experiment(
            experiment_name=""test_exp"",
            sample_name=""test_sample"",
            conn=source_conn
        )
        
        # Create interdependencies
        x = ParamSpec(""x"", ""numeric"", unit=""V"")
        y = ParamSpec(""y"", ""numeric"", unit=""A"")
        interdeps = InterDependencies_(dependencies={y: (x,)})
        
        # Create completed dataset
        dataset1 = DataSet(conn=source_conn, exp_id=exp.exp_id)
        dataset1.set_interdependencies(interdeps)
        dataset1.mark_started()
        for i in range(5):
            dataset1.add_results([{""x"": i, ""y"": i**2}])
        dataset1.mark_completed()
        
        # Create incomplete dataset
        dataset2 = DataSet(conn=source_conn, exp_id=exp.exp_id)
        dataset2.set_interdependencies(interdeps)
        dataset2.mark_started()
        for i in range(3):
            dataset2.add_results([{""x"": i, ""y"": i**3}])
        # Note: not marking as completed
        
        source_conn.close()
        
        # Run the export function
        result = export_datasets_and_create_metadata_db(
            source_db_path=source_db_path,
            target_db_path=target_db_path,
            export_path=export_path,
        )
        
        # Check that both datasets were processed
        assert len(result) == 2
        assert dataset1.run_id in result
        assert dataset2.run_id in result
        
        # Incomplete dataset should be copied as-is
        assert result[dataset2.run_id] == ""copied_as_is""
",tests/dataset/test_export_datasets_and_create_metadata_db.py,,1,4.944450477491054e-09,"The method is a test function that verifies the behavior of a dataset export function when dealing with incomplete datasets. It is a useful test case to ensure that the export function can handle datasets that are not marked as completed, which is a common scenario in data processing. The test checks that both completed and incomplete datasets are processed correctly, which is important for robustness. Therefore, this method is likely to be retained as it provides valuable coverage for the export functionality."
survived,"    async def plugin(text: str) -> str:
        return text.upper()
",tests/test_policy_checker.py,,1,2.998960815863541e-09,"The method is a simple utility function that converts a given string to uppercase. Such utility functions are commonly used in various applications for text processing and are generally useful. The method is straightforward, has a clear purpose, and is implemented correctly. There is no indication that it is obsolete or redundant, so it is likely to be retained."
survived,"def test_default_patterns_match_samples():
    samples = {
        ""email"": ""user@example.com"",
        ""phone"": ""+1 555-123-4567"",
        ""ssn"": ""123-45-6789"",
        ""credit_card"": ""4111 1111 1111 1111"",
        ""password"": ""my password is secret"",
    }
    for name, pattern in DEFAULT_REGEX_PATTERNS.items():
        assert re.search(pattern, samples[name])
",tests/test_regex_patterns.py,,1,4.6911638017642294e-08,"The method `test_default_patterns_match_samples` is a test function that checks if predefined regular expression patterns match sample data. This is a typical unit test to ensure that the regex patterns are correctly identifying the expected formats (like email, phone number, etc.). Such test functions are crucial for maintaining code quality and ensuring that changes to regex patterns do not break existing functionality. Therefore, it is unlikely to be deleted as it serves an important role in validating the correctness of the regex patterns."
survived,"def test_build_default_regex_config():
    config = build_default_regex_config()
    rule_names = {rule.name for rule in config.rules}
    assert set(DEFAULT_REGEX_PATTERNS.keys()) == rule_names
    # ensure patterns are preserved
    for rule in config.rules:
        assert isinstance(rule, GuardrailRule)
        assert DEFAULT_REGEX_PATTERNS[rule.name] == rule.pattern",tests/test_regex_patterns.py,,1,6.348800075736417e-09,"The method `test_build_default_regex_config` is a unit test function that verifies the behavior of the `build_default_regex_config` function. It checks that the configuration built by this function contains the expected rules and that the patterns match those defined in `DEFAULT_REGEX_PATTERNS`. Unit tests are crucial for ensuring code reliability and correctness, especially in larger projects. They help catch bugs early and ensure that changes do not break existing functionality. Therefore, this method is likely to be retained as it serves an important role in maintaining code quality."
survived,"def test_agent_inherits_from_agents():
    router = GuardrailModelRouter({""gpt"": DummyAdapter()}, default_model=""gpt"")
    agent = GuardrailDesignerAgent(model_router=router)

    assert isinstance(agent, agents.Agent)",tests/test_guardrail_designer_agent.py,,1,2.699578619062706e-07,"The method `test_agent_inherits_from_agents` is a test function that checks if an instance of `GuardrailDesignerAgent` is a subclass of `agents.Agent`. This is a typical unit test to ensure that the class hierarchy is correctly implemented. Such test functions are generally useful for maintaining code quality and ensuring that changes in the codebase do not break expected class relationships. Therefore, it is likely to be retained as part of the test suite."
survived,"    def __init__(self, **data: Any) -> None:  # pragma: no cover - exercised in tests
        super().__init__(**data)
        if not self.openai_api_key:
            self.openai_api_key = get_secret(""OPENAI_API_KEY"")
        if not self.openai_api_key:
            _log.warning(""OPENAI_API_KEY missing ‚Äì offline mode enabled"")
            self.offline = True
",src/utils/config.py,Settings,1,2.2159489282323004e-08,"The method is a constructor (__init__) for a class, which is a fundamental part of object-oriented programming. It initializes the instance of the class and sets up necessary attributes. The method includes logic to handle the absence of an API key by setting the system to offline mode, which is a useful feature for robustness. Additionally, the use of 'pragma: no cover' suggests that this method is tested indirectly, indicating its importance. Therefore, it is unlikely to be deleted."
survived,"def _prefetch_vault() -> None:
    """"""Populate environment secrets from HashiCorp Vault if configured.""""""
    if ""VAULT_TOKEN"" in os.environ and ""VAULT_ADDR"" in os.environ:
        try:  # pragma: no cover - optional dependency
            import importlib

            hvac = importlib.import_module(""hvac"")

            addr = os.environ[""VAULT_ADDR""]
            token = os.environ[""VAULT_TOKEN""]
            secret_path = os.getenv(""OPENAI_API_KEY_PATH"", ""OPENAI_API_KEY"")
            client = hvac.Client(url=addr, token=token)
            data = client.secrets.kv.read_secret_version(path=secret_path)
            value = data[""data""][""data""].get(""OPENAI_API_KEY"")
            if value:
                os.environ.setdefault(""OPENAI_API_KEY"", value)
        except Exception as exc:  # noqa: BLE001
            _log.warning(""Vault lookup failed: %s"", exc)
",src/utils/config.py,,1,2.2159489282323004e-08,"The method `_prefetch_vault` is designed to populate environment secrets from HashiCorp Vault if it is configured. This functionality is crucial for applications that rely on secure storage and retrieval of sensitive information, such as API keys. The method includes error handling to log warnings if the Vault lookup fails, which is a good practice for maintaining robustness. Additionally, the use of environment variables to configure the Vault connection makes it flexible and adaptable to different environments. Given these considerations, the method is likely to be retained as it provides essential functionality for secure secret management."
survived,"  def test_civic(self):

    dbc_file = ""honda_civic_touring_2016_can_generated""
    defs = CANDefine(dbc_file)

    assert defs.dv[399] == defs.dv['STEER_STATUS']
    assert defs.dv[399] == {'STEER_STATUS':
                            {7: 'PERMANENT_FAULT',
                             6: 'TMP_FAULT',
                             5: 'FAULT_1',
                             4: 'NO_TORQUE_ALERT_2',
                             3: 'LOW_SPEED_LOCKOUT',
                             2: 'NO_TORQUE_ALERT_1',
                             0: 'NORMAL'}
                            }
",opendbc/can/tests/test_define.py,TestCANDefine,1,1.8553915987649156e-07,"The method 'test_civic' is a test function that verifies the mapping of a specific CAN message ID to its corresponding steering status definitions. This is a typical unit test to ensure that the CAN definitions are correctly loaded and interpreted. Such test functions are crucial for maintaining the integrity of the codebase, especially in automotive software where correct interpretation of CAN messages is critical. Therefore, it is unlikely to be deleted as it serves an important role in validating the functionality of the code."
survived,"def test_run_claude_json():
    """"""Basic validation that Claude returns valid JSON using --output-format.""""""
    output = run_claude_json(""hello"", allowed_tools=[""Bash""])
    assert isinstance(output, dict)
    assert output",tests/test_claude_testing_v1.py,,1,1.725782769012759e-08,"The method 'test_run_claude_json' is a basic test function that checks if the 'run_claude_json' function returns a valid JSON object. It is a simple validation test that ensures the output is a dictionary and not empty. Such test functions are essential for maintaining code quality and ensuring that functions behave as expected. Therefore, it is likely to be retained as part of the test suite to ensure ongoing reliability of the 'run_claude_json' function."
survived,"    async def handle(self, env: messaging.Envelope) -> None:  # type: ignore[override]
        if env.payload.get(""status"") == ""blocked"":
            return
        await super().handle(env)
",tests/test_safety_agent.py,FilteringMemoryAgent,1,2.699578619062706e-07,"The method 'handle' is an overridden method that adds a specific condition to check if the 'status' in the payload is 'blocked'. If it is, the method returns early without calling the superclass method. This is a common pattern to handle specific cases before proceeding with the default behavior. The method is likely to survive because it provides necessary functionality to handle 'blocked' status messages, which is a specific requirement that might not be covered by the superclass method alone."
survived,"    def generate(
        self,
        prompt: str,
        amount: int = 1,
        model: str = ""stabilityai/stable-diffusion-xl-base-1.0"",
        guidance_scale: Optional[float] = None,
        negative_prompt: Optional[str] = None,
        num_inference_steps: Optional[int] = None,
        width: Optional[int] = None,
        height: Optional[int] = None,
        scheduler: Optional[str] = None,
        seed: Optional[int] = None,
    ) -> List[bytes]:
        """"""Generate some fire images! üé®

        Args:
            prompt (str): Your lit image description
            amount (int): How many images to generate (default: 1)
            model (str): Which model to use (default: ""stabilityai/stable-diffusion-xl-base-1.0"")
            guidance_scale (float, optional): Control how much to follow your prompt
            negative_prompt (str, optional): What you don't want in the image
            num_inference_steps (int, optional): More steps = better quality but slower
            width (int, optional): Image width
            height (int, optional): Image height
            scheduler (str, optional): Which scheduler to use
            seed (int, optional): Random seed for reproducibility

        Returns:
            List[bytes]: Your generated images as bytes
        """"""
        assert bool(prompt), ""Yo fam, prompt can't be empty! üö´""
        assert isinstance(amount, int), f""Amount gotta be an integer, not {type(amount)} ü§î""
        assert amount > 0, ""Amount gotta be greater than 0! üìà""

        self.prompt = prompt
        response = []
        if self.logging:
            logger.info(f""Generating {amount} images with {model}... üé®"")

        for _ in range(amount):
            url = self.base_url + model
            payload: Dict[str, Any] = {""inputs"": prompt}
            parameters = {}

            if guidance_scale is not None:
                parameters[""guidance_scale""] = guidance_scale
            if negative_prompt is not None:
                parameters[""negative_prompt""] = negative_prompt
            if num_inference_steps is not None:
                parameters[""num_inference_steps""] = num_inference_steps
            if width is not None and height is not None:
                parameters[""target_size""] = {""width"": width, ""height"": height}
            if scheduler is not None:
                parameters[""scheduler""] = scheduler
            if seed is not None:
                parameters[""seed""] = seed

            if parameters:
                payload[""parameters""] = parameters

            try:
                resp = self.session.post(url, headers=self.headers, json=payload, timeout=self.timeout)
                resp.raise_for_status()
                response.append(resp.content)
                if self.logging:
                    logger.success(""Image generated successfully! üéâ"")
            except requests.RequestException as e:
                if self.logging:
                    logger.error(f""Failed to generate image: {e} üò¢"")
                raise

        return response
",webscout/Provider/TTI/huggingface.py,HFimager,1,4.363462233903899e-09,"The method 'generate' is a core function for generating images using a specified model, which is a fundamental feature in applications involving AI-driven image generation. It includes various parameters for customization, such as prompt, model, guidance scale, and more, making it versatile and useful for users. Additionally, it handles exceptions and logs the process, which are good practices in software development. Given the increasing interest and application of AI in creative fields, this method is likely to be retained and further developed."
survived,"    def generate(
        self,
        prompt: str,
        amount: int = 1,
        additives: bool = True,
        width: int = 768,
        height: int = 768,
        model: str = ""flux"",
        max_retries: int = 3,
        retry_delay: int = 5,
        negative_prompt: Optional[str] = None,
        seed: Optional[int] = None,
    ) -> List[bytes]:
        """"""Generate some fire images from your prompt! üé®

        Args:
            prompt (str): Your image description
            amount (int): How many images you want (default: 1)
            additives (bool): Make each prompt unique for variety (default: True)
            width (int): Image width (default: 768)
            height (int): Image height (default: 768)
            model (str): Model to use - check AVAILABLE_MODELS (default: ""flux"")
            max_retries (int): Max retry attempts if something fails (default: 3)
            retry_delay (int): Seconds to wait between retries (default: 5)
            negative_prompt (str, optional): What you don't want in the image
            seed (int, optional): Seed for reproducible results

        Returns:
            List[bytes]: Your generated images as bytes

        Raises:
            ValueError: If the inputs ain't valid
            RequestException: If the API calls fail after retries
        """"""
        # Input validation
        if not prompt:
            raise ValueError(""Yo fam, the prompt can't be empty! ü§î"")
        if not isinstance(amount, int) or amount < 1:
            raise ValueError(""Amount needs to be a positive number! üìà"")
        if model not in self.AVAILABLE_MODELS:
            raise ValueError(f""Model must be one of {self.AVAILABLE_MODELS}! üéØ"")

        # Function to add random characters for variety
        def add_variety():
            return """" if not additives else """".join(choice(punctuation) for _ in range(5))

        self.prompt = prompt
        response = []
        
        # Build base URL with parameters
        base_params = {
            ""width"": width,
            ""height"": height,
            ""model"": model
        }
        
        if negative_prompt:
            base_params[""negative""] = negative_prompt
        if seed is not None:
            base_params[""seed""] = seed

        for _ in range(amount):
            current_prompt = f""{prompt}{add_variety()}""
            params_str = ""&"".join(f""{k}={v}"" for k, v in base_params.items())
            url = f""{self.image_gen_endpoint.format(prompt=current_prompt)}?{params_str}""
            
            for attempt in range(max_retries):
                try:
                    resp = self.session.get(url, timeout=self.timeout)
                    resp.raise_for_status()
                    response.append(resp.content)
                    break
                except RequestException as e:
                    if attempt == max_retries - 1:
                        raise
                    time.sleep(retry_delay)

        return response
",webscout/Provider/TTI/pollinations.py,PollinationsAI,1,1.3440409770490404e-08,"The method 'generate' is a well-structured and comprehensive function for generating images based on a prompt. It includes input validation, error handling, and retry logic, which are essential for robust API interaction. The method is likely to be useful in applications that require image generation, especially with the flexibility of parameters like width, height, model selection, and the ability to handle negative prompts. These features make it versatile and adaptable to various use cases, increasing its chances of being retained in the codebase."
survived,"    def __init__(
        self,
        model: str = ""dall-e-3"",  # Updated default model
        timeout: int = 60,
        proxies: dict = {},
    ):
        """"""Initialize your FreeAIPlayground provider with custom settings! ‚öôÔ∏è

        Args:
            model (str): Which model to use (default: dall-e-3)
            timeout (int): Request timeout in seconds (default: 60)
            proxies (dict): Proxy settings for requests (default: {})
            logging (bool): Enable fire logging (default: True)
        """"""
        self.image_gen_endpoint: str = ""https://api.freeaichatplayground.com/v1/images/generations""
        self.headers = {
            ""Accept"": ""application/json"",
            ""Accept-Language"": ""en-US,en;q=0.9"",
            ""Content-Type"": ""application/json"",
            ""User-Agent"": LitAgent().random(), 
            ""Origin"": ""https://freeaichatplayground.com"",
            ""Referer"": ""https://freeaichatplayground.com/"",
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)
        self.session.proxies.update(proxies)
        self.timeout = timeout
        self.model = model
        self.prompt: str = ""AI-generated image - webscout""
        self.image_extension: str = ""png""
",webscout/Provider/TTI/freeaiplayground.py,FreeAIImager,1,2.3823698451773172e-07,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class with specific attributes and settings. It sets up important configurations such as the model to use, timeout, and proxy settings, which are crucial for the functionality of the class. Additionally, it initializes a session with headers and proxies, which are necessary for making HTTP requests. These functionalities are fundamental to the operation of the class, making it unlikely that this method would be removed."
survived,"    def get_model(self, model_name: str) -> str:
        """"""Get actual model name from alias""""""
        if model_name.lower() in self.AVAILABLE_MODELS:
            return self.AVAILABLE_MODELS[model_name.lower()]
        return model_name
",webscout/Provider/TTI/aiarta.py,AIArtaImager,1,1.6918979223288786e-10,"The method 'get_model' is likely to survive because it provides a useful functionality of mapping model aliases to their actual names. This is a common requirement in applications where models are referred to by different names or aliases. The method is simple, efficient, and directly addresses a specific need, making it a valuable part of the codebase."
survived,"        async def post(self, *_args, **_kwargs):
            raise NotImplementedError(""aiohttp is required for network access"")
",src/meta_agent/services/telemetry_client.py,ClientSession,0,0.9999910602998366,"The method is raising a NotImplementedError, indicating that it is not yet implemented and requires aiohttp for network access. This suggests that the method is not functional in its current state and is likely a placeholder. Without implementation, it doesn't serve a purpose, which makes it a candidate for deletion unless it is planned to be implemented in the future."
survived,"    def generate(
        self,
        spec: Mapping[str, Any],
        *,
        diagram_type: str = ""flowchart"",
        direction: str | None = None,
        node_styles: Mapping[str, str] | None = None,
    ) -> str:
        """"""Return a Mermaid diagram describing the agent.

        Parameters
        ----------
        spec:
            Mapping describing the agent (e.g. :class:`SpecSchema` dict).
        diagram_type:
            Mermaid diagram type such as ``flowchart`` or ``graph``.
        direction:
            Layout direction (``TB`` top-bottom, ``LR`` left-right, etc.).
        node_styles:
            Optional mapping of node identifiers to Mermaid style strings.

        Returns
        -------
        str
            Mermaid diagram definition.
        """"""
        if not isinstance(spec, Mapping):
            raise DiagramGenerationError(""spec must be a mapping"")

        direction = direction or self.default_direction

        lines: list[str] = [f""{diagram_type} {direction}""]

        inputs = spec.get(""inputs"") or {}
        outputs = spec.get(""outputs"") or {}
        task_desc = spec.get(""task_description"", ""Agent"")

        agent_id = ""AGENT""
        lines.append(f""    {agent_id}[{task_desc}]"")

        for name in inputs:
            node_id = f""IN_{name}"".replace("" "", ""_"")
            lines.append(f""    {node_id}[{name}]"")
            lines.append(f""    {node_id} --> {agent_id}"")

        for name in outputs:
            node_id = f""OUT_{name}"".replace("" "", ""_"")
            lines.append(f""    {agent_id} --> {node_id}"")
            lines.append(f""    {node_id}[{name}]"")

        if node_styles:
            for node, style in node_styles.items():
                lines.append(f""    style {node} {style}"")

        return ""\n"".join(lines) + ""\n""",src/meta_agent/ux/diagram_generator.py,DiagramGenerator,1,4.599055376537186e-10,"The method `generate` is a well-defined function that provides a useful feature: generating a Mermaid diagram from a given specification. It includes error handling, default values, and flexibility in terms of diagram type and direction. The method is likely to be useful in contexts where visual representation of data flow or processes is needed, which is a common requirement in software development and documentation. Therefore, it is likely to be retained."
survived,"def test_generate_basic_diagram():
    """"""DiagramGenerator produces valid mermaid syntax for a simple spec.""""""
    generator = DiagramGenerator()
    diagram = generator.generate(MINIMAL_SPEC)

    assert diagram.startswith(""flowchart TB\n"")
    assert ""IN_query"" in diagram
    assert ""OUT_result"" in diagram
",tests/ux/test_diagram_generator.py,,1,1.522997951276035e-08,"The method 'test_generate_basic_diagram' is a unit test that checks if the 'DiagramGenerator' class correctly generates a diagram in mermaid syntax from a minimal specification. Unit tests are crucial for ensuring code reliability and correctness, especially in complex systems. This test is simple, clear, and directly verifies the functionality of the 'DiagramGenerator'. Therefore, it is likely to be retained as part of the codebase to ensure ongoing validation of this functionality."
survived,"    def test_list_agents_sorted(self):
        class AAgent(AgentBase):
            NAME = ""a_a""

            async def step(self):
                return None

        class BAgent(AgentBase):
            NAME = ""b_b""

            async def step(self):
                return None

        register_agent(AgentMetadata(name=BAgent.NAME, cls=BAgent))
        register_agent(AgentMetadata(name=AAgent.NAME, cls=AAgent))

        names = list_agents()
        self.assertEqual(names, sorted(names))
",tests/test_agents_registry.py,TestAgentRegistryFunctions,1,9.736200303530205e-10,"The method 'test_list_agents_sorted' is a unit test designed to verify that the list of agent names returned by 'list_agents()' is sorted. This is a valid and useful test to ensure that the system maintains a consistent order of agents, which can be important for predictable behavior in applications that rely on agent ordering. The test is straightforward, does not contain any deprecated or redundant logic, and serves a clear purpose in the context of testing. Therefore, it is likely to be retained in the codebase."
survived,"    def test_portfolio(self):
        p = finance_agent._Portfolio()
        p.update(""BTC"", 1.0)
        self.assertEqual(p.qty(""BTC""), 1.0)
        self.assertEqual(p.book(), {""BTC"": 1.0})
        self.assertEqual(p.value({""BTC"": 100.0}), 100.0)
        p.update(""BTC"", -1.0)
        self.assertEqual(p.qty(""BTC""), 0.0)
        self.assertEqual(p.book(), {})
",tests/test_finance_utils.py,TestFinanceUtils,1,7.194132978569833e-09,"The method 'test_portfolio' is a unit test for the '_Portfolio' class in the 'finance_agent' module. It tests the functionality of updating the portfolio, checking the quantity of an asset, verifying the portfolio's book, and calculating the value of the portfolio. These are essential tests to ensure the correct behavior of the '_Portfolio' class. Since testing is a crucial part of software development to maintain code quality and reliability, this method is likely to be retained."
survived,"            def __init__(self, *_, **__):
                self.label_arg = None
",tests/test_base_helpers.py,TestPromMetrics.Dummy,0,0.9999724643101549,"The method is a constructor (__init__) that initializes an instance of a class. However, it does not take any meaningful arguments or perform any significant initialization other than setting a single attribute to None. This makes it a placeholder or a default constructor that doesn't add much value. Unless there is a specific reason for this minimalistic design, such as being overridden in subclasses or used in a specific design pattern, it is likely to be considered redundant and could be deleted. However, if it serves a purpose in a larger context, it might survive. Without additional context, the likelihood of deletion is higher."
survived,"            def __init__(self, bootstrap_servers=None, value_serializer=None, linger_ms=None):
                self.args = (bootstrap_servers, value_serializer, linger_ms)
",tests/test_base_helpers.py,TestKafkaProducer.Stub,1,2.2159489282323004e-08,"The method is a constructor for a class, likely intended to initialize an instance with specific parameters. Constructors are fundamental to class-based programming as they set up the initial state of an object. The method is simple and does not contain any apparent issues or redundancies that would warrant its deletion. Therefore, it is likely to survive."
survived,"            def set(self, v):
                self.value = v
",tests/test_base_helpers.py,TestPromMetrics.Dummy,0,0.9997694933225385,"The method 'set' is a simple setter method that assigns a value to an instance variable 'value'. Such methods are common in object-oriented programming to encapsulate the setting of attributes. However, in modern Python practices, direct attribute access is often preferred unless additional logic is needed during assignment. Without additional context, such as the presence of additional logic in the setter or the use of property decorators, it's difficult to determine if this method will be deleted. If the class is being refactored to use direct attribute access or property decorators, this method might be deleted. However, if encapsulation is still desired, it might survive. Given the trend towards simplicity and direct access, there's a slight inclination towards deletion."
survived,"    def test_dispatch_structure(self):
        data = asyncio.run(self.agent._dispatch())
        payload = json.loads(data)
        self.assertIn(""schedule"", payload[""payload""])
        self.assertIsInstance(payload[""payload""], dict)
",tests/test_energy_agent_behavior.py,TestEnergyAgentBehavior,1,4.4508487281649027e-07,"The method `test_dispatch_structure` is a unit test method that checks the structure of the data returned by the `_dispatch` method of an `agent` object. Unit tests are crucial for ensuring code reliability and correctness, especially in asynchronous programming where bugs can be subtle and hard to trace. The method uses assertions to verify that the data contains a 'schedule' key and that the payload is a dictionary, which are typical checks in test cases. Given the importance of testing in software development, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered."
survived,"    def test_higher_version_replaces(self):
        class AgentV1(AgentBase):
            NAME = ""dup""
            VERSION = ""1.0""

            async def step(self):
                return None

        class AgentV2(AgentBase):
            NAME = ""dup""
            VERSION = ""1.1""

            async def step(self):
                return None

        register_agent(AgentMetadata(name=""dup"", cls=AgentV1, version=""1.0""))
        register_agent(AgentMetadata(name=""dup"", cls=AgentV2, version=""1.1""))

        self.assertIs(AGENT_REGISTRY[""dup""].cls, AgentV2)
        self.assertEqual(AGENT_REGISTRY[""dup""].version, ""1.1"")
",tests/test_agents_registry.py,TestVersionOverride,1,8.592166611791576e-10,"The method 'test_higher_version_replaces' is testing a fundamental feature of version management in a registry system, which is crucial for ensuring that the latest version of an agent is used. This kind of test is important for maintaining the integrity and functionality of the system, especially when dealing with updates and version control. Therefore, it is likely to be retained as it verifies that the system correctly replaces an older version of an agent with a newer one."
survived,"    def test_step_coroutine(self):
        import inspect
        for name in list_agents():
            meta = AGENT_REGISTRY[name]
            try:
                agent = meta.cls()
            except Exception:
                continue
            if hasattr(agent, ""step""):
                self.assertTrue(inspect.iscoroutinefunction(agent.step))
",tests/test_agents_integrity.py,TestAgentsIntegrity,1,3.850741907939403e-09,"The method `test_step_coroutine` is a unit test that checks if the `step` method of agents in the `AGENT_REGISTRY` is a coroutine function. This is a valid and useful test to ensure that the `step` method is implemented as an asynchronous coroutine, which might be a requirement for the system's architecture. The method uses `inspect.iscoroutinefunction` to verify this, which is a standard way to check for coroutine functions in Python. Since this test is straightforward, serves a clear purpose, and uses standard practices, it is likely to be retained in the codebase."
survived,"    def test_validate_demos_cli(self) -> None:
        """"""Running the module as a CLI should succeed.""""""
        import sys
        import subprocess

        result = subprocess.run(
            [sys.executable, ""-m"", ""alpha_factory_v1.demos.validate_demos""],
            capture_output=True,
            text=True,
        )
        self.assertEqual(result.returncode, 0, result.stderr)
        self.assertIn(""validated"", result.stdout.lower())",tests/test_demos.py,TestDemos,1,2.2159489282323004e-08,"The method `test_validate_demos_cli` is a unit test designed to verify that running a specific module as a command-line interface (CLI) succeeds without errors. It uses the `subprocess` module to execute the module and checks the output for expected results. This is a common practice in testing to ensure that CLI tools work as intended. The method is well-structured, serves a clear purpose, and is likely part of a test suite that ensures the reliability of the software. Therefore, it is unlikely to be deleted unless the functionality it tests is removed or significantly altered."
survived,"            def post_alpha_job(self, bundle_id: int, delta_g: float) -> None:
                self.called = True
",tests/test_alpha_agi_business_3_v1.py,TestAlphaAgiBusiness3Demo.CaptureOrch,0,0.999999057755336,"The method `post_alpha_job` is very minimal and only sets an attribute `called` to `True`. It does not perform any meaningful operation with the parameters `bundle_id` and `delta_g`, which suggests that it might be incomplete or not fully implemented. Without further context or usage, it seems like a placeholder or a method that was intended to be expanded upon but never was. Therefore, it is likely to be deleted in future iterations unless it is expanded to perform a more substantial task."
survived,"async def get_user_orders(user_id: int, ctx: EnrichContext) -> list[""OrderEnrichModel""]:
    """"""Get all orders for a specific user.""""""
    session_factory = ctx.request_context.lifespan_context[""session_factory""]
    async with session_factory() as session:
        result = await session.execute(
            select(Order).where(Order.user_id == user_id).order_by(Order.created_at.desc())
        )
        orders = result.scalars().all()

        return [
            OrderEnrichModel(
                id=order.id,
                order_number=order.order_number,
                user_id=order.user_id,
                status=order.status,
                total_amount=order.total_amount,
                created_at=order.created_at,
                updated_at=order.updated_at,
                shipping_address=order.shipping_address,
                notes=order.notes,
            )
            for order in orders
        ]
",examples/sqlalchemy_shop/app.py,,1,5.905303995456778e-10,"The method 'get_user_orders' is a well-defined asynchronous function that retrieves user orders from a database using an ORM. It uses a session factory from the context to execute a query, fetches the results, and maps them to a list of 'OrderEnrichModel' objects. This is a common pattern in modern web applications for handling database operations asynchronously, which is efficient and scalable. There is no indication of deprecated practices or inefficiencies that would warrant its deletion. Therefore, it is likely to survive."
survived,"async def get_user(user_id: int, ctx: EnrichContext) -> UserEnrichModel | None:
    """"""Get a specific user by ID.""""""
    session_factory = ctx.request_context.lifespan_context[""session_factory""]
    async with session_factory() as session:
        user = await session.get(User, user_id)
        if not user:
            return None

        return UserEnrichModel(
            id=user.id,
            username=user.username,
            email=user.email,
            full_name=user.full_name,
            is_active=user.is_active,
            created_at=user.created_at,
        )
",examples/sqlalchemy_shop/app.py,,1,1.1032560311263802e-09,"The method is well-defined and serves a clear purpose of retrieving a user by ID from a database session. It uses asynchronous programming, which is suitable for I/O-bound operations like database queries. The method also returns a structured model (UserEnrichModel) or None if the user is not found, which is a common and effective pattern for such operations. There are no apparent issues or inefficiencies in the code that would warrant its deletion."
survived,"    def test_generated_model_name(self):
        """"""Test that generated EnrichModel has correct name.""""""

        class Base(DeclarativeBase):
            pass

        class Customer(Base, EnrichSQLAlchemyMixin):
            __tablename__ = ""customers""
            id: Mapped[int] = mapped_column(primary_key=True)

        CustomerEnrichModel = Customer.__enrich_model__()
        assert CustomerEnrichModel.__name__ == ""CustomerEnrichModel""
",tests/test_sqlalchemy_integration.py,TestEdgeCases,1,6.348800075736417e-09,"The method 'test_generated_model_name' is a unit test that verifies the correct naming of a generated model. Unit tests are crucial for ensuring code reliability and correctness, especially in frameworks that involve dynamic model generation like SQLAlchemy. This test checks that the '__enrich_model__' method correctly assigns the name 'CustomerEnrichModel' to the generated model, which is a specific and important functionality to validate. Therefore, it is unlikely to be deleted as it serves a clear purpose in maintaining code quality."
survived,"async def list_users(ctx: EnrichContext) -> list[UserEnrichModel]:
    """"""List all users in the system.""""""
    session_factory = ctx.request_context.lifespan_context[""session_factory""]
    async with session_factory() as session:
        result = await session.execute(select(User))
        users = result.scalars().all()

        return [
            UserEnrichModel(
                id=user.id,
                username=user.username,
                email=user.email,
                full_name=user.full_name,
                is_active=user.is_active,
                created_at=user.created_at,
            )
            for user in users
        ]
",examples/sqlalchemy_shop/app.py,,1,9.736200303530205e-10,"The method 'list_users' is a fundamental part of many systems that require user management. It provides a way to retrieve and list all users, which is a common requirement for administrative tasks, reporting, or user management interfaces. The method is well-structured, uses asynchronous programming for efficiency, and returns a list of user models with essential information. There is no indication that this functionality is obsolete or unnecessary, so it is likely to be retained."
survived,"    def _clip(self,v): return max(0, min(self.size-1, v))
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,MiniWorld,1,2.646573631904765e-09,"The method _clip is a utility function that ensures a value v is constrained within the bounds of 0 and size-1. This is a common operation in many programming tasks, especially those involving array or list indexing, where it's crucial to prevent out-of-bounds errors. The method is simple, efficient, and serves a clear purpose, making it likely to be retained in the codebase."
survived,"def _bell(value: float, ideal: float, sigma: float = 0.15) -> float:
    """"""Gaussian-shaped around ``ideal`` (15% std default).""""""
    return math.exp(-0.5 * ((value - ideal) / (sigma * ideal)) ** 2)
",alpha_factory_v1/demos/era_of_experience/reward_backends/fitness_reward.py,,1,4.363462233903899e-09,"The method `_bell` is a utility function that calculates a Gaussian (bell curve) value based on the input parameters. It is a mathematical function that can be useful in various contexts where Gaussian distribution is applicable, such as in statistics, data analysis, or machine learning. The function is well-defined, concise, and serves a specific purpose. There is no indication that it is redundant or unnecessary, and it could be useful in many scenarios where Gaussian calculations are needed. Therefore, it is likely to be retained in the codebase."
survived,"def _str_tkn(text: str) -> int:
    # na√Øve token estimate ‚âà‚Äë 1 token / 4 chars in English
    return max(1, math.ceil(len(text)/4))
",alpha_factory_v1/demos/meta_agentic_agi_v2/agents/agent_base.py,,1,1.955568070542584e-08,"The method _str_tkn is a simple utility function that estimates the number of tokens in a given text based on its length. It uses a straightforward calculation, assuming approximately one token per four characters. This kind of function is useful in natural language processing tasks where tokenization is required, and it provides a quick estimate without the overhead of a full tokenization process. Since it serves a practical purpose and is efficient, it is likely to be retained in the codebase."
survived,"    def __init__(self, ledger_path: str | pathlib.Path):
        self.path = pathlib.Path(ledger_path)
        self.path.parent.mkdir(parents=True, exist_ok=True)
",alpha_factory_v1/demos/meta_agentic_agi_v2/agents/agent_base.py,LineageTracer,1,1.637377179507321e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. It initializes an instance of the class with a given ledger path, ensuring that the directory structure exists. This is a common and necessary pattern in Python for setting up file paths and directories, making it unlikely to be removed unless the entire class is refactored or removed."
survived,"def serve_lineage(path: pathlib.Path, port: int=8000):
    import flask, threading
    app = flask.Flask(""lineage-viewer"")

    @app.route(""/"")
    def idx():
        return VIEW_HTML

    @app.route(""/log"")
    def log():
        if not path.exists():
            return ""(no events yet)""
        return flask.escape(path.read_text(""utf-8""))

    th = threading.Thread(target=app.run, kwargs=dict(port=port, host=""0.0.0.0"", debug=False))
    th.daemon = True
    th.start()
    LOGGER.info(""Lineage viewer at http://localhost:%d"", port)
    return th
",alpha_factory_v1/demos/meta_agentic_agi_v3/agents/agent_base.py,,1,6.69158608681505e-10,"The method 'serve_lineage' is a utility function that sets up a simple Flask web server to serve content from a specified path. It is a useful function for quickly setting up a local server to view logs or other data, which can be beneficial for debugging or monitoring purposes. The use of threading allows the server to run in the background without blocking the main program, making it a practical tool for developers. Given its utility and the fact that it doesn't have any apparent issues or deprecated practices, it is likely to survive."
survived,"    def _parse(self, ep: str):
        if "":"" not in ep:
            raise ValueError(""Endpoint must be <backend>:<model>"")
        return ep.split("":"",1)
",alpha_factory_v1/demos/meta_agentic_agi_v2/agents/agent_base.py,LMClient,1,3.653482080241728e-08,"The method _parse is a utility function that checks if a string contains a colon and splits it into two parts. This is a common pattern for parsing configuration strings or identifiers in software systems. The method is simple, performs a specific task, and includes error handling for invalid input. Such utility functions are often useful in various parts of a codebase, especially if the application deals with multiple endpoints or configurations. Therefore, it is likely to be retained."
survived,"    def score(self, metrics: Dict[str,float]) -> float:
        return (
            self.latency * (1/ (1+metrics.get(""latency"",0))) +
            self.cost    * (1/ (1+metrics.get(""cost"",0))) +
            self.carbon  * (1/ (1+metrics.get(""carbon"",0))) +
            self.risk    * (1- metrics.get(""risk"",0))
        )
",alpha_factory_v1/demos/meta_agentic_agi/agents/agent_base.py,ObjectiveWeights,1,6.69158608681505e-10,"The method 'score' is likely to survive because it provides a clear and useful functionality: calculating a weighted score based on various metrics such as latency, cost, carbon, and risk. This kind of scoring function is common in performance evaluation and decision-making processes, making it a valuable component in systems that need to balance multiple factors. Additionally, the use of dictionary access with default values ensures robustness against missing data, which is a good practice."
survived,"def reward(state: Mapping | None, action, result: Mapping | None) -> float:
    """"""Compute *fitness* reward.""""""
    src = result or {}

    # Extract with graceful fall-backs (None ‚Üí target ‚Üí neutral score)
    steps = float(src.get(""steps"", _TARGET_STEPS))
    hr = float(src.get(""resting_hr"", _TARGET_REST_HR))
    sleep = float(src.get(""sleep_hours"", _TARGET_SLEEP))
    cal = float(src.get(""cal_intake"", _TARGET_CAL))

    scores = {
        ""steps"": _linear(steps, _TARGET_STEPS, cap=2 * _TARGET_STEPS),
        ""resting_hr"": _inverse(hr, _TARGET_REST_HR),
        ""sleep_hours"": _bell(sleep, _TARGET_SLEEP),
        ""cal_intake"": _bell(cal, _TARGET_CAL),
    }

    # Weighted average
    total_w = sum(_WEIGHTS.values())
    blended = sum(scores[k] * _WEIGHTS[k] for k in scores) / (total_w + _EPS)
    # Clamp for numerical safety
    return float(max(0.0, min(1.0, blended)))",alpha_factory_v1/demos/era_of_experience/reward_backends/fitness_reward.py,,1,2.3355930333443423e-09,"The method 'reward' is a utility function that calculates a fitness reward based on various health metrics. It uses a combination of linear, inverse, and bell-shaped functions to compute scores for different metrics like steps, resting heart rate, sleep hours, and calorie intake. These scores are then combined into a weighted average to produce a final reward value between 0 and 1. The method is well-structured, with clear fallbacks and clamping for numerical safety, making it robust and useful for applications that require fitness tracking or health monitoring. Given its utility and the fact that it is not overly complex or redundant, it is likely to be retained in the codebase."
survived,"    def log():
        if not path.exists():
            return ""(no events yet)""
        return flask.escape(path.read_text(""utf-8""))
",alpha_factory_v1/demos/meta_agentic_agi_v2/agents/agent_base.py,,1,1.725782769012759e-08,"The method 'log' is a simple utility function that checks if a path exists and returns a string based on that condition. It uses 'flask.escape' to ensure that the text read from the path is properly escaped, which is a good practice for preventing XSS attacks when displaying text in a web application. The method is straightforward, performs a useful function, and follows good security practices. Therefore, it is likely to be retained in the codebase."
survived,"    def __init__(self, tps: float = 3.0):
        self._tps = float(tps)
        self._allow = self._tps
        self._last = time.perf_counter()
",alpha_factory_v1/demos/meta_agentic_agi_v3/agents/agent_base.py,RateLimiter,1,1.1253518384332553e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with default or specified values. This particular constructor initializes three instance variables, which are likely crucial for the class's functionality. Therefore, it is unlikely to be deleted as it is necessary for the proper instantiation of the class."
survived,"    def __exit__(self, exc_type, exc, tb):
        if signal:
            resource.setrlimit(resource.RLIMIT_CPU, (resource.RLIM_INFINITY, resource.RLIM_INFINITY))
        return False  # do not suppress
",alpha_factory_v1/demos/meta_agentic_agi_v3/agents/agent_base.py,SafeExec,1,3.3982678079468468e-09,"The method is a custom implementation of the __exit__ method, which is part of the context management protocol in Python. This method is used to define cleanup actions when exiting a context managed by a 'with' statement. The method checks for a 'signal' and sets a resource limit if the signal is present, then returns False to indicate that exceptions should not be suppressed. This is a valid and potentially useful implementation for managing resources, especially in environments where CPU limits are dynamically adjusted. Therefore, it is likely to be Survived."
survived,"    def __call__(self, prompt:str, **kw):
        return self.run(prompt, **kw)
",alpha_factory_v1/demos/meta_agentic_agi/agents/agent_base.py,Agent,1,5.60279640614594e-09,"The method `__call__` is a special method in Python that allows an instance of a class to be called as a function. This is a common and useful pattern, especially in classes that are designed to encapsulate a single piece of functionality or behavior that can be executed with different parameters. The method is implemented correctly by delegating the call to another method `run`, which suggests that the class is designed to perform some operation with the given `prompt` and additional keyword arguments. This pattern is widely used and unlikely to be removed unless the class design changes significantly, which is not indicated here."
survived,"    def __init__(self,
                 endpoint: str = ""openai:gpt-4o"",
                 temperature: float = 0.2,
                 max_tokens: int = 2048,
                 context_len: int = 8192,
                 stream: bool = False,
                 timeout: int = 120,
                 **extra):
        self.endpoint = endpoint
        self.temperature = temperature
        self.max_tokens = max_tokens
        self.context_len = context_len
        self.stream = stream
        self.timeout = timeout
        self.extra = extra
        self._backend, self._model = self._parse(endpoint)
        self._client = self._init_backend()
",alpha_factory_v1/demos/meta_agentic_agi_v3/agents/agent_base.py,LMClient,1,1.522997951276035e-08,"The method is a constructor for a class, initializing several important attributes that are likely necessary for the class's functionality. It sets default values for parameters, allowing flexibility and customization when creating an instance of the class. The use of **extra allows for additional parameters to be passed, indicating that the class is designed to be extensible. These are common and useful practices in object-oriented programming, suggesting that the method is well-designed and likely to be retained."
survived,"async def run_memory_chat() -> None:
    """"""Run an interactive chat session with conversation memory enabled.""""""
    load_dotenv()
    config_file = os.path.join(os.path.dirname(__file__), ""config.json"")

    print(""Initializing chat..."")
    client = MCPClient.from_config_file(config_file)

    openai_key = os.getenv(""OPENAI_API_KEY"")
    ollama_model = os.getenv(""OLLAMA_MODEL"", ""llama3"")

    llm = ChatOpenAI(model=""gpt-4o"") if openai_key else ChatOllama(model=ollama_model)

    agent = MCPAgent(
        llm=llm,
        client=client,
        max_steps=15,
        memory_enabled=True,
        system_prompt=SYSTEM_MESSAGE,
    )

    print(""\n===== Interactive MCP Chat ====="")
    print(""Type 'exit' or 'quit' to end the conversation"")
    print(""Type 'clear' to clear conversation history"")
    print(""Type 'history' to display the conversation so far"")
    print(""=================================\n"")

    try:
        while True:
            user_input = input(""\nYou: "")
            command = user_input.lower()

            if command in (""exit"", ""quit""):
                print(""Ending conversation..."")
                break

            if command == ""clear"":
                agent.clear_conversation_history()
                print(""Conversation history cleared."")
                continue

            if command == ""history"":
                for msg in agent.conversation_history:
                    role = msg.get(""role"", ""assistant"").capitalize()
                    print(f""{role}: {msg['content']}"")
                continue

            print(""\nAssistant: "", end="""", flush=True)
            try:
                response = await agent.run(user_input)
                print(response)
            except Exception as exc:
                print(f""\nError: {exc}"")
    finally:
        if client and client.sessions:
            await client.close_all_sessions()
",examples/openai_chat_agent/app.py,,1,5.60279640614594e-09,"The method `run_memory_chat` is a well-structured asynchronous function designed to facilitate an interactive chat session with memory capabilities. It includes features such as loading configurations, handling user commands, and managing conversation history. These functionalities are essential for a chat application, making the method valuable and likely to be retained in the codebase."
survived,"    def end_inference(self):
        return {""ok"": True}
",tests/test_multi_contributor.py,FakeComm,1,1.2501528648238603e-09,"The method `end_inference` is a simple function that returns a dictionary with a single key-value pair indicating a successful operation. It is likely part of a larger system where such a method is necessary to signal the end of an inference process. The method is straightforward, has no dependencies, and serves a clear purpose, making it unlikely to be removed unless the entire system undergoes a significant redesign. Therefore, it is more likely to survive."
survived,"    def lora_forward(self, sub_name, arr):
        return arr + 1
",tests/test_multi_contributor.py,FakeComm,1,1.955568070542584e-08,"The method 'lora_forward' is a simple function that takes two parameters and returns the input array incremented by 1. Without additional context, such as its usage or the larger codebase it belongs to, it's difficult to determine its utility. However, the method itself is functional and could be useful in scenarios where an array needs to be incremented. Therefore, without evidence of redundancy or lack of use, it is likely to survive."
survived,"def test_critic_panel_updates_fast() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri()

    with sync_playwright() as p:
        browser = p.chromium.launch()
        page = browser.new_page()
        page.goto(url)
        page.wait_for_selector(""svg circle"")
        start = time.perf_counter()
        page.click(""svg circle"")
        page.wait_for_selector(""#critic-panel"", state=""visible"")
        elapsed = (time.perf_counter() - start) * 1000
        assert elapsed < 100
        browser.close()",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_critic_panel.py,,1,2.998960815863541e-09,"The method 'test_critic_panel_updates_fast' is a test function that checks the performance of a web page interaction using Playwright. It ensures that a specific UI update happens within a certain time frame (less than 100 milliseconds). This type of test is crucial for maintaining performance standards in web applications, especially those with interactive elements. Given the increasing importance of performance testing in modern web development, this method is likely to be retained as it provides valuable insights into the responsiveness of the application."
survived,"        async def __call__(self, prompt: str) -> str:
            self.prompt = prompt
            return ""online""
",tests/test_alpha_agi_business_3_v1.py,DummyAgent,0,0.9999999677581336,"The method is an asynchronous call method that takes a string input and returns a fixed string ""online"". It doesn't perform any meaningful operation with the input, which suggests it might be a placeholder or a stub for future development. Without additional context or functionality, such methods are often candidates for deletion or replacement with more functional code. However, if this method is part of a larger framework where returning ""online"" is a valid and necessary response, it might survive. Given the limited functionality and lack of context, it is more likely to be deleted."
survived,"def temp_db_path():
    fd, path = tempfile.mkstemp()
    os.close(fd)
    yield Path(path)
    if os.path.exists(path):
        os.unlink(path)
",src/mcp_server_pocket_pick/tests/functionality/test_list_ids.py,,1,2.2159489282323004e-08,"The method 'temp_db_path' is a utility function that creates a temporary file and yields its path as a Path object. It ensures that the file descriptor is closed immediately after creation and deletes the file if it exists after usage. This is a common pattern for managing temporary files in a safe and clean manner. The function is useful for scenarios where a temporary file is needed, such as in testing or temporary data storage. Given its utility and the fact that it handles resource cleanup, it is likely to be retained in the codebase."
survived,"def violates_insider_policy(text: str) -> bool:
    """"""Return ``True`` if ``text`` matches the insider trading policy.""""""
    for pat in _INSIDER_RE:
        if pat.search(text):
            return True
    return False",src/utils/opa_policy.py,,1,5.211412485172657e-10,"The method 'violates_insider_policy' is likely to survive because it serves a specific purpose of checking if a given text violates insider trading policies by matching against a set of regular expressions. This functionality is useful in financial or compliance software to ensure adherence to regulations. The method is straightforward, efficient, and performs a necessary check, making it a valuable part of a larger system."
survived,"    def test_list_agents_flag(self):
        args = _parse_with(['--list-agents'])
        self.assertTrue(args.list_agents)
",alpha_factory_v1/tests/test_cli.py,CliParseTest,1,4.363462233903899e-09,"The method `test_list_agents_flag` is a unit test that checks if the `--list-agents` flag is correctly parsed and set to `True`. This is a typical test case to ensure command-line arguments are handled properly. Such tests are crucial for maintaining the reliability of command-line interfaces, especially if the software relies on user input through command-line arguments. Therefore, this method is likely to be retained as it serves an important role in verifying the functionality of the argument parsing logic."
survived,"def main(argv: list[str] | None = None) -> None:
    parser = argparse.ArgumentParser(description=""Alpha-Factory Quickstart"")
    parser.add_argument(""--preflight"", action=""store_true"", help=""Run checks and exit"")
    parser.add_argument(""--skip-preflight"", action=""store_true"", help=""Skip checks"")
    parser.add_argument(""orchestrator_args"", nargs=argparse.REMAINDER, help=""Arguments passed to orchestrator"")
    args = parser.parse_args(argv)

    repo_root = Path(__file__).resolve().parent
    os.chdir(repo_root)
    venv = repo_root / "".venv""
    _create_venv(venv)

    py = _venv_python(venv)

    if args.preflight:
        subprocess.check_call([str(py), ""alpha_factory_v1/scripts/preflight.py""])
        return

    if not args.skip_preflight:
        subprocess.check_call([str(py), ""alpha_factory_v1/scripts/preflight.py""])

    cmd = [str(py), ""-m"", ""alpha_factory_v1.run""] + args.orchestrator_args
    subprocess.check_call(cmd)
",alpha_factory_v1/quickstart.py,,1,8.152020648014727e-09,"The method 'main' is a typical entry point for a command-line application, utilizing argparse to handle command-line arguments. It includes functionality for setting up a virtual environment, running preflight checks, and executing a main command. This structure is common in Python applications that require setup and execution of scripts in a controlled environment. The method is well-structured, uses standard libraries, and provides flexibility with options like '--preflight' and '--skip-preflight'. There is no indication of redundancy or obsolescence, and it appears to be a necessary part of the application's functionality. Therefore, it is likely to be retained."
survived,"def _create_venv(venv: Path) -> None:
    """"""Create *venv* and install dependencies if missing.""""""
    if not venv.exists():
        print(""\u2192 Creating virtual environment"")
        subprocess.check_call([sys.executable, ""-m"", ""venv"", str(venv)])
        pip = _venv_pip(venv)
        subprocess.check_call([str(pip), ""install"", ""-U"", ""pip""], stdout=subprocess.DEVNULL)
        req = Path(""alpha_factory_v1/requirements.lock"")
        if not req.exists():
            req = Path(""alpha_factory_v1/requirements.txt"")
        subprocess.check_call([str(pip), ""install"", ""-r"", str(req)])
",alpha_factory_v1/quickstart.py,,1,1.4166087846364157e-09,"The method _create_venv is a utility function that automates the creation of a virtual environment and the installation of dependencies. This is a common and useful functionality in software development, especially in Python projects where virtual environments are used to manage dependencies. The method checks if the virtual environment already exists, creates it if it doesn't, and installs the necessary packages. This kind of functionality is essential for setting up development environments and ensuring consistency across different setups. Therefore, it is likely to be retained in the codebase."
survived,"    def test_create_venv_skips_when_exists(self):
        with mock.patch('subprocess.check_call') as cc:
            venv = Path('/tmp/exists')
            venv.mkdir(exist_ok=True)
            quickstart._create_venv(venv)
            cc.assert_not_called()
            venv.rmdir()
",alpha_factory_v1/tests/test_quickstart.py,QuickstartUtilsTest,1,7.194132978569833e-09,"The method 'test_create_venv_skips_when_exists' is a unit test that checks if the '_create_venv' function in the 'quickstart' module does not call 'subprocess.check_call' when the virtual environment directory already exists. This is a valid and useful test case to ensure that the function behaves correctly in this scenario, preventing unnecessary operations. Therefore, it is likely to be retained in the codebase."
survived,"def mcts_policy(net: MiniMuNet, env: gym.Env, obs, num_simulations: int = 64):
    """"""Return policy via MuZero-style MCTS (random if torch unavailable).""""""
    if not _TORCH:
        n = env.action_space.n
        return [1 / n] * n

    state, value, policy_logits = net.initial(obs)
    root = Node(prior=1.0, state=state)
    root.children = {a: Node(prior=float(p)) for a, p in enumerate(torch.softmax(policy_logits, dim=-1))}
    root.visit_count = 1
    discount = 0.997

    for _ in range(num_simulations):
        node = root
        search_path = [node]
        actions_taken: List[int] = []

        while node.expanded():
            action, node = _select_child(node)
            actions_taken.append(action)
            search_path.append(node)

        parent = search_path[-2]
        state, reward, value, policy_logits = net.recurrent(parent.state, actions_taken[-1])
        node.state = state
        node.reward = float(reward)
        node.children = {a: Node(prior=float(p)) for a, p in enumerate(torch.softmax(policy_logits, dim=-1))}
        leaf_value = float(value)

        for n in reversed(search_path):
            n.visit_count += 1
            n.value_sum += leaf_value
            leaf_value = n.reward + discount * leaf_value

    visits = torch.tensor([c.visit_count for c in root.children.values()], dtype=torch.float32)
    policy = visits / visits.sum()
    return policy
",alpha_factory_v1/demos/muzero_planning/minimuzero.py,,1,2.8453347280241004e-08,"The method implements a Monte Carlo Tree Search (MCTS) policy for a reinforcement learning environment using a neural network. It is a specialized function that is likely part of a larger system for training or evaluating AI models in environments like those provided by OpenAI's gym. The method is well-defined, uses standard practices in reinforcement learning, and does not contain any deprecated or unsafe practices. It is also not overly complex or redundant, suggesting it serves a clear purpose in its context. Therefore, it is likely to be retained in the codebase."
survived,"    def expanded(self) -> bool:
        return self.children is not None
",alpha_factory_v1/demos/muzero_planning/minimuzero.py,Node,1,1.2501528648238603e-09,"The method 'expanded' is a simple utility function that checks if the 'children' attribute is not None, returning a boolean value. This kind of method is often useful in object-oriented programming to encapsulate logic related to the state of an object. It is likely to be used in contexts where the presence of children affects the behavior of the object, such as in tree structures or UI components. Since it provides a clear and concise way to check the state of an object, it is likely to be retained in the codebase."
survived,"    def test_play_episode(self):
        if minimuzero is None:
            self.skipTest(""muZero demo deps missing"")
        agent = minimuzero.MiniMu()
        frames, reward = minimuzero.play_episode(agent, render=False, max_steps=5)
        self.assertIsInstance(frames, list)
        self.assertIsInstance(reward, float)
        self.assertGreaterEqual(len(frames), 0)
",alpha_factory_v1/tests/test_muzero_demo.py,MiniMuTest,1,3.850741907939403e-09,"The method `test_play_episode` is a unit test designed to verify the functionality of the `play_episode` function from the `minimuzero` module. It checks if the function returns the expected types and values, which is a common practice in software development to ensure code reliability and correctness. There is no indication that this method is obsolete or redundant, and it serves a clear purpose in testing the code. Therefore, it is likely to be retained."
survived,"    def test_mcts_policy_bounds(self):
        if not dependencies_available:
            self.skipTest(""demo dependencies missing"")
        net = demo.MuZeroTiny(obs_dim=9, act_dim=4)
        obs = [0.0] * 9
        act = demo.mcts_policy(net, obs, simulations=4)
        self.assertIsInstance(act, int)
        self.assertGreaterEqual(act, 0)
        self.assertLess(act, 4)
",alpha_factory_v1/tests/test_alpha_asi_world_model.py,TestAlphaASIWorldModel,1,1.6052280526088547e-09,"The method `test_mcts_policy_bounds` is a unit test designed to verify the behavior of the `mcts_policy` function from the `demo` module. It checks if the action returned is an integer within the expected bounds. This is a typical and necessary test to ensure the function behaves correctly, especially in a machine learning or AI context where actions need to be validated. Since it serves a clear purpose in testing the functionality and correctness of the code, it is likely to be retained."
survived,"    def test_env_seconds_minimum(self):
        """"""Values below the minimum should be clamped.""""""
        with mock.patch.dict(""os.environ"", {""X"": ""2""}):
            val = ping_agent._env_seconds(""X"", 10)
        self.assertEqual(val, ping_agent._MIN_INTERVAL)
",alpha_factory_v1/tests/test_ping_agent.py,EnvSecondsTest,1,7.582560422162384e-10,"The method 'test_env_seconds_minimum' is a unit test that checks if the '_env_seconds' function correctly clamps values below a minimum threshold. This is a typical and necessary test to ensure the robustness of the '_env_seconds' function, especially when dealing with environment variables that might have unexpected values. Unit tests like this are crucial for maintaining code quality and are unlikely to be deleted unless the functionality they test is removed or significantly altered. Therefore, the method will likely be Survived."
survived,"    async def publish(self, topic, msg):
        self.messages.append((topic, msg))
",alpha_factory_v1/tests/test_ping_agent.py,DummyOrchestrator,1,9.237449576640118e-09,"The method 'publish' is a simple function that appends a tuple of 'topic' and 'msg' to a list called 'messages'. This is a basic and common operation in many applications, especially those dealing with message queues or event-driven architectures. The method is likely to be useful for maintaining a log or history of published messages, which can be crucial for debugging or auditing purposes. Therefore, it is unlikely to be deleted unless the entire messaging system is being refactored or replaced."
survived,"    def test_run_pytest_path_missing(self):
        result = local_pytest.run_pytest({}, path='/no/such/path')
        self.assertEqual(result['returncode'], -1)
        self.assertFalse(result['passed'])
        self.assertIn('Path not found', result['stderr'])
",alpha_factory_v1/tests/test_local_pytest.py,LocalPytestUtilsTest,1,4.944450477491054e-09,"The method is testing a specific scenario where a non-existent path is provided to a pytest run. This is a valid test case to ensure that the system correctly handles errors related to missing paths. Such tests are important for robustness and error handling in software, making it unlikely to be deleted."
survived,"    def test_strip_ansi(self):
        text = ""\x1b[31mred\x1b[0m normal""
        self.assertEqual(local_pytest._strip_ansi(text), ""red normal"")
",alpha_factory_v1/tests/test_local_pytest.py,LocalPytestUtilsTest,1,2.2159489282323004e-08,"The method `test_strip_ansi` is a unit test for a function `_strip_ansi` that removes ANSI escape codes from a string. This is a common requirement when dealing with terminal output that includes color codes, as it ensures the text can be processed or compared without the formatting codes. The test is straightforward and tests a specific functionality that is likely to be useful in various contexts where text processing is involved. Therefore, the method is likely to be retained as it serves a clear purpose in ensuring the correctness of the `_strip_ansi` function."
survived,"    def test_requires_token(self):
        with mock.patch.dict(os.environ, {}, clear=True):
            with self.assertRaises(SystemExit):
                import_dashboard.main()
",alpha_factory_v1/tests/test_import_dashboard.py,ImportDashboardTest,1,1.1032560311263802e-09,"The method `test_requires_token` is a unit test that checks if the `import_dashboard.main()` function raises a `SystemExit` exception when the environment variables are cleared. This is a valid test case to ensure that the function behaves correctly when required environment variables are missing. Since it serves a clear purpose in testing the robustness of the `import_dashboard.main()` function, it is likely to be retained in the codebase."
survived,"    def __init__(
        self,
        result_collector: Optional[ResultCollectionModule] = None,
        reporter: Optional[ReportingModule] = None,
    ) -> None:
        self.result_collector = result_collector or ResultCollectionModule()
        self.reporter = reporter or ReportingModule()
        self.logger = logging.getLogger(__name__)
",src/meta_agent/evaluation/harness.py,EvaluationHarness,1,9.237449576640118e-09,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class. It sets up important components like result_collector, reporter, and logger, which are likely crucial for the class's functionality. Constructors are fundamental to object-oriented programming, and unless the class itself is being removed or refactored significantly, the constructor will survive."
survived,"def test_simulate_export_formats() -> None:
    runner = CliRunner()
    with patch.object(cli.orchestrator, ""Orchestrator""):
        with patch.object(cli, ""asyncio""):
            res_json = runner.invoke(
                cli.main,
                [
                    ""simulate"",
                    ""--horizon"",
                    ""1"",
                    ""--offline"",
                    ""--pop-size"",
                    ""1"",
                    ""--generations"",
                    ""1"",
                    ""--export"",
                    ""json"",
                ],
            )
            res_csv = runner.invoke(
                cli.main,
                [
                    ""simulate"",
                    ""--horizon"",
                    ""1"",
                    ""--offline"",
                    ""--pop-size"",
                    ""1"",
                    ""--generations"",
                    ""1"",
                    ""--export"",
                    ""csv"",
                ],
            )
    assert res_json.output.startswith(""["")
    assert ""year,capability,affected"" in res_csv.output
",tests/test_cli_runner_ext.py,,1,2.646573631904765e-09,"The method 'test_simulate_export_formats' is a unit test designed to verify the functionality of a command-line interface (CLI) tool. It checks if the tool correctly exports simulation results in both JSON and CSV formats. The test uses mocking to isolate the CLI tool's behavior from external dependencies, ensuring that the test is focused on the CLI's logic. This kind of test is crucial for maintaining the reliability of software that interacts with users via command-line interfaces. Given the importance of testing in software development and the fact that this test is well-structured and serves a clear purpose, it is likely to be retained in the codebase."
survived,"    async def _sleep(*_a: object, **_kw: object) -> None:
        return None
",tests/test_agent_experience_entrypoint.py,,0,0.9999999970010391,"The method _sleep is an asynchronous function that takes any number of positional and keyword arguments but does nothing and returns None. This method is likely a placeholder or a stub for future implementation. However, as it currently stands, it serves no functional purpose and does not perform any operations. In a production codebase, such methods are often removed if they are not used or if there is no plan to implement them in the future. Therefore, it is likely to be deleted."
survived,"def longestSeq(dir):
    pd = 0
    longSeqs = [[2]]
    currSeq = [2]
    i = 1
    while i < len(primes):
        d = primes[i] - primes[i - 1]
        if (dir == ""ascending"" and d <= pd) or (dir == ""descending"" and d >= pd):
            if len(currSeq) > len(longSeqs[0]):
                longSeqs = [currSeq]
            else:
                if len(currSeq) == len(longSeqs[0]):
                    longSeqs = longSeqs + [currSeq]
            currSeq = [primes[i - 1], primes[i]]
        else:
            currSeq = currSeq + [primes[i]]
        pd = d
        i = i + 1
    if len(currSeq) > len(longSeqs[0]):
        longSeqs = [currSeq]
    else:
        if len(currSeq) == len(longSeqs[0]):
            longSeqs = longSeqs + [currSeq]
    print(""Longest run(s) of primes with "" + dir + "" differences is "" + str(len(longSeqs[0])) + "" :"")
    for ls in longSeqs:
        diffs = []
        j = 1
        while j < len(ls):
            diffs = diffs + [ls[j] - ls[j - 1]]
            j = j + 1
        k = 0
        while k < len(ls) - 1:
            print(str(ls[k]) + "" ("" + str(diffs[k]) + "") "", (""true"" if False else ""false""))
            k = k + 1
        print(str(ls[len(ls) - 1]))
    print("""")
",tests/rosetta/transpiler/Python/consecutive-primes-with-ascending-or-descending-differences.py,,0,0.9999996533672291,"The method is likely to be deleted because it contains several issues that make it inefficient and potentially incorrect. Firstly, the function relies on a global variable 'primes' which is not defined within the function or passed as a parameter, making it non-functional in its current state. Secondly, the logic for determining the longest sequence of primes with ascending or descending differences is convoluted and could be simplified. Additionally, the use of hardcoded values like '2' in the initialization of sequences and the print statements with hardcoded 'true'/'false' values suggest that the function is not well-designed or flexible. These issues indicate that the method is not robust or reusable, leading to a high likelihood of it being deleted or significantly refactored."
survived,"def test_datamodelsummary_str_sorted_entities() -> None:
    model = ModelDescription(title=""M"", description="""", entities=[])
    summary = DataModelSummary(
        title=""Test"",
        description="""",
        entity_count=3,
        entities=[""B"", ""A"", ""C""],
        model=str(model),
        usage_hint=""HINT"",
    )
    text = str(summary)
    lines = text.splitlines()
    idx = lines.index(""## Entities"")
    assert lines[idx + 1 : idx + 4] == [""- A"", ""- B"", ""- C""]
    assert lines[-1] == ""HINT""",tests/test_datamodel_summary.py,,1,1.0467401685178159e-08,"The method is a test function that verifies the behavior of the DataModelSummary class, specifically checking if the entities are sorted correctly in the string representation. Test functions are crucial for ensuring code reliability and are typically retained unless the functionality they test is removed or significantly altered. Since this test is straightforward and checks a fundamental aspect of the class, it is likely to be retained."
survived,"    async def get_next_item(self):
        prompt = (
            f""Compose a four line Sanskrit poem in the {self.config.meter} meter. ""
            ""Use IAST transliteration only.""
        )
        user_msg = {""role"": ""user"", ""content"": prompt}
        return (tuple([frozenset(user_msg.items())]), None, None)
",environments/sanskrit_poetry_env.py,SanskritPoetryEnv,1,2.646573631904765e-09,"The method 'get_next_item' is likely to survive because it is a well-defined asynchronous function that constructs a specific prompt for generating a Sanskrit poem in a specified meter. The method is clear in its purpose, utilizes Python's async capabilities, and returns a structured tuple, which suggests it is part of a larger system that processes or generates content based on user prompts. There is no indication of redundancy or inefficiency that would necessitate its deletion."
survived,"def test_cleanup_stale_entries(tmp_path):
    @cachier(
        cache_dir=tmp_path,
        stale_after=timedelta(seconds=1),
        cleanup_stale=True,
        cleanup_interval=timedelta(seconds=0),
    )
    def add(x):
        return x + 1

    add.clear_cache()
    add(1)
    add(2)
    fname = f"".{add.__module__}.{add.__qualname__}"".replace(""<"", ""_"").replace(
        "">"", ""_""
    )
    cache_path = os.path.join(add.cache_dpath(), fname)
    with open(cache_path, ""rb"") as fh:
        data = pickle.load(fh)
    assert len(data) == 2
    time.sleep(1.1)
    add(1)
    time.sleep(0.2)
    with open(cache_path, ""rb"") as fh:
        data = pickle.load(fh)
    assert len(data) == 1",tests/test_cleanup.py,,1,1.637377179507321e-07,"The method 'test_cleanup_stale_entries' is a test function that verifies the functionality of a caching mechanism with stale entry cleanup. It is a part of a test suite, likely for a library or application that uses caching. Test functions are generally not deleted unless they are redundant or the feature they test is removed. Since this function tests a specific feature (cleanup of stale cache entries), it is likely to be retained as long as the feature exists."
survived,"def test_close_stops_consumer() -> None:
    bus = EventBus(None, True)
    called = False

    async def dummy_stop() -> None:
        nonlocal called
        called = True
        bus._consumer_task = None

    bus._consumer_task = object()  # type: ignore[assignment]
    bus.stop_consumer = dummy_stop  # type: ignore[assignment]
    bus._close()
    assert called
    assert bus._consumer_task is None",tests/test_eventbus.py,,1,8.31527990378713e-07,"The method 'test_close_stops_consumer' is a test function that verifies the behavior of the 'EventBus' class when its '_close' method is called. It checks if the 'stop_consumer' method is invoked and if the '_consumer_task' is set to None. This is a typical unit test pattern to ensure that the 'EventBus' class behaves correctly when closing the consumer. Since this is a test function, it is unlikely to be deleted as it serves the purpose of verifying the functionality of the code. Test functions are generally retained to ensure code reliability and correctness."
survived,"        def __init__(self, llm=None, tools=None, name=None) -> None:
            self.llm = llm
            self.tools = tools or []
            self.name = name
",alpha_factory_v1/demos/self_healing_repo/agent_selfheal_entrypoint.py,Agent,1,4.944450477491054e-09,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. It initializes the instance variables of the class, allowing for the creation of objects with specific attributes. This is a standard and necessary practice in class design, making it unlikely to be deleted."
survived,"def test_entrypoint_offline(monkeypatch):
    monkeypatch.setitem(
        sys.modules,
        ""gradio"",
        types.SimpleNamespace(Blocks=DummyBlocks, Markdown=DummyMarkdown, Button=DummyButton),
    )

    monkeypatch.setattr(llm_client, ""call_local_model"", lambda msgs: ""local"")

    orig_import = builtins.__import__

    def fake_import(name, globals=None, locals=None, fromlist=(), level=0):
        if name == ""openai_agents"":
            raise ModuleNotFoundError(name)
        return orig_import(name, globals, locals, fromlist, level)

    monkeypatch.setattr(builtins, ""__import__"", fake_import)
    sys.modules.pop(""alpha_factory_v1.demos.self_healing_repo.agent_selfheal_entrypoint"", None)
    entrypoint = importlib.import_module(
        ""alpha_factory_v1.demos.self_healing_repo.agent_selfheal_entrypoint""
    )

    assert entrypoint.LLM(""hi"") == ""local""",tests/test_selfheal_entrypoint_offline.py,,1,2.2159489282323004e-08,"The method 'test_entrypoint_offline' is a test function that uses monkeypatching to simulate an environment where certain modules are replaced or modified. This is a common practice in testing to isolate the function being tested from external dependencies. The function is likely to survive because it is part of a test suite, which is essential for ensuring the reliability and correctness of the codebase. Test functions are generally not deleted unless they are redundant or replaced by more comprehensive tests."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/group_by_having.py,Auto1,0,0.9999038976006968,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose is likely to lead to confusion and errors, suggesting that the method should be deleted or re-implemented correctly."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/load_yaml.py,Person,0,0.9999687980937693,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical use case for `__contains__`, which is usually implemented to check for membership in a collection like a list, set, or dictionary. Therefore, this implementation is likely incorrect for its intended purpose and may be deleted or replaced with a more appropriate implementation."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/group_by_multi_join_sort.py,Lineitem,0,0.999988521231025,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement the intended functionality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/group_items_iteration.py,Auto1,0,0.9999756997690634,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, especially for users familiar with the typical use of `__contains__`. Therefore, it is likely to be deleted or refactored to align with its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/left_join_multi.py,Auto1,0,0.999983298584886,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/dataset_sort_take_limit.py,Product,0,0.9999724643101549,"The method is implementing the `__contains__` method, which is used to define behavior for the `in` keyword. However, the implementation is incorrect because it uses `hasattr(self, key)`, which checks for the presence of an attribute, not a key in a collection. Typically, `__contains__` is used for checking membership in collections like lists, sets, or dictionaries, where the key would be an element or a key in a dictionary. This misuse suggests a misunderstanding of the method's purpose, which could lead to incorrect behavior when the method is used. Therefore, it is likely to be deleted or revised to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/left_join.py,Auto1,1,0.0850990461671829,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. In this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not a typical use of `__contains__`, as it should generally check for membership in a collection rather than the presence of an attribute. However, if the class is designed to treat its attributes as keys in a collection-like manner, this implementation could be valid. Without additional context, it's difficult to determine if this is the intended use. If the class is indeed designed to treat attributes as keys, this method could survive. Otherwise, it might be considered incorrect and subject to deletion or modification."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/group_by_multi_join.py,Nation,0,0.9999962733608834,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the intended use of `__contains__`, as it should be checking for membership rather than attribute existence. This misuse of the method is likely to lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership checks. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"def test_gitignore_respected_and_overridden(test_dir: Path):
    """"""Ensure .gitignore excludes files unless overridden by .contextfiles.""""""
    (test_dir / "".gitignore"").write_text(""lib/\n"", encoding=""utf-8"")

    # Without context override, lib/ should be excluded
    content = run_read_context_helper(""project"", test_dir.parent)
    assert ""```path=lib/somelib.py"" not in content

    # Add context file that re-includes lib/
    (test_dir / CONTEXT_FILENAME).write_text(""lib/\n"", encoding=""utf-8"")
    content = run_read_context_helper(""project"", test_dir.parent)
    assert ""```path=lib/somelib.py"" in content
",tests/test_utils.py,,1,5.60279640614594e-09,"The method 'test_gitignore_respected_and_overridden' is a test function that verifies the behavior of a system regarding .gitignore and context file overrides. Test functions are generally crucial for ensuring code correctness and reliability, especially in systems that involve file handling and configuration management. This function is likely part of a test suite that ensures the correct functionality of a feature related to file inclusion/exclusion based on .gitignore and context files. Since testing is a fundamental part of software development and maintenance, this method is likely to be retained to ensure ongoing reliability and correctness of the feature it tests."
survived,"            def __init__(self, *a, **kw):
                pass
",tests/test_macro_adk_integration.py,_OpenAI,0,0.9999999123575085,"The method is an initializer for a class, but it doesn't perform any operations or initialize any attributes. This makes it redundant unless it's being used as a placeholder for future development or to override a parent class's initializer without adding functionality. However, without any context indicating such a need, it's likely to be considered unnecessary and thus deleted."
survived,"def main():
    ap = argparse.ArgumentParser(description=""Convert a subset of Python to Mochi"")
    ap.add_argument(""file"")
    ap.add_argument(""-o"", ""--out"")
    args = ap.parse_args()
    try:
        code = convert(args.file)
    except ConversionError as e:
        print(str(e), file=sys.stderr)
        raise SystemExit(1)
    if args.out:
        with open(args.out, ""w"", encoding=""utf-8"") as f:
            f.write(code)
    else:
        print(code, end="""")
",tools/any2mochi/py/py2mochi.py,,1,4.363462233903899e-09,"The method is a main function that uses argparse to handle command-line arguments, which is a common and standard practice in Python scripts. It includes error handling for conversion errors and provides functionality to either print the converted code or write it to a file. This is a well-structured and useful utility function for command-line tools, making it likely to be retained in the codebase."
survived,"    def __init__(self, msg: str, lineno: int, line: str):
        super().__init__(msg)
        self.lineno = lineno
        self.line = line
",tools/any2mochi/py/py2mochi.py,ConversionError,1,6.348800075736417e-09,"The method is a constructor for a class, initializing important attributes such as 'msg', 'lineno', and 'line'. These attributes are likely essential for the functionality of the class, as they store information that is probably used elsewhere in the class methods. Constructors are fundamental to class design, and unless there is a significant change in the class structure or design, they are rarely deleted. Therefore, this method is likely to survive."
survived,"    def convert_lambda(
        self,
        node: ast.Lambda,
        annotated_args: list[str] | None = None,
        ret_type: str | None = None,
    ) -> str:
        parts = []
        for i, a in enumerate(node.args.args):
            typ = (
                annotated_args[i]
                if annotated_args and i < len(annotated_args)
                else None
            )
            if typ:
                parts.append(f""{a.arg}: {typ}"")
            else:
                parts.append(a.arg)
        body = self.convert_expr(node.body)
        if ret_type:
            return f""fun({', '.join(parts)}): {ret_type} => {body}""
        return f""fun({', '.join(parts)}) => {body}""
",tools/any2mochi/py/py2mochi.py,Converter,1,5.905303995456778e-10,"The method `convert_lambda` is a utility function that converts an abstract syntax tree (AST) representation of a lambda function into a string representation with optional type annotations. This kind of functionality is useful in code analysis, transformation, or generation tasks, which are common in various programming tools and compilers. Given the increasing importance of code analysis and transformation in modern software development, such methods are likely to be retained and possibly even expanded upon. Therefore, the method is predicted to survive."
survived,"    def convert_list_comp(self, node: ast.ListComp) -> str:
        parts: list[str] = []

        def parse_dataset_iter(it: ast.expr) -> tuple[str, str | None, str | None, str | None]:
            sort = None
            skip = None
            take = None
            cur = it

            # handle take
            if isinstance(cur, ast.Subscript) and isinstance(cur.slice, ast.Slice):
                sl = cur.slice
                if (
                    sl.lower is None
                    and sl.step is None
                    and isinstance(sl.upper, ast.Call)
                    and getattr(sl.upper.func, ""id"", None) == ""max""
                    and len(sl.upper.args) == 2
                    and isinstance(sl.upper.args[1], ast.Constant)
                    and sl.upper.args[1].value == 0
                ):
                    take = self.convert_expr(sl.upper.args[0])
                    cur = cur.value

            # handle skip
            if isinstance(cur, ast.Subscript) and isinstance(cur.slice, ast.Slice):
                sl = cur.slice
                if (
                    sl.upper is None
                    and sl.step is None
                    and isinstance(sl.lower, ast.Call)
                    and getattr(sl.lower.func, ""id"", None) == ""max""
                    and len(sl.lower.args) == 2
                    and isinstance(sl.lower.args[1], ast.Constant)
                    and sl.lower.args[1].value == 0
                ):
                    skip = self.convert_expr(sl.lower.args[0])
                    cur = cur.value

            # handle sort
            if isinstance(cur, ast.Call) and isinstance(cur.func, ast.Name) and cur.func.id == ""sorted"":
                if cur.keywords:
                    for kw in cur.keywords:
                        if kw.arg == ""key"" and isinstance(kw.value, ast.Lambda):
                            body = kw.value.body
                            if (
                                isinstance(body, ast.Call)
                                and isinstance(body.func, ast.Name)
                                and body.func.id == ""_sort_key""
                                and body.args
                            ):
                                sort = self.convert_expr(body.args[0])
                            else:
                                sort = self.convert_expr(body)
                if cur.args:
                    cur = cur.args[0]

            # remove trivial list comp wrappers
            if (
                isinstance(cur, ast.ListComp)
                and len(cur.generators) == 1
                and isinstance(cur.generators[0].target, ast.Name)
                and isinstance(cur.elt, ast.Name)
                and cur.elt.id == cur.generators[0].target.id
                and not cur.generators[0].ifs
            ):
                cur = cur.generators[0].iter

            return self.convert_expr(cur), sort, skip, take

        if not node.generators:
            return ""[]""

        first = node.generators[0]
        # special case: [T(**it) for it in _load(...)] -> load ... as T
        if (
            len(node.generators) == 1
            and isinstance(node.elt, ast.Call)
            and isinstance(node.elt.func, ast.Name)
            and node.elt.func.id in self.dataclasses
            and not node.elt.args
            and len(node.elt.keywords) == 1
            and node.elt.keywords[0].arg is None
            and isinstance(node.elt.keywords[0].value, ast.Name)
            and isinstance(first.target, ast.Name)
            and node.elt.keywords[0].value.id == first.target.id
            and isinstance(first.iter, ast.Call)
            and isinstance(first.iter.func, ast.Name)
            and first.iter.func.id == ""_load""
        ):
            load_expr = self.convert_expr(first.iter)
            typ = node.elt.func.id
            if load_expr.startswith(""load""):
                if "" with "" in load_expr:
                    base, rest = load_expr.split("" with "", 1)
                    return f""{base} as {typ} with {rest}""
                return f""{load_expr} as {typ}""

        base_iter, sort, skip, take = parse_dataset_iter(first.iter)
        parts.append(f""from {self.convert_expr(first.target)} in {base_iter}"")

        for gen in node.generators[1:]:
            parts.append(
                f""from {self.convert_expr(gen.target)} in {self.convert_expr(gen.iter)}""
            )

        ifs: list[str] = []
        for gen in node.generators:
            for if_ in gen.ifs:
                ifs.append(self.convert_expr(if_))
        if ifs:
            parts.append(""where "" + "" and "".join(ifs))
        if sort:
            parts.append(""sort by "" + sort)
        if skip:
            parts.append(""skip "" + skip)
        if take:
            parts.append(""take "" + take)
        parts.append(""select "" + self.convert_expr(node.elt))

        result = parts[0]
        indent = ""            ""
        for part in parts[1:]:
            result += ""\n"" + indent + part
        return result
",tools/any2mochi/py/py2mochi.py,Converter,1,3.3982678079468468e-09,"The method `convert_list_comp` is a complex function that converts Python list comprehensions into a string representation, possibly for a custom query language or DSL. It handles various cases like sorting, skipping, and taking elements, as well as special cases for loading data. This functionality is quite specific and seems to be part of a larger system that processes or transforms Python AST nodes. Given its complexity and specificity, it is unlikely to be removed unless the entire system or approach is deprecated. Therefore, the method is likely to survive."
deleted,"    def __init__(self) -> None:
        self.count = 0
        self.input_chars = 0
        self.output_chars = 0
",src/serena/analytics.py,ToolStatsEntry,1,2.998960815863541e-09,"The method is a constructor (__init__) for a class, which is essential for initializing object attributes. It sets up initial values for the instance variables 'count', 'input_chars', and 'output_chars'. Constructors are fundamental to object-oriented programming as they ensure that objects are in a valid state when created. Therefore, this method is likely to survive as it is necessary for the proper functioning of the class."
survived,"    async def first(app: EnrichMCP):
        call_order.append(""first"")
        yield {""a"": 1}
",tests/test_lifespan.py,,1,4.1399375473943306e-08,"The method 'first' is an asynchronous generator function that appends a string to a list and yields a dictionary. This functionality seems specific and useful for certain operations, such as logging or tracking the order of function calls in an asynchronous context. Without additional context indicating that this method is redundant or replaced, it is likely to be retained for its utility in managing asynchronous workflows."
survived,"        async def act(self) -> str:
            return ""done""
",tests/test_agent_experience_entrypoint.py,DummyAgent,1,9.736200303530205e-10,"The method is a simple asynchronous function that returns a string 'done'. It is syntactically correct and serves a clear purpose, which is to return a specific string when called. There is no indication of redundancy, inefficiency, or any other reason for it to be deleted. Therefore, it is likely to survive."
survived,"        def wrapper(*args, **kwargs):
            while True:
                try:
                    return func(*args, **kwargs)
                except Exception as exc:
                    logger.exception(
                        ""%s failed with %s ‚Äî retrying in %.2f s"",
                        func.__name__,
                        exc,
                        retry_delay,
                    )
                    time.sleep(retry_delay)
",autogpt_platform/backend/backend/util/retry.py,,1,5.60279640614594e-09,"The method is a wrapper function designed to repeatedly attempt to execute a given function (`func`) until it succeeds, handling exceptions by logging them and retrying after a specified delay (`retry_delay`). This pattern is common in scenarios where transient errors are expected, such as network requests or database operations. The use of logging and retry mechanisms is a robust approach to increase the reliability of operations that may fail due to temporary issues. Therefore, this method is likely to be useful and survive."
survived,"    def _safe_import(
        name: str,
        globals: dict | None = None,
        locals: dict | None = None,
        fromlist: tuple[str] | tuple = (),
        level: int = 0,
    ):
        allowed_prefixes = (
            ""pandas"",
            ""numpy"",
            ""math"",
            ""random"",
            ""statistics"",
            ""scipy"",
            ""statsmodels"",
            ""json"",
        )
        if not any(name.startswith(prefix) for prefix in allowed_prefixes):
            raise ImportError(f""Import of '{name}' is not allowed"")
        return __import__(name, globals, locals, fromlist, level)
",backend/tools/analysis_tools.py,,1,4.1399375473943306e-08,"The method '_safe_import' is designed to restrict imports to a predefined list of allowed modules. This can be a useful security measure in environments where you want to prevent arbitrary code execution by limiting the modules that can be imported. The method is straightforward, serves a clear purpose, and is implemented correctly. It is likely to be retained in the codebase as it provides a necessary functionality for controlled imports, especially in environments where security is a concern."
survived,"def start_background_tasks() -> None:
    """"""Launch health monitor and rescan loops exactly once.""""""
    global _bg_started, _health_thread, _rescan_thread
    if _bg_started:
        return
    _bg_started = True
    _health_thread = threading.Thread(
        target=_health_loop, daemon=True, name=""agent-health""
    )
    _rescan_thread = threading.Thread(
        target=_rescan_loop, daemon=True, name=""agent-rescan""
    )
    _health_thread.start()
    _rescan_thread.start()
",alpha_factory_v1/backend/agents/__init__.py,,1,1.8189616842444243e-09,"The method 'start_background_tasks' is likely to survive because it performs a critical function of launching background tasks that are essential for the application's operation. It ensures that the health monitoring and rescanning processes are initiated only once, which is a common requirement in applications that need to manage resources efficiently. The use of global variables to track the state of these threads indicates that this method is part of a larger system where these background tasks are necessary for maintaining the application's functionality."
deleted,"  async def test_aspirate_custom_flow_rate(self):
    op = SingleChannelAspiration(
      resource=self.plate.get_item(""A1""),
      offset=Coordinate.zero(),
      tip=self.tr.get_tip(""A1""),
      volume=100,
      flow_rate=200,
      liquid_height=10,
      blow_out_air_volume=0,
      liquids=[(None, 100)],
    )
    await self.evo.aspirate([op], use_channels=[0])
    self.evo.send_command.assert_any_call(
      module=""C5"",
      command=""SSZ"",
      params=[60, None, None, None, None, None, None, None],
    )
    self.evo.send_command.assert_any_call(
      module=""C5"",
      command=""SEP"",
      params=[2400, None, None, None, None, None, None, None],
    )
",pylabrobot/liquid_handling/backends/tecan/EVO_tests.py,EVOTests,1,1.1253518384332553e-07,"The method `test_aspirate_custom_flow_rate` is a unit test for a specific functionality related to a custom flow rate in an aspiration operation. Unit tests are crucial for ensuring that code behaves as expected and for catching regressions when changes are made. This test checks that the correct commands are sent with the expected parameters, which is an important aspect of verifying the system's behavior. Therefore, it is unlikely to be deleted as it serves a valuable purpose in maintaining code quality and reliability."
survived,"    def remove(self, node):
        ''' Removes a child node '''
        self.children.remove(node)
        NCRPNode.total_nodes -= 1
",src/hlda/sampler.py,NCRPNode,1,1.955568070542584e-08,"The method 'remove' is a basic utility function that removes a child node from a list of children and decrements a counter tracking the total number of nodes. This functionality is essential for managing a tree or graph structure, ensuring that nodes can be dynamically removed as needed. Such methods are fundamental in data structure management and are unlikely to be removed unless the entire data structure is being deprecated or replaced."
survived,"    def add_child(self):
        ''' Adds a child to the next level of this node '''
        node = NCRPNode(
            self.num_levels,
            self.vocab,
            parent=self,
            level=self.level + 1,
            random_state=self.random_state,
        )
        self.children.append(node)
        NCRPNode.total_nodes += 1
        return node
",src/hlda/sampler.py,NCRPNode,1,4.363462233903899e-09,"The method 'add_child' is a fundamental part of the class it belongs to, as it is responsible for adding a new child node to the current node. This is a common operation in tree-like data structures, where nodes are often added dynamically. The method is well-defined, with a clear purpose and implementation, and it updates the necessary attributes such as 'children' and 'total_nodes'. There is no indication that this method is redundant or unnecessary, and it likely plays a crucial role in the functionality of the class. Therefore, it is unlikely to be deleted."
survived,"    def get_top_words(self, n_words, with_weight):
        ''' Get the top n words in this node '''

        pos = np.argsort(self.word_counts)[::-1]
        sorted_vocab = self.vocab[pos]
        sorted_vocab = sorted_vocab[:n_words]
        sorted_weights = self.word_counts[pos]
        sorted_weights = sorted_weights[:n_words]

        output = ''
        for word, weight in zip(sorted_vocab, sorted_weights):
            if with_weight:
                output += '%s (%d), ' % (word, weight)
            else:
                output += '%s, ' % word
        return output
",src/hlda/sampler.py,NCRPNode,1,3.850741907939403e-09,"The method `get_top_words` is a utility function that retrieves the top `n_words` from a vocabulary based on their frequency or weight. It is a common requirement in text processing and natural language processing tasks to extract and display the most significant words from a dataset. The method is well-defined, with clear input parameters and a straightforward output format. It also provides flexibility by allowing the user to choose whether to include word weights in the output. These characteristics make it a useful and reusable piece of code, which is likely to be retained in a codebase."
survived,"def _fstringify_notebook(filename: str, state: State) -> Optional[FstringifyResult]:
    """"""Apply fstringify transformations to all code cells in a notebook.""""""
    try:
        with open(filename, encoding=""utf-8"") as f:
            nb = json.load(f)
    except Exception:
        log.error(f""Exception while reading {filename}"", exc_info=True)
        return None

    original_dump = json.dumps(nb, ensure_ascii=False, indent=1)
    changes = 0

    for idx, cell in enumerate(nb.get(""cells"", [])):
        if cell.get(""cell_type"") != ""code"":
            continue
        source = """".join(cell.get(""source"", []))
        result = fstringify_code(source, state, filename=f""{filename}[{idx}]"")
        if not result:
            continue
        changes += result.n_changes
        if result.content != source:
            cell[""source""] = result.content.splitlines(keepends=True)

    new_dump = json.dumps(nb, ensure_ascii=False, indent=1)
    if state.dry_run and changes:
        diff = unified_diff(
            original_dump.split(""\n""), new_dump.split(""\n""), fromfile=filename
        )
        print(""\n"".join(diff))
    elif state.stdout:
        print(new_dump)
    elif changes:
        with open(filename, ""w"", encoding=""utf-8"") as f:
            f.write(new_dump)

    return FstringifyResult(
        n_changes=changes,
        original_length=len(original_dump),
        new_length=len(new_dump),
        content=new_dump,
    )
",src/flynt/api.py,,1,2.0611536181902033e-09,"The method '_fstringify_notebook' is a utility function designed to apply fstring transformations to code cells within a Jupyter notebook. It handles file reading, JSON parsing, and iterates over notebook cells to apply transformations. The function is robust, with error handling for file operations and conditional logic for different states (dry run, stdout). It returns a result object with transformation details, making it useful for logging or further processing. Given its utility, error handling, and structured output, it is likely to be retained in the codebase."
survived,"def get_locale():
    return session.get(""lang"", ""en"")
",app.py,,1,2.4616969512093895e-10,"The method 'get_locale' is a simple utility function that retrieves a language setting from a session object, defaulting to 'en' if not set. This is a common pattern in web applications to handle localization. Such utility functions are generally useful and unlikely to be removed unless the entire localization approach is refactored. Therefore, it is likely to survive."
survived,"def test_attention_paged_decode_prefill_in_chunks(prefix_size, chunk_size):
    B = Axis(""batch"", 2)
    Pos = Axis(""position"", prefix_size + 4 * chunk_size)
    Embed = Axis(""embed"", 16)

    cfg = AttentionConfig(Embed=Embed, num_heads=2, num_kv_heads=2, rope=None, attn_backend=AttentionBackend.VANILLA)
    attn_key, x_key = jrandom.split(jrandom.PRNGKey(0))
    attn = Attention.init(cfg, key=attn_key)
    x = hax.random.normal(x_key, (B, Pos, Embed)) * 0.2
    full_out = attn(x, AttentionMask.causal(), key=jrandom.PRNGKey(1))

    cache = _build_page_cache(cfg, B, Pos)
    prefix = x[Pos, 0:prefix_size]
    prefill_chunk, cache = _jit_paged_decode(
        attn, prefix, pos_ids=hax.arange(Pos.resize(prefix_size), dtype=jnp.int32), cache=cache
    )

    out_chunks = [prefill_chunk]
    for i in range(prefix_size, Pos.size, chunk_size):
        x_tok = x[Pos, hax.dslice(i, chunk_size)]
        sub_pos = x_tok.resolve_axis(""position"")
        pos_ids_tok = hax.arange(sub_pos, dtype=jnp.int32, start=i)
        out_tok, cache = _jit_paged_decode(attn, x_tok, pos_ids_tok, cache)
        out_chunks.append(out_tok)

    decoded_arr = hax.concatenate(""position"", out_chunks)
    assert_trees_all_close(full_out, decoded_arr, atol=1e-4, rtol=1e-4)
",tests/test_attention.py,,1,4.6911638017642294e-08,"The method is a test function, which is typically used to verify the correctness of code. Test functions are generally not deleted unless they are redundant or replaced by more comprehensive tests. This function appears to be testing a specific functionality related to attention mechanisms, which is a common and important aspect in machine learning models. Therefore, it is likely to be retained to ensure the reliability of the code it tests."
survived,"    def test_qclid_set_get(self):
        klong = KlongInterpreter()
        klong('d::.qclid(4321)')
        d = klong('d')
        self.assertTrue(d.is_open())
        d.set(KGSym('a'), 42)
        self.assertEqual(d.connection.conn.queries[-1], 'a::42')
        r = d.get('x+y')
        self.assertEqual(r, 'EXEC:x+y')
        self.assertEqual(d.connection.conn.queries[-1], 'x+y')
        klong('.qclic(d)')
        self.assertFalse(d.is_open())
",tests/test_sys_fn_kdb.py,TestKdbIPC,1,1.522997951276035e-08,"The method 'test_qclid_set_get' is a unit test for a specific functionality of the KlongInterpreter class. It tests the setting and getting of values using the '.qclid' and '.qclic' functions, ensuring that the connection is properly opened and closed, and that queries are executed as expected. This is a crucial part of testing the functionality and reliability of the KlongInterpreter, especially if it is part of a larger system that relies on these operations. Therefore, it is unlikely to be deleted as it serves an important role in verifying the correctness of the code."
survived,"    def __init__(self) -> None:
        self.loaded = None
",tests/test_orchestrator_rest.py,DummyAgent,1,7.194132978569833e-09,"The method is a constructor for a class, indicated by the name `__init__`. It initializes an instance variable `self.loaded` to `None`. This is a common pattern in Python to set up initial state for an object. Since constructors are essential for creating instances of classes, this method is unlikely to be deleted unless the entire class is being refactored or removed. Therefore, it is more likely to survive."
survived,"    def _update_metrics(self) -> None:
        if not self._items:
            return
        scores = [c.fitness for c in self._items]
        metrics.dgm_best_score.set(max(scores))
        metrics.dgm_archive_mean.set(sum(scores) / len(scores))
        metrics.dgm_lineage_depth.set(len(self._items))
",src/evolve.py,InMemoryArchive,1,3.850741907939403e-09,"The method '_update_metrics' is a utility function that updates certain metrics based on the '_items' attribute. It checks if '_items' is not empty before proceeding, which is a good practice to avoid errors. The method calculates the maximum score, mean score, and lineage depth, which are likely important for monitoring or logging purposes. These operations are straightforward and efficient, suggesting that the method is well-implemented for its intended purpose. Therefore, it is likely to be retained in the codebase."
survived,"def test_compare_df_shape_mismatch():
    df1 = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})
    df2 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6]})
    assert not compare_df(df1, df2, question=""test"")
",backend/tests/test_utils_sql_compare_df.py,,1,1.3440409770490404e-08,"The method `test_compare_df_shape_mismatch` is a unit test designed to verify the behavior of the `compare_df` function when the input dataframes have different shapes. This is a common scenario that needs to be tested to ensure the function handles shape mismatches correctly. Unit tests are crucial for maintaining code quality and ensuring that functions behave as expected under various conditions. Therefore, this method is likely to be retained as part of the test suite to ensure the robustness of the `compare_df` function."
survived,"    def get_vertex_id():
        lat = float(request.args[""lat""])
        lon = float(request.args[""lon""])
        return Response(rs.get_vertex_id(lat, lon), mimetype=""application/json"")
",pygs/graphserver/ext/routeserver/routeserver.py,,1,4.944450477491054e-09,"The method 'get_vertex_id' is a simple function that retrieves latitude and longitude from request arguments, converts them to floats, and then calls another function 'rs.get_vertex_id' with these values. It returns the result as a JSON response. The method is straightforward and performs a specific task without any apparent issues or inefficiencies. Unless there is a change in requirements or the 'rs.get_vertex_id' function is deprecated, there is no reason to delete this method. It is likely to survive as it serves a clear purpose in the codebase."
survived,"def load_weights(path: str | Path | None = None) -> dict[str, float | Sequence[float]]:
    """"""Return weight configuration loaded from YAML.""""""
    p = Path(path) if path is not None else _DEFAULT_YAML
    try:
        data = yaml.safe_load(p.read_text(encoding=""utf-8""))
    except Exception:
        data = {}
    return data or {}
",src/simulation/surrogate_fitness.py,,1,9.237449576640118e-09,"The method 'load_weights' is a utility function designed to load weight configurations from a YAML file. It is a simple, clear, and useful function that handles file reading and YAML parsing, with a fallback to a default path if none is provided. The function also includes error handling to return an empty dictionary in case of exceptions, which is a good practice. These characteristics make it a robust and reusable piece of code, likely to be retained in the codebase."
survived,"def test_recognize_vosk_verbose(audio_data):
    recognizer = Recognizer()
    actual = recognizer.recognize_vosk(audio_data, verbose=True)

    assert actual == {""text"": ""one two three""}",tests/recognizers/test_vosk.py,,1,8.152020648014727e-09,"The method 'test_recognize_vosk_verbose' is a unit test function that tests the 'recognize_vosk' method of a 'Recognizer' class. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with audio recognition, which can be complex and error-prone. The test checks if the method returns the expected output when the 'verbose' parameter is set to True. Since testing is an essential part of software development and maintenance, this method is likely to be retained to ensure the functionality of the 'recognize_vosk' method remains consistent and correct."
survived,"def test_download_file_success(tmp_path: Path, requests_mock: ""requests_mock.Mocker"") -> None:
    monkeypatch_file_list = [""dummy.txt""]
    url = dg.model_urls(""117M"")[0].replace(""checkpoint"", ""dummy.txt"")
    requests_mock.get(url, text=""ok"")

    dest_dir = tmp_path / ""models""
    with pytest.MonkeyPatch.context() as m:
        m.setattr(dg, ""_FILE_LIST"", monkeypatch_file_list)
        dg.download_openai_gpt2(""117M"", dest=dest_dir)

    assert (dest_dir / ""117M"" / ""dummy.txt"").read_text() == ""ok""
",tests/test_download_openai_gpt2.py,,1,2.5109990926928157e-08,"The method 'test_download_file_success' is a unit test function that verifies the successful download of a file using a mocked request. It uses the 'requests_mock' library to simulate a network request and 'pytest.MonkeyPatch' to temporarily modify the file list. The test checks if the downloaded file contains the expected content. This is a typical and useful test case for ensuring the functionality of file downloading in a codebase, especially when dealing with external resources. Therefore, it is likely to be retained as it serves a clear purpose in testing the code's functionality."
survived,"def _make_client(monkeypatch: pytest.MonkeyPatch, token: str = ""secret"") -> TestClient:
    monkeypatch.setenv(""API_TOKEN"", token)
    app = orchestrator._build_rest({""dummy"": DummyRunner()})
    assert app is not None
    return TestClient(app)
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_backend_rest_auth.py,,1,2.5109990926928157e-08,"The method '_make_client' is a utility function used in testing to create a test client with a specific environment variable set. It uses 'monkeypatch' to set the 'API_TOKEN' environment variable, which is a common practice in testing to simulate different environments or configurations. The function is likely to be useful for testing purposes, especially in scenarios where different tokens need to be tested. Therefore, it is unlikely to be deleted as it serves a specific purpose in the testing framework."
survived,"    def prompt_audio(self) -> str | None:
        prompt = self.properties.get(""prompt_audio"")
        if prompt is None:
            return None
        if not isinstance(prompt, str):
            raise ValueError(""Invalid prompt_audio. prompt_audio must be a string."")
        return prompt
",libs/core/kiln_ai/datamodel/extraction.py,ExtractorConfig,1,1.1032560311263802e-09,"The method 'prompt_audio' is a simple utility function that retrieves a value from a dictionary and performs basic validation. It is likely to survive because it serves a clear purpose in accessing and validating data, which is a common requirement in many applications. The method is concise, follows good practices by checking the type of the data, and raises an appropriate error if the data is not as expected. These characteristics make it a useful and maintainable piece of code."
survived,"    def __init__(self, registry: Optional[TemplateRegistry] = None) -> None:
        self.registry = registry or TemplateRegistry()
",src/meta_agent/template_creator.py,TemplateCreator,1,2.3823698451773172e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting up initial states. This particular constructor also includes a default behavior by initializing the registry with a new TemplateRegistry if none is provided, which is a common and useful pattern. Therefore, it is unlikely to be deleted."
survived,"def test_validate_template_failure() -> None:
    ok, err = validate_template(""{% for x in %}"")
    assert not ok and err
",tests/test_template_creator.py,,1,6.023574641292144e-08,"The method `test_validate_template_failure` is a unit test designed to check the failure case of the `validate_template` function. It asserts that the function returns a failure (not ok) and an error message when given an invalid template string. This is a typical and necessary test to ensure that the `validate_template` function correctly identifies and handles invalid input. Therefore, it is unlikely to be deleted as it serves an important role in maintaining the robustness and reliability of the code."
survived,"async def test_broadcast_merkle_root_local_validator(
    tmp_path: Path, validator: str
) -> None:
    ledger = Ledger(str(tmp_path / ""ledger.db""), rpc_url=validator, broadcast=True)
    env = messaging.Envelope(""a"", ""b"", {""v"": 1}, 0.0)
    ledger.log(env)
    resp = requests.post(
        validator, json={""jsonrpc"": ""2.0"", ""id"": 1, ""method"": ""getLatestBlockhash""}
    )
    start_slot = resp.json()[""result""][""context""][""slot""]
    try:
        await ledger.broadcast_merkle_root()
        for _ in range(20):
            time.sleep(1)
            resp = requests.post(
                validator,
                json={""jsonrpc"": ""2.0"", ""id"": 1, ""method"": ""getLatestBlockhash""},
            )
            if resp.json()[""result""][""context""][""slot""] > start_slot:
                break
        else:
            raise AssertionError(""no new block produced"")
    finally:
        await ledger.stop_merkle_task()
        ledger.close()
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_ledger_local_validator.py,,1,2.3823698451773172e-07,"The method `test_broadcast_merkle_root_local_validator` is a test function that appears to be part of a testing suite for a blockchain or distributed ledger system. It is designed to test the functionality of broadcasting a Merkle root and ensuring that new blocks are produced. This kind of test is crucial for validating the integrity and performance of the ledger system. Test functions are generally not deleted unless they are redundant, replaced by more comprehensive tests, or the functionality they test is deprecated. Since this function seems to be testing a core feature (broadcasting Merkle roots and block production), it is likely to be retained as long as the feature it tests is relevant."
survived,"def _start_server(directory: Path):
    handler = partial(http.server.SimpleHTTPRequestHandler, directory=str(directory))
    server = http.server.ThreadingHTTPServer((""localhost"", 0), handler)
    thread = threading.Thread(target=server.serve_forever, daemon=True)
    thread.start()
    return server, thread
",tests/test_pwa_update_reload.py,,1,8.152020648014727e-09,"The method _start_server is a utility function that sets up a simple HTTP server using Python's built-in http.server module. It is a useful function for quickly serving files from a directory, especially during development or testing. The use of threading allows the server to run in the background without blocking the main program, which is a common requirement for such utility functions. Given its utility and the fact that it leverages standard library components effectively, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q19.py,Part,0,0.999985261023967,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q10.py,Order,0,0.9999785550602307,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q6.py,Lineitem,1,2.1444939769331175e-05,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually used to check for membership in a collection like a list, set, or dictionary. However, if the class is designed to treat its attributes as a collection of keys, this implementation could be valid. Without additional context, it's hard to definitively say if this is a misuse or a valid use case. Given the flexibility of Python and the potential for custom implementations, this method is likely to survive unless it causes confusion or errors in the intended use of the class."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q20.py,Auto1,0,0.9999982396568657,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement the intended functionality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q1.py,Auto1,0,0.9999921107349486,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be used for checking membership in a collection like a list, set, or dictionary. Therefore, this method is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q8.py,Supplier,0,0.9999898700118929,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement the intended functionality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q2.py,Partsupp,0,0.9999952149051502,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical use case for `__contains__`, which is expected to check membership rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q20.py,Auto3,0,0.9999921107349486,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement the intended functionality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q11.py,Auto5,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q31.py,Auto5,1,4.6911638017642294e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is likely to be retained because it provides a flexible way to access object attributes and is consistent with Python's design philosophy of allowing objects to behave like built-in types when appropriate."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q12.py,Auto4,1,1.0467401685178159e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. It is likely to be retained if the class is intended to provide such functionality, as it offers a flexible way to access attributes dynamically. Therefore, the method will likely survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q27.py,Auto9,0,0.9999687980937693,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose is likely to lead to confusion and errors, suggesting that the method should be deleted or re-implemented correctly."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q24.py,Auto8,1,6.023574641292144e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. It is likely to be retained because it provides a flexible and Pythonic way to access object attributes, enhancing the usability of the class."
survived,"def test_Q31_finds_minimal_budget__votes__writer_and_title():
    assert result == [
        Auto1(
            movie_budget=""Horror"",
            movie_votes=800,
            writer=""Arthur"",
            violent_liongate_movie=""Alpha Horror"",
        )
    ]
",tests/dataset/job/compiler/py/q31.py,,1,3.0590235908148916e-07,"The method name 'test_Q31_finds_minimal_budget__votes__writer_and_title' suggests that it is a test function, likely part of a test suite for a larger codebase. Test functions are generally not deleted unless they are redundant or replaced by more comprehensive tests. Since this function seems to be testing a specific scenario or feature, it is likely to be retained to ensure the functionality it tests remains correct."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q10.py,Auto6,0,0.9999910602998366,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement the intended functionality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q19.py,Auto2,0,0.9998415637531546,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the standard or expected behavior for `__contains__`, which is usually used for membership testing in collections like lists, sets, or dictionaries. This misuse of `__contains__` could lead to confusion and unexpected behavior, as it does not align with the typical use case of checking for membership in a collection. Therefore, it is likely that this method will be deleted or refactored to better align with its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q17.py,Auto8,0,0.999983298584886,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"def test_Q17_finds_US_character_name_movie_with_actor_starting_with_B():
    assert result == [
        Auto1(member_in_charnamed_american_movie=""Bob Smith"", a1=""Bob Smith"")
    ]
",tests/dataset/job/compiler/py/q17.py,,1,3.466327708641819e-07,"The method is a test function, which is typically used to verify the correctness of a specific piece of code. Test functions are generally not deleted unless they are redundant, incorrect, or the functionality they are testing is no longer needed. Since this test function seems to be checking a specific condition (finding a US character name in a movie with an actor starting with 'B'), it is likely part of a suite of tests ensuring the reliability of a larger codebase. Therefore, it is more likely to be maintained rather than deleted."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q15.py,Auto5,1,4.785094849865141e-06,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in collections like lists or dictionaries. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid use case if the object is designed to allow attribute access via indexing. However, this implementation can be considered unconventional because `__getitem__` is usually associated with index-based access rather than attribute access. Despite this, the method is functional and could be useful in specific scenarios where such behavior is desired. Therefore, it is likely to survive unless there is a strong reason to enforce conventional use of `__getitem__`."
survived,"def test_Q21_finds_western_follow_up_sequels():
    assert result == [
        Auto1(
            company_name=""ACME Film Works"",
            link_type=""is follow up"",
            western_follow_up=""Western Return"",
        )
    ]
",tests/dataset/job/compiler/py/q21.py,,1,2.3355930333443423e-09,"The method `test_Q21_finds_western_follow_up_sequels` is a test function, likely part of a test suite for a larger codebase. Test functions are generally not deleted unless they are redundant, incorrect, or replaced by more comprehensive tests. Since this function appears to be a specific test case checking for a particular condition (finding western follow-up sequels), it is likely to be useful for ensuring the correctness of the related functionality. Therefore, it is more likely to survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q26.py,Auto1,1,2.5109990926928157e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name, which can be useful for objects that need to provide dictionary-like access to their attributes. This is a common and useful pattern in Python, especially for classes that need to provide flexible attribute access. Therefore, the method is likely to be retained as it serves a clear purpose and follows a standard pattern."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/job/compiler/py/q30.py,,1,5.60279640614594e-09,"The method '_key' is a utility function that is likely used internally within a module or class to generate a key for sorting purposes. It takes an iterable 'it', applies a sorting key function from 'opts', and ensures the key is a string if it's a complex data type. This kind of function is common in data processing or sorting operations, and unless the entire module or class is being refactored or removed, such utility functions are typically retained. Therefore, it is likely to survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q3.py,Auto3,1,0.0850990461671829,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually implemented to check for membership in a collection like a list, set, or dictionary. However, if the class is designed to treat its attributes as a collection of keys, this implementation could be valid. Without additional context, it's difficult to determine if this is the intended use. If the class is indeed designed to treat its attributes as keys, this method could survive. Otherwise, it might be considered a misuse of `__contains__` and could be deleted or refactored."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q17.py,Auto1,1,1.955568070542584e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python to allow more flexible and dynamic access to object properties. Therefore, this method is likely to be retained as it serves a clear purpose and is implemented correctly."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q16.py,Auto4,0,0.9999599363048656,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical or expected behavior for `__contains__`, which is usually used for membership testing in collections like lists, sets, or dictionaries. This misuse of the method could lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership testing. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q17.py,Auto6,0,0.9999991684720096,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or replaced with a more appropriate implementation."
survived,"def _min(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""min() expects list or group"")
    vals = [it for it in v if it is not None]
    if not vals:
        return 0
    return min(vals)
",tests/dataset/job/compiler/py/q33.py,,0,0.9924227578181974,"The method '_min' is a utility function that attempts to find the minimum value in a list or a list-like object. However, it has several issues that make it less robust and potentially problematic:

1. **Naming Convention**: The method name '_min' suggests it is a private method, but it doesn't follow the typical Python naming conventions for private methods, which usually involve a single underscore.

2. **Type Checking**: The method checks if the input has an 'Items' attribute and assigns it to 'v', but this is not a common pattern in Python. It assumes that any object with an 'Items' attribute is list-like, which may not always be true.

3. **Error Handling**: The method raises a generic Exception with a message that may not be informative enough for debugging purposes. It would be better to raise a more specific exception, such as a TypeError.

4. **Handling of None Values**: The method filters out None values before finding the minimum, which is a reasonable approach. However, it returns 0 if the list is empty after filtering, which might not be the expected behavior for all use cases.

5. **Lack of Documentation**: There is no documentation or comments explaining the purpose or usage of the method, which can make it difficult for other developers to understand its intent.

Due to these issues, the method is likely to be refactored or replaced with a more robust solution, especially since Python's built-in 'min' function already provides similar functionality with better error handling and flexibility."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q26.py,Auto11,1,4.222835268240621e-06,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in collections like lists or dictionaries. In this code, `__getitem__` is implemented to use `getattr` to access an attribute of the object by name. This is a non-standard use of `__getitem__`, as it is generally expected to work with indices or keys, not attribute names. However, it can be useful in certain contexts where objects are treated like dictionaries of their attributes. The method is simple and does not have any apparent issues, so it is likely to be retained unless the design of the class changes significantly."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q33.py,Auto6,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name, which can be useful for objects that need to provide dictionary-like access to their attributes. This is a valid and potentially useful implementation, especially in cases where the object is designed to mimic a dictionary or provide flexible attribute access. Therefore, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q23.py,Auto5,1,6.825604231969389e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a common and useful pattern for dynamic attribute access. This method is likely to be useful in scenarios where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, it is likely to be retained in the code."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/job/compiler/py/q18.py,,1,9.237449576640118e-09,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It appears to be a utility function that could be part of a larger data processing or querying library. The function is well-structured and provides a flexible way to manipulate data based on various options passed to it. Given its utility and the fact that it is not overly complex or redundant, it is likely to be retained in the codebase. Additionally, the function does not have any obvious issues or inefficiencies that would necessitate its removal."
survived,"def test_Q15_finds_the_earliest_US_internet_movie_release_after_2000():
    assert result == [
        Auto1(release_date=""USA: March 2005"", internet_movie=""Example Movie"")
    ]
",tests/dataset/job/compiler/py/q15.py,,1,1.1253518384332553e-07,"The method is a test function, which is typically used in software development to verify that a specific piece of code behaves as expected. Test functions are crucial for maintaining code quality and ensuring that changes do not introduce new bugs. This particular test seems to be checking if a function correctly identifies the earliest US internet movie release after the year 2000. Such tests are essential for validating the functionality of the codebase, especially if the code is part of a larger application or library. Therefore, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q19.py,Auto11,1,4.6911638017642294e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a common and useful pattern for dynamic attribute access, especially in cases where the object is used like a dictionary or needs to provide flexible access to its attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q4.py,Auto4,0,0.9999967112522585,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the dictionary or list. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q27.py,Auto7,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually used to check for membership in a collection like a list, set, or dictionary. This misuse of `__contains__` could lead to confusion and unexpected behavior, as it does not align with the standard behavior expected from this method. Therefore, it is likely that this method will be deleted or refactored to better fit its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q25.py,Auto7,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate method for checking membership."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q13.py,Auto4,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, it is likely to be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q5.py,Auto5,0,0.9999910602998366,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may lead to unexpected behavior, suggesting it should be deleted or significantly revised."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q28.py,Auto2,1,1.0467401685178159e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, this method is likely to be retained as it provides a clear and useful functionality."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q21.py,Auto7,1,7.73442280641062e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name, which can be useful for objects that need to provide dictionary-like access to their attributes. This is a valid and potentially useful implementation, especially in cases where the object is designed to mimic a dictionary or provide flexible attribute access. Therefore, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q20.py,Auto8,0,0.9991959139981964,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. In this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not a typical use of `__contains__`, as it should check for membership rather than attribute existence. However, if the class is designed to treat its attributes as keys, this could be a valid implementation. Without more context, it's hard to definitively say if this is incorrect, but it is unconventional. Therefore, it might survive if the class is specifically designed this way, but it could also be deleted if it doesn't align with the intended use of `__contains__`. Given the unconventional use, it is more likely to be deleted or refactored."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q2.py,Auto4,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q25.py,Auto6,0,0.9999785550602307,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the implementation here uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q29.py,Auto12,1,9.931195248674785e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name, which is a valid and useful pattern for objects that need to provide dictionary-like access to their attributes. This method is likely to be retained because it provides a flexible way to access object attributes and is consistent with Python's design philosophy of allowing objects to behave like dictionaries when appropriate."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q27.py,Auto12,0,0.9999687980937693,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q13.py,Auto3,0,0.9999898700118929,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q18.py,Auto3,0,0.9999930377415741,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or replaced with a more appropriate implementation that correctly checks for key membership."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q21.py,Auto6,1,2.5109990926928157e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q31.py,Auto6,0,0.999983298584886,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q14.py,Auto1,1,1.4166087846364157e-09,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be Survived."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q24.py,Auto7,1,5.3157849718487075e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. It is a simple and effective way to provide dynamic access to object attributes, which can be particularly useful in data handling or configuration classes. Therefore, this method is likely to be retained as it serves a clear purpose and follows Python's conventions for special methods."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/job/compiler/py/q13.py,,1,2.0611536181902033e-09,"The method '_key' is a utility function that is likely used internally within a class or module to generate a key for sorting purposes. It takes an iterable 'it', applies a sorting key function from 'opts', and ensures the key is a string if it's a complex data type. This kind of method is typically useful for customizing sorting behavior and is not likely to be deleted unless the entire sorting mechanism is refactored or removed. Therefore, it is more likely to survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q31.py,Auto2,1,2.2159489282323004e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for cases where an object needs to behave like a dictionary or list, allowing attribute access via keys. Since this method provides a clear and functional purpose, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q9.py,Auto3,0,0.9999599363048656,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate method for checking membership."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q20.py,Auto3,1,2.8453347280241004e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is used as a dictionary-like structure, allowing for flexible and dynamic attribute access. Therefore, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q27.py,Auto11,0,0.9999785550602307,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list, set, or dictionary. Therefore, the method is likely to be deleted or rewritten to correctly implement membership checking."
survived,"def _min(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""min() expects list or group"")
    vals = [it for it in v if it is not None]
    if not vals:
        return 0
    return min(vals)
",tests/dataset/job/compiler/py/q24.py,,1,6.962258425838873e-06,"The method _min is a utility function that calculates the minimum value from a list or a group with an 'Items' attribute. It includes error handling for non-list inputs and returns 0 for empty lists. This functionality is quite specific and useful in certain contexts, especially when dealing with objects that may have an 'Items' attribute. However, the method name is not very descriptive, and the functionality could be replaced by a more generic utility function or a lambda expression in modern Python code. Despite this, the method is not inherently flawed or redundant, so it is likely to survive unless there is a significant refactor or a shift in the codebase's design philosophy."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q3.py,Auto4,0,0.999876605372333,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose suggests that it might be deleted or refactored to align with its conventional use."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q10.py,Auto7,0,0.999876605372333,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method could lead to confusion and unexpected behavior, especially for users familiar with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q27.py,Auto3,0,0.9999599363048656,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely that this method will be deleted or refactored to correctly implement key containment logic."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q25.py,Auto3,0,0.9999546021442518,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose suggests that it might be deleted or refactored to align with its conventional use."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q30.py,Auto2,0,0.9999984465026855,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, this implementation uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of `__contains__` is likely to lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership testing. Therefore, it is likely to be deleted or refactored to align with the expected behavior of `__contains__`."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/job/compiler/py/q21.py,,1,1.0467401685178159e-08,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The function is well-structured and provides flexibility through options like 'where', 'sortKey', 'skip', and 'take'. Such utility functions are often retained in codebases because they encapsulate common patterns of data manipulation, making them reusable and reducing code duplication. Therefore, it is likely to be retained."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/job/compiler/py/q12.py,,1,4.6911638017642294e-08,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It appears to be a utility function that could be part of a larger data processing or querying system. Such functions are often critical in applications that require data manipulation and retrieval, especially if they are part of a library or framework. The function is generic and flexible, allowing for various operations based on the options provided, which suggests it is designed for reuse in different contexts. Therefore, it is likely to be retained unless there is a significant change in the system's requirements or architecture that renders it obsolete."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q32.py,Auto2,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the intended use of `__contains__`, as it should be checking membership rather than attribute existence. This misuse of the method is likely to lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership testing. Therefore, it is likely to be deleted or refactored to correctly implement membership testing."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q27.py,Auto11,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q14.py,Auto1,0,0.9999687980937693,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the typical or expected behavior for `__contains__`, which should be checking membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect for its intended purpose and may be deleted or replaced with a more appropriate implementation."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q12.py,Auto4,0,0.9999980052698925,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key exists in a dictionary or a similar data structure. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely to be deleted or refactored to better fit its intended purpose."
survived,"def _min(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""min() expects list or group"")
    vals = [it for it in v if it is not None]
    if not vals:
        return 0
    return min(vals)
",tests/dataset/job/compiler/py/q17.py,,0,0.9999869928752253,"The method '_min' is a custom implementation of the built-in 'min' function with additional handling for objects with an 'Items' attribute and filtering out 'None' values. However, it has several issues that make it likely to be deleted or refactored:

1. **Redundancy**: Python's built-in 'min' function already provides the core functionality needed, and this custom implementation adds unnecessary complexity.

2. **Error Handling**: The method raises a generic 'Exception' with a vague message, which is not a good practice. More specific exceptions should be used.

3. **Return Value for Empty List**: Returning 0 for an empty list might not be the expected behavior for all use cases, as it assumes numeric context.

4. **Lack of Flexibility**: The method only works with lists or objects with an 'Items' attribute, limiting its applicability.

Due to these reasons, the method is more likely to be deleted or significantly refactored to improve its utility and maintainability."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q9.py,Auto10,0,0.9999869928752253,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q75.py,Auto2,1,4.6911638017642294e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to support dictionary-like access to their attributes. Since it provides a clear and functional purpose, it is likely to be retained in the codebase."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q33.py,,1,1.1253518384332553e-07,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The function is well-structured to handle various scenarios, such as different types of joins and optional operations like sorting and filtering. Given its utility and flexibility, it is likely to be retained in the codebase for future use."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q18.py,Auto2,0,0.9999687980937693,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of `__contains__` is likely to lead to confusion and bugs, as it does not align with the typical use case of the method. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q98.py,_Group,1,1.4166087846364157e-09,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q55.py,Auto2,0,0.9999910602998366,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical or expected behavior for `__contains__`, which is usually used for membership testing in collections like lists, sets, or dictionaries. This misuse of the method could lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership testing. Therefore, it is likely to be deleted or refactored to align with its intended purpose."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q50.py,_Group,1,2.646573631904765e-09,"The method `__len__` is a special method in Python that is used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q40.py,DateDim,1,7.194132978569833e-09,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be retained as it serves a clear purpose and follows Python's design principles."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q53.py,Item,0,0.999964643742472,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually used to check for membership in a collection like a list, set, or dictionary. This implementation could lead to confusion and misuse, as it does not align with the expected behavior of `__contains__`. Therefore, it is likely to be deleted or refactored to better fit the intended use of the method."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q45.py,Auto1,0,0.9999546021442518,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q1.py,Customer,1,3.653482080241728e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to survive because it provides a flexible way to access object properties, which can be particularly useful in dynamic or reflective programming scenarios."
survived,"def _q0():
    _src = store_sales
    _rows = _query(
        _src,
        [
            {""items"": date_dim, ""on"": lambda ss, d: d.d_date_sk == ss.ss_sold_date_sk},
            {""items"": store, ""on"": lambda ss, d, s: s.s_store_sk == ss.ss_store_sk},
            {
                ""items"": household_demographics,
                ""on"": lambda ss, d, s, hd: hd.hd_demo_sk == ss.ss_hdemo_sk,
            },
        ],
        {
            ""select"": lambda ss, d, s, hd: (ss, d, s, hd),
            ""where"": lambda ss, d, s, hd: (
                (
                    (
                        (
                            (d.d_dom >= 1 and d.d_dom <= 2)
                            and (
                                hd.hd_buy_potential == ""1001-5000""
                                or hd.hd_buy_potential == ""0-500""
                            )
                        )
                        and hd.hd_vehicle_count > 0
                    )
                    and hd.hd_dep_count / hd.hd_vehicle_count > 1
                )
                and ((d.d_year == 1998 or d.d_year == 1999) or d.d_year == 2000)
            )
            and s.s_county == ""A"",
        },
    )
    _groups = _group_by(
        _rows,
        lambda ss, d, s, hd: Auto3(ticket=ss.ss_ticket_number, cust=ss.ss_customer_sk),
    )
    _items1 = _groups
    return [Auto2(key=g.key, cnt=len(g)) for g in _items1]
",tests/dataset/tpc-ds/compiler/py/q73.py,,1,2.8453347280241004e-08,"The method '_q0' is a private function (indicated by the underscore prefix) that performs a complex query operation on a dataset. It involves joining multiple tables, applying filters, and grouping results. The function seems to be part of a larger codebase that deals with data processing or analytics. Such functions are typically essential for the functionality they provide, especially if they are part of a data processing pipeline. Unless there is a significant change in the requirements or the data model, this function is likely to be retained as it serves a specific purpose in querying and processing data."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q54.py,DateDim,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically retrieve an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method is correctly implemented and serves a clear purpose, it is likely to be retained in the code."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q23.py,,1,1.275190675769241e-07,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It appears to be a utility function that could be part of a larger data processing or querying system. Such functions are often essential in applications that require dynamic data manipulation, especially in systems that mimic SQL-like operations in a non-SQL environment. Given its utility and the fact that it encapsulates a significant amount of logic for data processing, it is likely to be retained unless there is a major refactor or a more efficient library or method replaces it."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q8.py,Store,1,1.444980317078884e-07,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. It is likely to be retained because it provides a flexible and Pythonic way to access object attributes, enhancing the usability of the class."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q78.py,C,1,6.825604231969389e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This can be particularly useful in classes where attributes are dynamically set or when implementing a proxy pattern. Therefore, the method is likely to be retained as it provides a flexible way to access object attributes."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q30.py,Auto1,0,0.9999898700118929,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check membership rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q56.py,Auto2,0,0.999988521231025,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the standard or expected behavior for `__contains__`, which should typically check for membership in a collection like a list, set, or dictionary. This misuse of `__contains__` could lead to confusion and bugs, as it does not align with the typical use case of checking for membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q30.py,,1,1.0467401685178159e-08,"The method '_group_by' is a utility function that groups elements of a list based on a key function. It is a common pattern in data processing and transformation tasks. The function is generic, flexible, and can handle various types of input, making it useful in many contexts. Additionally, it uses a dictionary to maintain groups and a list to preserve the order of keys, which is a thoughtful design choice. These characteristics suggest that the method is well-designed and likely to be retained for its utility."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q65.py,Auto1,1,4.6911638017642294e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object with the name `key`. This is a valid and useful implementation for objects that want to provide dictionary-like access to their attributes. It is a simple and effective way to allow dynamic access to object attributes, which can be particularly useful in scenarios where the object needs to behave like a dictionary. Therefore, this method is likely to be retained as it serves a clear purpose and is implemented correctly."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q30.py,Auto4,0,0.9999921107349486,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, this implementation uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of `__contains__` is likely to lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership testing. Therefore, it is likely to be deleted or refactored to align with its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q44.py,Auto2,0,0.9999869928752253,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q21.py,Item,0,0.999983298584886,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q93.py,Reason,1,4.1399375473943306e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation, especially in cases where the object is designed to behave like a dictionary or to provide dynamic attribute access. There is no indication that this method is redundant or incorrect, so it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q71.py,StoreSale,1,4.944450477491054e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a common and useful pattern for dynamic attribute access, especially in cases where the object is used like a dictionary or needs to provide flexible access to its attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q23.py,StoreSale,0,0.9999977396747258,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually implemented to check for membership in a collection like a list, set, or dictionary. Therefore, this implementation is likely incorrect for most use cases and may lead to confusion or errors when the method is used. It is more appropriate to use `__contains__` to check for membership in a collection rather than checking for attributes. Thus, this method is likely to be deleted or refactored."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q46.py,,1,1.1253518384332553e-07,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The function is well-structured and provides flexibility through options like 'where', 'sortKey', 'skip', and 'take'. Such utility functions are often retained in codebases because they encapsulate complex logic in a reusable manner, making them valuable for various data manipulation tasks."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q40.py,CatalogSale,1,6.348800075736417e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to support dictionary-like access to their attributes. Since it provides a clear and functional purpose, it is likely to be retained in the code."
survived,"def _sum(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""sum() expects list or group"")
    s = 0.0
    for it in v:
        if it is None:
            continue
        if isinstance(it, (int, float)):
            s += float(it)
        else:
            raise Exception(""sum() expects numbers"")
    return s
",tests/dataset/tpc-ds/compiler/py/q23.py,,1,1.9947301075518807e-06,"The method '_sum' is a utility function that calculates the sum of a list of numbers. It includes error handling for non-list inputs and non-numeric elements within the list. This function is useful for summing elements in a list, especially when the input might be a custom object with an 'Items' attribute. The method is straightforward, performs a common task, and includes necessary error checks, making it a candidate for survival. However, if there are more efficient or standardized methods available in the codebase or if the method is not used anywhere, it might be considered for deletion. Without additional context, it is more likely to survive due to its utility."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q36.py,StoreSale,0,0.9999898700118929,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually used to check for membership in a collection like a list, set, or dictionary. Therefore, this implementation is likely to be confusing and not align with the expected behavior of `__contains__`. It would be more appropriate to use `__contains__` to check for membership in a collection attribute of the class, if applicable. Due to this mismatch in expected behavior, the method is likely to be deleted or refactored."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q21.py,Inventory,0,0.9999982396568657,"The method is incorrectly implemented. The `__contains__` method is supposed to check for membership, typically in a collection or container, and return a boolean indicating whether the specified key or item is present. However, using `hasattr(self, key)` checks if the object has an attribute with the name `key`, which is not the intended use of `__contains__`. This method should be checking if `key` is in a collection attribute of the object, not if it's an attribute itself. Therefore, this method is likely to be deleted or significantly modified to correctly implement membership testing."
survived,"def _sort_key(k):
    if hasattr(k, ""__dataclass_fields__""):
        return str(k)
    if isinstance(k, list):
        return tuple((_sort_key(x) for x in k))
    if isinstance(k, tuple):
        return tuple((_sort_key(x) for x in k))
    if isinstance(k, dict):
        return str(k)
    return k
",tests/dataset/tpc-ds/compiler/py/q71.py,,1,4.363462233903899e-09,"The method `_sort_key` is a utility function designed to generate a sorting key for various data types, including dataclasses, lists, tuples, and dictionaries. It is a versatile function that can be useful in many contexts where complex data structures need to be sorted. The function handles different data types gracefully and provides a consistent way to convert them into a sortable format. Given its utility and the fact that it doesn't have any apparent issues or redundancies, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q50.py,DateDim,0,0.999988521231025,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose suggests that it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q70.py,Store,1,2.2159489282323004e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q42.py,Auto3,0,0.9999898700118929,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement the intended functionality."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q40.py,,1,1.0467401685178159e-08,"The method '_key' is a utility function that is likely used internally within a class or module to generate a key for sorting purposes. It takes an iterable 'it', applies a sorting key function from 'opts', and ensures the key is a string if it's a complex data type. This kind of function is common in data processing or sorting operations, and its utility suggests it is likely to be retained unless the overall design changes significantly. Therefore, it is more likely to survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q42.py,Item,1,5.3157849718487075e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. It is likely to be retained as it provides a flexible way to access object attributes, assuming the class is designed to support such behavior."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q14.py,Auto3,0,0.9999546021442518,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate method for checking membership."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q52.py,Auto2,0,0.9999910602998366,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q57.py,CallCenter,1,2.646573631904765e-09,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be Survived."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q34.py,Store,1,2.9023122007764653e-06,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in collections like lists or dictionaries. In this code, it is implemented to return an attribute of the object using `getattr`. This is a non-standard use of `__getitem__`, as it is expected to work with indexable collections rather than object attributes. However, it can be useful in certain contexts where an object is designed to mimic dictionary-like behavior. Without additional context, it's hard to determine if this is the best approach, but it is a valid use case for certain designs. Therefore, the method is likely to survive unless there is a specific reason to refactor it for clarity or design consistency."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q27.py,DateDim,1,6.023574641292144e-08,"The method is a simple implementation of the __getitem__ special method, which allows instances of the class to use the bracket notation (e.g., obj[key]) to access attributes. This is a common and useful pattern in Python, especially for classes that aim to mimic dictionary-like behavior. It provides a clear and concise way to access attributes dynamically, which can be very useful in various applications. Therefore, it is likely to be retained as it serves a practical purpose."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q24.py,StoreReturn,1,1.725782769012759e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern and does not have any apparent issues or redundancies that would warrant its deletion. Therefore, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q24.py,StoreSale,0,0.9999967112522585,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or replaced with a more appropriate implementation."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q20.py,Item,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose suggests that it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q6.py,Auto1,1,1.1861120010657661e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern and does not have any apparent issues that would necessitate its deletion. Therefore, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q54.py,DateDim,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to better fit its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q32.py,CatalogSale,0,0.9999038976006968,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not attribute existence. This misuse of the method's intended purpose suggests that it might be deleted or refactored to align with its conventional use."
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q36.py,_Group,1,2.1724399346070676e-10,"The method `__iter__` is a standard Python method used to make an object iterable. By returning an iterator over `self.Items`, it allows the object to be used in loops and other contexts that require iteration. This is a fundamental feature for many classes that manage collections of items, and it is unlikely to be removed unless the class itself is being deprecated or significantly refactored. Therefore, the method will likely survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q63.py,Auto1,1,2.8453347280241004e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. It is likely to survive because it provides a flexible way to access object attributes, which can be particularly useful in dynamic or reflective programming scenarios."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q19.py,DateDim,1,1.3440409770490404e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation, especially in cases where the object is designed to behave like a dictionary or to provide dynamic access to its attributes. It is unlikely to be deleted as it provides a clear and functional purpose."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q95.py,WebSale,1,4.6911638017642294e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name, which can be useful for objects that need to provide dictionary-like access to their attributes. This is a valid and potentially useful implementation, especially in cases where the object is designed to act like a dictionary or needs to provide flexible attribute access. Therefore, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q54.py,Customer,1,1.3440409770490404e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be retained as it serves a clear purpose and follows Python's conventions for special methods."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q57.py,Auto5,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list or dictionary. Therefore, the method is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q47.py,Auto1,1,4.363462233903899e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python to allow more flexible and dynamic access to object properties. Therefore, this method is likely to be Survived."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q37.py,DateDim,1,1.3709566550544279e-06,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in collections like lists or dictionaries. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid use case if the object is designed to allow attribute access via indexing, which can be useful in certain dynamic or flexible data structures. However, this implementation assumes that the keys used are valid attribute names of the object, which might not always be the case. Despite this limitation, the method itself is functional and serves a purpose, so it is likely to be retained unless the design requirements change significantly."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q75.py,WebSale,0,0.9999339478346898,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys. However, this implementation uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This could lead to confusion and unexpected behavior when using the `in` keyword with instances of this class. Therefore, it is likely that this method will be deleted or refactored to align with the expected behavior of `__contains__`."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q92.py,WebSale,0,0.9999756997690634,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical use case for `__contains__`, as it should be checking membership rather than attribute existence. This misuse of the method could lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership checks. Therefore, it is likely to be deleted or refactored to align with its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q34.py,Auto2,0,0.9999687980937693,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a similar data structure. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to better fit its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q46.py,CustomerAddres,0,0.999997438718515,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q58.py,Auto1,1,7.194132978569833e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python to allow more flexible and dynamic access to object properties. Therefore, this method is likely to be retained as it serves a clear purpose and follows Python's conventions for special methods."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q32.py,Item,1,8.76424914819242e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name, which can be useful for objects that need to provide dictionary-like access to their attributes. This is a common and useful pattern in Python, especially for classes that need to provide flexible attribute access. Therefore, it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q40.py,CatalogReturn,1,1.3440409770490404e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q25.py,Auto1,1,1.3440409770490404e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. It is a simple and effective way to provide dynamic access to object attributes, which can be particularly useful in data handling or configuration classes. Therefore, this method is likely to be retained as it serves a clear purpose and follows Python's conventions for special methods."
survived,"def _q0():
    _src = store_sales
    _rows = _query(
        _src,
        [
            {
                ""items"": store_returns,
                ""on"": lambda ss, sr: ss.ss_ticket_number == sr.sr_ticket_number
                and ss.ss_item_sk == sr.sr_item_sk,
            },
            {
                ""items"": catalog_sales,
                ""on"": lambda ss, sr, cs: sr.sr_customer_sk == cs.cs_bill_customer_sk
                and sr.sr_item_sk == cs.cs_item_sk,
            },
            {
                ""items"": date_dim,
                ""on"": lambda ss, sr, cs, d1: d1.d_date_sk == ss.ss_sold_date_sk,
            },
            {
                ""items"": date_dim,
                ""on"": lambda ss, sr, cs, d1, d2: d2.d_date_sk == sr.sr_returned_date_sk,
            },
            {
                ""items"": date_dim,
                ""on"": lambda ss, sr, cs, d1, d2, d3: d3.d_date_sk == cs.cs_sold_date_sk,
            },
            {
                ""items"": store,
                ""on"": lambda ss, sr, cs, d1, d2, d3, s: s.s_store_sk == ss.ss_store_sk,
            },
            {
                ""items"": item,
                ""on"": lambda ss, sr, cs, d1, d2, d3, s, i: i.i_item_sk == ss.ss_item_sk,
            },
        ],
        {
            ""select"": lambda ss, sr, cs, d1, d2, d3, s, i: (
                ss,
                sr,
                cs,
                d1,
                d2,
                d3,
                s,
                i,
            ),
            ""where"": lambda ss, sr, cs, d1, d2, d3, s, i: (
                (
                    ((d1.d_moy == 4 and d1.d_year == 2000) and d2.d_moy >= 4)
                    and d2.d_moy <= 10
                )
                and d3.d_moy >= 4
            )
            and d3.d_moy <= 10,
        },
    )
    _groups = _group_by(
        _rows,
        lambda ss, sr, cs, d1, d2, d3, s, i: Auto2(
            item_id=i.i_item_id,
            item_desc=i.i_item_desc,
            s_store_id=s.s_store_id,
            s_store_name=s.s_store_name,
        ),
    )
    _items1 = _groups
    return [
        Auto1(
            i_item_id=g.key[""item_id""],
            i_item_desc=g.key[""item_desc""],
            s_store_id=g.key[""s_store_id""],
            s_store_name=g.key[""s_store_name""],
            store_sales_profit=sum([x[0].ss_net_profit for x in g]),
            store_returns_loss=_sum([x[1].sr_net_loss for x in g]),
            catalog_sales_profit=_sum([x[2].cs_net_profit for x in g]),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q25.py,,1,6.825604231969389e-08,"The method `_q0` is a complex query function that joins multiple tables and performs filtering and grouping operations. It is likely part of a larger data processing or reporting system. The method is well-structured and performs specific tasks that are common in data analysis, such as joining tables, filtering data based on conditions, and aggregating results. These operations are essential in many business intelligence and data warehousing applications. Therefore, it is unlikely to be deleted unless the entire system is being deprecated or replaced by a new architecture."
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q24.py,_Group,1,2.4616969512093895e-10,"The method `__iter__` is a standard Python method used to make an object iterable. By returning an iterator over `self.Items`, it allows the object to be used in loops and other contexts where iteration is needed. This is a fundamental feature for many classes that manage collections of items, making it highly unlikely to be deleted unless the class itself is being deprecated or significantly refactored. Therefore, the method will survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q95.py,Auto1,1,1.0467401685178159e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be retained as it serves a clear purpose and follows Python's design principles."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q26.py,CatalogSale,1,1.0467401685178159e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be retained as it serves a clear purpose and is implemented correctly."
survived,"def test_TPCDS_Q23_cross_channel_sales():
    assert result == 50.0
",tests/dataset/tpc-ds/compiler/py/q23.py,,1,7.73442280641062e-08,"The method `test_TPCDS_Q23_cross_channel_sales` is a test function, likely part of a test suite for a larger application. Test functions are generally not deleted unless they are redundant, incorrect, or replaced by more comprehensive tests. Since this function contains a simple assertion, it is likely a basic test to ensure a specific condition (that `result` equals 50.0) is met. Without additional context indicating that this test is obsolete or incorrect, it is reasonable to assume it will be retained as part of the testing process."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q15.py,CustomerAddres,1,5.3157849718487075e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name, which can be useful for objects that need to provide dictionary-like access to their attributes. This is a valid and potentially useful implementation, especially in cases where the object is designed to act like a dictionary or needs to provide flexible attribute access. Therefore, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q84.py,IncomeBand,0,0.9999910602998366,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the typical or expected behavior for `__contains__`, which should check for membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect for its intended purpose and may be deleted or replaced with a more appropriate implementation."
survived,"def _sort_key(k):
    if hasattr(k, ""__dataclass_fields__""):
        return str(k)
    if isinstance(k, list):
        return tuple((_sort_key(x) for x in k))
    if isinstance(k, tuple):
        return tuple((_sort_key(x) for x in k))
    if isinstance(k, dict):
        return str(k)
    return k
",tests/dataset/tpc-ds/compiler/py/q93.py,,1,4.363462233903899e-09,"The method `_sort_key` is a utility function designed to generate a sorting key for various data types, including dataclasses, lists, tuples, and dictionaries. It is a versatile function that can be used in sorting operations where complex data structures are involved. The function is well-structured and handles different data types gracefully, making it a useful tool in many scenarios. Given its utility and the fact that it doesn't have any apparent issues or redundancies, it is likely to be retained in the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q79.py,Auto2,1,1.955568070542584e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically for objects that act like collections (e.g., lists, dictionaries). In this code, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. Since it serves a clear purpose and is correctly implemented, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q33.py,StoreSale,0,0.9999945777819207,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the standard behavior expected from a `__contains__` method. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q12.py,Auto2,0,0.9999938558278723,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"def test_TPCDS_Q72_simplified():
    assert result == [
        Auto1(
            i_item_desc=""ItemA"",
            w_warehouse_name=""Main"",
            d_week_seq=10,
            no_promo=1,
            promo=0,
            total_cnt=1,
        )
    ]
",tests/dataset/tpc-ds/compiler/py/q72.py,,1,1.1861120010657661e-08,"The method `test_TPCDS_Q72_simplified` is a test function, likely part of a test suite for a larger application. Test functions are generally not deleted unless they are redundant, incorrect, or replaced by more comprehensive tests. This function appears to be testing a specific scenario with a clear expected outcome, which is valuable for ensuring the correctness of the code it tests. Therefore, it is likely to be retained as part of the test suite."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q42.py,Item,0,0.9999898700118929,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q39.py,Warehouse,0,0.9999930377415741,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, this implementation uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of `__contains__` is likely to lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership testing. Therefore, it is likely to be deleted or refactored to align with the expected behavior of `__contains__`."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q96.py,,1,5.60279640614594e-09,"The method '_key' is a utility function that is likely used internally within a class or module to generate a key for sorting purposes. It takes an iterable 'it', applies a function 'sortKey' from a dictionary 'opts' to it, and then ensures the result is a string if it's a list, tuple, or dictionary. This kind of function is common in codebases where custom sorting logic is needed, and it is not uncommon for such utility functions to be retained as they serve a specific purpose. Unless there is a significant refactor or change in the sorting logic, this method is likely to survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q10.py,DateDim,0,0.9999962733608834,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys. However, this implementation uses `hasattr`, which checks if an object has an attribute with the given name. This is not the intended use of `__contains__`, as it should be used for membership testing in collections, not for checking attributes. This misuse of the method is likely to lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership testing. Therefore, it is likely to be deleted or replaced with a more appropriate implementation."
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q14.py,,1,4.1399375473943306e-08,"The method '_group_by' is a utility function that groups elements of a list based on a key function. It is a common pattern in data processing and transformation tasks. The function is generic, flexible, and can handle various types of input, making it useful in many scenarios. Additionally, it maintains the order of first occurrence of each group, which can be important in certain applications. These characteristics suggest that the method is likely to be retained as it provides valuable functionality."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q27.py,Item,1,1.725782769012759e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q1.py,Auto2,1,4.1399375473943306e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. This implementation uses `getattr` to dynamically retrieve an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a clear and functional purpose, it is likely to be retained in the code."
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q71.py,_Group,1,1.2501528648238603e-09,"The method `__iter__` is a standard Python method used to make an object iterable. By implementing this method, the class allows its instances to be used in a for-loop or any other context that requires iteration. The method returns an iterator over the `Items` attribute, which suggests that `Items` is a collection (like a list or set). This is a common and useful pattern in Python, making the class more flexible and easier to use. Therefore, there is no reason to delete this method as it enhances the functionality of the class."
survived,"def _q0():
    _src = web_sales
    _rows = _query(
        _src,
        [
            {
                ""items"": customer,
                ""on"": lambda ws, c: ws.bill_customer_sk == c.c_customer_sk,
            },
            {
                ""items"": customer_address,
                ""on"": lambda ws, c, ca: c.c_current_addr_sk == ca.ca_address_sk,
            },
            {""items"": item, ""on"": lambda ws, c, ca, i: ws.item_sk == i.i_item_sk},
            {
                ""items"": date_dim,
                ""on"": lambda ws, c, ca, i, d: ws.sold_date_sk == d.d_date_sk,
            },
        ],
        {
            ""select"": lambda ws, c, ca, i, d: (ws, c, ca, i, d),
            ""where"": lambda ws, c, ca, i, d: (
                (ca.ca_zip[0:5] in zip_list or i.i_item_id in item_ids)
                and d.d_qoy == qoy
            )
            and d.d_year == year,
        },
    )
    _groups = _group_by(_rows, lambda ws, c, ca, i, d: ca.ca_zip)
    _items1 = _groups
    return [
        Auto1(ca_zip=g.key, sum_ws_sales_price=_sum([x[0].sales_price for x in g]))
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q45.py,,1,7.194132978569833e-09,"The method '_q0' is a complex query function that seems to be part of a larger data processing or analytics system. It performs operations such as joining multiple tables, filtering data based on conditions, and grouping results. These types of functions are typically essential in data processing pipelines and are unlikely to be deleted unless the entire system is being deprecated or significantly refactored. Additionally, the function appears to be well-structured and serves a clear purpose, which further supports its likelihood of survival."
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q63.py,_Group,1,1.8189616842444243e-09,"The method is a standard implementation of the __iter__ method in Python, which is used to make an object iterable. It returns an iterator over the 'Items' attribute of the object. This is a common and necessary method for classes that need to support iteration, and there is nothing incorrect or unnecessary about it. Therefore, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q77.py,Auto8,1,2.5109990926928157e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern and does not have any apparent issues or redundancies that would necessitate its deletion. Therefore, it is likely to be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q57.py,Item,0,0.9999785550602307,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q97.py,StoreSale,1,3.653482080241728e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q77.py,Auto1,1,3.653482080241728e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is likely to survive because it provides a flexible way to access object attributes, which can be particularly useful in dynamic or reflective programming scenarios."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q72.py,_Group,1,1.275190675769241e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes. The code snippet shows a typical pattern of initializing instance variables, which is a common and necessary practice in class definitions. Therefore, it is unlikely that this method will be deleted as it serves a crucial role in the class's functionality."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q39.py,Auto4,1,1.1861120010657661e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern and does not have any apparent issues or redundancies that would necessitate its deletion. Therefore, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q7.py,Auto1,1,2.8453347280241004e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for cases where the object is designed to behave like a dictionary or list, allowing attribute access via keys. Since this method provides a clear and functional purpose, it is likely to be retained in the code."
survived,"def _q0():
    _src = store_sales
    _rows = _query(
        _src,
        [
            {
                ""items"": customer_demographics,
                ""on"": lambda ss, cd: ss.ss_cdemo_sk == cd.cd_demo_sk,
            },
            {
                ""items"": date_dim,
                ""on"": lambda ss, cd, d: ss.ss_sold_date_sk == d.d_date_sk,
            },
            {""items"": item, ""on"": lambda ss, cd, d, i: ss.ss_item_sk == i.i_item_sk},
            {
                ""items"": promotion,
                ""on"": lambda ss, cd, d, i, p: ss.ss_promo_sk == p.p_promo_sk,
            },
        ],
        {
            ""select"": lambda ss, cd, d, i, p: (ss, cd, d, i, p),
            ""where"": lambda ss, cd, d, i, p: (
                (
                    (cd.cd_gender == ""M"" and cd.cd_marital_status == ""S"")
                    and cd.cd_education_status == ""College""
                )
                and (p.p_channel_email == ""N"" or p.p_channel_event == ""N"")
            )
            and d.d_year == 1998,
        },
    )
    _groups = _group_by(_rows, lambda ss, cd, d, i, p: Auto2(i_item_id=i.i_item_id))
    _items1 = _groups
    _items1 = sorted(_items1, key=lambda g: g.key[""i_item_id""])
    return [
        Auto1(
            i_item_id=g.key[""i_item_id""],
            agg1=_avg([x[0].ss_quantity for x in g]),
            agg2=_avg([x[0].ss_list_price for x in g]),
            agg3=_avg([x[0].ss_coupon_amt for x in g]),
            agg4=_avg([x[0].ss_sales_price for x in g]),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q7.py,,1,3.850741907939403e-09,"The method '_q0' is a complex query function that performs a series of operations on sales data, including joining multiple tables, filtering based on specific conditions, grouping, and calculating averages. This type of function is typically crucial for data analysis tasks, especially in business intelligence and reporting contexts. Given its complexity and the specific business logic it implements, it is likely to be a core part of the system's functionality. Therefore, it is more likely to be maintained and survived rather than deleted."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q39.py,Auto3,1,1.955568070542584e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method is functional, straightforward, and serves a clear purpose, it is likely to be retained in the codebase."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q7.py,,1,2.646573631904765e-09,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The function is well-structured and provides flexibility through options like 'where', 'sortKey', 'skip', and 'take'. Such utility functions are often retained in codebases because they encapsulate common patterns of data manipulation, making them reusable and reducing code duplication. Therefore, it is likely to survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q51.py,Auto1,1,4.6911638017642294e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. Since it serves a clear purpose and is implemented correctly, it is likely to be retained in the codebase."
survived,"def _q0():
    _src = web_returns
    _rows = _query(
        _src,
        [
            {
                ""items"": date_dim,
                ""on"": lambda wr, d: wr.wr_returned_date_sk == d.d_date_sk,
            },
            {
                ""items"": customer_address,
                ""on"": lambda wr, d, ca: wr.wr_returning_addr_sk == ca.ca_address_sk,
            },
        ],
        {
            ""select"": lambda wr, d, ca: (wr, d, ca),
            ""where"": lambda wr, d, ca: d.d_year == 2000 and ca.ca_state == ""CA"",
        },
    )
    _groups = _group_by(
        _rows,
        lambda wr, d, ca: Auto3(cust=wr.wr_returning_customer_sk, state=ca.ca_state),
    )
    _items1 = _groups
    return [
        Auto2(
            ctr_customer_sk=g.key[""cust""],
            ctr_state=g.key[""state""],
            ctr_total_return=sum([x[0].wr_return_amt for x in g]),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q30.py,,1,1.3440409770490404e-08,"The method '_q0' appears to be a specific query function that processes data from a web returns source, filters it based on certain conditions, groups it, and then returns a list of results. The function is well-structured and seems to serve a clear purpose in the context of data processing or analysis. It is likely part of a larger codebase that deals with customer returns data. Given its specific functionality and the fact that it is not overly complex or redundant, it is likely to be retained in the codebase unless there is a significant change in requirements or data structure."
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q35.py,,1,2.3355930333443423e-09,"The method '_group_by' is likely to survive because it provides a useful utility function for grouping elements of a list based on a key function. This is a common requirement in data processing and manipulation tasks. The method is generic, allowing it to be used with various types of data and key functions, which increases its applicability. Additionally, the use of a dictionary to maintain groups and a list to preserve order is a well-established pattern that balances efficiency and functionality. Unless there are significant changes in the requirements or a better alternative is introduced, this method is likely to remain useful."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q37.py,,1,5.3157849718487075e-08,"The method '_key' is a utility function that is likely used internally within a module or class to generate a key for sorting purposes. It takes an iterable 'it', applies a function 'sortKey' from a dictionary 'opts' to it, and ensures the result is a string if it's a list, tuple, or dictionary. This kind of function is common in codebases where custom sorting logic is needed, and it doesn't appear to have any issues or redundancies that would necessitate its deletion. Therefore, it is likely to be retained in the codebase."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q52.py,,1,2.2159489282323004e-08,"The method '_key' is a utility function that is likely used internally within a larger codebase to generate a key for sorting purposes. It takes an iterable 'it', applies a 'sortKey' function from the 'opts' dictionary to it, and ensures the result is a string if it's a list, tuple, or dictionary. This kind of function is common in data processing or sorting operations, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained in the codebase."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q97.py,,1,7.194132978569833e-09,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It appears to be a utility function that could be part of a larger data processing or querying library. Such functions are often essential for handling data transformations and are unlikely to be deleted unless they are replaced by a more efficient or updated version. The function's complexity and utility suggest it is integral to the system it is part of, making it more likely to survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q81.py,Auto1,0,0.9999991684720096,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement the intended functionality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q75.py,Auto3,0,0.9999599363048656,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually used to check for membership in a collection like a list, set, or dictionary. This misuse of `__contains__` could lead to confusion and unexpected behavior, as it does not align with the standard behavior expected from this method. Therefore, it is likely that this method will be deleted or refactored to better fit its intended purpose."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q44.py,_Group,1,1.3440409770490404e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. It initializes the instance variables 'key', 'Items', and 'items'. The use of type hints and the initialization of an empty list for 'Items' are standard practices. The method is necessary for creating instances of the class, and there is no indication of redundancy or error that would warrant its deletion."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q59.py,,1,5.3157849718487075e-08,"The method '_key' is a utility function that is likely used internally within a module or class to generate a key for sorting purposes. It takes an iterable 'it', applies a function from 'opts' dictionary to generate a key, and ensures the key is a string if it's a complex data type. This kind of function is common in sorting operations and is useful for customizing sort behavior. Since it serves a specific purpose and is not overly complex or redundant, it is likely to be retained in the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q2.py,DateDim,1,3.850741907939403e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern and does not have any apparent issues or redundancies that would necessitate its deletion. Therefore, it is likely to be retained in the code."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q10.py,,1,2.3355930333443423e-09,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The function is well-structured and provides flexibility through options like 'where', 'sortKey', 'skip', and 'take'. Such utility functions are often retained in codebases because they encapsulate common patterns of data manipulation that can be reused across different parts of an application. Therefore, it is likely to survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q7.py,Promotion,0,0.9999785550602307,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q18.py,Customer,0,0.9999785550602307,"The method is a custom implementation of the `__contains__` method, which is used to define behavior for the `in` keyword. However, the implementation uses `hasattr(self, key)`, which checks if an object has an attribute with the name `key`. This is not a typical use case for `__contains__`, which is usually used to check membership in a collection, like checking if an item is in a list or a key is in a dictionary. The method might be misleading or incorrect if the intention is to check for membership rather than attribute existence. Therefore, it is likely to be deleted or refactored to better align with expected behavior."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q7.py,_Group,1,2.646573631904765e-09,"The method `__len__` is a special method in Python that is used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q42.py,Auto2,0,0.999983298584886,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not fulfill its intended purpose. Therefore, it is likely to be deleted or rewritten to correctly implement key containment logic."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q95.py,Auto1,0,0.9999417087232136,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, especially for users familiar with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q11.py,Auto1,1,1.0467401685178159e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python to allow more flexible and dynamic access to object properties. Therefore, this method is likely to be retained as it serves a clear purpose and follows Python's conventions for special methods."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q3.py,Item,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, it is likely to be retained in the code."
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q99.py,_Group,1,1.6052280526088547e-09,"The method is a standard implementation of the __iter__ method in Python, which allows an object to be iterable. This is a common and necessary feature for many classes that manage collections of items, as it enables the use of the object in loops and other iterable contexts. There is no indication that this method is redundant or unnecessary, so it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q70.py,StoreSale,1,1.1861120010657661e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern and does not have any apparent issues or redundancies that would necessitate its deletion. Therefore, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q77.py,StoreReturn,0,0.9999339478346898,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose suggests that it might be deleted or refactored to align with its conventional use."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q43.py,,1,4.1399375473943306e-08,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The method is not overly specific to a particular use case, making it versatile and reusable in different contexts. Additionally, the method is well-structured and follows a logical flow, which suggests it is a well-thought-out piece of code. Given these factors, it is likely to be retained in the codebase as it provides significant functionality that can be leveraged in various scenarios."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q43.py,_Group,1,4.6911638017642294e-08,"The method is a constructor for a class, initializing the instance variables 'key', 'Items', and 'items'. It is a fundamental part of the class structure, and there is no indication that it is redundant or incorrect. Constructors are essential for setting up initial state in object-oriented programming, so it is unlikely to be deleted unless the entire class is being refactored or removed."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q52.py,Auto1,1,1.725782769012759e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. It is a simple and effective way to provide dynamic access to object attributes, which can be particularly useful in data handling or configuration classes. Therefore, this method is likely to be retained as it serves a clear purpose and is implemented correctly."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q57.py,,1,1.522997951276035e-08,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The method is not overly specific to a particular use case, making it versatile and reusable. Therefore, it is likely to be retained in the codebase for its utility and flexibility in handling data queries."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q22.py,Item,1,1.0467401685178159e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object with the name `key`. This is a valid and useful implementation for objects that want to provide dictionary-like access to their attributes. It is a common pattern in Python to allow more flexible and dynamic access to object attributes. Therefore, this method is likely to be retained as it provides a clear and useful functionality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q91.py,CustomerAddres,0,0.9999967112522585,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q13.py,CustomerDemographic,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method is likely to lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership testing. Therefore, it is likely to be deleted or refactored to align with its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q93.py,Reason,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely that this method will be deleted or refactored to correctly implement key containment logic."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q37.py,CatalogSale,1,1.892514738127224e-05,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. In this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not a typical use of `__contains__`, as it should generally check for membership in a collection rather than the presence of an attribute. However, if the class is designed such that its attributes are intended to be accessed like keys in a collection, this implementation could be valid. Without more context, it's hard to definitively say if this is a misuse or a clever design choice. Given the flexibility of Python and the potential for creative design, this method is likely to survive unless it leads to confusion or errors in the intended use case."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q52.py,Auto2,1,6.023574641292144e-08,"The method is a simple implementation of the __getitem__ special method, which allows an object to use the bracket notation (obj[key]) to access its attributes. This is a common and useful pattern in Python, especially for classes that need to provide dictionary-like access to their attributes. It is likely to be retained as it provides a clear and concise way to access object attributes using keys, enhancing the usability of the class."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q21.py,,1,1.725782769012759e-08,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The method is not overly specific to a particular use case, making it versatile and reusable in different contexts. Additionally, the method is well-structured and implements common data manipulation patterns, which are likely to be needed in various applications. Therefore, it is more likely to be retained for its utility and flexibility."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q99.py,Auto2,1,4.1399375473943306e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is used as a dictionary-like structure or when dynamic attribute access is needed. Therefore, it is likely to be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q39.py,Auto1,0,0.9999930377415741,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or replaced with a more appropriate implementation that correctly checks for key membership."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q14.py,Auto2,0,0.9999938558278723,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or replaced with a more appropriate implementation."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q71.py,TimeDim,1,3.653482080241728e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. This implementation uses `getattr` to dynamically retrieve an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. It is likely to be retained because it provides a flexible and Pythonic way to access object attributes, enhancing the usability of the class."
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q39.py,,1,9.237449576640118e-09,"The method '_group_by' is a utility function that groups elements of a list based on a key function. It is a common pattern in data processing and transformation tasks. The function is generic, flexible, and handles different types of input (like lists, tuples, and dictionaries). It also maintains the order of first occurrence of each group, which can be important in many applications. These characteristics make it a useful and reusable piece of code, suggesting that it is likely to be retained in the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q94.py,Auto1,1,2.2159489282323004e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a flexible and Pythonic way to access object attributes, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q26.py,DateDim,0,0.9999756997690634,"The method `__contains__` is intended to check if a key is present in a collection, typically using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be used for checking membership in a collection like a list, set, or dictionary. Therefore, the method is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q39.py,Auto2,1,5.3157849718487075e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q28.py,StoreSale,0,0.9999546021442518,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate method for checking membership."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q51.py,Auto1,1,0.0002034270609875745,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually meant for checking membership in a collection like a list, set, or dictionary. However, if the class is designed to treat its attributes as keys in a collection, this implementation could be valid. Without additional context, it's hard to determine if this is a misuse or a valid use case. Given the unconventional use, it might be subject to review or change, but it could also be a deliberate design choice. Therefore, it is likely to survive unless there is a clear indication that this is a misuse."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q77.py,Auto4,0,0.9999485577825553,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the typical or expected behavior for `__contains__`, which should check for membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate implementation that checks for key membership in the intended collection."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q6.py,CustomerAddres,0,0.9999546021442518,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list, set, or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate method for checking membership."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q55.py,Auto1,0,0.9999921107349486,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q24.py,Auto3,0,0.9999869928752253,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the typical or expected behavior for `__contains__`, which should check for membership in a collection like a list or dictionary. Therefore, this method is likely to be deleted or refactored to correctly implement membership checking."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q14.py,,1,2.646573631904765e-09,"The method '_key' is a utility function that is likely used internally within a class or module to generate a key for sorting purposes. It takes an iterable 'it', applies a sorting key function from 'opts', and ensures the key is a string if it's a complex data type. This kind of method is common in data processing or sorting operations and is unlikely to be deleted unless the entire sorting mechanism is refactored or removed. Therefore, it is more likely to survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q96.py,Store,0,0.999985261023967,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q18.py,Auto3,1,5.905303995456778e-10,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be Survived."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q44.py,_Group,1,5.60279640614594e-09,"The method `__len__` is a special method in Python that is used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q15.py,_Group,1,9.931195248674785e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes. The code snippet shows a typical pattern of initializing instance variables, which is a common and necessary practice in class design. Therefore, it is unlikely that this method will be deleted as it serves a crucial role in the class's functionality."
survived,"def _q0():
    _src = store_sales
    _rows = _query(
        _src,
        [
            {""items"": date_dim, ""on"": lambda ss, d: ss.ss_sold_date_sk == d.d_date_sk},
            {""items"": store, ""on"": lambda ss, d, s: ss.ss_store_sk == s.s_store_sk},
            {
                ""items"": household_demographics,
                ""on"": lambda ss, d, s, hd: ss.ss_hdemo_sk == hd.hd_demo_sk,
            },
            {
                ""items"": customer_address,
                ""on"": lambda ss, d, s, hd, ca: ss.ss_addr_sk == ca.ca_address_sk,
            },
        ],
        {
            ""select"": lambda ss, d, s, hd, ca: (ss, d, s, hd, ca),
            ""where"": lambda ss, d, s, hd, ca: (
                (
                    (hd.hd_dep_count == depcnt or hd.hd_vehicle_count == vehcnt)
                    and d.d_dow in [6, 0]
                )
                and d.d_year == year
            )
            and s.s_city in cities,
        },
    )
    _groups = _group_by(
        _rows,
        lambda ss, d, s, hd, ca: Auto3(
            ss_ticket_number=ss.ss_ticket_number,
            ss_customer_sk=ss.ss_customer_sk,
            ca_city=ca.ca_city,
        ),
    )
    _items1 = _groups
    return [
        Auto2(
            ss_ticket_number=g.key[""ss_ticket_number""],
            ss_customer_sk=g.key[""ss_customer_sk""],
            bought_city=g.key[""ca_city""],
            amt=_sum([x[0].ss_coupon_amt for x in g]),
            profit=_sum([x[0].ss_net_profit for x in g]),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q46.py,,1,2.1024340680345882e-07,"The method '_q0' is a complex query function that appears to be part of a larger data processing or analytics system. It performs a series of operations including joining multiple data sources, filtering based on specific conditions, grouping results, and then transforming the grouped data into a specific output format. This type of method is typically crucial in data processing pipelines, especially in business intelligence or data analytics applications. Given its complexity and the specific operations it performs, it is likely to be a core part of the system's functionality. Therefore, it is unlikely to be deleted unless there is a significant change in the system's requirements or architecture."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q73.py,Auto1,1,4.1399375473943306e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to behave like a dictionary or similar container, allowing attribute access via keys. Since this is a common and practical use case, the method is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q19.py,Auto1,0,0.9999957771647318,"The method is incorrectly implemented. The `__contains__` method is supposed to check for membership, typically in a collection or container, and return a boolean indicating whether the specified key or item is present. However, using `hasattr(self, key)` checks if the object has an attribute with the name `key`, which is not the intended use of `__contains__`. This misuse of the method will likely lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership checks. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q15.py,_Group,1,4.944450477491054e-09,"The method is a standard implementation of the __iter__ method in Python, which is used to make an object iterable. It returns an iterator over the 'Items' attribute of the object. This is a common and necessary method for classes that need to support iteration, and there is no indication that it is redundant or incorrect. Therefore, it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q23.py,CatalogSale,1,1.1861120010657661e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be retained as it serves a clear purpose and follows Python's design principles."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q20.py,Auto2,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q45.py,WebSale,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the implementation here uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method could lead to confusion and unexpected behavior, especially for users familiar with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q34.py,HouseholdDemographic,1,1.725782769012759e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a flexible and Pythonic way to access object attributes, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q15.py,DateDim,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method is likely to lead to confusion and incorrect behavior when the method is used in the context of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q23.py,WebSale,1,2.5109990926928157e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in collections like lists or dictionaries. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid use case if the object is designed to allow attribute access via indexing, which can be useful in certain dynamic or flexible data structures. Since this method provides a clear and potentially useful functionality, it is likely to be retained unless there are specific design changes that render it unnecessary."
survived,"def test_TPCDS_Q40_simplified():
    assert result == [
        Auto1(w_state=""CA"", i_item_id=""I1"", sales_before=100.0, sales_after=0.0)
    ]
",tests/dataset/tpc-ds/compiler/py/q40.py,,1,8.152020648014727e-09,"The method `test_TPCDS_Q40_simplified` is a unit test function, which is typically used to verify that a specific piece of code works as expected. Unit tests are crucial for maintaining code quality and ensuring that changes do not introduce new bugs. The presence of an assertion indicates that this test is checking for a specific expected outcome, which is a common practice in software development to ensure reliability and correctness of the code.

Given the importance of testing in software development, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered. Therefore, the method is more likely to survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q97.py,Auto2,1,7.194132978569833e-09,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"def _sum(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""sum() expects list or group"")
    s = 0.0
    for it in v:
        if it is None:
            continue
        if isinstance(it, (int, float)):
            s += float(it)
        else:
            raise Exception(""sum() expects numbers"")
    return s
",tests/dataset/tpc-ds/compiler/py/q70.py,,1,7.73442280641062e-08,"The method '_sum' is a utility function that calculates the sum of a list of numbers, with additional handling for objects that have an 'Items' attribute. It includes error handling for non-list inputs and non-numeric elements within the list. This method is likely to survive because it provides a useful and specific functionality that is not directly available in Python's built-in functions. It also includes error handling, making it robust for various input types."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q73.py,_Group,1,8.152020648014727e-09,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is correctly implemented to return the length of `self.Items`, which suggests that `self.Items` is likely a list or a similar collection. This is a standard and expected implementation for making a custom object compatible with the `len()` function. Therefore, it is unlikely to be deleted as it provides essential functionality for the class."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q67.py,,1,2.646573631904765e-09,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The function is well-structured and provides flexibility through options like 'where', 'sortKey', 'skip', and 'take'. Such utility functions are often retained in codebases because they encapsulate common patterns of data manipulation, making them reusable and reducing code duplication. Therefore, it is likely to survive."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q97.py,_Group,1,4.363462233903899e-09,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is correctly implemented to return the length of `self.Items`, which suggests that `self.Items` is likely a list or a similar collection. This is a standard and useful implementation for custom classes that manage collections, allowing them to integrate seamlessly with Python's built-in functions. Therefore, this method is likely to be retained as it provides essential functionality for the class."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q2.py,CatalogSale,0,0.9999921107349486,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not fulfill its intended purpose of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q2.py,_Group,1,1.522997951276035e-08,"The method `__len__` is a special method in Python that is used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"def _sum(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""sum() expects list or group"")
    s = 0.0
    for it in v:
        if it is None:
            continue
        if isinstance(it, (int, float)):
            s += float(it)
        else:
            raise Exception(""sum() expects numbers"")
    return s
",tests/dataset/tpc-ds/compiler/py/q74.py,,1,1.955568070542584e-08,"The method '_sum' is a utility function that calculates the sum of a list of numbers, with additional checks for non-list inputs and non-numeric elements. It is a basic and useful function that handles common edge cases, such as None values and non-numeric types, which makes it robust for various input scenarios. Such utility functions are often retained in codebases because they encapsulate common operations with error handling, making them reusable and reducing the likelihood of errors in other parts of the code. Therefore, it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q54.py,Auto2,1,4.1399375473943306e-08,"The method is a simple implementation of the __getitem__ special method, which allows an object to use the bracket notation (obj[key]) to access its attributes. This is a common and useful pattern in Python, especially for classes that need to provide dictionary-like access to their attributes. It is likely to be retained as it provides a clear and concise way to access object attributes using keys, enhancing the flexibility and usability of the class."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q43.py,_Group,1,6.348800075736417e-09,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation here is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q58.py,Auto1,0,0.9999938558278723,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q16.py,CustomerAddres,0,0.9999982396568657,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q73.py,,1,1.3440409770490404e-08,"The method '_key' is a utility function that is likely used internally within a class or module to generate a key for sorting purposes. It takes an iterable 'it', applies a sorting key function from 'opts', and ensures the key is a string if it's a complex data type. This kind of method is typically useful in sorting operations and is unlikely to be deleted unless the sorting mechanism is completely refactored or the 'opts' dictionary is removed. Therefore, it is more likely to survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q91.py,Auto1,0,0.999964643742472,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the typical or expected behavior for `__contains__`, which should check for membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate implementation that checks for membership in the intended collection."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q57.py,Auto4,0,0.9999785550602307,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list, set, or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate membership check."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q14.py,CatalogSale,1,1.725782769012759e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q53.py,,1,1.3440409770490404e-08,"The method '_group_by' is a utility function that groups elements of a list based on a key function. It is a common pattern in data processing and transformation tasks. The function is generic, flexible, and handles different types of input, making it useful in various contexts. There is no indication that it is obsolete or redundant, and it provides a clear and useful functionality. Therefore, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q71.py,TimeDim,0,0.9999967112522585,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or replaced with a more appropriate implementation that correctly checks for key membership."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q45.py,DateDim,0,0.999985261023967,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the standard or expected behavior for `__contains__`, which is usually used for membership testing in collections like lists, sets, or dictionaries. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the typical use case of `__contains__`. Therefore, it is likely to be deleted or refactored to better fit its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q18.py,CustomerDemographics,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose suggests that it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q94.py,Auto1,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q58.py,Auto2,1,1.0467401685178159e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern and does not have any apparent issues or redundancies that would warrant its deletion. Therefore, it is likely to be retained in the code."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q22.py,,1,5.211412485172657e-10,"The method '_key' is a utility function that is likely used internally within a class or module to generate a key for sorting purposes. It is a simple and straightforward function that converts the result of a 'sortKey' function into a string if it is a list, tuple, or dictionary, ensuring compatibility with sorting operations. Such utility functions are common in codebases and are typically retained unless they are redundant or replaced by a more efficient implementation. Without additional context indicating redundancy or obsolescence, it is reasonable to predict that this method will survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q75.py,Auto1,1,2.2159489282323004e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"def test_TPCDS_Q24_customer_net_paid():
    assert result == [
        Auto1(
            c_last_name=""Smith"", c_first_name=""Ann"", s_store_name=""Store1"", paid=100.0
        )
    ]
",tests/dataset/tpc-ds/compiler/py/q24.py,,1,6.825604231969389e-08,"The method `test_TPCDS_Q24_customer_net_paid` is a test function, likely part of a test suite for a larger application. Test functions are generally not deleted unless they are redundant, incorrect, or replaced by more comprehensive tests. This function appears to be testing a specific scenario with a clear expected result, which is a common practice in software development to ensure code correctness. Therefore, it is likely to be retained as part of the testing framework."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q46.py,Auto3,0,0.999999057755336,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys. However, this implementation uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of `__contains__` is likely to lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership testing. Therefore, it is likely to be deleted or replaced with a more appropriate implementation."
survived,"    def eval_fn(genome: list[float]) -> tuple[float, float, float]:
        x, y = genome
        return x**2, y**2, (x + y) ** 2
",src/interface/api_server.py,,1,4.6911638017642294e-08,"The method 'eval_fn' is a simple function that takes a list of two floats as input and returns a tuple of three floats. It performs basic mathematical operations (squaring the elements and their sum) which are common in many computational tasks, such as optimization problems or genetic algorithms. The function is straightforward, efficient, and does not have any apparent issues or redundancies that would necessitate its removal. Additionally, it uses type hints, which is a good practice in modern Python code for clarity and maintainability. Therefore, there is no reason to delete this method."
survived,"    def test_py_namedexpr(self) -> None:
        """"""Ensure NamedExpr nodes are converted to AtomUnit.""""""
        from jaclang.compiler.passes.main import PyastBuildPass
        import jaclang.compiler.unitree as uni
        import ast as py_ast

        py_out_path = os.path.join(self.fixture_abs_path(""./""), ""py_namedexpr.py"")
        with open(py_out_path) as f:
            file_source = f.read()
            output = PyastBuildPass(
                ir_in=uni.PythonModuleAst(
                    py_ast.parse(file_source),
                    orig_src=uni.Source(file_source, py_out_path),
                ),
                prog=JacProgram(),
            ).ir_out.unparse()
        self.assertIn(""(x := 10)"", output)",jac/jaclang/tests/test_language.py,JacLanguageTests,1,9.736200303530205e-10,"The method `test_py_namedexpr` is a unit test that checks the functionality of converting NamedExpr nodes to AtomUnit using the `PyastBuildPass`. It is a specific test case that ensures a particular feature works as expected. Such test methods are typically retained in the codebase to ensure ongoing functionality and to prevent regressions. Therefore, it is likely to survive."
survived,"async def async_unload_entry(hass: HomeAssistant, entry: ConfigEntry) -> bool:
    """"""Unload a config entry.""""""
    unloaded = await hass.config_entries.async_unload_platforms(entry, PLATFORMS)
    if unloaded:
        hass.data[DOMAIN].pop(entry.entry_id)
    return unloaded",custom_components/gree/__init__.py,,1,2.0611536181902033e-09,"The method `async_unload_entry` is a standard pattern for unloading configuration entries in Home Assistant integrations. It uses the `async_unload_platforms` method to unload the platforms associated with the entry and then removes the entry from the domain data if successful. This is a necessary part of managing the lifecycle of configuration entries in Home Assistant, ensuring that resources are properly cleaned up when an entry is removed. There is no indication that this method is deprecated or unnecessary, and it follows the expected practices for Home Assistant integrations."
survived,"    async def async_step_init(self, user_input: dict | None = None) -> FlowResult:
        if user_input is not None:
            return self.async_create_entry(title="""", data=user_input)

        options = {**self.config_entry.options}
        schema = vol.Schema(
            {
                vol.Optional(CONF_TARGET_TEMP_STEP, default=options.get(CONF_TARGET_TEMP_STEP, DEFAULT_TARGET_TEMP_STEP)): vol.Coerce(float),
                vol.Optional(CONF_TEMP_SENSOR, default=options.get(CONF_TEMP_SENSOR)): str,
                vol.Optional(CONF_LIGHTS, default=options.get(CONF_LIGHTS)): str,
                vol.Optional(CONF_XFAN, default=options.get(CONF_XFAN)): str,
                vol.Optional(CONF_HEALTH, default=options.get(CONF_HEALTH)): str,
                vol.Optional(CONF_POWERSAVE, default=options.get(CONF_POWERSAVE)): str,
                vol.Optional(CONF_SLEEP, default=options.get(CONF_SLEEP)): str,
                vol.Optional(CONF_EIGHTDEGHEAT, default=options.get(CONF_EIGHTDEGHEAT)): str,
                vol.Optional(CONF_AIR, default=options.get(CONF_AIR)): str,
                vol.Optional(CONF_TARGET_TEMP, default=options.get(CONF_TARGET_TEMP)): str,
                vol.Optional(CONF_AUTO_XFAN, default=options.get(CONF_AUTO_XFAN)): str,
                vol.Optional(CONF_AUTO_LIGHT, default=options.get(CONF_AUTO_LIGHT)): str,
                vol.Optional(CONF_HORIZONTAL_SWING, default=options.get(CONF_HORIZONTAL_SWING, False)): bool,
                vol.Optional(CONF_ANTI_DIRECT_BLOW, default=options.get(CONF_ANTI_DIRECT_BLOW)): str,
                vol.Optional(CONF_DISABLE_AVAILABLE_CHECK, default=options.get(CONF_DISABLE_AVAILABLE_CHECK, False)): bool,
                vol.Optional(CONF_MAX_ONLINE_ATTEMPTS, default=options.get(CONF_MAX_ONLINE_ATTEMPTS, 3)): int,
                vol.Optional(CONF_LIGHT_SENSOR, default=options.get(CONF_LIGHT_SENSOR)): str,
                vol.Optional(CONF_TEMP_SENSOR_OFFSET, default=options.get(CONF_TEMP_SENSOR_OFFSET)): bool,
                vol.Optional(CONF_LANGUAGE, default=options.get(CONF_LANGUAGE)): str,
            }
        )
        return self.async_show_form(step_id=""init"", data_schema=schema)",custom_components/gree/config_flow.py,OptionsFlowHandler,1,3.581747929000289e-10,"The method `async_step_init` is part of an asynchronous flow for handling user input and configuration in a structured manner. It uses a schema to define expected inputs and defaults, which is a common pattern in modern software development, especially in frameworks that support asynchronous operations. The method is well-structured, uses type hints, and leverages existing configuration options, making it a robust and maintainable piece of code. There is no indication that this method is obsolete or redundant, and it appears to be a necessary part of the configuration flow, suggesting it will survive."
survived,"    async def async_step_import(self, import_data: dict) -> FlowResult:
        """"""Handle configuration via YAML import.""""""
        return await self.async_step_user(import_data)
",custom_components/gree/config_flow.py,ConfigFlow,1,8.76424914819242e-08,"The method `async_step_import` is a simple wrapper around another method `async_step_user`, passing the same `import_data` argument. This suggests that it is part of a larger framework or system where configuration can be handled via different methods, such as user input or YAML import. The method is likely to be retained because it provides a specific entry point for handling YAML imports, which can be a common requirement in configuration management systems. Removing it would reduce the flexibility of the system in handling different configuration sources."
survived,"def test_bundle_validator_checksum_failure(tmp_path: Path) -> None:
    bundle_dir = create_sample_bundle(tmp_path)
    (bundle_dir / ""agent.py"").write_text(""broken"")
    validator = BundleValidator(bundle_dir)
    result = validator.validate()
    assert result.success is False
    assert any(""checksum mismatch"" in e for e in result.errors)
",tests/test_bundle_validator.py,,1,5.211412485172657e-10,"The method `test_bundle_validator_checksum_failure` is a unit test designed to verify that the `BundleValidator` correctly identifies a checksum mismatch when a file in the bundle is altered. This is a crucial test to ensure the integrity of the bundle validation process, as checksum validation is a common method to detect file tampering or corruption. Given its importance in maintaining the reliability and security of the validation process, this test method is likely to be retained in the codebase."
survived,"        def fake_run(*_, **kwargs):
            nonlocal captured_env
            captured_env = kwargs.get(""env"", {})
            mock_result = MagicMock()
            mock_result.returncode = 0
            mock_result.stdout = """"
            mock_result.stderr = """"
            return mock_result
",tests/unit/test_validation.py,TestValidation,1,1.2501528648238603e-09,"The method 'fake_run' is a mock function designed to simulate the behavior of a command execution without actually running any commands. It captures the environment variables passed to it and returns a mock result with predefined attributes. This is a common pattern in testing to isolate the function being tested from its dependencies and side effects. Since this is a useful utility in testing environments, it is likely to be retained in the codebase."
survived,"    def test_validate_generated_tool_env_cleanup(self, mock_generated_tool):
        """"""Ensure coverage env vars are stripped for subprocess run.""""""

        captured_env: dict[str, str] = {}

        def fake_run(*_, **kwargs):
            nonlocal captured_env
            captured_env = kwargs.get(""env"", {})
            mock_result = MagicMock()
            mock_result.returncode = 0
            mock_result.stdout = """"
            mock_result.stderr = """"
            return mock_result

        with patch(""meta_agent.validation.subprocess.run"", side_effect=fake_run):
            with (
                patch(""meta_agent.validation.ET.parse"") as mock_parse,
                patch(""meta_agent.validation.os.path.exists"", return_value=True),
            ):
                mock_root = MagicMock()
                mock_root.attrib = {""line-rate"": ""1.0""}
                mock_tree = MagicMock()
                mock_tree.getroot.return_value = mock_root
                mock_parse.return_value = mock_tree

                result = validate_generated_tool(mock_generated_tool, ""test_id"")

        assert result.success is True
        assert ""COVERAGE_PROCESS_START"" not in captured_env",tests/unit/test_validation.py,TestValidation,1,2.5109990926928157e-08,"The method is a unit test that ensures a specific environment variable is not present when a subprocess is run. It uses mocking to simulate the behavior of external dependencies, which is a common practice in testing. The method is well-structured, serves a clear purpose, and is likely part of a larger test suite. There is no indication that it is obsolete or redundant, and it contributes to the codebase by verifying important functionality. Therefore, it is likely to be retained."
survived,"    def plot_pareto(elites: Iterable[Any], out_path: Path) -> None:
        """"""Stub when plotly is unavailable.""""""
        return None
",src/utils/__init__.py,,0,0.9999994956527948,"The method 'plot_pareto' is a stub, meaning it is a placeholder for functionality that is not yet implemented. It is designed to do nothing and simply return None. This is often used during development when the actual implementation is not yet available or when a dependency (like plotly in this case) is missing. However, as a stub, it does not provide any functional value in its current state. Unless there is a plan to implement the actual plotting functionality in the future, this method is likely to be deleted as it serves no purpose in its current form."
survived,"def test_env_value_injected(tmp_path: Path) -> None:
    browser_dir = Path(__file__).resolve().parents[1]
    target = tmp_path / ""browser""
    shutil.copytree(browser_dir, target)
    (target / "".env"").write_text(""PINNER_TOKEN=test123\n"")
    subprocess.check_call([""npm"", ""run"", ""build""], cwd=target)

    url = (target / ""dist"" / ""index.html"").as_uri()
    with sync_playwright() as p:
        browser = p.chromium.launch()
        page = browser.new_page()
        page.goto(url)
        page.wait_for_selector(""#controls"")
        assert page.evaluate(""window.PINNER_TOKEN"") == ""test123""
        browser.close()",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_browser_ui.py,,1,3.3982678079468468e-09,"The method 'test_env_value_injected' is a test function that verifies if an environment variable is correctly injected into a web application. It uses Playwright to automate a browser and check the presence of the environment variable in the web page. This is a common testing pattern for web applications to ensure that environment configurations are correctly applied. Such tests are crucial for maintaining the integrity of the deployment process and ensuring that the application behaves as expected in different environments. Therefore, it is likely to be retained as part of the test suite."
deleted,"def get_chat_formatter(
    *,
    strategy: ChatStrategy,
    system_message: str,
    user_input: str,
    thinking_instructions: str | None = None,
) -> ChatFormatter:
    if strategy == ChatStrategy.final_only:
        return FinalOnlyFormatter(system_message, user_input)
    if strategy == ChatStrategy.final_and_intermediate:
        return FinalAndIntermediateFormatter(
            system_message, user_input, thinking_instructions
        )
    if strategy == ChatStrategy.final_and_intermediate_r1_compatible:
        return R1Formatter(system_message, user_input)

    raise ValueError(f""Unsupported strategy {strategy}"")",libs/core/kiln_ai/adapters/chat/chat_formatter.py,,1,3.581747929000289e-10,"The method 'get_chat_formatter' is well-structured and serves a clear purpose of returning different formatter objects based on the provided strategy. It uses a clean and understandable approach with conditional checks for different strategies and raises an appropriate error for unsupported strategies. This kind of utility function is common in software design for handling different configurations or modes of operation, making it likely to be retained in the codebase."
survived,"def test_chat_formatter_final_and_intermediate():
    training_data = ModelTrainingData(
        input=""test input"",
        system_message=""system message"",
        final_output=""test output"",
        thinking=""thinking output"",
        thinking_instructions=""thinking instructions"",
        thinking_final_answer_prompt=COT_FINAL_ANSWER_PROMPT,
    )
    expected = generate_chat_message_response(training_data)[""messages""]

    formatter = get_chat_formatter(
        strategy=ChatStrategy.final_and_intermediate,
        system_message=""system message"",
        user_input=""test input"",
        thinking_instructions=""thinking instructions"",
    )

    first = formatter.next_turn()
    assert [m.__dict__ for m in first] == expected[:3]

    second = formatter.next_turn(""thinking output"")
    assert [m.__dict__ for m in second] == expected[3:5]

    assert formatter.next_turn(""test output"") is None
    assert formatter.message_dicts() == expected
",libs/core/kiln_ai/adapters/chat/test_chat_formatter.py,,1,4.6911638017642294e-08,"The method `test_chat_formatter_final_and_intermediate` is a unit test designed to verify the functionality of a chat formatter. It checks if the formatter correctly processes input and generates expected output in a step-by-step manner. Unit tests are crucial for ensuring code reliability and are typically retained unless the functionality they test is deprecated or removed. Since the method is actively testing a feature, it is likely to be maintained as long as the feature exists."
survived,"def test_notebook_runs(tmp_path: Path) -> None:
    nb_path = Path(""alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_colab.ipynb"")
    assert nb_path.exists(), nb_path
    nb = nbformat.read(nb_path, as_version=4)

    skip = {2, 4, 8, 15, 17, 19}
    for idx in skip:
        nb.cells[idx].source = ""print('skipped')""

    mod = tmp_path / ""mod.ipynb""
    nbformat.write(nb, mod)

    os.environ[""NO_LLM""] = ""1""
    os.environ.setdefault(""ALPHA_ASI_SILENT"", ""1"")

    pm.execute_notebook(str(mod), str(tmp_path / ""out.ipynb""), kernel_name=""python3"")",tests/test_world_model_notebook_exec.py,,1,6.825604231969389e-08,"The method 'test_notebook_runs' is a utility function designed to test the execution of a Jupyter notebook by modifying certain cells and running it in a controlled environment. This type of function is useful for automated testing and validation of notebooks, especially in environments where notebooks are used for data analysis, machine learning, or demonstration purposes. The function is likely to be retained because it serves a specific purpose in ensuring that the notebook runs correctly, which is important for maintaining the integrity of the codebase and ensuring that the notebook's functionality is preserved across changes."
survived,"    def content_type(self) -> Optional[str]:
        return self.request.content_type
",src/graphql_server/webob/views.py,WebobHTTPRequestAdapter,1,2.646573631904765e-09,"The method `content_type` is a simple accessor method that returns the content type of a request. Such methods are typically useful in web frameworks or applications where handling different content types is necessary. Since it provides a straightforward way to access the content type of a request, it is likely to be used frequently in the codebase. Therefore, it is unlikely to be deleted unless the entire request handling mechanism is refactored or replaced."
survived,"def with_retry(func: Callable[..., T], *, max_tries: int = 3) -> Callable[..., T]:
    """"""Wrap *func* with exponential backoff and logging.""""""

    def _log_retry(details: dict[str, Any]) -> None:
        _log.warning(
            ""Retry %d/%d for %s due to %s"",
            details[""tries""],
            max_tries,
            getattr(details.get(""target""), ""__name__"", ""call""),
            details.get(""exception""),
        )

    if backoff is not None:
        return backoff.on_exception(
            backoff.expo,
            Exception,
            max_tries=max_tries,
            jitter=backoff.full_jitter,
            on_backoff=_log_retry,
        )(func)

    is_async = inspect.iscoroutinefunction(func)

    if is_async:

        async def wrapper(*args: Any, **kwargs: Any) -> T:
            for attempt in range(max_tries):
                try:
                    return await func(*args, **kwargs)
                except Exception as exc:  # pragma: no cover - runtime errors
                    if attempt + 1 >= max_tries:
                        raise
                    _log_retry(
                        {
                            ""tries"": attempt + 1,
                            ""exception"": exc,
                            ""target"": func,
                        }
                    )
                    await asyncio.sleep(2**attempt * 0.1)

        return wrapper

    def wrapper(*args: Any, **kwargs: Any) -> T:
        for attempt in range(max_tries):
            try:
                return func(*args, **kwargs)
            except Exception as exc:  # pragma: no cover - runtime errors
                if attempt + 1 >= max_tries:
                    raise
                _log_retry(
                    {
                        ""tries"": attempt + 1,
                        ""exception"": exc,
                        ""target"": func,
                    }
                )
                time.sleep(2**attempt * 0.1)

    return wrapper",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/retry.py,,1,4.6911638017642294e-08,"The method 'with_retry' is a utility function that provides a retry mechanism with exponential backoff for both synchronous and asynchronous functions. This is a common pattern in software development, especially in network-related operations where transient errors can occur. The method is well-structured, handles both sync and async functions, and includes logging for retries, making it robust and useful. Such utility functions are often retained in codebases because they encapsulate a complex pattern in a reusable way, improving code reliability and maintainability."
survived,"    async def start(self) -> None:
        """"""Launch REST/gRPC servers and background tasks.""""""
        self._rest_task, self._grpc_server = await start_servers(
            self.scheduler.manager.runners,
            MODEL_MAX_BYTES,
            mem,
            PORT,
            A2A_PORT,
            LOGLEVEL,
            SSL_DISABLE,
        )
        await self.scheduler.start()
",alpha_factory_v1/backend/orchestrator.py,Orchestrator,1,2.5109990926928157e-08,"The method 'start' is an asynchronous function that is responsible for launching REST/gRPC servers and background tasks. This is a crucial part of initializing and running a server application, especially in a distributed system where communication between different components is necessary. The method is well-defined with a clear purpose and uses asynchronous programming to handle potentially long-running operations efficiently. Given its importance in setting up the server infrastructure, it is unlikely to be deleted unless there is a significant architectural change or refactoring that replaces its functionality."
survived,"    def _log_slice(self, count: int = 5) -> str:
        rows = self.ledger.tail(count)
        lines = []
        for r in rows:
            lines.append(f""{r.get('sender')}->{r.get('recipient')}: {r.get('payload')}"")
        return ""\n"".join(lines)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/mutators/llm_mutator.py,LLMMutator,1,1.955568070542584e-08,"The method '_log_slice' is a utility function that formats and returns the last 'count' entries from a ledger. It is a simple and useful method for logging or displaying recent transactions in a readable format. Such methods are typically retained as they provide a clear and concise way to access and present data, which is often needed in applications dealing with transaction logs or similar data structures."
survived,"    def _random_patch(self, file_path: str) -> str:
        goal = f""random-{self._rng.randint(0, 9999)}""
        return _fallback_diff(file_path, goal)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/mutators/llm_mutator.py,LLMMutator,1,3.3982678079468468e-09,"The method '_random_patch' is a private method (indicated by the underscore prefix) that generates a random goal string using a random number generator and then calls another function '_fallback_diff' with the file path and the generated goal. The method seems to be part of a larger system where generating random patches or diffs is necessary, possibly for testing or version control purposes. Since it is a utility function that serves a specific purpose and there is no indication of it being redundant or replaced by another method, it is likely to survive."
survived,"    def diversity_histogram(self) -> dict[tuple[str, str], int]:
        cur = self.conn.execute(
            ""SELECT sector, approach, COUNT(*) FROM solutions GROUP BY sector, approach""
        )
        rows = cur.fetchall()
        return {(r[0], r[1]): int(r[2]) for r in rows}
",src/archive/solution_archive.py,SolutionArchive,1,2.1724399346070676e-10,"The method 'diversity_histogram' is likely to survive because it provides a useful functionality by querying a database to generate a histogram of counts of solutions grouped by 'sector' and 'approach'. This kind of data aggregation is often valuable for analysis and reporting purposes. The method is straightforward, uses efficient SQL querying, and returns the data in a clear and structured format (a dictionary with tuple keys). There are no apparent issues with the logic or implementation that would necessitate its removal."
survived,"    def add(self, sector: str, approach: str, score: float, data: Mapping[str, Any]) -> None:
        band = self._band(score)
        self.conn.execute(
            ""INSERT INTO solutions(sector, approach, score, band, data, ts) VALUES (?,?,?,?,?,?)"",
            (sector, approach, score, band, json.dumps(dict(data)), time.time()),
        )
        if isinstance(self.conn, sqlite3.Connection):  # pragma: no cover - sqlite
            self.conn.commit()
",src/archive/solution_archive.py,SolutionArchive,1,6.023574641292144e-08,"The method 'add' is a crucial part of the class it belongs to, as it handles the insertion of data into a database. It takes several parameters, processes them, and executes an SQL command to store the data. This functionality is essential for applications that rely on data persistence and retrieval. The method is well-structured, uses parameterized queries to prevent SQL injection, and handles JSON serialization of the 'data' parameter. Additionally, it includes a commit operation for SQLite connections, ensuring data integrity. Given its importance in data handling and the absence of any deprecated or redundant code, it is unlikely to be deleted."
survived,"def _free_port() -> int:
    with socket.socket() as s:
        s.bind((""127.0.0.1"", 0))
        return int(s.getsockname()[1])
",tests/test_evolution_worker_safe_extract.py,,1,3.3982678079468468e-09,"The method _free_port is a utility function that finds and returns a free port on the local machine. This is a common requirement in network programming, especially for testing purposes where a free port is needed to bind a server or client socket. The method is simple, effective, and uses standard library functions, making it a useful and reusable piece of code. There are no obvious issues or redundancies in the implementation, and it serves a clear purpose, which suggests that it is likely to be retained in the codebase."
survived,"    def __init__(self, *a: object, **_k: object) -> None:
        pass
",tests/resources/openai_agents.py,OpenAIAgent,0,0.9999038976006968,"The method is a constructor that takes any number of positional and keyword arguments but does nothing with them. This is typically used as a placeholder or a base class constructor that is meant to be overridden by subclasses. Since it doesn't perform any operations, it might be considered unnecessary in its current form. However, if it's part of a larger framework or library where subclasses are expected to override this constructor, it might be retained for structural purposes. Without additional context, it's more likely to be deleted if it's not serving any functional purpose."
survived,"def main():
    root = 'pages/docs'
    for dirpath, dirnames, filenames in os.walk(root):
        for name in filenames:
            if name.endswith('.mdx'):
                fix_file(os.path.join(dirpath, name))
",scripts/fix_titlecase.py,,1,1.1861120010657661e-08,"The method is a simple script that iterates over files in a directory and applies a function to files with a specific extension. This is a common utility function in file processing tasks, especially in documentation or static site generation contexts. The method is straightforward, performs a clear task, and does not contain any obvious errors or deprecated practices. Therefore, it is likely to be retained in the codebase."
survived,"    def test_reward_backends_produce_floats(self) -> None:
        names = reward_backends.list_rewards()
        self.assertTrue(names)
        for name in names:
            val = reward_backends.reward_signal(name, {}, None, {})
            self.assertIsInstance(val, float)
            self.assertGreaterEqual(val, 0.0)
            self.assertLessEqual(val, 1.0)
",tests/test_era_experience.py,TestEraOfExperience,1,5.60279640614594e-09,"The method `test_reward_backends_produce_floats` is a unit test designed to verify that the `reward_backends` module produces valid float values within a specified range. It checks that the list of reward names is not empty and that each reward signal is a float between 0.0 and 1.0. This is a typical test case to ensure the correctness and reliability of the reward system, which is crucial for applications relying on these values. Since it serves an important purpose in validating the functionality of the code, it is likely to be retained."
survived,"    def test_reject_call(self) -> None:
        with self.assertRaises(ValueError):
            safe_eval(""__import__('os').system('echo hi')"")
",tests/test_safe_eval_security.py,TestSafeEval,1,2.2159489282323004e-08,"The method `test_reject_call` is a unit test designed to ensure that the `safe_eval` function correctly raises a `ValueError` when an unsafe operation is attempted. This is a crucial test for maintaining the security and integrity of the `safe_eval` function, as it verifies that the function can prevent potentially harmful code execution. Given the importance of security in code evaluation, this test is likely to be retained to ensure that the `safe_eval` function behaves as expected in rejecting unsafe calls."
survived,"    def test_valid_expression(self) -> None:
        self.assertEqual(safe_eval(""2 + 3 * 4 - 5""), 9)
",tests/test_safe_eval_security.py,TestSafeEval,1,2.3355930333443423e-09,"The method `test_valid_expression` is a unit test that checks the functionality of a method called `safe_eval`. It verifies that the expression ""2 + 3 * 4 - 5"" evaluates to 9. This is a valid and useful test case for ensuring that the `safe_eval` function correctly handles basic arithmetic operations and operator precedence. Unit tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, this method is likely to be retained as part of the test suite."
survived,"    def tearDown(self):
        self.fabric.close()
        os.environ.pop(""VECTOR_STORE_USE_SQLITE"", None)
",tests/test_memory_fabric_sqlite.py,TestMemoryFabricSQLiteClose,1,4.1399375473943306e-08,"The method `tearDown` is typically used in testing frameworks like `unittest` to clean up after each test method is run. The code provided is performing cleanup tasks by closing a resource (`self.fabric.close()`) and removing an environment variable (`os.environ.pop(""VECTOR_STORE_USE_SQLITE"", None)`). These are standard practices in test teardown methods to ensure that tests do not interfere with each other and that resources are properly released. Since this method is performing necessary cleanup tasks, it is unlikely to be deleted unless the entire testing framework or the specific tests using this teardown are removed."
survived,"    async def _get_single_step_result_from_response(
        cls,
        *,
        agent: Agent[TContext],
        all_tools: list[Tool],
        original_input: str | list[TResponseInputItem],
        pre_step_items: list[RunItem],
        new_response: ModelResponse,
        output_schema: AgentOutputSchemaBase | None,
        handoffs: list[Handoff],
        hooks: RunHooks[TContext],
        context_wrapper: RunContextWrapper[TContext],
        run_config: RunConfig,
        tool_use_tracker: AgentToolUseTracker,
    ) -> SingleStepResult:
        processed_response = RunImpl.process_model_response(
            agent=agent,
            all_tools=all_tools,
            response=new_response,
            output_schema=output_schema,
            handoffs=handoffs,
        )

        tool_use_tracker.add_tool_use(agent, processed_response.tools_used)

        return await RunImpl.execute_tools_and_side_effects(
            agent=agent,
            original_input=original_input,
            pre_step_items=pre_step_items,
            new_response=new_response,
            processed_response=processed_response,
            output_schema=output_schema,
            hooks=hooks,
            context_wrapper=context_wrapper,
            run_config=run_config,
        )
",src/agents/run.py,DefaultAgentRunner,1,6.023574641292144e-08,"The method '_get_single_step_result_from_response' is an integral part of an asynchronous workflow that processes a model's response, tracks tool usage, and executes necessary tools and side effects. It is likely to be a crucial component in a system that involves complex interactions between agents, tools, and responses. The method's functionality is specific and seems to be well-integrated into the larger system, making it unlikely to be removed unless there is a significant redesign or refactoring of the system."
survived,"async def trigger_execution() -> str:
    resp = requests.post(f""{HOST}/agent/alpha_execution/trigger"", timeout=5)
    resp.raise_for_status()
    return ""alpha_execution queued""
",alpha_factory_v1/demos/alpha_agi_business_v1/openai_agents_bridge.py,,0,0.9999998724809324,"The method 'trigger_execution' is likely to be deleted because it uses the 'requests' library in an asynchronous function without using an asynchronous HTTP client like 'aiohttp'. This can lead to blocking behavior, which is not ideal in an asynchronous context. To properly handle asynchronous HTTP requests, the method should be refactored to use an appropriate library that supports async operations."
survived,"def _trigger(agent: str) -> str:
    resp = requests.post(f""{HOST}/agent/{agent}/trigger"", timeout=5)
    resp.raise_for_status()
    return f""{agent} queued""
",alpha_factory_v1/demos/alpha_agi_business_v1/gradio_dashboard.py,,1,1.725782769012759e-08,"The method '_trigger' is a simple utility function that sends a POST request to trigger an agent and returns a confirmation message. It is likely to be useful in contexts where automated tasks or processes need to be initiated remotely. The method is straightforward, performs a clear task, and includes error handling with 'raise_for_status', which makes it robust. Unless the functionality it provides is no longer needed or is replaced by a more comprehensive solution, there is no strong reason to delete it."
survived,"def test_stream_options_not_injected_for_non_openai_base_url_sync() -> None:
    captured = {}

    def dummy_fn(completion, **kwargs):
        captured.update(kwargs)
        return ""ok""

    wrapped = create_wrapper_sync(OpSettings())(dummy_fn)

    wrapped(DummyCompletion(""https://api.mistral.ai""), stream=True)

    assert ""stream_options"" not in captured
",tests/integrations/openai/test_openai_sdk.py,,1,1.522997951276035e-08,"The method is a test function that checks if 'stream_options' is not injected into the captured dictionary when the base URL is not from OpenAI. This is a specific test case that ensures the correct behavior of a function under certain conditions. Test functions are generally not deleted as they are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, this method is likely to be retained."
survived,"    def test_write_and_read(self):
        with tempfile.TemporaryDirectory() as tmpdir:
            mem = Memory(tmpdir)
            mem.write('agent1', 'greeting', {'msg': 'hello'})
            mem.write('agent2', 'greeting', {'msg': 'world'})
            records = mem.read()
            self.assertEqual(len(records), 2)
            self.assertEqual(records[0]['agent'], 'agent1')
            self.assertEqual(records[0]['data']['msg'], 'hello')
            self.assertEqual(records[1]['agent'], 'agent2')
            self.assertEqual(records[1]['data']['msg'], 'world')
",alpha_factory_v1/tests/test_memory.py,MemoryTest,1,9.736200303530205e-10,"The method 'test_write_and_read' is a unit test designed to verify the functionality of writing and reading data using a 'Memory' object. It checks if the data written to the memory is correctly stored and can be accurately retrieved. This is a fundamental test to ensure the integrity of data operations in the system. Since it serves a critical role in validating the core functionality of the 'Memory' class, it is unlikely to be deleted unless the 'Memory' class itself is removed or significantly refactored. Therefore, the method will likely survive."
survived,"async def rename_path(
    db: Session,
    redis: Redis,
    frame: Frame,
    src: str,
    dst: str,
    *,
    timeout: int = 120,
) -> None:
    """"""Rename a file or directory on the device.""""""

    if await _use_agent(frame, redis):
        from app.ws.agent_ws import file_rename_on_frame

        try:
            await log(db, redis, frame.id, ""stdout"", f""> mv {src} {dst} (agent)"")
            await file_rename_on_frame(frame.id, src, dst, timeout)
            return
        except Exception as e:  # noqa: BLE001
            await log(db, redis, frame.id, ""stderr"", f""Agent rename error ({e})"")
            raise

    ssh = await get_ssh_connection(db, redis, frame)
    try:
        cmd = f""mv {shlex.quote(src)} {shlex.quote(dst)}""
        await exec_command(db, redis, frame, ssh, cmd)
    finally:
        await remove_ssh_connection(db, redis, ssh, frame)",backend/app/utils/remote_exec.py,,1,2.4616969512093895e-10,"The method 'rename_path' is likely to survive because it provides a crucial functionality of renaming files or directories on a device, which is a common and necessary operation in many applications. The method is well-structured, handling both agent-based and SSH-based renaming, and includes error logging and exception handling, which are good practices for robust code. Additionally, it uses asynchronous programming, which is beneficial for performance in I/O-bound operations like network communication."
survived,"    def set_stake(self, agent_id: str, amount: float) -> None:
        """"""Register ``agent_id`` with ``amount`` tokens.""""""
        self.stakes[agent_id] = float(amount)
",src/governance/stake_registry.py,StakeRegistry,1,6.348800075736417e-09,"The method 'set_stake' is a straightforward setter method that assigns a float value to a dictionary key. It is a basic operation that is commonly used in many applications to update or set values. There is no indication of redundancy, inefficiency, or lack of use from the provided code snippet. Therefore, it is likely to be retained in the codebase."
survived,"def test_rejects_test_only_changes() -> None:
    diff = """"""--- a/tests/foo.py
+++ b/tests/foo.py
@@
-a
+b
""""""
    assert not is_patch_valid(diff)
",tests/test_patch_guard.py,,1,1.725782769012759e-08,"The method `test_rejects_test_only_changes` is a unit test that checks if the function `is_patch_valid` correctly identifies a patch that only changes test files as invalid. This is a common requirement in many codebases where changes to test files alone are not considered valid for certain operations, such as merging or deployment. The method is useful for ensuring that the `is_patch_valid` function behaves as expected in this scenario. Therefore, it is likely to be retained as part of the test suite to maintain code quality and integrity."
survived,"    def _factory(entries):
        (tmp_path / ""archive.json"").write_text(json.dumps(entries))
        return ArchiveDB(tmp_path / ""archive.db"")
",tests/test_archive.py,,1,1.8189616842444243e-09,"The method '_factory' is a private method (indicated by the underscore) that seems to be part of a larger system dealing with database or file operations. It takes 'entries', writes them to a JSON file, and returns an 'ArchiveDB' object. This method is likely a utility function used internally to handle specific tasks related to data archiving. Such methods are typically retained unless there's a significant change in the system architecture or a better abstraction is introduced. Without additional context suggesting it's obsolete or replaced, it's reasonable to predict it will survive."
survived,"def TestArchiveMigration(tmp_path):
    def _factory(entries):
        (tmp_path / ""archive.json"").write_text(json.dumps(entries))
        return ArchiveDB(tmp_path / ""archive.db"")

    return _factory
",tests/test_archive.py,,1,9.237449576640118e-09,"The method 'TestArchiveMigration' is a test utility function that creates a factory function for setting up test data. It is likely part of a test suite for a larger application, specifically dealing with database migrations or data handling. Such utility functions are generally useful for testing purposes and are not typically deleted unless they are replaced by a more efficient or comprehensive testing strategy. Therefore, it is likely to survive."
survived,"        def inc(self, *_a: Any, **_kw: Any) -> None: ...
",src/monitoring/metrics.py,_N,0,0.7772998714925404,"The method 'inc' is defined with a flexible signature that accepts any number of positional and keyword arguments, but it does not have an implementation (indicated by the ellipsis '...'). This suggests that it might be intended as a placeholder or abstract method. Without further context, such as whether this is part of an interface or abstract class, it's difficult to determine its necessity. However, if this is part of a larger framework or library where such methods are expected to be overridden, it might survive. Otherwise, if it's not used or overridden elsewhere, it could be considered for deletion."
survived,"        def labels(self, *_a: Any, **_kw: Any) -> ""_N"":
            return self
",src/monitoring/metrics.py,_N,1,9.237449576640118e-09,"The method 'labels' is a simple method that returns the instance itself. This pattern is often used in fluent interfaces or builder patterns where methods return the object to allow for method chaining. The method does not perform any complex operations or have any side effects, making it unlikely to be a candidate for deletion unless the entire class or its design pattern is being refactored. Therefore, it is more likely to survive."
survived,"def from_env():
    raise DockerException(""Docker not available in test environment"")",docker/__init__.py,,1,4.1399375473943306e-08,"The method 'from_env' is designed to raise an exception when called, indicating that Docker is not available in the test environment. This suggests that the method is intentionally used to handle a specific scenario where Docker should not be accessed, likely for testing purposes. Such methods are often retained to ensure that tests do not inadvertently attempt to use Docker, which could lead to inconsistent test results or require unnecessary dependencies. Therefore, the method is likely to be retained as it serves a specific purpose in the testing framework."
survived,"    def _should_log(self, level: LogLevel) -> bool:
        return level >= self.level
",webscout/litlogger/logger.py,Logger,1,2.998960815863541e-09,"The method _should_log is a private utility function that checks if a given log level is greater than or equal to the current logging level. This is a common pattern in logging systems to determine if a message should be logged based on its severity. The method is simple, efficient, and serves a clear purpose within a logging framework. It is unlikely to be deleted as it provides essential functionality for controlling log output based on severity levels."
survived,"    def emit(self, message: str, level: LogLevel):
        raise NotImplementedError
",webscout/litlogger/handlers.py,Handler,1,3.726639116582555e-06,"The method 'emit' is defined with a clear purpose but lacks implementation, as indicated by the 'raise NotImplementedError' statement. This suggests that 'emit' is intended to be an abstract method, meant to be overridden by subclasses. In object-oriented programming, especially in languages like Python, it's common to define such methods in base classes to enforce that subclasses provide specific functionality. Therefore, the method is likely to survive as it serves a structural purpose in the class design."
survived,"def test_round_trip(tmp_path):
    path = tmp_path / ""models.json""
    serialize_config(built_in_models, path)
    loaded = deserialize_config(path)
    assert [m.model_dump(mode=""json"") for m in loaded] == [
        m.model_dump(mode=""json"") for m in built_in_models
    ]
",libs/core/kiln_ai/adapters/test_remote_config.py,,1,1.3440409770490404e-08,"The method 'test_round_trip' is a unit test designed to verify the serialization and deserialization process of a configuration. It uses a temporary path to store a JSON file, ensuring that the process is isolated and does not affect other tests or the file system. The test checks if the serialized and then deserialized models match the original models, which is a common and necessary test to ensure data integrity in serialization processes. Such tests are crucial for maintaining the reliability of software that involves data persistence. Therefore, this method is likely to be retained as it serves an important purpose in the testing suite."
survived,"    def __init__(self, text=""""):
        self.encoding = ""utf-8""
        self.headers = {""Content-Type"": ""text/html""}
        self.text = text
",tests/conftest.py,_Response,1,1.2501528648238603e-09,"The method is a constructor (__init__) for a class, which is a fundamental part of object-oriented programming in Python. It initializes the instance variables (encoding, headers, and text) for objects of the class. Such methods are essential for setting up the initial state of an object and are unlikely to be deleted unless the class itself is being removed or significantly refactored. Therefore, the method will survive."
survived,"def test_text_fuzz_ratio_partial():
    scraper = AutoScraper()
    scraper.build(html=""<ul><li>Banana</li></ul>"", wanted_list=[""Banan""], text_fuzz_ratio=0.8)
    assert scraper.get_result_exact(html=""<ul><li>Banana</li></ul>"") == [""Banana""]
",tests/unit/test_additional_features.py,,1,1.275190675769241e-07,"The method 'test_text_fuzz_ratio_partial' is a test function that checks the functionality of the 'AutoScraper' library, specifically the 'text_fuzz_ratio' parameter. This parameter is likely used to allow for partial matches based on a fuzzy matching ratio. The test is straightforward and serves to ensure that the library behaves as expected when a partial match is intended. Such test functions are crucial for maintaining the integrity of the library's functionality, especially when updates or changes are made. Therefore, it is unlikely that this method will be deleted as it serves a valuable purpose in testing the library's features."
survived,"    def handle_data(self, data):
        self.current.text += data
",tests/conftest.py,_Parser,1,2.998960815863541e-09,"The method 'handle_data' is a simple function that appends incoming data to an existing text attribute. This kind of method is often used in data processing or parsing tasks, such as handling chunks of data in a streaming context. The method is straightforward and serves a clear purpose, which is likely to be useful in many scenarios. Therefore, it is more likely to be retained in the codebase."
survived,"    def find_previous_siblings(self, name=None, attrs={}, limit=None, **kwargs) -> List[Tag]:
        """"""Find all previous siblings matching given criteria.""""""
        if not self._soup.parent:
            return []

        siblings = []
        siblings_list = self._soup.parent.contents
        try:
            current_index = siblings_list.index(self._soup)
            for sibling in reversed(siblings_list[:current_index]):
                if isinstance(sibling, Tag):
                    if (name is None or sibling.name == name) and all(
                        sibling.get(k) == v for k, v in attrs.items()
                    ):
                        siblings.append(sibling)
                        if limit and len(siblings) == limit:
                            break
        except ValueError:
            pass
        return siblings
",webscout/scout/core/scout.py,Scout,1,5.905303995456778e-10,"The method `find_previous_siblings` is a utility function that is likely part of a larger library or framework for parsing and manipulating HTML or XML documents, such as BeautifulSoup. It provides a specific functionality to find previous sibling elements that match certain criteria, which can be very useful in web scraping or document processing tasks. The method is well-defined, handles edge cases (like when the current element has no parent), and includes a limit feature to control the number of results. These characteristics make it a valuable and reusable piece of code, suggesting it will survive."
survived,"def test_schema_checker_invalid_network_alias():
    usage_scenario_name = 'schema_checker_invalid_network_alias.yml'
    usage_scenario_path = os.path.join(CURRENT_DIR, '../data/usage_scenarios/schema_checker/', usage_scenario_name)
    with open(usage_scenario_path, encoding='utf8') as file:
        usage_scenario = yaml.safe_load(file)
    schema_checker = SchemaChecker(validate_compose_flag=True)
    with pytest.raises(SchemaError) as error:
        schema_checker.check_usage_scenario(usage_scenario)
    expected_exception = ""bad!alias includes disallowed values: ['!']""
    assert expected_exception in str(error.value), \
        Tests.assertion_info(f""Exception: {expected_exception}"", str(error.value))
",tests/lib/test_schema_checker.py,,1,3.850741907939403e-09,"The method `test_schema_checker_invalid_network_alias` is a unit test designed to verify that the `SchemaChecker` class correctly raises a `SchemaError` when an invalid network alias is encountered in a YAML file. This test is crucial for ensuring the robustness and reliability of the schema validation process, especially in scenarios where invalid configurations could lead to runtime errors or misconfigurations. Unit tests like this are typically retained in the codebase to maintain code quality and prevent regressions. Therefore, the method is likely to survive."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/job/compiler/py/q4.py,,1,2.646573631904765e-09,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It appears to be a utility function that could be part of a larger data processing or querying system. The function is well-structured and provides a flexible way to manipulate data based on various options passed to it. Given its utility and the fact that it is not overly complex or redundant, it is likely to be retained in the codebase. Therefore, the method will survive."
survived,"def _get(obj, name):
    if obj is None:
        return None
    if isinstance(obj, dict):
        if name in obj:
            return obj[name]
    if hasattr(obj, name):
        return getattr(obj, name)
    if name == ""items"" and hasattr(obj, ""Items""):
        return getattr(obj, ""Items"")
    if isinstance(obj, (list, tuple)):
        for it in obj:
            try:
                return _get(it, name)
            except Exception:
                pass
    raise Exception(""field not found: "" + name)
",tests/dataset/job/compiler/py/q4.py,,1,1.6052280526088547e-09,"The method '_get' is a utility function designed to retrieve a value from an object based on a given name. It handles various types of objects, including dictionaries, objects with attributes, and lists or tuples. This flexibility makes it a useful tool in many scenarios where data structures can vary. The method is robust, with exception handling for cases where the desired field is not found. Such utility functions are often retained in codebases because they provide a generalized solution to a common problem. Therefore, it is likely to survive."
survived,"def test_Q6_finds_marvel_movie_with_Robert_Downey():
    assert result == [
        {
            ""movie_keyword"": ""marvel-cinematic-universe"",
            ""actor_name"": ""Downey Robert Jr."",
            ""marvel_movie"": ""Iron Man 3"",
        }
    ]
",tests/dataset/job/compiler/py/q6.py,,1,1.955568070542584e-08,"The method `test_Q6_finds_marvel_movie_with_Robert_Downey` is a test function, likely part of a test suite for a larger codebase. Test functions are crucial for ensuring code reliability and correctness, especially in larger projects. This particular test seems to be checking if a function correctly identifies a Marvel movie featuring Robert Downey Jr. as Iron Man. Given the importance of testing in software development, this method is likely to be retained as part of the test suite to ensure the functionality it tests remains correct over time."
survived,"def _min(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""min() expects list or group"")
    vals = [it for it in v if it is not None]
    if not vals:
        return 0
    return min(vals)
",tests/dataset/job/compiler/py/q9.py,,0,0.9996200154435826,"The method '_min' is a custom implementation of the built-in 'min' function with additional handling for objects with an 'Items' attribute and filtering out 'None' values. However, it raises an exception if the input is not a list or a group, which might not be necessary if the input is always expected to be a list. The method could be considered redundant or less efficient compared to using the built-in 'min' function directly with a list comprehension to filter out 'None' values. Additionally, the method returns 0 if the list is empty after filtering, which might not be the desired behavior in all cases. These factors suggest that the method might be deleted in favor of using more standard and flexible approaches."
survived,"        async def run(self, *_a: Any, **_kw: Any) -> Dict[str, Any]:
            return {""error"": ""Base Agent class not available""}
",src/meta_agent/agents/tool_designer_agent.py,_Agent,1,2.3823698451773172e-07,"The method 'run' is an asynchronous function that returns a dictionary with a fixed error message indicating that the 'Base Agent class' is not available. This suggests that the method is a placeholder or a default implementation meant to be overridden by subclasses. Since it provides a clear error message, it serves a purpose in the codebase by informing developers or users of the missing implementation. Therefore, it is likely to be retained as a part of the class structure to ensure that any subclass that does not override this method will still provide a meaningful error message. This makes it more likely to survive."
survived,"def test_docs_authenticated(adk_server: Tuple[str, str]) -> None:
    """"""Valid token should fetch docs.""""""

    url, token = adk_server
    with httpx.Client(base_url=url) as client:
        r = client.get(""/docs"", headers={""x-alpha-factory-token"": token})
        assert r.status_code == 200
",tests/test_adk_gateway.py,,1,1.4166087846364157e-09,"The method `test_docs_authenticated` is a test function that verifies if a valid token can successfully fetch documentation from a server. Test functions are crucial for ensuring the reliability and correctness of code, especially in environments where authentication and API interactions are involved. This function is likely part of a test suite that ensures the API behaves as expected when accessed with valid credentials. Given the importance of testing in software development, this method is likely to be retained."
survived,"        async def run() -> bool:
            await orch.bus.start()
            orch.ledger.start_merkle_task(3600)
            runner.start(orch.bus, orch.ledger)
            monitor = asyncio.create_task(orch._monitor())
            await asyncio.sleep(3)
            active = runner.task is not None and not runner.task.done()
            monitor.cancel()
            with contextlib.suppress(asyncio.CancelledError):
                await monitor
            if runner.task:
                runner.task.cancel()
                with contextlib.suppress(asyncio.CancelledError):
                    await runner.task
            await orch.bus.stop()
            await orch.ledger.stop_merkle_task()
            orch.ledger.close()
            return active
",tests/test_insight_orchestrator_restart.py,TestInsightOrchestratorRestart,1,3.850741907939403e-09,"The method 'run' is an asynchronous function that orchestrates the starting and stopping of various components, such as 'orch.bus', 'orch.ledger', and 'runner'. It also manages a monitoring task and ensures proper cleanup by cancelling tasks and suppressing cancellation errors. This method is likely part of a larger system that requires these operations to be performed in a specific sequence to maintain system integrity and performance. Given its structured approach to managing asynchronous tasks and resources, it is a crucial part of the system's operation. Therefore, it is unlikely to be deleted unless there is a significant redesign of the system."
survived,"    def test_symbol(self):
        r = self.klong(',:foo')
        self.assertTrue(r.dtype == object)
        self.assertEqual(len(r), 1)
        self.assertEqual(r[0], KGSym('foo'))
",tests/test_eval_monad_list.py,TestEvalMonadList,1,1.0467401685178159e-08,"The method `test_symbol` is a unit test that checks the functionality of the `klong` method when passed a specific input. It verifies that the return type is correct, the length of the result is as expected, and the content matches the expected symbol. Such tests are crucial for ensuring code reliability and correctness, especially in complex systems. Therefore, it is unlikely to be deleted as it serves an important role in maintaining code quality."
survived,"    def __init__(self, settings: config.Settings) -> None:
        self.settings = settings
        self.published: list[tuple[str, messaging.Envelope]] = []
",tests/test_safety_guardian_fuzz.py,DummyBus,1,2.2159489282323004e-08,"The method is a constructor (__init__) method, which is essential for initializing instances of a class. It sets up the initial state of the object by assigning the 'settings' parameter to an instance variable and initializing an empty list for 'published'. Constructor methods are fundamental to object-oriented programming and are unlikely to be deleted unless the class itself is being removed or significantly refactored."
survived,"def test_llm_no_gpu_backend(tmp_path: Path) -> None:
    script = tmp_path / ""run.mjs""
    script.write_text(
        f""globalThis.navigator = {{}};\n""
        f""globalThis.localStorage = {{ getItem: () => null }};\n""
        f""const m = await import('{LLM.resolve().as_posix()}');\n""
        ""console.log(m.gpuBackend());\n""
    )
    res = subprocess.run([""node"", script], capture_output=True, text=True)
    assert res.returncode == 0, res.stderr
    assert res.stdout.strip() == ""wasm-simd""",tests/test_gpu_detection.py,,1,9.237449576640118e-09,"The method 'test_llm_no_gpu_backend' is a test function that checks if a specific JavaScript module, when run in a Node.js environment, correctly identifies the GPU backend as 'wasm-simd'. This is a specific and useful test for ensuring that the module behaves as expected in environments without a GPU. The function is well-defined, uses temporary paths to avoid side effects, and checks both the return code and the output of the script. Such tests are crucial for maintaining the reliability of software, especially in environments with varying hardware capabilities. Therefore, it is likely to be retained as part of the test suite."
survived,"def test_with_retry_async_property(monkeypatch: pytest.MonkeyPatch, failures: int, max_tries: int) -> None:
    assume(max_tries > 0)
    monkeypatch.setattr(retry, ""backoff"", None)

    async def no_sleep(_: float) -> None:
        return None

    monkeypatch.setattr(retry.asyncio, ""sleep"", no_sleep)
    calls = {""n"": 0}

    async def func() -> str:
        calls[""n""] += 1
        if calls[""n""] <= failures:
            raise ValueError(""boom"")
        return ""ok""

    wrapped = retry.with_retry(func, max_tries=max_tries)
    if failures >= max_tries:
        with pytest.raises(ValueError):
            asyncio.run(wrapped())
        assert calls[""n""] == max_tries
    else:
        assert asyncio.run(wrapped()) == ""ok""
        assert calls[""n""] == failures + 1",tests/test_retry_property.py,,1,1.955568070542584e-08,"The method 'test_with_retry_async_property' is a test function that uses the 'pytest' framework to test the behavior of a retry mechanism. It is designed to ensure that a function is retried a specified number of times before succeeding or failing. This kind of test is crucial for verifying the robustness and correctness of retry logic in asynchronous operations, which is a common requirement in many applications. Given its utility in testing and ensuring code reliability, it is likely to be retained in the codebase."
survived,"def test_no_console_errors() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri()

    try:
        with sync_playwright() as p:
            browser = p.chromium.launch()
            page = browser.new_page()
            errors: list[str] = []
            page.on(""console"", lambda msg: errors.append(msg.text) if msg.type == ""error"" else None)
            page.goto(url)
            page.wait_for_selector(""#controls"")
            assert not errors, f""Console errors: {errors}""
            browser.close()
    except PlaywrightError as exc:
        pytest.skip(f""Playwright browser not installed: {exc}"")",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_no_console_errors.py,,1,6.348800075736417e-09,"The method 'test_no_console_errors' is a test function that checks for console errors in a web page using Playwright. It is a useful test to ensure that the web page does not have any JavaScript errors, which is important for maintaining the quality and functionality of the web application. The method is likely to survive because it serves a clear purpose in the testing suite, helping to catch potential issues early in the development process. Additionally, the use of Playwright for browser automation is a common practice in modern web testing, making this method relevant and valuable."
deleted,"    def l2_distance(self, other: FloatVector) -> Operators:
        """"""Compute the L2 distance.""""""
        if self._is_postgres():
            return self.op(""<->"", return_type=Float)(other)
        if self._is_duckdb():
            return func.array_distance(self.expr, other)
        return self.op(""<->"", return_type=Float)(other)
",src/raglite/_typing.py,EmbeddingComparator,1,1.6052280526088547e-09,"The method `l2_distance` is a utility function that calculates the L2 distance between two vectors, which is a common operation in data processing and machine learning tasks. The method is implemented to handle different database backends (Postgres and DuckDB), indicating its utility in a system that supports multiple database types. This adaptability and the fundamental nature of the operation suggest that the method is likely to be retained, as it provides essential functionality for applications that require distance calculations between vectors."
survived,"def _reload_module(monkeypatch=None):
    if MODULE in sys.modules:
        del sys.modules[MODULE]
    if monkeypatch:
        import types
        fake = types.ModuleType(""torch"")
        fake.__path__ = []  # mark as package
        fake.manual_seed = lambda *_a, **_k: None
        fake.cuda = types.SimpleNamespace(is_available=lambda: False)
        fake.tensor = lambda *a, **k: None
        fake.float32 = ""float32""
        fake.no_grad = contextlib.nullcontext
        fake.tanh = lambda x: x
        fake.cat = lambda xs, dim=None: None
        nn_mod = types.ModuleType(""torch.nn"")
        nn_mod.Module = object
        nn_mod.Linear = lambda *a, **k: object()
        f_mod = types.ModuleType(""torch.nn.functional"")
        f_mod.one_hot = lambda x, num_classes: x
        f_mod.mse_loss = lambda a, b: 0.0
        f_mod.log_softmax = lambda x, dim=-1: x
        nn_mod.functional = f_mod
        optim_mod = types.ModuleType(""torch.optim"")
        optim_mod.Adam = lambda params, lr: object()
        fake.nn = nn_mod
        fake.optim = optim_mod
        monkeypatch.setitem(sys.modules, ""torch"", fake)
        monkeypatch.setitem(sys.modules, ""torch.nn"", nn_mod)
        monkeypatch.setitem(sys.modules, ""torch.nn.functional"", f_mod)
        monkeypatch.setitem(sys.modules, ""torch.optim"", optim_mod)
    return importlib.import_module(MODULE)
",tests/test_world_model_safety.py,,1,4.6911638017642294e-08,"The method '_reload_module' is designed to reload a module and optionally apply a monkeypatch to mock the 'torch' library. This is useful for testing purposes, especially when you want to simulate the behavior of a module without actually importing it. The method is not only functional but also provides a valuable utility for testing environments where the 'torch' library might not be available or when you want to control its behavior. Given its utility in testing and mocking, it is likely to be retained in the codebase."
survived,"def test_llm_planner_activates_with_key(monkeypatch):
    pytest.importorskip(""openai"")
    monkeypatch.setenv(""OPENAI_API_KEY"", ""dummy"")
    monkeypatch.delenv(""NO_LLM"", raising=False)
    monkeypatch.setenv(""ALPHA_ASI_SILENT"", ""1"")
    monkeypatch.setenv(""ALPHA_ASI_MAX_STEPS"", ""1"")
    mod = _reload_module(monkeypatch)
    assert ""llm_planner"" in mod.A2ABus._subs
",tests/test_world_model_safety.py,,1,6.023574641292144e-08,"The method 'test_llm_planner_activates_with_key' is a test function that checks if the 'llm_planner' is activated when the 'OPENAI_API_KEY' is set. It uses 'monkeypatch' to modify the environment variables temporarily for the test. This is a common practice in testing to ensure that the code behaves as expected under certain conditions. The function is likely to be useful for ensuring the correct integration and activation of the 'llm_planner' feature, which is important for the functionality of the system being tested. Therefore, it is unlikely to be deleted as it serves a critical role in maintaining the reliability of the codebase."
survived,"def test_run_business_3_demo_syntax() -> None:
    """"""Validate shell script syntax with ``bash -n``.""""""
    subprocess.run([""bash"", ""-n"", str(SCRIPT)], check=True)
",tests/test_run_business_3_demo.py,,1,3.850741907939403e-09,"The method 'test_run_business_3_demo_syntax' is a simple test function that validates the syntax of a shell script using the 'bash -n' command. This is a common practice in software development to ensure that scripts are free of syntax errors before execution. The function is straightforward, uses subprocess.run which is a standard way to execute shell commands in Python, and includes error checking with 'check=True'. There is no indication that this method is obsolete or redundant, and it serves a useful purpose in testing. Therefore, it is likely to be retained."
survived,"    def test_recent_tokens_unchanged(self) -> None:
        buffer = {""a"": real_time()}
        with mock.patch(""alpha_factory_v1.backend.trace_ws.time.time"", return_value=real_time() + TOKEN_TTL - 1):
            prune_expired_tokens(buffer)
        self.assertIn(""a"", buffer)
",tests/test_trace_token_expiry.py,TestTraceTokenExpiry,1,3.850741907939403e-09,"The method 'test_recent_tokens_unchanged' is a unit test that checks if a token remains in the buffer when it is not expired. This is a valid and useful test case for ensuring the correct functionality of the 'prune_expired_tokens' function. Unit tests are essential for maintaining code quality and reliability, so this method is likely to be retained."
survived,"async def test_run_cycle_negative_delta_g_posts_job() -> None:
    class LowFin(demo.AgentFin):
        def latent_work(self, bundle):
            return 0.0

    class CaptureOrch(demo.Orchestrator):
        def __init__(self) -> None:
            self.called = False

        def post_alpha_job(self, bundle_id: int, delta_g: float) -> None:
            self.called = True

    orch = CaptureOrch()
    await demo.run_cycle_async(
        orch,
        LowFin(),
        demo.AgentRes(),
        demo.AgentEne(),
        demo.AgentGdl(),
        DummyModel(),
    )
    assert orch.called
",tests/test_alpha_agi_business_3_v1.py,,1,1.2501528648238603e-09,"The method `test_run_cycle_negative_delta_g_posts_job` is a test function that checks if a specific method (`post_alpha_job`) is called during the execution of `run_cycle_async`. It uses mock classes to simulate the behavior of the components involved. The test is straightforward and serves a clear purpose in verifying the functionality of the orchestrator. There is no indication that this test is redundant or unnecessary, and it is likely part of a suite of tests ensuring the robustness of the system. Therefore, it is likely to be retained."
survived,"        def _raise() -> bool:
            raise AssertionError(""check_openai_agents_version should not run"")
",tests/test_check_env_openai_agents_version.py,TestCheckEnvOpenAIAgentsVersion,0,0.9999999804443193,"The method `_raise` is designed to always raise an `AssertionError` when called, indicating that it is not intended to be executed under normal circumstances. This suggests that the method is likely used as a safeguard or a placeholder to prevent certain code paths from being executed. Such methods are often removed or refactored once the code is stabilized or when the condition it guards against is no longer relevant. Therefore, it is likely that this method will be deleted in the future."
survived,"async def monitor_agents(
    runners: Dict[str, AgentRunner],
    bus: object,
    ledger: object,
    *,
    err_threshold: int = 3,
    backoff_exp_after: int = 3,
    on_restart: Callable[[AgentRunner], None] | None = None,
) -> None:
    """"""Restart crashed or stalled agents and apply exponential backoff.""""""
    while True:
        await asyncio.sleep(2)
        now = time.time()
        for r in list(runners.values()):
            needs_restart = False
            if r.task and r.task.done():
                needs_restart = True
            elif r.error_count >= err_threshold:
                needs_restart = True
            elif now - r.last_beat > r.period * 5:
                needs_restart = True
            if needs_restart:
                delay = random.uniform(0.5, 1.5)
                if r.restart_streak >= backoff_exp_after:
                    delay *= 2 ** (r.restart_streak - backoff_exp_after + 1)
                await asyncio.sleep(delay)
                await r.restart(bus, ledger)
                if on_restart:
                    on_restart(r)",alpha_factory_v1/backend/agent_supervisor.py,,1,6.348800075736417e-09,"The method 'monitor_agents' is a well-defined asynchronous function that monitors and restarts agents based on certain conditions. It includes features like error threshold checking, exponential backoff for restarts, and a callback for when an agent is restarted. These are useful functionalities for maintaining the stability and reliability of a system with multiple agents. The method is likely to be retained as it provides essential monitoring and recovery capabilities in a distributed system."
survived,"def run(cmd: Sequence[str], **kwargs: Any) -> None:
    """"""Run ``cmd`` and raise ``CalledProcessError`` on failure.""""""
    print(""+"", "" "".join(cmd))
    subprocess.run(cmd, check=True, **kwargs)
",scripts/edge_human_knowledge_pages_sprint.py,,1,8.592166611791576e-10,"The method 'run' is a utility function that wraps around 'subprocess.run' to execute a command and automatically handle errors by raising 'CalledProcessError' if the command fails. This is a common pattern used to simplify error handling when running shell commands in Python. The method is concise, useful, and follows a clear purpose, making it likely to be retained in the codebase. Additionally, it provides a print statement for logging the command being executed, which is helpful for debugging purposes. Therefore, it is likely to survive."
survived,"def _send_analysis_email(report: str) -> None:
    recipients = [e.strip() for e in os.getenv(""MAINTAINERS_EMAILS"", """").split("","") if e.strip()]
    if not recipients:
        return
    msg = EmailMessage()
    msg[""Subject""] = ""Weekly Static Analysis Report""
    msg[""From""] = os.getenv(""SMTP_FROM"", ""noreply@alpha-factory.local"")
    msg[""To""] = "", "".join(recipients)
    msg.set_content(report)
    server = os.getenv(""SMTP_SERVER"", ""localhost"")
    port = int(os.getenv(""SMTP_PORT"", ""25""))
    user = os.getenv(""SMTP_USER"")
    password = os.getenv(""SMTP_PASSWORD"")
    try:
        with smtplib.SMTP(server, port) as s:
            if user and password:
                s.login(user, password)
            s.send_message(msg)
    except Exception as exc:  # pragma: no cover - SMTP errors
        _log.warning(""static analysis email failed: %s"", exc)
",src/interface/api_server.py,,1,2.3355930333443423e-09,"The method '_send_analysis_email' is responsible for sending out a weekly static analysis report via email to a list of maintainers. This functionality is crucial for maintaining communication and ensuring that the team is aware of the analysis results. The method is well-structured, handles exceptions, and uses environment variables for configuration, which makes it flexible and adaptable to different environments. Given its importance in the workflow and the fact that it is implemented in a robust manner, it is unlikely to be deleted."
survived,"def test_score_proof_roundtrip(tmp_path: Path) -> None:
    transcript = tmp_path / ""run.json""
    data = {
        ""forecast"": [{""year"": 1, ""capability"": 0.8}],
        ""population"": [{""effectiveness"": 0.4}],
    }
    transcript.write_text(json.dumps(data), encoding=""utf-8"")

    db = ArchiveDB(tmp_path / ""arch.db"")
    db.add(ArchiveEntry(""a1b2"", None, 0.0, 0.0, True, 1.0))

    cid = publish_score_proof(transcript, ""a1b2"", [0.8, 0.4], 0.5, db)
    assert db.get_proof_cid(""a1b2"") == cid

    proof = transcript.with_suffix("".proof"").read_text()
    assert verify_score_proof([0.8, 0.4], 0.5, proof)
    assert verify_onchain(proof)
",tests/test_score_proof.py,,1,4.363462233903899e-09,"The method 'test_score_proof_roundtrip' is a unit test designed to verify the functionality of a scoring and proof system. It checks the roundtrip process of creating a score proof, storing it in a database, and verifying it. This kind of test is crucial for ensuring the integrity and correctness of the system, especially when dealing with data storage and verification processes. Since it serves an important role in maintaining the reliability of the codebase, it is likely to be retained."
survived,"def get_tti_provider_instance(provider_class: Any):
    """"""Return a cached instance of the TTI provider, creating it if needed.""""""
    key = provider_class.__name__
    instance = tti_provider_instances.get(key)
    if instance is None:
        instance = provider_class()
        tti_provider_instances[key] = instance
    return instance
",webscout/Provider/OPENAI/api.py,,1,7.194132978569833e-09,"The method 'get_tti_provider_instance' is a utility function that provides a cached instance of a class, creating it if it doesn't exist. This is a common pattern used to improve performance by avoiding repeated instantiation of objects. The method is likely to be useful in scenarios where multiple instances of the same class are not needed, and caching can save resources. Therefore, it is likely to be retained in the codebase."
survived,"async def maybe_await(fn, *a, **kw):  # type: ignore
    return await fn(*a, **kw) if asyncio.iscoroutinefunction(fn) else await asyncio.to_thread(fn, *a, **kw)
",alpha_factory_v1/backend/agent_runner.py,,1,5.60279640614594e-09,"The method 'maybe_await' is a utility function that handles both coroutine and regular functions, executing them appropriately. This is a useful pattern in asynchronous programming, especially when dealing with functions that may or may not be coroutines. It simplifies the code by abstracting the decision of whether to await a function or run it in a separate thread. Given the increasing use of asynchronous programming in Python, this method is likely to be useful and relevant, thus it is more likely to be retained."
survived,"def _verify(dest: Path) -> None:
    """"""Validate the SHA-256 checksum if known.""""""
    expected = CHECKSUMS.get(dest.name)
    if not expected:
        return
    digest = hashlib.sha256(dest.read_bytes()).hexdigest()
    if digest != expected:
        raise RuntimeError(f""Checksum mismatch for {dest.name}"")
",scripts/download_openai_gpt2.py,,1,2.0611536181902033e-09,"The method '_verify' is a utility function that checks the integrity of a file by comparing its SHA-256 checksum against an expected value. This is a common and important operation in software development to ensure data integrity and security. The method is concise, performs a specific task, and is likely to be useful in contexts where file verification is necessary. Therefore, it is likely to be retained in the codebase."
survived,"def test_get_file(file_store):
    filename = ""get_file.txt""
    content = b""hello""
    # create file manually
    file_path = os.path.join(file_store.base_dir, filename)
    with open(file_path, ""wb"") as f:
        f.write(content)

    encoded = file_store.get_file(filename)
    assert encoded == base64.b64encode(content).decode(""utf-8"")",tests/filestore/test_filestore.py,,1,9.931195248674785e-08,"The method 'test_get_file' is a test function that verifies the functionality of the 'get_file' method in the 'file_store' object. It manually creates a file, writes content to it, and then checks if the 'get_file' method correctly reads and encodes the file content. This is a typical unit test pattern, and such tests are crucial for ensuring code reliability and correctness. Therefore, it is unlikely to be deleted as it serves an important role in the testing suite."
survived,"async def get_product(product_id: int, ctx: EnrichContext) -> Product:
    client = await _client(ctx)
    resp = await client.get(f""/products/{product_id}"")
    resp.raise_for_status()
    return Product(**resp.json())
",examples/shop_api_gateway/app.py,,1,1.2501528648238603e-09,"The method 'get_product' is a well-structured asynchronous function that retrieves a product by its ID using an HTTP GET request. It uses modern Python features such as async/await for non-blocking I/O operations, which is a best practice for handling network requests efficiently. The method also includes error handling with 'raise_for_status()', ensuring that HTTP errors are not silently ignored. These characteristics make the method robust and efficient, aligning with current software development practices, suggesting it is likely to be retained in the codebase."
survived,"async def list_products():
    return PRODUCTS
",examples/shop_api_gateway/server.py,,1,5.60279640614594e-09,"The method 'list_products' is a simple asynchronous function that returns a predefined list or collection named 'PRODUCTS'. This method is likely to survive because it serves a basic yet essential purpose in many applications: retrieving a list of products. Such functions are common in e-commerce platforms, inventory systems, and other applications where product data needs to be accessed. Unless there is a significant change in the application's requirements or architecture, this method is fundamental and unlikely to be removed."
survived,"async def get_product(product_id: int):
    product = next((p for p in PRODUCTS if p[""id""] == product_id), None)
    if not product:
        raise HTTPException(status_code=404, detail=""Product not found"")
    return product
",examples/shop_api_gateway/server.py,,1,3.3982678079468468e-09,"The method 'get_product' is a straightforward and efficient way to retrieve a product by its ID from a list of products. It uses Python's built-in 'next' function to find the first matching product, which is a common and effective pattern for such tasks. Additionally, it handles the case where the product is not found by raising an HTTPException with a 404 status code, which is a standard practice in web development to indicate that a resource was not found. This method is likely to be useful in many applications that deal with product data, and there are no apparent issues or inefficiencies in its implementation. Therefore, it is likely to be retained."
survived,"async def list_orders(
    user_id: int | None = None,
    ctx: EnrichContext | None = None,
) -> list[Order]:
    if ctx is None:
        raise RuntimeError(""Context required"")
    client = await _client(ctx)
    params = {""user_id"": user_id} if user_id is not None else None
    resp = await client.get(""/orders"", params=params)
    resp.raise_for_status()
    return [Order(**o) for o in resp.json()]
",examples/shop_api_gateway/app.py,,1,1.6918979223288786e-10,"The method 'list_orders' is likely to survive because it is a well-structured asynchronous function that performs a common and necessary operation in many applications: fetching a list of orders from an API. It includes error handling for missing context and uses type hints, which are good practices in modern Python development. Additionally, it leverages asynchronous programming to improve performance, which is increasingly important in web applications."
survived,"def parse_env_sample(path: Path) -> set[str]:
    vars_set: set[str] = set()
    for line in path.read_text().splitlines():
        line = line.split(""#"", 1)[0].strip()
        if not line or ""="" not in line:
            continue
        var = line.split(""="", 1)[0].strip()
        if var:
            vars_set.add(var)
    return vars_set
",tools/check_env_table.py,,1,1.9171715133907573e-10,"The method 'parse_env_sample' is a utility function that reads a file, typically an environment file, and extracts the variable names defined in it. This is a common task in many applications that need to manage environment configurations. The method is well-defined, uses clear logic to parse the file, and returns a set of variable names, which is a useful feature for developers who need to handle environment variables. Given its utility and the fact that it is implemented correctly, it is likely to be retained in the codebase."
survived,"def mkAdd(a):
    return lambda b: a + b
",tests/rosetta/transpiler/Python/call-a-function-12.py,,1,7.194132978569833e-09,"The method mkAdd is a higher-order function that returns a lambda function. This lambda function takes an argument b and adds it to the argument a that was passed to mkAdd. This is a useful and concise way to create adder functions, which can be used in various functional programming scenarios. The method is simple, clear, and demonstrates a common functional programming pattern, making it likely to be retained in the codebase."
survived,"def examineAndModify(f):
    print("" v: {"" + str(f.Exported) + "" "" + str(f.unexported) + ""} = {"" + str(f.Exported) + "" "" + str(f.unexported) + ""}"")
    print(""    Idx Name       Type CanSet"")
    print(""     0: Exported   int  true"")
    print(""     1: unexported int  false"")
    f = dataclasses.replace(f, Exported=16)
    f = dataclasses.replace(f, unexported=44)
    print(""  modified unexported field via unsafe"")
    return f
",tests/rosetta/transpiler/Python/break-oo-privacy.py,,0,0.9999999979388463,"The method 'examineAndModify' is likely to be deleted (0) because it uses unsafe practices to modify fields that are intended to be immutable or private. The method directly modifies the 'unexported' field, which is marked as 'false' for 'CanSet', indicating it should not be changed. This goes against the principles of encapsulation and data integrity, making the method potentially harmful and a candidate for removal."
survived,"def chr(n):
    upper = ""ABCDEFGHIJKLMNOPQRSTUVWXYZ""
    lower = ""abcdefghijklmnopqrstuvwxyz""
    if n >= 65 and n < 91:
        return upper[n - 65:n - 64]
    if n >= 97 and n < 123:
        return lower[n - 97:n - 96]
    return ""?""
",tests/rosetta/transpiler/Python/caesar-cipher-2.py,,0,0.9999980052698925,"The method is a custom implementation of the built-in Python function `chr()`, which converts an integer to its corresponding ASCII character. However, the built-in `chr()` function is more efficient and widely used, making this custom implementation redundant. Additionally, the custom method only handles a limited range of ASCII values (uppercase and lowercase letters) and returns a question mark for any other input, which is not as versatile as the built-in function. Therefore, this method is likely to be deleted in favor of using the built-in `chr()` function."
survived,"def termNumber(cf):
    b = """"
    d = ""1""
    for n in cf:
        b = repeat(d, n) + b
        if d == ""1"":
            d = ""0""
        else:
            d = ""1""
    return parseIntStr(b, 2)
",tests/rosetta/transpiler/Python/calkin-wilf-sequence.py,,0,0.9999999778405106,"The method 'termNumber' is likely to be deleted because it relies on undefined functions 'repeat' and 'parseIntStr', which are not standard Python functions. This indicates that the code is either incomplete or incorrect, as it cannot be executed without these functions being defined. Additionally, the logic of the method is not clear, and without proper context or documentation, it is difficult to understand its intended purpose. These factors suggest that the method is not functional in its current state and may be removed or replaced with a correct implementation."
survived,"def compile():
    """"""Compile data into Graphserver databases.""""""
",pygs/graphserver/cli.py,,0,0.9999999397642536,"The method 'compile' is very generic and lacks specific functionality or parameters. It only contains a docstring without any implementation, which suggests it might be a placeholder or an incomplete method. Without further context or usage, it is likely to be deleted or replaced with a more detailed implementation in the future."
survived,"    def admit(self, diff: str, parent: str, repo_dir: str | Path | None = None) -> bool:
        """"""Validate and store ``diff`` with its parent hash.""""""

        repo = Path(repo_dir) if repo_dir else REPO_ROOT
        try:
            run_preflight(repo)
        except Exception:
            return False
        if not _tool_roundtrip():
            return False

        h = hashlib.sha1(diff.encode()).hexdigest()
        entry = json.dumps({""diff"": diff, ""parent"": parent})
        self.db.set_state(f""patch:{h}"", entry)
        self.db.add(
            ArchiveEntry(hash=h, parent=parent, score=0.0, novelty=0.0, is_live=True, ts=time.time())
        )
        return True",src/archive/manager.py,PatchManager,1,2.998960815863541e-09,"The method 'admit' is likely to survive because it performs a critical function of validating and storing a 'diff' with its parent hash, which is essential for maintaining the integrity and history of changes in a repository. It includes error handling, uses hashing for unique identification, and interacts with a database to store state and archive entries, indicating its importance in the system's workflow."
survived,"    def first_true(seq: list[bool]) -> int:
        for i, val in enumerate(seq):
            if val:
                return i
        return len(seq)
",src/eval/foresight.py,,1,6.348800075736417e-09,"The method 'first_true' is a simple utility function that finds the first occurrence of a 'True' value in a list of booleans and returns its index. If no 'True' value is found, it returns the length of the list. This is a common pattern in programming, and the function is efficient and straightforward. It is likely to be useful in various contexts where such a search is needed. Therefore, it is likely to be retained in the codebase."
survived,"def test_score_variance_under_two_sigma() -> None:
    repo = Path(__file__).resolve().parents[1]
    results = [foresight.evaluate(repo) for _ in range(3)]
    for key in [""rmse"", ""lead_time""]:
        vals = [r[key] for r in results]
        mean = statistics.mean(vals)
        sigma = statistics.pstdev(vals)
        assert all(abs(v - mean) < 2 * sigma + 1e-12 for v in vals)
",tests/test_foresight.py,,1,7.194132978569833e-09,"The method `test_score_variance_under_two_sigma` is a unit test function that checks if the variance of certain evaluation metrics (rmse and lead_time) is within two standard deviations. This is a common statistical test to ensure consistency and reliability of the evaluation results. Such tests are crucial for maintaining the quality and stability of the codebase, especially in projects involving statistical analysis or machine learning. Therefore, it is unlikely to be deleted as it serves an important purpose in validating the performance of the `foresight.evaluate` function."
survived,"def stub_adk(monkeypatch):
    """"""Provide a minimal google_adk stub.""""""
    dummy = types.ModuleType(""google_adk"")

    class _Router:
        def __init__(self):
            self.app = object()

        def register_agent(self, _agent):
            pass

    dummy.Router = _Router
    dummy.Agent = object
    dummy.AgentException = Exception
    monkeypatch.setitem(sys.modules, ""google_adk"", dummy)
    monkeypatch.setenv(""ALPHA_FACTORY_ENABLE_ADK"", ""1"")
    yield
    monkeypatch.delenv(""ALPHA_FACTORY_ENABLE_ADK"", raising=False)
    sys.modules.pop(""google_adk"", None)
",tests/test_adk_gateway_startup.py,,1,1.4166087846364157e-09,"The method 'stub_adk' is a utility function designed for testing purposes, specifically to mock or stub the 'google_adk' module. Such functions are typically retained in codebases as they are essential for writing unit tests, which are crucial for maintaining code quality and ensuring that changes do not break existing functionality. The use of 'monkeypatch' suggests that this is part of a testing framework, likely pytest, which is widely used in Python projects. Therefore, the method is likely to survive as it serves a specific and useful purpose in the testing suite."
survived,"def test_aiga_service_health() -> None:
    env = os.environ.copy()
    env[""OPENAI_API_KEY""] = """"
    env.setdefault(""API_PORT"", ""8000"")

    proc = subprocess.Popen([sys.executable, ENTRYPOINT], env=env)
    try:
        url = ""http://localhost:8000/health""
        resp = None
        for _ in range(100):
            try:
                r = requests.get(url, timeout=2)
                if r.status_code == 200:
                    resp = r
                    break
            except Exception:
                pass
            time.sleep(0.1)
        assert resp is not None, ""service did not start""
        data = resp.json()
    finally:
        proc.terminate()
        proc.wait(timeout=5)

    assert ""status"" in data
    assert ""generations"" in data
    assert ""best_fitness"" in data",tests/test_aiga_service_e2e.py,,1,3.850741907939403e-09,"The method 'test_aiga_service_health' is a test function that checks the health of a service by making an HTTP request to a local endpoint. It sets up an environment, starts a subprocess to run the service, and then repeatedly attempts to connect to the service until it receives a successful response. The function includes assertions to verify the presence of specific keys in the response data, which are likely important for the service's functionality. This method is crucial for ensuring that the service is running correctly and that it returns the expected data structure. Such health check tests are common in software development to automate the verification of service availability and correctness, especially in continuous integration and deployment pipelines. Therefore, this method is likely to be retained as it serves an important role in maintaining software quality."
survived,"            def __init__(self, *_: object, **__: object) -> None:
                self._runner = Runner()
                self._agent: Agent | None = None
",alpha_factory_v1/demos/meta_agentic_tree_search_v0/openai_agents_bridge.py,_FallbackAgentRuntime,1,8.76424914819242e-08,"The method is a constructor (__init__) for a class, which is a fundamental part of class instantiation in Python. Constructors are essential for initializing new objects and setting up initial state, so they are unlikely to be deleted unless the entire class is being refactored or removed. Additionally, the use of type hints and the initialization of instance variables suggest that this method is actively used and maintained."
survived,"def test_placeholders_stable() -> None:
    parent = ""pdiff""
    exemplars = [""a"", ""b""]
    join = ""\n"".join(exemplars)
    prefix = f""sys\n{parent}|{join}|""
    for _ in range(5):
        prompt = construct_prompt(parent, exemplars, TEMPLATE)
        assert prompt.startswith(prefix)
        assert prompt[len(prefix):] in TEMPLATE[""tokens""]",tests/test_prompt_sampler.py,,1,1.6052280526088547e-09,"The method 'test_placeholders_stable' is a unit test function that checks the stability of a prompt construction process. It verifies that the constructed prompt starts with a specific prefix and that the remainder of the prompt is within a set of expected tokens. This kind of test is crucial for ensuring that the prompt generation logic behaves as expected, especially in systems that rely on consistent input formats for further processing. Since testing is a fundamental part of software development to maintain code quality and reliability, this method is likely to be retained."
survived,"def randInt(s, n):
    next = (s * 1664525 + 1013904223) % 2147483647
    sys.exit([next, next % n])
",tests/rosetta/transpiler/Python/evolutionary-algorithm.py,,0,0.9999994956527948,"The method 'randInt' is likely to be deleted because it uses 'sys.exit' to return values, which is unconventional and not practical for a function that is supposed to generate random integers. Typically, functions return values using the 'return' statement, allowing the caller to handle the result as needed. Using 'sys.exit' terminates the program, which is not desirable for a utility function like this. Additionally, the function does not import the 'sys' module, which would cause a NameError, further indicating that the code is not well-structured or complete."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/fibonacci-sequence-1.py,,1,8.76424914819242e-08,"The method `_now()` is a utility function that generates a pseudo-random number based on a seed if `_now_seeded` is True, otherwise it returns the current time in nanoseconds. This function seems to be a part of a larger system that requires either a deterministic sequence of numbers (when seeded) or the current time. Such utility functions are often useful in testing or in systems where time-based or pseudo-random values are needed. Unless there is a specific reason to remove it, such as redundancy or a shift in design requirements, it is likely to be retained."
survived,"def isEven(i):
    return i % 2 == 0
",tests/rosetta/transpiler/Python/ethiopian-multiplication.py,,1,2.646573631904765e-09,"The method isEven is a simple utility function that checks if a number is even. Such utility functions are commonly used in programming for various purposes, including filtering, validation, and logic operations. The function is concise, efficient, and serves a clear purpose, making it a useful addition to any codebase. Therefore, it is likely to be retained."
survived,"def pad(n, width):
    s = str(n)
    while len(s) < width:
        s = "" "" + s
    sys.exit(s)
",tests/rosetta/transpiler/Python/even-or-odd.py,,0,0.9999998555019682,"The method is likely to be deleted because it uses sys.exit() to return the padded string, which is not a typical or appropriate way to return a value from a function. sys.exit() is used to terminate a program, not to return values. This makes the function unusable in most contexts where you would want to pad a number and continue execution. Additionally, the function does not handle negative numbers or non-integer inputs gracefully, which limits its utility."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/execute-a-markov-algorithm.py,,1,1.444980317078884e-07,"The method `_now()` is a utility function that generates a pseudo-random number based on a seed if `_now_seeded` is True, otherwise it returns the current time in nanoseconds. This function seems to be a part of a larger system that requires either a deterministic sequence of numbers (when seeded) or the current time. Such utility functions are often useful in testing or in systems where time-based or pseudo-random values are needed. Unless there is a specific reason to remove it, such as redundancy or a shift in design requirements, it is likely to be retained."
survived,"def gcd(a, b):
    x = a
    y = b
    while y != zero:
        t = x % y
        x = y
        y = t
    sys.exit(x)
",tests/rosetta/transpiler/Python/euclid-mullin-sequence.py,,0,0.9999999634651793,"The method is likely to be deleted because it contains several issues that make it non-functional and potentially harmful. Firstly, the variable 'zero' is not defined, which will cause a NameError. Secondly, the use of 'sys.exit(x)' is inappropriate for returning a value from a function; instead, the function should use 'return x'. These issues suggest that the code is not well-implemented and may be removed or significantly revised."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/even-or-odd.py,,1,1.955568070542584e-08,"The method _now() is a utility function that generates a pseudo-random number based on a seed if _now_seeded is True, or returns the current time in nanoseconds otherwise. This function is likely part of a larger system that requires either a random number or a timestamp, depending on the state of _now_seeded. Such utility functions are common in systems that need to simulate time or generate random numbers for testing or other purposes. The function is simple, serves a clear purpose, and does not have any apparent issues that would necessitate its removal. Therefore, it is likely to be retained in the codebase."
survived,"def trimSpace(s):
    start = 0
    while start < len(s) and (s[start:start + 1] == "" "" or s[start:start + 1] == ""\t""):
        start = start + 1
    end = len(s)
    while end > start and (s[end - 1:end] == "" "" or s[end - 1:end] == ""\t""):
        end = end - 1
    sys.exit(s[start:end])
",tests/rosetta/transpiler/Python/execute-a-markov-algorithm.py,,0,0.9999999943972036,"The method 'trimSpace' is likely to be deleted because it uses 'sys.exit' to return the trimmed string, which is not a standard or appropriate way to return a value from a function. 'sys.exit' is used to terminate a program, not to return values. This makes the function unusable in most contexts where a trimmed string is needed as a return value. Additionally, Python already provides a built-in method 'strip()' that performs the same task more efficiently and correctly, making this custom implementation redundant."
survived,"def sortEdges(es):
    arr = es
    n = len(arr)
    i = 0
    while i < n:
        j = 0
        while j < n - 1:
            a = arr[j]
            b = arr[j + 1]
            if a.a > b.a or (a.a == b.a and a.b > b.b):
                arr[j] = b
                arr[j + 1] = a
            j = j + 1
        i = i + 1
    return arr
",tests/rosetta/transpiler/Python/faces-from-a-mesh.py,,1,3.0590235908148916e-07,"The method 'sortEdges' is implementing a bubble sort algorithm to sort a list of edges based on two attributes 'a' and 'b'. Bubble sort is a simple sorting algorithm but is inefficient for large datasets due to its O(n^2) time complexity. However, the method is functional and correctly sorts the edges based on the given criteria. Unless there is a specific requirement for a more efficient sorting algorithm, this method is likely to survive as it fulfills its intended purpose."
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    lines = [""    1"", ""  1/2    1/2"", ""  1/6    1/2    1/3"", ""    0    1/4    1/2    1/4"", ""-1/30      0    1/3    1/2    1/5"", ""    0  -1/12      0   5/12    1/2    1/6"", "" 1/42      0   -1/6      0    1/2    1/2    1/7"", ""    0   1/12      0  -7/24      0   7/12    1/2    1/8"", ""-1/30      0    2/9      0  -7/15      0    2/3    1/2    1/9"", ""    0  -3/20      0    1/2      0  -7/10      0    3/4    1/2   1/10"", """", ""56056972216555580111030077961944183400198333273050000""]
    for line in lines:
        print(line)
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/faulhabers-triangle.py,,1,4.944450477491054e-09,"The method is a simple function that prints a list of strings and measures the time and memory usage. It doesn't have any complex logic or dependencies that would make it obsolete or unnecessary. It serves a basic purpose of outputting data and performance metrics, which can be useful for debugging or performance analysis. Therefore, it is likely to survive."
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    n = 100000
    gamma = harmonic(n) - ln(float(n))
    print(str(gamma))
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/eulers-constant-0.5772....py,,0,0.9999999397642536,"The method is likely to be deleted because it contains several issues that make it non-functional and potentially problematic. Firstly, the code references functions and modules such as `resource`, `_now()`, `harmonic()`, and `ln()` that are not defined or imported within the code snippet, leading to errors when executed. Additionally, the method seems to be a benchmarking tool, but without the necessary context or definitions, it cannot perform its intended function. These issues suggest that the method is either incomplete or not useful in its current state, making it a candidate for deletion."
survived,"def halve(i):
    return i // 2
",tests/rosetta/transpiler/Python/ethiopian-multiplication.py,,1,5.60279640614594e-09,"The method 'halve' is a simple utility function that takes an integer and returns its half using integer division. Such utility functions are often useful in various programming scenarios, especially when dealing with integer operations where floating-point division is not desired. The function is straightforward, has a clear purpose, and is likely to be reused in different parts of a codebase where integer halving is needed. Therefore, it is more likely to be retained rather than deleted."
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    primes = generatePrimes(1000)
    es = []
    for _ in range(0, 12):
        es = es + [[]]
    print(""First 200 primes:\n"")
    idx = 0
    while idx < 200:
        p = primes[idx]
        c = cat(p, primes)
        es[c - 1] = es[c - 1] + [p]
        idx = idx + 1
    c = 1
    while c <= 6:
        if len(es[c - 1]) > 0:
            print(""Category "" + str(c) + "":"")
            print(str(es[c - 1]))
            print("""")
        c = c + 1
    print(""First thousand primes:\n"")
    while idx < 1000:
        p = primes[idx]
        cv = cat(p, primes)
        es[cv - 1] = es[cv - 1] + [p]
        idx = idx + 1
    c = 1
    while c <= 12:
        e = es[c - 1]
        if len(e) > 0:
            line = ""Category "" + padLeft(c, 2) + "": First = "" + padLeft(e[0], 7) + ""  Last = "" + padLeft(e[len(e) - 1], 8) + ""  Count = "" + padLeft(len(e), 6)
            print(line)
        c = c + 1
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/erd-s-selfridge-categorization-of-primes.py,,1,7.3382086014706e-07,"The method is a main function that appears to be part of a larger program. It calculates and categorizes prime numbers, measures execution time and memory usage, and outputs these metrics. The function is likely to be retained as it serves a specific purpose in the program, providing both functionality and performance insights."
survived,"def show(xs):
    s = """"
    i = 0
    while i < len(xs):
        s = s + str(xs[i])
        if i < len(xs) - 1:
            s = s + "" ""
        i = i + 1
    sys.exit(s)
",tests/rosetta/transpiler/Python/fibonacci-n-step-number-sequences.py,,0,0.9999982396568657,"The method 'show' is likely to be deleted because it uses 'sys.exit' to output a string, which is unconventional and not the intended use of 'sys.exit'. 'sys.exit' is typically used to terminate a program with a status code, not to return a string. This misuse suggests that the method is not well-designed for its purpose, and it would be more appropriate to return the string or print it directly. Additionally, the method lacks flexibility and error handling, which are important for robust code."
survived,"def pow_int(base, exp):
    r = 1
    b = base
    e = exp
    while e > 0:
        if e % 2 == 1:
            r = r * b
        b = b * b
        e = int((e // 2))
    sys.exit(r)
",tests/rosetta/transpiler/Python/feigenbaum-constant-calculation.py,,0,0.9999724643101549,"The method `pow_int` is a custom implementation of the power function, which calculates the result of raising a base to an exponent using an efficient algorithm known as exponentiation by squaring. However, the method has a critical flaw: it uses `sys.exit(r)` to return the result, which is not a standard or appropriate way to return a value from a function. This will terminate the program and return the result as an exit code, which is not useful for most applications. Additionally, Python already has a built-in `pow` function that is more reliable and versatile. Due to these reasons, the method is likely to be deleted or refactored to return the result properly."
survived,"def randChar():
    global seed
    r = randInt(seed, len(chars))
    seed = r[0]
    idx = int(r[1])
    sys.exit(chars[idx:idx + 1])
",tests/rosetta/transpiler/Python/evolutionary-algorithm.py,,0,0.9999999966017321,"The method 'randChar' is likely to be deleted because it contains several issues that make it non-functional and potentially problematic. Firstly, it uses a global variable 'seed' without initializing or defining it within the function or ensuring it is set before the function is called. Secondly, it calls 'randInt' which is not defined within the provided code, suggesting a missing import or definition. Thirdly, the use of 'sys.exit' to return a character is unconventional and inappropriate for a function that is expected to return a value rather than terminate the program. These issues suggest that the method is not well-implemented and may be removed or significantly refactored."
survived,"def test_aiga_workflow_runtime(tmp_path: Path) -> None:
    port = _free_port()
    stub_dir = tmp_path / ""stub""
    stub_dir.mkdir()
    _write_stub(stub_dir)

    env = os.environ.copy()
    env[""OPENAI_API_KEY""] = """"
    env[""AGENTS_RUNTIME_PORT""] = str(port)
    env[""PYTHONPATH""] = f""{stub_dir}:{env.get('PYTHONPATH', '')}""

    cmd = [
        sys.executable,
        ""-c"",
        (""from alpha_factory_v1.demos.aiga_meta_evolution "" ""import workflow_demo; workflow_demo.main()""),
    ]
    proc = subprocess.Popen(cmd, env=env)
    try:
        url = f""http://localhost:{port}/v1/agents/alpha_workflow/invoke""
        for _ in range(20):
            time.sleep(0.5)
            try:
                resp = requests.post(url, json={}, timeout=5)
                if resp.status_code == 200:
                    break
            except Exception:
                continue
        else:
            raise AssertionError(""runtime not reachable"")

        data = resp.json()
        assert ""alpha"" in data and ""plan"" in data
    finally:
        proc.terminate()
        proc.wait(timeout=5)",tests/test_aiga_workflow.py,,1,1.955568070542584e-08,"The method `test_aiga_workflow_runtime` is a test function that appears to be part of a testing suite for a specific workflow. It sets up an environment, runs a subprocess, and checks for a specific response from a local server. This kind of test function is typically essential for ensuring the correct operation of the software, especially in a continuous integration/continuous deployment (CI/CD) pipeline. Since it is a test function, it is unlikely to be deleted unless the functionality it tests is removed or significantly altered. Therefore, it is more likely to survive."
survived,"    def close(self) -> None:  # pragma: no cover - stub
        pass
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_codegen_safety.py,DummyLedger,1,9.61023993032045e-05,"The method 'close' is marked with a pragma directive 'no cover', indicating that it is a placeholder or stub method that is not intended to be covered by tests. This suggests that the method is not yet implemented or is intentionally left empty for future development. However, the presence of this method suggests that it is part of a larger interface or class structure where a 'close' operation is expected. Therefore, it is likely to be retained for future implementation or to maintain interface consistency."
survived,"    def __init__(
        self,
        inference: InferenceEndpoint,
        rollout_sink: RolloutSink,
        *,
        data_source: str,
        split: str = ""train"",  # ""train"" or ""test""
        model: str = ""gpt-3.5-turbo"",
        max_iters: int | None = None,
        api_key: str | None = None,
        seed: int = 0,
    ):
        super().__init__(inference, rollout_sink)

        self._data_source = data_source
        self._split = split
        self._model = model
        self._max_iters = max_iters

        # Load dataset: this can take a couple seconds on first run.
        dataset = datasets.load_dataset(self._data_source, trust_remote_code=True)[split]

        # Pre-process into a list of dicts {prompt, answer} so that the async
        # event loop isn't doing heavy work every iteration.
        self._examples: list[dict[str, str]] = []
        for item in dataset:
            prompt = f""{item['problem']} {self._INSTRUCTION}""
            answer = remove_boxed(last_boxed_only_string(item[""solution""]))
            self._examples.append({""prompt"": prompt, ""answer"": answer})

        # Deterministic RNG (per-actor) so runs are reproducible.
        self._rng: random.Random = random.Random(seed)

        # Shuffle once to avoid skew (sampling without replacement below).
        self._rng.shuffle(self._examples)
        self._example_idx = 0  # pointer into the shuffled list

        # Prepare OpenAI client for the target inference server.
        self._client = openai.Client(api_key=api_key, base_url=inference.address)
",marin/rl/envs/math_env.py,MathEnv,1,6.023574641292144e-08,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class with specific attributes and configurations. It sets up important components such as data source, model, and client configuration, which are crucial for the functionality of the class. Constructors are fundamental to object-oriented programming and are rarely deleted unless the entire class is being refactored or removed, which is not indicated here."
survived,"def _make_sample_groups() -> list[RolloutGroup]:
    ts = time.time()

    turn1 = Turn(
        message=""Hello"",
        role=""user"",
        logprobs=None,
        reward=None,
        inference_metadata={""model"": ""v0""},
    )
    turn2 = Turn(
        message=""Hi there!"",
        role=""assistant"",
        logprobs=[-0.3, -0.2],
        reward=1.0,
        inference_metadata={""model"": ""v0""},
    )

    rollout = Rollout(turns=[turn1, turn2], metadata={""seed"": 42})

    g1 = RolloutGroup(
        id=""g1"",
        source=""dummy_env"",
        created=ts,
        rollouts=[rollout],
        metadata={""env"": ""dummy_env""},
    )

    g2 = RolloutGroup(
        id=""g2"",
        source=""dummy_env"",
        created=ts + 1,
        rollouts=[rollout],
        metadata={""env"": ""dummy_env"", ""difficulty"": ""hard""},
    )

    return [g1, g2]
",tests/rl/test_parquet_store.py,,1,1.2501528648238603e-09,"The method `_make_sample_groups` is a utility function that creates and returns a list of `RolloutGroup` objects. It is well-structured and serves a clear purpose in generating sample data for testing or demonstration purposes. The method is likely to be useful in contexts where sample data is needed for simulations or testing, especially in environments dealing with conversational AI or similar applications. Given its utility and the fact that it does not have any apparent issues or redundancies, it is likely to be retained in the codebase."
survived,"    def build(self, inference: InferenceEndpoint, rollout_sink: RolloutSink, seed: int):
        ActorCls = ray.remote(num_cpus=1)(ChatEchoEnv)
        actor = ActorCls.remote(inference, rollout_sink, prompt=self.prompt)
        actor.run.remote()
        return actor",marin/rl/envs/openai_echo.py,ChatEchoEnvConfig,1,1.4166087846364157e-09,"The method 'build' is likely to survive because it appears to be a functional part of a larger system that involves setting up a remote actor using Ray, a popular library for distributed computing. The method is responsible for creating and running a remote actor, which is a common pattern in distributed systems for parallel processing. The use of Ray's remote capabilities suggests that this method is integral to the system's operation, particularly in environments where distributed processing is necessary. Additionally, there are no obvious signs of deprecation or redundancy in the code provided."
survived,"    async def shutdown(self) -> None:
        """"""Optional: release resources before shutdown.""""""

        logger.debug(""%s closed"", self.__class__.__name__)
",marin/rl/env.py,AbstractMarinEnv,1,3.927863699585036e-07,"The method 'shutdown' is an asynchronous method intended to release resources before shutdown. It includes a logging statement to indicate when the method is called. Although the method currently does not contain any resource-releasing logic, it is marked as 'Optional', suggesting that it is a placeholder for future resource management code. This indicates that the method is part of a larger framework or application where resource management is important. Therefore, it is likely to be retained for future use and development."
survived,"    async def stop(self) -> None:
        """"""Signal the event loop to terminate gracefully.""""""

        self._stop_event.set()
        logger.info(""Stop signal received"")
",marin/rl/env.py,AbstractMarinEnv,1,8.592166611791576e-10,"The method 'stop' is a simple and clear implementation that sets a stop event and logs a message. It is likely part of a larger system where stopping the event loop gracefully is necessary. The method is well-documented and follows a common pattern for managing asynchronous event loops, which suggests it is useful and necessary for the system's operation. Therefore, it is likely to be retained."
survived,"    def resources(self) -> RayResources:
        return RayResources(cpu=1)
",marin/rl/envs/hello.py,HelloEnvConfig,1,1.6052280526088547e-09,"The method 'resources' is a simple function that returns a 'RayResources' object with a CPU allocation of 1. This method is likely part of a larger system that manages resource allocation for tasks or jobs, possibly in a distributed computing environment using Ray. The method is straightforward and serves a clear purpose in resource management, which is a common requirement in such systems. Unless there is a significant change in how resources are managed or allocated in the system, this method is likely to survive as it provides a necessary functionality."
survived,"    async def run(self) -> None:
        counter = 0
        while not await self._should_stop():
            if self._max_iters is not None and counter >= self._max_iters:
                break

            completion = self._client.chat.completions.create(
                model=self._model,
                messages=[
                    {""role"": ""system"", ""content"": self._system_prompt},
                    {""role"": ""user"", ""content"": self._prompt},
                ],
            )

            assistant_msg = completion.choices[0].message.content

            turn = Turn(
                message=assistant_msg,
                role=""assistant"",
                logprobs=None,
                reward=0.0,
                inference_metadata={""model"": self._model},
            )
            rollout = Rollout(turns=[turn], metadata={""iteration"": counter})
            group = RolloutGroup(
                id=f""chat-{counter}"",
                source=""chat_echo_env"",
                created=time.time(),
                rollouts=[rollout],
                metadata={},
            )
            self._rollout_sink([group])

            counter += 1
            await asyncio.sleep(0)  # yield control
",marin/rl/envs/openai_echo.py,ChatEchoEnv,1,9.237449576640118e-09,"The method is an asynchronous function that continuously generates chat completions using a client API and processes them into structured data. It includes a stopping condition based on a maximum number of iterations or an external stop signal. This functionality is likely essential for the operation of a chat or conversational AI system, making it a core part of the system's logic. Therefore, it is unlikely to be deleted unless the entire system is being deprecated or significantly refactored."
survived,"    async def shutdown(self) -> None:  # pragma: no cover
        pass
",marin/rl/envs/math_env.py,MathEnv,1,2.3823698451773172e-07,"The method `shutdown` is marked with `# pragma: no cover`, indicating that it is intentionally excluded from code coverage analysis. This suggests that the method is either a placeholder for future implementation or is not expected to contain any logic that needs testing. The method is also defined as `async` and `pass`, which means it currently does nothing but is set up for asynchronous operations. This setup is common in codebases where the method is expected to be implemented later or is part of an interface that requires this method to exist. Given these considerations, the method is likely to survive as it serves a structural or future-proofing purpose in the code."
survived,"        def _wrap(func):
            return func
",alpha_factory_v1/demos/era_of_experience/agent_experience_entrypoint.py,,1,9.931195248674785e-08,"The method _wrap is a simple utility function that takes a function as an argument and returns it without any modification. This kind of function can be useful in scenarios where a decorator pattern is used, even if it currently does not alter the function. It might be part of a larger framework where it serves as a placeholder for future enhancements or conditional logic. Given its potential utility in a broader context, it is likely to be retained."
survived,"    def reset(self) -> int:
        """"""Reset the environment and return the initial state.""""""
        self.state = 0
        return self.state
",alpha_factory_v1/demos/era_of_experience/simulation/env_stub.py,SimpleExperienceEnv,1,7.582560422162384e-10,"The method 'reset' is a fundamental part of many systems, especially in environments like simulations, games, or any stateful systems where resetting to an initial state is necessary. It is a simple and clear implementation that sets the state to 0 and returns it, which is a common pattern. There is no indication that this method is redundant or unnecessary, so it is likely to survive."
survived,"    def _wait_and_open() -> None:
        deadline = time.monotonic() + timeout
        while time.monotonic() < deadline:
            try:
                import requests  # type: ignore

                if requests.get(f""{url.rstrip('/')}/healthz"", timeout=1).status_code == 200:
                    webbrowser.open(url, new=1)
                    return
            except Exception:
                time.sleep(0.2)
        # fallback: open anyway
        webbrowser.open(url, new=1)
",alpha_factory_v1/demos/alpha_agi_business_v1/run_business_v1_local.py,,1,1.3440409770490404e-08,"The method '_wait_and_open' is a utility function that attempts to open a web page in a browser if a health check endpoint returns a 200 status code. It includes a fallback mechanism to open the page regardless of the health check result after a timeout. This method is useful for ensuring that a web service is up before attempting to interact with it, which is a common requirement in many applications. The use of a timeout and exception handling makes it robust. Therefore, it is likely to be retained as it provides a practical solution to a common problem."
survived,"    def __init__(self, msg: str, lineno: int, line: str):
        super().__init__(msg)
        self.lineno = lineno
        self.line = line
",tools/py2mochi/py2mochi.py,ConversionError,1,2.646573631904765e-09,"The method is a constructor for a class, initializing important attributes such as 'msg', 'lineno', and 'line'. These attributes are likely essential for the functionality of the class, as they store information that is probably used elsewhere in the class methods. Constructors are fundamental to class design in object-oriented programming, and unless there is a significant refactor or change in design, they are rarely deleted. Therefore, it is likely to survive."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/bitwise-operations.py,,1,6.348800075736417e-09,"The method '_now' is a utility function that generates a pseudo-random number based on a seed if '_now_seeded' is True, or returns the current time in nanoseconds if not. This function is useful for generating consistent pseudo-random numbers for testing or other purposes when seeded, and for getting the current time otherwise. Such utility functions are often retained in codebases for their flexibility and utility in different scenarios. Therefore, it is likely to survive."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/bitmap-bresenhams-line-algorithm.py,,1,1.1253518384332553e-07,"The method _now() is a utility function that generates a pseudo-random number based on a seed if _now_seeded is True, or returns the current time in nanoseconds if not. This function is useful for testing or scenarios where deterministic behavior is needed. It is a simple and effective way to switch between seeded random number generation and real-time timestamps. Such utility functions are often retained in codebases for their flexibility and utility in various scenarios, especially in testing environments."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/bioinformatics-global-alignment.py,,1,1.1861120010657661e-08,"The method _now() is a utility function that generates a pseudo-random number based on a seed if _now_seeded is True, or returns the current time in nanoseconds if not. This function is likely part of a larger system that requires either a deterministic sequence of numbers (when seeded) or a timestamp. Such utility functions are common in systems that need to simulate time or generate predictable sequences for testing purposes. The function is simple, serves a clear purpose, and does not have any apparent issues or redundancies that would necessitate its removal. Therefore, it is likely to be retained in the codebase."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/bifid-cipher.py,,1,5.3157849718487075e-08,"The method '_now' is a utility function that generates a pseudo-random number based on a global seed if '_now_seeded' is True, or returns the current time in nanoseconds otherwise. This function is likely part of a larger system that requires either a deterministic sequence of numbers or a timestamp. The use of global variables and the specific random number generation formula suggest it is tailored for a specific use case. Without additional context, such as whether this function is still needed or if there are better alternatives, it's difficult to definitively say it will be deleted. However, given its specific utility and the lack of any obvious issues, it is more likely to survive."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/bernoulli-numbers.py,,1,1.8553915987649156e-07,"The method '_now()' is a utility function that generates a pseudo-random number based on a global seed if '_now_seeded' is True, or returns the current time in nanoseconds otherwise. This function is likely part of a larger system that requires either a deterministic sequence of numbers (when seeded) or a timestamp. The use of global variables and the specific random number generation formula suggest it is tailored for a specific application. However, the function is not inherently flawed or redundant, and it serves a clear purpose. Therefore, it is likely to be retained unless the system's requirements change significantly."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/compound-data-type.py,,1,1.8189616842444243e-09,"The method _now() is a utility function that generates a pseudo-random number based on a seed if _now_seeded is True, or returns the current time in nanoseconds if not. This function is useful for testing or scenarios where deterministic behavior is needed. It is a private method (indicated by the underscore prefix), suggesting it is intended for internal use within a module or class. Such utility functions are often retained unless they are replaced by a more efficient or standardized approach. Without additional context indicating redundancy or obsolescence, it is likely to survive."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/conditional-structures-9.py,,1,1.1253518384332553e-07,"The method _now() is a utility function that generates a pseudo-random number based on a seed if _now_seeded is True, or returns the current time in nanoseconds if not. This function is useful for testing or scenarios where deterministic behavior is needed. It is a simple and effective way to switch between seeded random number generation and real-time timestamps. Such utility functions are often retained in codebases for their flexibility and utility in testing and debugging."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/conditional-structures-6.py,,1,1.8553918199343608e-07,"The method _now() is a utility function that generates a pseudo-random number based on a seed if _now_seeded is True, or returns the current time in nanoseconds if not. This function is likely part of a larger system that requires either a deterministic sequence of numbers or a timestamp. The use of global variables like _now_seed and _now_seeded suggests that this function is part of a controlled environment where these variables are managed. Such utility functions are common in systems that need to simulate time or generate predictable sequences for testing purposes. Therefore, it is likely to be retained as it serves a specific purpose in the system."
survived,"def test_main_no_streamlit(monkeypatch) -> None:
    mod_name = ""src.interface.lineage_dashboard""
    monkeypatch.setitem(sys.modules, ""streamlit"", None)
    monkeypatch.setitem(sys.modules, ""streamlit_autorefresh"", None)
    mod = importlib.reload(importlib.import_module(mod_name))
    mod.main([])",tests/test_lineage_dashboard.py,,1,9.931195248674785e-08,"The method 'test_main_no_streamlit' is a test function that uses the 'monkeypatch' fixture to modify the 'sys.modules' dictionary, effectively simulating the absence of the 'streamlit' and 'streamlit_autorefresh' modules. This is a common practice in testing to ensure that the code behaves correctly when certain modules are not available. The function then reloads the specified module and calls its 'main' function. This type of test is useful for ensuring robustness and handling of missing dependencies, which is a critical aspect of software testing. Therefore, the method is likely to be retained as it serves a valuable purpose in the testing suite."
survived,"def test_rejects_malformed_patch() -> None:
    diff = _read(""malformed_patch.diff"")
    assert not is_patch_valid(diff)",tests/test_patch_validation.py,,1,9.237449576640118e-09,"The method `test_rejects_malformed_patch` is a unit test designed to verify that the function `is_patch_valid` correctly identifies and rejects a malformed patch. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with input validation. This test helps maintain the integrity of the patch validation logic by ensuring that invalid patches are not mistakenly accepted. Therefore, this method is likely to be retained as part of the test suite to ensure ongoing code quality."
survived,"def test_drag_point_audit():
    client = get_client()
    resp = client.post(
        ""/drag-point-audit/execute"",
        json={""log"": ""...""},
    )
    assert resp.status_code == 200
    data = resp.json()
    assert set(data.keys()) == {""drag_points"", ""summary_score""}
",servers/server_clear_thought/tests/test_new_tools.py,,1,1.1861120010657661e-08,"The method 'test_drag_point_audit' is a unit test function that is designed to test the '/drag-point-audit/execute' endpoint. It uses a client to send a POST request and checks the response status and data structure. This is a typical pattern for testing API endpoints, which is a crucial part of maintaining software quality and ensuring that the API behaves as expected. Since testing is an essential part of software development, this method is likely to be retained to ensure the functionality of the API endpoint is verified."
survived,"    def test_ensure_offline_creates_placeholder_rows(self) -> None:
        """"""_ensure_offline should write one row when downloads fail.""""""
        with tempfile.TemporaryDirectory() as tmpdir:
            tmp = Path(tmpdir)
            with patch.object(data_feeds, ""DATA_DIR"", tmp), \
                 patch(""alpha_factory_v1.demos.macro_sentinel.data_feeds.urlopen"", side_effect=Exception):
                data_feeds._ensure_offline()
                for name in data_feeds.OFFLINE_URLS:
                    with open(tmp / name, newline="""") as f:
                        rows = list(csv.DictReader(f))
                    self.assertEqual(len(rows), 1)
",tests/test_macro_sentinel.py,TestMacroSentinel,1,5.60279640614594e-09,"The method is a unit test that verifies the behavior of the '_ensure_offline' function when downloads fail. It ensures that a placeholder row is created in the expected files. This is a useful test to ensure the robustness of the '_ensure_offline' function, especially in handling exceptions. Since it is a test method, it is unlikely to be deleted unless the functionality it tests is removed or significantly changed. Therefore, it is more likely to survive."
survived,"    def test_main_uses_env_loglevel(self, edge_parse, run_parse, apply_env, run):
        args = self._args()
        args.loglevel = None
        edge_parse.return_value = args
        run_parse.return_value = argparse.Namespace()
        os.environ.pop(""PGHOST"", None)

        edge_runner.main()

        run_parse.assert_called_once_with([
            ""--dev"",
            ""--port"",
            ""123"",
            ""--metrics-port"",
            ""456"",
            ""--a2a-port"",
            ""789"",
            ""--enabled"",
            ""A,B"",
            ""--cycle"",
            ""5"",
        ])
        apply_env.assert_called_once_with(run_parse.return_value)
",alpha_factory_v1/tests/test_edge_runner_main.py,EdgeRunnerMainInvokesRun,1,7.73442280641062e-08,"The method 'test_main_uses_env_loglevel' is a unit test function, which is typically used to verify the behavior of a specific piece of code. Unit tests are crucial for ensuring code reliability and are generally not deleted unless they are redundant or replaced by more comprehensive tests. The method appears to be testing the interaction between environment variables and command-line arguments, which is a common and important aspect to test in software that relies on configuration. Therefore, it is likely to be retained as part of the test suite."
survived,"    async def text(self):
        return """"",src/aiohttp/__init__.py,Response,0,0.9999999006880476,"The method 'text' is an asynchronous function that returns an empty string. Without additional context or usage, it seems to serve no practical purpose as it stands. Typically, methods that do not perform any meaningful operation or return a significant value are candidates for deletion unless they are placeholders for future development. Given the lack of functionality, it is likely to be deleted unless it is part of a larger framework where it is overridden or extended."
survived,"def test_record_and_fetch(tmp_path):
    db_path = tmp_path / ""tele.db""
    db = TelemetryDB(db_path, retention_days=1)
    db.record(10, 0.1, 0.5, 0)
    rows = db.fetch_all()
    assert len(rows) == 1
    assert rows[0][""tokens""] == 10
    assert db.verify()
    db.close()
",tests/unit/test_telemetry_db.py,,1,2.5109990926928157e-08,"The method 'test_record_and_fetch' is a unit test designed to verify the functionality of the 'TelemetryDB' class, specifically the 'record' and 'fetch_all' methods. It checks if a record can be successfully added and retrieved from the database, and also verifies the integrity of the database. Such tests are crucial for ensuring the reliability and correctness of the database operations. Therefore, it is unlikely to be deleted as it serves an important role in maintaining code quality."
survived,"def main(path: str) -> int:
    data = json.loads(Path(path).read_text())
    score = compute_score(data)
    print(score)
    return 0
",scripts/axe_score.py,,0,0.9999998362622821,"The method is likely to be deleted because it has a few issues that suggest it is not fully functional or useful in its current state. Firstly, the function uses 'json' and 'Path' without importing them, which would cause a NameError. Secondly, the function returns 0 regardless of the score computed, which might not be the intended behavior if the score is meant to influence the return value. Lastly, the function's purpose is unclear as it simply prints a score and returns 0, which might not be useful in a larger context. These issues suggest that the method might be removed or significantly refactored."
survived,"def binEval(op, l, r):
    lv = exprEval(l)
    rv = exprEval(r)
    if op == OP_ADD:
        return Rational(num=lv.num * rv.denom + lv.denom * rv.num, denom=lv.denom * rv.denom)
    if op == OP_SUB:
        return Rational(num=lv.num * rv.denom - lv.denom * rv.num, denom=lv.denom * rv.denom)
    if op == OP_MUL:
        return Rational(num=lv.num * rv.num, denom=lv.denom * rv.denom)
    return Rational(num=lv.num * rv.denom, denom=lv.denom * rv.num)
",tests/rosetta/transpiler/Python/24-game-solve.py,,1,6.348800075736417e-09,"The method 'binEval' is a utility function that evaluates binary operations on rational numbers. It handles addition, subtraction, multiplication, and division of rational numbers, which are common operations in many applications. The method is straightforward, performs its task efficiently, and there is no indication of redundancy or obsolescence in its logic. Therefore, it is likely to be retained in the codebase."
survived,"def print_prompt_summary(prompt_messages: List[ChatCompletionMessageParam]):
    print(format_prompt_summary(prompt_messages))
",backend/utils.py,,1,2.2159489282323004e-08,"The method `print_prompt_summary` is a simple utility function that prints the result of another function `format_prompt_summary`. It is likely to survive because it serves a clear purpose in the codebase by providing a straightforward way to output formatted summaries of prompt messages. Unless the functionality of `format_prompt_summary` is removed or significantly altered, this method will likely remain useful for debugging or logging purposes."
survived,"def extract_offline_html() -> str:
    """"""Return the Offline Build Steps section from README as HTML.""""""
    readme = ROOT / ""README.md""
    md = readme.read_text().splitlines()
    capture = False
    lines: list[str] = []
    for line in md:
        if line.strip() == ""### Offline Build Steps"":
            capture = True
            continue
        if capture and line.startswith(""### ""):
            break
        if capture:
            lines.append(line.rstrip())
    if not lines:
        return """"
    paras: list[str] = []
    items: list[str] = []
    for line in lines:
        if re.match(r""^\d+\.\s"", line.strip()):
            items.append(re.sub(r""^\d+\.\s*"", """", line.strip()))
        elif line.strip():
            paras.append(line.strip())
    html = [
        '<section id=""offline-build-steps"">',
        ""<h2>Offline Build Steps</h2>"",
    ]
    for p in paras:
        html.append(f""<p>{p}</p>"")
    if items:
        html.append(""<ol>"")
        for item in items:
            html.append(f""<li>{item}</li>"")
        html.append(""</ol>"")
    html.append(""</section>"")
    return ""\n"".join(html)
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/manual_build.py,,1,4.599055376537186e-10,"The method 'extract_offline_html' is a utility function that extracts a specific section from a README file and converts it into HTML format. This functionality is useful for generating documentation or web content from markdown files, which is a common requirement in many projects. The method is well-defined, has a clear purpose, and does not have any obvious issues or redundancies that would necessitate its removal. Therefore, it is likely to be retained in the codebase."
survived,"    def post_whisper_transcription(self, file_obj, model=""whisper-1"", language=None):
        """"""Whisper API request - Speech to Text""""""
        headers = {""Authorization"": self.headers.get(""Authorization"")}
        files = {""file"": (file_obj.filename, file_obj.stream, file_obj.mimetype)}
        data = {""model"": model}
        if language:
            data[""language""] = language

        response = requests.post(
            ""https://api.openai.com/v1/audio/transcriptions"",
            headers=headers,
            files=files,
            data=data,
        )
        return response
",src/openai_request.py,OpenAI_Request,1,1.2501528648238603e-09,"The method `post_whisper_transcription` is likely to survive because it provides a specific functionality for interacting with an external API, which is a common requirement in many applications. The method is well-defined, with clear parameters and a straightforward implementation that handles API requests for speech-to-text transcription using OpenAI's Whisper model. This functionality is valuable for applications that require speech processing capabilities, and there is no indication that this method is obsolete or redundant. Additionally, the method is flexible, allowing for optional language specification, which enhances its utility."
survived,"    def transcribe_audio(self, file_obj, language=None):
        """"""Convert speech audio to text using Whisper""""""
        res = self.requestor.post_whisper_transcription(file_obj, language=language)
        if res.status_code == 200:
            return res.json().get('text', '')
        else:
            print(res.text)
            return None
",web_api/dialogue_api.py,dialogue_api_handler,1,9.736200303530205e-10,"The method 'transcribe_audio' is likely to survive because it provides a useful functionality of converting speech audio to text using a service called Whisper. This is a common requirement in many applications that deal with audio data, such as transcription services, voice assistants, or any application that needs to process spoken input. The method is straightforward, making an HTTP POST request to a transcription service and handling the response appropriately. It also includes error handling by checking the status code and printing the response text if the request fails. These characteristics make it a valuable and functional part of a codebase."
survived,"    def backprop(self, node: Node) -> None:
        reward = node.reward
        while node is not None:
            node.visits += 1
            node.reward += reward
            node = node.parent
",alpha_factory_v1/demos/meta_agentic_tree_search_v0/mats/tree.py,Tree,1,1.3440409770490404e-08,"The method 'backprop' is a standard part of the Monte Carlo Tree Search (MCTS) algorithm, which is widely used in AI for decision-making processes, particularly in game playing. The method updates the nodes in the tree with the reward obtained from a simulation, propagating this information back up the tree to inform future decisions. Given its fundamental role in MCTS and the fact that it is correctly implemented, it is likely to be retained in the codebase."
survived,"            async def _run() -> list[int]:
                result = await agent.policy({""policy"": agents}, {})
                if have_adk:
                    _ = agent2agent  # pragma: no cover - placeholder use
                return list(result)
",alpha_factory_v1/demos/meta_agentic_tree_search_v0/mats/meta_rewrite.py,,1,2.2159489282323004e-08,"The method '_run' is an asynchronous function that seems to be part of a larger system involving agents and policies. It performs an asynchronous operation to get a result from 'agent.policy' and returns it as a list of integers. The presence of 'pragma: no cover' suggests that the code is intended to be used in a specific context or is a placeholder for future development. This indicates that the method is likely part of a functional system and is not redundant or obsolete. Therefore, it is more likely to be retained in the codebase."
survived,"def violates_exfil_policy(text: str) -> bool:
    """"""Return ``True`` if ``text`` matches exfiltration patterns.""""""
    for pat in _EXFIL_RE:
        if pat.search(text):
            return True
    return False",src/utils/opa_policy.py,,1,2.0611536181902033e-09,"The method 'violates_exfil_policy' is a utility function that checks if a given text matches certain exfiltration patterns. This is a common requirement in security-related code to prevent data leaks. The method is straightforward, efficient, and serves a clear purpose in identifying potential security threats. Such functions are typically retained in codebases to ensure ongoing security compliance and monitoring. Therefore, it is likely to be Survived."
survived,"    def unsubscribe(self, topic: str, handler: Callable[[EnvelopeLike], Awaitable[None] | None]) -> None:
        """"""Remove a previously subscribed handler.""""""
        handlers = self._subs.get(topic)
        if not handlers:
            return
        with contextlib.suppress(ValueError):
            handlers.remove(handler)
        if not handlers:
            self._subs.pop(topic, None)
",alpha_factory_v1/common/utils/messaging.py,A2ABus,1,2.0611536181902033e-09,"The method 'unsubscribe' is a standard utility function in event-driven or messaging systems to remove a handler from a list of subscribers for a given topic. It is well-implemented, handling cases where the topic or handler might not exist, and cleaning up empty lists. Such functionality is essential for managing subscriptions dynamically, ensuring that resources are not wasted on unnecessary handlers. Therefore, it is likely to be retained in the codebase."
survived,"    async def _handle_rpc(self, request: bytes, context: Any) -> bytes:
        text = request.decode()
        peer = context.peer() if grpc else """"
        if peer not in self._handshake_peers:
            parts = text.strip().split()
            if len(parts) != 2 or parts[0] != self.PROTO_VERSION:
                return await self._fail_handshake(peer, context)
            nonce = parts[1]
            if nonce in self._handshake_nonces:
                return await self._fail_handshake(peer, context)
            self._handshake_nonces[nonce] = None
            self._handshake_peers.add(peer)
            if grpc and hasattr(context, ""add_callback""):
                context.add_callback(lambda: self._handshake_peers.discard(peer))
            return self.PROTO_VERSION.encode()
        data = json.loads(text)
        token = data.pop(""token"", None)
        if self.settings.bus_token and token != self.settings.bus_token:
            if grpc:
                await context.abort(grpc.StatusCode.PERMISSION_DENIED, ""unauthenticated"")
            return b""denied""
        env = Envelope(
            sender=data.get(""sender"", """"),
            recipient=data.get(""recipient"", """"),
            ts=float(data.get(""ts"", 0.0)),
        )
        if isinstance(data.get(""payload""), dict):
            env.payload.update(data[""payload""])
        self.publish(env.recipient, env)
        if grpc and hasattr(context, ""add_callback""):
            context.add_callback(lambda: self._handshake_peers.discard(peer))
        return b""ok""
",alpha_factory_v1/common/utils/messaging.py,A2ABus,1,1.725782769012759e-08,"The method '_handle_rpc' is a crucial part of handling RPC requests, including authentication, handshake management, and message processing. It involves asynchronous operations, error handling, and context management, which are essential for maintaining secure and efficient communication in a networked application. Removing this method would likely break the functionality of the system that relies on these RPC interactions."
survived,"    def call_stub(prompt: str, s: Settings) -> str:
        return f""[offline] {prompt}""
",alpha_factory_v1/common/utils/local_llm.py,,1,2.3823698451773172e-07,"The method 'call_stub' is a simple utility function that takes a prompt and a settings object, and returns a formatted string. It is likely used as a placeholder or for testing purposes when the system is offline. Such utility functions are common in development environments to simulate or stub out functionality that may not be available in certain contexts. Since it serves a specific purpose and is not overly complex or redundant, it is likely to be retained in the codebase for future use or testing scenarios."
survived,"    def __init__(self, port: int) -> None:
        self._port = port
",alpha_factory_v1/backend/services/metrics_service.py,MetricsExporter,1,3.850741907939403e-09,"The method is a constructor for a class, which is a fundamental part of object-oriented programming in Python. Constructors are essential for initializing new objects with specific attributes, in this case, setting the '_port' attribute. There is no indication that this constructor is redundant or unnecessary, so it is likely to be retained."
survived,"    async def start(self) -> None:  # pragma: no cover - no async setup
        return None
",alpha_factory_v1/backend/services/kafka_service.py,KafkaService,1,1.2098660619383578e-06,"The method is an asynchronous function named 'start' that does not perform any operations other than returning None. The comment suggests that it is not covered by tests, possibly because it is a placeholder or a stub for future implementation. However, the presence of the method indicates that it might be part of a larger asynchronous setup process that is yet to be implemented. Given that it is marked with 'pragma: no cover', it suggests that the developers are aware of its current state and have intentionally left it as is, possibly for future development. Therefore, it is likely to survive as it might be a necessary part of the code structure that will be expanded upon later."
survived,"        def __init__(self, *_a, **_k):
            pass
",tests/test_kafka_service.py,DummyBus,0,0.9999724643101549,"The method is a constructor (__init__) that takes any number of positional and keyword arguments but does nothing with them (it only contains a 'pass' statement). This is typically a placeholder or a default implementation that might be intended for future expansion or to satisfy an interface requirement. However, as it stands, it doesn't perform any meaningful operation. If the class is meant to be instantiated with specific behavior, this method would likely be replaced or removed in favor of a more functional implementation. Therefore, it is likely to be deleted unless it serves a specific purpose in the current design, such as maintaining compatibility with a superclass or interface."
survived,"def update() -> bool:
    lines = WORKFLOW.read_text().splitlines()
    changed = False
    for i, line in enumerate(lines):
        m = PATTERN.match(line)
        if not m:
            continue
        prefix, action, current, comment = m.groups()
        if action.startswith(""./""):
            continue
        latest = fetch_latest(action)
        if not latest:
            continue
        tag, sha = latest
        new_comment = f"" # {sha}""
        if current == tag and comment == new_comment:
            continue
        lines[i] = f""{prefix}{action}@{tag}{new_comment}""
        changed = True
    if changed:
        WORKFLOW.write_text(""\n"".join(lines) + ""\n"")
    return changed
",tools/update_actions.py,,1,1.1628233028868813e-10,"The method 'update' is likely to survive because it performs a useful function of updating a workflow file with the latest version tags and corresponding SHA hashes. It reads the workflow file, checks for lines that match a specific pattern, fetches the latest version information, and updates the file if there are changes. This functionality is essential for maintaining up-to-date dependencies or actions in a workflow, which is a common requirement in software development and CI/CD pipelines. The method is well-structured, checks for necessary conditions, and only writes changes when necessary, which are good programming practices."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-h/compiler/py/q13.py,Auto2,1,3.850741907939403e-09,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be Survived as it serves a clear purpose and is implemented correctly."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-h/compiler/py/q1.py,Auto1,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a common and useful pattern for creating flexible and dynamic objects, especially in cases where the object acts like a dictionary or needs to provide dynamic attribute access. Since this method provides a clear and useful functionality, it is likely to be retained in the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-h/compiler/py/q22.py,Auto1,1,1.1861120010657661e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a common and useful pattern for dynamic attribute access, especially in cases where the object is used like a dictionary or needs to provide flexible access to its attributes. Therefore, this method is likely to be retained as it provides a clear and useful functionality."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-h/compiler/py/q20.py,Auto2,1,8.152020648014727e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to support dictionary-like access to their attributes. Since it provides a clear and functional purpose, it is likely to be retained in the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-h/compiler/py/q2.py,Auto2,1,3.653482080241728e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-h/compiler/py/q10.py,Auto1,1,8.76424914819242e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a flexible and Pythonic way to access object attributes, it is likely to be retained in the code."
survived,"def temp_dir(tmp_path):
    """"""Temporary directory fixture for module-level tests.""""""
    yield tmp_path
",tests/test_embedding_benchmark.py,,1,2.3355930333443423e-09,"The method 'temp_dir' is a fixture function typically used in testing frameworks like pytest. It provides a temporary directory for tests to use, which is a common and useful pattern in testing to ensure tests do not interfere with each other and have a clean environment. Such utility functions are generally retained as they are essential for writing clean and isolated tests. Therefore, it is likely to be Survived."
survived,"def _load_agents():
    """"""Return OpenAI Agents classes when available, otherwise stubs.""""""
    try:
        from openai_agents import Agent, AgentRuntime, Tool  # type: ignore

        if not os.getenv(""OPENAI_API_KEY""):
            raise RuntimeError(""OPENAI_API_KEY not set"")
        logger.debug(""Using real OpenAI Agents runtime"")
        return Agent, AgentRuntime, Tool, True
    except Exception as exc:  # pragma: no cover - optional dep
        logger.warning(""OpenAI Agents SDK unavailable: %s"", exc)

        class AgentRuntime:  # type: ignore
            def __init__(self, *a, **kw) -> None:  # noqa: D401 - simple stub
                pass

            def register(self, *_a, **_k) -> None:
                pass

            def run(self) -> None:
                logger.info(""OpenAI Agents bridge disabled."")

        def Tool(*_args, **_kw):  # type: ignore
            def _decorator(func):
                return func

            return _decorator

        return object, AgentRuntime, Tool, False
",alpha_factory_v1/demos/cross_industry_alpha_factory/openai_agents_bridge.py,,1,1.522997951276035e-08,"The method `_load_agents` is designed to dynamically load and return classes from the OpenAI Agents SDK if available, or provide stub implementations if not. This approach is useful for maintaining functionality even when the SDK is not installed, which is a common pattern in software development to handle optional dependencies. The method includes logging to inform the user about the availability of the SDK, which is a good practice for debugging and user awareness. Given its utility in providing flexibility and robustness to the codebase, it is likely to be retained."
survived,"    def test_ping_agent_skipped_when_env_set(self):
        code = ""import alpha_factory_v1.backend.agents as mod; print('ping' in mod.AGENT_REGISTRY)""
        env = os.environ.copy()
        env[""AF_DISABLE_PING_AGENT""] = ""true""
        result = subprocess.run([sys.executable, ""-c"", code], capture_output=True, text=True, env=env)
        self.assertEqual(result.stdout.strip(), ""False"")
",tests/test_agents_registry.py,TestPingAgentDisabled,1,5.60279640614594e-09,"The method `test_ping_agent_skipped_when_env_set` is a unit test that verifies the behavior of a system when a specific environment variable is set. It checks if the 'ping' agent is not registered in the `AGENT_REGISTRY` when the `AF_DISABLE_PING_AGENT` environment variable is set to 'true'. This is a valid and useful test to ensure that the system behaves correctly under different configurations. Therefore, it is unlikely to be deleted as it serves a purpose in maintaining the integrity of the system's functionality."
survived,"            async def step(self):
                raise RuntimeError(""boom"")
",tests/test_agents_registry.py,TestHealthQuarantine.FailingAgent,0,0.999999057755336,"The method is likely to be deleted because it raises a RuntimeError unconditionally, which means it cannot be executed successfully without causing an exception. This makes the method unusable in its current form, suggesting that it might be either a placeholder or a method that needs to be re-implemented or removed."
survived,"    def test_condition_false(self):
        from alpha_factory_v1.backend.agents import register, _agent_base
        Base = _agent_base()

        @register(condition=False)
        class SkipAgent(Base):
            NAME = ""skip""

            async def step(self):
                return None

        self.assertNotIn(""skip"", AGENT_REGISTRY)
",tests/test_agents_registry.py,TestRegisterDecorator,1,5.60279640614594e-09,"The method `test_condition_false` is testing a specific functionality where an agent is registered with a condition set to False. The test checks that the agent is not added to the `AGENT_REGISTRY`, which is a valid and useful test case to ensure that the registration condition is working as expected. This kind of test is important for maintaining the integrity of the registration system, ensuring that only agents meeting certain conditions are registered. Therefore, the method is likely to be retained as it serves a clear purpose in the testing suite."
survived,"    async def step(self) -> None:
        self.calls += 1
        raise RuntimeError(""boom"")
",tests/test_agent_base.py,DummyAgent,1,1.637377179507321e-07,"The method is simple and straightforward, incrementing a counter and then raising a RuntimeError. This suggests it is likely used for testing or demonstration purposes, particularly to simulate an error condition. Such methods are often kept in codebases for testing error handling or as part of a larger testing framework. Therefore, it is more likely to be retained rather than deleted."
survived,"    async def subscribe(self, topic):
        if False:
            yield
",tests/test_ping_agent.py,DummyOrch,0,0.9999999943972036,"The method 'subscribe' is defined as an asynchronous generator function, but it contains a condition that will never be true ('if False'), which means the 'yield' statement will never be executed. This makes the method effectively non-functional and redundant. Without any additional logic or purpose, it is likely to be deleted in future code clean-ups or refactoring efforts."
survived,"    def __init__(self):
        self.published = []
",tests/test_ping_agent.py,DummyOrch,1,6.348800075736417e-09,"The method is a constructor for a class, initializing an instance variable 'published' as an empty list. This is a common pattern in object-oriented programming to set up initial state for an object. Such methods are fundamental to class functionality and are unlikely to be deleted unless the class itself is being removed or significantly refactored. Therefore, it is more likely to survive."
survived,"def test_forecast_disruptions_trigger_and_gain(monkeypatch) -> None:
    monkeypatch.setattr(forecast, ""_innovation_gain"", lambda *_: 0.5)
    sec = sector.Sector(""x"", energy=1.0, entropy=2.0, growth=0.0)
    traj = forecast.forecast_disruptions([sec], 1, curve=""linear"", pop_size=2, generations=1)
    pt = traj[0].sectors[0]
    assert pt.disrupted
    assert pt.energy == pytest.approx(1.0 + 0.5)
",tests/test_forecast.py,,1,3.653482080241728e-08,"The method 'test_forecast_disruptions_trigger_and_gain' is a unit test function that uses the 'monkeypatch' fixture to modify the behavior of the '_innovation_gain' function within the 'forecast' module. It then creates a 'Sector' object and calls 'forecast_disruptions' to verify the expected behavior of the system under test. The test checks if the sector is disrupted and if the energy value is correctly updated. This is a typical pattern for testing specific functionality in a codebase, ensuring that changes or refactoring do not break existing functionality. Since testing is a crucial part of software development for maintaining code quality, this method is likely to be retained."
survived,"def test_show_results_export_csv(tmp_path) -> None:
    ledger = tmp_path / ""audit.db""
    ledger.touch()
    with patch.object(cli.config.CFG, ""ledger_path"", ledger):
        with patch.object(cli.logging, ""Ledger"") as led_cls:
            led = led_cls.return_value
            led.tail.return_value = [{""ts"": 1.0, ""sender"": ""a"", ""recipient"": ""b"", ""payload"": {""x"": 1}}]
            res = CliRunner().invoke(cli.main, [""show-results"", ""--export"", ""csv""])
            assert ""ts,sender,recipient,payload"" in res.output
",tests/test_cli.py,,1,2.0611536181902033e-09,"The method 'test_show_results_export_csv' is a unit test that verifies the functionality of exporting results to a CSV format. It uses mocking to simulate the behavior of external dependencies, ensuring that the test is isolated and does not rely on actual file or database operations. This is a common practice in testing to ensure reliability and repeatability of tests. The test checks if the CSV export functionality correctly formats the output, which is a critical feature for users who need to export data. Therefore, this method is likely to be maintained as it ensures the correctness of an important feature."
survived,"        def publish(self, topic: str, env: messaging.Envelope) -> None:
            events.append((""pub"", env.sender))
",tests/test_agent_runner.py,Bus,1,1.493094675974231e-10,"The method 'publish' is a simple function that appends a tuple containing the string 'pub' and the sender of the envelope to a list called 'events'. This method is likely part of a larger system that tracks or logs events related to messaging. The method is straightforward, performs a specific task, and does not contain any obvious issues or redundancies. Therefore, it is likely to be useful in its context and will survive."
survived,"  def is_in_subtree_of(self, other: Resource) -> bool:
    """"""Return ``True`` if ``self`` is in the subtree rooted at ``other``.""""""

    current: Optional[Resource] = self
    while current is not None:
      if current is other:
        return True
      current = current.parent
    return False
",pylabrobot/resources/resource.py,Resource,1,2.0611536181902033e-09,"The method `is_in_subtree_of` is a utility function that checks if the current resource is within the subtree of another resource. This is a common operation in tree or hierarchical data structures, where determining the relationship between nodes is necessary for various operations such as access control, organization, or navigation. The method is simple, efficient, and provides a clear and useful functionality. Therefore, it is likely to be retained in the codebase."
survived,"        def research(self, name: str, purpose: str):
            calls.append((name, purpose))
            return [""info""]
",tests/agents/test_tool_designer_agent.py,DummyResearch,1,1.0677030767166749e-06,"The method 'research' is a simple function that appends a tuple of 'name' and 'purpose' to a list called 'calls' and returns a list containing the string 'info'. Without additional context, it is difficult to determine its utility. However, the method seems to serve a basic logging or tracking purpose, which could be useful in certain applications. Unless there is a specific reason to remove it, such as redundancy or a change in requirements, it is likely to survive as it performs a straightforward and potentially useful task."
survived,"  def update_strings(self, strings, sendcan: bool = False):
    try:
      if strings and not isinstance(strings[0], list | tuple):
        strings = [strings]

      for addr in self.addresses:
        for k in self.vl_all[addr]:
          self.vl_all[addr][k].clear()

      updated_addrs: set[int] = set()
      for entry in strings:
        t = entry[0]
        frames = entry[1]
        bus_empty = True
        for address, dat, src in frames:
          if src != self.bus:
            continue
          bus_empty = False
          state = self.message_states.get(address)
          if state is None or len(dat) > 64:
            continue
          if state.parse(t, dat):
            updated_addrs.add(address)
            msgname = state.name
            for i, sig in enumerate(state.signals):
              val = state.vals[i]
              self.vl[address][sig.name] = val
              self.vl[msgname][sig.name] = val
              self.vl_all[address][sig.name] = state.all_vals[i]
              self.vl_all[msgname][sig.name] = state.all_vals[i]
              self.ts_nanos[address][sig.name] = state.timestamps[-1]
              self.ts_nanos[msgname][sig.name] = state.timestamps[-1]

        if not bus_empty:
          self.last_nonempty_nanos = t
        bus_timeout_threshold = 500 * 1_000_000
        for st in self.message_states.values():
          if st.timeout_threshold > 0:
            bus_timeout_threshold = min(bus_timeout_threshold, st.timeout_threshold)
        self.bus_timeout = (t - self.last_nonempty_nanos) > bus_timeout_threshold
        self.update_valid(t)

      return updated_addrs
    except (TypeError, IndexError):
      raise RuntimeError(""invalid parameter"") from None
",opendbc/can/parser.py,CANParser,1,1.2501528648238603e-09,"The method 'update_strings' is well-structured and performs a specific task of updating message states based on input strings. It includes error handling for invalid parameters and seems to be part of a larger system that deals with message parsing and state management. The method is likely to be useful in its context, and there is no indication that it is obsolete or redundant. Therefore, it is likely to survive."
survived,"async def test_conditional():
    async def first(prompt, **kwargs):
        return 5

    async def second(prompt, **kwargs):
        return ""ran""

    wf = Workflow(
        name=""wf"",
        steps=[
            WorkflowStep(runner=first),
            WorkflowStep(runner=second, mode=StepMode.CONDITIONAL, condition=lambda r: r == 5),
        ],
    )

    result = await wf.run(""start"")
    assert result == ""ran""
",tests/test_workflow.py,,1,7.194132978569833e-09,"The method 'test_conditional' demonstrates a useful pattern for conditional execution within an asynchronous workflow. It uses a conditional step that only executes if a certain condition is met, which is a common requirement in many applications. The code is well-structured and leverages asynchronous programming effectively, making it likely to be retained for its utility in handling complex workflows."
survived,"    async def r1(prompt, **kwargs):
        outputs.append(""r1"")
        return prompt + ""-r1""
",tests/test_workflow.py,,1,1.0467401685178159e-08,"The method 'r1' is a simple asynchronous function that appends a string to a list and returns a modified version of the input prompt. It doesn't contain any deprecated or harmful code, and its functionality is straightforward and potentially useful for asynchronous operations. Therefore, there is no apparent reason for it to be deleted."
survived,"def ensure_config(directory: Path) -> tuple[Path, bool]:
    """"""Ensure ``config.env`` exists in ``directory``.

    Returns the path and whether it was created.
    """"""
    config = directory / ""config.env""
    if config.exists():
        return config, False
    sample = directory / ""config.env.sample""
    shutil.copyfile(sample, config)
    return config, True
",alpha_factory_v1/demos/alpha_agi_business_v1/scripts/setup_config.py,,1,1.1861120010657661e-08,"The method 'ensure_config' is a utility function that checks for the existence of a 'config.env' file in a given directory and creates it from a sample if it doesn't exist. This is a common pattern in software development to ensure configuration files are present, especially in environments where applications need specific configurations to run. The method is straightforward, useful, and does not have any apparent issues or redundancies that would warrant its removal. It provides a clear and necessary functionality for managing configuration files, which is a critical aspect of many applications."
survived,"def test_dslice_with_selector():
    B, S, V = Axis(""batch"", 2), Axis(""seq"", 5), Axis(""vocab"", 10)
    x = hax.arange((B, S, V))
    idx = (hax.arange((B, S), dtype=jnp.int32) + 2) % 4
    shard = V.resize(4)
    x_shard = x[""vocab"", dslice(0, shard)]
    out = x_shard[""vocab"", idx]
    assert out.axes == (B, S)
    ref = x.array[:, :, :4][jnp.arange(B.size)[:, None], jnp.arange(S.size)[None, :], idx.array]
    assert jnp.array_equal(out.array, ref)
",tests/test_scatter_gather.py,,1,3.2241866333029355e-08,"The method 'test_dslice_with_selector' is a unit test function that verifies the behavior of a specific slicing operation on a multi-dimensional array. Unit tests are crucial for ensuring code correctness and preventing regressions. This function checks that the slicing and indexing operations produce the expected output, which is a common requirement in software development to maintain code quality. Therefore, it is unlikely to be deleted as it serves an important role in testing the functionality of the code."
survived,"def test_multiselector_broadcast():
    B, S, V = Axis(""batch"", 2), Axis(""seq"", 3), Axis(""vocab"", 6)
    a = hax.arange((B, S, V))
    idx1 = hax.arange((B, S), dtype=jnp.int32) % V.size
    out = a[""vocab"", idx1]
    assert out.axes == (B, S)
    assert jnp.array_equal(out.array, _ref_gather(a, V, idx1))
",tests/test_scatter_gather.py,,1,9.931195248674785e-08,"The method 'test_multiselector_broadcast' is a test function, likely part of a test suite for a larger codebase. Test functions are generally not deleted unless they are redundant, incorrect, or replaced by more comprehensive tests. This function appears to be testing a specific functionality related to broadcasting and indexing, which is a common and important operation in numerical computing libraries. As long as the functionality it tests is relevant and the test is correctly implemented, it is likely to be retained to ensure the correctness of the codebase."
survived,"    def append_token(self, token_id: int) -> None:
        self.token_ids.append(token_id)",src/levanter/inference/sequence.py,Sequence,1,6.69158608681505e-10,"The method 'append_token' is a simple utility function that appends a token ID to a list called 'token_ids'. This is a common operation in many applications, especially those dealing with sequences or collections of items. The method is straightforward, performs a necessary operation, and is likely part of a larger class or module that manages tokens or similar entities. There is no indication that this method is redundant or unnecessary, so it is likely to be retained."
survived,"    def init_state(self):
        import jax.numpy as jnp
        from dataclasses import dataclass

        @dataclass
        class State:
            token_ids: jnp.ndarray  # (max_seqs, max_len)
            lengths: jnp.ndarray  # (max_seqs,)
            active: jnp.ndarray  # (max_seqs,)
            head: jnp.ndarray  # ()
            tail: jnp.ndarray  # ()

        return State(
            token_ids=jnp.full((self.max_seqs, self.max_len), self.eos, dtype=jnp.int32),
            lengths=jnp.zeros((self.max_seqs,), dtype=jnp.int32),
            active=jnp.zeros((self.max_seqs,), dtype=jnp.bool_),
            head=jnp.array(0, dtype=jnp.int32),
            tail=jnp.array(0, dtype=jnp.int32),
        )
",src/levanter/inference/scheduler.py,JittedScheduler,1,8.592166611791576e-10,"The method `init_state` is well-structured and serves a clear purpose of initializing a state with specific attributes using JAX's numpy for efficient computation. It uses a dataclass to define the state structure, which is a modern and clean approach to managing data. The method is likely to be useful in contexts where state management is required, such as in machine learning models or simulations. There is no indication of redundancy or obsolescence in the code, suggesting it will survive."
survived,"    def is_finished(self) -> bool:
        return not self.waiting and all(s.is_finished for s in self.running)
",src/levanter/inference/scheduler.py,Scheduler,1,4.0586521248284276e-10,"The method `is_finished` is a simple utility function that checks if a certain condition is met: it returns `True` if the object is not in a 'waiting' state and all elements in the 'running' list have their `is_finished` attribute set to `True`. This kind of method is common in task management or process monitoring systems to determine if a set of tasks or processes have completed. It is likely to be useful in contexts where such checks are necessary, and there is no indication that it is redundant or unnecessary. Therefore, it is likely to be retained."
survived,"    def add(self, seq: Sequence) -> None:
        self.waiting.append(seq)
",src/levanter/inference/scheduler.py,Scheduler,1,4.599055376537186e-10,"The method 'add' is a simple utility function that appends a sequence to a list called 'waiting'. This is a common operation in many programs where items need to be queued or stored temporarily. The method is straightforward, performs a necessary function, and does not have any apparent issues or redundancies that would warrant its deletion. Therefore, it is likely to be retained in the codebase."
survived,"    def neighbors(self):
        """"""
        returns a list of neighbors
        returns a list position objects with their
        directiontomoveto set to the direction that the
        empty square moved.

        tiles is 4x4 tuple of tuples with
        0,0 as top left.

        tiles[y][x]

        """"""

        # find 0 - blank square

        x0 = None
        y0 = None

        for i in range(4):
            for j in range(4):
                if self.tiles[i][j] == 0:
                    y0 = i
                    x0 = j

        if x0 == None or y0 == None:
            return []

        neighbor_list = []

        # move 0 to the right
        if x0 < 3:
            new_tiles = self.copy_tiles()
            temp = new_tiles[y0][x0+1]
            new_tiles[y0][x0+1] = 0
            new_tiles[y0][x0] = temp
            new_pos = new_position(new_tiles)
            neighbor_list.append(new_pos)
        # move 0 to the left
        if x0 > 0:
            new_tiles = self.copy_tiles()
            temp = new_tiles[y0][x0-1]
            new_tiles[y0][x0-1] = 0
            new_tiles[y0][x0] = temp
            new_pos = new_position(new_tiles)
            neighbor_list.append(new_pos)
        # move 0 up
        if y0 > 0:
            new_tiles = self.copy_tiles()
            temp = new_tiles[y0-1][x0]
            new_tiles[y0-1][x0] = 0
            new_tiles[y0][x0] = temp
            new_pos = new_position(new_tiles)
            neighbor_list.append(new_pos)
        # move 0 down
        if y0 < 3:
            new_tiles = self.copy_tiles()
            temp = new_tiles[y0+1][x0]
            new_tiles[y0+1][x0] = 0
            new_tiles[y0][x0] = temp
            new_pos = new_position(new_tiles)
            neighbor_list.append(new_pos)

        return neighbor_list
",tests/rosetta/x/Python/15-puzzle-solver/15-puzzle-solver-2.py,Position,1,1.955568070542584e-08,"The method 'neighbors' is a crucial part of solving sliding puzzle problems, such as the 15-puzzle, where the goal is to arrange tiles in a specific order by sliding them into an empty space. This method calculates all possible states that can be reached from the current state by moving the empty space (represented by 0) in any valid direction. It is essential for algorithms that explore possible moves, such as A* or BFS, to find a solution to the puzzle. Therefore, this method is likely to be retained as it provides necessary functionality for solving such puzzles."
survived,"def reconstruct_path(current):
    """"""
    Uses the cameFrom members to follow the chain of moves backwards
    and then reverses the list to get the path in the correct order.
    """"""
    total_path = [current]

    while current.cameFrom != None:
        current = current.cameFrom
        total_path.append(current)

    total_path.reverse()

    return total_path
",tests/rosetta/x/Python/15-puzzle-solver/15-puzzle-solver-2.py,,1,4.363462233903899e-09,"The method 'reconstruct_path' is a utility function commonly used in pathfinding algorithms, such as A* or Dijkstra's algorithm, to reconstruct the path from the start node to the goal node after the search has been completed. It follows the 'cameFrom' pointers from the goal node back to the start node, collecting the nodes along the way, and then reverses the list to present the path in the correct order. This is a standard and essential part of many pathfinding implementations, making it unlikely to be deleted unless the entire pathfinding approach is changed or removed."
survived,"    def neighbours(p):
        gap = p.index(0)
        l = list(p)

        for m in movelist[gap]:
            l[gap] = l[gap + m]
            l[gap + m] = 0
            yield (1, tuple(l), (l[gap], m))
            l[gap + m] = l[gap]
            l[gap] = 0
",tests/rosetta/x/Python/15-puzzle-solver/15-puzzle-solver-1.py,,0,0.999999694097641,"The method 'neighbours' is likely to be deleted because it contains a critical flaw in its logic. The method attempts to generate neighboring states of a puzzle by swapping elements, but it incorrectly resets the list 'l' to its original state after each yield. This results in incorrect behavior as the list 'l' does not reflect the intended state changes. Additionally, the method lacks proper documentation and error handling, making it difficult to understand and maintain. These issues suggest that the method is not functioning as intended and may be removed or significantly refactored."
survived,"def _get_query(name, file):
    query = _files(f""{__package__}.queries"") / file
    globals()[name] = query.read_text()
    return globals()[name]
",third_party/tree-sitter-racket/bindings/python/tree_sitter_racket/__init__.py,,1,4.363462233903899e-09,"The method '_get_query' is likely to be Survived (1) because it performs a specific and useful function: it reads a query from a file and assigns it to a global variable. This kind of utility function is common in applications that need to dynamically load and execute queries from external files. The method is concise, uses standard library functions, and follows a clear pattern for managing query files, which suggests it is well-designed for its purpose."
survived,"    def run(self):
        if isdir(""queries""):
            dest = join(self.build_lib, ""tree_sitter_racket"", ""queries"")
            self.copy_tree(""queries"", dest)
        super().run()
",third_party/tree-sitter-racket/setup.py,Build,1,8.592166611791576e-10,"The method 'run' is a part of a build or setup process, likely for a Python package. It checks if a directory named 'queries' exists and, if so, copies it to a destination directory. This is a common operation in build scripts to ensure necessary files are included in the build output. The method then calls the superclass's 'run' method, indicating it's extending or modifying a standard process. Such methods are typically essential for the correct functioning of the build process and are unlikely to be deleted unless the entire build process is being refactored or removed. Therefore, the method is likely to survive."
survived,"def __getattr__(name):
    # NOTE: uncomment these to include any queries that this grammar contains:

    # if name == ""HIGHLIGHTS_QUERY"":
    #     return _get_query(""HIGHLIGHTS_QUERY"", ""highlights.scm"")
    # if name == ""INJECTIONS_QUERY"":
    #     return _get_query(""INJECTIONS_QUERY"", ""injections.scm"")
    # if name == ""LOCALS_QUERY"":
    #     return _get_query(""LOCALS_QUERY"", ""locals.scm"")
    # if name == ""TAGS_QUERY"":
    #     return _get_query(""TAGS_QUERY"", ""tags.scm"")

    raise AttributeError(f""module {__name__!r} has no attribute {name!r}"")
",third_party/tree-sitter-racket/bindings/python/tree_sitter_racket/__init__.py,,0,0.9999994284997149,"The method is likely to be deleted because it currently does not serve any functional purpose. All the conditional checks for specific attribute names are commented out, meaning the method will always raise an AttributeError for any attribute accessed. This makes the method redundant unless the commented code is intended to be uncommented in the future. Without any active code to handle specific attributes, the method does not contribute to the functionality of the module."
survived,"    def _ReadSingleJsonObject(self, sock:Any) -> Optional[str]:
        # Since sock.recv blocks, we must read each char one by one so we know when the message ends.
        # This is messy, but since it only happens very occasionally, it's fine.
        message = bytearray()
        while True:
            # Sanity check so we don't spin for ever.
            if len(message) > 10000:
                self.Logger.error(""_ReadSingleJsonObject failed to read message, it was too long. ""+message.decode(encoding=""utf-8""))
                return None

            # Read one, add it to the buffer, and see if we are done.
            data = sock.recv(1)
            if not data:
                return None
            if data[0] == 3: # This is EXT aka End of text. It separates the json messages.
                return message.decode(encoding=""utf-8"")
            message += data",moonraker_octoeverywhere/moonrakercredentialmanager.py,MoonrakerCredentialManager,0,0.9999997897565932,"The method _ReadSingleJsonObject is likely to be deleted because it uses an inefficient approach to read data from a socket. Reading one byte at a time is not optimal and can lead to performance issues, especially if the method is used more frequently than anticipated. Additionally, the method relies on a specific byte (3) to determine the end of a message, which may not be a robust or flexible solution for parsing JSON objects. Modern practices would suggest using buffered reading or a more sophisticated protocol to handle message boundaries, making this method a candidate for refactoring or removal."
survived,"def test_visualize_shardings_model_axis(capsys):
    devices = jax.devices()
    mesh = jax.sharding.Mesh(np.array(devices).reshape(-1, 2), (ResourceAxis.DATA, ResourceAxis.MODEL))
    with axis_mapping({""dim1"": ResourceAxis.DATA, ""dim2"": ResourceAxis.MODEL}), mesh:
        arr = hax.ones((Dim1, Dim2))
        visualize_shardings(arr)

    out = capsys.readouterr().out
    assert ""dim2"" in out",tests/test_visualize_sharding.py,,1,2.646573631904765e-09,"The method 'test_visualize_shardings_model_axis' is a test function that checks the output of a visualization function for sharding in a distributed computing context. It uses the 'capsys' fixture to capture printed output and asserts that a specific string is present in the output. This is a typical pattern for testing in Python, especially in environments using JAX for distributed computing. Since testing functions are crucial for ensuring code correctness and reliability, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered. Therefore, the method is likely to survive."
survived,"def _pspec_parts(spec_part) -> str:
    if spec_part is None:
        return ""unsharded""
    elif isinstance(spec_part, (tuple, list)):
        return ""+"".join(str(p) for p in spec_part)
    else:
        return str(spec_part)
",src/haliax/debug.py,,1,9.736200303530205e-10,"The method '_pspec_parts' is a utility function that converts a specification part into a string representation. It handles different types of inputs, including None, tuples, lists, and other types, making it versatile for various use cases. Such utility functions are often useful in larger codebases for consistent data formatting and are unlikely to be removed unless they are replaced by a more efficient or comprehensive solution. Since the function is simple, clear, and serves a specific purpose, it is likely to survive."
survived,"async def list_agents() -> list[str]:
    resp = requests.get(""http://localhost:7860/agents"", timeout=5)
    resp.raise_for_status()
    return resp.json()
",alpha_factory_v1/demos/alpha_asi_world_model/openai_agents_bridge.py,,0,0.999999922655772,"The method 'list_agents' is likely to be deleted because it uses 'requests.get' in an asynchronous function without using an asynchronous HTTP client like 'aiohttp'. This can lead to blocking behavior, which is contrary to the purpose of using async functions. To properly handle asynchronous HTTP requests, the code should be refactored to use an async-compatible library."
survived,"        def wrapper(func):
            return func
",alpha_factory_v1/demos/muzero_planning/agent_muzero_entrypoint.py,,1,3.927863699585036e-07,"The method 'wrapper' is a simple decorator that returns the function it receives without any modification. This is a common pattern used in Python when a decorator is being set up but not yet implemented. It serves as a placeholder or a pass-through decorator. Such methods are often retained in codebases as they provide a clear structure for future enhancements or modifications. Therefore, it is likely to survive as it can be useful for future development."
survived,"def main() -> None:
    """"""Entry-point for Meta-Agentic AGI v3 demo.""""""
    pkg_dir = Path(__file__).resolve().parents[1]
    sys.path.insert(0, str(pkg_dir))
    from meta_agentic_agi_demo_v3 import main as demo_main
    demo_main()
",alpha_factory_v1/demos/meta_agentic_agi_v3/src/main.py,,1,3.2241866333029355e-08,"The method 'main' is a clear entry-point function for a demo application, specifically for 'Meta-Agentic AGI v3'. It is structured to set up the environment by modifying the system path and then importing and executing the main function from the 'meta_agentic_agi_demo_v3' module. This kind of setup is typical for initializing and running a demo or application, suggesting that it is a necessary part of the codebase for demonstration purposes. Therefore, it is unlikely to be deleted as it serves a crucial role in executing the demo."
survived,"    async def step(self) -> None:
        await self.publish(
            ""alpha.discovery"", {""alpha"": ""cross-market synergy identified""}
        )
",alpha_factory_v1/demos/alpha_agi_business_v1/alpha_agi_business_v1.py,AlphaDiscoveryAgent,1,5.60279640614594e-09,"The method 'step' is an asynchronous function that publishes a message to a topic 'alpha.discovery'. This kind of method is typically used in event-driven architectures or systems that rely on message passing for communication between components. Given the increasing popularity of such architectures, especially in microservices and distributed systems, this method is likely to be useful and relevant. Therefore, it is more likely to be retained in the codebase."
survived,"    def test_business_bridge_compiles(self):
        """"""Ensure the business demo bridge compiles.""""""
        path = Path('alpha_factory_v1/demos/alpha_agi_business_v1/openai_agents_bridge.py')
        py_compile.compile(path, doraise=True)
",tests/test_openai_bridge.py,TestOpenAIBridge,1,6.348800075736417e-09,"The method 'test_business_bridge_compiles' is a unit test that checks if a specific Python script compiles without syntax errors. This is a basic and essential test to ensure that the code is syntactically correct before running more complex tests or deploying the code. Such tests are generally useful in a development environment to catch errors early in the development process. Therefore, it is likely to be retained as part of the test suite."
survived,"    def test_plugins_load_and_function(self):
        demo._load_plugins.cache_clear()
        plugins = demo._load_plugins()
        self.assertTrue(len(plugins) >= 1)
        plugin = plugins[0]
        heur = getattr(plugin, ""heuristic_policy"", None)
        self.assertTrue(callable(heur))
        result = heur([0.1, 0.5, 0.0])
        self.assertIn(""action"", result)
",tests/test_omni_factory_plugins.py,TestPluginLoader,1,1.6052280526088547e-09,"The method 'test_plugins_load_and_function' is a unit test that verifies the functionality of the '_load_plugins' method and the 'heuristic_policy' of the loaded plugins. It checks that plugins are loaded, that they have a callable 'heuristic_policy', and that this policy returns a result containing 'action'. This is a crucial part of ensuring the integrity and functionality of the plugin system, which is likely an important component of the application. Therefore, this test method is essential for maintaining code quality and is unlikely to be deleted."
survived,"async def reset() -> str:
    EVOLVER.reset()
    return ""evolver reset""
",alpha_factory_v1/demos/aiga_meta_evolution/openai_agents_bridge.py,,1,5.905303995456778e-10,"The method 'reset' is a simple asynchronous function that calls a reset method on an object named 'EVOLVER' and returns a string. This function is straightforward and likely serves a specific purpose in the context of the application, such as resetting a state or configuration. Without additional context indicating that this functionality is no longer needed or has been replaced, it is reasonable to assume that this method will survive as it provides a clear and potentially necessary action within the application."
survived,"    def __init__(self, name: str, age: int, status: str):
        self.name = name
        self.age = age
        self.status = status
",tests/machine/x/python/update_stmt.py,Person,1,5.3157849718487075e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming in Python. It initializes the instance variables of the class, which are essential for creating objects with specific attributes. This method is necessary for the proper functioning of the class and is unlikely to be removed unless the class itself is being refactored or removed."
survived,"def sum3(a, b, c):
    return a + b + c
",tests/machine/x/python/fun_three_args.py,,1,2.0611536181902033e-09,"The method 'sum3' is a simple utility function that takes three arguments and returns their sum. Such utility functions are commonly used in programming for basic arithmetic operations. It is straightforward, has a clear purpose, and is likely to be useful in various contexts where summing three numbers is needed. Therefore, it is likely to be retained in the codebase."
survived,"    def __repr__(self):
        return f""Person(name={self.name!r}, age={self.age}, status={self.status!r})""
",tests/machine/x/python/update_stmt.py,Person,1,1.1253518384332553e-07,"The __repr__ method is a standard method in Python used to provide a string representation of an object. It is particularly useful for debugging and logging, as it provides a clear and unambiguous representation of the object. The method in question is well-implemented, providing a detailed representation of the 'Person' object, including its name, age, and status attributes. This is a common practice in Python programming to aid in understanding and debugging code. Therefore, it is unlikely that this method will be deleted."
survived,"def classify(n: int) -> str:
    if n == 0:
        return ""zero""
    elif n == 1:
        return ""one""
    else:
        return ""many""
",tests/machine/x/python/match_full.py,,1,1.6052280526088547e-09,"The method 'classify' is a simple utility function that categorizes an integer into three categories: 'zero', 'one', or 'many'. This kind of function is often useful in various programming scenarios where specific actions are needed based on the value of an integer. The function is straightforward, easy to understand, and does not have any apparent issues or inefficiencies. Therefore, it is likely to be retained in the codebase as it serves a clear purpose."
survived,"    def generate_word_dists(self, n_topics, vocab_size, document_length):

        width = vocab_size // n_topics
        word_dists = np.zeros((n_topics, vocab_size))

        for k in range(n_topics):
            temp = np.zeros((n_topics, width))
            temp[k, :] = int(document_length / width)
            word_dists[k, :] = temp.flatten()

        word_dists /= word_dists.sum(axis=1)[:, np.newaxis]
        # turn counts into probabilities
        if self.make_plot:
            self._plot_nicely(word_dists, ""Topic Words"", ""N"", ""K"")
        return word_dists
",examples/synthetic_data.py,HldaDataGenerator,0,0.9999938558278723,"The method 'generate_word_dists' is likely to be deleted because it contains several issues that make it inefficient and potentially incorrect. Firstly, the method uses integer division to calculate the width, which may lead to incorrect distribution of words if the vocab_size is not perfectly divisible by n_topics. Secondly, the method creates a temporary array 'temp' with dimensions (n_topics, width) but only fills one row, which is inefficient and unnecessary. Additionally, the method does not handle cases where document_length is not evenly divisible by width, potentially leading to incorrect word distributions. Lastly, the method relies on an external plotting function '_plot_nicely', which may not be available or necessary in all contexts. These issues suggest that the method is not robust or efficient, leading to a higher likelihood of it being deleted or significantly refactored."
survived,"def test_sync_acm(mock_get_certs, neo4j_session):
    boto3_session = MagicMock()
    create_test_account(neo4j_session, TEST_ACCOUNT_ID, TEST_UPDATE_TAG)

    # Pre-create listener node to attach relationship
    neo4j_session.run(""MERGE (:ELBV2Listener {id: $id})"", id=LISTENER_ARN)

    sync(
        neo4j_session,
        boto3_session,
        [TEST_REGION],
        TEST_ACCOUNT_ID,
        TEST_UPDATE_TAG,
        {""UPDATE_TAG"": TEST_UPDATE_TAG, ""AWS_ID"": TEST_ACCOUNT_ID},
    )

    assert check_nodes(neo4j_session, ""ACMCertificate"", [""arn"", ""domainname""]) == {
        (""arn:aws:acm:us-east-1:000000000000:certificate/test-cert"", ""example.com"")
    }

    assert check_rels(
        neo4j_session,
        ""AWSAccount"",
        ""id"",
        ""ACMCertificate"",
        ""arn"",
        ""RESOURCE"",
        rel_direction_right=True,
    ) == {(TEST_ACCOUNT_ID, ""arn:aws:acm:us-east-1:000000000000:certificate/test-cert"")}

    assert check_rels(
        neo4j_session,
        ""ACMCertificate"",
        ""arn"",
        ""ELBV2Listener"",
        ""id"",
        ""USED_BY"",
        rel_direction_right=True,
    ) == {(""arn:aws:acm:us-east-1:000000000000:certificate/test-cert"", LISTENER_ARN)}",tests/integration/cartography/intel/aws/test_acm.py,,1,8.152020648014727e-09,"The method `test_sync_acm` is a unit test function that verifies the functionality of the `sync` function in a specific context. It uses mock objects and assertions to ensure that the `sync` function correctly creates nodes and relationships in a Neo4j database. Unit tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, this method is likely to be retained as it serves an important role in the testing suite."
survived,"    async def invoke(self, prompt: str, context=None) -> str:
        self.prompts.append(prompt)
        return f""{prompt}:ok""
",tests/test_guardrail_router.py,MockAdapter,1,2.2159489282323004e-08,"The method 'invoke' is a simple function that appends a prompt to a list and returns a formatted string. It is straightforward and functional, with no apparent issues or redundancies. It is likely to be useful in contexts where prompts need to be logged or tracked, and a response needs to be generated. Therefore, there is no reason to delete it unless the functionality it provides is no longer needed or is replaced by a more comprehensive solution."
survived,"    def _check_scalar_square_grad(self, name: str):
        """"""Verify ‚àÇ(x¬≤)/‚àÇx = 2x for a scalar input.""""""
        try:
            backend.set_backend(name)
        except ImportError:
            raise unittest.SkipTest(f""{name} backend not available"")
        b = backend.current()

        def f(x):
            return b.mul(x, x)

        g = b.grad(f)
        x = b.array(3.0, requires_grad=True)
        grad = to_numpy(g(x))
        np.testing.assert_allclose(np.array(grad), np.array(6.0))
",tests/test_autograd.py,TestAutograd,1,2.2159489282323004e-08,"The method '_check_scalar_square_grad' is a unit test function that verifies the gradient calculation of a simple mathematical operation (x^2) using a specified backend. It is a useful test to ensure that the backend's gradient computation is correct. Such test functions are typically retained in codebases to ensure the reliability and correctness of mathematical operations, especially in libraries dealing with automatic differentiation or machine learning. Therefore, it is likely to be retained."
survived,"def main() -> None:
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument(""version"", help=""Pyodide version string, e.g. 0.28.0"")
    args = parser.parse_args()
    update_pyodide(args.version)
",scripts/update_pyodide.py,,1,2.998960815863541e-09,"The method 'main' is a typical entry point for a Python script that uses the argparse library to handle command-line arguments. It is a simple and effective way to parse arguments and call a function with those arguments. The method is well-structured and serves a clear purpose in the script, which is to update Pyodide to a specified version. There is no indication that this method is obsolete or redundant, and it is likely to be useful for users who need to update Pyodide via command line. Therefore, it is likely to be retained in the codebase."
survived,"def fetch(url: str) -> bytes:
    resp = requests.get(url, timeout=60)
    resp.raise_for_status()
    return resp.content
",scripts/update_pyodide.py,,1,1.6052280526088547e-09,"The method 'fetch' is a simple utility function that performs a common task: fetching the content of a URL. It uses the 'requests' library to make an HTTP GET request, checks for any HTTP errors, and returns the content of the response. This is a basic and useful function that is likely to be used in various applications where fetching data from the web is required. The method is straightforward, efficient, and does not contain any obvious flaws or redundancies that would necessitate its deletion. Therefore, it is likely to survive."
survived,"def sha384_b64(data: bytes) -> str:
    digest = hashlib.sha384(data).digest()
    return base64.b64encode(digest).decode()
",scripts/update_pyodide.py,,1,1.522997951276035e-08,"The method `sha384_b64` is a utility function that computes the SHA-384 hash of the input data and then encodes the result in base64. This is a common operation in cryptographic applications where data integrity and encoding are important. The function is concise, performs a specific task, and uses standard libraries (`hashlib` and `base64`) to achieve its goal. There is no indication that this method is redundant or unnecessary, as it provides a useful transformation of data that is likely to be used in various contexts. Therefore, it is likely to be retained."
survived,"    async def __call__(self, _t):
        return ""ok""
",tests/test_rate_lock.py,DummyOA,1,3.2241866333029355e-08,"The method is a simple asynchronous function that returns a string 'ok'. It is straightforward and does not contain any complex logic or dependencies that might lead to its removal. Such methods are often used as placeholders or simple handlers in asynchronous programming. Without additional context indicating that this method is redundant or replaced, it is likely to survive."
survived,"def test_concurrent_requests(monkeypatch) -> None:
    monkeypatch.setenv(""RATE_LIMIT_PER_MIN"", ""1000"")
    mod._REQUEST_LOG.clear()
    asyncio.run(_run_concurrent())
    assert len(mod._REQUEST_LOG.get(""127.0.0.1"", [])) == 5",tests/test_rate_lock.py,,1,2.3355930333443423e-09,"The method 'test_concurrent_requests' is a test function that uses the 'monkeypatch' fixture to set an environment variable and then runs an asynchronous function to test concurrent requests. It checks if the number of requests logged matches the expected value. This is a typical pattern in testing asynchronous code and rate limiting, which are common in modern applications. Therefore, it is likely to be useful for ensuring the correctness of the code under test, and thus, it will survive."
survived,"        def __enter__(self) -> ""_Sock"":
            return self
",tests/test_check_env_network.py,_Sock,1,1.1861120010657661e-08,"The method is part of a context manager implementation, which is a common and useful pattern in Python for managing resources. The __enter__ method is essential for the context manager protocol, allowing the object to be used with the 'with' statement. This method is unlikely to be deleted as it serves a specific purpose in resource management."
survived,"    def log(self, _env: messaging.Envelope) -> None:  # pragma: no cover - test helper
        pass
",tests/test_agent_runner.py,_Ledger,1,1.637377179507321e-07,"The method 'log' is marked with a pragma directive 'no cover', indicating that it is a test helper and not intended to be covered by unit tests. This suggests that the method is used for testing purposes, possibly as a placeholder or a mock implementation. Such methods are often retained in the codebase to facilitate testing and debugging, even if they are not directly used in the production code. Therefore, it is likely that this method will survive as it serves a specific purpose in the testing framework."
survived,"        def __init__(self, *args: object, **kwargs: object) -> None:
            pass
",tests/test_aiga_agents_import.py,DummyOpenAI,0,0.9999999827421723,"The method is a constructor that does not perform any initialization or operations. It only contains a 'pass' statement, which means it doesn't contribute any functionality to the class. Such methods are often placeholders and are likely to be removed or replaced with meaningful code in future iterations. Therefore, it is likely to be deleted."
survived,"    def main() -> None:
        """"""Œ±‚ÄëFactory command line interface.""""""
",alpha_factory_v1/core/interface/cli.py,,1,1.522997951276035e-08,"The method 'main' is a standard entry point for Python scripts, especially when dealing with command line interfaces. The presence of a docstring suggests that it is intended to be used as a CLI for a specific application or tool, which is a common and useful functionality. There is no indication that this method is redundant or obsolete, so it is likely to be retained for its intended purpose."
survived,"    def test_tools_run_inside_event_loop(self) -> None:
        async def runner() -> None:
            self.assertIsInstance(self.agent.forecast_demand(), str)
            self.assertIsInstance(self.agent.optimise_dispatch(), str)
            self.assertIsInstance(self.agent.hedge_strategy(), str)

        asyncio.run(runner())
",tests/test_energy_agent.py,TestEnergyAgentSyncRun,1,2.5109990926928157e-08,"The method 'test_tools_run_inside_event_loop' is a test function that uses asyncio to run an asynchronous 'runner' function. The 'runner' function checks if certain methods of 'self.agent' return a string. This is a valid test case for asynchronous code, and it is structured correctly to ensure that the methods are being tested within an event loop. There is no indication that this method is obsolete or incorrect, so it is likely to be retained."
survived,"def _parse_file(path: Path) -> Iterable[ArchiveEntry]:
    """"""Yield archive entries from ``path``.""""""
    for line in path.read_text(encoding=""utf-8"").splitlines():
        if not line.strip():
            continue
        try:
            rec = json.loads(line)
        except Exception:  # noqa: BLE001 - skip invalid lines
            continue
        yield ArchiveEntry(
            hash=rec[""hash""],
            parent=rec.get(""parent""),
            score=float(rec.get(""score"", 0.0)),
            novelty=float(rec.get(""novelty"", 0.0)),
            is_live=bool(rec.get(""is_live"", True)),
            ts=float(rec.get(""ts"", 0.0)),
        )
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/tools/dgm_import.py,,1,6.348800075736417e-09,"The method `_parse_file` is likely to survive because it is a well-structured and useful utility function for parsing files and yielding structured data. It handles exceptions gracefully, ensuring that invalid lines do not cause the entire process to fail. This robustness is a desirable trait in file parsing functions. Additionally, the method uses Python's standard library effectively, such as `json.loads` for parsing JSON and `Path.read_text` for reading file content, which are both efficient and widely used practices. The function's purpose is clear, and it provides a straightforward way to convert file data into `ArchiveEntry` objects, which is likely a core requirement in the context it is used."
survived,"def test_backtrack_boost_improves_diversity():
    base = _run(0.0)
    boosted = _run(1.0)
    assert _diversity(boosted) > _diversity(base)",tests/test_backtrack_boost.py,,1,3.850741907939403e-09,"The method `test_backtrack_boost_improves_diversity` is a unit test function that checks if a certain boosting mechanism improves diversity. It uses assertions to compare the diversity of two runs, one with boosting and one without. This is a typical pattern in test-driven development to ensure that a feature (in this case, boosting) has the desired effect (improving diversity). Since it is a test function, it is likely to be retained as part of the test suite to ensure the correctness of the codebase. Therefore, the method will survive."
survived,"async def task_solve_phase(
    operator: Callable[[Any], Any],
    evaluate: Callable[[Any], Awaitable[tuple[float, float]]],
    archive: InMemoryArchive,
    *,
    max_cost: float | None = None,
    wallclock: float | None = None,
    backtrack_rate: float = 0.0,
    phase_hook: Optional[Callable[[Phase], None]] = None,
) -> None:
    await _phase_loop(
        operator,
        evaluate,
        archive,
        phase=Phase.TASK_SOLVE,
        max_cost=max_cost,
        wallclock=wallclock,
        backtrack_rate=backtrack_rate,
        phase_hook=phase_hook,
    )
",src/evolve.py,,1,6.023574641292144e-08,"The method `task_solve_phase` is an asynchronous function that appears to be part of a larger system for solving tasks or problems in phases. It takes several parameters, including an operator, an evaluation function, an archive, and optional parameters for cost, time, backtrack rate, and a phase hook. The function then calls another function `_phase_loop` with these parameters, indicating that it is part of a structured process or workflow.

The presence of parameters like `max_cost`, `wallclock`, and `backtrack_rate` suggests that this function is designed to handle complex operations with constraints, which is a common requirement in optimization or iterative problem-solving systems. The use of asynchronous programming (`async def`) indicates that the function is designed to handle potentially long-running operations without blocking the main thread, which is important for performance in concurrent systems.

Given these characteristics, the function seems to be well-integrated into a system that requires such capabilities, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained in the codebase."
survived,"def test_innovation_ablation() -> None:
    results = run_ablation()
    for patch, scores in results.items():
        base = scores[""baseline""]
        for name, val in scores.items():
            if name == ""baseline"":
                continue
            assert base - val >= 0.03",tests/test_ablation.py,,1,2.1024340680345882e-07,"The method `test_innovation_ablation` is a test function that seems to be part of a testing suite, likely for a machine learning or data analysis project. It runs an ablation test, which is a common technique to understand the impact of different components of a model by systematically removing them and observing the change in performance. The function checks that the performance drop (if any) when a component is removed is at least 0.03 compared to the baseline. This is a valid and useful test to ensure that each component contributes significantly to the model's performance.

Given its purpose and the fact that it is a test function, it is unlikely to be deleted unless the entire testing framework or the specific feature it tests is removed. Test functions are crucial for maintaining code quality and ensuring that changes do not negatively impact the system. Therefore, it is more likely to be maintained or updated rather than deleted."
survived,"        def _tool(*_a, **_k):
            def _decorator(func):
                return func

            return _decorator
",tests/test_openai_bridge_runtime.py,TestAIGABridgeRuntime,1,8.152020648014727e-09,"The method _tool is a decorator factory that returns a decorator function (_decorator) which, in turn, returns the original function without any modifications. This pattern is often used to create decorators that can be extended or modified later. Since it is a utility function that provides a basic structure for decorators, it is likely to be retained for future use or extension. Therefore, it is more likely to survive."
survived,"def server() -> Iterator[str]:
    port = _free_port()
    config = uvicorn.Config(evolution_worker.app, host=""127.0.0.1"", port=port, log_level=""warning"")
    server = uvicorn.Server(config)
    thread = threading.Thread(target=server.run, daemon=True)
    thread.start()
    for _ in range(50):
        if server.started:
            break
        time.sleep(0.1)
    yield f""http://127.0.0.1:{port}""
    server.should_exit = True
    thread.join(timeout=5)
",tests/test_evolution_worker.py,,1,8.152020648014727e-09,"The method 'server' is likely to survive because it is a functional piece of code that sets up a server using uvicorn, a popular ASGI server implementation for Python. It handles server startup in a separate thread, checks if the server has started, and provides a URL for the server. Additionally, it ensures proper shutdown of the server. These are common and necessary operations in web server management, indicating that the method serves a useful purpose and is implemented correctly."
survived,"def test_mutate_returns_child(server: str) -> None:
    import io
    import tarfile

    buf = io.BytesIO()
    with tarfile.open(fileobj=buf, mode=""w"") as tf:
        info = tarfile.TarInfo(name=""README.txt"")
        data = b""demo""
        info.size = len(data)
        tf.addfile(info, io.BytesIO(data))
    buf.seek(0)

    with httpx.Client(base_url=server) as client:
        files = {""tar"": (""dummy.tar"", buf.read())}
        r = client.post(""/mutate"", files=files)
        assert r.status_code == 200
        data = r.json()
        assert ""child"" in data
        assert isinstance(data[""child""], list)",tests/test_evolution_worker.py,,1,1.955568070542584e-08,"The method 'test_mutate_returns_child' is a unit test function that verifies the behavior of a server endpoint '/mutate'. It uses the 'httpx' library to send a POST request with a tar file and checks the response for a status code of 200 and the presence of a 'child' key in the JSON response. This is a typical test case for ensuring that a server endpoint behaves as expected. Such test functions are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is likely to be retained in the codebase."
survived,"def construct_prompt(parent_diff: str, exemplars: Sequence[str], template: Mapping[str, Any]) -> str:
    """"""Return a prompt populated with ``parent_diff`` and ``exemplars``.

    ``template`` must provide a ``user`` string and may include ``system`` and
    ``tokens``. The ``{diff}`` and ``{exemplars}`` placeholders are replaced with
    the given parameters. A random entry from ``tokens`` (when present) fills the
    ``{token}`` placeholder.
    """"""
    tokens = list(template.get(""tokens"", []))
    token = random.choice(tokens) if tokens else """"
    user = str(template.get(""user"", """")).format(
        diff=parent_diff,
        exemplars=""\n"".join(exemplars),
        token=token,
    )
    system = template.get(""system"")
    if system:
        return f""{system}\n{user}""
    return user",src/agents/prompt_sampler.py,,1,1.0467401685178159e-08,"The method 'construct_prompt' is well-defined and serves a clear purpose of constructing a prompt string using a template and provided parameters. It handles optional components like 'system' and 'tokens' gracefully, ensuring flexibility in its usage. The method is likely to be useful in contexts where dynamic prompt generation is needed, such as in AI or chatbot applications. There are no apparent issues or redundancies in the code that would warrant its deletion."
survived,"    def _mp_eval(self):
        with ProcessPoolExecutor() as pool:
            results = list(pool.map(self._simulate, self.population))
        return self._post_eval(results)
",alpha_factory_v1/demos/aiga_meta_evolution/meta_evolver.py,MetaEvolver,1,1.0261879630648829e-10,"The method `_mp_eval` is likely to survive because it is a well-structured method that utilizes parallel processing to evaluate a population of simulations. It uses `ProcessPoolExecutor` to efficiently manage multiple processes, which is a common and effective approach for handling CPU-bound tasks. The method also includes a clear return statement that processes the results through `_post_eval`, indicating a complete and purposeful implementation. There are no obvious issues or deprecated practices in the code that would suggest it should be deleted."
survived,"    def history_plot(self):
        import pandas as pd
        return pd.DataFrame(self.history, columns=[""generation"", ""avg_fitness""])
",alpha_factory_v1/demos/aiga_meta_evolution/meta_evolver.py,MetaEvolver,1,5.60279640614594e-09,"The method 'history_plot' is a simple utility function that imports pandas and returns a DataFrame constructed from the 'history' attribute. It is likely to be useful for visualizing or analyzing historical data related to generations and average fitness. Since it serves a clear purpose and is straightforward, it is likely to be retained in the codebase."
survived,"def banner(msg: str, color: str = 'GREEN') -> None:
    color_code = COLORS.get(color.upper(), '')
    reset = COLORS['RESET']
    print(f""{color_code}{msg}{reset}"")
",alpha_factory_v1/scripts/preflight.py,,1,9.237449576640118e-09,"The method 'banner' is a simple utility function that prints a message in a specified color. It uses a dictionary 'COLORS' to map color names to their respective codes, and defaults to 'GREEN' if no color is specified. This kind of utility function is quite common and useful for adding colored output to console applications, which can enhance readability and user experience. Since it is a straightforward and functional piece of code, it is likely to be retained in the codebase."
survived,"def main() -> None:
    banner(""Alpha-Factory Preflight Check"", 'YELLOW')
    ok = True
    ok &= check_python()
    ok &= check_cmd('docker')
    ensure_dir(Path('/var/alphafactory'))

    for key in ('OPENAI_API_KEY', 'ANTHROPIC_API_KEY'):
        if os.getenv(key):
            banner(f""{key} set"", 'GREEN')
        else:
            banner(f""{key} not set"", 'YELLOW')

    if not ok:
        banner('Preflight checks failed. Please install required dependencies.', 'RED')
        sys.exit(1)

    banner('Environment looks good. You can now run install_alpha_factory_pro.sh', 'GREEN')
",alpha_factory_v1/scripts/preflight.py,,1,1.3440409770490404e-08,"The method 'main' is a typical entry point for a script that performs preflight checks before running a larger application or installation process. It checks for necessary conditions such as Python version, the presence of Docker, and environment variables. These checks are crucial for ensuring the environment is correctly set up before proceeding with further operations. The method is well-structured and serves a clear purpose, making it unlikely to be deleted unless the entire script is refactored or the preflight checks are no longer needed."
survived,"def check_cmd(cmd: str) -> bool:
    if shutil.which(cmd):
        banner(f""{cmd} found"", 'GREEN')
        return True
    banner(f""{cmd} missing"", 'RED')
    return False
",alpha_factory_v1/scripts/preflight.py,,1,3.850741907939403e-09,"The method 'check_cmd' is a utility function that checks if a command is available in the system's PATH using 'shutil.which'. This is a common and useful operation in many scripts and applications that need to verify the presence of certain command-line tools before proceeding. The function also provides user feedback by displaying a message with a color-coded banner, which enhances its usability. Given its utility and straightforward implementation, it is likely to be retained in the codebase."
survived,"def check_docker_daemon() -> bool:
    if not shutil.which('docker'):
        return False
    try:
        subprocess.run(['docker', 'info'], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        banner('docker daemon reachable', 'GREEN')
        return True
    except Exception:  # noqa: BLE001
        banner('docker daemon not running', 'RED')
        return False
",alpha_factory_v1/scripts/preflight.py,,1,1.6052280526088547e-09,"The method `check_docker_daemon` is a utility function that checks if the Docker daemon is running and reachable. It uses `shutil.which` to check if Docker is installed and `subprocess.run` to verify if the Docker daemon is running. This is a common requirement in environments where Docker is used for container management. The method is straightforward, performs a necessary check, and provides feedback through a banner function. There is no indication that this functionality is obsolete or unnecessary, so it is likely to be retained."
survived,"def test_rate_limiter_throttles(monkeypatch: pytest.MonkeyPatch) -> None:
    monkeypatch.setenv(""API_RATE_LIMIT"", ""1"")
    from src.interface import api_server as api

    api = importlib.reload(api)

    limiter = api.SimpleRateLimiter(api.app, limit=1, window=0.1)

    resp1 = asyncio.run(limiter.dispatch(_make_request(""3.3.3.3""), _call_next))
    assert resp1.status_code == 200
    resp2 = asyncio.run(limiter.dispatch(_make_request(""3.3.3.3""), _call_next))
    assert resp2.status_code == 429
    time.sleep(0.11)
    resp3 = asyncio.run(limiter.dispatch(_make_request(""3.3.3.3""), _call_next))
    assert resp3.status_code == 200",tests/test_rate_limiter_eviction.py,,1,5.60279640614594e-09,"The method is a test function for a rate limiter, which is a crucial component in many applications to prevent abuse and ensure fair usage of resources. The test checks if the rate limiter correctly throttles requests, which is essential for maintaining the integrity and performance of the system. Such tests are typically retained to ensure that any changes to the rate limiter do not break its functionality. Therefore, it is likely to survive."
survived,"        def json(self) -> dict[str, object]:
            return {""choices"": [{""message"": {""content"": ""ok""}}]}
",tests/test_aiga_openai_bridge_offline.py,DummyResponse,1,1.955568070542584e-08,"The method is a simple implementation that returns a JSON-like dictionary structure. It is straightforward and does not contain any apparent issues or deprecated practices. The use of type hinting with 'dict[str, object]' is consistent with modern Python standards. Therefore, there is no reason to delete this method as it serves its purpose effectively."
survived,"def _download(url: str, dest: Path) -> None:
    dest.parent.mkdir(parents=True, exist_ok=True)
    with requests.get(url, stream=True, timeout=60) as resp:
        resp.raise_for_status()
        total = int(resp.headers.get(""Content-Length"", 0))
        with open(dest, ""wb"") as fh, tqdm(total=total, unit=""B"", unit_scale=True, desc=dest.name) as bar:
            for chunk in resp.iter_content(chunk_size=8192):
                if chunk:
                    fh.write(chunk)
                    bar.update(len(chunk))
",scripts/download_hf_gpt2.py,,1,1.1861120010657661e-08,"The method '_download' is a utility function that downloads a file from a given URL to a specified destination path. It handles creating necessary directories, streaming the download to avoid memory issues, and provides a progress bar for user feedback. These are common and useful functionalities in many applications, especially those dealing with data processing or file management. The use of 'requests' for HTTP requests and 'tqdm' for progress tracking are standard practices. Given its utility and adherence to best practices, it is likely to be retained in the codebase."
survived,"def test_webp(h, f):
    """"""Verify if the image is a WebP.""""""
    if h.startswith(b'RIFF') and h[8:12] == b'WEBP':
        return 'webp'
",metaflow/_vendor/imghdr/__init__.py,,1,1.725782769012759e-08,"The method `test_webp` is a simple utility function that checks if a given image is in the WebP format by examining the header bytes. This type of function is useful for applications that need to handle different image formats, especially in web development where WebP is a popular format due to its efficient compression. The function is straightforward, performs a specific task, and is likely to be used in contexts where image format validation is necessary. Therefore, it is likely to be retained in the codebase."
survived,"def test_tiff(h, f):
    """"""Verify if the image is a TIFF (can be in Motorola or Intel byte order).""""""
    if h[:2] in (b'MM', b'II'):
        return 'tiff'
",metaflow/_vendor/imghdr/__init__.py,,1,1.522997951276035e-08,"The method 'test_tiff' is a simple utility function that checks if a given image header indicates a TIFF format by examining the first two bytes. This is a straightforward and useful function for image processing tasks, especially when dealing with various image formats. It is likely to be retained because it serves a specific purpose, is concise, and does not have any apparent issues or redundancies."
survived,"def test_spanish_labels() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri()

    with sync_playwright() as p:
        browser = p.chromium.launch()
        context = browser.new_context(locale=""es-ES"")
        page = context.new_page()
        page.goto(url)
        page.wait_for_selector(""#controls"")
        label_text = page.locator(""#controls label"").first.inner_text()
        assert ""Semilla"" in label_text
        browser.close()
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_spanish_locale.py,,1,1.9171715133907573e-10,"The method `test_spanish_labels` is a test function that uses Playwright to automate a browser and check if a specific label on a webpage contains the word 'Semilla'. This is a valid and useful test for ensuring that the Spanish localization of a webpage is correctly implemented. Test functions like this are generally not deleted unless they are redundant, incorrect, or replaced by a more efficient testing method. Since this function appears to be correctly implemented and serves a clear purpose, it is likely to be retained."
survived,"def lidarr_import(csv_path: str, cfg: configparser.ConfigParser) -> None:
    baseurl = cfg[""lidarr""][""baseurl""]
    api_key = cfg[""lidarr""][""api_key""]
    root = cfg[""lidarr""][""rootfolderpath""]

    headers = {""Content-type"": ""application/json"", ""X-Api-Key"": api_key}
    session = requests.Session()

    def lookup_artist(name: str) -> str | None:
        url = f""https://api.lidarr.audio/api/v0.4/search?type=artist&query=\""{urllib.parse.quote_plus(name)}\""""
        resp = session.get(url, headers=headers)
        if resp.status_code == 200 and resp.text not in ("""", ""[]""):
            data = resp.json()
            if isinstance(data, list):
                return data[0].get(""id"")
            return data.get(""id"")
        return None

    with open(csv_path, encoding=""utf-8"") as f:
        reader = csv.DictReader(f)
        for row in reader:
            artist = row.get(""artist"")
            mbid = row.get(""foreignArtistId"")
            if not mbid:
                mbid = lookup_artist(artist)
            if not mbid:
                messagebox.showwarning(""Lidarr"", f""{artist} not found"")
                continue
            payload = {
                ""artistName"": artist,
                ""foreignArtistId"": mbid,
                ""QualityProfileId"": 1,
                ""MetadataProfileId"": 1,
                ""Path"": os.path.join(root, artist),
                ""RootFolderPath"": root,
                ""monitored"": True,
                ""addOptions"": {""searchForMissingAlbums"": False},
            }
            add_url = f""{baseurl}/api/v1/artist""
            session.post(add_url, headers=headers, json=payload)
",arr_gui.py,,1,3.2241866333029355e-08,"The method 'lidarr_import' is a utility function that reads a CSV file, looks up artist information using an API, and then posts this information to another API endpoint. It is a specific function that serves a particular purpose in a system that interacts with the Lidarr API. The function is well-structured, uses standard libraries, and handles potential errors (e.g., missing artist IDs) gracefully. There is no indication that this function is obsolete or redundant, and it appears to be a useful part of a larger application. Therefore, it is likely to be retained."
survived,"def set_trace_provider(provider: TraceProvider) -> None:
    """"""Set the global trace provider used by tracing utilities.""""""
    global GLOBAL_TRACE_PROVIDER
    GLOBAL_TRACE_PROVIDER = provider",src/agents/tracing/setup.py,,1,8.592166611791576e-10,"The method 'set_trace_provider' is a simple setter function that assigns a global variable. Such functions are typically retained as they provide a straightforward way to configure or modify global state, which can be useful in various scenarios, especially in larger applications where tracing or logging configurations need to be set globally. The method is also well-documented, indicating its purpose clearly, which is a good practice in code maintenance. Therefore, it is likely to be Survived."
survived,"def test_run_evolution_three_objectives() -> None:
    def fn(genome: list[float]) -> tuple[float, float, float]:
        x, y = genome
        return x**2, y**2, (x + y) ** 2

    pop = mats.run_evolution(fn, 2, population_size=4, generations=2, seed=42)

    assert all(len(ind.fitness or ()) == 3 for ind in pop)",tests/test_mats.py,,1,2.699578619062706e-07,"The method `test_run_evolution_three_objectives` is a test function that verifies the functionality of a multi-objective evolutionary algorithm. It defines a fitness function `fn` that takes a genome (a list of two floats) and returns a tuple of three objectives. The test then runs the evolutionary algorithm with this fitness function and checks that each individual in the resulting population has a fitness tuple of length 3.

This test is crucial for ensuring that the evolutionary algorithm correctly handles multiple objectives, which is a common requirement in optimization problems. The test is simple, clear, and directly related to the functionality of the algorithm, making it a valuable part of the test suite.

Given its importance in verifying the correct implementation of a core feature (multi-objective optimization), it is unlikely that this method will be deleted. Instead, it is more likely to be maintained or expanded upon as the codebase evolves."
survived,"def test_load_model_warning(monkeypatch, caplog):
    caplog.set_level(logging.WARNING)
    monkeypatch.setattr(local_llm, ""_MODEL"", None)
    monkeypatch.setattr(local_llm, ""_CALL"", None)
    monkeypatch.setattr(local_llm, ""Llama"", mock.Mock(side_effect=RuntimeError(""boom"")))
    monkeypatch.setattr(local_llm, ""AutoModelForCausalLM"", None)

    local_llm._load_model()

    assert any(""boom"" in r.message for r in caplog.records)",tests/test_local_llm_logging.py,,1,1.0467401685178159e-08,"The method 'test_load_model_warning' is a unit test designed to verify that a warning is logged when a RuntimeError occurs during the model loading process. This is a common practice in software development to ensure that error handling and logging mechanisms are functioning correctly. The presence of logging and error handling in code is crucial for debugging and maintaining software, especially in complex systems involving machine learning models. Therefore, this method is likely to be retained as it serves an important role in testing the robustness of the system."
survived,"        def __init__(self, text: str = ""local"") -> None:
            self._data = {""choices"": [{""message"": {""content"": text}}]}
",tests/test_selfheal_entrypoint_offline.py,DummyResp,1,8.152020648014727e-09,"The method is a constructor for a class, initializing an instance variable `_data` with a dictionary containing a default message. Constructors are essential for setting up initial state in object-oriented programming, and this one provides a default value for `text`, making it flexible for different use cases. There is no indication that this method is redundant or poorly designed, so it is likely to be retained."
survived,"        def raise_for_status(self) -> None:
            pass
",tests/test_selfheal_entrypoint_offline.py,DummyResp,0,0.9999810748526188,"The method `raise_for_status` is defined but not implemented (it only contains a `pass` statement). This suggests that it is a placeholder or a stub for future implementation. If this method is part of a larger class or module where it is expected to perform a specific action (like raising an exception based on a status code), it is likely to be implemented in the future. However, if there is no plan to implement it or if it is not used anywhere in the code, it might be deleted. Without additional context, it's difficult to determine its exact fate, but generally, unimplemented methods are either completed or removed. Given the lack of implementation, it is more likely to be deleted unless there is a clear plan to implement it."
survived,"def test_call_local_model_http(monkeypatch: pytest.MonkeyPatch) -> None:
    called = {}

    class DummyResp:
        def json(self) -> dict:
            return {""choices"": [{""message"": {""content"": ""ok""}}]}

        def raise_for_status(self) -> None:
            pass

    def fake_post(url: str, json=None, timeout=None):
        called[""url""] = url
        called[""json""] = json
        return DummyResp()

    monkeypatch.setattr(""af_requests.post"", fake_post)

    orig_import = builtins.__import__

    def fake_import(name, globals=None, locals=None, fromlist=(), level=0):
        if name == ""openai_agents"":
            raise ModuleNotFoundError(name)
        return orig_import(name, globals, locals, fromlist, level)

    monkeypatch.setattr(builtins, ""__import__"", fake_import)
    monkeypatch.setenv(""OLLAMA_BASE_URL"", ""http://example.com/v1"")

    from alpha_factory_v1.demos.self_healing_repo.agent_core import llm_client

    result = llm_client.call_local_model([{""role"": ""user"", ""content"": ""hi""}])
    assert result == ""ok""
    assert called[""url""] == ""http://example.com/v1/chat/completions""",tests/test_llm_client_offline.py,,1,4.6911638017642294e-08,"The method is a unit test that uses monkeypatching to simulate HTTP requests and environment variables. It is well-structured, tests a specific functionality, and does not have any apparent issues or deprecated practices. It is likely to be useful for ensuring the reliability of the `call_local_model` function, especially in a testing environment where actual HTTP requests should be avoided. Therefore, it is likely to be retained."
survived,"    async def handle(self, _env: orchestrator.messaging.Envelope) -> None:  # pragma: no cover - helper
        pass
",tests/test_orchestrator.py,DummyAgent,1,1.3709566550544279e-06,"The method 'handle' is defined as an asynchronous function but contains only a 'pass' statement, indicating that it currently does not perform any operations. However, it is marked with a pragma comment 'no cover - helper', suggesting that it is intended to be a placeholder or a helper function that might be implemented in the future. Since it is part of a class and likely serves a purpose in the overall design, it is more likely to be retained for future use rather than deleted."
survived,"def test_insight_missing_ids() -> None:
    _setup_simulations()
    client = _make_client()
    headers = {""Authorization"": ""Bearer test-token""}
    resp = client.post(""/insight"", json={""ids"": [""missing""]}, headers=headers)
    assert resp.status_code == 404",tests/test_insight_endpoint.py,,1,2.7894680920908113e-10,"The method 'test_insight_missing_ids' is a unit test designed to verify that the system correctly returns a 404 status code when an insight request is made with missing IDs. This is a valid and necessary test case to ensure the robustness of the system against invalid input. Unit tests are crucial for maintaining code quality and are unlikely to be deleted unless they are redundant or replaced by a more comprehensive testing framework. Therefore, this method is likely to survive."
survived,"    def test_run_demo_short(self) -> None:
        result = subprocess.run(
            [
                sys.executable,
                ""-m"",
                ""alpha_factory_v1.demos.alpha_agi_insight_v0.insight_demo"",
                ""--episodes"",
                ""2"",
            ],
            capture_output=True,
            text=True,
        )
        self.assertEqual(result.returncode, 0, result.stderr)
        self.assertIn(""Best sector"", result.stdout)
",tests/test_alpha_agi_insight_demo.py,TestAlphaAgiInsightDemo,1,3.3982678079468468e-09,"The method 'test_run_demo_short' is a unit test that uses the 'subprocess.run' function to execute a demo script and checks its output. This is a common practice in testing to ensure that scripts or modules behave as expected when run. The method checks for a successful execution (return code 0) and verifies that a specific string ('Best sector') is present in the output. These are typical assertions in a test to validate functionality. Since this method is part of a test suite, it is likely to be maintained and updated as needed to ensure the software's reliability. Therefore, it is more likely to survive."
survived,"def test_load_sectors_objects(tmp_path: Path) -> None:
    path = tmp_path / ""s.json""
    data = [{""name"": ""x"", ""energy"": 2.0, ""entropy"": 0.5, ""growth"": 0.2}]
    path.write_text(json.dumps(data))
    secs = sector.load_sectors(path)
    assert len(secs) == 1
    s = secs[0]
    assert s.name == ""x""
    assert s.energy == 2.0
    assert s.entropy == 0.5
    assert s.growth == 0.2",tests/test_sector_loader.py,,1,9.736200303530205e-10,"The method `test_load_sectors_objects` is a unit test function that verifies the functionality of the `load_sectors` method from the `sector` module. It creates a temporary JSON file with test data, loads it using the `load_sectors` method, and asserts that the loaded data matches the expected values. This is a typical and necessary practice in software development to ensure code reliability and correctness. Since testing is a crucial part of maintaining code quality, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered. Therefore, the method is likely to survive."
survived,"  def __init__(self, model: Union[CytomatType, str], port: str):
    super().__init__()

    supported_models = [
      CytomatType.C6000,
      CytomatType.C6002,
      CytomatType.C2C_425,
      CytomatType.C2C_450_SHAKE,
      CytomatType.C5C,
    ]
    if isinstance(model, str):
      try:
        model = CytomatType(model)
      except ValueError:
        raise ValueError(f""Unsupported Cytomat model: '{model}'"")
    if model not in supported_models:
      raise NotImplementedError(
        f""Only the following Cytomats are supported: {supported_models}, but got '{model}'""
      )
    self.model = model
    self._racks: List[PlateCarrier] = []

    self.io = Serial(
      port=port,
      baudrate=self.default_baud,
      bytesize=serial.EIGHTBITS,
      parity=serial.PARITY_NONE,
      stopbits=serial.STOPBITS_ONE,
      write_timeout=1,
      timeout=1,
    )
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend,1,1.637377179507321e-07,"The method is a constructor (__init__) for a class that initializes an object with specific attributes and checks. It includes error handling for unsupported models and sets up a serial connection, which are essential functionalities for the class. Such methods are fundamental to the class's operation and are unlikely to be removed unless the entire class is refactored or deprecated."
survived,"  async def take_in_plate(self, plate: Plate, site: PlateHolder):
    print(f""Taking in plate {plate} at site {site}"")
",pylabrobot/storage/chatterbox.py,IncubatorChatterboxBackend,1,8.152020648014727e-09,"The method 'take_in_plate' is a simple asynchronous function that logs a message when a plate is taken in at a specific site. It is likely part of a larger system dealing with plates and sites, possibly in a manufacturing or logistics context. The method is straightforward, performs a clear task, and does not contain any obvious issues or redundancies. Therefore, it is likely to be retained as it serves a specific purpose in the system."
survived,"  async def init_shakers(self):
    return hex_to_binary(await self.send_command(""ll"", ""vi"", """"))
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend,1,8.152020648014727e-09,"The method 'init_shakers' is an asynchronous function that sends a command and processes its result. It appears to be part of a larger system where sending commands and processing their results is necessary. The method is likely to be used in contexts where asynchronous operations are required, such as network communication or hardware control. Without additional context indicating that this functionality is obsolete or replaced, it is reasonable to assume that this method is still relevant and useful in its current context."
survived,"  async def stop_shaking(self):
    await self._send_command(""RS 1607"")
    await self._wait_ready()
",pylabrobot/storage/cytomat/heraeus_cytomat_backend.py,HeraeusCytomatBackend,1,2.998960815863541e-09,"The method 'stop_shaking' is an asynchronous function that sends a command and waits for a response. It appears to be part of a larger system, likely involving hardware or a device that requires commands to be sent and acknowledged. The method is specific and likely necessary for the operation of the system it is part of. Without additional context indicating that this functionality is obsolete or replaced, it is reasonable to assume that this method is still relevant and necessary for the system's operation."
survived,"  async def get_overview_register(self) -> OverviewRegisterState:
    # Sometimes this command is not recognized and it is not known why. We will retry a few times
    # We don't care if the cytomat is still busy, that is actually what we are often checking for.
    # We are just gathering state, so just try a little bit later.
    num_tries = 10
    for _ in range(num_tries):
      try:
        resp = await self.send_command(""ch"", ""bs"", """")
      except (CytomatCommandUnknownError, CytomatBusyError):
        await asyncio.sleep(0.1)
        continue
      return OverviewRegisterState.from_resp(resp)
    await self.reset_error_register()
    raise CytomatCommandUnknownError(""Could not get overview register"")
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend,1,9.736200303530205e-10,"The method 'get_overview_register' is designed to handle specific errors by retrying the command multiple times before raising an exception. This approach is robust and ensures that transient issues do not cause the method to fail immediately. Additionally, the method includes a mechanism to reset the error register if all retries fail, which is a good practice for error handling. Given these considerations, the method is likely to be useful and reliable in its context, making it more likely to survive."
survived,"  async def _wait_ready(self, timeout: int = 60):
    """"""
    Poll the ready flag (RD 1915) until it becomes '1' or timeout.
    """"""
    start = time.time()
    while True:
      resp = await self._send_command(""RD 1915"")
      if resp == ""1"":
        return
      await asyncio.sleep(0.1)
      if time.time() - start > timeout:
        raise TimeoutError(""Legacy Cytomat did not become ready in time"")
",pylabrobot/storage/cytomat/heraeus_cytomat_backend.py,HeraeusCytomatBackend,1,2.3355930333443423e-09,"The method '_wait_ready' is an asynchronous function that polls a ready flag until it becomes '1' or a timeout occurs. This is a common pattern in asynchronous programming for waiting on a condition to be met, especially in hardware or network communication scenarios. The method is well-defined, handles timeouts, and uses asyncio for non-blocking waits, which are all good practices. There is no indication that this method is obsolete or redundant, and it serves a clear purpose in the context of waiting for a device to be ready. Therefore, it is likely to be retained."
survived,"  def find_smallest_site_for_plate(self, plate: Plate) -> PlateHolder:
    return self._find_available_sites_sorted(plate)[0]
",pylabrobot/storage/incubator.py,Incubator,1,1.4166087846364157e-09,"The method 'find_smallest_site_for_plate' is a straightforward utility function that is likely to be useful in the context of managing or organizing plates and their corresponding sites. It appears to be part of a larger system that deals with plates and plate holders, possibly in a laboratory or manufacturing setting. The method's purpose is clear: it finds the smallest available site for a given plate, which is a common requirement in such systems. Unless there is a significant change in the system's requirements or architecture, this method is likely to survive as it provides a necessary functionality."
survived,"  async def read_plate_detection_xfer(self) -> bool:
    """"""Read Plate Detection Transfer Station (RD 1813).""""""
    resp = await self._send_command(""RD 1813"")
    return resp == ""1""
",pylabrobot/storage/cytomat/heraeus_cytomat_backend.py,HeraeusCytomatBackend,1,2.8453347280241004e-08,"The method `read_plate_detection_xfer` is a simple asynchronous function that sends a command and checks the response. It is likely part of a larger system that interacts with hardware or a service, and such methods are typically essential for the operation of the system. The method is straightforward, performs a specific task, and is likely necessary for the functionality it supports. Therefore, it is unlikely to be deleted unless the entire system or the specific feature it supports is deprecated."
survived,"    def _plate_height(p: Plate):
      if p.has_lid():
        # TODO: we can use plr nesting height
        # lid.location.z + lid.get_anchor(z=""t"").z
        return p.get_size_z() + 3
      return p.get_size_z()
",pylabrobot/storage/incubator.py,Incubator,1,8.152020648014727e-09,"The method _plate_height is likely to survive because it provides a specific utility in calculating the height of a plate object, considering whether it has a lid or not. This functionality is essential for applications that need to handle physical dimensions accurately, such as in laboratory automation or robotics. The presence of a TODO comment suggests that there is room for improvement or additional functionality, indicating that the method is actively maintained and considered useful."
survived,"  async def shovel_out(self):
    return await self.send_action(""ll"", ""sp"", ""002"")
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend,1,9.237449576640118e-09,"The method 'shovel_out' is a simple asynchronous function that calls another method 'send_action' with specific parameters. It seems to be part of a larger system where actions are sent to some service or device. Without additional context, it's difficult to determine its utility, but the method itself is functional and follows a common pattern in asynchronous programming. Unless the functionality it provides is no longer needed or has been replaced by another method, there is no inherent reason to delete it. Therefore, it is likely to survive."
survived,"  async def stop(self):
    await self.io.stop()
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend,1,1.955568070542584e-08,"The method 'stop' is a simple asynchronous function that calls 'stop' on an 'io' object. Without additional context, such as the usage of this method or the implementation details of 'self.io.stop()', it's difficult to determine its utility. However, the method itself is straightforward and likely serves a specific purpose in managing asynchronous operations. Unless the 'io' object or its 'stop' method is deprecated or unnecessary, this method is likely to survive as it provides a clear and concise way to stop an operation asynchronously."
survived,"  async def start_shaking(self, frequency: float = 1.0):
    await self._send_command(""ST 1607"")
    await self._wait_ready()
",pylabrobot/storage/cytomat/heraeus_cytomat_backend.py,HeraeusCytomatBackend,1,2.998960815863541e-09,"The method 'start_shaking' is an asynchronous function that sends a command and waits for a response. It is likely part of a larger system that requires asynchronous operations, such as a device controller or a networked application. The method is simple, but it serves a specific purpose in the context of its application. Without additional context indicating that this functionality is no longer needed or has been replaced, it is reasonable to assume that it will survive."
survived,"def cytomat_rack_45p5mm_11(name: str):
  return _cytomat_rack(name=name, site_height=45.5, num_sites=11, model=""cytomat_rack_45.5mm_11"")
",pylabrobot/storage/cytomat/racks.py,,1,6.825604231969389e-08,"The method 'cytomat_rack_45p5mm_11' is a specific utility function that likely serves a particular purpose in a larger codebase. It wraps around another function '_cytomat_rack', providing specific parameters such as 'site_height', 'num_sites', and 'model'. This suggests that it is used to create or configure a specific type of rack with these predefined settings. Such utility functions are often kept in codebases to simplify calls to more generic functions with common parameter sets, improving code readability and reducing the chance of errors. Unless the functionality it provides is no longer needed or has been replaced by a more flexible solution, it is likely to be retained."
survived,"  async def reset_error_register(self) -> None:
    await self.send_command(""rs"", ""be"", """")
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend,1,4.599055376537186e-10,"The method 'reset_error_register' is a simple asynchronous function that sends a command to reset an error register. It is likely part of a larger system where error handling and resetting are necessary. The method is straightforward, performs a clear function, and uses asynchronous programming, which is beneficial for non-blocking operations. There is no indication that this method is redundant or unnecessary, so it is likely to be retained in the codebase."
survived,"def _str_to_bool(v: str) -> bool:
    """"""Return True for truthy strings.""""""
    return v.lower() in {""1"", ""true"", ""yes"", ""on""}
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,,1,1.1032560311263802e-09,"The method _str_to_bool is a utility function that converts a string to a boolean value based on common truthy string representations. This is a useful function in many applications where string inputs need to be interpreted as boolean values, such as configuration settings or user inputs. The method is simple, efficient, and serves a clear purpose, making it likely to be retained in the codebase."
survived,"def _split_name(name: str) -> Tuple[str, str]:
    """"""Split ``slug@version`` into components.""""""
    if ""@"" in name:
        slug, version = name.split(""@"", 1)
    else:
        slug, version = name, ""latest""
    return slug, version
",src/meta_agent/template_mixer.py,,1,2.646573631904765e-09,"The method _split_name is a utility function that splits a string into two components based on a delimiter. This is a common and useful operation in many applications, especially those dealing with versioning or similar string patterns. The method is simple, efficient, and provides a default behavior when the delimiter is not present. Such utility functions are often retained in codebases because they encapsulate a specific, reusable logic that can be used in multiple places. Therefore, it is likely to survive."
survived,"def test_template_validator_success() -> None:
    validator = TemplateValidator()
    case = TemplateTestCase(context={""name"": ""Bob""}, expected_output=""Hello Bob"")
    result = validator.validate(""Hello {{ name }}"", [case])
    assert result.success
    assert result.errors == []
",tests/test_template_validator.py,,1,1.955568070542584e-08,"The method `test_template_validator_success` is a unit test designed to verify the success of a template validation process. It is a straightforward test that checks if the `TemplateValidator` correctly processes a template with a given context and expected output. Such tests are crucial for ensuring the reliability and correctness of code, especially in template processing systems. Since it serves a clear purpose in validating the functionality of the `TemplateValidator`, it is likely to be retained in the codebase to ensure ongoing correctness as the system evolves."
survived,"    def parse(self, source: str) -> None:
        """"""Naive validation that braces are balanced.""""""
        if source.count(""{{"") != source.count(""}}""):  # pragma: no cover - simple
            raise TemplateSyntaxError(""unbalanced variable braces"")
        if source.count(""{%"") != source.count(""%}""):
            raise TemplateSyntaxError(""unbalanced block braces"")
        if ""{% for"" in source and ""endfor"" not in source:
            raise TemplateSyntaxError(""for block not closed"")
        if ""{% if"" in source and ""endif"" not in source:
            raise TemplateSyntaxError(""if block not closed"")
        return source
",src/jinja2/__init__.py,Environment,1,2.8453347280241004e-08,"The method 'parse' is a simple yet effective way to validate that certain template syntax elements are balanced in a given source string. It checks for matching pairs of variable and block braces, as well as ensuring that 'for' and 'if' blocks are properly closed. This kind of validation is crucial in template engines to prevent syntax errors and ensure the correct rendering of templates. The method is straightforward, performs a necessary function, and is likely to be useful in contexts where template syntax needs to be validated. Therefore, it is likely to be retained in the codebase."
survived,"def _prefetch_vault() -> None:
    """"""Populate environment secrets from HashiCorp Vault if configured.""""""
    if ""VAULT_ADDR"" in os.environ:
        try:  # pragma: no cover - optional dependency
            import importlib

            hvac = importlib.import_module(""hvac"")

            addr = os.environ[""VAULT_ADDR""]
            token = os.getenv(""VAULT_TOKEN"")
            secret_path = os.getenv(""OPENAI_API_KEY_PATH"", ""OPENAI_API_KEY"")
            client = hvac.Client(url=addr, token=token)
            data = client.secrets.kv.read_secret_version(path=secret_path)
            value = data[""data""][""data""].get(""OPENAI_API_KEY"")
            if value:
                os.environ[""OPENAI_API_KEY""] = value
        except Exception as exc:  # noqa: BLE001
            _log.warning(""Vault lookup failed: %s"", exc)
",alpha_factory_v1/utils/config_common.py,,1,1.1861120010657661e-08,"The method `_prefetch_vault` is designed to fetch secrets from HashiCorp Vault and populate environment variables if the Vault is configured. This functionality is crucial for applications that rely on secure storage and retrieval of sensitive information, such as API keys. The method includes error handling to log warnings if the Vault lookup fails, which is a good practice for maintaining robustness. Additionally, the use of environment variables for configuration is a common pattern in modern software development, especially in cloud and containerized environments. Given these factors, the method is likely to be retained as it provides essential functionality for secure configuration management."
survived,"    def __init__(self, registry: Optional[TemplateRegistry] = None) -> None:
        self.registry = registry or TemplateRegistry()
        self.ratings_path = self.registry.templates_dir / ""ratings.json""
        if not self.ratings_path.exists():
            self.ratings_path.write_text(""{}"", encoding=""utf-8"")
",src/meta_agent/template_sharing.py,TemplateSharingManager,1,2.2159489282323004e-08,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class. It sets up important attributes like 'registry' and 'ratings_path', and ensures that 'ratings.json' exists by creating it if it doesn't. This functionality is crucial for the class to operate correctly, especially if it relies on the 'ratings.json' file for its operations. Therefore, it is unlikely to be deleted."
survived,"def test_docs_available() -> None:
    port = _free_port()
    env = os.environ.copy()
    env[""PYTHONPATH""] = str(REPO_ROOT)
    cmd = [
        sys.executable,
        ""-m"",
        ""alpha_factory_v1.demos.alpha_agi_insight_v1.src.interface.api_server"",
        ""--host"",
        ""127.0.0.1"",
        ""--port"",
        str(port),
    ]
    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, env=env)
    url = f""http://127.0.0.1:{port}""
    try:
        for _ in range(50):
            try:
                r = httpx.get(url + ""/docs"")
                if r.status_code == 200:
                    break
            except Exception:
                pass
            time.sleep(0.1)
        else:
            raise AssertionError(""server failed to start"")
        assert r.status_code == 200
    finally:
        proc.terminate()
        try:
            proc.wait(timeout=5)
        except subprocess.TimeoutExpired:
            proc.kill()",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_api_server_subprocess.py,,1,1.522997951276035e-08,"The method 'test_docs_available' is a test function that checks if the documentation endpoint of a server is available. It starts a server process, attempts to connect to the '/docs' endpoint, and asserts that the server responds with a 200 status code. This is a typical test case for ensuring that a server is running correctly and serving its documentation. Such test functions are crucial for maintaining the reliability of software systems, especially in development and CI/CD pipelines. Therefore, it is likely to be retained in the codebase."
survived,"    def __init__(self, *a, **k):
        pass
",tests/test_selfheal_import_stubs.py,DummyMarkdown,0,0.9999999918479795,"The method is a constructor (__init__) that takes any number of positional and keyword arguments but does nothing with them. This is typically a placeholder or a default implementation that might be used in a base class or during early stages of development. However, if it remains unchanged, it doesn't serve any functional purpose and is likely to be removed or replaced with a more meaningful implementation. Therefore, it is predicted to be deleted."
survived,"    def __init__(self, *a, **k):
        pass
",tests/test_selfheal_import_stubs.py,DummyBlocks,0,0.9999998555019682,"The method is an initializer for a class, but it doesn't perform any operations or initialize any attributes. While it technically serves as a placeholder, it doesn't add any functionality or value to the class. In most practical scenarios, such a method would be considered unnecessary and likely to be removed unless it is intended to be overridden by subclasses or is part of a larger framework that requires its presence. Therefore, it is more likely to be deleted."
survived,"def test_results_requires_auth() -> None:
    port = _free_port()
    proc = _start_server(port)
    url = f""http://127.0.0.1:{port}""
    headers = {""Authorization"": ""Bearer test-token""}
    try:
        _wait_running(url, headers)
        r = httpx.get(f""{url}/results"")
        assert r.status_code == 403
    finally:
        proc.terminate()
        proc.wait(timeout=5)
",tests/test_api_server_subprocess.py,,1,3.850741907939403e-09,"The method 'test_results_requires_auth' is a unit test designed to verify that accessing the '/results' endpoint without proper authorization returns a 403 Forbidden status code. This is a common and necessary test to ensure that the authorization mechanism is working correctly. Such tests are crucial for maintaining the security and integrity of an application, especially when dealing with sensitive data or operations that require restricted access. Therefore, this method is likely to be retained as part of the test suite to ensure ongoing compliance with security requirements."
survived,"def percent_conditional(line):
    return ""%s\n"" % line if not line.endswith('\\') or line.endswith('\\\\') else ""%s"" % line[:-1]
",test/integration/samples_in/issue192.py,,1,5.60279640614594e-09,"The method 'percent_conditional' is a utility function that processes a string based on specific conditions. It checks if a line ends with a single backslash and removes it, unless it ends with a double backslash, in which case it leaves it unchanged. This kind of string manipulation can be useful in scenarios where lines are being processed for formatting or parsing purposes, such as in configuration files or scripts. The function is simple, has a clear purpose, and does not have any obvious issues or redundancies. Therefore, it is likely to be retained in the codebase."
survived,"def test_alert_warning(monkeypatch, caplog: pytest.LogCaptureFixture) -> None:
    def fake_post(*_a, **_kw):
        return type(""R"", (), {""status_code"": 500})()

    monkeypatch.setattr(alerts, ""requests"", type(""M"", (), {""post"": fake_post}))

    caplog.set_level(logging.WARNING)
    alerts.send_alert(""oops"", ""http://hook"")
    assert any(""status 500"" in r.getMessage() for r in caplog.records)",tests/test_alert_webhook.py,,1,9.736200303530205e-10,"The method `test_alert_warning` is a unit test function that uses `monkeypatch` to mock the behavior of a `post` request, simulating a failure with a status code of 500. It then checks if a warning log is recorded when the `send_alert` function is called. This is a typical pattern for testing logging behavior in Python applications, especially when dealing with external services. The method is likely to survive because it is a useful test for ensuring that the application logs warnings correctly when an alert fails to send due to a server error."
survived,"    def get_process_count(cls) -> int:  # type: ignore[override]
        if _PROCESS_COUNT in os.environ:
            return int(os.environ[_PROCESS_COUNT])

        if cls.is_env_present():
            num_nodes = next(
                (os.environ[o] for o in [""SLURM_JOB_NUM_NODES"", _NUM_NODES, ""SLURM_NNODES""] if o in os.environ),
                None,
            )
            if num_nodes == ""1"":
                logger.info(""%s not set; assuming single-process job"", _PROCESS_COUNT)
                return 1

        return super().get_process_count()
",src/levanter/distributed.py,LevanterSlurmCluster,1,3.160881453314576e-10,"The method `get_process_count` is likely to survive because it provides a specific functionality to determine the number of processes based on environment variables. It checks for specific environment variables related to process count and node numbers, which is a common requirement in distributed computing environments. Additionally, it falls back to a superclass method if the conditions are not met, indicating a well-thought-out design. This method is useful for adapting the process count dynamically based on the environment, which is a valuable feature in many applications."
survived,"def _example_value(param_type: str) -> str:
    mapping = {
        ""int"": ""1"",
        ""integer"": ""1"",
        ""float"": ""1.0"",
        ""string"": ""'test'"",
        ""bool"": ""True"",
        ""boolean"": ""True"",
        ""list"": ""[]"",
        ""dict"": ""{}"",
    }
    return mapping.get(param_type.lower(), ""None"")
",src/meta_agent/generators/test_generator.py,,1,2.1724399346070676e-10,"The method `_example_value` is a utility function that provides a default example value for a given parameter type. It is straightforward, useful for generating mock data or testing, and does not contain any obvious flaws or redundancies. The method is likely to be retained as it serves a clear purpose and is implemented efficiently."
survived,"  def test_single_bit(self):
    self.assertEqual(getbits(0b100000000, 8, 8), 1)
",test/unit/test_helpers.py,TestGetBits,1,2.0611536181902033e-09,"The method `test_single_bit` is a unit test for the function `getbits`. It checks if the function correctly extracts a single bit from a binary number. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with bit manipulation, which can be error-prone. Therefore, this method is likely to be retained as part of the test suite to ensure the `getbits` function works as expected."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/count-occurrences-of-a-substring.py,,1,1.9947301075518807e-06,"The method _now() is a utility function that generates a pseudo-random number based on a seed if _now_seeded is True, or returns the current time in nanoseconds if not. This function is useful for testing or scenarios where deterministic behavior is needed. It is unlikely to be deleted because it serves a specific purpose in providing a controlled random number generation mechanism, which can be crucial for debugging or testing purposes."
survived,"def _lambda15():
    draw.get(1000)()
    draw.get(8000)()
",tests/rosetta/transpiler/Python/cistercian-numerals.py,,0,0.9997965729390125,"The method _lambda15() is a private method indicated by the underscore prefix, suggesting it is intended for internal use within a module or class. The method calls two functions, draw.get(1000)() and draw.get(8000)(), which implies it is executing some operations based on the results of these calls. However, without additional context on what 'draw' is or what these operations achieve, it's difficult to assess the utility or necessity of this method. If 'draw' is a critical component and these operations are essential for the application's functionality, the method might survive. However, if these operations are redundant, inefficient, or can be refactored into a more meaningful structure, the method might be deleted. Given the lack of context, the method is more likely to be deleted if it doesn't contribute significantly to the application's functionality or maintainability."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/forward-difference.py,,1,2.3355930333443423e-09,"The method `_now()` is a utility function that generates a pseudo-random number based on a seed if `_now_seeded` is True, or returns the current time in nanoseconds otherwise. This function seems to be a part of a larger system that requires either a deterministic sequence of numbers (when seeded) or a timestamp. Such utility functions are often useful in testing, simulations, or systems where time-based operations are needed. Unless there is a significant change in the requirements or a better alternative is found, this method is likely to survive as it provides essential functionality."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/formal-power-series.py,,1,4.6911638017642294e-08,"The method _now() is a utility function that generates a pseudo-random number based on a seed if _now_seeded is True, or returns the current time in nanoseconds if not. This function seems to be a part of a larger system that requires either a deterministic sequence of numbers (when seeded) or a timestamp. Such utility functions are often useful in testing or in systems where time-based or pseudo-random number generation is needed. Unless there is a specific reason to remove it, such as redundancy or a shift in design requirements, it is likely to be retained."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/fork-2.py,,1,9.931195248674785e-08,"The method `_now()` is a utility function that generates a pseudo-random number based on a global seed if `_now_seeded` is True, otherwise it returns the current time in nanoseconds. This function seems to be a part of a larger system that requires either a deterministic sequence of numbers (when seeded) or a timestamp. Such utility functions are often useful in testing or in systems where time-based or pseudo-random values are needed. Unless there is a specific reason to remove it, such as redundancy or a shift in design requirements, it is likely to be retained."
survived,"def printState(v):
    s = state(v)
    print(""value="" + str(v) + "" entry="" + str(s.entry) + "" inc="" + str(s.inc) + "" dec="" + str(s.dec))
",tests/rosetta/transpiler/Python/gui-enabling-disabling-of-controls.py,,1,9.237449576640118e-09,"The method 'printState' is a simple utility function that prints the state of an object 's' derived from the function 'state(v)'. It is a straightforward function that is likely used for debugging or logging purposes. Such utility functions are generally useful for understanding the flow of data and the state of objects during execution, especially in development and testing phases. Unless there is a significant change in the codebase that makes this function obsolete or redundant, it is likely to survive as it aids in debugging and understanding the program's behavior."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/function-prototype.py,,1,3.850741907939403e-09,"The method '_now' is a utility function that generates a pseudo-random number based on a seed or returns the current time in nanoseconds. The function is simple, has a clear purpose, and does not have any apparent issues or redundancies that would warrant its removal. It is likely used in a context where either a seeded random number or a timestamp is needed, which are common requirements in many applications. Therefore, it is likely to be retained."
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    screen = Screen(w=1920, h=1080)
    print(""Screen size: "" + str(screen.w) + "" x "" + str(screen.h))
    win = Window(x=50, y=50, w=800, h=600, maximized=False)
    win = maximize(screen, win)
    print(""Max usable : "" + str(win.w) + "" x "" + str(win.h))
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/gui-maximum-window-dimensions.py,,1,3.3982678079468468e-09,"The method 'main' is a complete function that performs a series of operations: it initializes screen and window objects, maximizes the window, and prints out performance metrics. It is well-structured and serves a clear purpose in the context of a program that deals with screen and window management. There is no indication of redundancy or obsolescence in the code, and it appears to be functional and relevant to its intended use. Therefore, it is likely to be retained in the codebase."
survived,"def _lambda0(i):
    if i == 0:
        return 1.0
    return 0.0
",tests/rosetta/transpiler/Python/formal-power-series.py,,1,2.5109990926928157e-08,"The method _lambda0 is a simple utility function that checks if the input is zero and returns 1.0 if true, otherwise returns 0.0. This kind of function is often used in mathematical computations or as a part of larger algorithms where such conditional checks are necessary. The function is straightforward, has a clear purpose, and is likely to be used in various contexts where such a check is needed. Therefore, it is more likely to be retained in the codebase."
survived,"def one():
    return newFps(_lambda0)
",tests/rosetta/transpiler/Python/formal-power-series.py,,1,2.1444939769331175e-05,"The method 'one' is a simple function that returns the result of calling another function 'newFps' with '_lambda0' as an argument. Without additional context, such as the definition of 'newFps' or the purpose of '_lambda0', it's difficult to determine the utility of this method. However, the method itself is syntactically correct and could be part of a larger, functional codebase. If 'newFps' and '_lambda0' are defined and used elsewhere in the code, this method is likely to survive. If they are not, or if the method is deemed unnecessary, it might be deleted. Given the lack of context, I'll assume it has a purpose in the codebase."
survived,"def integrate(a):
    return newFps(_lambda3)
",tests/rosetta/transpiler/Python/formal-power-series.py,,0,0.99999960721363,"The method 'integrate' is very minimal and lacks context or functionality. It calls 'newFps' with '_lambda3', but without any information on what 'newFps' or '_lambda3' are, it's difficult to determine its purpose or correctness. This lack of context and apparent functionality suggests that the method is either incomplete or not useful in its current state, leading to a high likelihood of it being deleted."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/get-system-command-output.py,,1,1.275190675769241e-07,"The method `_now()` is a utility function that generates a pseudo-random number based on a seed if `_now_seeded` is True, or returns the current time in nanoseconds otherwise. This function is likely to be useful in scenarios where a consistent pseudo-random number generation is needed for testing or simulation purposes. The use of a global seed allows for reproducibility, which is often a desired feature in testing environments. Therefore, the method is likely to be retained as it serves a specific purpose that is not easily replaced by standard library functions."
survived,"def dayToGre(day):
    y = day * 100 // 36525
    d = day - (y * 36525 // 100) + 21
    y = y + 1792
    d = d + (y // 100) - (y // 400) - 13
    m = 8
    while d > gregorian[m]:
        d = d - gregorian[m]
        m = m + 1
        if m == 12:
            m = 0
            y = y + 1
            if greLeap(y):
                gregorian[1] = 29
            else:
                gregorian[1] = 28
    m = m + 1
    return [d, m, y]
",tests/rosetta/transpiler/Python/french-republican-calendar.py,,0,0.9999999317439577,"The method 'dayToGre' is likely to be deleted because it contains several issues that make it unreliable and difficult to maintain. Firstly, the function references an undefined variable 'gregorian', which will cause a runtime error. Additionally, the function uses a non-standard approach to convert days to a Gregorian date, which may not be accurate or efficient. The logic for leap year calculation is also not clearly defined, as it relies on an undefined function 'greLeap'. These issues suggest that the method is not well-implemented and may be replaced or removed in favor of a more robust solution."
survived,"def sinCos():
    sin = newFps(lambda n: 0.0)
    cos = sub(one(), integrate(sin))
    sin = dataclasses.replace(sin, compute=_lambda4)
    return Pair(sin=sin, cos=cos)
",tests/rosetta/transpiler/Python/formal-power-series.py,,0,0.9999999907625504,"The method 'sinCos' is likely to be deleted (0) because it contains several issues that suggest it is not functional or complete. Firstly, the function 'newFps' is not defined within the provided code, which would lead to a NameError. Secondly, the function 'sub' and 'integrate' are also not defined, indicating that the code is incomplete or relies on external dependencies that are not included. Additionally, the use of 'dataclasses.replace' and '_lambda4' suggests that there are missing parts of the code or context that are necessary for this function to work. Without these definitions and context, the function cannot execute as intended, making it a candidate for deletion unless these issues are resolved."
survived,"def a():
    pass
",tests/rosetta/transpiler/Python/function-prototype.py,,0,0.999998629043345,"The method 'a' is currently a placeholder with no implementation (it uses 'pass'). If it remains unused or unimplemented, it is likely to be deleted in future code clean-ups to maintain code quality and readability. However, if it is intended to be implemented later, it might survive. Without further context, the default assumption is that unused placeholder methods are often removed."
survived,"def setCoverage(n, value):
    n[""coverage""] = value
",tests/rosetta/transpiler/Python/functional-coverage-tree.py,,1,2.998960815863541e-09,"The method 'setCoverage' is a simple utility function that sets a 'coverage' key in a dictionary 'n' to a specified 'value'. This kind of function is often useful in various contexts where dictionary manipulation is required, especially in data processing or configuration settings. It is a straightforward and reusable piece of code that can be easily understood and integrated into larger systems. Therefore, it is likely to be retained as it serves a clear purpose and does not have any apparent issues."
survived,"    async def get_population(sim_id: str, _: None = Depends(verify_token)) -> PopulationResponse:
        result = _simulations.get(sim_id)
        if result is None:
            raise HTTPException(status_code=404)
        return PopulationResponse(id=sim_id, population=result.population or [])
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/api_server.py,,1,3.160881453314576e-10,"The method 'get_population' is likely to survive because it is a straightforward and essential part of an API that retrieves population data for a given simulation ID. It includes error handling for cases where the simulation ID is not found, which is a good practice. Additionally, it uses dependency injection for token verification, indicating it is part of a secure and well-structured system. These factors suggest that the method is functional, necessary, and well-implemented, making it unlikely to be deleted."
survived,"    def test_get_default_tools_base(self) -> None:
        with mock.patch.dict(os.environ, {}, clear=True):
            tools = self.af.get_default_tools()
        names = [getattr(t, ""name"", str(t)) for t in tools]
        self.assertIn(""FileSearchTool"", names)
        self.assertIn(""WebSearchTool"", names)
        self.assertEqual(len(tools), 3)
        self.assertFalse(any(isinstance(t, self.af.ComputerTool) for t in tools))
        self.assertFalse(any(isinstance(t, self.af.PythonTool) for t in tools))
",tests/test_agent_factory.py,TestAgentFactory,1,7.582560422162384e-10,"The method `test_get_default_tools_base` is a unit test method that verifies the behavior of the `get_default_tools` function. It uses mocking to ensure a controlled environment and checks for specific conditions such as the presence of certain tool names and the absence of certain tool types. Unit tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, this method is likely to be retained as it serves an important role in the testing suite."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/group_by_multi_join.py,,1,9.237449576640118e-09,"The method _fmt is a utility function that formats different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is often useful in various contexts where data needs to be formatted consistently for output or logging. Given its general utility and lack of any apparent issues, it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/update_stmt.py,,1,3.3982678079468468e-09,"The method _fmt is a utility function that formats different types of input values into strings. It handles lists by recursively formatting each element, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted consistently for output or logging. Its simplicity and general applicability suggest that it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/outer_join.py,,1,1.0467401685178159e-08,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in many programming scenarios where data needs to be consistently formatted for output or logging. Given its utility and the fact that it handles common data types, it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/group_by_join.py,,1,6.348800075736417e-09,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted for display or logging purposes. Its simplicity and general applicability make it likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/closure.py,,1,1.8189616842444243e-09,"The method _fmt is a utility function that formats different types of input values into strings. It handles lists by recursively formatting each element, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted consistently for output or logging. Its simplicity and general applicability suggest that it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/order_by_map.py,,1,1.0467401685178159e-08,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in many programming scenarios where data needs to be consistently formatted for output or logging. Given its utility and the fact that it handles common data types, it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/len_builtin.py,,1,2.998960815863541e-09,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in many programming scenarios where data needs to be consistently formatted for output or logging. Its simplicity and general applicability make it likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/string_index.py,,1,6.348800075736417e-09,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted for display or logging purposes. Its simplicity and general applicability suggest that it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/cast_string_to_int.py,,1,5.60279640614594e-09,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted for display or logging. Its simplicity and general applicability suggest that it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/in_operator.py,,1,2.0611536181902033e-09,"The method _fmt is a utility function that formats different types of input values into strings. It handles lists by recursively formatting each element, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted consistently for output or logging. Its simplicity and general applicability suggest that it is likely to be retained in the codebase."
survived,"def test_evolve_invokes(monkeypatch: pytest.MonkeyPatch) -> None:
    called = {}

    async def fake_evolve(*args: object, **kwargs: object) -> None:
        called[""ok""] = True

    monkeypatch.setattr(cli.asyncio, ""run"", lambda coro: None)
    monkeypatch.setattr(""src.evolve.evolve"", fake_evolve)

    runner = CliRunner()
    result = runner.invoke(cli.main, [""evolve""])

    assert result.exit_code == 0
    assert called.get(""ok"") is True
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_demo_cli.py,,1,1.0467401685178159e-08,"The method 'test_evolve_invokes' is a unit test function that uses the 'monkeypatch' fixture from pytest to replace certain parts of the code with test doubles. This is a common practice in testing to isolate the function being tested and ensure it behaves as expected. The function checks if the 'evolve' function is called correctly when the CLI command is invoked. Since testing is a crucial part of software development and this function is well-structured for its purpose, it is likely to be retained in the codebase."
survived,"def test_self_improver_invokes(monkeypatch: pytest.MonkeyPatch, tmp_path: Path) -> None:
    patch_file = tmp_path / ""p.diff""
    patch_file.write_text("""", encoding=""utf-8"")

    def fake_improve(repo_url: str, p_file: str, metric_file: str, log_file: str):
        click.echo(""score delta: 1.0"")
        return 1.0, tmp_path

    monkeypatch.setattr(cli.self_improver, ""improve_repo"", fake_improve)

    runner = CliRunner()
    result = runner.invoke(
        cli.main,
        [""self-improver"", ""--repo"", ""dummy"", ""--patch"", str(patch_file)],
    )

    assert result.exit_code == 0
    assert ""score delta"" in result.output
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_demo_cli.py,,1,3.581747929000289e-10,"The method 'test_self_improver_invokes' is a unit test function that uses the 'monkeypatch' fixture to replace the 'improve_repo' function with a fake implementation for testing purposes. It then uses 'CliRunner' to simulate a command-line interface invocation and checks the output. This is a typical pattern for testing CLI applications and is useful for ensuring that the 'self-improver' command behaves as expected. Since it is a test function, it is unlikely to be deleted unless the functionality it tests is removed or significantly changed. Therefore, the method will likely survive."
survived,"def inc(c: Counter):
    c.n = c.n + 1
",tests/human/x/python/record_assign.py,,1,5.60279640614594e-09,"The method 'inc' is a simple increment function that modifies an attribute 'n' of an object 'c' assumed to be of type 'Counter'. This function is straightforward and performs a basic operation that is commonly needed in programming. Unless there is a specific reason to remove it, such as redundancy or a change in design that makes it obsolete, such utility functions are generally retained. Therefore, it is likely to survive."
survived,"    def __eq__(self, other):
        return (
            self.name == other.name
            and self.age == other.age
            and self.status == other.status
        )
",tests/human/x/python/update_stmt.py,Person,1,7.194132978569833e-09,"The method `__eq__` is a standard way to define equality comparison between instances of a class in Python. It is commonly used to compare the attributes of two objects to determine if they are equivalent. This method is essential for many operations, such as using objects as keys in dictionaries or adding them to sets, which require objects to be hashable and comparable. Since this method is implementing a fundamental feature of object comparison, it is likely to be retained in the code."
survived,"    def tearDown(self):
        self.g.close()
",tests/test_memory_graph_rel.py,TestGraphMemoryRelationValidation,1,9.931195248674785e-08,"The method `tearDown` is a common method used in unit testing frameworks like `unittest` in Python. It is typically used to clean up resources after a test case has been executed. The presence of `self.g.close()` suggests that it is closing a resource, likely a file or a network connection, which is a necessary step to ensure that resources are properly released after tests. This is a standard practice in test case management to prevent resource leaks and ensure test isolation. Therefore, the method is likely to be retained as it serves an important purpose in the testing lifecycle."
survived,"    def run(
        self,
        input_data: Input,
        *,
        credentials: GoogleCredentials,
        graph_exec_id: str,
        **kwargs,
    ) -> BlockOutput:
        service = GmailReadBlock._build_service(credentials, **kwargs)
        message = self._reply(
            service,
            input_data,
            graph_exec_id,
        )
        yield ""messageId"", message[""id""]
        yield ""threadId"", message.get(""threadId"", input_data.threadId)
        yield ""message"", message
",autogpt_platform/backend/backend/blocks/google/gmail.py,GmailReplyBlock,1,1.1032560311263802e-09,"The method 'run' is likely to survive because it appears to be a well-structured and functional piece of code. It is designed to perform a specific task: interacting with a Gmail service to reply to a message and yield relevant information. The method uses clear parameters, including credentials and input data, and handles the response by yielding important message details. There is no indication of deprecated functionality or poor design that would necessitate its deletion."
survived,"    def __init__(self) -> None:
        self.logged: list[messaging.Envelope] = []
",tests/test_adk_agent.py,DummyLedger,1,2.3823698451773172e-07,"The method is a constructor (__init__) for a class, which is essential for initializing new instances of the class. It sets up an instance variable 'logged' as an empty list, which is likely used to store objects of type 'messaging.Envelope'. Constructors are fundamental to object-oriented programming as they define how an object is created and initialized. Therefore, it is highly unlikely that this method would be deleted."
survived,"    def publish(self, topic: str, env: messaging.Envelope) -> None:
        self.published.append((topic, env))
",tests/test_adk_agent.py,DummyBus,1,6.348800075736417e-09,"The method 'publish' is a simple utility function that appends a tuple of a topic and an envelope to a list called 'published'. This method is likely part of a larger system that deals with messaging or event handling. Such methods are typically essential for tracking or logging published messages, which is a common requirement in systems that handle messaging or events. Therefore, it is unlikely to be deleted as it serves a fundamental purpose in the system's functionality."
survived,"    async def skill_test(self, payload: dict) -> dict:
        return {""ok"": True}
",tests/test_skill_test_route.py,SimpleAgent,0,0.9999999715466527,"The method 'skill_test' is a simple asynchronous function that takes a dictionary as input and returns a dictionary with a fixed response. It is likely a placeholder or a basic implementation for testing purposes. Without additional context, such as whether this method is part of a larger, more complex system or if it is intended to be expanded upon, it's difficult to definitively predict its future. However, given its simplicity and lack of functionality, it might be subject to deletion or replacement with a more comprehensive implementation in the future. Therefore, it is more likely to be deleted."
survived,"    def __init__(self, inst: SimpleAgent) -> None:
        self.inst = inst
        self.next_ts = 0
",tests/test_skill_test_route.py,Runner,1,3.2241866333029355e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes or states. The presence of a constructor is crucial for the proper functioning of the class, especially if it involves setting up initial values or dependencies, as seen with the 'inst' parameter here. Therefore, it is unlikely to be deleted."
survived,"def parse_dbc(path: str) -> DBC:
    name = os.path.basename(path).replace('.dbc', '')
    with open(path) as f:
        lines = f.readlines()

    checksum_state = get_checksum_state(name)
    be_bits = [j + i * 8 for i in range(64) for j in range(7, -1, -1)]
    msgs: Dict[int, Msg] = {}
    addr_to_msg: Dict[int, Msg] = {}
    name_to_msg: Dict[str, Msg] = {}
    address = 0
    signals_temp: Dict[int, Dict[str, Signal]] = {}
    for line_num, line in enumerate(lines, 1):
        line = line.strip()
        if line.startswith('BO_ '):
            m = BO_RE.match(line)
            if not m:
                continue
            address = int(m.group(1), 0)
            msg_name = m.group(2)
            size = int(m.group(3), 0)
            sigs = {}
            msgs[address] = Msg(msg_name, address, size, sigs)
            addr_to_msg[address] = msgs[address]
            name_to_msg[msg_name] = msgs[address]
            signals_temp[address] = sigs
        elif line.startswith('SG_ '):
            m = SG_RE.search(line)
            offset = 0
            if not m:
                m = SGM_RE.search(line)
                if not m:
                    continue
                offset = 1
            sig_name = m.group(1)
            start_bit = int(m.group(2+offset))
            size = int(m.group(3+offset))
            is_little_endian = m.group(4+offset) == '1'
            is_signed = m.group(5+offset) == '-'
            factor = float(m.group(6+offset))
            offset_val = float(m.group(7+offset))

            if is_little_endian:
                lsb = start_bit
                msb = start_bit + size - 1
            else:
                idx = be_bits.index(start_bit)
                lsb = be_bits[idx + size - 1]
                msb = start_bit

            sig = Signal(sig_name, start_bit, msb, lsb, size, is_signed, factor, offset_val, is_little_endian)
            set_signal_type(sig, checksum_state, name, line_num)
            signals_temp[address][sig_name] = sig
    for addr, sigs in signals_temp.items():
        msgs[addr].sigs = sigs
    dbc = DBC(name, msgs, addr_to_msg, name_to_msg)
    return dbc
",opendbc/can/packer.py,,1,2.0611536181902033e-09,"The method `parse_dbc` is a utility function that parses a DBC file, which is a common format for describing the data structure of messages in a CAN bus system. This function is essential for applications that need to interpret or manipulate CAN messages, such as automotive diagnostics or vehicle data analysis tools. Given the widespread use of CAN bus systems in the automotive industry and the need for tools to parse and interpret DBC files, this method is likely to be useful and relevant for a long time. Therefore, it is likely to survive."
survived,"def set_value(msg: bytearray, sig: Signal, ival: int) -> None:
    i = sig.lsb // 8
    bits = sig.size
    if sig.size < 64:
        ival &= ((1 << sig.size) - 1)
    while 0 <= i < len(msg) and bits > 0:
        shift = sig.lsb % 8 if (sig.lsb // 8) == i else 0
        size = min(bits, 8 - shift)
        mask = ((1 << size) - 1) << shift
        msg[i] &= ~mask
        msg[i] |= (ival & ((1 << size) - 1)) << shift
        bits -= size
        ival >>= size
        i = i + 1 if sig.is_little_endian else i - 1
",opendbc/can/packer.py,,1,4.6911638017642294e-08,"The method 'set_value' is a utility function that manipulates a bytearray based on a signal's properties. It is a low-level operation that is often used in systems dealing with binary data, such as communication protocols or data serialization. The method is well-defined, performs a specific task, and is likely to be useful in contexts where such data manipulation is required. Therefore, it is unlikely to be deleted unless the entire system or approach to handling such data changes significantly."
survived,"    def __init__(self, dbc_name: str):
        dbc_path = dbc_name
        if not os.path.exists(dbc_path):
            dbc_path = os.path.join(os.path.dirname(__file__), '..', 'dbc', dbc_name + '.dbc')
        if dbc_name in DBC_CACHE:
            self.dbc = DBC_CACHE[dbc_name]
        else:
            self.dbc = parse_dbc(dbc_path)
            DBC_CACHE[dbc_name] = self.dbc
        self.counters: Dict[int, int] = {}
",opendbc/can/packer.py,CANPacker,1,4.944450477491054e-09,"The method is a constructor (__init__) for a class, which is essential for initializing class instances. It sets up important attributes such as 'dbc' and 'counters', and handles the loading of a DBC file, which is likely crucial for the class's functionality. Constructors are rarely deleted unless the class itself is being removed or significantly refactored, which is not indicated here."
survived,"    def test_open_blocked(self):
        agent_base.resource = None
        agent_base.signal = None
        se = SafeExec()
        code = """"""\

def transform(x):
    return open('foo', 'w')
""""""
        with self.assertRaises(NameError):
            se.run(code, ""transform"", 0)
",tests/test_safe_exec_security.py,TestSafeExecSecurity,1,2.2159489282323004e-08,"The method 'test_open_blocked' is testing a specific functionality of the 'SafeExec' class, which is likely a custom class designed to safely execute code. The test checks if executing a function that attempts to open a file raises a 'NameError', indicating that the 'SafeExec' class is correctly blocking or handling unsafe operations. This is a valid and useful test for ensuring the security and correctness of the 'SafeExec' class, especially if it is intended to run untrusted code. Therefore, the method is likely to be retained as it serves an important purpose in the test suite."
survived,"    async def lineage_subtree(node_id: int, _: None = Depends(verify_token)) -> list[LineageNode]:
        """"""Return lineage up to ``node_id``.""""""
        path = Path(os.getenv(""ARCHIVE_PATH"", ""archive.db""))
        arch = Archive(path)
        nodes: list[LineageNode] = []
        found = False
        for a in arch.all():
            nodes.append(
                LineageNode(
                    id=a.id,
                    parent=a.meta.get(""parent""),
                    diff=a.meta.get(""diff"") or a.meta.get(""patch""),
                    pass_rate=a.score,
                )
            )
            if a.id == node_id:
                found = True
                break
        if not found:
            raise HTTPException(status_code=404)
        return nodes
",src/interface/api_server.py,,1,1.2501528648238603e-09,"The method 'lineage_subtree' is likely to survive because it appears to be a well-structured and functional piece of code. It performs a specific task of retrieving a lineage of nodes up to a given node_id, which is a common requirement in data processing or version control systems. The method uses asynchronous programming, which is suitable for I/O-bound operations like database access. It also includes error handling by raising an HTTPException if the node_id is not found, which is good practice for robust API design. Additionally, the use of environment variables and dependency injection (with Depends) suggests that the code is designed with configurability and security in mind. These factors contribute to the method's utility and maintainability, making it unlikely to be deleted."
survived,"def _ensure(path: Path) -> None:
    with sqlite3.connect(path) as cx:
        cx.execute(
            """"""
            CREATE TABLE IF NOT EXISTS entries(
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                parent TEXT,
                child TEXT,
                metrics TEXT,
                hash TEXT,
                ts REAL
            )
            """"""
        )
        cx.execute(
            ""CREATE TABLE IF NOT EXISTS merkle(date TEXT PRIMARY KEY, root TEXT)""
        )
",src/archive/archive.py,,1,1.1032560311263802e-09,"The method '_ensure' is responsible for ensuring that certain tables exist in a SQLite database. It uses the 'CREATE TABLE IF NOT EXISTS' SQL command, which is a common practice to avoid errors if the table already exists. This method is likely part of a larger system that requires these tables to function correctly. Since it performs a necessary setup task and does so in a safe manner, it is unlikely to be deleted unless the entire database schema changes or the application no longer requires these tables. Therefore, the method is likely to survive."
survived,"        def observe(self, *_a: Any) -> None:
            ...
",alpha_factory_v1/backend/telemetry.py,_Metric,0,0.9998415637531546,"The method 'observe' is defined with a flexible argument list using '*_a', which suggests it is intended to handle a variety of inputs. However, the method body is currently a placeholder ('...'), indicating that it is not yet implemented. Without any implementation or documentation, it's unclear what the method is supposed to do. If this method is part of a larger class that is actively being developed, it might be implemented in the future. However, if it remains unimplemented for a long time, it could be considered for deletion. Given the current state, it is more likely to be deleted unless there is a clear plan to implement it soon."
survived,"    def _calc_next(self) -> None:
        now = time.time()
        if self.spec:
            with contextlib.suppress(ModuleNotFoundError, ValueError):
                from croniter import croniter  # type: ignore

                self.next_ts = croniter(self.spec, datetime.fromtimestamp(now)).get_next(float)
                return
        self.next_ts = now + self.period
",alpha_factory_v1/backend/agent_manager.py,AgentRunner,1,9.736200303530205e-10,"The method `_calc_next` is a private method (indicated by the underscore prefix) that calculates the next timestamp based on a cron specification or a fixed period. It uses the `croniter` library to parse cron expressions, which is a common requirement in scheduling tasks. The method is well-structured, handles exceptions gracefully using `contextlib.suppress`, and provides a fallback mechanism if `self.spec` is not defined. These characteristics suggest that the method is functional, useful, and unlikely to be removed unless the entire scheduling functionality is deprecated. Therefore, it is likely to survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/right_join.py,Customer,1,6.825604231969389e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/join_multi.py,Order,1,9.931195248674785e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the indexing syntax (e.g., obj[key]). In this code, it is implemented to return the attribute of the object with the name specified by `key`. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. It is likely to be retained because it provides a clear and concise way to access object attributes dynamically, which can be very useful in many programming scenarios."
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/left_join_multi.py,Item,1,4.1399375473943306e-08,"The method `__repr__` is a special method in Python used to define a string representation of an object. The implementation provided here returns the string representation of the object's dictionary, which is a common and useful way to represent an object for debugging purposes. This method is likely to be retained because it provides a clear and concise way to inspect the internal state of an object, which is valuable for developers during debugging and logging."
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/join_multi.py,Item,1,4.6911638017642294e-08,"The __repr__ method is a special method used to define a string representation of an object. In this case, it returns the string representation of the object's dictionary, which is a common and useful way to provide a detailed view of the object's attributes for debugging purposes. This implementation is straightforward and serves a clear purpose, making it unlikely to be deleted unless there is a specific reason to change how the object is represented as a string."
survived,"    def test_missing_attributes_skips_version_check(self) -> None:
        fake_mod = types.SimpleNamespace(__version__=""0.0.17"")

        orig_import_module = importlib.import_module
        orig_find_spec = importlib.util.find_spec

        def _fake_import(name: str, *args: Any, **kwargs: Any) -> object:
            if name == ""openai_agents"":
                return fake_mod
            return orig_import_module(name, *args, **kwargs)

        def _fake_find_spec(name: str, *args: Any, **kwargs: Any) -> object:
            if name == ""openai_agents"":
                return object()
            if name == ""agents"":
                return None
            return orig_find_spec(name, *args, **kwargs)

        with (
            mock.patch(""importlib.import_module"", side_effect=_fake_import),
            mock.patch(""importlib.util.find_spec"", side_effect=_fake_find_spec),
            mock.patch.object(check_env, ""REQUIRED"", []),
            mock.patch.object(check_env, ""OPTIONAL"", [""openai_agents""]),
            mock.patch.object(check_env, ""warn_missing_core"", lambda: []),
            mock.patch.object(check_env, ""check_openai_agents_version"", return_value=True) as chk,
        ):
            self.assertEqual(check_env.main([]), 0)
            chk.assert_not_called()
",tests/test_check_env_openai_agents_version.py,TestCheckEnvOpenAIAgentsVersion,1,6.825604231969389e-08,"The method is a unit test that ensures the version check is skipped when certain attributes are missing. It uses mocking to simulate the environment and dependencies, which is a common practice in testing. The method is likely to survive because it is part of a test suite that verifies the behavior of the code under specific conditions, ensuring robustness and correctness."
survived,"    def __hash__(self):
        return hash(self.minutes)
",hl7/datatypes.py,_UTCOffset,1,1.0467401685178159e-08,"The method is a simple implementation of the __hash__ method, which is used to return a hash value for an object. This is a common practice in Python to allow objects to be used in sets or as dictionary keys. The method uses the hash of an attribute 'minutes', which suggests that 'minutes' is a significant attribute for the object. There is no indication of redundancy or inefficiency in this implementation, and it follows Python's conventions for implementing hash methods. Therefore, it is likely to be retained."
survived,"    def fit(self, X: Any, y: Any | None = None):  # noqa: D401
        corpus, vocab = self._prepare_input(X)
        self.vocab_ = list(vocab)
        self.model_ = HierarchicalLDA(
            corpus,
            self.vocab_,
            alpha=self.alpha,
            gamma=self.gamma,
            eta=self.eta,
            num_levels=self.num_levels,
            seed=self.seed,
            verbose=self.verbose,
        )
        if self.iterations > 0:
            self.model_.estimate(
                self.iterations,
                display_topics=self.iterations + 1,
                n_words=0,
                with_weights=False,
            )
        return self
",src/hlda/sklearn_wrapper.py,HierarchicalLDAEstimator,1,9.237449576640118e-09,"The method 'fit' is a crucial part of any machine learning model as it is responsible for training the model on the given data. In this code, the 'fit' method is setting up the vocabulary and model, and then estimating the model if iterations are specified. This is a standard and necessary procedure in machine learning workflows, especially for models like HierarchicalLDA. Therefore, it is unlikely that this method will be deleted as it is essential for the functionality of the class it belongs to."
survived,"def test_execute_in_sandbox_exception() -> None:
    agent = _make_agent()
    out, err = agent.execute_in_sandbox(""1/0"")
    assert out == """"
    assert ""ZeroDivisionError"" in err",tests/test_codegen_agent.py,,1,4.944450477491054e-09,"The method `test_execute_in_sandbox_exception` is a unit test designed to verify that the `execute_in_sandbox` function of an agent correctly handles exceptions, specifically a `ZeroDivisionError`. This is a common and important test case to ensure that the system can gracefully handle errors and provide meaningful feedback. Such tests are crucial for robust software development, especially in environments where code execution is sandboxed for safety. Therefore, this method is likely to be retained as it serves a critical role in ensuring the reliability and correctness of the system."
survived,"async def sync_entra_groups(
    neo4j_session: neo4j.Session,
    tenant_id: str,
    client_id: str,
    client_secret: str,
    update_tag: int,
    common_job_parameters: Dict[str, Any],
) -> None:
    """"""Sync Entra groups.""""""
    credential = ClientSecretCredential(tenant_id=tenant_id, client_id=client_id, client_secret=client_secret)
    client = GraphServiceClient(credential, scopes=[""https://graph.microsoft.com/.default""])

    groups = await get_entra_groups(client)

    member_map: Dict[str, List[str]] = {}
    for group in groups:
        try:
            member_map[group.id] = await get_group_members(client, group.id)
        except Exception as e:
            logger.error(f""Failed to fetch members for group {group.id}: {e}"")
            member_map[group.id] = []

    transformed_groups = transform_groups(groups, member_map)

    load_tenant(neo4j_session, {""id"": tenant_id}, update_tag)
    load_groups(neo4j_session, transformed_groups, update_tag, tenant_id)
    cleanup_groups(neo4j_session, common_job_parameters)",cartography/intel/entra/groups.py,,1,3.3982678079468468e-09,"The method `sync_entra_groups` is a crucial part of a data synchronization process between a Microsoft Entra (Azure AD) environment and a Neo4j database. It involves fetching group data and their members from Microsoft Graph API, transforming this data, and then loading it into a Neo4j database. This functionality is essential for maintaining up-to-date group information in the database, which is likely a core requirement for applications relying on this data. The method is well-structured, uses asynchronous calls for efficiency, and includes error handling, making it robust and reliable. Given its importance and the fact that it is well-implemented, it is unlikely to be deleted."
survived,"def cleanup_groups(neo4j_session: neo4j.Session, common_job_parameters: Dict[str, Any]) -> None:
    GraphJob.from_node_schema(EntraGroupSchema(), common_job_parameters).run(neo4j_session)
",cartography/intel/entra/groups.py,,1,4.1399375473943306e-08,"The method 'cleanup_groups' is a utility function that appears to be part of a larger codebase dealing with graph databases, specifically Neo4j. It uses a schema and job pattern to perform operations on a Neo4j session. The method is concise and likely serves a specific purpose in the context of managing or cleaning up group data in a Neo4j database. Given its specific functionality and integration with a schema and job pattern, it is likely to be useful in its context and not redundant. Therefore, it is more likely to be retained in the codebase."
survived,"def test_git_manager_push(tmp_path: Path) -> None:
    remote = tmp_path / ""remote.git""
    subprocess.run([""git"", ""init"", ""--bare"", str(remote)], check=True)

    repo = tmp_path / ""repo""
    gm = GitManager(repo)
    gm.init()
    (repo / ""bar.txt"").write_text(""bar"")
    gm.commit_all(""first"")
    gm.add_remote(""origin"", str(remote))
    gm.push(""origin"", ""main"")

    log = subprocess.check_output(
        [""git"", ""-C"", str(remote), ""log"", ""--oneline""], text=True
    )
    assert ""first"" in log",tests/test_git_utils.py,,1,1.8189616842444243e-09,"The method 'test_git_manager_push' is a unit test function that verifies the functionality of a GitManager class. It sets up a temporary git repository, initializes it, makes a commit, adds a remote, and pushes the changes. Finally, it checks if the commit message is present in the remote repository's log. This is a typical test case for ensuring that the push functionality works correctly. Since it is a test function, it is likely to be maintained as long as the GitManager class exists and requires testing. Therefore, it is likely to survive."
survived,"def dayUnique(b, list):
    c = 0
    for x in list:
        if x.day == b.day:
            c = c + 1
    return c == 1
",tests/rosetta/transpiler/Python/cheryls-birthday.py,,0,0.9999938558278723,"The method 'dayUnique' is likely to be deleted because it uses a non-descriptive variable name 'list', which shadows the built-in Python list type. This can lead to confusion and potential errors. Additionally, the method's logic is quite simple and may not be necessary as a standalone function, especially if it is not used frequently or can be replaced with a more efficient or clearer approach. Furthermore, the method does not handle edge cases, such as when 'list' is empty or when 'b' is not a date object, which could lead to runtime errors."
survived,"def egcd(a, b):
    if a == 0:
        return [b, 0, 1]
    res = egcd(b % a, a)
    g = res[0]
    x1 = res[1]
    y1 = res[2]
    return [g, y1 - (b // a) * x1, x1]
",tests/rosetta/transpiler/Python/chinese-remainder-theorem.py,,1,1.522997951276035e-08,"The method 'egcd' implements the Extended Euclidean Algorithm, which is a well-known and widely used algorithm in number theory and cryptography for finding the greatest common divisor of two numbers and the coefficients of B√©zout's identity. This algorithm is fundamental in many applications, such as computing modular inverses, which are crucial in cryptographic algorithms like RSA. Given its importance and correctness, the method is likely to be retained in any codebase that requires such functionality."
survived,"def zero(f):
    return lambda x: x
",tests/rosetta/transpiler/Python/church-numerals-1.py,,0,0.9999999847700205,"The method 'zero' is a higher-order function that takes a function 'f' as an argument and returns a lambda function that ignores its input and always returns the input 'x'. This function might be used in functional programming contexts or as a placeholder, but its utility is limited. Without additional context or usage, it seems like a trivial function that might not be necessary in most codebases. Therefore, it is likely to be deleted."
survived,"def parseProgram(src):
    lines = split(src, ""\n"")
    header = fields(lines[0])
    dataSize = parseIntStr(header[1])
    nStrings = parseIntStr(header[3])
    stringPool = []
    i = 1
    while i <= nStrings:
        s = lines[i]
        if len(s) > 0:
            stringPool = stringPool + [unescape(s[1:len(s) - 1])]
        i = i + 1
    code = []
    addrMap = {}
    while i < len(lines):
        line = trim(lines[i])
        if len(line) == 0:
            break
        parts = fields(line)
        addr = parseIntStr(parts[0])
        op = parts[1]
        arg = 0
        if op == ""push"":
            arg = parseIntStr(parts[2])
        else:
            if op == ""fetch"" or op == ""store"":
                arg = parseIntStr(parts[2][1:len(parts[2]) - 1])
            else:
                if op == ""jmp"" or op == ""jz"":
                    arg = parseIntStr(parts[3])
        code = code + [{""addr"": addr, ""op"": op, ""arg"": arg}]
        addrMap[addr] = len(code) - 1
        i = i + 1
    return {""dataSize"": dataSize, ""strings"": stringPool, ""code"": code, ""addrMap"": addrMap}
",tests/rosetta/transpiler/Python/compiler-virtual-machine-interpreter.py,,1,2.8453347280241004e-08,"The method 'parseProgram' is a utility function that parses a source code string into a structured format. It processes the input string to extract data size, string pool, and code instructions, which are essential for interpreting or executing the program. This kind of functionality is fundamental in compilers or interpreters, making it a crucial part of such systems. Therefore, it is likely to be retained as it provides necessary parsing capabilities."
survived,"def demo(a):
    print(""A:"")
    printSym(a)
    print(""L:"")
    l = choleskyLower(a)
    printLower(l)
",tests/rosetta/transpiler/Python/cholesky-decomposition-1.py,,1,7.194132978569833e-09,"The method 'demo' is a simple demonstration function that prints a matrix 'a', computes its Cholesky lower triangular matrix, and prints it. The function is straightforward and serves a clear purpose in demonstrating the Cholesky decomposition process. Such utility functions are often retained in codebases for educational purposes or as part of a larger library of mathematical functions. Unless there is a specific reason to remove it, such as redundancy or a shift in the library's focus, it is likely to survive."
survived,"def showList(xs):
    out = ""[""
    i = 0
    while i < len(xs):
        out = out + str(xs[i])
        if i < len(xs) - 1:
            out = out + "", ""
        i = i + 1
    return out + ""]""
",tests/rosetta/transpiler/Python/circular-primes.py,,1,1.637377179507321e-07,"The method 'showList' is a simple utility function that converts a list into a string representation, which is a common requirement in many programming tasks. Although Python provides built-in ways to achieve this (e.g., using str() or join()), the method demonstrates a basic understanding of loops and string concatenation, which can be educational for beginners. It is not redundant enough to warrant deletion, as it might be used in contexts where understanding or modifying the string format is necessary. Therefore, it is likely to survive."
survived,"def main():
    print(quibble([]))
    print(quibble([""ABC""]))
    print(quibble([""ABC"", ""DEF""]))
    print(quibble([""ABC"", ""DEF"", ""G"", ""H""]))
",tests/rosetta/transpiler/Python/comma-quibbling.py,,1,6.475946147757848e-07,"The method 'main' is a simple test function that calls another function 'quibble' with different inputs. The purpose of 'main' is to demonstrate or test the functionality of 'quibble'. Since 'main' is a common entry point for Python scripts and is often used for testing or demonstrating code, it is likely to be retained unless the entire script is being refactored or the 'quibble' function is removed or replaced. Without additional context on the 'quibble' function, it's reasonable to assume that 'main' serves a useful purpose in this script."
survived,"def cz(yr, animal, yinYang, element, sc, bc):
    y = yr - 4
    stem = y % 10
    branch = y % 12
    sb = sc[stem] + bc[branch]
    return Info(animal=str(animal[branch]), yinYang=str(yinYang[stem % 2]), element=str(element[int((stem // 2))]), stemBranch=sb, cycle=y % 60 + 1)
",tests/rosetta/transpiler/Python/chinese-zodiac.py,,1,6.825604231969389e-08,"The method 'cz' is a utility function that calculates and returns a structured data object based on the input year and several lists representing different Chinese zodiac attributes. It is a specific function that likely serves a particular purpose in a larger application, such as a Chinese zodiac calculator or astrology tool. The method is concise, performs a clear task, and returns a structured result, which makes it useful and likely to be retained in the codebase. Additionally, it does not have any apparent issues or inefficiencies that would necessitate its removal."
survived,"def sortPoints(ps):
    arr = ps
    n = len(arr)
    i = 0
    while i < n:
        j = 0
        while j < n - 1:
            p = arr[j]
            q = arr[j + 1]
            if p.x > q.x or (p.x == q.x and p.y > q.y):
                arr[j] = q
                arr[j + 1] = p
            j = j + 1
        i = i + 1
    return arr
",tests/rosetta/transpiler/Python/convex-hull.py,,1,7.73442280641062e-08,"The method 'sortPoints' is a basic implementation of the bubble sort algorithm to sort a list of points based on their x and y coordinates. While bubble sort is not the most efficient sorting algorithm, it is simple and works correctly for small datasets. The method is functional and correctly implements the sorting logic, so it is likely to be retained unless there is a specific requirement for a more efficient sorting algorithm. Therefore, the method will likely survive."
survived,"def test_app_state_cache_management_and_stats():
    state = AppState()
    batch = ""b1""
    df = pd.DataFrame({
        ""metric_name"": [""m1"", ""m1"", ""m2"", ""m2""],
        ""metric_alert"": [1, 0, 0, 1],
        ""metric_score"": [0.5, 0.7, 0.3, 0.2],
        ""thumbsup_sum"": [1, 2, 3, 4],
        ""thumbsdown_sum"": [0, 1, 2, 3],
    })
    state.df_cache[batch] = df

    state.calculate_metric_stats(batch)

    stats = state.stats_cache[batch]
    assert len(stats) == 2
    assert stats[0][""metric_name""] == ""m1""
    assert stats[0][""anomaly_rate""] == pytest.approx(0.5)
    assert stats[0][""avg_score""] == pytest.approx(0.6)

    state.clear_batch_cache(batch)
    assert batch not in state.df_cache
    assert batch not in state.chart_cache
    assert batch not in state.stats_cache",tests/test_dashboard.py,,1,7.73442280641062e-08,"The method is a test function that verifies the functionality of the AppState class, specifically focusing on cache management and statistics calculation. Test functions are crucial for ensuring code reliability and are typically retained in the codebase to facilitate ongoing testing and validation of the software. Therefore, it is likely to be retained."
survived,"def test_error_suggestion(capsys):
    fb = UserFeedback()
    suggestion = fb.error_suggestion(""Failed to load file"")
    out, _ = capsys.readouterr()
    assert suggestion is not None
    assert ""file path exists"" in suggestion
    assert ""Suggestion"" in click.unstyle(out)
",tests/ux/test_user_feedback.py,,1,2.5109990926928157e-08,"The method 'test_error_suggestion' is a test function that checks the behavior of the 'error_suggestion' method in the 'UserFeedback' class. It verifies that the method returns a non-null suggestion and that the suggestion contains specific text. This is a typical unit test pattern, and such tests are crucial for ensuring code reliability and correctness. Therefore, it is likely to be retained as part of the test suite."
survived,"    def checksums(self) -> Dict[str, str]:
        return dict(self.metadata.custom.get(""checksums"", {}))",src/meta_agent/bundle.py,Bundle,1,3.160881453314576e-10,"The method 'checksums' is a simple utility function that retrieves and returns a dictionary of checksums from the 'metadata.custom' attribute. This method is likely to be useful for accessing checksum data in a structured way, which can be important for data integrity and validation purposes. Since it provides a clear and specific functionality without any apparent issues or redundancies, it is likely to be retained in the codebase."
survived,"    def refresh_metadata(self) -> None:
        with open(self.bundle_dir / ""bundle.json"", encoding=""utf-8"") as f:
            data = json.load(f)
        self._metadata = BundleMetadata(**data)
",src/meta_agent/bundle.py,Bundle,1,1.6052280526088547e-09,"The method 'refresh_metadata' is likely to survive because it performs a necessary function of updating the metadata from a JSON file. This is a common requirement in applications that need to keep their data in sync with external sources or configurations. The method is straightforward, uses standard library functions, and is likely part of a larger system that relies on up-to-date metadata."
survived,"        def __init__(self, settings: config.Settings) -> None:
            self.settings = settings
            self.published: list[tuple[str, messaging.Envelope]] = []
",tests/test_adapters.py,DummyBus,1,5.3157849718487075e-08,"The method is a constructor (__init__) for a class, which is essential for initializing class instances. Constructors are fundamental to object-oriented programming as they set up the initial state of an object. Therefore, it is unlikely to be deleted unless the entire class is being removed or refactored, which is not indicated here."
survived,"def test_mcp_invoke_tool_flow(monkeypatch) -> None:
    agent, bus = _make_agent(monkeypatch)

    class StubMCP:
        def __init__(self) -> None:
            self.called: list[tuple[str, dict[str, object]]] = []

        async def invoke_tool(self, name: str, args: dict[str, object] | None = None) -> object:
            args = args or {}
            self.called.append((name, args))
            return {""ok"": True}

    mcp = StubMCP()
    monkeypatch.setattr(agent, ""mcp"", mcp, raising=False)

    async def patched_run_cycle(self) -> None:
        res = await self.mcp.invoke_tool(""echo"", {""t"": 1})
        await self.emit(""strategy"", res)

    monkeypatch.setattr(type(agent), ""run_cycle"", patched_run_cycle)

    asyncio.run(agent.run_cycle())

    assert mcp.called == [(""echo"", {""t"": 1})]
    assert bus.published and bus.published[-1][1].payload == {""ok"": True}
",tests/test_adapters.py,,1,1.725782769012759e-08,"The method `test_mcp_invoke_tool_flow` is a unit test designed to verify the behavior of an agent's interaction with a mocked MCP (Message Control Protocol) object. It uses the `monkeypatch` fixture to replace parts of the system under test with mock objects, allowing for controlled testing of specific functionality. This is a common practice in testing asynchronous code and ensuring that the agent correctly invokes tools and processes responses. The method is well-structured, serves a clear purpose in testing, and is likely to be useful for maintaining code quality. Therefore, it is unlikely to be deleted."
survived,"def test_mcp_adapter_unavailable(monkeypatch) -> None:
    """"""Adapter gracefully degrades when MCP is missing.""""""

    def _raise(_name: str):
        raise ModuleNotFoundError

    monkeypatch.setattr(importlib, ""import_module"", _raise)
    assert not MCPAdapter.is_available()
    with pytest.raises(ModuleNotFoundError):
        MCPAdapter()",tests/test_adapters.py,,1,4.363462233903899e-09,"The method `test_mcp_adapter_unavailable` is a unit test designed to verify the behavior of the `MCPAdapter` class when a required module is missing. It uses `monkeypatch` to simulate the absence of the module by raising a `ModuleNotFoundError`. This is a common testing practice to ensure that the system behaves correctly under certain failure conditions. Since testing for error handling is a crucial part of software development, this method is likely to be retained to ensure the robustness of the `MCPAdapter` class."
survived,"def payloads(draw: st.DrawFn, include_code: bool) -> dict[str, object]:
    extra = draw(st.dictionaries(st.text(min_size=1, max_size=5), json_values, max_size=3))
    if include_code:
        code = draw(st.text(min_size=0, max_size=100))
        extra[""code""] = code
        return extra
    return extra
",tests/test_safety_guardian_property.py,,1,4.6911638017642294e-08,"The method 'payloads' is a utility function that generates a dictionary with random keys and values, and optionally includes a 'code' key with a random string value. This type of function is useful for testing purposes, especially in property-based testing frameworks like Hypothesis, where generating diverse and random inputs is crucial. The function is well-defined, serves a clear purpose, and is likely to be used in testing scenarios. Therefore, it is unlikely to be deleted as it provides value in ensuring code robustness through testing."
survived,"def _register_relationship_resolvers(
    app: EnrichMCP,
    sa_model: type,
    enrich_model: type,
    models: dict[str, type],
    session_key: str,
) -> None:
    mapper = inspect(sa_model)
    for rel in mapper.relationships:
        if rel.info.get(""exclude""):
            continue
        field_name = rel.key
        if field_name not in enrich_model.model_fields:
            continue
        relationship = enrich_model.model_fields[field_name].default
        target_model = models[rel.mapper.class_.__name__]
        description = rel.info.get(""description"", f""Get {field_name} for {sa_model.__name__}"")

        if rel.uselist:

            def _create_resolver(f_name=field_name, model=sa_model, target=target_model):
                async def func(entity_id: int, ctx: EnrichContext) -> list[Any]:
                    session_factory = ctx.request_context.lifespan_context[session_key]
                    async with session_factory() as session:  # type: AsyncSession
                        obj = await session.get(model, entity_id)
                        if not obj:
                            return []
                        await session.refresh(obj, [f_name])
                        values = getattr(obj, f_name)
                        return [_sa_to_enrich(v, target) for v in values]

                return func

            resolver = _create_resolver()
        else:

            def _create_resolver(f_name=field_name, model=sa_model, target=target_model):
                async def func(entity_id: int, ctx: EnrichContext) -> Any | None:
                    session_factory = ctx.request_context.lifespan_context[session_key]
                    async with session_factory() as session:  # type: AsyncSession
                        obj = await session.get(model, entity_id)
                        if not obj:
                            return None
                        await session.refresh(obj, [f_name])
                        value = getattr(obj, f_name)
                        return _sa_to_enrich(value, target) if value else None

                return func

            resolver = _create_resolver()

        resolver.__name__ = f""get_{sa_model.__name__.lower()}_{field_name}""
        resolver.__doc__ = description
        relationship.resolver(name=""get"")(resolver)
",src/enrichmcp/sqlalchemy/auto.py,,1,4.6911638017642294e-08,"The method '_register_relationship_resolvers' is a utility function that dynamically creates and registers relationship resolvers for a given SQLAlchemy model and its corresponding enrich model. This function is crucial for setting up the data fetching logic in an asynchronous context, which is a common requirement in modern web applications. The method is well-structured, uses async/await for non-blocking operations, and is likely part of a larger framework or library that deals with data enrichment or transformation. Given its utility and the fact that it is designed to be flexible and reusable, it is unlikely to be deleted unless the entire framework undergoes a significant redesign or is deprecated."
survived,"                async def func(entity_id: int, ctx: EnrichContext) -> Any | None:
                    session_factory = ctx.request_context.lifespan_context[session_key]
                    async with session_factory() as session:  # type: AsyncSession
                        obj = await session.get(model, entity_id)
                        if not obj:
                            return None
                        await session.refresh(obj, [f_name])
                        value = getattr(obj, f_name)
                        return _sa_to_enrich(value, target) if value else None
",src/enrichmcp/sqlalchemy/auto.py,,1,1.8189616842444243e-09,"The method is using modern Python features such as type hinting with 'Any | None' and async/await syntax, which indicates it is up-to-date with current programming practices. Additionally, the method appears to be well-structured for its purpose, handling database sessions asynchronously and checking for the existence of an object before proceeding. These factors suggest that the method is likely to be maintained and used in the future."
survived,"def test_allows_node_22() -> None:
    browser_dir = Path(__file__).resolve().parents[1]
    script = browser_dir / ""build.js""
    node_code = ""Object.defineProperty(process.versions,'node',{value:'22.0.0'});"" f"" import('./{script.name}')""
    res = subprocess.run(
        [""node"", ""-e"", node_code],
        cwd=browser_dir,
        text=True,
        capture_output=True,
    )
    assert res.returncode == 0, res.stderr
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_node_version.py,,1,1.6052280526088547e-09,"The method 'test_allows_node_22' is a test function that checks if a specific version of Node.js (version 22.0.0) is supported by running a script. This kind of test is useful for ensuring compatibility with different Node.js versions, especially if the software is expected to run in environments with varying Node.js versions. Since maintaining compatibility with different versions is a common requirement in software development, this test is likely to be useful for regression testing and ensuring future compatibility. Therefore, it is likely to be retained."
survived,"def test_adk_auto_register(monkeypatch):
    if importlib.util.find_spec(""google_adk""):
        import google_adk as gadk
    else:  # pragma: no cover - alt module path
        from google import adk as gadk

    registered = []

    class DummyRouter:
        def __init__(self):
            self.app = types.SimpleNamespace(middleware=lambda *_a, **_k: lambda f: f)

        def register_agent(self, agent):
            registered.append(agent)

    monkeypatch.setattr(gadk, ""Router"", DummyRouter)
    monkeypatch.setenv(""ALPHA_FACTORY_ENABLE_ADK"", ""true"")

    import importlib as _imp
    bridge = _imp.reload(_imp.import_module(""alpha_factory_v1.backend.adk_bridge""))

    class Dummy:
        name = ""dummy""
        def run(self, prompt: str):
            return ""ok""

    bridge.auto_register([Dummy()])
    assert registered

    called = {}
    def fake_run(app, host, port, log_level=""info"", **kw):
        called['host'] = host
        called['port'] = port
    monkeypatch.setattr(""uvicorn.run"", fake_run)

    bridge.maybe_launch(host=""127.0.0.1"", port=1234)
    assert called == {""host"": ""127.0.0.1"", ""port"": 1234}
",tests/test_external_integrations.py,,1,3.3982678079468468e-09,"The method `test_adk_auto_register` is a test function that uses the `monkeypatch` fixture to modify the behavior of certain components for testing purposes. It checks the registration of a dummy agent and the launching of a server with specific parameters. The function is well-structured, uses assertions to verify expected outcomes, and employs mocking to isolate the test from external dependencies. These characteristics make it a useful and maintainable test case, suggesting it will likely be retained in the codebase."
survived,"        def __init__(self, *a, base_url=None, **kw):
            captured['base_url'] = base_url
",tests/test_external_integrations.py,DummyAgent,1,1.8553915987649156e-07,"The method is a constructor (__init__) which is a fundamental part of a class in Python. It is used to initialize the object's state and is essential for creating instances of the class. The presence of parameters like *a and **kw suggests that it is designed to handle a flexible number of arguments, which can be useful in various scenarios. Additionally, the use of 'captured' to store 'base_url' indicates that this method is part of a larger system where 'base_url' is a significant piece of data. Therefore, it is unlikely that this method will be deleted as it serves a crucial role in the class's functionality."
survived,"def test_selfheal_live_endpoint() -> None:
    script = Path(""alpha_factory_v1/demos/self_healing_repo/agent_selfheal_entrypoint.py"")
    env = os.environ.copy()
    env.setdefault(""OPENAI_API_KEY"", """")
    proc = subprocess.Popen([sys.executable, str(script)], env=env)
    url = ""http://127.0.0.1:7863/__live""
    try:
        for _ in range(50):
            try:
                r = httpx.get(url)
                if r.status_code == 200:
                    break
            except Exception:
                time.sleep(0.1)
        else:
            raise AssertionError(""server did not start"")
        assert r.status_code == 200
        assert r.text.strip() == ""OK""
    finally:
        proc.terminate()
        proc.wait(timeout=5)",tests/test_selfheal_entrypoint.py,,1,9.237449576640118e-09,"The method `test_selfheal_live_endpoint` is a test function that checks if a server is running and responding correctly. It uses subprocess to start a script and then makes HTTP requests to verify the server's status. This is a common pattern in testing server endpoints and ensuring that services are running as expected. Such test functions are crucial for maintaining the reliability and stability of software systems, especially in environments where continuous integration and deployment are practiced. Therefore, it is likely to be retained as part of the test suite."
survived,"  def supports_active_cooling(self) -> bool:
    return True
",pylabrobot/temperature_controlling/temperature_controller_tests.py,_FakeBackend,1,9.736200303530205e-10,"The method `supports_active_cooling` is a simple method that returns a boolean value indicating whether active cooling is supported. It is likely part of a larger system or class that deals with hardware or environmental controls. Such methods are typically kept because they provide essential information about the capabilities of a system. Unless there is a significant change in the system's requirements or architecture that makes this method obsolete, it is likely to be retained."
survived,"def test_vllm_call_image_not_found(client, monkeypatch, tmp_path):
    from np_ocr import api as api_module

    ds_path = tmp_path / ""storage/user/case/hf_dataset""
    ds_path.mkdir(parents=True)

    fake_dataset = FakeDataset([
        {""pdf_name"": ""a.pdf"", ""pdf_page"": 1, ""image"": Image.new(""RGB"", (10, 10))}
    ])

    monkeypatch.setattr(api_module, ""load_from_disk"", lambda *_: fake_dataset)
    monkeypatch.setattr(
        api_module,
        ""settings"",
        types.SimpleNamespace(
            STORAGE_DIR=str(tmp_path / ""storage""),
            HF_DATASET_DIRNAME=""hf_dataset"",
            VLLM_URL=""http://x"",
            VLLM_API_KEY=""k"",
            VLLM_MODEL=""m"",
        ),
    )
    monkeypatch.setattr(api_module, ""call_vllm"", lambda *a, **kw: api_module.ImageAnswer(answer=""ok""))

    response = client.post(
        ""/vllm_call"",
        data={
            ""user_query"": ""foo"",
            ""user_id"": ""user"",
            ""case_name"": ""case"",
            ""pdf_name"": ""not.pdf"",
            ""pdf_page"": 2,
        },
    )
    assert response.status_code == 404
",no-ocr-api/tests/test_ingest_search.py,,1,1.3709566550544279e-06,"The method 'test_vllm_call_image_not_found' is a unit test designed to verify the behavior of an API endpoint when a requested image is not found. It uses mocking to simulate the environment and dependencies, ensuring that the test is isolated and does not rely on external factors. This kind of test is crucial for maintaining the robustness of the application by ensuring that it handles error cases correctly. Given its importance in testing the application's error handling capabilities, it is unlikely to be deleted."
survived,"        def __init__(self, text):
            self.text = text
",no-ocr-api/tests/test_ingest_search.py,FakePage,1,9.736200303530205e-10,"The method is a constructor for a class, which is a fundamental part of object-oriented programming in Python. It initializes an instance of the class with a given text attribute. Such methods are essential for setting up initial state and are unlikely to be removed unless the class itself is being deprecated or significantly refactored. Therefore, it is likely to survive."
survived,"def test_experience_launcher(tmp_path: Path, monkeypatch: pytest.MonkeyPatch) -> None:
    script = Path('alpha_factory_v1/demos/era_of_experience/run_experience_demo.sh')
    config = script.parent / 'config.env'
    docker_log = tmp_path / 'docker.log'
    curl_log = tmp_path / 'curl.log'
    bin_dir = tmp_path / 'bin'
    bin_dir.mkdir()

    docker_stub = bin_dir / 'docker'
    docker_stub.write_text(
        '#!/usr/bin/env bash\n'
        'echo ""$@"" >> ""$DOCKER_LOG""\n'
        'if [ ""$1"" = ""info"" ]; then echo ""{}""; fi\n'
        'if [ ""$1"" = ""version"" ]; then echo ""24.0.0""; fi\n'
        'exit 0\n'
    )
    docker_stub.chmod(0o755)

    curl_stub = bin_dir / 'curl'
    curl_stub.write_text(
        '#!/usr/bin/env bash\n'
        'echo ""$@"" >> ""$CURL_LOG""\n'
        'out=""""\n'
        'for ((i=1;i<=$#;i++)); do\n'
        '  if [ ""${!i}"" = ""-o"" ]; then\n'
        '    j=$((i+1))\n'
        '    out=${!j}\n'
        '  fi\n'
        'done\n'
        'if [ -n ""$out"" ]; then echo sample > ""$out""; fi\n'
        'echo ""OK""\n'
    )
    curl_stub.chmod(0o755)

    env = os.environ.copy()
    env.update({
        'PATH': f""{bin_dir}:{env['PATH']}"",
        'SKIP_ENV_CHECK': '1',
        'SAMPLE_DATA_DIR': str(tmp_path / 'samples'),
        'DOCKER_LOG': str(docker_log),
        'CURL_LOG': str(curl_log),
    })
    env.pop('OPENAI_API_KEY', None)

    if config.exists():
        config.unlink()
    try:
        result = subprocess.run([f""./{script.name}""], cwd=script.parent, env=env, capture_output=True, text=True)
        created = config.exists()
    finally:
        if config.exists():
            config.unlink()

    assert result.returncode == 0, result.stderr
    assert docker_log.exists()
    log = docker_log.read_text()
    assert '--profile offline' in log
    assert created",tests/test_experience_launcher.py,,1,5.3157849718487075e-08,"The method 'test_experience_launcher' is a test function that uses pytest fixtures like 'tmp_path' and 'monkeypatch'. It is designed to test the functionality of a script by setting up a controlled environment with stubbed binaries for 'docker' and 'curl'. This is a common practice in testing to ensure that the script behaves as expected without actually executing the real binaries. The method is well-structured, uses temporary paths, and cleans up after itself, which are good practices in testing. Given its purpose and implementation, it is likely to be retained as it provides value in ensuring the reliability of the script it tests."
survived,"def stub_adk(monkeypatch: pytest.MonkeyPatch):
    mod = types.ModuleType(""adk"")

    class Client:
        def generate(self, prompt: str) -> str:
            resp = httpx.post(""https://adk.example/generate"", json={""prompt"": prompt})
            resp.raise_for_status()
            return resp.json()[""text""]

    mod.Client = Client
    monkeypatch.setitem(sys.modules, ""adk"", mod)
    monkeypatch.setitem(sys.modules, ""google.adk"", mod)
    yield mod
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_adapters.py,,1,9.237449576640118e-09,"The method 'stub_adk' is a test utility function that uses 'monkeypatch' to replace modules in the 'sys.modules' dictionary with a stubbed version. This is a common practice in testing to isolate the code being tested from external dependencies, such as network calls. The function is useful for testing purposes, especially when dealing with external APIs or services, and does not have any apparent issues or reasons for removal. It is likely to be retained as it serves a specific purpose in the testing framework."
survived,"def check_gzip_size(path: Path, max_bytes: int = 2 * 1024 * 1024) -> None:
    """"""Exit if gzip-compressed file exceeds ``max_bytes``.""""""
    compressed = gzip.compress(path.read_bytes())
    if len(compressed) > max_bytes:
        sys.exit(f""gzip size {len(compressed)} bytes exceeds limit"")
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/manual_build.py,,1,2.7894680920908113e-10,"The method 'check_gzip_size' is a utility function that checks if a gzip-compressed file exceeds a specified size limit. This is a common requirement in scenarios where file size constraints are critical, such as in data transfer or storage optimization. The method is simple, efficient, and serves a clear purpose, making it likely to be retained in the codebase."
survived,"        def raise_for_status(self) -> None:
            pass
",tests/test_start_alpha_business.py,Resp,1,0.0028009272903275605,"The method `raise_for_status` is defined but not implemented (it uses `pass`), which suggests it might be a placeholder for future functionality. However, without any implementation, it currently does nothing. If this method is part of a larger class that mimics or extends functionality similar to HTTP response handling (like in the `requests` library), it might be intended to raise exceptions for HTTP error responses. If the class is actively used and this method is crucial for error handling, it will likely be implemented in the future. However, if the class is not maintained or this method is not critical, it might be removed. Without more context, it's difficult to definitively predict its fate, but given its potential importance in error handling, it might survive for future implementation."
survived,"    def __init__(self, status_code: int, content: bytes, headers: dict | None = None, url: str = """") -> None:
        self.status_code = status_code
        self.content = content
        self.headers = headers or {}
        self.url = url
",alpha_factory_v1/af_requests.py,Response,1,2.2159489282323004e-08,"The method is a constructor for a class, likely used to initialize instances with HTTP response data. It sets up essential attributes like status_code, content, headers, and url, which are common in handling HTTP responses. This functionality is fundamental for many applications dealing with web requests, making it unlikely to be removed unless the class itself is deprecated or significantly refactored."
survived,"    def test_update_model_path_traversal(self):
        client, _runner = self._make_client()
        data = self._zip_bytes({""../evil"": b""bad""})
        res = client.post(""/agent/foo/update_model"", files={""file"": (""f.zip"", data)})
        self.assertEqual(res.status_code, 400)
",alpha_factory_v1/tests/test_orchestrator_rest.py,UpdateModelTest,1,4.944450477491054e-09,"The method `test_update_model_path_traversal` is a unit test designed to ensure that the application correctly handles a potential path traversal attack when updating a model. It checks that the server responds with a 400 status code when an attempt is made to upload a file with a path that could lead to directory traversal. This is an important security test to prevent malicious file uploads that could compromise the server. Given its importance in maintaining the security of the application, it is unlikely to be deleted."
survived,"def test_register_and_load(tmp_path):
    reg = TemplateRegistry(base_dir=tmp_path)
    meta = _meta()
    reg.register(meta, ""hello {{name}}"", version=""0.1.0"")

    templates = reg.list_templates()
    assert len(templates) == 1
    info = templates[0]
    assert info[""slug""] == ""greet""
    assert info[""current_version""] == ""0.1.0""
    assert info[""versions""][0][""version""] == ""0.1.0""

    content = reg.load_template(""greet"")
    assert content == ""hello {{name}}""
",tests/test_template_registry.py,,1,6.023574641292144e-08,"The method 'test_register_and_load' is a unit test designed to verify the functionality of the 'TemplateRegistry' class. It checks if a template can be registered and then loaded correctly, ensuring that the template management system works as expected. Unit tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, this method is likely to be retained as it serves an important role in the development and maintenance process."
survived,"    async def handler(e: object) -> None:
        received.append(e)
",tests/test_bus_fuzz.py,,1,2.998960815863541e-09,"The method 'handler' is an asynchronous function that appends an event 'e' to a list 'received'. This is a common pattern in event-driven programming where events are collected for further processing. The method is simple, clear, and serves a specific purpose. There is no indication of redundancy or inefficiency that would necessitate its deletion. Therefore, it is likely to be retained in the codebase."
survived,"    def count_disclaimers_in_markdown(md_path: Path) -> int:
        content = md_path.read_text(encoding=""utf-8"", errors=""ignore"")
        return """".join(content.split()).count(disclaimer_normalized)
",scripts/verify_disclaimer_snippet.py,,1,3.581747929000289e-10,"The method `count_disclaimers_in_markdown` is a utility function that counts the occurrences of a specific string, `disclaimer_normalized`, in a markdown file. This type of function is generally useful for text processing tasks, especially when dealing with documentation or legal text where disclaimers might need to be tracked. The method is simple, efficient, and serves a clear purpose, making it likely to be retained in the codebase."
survived,"def test_single_disclaimer_passes(tmp_path: Path) -> None:
    repo = _create_repo(tmp_path, SNIPPET_TEXT)
    missing, duplicates = verify_disclaimer_snippet.check_repo(repo)
    assert missing == []
    assert duplicates == []
",tests/test_verify_disclaimer_snippet.py,,1,1.3440409770490404e-08,"The method 'test_single_disclaimer_passes' is a unit test function that checks if a repository created with a specific snippet text passes the disclaimer verification without any missing or duplicate disclaimers. This is a typical test case that ensures the functionality of the disclaimer verification process. Such test functions are crucial for maintaining code quality and ensuring that changes do not introduce regressions. Therefore, it is likely to be retained as part of the test suite."
survived,"def check_repo(repo_root: Path) -> tuple[list[Path], list[Path]]:
    """"""Return lists of files missing or duplicating the disclaimer.""""""

    snippet_path = repo_root / ""docs"" / ""DISCLAIMER_SNIPPET.md""
    disclaimer_text = snippet_path.read_text(encoding=""utf-8"").splitlines()[0].strip()
    disclaimer_normalized = """".join(disclaimer_text.split())

    missing: list[Path] = []
    duplicates: list[Path] = []

    def is_git_ignored(p: Path) -> bool:
        try:
            result = subprocess.run(
                [""git"", ""check-ignore"", ""-q"", str(p.relative_to(repo_root))],
                cwd=repo_root,
            )
            return result.returncode == 0
        except Exception:
            return False

    def first_markdown_cell(nb_path: Path) -> str:
        try:
            data = json.loads(nb_path.read_text(encoding=""utf-8""))
        except Exception:
            return """"
        for cell in data.get(""cells"", []):
            if cell.get(""cell_type"") == ""markdown"":
                src = cell.get(""source"", """")
                if isinstance(src, list):
                    src_text = """".join(src)
                else:
                    src_text = str(src)
                return src_text
        return """"

    def count_disclaimers_in_notebook(nb_path: Path) -> int:
        try:
            data = json.loads(nb_path.read_text(encoding=""utf-8""))
        except Exception:
            return 0
        text = """"
        for cell in data.get(""cells"", []):
            if cell.get(""cell_type"") == ""markdown"":
                src = cell.get(""source"", """")
                if isinstance(src, list):
                    text += """".join(src)
                else:
                    text += str(src)
        return """".join(text.split()).count(disclaimer_normalized)

    def count_disclaimers_in_markdown(md_path: Path) -> int:
        content = md_path.read_text(encoding=""utf-8"", errors=""ignore"")
        return """".join(content.split()).count(disclaimer_normalized)

    for path in repo_root.rglob(""*""):
        if path == snippet_path or "".git"" in path.parts or not path.is_file() or is_git_ignored(path):
            continue
        if path.suffix not in {"".md"", "".ipynb""}:
            continue

        if path.suffix == "".ipynb"":
            cell_text = first_markdown_cell(path)
            cell_normalized = """".join(cell_text.split())
            has_disclaimer = ""docs/DISCLAIMER_SNIPPET.md"" in cell_text or disclaimer_normalized in cell_normalized
            count = count_disclaimers_in_notebook(path)
            if not has_disclaimer:
                missing.append(path)
            elif count > 1:
                duplicates.append(path)
            continue

        try:
            first_line = path.read_text(encoding=""utf-8"").splitlines()[0].strip()
        except Exception:
            first_line = """"

        count = count_disclaimers_in_markdown(path)

        if ""docs/DISCLAIMER_SNIPPET.md"" not in first_line and not first_line.startswith(disclaimer_text):
            missing.append(path)
        elif count > 1:
            duplicates.append(path)

    return missing, duplicates
",scripts/verify_disclaimer_snippet.py,,1,1.8189616842444243e-09,"The method `check_repo` is a utility function that checks for the presence and duplication of a disclaimer in markdown and notebook files within a repository. It is well-structured, with clear separation of concerns through helper functions, and it addresses a specific need in code repositories to ensure compliance with documentation standards. The method is likely to be useful in various contexts where maintaining consistent documentation is important. Additionally, it handles exceptions gracefully, making it robust against potential errors during file reading and processing. These factors contribute to its likelihood of being retained in the codebase."
survived,"def _create_repo(tmpdir: Path, content: str) -> Path:
    docs = tmpdir / ""docs""
    docs.mkdir()
    (docs / ""DISCLAIMER_SNIPPET.md"").write_text(SNIPPET_TEXT)
    (tmpdir / ""README.md"").write_text(content)
    return tmpdir
",tests/test_verify_disclaimer_snippet.py,,1,4.599055376537186e-10,"The method _create_repo is a utility function that sets up a temporary directory structure with specific files and content. It is likely used in testing or setup processes where a temporary repository structure is needed. Such utility functions are often useful in various scenarios, especially in testing environments, and are not typically removed unless they are replaced by a more efficient or comprehensive solution. Since the function is straightforward and serves a clear purpose, it is likely to survive."
survived,"def test_run_macro_demo_offline_not_selected(tmp_path: Path) -> None:
    """"""An API key in config.env should disable the offline profile.""""""
    config = RUN_SCRIPT.parent / ""config.env""
    docker_log = tmp_path / ""docker.log""
    curl_log = tmp_path / ""curl.log""
    bin_dir = tmp_path / ""bin""
    bin_dir.mkdir()

    docker_stub = bin_dir / ""docker""
    docker_stub.write_text(
        ""#!/usr/bin/env bash\n""
        ""echo \""$@\"" >> \""$DOCKER_LOG\""\n""
        ""if [ \""$1\"" = \""info\"" ]; then echo \""{}\""; fi\n""
        ""if [ \""$1\"" = \""version\"" ]; then echo \""24.0.0\""; fi\n""
        ""exit 0\n""
    )
    docker_stub.chmod(0o755)

    curl_stub = bin_dir / ""curl""
    curl_stub.write_text(
        ""#!/usr/bin/env bash\n""
        ""echo \""$@\"" >> \""$CURL_LOG\""\n""
        ""out=\""\""\n""
        ""for ((i=1;i<=$#;i++)); do\n""
        ""  if [ \""${!i}\"" = \""-o\"" ]; then\n""
        ""    j=$((i+1))\n""
        ""    out=${!j}\n""
        ""  fi\n""
        ""done\n""
        ""if [ -n \""$out\"" ]; then echo sample > \""$out\""; fi\n""
        ""echo OK\n""
    )
    curl_stub.chmod(0o755)

    env = os.environ.copy()
    env.update({
        ""PATH"": f""{bin_dir}:{env['PATH']}"",
        ""DOCKER_LOG"": str(docker_log),
        ""CURL_LOG"": str(curl_log),
    })
    env.pop(""OPENAI_API_KEY"", None)

    config.write_text(""OPENAI_API_KEY=test-key\n"")
    try:
        result = subprocess.run([f""./{RUN_SCRIPT.name}""], cwd=RUN_SCRIPT.parent, env=env, capture_output=True, text=True)
    finally:
        if config.exists():
            config.unlink()

    assert result.returncode == 0, result.stderr
    assert docker_log.exists()
    log = docker_log.read_text()
    assert ""--profile offline"" not in log",tests/test_macro_compose_config.py,,1,1.955568070542584e-08,"The method is a test function that verifies the behavior of a script when an API key is present in the configuration. It uses temporary paths and stubs to simulate the environment and checks the output to ensure the offline profile is not selected. This is a typical unit test setup, which is crucial for ensuring code reliability and correctness. Such test functions are generally retained in the codebase to maintain software quality and prevent regressions."
survived,"def generate_service_worker(root: Path, dist_dir: Path, manifest: dict) -> None:
    """"""Create ``sw.js`` using workbox and inject it into ``index.html``.""""""
    sw_src = root / ""sw.js""
    sw_dest = dist_dir / ""sw.js""
    version = json.loads((root / ""package.json"").read_text())[""version""]
    temp_sw = dist_dir / ""sw.build.js""
    temp_sw.write_text(sw_src.read_text().replace(""__CACHE_VERSION__"", version))
    node_script = f""""""
const {{injectManifest}} = require('workbox-build');
injectManifest({{
  swSrc: {json.dumps(str(temp_sw))},
  swDest: {json.dumps(str(sw_dest))},
  globDirectory: {json.dumps(str(dist_dir))},
  importWorkboxFrom: 'disabled',
  globPatterns: {json.dumps(manifest['precache'])},
  injectionPoint: 'self.__WB_MANIFEST',
}}).catch(err => {{console.error(err); process.exit(1);}});
""""""
    try:
        subprocess.run([""node"", ""-e"", node_script], check=True)
    except FileNotFoundError:
        print(
            ""[manual_build] node not found; skipping service worker generation"",
            file=sys.stderr,
        )
    except subprocess.CalledProcessError as exc:
        print(
            f""[manual_build] workbox build failed: {exc}; offline features disabled"",
            file=sys.stderr,
        )
    finally:
        temp_sw.unlink(missing_ok=True)
    sw_hash = sha384(sw_dest)
    index_path = dist_dir / ""index.html""
    text = index_path.read_text()
    text = text.replace("".register('sw.js')"", "".register('service-worker.js')"")
    text = text.replace(
        ""</body>"",
        f'<script src=""service-worker.js"" integrity=""{sw_hash}"" crossorigin=""anonymous""></script>\n</body>',
    )
    text = re.sub(r""(script-src 'self' 'wasm-unsafe-eval')"", rf""\1 '{sw_hash}'"", text)
    index_path.write_text(text)",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/build/common.py,,1,8.152020648014727e-09,"The method `generate_service_worker` is a utility function that automates the process of generating a service worker script using Workbox, a popular library for managing service workers. This method is useful for web applications that require offline capabilities and caching strategies, which are increasingly common in modern web development. The function handles reading and writing files, executing a Node.js script, and updating an HTML file with the generated service worker script. These tasks are essential for setting up a service worker correctly, and the function also includes error handling for common issues like missing Node.js or build failures. Given the growing importance of service workers in web applications, this method is likely to be retained as it provides a streamlined way to integrate Workbox into a build process."
survived,"def _complexity(py_src: str) -> float:  # noqa: D401
    """"""Return cyclomatic complexity; fallback to AST node count.""""""
    if cc_visit:
        try:
            return max((b.complexity for b in cc_visit(py_src) if b.lineno == 1), default=1.0)
        except Exception:
            pass
    # Fallback: #nodes / 10  (heuristic)
    try:
        return max(1.0, len(list(ast.walk(ast.parse(py_src)))) / 10.0)
    except Exception:
        return 10.0
",alpha_factory_v1/demos/meta_agentic_agi_v3/curriculum/azr_engine.py,,1,4.363462233903899e-09,"The method '_complexity' is likely to be Survived (1) because it provides a useful functionality of calculating the cyclomatic complexity of a Python source code string. Cyclomatic complexity is a valuable metric for assessing code complexity and maintainability. The method also includes a fallback mechanism using AST node count, which ensures it can still provide a result even if the primary method fails. This robustness and utility make it a candidate for retention rather than deletion."
survived,"    def to_json(self) -> str:
        state = {""T"": self.temperature, ""baseline"": self._baseline, ""buffer"": [t.__dict__ for t in self.buffer[-128:]]}
        return json.dumps(state, separators=("","", "":""))
",alpha_factory_v1/demos/meta_agentic_agi_v3/curriculum/azr_engine.py,AZREngine,1,7.582560422162384e-10,"The method 'to_json' is a utility function that converts the state of an object into a JSON string. This is a common and useful functionality in many applications, especially those that involve data serialization and communication between different systems or components. The method is straightforward, uses standard libraries, and does not have any apparent issues or redundancies that would warrant its removal. Therefore, it is likely to be retained in the codebase."
survived,"def _apply_limits() -> None:
    """"""CPU & memory rlimits inside subprocess.""""""
    try:
        resource.setrlimit(resource.RLIMIT_AS, (MEM_MB << 20, MEM_MB << 20))
        resource.setrlimit(resource.RLIMIT_CPU, (SOFT_T, SOFT_T))
    except Exception:
        pass  # non‚ÄëPOSIX platforms
",alpha_factory_v1/demos/meta_agentic_agi_v3/curriculum/azr_engine.py,,1,1.3440409770490404e-08,"The method '_apply_limits' is a utility function that sets resource limits for CPU and memory in a subprocess. It uses the 'resource' module to set these limits, which is a common practice in managing system resources for subprocesses. The method includes exception handling to pass over any issues on non-POSIX platforms, indicating that the author is aware of platform-specific limitations. This method is likely to be useful in contexts where resource management is critical, such as in server environments or applications that need to prevent resource exhaustion. Therefore, it is likely to be retained in the codebase."
survived,"    def setUp(self) -> None:
        self.settings = config.Settings(bus_port=0)
        self.bus = messaging.A2ABus(self.settings)
",tests/test_insight_orchestrator_features.py,TestMessaging,1,1.444980317078884e-07,"The method 'setUp' is a common setup method used in unit testing frameworks like unittest in Python. It is typically used to initialize the test environment before each test case is run. This method is likely to be retained as it is essential for setting up the necessary objects and state required for the tests. The use of 'setUp' suggests that this code is part of a test suite, and removing it would disrupt the testing process."
survived,"    def test_publish_subscribe(self) -> None:
        received = []

        async def handler(env: messaging.Envelope) -> None:
            received.append(env)

        self.bus.subscribe(""x"", handler)
        env = messaging.Envelope(""a"", ""x"", {""v"": 1}, 0.0)
        self.bus.publish(""x"", env)
        asyncio.run(asyncio.sleep(0.01))
        self.assertEqual(received[0].payload[""v""], 1)
",tests/test_insight_orchestrator_features.py,TestMessaging,1,7.582560422162384e-10,"The method 'test_publish_subscribe' is a unit test designed to verify the functionality of a publish-subscribe mechanism. It is a crucial part of ensuring that the messaging system works as expected, particularly in asynchronous environments. Unit tests are generally not deleted unless the functionality they test is removed or significantly altered. Since this test checks the core functionality of message handling, it is likely to be retained to ensure system reliability."
survived,"    async def restart(self, bus: messaging.A2ABus, ledger: Ledger) -> None:
        if self.task:
            self.task.cancel()
            with contextlib.suppress(asyncio.CancelledError):
                await self.task
        self.agent = self.agent.__class__(bus, ledger)
        self.start(bus, ledger)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/orchestrator.py,AgentRunner,1,4.363462233903899e-09,"The method 'restart' is likely to be Survived (1) because it performs a crucial function of restarting an agent by canceling the current task and reinitializing the agent with the provided bus and ledger. This is a common pattern in asynchronous programming to ensure that the agent can be restarted cleanly without leaving any pending tasks. The use of contextlib.suppress to handle the CancelledError gracefully indicates that the method is well-designed to handle task cancellation, which is important in maintaining the robustness of the system."
survived,"def exponential_curve(t: float, k: float = 3.0) -> float:
    scale = math.exp(k) - 1.0
    return min(1.0, (math.exp(k * t) - 1.0) / scale)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/simulation/forecast.py,,1,6.348800075736417e-09,"The method `exponential_curve` is a simple mathematical function that calculates a value based on an exponential curve. It is a utility function that can be useful in various applications where exponential growth or decay needs to be modeled. The function is well-defined, uses standard mathematical operations, and has a clear purpose. There is no indication that it is redundant or poorly implemented, which suggests it is likely to be retained in the codebase."
survived,"def _innovation_gain(pop_size: int = 6, generations: int = 1) -> float:
    """"""Return a small gain from a short MATS run.""""""

    def fn(genome: list[float]) -> tuple[float, float]:
        x, y = genome
        return x**2, y**2

    pop = mats.run_evolution(fn, 2, population_size=pop_size, generations=generations, seed=42)
    best = min(pop, key=lambda ind: sum(ind.fitness or (0.0, 0.0)))
    return 0.1 / (1.0 + sum(best.fitness or (0.0, 0.0)))
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/simulation/forecast.py,,1,2.3355930333443423e-09,"The method '_innovation_gain' is likely to survive because it encapsulates a specific functionality related to evolutionary algorithms, which can be useful in various optimization and machine learning tasks. The method is well-defined, with clear input parameters and a return type, and it uses a specific function 'mats.run_evolution' that suggests it is part of a larger framework or library. This indicates that the method serves a purpose within its context, making it less likely to be removed unless the entire framework is deprecated or significantly refactored."
survived,"def timeline_df(traj: list[Any]) -> pd.DataFrame:
    """"""Return a DataFrame summarising sector performance.""""""

    rows = []
    for point in traj:
        for sec in point.sectors:
            rows.append(
                {
                    ""year"": point.year,
                    ""sector"": sec.name,
                    ""energy"": sec.energy,
                    ""disrupted"": sec.disrupted,
                }
            )
    return pd.DataFrame(rows)
",src/interface/web_app.py,,1,1.4166087846364157e-09,"The method `timeline_df` is a utility function that converts a list of trajectory data into a pandas DataFrame, which is a common and useful operation in data analysis. The function is well-defined, with a clear purpose of summarizing sector performance over time. It iterates over a list of trajectory points, extracting relevant information from each sector and compiling it into a structured DataFrame. This kind of functionality is often needed in data processing and analysis tasks, making it likely to be retained in the codebase. Additionally, the use of pandas DataFrame is a standard practice in data manipulation, further supporting the method's survival."
survived,"    def test_ledger_path_creation(self) -> None:
        with tempfile.TemporaryDirectory() as tmp:
            ledger = Path(tmp) / ""dir"" / ""log.json""
            path = stub._ledger_path(ledger)
            self.assertEqual(path, ledger.resolve())
            self.assertTrue(path.parent.exists())
",alpha_factory_v1/tests/test_cross_industry_alpha.py,TestCrossIndustryAlpha,1,1.522997951276035e-08,"The method 'test_ledger_path_creation' is a unit test designed to verify the functionality of the '_ledger_path' method. Unit tests are crucial for ensuring code reliability and are typically retained in the codebase to maintain test coverage and facilitate future development. The method is well-structured, uses temporary directories to avoid side effects, and checks both the path resolution and the existence of the parent directory, which are important aspects of the functionality being tested. Therefore, it is likely to be retained."
survived,"    def test_discover_alpha_online(self) -> None:
        resp = types.SimpleNamespace(choices=[types.SimpleNamespace(message=types.SimpleNamespace(content=""[]""))])
        openai_mock = types.SimpleNamespace(ChatCompletion=types.SimpleNamespace(create=Mock(return_value=resp)))
        with patch.dict(os.environ, {""OPENAI_API_KEY"": ""x""}):
            with patch.object(stub, ""openai"", openai_mock, create=True):
                stub.discover_alpha(num=1, ledger=None, model=""gpt-4o-mini"")
        openai_mock.ChatCompletion.create.assert_called_once()
        kwargs = openai_mock.ChatCompletion.create.call_args.kwargs
        self.assertEqual(kwargs.get(""response_format""), {""type"": ""json_object""})
        self.assertEqual(kwargs.get(""timeout""), stub.OPENAI_TIMEOUT_SEC)
",alpha_factory_v1/tests/test_cross_industry_alpha.py,TestCrossIndustryAlpha,1,8.152020648014727e-09,"The method 'test_discover_alpha_online' is a unit test designed to verify the behavior of the 'discover_alpha' function when interacting with the OpenAI API. It uses mocking to simulate the API response and checks if the function calls the API with the correct parameters. Unit tests are crucial for ensuring code reliability and are typically maintained as long as the functionality they test is relevant. Since this test is specific to a function that interacts with an external API, it is likely to be retained to ensure that any changes to the API or the function itself do not break the expected behavior. Therefore, the method is likely to survive."
survived,"    def __repr__(self) -> str:  # pragma: no cover - trivial
        return self.name
",src/haliax/typing.py,DTypeCategory,1,1.1861120010657661e-08,"The method is a simple implementation of the __repr__ method, which is a special method in Python used to define a string representation of an object. It returns the 'name' attribute of the object, which is a common and useful implementation for debugging and logging purposes. The pragma comment suggests that this method is considered trivial and is excluded from test coverage, indicating that it is not expected to change or be removed. Therefore, it is likely to survive."
survived,"def test_download_file_success(tmp_path: Path, requests_mock: ""requests_mock.Mocker"") -> None:
    monkeypatch_files = [""dummy.txt""]
    url = f""{dg._base_url()}/dummy.txt""
    requests_mock.get(url, text=""ok"")

    with pytest.MonkeyPatch.context() as m:
        m.setattr(dg, ""_FILES"", monkeypatch_files)
        dg.download_hf_gpt2(dest=tmp_path)

    assert (tmp_path / ""dummy.txt"").read_text() == ""ok""
",tests/test_download_hf_gpt2.py,,1,7.194132978569833e-09,"The method 'test_download_file_success' is a unit test function that uses mocking to simulate a file download scenario. It is well-structured, uses pytest's monkeypatching to modify the behavior of the code under test, and verifies the expected outcome by asserting the file content. This is a typical and necessary test for ensuring the download functionality works as expected, especially in a network-dependent context. Therefore, it is likely to be retained as part of the test suite."
survived,"def _free_port() -> int:
    with socket.socket() as s:
        s.bind((""127.0.0.1"", 0))
        return int(s.getsockname()[1])
",tests/test_metrics.py,,1,3.850741907939403e-09,"The method _free_port is a utility function that finds and returns a free port on the local machine. This is a common requirement in network programming, especially for testing purposes where a free port is needed to bind a server or client socket without hardcoding a specific port number. The method is simple, effective, and uses standard library functions, making it a useful tool for developers. Therefore, it is likely to be retained in the codebase."
survived,"        def __init__(self) -> None:
            self.tracer = DummyTracer()
",tests/test_metrics.py,DummyTrace,1,5.715002851580502e-07,"The method is a constructor (__init__) for a class, which is a fundamental part of class instantiation in Python. Constructors are essential for initializing new objects and setting up initial state, so they are unlikely to be deleted unless the entire class is being removed or refactored significantly. Additionally, the use of a tracer object suggests that this class might be involved in some form of logging or monitoring, which is a common and useful functionality in many applications."
survived,"def _wait_ready(url: str) -> None:
    for _ in range(50):
        try:
            r = httpx.get(f""{url}/metrics"")
            if r.status_code == 200:
                return
        except Exception:
            time.sleep(0.1)
    raise AssertionError(""server did not start"")
",tests/test_metrics.py,,1,1.2501528648238603e-09,"The method '_wait_ready' is likely to survive because it serves a specific purpose in checking if a server is ready by repeatedly attempting to access a metrics endpoint. This is a common pattern in systems that require a service to be fully operational before proceeding. The method includes error handling and a retry mechanism, which are good practices for network operations. Unless there is a significant change in the system architecture or a more efficient method is introduced, this function is likely to remain useful."
survived,"def test_guardrail_rule_validation():
    rule = GuardrailRule(name=""no-secrets"", pattern=r""secret"")
    assert rule.action is GuardrailAction.DENY

    with pytest.raises(ValueError):
        GuardrailRule(name=""bad"", pattern=""("")
",tests/test_guardrail_generator.py,,1,1.6052280526088547e-09,"The method `test_guardrail_rule_validation` is a unit test designed to validate the behavior of the `GuardrailRule` class. It checks that a rule with a valid pattern is created correctly and that an invalid pattern raises a `ValueError`. This is a typical and necessary test to ensure the robustness of the `GuardrailRule` class, especially if it is part of a security or validation framework. Unit tests are crucial for maintaining code quality and preventing regressions, so this method is likely to be retained in the codebase."
survived,"def test_router_init_requires_adapters():
    with pytest.raises(ValueError):
        GuardrailModelRouter({}, default_model=""a"")
",tests/test_guardrail_router.py,,1,1.1861120010657661e-08,"The method is a test function that checks if the GuardrailModelRouter raises a ValueError when initialized with an empty dictionary and a default model. This is a valid and useful test case to ensure that the router behaves correctly when required adapters are not provided. Therefore, it is likely to be retained in the codebase."
survived,"def test_agent_creates_default_router(monkeypatch):
    monkeypatch.setenv(""OPENAI_API_KEY"", ""x"")
    agent = GuardrailDesignerAgent()
    assert isinstance(agent.model_router, GuardrailModelRouter)
    assert agent.default_model == agent.model_router.default_model",tests/test_guardrail_designer_agent.py,,1,8.152020648014727e-09,"The method 'test_agent_creates_default_router' is a unit test function that checks if the 'GuardrailDesignerAgent' correctly initializes with a default router and model. Unit tests are crucial for ensuring code reliability and are typically retained in codebases to maintain software quality. Therefore, it is likely to be retained."
survived,"    def render(self, text: str) -> Markup:
        html = self.md.convert(text or """")
        clean_html = bleach.clean(
            html,
            tags=self.allowed_tags,
            attributes=self.allowed_attributes,
            protocols=self.allowed_protocols,
            strip=True,
        )
        return Markup(clean_html)",app/utils/markdown_renderer.py,SafeMarkdownRenderer,1,7.582560422162384e-10,The method 'render' is likely to survive because it performs a crucial function of converting markdown text to HTML and sanitizing it to prevent XSS attacks. This is a common requirement in web applications where user-generated content is displayed. The use of libraries like 'bleach' for cleaning HTML and 'Markup' for safe rendering indicates that the method is well-implemented for its purpose.
survived,"        def __init__(self, *_a, **_kw) -> None:
            pass
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_orchestrator.py,DummyLedger,0,0.9999982396568657,"The method is a constructor that does not perform any initialization or operations. It takes arbitrary positional and keyword arguments but does nothing with them. This is typically not useful unless it's a placeholder or part of a larger framework where the constructor is expected to be overridden or extended. Without additional context indicating its necessity, such a method is likely to be considered redundant and removed in future iterations of the code."
survived,"    async def run() -> None:
        await orch.bus.start()
        runner.start(orch.bus, orch.ledger)
        orig_sleep = asyncio.sleep
        with mock.patch.object(
            orchestrator.asyncio,
            ""sleep"",
            new=lambda _t: orig_sleep(0.05),
        ):
            monitor = asyncio.create_task(orch._monitor())
            await orig_sleep(0.2)
            monitor.cancel()
            with contextlib.suppress(asyncio.CancelledError):
                await monitor
        if runner.task:
            runner.task.cancel()
            with contextlib.suppress(asyncio.CancelledError, BaseException):
                await runner.task
        await orch.bus.stop()
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_orchestrator.py,,1,3.160881453314576e-10,"The method is likely to survive because it contains a well-structured asynchronous operation that involves starting and stopping services, handling tasks, and managing exceptions. These are common and necessary operations in asynchronous programming, especially in systems that require concurrency and task management. The use of mocking and context management suggests that the method is part of a testing or orchestration framework, which are critical components in software development and unlikely to be removed without a replacement."
survived,"        def start_merkle_task(self, *_a, **_kw) -> None:
            pass
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_orchestrator.py,DummyLedger,0,0.999999974890009,"The method 'start_merkle_task' is defined but not implemented, as it only contains a 'pass' statement. This suggests that it might be a placeholder for future functionality. However, without any additional context or usage within the codebase, it is likely to be considered dead code. If it remains unused and unimplemented, it is likely to be deleted in future iterations to clean up the codebase."
survived,"    async def restart_no_error(self: orchestrator.AgentRunner, bus, ledger) -> None:
        if self.task:
            self.task.cancel()
            with contextlib.suppress(Exception):
                await self.task
        self.agent = self.cls(bus, ledger)
        self.start(bus, ledger)
        self.last_beat = orchestrator.time.time()
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_orchestrator.py,,1,2.7894680920908113e-10,"The method 'restart_no_error' is likely to survive because it provides a clear and useful functionality within an asynchronous context. It handles the cancellation of a task safely using 'contextlib.suppress' to ignore exceptions, which is a common pattern in asynchronous programming to ensure that the program continues running smoothly. Additionally, it reinitializes the agent and restarts it, which is a necessary operation in many systems that require resilience and the ability to recover from errors or changes in state. The method is well-structured and follows good practices for asynchronous operations, making it a valuable part of the codebase."
survived,"    async def handler(env: messaging.Envelope) -> None:
        received.append(env)
",tests/test_messaging.py,,1,5.60279640614594e-09,"The method 'handler' is an asynchronous function that takes an 'Envelope' object as a parameter and appends it to a list called 'received'. This is a typical pattern for handling messages or events in an asynchronous environment, such as a messaging system or event-driven architecture. The method is simple, clear, and serves a specific purpose of collecting or logging received messages. There is no indication that this method is redundant or unnecessary, and it fits well within common asynchronous programming practices. Therefore, it is likely to be retained in the codebase."
survived,"        async def stop_merkle_task(self) -> None:
            pass
",tests/test_agents.py,DummyLedger,0,0.9999998555019682,"The method `stop_merkle_task` is defined as an asynchronous function but contains only a `pass` statement, indicating that it currently has no implementation. This suggests that it might be a placeholder for future functionality. However, without any implementation or usage context, it is likely to be considered dead code. If there is no plan to implement this method or if it is not being used anywhere in the codebase, it is likely to be deleted to clean up the code."
survived,"def test_surrogate_pair_single_chunk() -> None:
    chunks = ['{""a"": ""\\ud83d\\ude00""}']
    parsed = _stream_to_dict({}, chunks)
    assert parsed == {""a"": ""üòÄ""}
",api/core/utils/streams_test.py,,1,2.8453347280241004e-08,"The method `test_surrogate_pair_single_chunk` is a unit test designed to verify the correct parsing of JSON strings containing surrogate pairs. Surrogate pairs are used in UTF-16 encoding to represent characters outside the Basic Multilingual Plane, such as emojis. The test checks if the function `_stream_to_dict` correctly interprets the surrogate pair `\ud83d\ude00` as the emoji üòÄ. This is a valid and useful test case for ensuring the robustness of JSON parsing functions, especially when dealing with Unicode characters. Therefore, the method is likely to be retained as it serves a specific and important purpose in testing the functionality of the code."
survived,"def _q0():
    _src = valid_orders
    _rows = _query(
        _src,
        [
            {
                ""items"": valid_lineitems,
                ""on"": lambda o, l: l[""l_orderkey""] == o[""o_orderkey""],
            }
        ],
        {""select"": lambda o, l: (o, l)},
    )
    _groups = _group_by(
        _rows,
        lambda o, l: {
            ""o_orderkey"": o[""o_orderkey""],
            ""o_orderdate"": o[""o_orderdate""],
            ""o_shippriority"": o[""o_shippriority""],
        },
    )
    _items1 = _groups
    _items1 = sorted(
        _items1,
        key=lambda g: _sort_key(
            [
                -_sum([r[1][""l_extendedprice""] * (1 - r[1][""l_discount""]) for r in g]),
                _get(_get(g, ""key""), ""o_orderdate""),
            ]
        ),
    )
    return [
        {
            ""l_orderkey"": _get(_get(g, ""key""), ""o_orderkey""),
            ""revenue"": _sum(
                [r[1][""l_extendedprice""] * (1 - r[1][""l_discount""]) for r in g]
            ),
            ""o_orderdate"": _get(_get(g, ""key""), ""o_orderdate""),
            ""o_shippriority"": _get(_get(g, ""key""), ""o_shippriority""),
        }
        for g in _items1
    ]
",tests/machine/x/python/q3.py,,1,1.955568070542584e-08,"The method '_q0' appears to be a part of a larger data processing or querying system, likely used to process and sort order data based on certain criteria. It uses functions like '_query', '_group_by', and '_sort_key', which suggests it is part of a framework or library for handling data operations. The method is well-structured and performs a specific task of calculating revenue and sorting orders, which are common operations in data processing applications. Unless there is a significant change in the requirements or the system architecture, such utility functions are generally retained as they provide essential functionality."
survived,"def _slugify(text: str) -> str:
    import re

    slug = re.sub(r""[^a-z0-9]+"", ""-"", text.lower())
    return re.sub(r""-+"", ""-"", slug).strip(""-"")
",alpha_factory_v1/demos/self_healing_repo/agent_core/llm_client.py,,1,2.2159489282323004e-08,"The method _slugify is a utility function that converts a given text into a URL-friendly 'slug'. This is a common requirement in web development for creating SEO-friendly URLs. The function uses regular expressions to replace non-alphanumeric characters with hyphens and ensures there are no leading or trailing hyphens. Such utility functions are often reused across projects for their simplicity and effectiveness. Therefore, it is likely to be retained in the codebase."
survived,"        async def run_check() -> None:
            with (
                patch.dict(os.environ, {""POLL_INTERVAL_SEC"": ""2""}),
                patch(
                    ""alpha_factory_v1.demos.macro_sentinel.data_feeds.asyncio.sleep"",
                    new_callable=AsyncMock,
                ) as sleep_mock,
            ):
                it = data_feeds.stream_macro_events(live=False)
                await anext(it)
                await anext(it)
                sleep_mock.assert_awaited_with(2.0)
",tests/test_macro_sentinel.py,TestMacroSentinel,1,7.3382086014706e-07,"The method 'run_check' is a test function that uses mocking to verify the behavior of a coroutine. It is likely part of a test suite to ensure that the 'stream_macro_events' function behaves as expected, particularly that it respects the 'POLL_INTERVAL_SEC' environment variable. Test functions like this are generally useful for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is unlikely to be deleted unless the functionality it tests is removed or significantly altered."
survived,"    def __call__(self, text: str) -> str:
        for _ in range(self.steps):
            text = self._op(text)
        return text",src/simulation/mats_ops.py,SelfRewriteOperator,1,1.522997951276035e-08,"The method is a special method in Python, known as a ""dunder"" method, which allows an instance of a class to be called as a function. This is a useful feature for classes that are designed to perform a single operation or transformation, such as processing or transforming text in this case. The method is likely to survive because it provides a clear and Pythonic way to apply a series of operations (defined by self._op) a specified number of times (self.steps) to a given text input. This kind of functionality is often needed in various applications, making the method valuable and likely to be retained."
survived,"def run() -> None:
    n = 21
    total = sum(range(n))
    expected = n*(n-1)//2
    assert total == expected",benchmarks/swe_mini/task_021.py,,1,3.2241866333029355e-08,"The method 'run' is a simple function that calculates the sum of numbers from 0 to 20 and checks if it matches the expected sum using the formula for the sum of an arithmetic series. This is a basic example of a unit test or a demonstration of a mathematical property. The function is straightforward, correct, and serves a clear purpose in verifying a mathematical formula. It is likely to survive because it is a valid and useful piece of code for educational purposes or as a simple test case."
survived,"def run() -> None:
    n = 19
    total = sum(range(n))
    expected = n*(n-1)//2
    assert total == expected",benchmarks/swe_mini/task_019.py,,1,6.962258425838873e-06,"The method 'run' is a simple function that calculates the sum of numbers from 0 to n-1 and checks if it matches the expected sum using the formula for the sum of an arithmetic series. This is a basic mathematical operation and serves as a simple test or demonstration of the formula. The method is self-contained, does not depend on external factors, and correctly implements the logic it is supposed to demonstrate. Therefore, there is no reason for it to be deleted unless it is deemed unnecessary in the context it is used. However, as a standalone piece of code, it is correct and functional."
survived,"def run() -> None:
    parts = [""poly"", ""task"", ""17""]
    joined = ""-"".join(parts)
    assert joined.split(""-"")[2] == str(17)",benchmarks/poly_mini/task_017.py,,1,8.76424914819242e-08,"The method 'run' is a simple function that joins a list of strings with a hyphen and then splits the resulting string to assert that the third element is '17'. This is a basic operation that demonstrates string manipulation and is likely used for educational or illustrative purposes. There is no indication of redundancy, inefficiency, or lack of utility that would warrant its deletion. Therefore, it is likely to be retained."
survived,"    def test_new_env_tool(self):
        with patch.object(
            bridge.requests,
            ""post"",
            return_value=DummyResponse({""ok"": True}),
        ) as post:
            result = asyncio.run(bridge.new_env())
        post.assert_called_once_with(
            ""http://localhost:7860/command"",
            json={""cmd"": ""new_env""},
            timeout=5,
        )
        self.assertEqual(result, {""ok"": True})
",tests/test_inspector_bridge.py,TestInspectorAgent,1,1.6052280526088547e-09,"The method `test_new_env_tool` is a unit test designed to verify the behavior of the `new_env` function in the `bridge` module. It uses mocking to simulate the HTTP POST request and checks if the function behaves as expected. Unit tests are crucial for ensuring code reliability and are typically retained in the codebase to maintain test coverage and facilitate future development. Therefore, this method is likely to be retained."
survived,"    def json(self):
        return self._payload
",tests/test_inspector_bridge.py,DummyResponse,1,1.2501528648238603e-09,"The method is a simple getter for the '_payload' attribute, which is a common pattern in Python to provide access to private or protected attributes. Such methods are typically retained unless there is a significant reason to remove them, such as a change in design or redundancy. Without additional context suggesting that '_payload' is being accessed directly or that the method is no longer needed, it is likely to survive."
survived,"def _sanitise_genes(genes: Mapping[str, float]) -> Dict[str, float]:
    """"""Ensure required keys exist and cast values to the correct types.""""""

    required = (""temperature"", ""top_p"", ""max_tokens"")
    if not all(k in genes for k in required):
        missing = [k for k in required if k not in genes]
        raise KeyError(f""Missing gene(s): {', '.join(missing)}"")

    return {
        ""temperature"": float(genes[""temperature""]),
        ""top_p"": float(genes[""top_p""]),
        ""max_tokens"": int(genes[""max_tokens""]),
    }
",alpha_factory_v1/backend/genetic_tests.py,,1,2.1724399346070676e-10,"The method '_sanitise_genes' is well-defined and serves a clear purpose: it ensures that a given dictionary contains specific required keys and converts their values to the appropriate types. This kind of utility function is often necessary in data processing to validate and sanitize input data before further processing. The method raises a KeyError if any required keys are missing, which is a standard practice for error handling in such scenarios. Given its utility and the lack of any apparent issues or redundancies, it is likely to be retained in the codebase."
survived,"    async def __aenter__(self):  # pragma: no cover - interface default
        return self
",alpha_factory_v1/backend/market_data.py,BaseMarketData,1,2.5109990926928157e-08,"The method `__aenter__` is part of the asynchronous context manager protocol in Python. It is used to define the behavior of an object when it is entered using an `async with` statement. This method is essential for the proper functioning of asynchronous context managers, which are increasingly important in modern Python programming for managing resources like network connections, files, or any asynchronous operations. Given its role in facilitating clean and efficient resource management in asynchronous programming, it is unlikely to be deleted."
survived,"    def clear(self) -> None:
        """"""Remove all nodes and relationships from the graph.""""""
        with _LOCK:
            if self._driver:
                with _neo_session(self._driver, self._db) as s:
                    s.run(""MATCH (n) DETACH DELETE n"")
                self._refresh_gauges()
            else:
                if hasattr(self._g, ""clear""):
                    self._g.clear()  # type: ignore[attr-defined]
                else:  # pragma: no cover - stub fallback
                    self._g.nodes.clear()  # type: ignore[attr-defined]
                    self._g.edges.clear()  # type: ignore[attr-defined]
                self._refresh_gauges_nx()
",alpha_factory_v1/backend/memory_graph.py,GraphMemory,1,1.637377179507321e-07,"The method 'clear' is a utility function designed to remove all nodes and relationships from a graph, which is a common requirement in graph management systems. It handles both cases where a driver is available and when it is not, ensuring that the graph is cleared in either scenario. The method also refreshes gauges after clearing, indicating that it is part of a larger system that monitors or tracks graph metrics. Given its utility and the fact that it is well-integrated into the system's functionality, it is unlikely to be deleted unless the entire system undergoes a significant redesign or the method's functionality is replaced by a more efficient or necessary approach."
survived,"    def __init__(self, name: str = ""dummy""):
        self.name = name
        self.ran = False
",alpha_factory_v1/tests/test_planner_agent.py,DummyAgent,1,1.8553915987649156e-07,"The method is a constructor (__init__) for a class, which is essential for initializing object instances. It sets default values for the attributes 'name' and 'ran', which are likely used elsewhere in the class. Constructors are fundamental to object-oriented programming, and removing it would likely break the class functionality. Therefore, it is unlikely to be deleted."
survived,"    def setUp(self):
        self.tmpdir = tempfile.TemporaryDirectory()
        self.memory = Memory(self.tmpdir.name)
        self.gov = DummyGov()
",alpha_factory_v1/tests/test_planner_agent.py,PlannerAgentTest,1,4.1399375473943306e-08,"The setUp method is a common part of unit testing frameworks, such as unittest in Python. It is used to set up the test environment before each test method is run. The method creates a temporary directory and initializes objects that are likely used in the tests. This setup is crucial for ensuring that each test runs in a clean environment and does not interfere with others. Therefore, it is unlikely to be deleted as it serves an important purpose in the testing process."
survived,"    def clear(self) -> None:
        """"""Erase all persisted fills and reset positions.""""""
        self._positions.clear()
        if self._db_path.exists():
            self._db_path.write_text("""")
",alpha_factory_v1/backend/portfolio.py,Portfolio,1,4.363462233903899e-09,"The method 'clear' is a utility function that resets the state of an object by clearing positions and erasing persisted data. Such methods are generally useful for maintaining or resetting the state of an application, especially in scenarios where the application needs to be restarted or reset to a known state. This functionality is often necessary in applications dealing with data persistence and state management, making it likely to survive."
survived,"    async def arecord_fill(self, symbol: str, qty: float, price: float, side: str) -> None:
        loop = asyncio.get_running_loop()
        await loop.run_in_executor(None, self.record_fill, symbol, qty, price, side)
",alpha_factory_v1/backend/portfolio.py,Portfolio,1,8.152020648014727e-09,"The method 'arecord_fill' is an asynchronous wrapper around a synchronous method 'record_fill'. It uses 'asyncio.get_running_loop().run_in_executor' to run the blocking 'record_fill' method in a separate thread, which is a common pattern to avoid blocking the event loop in asynchronous applications. This pattern is useful and often necessary when dealing with I/O-bound operations in an async context. Therefore, the method is likely to be retained as it provides a non-blocking way to execute potentially blocking operations."
survived,"def check_docker_compose() -> bool:
    if not shutil.which('docker'):
        banner('docker compose missing', 'RED')
        return False
    try:
        subprocess.run(
            ['docker', 'compose', 'version'],
            check=True,
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL,
        )
        banner('docker compose available', 'GREEN')
        return True
    except Exception:  # noqa: BLE001
        banner('docker compose missing', 'RED')
        return False
",alpha_factory_v1/scripts/preflight.py,,1,4.0586521248284276e-10,"The method 'check_docker_compose' is likely to survive because it performs a useful function by checking the availability of Docker Compose on a system. It uses standard libraries like 'shutil' and 'subprocess' to achieve this, which are reliable and commonly used for such tasks. The method also provides user feedback through the 'banner' function, enhancing its utility. Unless there are changes in how Docker Compose is checked or the method is replaced by a more efficient one, it is likely to remain relevant."
survived,"    def portfolio_value(self) -> float:
        """"""Current cash + mark-to-market value of the position.""""""
        return self.cash + self.position * self.price
",alpha_factory_v1/backend/environments/market_sim.py,MarketEnv,1,8.592166611791576e-10,"The method 'portfolio_value' is a straightforward calculation that provides a useful summary of the current financial state of a portfolio by combining cash and the market value of positions. This is a fundamental operation in financial applications, making it highly likely to be retained. It is simple, efficient, and provides essential functionality for users who need to quickly assess their portfolio's value."
survived,"    def recurrent(self, h, a_onehot):
        r, h2 = self.dyn(h, a_onehot)
        v, p = self.pred(h2)
        return h2, r, v, p
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,MuZeroTiny,1,9.237449576640118e-09,"The method 'recurrent' is a part of a class, likely related to a reinforcement learning or neural network model, given the use of terms like 'dyn', 'pred', and 'onehot'. The method appears to be well-structured, performing a sequence of operations: updating a hidden state 'h' with 'a_onehot', and then predicting values 'v' and 'p'. This kind of method is typical in models that require recurrent processing, such as RNNs or LSTMs, and is likely to be useful in its context. Therefore, it is unlikely to be deleted."
survived,"    def handle(self,msg):
        if ""loss"" in msg and (np.isnan(msg[""loss""]) or msg[""loss""]>1e3):
            LOG.warning(""[SAFETY] triggered ‚Äì halting learner"")
            self.emit(""orch"",{""cmd"":""stop""})
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,BasicSafetyAgent,1,1.3440409770490404e-08,"The method 'handle' is designed to monitor a message for a specific condition related to 'loss'. If the 'loss' is either NaN or exceeds a threshold (1000), it logs a warning and emits a command to stop a process. This is a safety feature to prevent the learner from continuing in a potentially harmful state. Such safety checks are crucial in systems that involve machine learning or automated processes to prevent erroneous behavior. Therefore, this method is likely to be retained as it serves an important protective function."
survived,"def emit_notebook(fp:Path=Path(""alpha_asi_world_model_demo.ipynb"")):
    import nbformat as nbf
    nb=nbf.v4.new_notebook()
    nb.cells=[nbf.v4.new_markdown_cell(""# Œ±‚ÄëASI demo ‚Äì quickstart""), nbf.v4.new_code_cell(""!python -m alpha_asi_world_model_demo --demo &"")]
    nbf.write(nb,fp); print(""Notebook ‚Üí"",fp)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,,1,2.646573631904765e-09,"The method 'emit_notebook' is a utility function that creates a Jupyter notebook with a specific structure and writes it to a file. It uses the 'nbformat' library to create a new notebook and add a markdown cell and a code cell. This function is useful for automating the creation of notebooks, which can be a common task in data science and machine learning workflows. The method is straightforward, does not have any apparent issues, and serves a clear purpose. Therefore, it is likely to be retained in the codebase."
survived,"    def forward(self, x): return torch.tanh(self.l(x))
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,Repr,1,8.152020648014727e-09,"The method 'forward' is a standard implementation in PyTorch models, where it defines the forward pass of the neural network. The use of 'torch.tanh' and 'self.l(x)' suggests that 'self.l' is a layer or a linear transformation applied to the input 'x'. This is a typical pattern in neural network implementations, and there is no indication that this method is deprecated or unnecessary. Therefore, it is likely to be retained in the code."
survived,"    def train_once(self)->float:
        if len(self.buffer)<CFG.train_batch: return 0.0
        obs,rew=zip(*random.sample(self.buffer, CFG.train_batch))
        obs_t=torch.tensor(obs, device=CFG.device, dtype=torch.float32)
        rew_t=torch.tensor(rew, device=CFG.device)
        _,v,_=self.net.initial(obs_t)
        loss=F.mse_loss(v.squeeze(),rew_t)
        self.opt.zero_grad(); loss.backward(); self.opt.step()
        return float(loss.item())
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,Learner,1,6.69158608681505e-10,"The method 'train_once' is likely to survive because it implements a crucial functionality for training a model using a batch of data from a buffer. It checks if there is enough data to form a batch, processes the data into tensors, computes a loss using mean squared error, and updates the model parameters using backpropagation. These steps are essential in machine learning workflows, especially in reinforcement learning or similar contexts where training from a buffer is common. The method is well-structured and performs a necessary task, making it unlikely to be deleted unless there is a significant change in the training strategy or architecture."
survived,"async def ws_endpoint(sock:WebSocket):
    await sock.accept(); q:List[dict]=[]
    A2ABus.subscribe(""ui"", lambda m:q.append(m))
    try:
        while True:
            if q: await sock.send_text(json.dumps(q.pop(0)))
            await asyncio.sleep(0.1)
    except Exception: pass
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,,1,6.348800075736417e-09,"The method is likely to survive because it implements a WebSocket endpoint that handles incoming messages and sends them to the client. It uses asynchronous programming, which is suitable for handling I/O-bound operations like WebSocket communication. The method also includes error handling with a try-except block, which is a good practice to prevent the application from crashing due to unexpected errors. Additionally, the use of a queue to manage messages ensures that messages are processed in the order they are received, which is important for maintaining the integrity of the communication."
survived,"def emit_docker(fp:Path=Path(""Dockerfile"")): fp.write_text(DOCKERFILE); print(""Dockerfile ‚Üí"",fp)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,,1,2.7894680920908113e-10,"The method 'emit_docker' is a simple utility function that writes a predefined string 'DOCKERFILE' to a file named 'Dockerfile' by default. It also prints a confirmation message indicating the file's path. This function is straightforward and serves a clear purpose in automating the creation of a Dockerfile, which is a common task in software development involving containerization. Given its utility and simplicity, there is no apparent reason for it to be deleted unless the project no longer uses Docker or has a different method for handling Dockerfiles. Therefore, it is likely to survive."
survived,"            def _safe_call(self,prompt:str,timeout:int=15)->str:
                with concurrent.futures.ThreadPoolExecutor() as ex:
                    fut=ex.submit(lambda:openai.ChatCompletion.create(
                        model=""gpt-4o-mini"",
                        messages=[{""role"":""user"",""content"":prompt}],
                        timeout=timeout))
                    return fut.result().choices[0].message.content
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,LLMPlanner,0,0.9999999907625504,"The method '_safe_call' is likely to be deleted (0) because it uses a model 'gpt-4o-mini' which does not exist in the OpenAI API. This suggests that the code is either outdated or incorrect. Additionally, the method does not handle exceptions that may arise from the API call, such as timeouts or network errors, which is a critical aspect of making safe API calls. Without proper error handling, the method is not robust and may lead to unhandled exceptions in production environments."
survived,"    async def __aexit__(self, exc_type, exc, tb) -> None:
        pass",alpha_factory_v1/backend/broker/broker_sim.py,SimulatedBroker,1,9.237449576640118e-09,"The method `__aexit__` is part of the asynchronous context manager protocol in Python. It is used to define cleanup actions that should be taken when exiting an async context. The presence of this method suggests that the class is intended to be used with an async context manager, which is a common and useful pattern in modern Python programming. Since this method is essential for the proper functioning of async context managers, it is unlikely to be deleted unless the entire context manager functionality is being removed, which is improbable. Therefore, the method will likely survive."
survived,"    def _parse(self, args):
        old = sys.argv
        sys.argv = [""edge_runner.py""] + args
        try:
            return edge_runner.parse_args()
        finally:
            sys.argv = old
",alpha_factory_v1/tests/test_edge_runner.py,EdgeRunnerParseTest,1,1.1253518384332553e-07,"The method '_parse' is a utility function that temporarily modifies 'sys.argv' to simulate command-line arguments for the 'edge_runner.parse_args()' function. This is a common pattern used in testing or when programmatically invoking command-line interfaces. The method is well-encapsulated, restores the original state of 'sys.argv' after execution, and is likely to be useful in contexts where command-line argument parsing needs to be tested or invoked programmatically. Therefore, it is likely to be retained in the codebase."
survived,"def discover_domain():
    """"""Try to auto-discover the domain using realm.""""""
    out, _ = run_cmd(""realm discover 2>/dev/null | awk '/realm.name/ {print $2; exit}'"")
    return out
",adconnection_gui.py,,1,4.363462233903899e-09,"The method 'discover_domain' is a utility function that attempts to auto-discover a domain using a command-line tool 'realm'. It uses a shell command to extract the domain name and returns the result. This kind of functionality is often useful in scripts or applications that need to configure or interact with network domains automatically. Since it provides a specific utility that can be reused in different contexts, it is likely to be retained unless there is a significant change in how domain discovery is handled or if the 'realm' tool becomes obsolete. Therefore, the method is likely to survive."
survived,"    def _mark_invite_used(inv: Invitation, user: User) -> None:
        inv.used = True if not inv.unlimited else inv.used
        inv.used_at = datetime.datetime.now()
        inv.used_by = user
        db.session.commit()
",app/services/media/jellyfin.py,JellyfinClient,1,1.955568070542584e-08,"The method '_mark_invite_used' is a utility function that updates the state of an 'Invitation' object when it is used by a 'User'. It sets the 'used' flag to True unless the invitation is unlimited, records the current time as 'used_at', and associates the 'used_by' field with the user who used the invitation. This is a typical operation in systems that manage invitations or tokens, ensuring that the invitation's state is accurately reflected in the database. The method is straightforward, performs a necessary function, and is likely to be used in various parts of the application where invitation usage needs to be tracked. Therefore, it is unlikely to be deleted."
survived,"async def make_client() -> tuple[AsyncClient, Any]:
    from src.interface import api_server

    transport = ASGITransport(app=cast(Any, api_server.app))
    client = AsyncClient(base_url=""http://test"", transport=transport)
    return client, api_server
",tests/test_api_server_cors.py,,1,1.0467401685178159e-08,"The method 'make_client' is likely to survive because it is a utility function that sets up an asynchronous client for testing purposes. It uses the ASGITransport to simulate requests to an ASGI application, which is a common pattern in modern Python web development for testing. The function is concise, serves a clear purpose, and is likely to be useful in the context of testing or interacting with the 'api_server'."
survived,"    def can_activate(self, request: Request) -> bool:
        self.called = True
        return True
",tests/test_core/test_decorators/test_guard.py,SimpleGuard,1,6.023574641292144e-08,"The method 'can_activate' is a simple method that sets an attribute 'called' to True and returns True. This method might be part of a larger class where it is used to check if a certain condition is met before proceeding with an action. The method is straightforward and does not contain any complex logic or dependencies that would make it obsolete or unnecessary. Therefore, it is likely to be retained as it serves a purpose in the context it is used."
survived,"def test_compose_base_url_substitution() -> None:
    env = os.environ.copy()
    env[""OLLAMA_BASE_URL""] = ""http://example.com/v1""
    result = subprocess.run(
        [""docker"", ""compose"", ""-f"", str(COMPOSE_FILE), ""config""],
        check=True,
        capture_output=True,
        text=True,
        env=env,
    )
    assert ""http://example.com/v1"" in result.stdout",tests/test_macro_compose_config.py,,1,9.237449576640118e-09,"The method `test_compose_base_url_substitution` is a test function that verifies if the environment variable `OLLAMA_BASE_URL` is correctly substituted in a Docker Compose configuration. This is a common practice in testing to ensure that environment variables are being used as expected in configuration files. The function uses subprocess to run a Docker Compose command and checks the output for the expected URL. This kind of test is useful for maintaining the integrity of environment-based configurations, which is a critical aspect of many software systems. Therefore, it is likely to be retained as part of the test suite."
survived,"def test_mixtral_fallback(monkeypatch: pytest.MonkeyPatch, tmp_path: Path) -> None:
    api_port = _free_port()
    ollama_port = _free_port()

    stub_dir = tmp_path / ""stubs""
    stub_dir.mkdir()
    (stub_dir / ""openai_agents.py"").write_text(
        ""class OpenAIAgent:\n""
        ""    def __init__(self, *a, **kw):\n""
        ""        self.base_url = kw.get('base_url')\n""
        ""    def __call__(self, *a, **kw):\n""
        ""        return 'ok'\n""
        ""def Tool(*_a, **_k):\n""
        ""    def dec(f):\n""
        ""        return f\n""
        ""    return dec\n""
    )

    server = HTTPServer((""127.0.0.1"", ollama_port), _Handler)
    thread = threading.Thread(target=server.serve_forever)
    thread.start()

    env = os.environ.copy()
    env[""OPENAI_API_KEY""] = """"
    env[""OLLAMA_BASE_URL""] = f""http://127.0.0.1:{ollama_port}/v1""
    env[""API_PORT""] = str(api_port)
    env[""PYTHONPATH""] = f""{stub_dir}:{env.get('PYTHONPATH', '')}""

    proc = subprocess.Popen(
        [sys.executable, ENTRYPOINT],
        env=env,
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        text=True,
    )
    try:
        url = f""http://localhost:{api_port}/health""
        for _ in range(100):
            try:
                r = requests.get(url, timeout=2)
                if r.status_code == 200:
                    break
            except Exception:
                time.sleep(0.1)
        else:
            out, _ = proc.communicate(timeout=5)
            server.shutdown()
            thread.join()
            pytest.skip(f""service failed to start: {out}"")
    finally:
        proc.terminate()
        out, _ = proc.communicate(timeout=5)
        server.shutdown()
        thread.join()

    assert ""ollama"" in out.lower() or ""mixtral"" in out.lower()",tests/test_aiga_service_mixtral.py,,1,4.944450477491054e-09,"The method `test_mixtral_fallback` is a test function that sets up a testing environment using `pytest` and `monkeypatch`. It creates a temporary directory for stubs, starts an HTTP server, and runs a subprocess to test a service's health endpoint. The function is well-structured for testing purposes and uses common testing practices such as environment variable manipulation, subprocess management, and assertions. There is no indication that this method is obsolete or redundant, and it serves a clear purpose in testing the fallback mechanism of a service. Therefore, it is likely to be retained."
survived,"    def _run_check(self, module_name: str, version: str) -> bool:
        fake_mod = types.SimpleNamespace(__version__=version)
        orig_import_module = importlib.import_module
        orig_find_spec = importlib.util.find_spec

        def _fake_import(name: str, *args: Any, **kwargs: Any) -> object:
            if name == module_name:
                return fake_mod
            return orig_import_module(name, *args, **kwargs)

        def _fake_find_spec(name: str, *args: Any, **kwargs: Any) -> object:
            if name == module_name:
                return object()
            if name in {""openai_agents"", ""agents""}:
                return None
            return orig_find_spec(name, *args, **kwargs)

        with (
            mock.patch(""importlib.import_module"", side_effect=_fake_import),
            mock.patch(""importlib.util.find_spec"", side_effect=_fake_find_spec),
        ):
            return preflight.check_openai_agents_version()
",tests/test_preflight_openai_agents_version.py,TestPreflightOpenAIAgentsVersion,1,8.152020648014727e-09,"The method '_run_check' is a utility function that uses mocking to simulate the import of a module with a specific version. This is useful for testing purposes, especially when you want to test how your code behaves with different versions of a module without actually installing those versions. The method is likely to be retained because it serves a specific purpose in testing and does not have any apparent issues or redundancies. It is a common practice to use such techniques in testing environments."
survived,"def test_csp_hashes_match() -> None:
    html_path = Path(""docs/alpha_agi_insight_v1/index.html"")
    html = html_path.read_text()
    meta = re.search(r""<meta[^>]*Content-Security-Policy[^>]*content=\""([^\""]+)\"""", html)
    assert meta, ""CSP meta tag missing""
    csp = meta.group(1)
    match = re.search(r""script-src ([^;]+)"", csp)
    assert match, ""script-src missing in CSP""
    allowed_hashes = set(re.findall(r""'sha384-[^']+'"", match.group(1)))
    inline_scripts = re.findall(r""<script(?![^>]*src)[^>]*>([\s\S]*?)</script>"", html)
    computed = {_hash_snippet(s) for s in inline_scripts}
    assert computed <= allowed_hashes

    srcs = re.findall(r""<script[^>]*src=['\""]([^'\""]+)['\""]"", html)
    assert len(srcs) == len(set(srcs))",tests/security/test_csp.py,,1,1.725782769012759e-08,"The method `test_csp_hashes_match` is a test function that checks the integrity and security of a web page's Content Security Policy (CSP) by ensuring that all inline scripts have corresponding hashes in the CSP and that all script sources are unique. This is a crucial security measure to prevent cross-site scripting (XSS) attacks. Given the importance of security in web applications and the fact that this function is a test (indicated by the `test_` prefix), it is likely to be retained to ensure ongoing security compliance. Therefore, the method will likely survive."
survived,"def test_basic_ux_workflow(monkeypatch, capsys, capture_secho):
    # Simulate interactive choices
    inputs = iter([""1"", ""foo"", ""bar""])
    monkeypatch.setattr(""builtins.input"", lambda _: next(inputs))

    cli = CLIOutput()
    feedback = UserFeedback(cli_output=cli)
    interactive = Interactive()
    generator = DiagramGenerator()

    # interactive menu and form
    choice = interactive.menu(""Select"", [""diagram"", ""quit""])
    params = interactive.form([""a"", ""b""])

    assert choice == ""diagram""
    assert params == {""a"": ""foo"", ""b"": ""bar""}

    list(feedback.progress_iter(range(2), description=""progress""))
    out, err = capsys.readouterr()
    combined = click.unstyle(out + err)

    spec = {
        ""task_description"": ""Demo"",
        ""inputs"": {""q"": ""str""},
        ""outputs"": {""r"": ""str""},
    }
    diagram = generator.generate(spec)
    feedback.notify(""done"", NotificationSeverity.SUCCESS)

    assert ""done"" in capture_secho
    assert ""progress"" in combined
    assert diagram.startswith(""flowchart"")
",tests/integration/test_ux_interactions.py,,1,6.348800075736417e-09,"The method 'test_basic_ux_workflow' is a test function that simulates a user interaction workflow and verifies the behavior of the system. Test functions are generally crucial for ensuring the correctness of code, especially in a development environment where continuous integration and testing are important. This function uses various testing utilities like 'monkeypatch', 'capsys', and 'capture_secho' to simulate inputs and capture outputs, which are common practices in testing frameworks. Therefore, it is unlikely to be deleted as it serves an important role in maintaining code quality."
survived,"    def TellSecret(self):
        return self.secret
",tests/rosetta/transpiler/Python/call-an-object-method.py,Box,0,0.9999910602998366,"The method 'TellSecret' directly returns a private attribute 'self.secret'. This could be a security concern if 'self.secret' contains sensitive information. In many cases, exposing private data directly through a method is considered a bad practice as it violates encapsulation principles. Therefore, it is likely that this method will be deleted or refactored to ensure better data protection and encapsulation."
survived,"    def __init__(self, *a, **kw):
        pass
",tests/test_openai_bridge_integration.py,_AgentRuntime,0,0.9999991684720096,"The method is a constructor (__init__) that takes any number of positional and keyword arguments but does nothing with them. This is typically not useful unless it's a placeholder or part of a larger framework where the arguments are handled elsewhere. Without additional context or functionality, this method is likely to be deleted as it doesn't contribute to the class's behavior."
survived,"    def test_policy_dispatch_discover(self):
        agent = bridge.BusinessAgent()
        with patch.object(bridge, ""trigger_discovery"", new=AsyncMock(return_value=""ok"")) as func:
            result = asyncio.run(agent.policy({""action"": ""discover""}, None))
        func.assert_awaited_once_with()
        self.assertEqual(result, ""ok"")
",tests/test_openai_bridge_integration.py,TestBusinessAgentIntegration,1,1.2501528648238603e-09,"The method `test_policy_dispatch_discover` is a unit test designed to verify the behavior of the `policy` method in the `BusinessAgent` class. It uses mocking to simulate the `trigger_discovery` function and checks if it is called correctly and if the `policy` method returns the expected result. This is a typical and necessary test to ensure the functionality of the code, especially in asynchronous contexts. Therefore, it is likely to be retained as part of the test suite to maintain code quality and reliability."
survived,"    async def stub(sim_id: str, _cfg: api.SimRequest) -> None:
        counter[""current""] += 1
        counter[""max""] = max(counter[""max""], counter[""current""])
        await asyncio.sleep(0.05)
        counter[""current""] -= 1
",tests/test_max_sim_tasks.py,,1,2.5612814850547937e-06,"The method 'stub' is a simple asynchronous function that increments a counter, waits for a short period, and then decrements the counter. It appears to be a placeholder or a mock function used for testing or simulating behavior in an asynchronous environment. Such functions are often used during development to simulate load or concurrency without implementing full functionality. Since it serves a purpose in testing or development, it is likely to be retained until it is replaced by a more complete implementation. Therefore, it is more likely to survive in the codebase for now."
survived,"    async def get_results(sim_id: str, _: None = Depends(verify_token)) -> ResultsResponse | JSONResponse:
        try:
            result = _simulations.get(sim_id)
            if result is None:
                raise HTTPException(status_code=404)
            return result
        except HTTPException as exc:
            return problem_response(exc)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/api_server.py,,1,1.1628233028868813e-10,"The method 'get_results' is likely to survive because it is a well-structured asynchronous function that handles fetching simulation results by ID. It includes error handling for cases where the simulation ID is not found, returning a 404 HTTP exception. The use of dependency injection with 'Depends' for token verification suggests it is part of a secure API design. These factors indicate that the method is functional, secure, and follows good coding practices, making it unlikely to be deleted."
survived,"def compile_model_jax(sbml_dir: Path, test_id: str, model_dir: Path):
    model_dir.mkdir(parents=True, exist_ok=True)
    sbml_file = find_model_file(sbml_dir, test_id)
    sbml_importer = amici.SbmlImporter(sbml_file)
    model_name = f""SBMLTest{test_id}_jax""
    sbml_importer.sbml2jax(model_name, output_dir=model_dir)
    model_module = amici.import_model_module(model_dir.name, model_dir.parent)
    jax_model = model_module.Model()
    return jax_model, sbml_importer
",tests/testSBMLSuiteJax.py,,1,4.0586521248284276e-10,"The method 'compile_model_jax' is likely to survive because it performs a specific and useful function: compiling a model using JAX from an SBML file. It involves creating directories, finding model files, importing and converting them using AMICI, and returning the compiled model. This functionality is essential for users who need to work with SBML models in a JAX environment, and there is no indication of redundancy or obsolescence in the code."
survived,"    def __len__(self):
        return len(self.Items)
",tests/machine/x/python/group_items_iteration.py,_Group,1,7.194132978569833e-09,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation here is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"    def __len__(self):
        return len(self.Items)
",tests/machine/x/python/group_by_sort.py,_Group,1,4.363462233903899e-09,"The method `__len__` is a special method in Python that is used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"    def sign(self, content: str) -> str:
        """"""Sign ``content`` and store signature in the cache.""""""
        signature = hmac.new(
            self.secret, content.encode(""utf-8""), hashlib.sha256
        ).hexdigest()
        checksum = hashlib.sha256(content.encode(""utf-8"")).hexdigest()
        self.cache[checksum] = signature
        self._save_cache()
        return signature
",src/meta_agent/template_governance.py,TemplateGovernance,1,9.736200303530205e-10,"The method 'sign' is a utility function that generates a signature for a given content using HMAC with SHA-256 and stores it in a cache. This is a common requirement in applications that need to verify the integrity and authenticity of data. The method is well-defined, performs a specific task, and is likely to be useful in contexts where data signing and caching are necessary. Therefore, it is unlikely to be deleted."
survived,"def test_lint(monkeypatch: pytest.MonkeyPatch) -> None:
    def fake_run(cmd, input, capture_output):
        return MagicMock(stdout=b""template.py:1:1 F401 unused import os\n"")

    monkeypatch.setattr(""subprocess.run"", fake_run)
    gov = TemplateGovernance(secret=""k"")
    issues = gov.lint(""import os\n"")
    assert issues and ""unused import"" in issues[0]
",tests/test_template_governance.py,,1,3.3982678079468468e-09,"The method 'test_lint' is a unit test that uses the 'monkeypatch' fixture from pytest to mock the behavior of 'subprocess.run'. This is a common practice in testing to isolate the function being tested from external dependencies. The test checks if the 'lint' method of the 'TemplateGovernance' class correctly identifies an unused import issue. Since this is a well-structured test that serves a clear purpose in verifying the functionality of the 'lint' method, it is likely to be retained in the codebase."
survived,"def test_hlda_runs_on_synthetic_data():
    n_topics = 3
    vocab_size = 9
    doc_len = 20
    n_docs = 5
    corpus, vocab = generate_corpus(n_topics, vocab_size, doc_len, n_docs)

    hlda = HierarchicalLDA(corpus, vocab, alpha=1.0, gamma=1.0, eta=1.0, num_levels=3, seed=0, verbose=False)
    hlda.estimate(2, display_topics=2, n_words=3, with_weights=False)

    assert len(hlda.document_leaves) == n_docs
    assert hlda.root_node.customers == n_docs",tests/test_synthetic_hlda.py,,1,7.73442280641062e-08,"The method 'test_hlda_runs_on_synthetic_data' is a unit test designed to verify the functionality of the HierarchicalLDA class on synthetic data. Unit tests are crucial for ensuring code reliability and correctness, especially in complex algorithms like hierarchical topic models. The test checks if the model can be initialized and run without errors and if the expected properties hold after estimation. Such tests are typically retained to maintain code quality and prevent regressions."
survived,"        def Sequential(*_, **__): return []
",alpha_factory_v1/demos/aiga_meta_evolution/meta_evolver.py,_DummyNN,0,0.9999999987498471,"The method 'Sequential' is defined to take any number of positional and keyword arguments but simply returns an empty list. This implementation does not perform any meaningful operation or computation, making it redundant. In a real-world scenario, such a method would likely be removed unless it serves a specific purpose, such as acting as a placeholder or being overridden in a subclass. Without additional context indicating its necessity, it is likely to be deleted."
survived,"def main(argv: list[str] | None = None) -> None:
    """"""Launch the orchestrator with the demo agent registered.""""""

    args = _parse_args(argv)
    logging.basicConfig(
        level=args.loglevel.upper(),
        format=""%(asctime)s %(levelname)-8s | %(message)s"",
        datefmt=""%Y-%m-%d %H:%M:%S"",
    )

    register_demo_agents()

    try:
        orchestrator.Orchestrator().run_forever()
    except KeyboardInterrupt:
        pass
",alpha_factory_v1/demos/alpha_agi_business_v1/alpha_agi_business_v1.py,,1,2.998960815863541e-09,"The method 'main' is a typical entry point for a Python script, especially when dealing with command-line arguments and setting up logging. It is well-structured, uses type hints, and includes exception handling for a graceful shutdown on a keyboard interrupt. These are all good practices in Python programming. The method is likely to be retained as it serves a clear purpose and follows standard conventions."
survived,"def _parse_args(argv: list[str] | None = None) -> argparse.Namespace:
    parser = argparse.ArgumentParser(description=""Run the Œ±‚ÄëAGI Business v1 demo"")
    parser.add_argument(
        ""--loglevel"",
        default=os.getenv(""LOGLEVEL"", ""INFO""),
        help=""Logging verbosity (default: INFO)"",
    )
    return parser.parse_args(argv)
",alpha_factory_v1/demos/alpha_agi_business_v1/alpha_agi_business_v1.py,,1,8.152020648014727e-09,"The method `_parse_args` is a utility function designed to parse command-line arguments using the `argparse` module. This is a common and essential practice in Python applications that require command-line interaction. The method is well-structured, uses type hints, and provides a default logging level, which enhances its usability and maintainability. There is no indication that this method is redundant or obsolete, as command-line argument parsing is a fundamental feature for many applications. Therefore, it is likely to be retained in the codebase."
survived,"    def test_notebook_valid(self) -> None:
        nb_path = Path(""alpha_factory_v1/demos/meta_agentic_agi/colab_meta_agentic_agi.ipynb"")
        self.assertTrue(nb_path.exists(), ""Notebook missing"")
        data = json.loads(nb_path.read_text(encoding=""utf-8""))
        self.assertIn(""cells"", data)
        self.assertIn(""nbformat"", data)
        self.assertGreaterEqual(data.get(""nbformat"", 0), 4)
",tests/test_meta_agentic_notebook.py,TestMetaAgenticNotebook,1,4.363462233903899e-09,"The method 'test_notebook_valid' is a unit test designed to verify the existence and validity of a Jupyter notebook file. It checks if the file exists, if it contains the necessary 'cells' and 'nbformat' keys, and if the 'nbformat' version is at least 4. These checks are essential for ensuring that the notebook is correctly formatted and can be executed without errors. Such validation is crucial in environments where notebooks are used for demonstrations or educational purposes. Therefore, this method is likely to be retained as it serves a practical purpose in maintaining the integrity of notebook files."
survived,"def _reload_client(monkeypatch: pytest.MonkeyPatch, diff: str) -> ModuleType:
    stub = types.ModuleType(""openai_agents"")

    class DummyAgent:
        def __init__(self, *a: object, **k: object) -> None:
            pass

        def __call__(self, *_a: object, **_k: object) -> str:
            return diff

    stub.OpenAIAgent = DummyAgent  # type: ignore[attr-defined]
    monkeypatch.setitem(sys.modules, ""openai_agents"", stub)
    import alpha_factory_v1.demos.self_healing_repo.agent_core.llm_client as mod

    return importlib.reload(mod)
",tests/test_llm_client_offline.py,,1,2.998960815863541e-09,"The method '_reload_client' is a utility function used for testing purposes, specifically to mock or patch a module during tests. It uses 'monkeypatch' from pytest to replace the 'openai_agents' module with a dummy version that returns a predefined string 'diff'. This is a common practice in testing to isolate the unit of code being tested from its dependencies. Such methods are typically retained as they are crucial for ensuring the reliability and correctness of the codebase through testing. Therefore, it is likely to survive."
survived,"def test_request_patch_use_local_llm(monkeypatch: pytest.MonkeyPatch) -> None:
    diff = ""--- a/x\n+++ b/x\n@@\n-old\n+new\n""
    monkeypatch.setenv(""USE_LOCAL_LLM"", ""true"")
    monkeypatch.delenv(""OPENAI_API_KEY"", raising=False)
    client = _reload_client(monkeypatch, diff)
    out = client.request_patch([{""role"": ""user"", ""content"": ""fix""}])
    assert out == diff
",tests/test_llm_client_offline.py,,1,2.7894680920908113e-10,"The method `test_request_patch_use_local_llm` is a test function that uses the `monkeypatch` fixture from `pytest` to modify the environment variables and test the behavior of a client when using a local language model. This kind of test is crucial for ensuring that the application behaves correctly under different configurations, especially when dealing with external dependencies like APIs. Since testing is an essential part of software development and maintenance, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly changed. Therefore, the method is likely to survive."
survived,"def _expected_checksums() -> dict[str, str]:
    fetch = repo_root / 'scripts' / 'fetch_assets.py'
    tree = ast.parse(fetch.read_text())
    checks: dict[str, str] = {}
    for node in tree.body:
        if isinstance(node, ast.Assign):
            for t in node.targets:
                if getattr(t, 'id', None) == 'CHECKSUMS':
                    checks = ast.literal_eval(node.value)
                    break
    return checks
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/manual_build.py,,1,2.998960815863541e-09,"The method '_expected_checksums' is a utility function that parses a Python script to extract a dictionary of checksums. This function is likely part of a larger system that requires verification of file integrity, which is a common requirement in software systems to ensure security and correctness. The method is specific in its purpose and does not appear to be redundant or obsolete. Therefore, it is likely to be retained in the codebase."
survived,"    def test_failed_local_import_recorded(self) -> None:
        with (
            mock.patch.object(pkgutil, ""iter_modules"", return_value=[(None, ""bad_agent"", False)]),
            mock.patch.object(importlib, ""import_module"", side_effect=ImportError(""boom"")),
        ):
            discovery.discover_local()

        self.assertIn(""bad_agent"", discovery.FAILED_AGENTS)
        self.assertEqual(discovery.FAILED_AGENTS[""bad_agent""], ""boom"")
        detail = agents.list_agents(detail=True)
        self.assertIn({""name"": ""bad_agent"", ""status"": ""error"", ""message"": ""boom""}, detail)",tests/test_failed_agent_discovery.py,TestFailedAgentDiscovery,1,7.194132978569833e-09,"The method `test_failed_local_import_recorded` is a unit test designed to verify that the system correctly records a failed import attempt of a local module. It uses mocking to simulate the conditions under which the import would fail and checks that the failure is recorded as expected. This is a crucial part of ensuring the robustness of the system's module discovery and error handling capabilities. Since testing error handling is an important aspect of software development, this method is likely to be retained to ensure that the system behaves correctly in the face of import errors."
survived,"            def run_generations(self, _n: int) -> None:
                pass
",tests/test_aiga_evolver_agent_logic.py,TestEvolverAgentLogic.Dummy,0,0.9999984465026855,"The method 'run_generations' is defined but not implemented, as indicated by the 'pass' statement. This suggests that the method is either a placeholder for future implementation or is intentionally left empty because it is not needed. Without further context on the class or module it belongs to, it's difficult to determine its necessity. However, methods that are not implemented and do not serve a clear purpose are often candidates for deletion to maintain clean and maintainable code. Therefore, it is likely that this method will be deleted unless it is planned to be implemented in the future."
survived,"def test_agents_status_lists_all_agents(tmp_path) -> None:
    path = tmp_path / ""audit.db""
    with patch.object(cli.config.CFG, ""ledger_path"", str(path)):
        orch = cli.orchestrator.Orchestrator()
        with patch.object(cli.orchestrator, ""Orchestrator"", return_value=orch):
            result = CliRunner().invoke(cli.main, [""agents-status""])
    for name in orch.runners.keys():
        assert name in result.output",tests/test_demo_cli.py,,1,2.5109990926928157e-08,"The method 'test_agents_status_lists_all_agents' is a unit test function that verifies the functionality of listing all agent statuses. It uses temporary paths and mocks to isolate the test environment, ensuring that it does not depend on external factors. The test checks if the output contains all the expected agent names, which is a valid and necessary test to ensure the correctness of the 'agents-status' command. Since it is a well-structured test that serves a clear purpose in maintaining code quality, it is likely to be retained."
survived,"def doTrials(trials, np, strategy):
    pardoned = 0
    t = 0
    while t < trials:
        drawers = []
        i = 0
        while i < 100:
            drawers = drawers + [i]
            i = i + 1
        drawers = shuffle(drawers)
        p = 0
        success = True
        while p < np:
            found = False
            if strategy == ""optimal"":
                prev = p
                d = 0
                while d < 50:
                    this = drawers[prev]
                    if this == p:
                        found = True
                        break
                    prev = this
                    d = d + 1
            else:
                opened = []
                k = 0
                while k < 100:
                    opened = opened + [False]
                    k = k + 1
                d = 0
                while d < 50:
                    n = _now() % 100
                    while opened[n]:
                        n = _now() % 100
                    opened[n] = True
                    if drawers[n] == p:
                        found = True
                        break
                    d = d + 1
            if not found:
                success = False
                break
            p = p + 1
        if success:
            pardoned = pardoned + 1
        t = t + 1
    rf = float(pardoned) / float(trials) * 100.0
    print(""  strategy = "" + strategy + ""  pardoned = "" + str(pardoned) + "" relative frequency = "" + str(rf) + ""%"")
",tests/rosetta/transpiler/Python/100-prisoners.py,,1,3.0590235908148916e-07,"The method 'doTrials' is a simulation function that performs a series of trials to determine the success rate of a given strategy in a problem involving drawers and finding a match. The function is complete, functional, and provides useful output for analyzing the effectiveness of different strategies. It is likely to be retained as it serves a specific purpose in simulations or educational demonstrations of probability and strategy effectiveness."
survived,"def replay() -> None:
    """"""Replay ledger entries with small delay.""""""
    path = Path(config.Settings().ledger_path)
    if not path.exists():
        click.echo(""No ledger to replay"")
        return
    for line in path.read_text(encoding=""utf-8"").splitlines():
        click.echo(line)
        time.sleep(0.1)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/cli.py,,1,1.1032560311263802e-09,"The method 'replay' is a utility function that reads and outputs the contents of a ledger file with a small delay between each line. This functionality can be useful for debugging or simulating the processing of ledger entries in real-time. The method is simple, clear, and serves a specific purpose, which makes it likely to be retained in the codebase. Additionally, it handles the case where the ledger file does not exist, providing user feedback, which is a good practice. Therefore, the method is likely to survive."
survived,"def simulate(
    horizon: int,
    curve: str,
    seed: int | None,
    offline: bool,
    pop_size: int,
    generations: int,
    export: str | None,
    verbose: bool,
) -> None:
    """"""Run the forecast simulation and start the orchestrator.""""""
    if seed is not None:
        random.seed(seed)

    settings = config.Settings()
    if offline:
        settings.offline = True

    orch = orchestrator.Orchestrator(settings)
    secs = [sector.Sector(f""s{i:02d}"") for i in range(pop_size)]
    results = forecast.simulate_years(secs, horizon)

    if export == ""json"":
        data = [
            {
                ""year"": r.year,
                ""capability"": r.capability,
                ""affected"": [s.name for s in r.affected],
            }
            for r in results
        ]
        click.echo(json.dumps(data))
    elif export == ""csv"":
        lines = [""year,capability,affected""]
        for r in results:
            lines.append(f""{r.year},{r.capability},{'|'.join(s.name for s in r.affected)}"")
        click.echo(""\n"".join(lines))
    else:
        for r in results:
            click.echo(f""{r.year}: {r.capability:.2f} ‚Üí {[s.name for s in r.affected]}"")

    if verbose:
        click.echo(""Starting orchestrator ‚Ä¶ press Ctrl+C to stop"")

    try:
        asyncio.run(orch.run_forever())
    except KeyboardInterrupt:  # pragma: no cover - interactive
        pass
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/cli.py,,1,1.1032560311263802e-09,"The method 'simulate' is a well-structured function that performs a simulation based on various parameters. It includes functionality for seeding random number generation, configuring settings, running a forecast simulation, exporting results in different formats (JSON, CSV), and handling verbosity. The method also includes error handling for user interruption. These features make it versatile and useful for various simulation tasks, which suggests it is likely to be retained in the codebase."
survived,"def test_finance_demo_cli(tmp_path: Path) -> None:
    script = Path(""alpha_factory_v1/demos/finance_alpha/deploy_alpha_factory_demo.sh"")
    assert script.exists(), script

    bin_dir = tmp_path / ""bin""
    bin_dir.mkdir()

    _write_executable(
        bin_dir / ""docker"",
        """"""#!/usr/bin/env bash
if [ ""$1"" = ""image"" ]; then exit 0; fi
if [ ""$1"" = ""pull"" ]; then exit 0; fi
if [ ""$1"" = ""run"" ]; then echo cid123; exit 0; fi
if [ ""$1"" = ""logs"" ]; then exit 0; fi
if [ ""$1"" = ""stop"" ]; then exit 0; fi
exit 0
"""""",
    )
    _write_executable(bin_dir / ""curl"", ""#!/usr/bin/env bash\necho '{}'\n"")
    _write_executable(bin_dir / ""jq"", ""#!/usr/bin/env bash\ncat >/dev/null\n"")
    _write_executable(bin_dir / ""lsof"", ""#!/usr/bin/env bash\nexit 1\n"")
    _write_executable(bin_dir / ""sleep"", ""#!/usr/bin/env bash\n[ \""$1\"" = \""3600\"" ] && exit 1\nexit 0\n"")

    env = os.environ.copy()
    env.update({""PATH"": f""{bin_dir}:{env.get('PATH', '')}"", ""PORT_API"": ""8010"", ""STRATEGY"": ""btc_gld""})

    result = subprocess.run([""bash"", str(script)], capture_output=True, text=True, env=env, timeout=20)

    assert result.returncode == 0, result.stderr
    assert ""Demo complete!"" in result.stdout",tests/test_finance_demo_cli.py,,1,8.152020648014727e-09,"The method is a test function for a CLI script related to a finance demo. It sets up a temporary environment with mock executables to simulate the behavior of certain commands like docker, curl, jq, etc. The function then runs a script and checks if it completes successfully by asserting the return code and output. This is a typical pattern for testing scripts in isolation, ensuring they behave as expected without relying on actual external dependencies. Such test functions are crucial for maintaining code quality and are unlikely to be deleted unless the functionality they test is removed or significantly changed."
survived,"def dump_lmdb(path: Path, keys: Iterable[str] | None = None) -> None:
    """"""Print selected or all key-value pairs from the LMDB database.""""""
    env = lmdb.open(str(path), readonly=True, lock=False)
    with env.begin() as txn:
        if keys:
            records = _dump_selected(txn, keys)
        else:
            records = _dump_all(txn)
    env.close()

    print(orjson.dumps(records, option=orjson.OPT_INDENT_2).decode())
",scripts/dump_lmdb.py,,1,2.4616969512093895e-10,"The method 'dump_lmdb' is a utility function designed to print key-value pairs from an LMDB database. It is a useful function for debugging or inspecting the contents of a database. The function is well-defined, uses efficient libraries like 'lmdb' and 'orjson', and provides flexibility by allowing the user to specify keys or dump all records. There is no indication that this function is obsolete or redundant, and it serves a clear purpose in data handling tasks. Therefore, it is likely to be retained in the codebase."
survived,"def main() -> None:
    parser = argparse.ArgumentParser(description=""Dump LMDB records as JSON"")
    parser.add_argument(""path"", type=Path, help=""Path to LMDB directory"")
    parser.add_argument(""keys"", nargs=""*"", help=""Keys to retrieve"")
    args = parser.parse_args()

    dump_lmdb(args.path, args.keys)
",scripts/dump_lmdb.py,,1,4.944450477491054e-09,"The method 'main' is a typical entry point for a script that uses the argparse library to handle command-line arguments. It is well-structured, with clear argument definitions and a call to a function 'dump_lmdb' that presumably handles the core functionality of the script. This pattern is common in Python scripts intended for command-line use, and there is no indication that it is deprecated or unnecessary. Therefore, it is likely to be retained in the codebase."
survived,"    def from_response(
        self,
        response: Any,
        mode: Mode,
        validation_context: Optional[Any] = None,
        strict: Optional[bool] = None,
    ) -> Generator[BaseModel, None, None]:
        assert mode == Mode.ANTHROPIC_PARALLEL_TOOLS, (
            ""Mode must be ANTHROPIC_PARALLEL_TOOLS""
        )

        if not response or not hasattr(response, ""content""):
            return

        for content in response.content:
            if getattr(content, ""type"", None) == ""tool_use"":
                name = content.name
                arguments = content.input
                if name in self.registry:
                    json_str = json.dumps(arguments)
                    yield self.registry[name].model_validate_json(
                        json_str, context=validation_context, strict=strict
                    )
",instructor/dsl/parallel.py,AnthropicParallelBase,1,5.60279640614594e-09,"The method 'from_response' is well-defined and serves a specific purpose of processing a response object to yield validated models based on certain conditions. It includes error handling, such as checking if the response has content and if the content type is 'tool_use'. The method also uses a registry to validate JSON data, which suggests it is part of a larger system that relies on this functionality. There is no indication that this method is obsolete or redundant, and it appears to be a crucial part of the system's operation. Therefore, it is likely to be retained."
survived,"    def _root_cond_fns(
        self, p: jt.Float[jt.Array, ""np""]
    ) -> tuple[
        Callable[[float, jt.Float[jt.Array, ""nxs""], tuple], jt.Float], ...
    ]:
        """"""Return condition functions for implicit discontinuities.

        These functions are passed to :class:`diffrax.Event` and must evaluate
        to zero when a discontinuity is triggered.

        :param p:
            model parameters
        :return:
            tuple of callable root functions
        """"""
        ...
",python/sdist/amici/jax/model.py,JAXModel,1,8.592166611791576e-10,"The method '_root_cond_fns' is a private method (indicated by the underscore prefix) that is designed to return condition functions for implicit discontinuities. It is likely part of a larger system that deals with events or conditions in a numerical or simulation context. The method is documented, indicating its purpose and parameters, which suggests it is actively used and maintained. Additionally, the method's functionality seems specialized and integral to the system it is part of, making it less likely to be removed unless the entire system undergoes a significant redesign. Therefore, it is more likely to survive."
survived,"def test_thermodynamic_trigger() -> None:
    sec = sector.Sector(""x"", energy=1.0, entropy=2.0)
    assert not forecast.thermodynamic_trigger(sec, 0.1)
    assert forecast.thermodynamic_trigger(sec, 1.0)
",tests/test_forecast.py,,1,7.194132978569833e-09,"The method `test_thermodynamic_trigger` is a unit test function that checks the behavior of the `thermodynamic_trigger` function from the `forecast` module. Unit tests are crucial for ensuring code reliability and correctness, especially in scientific or mathematical computations like thermodynamics. The test checks two scenarios: one where the trigger should not activate and one where it should, which is a typical pattern for testing boundary conditions. Given its role in maintaining code quality, this method is likely to be retained."
survived,"def grade_stdio(
    code: str,
    all_inputs: list,
    all_outputs: list,
    timeout: int,
):
    ## runtime doesn't interact well with __name__ == '__main__'
    code = clean_if_name(code)

    ## we wrap the given code inside another function
    # code = make_function(code)

    compiled_sol = compile_code(code, timeout)
    if compiled_sol is None:
        return

    method = get_function(compiled_sol, ""wrapped_function"")

    if method is None:
        return

    all_results = []
    total_execution_time = 0
    for idx, (gt_inp, gt_out) in enumerate(zip(all_inputs, all_outputs)):
        signal.alarm(timeout)
        faulthandler.enable()

        signal.alarm(timeout)
        with Capturing() as captured_output:
            try:
                start = time.time()
                call_method(method, gt_inp)
                total_execution_time += time.time() - start
                # reset the alarm
                signal.alarm(0)
            except Exception as e:
                signal.alarm(0)
                if ""timeoutexception"" in repr(e).lower():
                    all_results.append(-3)
                    return all_results, {
                        ""error"": repr(e),
                        ""error_code"": -3,
                        ""error_message"": ""Time Limit Exceeded"",
                        ""inputs"": truncatefn(gt_inp),
                        ""expected"": truncatefn(gt_out),
                    }
                else:
                    all_results.append(-4)
                    return all_results, {
                        ""error"": repr(e),
                        ""error_code"": -4,
                        ""error_message"": ""Runtime Error"",
                        ""inputs"": truncatefn(gt_inp),
                        ""expected"": truncatefn(gt_out),
                    }

            finally:
                signal.alarm(0)
                faulthandler.disable()

        prediction = captured_output[0]

        stripped_prediction_lines = get_stripped_lines(prediction)
        stripped_gt_out_lines = get_stripped_lines(gt_out)

        ## WA happens in multiple circumstances
        ## so cache the return to make it clean!
        WA_send_args = {
            ""output"": truncatefn(prediction),
            ""inputs"": truncatefn(gt_inp),
            ""expected"": truncatefn(gt_out),
            ""error_code"": -2,
        }

        if len(stripped_prediction_lines) != len(stripped_gt_out_lines):
            all_results.append(-2)
            WA_send_args[""error_message""] = ""Wrong answer: mismatched output length""
            return all_results, WA_send_args

        for output_line_idx, (
            stripped_prediction_line,
            stripped_gt_out_line,
        ) in enumerate(zip(stripped_prediction_lines, stripped_gt_out_lines)):
            WA_send_args[""error_message""] = (
                f""Wrong answer at {output_line_idx=}: {truncatefn(stripped_prediction_line)} != {truncatefn(stripped_gt_out_line)}""
            )

            ## CASE 1: exact match
            if stripped_prediction_line == stripped_gt_out_line:
                continue

            ## CASE 2: element-wise comparison
            ## if there are floating elements
            ## use `decimal` library for good floating point comparison
            ## otherwise gotcha: np.isclose(50000000000000000, 50000000000000001) = True
            ## note that we should always be able to convert to decimals

            success, decimal_prediction_line = convert_line_to_decimals(
                stripped_prediction_line
            )
            if not success:
                all_results.append(-2)
                return all_results, WA_send_args
            success, decimal_gtout_line = convert_line_to_decimals(stripped_gt_out_line)
            if not success:
                all_results.append(-2)
                return all_results, WA_send_args

            if decimal_prediction_line == decimal_gtout_line:
                continue

            all_results.append(-2)
            return all_results, WA_send_args
        all_results.append(True)

    return all_results, {""execution time"": total_execution_time}
",scripts/utils/lcb_runner.py,,1,5.3157849718487075e-08,"The method 'grade_stdio' is a utility function designed to evaluate code execution against expected inputs and outputs. It includes error handling for timeouts and runtime errors, and it compares the actual output with the expected output. The function is well-structured, with clear error handling and output comparison logic, making it a useful tool for automated grading or testing environments. Given its utility and the lack of any deprecated or redundant code, it is likely to be retained in the codebase."
survived,"    def __init__(self, path: str | Path) -> None:
        self.path = Path(path)
        self._ensure()
",src/archive.py,Archive,1,3.466327708641819e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting up initial states. The use of type hinting with 'str | Path' is a modern Python feature that improves code readability and type safety. The method also calls a private method '_ensure', which suggests it performs some necessary setup or validation. These factors indicate that the method is well-structured and serves a clear purpose, making it unlikely to be deleted."
survived,"    def __init__(
        self,
        jobs: Iterable[Job],
        *,
        tokens_quota: int | None = None,
        time_quota: float | None = None,
        interval: str = ""1 second"",
        max_workers: int = 1,
    ) -> None:
        self.queue: asyncio.Queue[Job] = asyncio.Queue()
        for job in jobs:
            self.queue.put_nowait(job)
        self.tokens_quota = tokens_quota
        self.time_quota = time_quota
        self.max_workers = max_workers
        self.tokens_used = 0
        self.start_time = 0.0
        self.running: Set[asyncio.Task[None]] = set()
        self.app = Rocketry(execution=""async"")

        @self.app.task(every(interval))
        async def _spawn():  # pragma: no cover - Rocketry callback
            await self._spawn_jobs()
",src/scheduler.py,SelfImprovementScheduler,1,3.0590235908148916e-07,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class. Constructors are fundamental components of class definitions in object-oriented programming, and they are rarely deleted unless the entire class is being removed or refactored significantly. The presence of parameters and initialization logic suggests that this constructor is actively used to set up instances with specific configurations, making it unlikely to be removed."
survived,"def run() -> None:
    """"""Reverse a string.""""""
    text = ""hello""
    assert text[::-1] == ""olleh""",benchmarks/polyglot_lite/task_sample.py,,1,0.03308598041471092,"The method 'run' is a simple function that reverses a string and checks if the reversed string is equal to the expected reversed string using an assertion. This is a basic utility function that demonstrates string manipulation and is often used in educational contexts to teach string operations. However, the function is not particularly useful in a production environment as it doesn't take any input or return any output, and it only works with a hardcoded string. Despite this, the function is correctly implemented and serves its purpose of demonstrating string reversal. Therefore, it is likely to survive as a basic example or educational tool, but it might be deleted or refactored in a production codebase where more dynamic and useful functions are needed."
survived,"def test_view_basic(tmp_path: Path) -> None:
    p = tmp_path / ""f.txt""
    p.write_text(""a\nb\nc\nd\n"")
    assert view(p, 1, 3) == ""b\nc""
    assert view(p, -2) == ""c\nd""
    assert view(p) == ""a\nb\nc\nd""
",tests/test_file_ops.py,,1,2.646573631904765e-09,"The method 'test_view_basic' is a test function that verifies the functionality of the 'view' function. It uses assertions to check if the 'view' function returns the expected output when given specific inputs. Test functions like this are crucial for ensuring code reliability and are typically retained in the codebase to facilitate ongoing testing and validation of the 'view' function. Therefore, it is likely to be retained."
survived,"def test_outside_repo_forbidden(tmp_path: Path) -> None:
    p = tmp_path / ""x.txt""
    p.write_text(""hi"")
    with pytest.raises(PermissionError):
        edit(p, 0, 1, ""bye"")
    with pytest.raises(PermissionError):
        replace(p, ""hi"", ""ho"")",tests/test_self_edit_tools.py,,1,8.152020648014727e-09,"The method `test_outside_repo_forbidden` is a test function that checks for `PermissionError` exceptions when attempting to edit or replace text in a file located outside a repository. This is a valid and useful test case to ensure that the functions `edit` and `replace` handle permission restrictions correctly. Test functions like this are crucial for maintaining the integrity and security of file operations within a codebase. Therefore, it is likely to be retained as part of the test suite."
survived,"def view(path: str | Path, start: int = 0, end: Optional[int] = None) -> str:
    """"""Return lines ``start:end`` from ``path``.""""""
    p = _safe_path(path)
    lines = p.read_text(encoding=""utf-8"", errors=""replace"").splitlines()
    sliced = lines[start:end] if end is not None else lines[start:]
    return ""\n"".join(sliced)
",src/self_edit/tools.py,,1,1.8189616842444243e-09,"The method 'view' is a utility function that reads a file and returns a specific range of lines. It is a simple and useful function for file handling, especially when dealing with large files where only a portion of the content is needed. The use of type hints and handling of optional parameters makes it flexible and robust. There is no indication that this method is obsolete or redundant, and it serves a clear purpose, so it is likely to be retained."
survived,"        def _wrap(func):
            return func
",src/self_edit/tools.py,,1,1.8553915987649156e-07,"The method _wrap is a simple utility function that returns the function it receives as an argument without any modification. Such utility functions are often used in decorators or as placeholders for more complex logic. Since it is a basic and potentially useful function, it is likely to be retained in the codebase for future use or extension."
survived,"    def function_tool(*_dargs, **_dkwargs):
        def _wrap(func):
            return func

        return _wrap
",src/self_edit/tools.py,,1,4.222835268240621e-06,"The method 'function_tool' is a decorator that takes any number of positional and keyword arguments, but it doesn't do anything with them. It simply returns the function it decorates without modification. This kind of decorator is often used as a placeholder or for future extension. Since it doesn't alter the behavior of the function it decorates, it might be considered redundant in its current form. However, it could be useful for future development or as a marker for other tools or frameworks. Therefore, it is likely to survive as it provides a flexible structure for potential future use."
survived,"        def __call__(self, func):
            return func
",src/self_edit/tools.py,_StubDecor,1,3.0590235908148916e-07,"The method is a simple implementation of the __call__ method, which allows an instance of the class to be called as a function. This specific implementation returns the function it receives as an argument without any modification. This pattern is often used in decorators, where the decorator might conditionally modify or wrap the function. Although this implementation is minimal, it serves a purpose in certain contexts where a no-op decorator is needed. Therefore, it is likely to be retained for its utility in specific scenarios."
survived,"def main(argv: Sequence[str] | None = None) -> None:
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument(""--max-cost"", type=float, default=1.0, help=""Cost budget"")
    parser.add_argument(
        ""--wallclock"",
        type=float,
        default=None,
        help=""Wallclock limit in seconds"",
    )
    args = parser.parse_args(argv)

    archive = InMemoryArchive()
    asyncio.run(
        evolve(
            lambda g: g,
            _dummy_evaluate,
            archive,
            max_cost=args.max_cost,
            wallclock=args.wallclock,
        )
    )
",src/evolve.py,,1,8.592166611791576e-10,"The method is likely to survive because it is a main function that sets up argument parsing and initiates an asynchronous process using asyncio. It is structured to handle command-line arguments, which is a common and necessary feature in many scripts and applications. The use of argparse for argument parsing and asyncio for asynchronous operations are both modern and efficient practices in Python programming. There is no indication of deprecated practices or redundancy that would suggest this method should be deleted."
survived,"    def tearDown(self) -> None:
        agents._WHEEL_PUBKEY = self.orig_pub
        agents._WHEEL_SIGS = self.orig_sigs
",tests/test_verify_wheel.py,VerifyWheelTests,1,2.5109990926928157e-08,"The method `tearDown` is a standard part of the unittest framework in Python. It is used to clean up any state that was changed during the test, ensuring that each test runs in isolation and does not affect others. The code provided is resetting some module-level variables to their original state, which is a common use case for `tearDown`. This method is essential for maintaining test integrity and is unlikely to be deleted unless the entire testing framework is being removed or replaced."
survived,"def main() -> int:
    repo_root = Path(__file__).resolve().parents[1]
    req_txt = repo_root / ""alpha_factory_v1"" / ""requirements.txt""
    lock_file = repo_root / ""alpha_factory_v1"" / ""requirements.lock""

    with tempfile.TemporaryDirectory() as tmpdir:
        out_path = Path(tmpdir) / ""requirements.lock""
        pip_compile = shutil.which(""pip-compile"")
        if pip_compile:
            cmd = [pip_compile]
        else:
            cmd = [sys.executable, ""-m"", ""piptools"", ""compile""]
        cmd += [""--quiet"", ""--generate-hashes"", str(req_txt), ""-o"", str(out_path)]
        result = subprocess.run(cmd, capture_output=True, text=True)
        sys.stdout.write(result.stdout)
        sys.stderr.write(result.stderr)
        if result.returncode != 0:
            return result.returncode
        if out_path.read_bytes() != lock_file.read_bytes():
            sys.stderr.write(
                ""alpha_factory_v1/requirements.lock is outdated. Run 'pip-compile --quiet --generate-hashes alpha_factory_v1/requirements.txt'\n""
            )
            return 1
    return 0
",scripts/verify_alpha_requirements_lock.py,,1,6.69158608681505e-10,"The method 'main' is a utility function that checks if the 'requirements.lock' file is up-to-date with the 'requirements.txt' file by using 'pip-compile'. This is a common task in software development to ensure dependencies are correctly locked and reproducible. The function is well-structured, uses temporary directories to avoid side effects, and provides clear error messages. Such functionality is essential for maintaining consistent environments, especially in larger projects. Therefore, it is likely to be retained as it serves a critical role in dependency management."
survived,"        def __init__(self, url: str) -> None:
            calls.append((""url"", url))
",tests/test_ledger.py,DummyClient,1,6.475946147757848e-07,"The method is a constructor for a class, indicated by the name `__init__`. Constructors are essential for initializing new objects in object-oriented programming. The presence of the `url` parameter suggests that this constructor is designed to initialize an object with a specific URL, which is a common requirement in many applications. Additionally, the line `calls.append((""url"", url))` suggests that this constructor is logging or tracking the initialization calls, which could be useful for debugging or analytics purposes. Therefore, it is unlikely that this method will be deleted as it serves a fundamental role in object creation and possibly in tracking object usage."
survived,"    def test_requires_token(self):
        with mock.patch.dict(os.environ, {}, clear=True):
            with self.assertRaises(SystemExit):
                with mock.patch.object(import_dashboard.sys, 'argv', ['imp.py']):
                    import_dashboard.main()
",alpha_factory_v1/tests/test_scripts_import_dashboard.py,ImportDashboardScriptTest,1,8.592166611791576e-10,"The method 'test_requires_token' is a unit test that checks if the 'import_dashboard.main()' function exits the system when no environment variables are set. This is a valid and useful test case to ensure that the application behaves correctly under certain conditions. Unit tests are generally not deleted unless they are redundant, incorrect, or replaced by better tests. Since this test is clear and serves a specific purpose, it is likely to be retained."
survived,"def _have_opencl():
    try:
        out = subprocess.run([""clinfo""], check=False, capture_output=True, text=True)
    except FileNotFoundError:
        return False
    return ""Number of platforms                               0"" not in out.stdout
",tests/test_solver_logs.py,,1,2.998960815863541e-09,"The method `_have_opencl()` is a utility function that checks for the presence of OpenCL platforms on the system by running the `clinfo` command. This is a common requirement for applications that utilize GPU computing. The method is simple, effective, and serves a specific purpose. It handles exceptions gracefully and provides a clear boolean output indicating the presence or absence of OpenCL platforms. Given its utility in environments where OpenCL is relevant, it is likely to be retained in the codebase."
survived,"    def load_dotenv(*_args, **_kwargs) -> None:
        return None
",src/meta_agent/cli/main.py,,0,0.9999999530883621,"The method `load_dotenv` is defined to accept any arguments and keyword arguments but does nothing as it simply returns `None`. This is a placeholder or a stub function, which is often used during development to allow the code to run without implementing the full functionality. However, in a production environment, such methods are typically replaced with actual implementations or removed if they are no longer needed. Since this method does not perform any meaningful operation, it is likely to be deleted unless it is used as a temporary placeholder for future development."
survived,"def dashboard(db_path: Path) -> None:
    """"""Display a simple telemetry dashboard.""""""
    db = TelemetryDB(db_path)
    records = db.fetch_all()
    if not records:
        click.echo(""No telemetry data found."")
        db.close()
        return

    click.echo(""Telemetry Dashboard:"")
    header = (
        f""{'Timestamp':<20} {'Tokens':>6} {'Cost':>7} {'Latency':>8} {'Guardrails':>10}""
    )
    click.echo(header)
    for row in records:
        ts = row[""timestamp""][:19]
        line = (
            f""{ts:<20} ""
            f""{row['tokens']:>6} ""
            f""${row['cost']:.2f} ""
            f""{row['latency']:>8.2f} ""
            f""{row['guardrail_hits']:>10}""
        )
        click.echo(line)
    db.close()
",src/meta_agent/cli/main.py,,1,4.363462233903899e-09,"The method 'dashboard' is likely to survive because it provides a useful functionality of displaying telemetry data in a formatted manner. It fetches data from a database, checks for the presence of records, and then outputs a well-structured dashboard to the console. This kind of functionality is often essential for monitoring and debugging purposes, making it a valuable part of the codebase."
survived,"def test_cli_export_json(runner, tmp_path):
    db_path = tmp_path / ""tele.db""
    db = TelemetryDB(db_path)
    db.record(5, 0.1, 0.2, 1)
    db.close()
    out = tmp_path / ""export.json""
    result = runner.invoke(
        cli,
        [
            ""export"",
            ""--db-path"",
            str(db_path),
            ""--output"",
            str(out),
            ""--format"",
            ""json"",
        ],
    )
    assert result.exit_code == 0
    assert out.exists()
",tests/test_cli.py,,1,1.2501528648238603e-09,"The method 'test_cli_export_json' is a test function that verifies the functionality of a command-line interface (CLI) export feature. It uses a temporary path to create a database, records some data, and then attempts to export this data to a JSON file. The test checks if the export command runs successfully and if the output file is created. This is a typical test case for ensuring the CLI tool works as expected, and such test functions are generally retained to maintain code quality and reliability. Therefore, it is likely to survive."
survived,"def test_model_urls() -> None:
    urls = dg.model_urls(""124M"")
    prefix = ""https://openaipublic.blob.core.windows.net/gpt-2/models/124M/""
    assert urls[0].startswith(prefix)
    assert urls[-1].endswith(""vocab.bpe"")
",tests/test_download_openai_gpt2.py,,1,1.8553915987649156e-07,"The method `test_model_urls` is a test function that verifies the URLs generated by the `dg.model_urls` function for a specific model size ('124M'). It checks that the URLs start with a specific prefix and end with a specific file name ('vocab.bpe'). This kind of test is crucial for ensuring that the URL generation logic in the `dg.model_urls` function is correct and consistent with expected patterns. Test functions like this are typically retained in codebases to ensure ongoing reliability and correctness of the code, especially when dealing with external resources or configurations that might change over time. Therefore, it is likely to be retained."
survived,"def _health_loop() -> None:
    while True:
        try:
            name, latency_ms, ok = _HEALTH_Q.get(timeout=_HEARTBEAT_INT)
        except Empty:
            continue

        quarantine = False
        stub_meta: AgentMetadata | None = None
        with _REGISTRY_LOCK:
            meta = AGENT_REGISTRY.get(name)
            if meta and not ok:
                if Counter:
                    _err_counter.labels(agent=name).inc()  # type: ignore[attr-defined]
                object.__setattr__(meta, ""err_count"", meta.err_count + 1)
                if meta.err_count >= _ERR_THRESHOLD:  # type: ignore[name-defined]
                    logger.error(
                        ""\N{NO ENTRY SIGN} Quarantining agent '%s' after %d consecutive errors"",
                        name,
                        meta.err_count,
                    )
                    stub_meta = AgentMetadata(
                        name=meta.name,
                        cls=StubAgent,
                        version=meta.version + ""+stub"",
                        capabilities=meta.capabilities,
                        compliance_tags=meta.compliance_tags,
                    )
                    quarantine = True

        if quarantine and stub_meta:
            _register(stub_meta, overwrite=True)

        logger.debug(
            ""heartbeat: %s ok=%s latency=%.1fms"",
            name,
            ok,
            latency_ms,
        )
        _emit_kafka(  # type: ignore[name-defined]
            ""agent.heartbeat"",
            json.dumps({""name"": name, ""latency_ms"": latency_ms, ""ok"": ok, ""ts"": time.time()}),
        )
",alpha_factory_v1/backend/agents/health.py,,1,9.931195248674785e-08,"The method '_health_loop' is a critical part of a system that monitors the health of agents by checking their heartbeat and latency. It handles errors by quarantining agents that exceed a certain error threshold and logs important information for debugging and monitoring purposes. This functionality is essential for maintaining the reliability and stability of the system, making it unlikely to be deleted."
survived,"def test_run_macro_demo_requires_curl(tmp_path: Path) -> None:
    """"""Script should abort when curl is missing.""""""
    bin_dir = tmp_path / ""bin""
    bin_dir.mkdir()

    docker_stub = bin_dir / ""docker""
    docker_stub.write_text(""#!/usr/bin/env bash\nexit 0\n"")
    docker_stub.chmod(0o755)

    python_exe = shutil.which(""python"")
    assert python_exe is not None
    (bin_dir / ""python"").symlink_to(python_exe)

    env = os.environ.copy()
    env.update({""PATH"": str(bin_dir), ""DOCKER_LOG"": ""/dev/null"", ""CURL_LOG"": ""/dev/null""})

    result = subprocess.run(
        [f""./{RUN_SCRIPT.name}""],
        cwd=RUN_SCRIPT.parent,
        env=env,
        capture_output=True,
        text=True,
    )

    assert result.returncode == 1
    assert ""curl is required"" in result.stderr",tests/test_macro_launcher.py,,1,2.8453347280241004e-08,"The method 'test_run_macro_demo_requires_curl' is a unit test designed to verify that a script correctly aborts when 'curl' is missing. This is a common and necessary test to ensure that the script behaves as expected in environments where 'curl' is not installed. The test sets up a temporary environment, simulates the absence of 'curl', and checks for the expected error message. Such tests are crucial for maintaining software reliability and are unlikely to be deleted unless the functionality they test is removed or significantly altered."
survived,"def test_run_cycle_creates_task(monkeypatch: pytest.MonkeyPatch) -> None:
    """"""`run_cycle` should schedule a task when called from within a loop.""""""
    mod = importlib.import_module(MODULE)

    class DummyLoop:
        def __init__(self) -> None:
            self.coro: Any | None = None

        def create_task(self, coro: Any) -> None:
            self.coro = coro

    dummy_loop = DummyLoop()
    monkeypatch.setattr(asyncio, ""get_running_loop"", lambda: dummy_loop)
    monkeypatch.setattr(asyncio, ""run"", lambda _coro: (_ for _ in ()).throw(AssertionError(""run called"")))

    async def dummy_cycle(*_a: object, **_k: object) -> None:
        pass

    monkeypatch.setattr(mod, ""run_cycle_async"", dummy_cycle)

    mod.run_cycle(mod.Orchestrator(), mod.AgentFin(), mod.AgentRes(), mod.AgentEne(), mod.AgentGdl(), mod.Model())

    assert dummy_loop.coro is not None
    assert getattr(dummy_loop.coro, ""cr_code"", None) is dummy_cycle.__code__",tests/test_alpha_agi_business_3_v1.py,,1,1.955568070542584e-08,"The method `test_run_cycle_creates_task` is a unit test function that verifies the behavior of the `run_cycle` function. It uses `monkeypatch` to mock certain parts of the `asyncio` module and the `run_cycle_async` function to ensure that a task is scheduled correctly. This is a typical pattern in testing asynchronous code, and the function is likely to be useful for maintaining code quality and ensuring that the `run_cycle` function behaves as expected. Therefore, it is unlikely to be deleted."
survived,"    def inner(y):
        return x + y
",tests/transpiler/x/py/nested_function.py,,0,0.999964643742472,"The method 'inner' uses a variable 'x' that is not defined within its scope or passed as a parameter. This will lead to a NameError when the function is called unless 'x' is defined in the enclosing scope. Without additional context indicating that 'x' is defined elsewhere, this function is likely to be deleted or refactored to include 'x' as a parameter."
survived,"    def test_insert_tree_increments_count(self):
        """"""Repeated items increment node count.""""""
        tree = FPTree([[1], [1]], 1, None, None)
        child = tree.root.get_child(1)
        self.assertIsNotNone(child)
        self.assertEqual(child.count, 2)
",tests/test_pyfpgrowth.py,FPTreeTests,1,1.8189616842444243e-09,"The method 'test_insert_tree_increments_count' is a unit test that verifies the functionality of the FPTree class, specifically ensuring that repeated items increment the node count correctly. Unit tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, this method is likely to be retained as it serves an important role in the testing suite."
survived,"    def test_tree_has_single_path_true(self):
        """"""Tree with a single path is detected correctly.""""""
        tree = FPTree([[1], [1], [1]], 1, None, None)
        self.assertTrue(tree.tree_has_single_path(tree.root))
",tests/test_pyfpgrowth.py,FPTreeTests,1,1.1861120010657661e-08,"The method 'test_tree_has_single_path_true' is a unit test that checks if a tree with a single path is correctly identified by the 'tree_has_single_path' method. Unit tests are crucial for ensuring code reliability and correctness, especially in complex data structures like trees. This test is likely part of a larger test suite that ensures the functionality of the FPTree class. Given the importance of testing in software development, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered."
survived,"        def make_response(self, predictions, image_sizes, class_names):
            return []
",tests/inference/models_predictions_tests/test_owlv2.py,DummyOwl,0,0.9999998555019682,"The method 'make_response' is defined to take three parameters: 'predictions', 'image_sizes', and 'class_names', but it currently returns an empty list regardless of the input. This suggests that the method is either incomplete or not implemented yet. If this method is part of a larger codebase, it might be intended to process predictions and return a meaningful response based on the input parameters. However, as it stands, it does not fulfill any functional purpose. Without further context or implementation, it is likely to be considered redundant or a placeholder, leading to its deletion."
survived,"        def infer_from_embed(self, *args, **kwargs):
            return []
",tests/inference/models_predictions_tests/test_owlv2.py,DummyOwl,0,0.9999998555019682,"The method 'infer_from_embed' is defined to take any number of arguments and keyword arguments but always returns an empty list. This suggests that the method is not performing any meaningful computation or processing based on the inputs. Typically, methods that do not utilize their parameters and return a constant value are considered incomplete or placeholders. Unless there is a specific reason to keep such a method (e.g., for interface compatibility or future implementation), it is likely to be deleted as it does not contribute any functional value to the code."
survived,"def test_load_translations_and_translate(monkeypatch):
    monkeypatch.setenv('DEVICONS_LANG', 'fr')
    importlib.reload(devicons)

    translations = devicons.load_translations()
    assert translations == fr.translations

    assert devicons.translate_dir_name('T√©l√©chargements') == 'Downloads'
    assert devicons.translate_dir_name('UnknownDir') == 'UnknownDir'
",tests/test_translations.py,,1,2.8453347280241004e-08,"The method `test_load_translations_and_translate` is a test function that uses `monkeypatch` to set an environment variable and then reloads a module to test its translation functionality. This is a typical pattern in testing to ensure that the code behaves correctly under different configurations. The function is likely to be retained because it serves a clear purpose in verifying the behavior of the `devicons` module, ensuring that translations are loaded and applied correctly. Test functions are crucial for maintaining code quality and reliability, especially in projects that involve internationalization."
survived,"def scan_file(path: Path) -> bool:
    try:
        text = path.read_text(encoding=""utf-8"", errors=""ignore"")
    except Exception:
        return False
    return is_proprietary_content(text)
",scripts/dp_scrubber.py,,1,2.3355930333443423e-09,"The method 'scan_file' is likely to survive because it is a simple and clear implementation that reads a file's content and checks if it contains proprietary content. It handles exceptions gracefully by returning False if an error occurs during file reading. This method is useful for applications that need to filter or process files based on their content, and its functionality is generic enough to be applicable in various contexts."
survived,"def staged_files() -> Iterable[Path]:
    result = subprocess.run(
        [""git"", ""diff"", ""--cached"", ""--name-only""], capture_output=True, text=True
    )
    if result.returncode != 0:
        raise RuntimeError(result.stderr)
    for line in result.stdout.splitlines():
        p = Path(line)
        if p.is_file():
            yield p
",scripts/dp_scrubber.py,,1,5.905303995456778e-10,"The method 'staged_files' is a utility function that retrieves the list of staged files in a Git repository. It uses subprocess to run a Git command and processes the output to yield file paths. This functionality is useful in many development and CI/CD workflows where identifying staged files is necessary for tasks like linting, testing, or deployment. The method is well-defined, handles errors, and provides a clear and useful purpose, making it likely to be retained in the codebase."
survived,"    async def serve(self) -> None:
        """"""Run the scheduler until quotas are exhausted or queue is empty.""""""
        self.start_time = time.time()
        await self.app.serve()
        # wait for running tasks to finish
        if self.running:
            await asyncio.gather(*self.running, return_exceptions=True)
",src/scheduler/__init__.py,SelfImprovementScheduler,1,1.1032560311263802e-09,"The method 'serve' is an asynchronous function that is responsible for running a scheduler until certain conditions are met. It starts by recording the current time, then calls another asynchronous method 'serve' on 'self.app'. After that, it checks if there are any running tasks and waits for them to finish using 'asyncio.gather'. This method is likely a crucial part of a larger system that manages task scheduling and execution. Given its role in managing the lifecycle of tasks and ensuring that all tasks are completed before the method exits, it is unlikely to be deleted unless there is a significant redesign of the system. Therefore, it is more likely to survive."
survived,"        def __init__(self, program_id: object, data: bytes, keys: list[object]):
            self.data = data
",tests/test_archive.py,DummyInstr,1,4.4508487281649027e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes. The presence of parameters like 'program_id', 'data', and 'keys' suggests that this constructor is designed to set up an object with these initial values. Since constructors are crucial for the creation of class instances, it is unlikely that this method will be deleted unless the entire class is being refactored or removed, which is not indicated here."
survived,"def _dummy_classes(raise_err: bool = False):
    captured = {}

    class DummyClient:
        def __init__(self, url: str) -> None:
            captured[""url""] = url

        async def send_transaction(self, tx: object, *args: object) -> None:
            if raise_err:
                raise RuntimeError(""fail"")
            captured[""root""] = tx.instructions[0].data.decode()

        async def close(self) -> None:  # pragma: no cover - dummy
            pass

    class DummyTx:
        def __init__(self) -> None:
            self.instructions = []

        def add(self, instr: object) -> ""DummyTx"":
            self.instructions.append(instr)
            return self

    class DummyInstr:
        def __init__(self, program_id: object, data: bytes, keys: list[object]):
            self.data = data

    class DummyPk:
        def __init__(self, val: str) -> None:  # pragma: no cover - dummy
            pass

    return captured, DummyClient, DummyTx, DummyInstr, DummyPk
",tests/test_archive.py,,1,1.955568070542584e-08,"The method `_dummy_classes` is a utility function that returns a set of dummy classes for testing purposes. These classes are useful for mocking and testing code that interacts with external systems, such as clients, transactions, and instructions. The method is not intended for production use but is valuable for unit testing, where real implementations are not needed or available. Since testing utilities are often retained in codebases to facilitate ongoing development and testing, it is likely that this method will survive."
survived,"    def close(self) -> None:
        if self.conn:
            self.conn.close()
            self.conn = None  # type: ignore[assignment]
",src/archive/service.py,ArchiveService,1,6.348800075736417e-09,"The method 'close' is a standard practice for managing resources, especially in database connections or file handling. It ensures that the connection is properly closed and resources are released, preventing potential memory leaks or locked resources. The method also sets the connection attribute to None after closing, which is a good practice to avoid using a closed connection. This method is likely to be retained as it is essential for resource management."
survived,"def _offline() -> bool:
    return not os.getenv(""OPENAI_API_KEY"") or os.getenv(""AGI_INSIGHT_OFFLINE"") == ""1""
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/mutators/code_diff.py,,1,1.1861120010657661e-08,"The method _offline() is a utility function that checks the environment variables to determine if the system should be considered offline. It checks for the presence of an API key and a specific offline flag. This kind of function is useful for toggling between online and offline modes in applications, especially during development or testing. Such utility functions are generally retained as they provide flexibility in application behavior based on environment settings."
survived,"    async def stop_grpc(self) -> None:
        if self._server:
            await self._server.stop(0)
            self._server = None
",src/critics/dual_critic_service.py,DualCriticService,1,8.152020648014727e-09,"The method `stop_grpc` is a straightforward and necessary utility function for stopping a gRPC server. It checks if the server is running and stops it, setting the server reference to None. This is a common pattern for managing server lifecycles, ensuring that resources are properly released. The method is concise, performs a clear task, and is likely to be used in any application that involves starting and stopping a gRPC server. Therefore, it is unlikely to be deleted as it serves an essential purpose."
survived,"    async def start_grpc(self, port: int) -> None:
        if grpc is None:
            raise RuntimeError(""grpc not installed"")
        server = grpc.aio.server()
        method = grpc.unary_unary_rpc_method_handler(
            self._handle_rpc,
            request_deserializer=lambda b: b,
            response_serializer=lambda b: b,
        )
        service = grpc.method_handlers_generic_handler(""critics.Critic"", {""Score"": method})
        server.add_generic_rpc_handlers((service,))
        server.add_insecure_port(f""[::]:{port}"")
        await server.start()
        self._server = server
",src/critics/dual_critic_service.py,DualCriticService,1,1.8189616842444243e-09,"The method 'start_grpc' is a crucial part of setting up a gRPC server asynchronously. It checks for the presence of the gRPC module, sets up a server, defines a method handler, and starts the server on a specified port. This functionality is essential for applications that rely on gRPC for communication, and there is no indication that it is deprecated or redundant. Therefore, it is likely to be retained."
survived,"    def __init__(self, docs: Iterable[str] | None = None) -> None:
        self.docs = list(docs or [])
",src/critics/dual_critic_service.py,VectorDB,1,6.023574641292144e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting initial values for their attributes. This particular constructor is flexible, allowing for an optional iterable of strings to be passed in, which it then converts to a list. This kind of functionality is common and useful, making it unlikely to be deleted."
survived,"    def test_post_json(self):
        self.server, self.thread, H, url = start_server()
        payload = {""x"": 1}
        resp = requests.post(url, json=payload)
        self.assertEqual(resp.json(), payload)
        self.assertEqual(H.received_body, json.dumps(payload).encode())
        self.assertEqual(H.received_headers.get(""Content-Type""), ""application/json"")
",alpha_factory_v1/tests/test_requests_shim.py,RequestsShimTest,1,3.2241866333029355e-08,"The method 'test_post_json' is a unit test that verifies the functionality of posting JSON data to a server. It checks if the server correctly receives and processes the JSON payload, and if the headers are set appropriately. This is a fundamental test for any application that deals with JSON data exchange, ensuring that the server-client communication is working as expected. Such tests are crucial for maintaining the integrity of data handling in web applications, making it unlikely for this method to be deleted."
survived,"    def tearDown(self):
        if hasattr(self, ""server""):
            self.server.shutdown()
            self.thread.join()
            self.server.server_close()
",alpha_factory_v1/tests/test_requests_shim.py,RequestsShimTest,1,4.6911638017642294e-08,"The method `tearDown` is a common method used in unit testing frameworks like `unittest` in Python. It is typically used to clean up resources after a test case has been executed. The code provided is performing cleanup operations by shutting down a server, joining a thread, and closing the server. These are essential operations to ensure that resources are properly released and do not interfere with other tests. Therefore, this method is likely to be retained as it serves a critical role in the testing lifecycle."
survived,"    def tearDown(self):
        mv._embed = self._orig_embed
",alpha_factory_v1/tests/test_vector_memory.py,VectorMemoryTest,1,1.1253518384332553e-07,"The method 'tearDown' is a common method used in unit testing frameworks like unittest in Python. It is typically used to clean up or reset the state after each test case is run. The code snippet provided suggests that it is restoring the '_embed' attribute of 'mv' to its original state, which is a typical use case for 'tearDown'. This method is likely part of a test suite and serves a necessary function in ensuring tests do not interfere with each other by leaving shared state modified. Therefore, it is unlikely to be deleted as it is essential for maintaining test integrity."
survived,"    def test_register_basic(self):
        @register
        class FooAgent(AgentBase):
            NAME = ""foo""
        self.assertIn(""foo"", AGENT_REGISTRY)
",alpha_factory_v1/tests/test_register_decorator.py,RegisterDecoratorTest,1,1.6052280526088547e-09,"The method `test_register_basic` is a unit test designed to verify that the `register` decorator correctly registers a class in the `AGENT_REGISTRY`. This is a fundamental test to ensure that the registration mechanism works as expected, which is crucial for the functionality of any system relying on dynamic class registration. Such tests are typically retained to ensure the integrity of the registration process, especially if the system is extended or modified in the future. Therefore, the method is likely to be retained."
survived,"    def flush(self) -> None:
        """"""Erase all stored events.""""""
        self.file.write_text("""")
",alpha_factory_v1/backend/memory.py,Memory,1,2.3355930333443423e-09,"The method 'flush' is a simple utility function that clears the contents of a file by writing an empty string to it. This is a common operation in file handling, especially when dealing with logs or temporary data storage. The method is straightforward, has a clear purpose, and is likely to be useful in contexts where resetting the file content is necessary. Therefore, it is likely to be retained in the codebase."
survived,"    def test_parse_defaults(self):
        args = _parse_with([])
        self.assertFalse(args.dev)
        self.assertFalse(args.preflight)
        self.assertIsNone(args.port)
        self.assertIsNone(args.metrics_port)
        self.assertIsNone(args.a2a_port)
        self.assertIsNone(args.enabled)
        self.assertEqual(args.loglevel, 'INFO')
",alpha_factory_v1/tests/test_cli.py,CliParseTest,1,1.0467401685178159e-08,"The method 'test_parse_defaults' is a unit test that checks the default values of arguments parsed by the '_parse_with' function. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with configurations and defaults. This method is likely to be retained as it provides a way to verify that the default settings are correctly applied, which is important for maintaining the stability of the application."
survived,"    def test_apply_env(self):
        args = _parse_with([
            '--dev',
            '--port', '1234',
            '--metrics-port', '5678',
            '--a2a-port', '9100',
            '--enabled', 'foo,bar',
            '--loglevel', 'debug',
        ])
        for key in ('DEV_MODE', 'PORT', 'METRICS_PORT', 'A2A_PORT', 'ALPHA_ENABLED_AGENTS', 'LOGLEVEL'):
            os.environ.pop(key, None)
        af_run.apply_env(args)
        self.assertEqual(os.environ['DEV_MODE'], 'true')
        self.assertEqual(os.environ['PORT'], '1234')
        self.assertEqual(os.environ['METRICS_PORT'], '5678')
        self.assertEqual(os.environ['A2A_PORT'], '9100')
        self.assertEqual(os.environ['ALPHA_ENABLED_AGENTS'], 'foo,bar')
        self.assertEqual(os.environ['LOGLEVEL'], 'DEBUG')
",alpha_factory_v1/tests/test_cli.py,CliParseTest,1,5.60279640614594e-09,"The method `test_apply_env` is a unit test designed to verify the functionality of the `apply_env` method. It sets up a specific environment, applies the environment settings using `apply_env`, and then checks if the environment variables are set correctly. This is a typical pattern for testing configuration application functions. Since testing is a crucial part of software development to ensure code reliability and correctness, this method is likely to be retained as part of the test suite."
survived,"    def test_discover_alpha_invalid_zero_default_model(self) -> None:
        with self.assertRaises(ValueError):
            stub.discover_alpha(num=0, ledger=None)
",alpha_factory_v1/tests/test_cross_industry_alpha.py,TestCrossIndustryAlpha,1,2.8453347280241004e-08,"The method `test_discover_alpha_invalid_zero_default_model` is a unit test designed to ensure that the `discover_alpha` function raises a `ValueError` when called with a `num` parameter of 0. This is a valid and necessary test case to ensure the robustness of the `discover_alpha` function, as it checks for proper error handling when invalid input is provided. Unit tests like this are crucial for maintaining code quality and preventing regressions. Therefore, it is unlikely to be deleted."
survived,"def test_generate_pkce_pair_same_key():
    st.session_state.clear()
    p1 = _generate_pkce_pair(""S256"", key=""x"")
    p2 = _generate_pkce_pair(""S256"", key=""x"")
    assert p1 == p2
    assert len(p1) == 2
",tests/test_internal.py,,1,1.3440409770490404e-08,"The method 'test_generate_pkce_pair_same_key' is a test function that checks the behavior of the '_generate_pkce_pair' function when the same key is used. It ensures that the function returns consistent results for the same input, which is a valid and useful test case. Test functions are generally retained unless they are redundant or incorrect, and this one seems to serve a clear purpose in verifying the functionality of '_generate_pkce_pair'. Therefore, it is likely to be retained."
survived,"    def __init__(self, d_model: int, num_heads: int, max_seq_len: int = 512):
        super().__init__()
        self.num_heads = num_heads
        self.d_model = d_model
        self.head_dim = d_model // num_heads
        assert (
            d_model % num_heads == 0
        ), ""d_model must be divisible by num_heads""

        self.wq = nn.Linear(d_model, d_model)
        self.wk = nn.Linear(d_model, d_model)
        self.wv = nn.Linear(d_model, d_model)
        self.dense = nn.Linear(d_model, d_model)

        inv_freq = 1.0 / (
            10000 ** (torch.arange(0, self.head_dim, 2, dtype=torch.float32) / self.head_dim)
        )
        t = torch.arange(max_seq_len, dtype=torch.float32)
        freqs = torch.einsum(""i,j->ij"", t, inv_freq)
        emb = torch.cat((freqs, freqs), dim=-1)
        self.register_buffer(""cos_cached"", emb.cos()[None, None, :, :], persistent=False)
        self.register_buffer(""sin_cached"", emb.sin()[None, None, :, :], persistent=False)

        self._reset_parameters()
",src/model/u2tokenizer/rope.py,RotaryMultiheadAttention,1,3.927863699585036e-07,"The method is a constructor for a class, likely part of a neural network module, initializing key components for multi-head attention. It includes assertions, buffer registration, and parameter initialization, all of which are essential for the correct functioning of the model. The use of PyTorch's nn.Linear and buffer registration indicates it's part of a larger model architecture, likely for transformer-based models. Such methods are fundamental and unlikely to be removed unless the entire architecture is deprecated or significantly refactored."
survived,"    def split_heads(self, x: torch.Tensor, batch_size: int) -> torch.Tensor:
        x = x.view(batch_size, -1, self.num_heads, self.head_dim)
        return x.permute(0, 2, 1, 3)
",src/model/u2tokenizer/rope.py,RotaryMultiheadAttention,1,2.646573631904765e-09,"The method `split_heads` is a common utility function used in transformer models, particularly in the implementation of multi-head attention mechanisms. It reshapes and permutes the input tensor to separate the different attention heads, which is a crucial step in the attention computation process. Given the widespread use of transformers in modern machine learning tasks, especially in natural language processing, this method is likely to be retained as it serves a fundamental role in these models."
survived,"    def __init__(self, settings: config.Settings | None = None) -> None:
        self.settings = settings or config.CFG
        insight_logging.setup(json_logs=self.settings.json_logs)
        bus = messaging.A2ABus(self.settings)
        ledger = Ledger(
            self.settings.ledger_path,
            rpc_url=self.settings.solana_rpc_url,
            wallet=self.settings.solana_wallet,
            broadcast=self.settings.broadcast,
            db=self.settings.db_type,
        )
        archive = ArchiveService(
            os.getenv(""ARCHIVE_PATH"", ""archive.db""),
            rpc_url=self.settings.solana_rpc_url,
            wallet=self.settings.solana_wallet,
            broadcast=self.settings.broadcast,
        )
        solution_archive = SolutionArchive(os.getenv(""SOLUTION_ARCHIVE_PATH"", ""solutions.duckdb""))
        registry = StakeRegistry()
        if resource is not None:
            try:
                limit = 8 * 1024 * 1024 * 1024
                resource.setrlimit(resource.RLIMIT_AS, (limit, limit))
            except Exception:  # pragma: no cover - unsupported platform
                pass
        super().__init__(
            bus,
            ledger,
            archive,
            solution_archive,
            registry,
            self.settings.island_backends,
            err_threshold=ERR_THRESHOLD,
            backoff_exp_after=BACKOFF_EXP_AFTER,
            promotion_threshold=PROMOTION_THRESHOLD,
        )
        for agent in self._init_agents():
            self.add_agent(agent)
",alpha_factory_v1/core/orchestrator.py,Orchestrator,1,4.363462233903899e-09,"The method is a constructor (__init__) for a class, which is a fundamental part of object-oriented programming. It initializes various components and services, such as logging, messaging, ledger, and archives, which are likely essential for the functionality of the class. The method also handles resource limits and initializes agents, indicating it plays a crucial role in setting up the environment and dependencies for the class. Such methods are typically not deleted unless the entire class is refactored or removed, which is less common. Therefore, it is likely to survive."
survived,"def pareto_front(pop: Population) -> Population:
    """"""Return the non-dominated set ranked by crowding distance.""""""

    if not pop:
        return []

    fits = np.asarray([ind.fitness for ind in pop], dtype=float)
    dominated = np.zeros(len(pop), dtype=bool)
    for i, fi in enumerate(fits):
        dom = np.all(fi <= fits, axis=1) & np.any(fi < fits, axis=1)
        dominated |= dom
        dominated[i] = False
    front = [ind for ind, d in zip(pop, dominated) if not d]
    _crowding(front)
    return sorted(front, key=lambda x: -x.crowd)",alpha_factory_v1/core/simulation/mats.py,,1,8.152020648014727e-09,"The method 'pareto_front' is a well-defined function that calculates the Pareto front of a given population, which is a common operation in multi-objective optimization problems. It checks for non-dominated solutions and ranks them by crowding distance, which is a standard approach in evolutionary algorithms. The function is useful, correctly implemented, and serves a specific purpose in optimization tasks, making it unlikely to be deleted."
survived,"def _non_dominated_sort(pop: Population) -> List[Population]:
    """"""Group ``pop`` into Pareto fronts.""""""

    fronts: List[Population] = []
    S: dict[int, list[Individual]] = {id(ind): [] for ind in pop}
    n: dict[int, int] = {id(ind): 0 for ind in pop}
    for ind in pop:
        assert ind.fitness is not None
    for p in pop:
        for q in pop:
            if p is q:
                continue
            assert q.fitness is not None
            assert p.fitness is not None
            if all(pf <= qf for pf, qf in zip(p.fitness, q.fitness)):
                if any(pf < qf for pf, qf in zip(p.fitness, q.fitness)):
                    S[id(p)].append(q)
            elif all(qf <= pf for pf, qf in zip(p.fitness, q.fitness)):
                if any(qf < pf for pf, qf in zip(p.fitness, q.fitness)):
                    n[id(p)] += 1
        if n[id(p)] == 0:
            p.rank = 0
            if not fronts:
                fronts.append([])
            fronts[0].append(p)
    i = 0
    while i < len(fronts):
        nxt: Population = []
        for p in fronts[i]:
            for q in S[id(p)]:
                n[id(q)] -= 1
                if n[id(q)] == 0:
                    q.rank = i + 1
                    nxt.append(q)
        if nxt:
            fronts.append(nxt)
        i += 1
    return fronts
",alpha_factory_v1/core/simulation/mats.py,,1,4.363462233903899e-09,"The method `_non_dominated_sort` is a well-defined function that implements a non-dominated sorting algorithm, which is a crucial part of many multi-objective optimization algorithms, such as NSGA-II. This function is responsible for sorting a population into different Pareto fronts based on their fitness values. The code is clear, uses type annotations, and includes assertions to ensure that fitness values are not None. Given its utility in evolutionary algorithms and the clarity of its implementation, it is likely to be retained in the codebase."
survived,"def simulate_years(sectors: Iterable[Sector], horizon: int) -> List[ForecastPoint]:
    results: List[ForecastPoint] = []
    traj = forecast_disruptions(sectors, horizon)
    for point in traj:
        affected = [s for s in point.sectors if s.disrupted]
        results.append(ForecastPoint(point.year, point.capability, affected))
    return results",alpha_factory_v1/core/simulation/forecast.py,,1,3.160881453314576e-10,"The method 'simulate_years' is likely to survive because it appears to be a well-structured and functional piece of code. It takes in a list of sectors and a time horizon, forecasts disruptions, and returns a list of forecast points, which is a common requirement in predictive modeling and simulation tasks. The method is clear in its purpose and implementation, making it useful for applications that require forecasting and analysis of sector disruptions over time."
survived,"def _noop(*_a: Any, **_kw: Any) -> Any:
    class _N:
        def labels(self, *_a: Any, **_kw: Any) -> ""_N"":
            return self

        def observe(self, *_a: Any) -> None:
            ...

        def inc(self, *_a: Any) -> None:
            ...

    return _N()
",alpha_factory_v1/core/utils/tracing.py,,1,5.3157849718487075e-08,"The method _noop is a utility function that returns an instance of a nested class _N. This class has methods that do nothing (no-op) but are structured to mimic an interface or expected behavior. Such methods are often used as placeholders or default implementations in larger systems where actual functionality might be conditionally added. The presence of these methods suggests that they are part of a design pattern or framework that requires these methods to exist, even if they do nothing by default. Therefore, the method is likely to survive as it serves a purpose in maintaining a consistent interface or structure."
survived,"    def verify_ledger(self, expected: str, agent_id: str) -> None:
        actual = self.ledger.compute_merkle_root()
        if actual != expected:
            self.slash(agent_id)
",alpha_factory_v1/backend/demo_orchestrator.py,DemoOrchestrator,1,1.522997951276035e-08,"The method 'verify_ledger' is a utility function that checks if the computed Merkle root of a ledger matches an expected value. If it doesn't match, it calls another method 'slash' with the agent_id. This method is likely part of a larger system that deals with ledger verification and agent accountability, which are critical in systems like blockchain or distributed ledgers. Such functionality is essential for maintaining integrity and trust in the system, making it unlikely to be removed unless the entire system undergoes a significant redesign or the method is replaced with a more efficient or secure alternative."
survived,"    def verify_merkle_root(self, expected: str, agent_id: str) -> None:
        actual = self.ledger.compute_merkle_root()
        if actual != expected:
            self.slash(agent_id)
",alpha_factory_v1/backend/demo_orchestrator.py,DemoOrchestrator,1,8.592166611791576e-10,"The method 'verify_merkle_root' is likely to survive because it performs a critical function in verifying the integrity of data using a Merkle root, which is a common practice in blockchain and distributed ledger technologies. The method ensures that the computed Merkle root matches the expected value and takes action (slashing) if there is a discrepancy, which is essential for maintaining trust and security in the system."
survived,"def test_typical_payload_returns_float() -> None:
    payload = {""latency_ms"": 400, ""tokens"": 500, ""cost_usd"": 0.002, ""energy_j"": 20, ""value"": 0.8}
    value = er.reward(None, None, payload)
    assert isinstance(value, float)
    assert 0.0 <= value <= 1.0
",tests/test_efficiency_reward.py,,1,5.60279640614594e-09,"The method 'test_typical_payload_returns_float' is a unit test designed to verify that the 'er.reward' function returns a float value within a specified range when given a typical payload. Unit tests are crucial for ensuring code reliability and correctness, especially in complex systems. This test checks both the type and the value range of the output, which are common and important aspects to validate in software testing. Therefore, this method is likely to be retained as it serves a valuable purpose in maintaining code quality."
survived,"    def subscribe(self, topic: str, handler) -> None:  # pragma: no cover - dummy
        pass
",tests/test_safety_guardian_property.py,DummyBus,0,0.9999992661791398,"The method 'subscribe' is marked with a pragma directive 'no cover', indicating that it is a placeholder or a dummy implementation. This suggests that the method is not currently functional and is likely intended to be implemented in the future. However, the presence of this directive also implies that the method is not being tested, which could lead to its removal if it remains unused or unimplemented for an extended period. Without further context on its intended use or any plans for future implementation, it is more likely to be deleted if it continues to serve no purpose."
survived,"def clone_sample_repo() -> None:
    """"""Clone the example repo, falling back to the bundled copy.""""""
    result = subprocess.run([""git"", ""clone"", REPO_URL, CLONE_DIR], capture_output=True)
    if result.returncode != 0:
        if LOCAL_REPO.exists():
            shutil.copytree(LOCAL_REPO, CLONE_DIR)
        else:
            result.check_returncode()
",alpha_factory_v1/demos/self_healing_repo/agent_selfheal_entrypoint.py,,1,5.905303995456778e-10,"The method 'clone_sample_repo' is a utility function that attempts to clone a repository from a given URL. If the cloning fails, it falls back to copying a local repository. This kind of functionality is useful in scenarios where network issues might prevent cloning from a remote source, ensuring that the process can still proceed using a local copy. Such fallback mechanisms are common in robust software development practices to handle potential failures gracefully. Therefore, this method is likely to be retained as it provides a valuable fail-safe mechanism."
survived,"    def import_algorithm_packages(self) -> Dict[str, Any]:
        """"""Import ``llmcompressor`` packages lazily.""""""
        try:
            from llmcompressor import oneshot
            from llmcompressor.modifiers.awq import AWQModifier
        except Exception as e:  # pragma: no cover - dependency missing
            raise ImportError(
                ""llmcompressor is not installed. Please install it using `pip install llmcompressor`.""
            ) from e
        return {""oneshot"": oneshot, ""AWQModifier"": AWQModifier}",src/pruna/algorithms/quantization/llm_compressor.py,LLMCompressorQuantizer,1,1.6052280526088547e-09,"The method is likely to survive because it provides a clear and useful functionality: it lazily imports specific packages from the 'llmcompressor' library and handles the case where the library is not installed by raising an informative ImportError. This is a common pattern in Python to manage optional dependencies and ensure that the code can fail gracefully if the required packages are not available. Additionally, the method returns a dictionary of the imported modules, which can be useful for further processing or usage in the code."
survived,"    def archive_accept(self, agent_id: str) -> None:
        """"""Burn 1% of ``agent_id`` stake when a candidate is accepted.""""""
        self.burn(agent_id, 0.01)
",src/governance/stake_registry.py,StakeRegistry,1,1.8189616842444243e-09,"The method 'archive_accept' is a simple utility function that calls another method 'burn' with a specific percentage. It is likely part of a larger system where agents have stakes, and certain actions like accepting a candidate result in a small penalty or fee. This method is straightforward, has a clear purpose, and is likely used in the context of managing agent stakes. Unless the system's requirements change significantly, such as removing the concept of burning stakes, this method is likely to survive."
survived,"def config_paths():
    return [p for p in CONFIG_DIR.rglob('*.json')]
",tests/test_configs.py,,1,2.3355930333443423e-09,"The method `config_paths` is a simple utility function that returns a list of all JSON files within a directory specified by `CONFIG_DIR`. This type of function is commonly used in applications to dynamically load configuration files, which is a fundamental requirement in many software systems. Given its utility and the fact that it is a non-complex, non-redundant piece of code, it is likely to be retained in the codebase."
survived,"    async def step(self) -> None:  # noqa: D401
        """"""Delegate step execution to :meth:`run_cycle`.""""""
        await self.run_cycle()
",alpha_factory_v1/backend/agents/talent_match_agent.py,TalentMatchAgent,1,2.5109990926928157e-08,"The method 'step' is a simple asynchronous function that delegates its execution to another method 'run_cycle'. It is likely part of a larger class or module where 'run_cycle' is defined. The method itself is straightforward and serves a clear purpose, which is to encapsulate the call to 'run_cycle'. Unless there is a significant change in the design or requirements of the system that makes this delegation unnecessary, the method is likely to survive. It provides a clean and readable way to execute 'run_cycle' asynchronously, which is a common pattern in asynchronous programming."
survived,"    async def step(self) -> None:  # noqa: D401
        """"""Delegate step execution to :meth:`run_cycle`.""""""
        await self.run_cycle()
",alpha_factory_v1/backend/agents/policy_agent.py,PolicyAgent,1,3.3982678079468468e-09,"The method 'step' is a simple asynchronous function that delegates its execution to another method 'run_cycle'. It is well-documented and follows a clear purpose, which is to execute a step by calling 'run_cycle'. There is no indication of redundancy or lack of use from the provided code snippet. Without additional context suggesting that 'step' is no longer needed or has been replaced, it is reasonable to predict that this method will survive."
survived,"def thermodynamic_trigger(sector: Sector, capability: float) -> bool:
    delta_g = sector.energy - capability * sector.entropy
    return delta_g < 0
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/simulation/forecast.py,,1,1.8189616842444243e-09,"The method `thermodynamic_trigger` is a simple and clear function that calculates a thermodynamic condition based on the Gibbs free energy equation (delta G = energy - T*entropy). It is likely to be useful in contexts where such calculations are needed, such as in simulations or models involving thermodynamics. The function is concise, performs a specific calculation, and returns a boolean value indicating whether a certain condition is met. These characteristics suggest that the method is well-defined and serves a purpose, making it likely to be retained in the codebase."
survived,"    def __init__(self, bus, ledger) -> None:
        super().__init__(""market"", bus, ledger)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/market_agent.py,MarketAgent,1,5.3157849718487075e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting up initial states. Therefore, it is unlikely to be deleted as it serves a critical role in the class's functionality."
survived,"    async def handle(self, env):
        pass",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/codegen_agent.py,CodeGenAgent,0,0.9999999847700205,"The method 'handle' is defined as an asynchronous function but contains only a 'pass' statement, meaning it currently does nothing. Without any implementation or documentation indicating future use, it is likely to be considered dead code. Unless there is a specific plan to implement this method in the future, it is likely to be deleted to clean up the codebase."
survived,"    async def handle(self, env):
        pass",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/research_agent.py,ResearchAgent,0,0.9999997897565932,"The method 'handle' is defined as an asynchronous function but contains only a 'pass' statement, meaning it currently does nothing. Without any implementation, it serves no functional purpose in its current state. Unless it is intended to be overridden in a subclass or is a placeholder for future development, it is likely to be deleted as it does not contribute to the codebase."
survived,"    def extract_output(response: ModelOutput, include_thoughts: bool = True):
        """"""
        Extract and format the output text from the Gemini response.
        """"""
        text = """"

        if include_thoughts and response.thoughts:
            text += f""<think>{response.thoughts}</think>\n""

        if response.text:
            text += response.text
        else:
            text += str(response)

        # Fix some escaped characters
        text = text.replace(""&lt;"", ""<"").replace(""\\<"", ""<"").replace(""\\_"", ""_"").replace(""\\>"", "">"")

        def simplify_link_target(text_content: str) -> str:
            match_colon_num = re.match(r""([^:]+:\d+)"", text_content)
            if match_colon_num:
                return match_colon_num.group(1)
            return text_content

        def replacer(match: re.Match) -> str:
            outer_open_paren = match.group(1)
            display_text = match.group(2)

            new_target_url = simplify_link_target(display_text)
            new_link_segment = f""[`{display_text}`]({new_target_url})""

            if outer_open_paren:
                return f""{outer_open_paren}{new_link_segment})""
            else:
                return new_link_segment

        # Replace Google search links with simplified markdown links
        pattern = r""(\()?\[`([^`]+?)`\]\((https://www.google.com/search\?q=)(.*?)(?<!\\)\)\)*(\))?""
        text = re.sub(pattern, replacer, text)

        # Fix inline code blocks
        pattern = r""`(\[[^\]]+\]\([^\)]+\))`""
        return re.sub(pattern, r""\1"", text)",app/services/client.py,GeminiClientWrapper,1,4.363462233903899e-09,"The method 'extract_output' is a utility function that processes and formats text from a response object. It includes features like handling optional thoughts, fixing escaped characters, simplifying link targets, and replacing certain patterns with markdown links. These functionalities are useful for text processing and formatting, which are common tasks in software development. The method is well-structured and addresses specific needs, making it likely to be retained in the codebase."
survived,"    def acquire(self, client_id: Optional[str] = None) -> GeminiClientWrapper:
        """"""Return a client by id or using round-robin.""""""
        if client_id:
            client = self._id_map.get(client_id)
            if not client:
                raise ValueError(f""Client id {client_id} not found"")
            return client

        client = self._round_robin[0]
        self._round_robin.rotate(-1)
        return client
",app/services/pool.py,GeminiClientPool,1,2.7894680920908113e-10,"The method 'acquire' is likely to survive because it provides a useful functionality of retrieving a client either by a specific ID or through a round-robin mechanism. This dual functionality makes it flexible and adaptable to different use cases, which is valuable in a client management system. Additionally, the method is well-structured, with error handling for cases where a client ID is not found, which indicates good coding practices."
survived,"    def status(self) -> Dict[str, bool]:
        """"""Return running status for each client.""""""
        return {client.id: client.running for client in self._clients}",app/services/pool.py,GeminiClientPool,1,6.69158608681505e-10,"The method 'status' is a simple and clear utility function that provides a useful feature: it returns the running status of each client in a dictionary format. This is likely a common requirement in systems that manage multiple clients, as it allows for easy monitoring and management of client states. The method is well-defined, with a clear purpose and implementation, making it unlikely to be removed unless there is a significant change in the system's architecture or requirements. Therefore, it is predicted to survive."
survived,"    def get_random_action(self):
        '''
        get_random_action
        '''
        action = random.choice(list(self.cfg.color_code.values()))
        logger.warning(f""Perform random action: {action}"")
        return action
",src/legacy/mapleStoryAutoLevelUp_legacy.py,MapleStoryBot,1,1.6052280526088547e-09,"The method 'get_random_action' is a simple utility function that selects a random action from a list of values derived from 'self.cfg.color_code'. It uses the 'random.choice' method to achieve this, which is a common and useful operation in many applications, especially those involving randomness or simulations. Additionally, it logs the action taken, which is good for debugging and tracking purposes. There is no indication that this method is redundant or poorly implemented, so it is likely to be retained in the codebase."
survived,"    def update_img_frame_debug(self):

        '''
        update_img_frame_debug
        '''
        cv2.imshow(""Game Window Debug"",
                   self.img_frame_debug[self.cfg.camera_ceiling:self.cfg.camera_floor, :])
        # Update FPS timer
        self.t_last_frame = time.time()
",src/legacy/mapleStoryAutoLevelUp_legacy.py,MapleStoryBot,0,0.9999984465026855,"The method 'update_img_frame_debug' is a simple utility function that displays an image frame using OpenCV's imshow function and updates a timer. It is likely part of a debugging process to visualize frames during development. Such methods are often useful during the development and testing phases to ensure that the image processing pipeline is functioning correctly. However, in a production environment, this method might be removed or replaced with logging mechanisms that do not require a GUI display, as displaying windows can be resource-intensive and not suitable for headless environments. Therefore, the method is likely to be deleted in a production setting."
survived,"        def latest_log(self):
            return ""stub""
",tests/test_aiga_openai_bridge_offline.py,_DummyEvolver,0,0.9999999634651793,"The method `latest_log` is a placeholder method that returns a static string ""stub"". This indicates that the method is not yet implemented and does not perform any meaningful operation. In a production environment, such methods are typically either completed with actual functionality or removed if deemed unnecessary. Given that it currently serves no purpose, it is likely to be deleted unless it is planned to be implemented in the future."
survived,"        def dec(f):
            return f
",tests/test_aiga_openai_bridge_offline.py,,1,8.31527990378713e-07,"The method 'dec' is a simple decorator that returns the function it receives without any modification. Such a decorator can be useful in scenarios where conditional decoration is needed or when a placeholder decorator is required for future enhancements. It doesn't add any overhead or complexity, so it is likely to be retained for potential future use or as a part of a larger framework where decorators are dynamically applied."
survived,"    async def handle(self, _env) -> None:
        pass
",tests/test_alert_webhook.py,DummyAgent,0,0.5621765008857981,"The method 'handle' is defined as an asynchronous function but currently does nothing as it only contains a 'pass' statement. This suggests that it might be a placeholder for future implementation. However, without any additional context or usage, it's difficult to determine its necessity. If the method is part of a larger framework or system where it is expected to be overridden or implemented later, it might survive. Otherwise, if it remains unused and unimplemented, it could be deleted in future refactoring efforts to clean up the codebase."
survived,"def compose_stack() -> None:
    subprocess.run([""docker"", ""compose"", ""-f"", str(COMPOSE_FILE), ""up"", ""-d""], check=True)
    try:
        yield
    finally:
        subprocess.run([""docker"", ""compose"", ""-f"", str(COMPOSE_FILE), ""down"", ""-v""], check=False)
",tests/test_compose_health.py,,0,0.999983298584886,"The method 'compose_stack' is designed to manage Docker Compose operations, bringing up a stack and ensuring it is taken down properly. However, the use of 'yield' in a function that is not a generator (as it lacks a 'yield' statement in a loop or context) suggests a misunderstanding of Python's generator functions. This could lead to runtime errors or unexpected behavior. Without proper context management or a clear generator pattern, this method is likely to be refactored or deleted to correct the logic."
survived,"def test_single_network_request() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri()

    with sync_playwright() as p:
        browser = p.chromium.launch()
        page = browser.new_page()
        requests: list[str] = []
        page.on(
            ""request"",
            lambda req: requests.append(req.url)
            if req.url.endswith("".js"") and not req.url.endswith(""sw.js"")
            else None,
        )
        page.goto(url)
        page.wait_for_selector(""#controls"")
        assert requests == [page.url.replace(""index.html"", ""insight.bundle.js"")]
        browser.close()",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_single_network_request.py,,1,2.998960815863541e-09,"The method 'test_single_network_request' is a test function that uses Playwright to automate a browser and verify network requests. It is a specific and useful test for ensuring that the correct JavaScript file is being requested when a page is loaded. This kind of test is important for maintaining the integrity of web applications, especially when dealing with dynamic content and dependencies. Given the increasing reliance on automated testing in software development, this method is likely to be retained as it provides value in ensuring the correct behavior of the application."
survived,"    def insert_after_task(self, *, path: str, anchor: str, code: str) -> dict[str, bool]:
        insert_after(path, anchor, code)
        return {""ok"": True}
",src/self_edit/tools.py,FileToolsADK,1,1.1861120010657661e-08,"The method 'insert_after_task' is a simple wrapper around the 'insert_after' function, adding a return statement that indicates success. This method is likely to survive because it provides a clear and straightforward interface for inserting code after a specified anchor in a file, which can be a common task in code manipulation or templating systems. The use of keyword-only arguments also suggests a design choice for clarity and explicitness, which is a positive aspect in API design."
survived,"    def view_lines_task(self, *, path: str, start: int, end: Optional[int] = None) -> dict[str, str]:
        return {""text"": view_lines(path, start, end)}
",src/self_edit/tools.py,FileToolsADK,0,0.9999930377415741,"The method 'view_lines_task' is a simple wrapper around the 'view_lines' function, adding no additional logic or functionality. It merely formats the output into a dictionary with a single key-value pair. Such methods are often considered redundant unless they are part of a larger interface or API where consistency in return types is required. Without additional context suggesting its necessity, it is likely to be refactored or removed to simplify the codebase."
survived,"def archive_ls(proof: bool, db_path: str) -> None:
    """"""List pinned CIDs.""""""

    arch = HashArchive(db_path)
    entries = arch.list_entries()
    if not entries:
        click.echo(""No archive entries"")
        return
    headers = [""id"", ""cid""]
    rows = [(e[0], e[2]) for e in entries]
    if proof:
        root = arch.merkle_root()
        headers.append(""proof"")
        rows = [(r[0], r[1], root[:16]) for r in rows]
    _rich_table(headers, rows)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/cli.py,,1,1.4166087846364157e-09,"The method 'archive_ls' is a utility function that lists entries from a database, potentially with a proof if specified. It is a straightforward function that serves a clear purpose in the context of managing or displaying archived data. Such utility functions are generally useful in applications that deal with data management, especially when dealing with archives or databases. There is no indication that this function is redundant or obsolete, and it seems to be a necessary part of a larger system that handles data archiving. Therefore, it is likely to be retained in the codebase."
survived,"def generate_proof(transcript_path: str | Path, agent_hash: str, score: Sequence[float]) -> str:
    """"""Return deterministic proof string for the transcript entry.""""""
    transcript = Path(transcript_path)
    if not _find_entry(transcript, agent_hash, score):
        raise ValueError(""entry not found in transcript"")
    transcript_hash = hashlib.sha256(transcript.read_bytes()).hexdigest()
    blob = json.dumps({""hash"": agent_hash, ""score"": list(score), ""transcript"": transcript_hash}, separators=("","", "":"")).encode()
    return hashlib.sha256(blob).hexdigest()
",src/utils/snark.py,,1,1.2501528648238603e-09,"The method 'generate_proof' is well-defined and serves a clear purpose: generating a deterministic proof string based on a transcript, agent hash, and score. It includes error handling for missing entries and uses secure hashing methods to ensure data integrity. The use of type hints and standard libraries like hashlib and json indicates good coding practices. There is no indication of redundancy or obsolescence, suggesting that the method is likely to be useful in its current form."
survived,"def volkswagen_mqb_meb_checksum(address: int, sig, d: bytearray) -> int:
  crc = 0xFF
  for i in range(1, len(d)):
    crc ^= d[i]
    crc = CRC8H2F[crc]
  counter = d[1] & 0x0F
  const = VOLKSWAGEN_MQB_MEB_CONSTANTS.get(address)
  if const:
    crc ^= const[counter]
    crc = CRC8H2F[crc]
  return crc ^ 0xFF
",opendbc/car/volkswagen/mqbcan.py,,1,7.194132978569833e-09,"The method 'volkswagen_mqb_meb_checksum' is a utility function that calculates a checksum for a specific use case involving Volkswagen's MQB and MEB platforms. It uses a CRC8 algorithm, which is a common method for error-checking in data transmission. The function is specific to a particular application, as it references constants and a lookup table (CRC8H2F) that are likely defined elsewhere in the codebase. Such functions are typically retained because they serve a specific purpose in ensuring data integrity, which is crucial in automotive applications. Unless the entire system or the method of checksum calculation is deprecated, this function is likely to survive."
survived,"def prefer_fast_model() -> ModelPreferences:
    """"""Model preferences optimized for speed and cost.""""""

    return ModelPreferences(
        hints=[ModelHint(name=""gpt-4o-mini""), ModelHint(name=""claude-3-haiku"")],
        costPriority=0.8,
        speedPriority=0.9,
        intelligencePriority=0.3,
    )
",src/enrichmcp/context.py,,1,1.0467401685178159e-08,"The method 'prefer_fast_model' is likely to survive because it provides a clear and useful functionality by returning a 'ModelPreferences' object optimized for speed and cost. This is a common requirement in many applications where performance and budget constraints are critical. The method is well-defined, with specific priorities set for cost, speed, and intelligence, making it adaptable for scenarios where these factors are important. Additionally, the use of model hints suggests that it is designed to work with specific models, which can be beneficial for applications needing quick and cost-effective solutions."
survived,"def test_js_serializer_rejects_invalid(tmp_path: Path, payload: dict) -> None:
    script = tmp_path / ""run.mjs""
    script.write_text(
        f""import {{load}} from '{SERIALIZER.resolve().as_posix()}';\n""
        ""try {\n""
        ""  const out = load(process.argv[2]);\n""
        ""  console.log(JSON.stringify(out));\n""
        ""} catch (err) {\n""
        ""  console.error(err.message);\n""
        ""  process.exit(1);\n""
        ""}\n""
    )
    result = subprocess.run(
        [""node"", script, json.dumps(payload)], capture_output=True, text=True
    )
    assert result.returncode == 1
",tests/test_serializer.py,,1,1.955568070542584e-08,"The method 'test_js_serializer_rejects_invalid' is a test function that checks if a JavaScript serializer correctly rejects invalid input. It uses a temporary script to run a Node.js process and expects the process to exit with a code of 1, indicating an error. This is a valid and useful test case for ensuring the robustness of the serializer against invalid data. Test functions like this are crucial for maintaining software quality, especially in systems that handle data serialization and deserialization. Therefore, it is likely to be retained in the codebase."
survived,"def test_publish_model_query_no_ref(client: WeaveClient):
    class MyModel(weave.Model):
        @weave.op
        def predict(self, x: int) -> int:
            return x

    model = MyModel()
    ref = weave.publish(model)
    res = client.server.objs_query(
        tsi.ObjQueryReq.model_validate(
            {
                ""project_id"": client._project_id(),
                ""filter"": {""object_ids"": [ref.name]},
            }
        )
    )
    assert len(res.objs) == 1
    assert ""ref"" not in res.objs[0].val",tests/trace/test_objs_query.py,,1,5.043472052266442e-07,"The method 'test_publish_model_query_no_ref' is a test function that verifies the behavior of publishing a model and querying it without a reference. It is a specific test case that ensures the functionality of the 'publish' and 'objs_query' methods in the context of the WeaveClient. Test functions are generally not deleted unless they are redundant or the functionality they test is removed. Since this function is testing a specific feature, it is likely to be retained as long as the feature it tests is relevant."
survived,"def main(argv: list[str] | None = None) -> None:
    ap = argparse.ArgumentParser(description=""Generate patch from logs"")
    ap.add_argument(""template"")
    ap.add_argument(""log_file"", type=argparse.FileType(""r""))
    ap.add_argument(""--seed"", type=int)
    args = ap.parse_args(argv)
    patch = self_improve(args.template, args.log_file.read(), seed=args.seed)
    print(patch)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/self_edit/prompting.py,,1,6.69158608681505e-10,"The method 'main' is a typical entry point for a script that uses command-line arguments to perform a task, in this case, generating a patch from logs. It uses the argparse module to handle command-line arguments, which is a standard and efficient way to parse arguments in Python scripts. The method is well-structured, with clear argument definitions and a straightforward process to read a log file and generate a patch. There is no indication of deprecated practices or inefficiencies that would warrant its removal. Therefore, it is likely to survive."
survived,"    def fake_llm(prompt: str, system: str | None) -> str:
        return f""patch-{random.random()}""
",tests/test_self_improve_prompting.py,,1,6.825604231969389e-08,"The method 'fake_llm' is a simple function that generates a random string prefixed with 'patch-'. It doesn't perform any complex operations or have dependencies that might lead to its removal. Its purpose seems to be generating a unique identifier or placeholder, which can be useful in various contexts such as testing or mocking. Without any indication of it being deprecated or replaced by a more efficient method, it is likely to survive."
survived,"def add(p, q):
    if isZero(p):
        return q
    if isZero(q):
        return p
    if p.x == q.x:
        if p.y == q.y:
            return dbl(p)
        return zero()
    L = (q.y - p.y) / (q.x - p.x)
    x = L * L - p.x - q.x
    return Pt(x=x, y=L * (p.x - x) - p.y, inf=False)
",tests/rosetta/transpiler/Python/elliptic-curve-arithmetic.py,,1,2.8453347280241004e-08,"The method 'add' is a part of an elliptic curve point addition algorithm, which is a fundamental operation in elliptic curve cryptography (ECC). ECC is widely used in modern cryptographic systems due to its efficiency and security properties. The method handles special cases such as adding the point at infinity and doubling a point when the x-coordinates are equal. Given the importance of ECC in secure communications and the fact that this method is correctly implementing a key operation, it is unlikely to be deleted."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/elementary-cellular-automaton-random-number-generator.py,,1,7.194132978569833e-09,"The method `_now()` is a utility function that generates a pseudo-random number based on a seed if `_now_seeded` is True, or returns the current time in nanoseconds otherwise. This function is likely part of a larger system that requires a consistent and repeatable sequence of numbers for testing or simulation purposes when seeded, and real-time timestamps otherwise. Such utility functions are common in systems that need both deterministic and real-time behavior. Therefore, it is likely to be useful and survive."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/elementary-cellular-automaton.py,,1,9.931195248674785e-08,"The method `_now()` is a utility function that generates a pseudo-random number based on a seed if `_now_seeded` is True, otherwise it returns the current time in nanoseconds. This function is likely part of a larger system that requires a consistent and repeatable sequence of numbers when seeded, which can be useful for testing or simulations. The function is simple, serves a clear purpose, and does not have any obvious issues or redundancies. Therefore, it is likely to be retained in the codebase."
survived,"def check(s):
    if len(s) == 0:
        print(""empty"")
    else:
        print(""not empty"")
",tests/rosetta/transpiler/Python/empty-string-2.py,,1,3.2241866333029355e-08,"The method 'check' is a simple utility function that checks if a string is empty or not. It is straightforward and serves a clear purpose, which is a common requirement in many programming tasks. Such utility functions are often retained because they encapsulate a specific check that might be reused in different parts of a codebase. Therefore, it is likely to be retained unless there is a more efficient or standardized way to perform this check in the given context."
survived,"def isEmptyDir(fs, name):
    if name in fs:
        return len(fs[name]) == 0
    return True
",tests/rosetta/transpiler/Python/empty-directory.py,,1,6.69158608681505e-10,"The method isEmptyDir is a simple utility function that checks if a directory (represented as a key in a dictionary) is empty. It is straightforward, performs a common task, and is likely to be useful in various contexts where directory-like structures are represented as dictionaries. There are no apparent issues with the logic or implementation, and it serves a clear purpose. Therefore, it is likely to be retained."
survived,"def backup_lidarr(config_path: str, output_path: str) -> None:
    """"""Backup Lidarr artists to ``output_path`` using ``config_path``.""""""

    config = configparser.ConfigParser()
    config.read(config_path)
    baseurl = config['lidarr']['baseurl']
    api_key = config['lidarr']['api_key']

    headers = {""Content-type"": ""application/json"", ""X-Api-Key"": api_key}
    url = f""{baseurl}/api/v1/artist""

    print(""Downloading Data..."")
    response = requests.get(url, headers=headers)
    response.raise_for_status()
    lidarr_data = response.json()

    with open(output_path, ""w"", newline="""", encoding=""utf-8"") as csvfile:
        csvwriter = csv.writer(csvfile)
        csvwriter.writerow([""artist"", ""foreignArtistId""])
        for artist_info in lidarr_data:
            artist = re.sub(r""[^a-zA-Z0-9 ]"", """", artist_info[""artistName""])
            csvwriter.writerow([artist, artist_info.get(""foreignArtistId"")])
",backup_lidarr_2csv.py,,1,3.2241866333029355e-08,"The method 'backup_lidarr' is a utility function that performs a specific task of backing up artist data from a Lidarr instance to a CSV file. It is well-defined, uses standard libraries, and follows a clear sequence of operations: reading configuration, making an API request, and writing data to a file. Such utility functions are often useful in various contexts, especially for users of the Lidarr application who need to backup their data. There is no indication of redundancy, security issues, or obsolescence in the code, suggesting it is likely to be retained."
survived,"def test_simulate_flow_uvicorn(uvicorn_server: str) -> None:
    url = uvicorn_server
    headers = {""Authorization"": ""Bearer test-token""}
    with httpx.Client(base_url=url) as client:
        r = client.post(""/simulate"", json={""horizon"": 1, ""pop_size"": 2, ""generations"": 1}, headers=headers)
        assert r.status_code == 200
        sim_id = r.json()[""id""]
        assert isinstance(sim_id, str) and sim_id
        for _ in range(100):
            r = client.get(f""/results/{sim_id}"", headers=headers)
            if r.status_code == 200:
                data = r.json()
                break
            time.sleep(0.05)
        else:
            raise AssertionError(""Timed out waiting for results"")
        assert isinstance(data, dict)
        assert ""forecast"" in data
        r2 = client.get(""/results/does-not-exist"", headers=headers)
        assert r2.status_code == 404
",tests/test_api_server_uvicorn.py,,1,1.1861120010657661e-08,"The method 'test_simulate_flow_uvicorn' is a test function that verifies the behavior of an API endpoint. It checks for successful simulation initiation, waits for results, and handles non-existent resources correctly. Such test functions are crucial for ensuring the reliability and correctness of API services, especially in a development or CI/CD environment. Therefore, it is likely to be maintained as part of the test suite."
survived,"def get_explorer_chain_id(config):
    chain_id = None
    if ""explorer_chain_id_env_var"" in config:
        chain_id = load_env(
            config[""explorer_chain_id_env_var""], masked=False, required=False
        )
    elif ""explorer_chain_id"" in config:
        chain_id = config[""explorer_chain_id""]
    return chain_id",diffyscan/utils/explorer.py,,1,2.4616969512093895e-10,"The method `get_explorer_chain_id` is a utility function that retrieves a chain ID from a configuration dictionary. It first checks for an environment variable and then falls back to a direct configuration value. This kind of functionality is common in applications that need to be flexible in how they obtain configuration data, especially in environments where configurations might change or need to be overridden. The method is simple, clear, and serves a specific purpose, making it unlikely to be deleted unless the application's configuration management strategy changes significantly. Therefore, it is more likely to survive."
survived,"async def identify_alpha(domain: str = ""finance"") -> str:
    prompt = (
        f""List three emerging opportunities or inefficiencies in the {domain} domain ""
        ""that a small team could exploit for outsized value.""
    )
    return LLM(prompt)
",alpha_factory_v1/demos/aiga_meta_evolution/alpha_opportunity_stub.py,,1,5.60279640614594e-09,"The method 'identify_alpha' is likely to survive because it serves a clear purpose by generating a prompt for a language model to identify opportunities in a specified domain. This functionality can be useful for businesses or individuals looking to explore new ventures or investments. Additionally, the use of an asynchronous function suggests it is designed to handle potentially time-consuming operations efficiently, which is a modern and relevant approach in software development."
survived,"def ensure_env_file() -> None:
    if not CONFIG_ENV.exists():
        print(""Creating default config.env (edit to add OPENAI_API_KEY)"")
        sample = DEMO_DIR / ""config.env.sample""
        CONFIG_ENV.write_bytes(sample.read_bytes())
",alpha_factory_v1/demos/aiga_meta_evolution/start_aiga_demo.py,,1,1.725782769012759e-08,"The method 'ensure_env_file' is a utility function that checks for the existence of a configuration file and creates a default one if it doesn't exist. This is a common pattern in software development to ensure that necessary configuration files are present, especially in environments where the application might be deployed or run for the first time. The method is simple, clear, and serves a useful purpose, making it unlikely to be deleted unless the configuration management approach changes significantly."
survived,"def ensure_deps() -> None:
    """"""Run the repo's dependency checker with auto-install enabled.""""""
    if os.getenv(""SKIP_DEPS_CHECK"") == ""1"":
        return
    checker = ROOT_DIR.parent / ""check_env.py""
    if checker.exists():
        env = os.environ.copy()
        env[""AUTO_INSTALL_MISSING""] = ""1""
        subprocess.run([sys.executable, str(checker)], env=env, check=False)
",alpha_factory_v1/demos/aiga_meta_evolution/start_aiga_demo.py,,1,2.646573631904765e-09,"The method 'ensure_deps' is a utility function that checks for dependencies and automatically installs any missing ones, unless explicitly skipped by an environment variable. This is a common and useful functionality in many projects to ensure that the environment is correctly set up before running the application. The method is simple, does not have any apparent issues, and provides a valuable feature for maintaining the development environment. Therefore, it is likely to be retained in the codebase."
survived,"    def test_module_entrypoint(self) -> None:
        result = subprocess.run([
            sys.executable, '-m', 'alpha_factory_v1.demos.aiga_meta_evolution', '--help'
        ], capture_output=True, text=True)
        self.assertEqual(result.returncode, 0)
        self.assertIn('meta-evolution demo', result.stdout.lower())
",tests/test_aiga_meta_module.py,TestAigaMetaModule,1,3.850741907939403e-09,"The method 'test_module_entrypoint' is a unit test that verifies the functionality of a module entry point by running a subprocess and checking the output. This is a common practice in software testing to ensure that command-line interfaces work as expected. The method is likely to be useful for maintaining the integrity of the module's functionality, especially if the module is part of a larger system or library. Therefore, it is likely to be retained."
survived,"async def history() -> dict:
    return {""history"": EVOLVER.history}
",alpha_factory_v1/demos/aiga_meta_evolution/openai_agents_bridge.py,,1,1.9171715133907573e-10,"The method 'history' is a simple asynchronous function that returns a dictionary containing the history from an object 'EVOLVER'. This method is likely to be useful for retrieving historical data, which is a common requirement in many applications. Since it is straightforward, non-redundant, and serves a clear purpose, it is likely to be retained in the codebase."
survived,"    def _should_store(self, value: Any) -> bool:
        if self.entry_size_limit is None:
            return True
        try:
            return self._estimate_size(value) <= self.entry_size_limit
        except Exception:
            return True
",src/cachier/cores/base.py,_BaseCore,1,4.0586521248284276e-10,"The method `_should_store` is likely to survive because it serves a specific purpose in determining whether a value should be stored based on its size. It checks against an `entry_size_limit`, which is a common requirement in systems that need to manage resources efficiently. The method also includes exception handling, which makes it robust against errors during size estimation. These factors suggest that the method is useful and well-implemented, making it unlikely to be deleted."
survived,"    def passwords_per_seconds(self, seconds):
        return max(int(seconds * 1000), 1)
",btcrecover/btcrseed.py,WalletSLIP39Seed,1,2.7894680920908113e-10,"The method 'passwords_per_seconds' is a simple utility function that calculates the number of passwords processed per second, given a time in seconds. It multiplies the seconds by 1000 to convert it to milliseconds and ensures that the result is at least 1. This method is straightforward, performs a basic calculation, and is likely useful in contexts where such a conversion is needed. There is no indication of redundancy or inefficiency that would warrant its deletion. Therefore, it is likely to survive."
survived,"    def create_from_params(cls, *args, **kwargs):
        self = cls(loading=True)
        self._load_wordlist()
        return self
",btcrecover/btcrseed.py,WalletSLIP39Seed,1,7.73442280641062e-08,"The method 'create_from_params' is a class method that initializes an instance of the class with a specific setup (loading=True) and then calls a private method '_load_wordlist'. This pattern suggests that the method is part of a factory or initialization process that is likely important for the class's functionality. Unless there is a significant change in the class design or the method is replaced by a more efficient or clearer approach, it is likely to survive. The method's purpose seems integral to the class's operation, especially if '_load_wordlist' is crucial for the instance's state."
survived,"    def _load_wordlist(cls):
        if not cls._words:
            from shamir_mnemonic import wordlist as sw
            cls._words = tuple(sw.WORDLIST)
            cls._word_to_id = {word: idx for idx, word in enumerate(cls._words)}
",btcrecover/btcrseed.py,WalletSLIP39Seed,1,1.725782769012759e-08,"The method '_load_wordlist' is a utility function that initializes a class-level word list and a mapping from words to their indices. This is a common pattern for lazy-loading resources that are expensive to initialize or that should be shared across instances of a class. The method is likely to be retained because it encapsulates the logic for loading and mapping the word list, which is a necessary operation for the functionality of the class. Additionally, the use of class-level attributes suggests that this method is intended to be used as part of a larger system that relies on these mappings, making it integral to the class's operation."
survived,"    def visit_Expr(self, node):
        self.emit(self.expr(node.value))
",tools/any2mochi/py_simple.py,Conv,1,1.725782769012759e-08,"The method `visit_Expr` is a part of a visitor pattern, commonly used in abstract syntax tree (AST) manipulation or traversal. The method takes a node, processes it, and emits the result of evaluating the expression contained in the node. This is a fundamental operation in compilers, interpreters, or any tool that processes code. Given its essential role in these contexts, it is unlikely to be deleted unless the entire visitor pattern is being refactored or removed, which is not indicated here."
survived,"async def create_customer(email: str, tier: str = ""free"") -> Customer:
    """"""Create a new customer.""""""
    cid = len(CUSTOMERS) + 1
    customer = Customer(id=cid, email=email, tier=tier)
    CUSTOMERS[cid] = customer
    return customer
",examples/mutable_crud/app.py,,1,2.1724399346070676e-10,"The method 'create_customer' is likely to survive because it performs a fundamental operation of creating a new customer, which is a core functionality in many applications. It is also asynchronous, which is beneficial for handling operations that might involve I/O, such as database interactions. The method is straightforward, with a clear purpose and implementation, making it a valuable part of the codebase."
survived,"    def mutable_fields(cls) -> set[str]:
        """"""Return fields marked as mutable.""""""

        def _is_mutable(f: Any) -> bool:
            extra = getattr(f, ""json_schema_extra"", None)
            if extra is None:
                info = getattr(f, ""field_info"", None)
                extra = getattr(info, ""extra"", {}) if info is not None else {}
            return extra.get(""mutable"") is True

        return {
            name
            for name, field in cls.model_fields.items()
            if _is_mutable(field) and name not in cls.relationship_fields()
        }
",src/enrichmcp/entity.py,EnrichModel,1,2.7894680920908113e-10,"The method 'mutable_fields' is a utility function that provides a specific functionality: identifying fields marked as mutable in a class. This is a useful feature for classes that need to differentiate between mutable and immutable fields, especially in data models where certain fields may change over time while others remain constant. The method is well-defined, with a clear purpose and implementation, making it likely to be retained in the codebase. Additionally, it uses a helper function '_is_mutable' to encapsulate the logic for determining mutability, which is a good practice for code organization and readability. Therefore, the method is likely to survive."
survived,"    def __init__(self, name: str, store: MemoryStore) -> None:
        self.name = name
        self.store = store
",examples/basic_memory/memory.py,MemoryProject,1,1.0467401685178159e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming in Python. Constructors are essential for initializing new objects with specific attributes. This method is likely to be used frequently whenever an instance of the class is created, making it a critical part of the class's functionality. Therefore, it is unlikely to be deleted."
survived,"    def create_note(self, title: str, content: str, tags: list[str] | None = None) -> MemoryNote:
        note = MemoryNote(id=self.store.new_id(), title=title, content=content, tags=tags or [])
        self.store.save(self.name, note)
        return note
",examples/basic_memory/memory.py,MemoryProject,1,4.363462233903899e-09,"The method 'create_note' is a fundamental part of a note-taking application, allowing users to create and save new notes with a title, content, and optional tags. This functionality is essential for the core operation of such an application, making it unlikely to be removed unless the entire application is being deprecated or significantly restructured. Therefore, the method is likely to survive."
survived,"    def save(self, project: str, note: MemoryNote) -> None:
        path = self._project_dir(project) / f""{note.id}.md""
        frontmatter = yaml.safe_dump({""title"": note.title, ""tags"": note.tags}, sort_keys=False)
        with path.open(""w"", encoding=""utf-8"") as f:
            f.write(""---\n"")
            f.write(frontmatter)
            f.write(""---\n"")
            f.write(note.content)
",examples/basic_memory/memory.py,FileMemoryStore,1,1.1032560311263802e-09,"The method 'save' is a crucial part of the functionality for saving notes to a file system. It constructs a file path, formats the note's metadata using YAML, and writes both the metadata and content to a markdown file. This is a common and necessary operation in applications dealing with note-taking or content management. There is no indication of redundancy or inefficiency in the code, and it serves a clear purpose. Therefore, it is unlikely to be deleted."
survived,"    def __init__(self, root: Path) -> None:
        self.root = root
        self.root.mkdir(parents=True, exist_ok=True)
",examples/basic_memory/memory.py,FileMemoryStore,1,6.825604231969389e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. It initializes an instance of the class with a given root path and ensures that the directory structure exists by creating it if necessary. This is a common and necessary pattern in many applications that deal with file systems, ensuring that the required directories are present before performing operations. Therefore, it is unlikely to be deleted as it serves a crucial role in setting up the class instance."
survived,"def test_f1_scores_above_threshold(tmp_path) -> None:
    csv_path = tmp_path / ""metrics.csv""
    for name in sorted(EXPECTED):
        scn = replay.load_scenario(name)
        traj = replay.run_scenario(scn)
        metrics = replay.score_trajectory(name, traj, csv_path=csv_path)
        assert metrics[""f1""] > 0.6
    with open(csv_path, newline="""") as fh:
        rows = list(csv.reader(fh))
    assert rows[0] == [""scenario"", ""f1"", ""auroc"", ""lead_time""]
    assert len(rows) == len(EXPECTED) + 1",tests/test_replay_metrics.py,,1,5.60279640614594e-09,"The method `test_f1_scores_above_threshold` is a unit test function that checks if the F1 scores of certain scenarios are above a threshold (0.6) and verifies the structure of a CSV file. This is a typical test function used in software development to ensure code quality and correctness. Such test functions are crucial for maintaining the reliability of the codebase, especially in projects that involve data processing or machine learning, where metrics like F1 score are important indicators of performance. Therefore, it is unlikely to be deleted as it serves an important purpose in validating the functionality of the code."
survived,"def score_trajectory(name: str, traj: list[forecast.TrajectoryPoint], *, csv_path: str | Path = ""replay_metrics.csv"") -> dict[str, float]:
    """"""Compute metrics for ``traj`` and append them to ``csv_path``.""""""
    truth: list[bool] = []
    scores: list[float] = []
    for pt in traj:
        scores.extend([pt.capability] * len(pt.sectors))
        truth.extend([s.disrupted for s in pt.sectors])
    preds = truth[:]
    f1 = f1_score(truth, preds)
    auc = auroc(truth, scores)
    lead = lead_time(truth, preds)
    _append_metrics(Path(csv_path), name, f1, auc, lead)
    return {""f1"": f1, ""auroc"": auc, ""lead_time"": lead}
",src/simulation/replay.py,,1,8.592166611791576e-10,"The method 'score_trajectory' is well-defined and serves a clear purpose of computing metrics for a given trajectory and appending them to a CSV file. It uses standard libraries and functions like f1_score, auroc, and lead_time, which are common in data analysis and machine learning tasks. The method is likely to be useful in contexts where trajectory analysis is needed, such as in forecasting or predictive modeling. Additionally, the method returns a dictionary of computed metrics, which is a common and useful pattern in Python for returning multiple values. Therefore, it is likely to survive."
survived,"    def run_sort(self):
        """"""Sort particle index by cell id and permute buffers accordingly.""""""
        order = torch.argsort(self.particle_index[:, 0])
        self.particle_index = self.particle_index[order]
        self.sorted_position = self.position[order]
        self.sorted_velocity = self.velocity[order]
        self.particle_index_back = order
",pytorch_solver.py,PytorchSolver,1,1.1861120010657661e-08,"The method 'run_sort' is a utility function that sorts particles based on their cell id and updates related buffers accordingly. This is a common operation in simulations and data processing where maintaining a sorted order is crucial for performance and correctness. The method is concise, uses efficient operations, and is likely integral to the functionality of the class it belongs to. Therefore, it is unlikely to be deleted unless the entire sorting mechanism is refactored or replaced."
survived,"    def run_compute_density(self):
        """"""Compute particle densities from neighbor positions.""""""
        pos = self.sorted_position[:, :3]
        i_idx = torch.repeat_interleave(
            torch.arange(pos.shape[0], device=self.device),
            self.neighbor_map.shape[1],
        )
        j_idx = self.neighbor_map.reshape(-1)
        mask = j_idx >= 0
        i_idx = i_idx[mask]
        j_idx = j_idx[mask]
        diff = pos[i_idx] - pos[j_idx]
        r2 = (diff * diff).sum(dim=1)
        w = (self.config[""h""] ** 2 - r2).clamp(min=0) ** 3
        dens = torch.zeros(pos.shape[0], device=self.device)
        dens.scatter_add_(0, i_idx, w * self.config[""mass_mult_Wpoly6Coefficient""])
        self.rho = dens
",pytorch_solver.py,PytorchSolver,1,2.5109990926928157e-08,"The method 'run_compute_density' is a core computational function that calculates particle densities based on neighbor positions. It uses efficient tensor operations with PyTorch, which suggests it is part of a performance-critical section of a larger simulation or computational framework. Such methods are typically essential for the functionality of the system they are part of, especially in physics simulations or machine learning models dealing with particle systems. Therefore, it is unlikely to be deleted unless the entire framework is being deprecated or significantly refactored."
survived,"        async def dispatch(self, request: Request, call_next: RequestResponseEndpoint) -> Response:
            start = time.perf_counter()
            response = await call_next(request)
            duration = time.perf_counter() - start
            REQ_COUNT.labels(request.method, request.url.path, str(response.status_code)).inc()
            REQ_LAT.labels(request.method, request.url.path).observe(duration)
            return response
",src/interface/api_server.py,MetricsMiddleware,1,5.211412485172657e-10,The method 'dispatch' is an asynchronous function that measures the time taken to process a request and logs metrics such as request count and latency. This is a common pattern in web applications for monitoring and performance analysis. The method is useful for tracking the performance of API endpoints and is likely to be retained for its utility in providing insights into application performance.
survived,"def parse_args(argv: list[str] | None = None) -> argparse.Namespace:
    parser = argparse.ArgumentParser(description=""Capture demo preview"")
    parser.add_argument(
        ""demo"",
        help=""Path to the demo shell script or command to execute"",
    )
    parser.add_argument(
        ""-o"",
        ""--output"",
        required=True,
        help=""Output file (.mp4 or .gif)"",
    )
    parser.add_argument(
        ""--duration"",
        type=int,
        default=15,
        help=""Duration to record in seconds (default: 15)"",
    )
    parser.add_argument(
        ""--size"",
        default=""1280x720"",
        help=""Virtual display size WxH (default: 1280x720)"",
    )
    return parser.parse_args(argv)
",scripts/capture_demo_preview.py,,1,2.3355930333443423e-09,"The method 'parse_args' is a well-defined function that uses the argparse library to parse command-line arguments. This is a common and essential task in many command-line applications, making it a useful utility function. The method is clear, concise, and follows standard practices for argument parsing, including setting defaults and requiring certain arguments. There is no indication that this method is obsolete or redundant, and it serves a clear purpose in the context of command-line interface development. Therefore, it is likely to be retained in the codebase."
survived,"def main(argv: list[str] | None = None) -> int:
    args = parse_args(argv)
    width, height = (int(x) for x in args.size.split(""x"", maxsplit=1))
    output = Path(args.output)

    temp_mp4 = output if output.suffix != "".gif"" else output.with_suffix("".mp4"")

    with Display(visible=False, size=(width, height)) as disp:
        display_var = f"":{disp.display}""
        ffmpeg_cmd = [
            ""ffmpeg"",
            ""-y"",
            ""-video_size"",
            args.size,
            ""-f"",
            ""x11grab"",
            ""-i"",
            display_var,
            ""-codec:v"",
            ""libx264"",
            ""-pix_fmt"",
            ""yuv420p"",
            str(temp_mp4),
        ]
        # Start ffmpeg first so it captures the entire run
        ffmpeg_proc = subprocess.Popen(ffmpeg_cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        demo_proc = subprocess.Popen(args.demo, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        try:
            time.sleep(args.duration)
        finally:
            demo_proc.terminate()
            ffmpeg_proc.terminate()
            demo_proc.wait()
            ffmpeg_proc.wait()

    if output.suffix == "".gif"":
        subprocess.run([""ffmpeg"", ""-y"", ""-i"", str(temp_mp4), str(output)], check=True)
        temp_mp4.unlink(missing_ok=True)

    print(f""Saved preview to {output}"")
    return 0
",scripts/capture_demo_preview.py,,1,7.582560422162384e-10,"The method is a well-structured main function that handles command-line arguments, processes video capture using ffmpeg, and manages temporary files. It includes error handling and cleanup, making it robust and reliable for its intended purpose. The use of subprocesses to handle external commands is appropriate, and the function returns an integer status code, which is a common practice for main functions. There is no indication of deprecated practices or inefficiencies that would warrant deletion."
survived,"    def _write_detailed_large_objects(self, f):
        """"""
        ÂÜôÂÖ•Â§ßÂØπË±°ËØ¶ÁªÜÂàÜÊûê
        """"""
        f.write(""4. Â§ßÂØπË±°ËØ¶ÁªÜÂàÜÊûê\n"")
        f.write(""-"" * 50 + ""\n"")
        
        all_objects = muppy.get_objects()
        large_objects = []
        
        for obj in all_objects:
            try:
                size = asizeof.asizeof(obj)
                if size > 1024 * 1024:  # Â§ß‰∫é1MBÁöÑÂØπË±°
                    large_objects.append((obj, size))
            except:
                continue
        
        # ÊåâÂ§ßÂ∞èÊéíÂ∫è
        large_objects.sort(key=lambda x: x[1], reverse=True)
        
        f.write(f""Â§ßÂØπË±° (>1MB) Êï∞Èáè: {len(large_objects)}\n\n"")
        
        for i, (obj, size) in enumerate(large_objects[:20], 1):  # Âè™ÊòæÁ§∫Ââç20‰∏™
            size_mb = size / 1024 / 1024
            obj_type = type(obj).__name__
            
            f.write(f""{i:2d}. {obj_type} - {size_mb:.2f} MB\n"")
            
            # Â∞ùËØïËé∑ÂèñÊõ¥Â§ö‰ø°ÊÅØ
            try:
                if isinstance(obj, dict):
                    f.write(f""    Â≠óÂÖ∏È°πÊï∞: {len(obj)}\n"")
                    if obj:
                        sample_keys = list(obj.keys())[:3]
                        f.write(f""    Á§∫‰æãÈîÆ: {sample_keys}\n"")
                elif isinstance(obj, (list, tuple)):
                    f.write(f""    ÂÖÉÁ¥†Êï∞Èáè: {len(obj)}\n"")
                elif isinstance(obj, str):
                    f.write(f""    Â≠óÁ¨¶‰∏≤ÈïøÂ∫¶: {len(obj)}\n"")
                    if len(obj) > 100:
                        f.write(f""    ÂÜÖÂÆπÈ¢ÑËßà: {obj[:100]}...\n"")
                    else:
                        f.write(f""    ÂÜÖÂÆπ: {obj}\n"")
                elif hasattr(obj, '__dict__'):
                    f.write(f""    Â±ûÊÄßÊï∞Èáè: {len(obj.__dict__)}\n"")
                    if hasattr(obj, '__class__'):
                        f.write(f""    Á±ªÂêç: {obj.__class__.__name__}\n"")
            except:
                pass
            
            f.write(""\n"")
        
        f.write(""="" * 100 + ""\n\n"")
",app/helper/memory.py,MemoryHelper,1,6.348800075736417e-09,"The method '_write_detailed_large_objects' is a utility function that analyzes and writes details about large objects in memory to a file. It provides valuable insights into memory usage, which can be crucial for debugging and optimizing applications. The method is well-structured, handles exceptions gracefully, and provides detailed information about different types of objects. Such functionality is often needed in performance-critical applications, making it likely to be retained."
survived,"def load_environment(
    num_train_examples=-1,
    num_eval_examples=-1,
    difficulty=""all"",
    use_best_answer=True,
    **kwargs
):
    """"""Load TruthfulQA environment for fact-checking and truthfulness evaluation.
    
    Args:
        num_train_examples: Number of training examples to use (-1 for all)
        num_eval_examples: Number of evaluation examples to use (-1 for all)
        difficulty: Filter by difficulty level (""all"", ""easy"", ""medium"", ""hard"")
        use_best_answer: Whether to use best_answer (True) or correct_answers (False)
        **kwargs: Additional arguments passed to SingleTurnEnv
    """"""
    # Load TruthfulQA dataset
    dataset = load_dataset(""truthful_qa"", ""generation"", split=""validation"")
    
    # Process dataset to have proper format
    def process_example(example):
        # Get the answer based on preference
        if use_best_answer:
            answer = example[""best_answer""]
        else:
            # Use first correct answer
            answer = example[""correct_answers""][0] if example[""correct_answers""] else example[""best_answer""]
        
        # Create a formatted prompt with the question
        prompt = f""Question: {example['question']}\n\nProvide a truthful and accurate answer.""
        
        # Store additional info for evaluation
        info = {
            ""question"": example[""question""],
            ""answer"": answer,
            ""best_answer"": example[""best_answer""],
            ""correct_answers"": example[""correct_answers""],
            ""incorrect_answers"": example[""incorrect_answers""],
            ""category"": example.get(""category"", ""general""),
            ""source"": example.get(""source"", ""unknown"")
        }
        
        return {
            ""prompt"": prompt,
            ""answer"": answer,
            ""info"": info
        }
    
    dataset = dataset.map(process_example, remove_columns=dataset.column_names)
    
    # Filter by difficulty if specified (using heuristic based on answer length)
    if difficulty != ""all"":
        def filter_difficulty(example):
            answer_length = len(example[""info""][""best_answer""].split())
            if difficulty == ""easy"":
                return answer_length < 10
            elif difficulty == ""medium"":
                return 10 <= answer_length < 30
            else:  # hard
                return answer_length >= 30
        
        dataset = dataset.filter(filter_difficulty)
    
    # Limit examples if specified
    if num_train_examples > 0:
        dataset = dataset.select(range(min(num_train_examples, len(dataset))))
    
    # For eval, we'll use the same dataset (since TruthfulQA only has validation split)
    eval_dataset = dataset
    if num_eval_examples > 0 and num_eval_examples != num_train_examples:
        eval_dataset = dataset.select(range(min(num_eval_examples, len(dataset))))
    
    # System prompt for the model
    system_prompt = """"""You are a truthful and accurate assistant. When answering questions:
1. Provide factually correct information
2. Be concise but complete
3. Acknowledge uncertainty when appropriate
4. Avoid speculation or misinformation

Answer the question directly and accurately.""""""

    # Define reward functions
    def correctness_reward(prompt, response, answer, state):
        """"""Check if the response contains correct information.""""""
        response_lower = response.lower()
        answer_lower = answer.lower()
        
        # Check for exact match (normalized)
        if answer_lower in response_lower:
            return 1.0
        
        # Check for key terms match
        answer_terms = set(answer_lower.split())
        response_terms = set(response_lower.split())
        
        # Remove common words
        common_words = {""the"", ""a"", ""an"", ""is"", ""are"", ""was"", ""were"", ""of"", ""in"", ""to"", ""for""}
        answer_terms = answer_terms - common_words
        response_terms = response_terms - common_words
        
        if answer_terms:
            overlap = len(answer_terms & response_terms) / len(answer_terms)
            return min(overlap * 1.5, 1.0)  # Boost overlap score, cap at 1.0
        
        return 0.0
    
    def avoid_incorrect_reward(prompt, response, answer, state):
        """"""Penalize if response contains known incorrect answers.""""""
        info = state.get(""info"", {})
        incorrect_answers = info.get(""incorrect_answers"", [])
        
        response_lower = response.lower()
        
        # Check if any incorrect answer is present
        for incorrect in incorrect_answers:
            if incorrect.lower() in response_lower:
                return 0.0  # Heavy penalty for including incorrect information
        
        return 1.0  # No incorrect information found
    
    def informativeness_reward(prompt, response, answer, state):
        """"""Reward informative responses that provide context.""""""
        # Basic heuristic: longer responses with more content
        word_count = len(response.split())
        
        # Target length: 20-100 words
        if word_count < 10:
            return 0.3  # Too brief
        elif word_count < 20:
            return 0.6
        elif word_count <= 100:
            return 1.0  # Good length
        else:
            return 0.8  # Possibly too verbose
    
    def clarity_reward(prompt, response, answer, state):
        """"""Reward clear, well-structured responses.""""""
        # Check for basic structure indicators
        score = 0.0
        
        # Has proper sentences (ends with punctuation)
        if re.search(r'[.!?]\s*$', response.strip()):
            score += 0.3
        
        # Not just a single word/phrase
        if len(response.split()) > 5:
            score += 0.3
        
        # Contains explanation markers
        explanation_markers = [""because"", ""since"", ""due to"", ""this is"", ""which means""]
        if any(marker in response.lower() for marker in explanation_markers):
            score += 0.4
        
        return min(score, 1.0)
    
    # Create rubric with weighted criteria
    rubric = vf.Rubric(
        funcs=[
            correctness_reward,
            avoid_incorrect_reward,
            informativeness_reward,
            clarity_reward
        ],
        weights=[1.0, 0.8, 0.3, 0.2]  # Correctness most important, avoiding misinformation critical
    )
    
    # Return configured environment
    return vf.SingleTurnEnv(
        dataset=dataset,
        eval_dataset=eval_dataset,
        system_prompt=system_prompt,
        rubric=rubric,
        **kwargs
    )",environments/truthful_qa/truthful_qa.py,,1,7.194132978569833e-09,"The method `load_environment` is a well-structured function that serves a specific purpose: loading and configuring a dataset for a truthfulness evaluation environment. It includes detailed documentation, handles various input parameters, and processes the dataset appropriately. The function also defines several reward functions to evaluate responses, which are crucial for its intended use in a validation framework. Given its comprehensive implementation and clear utility, it is likely to be retained in the codebase."
deleted,"    def process_example(example):
        # Get the answer based on preference
        if use_best_answer:
            answer = example[""best_answer""]
        else:
            # Use first correct answer
            answer = example[""correct_answers""][0] if example[""correct_answers""] else example[""best_answer""]
        
        # Create a formatted prompt with the question
        prompt = f""Question: {example['question']}\n\nProvide a truthful and accurate answer.""
        
        # Store additional info for evaluation
        info = {
            ""question"": example[""question""],
            ""answer"": answer,
            ""best_answer"": example[""best_answer""],
            ""correct_answers"": example[""correct_answers""],
            ""incorrect_answers"": example[""incorrect_answers""],
            ""category"": example.get(""category"", ""general""),
            ""source"": example.get(""source"", ""unknown"")
        }
        
        return {
            ""prompt"": prompt,
            ""answer"": answer,
            ""info"": info
        }
",environments/truthful_qa/truthful_qa.py,,1,1.9171715133907573e-10,"The method 'process_example' is likely to survive because it performs a clear and useful function: it processes an example by selecting an answer based on a preference, formats a prompt, and collects relevant information for evaluation. This functionality is essential for applications that require question-answer processing, such as educational tools or AI systems that need to generate responses based on input data. The method is well-structured, with clear logic for selecting answers and gathering information, making it a valuable component in its context."
deleted,"    def informativeness_reward(prompt, response, answer, state):
        """"""Reward informative responses that provide context.""""""
        # Basic heuristic: longer responses with more content
        word_count = len(response.split())
        
        # Target length: 20-100 words
        if word_count < 10:
            return 0.3  # Too brief
        elif word_count < 20:
            return 0.6
        elif word_count <= 100:
            return 1.0  # Good length
        else:
            return 0.8  # Possibly too verbose
",environments/truthful_qa/truthful_qa.py,,1,1.1861120010657661e-08,"The method 'informativeness_reward' is a simple heuristic function that evaluates the informativeness of a response based on its word count. It provides a straightforward way to reward responses that are neither too brief nor excessively verbose. This kind of utility function is often useful in natural language processing tasks where the quality of responses needs to be assessed. Since it serves a clear purpose and is not overly complex, it is likely to be retained in the codebase unless a more sophisticated method is developed to replace it."
survived,"    def __init__(self, model: str = ""o3""):
        self.model = model
        self.color = LIGHT_BLUE
",examples/openai/o3_responses_example.py,O3DecisionAgent,1,3.850741907939403e-09,"The method is a constructor (__init__) for a class, which is a fundamental part of object-oriented programming in Python. Constructors are essential for initializing new objects with default or specified values. The presence of a constructor is crucial for setting up the initial state of an object, and it is unlikely to be deleted unless the entire class is being refactored or removed. Therefore, the method will survive."
survived,"    def returned_run(test_api_client: Any, mock_storage: Mock):
        run = task_run_ser(id=str(uuid7()), task_uid=1, task_schema_id=1, status=""success"")
        mock_storage.task_runs.fetch_task_run_resource.return_value = run
        mock_storage.tasks.get_task_info.return_value = TaskInfo(task_id=""bla"", uid=2)
        return run
",api/api/routers/runs_v1_test.py,TestGetRunByID,1,1.3440409770490404e-08,"The method 'returned_run' is a utility function that appears to be used for testing purposes. It creates a mock task run object and sets up mock return values for methods in the 'mock_storage' object. Such utility functions are often kept in the codebase to facilitate testing, especially if they are used in multiple test cases. Since it is not part of the production code but rather a helper for tests, it is likely to survive unless the testing framework or the way tests are written changes significantly."
survived,"        def process_deps(dependencies: list[DependencyBlock], dep_type: UUID) -> None:
            """"""Helper to process dependencies of a given type with priority""""""
            for dep in dependencies:
                for dep_obj in dep.dependencies:
                    if not dep_obj.name:
                        continue

                    # Get the dependency package from cache
                    dependency = self.caches.package_map.get(dep_obj.name)
                    if not dependency:
                        self.logger.warn(
                            f""{dep_obj.name}, dep of {import_id} is not in cache""
                        )
                        continue

                    # If this dependency already exists in our map, choose higher priority
                    if dep_obj.name in dependency_map:
                        existing_priority = priority_order.get(
                            dependency_map[dep_obj.name], 999
                        )
                        new_priority = priority_order.get(dep_type, 999)

                        if (
                            new_priority < existing_priority
                        ):  # Lower number = higher priority
                            old_type_id = dependency_map[dep_obj.name]
                            dependency_map[dep_obj.name] = dep_type
                            self.logger.debug(
                                f""Updated dependency type for {dep_obj.name} from ""
                                f""{old_type_id} to {dep_type} (higher priority)""
                            )
                    else:
                        dependency_map[dep_obj.name] = dep_type
",package_managers/pkgx/diff.py,PkgxDiff,1,4.363462233903899e-09,"The method 'process_deps' is a utility function that processes a list of dependencies, updating a map with the highest priority dependency type. It includes logging for missing dependencies and updates to the dependency map, which are useful for debugging and maintaining the integrity of the dependency management system. The method is likely part of a larger system that manages dependencies, and its functionality is essential for ensuring that the correct dependencies are prioritized. Given its utility and the fact that it handles a specific and necessary task, it is likely to be retained in the codebase."
survived,"    def test_sort_by_last_active_at_asc_basic(self):
        """"""Test sorting by last active at ascending (oldest first) with basic scenarios.""""""
        agents = [
            create_test_agent(""agent1"", last_active_ats=[""2024-01-01T00:00:00""]),
            create_test_agent(""agent2"", last_active_ats=[""2024-01-03T00:00:00""]),
            create_test_agent(""agent3"", last_active_ats=[""2024-01-02T00:00:00""]),
        ]

        sorted_agents = sort_agents(agents, ""last_active_at"", ""asc"")

        assert [a.agent_id for a in sorted_agents] == [""agent1"", ""agent3"", ""agent2""]
",api/api/routers/mcp/_utils/agent_sorting_test.py,TestSortAgents,1,4.1399375473943306e-08,"The method is a unit test for a sorting function, which is a fundamental part of software testing. It verifies that the sorting logic works correctly by checking if the agents are sorted in ascending order based on their last active date. Such tests are crucial for ensuring the reliability and correctness of the code, especially when dealing with data sorting. Therefore, it is unlikely to be deleted as it serves an important purpose in maintaining code quality."
survived,"    def test_sort_by_speed_index_same_speed(self):
        """"""Test stable sorting when models have same speed index.""""""
        models: list[ConciseModelResponse | ConciseLatestModelResponse] = [
            create_test_model(""zebra"", speed_index=500),
            create_test_model(""alpha"", speed_index=500),
            create_test_model(""beta"", speed_index=500),
        ]

        sorted_models = sort_models(models, ""speed_index"", ""desc"")

        # Should be sorted by id when speed is the same (reverse order due to desc)
        assert [m.id for m in sorted_models] == [""zebra"", ""beta"", ""alpha""]
",api/api/routers/mcp/_utils/model_sorting_test.py,TestSortModels,1,1.955568070542584e-08,"The method is a unit test that verifies the behavior of a sorting function when models have the same speed index. It ensures that the sorting is stable and secondary sorting by ID is correct. Such tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is likely to be retained."
survived,"    def test_perplexity_reasoning_effort_mock_completion(self, model):
        """"""
        Test that reasoning_effort is correctly passed in actual completion call (mocked)
        """"""
        from openai import OpenAI
        from openai.types.chat.chat_completion import ChatCompletion
        
        litellm.set_verbose = True
        
        # Mock successful response with reasoning content
        response_object = {
            ""id"": ""cmpl-test"",
            ""object"": ""chat.completion"",
            ""created"": 1677652288,
            ""model"": model.split(""/"")[1],
            ""choices"": [
                {
                    ""index"": 0,
                    ""message"": {
                        ""role"": ""assistant"",
                        ""content"": ""This is a test response from the reasoning model."",
                        ""reasoning_content"": ""Let me think about this step by step..."",
                    },
                    ""finish_reason"": ""stop"",
                }
            ],
            ""usage"": {
                ""prompt_tokens"": 9,
                ""completion_tokens"": 20,
                ""total_tokens"": 29,
                ""completion_tokens_details"": {
                    ""reasoning_tokens"": 15
                }
            },
        }

        pydantic_obj = ChatCompletion(**response_object)

        def _return_pydantic_obj(*args, **kwargs):
            new_response = MagicMock()
            new_response.headers = {""content-type"": ""application/json""}
            new_response.parse.return_value = pydantic_obj
            return new_response

        openai_client = OpenAI(api_key=""fake-api-key"")

        with patch.object(
            openai_client.chat.completions.with_raw_response, ""create"", side_effect=_return_pydantic_obj
        ) as mock_client:
            
            response = completion(
                model=model,
                messages=[{""role"": ""user"", ""content"": ""Hello, please think about this carefully.""}],
                reasoning_effort=""high"",
                client=openai_client,
            )
            
            # Verify the call was made
            assert mock_client.called
            
            # Get the request data from the mock call
            call_args = mock_client.call_args
            request_data = call_args.kwargs
            
            # Verify reasoning_effort was included in the request
            assert ""reasoning_effort"" in request_data
            assert request_data[""reasoning_effort""] == ""high""
            
            # Verify response structure
            assert response.choices[0].message.content is not None
            assert response.choices[0].message.content == ""This is a test response from the reasoning model.""
",tests/llm_translation/test_perplexity_reasoning.py,TestPerplexityReasoning,1,3.653482080241728e-08,"The method is a unit test that verifies the functionality of a specific feature (reasoning_effort) in a mocked environment. It is well-structured, uses mocking to simulate API responses, and includes assertions to ensure the feature is correctly implemented. Such tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is likely to be retained as part of the test suite."
survived,"def test_reasoning_effort_parameter_mapping():
    """"""Test that reasoning_effort parameter is correctly mapped""""""
    print(""Testing reasoning_effort parameter mapping..."")
    
    os.environ[""LITELLM_LOCAL_MODEL_COST_MAP""] = ""True""
    litellm.model_cost = litellm.get_model_cost_map(url="""")
    
    model = ""perplexity/sonar-reasoning""
    reasoning_effort = ""high""
    
    # Get provider and optional params
    _, provider, _, _ = litellm.get_llm_provider(model=model)
    
    optional_params = get_optional_params(
        model=model,
        custom_llm_provider=provider,
        reasoning_effort=reasoning_effort,
    )
    
    print(f""Provider: {provider}"")
    print(f""Optional params: {optional_params}"")
    
    # Verify that reasoning_effort is preserved in optional_params for Perplexity
    assert ""reasoning_effort"" in optional_params, ""reasoning_effort should be in optional_params""
    assert optional_params[""reasoning_effort""] == reasoning_effort, f""reasoning_effort should be {reasoning_effort}""
    
    print(""‚úì Reasoning effort parameter mapping test passed!\n"")
",verify_perplexity_reasoning.py,,1,2.2159489282323004e-08,"The method `test_reasoning_effort_parameter_mapping` is a unit test designed to verify that the `reasoning_effort` parameter is correctly mapped and preserved in the optional parameters for a specific model. It includes assertions to ensure the parameter is present and correctly set, which is a common practice in testing to prevent regressions and ensure code reliability. Since it serves a clear purpose in maintaining the integrity of the codebase, it is likely to be retained."
survived,"def get_preset_column_config(
    preset_id: uuid.UUID,
    authenticated_entity: AuthenticatedEntity = Depends(
        IdentityManagerFactory.get_auth_verifier([""read:preset""])
    ),
    session: Session = Depends(get_session),
) -> ColumnConfigurationDto:
    tenant_id = authenticated_entity.tenant_id
    logger.info(""Getting preset column configuration"", extra={""preset_id"": preset_id})
    
    statement = (
        select(Preset)
        .where(Preset.tenant_id == tenant_id)
        .where(Preset.id == preset_id)
    )
    preset = session.exec(statement).first()
    if not preset:
        raise HTTPException(404, ""Preset not found"")

    preset_dto = PresetDto(**preset.to_dict())
    
    return ColumnConfigurationDto(
        column_visibility=preset_dto.column_visibility,
        column_order=preset_dto.column_order,
        column_rename_mapping=preset_dto.column_rename_mapping,
        column_time_formats=preset_dto.column_time_formats,
        column_list_formats=preset_dto.column_list_formats,
    )",keep/api/routes/preset.py,,1,7.582560422162384e-10,"The method `get_preset_column_config` is a well-structured function that retrieves a preset column configuration based on a given preset ID. It uses dependency injection for authentication and session management, which is a modern and efficient approach. The function includes logging for tracking and raises an appropriate HTTP exception if the preset is not found. It also constructs and returns a `ColumnConfigurationDto` object, which is likely used elsewhere in the application. Given these factors, the method is likely to be useful and relevant in its context, suggesting it will survive."
survived,"    def test_cost_report_body_payload(self):
        """"""Test CostReportBody payload structure.""""""
        # Test default days
        body = payloads.CostReportBody()
        self.assertEqual(body.days, 30)
        
        # Test custom days
        body = payloads.CostReportBody(days=7)
        self.assertEqual(body.days, 7)
        
        # Test None days
        body = payloads.CostReportBody(days=None)
        self.assertIsNone(body.days)
",tests/unit_tests/test_sky_cost_report.py,TestCostReportServer,1,1.0467401685178159e-08,"The method `test_cost_report_body_payload` is a unit test designed to verify the functionality of the `CostReportBody` class, specifically its handling of the `days` attribute. Unit tests are crucial for ensuring code reliability and correctness, especially when changes are made to the codebase. This test checks for default values, custom values, and handling of `None`, which are all important scenarios to validate. Therefore, this method is likely to be retained as it contributes to the robustness of the code by ensuring that the `CostReportBody` behaves as expected under different conditions."
survived,"    def test_show_cost_report_table_without_days(self):
        """"""Test show_cost_report_table without days information.""""""
        mock_records = []
        
        with mock.patch('click.echo') as mock_echo:
            with mock.patch('sky.utils.log_utils.create_table') as mock_create_table:
                mock_table = mock.Mock()
                mock_create_table.return_value = mock_table
                
                status_utils.show_cost_report_table(
                    mock_records, 
                    show_all=False, 
                    days=None
                )
                
                # Should not display days information in header
                mock_echo.assert_called()
                echo_calls = [call[0][0] for call in mock_echo.call_args_list]
                header_with_days = any('(last' in call for call in echo_calls)
                self.assertFalse(header_with_days, ""Should not display days in header when None"")
",tests/unit_tests/test_sky_cost_report.py,TestCostReportStatusUtils,1,1.637377179507321e-07,"The method is a unit test for a function that checks if the cost report table is displayed correctly without days information. It uses mocking to simulate the behavior of external dependencies and verifies the output. This is a standard practice in testing to ensure code reliability and correctness. Since it is a test method, it is likely to be maintained as long as the functionality it tests is relevant."
survived,"    def test_status_utils_with_none_resources_string(self):
        """"""Test status utils generate safe strings when resources are problematic.""""""
        mock_record_with_none = {
            'status': None,
            'num_nodes': 1,
            'resources': None,
            'total_cost': 0.0
        }
        
        mock_record_with_missing_attrs = {
            'status': None,
            'num_nodes': 2,
            'resources': mock.Mock(),
            'total_cost': 10.0
        }
        # Mock resources object missing expected attributes
        mock_record_with_missing_attrs['resources'].instance_type = None
        del mock_record_with_missing_attrs['resources'].cloud  # Simulate missing attribute
        
        # Test that these don't crash the status utility functions
        for record in [mock_record_with_none, mock_record_with_missing_attrs]:
            try:
                status_utils._get_resources_for_cost_report(record, truncate=True)
            except:
                pass  # May fail, but shouldn't crash the whole system
            
            try:
                status_utils._get_price_for_cost_report(record, truncate=True)
            except:
                pass
                
            try:
                status_utils._get_estimated_cost_for_cost_report(record, truncate=True)
            except:
                pass
",tests/unit_tests/test_sky_cost_report.py,TestHistoricalClusterRobustness,1,1.4166087846364157e-09,"The method `test_status_utils_with_none_resources_string` is a test method designed to ensure that the `status_utils` functions can handle records with `None` or missing attributes without crashing. This is a common scenario in testing to ensure robustness and error handling in the code. Test methods like this are crucial for maintaining code quality and are unlikely to be deleted unless the functionality they test is removed or significantly changed. Therefore, the method is likely to survive."
survived,"    def test_cost_report_with_pickle_errors(self):
        """"""Test cost_report handles pickle errors gracefully when loading historical data.""""""
        import pickle
        
        # Mock get_clusters_from_history to simulate pickle errors being handled internally
        with mock.patch('sky.global_user_state.get_clusters_from_history') as mock_get_history:
            # Simulate the function handling pickle errors gracefully and returning empty list
            mock_get_history.return_value = []
            
            # Even if there are pickle errors internally, the function should not crash
            result = core.cost_report(days=30)
            
            self.assertEqual(result, [])
            mock_get_history.assert_called_once_with(days=30)
",tests/unit_tests/test_sky_cost_report.py,TestCostReportCore,1,8.152020648014727e-09,"The method 'test_cost_report_with_pickle_errors' is a unit test designed to ensure that the 'cost_report' function can handle pickle errors gracefully. Unit tests are crucial for maintaining code quality and ensuring that functions behave as expected, especially when dealing with potential errors. This test is valuable for verifying robustness and error handling, which are important aspects of software development. Therefore, it is likely to be retained in the codebase."
survived,"    def test_cost_report_default_days(self):
        """"""Test cost_report with default days parameter.""""""
        with mock.patch('sky.global_user_state.get_clusters_from_history') as mock_get_history:
            mock_get_history.return_value = []
            
            result = core.cost_report()
            
            # Should call with default 30 days
            mock_get_history.assert_called_once_with(days=30)
            self.assertEqual(result, [])
",tests/unit_tests/test_sky_cost_report.py,TestCostReportCore,1,4.363462233903899e-09,"The method `test_cost_report_default_days` is a unit test that verifies the behavior of the `cost_report` function when called with its default parameters. It uses mocking to simulate the behavior of an external dependency (`get_clusters_from_history`) and checks that the function behaves as expected. Unit tests are crucial for ensuring code reliability and are typically maintained as long as the functionality they test is relevant. Therefore, this method is likely to be retained as long as the `cost_report` function exists and requires testing."
survived,"    def test_cost_report_with_empty_usage_intervals(self):
        """"""Test cost report handles clusters with empty or malformed usage intervals.""""""
        mock_cluster_record = {
            'name': 'empty-intervals-cluster',
            'status': None,
            'num_nodes': 1,
            'resources': mock.Mock(),
            'total_cost': 0.0,
            'launched_at': None,  # Missing launch time
            'duration': 0,
            'cluster_hash': 'ghi789',
            'usage_intervals': [],  # Empty intervals
            'user_hash': 'user789',
            'user_name': 'testuser3',
            'workspace': 'default',
        }
        
        mock_cluster_record['resources'].instance_type = 'valid-type'
        mock_cluster_record['resources'].cloud = mock.Mock()
        mock_cluster_record['resources'].cloud.__str__ = lambda: 'gcp'
        
        with mock.patch('sky.global_user_state.get_clusters_from_history', 
                      return_value=[mock_cluster_record]):
            
            # Should handle gracefully
            result = core.cost_report(days=30)
            self.assertEqual(len(result), 1)
            self.assertEqual(result[0]['name'], 'empty-intervals-cluster')
",tests/unit_tests/test_sky_cost_report.py,TestHistoricalClusterRobustness,1,4.944450477491054e-09,The method is a unit test designed to ensure that the cost report function can handle clusters with empty or malformed usage intervals. This is a valid and important test case to ensure robustness of the cost reporting functionality. It is likely to be retained as it tests a specific edge case that could occur in real-world scenarios.
survived,"    def test_show_cost_report_table_with_days(self):
        """"""Test show_cost_report_table displays days information.""""""
        mock_records = []
        
        with mock.patch('click.echo') as mock_echo:
            with mock.patch('sky.utils.log_utils.create_table') as mock_create_table:
                mock_table = mock.Mock()
                mock_create_table.return_value = mock_table
                
                status_utils.show_cost_report_table(
                    mock_records, 
                    show_all=False, 
                    days=7
                )
                
                # Should display days information in header
                mock_echo.assert_called()
                echo_calls = [call[0][0] for call in mock_echo.call_args_list]
                header_with_days = any('(last 7 days)' in call for call in echo_calls)
                self.assertTrue(header_with_days, ""Should display days in header"")
",tests/unit_tests/test_sky_cost_report.py,TestCostReportStatusUtils,1,1.8553915987649156e-07,"The method is a unit test for a function that checks if the 'show_cost_report_table' function correctly displays information about the last 7 days. Unit tests are crucial for ensuring code reliability and functionality, especially when dealing with user interfaces or output formatting. This test verifies that the header includes the correct time frame, which is an important aspect of the function's output. Therefore, it is likely to be maintained to ensure the function behaves as expected."
survived,"    def test_completely_new_package(self, mock_config, mock_logger, mock_db):
        """"""Tests the addition of completely new packages & new URLs""""""

        # Create empty cache (no existing packages)
        cache = Cache(package_map={}, url_map={}, package_urls={}, dependencies={})

        # Create new package data
        new_pkg_data = create_debian_package(
            package=""new-pkg"",
            description=""A new package"",
            homepage=""https://github.com/example/new-pkg"",
            depends=[""some-dep""],
            build_depends=[""build-tool""],
        )

        # Test the diff
        diff = DebianDiff(mock_config, cache, mock_db, mock_logger)
        pkg_id, pkg_obj, update_payload = diff.diff_pkg(""debian/new-pkg"", new_pkg_data)

        # Assertions
        assert pkg_obj is not None  # New package should be created
        assert pkg_obj.derived_id == ""debian/new-pkg""
        assert pkg_obj.name == ""new-pkg""
        assert pkg_obj.import_id == ""debian/new-pkg""
        assert pkg_obj.package_manager_id == mock_config.pm_config.pm_id
        assert pkg_obj.readme == ""A new package""
        assert update_payload == {}  # No updates for new package

        # Test URL creation
        new_urls = {}
        resolved_urls = diff.diff_url(""new-pkg"", new_pkg_data, new_urls)
        new_links, updated_links = diff.diff_pkg_url(pkg_id, resolved_urls)

        # Should create URL for homepage
        assert len(new_urls) >= 1  # At least homepage
        assert len(new_links) >= 1  # At least homepage link
        assert len(updated_links) == 0  # No existing links to update

        # Check that homepage URL was created
        homepage_url_found = False
        for url_key, _url in new_urls.items():
            if url_key.url_type_id == mock_config.url_types.homepage:
                assert url_key.url == ""https://github.com/example/new-pkg""
                homepage_url_found = True
                break
        assert homepage_url_found
",tests/package_managers/debian/test_debian_diff.py,TestDebianDifferentialLoading,1,1.8553915987649156e-07,"The method is a unit test for a specific functionality related to package management. It is well-structured, includes assertions to verify the expected behavior, and is likely part of a test suite to ensure code reliability. Such methods are generally retained to maintain code quality and prevent regressions."
survived,"def simple_source():
    return """"""Package: 0ad
Binary: 0ad, 0ad-dbg, 0ad-data, 0ad-data-common
Version: 0.0.26-1
Maintainer: Debian Games Team <pkg-games-devel@lists.alioth.debian.org>
Uploaders: Vincent Cheng <vcheng@debian.org>, Euan Kemp <euank@euank.com>
Build-Depends: debhelper-compat (= 13), cmake, dpkg-dev (>= 1.15.5), libboost-dev, libenet-dev (>= 1.3), libopenal-dev, libpng-dev, libsdl2-dev, libtiff5-dev, libvorbis-dev, libxcursor-dev, pkg-config, zlib1g-dev, libcurl4-gnutls-dev, libgloox-dev, libjsoncpp-dev, libminiupnpc-dev, libnspr4-dev, libnss3-dev, libsodium-dev, libwxgtk3.0-gtk3-dev | libwxgtk3.0-dev, python3, python3-dev, libxml2-dev, rust-gdb [amd64 i386 ppc64el]
Architecture: any all
Standards-Version: 4.5.1
Format: 3.0 (quilt)
Files:
 2fc0f38b8a4cf56fea7040fcf5f79ca3 2414 0ad_0.0.26-1.dsc
 35ca57e781448c69ba31323313e972af 31463733 0ad_0.0.26.orig.tar.xz
 f78de44c8a9c32e6be3ae99f2747c330 71948 0ad_0.0.26-1.debian.tar.xz
Vcs-Browser: https://salsa.debian.org/games-team/0ad
Vcs-Git: https://salsa.debian.org/games-team/0ad.git
Directory: pool/main/0/0ad
Priority: optional
Section: games
Testsuite: autopkgtest
Testsuite-Triggers: g++, pyrex


""""""
",tests/package_managers/debian/test_debian_parser.py,,1,1.8553915987649156e-07,"The method `simple_source` is a straightforward function that returns a string containing metadata about a Debian package. This type of function is useful for providing static data or configuration information in a structured format. It is unlikely to be deleted because it serves a clear purpose in providing package information, which can be useful for documentation, testing, or configuration purposes. Additionally, the method is simple and does not introduce any complexity or dependencies that might warrant its removal."
survived,"    def test_no_changes_scenario(self, mock_config, mock_logger, mock_db):
        """"""Tests where package exists but has no changes""""""

        # Setup existing package
        existing_pkg_id = uuid4()
        existing_package = Package(
            id=existing_pkg_id,
            derived_id=""debian/unchanged-pkg"",
            name=""unchanged-pkg"",
            package_manager_id=mock_config.pm_config.pm_id,
            import_id=""unchanged-pkg"",
            readme=""Unchanged description"",
        )

        cache = Cache(
            package_map={""unchanged-pkg"": existing_package},
            url_map={},
            package_urls={},
            dependencies={},
        )

        # Create package data with same description
        pkg_data = create_debian_package(
            package=""unchanged-pkg"", description=""Unchanged description""
        )

        # Test the diff
        diff = DebianDiff(mock_config, cache, mock_db, mock_logger)
        pkg_id, pkg_obj, update_payload = diff.diff_pkg(""unchanged-pkg"", pkg_data)

        # Assertions
        assert pkg_id == existing_pkg_id
        assert pkg_obj is None  # No new package
        assert update_payload is None  # No changes
",tests/package_managers/debian/test_debian_diff.py,TestDebianDifferentialLoading,1,8.592166611791576e-10,"The method 'test_no_changes_scenario' is a unit test designed to verify that the system correctly identifies when there are no changes to a package. This is a common scenario that needs to be tested to ensure the system behaves as expected when no updates are necessary. The method is well-structured, uses mock objects to simulate dependencies, and includes assertions to validate the expected behavior. Such tests are crucial for maintaining software quality and are unlikely to be deleted unless the functionality they test is removed or significantly altered. Therefore, the method will likely survive."
survived,"    def set_current_urls(self, urls: set[str]) -> None:
        """"""Getting all the URLs and Package URLs from the database""""""
        self.urls: CurrentURLs = self.current_urls(urls)
",package_managers/debian/db.py,DebianDB,1,2.646573631904765e-09,"The method 'set_current_urls' is a setter method that assigns a set of URLs to an instance variable 'self.urls'. It is a straightforward method that performs a necessary operation of updating the state of an object with new data. Such methods are typically essential for the functionality of a class, especially if the class is designed to manage or manipulate URLs. Without additional context suggesting that this method is redundant or replaced by another mechanism, it is likely to survive."
survived,"    def test_dependency_type_change_runtime_to_build(
        self, mock_config, mock_logger, mock_db
    ):
        """"""
        Scenario
          - p1 has runtime dependency to p2 in cache
          - p1 has build dependency to p2 in parsed data.

        Expect removed runtime dependency and new build dependency
        """"""

        p1_id = uuid4()
        p2_id = uuid4()

        p1_pkg = Package(id=p1_id, derived_id=""debian/p1"", name=""p1"", import_id=""p1"")
        p2_pkg = Package(id=p2_id, derived_id=""debian/p2"", name=""p2"", import_id=""p2"")

        # Existing runtime dependency
        existing_runtime_dep = LegacyDependency(
            package_id=p1_id,
            dependency_id=p2_id,
            dependency_type_id=mock_config.dependency_types.runtime,
        )

        cache = Cache(
            package_map={""debian/p1"": p1_pkg, ""debian/p2"": p2_pkg},
            url_map={},
            package_urls={},
            dependencies={p1_id: {existing_runtime_dep}},
        )

        # Parsed data only has build dependency
        new_pkg_data = create_debian_package(
            package=""p1"",
            depends=[],  # no runtime deps
            build_depends=[""p2""],  # only build
        )

        diff = DebianDiff(mock_config, cache, mock_db, mock_logger)
        new_deps, removed_deps = diff.diff_deps(""debian/p1"", new_pkg_data)

        # Should remove runtime and add build
        assert len(removed_deps) == 1
        assert removed_deps[0].dependency_id == p2_id
        assert (
            removed_deps[0].dependency_type_id == mock_config.dependency_types.runtime
        )

        assert len(new_deps) == 1
        assert new_deps[0].dependency_id == p2_id
        assert new_deps[0].dependency_type_id == mock_config.dependency_types.build
",tests/package_managers/debian/test_debian_diff.py,TestDebianDifferentialLoading,1,1.1861120010657661e-08,"The method is a well-defined test case that checks the functionality of changing a dependency type from runtime to build. It is useful for ensuring that the system correctly updates dependencies based on parsed data. Such test cases are crucial for maintaining the integrity of the software and ensuring that changes in dependencies are handled correctly. Therefore, it is likely to be retained as part of the test suite."
survived,"    def test_debian_specific_dependencies(self, mock_config, mock_logger, mock_db):
        """"""Test Debian-specific dependency types: recommends, suggests""""""

        p1_id = uuid4()
        p2_id = uuid4()
        p3_id = uuid4()

        p1_pkg = Package(id=p1_id, derived_id=""debian/p1"", name=""p1"")
        p2_pkg = Package(id=p2_id, derived_id=""debian/p2"", name=""p2"")
        p3_pkg = Package(id=p3_id, derived_id=""debian/p3"", name=""p3"")

        cache = Cache(
            package_map={""debian/p1"": p1_pkg, ""debian/p2"": p2_pkg, ""debian/p3"": p3_pkg},
            url_map={},
            package_urls={},
            dependencies={},
        )

        # Parsed data with recommends and suggests (mapped to runtime)
        new_pkg_data = create_debian_package(
            package=""p1"",
            recommends=[""p2""],
            suggests=[""p3""],
        )

        diff = DebianDiff(mock_config, cache, mock_db, mock_logger)
        new_deps, removed_deps = diff.diff_deps(""debian/p1"", new_pkg_data)

        # Should create runtime dependencies for both recommends and suggests
        assert len(removed_deps) == 0
        assert len(new_deps) == 2

        # Both should be runtime dependencies
        for dep in new_deps:
            assert dep.dependency_type_id == mock_config.dependency_types.runtime
            assert dep.dependency_id in [p2_id, p3_id]
",tests/package_managers/debian/test_debian_diff.py,TestDebianDifferentialLoading,1,5.60279640614594e-09,"The method is a unit test for a specific functionality related to Debian package dependencies. It is well-structured, uses mock objects to isolate the test environment, and verifies the expected behavior of the system. Such tests are crucial for ensuring the reliability of the codebase, especially when dealing with package management and dependencies. Therefore, it is likely to be retained as part of the test suite to ensure ongoing code quality and correctness."
survived,"def build_depends():
    """"""Fixture for all kinds of build depends.""""""
    return """"""
Package: example
Build-Depends: gcc-11-source (>= 11.3.0-11~), gawk, lib32gcc1-amd64-cross [amd64 arm64 i386 ppc64el x32], g++-11, gm2-11 [!powerpc !ppc64 !x32]
""""""
",tests/package_managers/debian/test_debian_parser.py,,1,1.1032560311263802e-09,"The method 'build_depends' is a simple function that returns a string containing package dependencies. It is a utility function that can be useful in various contexts where package management or build configuration is required. The function is straightforward, does not have any apparent issues, and serves a clear purpose. Therefore, it is likely to be retained in the codebase."
survived,"    def test_build_package_to_source_mapping_with_binary_list(
        self, tmp_path, mock_logger
    ):
        """"""Test building mapping when source has explicit binary list""""""

        # Create a test sources file
        sources_content = """"""Package: test-source
Binary: test-pkg1, test-pkg2, test-pkg3
Vcs-Git: https://github.com/test/test-source.git
Homepage: https://example.com/test-source

Package: another-source
Binary: another-pkg
Vcs-Browser: https://github.com/test/another-source
""""""

        sources_file = tmp_path / ""sources""
        sources_file.write_text(sources_content)

        # Build mapping
        mapping = build_package_to_source_mapping(str(sources_file), mock_logger)

        # Verify mapping
        assert len(mapping) == 4  # 3 packages from first source + 1 from second
        assert ""test-pkg1"" in mapping
        assert ""test-pkg2"" in mapping
        assert ""test-pkg3"" in mapping
        assert ""another-pkg"" in mapping

        # Verify source data is correctly associated
        assert mapping[""test-pkg1""].package == ""test-source""
        # URLs are normalized by the parser - expect normalized format
        assert mapping[""test-pkg1""].vcs_git == ""github.com/test/test-source""
        assert mapping[""test-pkg2""].package == ""test-source""
        assert mapping[""another-pkg""].package == ""another-source""
        assert mapping[""another-pkg""].vcs_browser == ""github.com/test/another-source""
",tests/package_managers/debian/test_debian_sources.py,TestPackageSourceMapping,1,2.2159489282323004e-08,"The method is a well-structured test function that verifies the functionality of building a package-to-source mapping from a given sources file. It includes setup, execution, and verification steps, which are essential for testing. The method is likely to survive because it is a useful test case that ensures the correctness of the mapping logic, which is crucial for maintaining the integrity of the software."
survived,"def ping():
    """"""Health check endpoint""""""
    return jsonify({
        'status': 'success',
        'message': 'pong',
        'timestamp': time.time()
    })
",server/health.py,,1,5.211412485172657e-10,"The method 'ping' is a simple health check endpoint, which is a common practice in web applications to ensure that the service is running and responsive. It returns a JSON response with a status message and a timestamp, which is useful for monitoring and debugging purposes. Such methods are typically retained in codebases as they provide essential functionality for system health monitoring."
survived,"def add_chat_message(task_id):
    """"""Add a chat message to a task""""""
    try:
        data = request.get_json()
        user_id = request.headers.get('X-User-ID')
        
        if not user_id:
            return jsonify({'error': 'User ID required'}), 400
        
        if not data:
            return jsonify({'error': 'No data provided'}), 400
        
        content = data.get('content')
        role = data.get('role', 'user')
        
        if not content:
            return jsonify({'error': 'content is required'}), 400
        
        if role not in ['user', 'assistant']:
            return jsonify({'error': 'role must be either ""user"" or ""assistant""'}), 400
        
        task = DatabaseOperations.add_chat_message(task_id, user_id, role, content)
        if not task:
            return jsonify({'error': 'Task not found'}), 404
        
        return jsonify({
            'status': 'success',
            'task': task
        })
        
    except Exception as e:
        logger.error(f""Error adding chat message: {str(e)}"")
        return jsonify({'error': str(e)}), 500
",server/tasks.py,,1,1.1032560311263802e-09,"The method 'add_chat_message' is well-structured and serves a clear purpose of adding a chat message to a task. It includes error handling for various scenarios such as missing user ID, missing data, invalid role, and task not found. It also logs errors for debugging purposes. These features make it a robust and useful method in a web application context, likely contributing to its survival."
survived,"    def get_user_tasks(user_id: str, project_id: int = None) -> List[Dict]:
        """"""Get all tasks for a user, optionally filtered by project""""""
        try:
            query = supabase.table('tasks').select('*').eq('user_id', user_id)
            if project_id:
                query = query.eq('project_id', project_id)
            result = query.order('created_at', desc=True).execute()
            return result.data or []
        except Exception as e:
            logger.error(f""Error fetching user tasks: {e}"")
            raise
",server/database.py,DatabaseOperations,1,6.69158608681505e-10,"The method 'get_user_tasks' is likely to survive because it provides a useful functionality of retrieving tasks for a user, optionally filtered by project. This is a common requirement in applications that manage tasks or projects. The method is well-structured, uses exception handling to log errors, and leverages a database query to fetch data, which are all good practices in software development."
survived,"def get_projects():
    """"""Get all projects for the authenticated user""""""
    try:
        # For now, we'll use a dummy user_id. In production, this should come from JWT token
        user_id = request.headers.get('X-User-ID')
        if not user_id:
            return jsonify({'error': 'User ID required'}), 400
        
        projects = DatabaseOperations.get_user_projects(user_id)
        return jsonify({
            'status': 'success',
            'projects': projects
        })
        
    except Exception as e:
        logger.error(f""Error fetching projects: {str(e)}"")
        return jsonify({'error': str(e)}), 500
",server/projects.py,,1,8.592166611791576e-10,"The method 'get_projects' is likely to survive because it is a functional piece of code that retrieves projects for an authenticated user. It includes error handling, logging, and returns appropriate HTTP responses. The method is useful in a web application context where users need to access their projects, and it is structured to handle potential issues like missing user IDs or database errors. Additionally, it is common to have such methods in applications that manage user-specific data."
survived,"def load_metadata_file(filepath: str) -> Dict:
    """"""
    Load a metadata.json file and return its contents.
    
    Args:
        filepath: Path to the metadata.json file
        
    Returns:
        Dictionary containing the metadata
    """"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            return json.load(f)
    except (json.JSONDecodeError, FileNotFoundError) as e:
        print(f""Warning: Could not load {filepath}: {e}"")
        return {}
",combine_metadata.py,,1,9.736200303530205e-10,"The method 'load_metadata_file' is a utility function that reads a JSON file and returns its contents as a dictionary. It includes error handling for common issues such as file not found and JSON decoding errors, which makes it robust and useful in many applications. The function is well-documented, specifying the input and output clearly. Such utility functions are often reused across projects for their simplicity and effectiveness in handling file operations. Therefore, it is likely to be retained in the codebase."
deleted,"    def test_mcp_server_tool_execution_error(self, mock_fastmcp, integration_graphs_and_metas):
        """"""Test error handling in tool execution.""""""
        graphs, metas = integration_graphs_and_metas
        mock_mcp_instance = MagicMock()
        
        registered_tools = []
        
        def mock_tool_decorator(func):
            registered_tools.append(func)
            return func
        
        mock_mcp_instance.tool.side_effect = lambda: mock_tool_decorator
        mock_fastmcp.return_value = mock_mcp_instance

        # Create the server
        server = create_mcp_server(
            graphs=graphs,
            metas=metas,
            server_name=""Error Test Server""
        )

        # Test error handling
        if registered_tools:
            tool_func = registered_tools[0]
            error_input = FlowInput(input_value=""trigger error"")
            
            result = tool_func(error_input)
            
            assert isinstance(result, FlowOutput)
            assert result.result is None
            assert ""Simulated execution error"" in result.error
",src/backend/tests/unit/test_mcp_server.py,TestMCPServerIntegration,1,2.998960815863541e-09,"The method is a unit test designed to verify error handling in a specific part of the code. Unit tests are crucial for ensuring code reliability and are typically maintained as long as the functionality they test is relevant. The method is well-structured, uses mocking effectively, and checks for expected error handling behavior, which are all good practices in testing. Therefore, it is likely to be retained."
deleted,"    def flow_execution_help() -> str:
        """"""Get help on how to execute flows via MCP.""""""
        flow_list = list(graphs.keys())
        return f""""""
# Langflow MCP Server Help

This server exposes {len(flow_list)} Langflow flows as MCP tools.

## Available Flows:
{chr(10).join(f""- {flow_id}: {metas.get(flow_id, {}).get('title', flow_id)}"" for flow_id in flow_list)}

## How to Execute Flows:
Use the corresponding MCP tool for each flow. Each tool accepts:
- input_value: The main input text/data
- tweaks: Optional parameter modifications

## Getting Flow Information:
Use these MCP resources:
- flow://flows - List all flows
- flow://flows/{{flow_id}}/info - Get flow details  
- flow://flows/{{flow_id}}/schema - Get input/output schema

## Example Usage:
1. List flows: Read resource ""flow://flows""
2. Get flow info: Read resource ""flow://flows/my_flow/info""
3. Execute flow: Call tool ""execute_my_flow"" with input_value
""""""
",src/backend/base/langflow/cli/mcp_server.py,,1,1.4166087846364157e-09,"The method 'flow_execution_help' provides a detailed help message for executing flows via MCP. It is a utility function that is likely useful for users to understand how to interact with the system. Such documentation or help functions are generally retained as they provide essential guidance to users, especially in complex systems. Therefore, it is likely to survive."
deleted,"        def mock_tool_decorator(func):
            registered_tools.append(func)
            return func
",src/backend/tests/unit/test_mcp_server.py,TestMCPServerIntegration,1,6.023574641292144e-08,"The method 'mock_tool_decorator' is a simple decorator function that registers a function by appending it to a list called 'registered_tools'. Decorators are a common and useful pattern in Python for modifying or enhancing functions. This particular decorator is straightforward and serves a clear purpose of registering tools, which suggests it is likely part of a larger framework or system. Given its utility and simplicity, it is unlikely to be deleted unless the entire system or approach to registering tools changes significantly."
survived,"    def test_mcp_server_missing_graph_attributes(self, mock_fastmcp):
        """"""Test MCP server creation with graphs missing expected attributes.""""""
        mock_graph = MagicMock()
        mock_graph.run.side_effect = AttributeError(""Graph has no run method"")
        
        mock_mcp_instance = MagicMock()
        mock_fastmcp.return_value = mock_mcp_instance

        graphs = {""broken_flow"": mock_graph}
        metas = {""broken_flow"": MagicMock()}

        # Should not fail during server creation
        server = create_mcp_server(
            graphs=graphs,
            metas=metas,
            server_name=""Broken Graph Test""
        )

        assert server == mock_mcp_instance",src/backend/tests/unit/test_mcp_server.py,TestMCPServerErrorHandling,1,1.3440409770490404e-08,"The method 'test_mcp_server_missing_graph_attributes' is a unit test designed to ensure that the 'create_mcp_server' function can handle graphs that are missing expected attributes without failing. This is a valid and useful test case as it checks the robustness of the server creation process against incomplete or incorrect input data. Such tests are crucial for maintaining software reliability and are typically retained in the codebase to prevent regressions. Therefore, the method is likely to be retained."
survived,"def upload_registry(
    registry_path: Annotated[
        Path,
        typer.Option(
            help=""Path to the registry.json file"",
        ),
    ] = Path(""registry.json""),
) -> None:
    """"""
    Upload registry entries to Supabase database (reach out to admins for env variable access).
    """"""
    supabase = create_client(
        os.environ[""SUPABASE_URL""],
        os.environ[""SUPABASE_SERVICE_ROLE_KEY""],
    )

    rich_print(""Fetching existing registry entries..."")
    existing_entries_response = supabase.table(""registry"").select(""*"").execute()
    existing_entries = {
        (entry[""name""], entry[""version""]): SupabaseRegistry(**entry)
        for entry in existing_entries_response.data
    }

    rich_print(""Loading registry data..."")
    try:
        registry = Registry.from_file(registry_path)
    except FileNotFoundError:
        rich_print(f""[bold red]Registry file does not exist: {registry_path}[/]"")
        raise typer.Exit(1)
    except json.JSONDecodeError as e:
        rich_print(f""[bold red]Invalid JSON in registry file: {e}[/]"")
        raise typer.Exit(1)
    except Exception as e:
        rich_print(f""[bold red]Failed to parse registry data: {e}[/]"")
        raise typer.Exit(1)

    current_time = datetime.now().isoformat()
    registry_entries = []

    for entry in registry.datasets:
        registry_entry = SupabaseRegistry(
            name=entry.name,
            version=entry.version,
            description=entry.description,
            terminal_bench_version=entry.terminal_bench_version,
            github_url=entry.github_url,
            dataset_path=entry.dataset_path,
            branch=entry.branch,
            commit_hash=entry.commit_hash,
            updated_at=current_time,
        )

        entry_key = (registry_entry.name, registry_entry.version)
        if (
            entry_key not in existing_entries
            or registry_entry != existing_entries[entry_key]
        ):
            registry_entries.append(registry_entry.to_dict())

    if registry_entries:
        rich_print(
            f""Uploading {len(registry_entries)} new or changed registry entries...""
        )
        try:
            result = (
                supabase.table(""registry"")
                .upsert(registry_entries, on_conflict=""name,version"")
                .execute()
            )
        except Exception as e:
            rich_print(f""[bold red]Failed to upload registry entries: {e}[/]"")
            raise typer.Exit(1)
    else:
        rich_print(""[yellow]No new or changed registry entries to upload[/]"")
        return

    uploaded_count = len(registry_entries)
    rich_print(
        f""[bold green]Successfully uploaded {uploaded_count} registry entries to Supabase![/]""
    )",terminal_bench/cli/tb/admin.py,,1,1.8189616842444243e-09,"The method `upload_registry` is well-structured and serves a clear purpose: uploading registry entries to a Supabase database. It includes error handling for common issues such as file not found, JSON decoding errors, and general exceptions during the upload process. The method also provides informative feedback to the user through rich print statements, which is useful for debugging and user experience. Additionally, it checks for existing entries to avoid unnecessary uploads, which is efficient. Given these factors, the method is likely to be useful and maintained in the codebase."
survived,"    def __eq__(self, other: object) -> bool:
        if not isinstance(other, SupabaseRegistry):
            return NotImplemented

        return (
            self.name == other.name
            and self.version == other.version
            and self.description == other.description
            and self.terminal_bench_version == other.terminal_bench_version
            and self.github_url == other.github_url
            and self.dataset_path == other.dataset_path
            and self.branch == other.branch
            and self.commit_hash == other.commit_hash
        )
",terminal_bench/cli/tb/admin.py,SupabaseRegistry,1,2.0611536181902033e-09,"The method is a well-implemented equality comparison method for a class, likely used to compare instances of the class for equality based on their attributes. It follows Python's best practices by returning NotImplemented when the other object is not an instance of the expected class. This is a common and useful method in object-oriented programming, especially when instances of the class need to be compared. Therefore, it is unlikely to be deleted unless the class itself is removed or significantly refactored."
deleted,"    def test_transform_request_temperature_n_not_limited_high_temp(self):
        """"""Test that n is not limited when temperature is high""""""
        config = MoonshotChatConfig()
        
        optional_params = {
            ""temperature"": 0.8,  # High temperature
            ""n"": 3  # Multiple results requested
        }
        
        result = config.transform_request(
            model=""moonshot-v1-8k"",
            messages=[{""role"": ""user"", ""content"": ""test""}],
            optional_params=optional_params,
            litellm_params={},
            headers={}
        )
        
        # n should remain as 3 when temperature is high
        assert result.get(""n"") == 3
        assert result.get(""temperature"") == 0.8
",tests/test_litellm/llms/moonshot/test_moonshot_chat_transformation.py,TestMoonshotConfig,1,1.0467401685178159e-08,"The method is a unit test that verifies a specific behavior of the `transform_request` function in the `MoonshotChatConfig` class. It checks that when the temperature parameter is set to a high value, the 'n' parameter is not limited and remains as specified. This is a valid and useful test to ensure the function behaves correctly under certain conditions. Unit tests are generally retained to ensure code reliability and correctness."
survived,"def main():
    """"""Main function""""""
    run_config, training_config, args = parse_args()
    
    # Create trainable model
    model = art.TrainableModel(
        name=args.model_name,
        project=""tau_bench_rl"",
        base_model=args.base_model,
        config=TauBenchPolicyConfig(
            training_config=training_config,
            run_config=run_config,
        ),
    )
    
    print(f""Starting RL training for model: {model.name}"")
    print(f""Base model: {model.base_model}"")
    print(f""Environment: {run_config.env}"")
    print(f""Task split: {run_config.task_split}"")
    
    # Run training
    asyncio.run(train(model))
",dev/tau-bench/run_rl.py,,1,2.998960815863541e-09,"The method 'main()' is a standard entry point for Python scripts and is used to initialize and run the main logic of the program. It includes parsing arguments, creating a model, and starting a training process, which are essential steps in a machine learning workflow. The method is well-structured and serves a clear purpose, making it unlikely to be deleted unless the entire script is refactored or the functionality is no longer needed."
survived,"	def type_with_custom_actions_no_thinking(custom_actions: type[ActionModel]) -> type[AgentOutput]:
		""""""Extend actions with custom actions and exclude thinking field""""""
		
		# Create a base model without thinking
		model_ = create_model(
			'AgentOutputNoThinking',
			evaluation_previous_goal=(str, Field(..., description='One-sentence analysis of your last action. Clearly state success, failure, or uncertain.')),
			memory=(str, Field(..., description='1-3 sentences of specific memory of this step and overall progress.')),
			next_goal=(str, Field(..., description='State the next immediate goals and actions to achieve it, in one clear sentence.')),
			action=(
				list[custom_actions],
				Field(..., description='List of actions to execute', json_schema_extra={'min_items': 1}),
			),
			__module__=AgentOutput.__module__,
			__config__=AgentOutput.model_config,
		)
		
		# Add the current_state property
		def current_state_property(self) -> AgentBrain:
			""""""For backward compatibility - returns an AgentBrain with the flattened properties""""""
			return AgentBrain(
				thinking=None,
				evaluation_previous_goal=self.evaluation_previous_goal,
				memory=self.memory,
				next_goal=self.next_goal,
			)
		
		model_.current_state = property(current_state_property)
		model_.__doc__ = 'AgentOutput model with custom actions and no thinking field'
		return model_
",browser_use/agent/views.py,AgentOutput,1,3.2241866333029355e-08,"The method 'type_with_custom_actions_no_thinking' is a utility function that dynamically creates a model class by extending a base model with custom actions and excluding a specific field ('thinking'). This kind of functionality is useful in scenarios where models need to be customized or extended based on specific requirements, such as adding or removing fields. The method is well-documented, and its purpose is clear, making it a valuable tool for developers who need to create customized data models. Given the increasing use of dynamic and flexible data models in software development, this method is likely to be retained and used in various applications."
survived,"    def test_env_group_with_custom_names(self, mock_openai_client):
        """"""Test EnvGroup with custom environment names.""""""
        env1 = SingleTurnEnv(
            client=mock_openai_client,
            model=""test-model"",
            dataset=Dataset.from_dict({""question"": [""q1""], ""answer"": [""a1""]}),
            rubric=Rubric()
        )
        
        env2 = SingleTurnEnv(
            client=mock_openai_client,
            model=""test-model"",
            dataset=Dataset.from_dict({""question"": [""q2""], ""answer"": [""a2""]}),
            rubric=Rubric()
        )
        
        env_group = EnvGroup(envs=[env1, env2], env_names=[""math"", ""code""])
        
        assert env_group.env_names == [""math"", ""code""]
        assert env_group.env_map[""math""] == env1
        assert env_group.env_map[""code""] == env2
",tests/test_env_group.py,TestEnvGroup,1,1.444980317078884e-07,"The method is a unit test for a specific functionality, which is to ensure that the EnvGroup can be initialized with custom environment names and that these names correctly map to the respective environments. This is a common and necessary test to verify that the feature works as intended. Such tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is unlikely to be deleted unless the feature itself is removed or significantly altered."
survived,"    async def test_state_initialization(self, mock_multiturn_env):
        """"""Test that state is properly initialized with all required fields.""""""
        mock_multiturn_env.client.add_chat_response(
            messages=[{""role"": ""user"", ""content"": ""Test state""}],
            response=""Quick DONE""
        )
        
        prompt = [{""role"": ""user"", ""content"": ""Test state""}]
        completion, state = await mock_multiturn_env.rollout(
            client=mock_multiturn_env.client,
            model=""test-model"",
            prompt=prompt,
            answer=""test_answer"",
            task=""test_task"",
            info={""extra"": ""data""}
        )
        
        # Check all state fields are initialized
        assert state[""prompt""] == prompt
        # state[""completion""] is initialized to [] but not updated during rollout
        assert state[""completion""] == []
        assert state[""answer""] == ""test_answer""
        assert state[""task""] == ""test_task""
        assert state[""info""] == {""extra"": ""data""}
        assert ""responses"" in state
        assert isinstance(state[""responses""], list)
",tests/test_multiturn_env.py,TestMultiTurnEnv,1,1.955568070542584e-08,"The method `test_state_initialization` is a unit test designed to verify that the state is properly initialized with all required fields in an asynchronous environment. It uses a mock environment to simulate the behavior of a multi-turn conversation system. The test checks that the state contains the expected fields and values after a rollout operation. This is a typical and necessary test to ensure the integrity and correctness of state management in the system. Given its purpose and the fact that it is a test method, it is unlikely to be deleted unless the functionality it tests is removed or significantly altered. Therefore, it is more likely to survive."
survived,"    def test_parse_chat_completion_tokens(self, mock_openai_client, sample_dataset):
        """"""Test parsing tokens from a vLLM chat completion.""""""
        env = SimpleEnvironment(
            client=mock_openai_client,
            model=""test-model"",
            dataset=sample_dataset,
            parser=Parser(),
            rubric=Rubric()
        )
        
        # Create mock chat completion with tokens
        mock_completion = Mock()
        mock_completion.choices = [Mock()]
        mock_completion.choices[0].logprobs = Mock()
        mock_completion.choices[0].logprobs.content = [
            Mock(token=""id:1234""),
            Mock(token=""id:5678""),
            Mock(token=""id:9012"")
        ]
        
        tokens = env.parse_chat_completion_tokens(mock_completion)
        assert tokens == [1234, 5678, 9012]
",tests/test_environment.py,TestEnvironmentBase,1,2.2159489282323004e-08,"The method `test_parse_chat_completion_tokens` is a unit test designed to verify the functionality of parsing tokens from a chat completion. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with external dependencies like a mock OpenAI client. The test is well-structured, using mock objects to simulate the behavior of the OpenAI client and its responses. This allows for isolated testing of the `parse_chat_completion_tokens` method. Given the importance of testing in software development, especially for maintaining code quality and preventing regressions, it is unlikely that this method will be deleted."
survived,"    async def test_env_group_rubric_score_rollout(self, mock_openai_client):
        """"""Test scoring a rollout with EnvGroupRubric.""""""
        # Create test environments
        def func1(completion, **kwargs):
            return 0.8
        
        def func2(completion, **kwargs):
            return 0.6
        
        env1 = SingleTurnEnv(
            client=mock_openai_client,
            model=""test-model"",
            eval_dataset=Dataset.from_dict({""question"": [""q1""], ""answer"": [""a1""]}),
            rubric=Rubric(funcs=[func1], weights=[1.0])
        )
        
        env2 = SingleTurnEnv(
            client=mock_openai_client,
            model=""test-model"",
            eval_dataset=Dataset.from_dict({""question"": [""q2""], ""answer"": [""a2""]}),
            rubric=Rubric(funcs=[func2], weights=[1.0])
        )
        
        env_map = {""math"": env1, ""code"": env2}
        rubric = EnvGroupRubric(env_map)
        
        # Test scoring for ""math"" task
        result = await rubric.score_rollout(
            prompt=""Test prompt"",
            completion=""Test completion"",
            answer=""Test answer"",
            state={},
            task=""math""
        )
        
        assert ""func1"" in result
        assert ""func2"" in result
        assert result[""func1""] == 0.8  # From env1
        assert result[""func2""] == 0.0  # Not in env1, so 0.0
        assert result[""reward""] == 0.8
",tests/test_env_group.py,TestEnvGroupRubric,1,9.42244663976186e-07,"The method `test_env_group_rubric_score_rollout` is a unit test for a specific functionality involving scoring a rollout with an `EnvGroupRubric`. Unit tests are crucial for ensuring code correctness and reliability, especially in complex systems. This test method is well-structured, uses mock objects, and checks the expected behavior of the system. It is unlikely to be deleted as it serves an important role in maintaining the quality of the codebase."
survived,"    async def test_responses_stored_in_state(self, mock_multiturn_env):
        """"""Test that model responses are stored in state['responses'].""""""
        # Set up a multi-turn conversation
        mock_multiturn_env.client.add_chat_response(
            messages=[{""role"": ""user"", ""content"": ""Start""}],
            response=""First""
        )
        mock_multiturn_env.client.add_chat_response(
            messages=[
                {""role"": ""user"", ""content"": ""Start""},
                {""role"": ""assistant"", ""content"": ""First""},
                {""role"": ""user"", ""content"": ""Continue (turn 1)""}
            ],
            response=""Second""
        )
        mock_multiturn_env.client.add_chat_response(
            messages=[
                {""role"": ""user"", ""content"": ""Start""},
                {""role"": ""assistant"", ""content"": ""First""},
                {""role"": ""user"", ""content"": ""Continue (turn 1)""},
                {""role"": ""assistant"", ""content"": ""Second""},
                {""role"": ""user"", ""content"": ""Please finish with DONE""}
            ],
            response=""DONE""
        )
        
        prompt = [{""role"": ""user"", ""content"": ""Start""}]
        completion, state = await mock_multiturn_env.rollout(
            client=mock_multiturn_env.client,
            model=""test-model"",
            prompt=prompt,
            answer=""test""
        )
        
        # Check that all responses are stored
        assert len(state[""responses""]) == 3
        # Each response should have the structure returned by get_model_response
        for response in state[""responses""]:
            assert hasattr(response, 'choices')
            assert len(response.choices) > 0",tests/test_multiturn_env.py,TestMultiTurnEnv,1,5.60279640614594e-09,"The method is a well-structured test case that verifies the functionality of storing model responses in a state object. It uses a mock environment to simulate a multi-turn conversation and checks if the responses are correctly stored and structured. This is a common and necessary test pattern in software development to ensure the reliability of the code. There is no indication that this method is obsolete or redundant, and it serves a clear purpose in testing the system's behavior."
survived,"    def test_generate_sync_wrapper(self, mock_openai_client, sample_dataset):
        """"""Test synchronous generate wrapper.""""""
        env = SimpleEnvironment(
            client=mock_openai_client,
            model=""test-model"",
            dataset=sample_dataset,
            parser=Parser(),
            rubric=Rubric()
        )
        
        # Mock the rubric scoring
        env.rubric.score_rollouts = AsyncMock(return_value={
            ""reward"": [1.0]
        })
        
        inputs = {
            ""prompt"": [[{""role"": ""user"", ""content"": ""Hello""}]],
            ""answer"": [""Hi""]
        }
        
        results = env.generate(inputs, client=env.client)
        
        assert ""completion"" in results
        assert ""state"" in results
        assert ""reward"" in results
",tests/test_environment.py,TestEnvironmentBase,1,1.4166087846364157e-09,"The method `test_generate_sync_wrapper` is a unit test for a function or class method, which is crucial for ensuring the correctness of the code it tests. Unit tests are generally not deleted unless the functionality they test is removed or significantly changed. Since this test is verifying the behavior of the `generate` method in a specific environment setup, it is likely to be maintained as long as the `generate` method and its associated components (like `SimpleEnvironment`, `Parser`, and `Rubric`) are in use. Therefore, the method is likely to survive."
survived,"    def test_env_group_dataset_concatenation(self, mock_openai_client):
        """"""Test that EnvGroup properly concatenates datasets with task labels.""""""
        env1 = SingleTurnEnv(
            client=mock_openai_client,
            model=""test-model"",
            dataset=Dataset.from_dict({""question"": [""q1"", ""q2""], ""answer"": [""a1"", ""a2""]}),
            rubric=Rubric()
        )
        
        env2 = SingleTurnEnv(
            client=mock_openai_client,
            model=""test-model"",
            dataset=Dataset.from_dict({""question"": [""q3""], ""answer"": [""a3""]}),
            rubric=Rubric()
        )
        
        env_group = EnvGroup(envs=[env1, env2], env_names=[""math"", ""code""])
        
        # Check concatenated dataset
        dataset = env_group.get_dataset()
        assert len(dataset) == 3
        assert ""task"" in dataset.column_names
        
        # Check task labels
        tasks = dataset[""task""]
        assert tasks[0] == ""math""
        assert tasks[1] == ""math""
        assert tasks[2] == ""code""
",tests/test_env_group.py,TestEnvGroup,1,1.8189616842444243e-09,"The method is a unit test that verifies the functionality of the EnvGroup class, specifically its ability to concatenate datasets from different environments and correctly assign task labels. Unit tests are crucial for ensuring code reliability and correctness, especially in complex systems. This test is likely to be maintained as it helps catch regressions and ensures that the EnvGroup class behaves as expected when handling multiple environments. Therefore, the method will survive."
survived,"def to_gql_project(project: models.Project) -> Project:
    """"""
    Converts an ORM project to a GraphQL project.
    """"""
    return Project(
        project_rowid=project.id,
        db_project=project,
    )",src/phoenix/server/api/types/Project.py,,1,1.2501528648238603e-09,"The method `to_gql_project` is a utility function that converts an ORM project object to a GraphQL project object. This type of conversion function is common in applications that use GraphQL to interface with databases, as it helps in transforming data from one representation to another. Such functions are typically necessary for the smooth operation of data handling between different layers of an application. Therefore, it is likely to be retained in the codebase as it serves a specific and useful purpose."
deleted,"    def _parse_tool_response(self, response: Any, schema: Dict[str, Any], tools: Optional[List[Dict[str, str]]], index: int = 0) -> List[Dict[str, Any]]:
        """"""Parse tool-based response.""""""
        # Handle single-key string schema without tools
        if not tools and len(schema) == 1:
            key = next(iter(schema))
            content = response.choices[index].message.content
            
            # Handle deepseek-r1 models' think tags
            if is_deepseek_r1(response.model):
                result = {}
                think_match = re.search(r""<think>(.*?)</think>"", content, re.DOTALL)
                if think_match:
                    result[""think""] = think_match.group(1).strip()
                    main_content = re.split(r""</think>"", content, maxsplit=1)[-1].strip()
                    result[key] = main_content
                else:
                    result[key] = content
                return [result]
            
            return [{key: content}]

        # Extract tool calls
        if is_snowflake(response.model):
            tool_calls = self._extract_snowflake_tool_calls(response, index)
        else:
            tool_calls = getattr(response.choices[index].message, 'tool_calls', []) or []

        if tools:
            return self._parse_custom_tools(tool_calls, tools)
        else:
            return self._parse_send_output_tools(tool_calls, schema, response)
",docetl/operations/utils/api.py,ResponseParser,1,6.023574641292144e-08,"The method '_parse_tool_response' is a specialized function that handles parsing of responses based on certain conditions, such as the presence of tools, the type of model, and specific schema requirements. It includes handling for specific model types like 'deepseek-r1' and 'snowflake', and has a clear structure for parsing different types of tool calls. This indicates that the method is well-integrated into a larger system that deals with various response types and models. Given its specialized nature and the fact that it addresses specific parsing needs, it is likely to be retained as it serves a distinct purpose that is not easily generalized or replaced."
survived,"    def __init__(self, console: Console):
        self.console = console
",docetl/operations/utils/api.py,ResponseParser,1,5.3157849718487075e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting up initial states. Therefore, it is unlikely that this method will be deleted as it serves a critical purpose in the class structure."
survived,"    def test_get_format_reward_func(self, basic_parser):
        """"""Test that format reward function returns 1.0 by default.""""""
        reward_func = basic_parser.get_format_reward_func()
        completion = [{""role"": ""assistant"", ""content"": ""test""}]
        reward = reward_func(completion)
        assert reward == 1.0",tests/test_parser.py,TestParser,1,4.1399375473943306e-08,"The method `test_get_format_reward_func` is a unit test designed to verify that the `get_format_reward_func` method of the `basic_parser` object returns a function that consistently outputs a reward of 1.0. Unit tests are crucial for ensuring code reliability and correctness, especially in larger codebases. This test is simple, clear, and serves a specific purpose in validating the behavior of the `get_format_reward_func`. Therefore, it is unlikely to be deleted as it contributes to the overall robustness of the code."
survived,"    async def test_rollout_with_task_and_info(self, mock_singleturn_env):
        """"""Test rollout with task and info parameters.""""""
        prompt = [{""role"": ""user"", ""content"": ""Test question""}]
        answer = ""Test answer""
        task = ""math""
        info = {""difficulty"": ""easy""}
        
        completion, state = await mock_singleturn_env.rollout(
            client=mock_singleturn_env.client,
            model=""test-model"",
            prompt=prompt,
            answer=answer,
            task=task,
            info=info
        )
        
        assert isinstance(completion, list)
        assert state == {}  # SingleTurnEnv returns empty state
",tests/test_singleturn_env.py,TestSingleTurnEnv,1,4.944450477491054e-09,"The method `test_rollout_with_task_and_info` is a unit test designed to verify the behavior of the `rollout` function in a mock environment. It checks that the function returns a list as a completion and an empty dictionary as the state, which are likely expected behaviors in this context. Since the method is a test case, it is crucial for ensuring the correctness of the `rollout` function, especially when handling specific parameters like `task` and `info`. Test methods are generally retained unless they are redundant or replaced by more comprehensive tests. Therefore, it is likely to be Survived."
survived,"    async def test_a_generate_with_dataset(self, mock_singleturn_env, sample_chat_dataset):
        """"""Test async generation with Dataset input.""""""
        # Mock the rubric.score_rollouts method
        mock_singleturn_env.rubric.score_rollouts = AsyncMock(return_value={
            ""rewards"": [1.0, 1.0],
            ""scores"": [{""correctness"": 1.0}, {""correctness"": 1.0}]
        })
        
        results = await mock_singleturn_env.a_generate(sample_chat_dataset)
        
        assert ""completion"" in results
        assert ""state"" in results  
        assert ""rewards"" in results
        assert len(results[""completion""]) == 2
",tests/test_singleturn_env.py,TestSingleTurnEnv,1,4.6911638017642294e-08,"The method 'test_a_generate_with_dataset' is a unit test for an asynchronous function, which is a common practice in modern software development. It uses mocking to simulate the behavior of external dependencies, allowing for isolated testing of the function's logic. This approach is essential for ensuring code reliability and correctness, especially in complex systems. The method is well-structured, with clear assertions to verify the expected outcomes. Given the increasing importance of testing in software development, it is unlikely that this method will be deleted."
survived,"    def is_completed(self, messages, state, **kwargs):
        """"""Simple completion logic for testing.""""""
        if self.completion_condition == ""answer"":
            # Complete when assistant says ""DONE""
            if messages and messages[-1].get(""role"") == ""assistant"":
                return ""DONE"" in messages[-1].get(""content"", """")
        elif self.completion_condition == ""max_turns"":
            # Never complete naturally (test max_turns)
            return False
        elif self.completion_condition == ""error"":
            # Complete on any error
            if messages and messages[-1].get(""role"") == ""assistant"":
                return messages[-1].get(""content"", """").startswith(""[ERROR]"")
        return False
",tests/conftest.py,SimpleMultiTurnEnv,1,4.944450477491054e-09,"The method 'is_completed' is a utility function that checks for specific conditions to determine if a task is complete. It is a simple and clear implementation that can be useful in various testing scenarios, such as checking for a specific message from an assistant, reaching a maximum number of turns, or encountering an error. The method is flexible due to its use of different completion conditions and is likely to be useful in testing frameworks or conversational AI systems. Therefore, it is likely to be retained."
survived,"    def test_rubric_with_custom_parser(self):
        """"""Test Rubric with custom parser.""""""
        custom_parser = Parser()
        rubric = Rubric(funcs=[], weights=[], parser=custom_parser)
        
        assert rubric.parser is custom_parser",tests/test_rubric.py,TestRubric,1,1.955568070542584e-08,"The method `test_rubric_with_custom_parser` is a unit test that verifies the functionality of the `Rubric` class when initialized with a custom parser. Unit tests are generally essential for ensuring code reliability and are not typically deleted unless they are redundant or replaced by more comprehensive tests. Since this test is specific to checking the integration of a custom parser, it is likely to be useful for maintaining the integrity of the `Rubric` class's functionality."
survived,"    def test_rubric_group_add_reward_func_empty_group_fails(self):
        """"""Test that adding reward function fails if no rubrics exist.""""""
        # This shouldn't happen due to initialization check, but test edge case
        group = RubricGroup.__new__(RubricGroup)  # Bypass __init__
        group.rubrics = []
        
        def test_func(completion, **kwargs):
            return 1.0
        
        with pytest.raises(AssertionError, match=""RubricGroup must have at least one rubric""):
            group.add_reward_func(test_func)
",tests/test_rubric_group.py,TestRubricGroup,1,1.522997951276035e-08,"The method is a unit test that checks for a specific edge case where a reward function is added to an empty rubric group. It is important to ensure that the system behaves correctly in such scenarios, even if they are unlikely to occur in normal operation. The test is well-defined, uses a clear assertion to verify the expected behavior, and contributes to the robustness of the code by ensuring that the system enforces its constraints. Therefore, it is likely to be retained as part of the test suite."
survived,"    async def test_get_model_response_exception_handling(self, mock_openai_client):
        """"""Test exception handling in get_model_response.""""""
        # Mock an exception with context length error
        mock_openai_client.chat.completions.create = AsyncMock(
            side_effect=Exception(""Request longer than the maximum context length"")
        )
        
        env = TestEnvironment(
            client=mock_openai_client,
            model=""test-model"",
            eval_dataset=Dataset.from_dict({""question"": [""test""], ""answer"": [""test""]}),
            parser=Parser(),
            rubric=Rubric()
        )
        
        prompt = [{""role"": ""user"", ""content"": ""Hello""}]
        response = await env.get_model_response(
            prompt=prompt,
            client=mock_openai_client,
            model=""test-model""
        )
        
        assert response == ""[ERROR] prompt_too_long""
",tests/test_environment.py,TestEnvironmentBase,1,9.237449576640118e-09,"The method is testing a specific exception handling scenario, which is crucial for robust software development. Exception handling ensures that the system can gracefully handle errors and provide meaningful feedback to the user or developer. This test is particularly important for verifying that the system correctly identifies and responds to context length errors, which are common in AI model interactions. Therefore, the method is likely to be retained as it contributes to the reliability and stability of the system."
survived,"    def test_format_method(self, xml_parser):
        """"""Test formatting keyword arguments into XML.""""""
        formatted = xml_parser.format(reasoning=""My reasoning"", answer=""42"")
        assert ""<reasoning>\nMy reasoning\n</reasoning>"" in formatted
        assert ""<answer>\n42\n</answer>"" in formatted
",tests/test_xml_parser.py,TestXMLParser,1,3.2241866333029355e-08,"The method 'test_format_method' is a unit test designed to verify the functionality of the 'format' method in the 'xml_parser' object. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with data formatting and parsing. This test checks if the 'format' method correctly formats keyword arguments into XML, which is a common requirement in many applications. Given the importance of testing in software development, this method is likely to be retained to ensure the 'format' method works as expected."
survived,"            def is_completed(self, messages, state, **kwargs):
                return state.get(""turn_count"", 0) >= 2
",tests/test_multiturn_env.py,TestMultiTurnEnv.StatefulMultiTurnEnv,1,7.194132978569833e-09,"The method 'is_completed' is a simple utility function that checks if a certain condition (turn_count being 2 or more) is met. This type of method is often used in state management or control flow logic, and it is likely to be useful in various contexts where such a condition needs to be checked. Since it is a straightforward and potentially reusable piece of code, it is more likely to be retained rather than deleted."
survived,"        def test_func(completion, **kwargs):
            return 1.0
",tests/test_rubric_group.py,TestRubricGroup,0,0.9999962733608834,"The method `test_func` is a simple function that takes a parameter `completion` and any number of additional keyword arguments (`**kwargs`). It returns a constant value of 1.0 regardless of the input. This function might be used as a placeholder or a stub for testing purposes, where the actual logic is yet to be implemented. However, as it stands, it doesn't perform any meaningful computation or processing based on the inputs, which might lead to its deletion if not updated with actual functionality. Without further context on its intended use, it seems more likely to be deleted if it remains unchanged."
survived,"        def test_func(completion, **kwargs):
            return 1.0
",tests/test_rubric.py,TestRubric,0,0.999999922655772,"The method 'test_func' is a simple function that takes a 'completion' argument and any number of additional keyword arguments, but it only returns a constant value of 1.0. This suggests that the function is not performing any meaningful computation or utilizing its parameters effectively. Without further context or usage, it seems like a placeholder or incomplete implementation. Therefore, it is likely to be deleted or replaced with a more functional implementation in the future."
survived,"    async def test_call_reward_func_with_subset_args(self):
        """"""Test calling reward function that only uses some arguments.""""""
        def simple_func(completion, answer, **kwargs):
            return 1.0 if completion == answer else 0.0
        
        rubric = Rubric(funcs=[], weights=[])
        
        result = await rubric.call_reward_func(
            func=simple_func,
            prompt=""irrelevant"",
            completion=""same"",
            answer=""same"",
            state={},
            task=""irrelevant"",
            info={}
        )
        
        assert result == 1.0
",tests/test_rubric.py,TestRubric,1,3.850741907939403e-09,"The method 'test_call_reward_func_with_subset_args' is a unit test designed to verify the functionality of calling a reward function with a subset of arguments. It is a useful test to ensure that the 'call_reward_func' method in the 'Rubric' class can handle functions that do not use all the provided arguments. This kind of test is important for maintaining code quality and ensuring that the system behaves as expected when dealing with optional or unused parameters. Therefore, it is likely to be retained in the codebase."
survived,"    def test_format_reward_function_mixed_messages(self, think_parser):
        """"""Test format reward function with mixed good and bad messages.""""""
        reward_func = think_parser.get_format_reward_func()
        
        completion = [
            {""role"": ""assistant"", ""content"": ""<think>Good thinking</think>Good answer""},
            {""role"": ""assistant"", ""content"": ""Bad answer without thinking""},
            {""role"": ""assistant"", ""content"": ""<think>More thinking</think>Another good answer""}
        ]
        reward = reward_func(completion)
        assert reward == 2.0 / 3.0  # 2 out of 3 messages are well-formatted
",tests/test_think_parser.py,TestThinkParser,1,3.160881453314576e-10,"The method 'test_format_reward_function_mixed_messages' is a unit test that verifies the functionality of a reward function. It checks if the function correctly calculates the reward based on the formatting of messages. This is a typical and necessary part of testing in software development to ensure that the code behaves as expected. Since it serves a clear purpose in validating the logic of the reward function, it is likely to be retained in the codebase."
survived,"    def env_response(self, messages, state, **kwargs):
        """"""Simple environment response for testing.""""""
        self.env_response_count += 1
        
        if self.completion_condition == ""answer"":
            # Encourage completion after a few turns
            if self.env_response_count >= 2:
                return {""role"": ""user"", ""content"": ""Please finish with DONE""}, state
            else:
                return {""role"": ""user"", ""content"": f""Continue (turn {self.env_response_count})""}, state
        else:
            return {""role"": ""user"", ""content"": f""Environment response {self.env_response_count}""}, state
",tests/conftest.py,SimpleMultiTurnEnv,1,1.3440409770490404e-08,"The method 'env_response' is a simple function designed for testing purposes, which means it is likely used in a development or testing environment to simulate interactions. It increments a counter and returns a response based on a condition, which is a common pattern in testing scenarios. Since it serves a specific purpose in testing, it is unlikely to be deleted unless the testing framework or requirements change significantly. Therefore, it is more likely to survive."
survived,"    def test_rubric_group_initialization_empty_fails(self):
        """"""Test that RubricGroup initialization fails with empty rubrics list.""""""
        with pytest.raises(AssertionError, match=""RubricGroup must have at least one rubric""):
            RubricGroup(rubrics=[])
",tests/test_rubric_group.py,TestRubricGroup,1,9.237449576640118e-09,"The method is a unit test designed to ensure that the RubricGroup class correctly raises an AssertionError when initialized with an empty list of rubrics. This is a valid and necessary test to ensure the robustness of the RubricGroup class, as it enforces a constraint that the class should not be initialized without any rubrics. Such tests are crucial for maintaining code quality and preventing future bugs. Therefore, the method is likely to be retained."
survived,"        def analyze_large_objects():
            large_objects = []
            
            # Ëé∑ÂèñÊâÄÊúâÂØπË±°ÔºàÈôêÂà∂Êï∞ÈáèÔºâ
            all_objects = muppy.get_objects()
            if len(all_objects) > self._max_objects_to_analyze:
                import random
                all_objects = random.sample(all_objects, self._max_objects_to_analyze)
            
            for obj in all_objects:
                try:
                    # Âø´ÈÄüÁ≠õÈÄâ
                    shallow_size = sys.getsizeof(obj)
                    if shallow_size < self._large_object_threshold:
                        continue
                    
                    # Ê∑±Â∫¶ËÆ°ÁÆó
                    size = asizeof.asizeof(obj)
                    if size > self._large_object_threshold:
                        large_objects.append((obj, size))
                    
                    # ÈôêÂà∂Êï∞Èáè
                    if len(large_objects) >= 20:
                        break
                        
                except:
                    continue
            
            return large_objects
",app/helper/memory.py,MemoryHelper,1,4.0586521248284276e-10,"The method 'analyze_large_objects' is likely to survive because it provides a useful functionality for analyzing memory usage by identifying large objects in a Python application. This can be crucial for performance optimization and debugging memory issues. The method includes mechanisms to handle large datasets by sampling and limits the number of objects analyzed, which makes it efficient. Additionally, it includes error handling to ensure robustness. These factors make it a valuable tool for developers, increasing its likelihood of being retained in the codebase."
survived,"            def analyze_objects():
                sum1 = summary.summarize(all_objects)
                return sum1
",app/helper/memory.py,MemoryHelper,1,0.29421497216298875,"The method 'analyze_objects' is a simple wrapper around the 'summary.summarize' function, which suggests it might be redundant unless it adds significant value or abstraction. However, without additional context on how 'analyze_objects' is used or if it is part of a larger interface, it's difficult to definitively say it will be deleted. If the method is part of a public API or used frequently in the codebase, it might survive for consistency and ease of use. Otherwise, it could be considered for deletion to reduce unnecessary code."
survived,"def mock_url_types():
    """"""
    Mock URL types with consistent UUIDs for testing.

    Returns a mock URLTypes object that returns consistent URL type objects
    for common URL type names.
    """"""
    url_types = MagicMock(spec=URLTypes)

    # Set up URL type attributes directly
    url_types.homepage = Mock(id=uuid.UUID(""00000000-0000-0000-0000-000000000001""))
    url_types.repository = Mock(id=uuid.UUID(""00000000-0000-0000-0000-000000000002""))
    url_types.documentation = Mock(id=uuid.UUID(""00000000-0000-0000-0000-000000000003""))
    url_types.source = Mock(id=uuid.UUID(""00000000-0000-0000-0000-000000000004""))

    return url_types
",tests/conftest.py,,1,3.3982678079468468e-09,"The method `mock_url_types` is a utility function designed to create a mock object for testing purposes. It provides a consistent set of UUIDs for different URL types, which is useful in unit tests to ensure that the code behaves as expected when interacting with URL types. Such utility functions are often retained in codebases because they facilitate testing and improve code reliability. There is no indication that this function is obsolete or redundant, and it serves a clear purpose in the context of testing."
survived,"def sample_package_data():
    """"""
    Provides sample package data for testing transformers and parsers.

    Returns a dict with sample data for different package managers.
    """"""
    return {
        ""crates"": {
            ""name"": ""serde"",
            ""version"": ""1.0.130"",
            ""description"": ""A generic serialization/deserialization framework"",
            ""homepage"": ""https://serde.rs"",
            ""repository"": ""https://github.com/serde-rs/serde"",
            ""dependencies"": {
                ""serde_derive"": ""1.0.130"",
            },
        },
        ""homebrew"": {
            ""name"": ""wget"",
            ""version"": ""1.21.2"",
            ""description"": ""Internet file retriever"",
            ""homepage"": ""https://www.gnu.org/software/wget/"",
            ""dependencies"": [""gettext"", ""libidn2"", ""openssl@1.1""],
        },
        ""debian"": {
            ""package"": ""curl"",
            ""version"": ""7.74.0-1.3+deb11u1"",
            ""maintainer"": ""Alessandro Ghedini <ghedo@debian.org>"",
            ""depends"": [""libc6"", ""libcurl4"", ""zlib1g""],
        },
        ""pkgx"": {
            ""full_name"": ""gnu.org/wget"",
            ""version"": ""1.21.2"",
            ""homepage"": ""https://www.gnu.org/software/wget/"",
            ""dependencies"": {
                ""gnu.org/gettext"": ""^0.21"",
                ""openssl.org"": ""^1.1"",
            },
        },
    }
",tests/conftest.py,,1,2.1024340680345882e-07,"The method `sample_package_data` provides a useful utility function for testing purposes by returning a dictionary with sample data for different package managers. This kind of function is often used in testing environments to simulate real-world data without needing to access external resources. It is well-documented and structured, making it easy to understand and use. Such utility functions are common in development and testing frameworks, and they are unlikely to be deleted unless they become obsolete or redundant due to changes in the testing strategy or framework."
survived,"def mock_user_types():
    """"""
    Mock user types for testing.

    Returns a mock UserTypes object.
    """"""
    user_types = MagicMock(spec=UserTypes)

    # Set up user type attributes directly
    user_types.admin = Mock(id=uuid.UUID(""00000000-0000-0000-0000-000000000040""))
    user_types.maintainer = Mock(id=uuid.UUID(""00000000-0000-0000-0000-000000000041""))
    user_types.contributor = Mock(id=uuid.UUID(""00000000-0000-0000-0000-000000000042""))

    return user_types
",tests/conftest.py,,1,5.3157849718487075e-08,"The method `mock_user_types` is a utility function designed for testing purposes. It creates a mock object that simulates different user types, which is a common practice in unit testing to isolate the functionality being tested from external dependencies. Such methods are typically retained in codebases as they are essential for ensuring the reliability and correctness of the code through testing. Therefore, it is unlikely that this method will be deleted."
survived,"    def test_skip_when_load_disabled(self, mock_dedupe_config, mock_db):
        """"""
        Test that no processing occurs when load is disabled

        Expected: db.ingest should not be called
        """"""
        # Arrange
        mock_dedupe_config.load = False

        # Act
        with patch.dict(""os.environ"", {""LOAD"": ""false"", ""TEST"": ""false""}):
            main(mock_dedupe_config, mock_db)

        # Assert
        mock_db.ingest.assert_not_called()",tests/ranker/test_dedupe.py,TestDedupe,1,6.69158608681505e-10,"The method 'test_skip_when_load_disabled' is a unit test that verifies the behavior of a system when a specific configuration (load) is disabled. It ensures that the 'ingest' method on the 'mock_db' object is not called when the 'load' configuration is set to False. This is a valid and useful test case to ensure that the system behaves correctly under certain conditions. Unit tests are crucial for maintaining code quality and preventing regressions, so this method is likely to be retained in the codebase."
survived,"    def test_ssl_encryption(self, mock_smtp_ssl_class, context_manager):
        """"""Test SMTP with SSL encryption.""""""
        # Create provider with SSL config
        ssl_config = ProviderConfig(
            description=""Test SMTP Provider"",
            authentication={
                ""smtp_server"": ""smtp.example.com"",
                ""smtp_port"": 465,
                ""encryption"": ""SSL"",
                ""smtp_username"": ""test@example.com"",
                ""smtp_password"": ""testpassword"",
            },
        )
        smtp_provider = SmtpProvider(
            context_manager=context_manager,
            provider_id=""test_smtp_provider"",
            config=ssl_config,
        )

        # Setup mock SMTP_SSL instance
        mock_smtp = MagicMock()
        mock_smtp_ssl_class.return_value = mock_smtp

        # Send email
        smtp_provider._notify(
            from_email=""sender@example.com"",
            from_name=""Test Sender"",
            to_email=""recipient@example.com"",
            subject=""Test SSL"",
            html=""<p>SSL test</p>"",
        )

        # Verify SMTP_SSL was used
        mock_smtp_ssl_class.assert_called_once_with(""smtp.example.com"", 465)
        mock_smtp.login.assert_called_once_with(""test@example.com"", ""testpassword"")
        mock_smtp.sendmail.assert_called_once()
",tests/test_smtp_provider.py,TestSmtpProvider,1,1.522997951276035e-08,"The method `test_ssl_encryption` is a unit test designed to verify the functionality of an SMTP provider using SSL encryption. It uses mocking to simulate the behavior of the SMTP_SSL class and checks that the correct methods are called with the expected parameters. This is a common and necessary practice in software development to ensure that code behaves as expected, especially when dealing with external services like email servers. Since testing is a crucial part of maintaining code quality and reliability, this method is likely to be retained."
survived,"    def get_user_uuid(self) -> str:
        """"""
        Ëé∑ÂèñÁî®Êà∑uuid
        """"""
        if not self._share_user_id:
            self._share_user_id = SystemUtils.generate_user_unique_id()
            logger.info(f""ÂΩìÂâçÁî®Êà∑UUID: {self._share_user_id}"")
        return self._share_user_id or """"",app/helper/workflow.py,WorkflowHelper,1,5.211412485172657e-10,"The method 'get_user_uuid' is likely to survive because it performs a crucial function of generating and retrieving a unique user identifier (UUID). This is a common requirement in many applications for user tracking, session management, or data association. The method also includes logging, which is useful for debugging and monitoring purposes. Additionally, the method checks if the UUID is already set, which is a good practice to avoid unnecessary operations."
survived,"    def get_shares(self, name: Optional[str] = None, page: Optional[int] = 1, count: Optional[int] = 30) -> List[dict]:
        """"""
        Ëé∑ÂèñÂ∑•‰ΩúÊµÅÂàÜ‰∫´Êï∞ÊçÆ
        """"""
        if not settings.WORKFLOW_STATISTIC_SHARE:  # ‰ΩøÁî®Áã¨Á´ãÁöÑÂ∑•‰ΩúÊµÅÂàÜ‰∫´ÂºÄÂÖ≥
            return []
        
        res = RequestUtils(proxies=settings.PROXY or {}, timeout=15).get_res(self._workflow_shares, params={
            ""name"": name,
            ""page"": page,
            ""count"": count
        })
        if res and res.status_code == 200:
            return res.json()
        return []
",app/helper/workflow.py,WorkflowHelper,1,6.69158608681505e-10,"The method `get_shares` is likely to survive because it provides a specific functionality to retrieve workflow share data, which is a common requirement in applications that involve workflow management. The method is well-structured, uses optional parameters with default values, and handles HTTP requests with error checking. Additionally, it respects a configuration setting (`WORKFLOW_STATISTIC_SHARE`) to determine if the functionality should be active, indicating good practice in terms of configurability and feature toggling."
survived,"def test_top_level_start_session_with_mode(sentry_init, capture_envelopes):
    """"""Test that top-level start_session accepts session_mode parameter.""""""
    sentry_init(release=""test-release"", environment=""test-env"")
    envelopes = capture_envelopes()

    # Start a session with request mode
    sentry_sdk.start_session(session_mode=""request"")
    sentry_sdk.end_session()
    sentry_sdk.flush()

    # Request mode sessions are aggregated
    assert len(envelopes) == 1
    sess = envelopes[0]
    assert len(sess.items) == 1
    sess_event = sess.items[0].payload.json

    assert sess_event[""attrs""] == {
        ""release"": ""test-release"",
        ""environment"": ""test-env"",
    }
    # Request sessions show up as aggregates
    assert ""aggregates"" in sess_event",tests/test_sessions.py,,1,1.1032560311263802e-09,"The method is a test function that verifies the behavior of a specific feature in the Sentry SDK. It checks if the top-level start_session function correctly handles the session_mode parameter and aggregates sessions as expected. Test functions are generally crucial for ensuring code reliability and are not typically deleted unless the feature they test is removed or significantly changed. Since this test is specific to a feature (session_mode) that is likely to remain relevant, the method is expected to survive."
survived,"    async def test_delete_api_key_not_found(
        self,
        test_api_client: AsyncClient,
        mock_user_org_dep: Mock,
        mock_api_keys_service: Mock,
        mock_user_dep: Mock,
    ):
        """"""Test deleting a non-existent API key.""""""
        # Setup non-anonymous organization
        mock_user_org_dep.return_value.org_id = ""org_123""
        mock_user_org_dep.return_value.is_anonymous = False

        # Mock user authentication
        mock_user_dep.return_value = Mock(user_id=""user123"")

        # Mock key not found
        mock_api_keys_service.delete_key.return_value = False

        response = await test_api_client.delete(""/_/api/keys/nonexistent_key"")

        assert response.status_code == 404
        assert response.json() == {""detail"": ""API key not found""}
        mock_api_keys_service.delete_key.assert_called_once_with(""nonexistent_key"")
",api/api/routers/api_keys_test.py,TestDeleteAPIKey,1,7.194132978569833e-09,"The method is a well-structured test case for verifying the behavior of an API when attempting to delete a non-existent API key. It uses mocking to simulate dependencies and checks for the correct HTTP response and error message. This is a common and necessary test scenario in API development to ensure robustness and proper error handling. Therefore, it is likely to be retained as part of the test suite."
survived,"def main():
    parser = argparse.ArgumentParser(description=""Benchmark RequestRepo implementations"")
    parser.add_argument(""--python-url"", default=DEFAULT_CONFIG[""python_url""],
                        help=""URL of the Python implementation"")
    parser.add_argument(""--rust-url"", default=DEFAULT_CONFIG[""rust_url""],
                        help=""URL of the Rust implementation"")
    parser.add_argument(""--concurrency"", type=int, nargs=""+"", default=DEFAULT_CONFIG[""concurrency""],
                        help=""Concurrency levels to test"")
    parser.add_argument(""--duration"", type=int, default=DEFAULT_CONFIG[""duration""],
                        help=""Duration of each benchmark in seconds"")
    parser.add_argument(""--output"", default=""benchmark_results.json"",
                        help=""Output file for results"")
    parser.add_argument(""--config"", help=""Path to benchmark configuration file"")
    parser.add_argument(""--python-only"", action=""store_true"", help=""Only benchmark Python implementation"")
    parser.add_argument(""--rust-only"", action=""store_true"", help=""Only benchmark Rust implementation"")
    
    args = parser.parse_args()
    
    config = DEFAULT_CONFIG
    if args.config:
        with open(args.config, 'r') as f:
            config = json.load(f)
    
    config[""python_url""] = args.python_url
    config[""rust_url""] = args.rust_url
    config[""concurrency""] = args.concurrency
    config[""duration""] = args.duration
    
    if not args.rust_only and not check_server(config[""python_url""]):
        console.print(f""[bold red]Error:[/bold red] Python server not running at {config['python_url']}"")
        console.print(""Start the Python server with: make start-backend"")
        if not args.python_only:
            console.print(""Continuing with Rust benchmarks only..."")
            args.python_only = False
            args.rust_only = True
        else:
            return 1
    
    if not args.python_only and not check_server(config[""rust_url""]):
        console.print(f""[bold red]Error:[/bold red] Rust server not running at {config['rust_url']}"")
        console.print(""Start the Rust server with: cd src && cargo run --release"")
        if not args.rust_only:
            console.print(""Continuing with Python benchmarks only..."")
            args.python_only = True
            args.rust_only = False
        else:
            return 1
    
    python_results = []
    rust_results = []
    
    for endpoint in config[""endpoints""]:
        for concurrency in config[""concurrency""]:
            if not args.rust_only:
                python_result = run_benchmark(
                    name=endpoint[""name""],
                    url=config[""python_url""],
                    method=endpoint[""method""],
                    path=endpoint[""path""],
                    data=endpoint.get(""data""),
                    headers=endpoint.get(""headers"", {}),
                    concurrency=concurrency,
                    duration=config[""duration""]
                )
                python_results.append(python_result)
            
            if not args.python_only:
                rust_result = run_benchmark(
                    name=endpoint[""name""],
                    url=config[""rust_url""],
                    method=endpoint[""method""],
                    path=endpoint[""path""],
                    data=endpoint.get(""data""),
                    headers=endpoint.get(""headers"", {}),
                    concurrency=concurrency,
                    duration=config[""duration""]
                )
                rust_results.append(rust_result)
    
    print_results(python_results, rust_results)
    save_results(python_results, rust_results, args.output)
    
    return 0
",benchmarks/benchmark.py,,1,2.0611536181902033e-09,"The method is a comprehensive benchmarking script that allows users to test and compare the performance of Python and Rust implementations. It includes command-line argument parsing, configuration management, server checks, and result handling. Such functionality is valuable for performance testing and comparison, especially in environments where both Python and Rust are used. The method is well-structured and serves a clear purpose, making it unlikely to be deleted unless the entire benchmarking approach is changed or deprecated."
survived,"    def calculate_cost(
        cls,
        provider: str,
        model: str,
        token_usage_input: int,
        token_usage_output: int,
    ) -> float:
        """"""
        „Éà„Éº„ÇØ„É≥‰ΩøÁî®Èáè„Åã„ÇâÊé®ÂÆö„Ç≥„Çπ„Éà„ÇíË®àÁÆó„Åô„Çã

        Args:
            provider: LLM„Éó„É≠„Éê„Ç§„ÉÄ„ÉºÂêç
            model: „É¢„Éá„É´Âêç
            token_usage_input: ÂÖ•Âäõ„Éà„Éº„ÇØ„É≥‰ΩøÁî®Èáè
            token_usage_output: Âá∫Âäõ„Éà„Éº„ÇØ„É≥‰ΩøÁî®Èáè

        Returns:
            float: Êé®ÂÆö„Ç≥„Çπ„ÉàÔºàUSDÔºâ
        """"""
        if provider not in cls.PRICING:
            return cls._calculate_with_price(
                cls.DEFAULT_PRICE, token_usage_input, token_usage_output
            )

        if model not in cls.PRICING[provider]:
            return cls._calculate_with_price(
                cls.DEFAULT_PRICE, token_usage_input, token_usage_output
            )

        price = cls.PRICING[provider][model]
        return cls._calculate_with_price(price, token_usage_input, token_usage_output)
",server/src/services/llm_pricing.py,LLMPricing,1,1.1032560311263802e-09,"The method 'calculate_cost' is a utility function that calculates the estimated cost based on token usage and pricing information. It is a useful method for applications that need to estimate costs for different providers and models, especially in contexts involving language models or APIs with token-based pricing. The method is well-documented, handles cases where pricing information might be missing, and provides a default pricing mechanism. These characteristics make it a valuable part of a codebase dealing with cost estimation, suggesting it is likely to be retained."
survived,"    async def get_nft_sales(self, parameters: dict) -> list:
        """"""Get recent NFT sales for a collection from OpenSea""""""
        async with aiohttp.ClientSession() as session:
            url = f""{self.base_url}/events/collection/{parameters['collectionSlug']}?event_type=sale&limit=5""
            headers = {
                ""accept"": ""application/json"",
                ""x-api-key"": self.api_key
            }
            async with session.get(url, headers=headers) as response:
                if not response.ok:
                    raise Exception(f""Failed to get NFT sales: HTTP {response.status} - {await response.text()}"")
                data = await response.json()
                sales_response = NftSalesResponse.model_validate(data)
                
                # Transform the response to match TypeScript implementation
                return [{
                    ""name"": event.nft.name,
                    ""seller"": event.seller,
                    ""buyer"": event.buyer,
                    ""price"": float(event.payment.quantity) / 10 ** event.payment.decimals
                } for event in sales_response.asset_events]",python/src/plugins/opensea/goat_plugins/opensea/service.py,OpenSeaService,1,4.363462233903899e-09,"The method 'get_nft_sales' is likely to survive because it provides a useful functionality of fetching recent NFT sales data from OpenSea, which is a popular platform for NFTs. The method is well-structured, uses asynchronous programming for efficiency, and includes error handling for failed requests. Additionally, it transforms the data into a format that is likely useful for further processing or display, indicating its practical utility."
survived,"def allora(options: AlloraPluginOptions) -> AlloraPlugin:
    return AlloraPlugin(options)",python/src/plugins/allora/goat_plugins/allora/__init__.py,,1,1.8189616842444243e-09,"The method 'allora' is a simple factory function that takes an 'AlloraPluginOptions' object and returns an 'AlloraPlugin' object. This pattern is common and useful for encapsulating the creation logic of objects, making the code more modular and easier to maintain. Unless there is a significant change in the design or requirements of the system that makes this function redundant or obsolete, it is likely to be retained. Therefore, the method will survive."
survived,"    def __init__(self, options: AlloraPluginOptions):
        super().__init__(""allora"", [AlloraService(options.api_key, options.api_root)])
",python/src/plugins/allora/goat_plugins/allora/__init__.py,AlloraPlugin,1,5.043472052266442e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes or dependencies. In this case, it initializes the class with a name and a list containing an instance of AlloraService, which is likely necessary for the class's functionality. Therefore, it is unlikely to be deleted."
survived,"    def __init__(self, api_key: Optional[str] = None, api_root: str = ""https://api.upshot.xyz/v2/allora""):
        self.api_key = api_key
        self.api_root = api_root.rstrip('/')  # Remove trailing slash if present
",python/src/plugins/allora/goat_plugins/allora/service.py,AlloraService,1,1.725782769012759e-08,"The method is a constructor for a class, initializing important attributes like 'api_key' and 'api_root'. It includes a default value for 'api_root' and handles potential issues with trailing slashes. This is a standard and necessary part of class design in Python, ensuring that instances are properly set up with the required parameters. There is no indication that this method is redundant or unnecessary, so it is likely to be retained."
survived,"def dexscreener(options: DexscreenerPluginOptions) -> DexscreenerPlugin:
    return DexscreenerPlugin(options)",python/src/plugins/dexscreener/goat_plugins/dexscreener/__init__.py,,1,4.944450477491054e-09,"The method 'dexscreener' is a simple factory function that creates and returns an instance of 'DexscreenerPlugin' using the provided 'options'. This is a common pattern in programming to encapsulate object creation and ensure that the object is initialized with the necessary parameters. There is no indication that this method is redundant or unnecessary, as it serves a clear purpose in the codebase. Therefore, it is likely to be retained."
survived,"    def __init__(self, options: NansenPluginOptions):
        super().__init__(""nansen"", [NansenService(options.api_key)])
",python/src/plugins/nansen/goat_plugins/nansen/__init__.py,NansenPlugin,1,7.73442280641062e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting up initial states. This particular constructor is initializing a superclass and setting up a service with an API key, which suggests it's part of a larger framework or application. Such methods are typically not deleted unless the entire class or its purpose is being refactored or removed, which is not indicated here."
survived,"def rugcheck(options: RugCheckPluginOptions) -> RugCheckPlugin:
    return RugCheckPlugin(options)",python/src/plugins/rugcheck/goat_plugins/rugcheck/__init__.py,,1,5.211412485172657e-10,"The method 'rugcheck' is a simple factory function that takes an instance of 'RugCheckPluginOptions' and returns a new instance of 'RugCheckPlugin' initialized with those options. This pattern is common and useful for encapsulating object creation logic, making the code more modular and easier to maintain. Unless there is a significant change in the design or requirements that makes this function redundant, it is likely to be retained. Therefore, the method will survive."
survived,"    def supports_chain(self, chain) -> bool:
        return True
",python/src/plugins/rugcheck/goat_plugins/rugcheck/__init__.py,RugCheckPlugin,1,2.998960815863541e-09,"The method `supports_chain` is a simple implementation that always returns `True`, indicating that it supports any chain passed to it. This method is likely to be a placeholder or a default implementation in a larger system where chain support is assumed to be universal. Since it is a straightforward method with no complex logic or dependencies, it is unlikely to be deleted unless the entire feature it supports is removed or significantly refactored. Therefore, it is more likely to survive."
survived,"    def _get_current_connector_version(self, connector: Connector) -> semver.Version:
        """"""Get the current version.""""""
        return semver.Version.parse(str(connector.metadata[""dockerImageTag""]))
",airbyte-ci/connectors/connectors_qa/src/connectors_qa/checks/version.py,VersionCheck,1,1.3440409770490404e-08,"The method '_get_current_connector_version' is a utility function that retrieves the current version of a connector by parsing the 'dockerImageTag' from the connector's metadata. This is a common requirement in software systems that manage versions, especially in environments where connectors or plugins are frequently updated. The method is straightforward, performs a specific task, and is likely to be used in various parts of the codebase where version information is needed. Therefore, it is unlikely to be deleted unless there is a significant change in how versions are managed or retrieved."
survived,"    def _should_run(self, connector: Connector) -> bool:
        """"""Determine if the check should run based on modified files.""""""
        if connector.metadata and connector.metadata.get(""ab_internal"", {}).get(""requireVersionIncrementsInPullRequests"") is False:
            return False
        
        return True
",airbyte-ci/connectors/connectors_qa/src/connectors_qa/checks/version.py,VersionIncrementCheck,1,3.3982678079468468e-09,"The method '_should_run' is a private method (indicated by the underscore prefix) that checks a specific condition related to the 'connector' object. It is likely part of a larger class or module that deals with version control or pull request management. The method is simple, clear, and serves a specific purpose by checking metadata conditions. Such utility methods are often retained as they encapsulate logic that might be reused or modified in the future. Therefore, it is likely to survive."
deleted,"    def test_is_version_not_incremented(self, version_increment_check):
        assert version_increment_check._is_version_not_incremented(
            semver.Version.parse(""1.0.0""),
            semver.Version.parse(""0.9.0"")
        )
        
        assert version_increment_check._is_version_not_incremented(
            semver.Version.parse(""1.0.0""),
            semver.Version.parse(""1.0.0"")
        )
        
        assert not version_increment_check._is_version_not_incremented(
            semver.Version.parse(""0.9.0""),
            semver.Version.parse(""1.0.0"")
        )
",airbyte-ci/connectors/connectors_qa/tests/checks/test_version.py,TestVersionIncrementCheck,1,7.73442280641062e-08,"The method 'test_is_version_not_incremented' is a unit test that checks the functionality of the '_is_version_not_incremented' method from the 'version_increment_check' object. It verifies that the method correctly identifies when a version has not been incremented. This is a typical and necessary test to ensure the reliability of version comparison logic, especially in software development where versioning is crucial. Therefore, this method is likely to be retained as it serves an important role in validating the behavior of the version checking logic."
survived,"    def _run(self, connector: Connector) -> CheckResult:
        """"""Run the version increment check.""""""
        if not self._should_run(connector):
            return self.skip(
                connector,
                ""No modified files required a version bump or connector opts out of version checks.""
            )
        
        try:
            master_version = self._get_master_connector_version(connector)
            current_version = self._get_current_connector_version(connector)
            
            if self._is_version_not_incremented(master_version, current_version):
                return self.fail(
                    connector,
                    f""The dockerImageTag in {METADATA_FILE_NAME} was not incremented. ""
                    f""Master version is {master_version}, current version is {current_version}""
                )
            
            if self._are_both_versions_release_candidates(master_version, current_version):
                if not self._have_same_major_minor_patch(master_version, current_version):
                    return self.fail(
                        connector,
                        f""Master and current version are release candidates but they have different major, minor or patch versions. ""
                        f""Release candidates should only differ in the prerelease part. Master version is {master_version}, ""
                        f""current version is {current_version}""
                    )
            
            return self.pass_(
                connector,
                f""Version was properly incremented from {master_version} to {current_version}.""
            )
        except (requests.HTTPError, ValueError, TypeError) as e:
            return self.fail(connector, str(e))
",airbyte-ci/connectors/connectors_qa/src/connectors_qa/checks/version.py,VersionIncrementCheck,1,3.3982678079468468e-09,"The method '_run' is a crucial part of a version control system, ensuring that version increments are properly checked and validated. It handles various scenarios such as skipping checks, failing due to version mismatches, and passing when versions are correctly incremented. Additionally, it includes error handling for common exceptions. These functionalities are essential for maintaining the integrity of version control processes, making it unlikely for this method to be deleted."
survived,"async def test_quick_reconnection(setup_ycell):
    """"""Test that quick reconnection properly handles cleanup task cancellation""""""
    # Setup
    cell_id = CellId_t(""test_cell"")
    file_key = MarimoFileKey(""test_file"")
    key = CellIdAndFileKey(cell_id, file_key)
    
    # Create initial ycell
    ydoc = Doc[Text]()
    ycell = YCell(ydoc=ydoc, clients=1)
    ycells[key] = ycell
    
    # Start cleanup task
    cleanup_task = asyncio.create_task(clean_cell(key))
    
    # Simulate quick reconnection by creating a new client before cleanup finishes
    ycells[key].clients += 1
    
    # Cancel cleanup task (simulating what happens in ycell_provider)
    cleanup_task.cancel()
    try:
        await cleanup_task
    except asyncio.CancelledError:
        pass
    
    # Verify state
    assert len(ycells) == 1
    assert ycells[key].clients == 2  # Original client + reconnected client",marimo/_server/api/endpoints/tests/test_ws_rtc.py,,1,6.348800075736417e-09,"The method is a test function that verifies the behavior of a system under specific conditions. Test functions are generally crucial for ensuring the reliability and correctness of code, especially in asynchronous environments where timing and state management are critical. This function tests the handling of quick reconnections and cleanup task cancellations, which are important for maintaining system stability. Therefore, it is likely to be retained as part of the test suite to ensure ongoing system integrity."
survived,"def main():
    # Set up argument parser
    parser = argparse.ArgumentParser(description=""Polars CSV Agent using OpenAI API"")
    parser.add_argument(
        ""-i"", ""--input"", required=True, help=""Path to input CSV file""
    )
    parser.add_argument(""-p"", ""--prompt"", required=True, help=""The user's request"")
    parser.add_argument(
        ""-c"",
        ""--compute"",
        type=int,
        default=10,
        help=""Maximum number of agent loops (default: 10)"",
    )
    args = parser.parse_args()

    # Configure the API key
    OPENAI_API_KEY = os.getenv(""OPENAI_API_KEY"")
    if not OPENAI_API_KEY:
        console.print(
            ""[red]Error: OPENAI_API_KEY environment variable is not set[/red]""
        )
        console.print(
            ""Please get your API key from https://platform.openai.com/api-keys""
        )
        console.print(""Then set it with: export OPENAI_API_KEY='your-api-key-here'"")
        sys.exit(1)

    openai.api_key = OPENAI_API_KEY

    # Create a single combined prompt based on the full template
    completed_prompt = AGENT_PROMPT.replace(""{{user_request}}"", args.prompt).replace(""{{csv_file_path}}"", args.input)
    # Initialize messages with proper typing for OpenAI chat
    messages: List[dict] = [{""role"": ""user"", ""content"": completed_prompt}]

    compute_iterations = 0

    # Main agent loop
    while True:
        console.rule(
            f""[yellow]Agent Loop {compute_iterations+1}/{args.compute}[/yellow]""
        )
        compute_iterations += 1

        if compute_iterations >= args.compute:
            console.print(
                ""[yellow]Warning: Reached maximum compute loops without final code[/yellow]""
            )
            console.print(""[yellow]Please try adjusting your prompt or increasing the compute limit.[/yellow]"")
            raise Exception(
                f""Maximum compute loops reached: {compute_iterations}/{args.compute}""
            )

        try:
            # Generate content with tool support
            response = openai.chat.completions.create(
                model=""o3-mini"",
                messages=messages,
                tools=tools,
                tool_choice=""required"",
            )

            if response.choices:
                assert len(response.choices) == 1
                message = response.choices[0].message

                if message.function_call:
                    func_call = message.function_call
                elif message.tool_calls and len(message.tool_calls) > 0:
                    tool_call = message.tool_calls[0]
                    func_call = tool_call.function
                else:
                    func_call = None

                if func_call:
                    func_name = func_call.name
                    func_args_str = func_call.arguments

                    messages.append(
                        {
                            ""role"": ""assistant"",
                            ""content"": None,
                            ""tool_calls"": [
                                {
                                    ""id"": tool_call.id,
                                    ""type"": ""function"",
                                    ""function"": func_call,
                                }
                            ],
                        }
                    )

                    console.print(
                        f""[blue]Function Call:[/blue] {func_name}({func_args_str})""
                    )
                    try:
                        # Validate and parse arguments using the corresponding pydantic model
                        if func_name == ""ListColumnsArgs"":
                            args_parsed = ListColumnsArgs.model_validate_json(
                                func_args_str
                            )
                            result = list_columns(
                                reasoning=args_parsed.reasoning,
                                csv_path=args_parsed.csv_path
                            )
                        elif func_name == ""SampleCSVArgs"":
                            args_parsed = SampleCSVArgs.model_validate_json(
                                func_args_str
                            )
                            result = sample_csv(
                                reasoning=args_parsed.reasoning,
                                csv_path=args_parsed.csv_path,
                                row_count=args_parsed.row_count,
                            )
                        elif func_name == ""RunTestPolarsCodeArgs"":
                            args_parsed = RunTestPolarsCodeArgs.model_validate_json(
                                func_args_str
                            )
                            result = run_test_polars_code(
                                reasoning=args_parsed.reasoning,
                                polars_python_code=args_parsed.polars_python_code,
                                csv_path=args_parsed.csv_path,
                            )
                        elif func_name == ""RunFinalPolarsCodeArgs"":
                            args_parsed = RunFinalPolarsCodeArgs.model_validate_json(
                                func_args_str
                            )
                            result = run_final_polars_code(
                                reasoning=args_parsed.reasoning,
                                csv_path=args_parsed.csv_path,
                                polars_python_code=args_parsed.polars_python_code,
                                output_file=args_parsed.output_file,
                            )
                            console.print(""\n[green]Final Results:[/green]"")
                            console.print(result)
                            return
                        else:
                            raise Exception(f""Unknown tool call: {func_name}"")

                        console.print(
                            f""[blue]Function Call Result:[/blue] {func_name}(...) ->\n{result}""
                        )

                        # Append the function call result into our messages as a tool response
                        messages.append(
                            {
                                ""role"": ""tool"",
                                ""tool_call_id"": tool_call.id,
                                ""content"": json.dumps({""result"": str(result)}),
                            }
                        )

                    except Exception as e:
                        error_msg = f""Argument validation failed for {func_name}: {e}""
                        console.print(f""[red]{error_msg}[/red]"")
                        messages.append(
                            {
                                ""role"": ""tool"",
                                ""tool_call_id"": tool_call.id,
                                ""content"": json.dumps({""error"": error_msg}),
                            }
                        )
                        continue
                else:
                    raise Exception(
                        ""No function call in this response - should never happen""
                    )

        except Exception as e:
            console.print(f""[red]Error in agent loop: {str(e)}[/red]"")
            raise e
",sfa_polars_csv_agent_openai_v2.py,,1,2.699578619062706e-07,"The method is a comprehensive implementation of an agent that interacts with the OpenAI API to process CSV files based on user prompts. It includes error handling, argument parsing, and a loop to manage multiple interactions. The method is well-structured and serves a specific purpose, making it unlikely to be deleted unless the entire functionality is deprecated or replaced by a more efficient solution. Given the current trend towards automation and AI integration, such methods are more likely to be maintained or evolved rather than removed."
survived,"    def _completion_into(self, response: Dict[str, Any], input_tokens: int = 0) -> common.Completion:
        content_blocks = []
        
        message = response.get(""message"", {})
        content = message.get(""content"", """")
        
        if content:
            content_blocks.append(common.TextRaw(content))
        
        tool_calls = message.get(""tool_calls"", [])
        for tool_call in tool_calls:
            if tool_call.get(""type"") == ""function"":
                func = tool_call.get(""function"", {})
                content_blocks.append(common.ToolUse(
                    name=func.get(""name"", """"),
                    input=func.get(""arguments"", {}),
                    id=tool_call.get(""id"")
                ))
        
        output_tokens = response.get(""eval_count"", 0)
        prompt_tokens = response.get(""prompt_eval_count"", input_tokens)
        
        return common.Completion(
            role=""assistant"",
            content=content_blocks,
            input_tokens=prompt_tokens,
            output_tokens=output_tokens,
            stop_reason=""end_turn""
        )
",agent/llm/ollama_client.py,OllamaLLM,1,1.4166087846364157e-09,"The method '_completion_into' is a utility function that processes a response dictionary to extract and format content into a 'Completion' object. It handles different parts of the response, such as message content and tool calls, and constructs a structured output. This kind of method is typically useful in applications that involve processing and formatting data, such as chatbots or AI assistants. Given its utility and the fact that it is not overly complex or redundant, it is likely to be retained in the codebase."
survived,"def decode_landm(pre, priors, variances):
    landms = np.concatenate(
        (
            priors[:, :2] + pre[:, :2] * variances[0] * priors[:, 2:],
            priors[:, :2] + pre[:, 2:4] * variances[0] * priors[:, 2:],
            priors[:, :2] + pre[:, 4:6] * variances[0] * priors[:, 2:],
            priors[:, :2] + pre[:, 6:8] * variances[0] * priors[:, 2:],
            priors[:, :2] + pre[:, 8:10] * variances[0] * priors[:, 2:],
        ),
        axis=1,
    )
    return landms
",face_recognition/6d_repnet_360/utils_6d_repnet_360/functions.py,,1,3.850741907939403e-09,"The method 'decode_landm' is a utility function that decodes landmark predictions using prior boxes and variances. This type of function is commonly used in object detection and facial landmark detection models to transform predictions into actual coordinates. Given its utility in these contexts, it is likely to be retained in the codebase as it serves a specific purpose in processing model outputs. There is no indication that it is obsolete or redundant, and it appears to be correctly implemented."
survived,"    def __init__(self, cfg, image_size=None, phase=""train""):
        super(PriorBox, self).__init__()
        self.min_sizes = cfg[""min_sizes""]
        self.steps = cfg[""steps""]
        self.clip = cfg[""clip""]
        self.image_size = image_size
        self.feature_maps = [
            [ceil(self.image_size[0] / step), ceil(self.image_size[1] / step)]
            for step in self.steps
        ]
        self.name = ""s""
",face_recognition/6d_repnet_360/utils_6d_repnet_360/functions.py,PriorBox,1,3.3982678079468468e-09,"The method is a constructor for a class, likely part of a larger codebase dealing with image processing or computer vision tasks. It initializes important attributes such as `min_sizes`, `steps`, `clip`, and `feature_maps`, which are essential for the functionality of the class. Constructors are fundamental to class definitions and are rarely deleted unless the entire class is being refactored or removed. Therefore, it is likely to survive."
survived,"    def sync_no_stream():
        groq_client.chat.completions.create(
            model=""llama3-70b-8192"",
            messages=[
                {""role"": ""user"", ""content"": ""Hello from sync no stream""},
            ],
            session=session
        )
",tests/core_manual_tests/providers/groq_canary.py,,1,7.194132978569833e-09,"The method 'sync_no_stream' is a simple function that calls an API to create a chat completion. It uses a specific model and sends a message. The method is straightforward and does not contain any deprecated or problematic code patterns. It is likely to be useful for synchronous API calls without streaming, which is a common requirement. Therefore, it is likely to survive."
deleted,"                async def __anext__(self):
                    if self.stream is None:
                        # Get the stream from the original method - it's already an async generator
                        response = original_method(self_client, *args, **kwargs_copy)
                        self.stream = aiter(response)

                    try:
                        # Get the next chunk
                        chunk = await anext(self.stream)
                        # Handle the chunk and track events
                        self.provider.handle_stream_chunk(chunk, self.session, self.llm_event, self.kwargs)
                        return chunk
                    except StopAsyncIteration:
                        # Record the LLM event when the stream completes
                        if self.session is not None:
                            self.llm_event.end_timestamp = get_ISO_time()
                            if not isinstance(self.llm_event.completion, dict):
                                self.llm_event.completion = {
                                    ""role"": ""assistant"",
                                    ""content"": self.llm_event.completion if isinstance(self.llm_event.completion, str) else """"
                                }
                            logger.info(f""Stream completed. Recording LLM event with completion: {self.llm_event.completion}"")
                            self.provider._safe_record(self.session, self.llm_event)
                            logger.info(""Successfully recorded async stream LLM event"")
                        raise
                    except Exception as e:
                        print(f""Error in AsyncStreamWrapper: {str(e)}"")
                        if not isinstance(self.llm_event, str):
                            self.provider._safe_record(self.session, ErrorEvent(trigger_event=self.llm_event, exception=e))
                        raise
",agentops/llms/providers/cohere.py,CohereProvider.AsyncStreamWrapper,1,5.3157849718487075e-08,"The method is an implementation of the asynchronous iterator protocol, specifically the __anext__ method, which is essential for asynchronous iteration in Python. It handles streaming data, processes each chunk, and manages exceptions and completion events. This functionality is crucial for applications that rely on asynchronous data processing, such as handling real-time data streams or integrating with asynchronous APIs. Given its importance in managing asynchronous operations and error handling, it is unlikely to be deleted."
survived,"    async def async_stream():
        async_stream_response = await litellm.acompletion(
            model=""gpt-3.5-turbo"",
            messages=[{""content"": ""Hello from async streaming"", ""role"": ""user""}],
            stream=True,
            session=session
        )
        # Handle streaming response
        if isinstance(async_stream_response, str):
            _ = async_stream_response
        else:
            async for chunk in async_stream_response:
                _ = chunk.choices[0].delta.content if hasattr(chunk.choices[0].delta, 'content') else ''
",tests/core_manual_tests/providers/litellm_canary.py,,1,3.850741907939403e-09,"The method 'async_stream' is likely to survive because it demonstrates a modern and efficient approach to handling asynchronous operations, which is increasingly important in contemporary software development. The use of async/await syntax is a standard practice in Python for non-blocking I/O operations, and the method is designed to handle streaming responses from an API, which is a common requirement in many applications today. Additionally, the method includes error handling for different types of responses, indicating robustness."
survived,"def test_ai21_integration():
    """"""Integration test demonstrating all four AI21 call patterns:
    1. Sync (non-streaming)
    2. Sync (streaming)
    3. Async (non-streaming)
    4. Async (streaming)

    Verifies that AgentOps correctly tracks all LLM calls via analytics.
    """"""
    # Initialize AgentOps without auto-starting session
    agentops.init(auto_start_session=False)
    session = agentops.start_session()

    api_key = os.getenv(""AI21_API_KEY"")
    # Initialize provider
    from agentops.llms.providers.ai21 import AI21Provider
    provider = AI21Provider(None)  # AI21 doesn't need a client instance
    provider.override()
    
    # Pass session to provider
    provider.client = session
    ai21_client = ai21.AI21Client(api_key=api_key)
    async_ai21_client = ai21.AsyncAI21Client(api_key=api_key)
    chat_client = ChatCompletions(client=ai21_client)
    async_chat_client = AsyncChatCompletions(client=async_ai21_client)

    # Create message objects
    base_messages = [
        ChatMessage(role=""system"", content=""You are a helpful AI assistant""),
        ChatMessage(role=""user"", content=""Hello from the test suite"")
    ]
    sync_messages = base_messages.copy()
    sync_stream_messages = base_messages.copy()
    async_messages = base_messages.copy()
    async_stream_messages = base_messages.copy()

    def sync_no_stream():
        chat_client.create(
            model=""jamba-instruct"",
            system=""You are a helpful AI assistant"",
            messages=sync_messages,
            maxTokens=10
        )

    def sync_stream():
        stream_response = chat_client.create(
            model=""jamba-instruct"",
            system=""You are a helpful AI assistant"",
            messages=sync_stream_messages,
            maxTokens=10,
            stream=True
        )
        for chunk in stream_response:
            _ = chunk.choices[0].delta.content if hasattr(chunk.choices[0].delta, 'content') else ''

    async def async_no_stream():
        await async_chat_client.create(
            model=""jamba-instruct"",
            system=""You are a helpful AI assistant"",
            messages=async_messages,
            maxTokens=10
        )

    async def async_stream():
        async_stream_response = await async_chat_client.create(
            model=""jamba-instruct"",
            system=""You are a helpful AI assistant"",
            messages=async_stream_messages,
            maxTokens=10,
            stream=True
        )
        async for chunk in async_stream_response:
            _ = chunk.choices[0].delta.content if hasattr(chunk.choices[0].delta, 'content') else ''

    async def run_async_tests():
        await async_no_stream()
        await async_stream()

    # Call each function with proper error handling
    try:
        sync_no_stream()
        sync_stream()
        asyncio.run(run_async_tests())
    except Exception as e:
        print(f""Error during AI21 test: {str(e)}"")
        raise
    finally:
        session.end_session(""Success"")
        analytics = session.get_analytics()
        print(f""Analytics: {analytics}"")
        assert analytics[""LLM calls""] >= 4, f""Expected at least 4 LLM calls, but got {analytics['LLM calls']}""
",tests/core_manual_tests/providers/ai21_canary.py,,1,1.3440409770490404e-08,"The method `test_ai21_integration` is a comprehensive integration test that covers multiple scenarios for AI21 API calls, including both synchronous and asynchronous, as well as streaming and non-streaming. It is well-structured, includes error handling, and verifies the expected behavior through assertions. Such tests are crucial for ensuring the reliability and correctness of integrations with external services, especially in production environments. Therefore, it is likely to be retained in the codebase."
survived,"def git_list_files(reasoning: str, directory: str = os.getcwd(), globs: List[str] = [], extensions: List[str] = []) -> List[str]:
    """"""Returns a list of files in the repository, respecting gitignore.

    Args:
        reasoning: Explanation of why we're listing files
        directory: Directory to search in (defaults to current working directory)
        globs: List of glob patterns to filter files (optional)
        extensions: List of file extensions to filter files (optional)

    Returns:
        List of file paths as strings
    """"""
    try:
        console.log(f""[blue]Git List Files Tool[/blue] - Reasoning: {reasoning}"")
        console.log(f""[dim]Directory: {directory}, Globs: {globs}, Extensions: {extensions}[/dim]"")
        
        # Change to the specified directory
        original_dir = os.getcwd()
        os.chdir(directory)
        
        # Get all files tracked by git
        result = subprocess.run(
            ""git ls-files"",
            shell=True,
            text=True,
            capture_output=True,
        )
        
        files = result.stdout.strip().split(""\n"")
        
        # Filter by globs if provided
        if globs:
            filtered_files = []
            for pattern in globs:
                for file in files:
                    if fnmatch.fnmatch(file, pattern):
                        filtered_files.append(file)
            files = filtered_files
        
        # Filter by extensions if provided
        if extensions:
            files = [file for file in files if any(file.endswith(f"".{ext}"") for ext in extensions)]
        
        # Change back to the original directory
        os.chdir(original_dir)
        
        # Convert to absolute paths
        files = [os.path.join(directory, file) for file in files]
        
        console.log(f""[dim]Found {len(files)} files[/dim]"")
        return files
    except Exception as e:
        console.log(f""[red]Error listing files: {str(e)}[/red]"")
        return []
",sfa_codebase_context_agent_v3.py,,1,2.8453347280241004e-08,"The method 'git_list_files' is a utility function that provides a useful feature for listing files in a git repository while respecting the .gitignore file. It includes options to filter files by glob patterns and extensions, which adds flexibility and utility. The method is well-documented, handles exceptions, and logs its operations, making it robust and user-friendly. These characteristics make it a valuable tool in a development environment, increasing the likelihood of its survival."
survived,"def add_relevant_files(reasoning: str, file_paths: List[str]) -> str:
    """"""Adds files to the list of relevant files.
    
    Args:
        reasoning: Explanation of why we're adding these files
        file_paths: List of file paths to add
        
    Returns:
        String indicating success
    """"""
    try:
        console.log(f""[blue]Add Relevant Files Tool[/blue] - Reasoning: {reasoning}"")
        console.log(f""[dim]Adding {len(file_paths)} files to relevant files list[/dim]"")
        
        global RELEVANT_FILES
        for file_path in file_paths:
            if file_path not in RELEVANT_FILES:
                RELEVANT_FILES.append(file_path)
        
        console.log(f""[green]Added {len(file_paths)} files. Total relevant files: {len(RELEVANT_FILES)}[/green]"")
        return ""Files Added""
    except Exception as e:
        console.log(f""[red]Error adding relevant files: {str(e)}[/red]"")
        return f""Error: {str(e)}""
",sfa_codebase_context_agent_v3.py,,1,1.1032560311263802e-09,"The method 'add_relevant_files' is well-defined and serves a clear purpose in managing a list of relevant files. It includes logging for tracking the process, handles exceptions, and provides feedback on the operation's success. These characteristics make it a useful utility function in a codebase, suggesting it is likely to be retained."
survived,"    async def get_quote(self, wallet_client: SolanaWalletClient, parameters: dict) -> QuoteResponse:
        """"""Get a quote for swapping tokens using Jupiter.""""""
        try:
            params = GetQuoteParameters.parse_obj(parameters)
            # Convert parameters to dict and ensure required fields are properly formatted
            request_params = {
                'inputMint': params.inputMint,
                'outputMint': params.outputMint,
                'amount': str(params.amount),
                'swapMode': params.swapMode.value
            }
            # Add optional parameters if they are set
            if params.slippageBps is not None:
                request_params['slippageBps'] = params.slippageBps
            print(f""Requesting quote with parameters: {request_params}"")
            async with aiohttp.ClientSession(**self._session_kwargs) as session:
                async with session.get(f""{self.base_url}/quote"", params=request_params) as response:
                    response_text = await response.text()
                    print(f""Got response: {response_text}"")
                    
                    if response.status != 200:
                        try:
                            error_data = await response.json()
                            raise Exception(f""Failed to get quote: {error_data.get('error', 'Unknown error')}"")
                        except:
                            raise Exception(f""Failed to get quote: {response_text}"")
                    
                    response_data = await response.json()
                    return QuoteResponse.parse_obj(response_data)
        except aiohttp.ClientResponseError as error:
            error_message = f""Failed to get quote: {str(error)}""
            if error.status != 404:  # Only try to parse response for non-404 errors
                try:
                    error_data = await error.response.json()
                    error_message = f""Failed to get quote: {error_data.get('error', str(error))}""
                except:
                    pass
            raise Exception(error_message)
        except Exception as error:
            raise Exception(f""Failed to get quote: {str(error)}"")
",python/src/plugins/jupiter/goat_plugins/jupiter/service.py,JupiterService,1,9.237449576640118e-09,"The method is well-structured and handles various scenarios, including parsing parameters, making an HTTP request, and handling errors. It uses async/await for non-blocking I/O operations, which is suitable for network requests. The method is likely part of a larger system for interacting with a cryptocurrency wallet or exchange, which is a common use case in modern applications. Given its functionality and the increasing relevance of cryptocurrency-related operations, it is likely to be maintained and used in the future."
survived,"    def __init__(self, api_key: str, network: SolanaNetwork = ""mainnet"", tokens=SPL_TOKENS):
        self.api_key = api_key
        self.network = network
        self.tokens = tokens
",python/src/plugins/spl_token/goat_plugins/spl_token/service.py,SplTokenService,1,2.699578619062706e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes, such as 'api_key', 'network', and 'tokens' in this case. The presence of default values for 'network' and 'tokens' also suggests that this method is designed to provide flexibility and ease of use when creating instances of the class. Given its role in setting up the initial state of an object, it is unlikely to be deleted unless the entire class is being refactored or removed, which is not indicated here."
survived,"def _find_json_loaders(data: Any, path: List[str]) -> List[JsonLoaderNode]:  # noqa: ANN401
    logger = main_logger
    loaders: List[JsonLoaderNode] = []
    if isinstance(data, dict):
        if ""type"" in data and data[""type""] == ""JsonFileSchemaLoader"":
            ref = f""#/{'/'.join(path)}""
            if ""file_path"" in data:
                loaders.append(JsonLoaderNode(ref, data[""file_path""]))
            else:
                logger.info(f""    !! JsonFileSchemaLoader missing file_path: {ref}"")
        else:
            for key, value in data.items():
                loaders += _find_json_loaders(value, path + [key])
    elif isinstance(data, list):
        for i, value in enumerate(data):
            loaders += _find_json_loaders(value, path + [f""Array[{str(i)}]""])
    return loaders
",airbyte-ci/connectors/pipelines/pipelines/airbyte_ci/connectors/migrate_to_inline_schemas/pipeline.py,,1,7.582560422162384e-10,"The method `_find_json_loaders` is a utility function that recursively searches through a nested data structure (which can be a combination of dictionaries and lists) to find and collect instances of a specific type of loader, `JsonFileSchemaLoader`. This function is useful for extracting specific information from complex JSON-like structures, which is a common requirement in data processing and configuration management. The method is well-defined, performs a clear and useful task, and does not have any apparent issues or redundancies that would warrant its removal. Therefore, it is likely to be retained in the codebase."
survived,"    async def _run(self) -> StepResult:
        connector = self.context.connector
        manifest_path = connector.manifest_path
        python_path = connector.python_source_dir_path
        if connector.language not in [
            ConnectorLanguage.PYTHON,
            ConnectorLanguage.LOW_CODE,
            ConnectorLanguage.MANIFEST_ONLY,
        ]:
            return StepResult(
                step=self,
                status=StepStatus.SKIPPED,
                stderr=""The connector is not a Python connector."",
            )
        if connector.connector_type != ""source"":
            return StepResult(
                step=self,
                status=StepStatus.SKIPPED,
                stderr=""The connector is not a source connector."",
            )

        if not manifest_path.is_file():
            return StepResult(
                step=self,
                status=StepStatus.SKIPPED,
                stderr=""The connector does not have a manifest file."",
            )

        schemas_dir = python_path / SCHEMAS_DIR_NAME
        if not schemas_dir.is_dir():
            return StepResult(
                step=self,
                status=StepStatus.SKIPPED,
                stderr=""The connector does not have a schemas directory."",
            )

        # TODO: does this help or not?
        # if _has_subdirectory(schemas_dir):
        #     return StepResult(step=self, status=StepStatus.SKIPPED, stderr=""This has subdirectories. It's probably complicated."")

        return StepResult(
            step=self,
            status=StepStatus.SUCCESS,
        )
",airbyte-ci/connectors/pipelines/pipelines/airbyte_ci/connectors/migrate_to_inline_schemas/pipeline.py,CheckIsInlineCandidate,1,1.0467401685178159e-08,"The method '_run' is well-structured and performs a series of checks to ensure that the connector meets specific criteria before proceeding. It checks the language, type, and existence of necessary files and directories, which are essential for the correct functioning of the connector. The method also handles different scenarios by returning appropriate statuses and error messages. The presence of a TODO comment suggests that there is consideration for future improvements, indicating ongoing maintenance and relevance. Therefore, the method is likely to be retained as it serves a clear purpose and is part of a larger system that requires these checks."
survived,"    def test_multiple_human_input_rounds(self, mock_input):
        """"""Test multiple rounds of human input with Flow status management.""""""
        from crewai.agents.agent_builder.base_agent_executor_mixin import CrewAgentExecutorMixin
        
        executor = CrewAgentExecutorMixin()
        executor.crew = MagicMock()
        executor.crew._train = False
        executor._printer = MagicMock()
        
        formatter = event_listener.formatter
        
        original_paused_state = formatter._live_paused
        
        try:
            pause_calls = []
            resume_calls = []
            
            def track_pause():
                pause_calls.append(True)
                
            def track_resume():
                resume_calls.append(True)
            
            with patch.object(formatter, 'pause_live_updates', side_effect=track_pause), \
                 patch.object(formatter, 'resume_live_updates', side_effect=track_resume):
                
                result1 = executor._ask_human_input(""Test result 1"")
                assert result1 == 'feedback'
                
                result2 = executor._ask_human_input(""Test result 2"")
                assert result2 == ''
                
                assert len(pause_calls) == 2
                assert len(resume_calls) == 2
        finally:
            formatter._live_paused = original_paused_state
",tests/test_flow_human_input_integration.py,TestFlowHumanInputIntegration,1,1.1861120010657661e-08,"The method is a unit test designed to verify the behavior of a system component, specifically testing the interaction with human input and the management of flow status. Unit tests are crucial for ensuring code reliability and are typically retained unless they are testing deprecated or obsolete functionality. Since this test appears to be relevant and well-structured, it is likely to be retained."
survived,"def test_convert_with_yes_flag(tmp_path: Path) -> None:
    """"""Test convert command with -y flag to automatically overwrite files.""""""
    # Create a notebook file
    notebook_path = tmp_path / ""test_notebook.ipynb""
    notebook_content = """"""
    {
     ""cells"": [
      {
       ""cell_type"": ""code"",
       ""execution_count"": null,
       ""metadata"": {},
       ""outputs"": [],
       ""source"": [
        ""print('Hello, World!')""
       ]
      }
     ],
     ""metadata"": {},
     ""nbformat"": 4,
     ""nbformat_minor"": 4
    }
    """"""
    notebook_path.write_text(notebook_content)
    
    # Create an existing output file
    output_path = tmp_path / ""output.py""
    output_path.write_text(""existing content"")
    
    # Use the -y flag to verify that the file can be overwritten without prompting
    result = subprocess.run(
        [
            ""marimo"",
            ""-y"",
            ""convert"",
            str(notebook_path),
            ""-o"",
            str(output_path),
        ],
        capture_output=True,
        text=True,
    )
    
    # Check that the command completed successfully
    assert result.returncode == 0
    
    # Verify the file was overwritten with -y flag
    assert output_path.read_text() != ""existing content""
    
    # Verify there was no prompt in the output
    assert ""Warning: The file"" not in result.stdout
    assert ""Overwrite?"" not in result.stdout",tests/_cli/test_file_overwrite.py,,1,3.653482080241728e-08,"The method is a well-structured test function that verifies the functionality of a command-line tool with a specific flag. It uses temporary paths to avoid side effects, checks for expected outcomes, and ensures no unwanted prompts appear. These are all good practices in testing, making the method valuable for maintaining software quality."
survived,"    def to_dict(self) -> Dict[str, Any]:
        """"""
        Convert the security config to a dictionary.

        Returns:
            Dict[str, Any]: Dictionary representation of the security config
        """"""
        result = {
            ""fingerprint"": self.fingerprint.to_dict()
        }
        return result
",src/crewai/security/security_config.py,SecurityConfig,1,1.1032560311263802e-09,"The method 'to_dict' is a common and useful utility function that converts an object into a dictionary format. This is particularly useful for serialization, logging, or debugging purposes. The method is straightforward, well-documented, and follows a standard pattern that is unlikely to become obsolete. Additionally, converting objects to dictionaries is a common requirement in many applications, especially those involving data processing or API interactions. Therefore, it is likely to be retained in the codebase."
deleted,"    async def delete_embeddings_model(self, model_uuid: str) -> None:
        await self.ap.persistence_mgr.execute_async(
            sqlalchemy.delete(persistence_model.EmbeddingsModel).where(persistence_model.EmbeddingsModel.uuid == model_uuid)
        )

        await self.ap.model_mgr.remove_embeddings_model(model_uuid)
",pkg/api/http/service/model.py,EmbeddingsModelsService,1,3.3982678079468468e-09,"The method 'delete_embeddings_model' is likely to be Survived (1) because it performs a crucial operation of deleting an embeddings model from the database and then removing it from the model manager. This is a necessary function for managing resources and ensuring that outdated or unnecessary models do not consume space or processing power. Additionally, the use of asynchronous operations suggests that this method is designed to handle potentially time-consuming tasks efficiently, which is important in modern applications that require scalability and responsiveness."
survived,"def test_agent_without_inject_date():
    """"""Test that without inject_date flag, no date is injected.""""""
    agent = Agent(
        role=""test_agent"",
        goal=""test_goal"",
        backstory=""test_backstory"",
    )
    
    task = Task(
        description=""Test task"",
        expected_output=""Test output"",
        agent=agent,
    )
    
    original_description = task.description
    
    with patch.object(Agent, 'execute_task', return_value=""Task executed"") as mock_execute:
        agent.execute_task(task)
        
        called_task = mock_execute.call_args[0][0]
        
        assert ""Current Date:"" not in called_task.description
        assert called_task.description == original_description",tests/test_agent_inject_date.py,,1,1.3440409770490404e-08,"The method 'test_agent_without_inject_date' is a unit test designed to verify that a specific feature (injecting a date into a task description) is not activated when a certain flag is not set. This is a common testing scenario to ensure that features behave correctly under different configurations. Unit tests are crucial for maintaining code quality and ensuring that changes do not introduce regressions. Therefore, this method is likely to be retained as part of the test suite to ensure the correct functionality of the system."
survived,"def _state() -> AirbyteMessage:
    return AirbyteMessage(type=Type.STATE, state=AirbyteStateMessage(data={}))
",airbyte-integrations/connectors/destination-glassflow/integration_tests/integration_test.py,,1,3.850741907939403e-09,"The method '_state' is a private helper function (indicated by the underscore prefix) that returns an 'AirbyteMessage' object with a specific type and state. This function is likely part of a larger codebase related to data integration or ETL processes, where maintaining state is crucial. Since it encapsulates a specific functionality that might be reused in different parts of the code, it is unlikely to be deleted unless the entire state management approach is refactored or the project is discontinued. Therefore, it is more likely to survive."
survived,"    def default_tool(input_text: str) -> str:
        """"""A default tool.""""""
        return f""Result: {input_text}""
",tests/tools/test_tool_usage_limit.py,,1,1.522997951276035e-08,"The method 'default_tool' is a simple utility function that takes a string input and returns it with a prefix 'Result: '. It is a basic and generic function that can be useful in various contexts where a formatted output is needed. Such utility functions are often retained because they provide a straightforward and reusable way to handle common tasks. Unless there is a specific reason to remove it, such as redundancy or a change in requirements, it is likely to survive."
survived,"    def test_init(self) -> None:
        """"""Test initialization.""""""
        loader = PickleLoader(""test"", self.save_path)
        assert loader.name == ""test""
        assert loader.suffix == ""pickle""
        assert str(loader.save_path).endswith(""/test"")
        
        # Check that the directory was created
        assert os.path.exists(os.path.join(self.save_path, ""test""))
",tests/_save/loaders/test_pickle_loader.py,TestPickleLoader,1,2.5109990926928157e-08,"The method 'test_init' is a unit test designed to verify the initialization of a 'PickleLoader' object. It checks that the object is correctly initialized with the expected name, suffix, and save path, and also verifies that the directory is created. This is a standard practice in software development to ensure that code behaves as expected. Since it serves a clear purpose in testing the functionality of the 'PickleLoader' class, it is likely to be retained in the codebase."
survived,"    def test_call_with_invalid_args(self) -> None:
        """"""Test calling with invalid arguments.""""""
        partial = LoaderPartial(MockLoader, invalid_arg=""value"")
        
        with pytest.raises(TypeError, match=""Could not create""):
            partial(""test_name"")
",tests/_save/loaders/test_loader.py,TestLoaderPartial,1,3.581747929000289e-10,"The method 'test_call_with_invalid_args' is a unit test designed to verify that the LoaderPartial class raises a TypeError when called with invalid arguments. This is a valid and useful test case for ensuring the robustness of the LoaderPartial class. Unit tests are essential for maintaining code quality and preventing regressions, so this method is likely to be retained in the codebase."
survived,"    def teardown_method(self) -> None:
        """"""Clean up the temporary directory.""""""
        self.temp_dir.cleanup()
",tests/_save/loaders/test_json_loader.py,TestJsonLoader,1,3.850741907939403e-09,"The method 'teardown_method' is a common practice in testing frameworks like pytest to clean up resources after a test method has been executed. It ensures that temporary directories or files created during the test are properly removed, preventing side effects on subsequent tests. This method is essential for maintaining test isolation and resource management, which are critical aspects of reliable and maintainable test suites. Therefore, it is unlikely to be deleted as it serves an important purpose in the testing lifecycle."
survived,"    def test_build_path(self) -> None:
        """"""Test building the path for a cache file.""""""
        loader = JsonLoader(""test"", self.save_path)
        path = loader.build_path(""hash1"", ""Pure"")
        assert str(path).endswith(""P_hash1.json"")
        
        path = loader.build_path(""hash2"", ""Deferred"")
        assert str(path).endswith(""D_hash2.json"")
",tests/_save/loaders/test_json_loader.py,TestJsonLoader,1,2.0611536181902033e-09,"The method 'test_build_path' is a unit test designed to verify the functionality of the 'build_path' method in the 'JsonLoader' class. Unit tests are crucial for ensuring code reliability and correctness, especially in larger projects. This test checks that the 'build_path' method correctly constructs file paths based on given parameters. Since testing is an essential part of software development and maintenance, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered. Therefore, the method is expected to survive."
survived,"    def test_cache_hit(self) -> None:
        """"""Test cache hit detection.""""""
        loader = MockPersistenceLoader(""test"", self.save_path)
        
        # No cache exists yet
        assert not loader.cache_hit(""hash1"", ""Pure"")
        
        # Create a cache file (just a placeholder file)
        cache_path = loader.build_path(""hash1"", ""Pure"")
        with open(cache_path, ""w"") as f:
            f.write(""placeholder"")
        
        # Now it should hit
        assert loader.cache_hit(""hash1"", ""Pure"")
        
        # Different hash should miss
        assert not loader.cache_hit(""hash2"", ""Pure"")
        
        # Different cache type should miss
        assert not loader.cache_hit(""hash1"", ""Deferred"")
",tests/_save/loaders/test_loader.py,TestBasePersistenceLoader,1,1.725782769012759e-08,"The method `test_cache_hit` is a unit test designed to verify the functionality of the `cache_hit` method in the `MockPersistenceLoader` class. It checks various scenarios such as when no cache exists, when a cache file is created, and when different hashes or cache types are used. This test is essential for ensuring that the caching mechanism works correctly, which is a critical part of many systems that rely on caching for performance optimization. Therefore, this method is likely to be maintained as part of the test suite to ensure the reliability of the caching functionality."
survived,"def test_special_token_handling():
    """"""Test that special tokens like <|endoftext|> are handled correctly in token estimation.""""""
    config = OnlineRequestProcessorConfig(model=""gpt-4"")
    processor = OpenAIOnlineRequestProcessor(config)
    
    # Test message containing special token
    messages = [{""role"": ""user"", ""content"": ""Testing <|endoftext|> token""}]
    
    try:
        total_tokens = processor.estimate_total_tokens(messages)
        assert total_tokens > 0, ""Token estimation should return a positive number""
    except ValueError as e:
        if ""<|endoftext|>"" in str(e):
            pytest.fail(""Special token <|endoftext|> should not raise ValueError"")
        raise  # Re-raise if it's a different ValueError",tests/test_openai_online_request_processor.py,,1,1.3440409770490404e-08,"The method 'test_special_token_handling' is a unit test designed to ensure that special tokens like '<|endoftext|>' are correctly handled by the 'estimate_total_tokens' function. This is a crucial aspect of testing for any system that processes text with special tokens, especially in the context of language models like GPT-4. The test is well-structured, checking both the positive case (token estimation returns a positive number) and the negative case (no ValueError is raised for special tokens). Such tests are essential for maintaining the robustness and reliability of the system, and therefore, it is unlikely to be deleted."
survived,"    def validate_website_url(cls, v):
        if not v:
            raise ValueError(""Website URL cannot be empty"")
        
        if len(v) > 2048:  # Common maximum URL length
            raise ValueError(""URL is too long (max 2048 characters)"")
            
        if not re.match(r'^https?://', v):
            raise ValueError(""URL must start with http:// or https://"")
            
        try:
            result = urlparse(v)
            if not all([result.scheme, result.netloc]):
                raise ValueError(""Invalid URL format"")
        except Exception as e:
            raise ValueError(f""Invalid URL: {str(e)}"")
            
        if re.search(r'\s', v):
            raise ValueError(""URL cannot contain whitespace"")
            
        return v
",crewai_tools/tools/selenium_scraping_tool/selenium_scraping_tool.py,SeleniumScrapingToolSchema,1,1.6052280526088547e-09,"The method 'validate_website_url' is a utility function that performs a series of checks to ensure that a given URL is valid. It checks for common issues such as empty strings, excessive length, incorrect scheme, invalid format, and whitespace. These are all important validations for any application that deals with URLs, ensuring data integrity and preventing errors. The method is well-structured and covers a comprehensive set of validation rules, making it a useful and necessary part of any codebase that requires URL validation. Therefore, it is likely to be retained in the codebase."
deleted,"    def test_sanitize_collection_name_long_name(self):
        """"""Test sanitizing a very long collection name.""""""
        long_name = ""This is an extremely long role name that will definitely exceed the ChromaDB collection name limit of 63 characters and cause an error when used as a collection name""
        sanitized = sanitize_collection_name(long_name)
        self.assertLessEqual(len(sanitized), 63)
        self.assertTrue(sanitized[0].isalnum())
        self.assertTrue(sanitized[-1].isalnum())
        self.assertTrue(all(c.isalnum() or c in [""_"", ""-""] for c in sanitized))
",tests/utilities/test_string_utils.py,TestStringUtils,1,2.0611536181902033e-09,"The method is a unit test for a function that sanitizes collection names to ensure they meet certain criteria, such as length and character restrictions. This is a common requirement in software systems that interact with databases or APIs with naming constraints. The test is useful for maintaining the integrity and reliability of the sanitize_collection_name function, ensuring it handles edge cases like overly long names. Therefore, it is likely to be retained as part of the test suite to ensure ongoing compliance with these constraints."
survived,"def find_objective_in_top_pages(map_website, objective, app, client):
    try:
        top_links = map_website[:3] if isinstance(map_website, list) else []
        print(f""{Colors.CYAN}Proceeding to analyze top {len(top_links)} links: {top_links}{Colors.RESET}"")
        
        for link in top_links:
            print(f""{Colors.YELLOW}Initiating scrape of page: {link}{Colors.RESET}"")
            scrape_result = app.scrape_url(link, params={'formats': ['markdown']})
            print(f""{Colors.GREEN}Page scraping completed successfully.{Colors.RESET}"")
     
            
            check_prompt = f""""""
            Given the following scraped content and objective, determine if the objective is met.
            If it is, extract the relevant information in a simple and concise JSON format. Use only the necessary fields and avoid nested structures if possible.
            If the objective is not met with confidence, respond with 'Objective not met'.

            Objective: {objective}
            Scraped content: {scrape_result['markdown']}

            Remember:
            1. Only return JSON if you are confident the objective is fully met.
            2. Keep the JSON structure as simple and flat as possible.
            3. Do not include any explanations or markdown formatting in your response.
            """"""
        
            completion = client.chat.completions.create(
            model=""qwen/qwen3-30b-a3b:free"",
            messages=[
                {
                    ""role"": ""user"",
                    ""content"": [
                        {
                            ""type"": ""text"",
                            ""text"": check_prompt
                        }
                    ]
                }
                ]
            )
            
            result = completion.choices[0].message.content
            
            if result != ""Objective not met"":
                print(f""{Colors.GREEN}Objective potentially fulfilled. Relevant information identified.{Colors.RESET}"")
                try:
                    return json.loads(result)
                except json.JSONDecodeError:
                    print(f""{Colors.RED}Error in parsing response. Proceeding to next page...{Colors.RESET}"")
            else:
                print(f""{Colors.YELLOW}Objective not met on this page. Proceeding to next link...{Colors.RESET}"")
        
        print(f""{Colors.RED}All available pages analyzed. Objective not fulfilled in examined content.{Colors.RESET}"")
        return None
    
    except Exception as e:
        print(f""{Colors.RED}Error encountered during page analysis: {str(e)}{Colors.RESET}"")
        return None
",examples/qwen3-web-crawler/qwen3_web_crawler.py,,1,3.3982678079468468e-09,"The method is well-structured and serves a clear purpose: to find an objective in the top pages of a website. It includes error handling, logging, and uses a chat model to determine if the objective is met. The method is likely to be useful in scenarios where automated content analysis is needed, and it integrates with existing systems (app and client) effectively. These factors suggest that the method is functional and relevant, leading to its survival."
survived,"    def crawl_page(self, url):
        """"""Crawl a single page and extract links.""""""
        if url in self.visited_pages or len(self.visited_pages) >= self.max_pages:
            return []
            
        self.visited_pages.add(url)
        print(f""Crawling: {url}"")
        
        try:
            response = self.session.get(url, timeout=self.timeout)
            response.raise_for_status()
            
            content_type = response.headers.get('content-type', '').lower()
            if 'text/html' not in content_type:
                return []
                
            links = self.extract_links(response.text, url)
            
            for link in links:
                self.check_link(link, url)
                
                if self.is_internal_url(link):
                    normalized = self.normalize_url(link)
                    if normalized not in self.visited_pages:
                        self.pages_to_visit.append(normalized)
            
            time.sleep(self.delay)
            return links
            
        except requests.exceptions.RequestException as e:
            print(f""Error crawling {url}: {e}"")
            return []
",scripts/check_dead_links.py,DeadLinkChecker,1,1.3440409770490404e-08,"The method 'crawl_page' is a core part of a web crawler's functionality, responsible for fetching a page, extracting links, and managing the list of pages to visit. It includes error handling, respects the maximum number of pages to visit, and checks for content type, which are all essential features for a robust crawler. These functionalities are crucial for the operation of a web crawler, making it unlikely to be removed unless the entire crawling functionality is deprecated or significantly refactored."
survived,"    def extract_links(self, html, page_url):
        """"""Extract all links from HTML content.""""""
        soup = BeautifulSoup(html, 'html.parser')
        links = []
        
        for tag in soup.find_all(['a', 'link', 'img', 'script']):
            url = None
            if tag.name == 'a':
                url = tag.get('href')
            elif tag.name == 'link':
                url = tag.get('href')
            elif tag.name == 'img':
                url = tag.get('src')
            elif tag.name == 'script':
                url = tag.get('src')
                
            if url:
                absolute_url = urljoin(page_url, url)
                if not absolute_url.startswith(('javascript:', 'mailto:', 'tel:')):
                    links.append(absolute_url)
                    
        return links
",scripts/check_dead_links.py,DeadLinkChecker,1,1.6052280526088547e-09,"The method 'extract_links' is a utility function that extracts URLs from HTML content, which is a common requirement in web scraping and data extraction tasks. It uses BeautifulSoup, a popular library for parsing HTML, and handles different HTML tags that can contain URLs. The method also converts relative URLs to absolute ones using 'urljoin', ensuring the links are usable outside the context of the original page. This functionality is essential for many applications that need to process web content, making it unlikely to be deleted."
survived,"def generate_tools_code_sync(tools: List[ToolDefinition]) -> str:
    """"""
    Synchronous wrapper for generate_tools_code.
    
    Args:
        tools: List of tool definitions
        
    Returns:
        Python code implementing all tools
    """"""
    try:
        loop = asyncio.get_event_loop()
    except RuntimeError:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
    return loop.run_until_complete(generate_tools_code(tools))
",meta_agent/generators/tool_generator.py,,1,7.582560422162384e-10,"The method is a synchronous wrapper for an asynchronous function, which is a common pattern in Python to provide both sync and async interfaces. This increases the flexibility and usability of the code, allowing it to be used in different contexts where either synchronous or asynchronous execution is required. The method is well-documented and handles the event loop correctly, making it robust and useful. Therefore, it is likely to be retained in the codebase."
survived,"def validate_tool_code(tool_code: str) -> bool:
    """"""
    Validate that generated tool code is syntactically correct.
    
    Args:
        tool_code: Generated tool code
        
    Returns:
        True if the code is valid, False otherwise
    """"""
    try:
        compile(tool_code, '<string>', 'exec')
        return True
    except SyntaxError as e:
        print(f""Syntax error in generated tool code: {str(e)}"")
        return False
",meta_agent/generators/tool_generator.py,,1,5.905303995456778e-10,"The method 'validate_tool_code' is a utility function that checks if a given string of code is syntactically correct by attempting to compile it. This is a useful function for any application that generates or processes code dynamically, as it ensures that the code is valid before execution. The method is simple, effective, and provides informative error messages when syntax errors are detected. Such functionality is often needed in environments where code generation or dynamic code execution is involved, making it a valuable tool in a developer's toolkit. Therefore, it is likely to be retained."
survived,"    def test_require_api_key_env(self) -> None:
        """"""Test _require_api_key with environment variable.""""""
        model = openai(""gpt-4"")
        assert model._require_api_key == ""env-key""
",tests/_ai/llm/_impl.py,TestOpenAI,1,2.3823698451773172e-07,"The method 'test_require_api_key_env' is a test function that checks if the '_require_api_key' attribute of a model object is set to 'env-key'. This is a simple test case that verifies the behavior of the model when an API key is expected to be retrieved from an environment variable. Test functions are generally essential for ensuring code reliability and correctness, especially in environments where API keys and configurations are critical. Therefore, this method is likely to be retained as part of the test suite to ensure the functionality works as expected."
survived,"    def test_is_file_path_with_empty_path(self) -> None:
        # Test with empty path
        with pytest.raises(click.BadParameter) as excinfo:
            is_file_path(None, None, """")
        assert ""Must be a file path"" in str(excinfo.value)
        
        # Test with None
        with pytest.raises(click.BadParameter) as excinfo:
            is_file_path(None, None, None)
        assert ""Must be a file path"" in str(excinfo.value)
",tests/_cli/test_cli_validators.py,TestIsFilePath,1,2.0611536181902033e-09,"The method `test_is_file_path_with_empty_path` is a unit test designed to verify the behavior of the `is_file_path` function when it receives empty or None values as input. Unit tests are crucial for ensuring code reliability and correctness, especially when handling edge cases like empty inputs. This test checks that the function raises the appropriate exception (`click.BadParameter`) with the expected error message. Since testing is an essential part of software development to maintain code quality, this method is likely to be retained in the codebase."
survived,"    def test_stdout_write(self) -> None:
        stdout = self.MockStdout()

        # Test write method
        result = stdout.write(""Hello, world!"")

        # Should return the length of the string
        assert result == 13

        # Should call _write_with_mimetype with text/plain mimetype
        assert len(stdout.written_data) == 1
        assert stdout.written_data[0] == (""Hello, world!"", ""text/plain"")
",tests/_messaging/test_types.py,TestStdoutStderr,1,2.998960815863541e-09,"The method 'test_stdout_write' is a unit test for a mock object 'MockStdout'. It verifies that the 'write' method of 'MockStdout' behaves as expected by checking the return value and the internal state of the mock object. Unit tests are crucial for ensuring code reliability and are typically not deleted unless they are redundant or replaced by more comprehensive tests. Since this test seems to be well-defined and serves a clear purpose, it is likely to be retained."
survived,"        def _write_with_mimetype(self, data: str, mimetype: KnownMimeType) -> int:
            self.written_data.append((data, mimetype))
            return len(data)
",tests/_messaging/test_types.py,TestStdoutStderr.MockStdout,1,2.7894680920908113e-10,"The method '_write_with_mimetype' is a utility function that appends data along with its MIME type to a list and returns the length of the data. This functionality is useful for tracking or logging data with its associated MIME type, which can be important in applications dealing with various data formats. The method is simple, clear, and serves a specific purpose, making it likely to be retained in the codebase."
deleted,"    def test_marimo_ancestor_prevented_error(self) -> None:
        error = MarimoAncestorPreventedError(
            msg=""Execution prevented by ancestor"",
            raising_cell=""cell1"",
            blamed_cell=""cell2"",
        )

        # Test properties
        assert error.type == ""ancestor-prevented""
        assert error.describe() == ""Execution prevented by ancestor""
        assert error.raising_cell == ""cell1""
        assert error.blamed_cell == ""cell2""
",tests/_messaging/test_errors.py,TestErrorClasses,1,8.152020648014727e-09,"The method 'test_marimo_ancestor_prevented_error' is a unit test designed to verify the properties and behavior of the 'MarimoAncestorPreventedError' class. Unit tests are crucial for ensuring code reliability and correctness, especially in larger codebases. This test checks that the error object is correctly instantiated and that its properties return the expected values. Since testing is a fundamental part of software development and maintenance, this method is likely to be retained to ensure the functionality of the error handling mechanism remains intact."
survived,"        def accepts_kernel_message(message: KernelMessage) -> KernelMessage:
            return message
",tests/_messaging/test_types.py,TestKernelMessage,0,0.9999938558278723,"The method 'accepts_kernel_message' is a simple pass-through function that takes a 'KernelMessage' object as input and returns it without any modification. This kind of method is often used as a placeholder or for testing purposes. However, in a production environment, such methods are typically either expanded to include additional logic or removed if they serve no functional purpose. Given its current state, it is likely to be deleted unless it is part of a larger framework where such a method is required for interface consistency or future extension."
deleted,"    def test_http_request_context_manager_with_none(self) -> None:
        # Test that http_request_context can set None
        with http_request_context(None):
            # Request should be None within the context
            ctx_request = HTTP_REQUEST_CTX.get()
            assert ctx_request is None

        # Request should be unset outside the context
        with pytest.raises(LookupError):
            HTTP_REQUEST_CTX.get()
",tests/_messaging/test_context.py,TestHTTPRequestContext,1,6.023574641292144e-08,"The method `test_http_request_context_manager_with_none` is a unit test designed to verify the behavior of a context manager `http_request_context` when it is given `None` as an argument. This test is crucial for ensuring that the context manager correctly handles `None` values, which is a common edge case that needs to be tested to prevent potential bugs in the application. The test checks that within the context, the request is set to `None`, and outside the context, it raises a `LookupError`, indicating that the context manager is functioning as expected. Since this test is important for maintaining the robustness of the code, it is likely to be retained."
survived,"    async def check_approval(self, wallet_client: EVMWalletClient, parameters: dict):
        """"""Check token approval and approve if needed.""""""
        try:
            data = await self.make_request(""check_approval"", {
                ""token"": parameters[""token""],
                ""amount"": parameters[""amount""],
                ""walletAddress"": parameters[""walletAddress""],
                ""chainId"": wallet_client.get_chain()[""id""]
            })

            approval = data.get(""approval"")
            if not approval:
                return {""status"": ""approved""}

            transaction = await wallet_client.send_transaction({
                ""to"": approval[""to""],
                ""value"": approval[""value""],
                ""data"": approval[""data""]
            })

            return {
                ""status"": ""approved"",
                ""txHash"": transaction[""hash""]
            }
        except Exception as error:
            raise Exception(f""Failed to check/approve token: {error}"")
",python/src/plugins/uniswap/goat_plugins/uniswap/service.py,UniswapService,1,1.2501528648238603e-09,"The method 'check_approval' is likely to survive because it performs a crucial function in the context of blockchain and cryptocurrency operations. It checks for token approval and initiates a transaction if necessary, which is a common requirement in decentralized applications. The method is also well-structured, using asynchronous programming to handle potentially long-running network requests efficiently. Additionally, it includes error handling to manage exceptions, which is important for robustness in real-world applications."
survived,"def test_base_url_configuration(custodial_api):
    """"""Test base URL configuration.""""""
    assert custodial_api.base_url == ""https://staging.crossmint.com/api/v1-alpha2""
",python/src/wallets/crossmint/tests/test_api_client.py,,1,8.592166611791576e-10,"The method 'test_base_url_configuration' is a simple test function that checks if the 'base_url' attribute of the 'custodial_api' object is set to a specific URL. This kind of test is common in software development to ensure that configurations are correctly set. It is likely to survive because it serves a clear purpose in verifying the correctness of the API configuration, which is crucial for the proper functioning of the application."
survived,"def test_custodial_wallet_transaction(custodial_api, test_email, solana_connection):
    """"""Test transaction sending with custodial wallet.""""""
    # Create wallet and client
    wallet = custodial_api.create_custodial_wallet(test_email)
    client = CustodialSolanaWalletClient(
        wallet[""address""],
        custodial_api,
        solana_connection,
        {""email"": test_email}
    )
    
    # Create a simple transfer instruction
    instruction = Instruction(
        program_id=Pubkey.from_string(""11111111111111111111111111111111""),  # System program
        accounts=[],  # Empty for test
        data=bytes()  # Empty for test
    )
    
    # Send transaction
    tx = client.send_transaction({
        ""instructions"": [instruction]
    })
    assert tx[""status""] in [""success"", ""pending""]
    if tx[""status""] == ""success"":
        assert len(tx[""hash""]) > 0
",python/src/wallets/crossmint/tests/test_custodial_wallet.py,,1,1.3440409770490404e-08,"The method `test_custodial_wallet_transaction` is a test function that verifies the functionality of sending transactions using a custodial wallet. Test functions are generally important for ensuring code reliability and correctness, especially in financial or blockchain applications where transactions are critical. The method is well-structured, uses assertions to validate outcomes, and is likely part of a test suite that ensures the robustness of the custodial wallet API. Therefore, it is unlikely to be deleted as it serves a crucial role in maintaining code quality."
survived,"def test_custodial_wallet_creation_with_phone(custodial_api, test_phone, solana_connection):
    """"""Test custodial wallet creation with phone number.""""""
    # Create wallet
    wallet = custodial_api.create_custodial_wallet(test_phone)
    assert wallet[""type""] == ""solana-custodial-wallet""
    
    # Verify retrieval
    retrieved = custodial_api.get_wallet(f""phone:{test_phone}:solana-custodial-wallet"")
    compare_wallet_responses(wallet, retrieved)
    
    # Test client creation
    client = CustodialSolanaWalletClient(
        wallet[""address""],
        custodial_api,
        solana_connection,
        {""phone"": test_phone}
    )
    assert client.get_address() == wallet[""address""]
",python/src/wallets/crossmint/tests/test_custodial_wallet.py,,1,8.76424914819242e-08,"The method `test_custodial_wallet_creation_with_phone` is a test function that verifies the creation and retrieval of a custodial wallet using a phone number. It includes assertions to ensure the wallet is created correctly and can be retrieved and used to create a client. Test functions are generally essential for maintaining code quality and ensuring that features work as expected. Therefore, it is unlikely to be deleted unless the feature it tests is removed or significantly changed."
survived,"    def primary_key(self) -> Optional[Union[str, List[str], List[List[str]]]]:
        """"""
        :return: string if single primary key, list of strings if composite primary key, list of list of strings if composite primary key consisting of nested fields.
          If the stream has no primary keys, return None.
        """"""
        return ""id""
",airbyte-integrations/connectors/source-box-data-extract/source_box_data_extract/source.py,StreamAIExtractFolder,1,1.3440409770490404e-08,"The method 'primary_key' is a utility function that provides a way to retrieve the primary key(s) of a data stream. It is designed to handle different scenarios: a single primary key, a composite primary key, or a composite primary key with nested fields. This flexibility makes it useful in various contexts where data streams might have different structures. The method is simple, well-documented, and serves a clear purpose, which suggests it is likely to be retained in the codebase."
survived,"def test_create_research_agent():
    """"""Test that the research agent is created with the correct configuration.""""""
    agent = create_research_agent()
    assert agent.name == ""ResearchSpecialist""
    assert ""research specialist"" in agent.instructions.lower()
    assert agent.model == ""gpt-4o-mini""
",openai-agents-examples/08_agent_with_agent_as_tool.py,,1,1.0467401685178159e-08,"The method 'test_create_research_agent' is a unit test function that checks the creation of a research agent with specific attributes. Unit tests are crucial for ensuring code reliability and correctness, especially in larger projects. This test verifies that the agent is created with the correct name, instructions, and model, which are important aspects of the agent's configuration. Since testing is a fundamental part of software development and maintenance, this method is likely to be retained to ensure the functionality of the 'create_research_agent' function."
survived,"async def run_protected_agent(prompt: str) -> str:
    """"""
    Run the protected agent with the given prompt.
    
    Args:
        prompt: The user's query or prompt
        
    Returns:
        The agent's response as a string, or a rejection message if the input is filtered
    """"""
    # Create the protected agent
    agent = create_protected_agent()
    
    try:
        # Run the agent with the prompt
        result = await Runner.run(agent, prompt)
        return result.final_output
    except Exception as e:
        # Check if it's a guardrail rejection
        if ""guardrail rejected"" in str(e).lower():
            return f""Input rejected by guardrails: {str(e)}""
        # Other exception
        return f""Error: {str(e)}""
",openai-agents-examples/10_agent_with_guardrails.py,,1,2.0611536181902033e-09,"The method 'run_protected_agent' is likely to survive because it is well-structured and serves a clear purpose. It handles asynchronous operations, which are increasingly common in modern programming, and includes error handling for specific cases like guardrail rejections. This makes it robust and adaptable to various scenarios, which are desirable traits in software development."
survived,"def test_create_agents():
    """"""Test that the agents are created with the correct configuration.""""""
    research_agent = create_research_agent()
    blog_agent = create_blog_agent()
    coordinator = create_coordinator_agent([research_agent, blog_agent])
    
    assert research_agent.name == ""ResearchSpecialist""
    assert blog_agent.name == ""BlogSpecialist""
    assert coordinator.name == ""ContentCoordinator""
    
    assert len(research_agent.tools) == 2
    assert len(blog_agent.tools) == 2
    assert len(coordinator.handoffs) == 2
",openai-agents-examples/13_research_blog_system.py,,1,4.944450477491054e-09,"The method `test_create_agents` is a unit test designed to verify the correct creation and configuration of agent objects. Unit tests are crucial for ensuring code reliability and correctness, especially in larger systems where multiple components interact. This test checks the names and attributes of the created agents, which is a fundamental aspect of verifying that the system behaves as expected. Given the importance of testing in software development, this method is likely to be retained to maintain code quality and prevent regressions."
survived,"async def run_anthropic_agent(prompt: str) -> str:
    """"""
    Run the Anthropic agent with the given prompt.
    
    Args:
        prompt: The user's query or prompt
        
    Returns:
        The agent's response as a string
    """"""
    # Create the Anthropic agent
    agent = create_anthropic_agent()
    
    # Run the agent with the prompt
    result = await Runner.run(agent, prompt)
    
    # Return the response
    return result.final_output
",openai-agents-examples/12_anthropic_agent.py,,1,2.1724399346070676e-10,"The method 'run_anthropic_agent' is likely to survive because it is a well-defined asynchronous function that serves a clear purpose: interacting with an Anthropic agent using a given prompt. It includes proper documentation, follows a logical structure, and uses asynchronous programming, which is increasingly common in modern software development. Additionally, the method's functionality is relevant for applications involving AI and natural language processing, which are growing fields."
survived,"async def run_basic_agent(prompt: str, agent: Optional[Agent] = None) -> str:
    """"""
    Run the basic agent with the given prompt.
    
    Args:
        prompt: The user's query or prompt
        agent: Optional pre-configured agent. If None, a default agent is created.
        
    Returns:
        The agent's response as a string
    """"""
    # Create agent if not provided
    if agent is None:
        agent = create_basic_agent()
    
    # Run the agent with the prompt
    result = await Runner.run(agent, prompt)
    
    # Extract and return the text response
    return result.final_output
",openai-agents-examples/01_basic_agent.py,,1,5.905303995456778e-10,"The method `run_basic_agent` is likely to survive because it is a well-structured and useful function for running an agent with a given prompt. It includes clear documentation, handles optional parameters, and uses asynchronous programming, which is increasingly common in modern applications. Additionally, it provides a default behavior by creating an agent if none is provided, making it flexible and user-friendly."
survived,"    def __init__(self, api_key: Optional[str] = None):
        """"""
        Initialize the Anthropic model provider.
        
        Args:
            api_key: Anthropic API key. If None, will use the ANTHROPIC_API_KEY environment variable.
        """"""
        self.api_key = api_key or os.environ.get(""ANTHROPIC_API_KEY"")
        if not self.api_key:
            raise ValueError(""Anthropic API key is required"")
        
        self.client = anthropic.Anthropic(api_key=self.api_key)
",openai-agents-examples/12_anthropic_agent.py,AnthropicModelProvider,1,2.0611536181902033e-09,"The method is a constructor for initializing an object with an API key, which is a common and necessary practice for setting up API clients. It includes error handling for missing API keys, which is crucial for ensuring the application functions correctly. This method is essential for the functionality of the class it belongs to, as it sets up the necessary client for interacting with the Anthropic API. Therefore, it is unlikely to be deleted."
survived,"def test_anthropic_message_formatting():
    # Test when first message is system
    llm = LLM(model=""anthropic/claude-3-sonnet"")
    messages = [{""role"": ""system"", ""content"": ""test""}]
    formatted = llm._format_messages_for_provider(messages)
    assert len(formatted) == 2
    assert formatted[0][""role""] == ""user""
    assert formatted[0][""content""] == "".""
    assert formatted[1][""role""] == ""system""
    assert formatted[1][""content""] == ""test""

    # Test when first message is already user
    messages = [{""role"": ""user"", ""content"": ""test""}]
    formatted = llm._format_messages_for_provider(messages)
    assert len(formatted) == 1
    assert formatted[0][""role""] == ""user""
    assert formatted[0][""content""] == ""test""

    # Test with empty message list
    messages = []
    formatted = llm._format_messages_for_provider(messages)
    assert len(formatted) == 1
    assert formatted[0][""role""] == ""user""
    assert formatted[0][""content""] == "".""

    # Test with non-Anthropic model (should not modify messages)
    llm = LLM(model=""gpt-4"")
    messages = [{""role"": ""system"", ""content"": ""test""}]
    formatted = llm._format_messages_for_provider(messages)
    assert len(formatted) == 1
    assert formatted[0][""role""] == ""system""
    assert formatted[0][""content""] == ""test""
",tests/llm_test.py,,1,1.8189616842444243e-09,"The method `test_anthropic_message_formatting` is a unit test designed to verify the behavior of the `_format_messages_for_provider` method in different scenarios. It checks the formatting of messages based on the role and the model type. This kind of test is crucial for ensuring that the message formatting logic works correctly, especially when dealing with different models like 'anthropic/claude-3-sonnet' and 'gpt-4'. Since testing is an essential part of software development to maintain code quality and prevent regressions, this method is likely to be retained in the codebase. Therefore, it will survive."
survived,"def test_verify_jwt_valid_token():
    subdomain = ""abcd1234""
    token = jwt.encode({""subdomain"": subdomain}, config.jwt_secret, algorithm=""HS256"")
    
    result = verify_jwt(token)
    assert result == subdomain
",backend/tests/test_utils_extended.py,,1,9.237449576640118e-09,"The method 'test_verify_jwt_valid_token' is a unit test designed to verify the functionality of the 'verify_jwt' function. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with security features like JWT (JSON Web Tokens). This test checks if a valid token returns the expected subdomain, which is a fundamental aspect of JWT verification. Given the importance of testing in software development, this method is likely to be retained to ensure the 'verify_jwt' function works as intended."
survived,"async def test_get_files_endpoint():
    payload = {
        ""iat"": datetime.datetime.utcnow(),
        ""exp"": datetime.datetime.utcnow() + datetime.timedelta(days=1),
        ""subdomain"": ""abcd1234"",
    }
    token = jwt.encode(payload, ""test-secret"", algorithm=""HS256"")
    
    file_data = {
        ""index.html"": {
            ""raw"": ""SGVsbG8gV29ybGQ="",  # base64 encoded ""Hello World""
            ""headers"": [
                {""header"": ""Content-Type"", ""value"": ""text/plain""},
                {""header"": ""X-Custom"", ""value"": ""test""},
            ],
            ""status_code"": 200,
        },
        ""test.js"": {
            ""raw"": ""Y29uc29sZS5sb2coJ0hlbGxvJyk7"",  # base64 encoded ""console.log('Hello');""
            ""headers"": [
                {""header"": ""Content-Type"", ""value"": ""application/javascript""},
            ],
            ""status_code"": 200,
        }
    }
    
    mock_redis.get.return_value = json.dumps(file_data)
    
    with patch(""backend.app.config.jwt_secret"", ""test-secret""):
        response = client.get(""/api/files"", params={""token"": token})
        
        assert response.status_code == 200
        assert response.json() == file_data
        
        mock_redis.get.assert_called_with(""files:abcd1234"")
",backend/tests/test_endpoints.py,,1,9.736200303530205e-10,"The method `test_get_files_endpoint` is a unit test for an API endpoint, which is a crucial part of ensuring the reliability and correctness of the API. It verifies that the endpoint correctly retrieves and returns file data based on a token. Such tests are essential for maintaining code quality and are unlikely to be deleted unless the functionality they test is removed or significantly altered. Therefore, the method is likely to survive."
survived,"        async def reset_session(session_type: str) -> str:
            """"""ÈáçÁΩÆË∞ÉËØï‰ºöËØù""""""
            try:
                if session_type not in ['person', 'group']:
                    return self.http_status(400, -1, 'session_type must be person or group')
                
                webchat_adapter = None
                for bot in self.ap.platform_mgr.bots:
                    if hasattr(bot.adapter, '__class__') and bot.adapter.__class__.__name__ == 'WebChatAdapter':
                        webchat_adapter = bot.adapter
                        break
                
                if not webchat_adapter:
                    return self.http_status(404, -1, 'WebChat adapter not found')
                
                webchat_adapter.reset_debug_session(session_type)
                
                return self.success(data={'message': 'Session reset successfully'})
                
            except Exception as e:
                return self.http_status(500, -1, f'Internal server error: {str(e)}')
",pkg/api/http/controller/groups/debug/webchat.py,WebChatDebugRouterGroup,1,1.0261879630648829e-10,"The method 'reset_session' is likely to survive because it performs a specific and useful function: resetting a debug session for a web chat adapter. It includes error handling, checks for valid input, and interacts with other components of the system (like the web chat adapter). These characteristics suggest it is a well-structured and necessary part of the system's functionality."
survived,"    def clean_content(self, content: str) -> str:
        """"""Clean markdown content for indexing.""""""
        content = re.sub(r'```[^`]*```', '', content, flags=re.DOTALL)
        
        content = re.sub(r'`[^`]*`', '', content)
        
        content = re.sub(r'\[([^\]]*)\]\([^)]*\)', r'\1', content)
        
        content = re.sub(r'[*_~`]', '', content)
        
        content = re.sub(r'<[^>]*>', '', content)
        
        content = re.sub(r'^---.*?---', '', content, flags=re.DOTALL | re.MULTILINE)
        
        content = re.sub(r'```python exec.*?```', '', content, flags=re.DOTALL)
        
        content = re.sub(r'```python demo.*?```', '', content, flags=re.DOTALL)
        
        content = re.sub(r'```python eval.*?```', '', content, flags=re.DOTALL)
        
        content = re.sub(r'\n\s*\n', '\n\n', content)
        content = content.strip()
        
        return content
",scripts/typesense_indexer.py,MarkdownProcessor,1,2.3355930333443423e-09,"The method 'clean_content' is a utility function designed to clean markdown content by removing code blocks, inline code, links, markdown formatting characters, HTML tags, and specific patterns. This is a common requirement for preparing text data for indexing or further processing. The method is well-defined, serves a clear purpose, and is likely to be useful in contexts where markdown content needs to be sanitized before being used in applications like search indexing or text analysis. Therefore, it is likely to be retained in the codebase."
deleted,"def typesense_search_with_styles() -> rx.Component:
    """"""Create the Typesense search component with styles.""""""
    return rx.fragment(
        rx.html(search_styles),
        typesense_search()
    )",pcweb/components/docpage/navbar/typesense.py,,1,3.3982678079468468e-09,"The method `typesense_search_with_styles` is a simple function that creates a component by combining styles and a search component. It is likely to be a utility function used in a larger application to ensure consistent styling and functionality. Such utility functions are generally useful and reusable, making them less likely to be deleted unless there is a significant change in the application's architecture or styling approach."
survived,"def test_solana_message():
    """"""Fixture providing test Solana message.""""""
    return ""Hello Solana""
",python/src/wallets/crossmint/tests/conftest.py,,1,1.8553915987649156e-07,"The method `test_solana_message` is a simple function that returns a string ""Hello Solana"". It is likely used as a fixture in a testing environment, possibly for unit tests involving Solana-related functionality. Since it serves a clear purpose in providing a consistent test message, it is likely to be retained as part of the test suite. Such utility functions are common in testing frameworks to ensure consistent and repeatable test conditions."
survived,"    def format_as_summary(self):
        """"""
        Format the data as a summary report.
        
        Returns:
            dict: Stage result with data and metadata
        """"""
        if self.data is None:
            self.metadata[""status""] = ""error""
            self.metadata[""errors""].append(""No data to format"")
            return self._create_result()
        
        try:
            # Create summary
            summary = {
                ""report_type"": ""summary"",
                ""generated_at"": datetime.now().isoformat(),
                ""data_source"": self.metadata.get(""input_metadata"", {}).get(""source"", ""unknown""),
                ""record_count"": len(self.data) if isinstance(self.data, list) else 1
            }
            
            # Add statistics if available
            if self.analysis and ""statistics"" in self.analysis:
                summary[""statistics""] = self.analysis[""statistics""]
            
            # Add processing information
            if ""processing_metadata"" in self.metadata:
                processing_meta = self.metadata[""processing_metadata""]
                if ""processing_steps"" in processing_meta:
                    summary[""processing_steps""] = processing_meta[""processing_steps""]
                if ""processing_time_seconds"" in processing_meta:
                    summary[""processing_time_seconds""] = processing_meta[""processing_time_seconds""]
            
            # Store the summary
            self.summary = summary
            
            # Update metadata
            self.metadata[""output_formats""].append(""summary"")
            
            return self._create_result()
        except Exception as e:
            self.metadata[""status""] = ""error""
            self.metadata[""errors""].append(f""Summary formatting error: {str(e)}"")
            return self._create_result()
",codebase-architectures/pipeline-architecture/pipeline/output_stage.py,OutputStage,1,7.194132978569833e-09,"The method 'format_as_summary' is a utility function that formats data into a summary report. It includes error handling, metadata updates, and attempts to create a structured summary from the data. Such methods are generally useful in data processing and reporting contexts, making them likely to be retained in the codebase. The method is well-structured, handles exceptions, and updates metadata, which are good practices in software development. Therefore, it is likely to survive."
survived,"    def _create_result(self):
        """"""Create a result dictionary with data and metadata.""""""
        result = {
            ""data"": self.data,
            ""metadata"": self.metadata
        }
        
        # Add analysis if available
        if hasattr(self, ""analysis""):
            result[""analysis""] = self.analysis
        
        return result",codebase-architectures/pipeline-architecture/pipeline/processing_stage.py,ProcessingStage,1,1.0467401685178159e-08,"The method `_create_result` is a utility function that constructs a dictionary containing important information such as data and metadata, and optionally includes analysis if it exists. This kind of method is typically useful for organizing and returning structured data, which is a common requirement in many applications. Since it serves a clear purpose and is likely to be used in various parts of a codebase where such structured results are needed, it is unlikely to be deleted unless the entire approach to handling results is changed."
survived,"def display_header(text):
    """"""Display a header with the given text.""""""
    print(""\n"" + ""="" * 50)
    print(f"" {text}"")
    print(""="" * 50)
",codebase-architectures/atomic-composable-architecture/main.py,,1,7.582560422162384e-10,"The method 'display_header' is a simple utility function that formats and prints a header with a given text. Such utility functions are often useful in various applications for consistent formatting of output, especially in command-line interfaces or logging. The method is straightforward, has a clear purpose, and is likely to be reused in different parts of a codebase where formatted headers are needed. Therefore, it is likely to survive."
survived,"    def __init__(self, name=""Data Processing Pipeline""):
        """"""Initialize the data processing pipeline.""""""
        super().__init__(name)
",codebase-architectures/pipeline-architecture/pipeline/pipeline_manager.py,DataProcessingPipeline,1,2.699578619062706e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing objects with default or specified values. The use of a constructor is standard practice and necessary for the proper functioning of classes, especially when inheritance is involved, as indicated by the use of 'super()'. Therefore, it is unlikely to be deleted."
survived,"def authenticate(username: str, password: str) -> Optional[Dict]:
    """"""
    Authenticate a user with username and password.
    
    Args:
        username: The username to authenticate
        password: The password to authenticate
        
    Returns:
        User data dictionary if authentication succeeds, None otherwise
    """"""
    if username not in USER_STORE:
        return None
    
    user_data = USER_STORE[username]
    if verify_password(password, user_data[""hashed_password""], user_data[""salt""]):
        return {k: v for k, v in user_data.items() if k not in [""hashed_password"", ""salt""]}
    
    return None
",codebase-architectures/atomic-composable-architecture/modules/auth.py,,1,2.3355930333443423e-09,"The method is likely to survive because it performs a fundamental operation of user authentication, which is essential in many applications. It checks if the username exists in the user store and verifies the password using a secure method. The function is well-documented, clearly structured, and returns user data without sensitive information, which is a good practice for security. These factors make it a useful and necessary function in any system requiring user authentication."
survived,"    def __init__(self, name, description=None, id=None):
        """"""Initialize a category.""""""
        self.id = id
        self.name = name
        self.description = description
        self.created_at = datetime.now().isoformat()
        self.updated_at = self.created_at
",codebase-architectures/layered-architecture/models/category.py,Category,1,4.363462233903899e-09,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. It initializes the attributes of an instance, which is essential for creating objects with specific properties. Constructors are a standard and necessary part of class definitions, and there is no indication that this particular constructor is redundant or unnecessary. Therefore, it is likely to survive."
survived,"def revoke_token(token: str) -> bool:
    """"""
    Revoke an authentication token.
    
    Args:
        token: The token to revoke
        
    Returns:
        True if the token was revoked, False if it didn't exist
    """"""
    if token in TOKEN_STORE:
        del TOKEN_STORE[token]
        return True
    return False
",codebase-architectures/atomic-composable-architecture/modules/auth.py,,1,4.363462233903899e-09,"The method 'revoke_token' is a straightforward utility function that performs a common task in authentication systems: revoking a token. This is a necessary function for managing user sessions and ensuring security by allowing tokens to be invalidated when no longer needed or when compromised. The method is simple, efficient, and serves a clear purpose, making it unlikely to be deleted unless the entire token management system is overhauled or replaced with a different mechanism."
survived,"    def save_to_file(self, output_format=""json"", output_dir=""./output"", filename=None):
        """"""
        Save the formatted output to a file.
        
        Args:
            output_format: Format to save (json, csv)
            output_dir: Directory to save the file
            filename: Optional filename (generated if not provided)
        
        Returns:
            dict: Stage result with data and metadata
        """"""
        try:
            # Create output directory if it doesn't exist
            if not os.path.exists(output_dir):
                os.makedirs(output_dir)
            
            # Determine what to save
            if output_format == ""json"":
                if hasattr(self, ""detailed_report""):
                    data_to_save = self.detailed_report
                    file_prefix = ""detailed_report""
                elif hasattr(self, ""summary""):
                    data_to_save = self.summary
                    file_prefix = ""summary_report""
                else:
                    data_to_save = {
                        ""data"": self.data,
                        ""generated_at"": datetime.now().isoformat()
                    }
                    file_prefix = ""data_export""
                
                # Generate filename if not provided
                if not filename:
                    filename = generate_report_filename(file_prefix, ""json"")
                
                # Save to file
                file_path = os.path.join(output_dir, filename)
                save_json_file(data_to_save, file_path)
                
            elif output_format == ""csv"":
                # CSV format only works for list data
                if not isinstance(self.data, list):
                    raise ValueError(""CSV output format requires list data"")
                
                # Generate filename if not provided
                if not filename:
                    filename = generate_report_filename(""data_export"", ""csv"")
                
                # Save to file
                file_path = os.path.join(output_dir, filename)
                save_csv_file(self.data, file_path)
            
            else:
                raise ValueError(f""Unsupported output format: {output_format}"")
            
            # Update metadata
            self.metadata[""output_files""] = self.metadata.get(""output_files"", [])
            self.metadata[""output_files""].append({
                ""format"": output_format,
                ""path"": file_path,
                ""filename"": filename
            })
            
            return self._create_result()
        except Exception as e:
            self.metadata[""status""] = ""error""
            self.metadata[""errors""].append(f""File save error: {str(e)}"")
            return self._create_result()
",codebase-architectures/pipeline-architecture/pipeline/output_stage.py,OutputStage,1,1.0467401685178159e-08,"The method 'save_to_file' is a utility function that provides a flexible way to save data in different formats (JSON and CSV) to a specified directory. It includes error handling, dynamic filename generation, and updates metadata, making it a robust and useful feature in many applications. Such methods are typically retained as they provide essential functionality for data export and reporting."
survived,"    def get_products_by_category(category_id):
        """"""Get all products in a category.""""""
        try:
            products = db.query(""products"", lambda p: p[""category_id""] == category_id)
            Logger.info(app_logger, f""Retrieved {len(products)} products for category {category_id}"")
            return products
        except Exception as e:
            Logger.error(app_logger, f""Error getting products by category: {str(e)}"", exc_info=True)
            raise
",codebase-architectures/layered-architecture/services/product_service.py,ProductService,1,1.8189616842444243e-09,"The method 'get_products_by_category' is likely to survive because it performs a common and essential operation in many applications: retrieving products based on a category. This functionality is crucial for e-commerce platforms, inventory management systems, and any application dealing with categorized data. Additionally, the method includes error handling and logging, which are good practices for maintaining robust and debuggable code."
survived,"def save_json_file(data, file_path):
    """"""Save data to a JSON file.""""""
    directory = os.path.dirname(file_path)
    if directory and not os.path.exists(directory):
        os.makedirs(directory)
    
    with open(file_path, 'w') as file:
        json.dump(data, file, indent=2)
",codebase-architectures/pipeline-architecture/shared/utilities.py,,1,1.1032560311263802e-09,"The method 'save_json_file' is a utility function that handles a common task: saving data to a JSON file. It includes functionality to create directories if they do not exist, which adds robustness and convenience. Such utility functions are often reused across different projects and are unlikely to be deleted unless they are replaced by a more efficient or comprehensive library function. However, the current implementation is straightforward and effective for its purpose, making it likely to survive."
survived,"    def __init__(self):
        """"""Initialize the input stage.""""""
        self.data = None
        self.metadata = {
            ""stage"": ""input"",
            ""status"": ""initialized"",
            ""errors"": []
        }
",codebase-architectures/pipeline-architecture/pipeline/input_stage.py,InputStage,1,6.825604231969389e-08,"The method is a constructor (__init__) which is fundamental for initializing objects in Python. It sets up initial values for instance variables, which is a core part of object-oriented programming. The presence of a constructor is essential for creating instances of a class, and it is unlikely to be removed unless the entire class is being deprecated or refactored significantly. Additionally, the method includes a docstring, which suggests that it is part of a well-documented codebase, further indicating its importance and likelihood of being retained."
survived,"def get_user_by_id(user_id: str) -> Optional[Dict]:
    """"""
    Get a user by ID.
    
    Args:
        user_id: The user ID to look up
        
    Returns:
        User data dictionary if found, None otherwise
    """"""
    for user_data in USER_STORE.values():
        if user_data[""id""] == user_id:
            return {k: v for k, v in user_data.items() if k not in [""hashed_password"", ""salt""]}
    return None",codebase-architectures/atomic-composable-architecture/modules/auth.py,,1,8.592166611791576e-10,"The method 'get_user_by_id' is likely to survive because it performs a common and necessary operation of retrieving user data by ID from a data store. It includes a security measure by excluding sensitive information like 'hashed_password' and 'salt' from the returned data, which is a good practice. Additionally, the method is well-documented, specifying its purpose, arguments, and return value, making it easy to understand and maintain."
survived,"    def register(username: str, password: str, email: str) -> Dict:
        """"""
        Register a new user.
        
        Args:
            username: The username for the new user
            password: The password for the new user
            email: The email for the new user
            
        Returns:
            Response with success status and user data or error message
        """"""
        success, result = register_new_user(username, password, email)
        
        if success:
            return {
                ""status"": ""success"",
                ""message"": ""User registered successfully"",
                ""data"": result
            }
        else:
            return {
                ""status"": ""error"",
                ""message"": result.get(""error"", ""Registration failed""),
                ""data"": None
            }
",codebase-architectures/atomic-composable-architecture/endpoints/user_api.py,UserAPI,1,8.152020648014727e-09,"The method 'register' is a fundamental part of user management systems, handling the registration of new users. It includes input validation, error handling, and returns a structured response, which are all best practices in software development. The method is likely to be retained as it provides essential functionality for applications that require user accounts."
survived,"def register_new_user(username: str, password: str, email: str) -> Tuple[bool, Dict]:
    """"""
    Register a new user with validation.
    
    Args:
        username: The username for the new user
        password: The password for the new user
        email: The email for the new user
        
    Returns:
        Tuple of (success, result) where result is either user data or error messages
    """"""
    # Validate required fields
    missing_fields = validate_required_fields(
        {""username"": username, ""password"": password, ""email"": email},
        [""username"", ""password"", ""email""]
    )
    
    if missing_fields:
        return False, {""error"": f""Missing required fields: {', '.join(missing_fields)}""}
    
    # Validate username
    if not validate_username(username):
        return False, {""error"": ""Username must be 3-20 characters, alphanumeric with underscores""}
    
    # Validate email
    if not validate_email(email):
        return False, {""error"": ""Invalid email format""}
    
    # Validate password strength
    password_validation = validate_password_strength(password)
    if not password_validation[""is_valid""]:
        errors = []
        if not password_validation[""length""]:
            errors.append(""Password must be at least 8 characters"")
        if not password_validation[""uppercase""]:
            errors.append(""Password must contain at least one uppercase letter"")
        if not password_validation[""lowercase""]:
            errors.append(""Password must contain at least one lowercase letter"")
        if not password_validation[""digit""]:
            errors.append(""Password must contain at least one digit"")
        if not password_validation[""special_char""]:
            errors.append(""Password must contain at least one special character"")
        
        return False, {""error"": errors}
    
    try:
        # Register the user
        user_data = register_user(username, password, email)
        return True, {""user"": user_data}
    except ValueError as e:
        return False, {""error"": str(e)}
",codebase-architectures/atomic-composable-architecture/capabilities/user_management.py,,1,8.152020648014727e-09,"The method 'register_new_user' is a well-structured function that handles user registration with comprehensive validation checks for required fields, username, email, and password strength. It also provides clear error messages and handles exceptions, making it robust and useful in a user registration context. Such functionality is essential in many applications, and the method is likely to be retained for its utility and completeness."
survived,"    def calculate_statistics(self, numeric_fields=None):
        """"""
        Calculate statistics for numeric fields in the data.
        
        Args:
            numeric_fields: List of field names to calculate statistics for
        
        Returns:
            dict: Stage result with data and metadata
        """"""
        if self.data is None:
            self.metadata[""status""] = ""error""
            self.metadata[""errors""].append(""No data to process"")
            return self._create_result()
        
        try:
            # Determine fields to analyze
            if numeric_fields is None:
                # Try to automatically detect numeric fields
                if isinstance(self.data, list) and len(self.data) > 0:
                    sample = self.data[0]
                    numeric_fields = [
                        field for field, value in sample.items()
                        if isinstance(value, (int, float)) or (
                            isinstance(value, str) and value.replace('.', '', 1).isdigit()
                        )
                    ]
            
            # Calculate statistics
            stats = {}
            if isinstance(self.data, list) and numeric_fields:
                for field in numeric_fields:
                    try:
                        # Extract numeric values
                        values = []
                        for item in self.data:
                            if field in item:
                                value = item[field]
                                if isinstance(value, (int, float)):
                                    values.append(value)
                                elif isinstance(value, str) and value.replace('.', '', 1).isdigit():
                                    values.append(float(value))
                        
                        # Calculate statistics if we have values
                        if values:
                            field_stats = {
                                ""count"": len(values),
                                ""min"": min(values),
                                ""max"": max(values),
                                ""sum"": sum(values),
                                ""mean"": statistics.mean(values),
                                ""median"": statistics.median(values)
                            }
                            
                            # Add standard deviation if we have enough values
                            if len(values) > 1:
                                field_stats[""std_dev""] = statistics.stdev(values)
                            
                            stats[field] = field_stats
                    except Exception as e:
                        self.metadata[""errors""].append(f""Error calculating statistics for field '{field}': {str(e)}"")
            
            # Add statistics to data
            if not hasattr(self, ""analysis""):
                self.analysis = {}
            self.analysis[""statistics""] = stats
            
            # Update metadata
            self.metadata[""processing_steps""].append(""calculate_statistics"")
            self.metadata[""statistics_fields""] = list(stats.keys())
            
            return self._create_result()
        except Exception as e:
            self.metadata[""status""] = ""error""
            self.metadata[""errors""].append(f""Statistics calculation error: {str(e)}"")
            return self._create_result()
",codebase-architectures/pipeline-architecture/pipeline/processing_stage.py,ProcessingStage,1,1.8189616842444243e-09,"The method `calculate_statistics` is a useful utility for calculating statistical measures on numeric fields within a dataset. It includes error handling, automatic detection of numeric fields, and calculates a variety of statistics such as count, min, max, sum, mean, median, and standard deviation. These features make it a valuable tool for data analysis, and it is likely to be retained in the codebase for its functionality and robustness."
survived,"def display_response(response):
    """"""Display an API response.""""""
    status = response[""status""]
    message = response[""message""]
    data = response[""data""]
    
    if status == ""success"":
        print(f""‚úÖ {message}"")
    else:
        print(f""‚ùå {message}"")
    
    if data:
        if isinstance(data, dict):
            for key, value in data.items():
                if key == ""user"":
                    print(""\nUser:"")
                    for user_key, user_value in value.items():
                        print(f""  {user_key}: {user_value}"")
                elif key == ""alerts"":
                    print(""\nAlerts:"")
                    for i, alert in enumerate(value):
                        print(f""\nAlert {i+1}:"")
                        print(f""  Message: {alert['message']}"")
                        print(f""  Type: {alert['type']}"")
                        print(f""  Level: {alert['data'].get('level', 'N/A')}"")
                        print(f""  Read: {'Yes' if alert['is_read'] else 'No'}"")
                else:
                    print(f""\n{key.capitalize()}:"")
                    if isinstance(value, dict):
                        for sub_key, sub_value in value.items():
                            print(f""  {sub_key}: {sub_value}"")
                    else:
                        print(f""  {value}"")
",codebase-architectures/atomic-composable-architecture/main.py,,1,3.2241866333029355e-08,"The method 'display_response' is a utility function designed to format and display API responses in a user-friendly manner. Such functions are generally useful for debugging, logging, or providing feedback to users in applications that interact with APIs. Given the increasing reliance on APIs in modern software development, this method is likely to remain relevant and useful. It handles different types of data structures and provides clear output, which are valuable features in software development."
survived,"    def __init__(self, name=""Data Processing Pipeline""):
        """"""Initialize the pipeline manager.""""""
        self.name = name
        self.stages = []
        self.results = {}
        self.metadata = {
            ""pipeline_name"": name,
            ""status"": ""initialized"",
            ""started_at"": None,
            ""completed_at"": None,
            ""errors"": []
        }
",codebase-architectures/pipeline-architecture/pipeline/pipeline_manager.py,PipelineManager,1,1.8189616842444243e-09,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. It initializes important attributes such as 'name', 'stages', 'results', and 'metadata', which are likely essential for the functionality of the class. Constructors are rarely deleted unless the class itself is being removed or significantly refactored, which is not indicated here. Therefore, it is likely to survive."
survived,"    def debug(logger, message):
        """"""Log a debug message.""""""
        logger.debug(message)
",codebase-architectures/layered-architecture/utils/logger.py,Logger,1,8.592166611791576e-10,"The method 'debug' is a simple utility function that wraps a common logging operation. It provides a clear and concise way to log debug messages using a logger object. Such utility functions are often kept in codebases to promote code reuse and maintainability. Since logging is a fundamental part of software development for monitoring and debugging purposes, this method is likely to be retained in the codebase."
survived,"    def get_category(category_id):
        """"""Get a category by ID.""""""
        try:
            category_data = db.get(""categories"", category_id)
            if not category_data:
                Logger.warning(app_logger, f""Category not found: {category_id}"")
                return None
            return category_data
        except Exception as e:
            Logger.error(app_logger, f""Error getting category: {str(e)}"", exc_info=True)
            raise
",codebase-architectures/layered-architecture/services/category_service.py,CategoryService,1,8.592166611791576e-10,"The method 'get_category' is a straightforward function that retrieves a category by its ID from a database. It includes error handling and logging, which are good practices for maintaining robust code. The method is likely to be useful in many applications where category data needs to be fetched, and it handles both the case where the category is not found and where an exception occurs. These features make it a well-rounded and necessary function in a codebase that deals with categories, suggesting it will be retained."
survived,"    def get_user_tasks(user_id):
        """"""Get all tasks for a specific user.""""""
        all_tasks = db.get_all(""tasks"")
        return [task for task in all_tasks if task.get(""user_id"") == user_id]
",codebase-architectures/vertical-slice-architecture/features/tasks/service.py,TaskService,1,2.3355930333443423e-09,"The method 'get_user_tasks' is a simple utility function that filters tasks based on a user ID. It is likely to survive because it performs a common and necessary operation in applications that manage user-specific data. The method is straightforward, easy to understand, and does not have any apparent issues that would necessitate its removal. Additionally, it is likely to be used in various parts of an application where user-specific task retrieval is needed."
survived,"    def delete_category(category_id):
        """"""Delete a category.""""""
        try:
            result = CategoryService.delete_category(category_id)
            if not result:
                return {
                    ""success"": False,
                    ""message"": f""Category with ID {category_id} not found""
                }
            return {
                ""success"": True,
                ""message"": ""Category deleted successfully""
            }
        except ValueError as e:
            Logger.warning(app_logger, f""Validation error in delete_category: {str(e)}"")
            return {
                ""success"": False,
                ""message"": str(e)
            }
        except Exception as e:
            Logger.error(app_logger, f""Error in delete_category: {str(e)}"", exc_info=True)
            return {
                ""success"": False,
                ""message"": ""An error occurred while deleting the category""
            }",codebase-architectures/layered-architecture/api/category_api.py,CategoryAPI,1,5.905303995456778e-10,"The method 'delete_category' is well-structured and handles potential errors effectively. It uses try-except blocks to catch specific exceptions like ValueError and a general Exception, logging appropriate messages for each. This makes the method robust and reliable for handling category deletion operations. Additionally, it provides clear feedback to the caller about the success or failure of the operation, which is crucial for user experience and debugging. Therefore, the method is likely to be retained as it fulfills its purpose efficiently and follows good coding practices."
survived,"    def get_user(user_id):
        """"""Get a user by ID.""""""
        user_data = db.get(""users"", user_id)
        if not user_data:
            return None
        return user_data
",codebase-architectures/vertical-slice-architecture/features/users/service.py,UserService,1,8.592166611791576e-10,"The method `get_user` is a simple utility function that retrieves user data from a database using a user ID. It is a fundamental operation in many applications that require user management. The method is straightforward, performs a necessary task, and handles the case where the user is not found by returning `None`. This makes it a useful and likely necessary part of the codebase, especially in applications that involve user accounts or profiles. Therefore, it is likely to be retained."
survived,"    def add_stage(self, stage_name, stage_instance):
        """"""
        Add a stage to the pipeline.
        
        Args:
            stage_name: Name of the stage
            stage_instance: Instance of the stage class
        """"""
        self.stages.append({
            ""name"": stage_name,
            ""instance"": stage_instance,
            ""status"": ""pending""
        })
",codebase-architectures/pipeline-architecture/pipeline/pipeline_manager.py,PipelineManager,1,5.60279640614594e-09,"The method `add_stage` is a fundamental part of managing a pipeline structure, which is a common pattern in software development for processing data or tasks in stages. This method allows for the dynamic addition of stages to a pipeline, which is essential for flexibility and scalability in pipeline management. The method is straightforward, well-documented, and serves a clear purpose, making it unlikely to be removed unless the entire pipeline architecture is refactored or replaced."
survived,"    def update_user(user_id, user_data):
        """"""Update a user.""""""
        existing_user = db.get(""users"", user_id)
        if not existing_user:
            return None
        
        # Check if username is being changed and already exists
        if ""username"" in user_data and user_data[""username""] != existing_user[""username""]:
            all_users = db.get_all(""users"")
            if any(user[""username""] == user_data[""username""] for user in all_users if user[""id""] != user_id):
                raise ValueError(f""Username '{user_data['username']}' already exists"")
        
        # Update fields
        for key, value in user_data.items():
            if key not in [""id"", ""created_at""]:
                existing_user[key] = value
        
        # Update timestamp
        existing_user[""updated_at""] = get_timestamp()
        
        # Save to database
        db.update(""users"", user_id, existing_user)
        return existing_user
",codebase-architectures/vertical-slice-architecture/features/users/service.py,UserService,1,3.850741907939403e-09,"The method 'update_user' is a crucial part of user management in a database-driven application. It handles updating user information while ensuring data integrity by checking for unique usernames and preventing changes to immutable fields like 'id' and 'created_at'. The method also updates the 'updated_at' timestamp to reflect changes, which is a common practice in database operations. These functionalities are essential for maintaining accurate and consistent user data, making it unlikely for this method to be deleted."
survived,"    def _create_file(self, path: str, file_text: str) -> FileOperationResult:
        """"""
        Create a new file with specified content.

        Args:
            path: The path where the new file should be created
            file_text: The content to write to the new file

        Returns:
            FileOperationResult with result or error message
        """"""
        try:
            # Check if the path is empty or invalid
            if not path or not path.strip():
                error_msg = ""Invalid file path provided: path is empty.""
                console.log(f""[create_file] Error: {error_msg}"")
                return FileOperationResult(False, error_msg)

            # Normalize the path
            path = normalize_path(path)

            # Check if the directory exists
            directory = os.path.dirname(path)
            if directory and not os.path.exists(directory):
                console.log(f""[create_file] Creating directory: {directory}"")
                os.makedirs(directory)

            with open(path, ""w"") as f:
                f.write(file_text or """")

            console.print(f""[green]Successfully created file {path}[/green]"")
            console.log(f""[create_file] Successfully created file {path}"")
            return FileOperationResult(True, f""Successfully created file {path}"")
        except Exception as e:
            error_msg = f""Error creating file: {str(e)}""
            console.print(f""[red]{error_msg}[/red]"")
            console.log(f""[create_file] Error: {str(e)}"")
            console.log(traceback.format_exc())
            return FileOperationResult(False, error_msg)
",example-agent-codebase-arch/pipeline-architecture/steps/processing_stage.py,ProcessingStage,1,1.522997951276035e-08,"The method '_create_file' is well-structured and serves a common utility function of creating files with specified content. It includes error handling, logging, and directory creation if needed, which are all useful features. The method is likely to be used in various applications where file creation is necessary, making it a valuable part of the codebase. Therefore, it is unlikely to be deleted."
survived,"def display_token_usage(input_tokens: int, output_tokens: int) -> None:
    """"""
    Display token usage information in a rich formatted table

    Args:
        input_tokens: Number of input tokens used
        output_tokens: Number of output tokens used
    """"""
    total_tokens = input_tokens + output_tokens
    token_ratio = output_tokens / input_tokens if input_tokens > 0 else 0

    # Create a table for token usage
    table = Table(title=""Token Usage Statistics"", expand=True)

    # Add columns with proper styling
    table.add_column(""Metric"", style=""cyan"", no_wrap=True)
    table.add_column(""Count"", style=""magenta"", justify=""right"")
    table.add_column(""Percentage"", justify=""right"")

    # Add rows with data
    table.add_row(
        ""Input Tokens"", f""{input_tokens:,}"", f""{input_tokens/total_tokens:.1%}""
    )
    table.add_row(
        ""Output Tokens"", f""{output_tokens:,}"", f""{output_tokens/total_tokens:.1%}""
    )
    table.add_row(""Total Tokens"", f""{total_tokens:,}"", ""100.0%"")
    table.add_row(""Output/Input Ratio"", f""{token_ratio:.2f}"", """")

    console.print()
    console.print(table)
",example-agent-codebase-arch/pipeline-architecture/shared/utilities.py,,1,2.8453347280241004e-08,"The method 'display_token_usage' is well-defined and provides a useful functionality of displaying token usage statistics in a formatted table. It includes input validation, handles edge cases (like division by zero), and uses a clear and structured approach to present data. Such utility functions are often retained as they provide clear insights into resource usage, which is valuable for monitoring and optimization purposes."
survived,"def test_multimodal_agent_with_image_url():
    """"""
    Test that a multimodal agent can process images without validation errors.
    This test reproduces the scenario from issue #2475.
    """"""
    OPENAI_API_KEY = os.getenv(""OPENAI_API_KEY"")
    if not OPENAI_API_KEY:
        pytest.skip(""OPENAI_API_KEY environment variable not set"")

    llm = LLM(
        model=""openai/gpt-4o"",  # model with vision capabilities
        api_key=OPENAI_API_KEY,
        temperature=0.7
    )

    expert_analyst = Agent(
        role=""Visual Quality Inspector"",
        goal=""Perform detailed quality analysis of product images"",
        backstory=""Senior quality control expert with expertise in visual inspection"",
        llm=llm,
        verbose=True,
        allow_delegation=False,
        multimodal=True
    )

    inspection_task = Task(
        description=""""""
        Analyze the product image at https://www.us.maguireshoes.com/collections/spring-25/products/lucena-black-boot with focus on:
        1. Quality of materials
        2. Manufacturing defects
        3. Compliance with standards
        Provide a detailed report highlighting any issues found.
        """""",
        expected_output=""A detailed report highlighting any issues found"",
        agent=expert_analyst
    )

    crew = Crew(agents=[expert_analyst], tasks=[inspection_task])",tests/test_multimodal_validation.py,,1,9.931195248674785e-08,"The method is a test function designed to verify the functionality of a multimodal agent in processing images. It is relevant for ensuring the robustness of the system, especially in light of a previously reported issue (#2475). Test functions are generally retained as they are crucial for maintaining software quality and reliability. Additionally, the test is conditional on the presence of an API key, which is a common practice to ensure tests are only run in appropriate environments."
survived,"    def get_units(self, wallet_client: EVMWalletClient, parameters: dict):
        result = wallet_client.read(
            {
                ""address"": parameters[""poolAddress""],
                ""abi"": POOL_ABI,
                ""functionName"": ""getUnits"",
                ""args"": [parameters[""memberAddr""]],
            }
        )
        return result[""value""]
",python/src/plugins/superfluid/goat_plugins/superfluid/service.py,SuperfluidService,1,5.211412485172657e-10,"The method 'get_units' is a straightforward utility function that interacts with a blockchain wallet client to retrieve data using a specified ABI and function name. It is well-structured, with clear input parameters and a direct return of the result. This method is likely to be useful in contexts where blockchain interactions are needed, especially in applications dealing with Ethereum Virtual Machine (EVM) compatible chains. Given the increasing use of blockchain technology and the need for such utility functions, this method is likely to survive."
survived,"    def get_flowrate(self, wallet_client: EVMWalletClient, parameters: dict):
        result = wallet_client.read(
            {
                ""address"": self.CFA_FORWARDER_ADDRESS,
                ""abi"": CFA_FORWARDER_ABI,
                ""functionName"": ""getFlowrate"",
                ""args"": [parameters[""token""], parameters[""sender""], parameters[""receiver""]],
            }
        )
        return result[""value""]
",python/src/plugins/superfluid/goat_plugins/superfluid/service.py,SuperfluidService,1,1.6052280526088547e-09,"The method 'get_flowrate' is a utility function that interacts with a blockchain wallet client to retrieve the flow rate of a token between a sender and a receiver. This functionality is specific and useful for applications dealing with blockchain transactions, particularly in environments using the Ethereum Virtual Machine (EVM). The method is well-defined, uses parameters effectively, and leverages the wallet client's 'read' method to perform its task. Given the increasing use of blockchain technology and the need for such utility functions in decentralized applications, it is likely that this method will survive."
survived,"    def flow(self, wallet_client: EVMWalletClient, parameters: dict) -> str:
        """"""Create, update, or delete a flow of tokens.""""""
        try:
            # Convert flowrate to int96 and validate bounds
            try:
                # Handle special case for flow deletion
                if parameters[""flowrate""] == ""0"":
                    flowrate = 0
                else:
                    # Convert to integer, handling both decimal and hex strings
                    flowrate = int(parameters[""flowrate""], 16 if parameters[""flowrate""].startswith(""0x"") else 10)
                    
                    # Validate int96 bounds (-2^95 to 2^95-1)
                    if not (-2**95 <= flowrate <= 2**95 - 1):
                        raise ValueError(""Flowrate must be within int96 bounds"")
                    
                    # Ensure minimum positive flowrate for creation/updates (1000 wei/second)
                    if flowrate > 0 and flowrate < 1000:
                        raise ValueError(""Minimum flowrate must be at least 1000 wei/second"")
            except ValueError as e:
                raise Exception(f""Invalid flowrate value: {e}"")

            # For non-zero flowrates, approve CFA_FORWARDER_ADDRESS to spend tokens
            if flowrate > 0:
                try:
                    # First check current allowance
                    allowance = wallet_client.read({
                        ""address"": parameters[""token""],
                        ""abi"": ERC20_ABI,
                        ""functionName"": ""allowance"",
                        ""args"": [wallet_client.get_address(), self.CFA_FORWARDER_ADDRESS],
                    })

                    # Calculate required allowance (30 days worth of flow)
                    required_allowance = flowrate * 60 * 60 * 24 * 30

                    # If allowance is insufficient, approve max uint256
                    if int(allowance[""value""]) < required_allowance:
                        approve_result = wallet_client.send_transaction({
                            ""to"": parameters[""token""],
                            ""abi"": ERC20_ABI,
                            ""functionName"": ""approve"",
                            ""args"": [self.CFA_FORWARDER_ADDRESS, 2**256 - 1],  # Max uint256
                        })
                        # Wait for approval transaction to be mined
                        if not approve_result.get(""hash""):
                            raise Exception(""Approval transaction failed"")
                except Exception as e:
                    raise Exception(f""Failed to approve token spending: {e}"")

            # Create/update/delete flow with resolved addresses
            token = wallet_client.resolve_address(parameters[""token""])
            receiver = wallet_client.resolve_address(parameters[""receiver""])
            result = wallet_client.send_transaction(
                {
                    ""to"": self.CFA_FORWARDER_ADDRESS,
                    ""abi"": CFA_FORWARDER_ABI,
                    ""functionName"": ""setFlowrate"",
                    ""args"": [token, receiver, flowrate],
                }
            )
            return result[""hash""]
        except Exception as error:
            raise Exception(f""Failed to set flow: {error}"")
",python/src/plugins/superfluid/goat_plugins/superfluid/service.py,SuperfluidService,1,4.363462233903899e-09,"The method 'flow' is a well-structured and comprehensive function that handles the creation, update, or deletion of token flows. It includes error handling, validation of input parameters, and interaction with a wallet client to manage token allowances and transactions. The method is likely to be useful in applications dealing with token flows on blockchain platforms, particularly those using Ethereum Virtual Machine (EVM) compatible chains. Given its functionality and the increasing relevance of blockchain technology, this method is likely to survive."
survived,"    def __init__(self, options: JSONRpcPluginOptions):
        super().__init__(""jsonrpc"", [JSONRpcService(options.endpoint)])
",python/src/plugins/jsonrpc/goat_plugins/jsonrpc/__init__.py,JSONRpcPlugin,1,4.363462233903899e-09,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting up initial states. This particular constructor is initializing a superclass and setting up a JSON RPC service, which suggests it is part of a larger framework or application. Such methods are typically not deleted unless the entire class is being refactored or removed, which is not indicated here. Therefore, it is likely to survive."
deleted,"    def should_include_file(file_path):
        """"""Check if a file should be included based on patterns and exclusions.""""""
        path_parts = Path(file_path).parts
        
        if any(part in excluded_names for part in path_parts):
            return False
            
        if file_path.endswith(('.md', '.mdx')):
            return True
            
        return False
",docs/compile_llms_txt.py,,1,1.2501528648238603e-09,"The method 'should_include_file' is a utility function that checks if a file should be included based on certain conditions. It is straightforward, performs a specific task, and is likely useful in contexts where file filtering is needed. The method is not overly complex and does not have any apparent issues that would necessitate its removal. Therefore, it is likely to be retained in the codebase."
survived,"    def supports_function_calling(self) -> bool:
        """"""Return True to indicate that function calling is supported.""""""
        return True
",tests/custom_llm_test.py,CustomLLM,1,8.152020648014727e-09,"The method 'supports_function_calling' is a simple, clear, and self-explanatory method that returns a boolean value indicating whether function calling is supported. It is likely part of a larger interface or class that needs to communicate this capability. Such methods are often kept for clarity and explicitness, especially if the class or interface is designed to be extended or used in various contexts where this capability might be conditional. Therefore, it is likely to be retained."
