status,method,filepath,class_name,predict,prob_deleted,reason
survived,"def test_positional_param_removed():
    old_code = ""def func(a, b, c): pass""
    new_code = ""def func(a, b): pass""

    old_tree = ast.parse(old_code)
    new_tree = ast.parse(new_code)
    errors = check_signature_compatibility(old_tree.body[0], new_tree.body[0])

    assert len(errors) == 1
    assert errors[0].message == ""Positional param 'c' was removed.""
    assert errors[0].param_name == ""c""
",tests/dev/test_check_function_signatures.py,,1,3.160881453314576e-10,"The method 'test_positional_param_removed' is a unit test designed to verify that a specific error is raised when a positional parameter is removed from a function signature. This is a valid and useful test case for ensuring backward compatibility in code changes. It checks that the function 'check_signature_compatibility' correctly identifies the removal of a parameter and raises the appropriate error. Such tests are crucial for maintaining code quality and preventing regressions, so it is likely to be retained in the codebase."
survived,"def get_tooltip_data(df):
    """"""Return the tooltip data in a format suitable for JSON serialization.""""""
    return df.to_dict()
",triton_viz/visualizer/tooltip.py,,1,4.944450477491054e-09,"The method `get_tooltip_data` is a simple utility function that converts a DataFrame to a dictionary format, which is a common operation when preparing data for JSON serialization. This functionality is useful in many data processing and web development contexts where data needs to be sent from a server to a client in a JSON format. The method is straightforward, does not have any apparent issues, and serves a clear purpose. Therefore, it is likely to be retained in the codebase."
survived,"def serialize_for_json(obj):
    if isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, torch.Tensor):
        return obj.cpu().numpy().tolist()
    raise TypeError(f""Object of type {obj.__class__.__name__} is not JSON serializable"")",triton_viz/visualizer/draw.py,,1,5.60279640614594e-09,"The method 'serialize_for_json' is a utility function designed to convert various data types, particularly those from numpy and PyTorch, into formats that can be easily serialized into JSON. This is a common requirement in data processing and machine learning applications where data needs to be saved or transmitted in a JSON format. The function handles numpy arrays, numpy integers, numpy floating-point numbers, and PyTorch tensors, which are frequently used in scientific computing and deep learning. Given its utility and the increasing use of these libraries, the method is likely to be useful and relevant, thus it is likely to survive."
survived,"def stop_server(flask_thread):
    # Implement a way to stop the Flask server
    pass",triton_viz/visualizer/interface.py,,0,0.9999998874648162,"The method `stop_server` is currently a placeholder with no implementation. It is intended to stop a Flask server, which is a common requirement in web applications. However, without any implementation details, it doesn't serve any functional purpose. If the method remains unimplemented, it is likely to be deleted in the future as it doesn't contribute to the codebase. However, if the need to stop the server is crucial, it might be implemented later. For now, given its current state, it is more likely to be deleted."
deleted,"def precompute_c_values(op_data):
    input_data = op_data[""input_data""]
    other_data = op_data[""other_data""]
    rows, inner_dim = input_data.shape
    cols = other_data.shape[1]

    precomputed = {}
    for i in range(rows):
        for j in range(cols):
            precomputed[(i, j)] = [0] * (inner_dim + 1)
            for k in range(1, inner_dim + 1):
                precomputed[(i, j)][k] = torch.dot(
                    input_data[i, :k], other_data[:k, j]
                ).item()

    return precomputed
",triton_viz/visualizer/interface.py,,0,0.999998790133938,"The method 'precompute_c_values' is likely to be deleted because it has several inefficiencies and potential issues. Firstly, it uses nested loops which can be computationally expensive, especially for large datasets. Secondly, it relies on the 'torch.dot' function, which suggests a dependency on PyTorch, but this is not explicitly mentioned or imported in the code snippet. Additionally, the method's purpose is not clear from its name or implementation, which can lead to maintenance challenges. These factors combined suggest that the method might be refactored or removed in favor of a more efficient and clear solution."
survived,"def pandas_static_corrmatrix(a):
    """"""Compute correlation matrix using pandas.""""""
    df = pandas_matrix_setup(a)
    return lambda: df.corr()
",numbagg/test/conftest.py,,1,1.4166087846364157e-09,"The method `pandas_static_corrmatrix` is likely to be Survived (1) because it provides a useful functionality of computing a correlation matrix using pandas, which is a common requirement in data analysis. The method is concise and leverages pandas' built-in capabilities to perform a standard operation efficiently. Unless there are changes in the requirements or the method is replaced by a more efficient or necessary alternative, it is likely to remain useful."
survived,"def move_nancovmatrix(a, window, min_count, out):
    """"""
    Moving window covariance matrix gufunc.

    For 2D input, computes covariance between variables (rows) across observations (columns in the window).
    """"""
    n_vars = a.shape[0]
    n_obs = a.shape[1]
    min_count = max(min_count, 1)

    # Initialize running statistics
    sums = np.zeros(n_vars, dtype=a.dtype)
    counts = np.zeros(n_vars, dtype=np.int64)

    # Initialize pairwise statistics
    prods = np.zeros((n_vars, n_vars), dtype=a.dtype)
    pair_counts = np.zeros((n_vars, n_vars), dtype=np.int64)

    for t in range(n_obs):
        # Remove old values when window slides
        if t >= window:
            for i in range(n_vars):
                old_val = a[i, t - window]
                if not np.isnan(old_val):
                    sums[i] -= old_val
                    counts[i] -= 1

                    # Update pairwise products
                    for j in range(n_vars):
                        old_val_j = a[j, t - window]
                        if not np.isnan(old_val_j):
                            prods[i, j] -= old_val * old_val_j
                            pair_counts[i, j] -= 1

        # Add new values
        for i in range(n_vars):
            new_val = a[i, t]
            if not np.isnan(new_val):
                sums[i] += new_val
                counts[i] += 1

                # Update pairwise products
                for j in range(n_vars):
                    new_val_j = a[j, t]
                    if not np.isnan(new_val_j):
                        prods[i, j] += new_val * new_val_j
                        pair_counts[i, j] += 1

        # Compute covariance matrix for current window
        for i in range(n_vars):
            for j in range(n_vars):
                n = pair_counts[i, j]
                if n >= min_count:
                    if n > 1:
                        # Unbiased covariance with ddof=1
                        cov = (prods[i, j] - sums[i] * sums[j] / n) / (n - 1)
                        out[t, i, j] = cov
                    else:
                        # n == 1, covariance is undefined (requires at least 2 points)
                        out[t, i, j] = np.nan
                else:
                    out[t, i, j] = np.nan",numbagg/moving_matrix.py,,1,2.5109990926928157e-08,"The method 'move_nancovmatrix' is a specialized function for computing a moving window covariance matrix, which is a common requirement in time series analysis and data processing. It handles missing data (NaNs) gracefully, which is a valuable feature in real-world datasets. The function is well-documented, and its implementation is efficient for the task it performs. Given the utility and specificity of this function, it is likely to be retained in a codebase where such functionality is needed."
survived,"    def test_with_nans(self, func):
        """"""Test with NaN values.""""""
        data = np.array(
            [[1, 2, np.nan, 4], [2, 4, 6, np.nan], [np.nan, 1, 2, 3]], dtype=np.float64
        )
        result = func(data)

        # Check shape and symmetry
        assert result.shape == (3, 3)
        assert_allclose(result, result.T, equal_nan=True)

        # For correlation, check diagonal is 1 where not NaN
        if func == nancorrmatrix:
            assert_allclose(np.diag(result), [1.0, 1.0, 1.0])
",numbagg/test/test_matrix_functions.py,TestMatrixFunctions,1,8.76424914819242e-08,"The method 'test_with_nans' is a unit test designed to verify the behavior of a function when handling NaN values. It checks the shape, symmetry, and specific properties of the result, which are crucial for ensuring the correctness of functions dealing with NaN values, such as correlation matrices. Given the importance of testing edge cases like NaN handling in data processing, this method is likely to be retained as it provides valuable validation for the function it tests."
survived,"    def test_single_variable(self, func):
        """"""Test with single variable (1x1 matrix).""""""
        data = np.array([[1, 2, 3, 4]], dtype=np.float64)
        alpha = 0.4
        result = func(data, alpha=alpha)

        # Check shape
        assert result.shape == (4, 1, 1)

        # Diagonal should be 1 for correlation (once we have enough data), positive for covariance
        if func == move_exp_nancorrmatrix:
            # First time step might be NaN, but later ones should be 1.0
            assert (
                np.isnan(result[0, 0, 0]) or result[0, 0, 0] == 1.0
            )  # First might be NaN
            assert_allclose(
                result[1:, 0, 0], [1.0, 1.0, 1.0], rtol=1e-10
            )  # Later should be 1
        else:
            # For covariance, check finite values are non-negative
            finite_mask = np.isfinite(result[:, 0, 0])
            assert np.all(result[finite_mask, 0, 0] >= 0)
",numbagg/test/test_move_exp_matrix.py,TestMoveExpMatrixFunctions,1,4.1399375473943306e-08,"The method `test_single_variable` is a unit test designed to verify the behavior of a function that calculates either a moving exponential correlation matrix or covariance matrix. It is a specific test case that checks the output for a single variable input, ensuring the function handles this edge case correctly. Unit tests are crucial for maintaining code quality and ensuring that changes do not introduce bugs. Therefore, this method is likely to be retained as part of the test suite to ensure the reliability of the function it tests."
survived,"    def test_covariance_with_nans(self):
        """"""Test consistency with NaN values.""""""
        np.random.seed(456)

        # Create two time series with some NaN values
        n_obs = 30
        a1 = np.random.randn(n_obs)
        a2 = np.random.randn(n_obs) * 2

        # Add some NaN values
        a1[5:8] = np.nan
        a2[15:17] = np.nan

        alpha = 0.3

        # Compute using non-matrix function
        cov_nonmatrix = move_exp_nancov(a1, a2, alpha=alpha)

        # Compute using matrix function
        data_matrix = np.array([a1, a2])
        cov_matrix_result = move_exp_nancovmatrix(data_matrix, alpha=alpha)
        cov_from_matrix = cov_matrix_result[:, 0, 1]

        # They should match
        assert_allclose(cov_nonmatrix, cov_from_matrix, rtol=1e-10)
",numbagg/test/test_move_exp_matrix_consistency.py,TestMoveExpMatrixConsistency,1,1.3440409770490404e-08,"The method is a unit test that verifies the consistency of two different implementations of a covariance calculation function when handling NaN values. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with edge cases like NaNs. This test helps maintain the integrity of the covariance functions, making it unlikely to be deleted."
survived,"    def test_single_valid_observation(self):
        """"""Test with only one valid observation per variable.""""""
        data = np.array(
            [[1.0, np.nan, np.nan, np.nan], [np.nan, 2.0, np.nan, np.nan]],
            dtype=np.float64,
        )

        result_corr = move_exp_nancorrmatrix(data, alpha=0.5)
        result_cov = move_exp_nancovmatrix(data, alpha=0.5)

        # Should have shape (4, 2, 2)
        assert result_corr.shape == (4, 2, 2)
        assert result_cov.shape == (4, 2, 2)

        # Most values should be NaN since we need at least 2 observations for correlation/covariance
        assert np.sum(np.isnan(result_corr)) > np.sum(np.isfinite(result_corr))
        assert np.sum(np.isnan(result_cov)) > np.sum(np.isfinite(result_cov))",numbagg/test/test_move_exp_matrix.py,TestMoveExpMatrixFunctions,1,3.653482080241728e-08,"The method `test_single_valid_observation` is a unit test designed to verify the behavior of the functions `move_exp_nancorrmatrix` and `move_exp_nancovmatrix` when provided with a dataset that has only one valid observation per variable. This is a valid test case to ensure that the functions handle edge cases correctly, particularly when there is insufficient data to compute meaningful correlation or covariance. The test checks the shape of the output and ensures that the majority of the results are NaN, which is the expected behavior when there are not enough observations. Since this test is useful for validating the robustness of the functions against edge cases, it is likely to be retained in the codebase."
survived,"    def _load_model_info(self, model_name: str) -> Optional[Dict[str, Any]]:
        """"""Load information about a specific model""""""
        from .scanner import ModelScanner
        
        scanner = ModelScanner(self.base_path)
        search_results = scanner.search_by_model_name(model_name)
        
        if not search_results['matches']:
            return None
        
        model_info = {
            'name': model_name,
            'files': [],
            'config': None,
            'metadata': {},
            'size': 0
        }
        
        # Collect all files from matches
        for category, files in search_results['matches'].items():
            for file_info in files:
                model_info['files'].append(file_info)
                model_info['size'] += file_info.get('size', 0)
                
                # Try to load config
                file_path = self.base_path / file_info['path']
                if file_path.name in ['config.json', 'model_config.json']:
                    try:
                        with open(file_path, 'r') as f:
                            model_info['config'] = json.load(f)
                    except:
                        pass
        
        return model_info
",src/haconiwa/scan/comparator.py,ModelComparator,1,5.211412485172657e-10,"The method '_load_model_info' is likely to survive because it performs a specific and useful function: loading and organizing information about a model based on its name. It uses a 'ModelScanner' to search for model files, aggregates file information, and attempts to load configuration data. This functionality is essential for applications that need to manage or utilize machine learning models, making it a valuable part of the codebase."
survived,"    def test_generate_for_pattern_fix(self):
        """"""Test pattern fix YAML generation""""""
        pattern = ""deprecated_api\\(\\)""
        fix_description = ""replace with new_api()""
        files = [
            'src/main.py',
            'src/utils.py',
            'src/api.py'
        ]
        
        config = self.generator.generate_for_pattern_fix(
            pattern,
            fix_description,
            files
        )
        
        assert config['provider'] == 'claude'
        assert config['metadata']['pattern'] == pattern
        assert config['metadata']['fix'] == fix_description
        assert len(config['tasks']) == 3
        
        # Check pattern fix prompts
        for task in config['tasks']:
            assert f""Find all occurrences of pattern '{pattern}'"" in task['prompt']
            assert fix_description in task['prompt']
        
        assert config['options']['permission_mode'] == 'acceptEdits'  # Auto-accept
",tests/test_scan/test_generate_parallel.py,TestParallelYAMLGenerator,1,9.931195248674785e-08,"The method `test_generate_for_pattern_fix` is a unit test designed to verify the functionality of a method that generates a configuration for fixing a specific pattern in code files. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with automated code modifications. The test checks various aspects of the generated configuration, such as the provider, metadata, tasks, and options, which are all important for validating the expected behavior of the `generate_for_pattern_fix` method. Since this test is essential for maintaining the integrity of the codebase and ensuring that the pattern fix generation works as intended, it is likely to be retained."
survived,"    def test_scan_generate_parallel_config_migration(self, runner):
        """"""Test generate-parallel-config for model migration""""""
        with tempfile.TemporaryDirectory() as tmpdir:
            output_path = Path(tmpdir) / ""migration.yaml""
            
            result = runner.invoke(
                scan_app,
                [""generate-parallel-config"",
                 ""--migration"", ""gpt-3.5:gpt-4"",
                 ""--max-files"", ""5"",
                 ""--output"", str(output_path)]
            )
            
            assert result.exit_code == 0
            assert ""Generated migration YAML"" in result.stdout
",tests/test_scan/test_cli.py,TestScanCLI,1,3.3982678079468468e-09,"The method is a test function that verifies the functionality of a command-line interface (CLI) tool. It uses a temporary directory to store output, checks the exit code of the command, and validates the output message. Such test functions are crucial for ensuring the reliability and correctness of software, especially when dealing with migrations and configurations. Therefore, it is likely to be maintained as part of the test suite to ensure ongoing functionality and correctness of the CLI tool."
survived,"    def _extract_files_from_matches(self, matches: Dict[str, List[Any]], max_files: int) -> List[str]:
        """"""Extract file paths from scan match results""""""
        files = []
        
        for category, file_list in matches.items():
            for file_info in file_list:
                if 'path' in file_info:
                    files.append(file_info['path'])
                    if len(files) >= max_files:
                        return files
        
        return files
",src/haconiwa/scan/generate_parallel.py,ParallelYAMLGenerator,1,3.160881453314576e-10,"The method '_extract_files_from_matches' is a utility function that extracts file paths from a dictionary of matches. It is well-defined, performs a specific task, and includes a mechanism to limit the number of files extracted, which is useful for managing large datasets. The method is likely to be useful in various contexts where file path extraction is needed, making it a candidate for survival."
survived,"    def _create_table(self, rows: List[Dict[str, Any]]) -> str:
        """"""Create ASCII table from rows""""""
        if not rows:
            return ""No data""
        
        # Get column names
        columns = list(rows[0].keys())
        
        # Calculate column widths
        widths = {}
        for col in columns:
            widths[col] = max(
                len(str(col)),
                max(len(str(row.get(col, ''))) for row in rows)
            )
        
        # Create header
        header = ""| "" + "" | "".join(col.ljust(widths[col]) for col in columns) + "" |""
        separator = ""+"" + ""+"".join(""-"" * (widths[col] + 2) for col in columns) + ""+""
        
        # Create rows
        lines = [separator, header, separator]
        
        for row in rows:
            line = ""| "" + "" | "".join(
                str(row.get(col, '')).ljust(widths[col]) for col in columns
            ) + "" |""
            lines.append(line)
        
        lines.append(separator)
        return ""\n"".join(lines)
",src/haconiwa/scan/formatter.py,OutputFormatter,1,2.5109990926928157e-08,"The method '_create_table' is a utility function that generates an ASCII table from a list of dictionaries. This is a common requirement in many applications for displaying tabular data in a text-based format. The method is well-structured, handles edge cases (like empty rows), and dynamically calculates column widths based on the data provided. Such functionality is often useful for logging, debugging, or displaying data in command-line interfaces. Therefore, it is likely to be retained in the codebase."
survived,"    def __init__(self, base_path: Path):
        self.base_path = Path(base_path)
        
        # Default prompts for different file types and patterns
        self.default_prompts = {
            'model': {
                'validation': ""Add comprehensive validation methods with type hints and error handling"",
                'optimization': ""Optimize model inference performance and add caching"",
                'documentation': ""Add detailed docstrings and usage examples"",
                'testing': ""Implement unit tests with various edge cases"",
                'refactoring': ""Refactor for better maintainability and code organization""
            },
            'api': {
                'endpoints': ""Implement RESTful CRUD endpoints with proper error handling"",
                'authentication': ""Add JWT authentication and authorization"",
                'validation': ""Add request/response validation with schemas"",
                'documentation': ""Add OpenAPI/Swagger documentation"",
                'rate_limiting': ""Implement rate limiting and request throttling""
            },
            'utils': {
                'type_hints': ""Add comprehensive type hints to all functions"",
                'error_handling': ""Implement robust error handling and logging"",
                'optimization': ""Optimize performance for large-scale operations"",
                'documentation': ""Add detailed docstrings with examples"",
                'testing': ""Create comprehensive unit tests""
            },
            'config': {
                'validation': ""Add configuration validation and type checking"",
                'environment': ""Implement environment-specific configurations"",
                'documentation': ""Document all configuration options"",
                'defaults': ""Add sensible defaults with overrides"",
                'schema': ""Create configuration schema validation""
            },
            'service': {
                'implementation': ""Implement core service functionality with error handling"",
                'dependency_injection': ""Add dependency injection patterns"",
                'async': ""Convert to async/await for better performance"",
                'monitoring': ""Add monitoring and metrics collection"",
                'testing': ""Implement integration and unit tests""
            }
        }
        
        # Task templates for common scenarios
        self.task_templates = {
            'add_type_hints': ""Add comprehensive type hints to all functions and methods"",
            'add_validation': ""Implement input validation and error handling"",
            'add_tests': ""Create unit tests with pytest covering edge cases"",
            'add_docs': ""Add detailed docstrings following Google style guide"",
            'refactor': ""Refactor for better readability and maintainability"",
            'optimize': ""Optimize performance and reduce computational complexity"",
            'security': ""Implement security best practices and input sanitization"",
            'async_conversion': ""Convert synchronous code to async/await pattern"",
            'error_handling': ""Add comprehensive error handling and logging"",
            'api_implementation': ""Implement RESTful API endpoints with validation""
        }
",src/haconiwa/scan/generate_parallel.py,ParallelYAMLGenerator,1,3.2887477414614998e-06,"The method is a constructor (__init__) for a class that initializes important attributes such as base_path, default_prompts, and task_templates. These attributes are likely essential for the functionality of the class, as they provide default prompts and task templates for various operations. Removing this method would likely break the initialization process of the class, leading to errors when trying to access these attributes. Therefore, it is unlikely that this method will be deleted."
survived,"    def generate(self, model_name: str, guide_type: str = 'development') -> str:
        """"""Generate a guide for the specified model""""""
        # Load model information
        model_info = self._load_model_info(model_name)
        
        if not model_info:
            return f""# Error: Model '{model_name}' not found\n\nPlease check the model name and try again.""
        
        # Generate guide using appropriate template
        generator = self.templates.get(guide_type, self._generate_development_guide)
        return generator(model_info)
",src/haconiwa/scan/guide_generator.py,GuideGenerator,1,6.69158608681505e-10,"The method 'generate' is well-defined and serves a clear purpose of generating a guide for a specified model. It includes error handling for cases where the model information is not found, and it uses a flexible approach to select the appropriate guide generation template based on the 'guide_type' parameter. This makes the method versatile and useful in various contexts where different types of guides might be needed. Additionally, the method is concise and leverages helper functions (like '_load_model_info' and '_generate_development_guide'), which suggests good code organization. There is no indication that this method is obsolete or redundant, so it is likely to be retained in the codebase."
survived,"    def _generate_quickstart_guide(self, model_info: Dict[str, Any]) -> str:
        """"""Generate a quickstart guide""""""
        lines = [
            f""# Quick Start: {model_info['name']}"",
            f""\nGet started with {model_info['name']} in 5 minutes!"",
            ""\n## 1. Installation"",
            ""```bash"",
            ""# Clone the repository or download model files"",
            ""git clone <repository-url>"",
            ""cd "" + model_info['name'].lower().replace(' ', '-'),
            """",
            ""# Install dependencies"",
            ""pip install -r requirements.txt"",
            ""```"",
            ""\n## 2. Basic Example"",
            ""```python"",
            f""# Quick example using {model_info['name']}"",
            ""import json"",
            """",
            ""# Load configuration"",
            ""with open('config.json', 'r') as f:"",
            ""    config = json.load(f)"",
            """",
            ""# Your code here"",
            ""# model = load_model(config)"",
            ""# result = model.predict('Hello, world!')"",
            ""# print(result)"",
            ""```"",
            ""\n## 3. Next Steps"",
            ""- Read the full development guide"",
            ""- Explore example scripts"",
            ""- Check model configuration options"",
            ""- Join the community for support""
        ]
        
        return ""\n"".join(lines)",src/haconiwa/scan/guide_generator.py,GuideGenerator,1,2.7894680920908113e-10,"The method '_generate_quickstart_guide' is a utility function that generates a quickstart guide for a given model. It is a useful feature for users who need to quickly understand how to set up and use a model. The method is well-structured, easy to understand, and provides a clear and concise guide. Such methods are typically retained in codebases as they enhance user experience and provide essential documentation support. Therefore, it is likely to survive."
survived,"def guide(
    model_name: str = typer.Argument(..., help=""Model name to generate guide for""),
    type: str = typer.Option(""development"", ""--type"", ""-t"", 
                            help=""Guide type (development/usage/integration/quickstart)""),
    path: Optional[Path] = typer.Option(None, ""--path"", ""-p"", help=""Base path to search in""),
    output: Optional[Path] = typer.Option(None, ""--output"", ""-o"", help=""Output file path"")
):
    """"""Generate development guide for specific AI model""""""
    generator = GuideGenerator(base_path=path or Path.cwd())
    
    guide_text = generator.generate(model_name, guide_type=type)
    
    if output:
        output.write_text(guide_text)
        typer.echo(f""Guide saved to: {output}"")
    else:
        typer.echo(guide_text)
",src/haconiwa/scan/cli.py,,1,5.211412485172657e-10,"The method 'guide' is a well-structured function that uses the Typer library to create a command-line interface for generating guides for AI models. It includes options for specifying the model name, guide type, base path, and output file path, making it flexible and useful for various scenarios. The function is likely to be useful in a development environment where documentation or guides need to be generated programmatically. Given its utility and the fact that it is implemented using a popular library (Typer), it is likely to be retained in the codebase."
survived,"    def test_model_name_normalization(self, temp_model_dir):
        """"""Test model name normalization""""""
        scanner = ModelScanner(temp_model_dir)
        
        # Test various prefixes
        test_cases = [
            (""gpt-4"", ""4""),
            (""claude-3-opus"", ""3-opus""),
            (""llama-2-70b"", ""2-70b""),
            (""mistral-7b"", ""7b""),
            (""gemini-pro"", ""pro"")
        ]
        
        for original, expected in test_cases:
            normalized = scanner._normalize_model_name(original)
            assert normalized == expected
",tests/test_scan/test_scanner.py,TestModelScanner,1,7.582560422162384e-10,"The method 'test_model_name_normalization' is a unit test designed to verify the functionality of the '_normalize_model_name' method in the 'ModelScanner' class. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with string manipulations and expected outputs. This test method is well-structured, with clear test cases that cover a variety of input scenarios. It is likely to be maintained as part of the test suite to ensure that any changes to the '_normalize_model_name' method do not break existing functionality. Therefore, it is predicted to survive."
survived,"    def __init__(self, 
                 base_path: Path,
                 strip_prefix: bool = True,
                 ignore_patterns: Optional[List[str]] = None,
                 whitelist: Optional[List[str]] = None):
        self.base_path = Path(base_path)
        self.strip_prefix = strip_prefix
        self.ignore_patterns = ignore_patterns or [
            ""*.pyc"", ""__pycache__"", "".git"", "".venv"", 
            ""node_modules"", ""*.egg-info"", "".pytest_cache""
        ]
        self.whitelist = whitelist or []
        
        # Common model name prefixes to strip
        self.model_prefixes = [
            ""gpt-"", ""claude-"", ""llama-"", ""mistral-"", ""gemini-"",
            ""palm-"", ""anthropic-"", ""openai-"", ""meta-"", ""google-""
        ]
        
        # File type mappings
        self.file_type_mappings = {
            '.py': 'python',
            '.js': 'javascript',
            '.ts': 'typescript',
            '.md': 'markdown',
            '.json': 'json',
            '.yaml': 'yaml',
            '.yml': 'yaml',
            '.txt': 'text',
            '.sh': 'shell',
            '.dockerfile': 'docker',
            '.toml': 'toml',
            '.ini': 'config',
            '.conf': 'config'
        }
",src/haconiwa/scan/scanner.py,ModelScanner,1,2.2159489282323004e-08,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class with specific attributes. It sets up default values for attributes and handles optional parameters, making it a crucial part of the class's functionality. Such methods are rarely deleted unless the entire class is being refactored or removed, which is not indicated here."
survived,"def generate_parallel_config(
    source: Optional[str] = typer.Option(None, ""--source"", ""-s"", 
                                        help=""Source: 'last-search', 'model:name', or file path""),
    action: str = typer.Option(""refactor"", ""--action"", ""-a"",
                              help=""Action type: refactor, add_type_hints, add_tests, etc.""),
    max_files: int = typer.Option(10, ""--max-files"", ""-m"", help=""Maximum number of files""),
    output: Path = typer.Option(""parallel-dev.yaml"", ""--output"", ""-o"", help=""Output YAML file""),
    example: bool = typer.Option(False, ""--example"", help=""Generate example YAML""),
    migration: Optional[List[str]] = typer.Option(None, ""--migration"",
                                                  help=""Generate migration YAML (old:new)""),
    pattern_fix: Optional[List[str]] = typer.Option(None, ""--pattern-fix"",
                                                    help=""Fix pattern (pattern:description)""),
    project_wide: Optional[str] = typer.Option(None, ""--project-wide"",
                                              help=""Generate project-wide changes for file pattern""),
    exclude: Optional[List[str]] = typer.Option(None, ""--exclude"", ""-e"",
                                               help=""Exclude patterns for project-wide""),
    prompt_file: Optional[Path] = typer.Option(None, ""--prompt-file"",
                                              help=""File with custom prompts (file:prompt per line)"")
):
    """"""Generate parallel development configuration YAML from scan results""""""
    
    generator = ParallelYAMLGenerator(base_path=Path.cwd())
    
    # Handle different generation modes
    if example:
        # Generate example YAML
        config = generator.create_example_yaml()
        typer.echo(""ðŸ“ Generated example parallel-dev.yaml"")
    
    elif migration and len(migration) == 1 and ':' in migration[0]:
        # Migration mode
        old_model, new_model = migration[0].split(':', 1)
        scanner = ModelScanner(base_path=Path.cwd())
        
        # Find files containing old model
        results = scanner.search_by_model_name(old_model)
        files = []
        for category, file_list in results['matches'].items():
            for file_info in file_list:
                files.append(file_info['path'])
                if len(files) >= max_files:
                    break
        
        config = generator.generate_for_model_migration(old_model, new_model, files)
        typer.echo(f""ðŸ”„ Generated migration YAML: {old_model} â†’ {new_model}"")
    
    elif pattern_fix and len(pattern_fix) == 1 and ':' in pattern_fix[0]:
        # Pattern fix mode
        pattern, description = pattern_fix[0].split(':', 1)
        scanner = ModelScanner(base_path=Path.cwd())
        
        # Find files containing pattern
        results = scanner.search_content(pattern)
        files = [match['file'] for match in results['matches'][:max_files]]
        
        config = generator.generate_for_pattern_fix(pattern, description, files)
        typer.echo(f""ðŸ”§ Generated pattern fix YAML for: {pattern}"")
    
    elif project_wide:
        # Project-wide mode
        config = generator.generate_project_wide(
            action=action,
            file_pattern=project_wide,
            exclude_patterns=exclude
        )
        typer.echo(f""ðŸŒ Generated project-wide YAML for: {project_wide}"")
    
    else:
        # Standard mode - from search results or model name
        custom_prompts = {}
        if prompt_file and prompt_file.exists():
            # Load custom prompts
            for line in prompt_file.read_text().splitlines():
                if ':' in line:
                    file_path, prompt = line.split(':', 1)
                    custom_prompts[file_path.strip()] = prompt.strip()
        
        if source and source.startswith('model:'):
            # Search for specific model
            model_name = source[6:]
            scanner = ModelScanner(base_path=Path.cwd())
            scan_results = scanner.search_by_model_name(model_name)
        elif source and Path(source).exists():
            # Load from file
            source_path = Path(source)
            if source_path.suffix in ['.json', '.yaml', '.yml']:
                with open(source_path, 'r') as f:
                    if source_path.suffix == '.json':
                        scan_results = json.load(f)
                    else:
                        scan_results = yaml.safe_load(f)
            else:
                typer.echo(""Error: Source file must be JSON or YAML"", err=True)
                raise typer.Exit(1)
        else:
            # Try to use last search results (would need to implement caching)
            typer.echo(""ðŸ“ Using current directory analysis..."")
            analyzer = ModelAnalyzer(base_path=Path.cwd())
            scan_results = analyzer.analyze_directory()
        
        config = generator.generate_from_scan_results(
            scan_results,
            action=action,
            max_files=max_files,
            custom_prompts=custom_prompts
        )
        typer.echo(f""âœ¨ Generated parallel-dev YAML with {len(config['tasks'])} tasks"")
    
    # Save YAML file
    saved_path = generator.save_yaml(config, output)
    typer.echo(f""ðŸ’¾ Saved to: {saved_path}"")
    
    # Show preview
    typer.echo(""\nðŸ“‹ Preview:"")
    typer.echo(f""Provider: {config['provider']}"")
    typer.echo(f""Total tasks: {len(config['tasks'])}"")
    if config['tasks']:
        typer.echo(""\nFirst 3 tasks:"")
        for i, task in enumerate(config['tasks'][:3], 1):
            typer.echo(f""{i}. {task['file']}"")
            typer.echo(f""   â†’ {task['prompt'][:80]}{'...' if len(task['prompt']) > 80 else ''}"")
    
    typer.echo(f""\nâœ… Generated YAML file is ready: {output}"")
",src/haconiwa/scan/cli.py,,1,1.1861120010657661e-08,"The method `generate_parallel_config` is a comprehensive function that provides a command-line interface for generating YAML configuration files for parallel development. It includes various options for different modes of operation, such as example generation, migration, pattern fixing, and project-wide changes. The method is well-structured, uses external classes like `ParallelYAMLGenerator` and `ModelScanner`, and provides detailed feedback to the user through `typer.echo` statements. Given its utility, complexity, and the fact that it is part of a command-line tool, it is unlikely to be deleted. Instead, it is more likely to be maintained or enhanced as the tool evolves."
survived,"    def temp_model_dir(self):
        """"""Create a temporary directory with test models""""""
        with tempfile.TemporaryDirectory() as tmpdir:
            base_path = Path(tmpdir)
            
            # Create test model structure
            model_dir = base_path / ""models"" / ""test"" / ""o1-mini""
            model_dir.mkdir(parents=True)
            
            # Create config
            config = {
                ""model_name"": ""o1-mini"",
                ""model_type"": ""language"",
                ""parameters"": ""3B""
            }
            with open(model_dir / ""config.json"", ""w"") as f:
                json.dump(config, f)
            
            # Create model file
            (model_dir / ""model.pt"").touch()
            
            # Create example
            with open(model_dir / ""example.py"", ""w"") as f:
                f.write(""# Example for o1-mini\nprint('Hello from o1-mini')"")
            
            yield base_path
",tests/test_scan/test_cli.py,TestScanCLI,1,3.2241866333029355e-08,"The method 'temp_model_dir' is a utility function that creates a temporary directory structure for testing purposes. It sets up a directory with a specific structure, including configuration files and example scripts, which can be useful for testing model loading and configuration in a controlled environment. Such utility functions are often retained in codebases because they facilitate testing and development processes by providing a consistent and repeatable setup. Therefore, it is likely to be retained."
survived,"    def test_search_by_model_name_no_strip(self, temp_model_dir):
        """"""Test searching without prefix stripping""""""
        scanner = ModelScanner(temp_model_dir, strip_prefix=False)
        
        results = scanner.search_by_model_name(""claude-3-opus"")
        assert results['normalized_name'] == ""claude-3-opus""
",tests/test_scan/test_scanner.py,TestModelScanner,1,1.0467401685178159e-08,"The method 'test_search_by_model_name_no_strip' is a unit test designed to verify the functionality of the 'search_by_model_name' method in the 'ModelScanner' class. It specifically tests the behavior when the 'strip_prefix' option is set to False. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with specific configurations or options. Since this test is focused on a specific feature (prefix stripping) and is part of a testing suite, it is likely to be maintained to ensure the feature works as expected. Therefore, the method is likely to survive."
survived,"    def _format_tree(self, data: Any) -> str:
        """"""Format as tree structure""""""
        if not isinstance(data, dict):
            return str(data)
        
        lines = []
        
        def build_tree(node: Dict[str, Any], prefix: str = """", is_last: bool = True):
            """"""Recursively build tree representation""""""
            items = [(k, v) for k, v in node.items() if k != '__files__']
            files = node.get('__files__', [])
            
            # Add directories
            for i, (key, value) in enumerate(items):
                is_last_item = i == len(items) - 1 and not files
                
                connector = ""â””â”€â”€ "" if is_last_item else ""â”œâ”€â”€ ""
                lines.append(f""{prefix}{connector}{key}/"")
                
                if isinstance(value, dict):
                    extension = ""    "" if is_last_item else ""â”‚   ""
                    build_tree(value, prefix + extension, is_last_item)
            
            # Add files
            for i, file_info in enumerate(files):
                is_last_file = i == len(files) - 1
                connector = ""â””â”€â”€ "" if is_last_file else ""â”œâ”€â”€ ""
                
                if isinstance(file_info, dict):
                    name = file_info.get('name', 'Unknown')
                    size = file_info.get('size', 0)
                    size_str = self._format_size(size)
                    lines.append(f""{prefix}{connector}{name} ({size_str})"")
                else:
                    lines.append(f""{prefix}{connector}{file_info}"")
        
        build_tree(data)
        return ""\n"".join(lines)
",src/haconiwa/scan/formatter.py,OutputFormatter,1,1.1861120010657661e-08,"The method _format_tree is a utility function that formats a nested dictionary structure into a tree-like string representation. This is a common requirement for visualizing hierarchical data structures, such as file systems or organizational charts. The method is well-implemented, handling both directories and files, and includes a helper function to format file sizes. Such functionality is often useful in various applications, especially those dealing with file management or data visualization. Therefore, it is likely to be retained in the codebase."
survived,"    def test_ignore_patterns(self, temp_model_dir):
        """"""Test ignore patterns functionality""""""
        # Create files that should be ignored
        (temp_model_dir / ""models"" / ""__pycache__"").mkdir(parents=True)
        (temp_model_dir / ""models"" / "".git"").mkdir(parents=True)
        (temp_model_dir / ""models"" / ""test.pyc"").touch()
        
        scanner = ModelScanner(temp_model_dir)
        
        # These should not appear in results
        results = scanner.search_by_model_name(""pycache"")
        assert results['total_files'] == 0
        
        results = scanner.search_by_model_name(""git"")
        assert results['total_files'] == 0
",tests/test_scan/test_scanner.py,TestModelScanner,1,5.60279640614594e-09,"The method 'test_ignore_patterns' is a unit test designed to verify the functionality of ignoring certain patterns (like '__pycache__', '.git', and '.pyc' files) in a directory scanning process. This is a common requirement in many software projects to ensure that temporary or irrelevant files do not interfere with the main functionality. The method is useful for maintaining the integrity of the scanning process and ensuring that only relevant files are considered. Therefore, it is likely to be retained as it serves a critical testing purpose."
survived,"    def _iter_files(self, file_types: Optional[List[str]] = None):
        """"""Iterate through files with optional type filtering""""""
        for root, dirs, files in os.walk(self.base_path):
            root_path = Path(root)
            
            # Filter directories
            dirs[:] = [d for d in dirs if not self._should_ignore(root_path / d)]
            
            for file in files:
                file_path = root_path / file
                
                if file_types:
                    if not any(file_path.suffix == ft for ft in file_types):
                        continue
                
                yield file_path
",src/haconiwa/scan/scanner.py,ModelScanner,1,1.2501528648238603e-09,"The method '_iter_files' is a utility function that provides a flexible way to iterate over files in a directory, with optional filtering based on file types. This is a common requirement in many applications that deal with file system operations, such as data processing, file management, or content indexing. The method is well-structured, uses Python's built-in 'os.walk' for directory traversal, and employs list comprehensions for filtering, which are both efficient and Pythonic. Additionally, the use of 'Path' from the 'pathlib' module enhances readability and cross-platform compatibility. Given these factors, the method is likely to be useful and relevant in various contexts, suggesting it will be retained in the codebase."
survived,"    def _compare_parameters(self, model_data: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
        """"""Compare model parameters""""""
        parameters = {}
        
        for model, data in model_data.items():
            model_params = {
                'total_parameters': 'Unknown',
                'layers': 'Unknown',
                'hidden_size': 'Unknown',
                'vocabulary_size': 'Unknown'
            }
            
            # Extract from config
            if data.get('config'):
                config = data['config']
                
                # Common parameter names across different frameworks
                param_mappings = {
                    'total_parameters': ['n_params', 'num_parameters', 'total_params'],
                    'layers': ['n_layers', 'num_layers', 'num_hidden_layers'],
                    'hidden_size': ['hidden_size', 'd_model', 'n_embd'],
                    'vocabulary_size': ['vocab_size', 'vocabulary_size', 'n_vocab']
                }
                
                for param_key, possible_names in param_mappings.items():
                    for name in possible_names:
                        if name in config:
                            model_params[param_key] = config[name]
                            break
            
            parameters[model] = model_params
        
        return parameters
",src/haconiwa/scan/comparator.py,ModelComparator,1,1.6052280526088547e-09,"The method '_compare_parameters' is a utility function that extracts and compares model parameters from a given dictionary. It is useful for standardizing parameter extraction across different model configurations, especially when dealing with multiple frameworks that might use different naming conventions for similar parameters. This kind of functionality is often needed in machine learning and data science projects to ensure consistency and ease of analysis. Therefore, it is likely to be retained as it provides a clear and necessary function."
survived,"    def _format_json(self, data: Any) -> str:
        """"""Format as JSON""""""
        return json.dumps(data, indent=2, default=str)
",src/haconiwa/scan/formatter.py,OutputFormatter,1,5.211412485172657e-10,"The method `_format_json` is a utility function that formats data as a JSON string with indentation for readability. This is a common and useful functionality in many applications that deal with JSON data, as it helps in debugging and logging by providing a human-readable format. The method is simple, effective, and leverages Python's built-in `json.dumps` function, making it unlikely to be deleted unless the entire codebase is being refactored to remove JSON handling or if a more comprehensive JSON handling library is adopted. Therefore, it is likely to survive."
survived,"def _transform_for_matrix_function(a):
    """"""Transform array for STATIC matrix functions expecting (..., vars, obs) convention.

    Input convention (from benchmark): (..., obs, vars) - batch dims at front
    Output convention (for static funcs): (..., vars, obs) - swap last two dimensions
    Moving functions use input as-is since they expect (..., obs, vars).
    """"""
    return a.swapaxes(-2, -1)
",numbagg/test/conftest.py,,1,1.8189616842444243e-09,"The method _transform_for_matrix_function is a utility function that swaps the last two axes of a numpy array. This is a common operation needed when interfacing with different libraries or functions that expect data in a specific shape. The function is simple, well-documented, and serves a clear purpose in transforming data for compatibility with static matrix functions. Such utility functions are often retained in codebases because they encapsulate a specific transformation logic that might be reused in multiple places. Therefore, it is likely to survive."
survived,"def test_benchmark_matrix(benchmark, func, func_callable, shape):
    """"""
    Benchmark matrix functions on matrix-friendly shapes.
    """"""
    benchmark.group = f""{func}|{shape}""
    benchmark(func_callable)
",numbagg/test/test_benchmark.py,,1,1.522997951276035e-08,"The method 'test_benchmark_matrix' is a utility function designed to benchmark matrix operations. It is concise, has a clear purpose, and is likely used in a testing or performance evaluation context. Such functions are generally useful for developers to assess the efficiency of their code, especially in performance-critical applications. Therefore, it is likely to be retained in the codebase."
survived,"    def get_column_value(summary_df, func, lib, dimension, matrix_shape_exclusions):
        """"""Extract column value for a function/library pair with matrix function handling.""""""
        matching_cols = [
            col for col in summary_df.columns if col[0].removesuffix(""_ratio"") == lib
        ]

        if not matching_cols or func not in summary_df.index:
            return ""n/a""

        # For matrix functions, try to find matrix-specific column first
        value = None
        if ""matrix"" in func:
            matrix_cols = [
                col
                for col in matching_cols
                if not any(exclusion in col[1] for exclusion in matrix_shape_exclusions)
            ]
            if matrix_cols:
                value = summary_df.loc[func, matrix_cols[0]]

        # Fallback to first column if no matrix-specific column found
        if value is None:
            value = summary_df.loc[func, matching_cols[0]]

        return value if not pd.isna(value) else ""n/a""
",numbagg/test/run_benchmarks.py,,1,4.363462233903899e-09,"The method is well-defined and serves a specific purpose of extracting column values based on certain conditions. It handles edge cases like missing columns or NaN values, making it robust. The logic for handling matrix-specific columns adds value for specific use cases, indicating that it is a useful utility function. There is no indication of redundancy or obsolescence, suggesting it will be retained."
survived,"    def test_rolling_zero_variance_windows(self, move_func, expected_diag):
        """"""Test rolling windows with zero variance.""""""
        # Moving functions expect (obs, vars) format
        data = np.array(
            [[1, 2], [1, 2], [1, 2], [2, 3], [3, 4], [4, 5]], dtype=np.float64
        )
        result = move_func(data, window=3, min_count=2)

        # First full window has constant values
        if move_func == move_nancorrmatrix:
            # Correlation undefined for zero variance
            assert np.isnan(result[2, 0, 1])
        else:
            # Covariance should be 0
            assert result[2, 0, 0] == 0.0
            assert result[2, 1, 1] == 0.0
            assert result[2, 0, 1] == 0.0

        # Later windows have variance
        assert not np.all(np.isnan(result[5]))
",numbagg/test/test_matrix_functions.py,TestMovingMatrices,1,8.152020648014727e-09,"The method is a test function that checks the behavior of a moving function with rolling windows, specifically focusing on cases with zero variance. Test functions are generally crucial for ensuring code correctness and reliability, especially in numerical computations. This function is likely part of a test suite for a larger library or application, and removing it could lead to undetected bugs or issues in the future. Therefore, it is more likely to be retained."
survived,"def set_version_for_deployment(cfg: Config, version: str, branch: Optional[str] = None) -> bool:
    """"""Set version for deployment without interactive prompts.

    Returns True if successful, False otherwise.
    """"""
    if has_bouncelock_file(cfg):
        print(f""{cfg.env.value} is currently bounce locked. Cannot set new version."")
        return False

    release: Optional[Release] = None
    to_set: Optional[str] = None

    if version == ""latest"":
        release = find_latest_release(cfg, branch or """")
        if not release:
            print(""Unable to find latest version"" + (f"" for branch {branch}"" if branch else """"))
            return False
    else:
        try:
            release = find_release(cfg, Version.from_string(version))
        except Exception as e:
            print(f""Invalid version format {version}: {e}"")
            return False

        if not release:
            print(f""Unable to find version {version}"")
            return False

    to_set = release.key

    # Check compiler discovery
    if (
        (cfg.env.value != ""runner"")
        and not cfg.env.is_windows
        and not runner_discoveryexists(cfg.env.value, str(release.version))
    ):
        print(f""Warning: Compiler discovery has not run for {cfg.env.value}/{release.version}"")
        # In deployment context, we proceed anyway

    # Log the new build
    try:
        log_new_build(cfg, to_set)
    except Exception as e:
        print(f""Failed to log new build: {e}"")
        return False

    # Deploy static files
    if release.static_key:
        try:
            if cfg.env.is_windows:
                if not deploy_staticfiles_windows(release):
                    print(""Failed to deploy static files (Windows)"")
                    return False
            else:
                if not deploy_staticfiles(release):
                    print(""Failed to deploy static files"")
                    return False
        except Exception as e:
            print(f""Failed to deploy static files: {e}"")
            return False
    else:
        # Use old deploy method if no static_key
        old_deploy_staticfiles(None, to_set)

    # Set the current key
    try:
        set_current_key(cfg, to_set)
    except Exception as e:
        print(f""Failed to set current key: {e}"")
        return False

    # Notify sentry
    notify_sentry_deployment(cfg, release)

    return True
",bin/lib/builds_core.py,,1,2.8453347280241004e-08,"The method 'set_version_for_deployment' is a crucial part of the deployment process, handling version setting, logging, static file deployment, and error handling. It includes checks for environment conditions and error handling, making it robust and essential for deployment operations. Such methods are typically retained unless there's a significant change in the deployment strategy or architecture."
survived,"    def test_claude_desktop_with_new_options(self):
        """"""Test claude-desktop install with new uv options.""""""
        from pathlib import Path

        command, bound, _ = install_app.parse_args(
            [
                ""claude-desktop"",
                ""server.py"",
                ""--python"",
                ""3.10"",
                ""--project"",
                ""/my/project"",
                ""--with-requirements"",
                ""reqs.txt"",
            ]
        )

        assert bound.arguments[""python""] == ""3.10""
        assert bound.arguments[""project""] == Path(""/my/project"")
        assert bound.arguments[""with_requirements""] == Path(""reqs.txt"")
",tests/cli/test_install.py,TestClaudeDesktopInstall,1,2.998960815863541e-09,"The method 'test_claude_desktop_with_new_options' is a unit test function that verifies the behavior of the 'install_app.parse_args' function with specific arguments. It checks if the parsed arguments match the expected values. This is a typical use case in software testing to ensure that the code behaves as expected when given certain inputs. Since testing is a crucial part of software development to maintain code quality and reliability, this method is likely to be retained in the codebase."
survived,"    def test_dev_command_parsing_with_new_options(self):
        """"""Test dev command parsing with new uv options.""""""
        command, bound, _ = app.parse_args(
            [
                ""dev"",
                ""server.py"",
                ""--python"",
                ""3.10"",
                ""--project"",
                ""/workspace"",
                ""--with-requirements"",
                ""dev-requirements.txt"",
                ""--with"",
                ""pytest"",
            ]
        )
        assert command is not None
        assert bound.arguments[""server_spec""] == ""server.py""
        assert bound.arguments[""python""] == ""3.10""
        assert bound.arguments[""project""] == Path(""/workspace"")
        assert bound.arguments[""with_requirements""] == Path(""dev-requirements.txt"")
        assert bound.arguments[""with_packages""] == [""pytest""]
",tests/cli/test_cli.py,TestDevCommand,1,1.1861120010657661e-08,"The method is a unit test for a command-line argument parser, which is a common and necessary functionality in many applications. It ensures that the parser correctly interprets and binds command-line arguments to the expected variables. This kind of test is crucial for maintaining the integrity of the command-line interface, especially when new options are added. Therefore, it is likely to be maintained as part of the test suite to ensure ongoing reliability and correctness of the argument parsing logic."
survived,"    def test_claude_code_with_new_options(self):
        """"""Test claude-code install with new uv options.""""""
        from pathlib import Path

        command, bound, _ = install_app.parse_args(
            [
                ""claude-code"",
                ""server.py"",
                ""--python"",
                ""3.11"",
                ""--project"",
                ""/workspace"",
                ""--with-requirements"",
                ""requirements.txt"",
            ]
        )

        assert bound.arguments[""python""] == ""3.11""
        assert bound.arguments[""project""] == Path(""/workspace"")
        assert bound.arguments[""with_requirements""] == Path(""requirements.txt"")
",tests/cli/test_install.py,TestClaudeCodeInstall,1,2.2159489282323004e-08,"The method 'test_claude_code_with_new_options' is a unit test designed to verify the functionality of the 'install_app.parse_args' method with specific arguments. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with command-line argument parsing, which can be error-prone. The test checks if the parsed arguments match the expected values, which is a common practice in software development to prevent regressions and ensure that changes do not break existing functionality. Therefore, this method is likely to be retained as part of the test suite to maintain code quality."
survived,"    def test_run_with_uv_python_version(self, mock_run):
        """"""Test run_with_uv with Python version.""""""
        mock_run.return_value = Mock(returncode=0)

        with pytest.raises(SystemExit) as exc_info:
            run_with_uv(""server.py"", python_version=""3.11"")

        assert exc_info.value.code == 0

        cmd = mock_run.call_args[0][0]
        expected = [
            ""uv"",
            ""run"",
            ""--python"",
            ""3.11"",
            ""--with"",
            ""fastmcp"",
            ""fastmcp"",
            ""run"",
            ""server.py"",
        ]
        assert cmd == expected
",tests/cli/test_run_with_uv.py,TestRunWithUv,1,1.725782769012759e-08,"The method `test_run_with_uv_python_version` is a unit test designed to verify the behavior of the `run_with_uv` function when a specific Python version is provided. It uses mocking to simulate the function's behavior and checks if the correct command is constructed and executed. This is a typical and necessary part of testing in software development to ensure code reliability and correctness. Therefore, it is unlikely to be deleted as it serves a crucial role in maintaining code quality."
survived,"    def test_python_option(self):
        """"""Test --python option for all install commands.""""""
        commands_to_test = [
            [""claude-code"", ""server.py"", ""--python"", ""3.11""],
            [""claude-desktop"", ""server.py"", ""--python"", ""3.11""],
            [""cursor"", ""server.py"", ""--python"", ""3.11""],
            [""mcp-json"", ""server.py"", ""--python"", ""3.11""],
        ]

        for cmd_args in commands_to_test:
            command, bound, _ = install_app.parse_args(cmd_args)
            assert command is not None
            assert bound.arguments[""python""] == ""3.11""
",tests/cli/test_install.py,TestInstallCommandParsing,1,5.60279640614594e-09,"The method 'test_python_option' is a unit test designed to verify that the '--python' option is correctly parsed and applied for various install commands. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with command-line interfaces and argument parsing. This method is likely to be maintained as it provides a way to automatically verify that the '--python' option is functioning as expected across different commands. Removing it could lead to undetected bugs or regressions in the future."
survived,"def _load_clusters_from_checkpoint(checkpoint_path: Union[str, Path]) -> List[Cluster]:
    """"""Load clusters from a checkpoint file.
    
    Args:
        checkpoint_path: Path to the checkpoint file
        
    Returns:
        List of clusters loaded from the checkpoint
        
    Raises:
        FileNotFoundError: If checkpoint file doesn't exist
        ValueError: If checkpoint file is malformed
    """"""
    checkpoint_path = Path(checkpoint_path)
    
    if not checkpoint_path.exists():
        raise FileNotFoundError(f""Checkpoint file not found: {checkpoint_path}"")
    
    try:
        with open(checkpoint_path) as f:
            clusters = [Cluster.model_validate_json(line) for line in f]
        logger.info(f""Loaded {len(clusters)} clusters from {checkpoint_path}"")
        return clusters
    except Exception as e:
        raise ValueError(f""Failed to load clusters from {checkpoint_path}: {e}"")
",kura/v1/visualization.py,,1,1.1032560311263802e-09,"The method '_load_clusters_from_checkpoint' is well-defined and serves a clear purpose of loading cluster data from a checkpoint file. It includes error handling for common issues such as file not found and malformed data, which are essential for robust file operations. Additionally, it logs the number of clusters loaded, which is useful for debugging and monitoring. These characteristics make it a useful utility function that is likely to be retained in the codebase."
survived,"def make_arms(tokens, learner_args=None):
    """"""Helper to create arms with proper learner args.""""""
    if learner_args is None:
        learner_args = {""alpha"": 1.0, ""beta"": 1.0}
    return [Arm(token, learner=NormalRegressor(**learner_args)) for token in tokens]  # type: ignore
",tests/test_agent_pipeline.py,,1,4.944450477491054e-09,"The method 'make_arms' is a utility function that creates a list of 'Arm' objects, each initialized with a 'NormalRegressor' learner. It provides a default configuration for 'learner_args' if none is provided, ensuring flexibility and ease of use. The function is concise, serves a clear purpose, and is likely part of a larger system dealing with machine learning or probabilistic models. Such utility functions are generally useful and unlikely to be removed unless the entire system undergoes a significant redesign or the approach to creating 'Arm' objects changes fundamentally."
survived,"    def __repr__(self) -> str:
        """"""String representation.""""""
        steps_repr = [
            f""('{name}', {transformer.__class__.__name__})""
            for name, transformer in self.steps
        ]
        return f""NonContextualAgentPipeline(steps=[{', '.join(steps_repr)}], final_agent={self._agent!r})""
",bayesianbandits/pipelines/_agent.py,NonContextualAgentPipeline,1,5.60279640614594e-09,"The __repr__ method is a standard and useful method in Python classes for providing a string representation of an object. This is particularly helpful for debugging and logging purposes. The method in question is well-implemented, providing a clear and informative representation of the object, including the class names of the transformers in the steps and the final agent. Such methods are generally retained in codebases because they enhance the readability and maintainability of the code."
survived,"    def __repr__(self) -> str:
        """"""String representation.""""""
        steps_repr = [
            f""('{name}', {transformer.__class__.__name__})""
            for name, transformer in self.steps
        ]
        learner_repr = f""learner={self._learner.__class__.__name__}""
        if steps_repr:
            return f""LearnerPipeline(steps=[{', '.join(steps_repr)}], {learner_repr})""
        else:
            return f""LearnerPipeline(steps=[], {learner_repr})""
",bayesianbandits/pipelines/_learner.py,LearnerPipeline,1,2.4616969512093895e-10,"The method `__repr__` is a standard way to provide a string representation of an object in Python. It is useful for debugging and logging purposes, as it allows developers to easily see the state of an object. The implementation here is clear and provides a detailed representation of the `LearnerPipeline` object, including the steps and the learner. This kind of method is generally considered good practice and is unlikely to be removed unless the class design changes significantly. Therefore, it is likely to survive."
survived,"    def test_agent_dispatch(self):
        """"""Test factory dispatches to NonContextualAgentPipeline for Agent.""""""
        arms = make_arms(range(3))
        agent = Agent(arms, ThompsonSampling())
        steps = [(""identity"", FunctionTransformer())]

        pipeline = AgentPipeline(steps, agent)

        assert isinstance(pipeline, NonContextualAgentPipeline)
        assert pipeline._agent is agent
",tests/test_agent_pipeline.py,TestAgentPipelineFactory,1,1.0467401685178159e-08,"The method `test_agent_dispatch` is a unit test designed to verify that the `AgentPipeline` correctly dispatches to a `NonContextualAgentPipeline` when initialized with an `Agent`. This is a specific test case that ensures the correct behavior of the code, which is crucial for maintaining code quality and reliability. Unit tests are generally not deleted unless they are redundant, incorrect, or the functionality they test is removed. Since this test is straightforward and serves a clear purpose, it is likely to be retained."
survived,"    def test_update(self):
        """"""Test update method.""""""
        arms = make_arms(range(3))
        agent = Agent(arms, ThompsonSampling(), random_seed=42)
        steps = []

        pipeline = NonContextualAgentPipeline(steps, agent)

        y = np.array([1.0, 2.0])

        # Pull to set arm_to_update
        pipeline.pull()

        # Should not raise
        pipeline.update(y)
",tests/test_agent_pipeline.py,TestNonContextualAgentPipeline,1,6.475946147757848e-07,"The method `test_update` is a unit test for the `update` method of the `NonContextualAgentPipeline` class. Unit tests are crucial for ensuring that code behaves as expected and for catching regressions when code changes. This test specifically checks that the `update` method can be called without raising an exception, which is a basic but important test case. Given the importance of testing in software development, especially for methods that are part of a larger system like a pipeline, it is unlikely that this test method will be deleted. Instead, it is more likely to be maintained or expanded to cover more test cases."
survived,"    def test_sample_method(self):
        """"""Test sample method delegates correctly.""""""
        X = np.array([[1, 2], [3, 4]])

        # Train the pipeline first
        self.pipeline.partial_fit(X, np.array([1, 2]))

        # Now sample
        self.pipeline.sample(X, size=5)

        assert len(self.mock_learner.sample_calls) == 1
        received_X, size = self.mock_learner.sample_calls[0]
        assert size == 5
        # X should be transformed
        assert received_X.shape == X.shape
",tests/test_learner_pipeline.py,TestLearnerPipelineInterface,1,2.699578619062706e-07,"The method 'test_sample_method' is a unit test for a specific functionality of a pipeline, ensuring that the 'sample' method is called correctly and behaves as expected. Unit tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered."
survived,"    def test_validate_valid_steps(self):
        """"""Test validation with valid steps.""""""
        steps = [
            (""step1"", FunctionTransformer()),
            (""step2"", StandardScaler()),
        ]
        # Should not raise
        _validate_steps(steps)
",tests/test_agent_pipeline.py,TestValidateSteps,1,9.931195248674785e-08,"The method `test_validate_valid_steps` is a unit test designed to ensure that the `_validate_steps` function works correctly when provided with valid input. Unit tests are crucial for maintaining code quality and ensuring that functions behave as expected. This method is likely part of a test suite that verifies the functionality of a larger system, and such tests are generally retained to prevent regressions and to facilitate future development. Therefore, it is unlikely that this method will be deleted."
survived,"        def normalize_features(X):
            """"""Simple normalization.""""""
            return X / (np.linalg.norm(X, axis=1, keepdims=True) + 1e-8)
",tests/test_agent_pipeline.py,TestIntegrationScenarios,1,5.211412485172657e-10,"The method 'normalize_features' is a simple and effective way to normalize data, which is a common preprocessing step in machine learning and data analysis. It uses L2 normalization to scale the features, which is widely used to ensure that each feature contributes equally to the distance calculations in algorithms like k-nearest neighbors or clustering. The addition of a small constant (1e-8) prevents division by zero, making the function robust. Given its utility and simplicity, it is likely to be retained in the codebase."
survived,"    def test_repr(self):
        """"""Test string representation.""""""
        arms = make_arms(range(3))
        agent = ContextualAgent(arms, ThompsonSampling())
        steps = [(""transform"", FunctionTransformer())]

        pipeline = ContextualAgentPipeline(steps, agent)
        repr_str = repr(pipeline)

        assert ""ContextualAgentPipeline"" in repr_str
        assert ""FunctionTransformer"" in repr_str
",tests/test_agent_pipeline.py,TestContextualAgentPipeline,1,4.944450477491054e-09,"The method `test_repr` is a unit test designed to verify the string representation of a `ContextualAgentPipeline` object. It checks if the `repr` function correctly includes the class names `ContextualAgentPipeline` and `FunctionTransformer` in its output. This is a standard practice in testing to ensure that the `__repr__` method of a class provides useful and expected information. Since this is a valid and useful test, it is likely to be retained in the codebase."
survived,"    def test_missing_learner_methods_error(self):
        """"""Test that learner without Learner protocol raises ValueError.""""""

        class BadLearner:
            def partial_fit(self, X, y):
                pass

            # Missing sample, predict, decay

        with pytest.raises(
            ValueError, match=""Missing methods: \\['sample', 'predict', 'decay'\\]""
        ):
            LearnerPipeline(steps=[], learner=BadLearner())
",tests/test_learner_pipeline.py,TestLearnerPipelineInit,1,2.998960815863541e-09,"The method is a unit test designed to ensure that a specific error is raised when a class does not implement required methods. Such tests are crucial for maintaining code quality and ensuring that the system behaves as expected when encountering incorrect implementations. Therefore, it is likely to be retained as part of the test suite."
survived,"    def test_dict_vectorizer_integration(self):
        """"""Test integration with DictVectorizer.""""""
        # Pre-fit vectorizer
        vectorizer = DictVectorizer()
        historical_dicts = [
            {""user"": ""A"", ""item"": ""X""},
            {""user"": ""B"", ""item"": ""Y""},
        ]
        vectorizer.fit(historical_dicts)

        arms = [
            Arm(i, learner=NormalRegressor(alpha=1.0, beta=1.0, sparse=True))
            for i in range(3)
        ]
        agent = ContextualAgent(arms, ThompsonSampling(), random_seed=42)

        steps = [(""vectorize"", vectorizer)]
        pipeline = ContextualAgentPipeline(steps, agent)

        X = [{""user"": ""A"", ""item"": ""X""}, {""user"": ""B"", ""item"": ""Y""}]

        actions = pipeline.pull(X)
        assert len(actions) == 2

        y = np.array([1.0, 2.0])
        pipeline.update(X, y)
",tests/test_agent_pipeline.py,TestTransformationFlow,1,3.3982678079468468e-09,"The method `test_dict_vectorizer_integration` is a unit test designed to verify the integration of a `DictVectorizer` with a `ContextualAgentPipeline`. It is a specific test case that ensures the components work together as expected, which is crucial for maintaining the integrity of the system when changes are made. Such test methods are typically retained to ensure ongoing functionality and to catch regressions. Therefore, it is likely to be Survived."
survived,"    def __getitem__(self, ind: Union[int, str]) -> Any:
        """"""Get a step by index or name.""""""
        if isinstance(ind, str):
            return self.named_steps[ind]
        return self.steps[ind]
",bayesianbandits/pipelines/_agent.py,NonContextualAgentPipeline,1,6.348800075736417e-09,"The method `__getitem__` is a standard way to allow object instances to use the indexing syntax (e.g., obj[ind]). This method is useful for accessing elements in a collection-like object by index or key. The implementation here supports both integer and string indices, which makes it versatile for accessing elements by position or by name. This is a common pattern in Python, especially in classes that mimic list or dictionary behavior. There is no indication that this method is redundant or unnecessary, so it is likely to be retained."
survived,"    def _format_prp_documentation(self, docs: List[str]) -> str:
        """"""Format documentation links for PRP.""""""
        return ""\n"".join(f""- {doc}"" for doc in docs)
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,1,4.599055376537186e-10,"The method _format_prp_documentation is a utility function that formats a list of documentation links into a string with each link prefixed by a dash and a newline character. This is a simple and useful function for organizing and displaying documentation links in a readable format. It is likely to be used in contexts where documentation needs to be presented in a structured way, such as in a user interface or a report. The method is straightforward, performs a clear task, and is likely to be reused in various parts of a codebase that deals with documentation. Therefore, it is likely to survive."
survived,"    def _generate_prp_implementation_blueprint(self, feature_request: str, analysis: Dict[str, Any]) -> str:
        """"""Generate implementation blueprint for PRP.""""""
        return f""Implementation plan for: {feature_request}""
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,1,2.3355930333443423e-09,"The method '_generate_prp_implementation_blueprint' is a simple utility function that generates a string based on the input parameters. It is likely part of a larger system that deals with feature requests and their analysis. The method is straightforward, has a clear purpose, and does not have any apparent issues or redundancies that would necessitate its removal. Therefore, it is likely to be retained in the codebase."
survived,"def demonstrate_context_engineering_benefits():
    """"""
    Demonstrate the benefits of Context Engineering methodology.
    """"""
    print(""\nðŸ“Š Context Engineering vs Traditional Approaches"")
    print(""="" * 60)
    
    # Traditional approach simulation
    print(""\nâŒ Traditional AI Coding Approach:"")
    print(""   1. Write basic prompt: 'Implement user authentication'"")
    print(""   2. AI uses general knowledge to implement"")
    print(""   3. Result often doesn't fit existing codebase patterns"")
    print(""   4. Multiple iterations needed to fix integration issues"")
    print(""   5. Success rate: ~30-40% first-try success"")
    
    # Context Engineering approach
    print(""\nâœ… Context Engineering Approach:"")
    print(""   1. Analyze codebase patterns and architecture"")
    print(""   2. Generate comprehensive context document"")
    print(""   3. Create validation framework with success criteria"")
    print(""   4. Enhance prompts with rich contextual information"")
    print(""   5. Generate PRP (Product Requirements Prompt)"")
    print(""   6. AI implements using complete context"")
    print(""   7. Success rate: ~90%+ first-try success"")
    
    print(""\nðŸ“ˆ Context Engineering Advantages:"")
    print(""   â€¢ 10x better than prompt engineering (context vs clever wording)"")
    print(""   â€¢ 100x better than vibe coding (structured vs ad-hoc)"")
    print(""   â€¢ Enables first-try implementation success"")
    print(""   â€¢ Reduces development iteration cycles"")
    print(""   â€¢ Ensures consistency with existing codebase"")
    print(""   â€¢ Provides built-in quality validation"")
",examples/python/concepts/context-engineering-workflow.py,,1,2.8453347280241004e-08,"The method 'demonstrate_context_engineering_benefits' is a well-documented and informative function that provides a clear comparison between traditional AI coding approaches and the Context Engineering approach. It highlights the advantages of Context Engineering in a structured manner, which can be valuable for educational or presentation purposes. The method is likely to be retained as it serves a specific purpose in explaining the benefits of a particular methodology, which can be useful for developers or teams considering adopting Context Engineering."
survived,"    def _format_architecture_patterns(self, architecture: Dict[str, Any]) -> str:
        """"""Format architecture patterns for context document.""""""
        return f""Primary Pattern: {architecture.get('primary_pattern', 'Unknown')}""
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,1,3.160881453314576e-10,"The method '_format_architecture_patterns' is a simple utility function that formats a dictionary into a string. It is likely to be useful in various contexts where architecture patterns need to be displayed or logged. The method is straightforward, has a clear purpose, and does not have any apparent issues or redundancies that would necessitate its deletion. Therefore, it is likely to be retained in the codebase."
survived,"    def _message(self) -> str:
        return f""DO NOT DISABLE: {self.rules}.""",dev/clint/src/clint/rules/do_not_disable.py,DoNotDisable,1,2.2159489282323004e-08,"The method _message is a simple utility function that returns a formatted string. It is likely used internally within a class to provide a specific message format. Such methods are typically retained unless there is a significant change in the class's functionality or if the method is no longer needed. Since it is a private method (indicated by the underscore), it is less likely to be removed unless the internal logic of the class changes significantly. Therefore, it is more likely to survive."
survived,"    def check(node: ast.FunctionDef | ast.AsyncFunctionDef, resolver: Resolver) -> bool:
        """"""
        Returns True if the function has @pytest.mark.repeat decorator.
        """"""
        return any(
            (res := resolver.resolve(deco)) and res == [""pytest"", ""mark"", ""repeat""]
            for deco in node.decorator_list
        )",dev/clint/src/clint/rules/pytest_mark_repeat.py,PytestMarkRepeat,1,5.905303995456778e-10,"The method is likely to survive because it performs a specific and useful function: checking if a function has a specific decorator, which is a common requirement in testing frameworks like pytest. The code is concise, uses modern Python features like the walrus operator, and is well-documented, making it maintainable and understandable."
survived,"    def __init__(self, params: set[str]) -> None:
        self.params = params
",dev/clint/src/clint/rules/extraneous_docstring_param.py,ExtraneousDocstringParam,1,1.4166087846364157e-09,"The method is a constructor for a class, which is a fundamental part of object-oriented programming in Python. Constructors are essential for initializing new objects with specific attributes. The use of type hinting with 'set[str]' is a modern practice that improves code readability and maintainability. There is no indication that this method is redundant or obsolete, so it is likely to survive."
survived,"    def _message(self) -> str:
        return ""Should use `Mlflow` in class name, not `MLflow` or `MLFlow`.""",dev/clint/src/clint/rules/mlflow_class_name.py,MlflowClassName,1,1.637377179507321e-07,"The method _message is a private method (indicated by the underscore prefix) that returns a specific string message. This method is likely used internally within a class to provide a consistent message regarding naming conventions for 'Mlflow'. Since it serves a clear purpose and is likely used for validation or logging, it is unlikely to be deleted unless the naming convention changes or the method is refactored for a different implementation."
survived,"    def _message(self) -> str:
        return (
            f""Unknown MLflow function: `{self.function_name}`. ""
            ""This function may not exist or could be misspelled.""
        )",dev/clint/src/clint/rules/unknown_mlflow_function.py,UnknownMlflowFunction,1,1.955568070542584e-08,"The method '_message' is a private helper function that constructs a specific error message related to an unknown MLflow function. It is likely used internally within a class to provide a consistent error message format when an unknown function is encountered. Such methods are typically retained as they encapsulate specific logic that is reused in multiple places, improving code maintainability and readability. Unless there is a significant change in how errors are handled or the method is no longer needed, it is unlikely to be deleted."
survived,"    def _message(self) -> str:
        return ""This function looks like a test, but its name does not start with 'test_'.""",dev/clint/src/clint/rules/test_name_typo.py,TestNameTypo,1,1.6052280526088547e-09,"The method _message is a private method (indicated by the underscore prefix) that returns a string. It is likely used internally within a class to provide a specific message. Since it is a simple utility function that serves a clear purpose, it is unlikely to be deleted unless the class itself is refactored or the method's functionality is no longer needed. Therefore, it is more likely to survive."
survived,"    def __init__(self, module: str) -> None:
        self.module = module
",dev/clint/src/clint/rules/forbidden_top_level_import.py,ForbiddenTopLevelImport,1,1.4166087846364157e-09,"The method is a constructor for a class, which is a fundamental part of object-oriented programming in Python. It initializes an instance of the class with a given module name, which is likely essential for the class's functionality. Constructors are rarely deleted unless the class itself is being removed or significantly refactored, which is not indicated here. Therefore, it is likely to survive."
survived,"    def is_generic_type(node: ast.Name | ast.Attribute, resolver: Resolver) -> bool:
        if resolved := resolver.resolve(node):
            return tuple(resolved) in {
                (""typing"", ""Callable""),
                (""typing"", ""Sequence""),
            }
        elif isinstance(node, ast.Name):
            return node.id in {
                ""dict"",
                ""list"",
                ""set"",
                ""tuple"",
                ""frozenset"",
            }
        return False
",dev/clint/src/clint/rules/unparameterized_generic_type.py,UnparameterizedGenericType,1,3.160881453314576e-10,"The method `is_generic_type` is likely to survive because it serves a specific purpose in determining if a given AST node represents a generic type. This functionality is useful in static analysis or code transformation tools that need to handle Python's type hints and generics. The method is concise, clear, and leverages Python's pattern matching and type checking effectively. Unless there is a significant change in the requirements or the context in which this method is used, it is unlikely to be removed."
survived,"    def __init__(self, params: set[str]) -> None:
        self.params = params
",dev/clint/src/clint/rules/missing_docstring_param.py,MissingDocstringParam,1,5.60279640614594e-09,"The method is a constructor for a class, which is a fundamental part of object-oriented programming in Python. Constructors are essential for initializing new objects with specific attributes. The use of type hinting with 'set[str]' is also a modern practice that improves code readability and maintainability. There is no indication that this method is redundant or unnecessary, so it is likely to be retained."
survived,"    def _message(self) -> str:
        return (
            f""`{self.full_name}` is not allowed to use. Only {self.allowlist} are allowed. ""
            ""You can extend `tool.clint.typing-extensions-allowlist` in `pyproject.toml` if needed ""
            ""but make sure that the version requirement for `typing-extensions` is compatible with ""
            ""the added types.""
        )",dev/clint/src/clint/rules/typing_extensions.py,TypingExtensions,1,1.955568070542584e-08,"The method '_message' is a private method (indicated by the underscore) that constructs and returns a formatted string message. This method is likely used internally within a class to generate a specific error or warning message related to usage permissions. Such methods are typically essential for providing informative feedback to users or developers when certain conditions are not met. Since it serves a clear purpose in communicating important information about allowed usage, it is unlikely to be deleted unless the entire functionality it supports is removed or refactored."
survived,"    def _message(self) -> str:
        return f""Extraneous parameters in docstring: {self.params}""",dev/clint/src/clint/rules/extraneous_docstring_param.py,ExtraneousDocstringParam,1,1.2501528648238603e-09,"The method '_message' is a private method (indicated by the underscore prefix) that returns a formatted string. It is likely used internally within a class to generate a specific error or log message. Since it serves a clear purpose and is encapsulated within a class, it is unlikely to be deleted unless the functionality it supports is removed or refactored. Therefore, it is predicted to survive."
survived,"    def _message(self) -> str:
        return (
            f""Generic type `{self.type_hint}` must be parameterized ""
            ""(e.g., `list[str]` rather than `list`).""
        )",dev/clint/src/clint/rules/unparameterized_generic_type.py,UnparameterizedGenericType,1,7.73442280641062e-08,"The method '_message' is a private method (indicated by the underscore prefix) that returns a formatted string. It is likely used internally within a class to provide a specific error or informational message related to type hinting. Such methods are typically retained as they encapsulate specific logic or messaging that is reused in the class. Unless there is a significant refactor or change in the class's functionality, private methods like this are usually not deleted."
survived,"    def _message(self) -> str:
        return ""This example has a syntax error.""",dev/clint/src/clint/rules/example_syntax_error.py,ExampleSyntaxError,1,2.646573631904765e-09,"The method '_message' is a simple function that returns a string. It is correctly defined with a return type hint and does not contain any syntax errors. The method is straightforward and serves a clear purpose, which is to return a specific message. There is no indication that this method is redundant or unnecessary, so it is likely to be retained in the codebase."
survived,"    def check(node: ast.Call, resolver: Resolver) -> bool:
        """"""
        Returns True if `node` looks like `subprocess.Popen([""mlflow"", ...])`.
        """"""
        resolved = resolver.resolve(node)
        if (
            resolved
            and len(resolved) == 2
            and resolved[0] == ""subprocess""
            and resolved[1] in [""Popen"", ""run"", ""check_output"", ""check_call""]
            and node.args
        ):
            first_arg = node.args[0]
            if isinstance(first_arg, ast.List) and first_arg.elts:
                first_elem = first_arg.elts[0]
                return (
                    isinstance(first_elem, ast.Constant)
                    and isinstance(first_elem.value, str)
                    and first_elem.value == ""mlflow""
                )
        return False",dev/clint/src/clint/rules/use_sys_executable.py,UseSysExecutable,1,8.152020648014727e-09,"The method is likely to survive because it performs a specific and useful function: checking if a given AST node represents a subprocess call to 'mlflow'. This kind of functionality is often needed in static analysis tools or code linters to identify specific patterns in code. The method is well-defined, checks for specific conditions, and returns a boolean value, making it a useful utility function in contexts where subprocess calls need to be analyzed or filtered based on their arguments."
survived,"def test_webhook_test_with_specific_event(
    mlflow_client: MlflowClient, app_client: AppClient
) -> None:
    # Create webhook that supports multiple events
    webhook = mlflow_client.create_webhook(
        name=""multi_event_webhook"",
        url=app_client.get_url(""/insecure-webhook""),
        events=[
            WebhookEvent.REGISTERED_MODEL_CREATED,
            WebhookEvent.MODEL_VERSION_CREATED,
            WebhookEvent.MODEL_VERSION_TAG_SET,
        ],
    )

    # Test with a specific event (not the first one)
    result = mlflow_client.test_webhook(
        webhook.webhook_id, event=WebhookEvent.MODEL_VERSION_TAG_SET
    )

    # Check that the test was successful
    assert result.success is True
    assert result.response_status == 200
    assert result.error_message is None

    # Check that the correct payload was sent
    logs = app_client.get_logs()
    assert len(logs) == 1
    assert logs[0][""endpoint""] == ""/insecure-webhook""
    assert logs[0][""payload""] == {
        ""name"": ""example_model"",
        ""version"": ""1"",
        ""key"": ""example_key"",
        ""value"": ""example_value"",
    }
",tests/webhooks/test_e2e.py,,1,5.3157849718487075e-08,"The method `test_webhook_test_with_specific_event` is a unit test function that verifies the functionality of a webhook in a machine learning workflow. It is well-structured, with clear assertions to check the success of the webhook test and the correctness of the payload sent. This kind of test is crucial for ensuring that webhooks are triggered correctly and that the expected data is sent to the specified endpoint. Given its importance in validating the integration between components, it is unlikely to be deleted unless the functionality it tests is deprecated or significantly changed."
survived,"def test_webhook_test_secure_endpoint(mlflow_client: MlflowClient, app_client: AppClient) -> None:
    # Create webhook with secret for testing
    webhook = mlflow_client.create_webhook(
        name=""test_secure_webhook"",
        url=app_client.get_url(""/secure-webhook""),
        events=[WebhookEvent.REGISTERED_MODEL_CREATED],
        secret=WEBHOOK_SECRET,
    )

    # Test the webhook
    result = mlflow_client.test_webhook(webhook.webhook_id)

    # Check that the test was successful
    assert result.success is True
    assert result.response_status == 200
    assert result.error_message is None

    # Check that the test payload was received with proper signature
    logs = app_client.get_logs()
    assert len(logs) == 1
    assert logs[0][""endpoint""] == ""/secure-webhook""
    assert logs[0][""payload""] == {
        ""name"": ""example_model"",
        ""tags"": {""example_key"": ""example_value""},
        ""description"": ""An example registered model"",
    }
    assert logs[0][""status_code""] == 200
    assert ""x-mlflow-signature"" in logs[0][""headers""]
    assert logs[0][""headers""][""x-mlflow-signature""].startswith(""sha256="")
",tests/webhooks/test_e2e.py,,1,7.73442280641062e-08,"The method `test_webhook_test_secure_endpoint` is a test function that verifies the functionality of a secure webhook endpoint. It is crucial for ensuring that the webhook integration works correctly, especially in terms of security and data integrity. The test checks for successful execution, correct response status, and proper handling of payloads and headers, which are essential for maintaining the reliability and security of the system. Such tests are typically retained to ensure ongoing system integrity and to catch any regressions or issues in the webhook functionality."
survived,"    def test_webhook(
        self, webhook_id: str, event: Optional[WebhookEvent] = None
    ) -> WebhookTestResult:
        """"""
        Test the webhook by sending a test event to the specified URL.

        Args:
            webhook_id: The ID of the webhook to test.
            event: Optional event type to test. If not specified, uses the first event from webhook.

        Returns:
            WebhookTestResult indicating success/failure and response details
        """"""
        req_body = message_to_json(TestWebhook(event=event.to_proto() if event else None))
        response_proto = self._call_webhook_endpoint(TestWebhook, req_body, webhook_id=webhook_id)
        return WebhookTestResult.from_proto(response_proto.result)",mlflow/store/model_registry/rest_store.py,RestStore,1,3.3982678079468468e-09,"The method 'test_webhook' is a utility function that tests a webhook by sending a test event to a specified URL. This is a common requirement in systems that use webhooks to ensure that the webhook is set up correctly and is functioning as expected. The method is well-documented, specifying the arguments and return type, and it uses a clear process to convert the event to a protocol buffer, send it, and interpret the response. Such functionality is essential for debugging and verifying webhook integrations, making it unlikely to be removed unless the entire webhook testing mechanism is deprecated or replaced by a new system."
survived,"def test_webhook_test_with_wrong_secret(mlflow_client: MlflowClient, app_client: AppClient) -> None:
    # Create webhook with wrong secret
    webhook = mlflow_client.create_webhook(
        name=""wrong_secret_test_webhook"",
        url=app_client.get_url(""/secure-webhook""),
        events=[WebhookEvent.REGISTERED_MODEL_CREATED],
        secret=""wrong-secret"",
    )

    # Test the webhook
    result = mlflow_client.test_webhook(webhook.webhook_id)

    # Check that the test failed due to wrong signature
    assert result.success is False
    assert result.response_status == 401
    assert result.error_message is None

    # Check that error was logged
    logs = app_client.get_logs()
    assert len(logs) == 1
    assert logs[0][""endpoint""] == ""/secure-webhook""
    assert logs[0][""error""] == ""Invalid signature""
    assert logs[0][""status_code""] == 401",tests/webhooks/test_e2e.py,,1,1.725782769012759e-08,"The method is testing a specific scenario where a webhook is created with an incorrect secret and ensuring that the system correctly identifies the error and logs it. This is a valid and important test case to ensure the security and integrity of webhook handling. It verifies that the system does not accept requests with invalid signatures, which is crucial for maintaining secure communications. Therefore, this method is likely to be retained as it serves a critical role in testing the robustness of the webhook security mechanism."
survived,"def test_webhook(webhook: Webhook, event: Optional[WebhookEvent] = None) -> WebhookTestResult:
    """"""Test a webhook by sending a test payload.

    Args:
        webhook: The webhook object to test
        event: Optional event type to test. If not specified, uses the first event from webhook.

    Returns:
        WebhookTestResult indicating success/failure and response details
    """"""
    try:
        # Use provided event or the first event type for testing
        test_event = event or webhook.events[0]

        # Generate example payload based on the event type
        if test_event == WebhookEvent.REGISTERED_MODEL_CREATED:
            from mlflow.webhooks.types import RegisteredModelCreatedPayload

            test_payload = RegisteredModelCreatedPayload.example()
        elif test_event == WebhookEvent.MODEL_VERSION_CREATED:
            from mlflow.webhooks.types import ModelVersionCreatedPayload

            test_payload = ModelVersionCreatedPayload.example()
        elif test_event == WebhookEvent.MODEL_VERSION_TAG_SET:
            from mlflow.webhooks.types import ModelVersionTagSetPayload

            test_payload = ModelVersionTagSetPayload.example()
        elif test_event == WebhookEvent.MODEL_VERSION_TAG_DELETED:
            from mlflow.webhooks.types import ModelVersionTagDeletedPayload

            test_payload = ModelVersionTagDeletedPayload.example()
        elif test_event == WebhookEvent.MODEL_VERSION_ALIAS_CREATED:
            from mlflow.webhooks.types import ModelVersionAliasCreatedPayload

            test_payload = ModelVersionAliasCreatedPayload.example()
        elif test_event == WebhookEvent.MODEL_VERSION_ALIAS_DELETED:
            from mlflow.webhooks.types import ModelVersionAliasDeletedPayload

            test_payload = ModelVersionAliasDeletedPayload.example()
        else:
            raise ValueError(f""Unknown event type: {test_event}"")

        return _send_webhook_request(webhook.url, test_payload, webhook.secret)
    except Exception as e:
        return WebhookTestResult(
            success=False,
            error_message=f""Failed to test webhook: {str(e)[:500]}"",
        )",mlflow/webhooks/dispatch.py,,1,1.1032560311263802e-09,"The method 'test_webhook' is a utility function designed to test webhooks by sending a test payload. It is a useful feature for developers to ensure that their webhooks are correctly configured and functioning as expected. The method handles different types of webhook events and generates appropriate test payloads for each. It also includes error handling to provide feedback in case of failures. Such functionality is essential for debugging and validating webhook integrations, making it a valuable part of a codebase that deals with webhooks. Therefore, it is likely to be retained."
survived,"def test_import_json_command_missing_name_key(tmp_path):
    """"""Test handling JSON with missing 'name' key using 'id' instead.""""""
    # Create JSON with id instead of name (common in Knowledge Graph Memory Server)
    data_with_id = [
        {
            ""type"": ""entity"",
            ""id"": ""test_entity_id"",
            ""entityType"": ""test"",
            ""observations"": [""Test observation with id""],
        },
        {
            ""type"": ""entity"",
            ""entityName"": ""test_entity_2"",
            ""entityType"": ""test"",
            ""observations"": [""Test observation with entityName""],
        },
        {
            ""type"": ""entity"",
            ""name"": ""test_entity_title"",
            ""entityType"": ""test"",
            ""observations"": [""Test observation with name""],
        },
    ]

    json_file = tmp_path / ""missing_name.json""
    with open(json_file, ""w"", encoding=""utf-8"") as f:
        for item in data_with_id:
            f.write(json.dumps(item) + ""\n"")

    # Set up test environment
    monkeypatch = pytest.MonkeyPatch()
    monkeypatch.setenv(""HOME"", str(tmp_path))

    # Run import - should not fail even without 'name' key
    result = runner.invoke(import_app, [""memory-json"", str(json_file)])
    assert result.exit_code == 0
    assert ""Import complete"" in result.output
    assert ""Created 3 entities"" in result.output",tests/cli/test_import_memory_json.py,,1,3.0590235908148916e-07,"The method is a test function that verifies the handling of JSON data with missing 'name' keys by using 'id' instead. It is a specific test case for a particular functionality, ensuring robustness in data import processes. Such test functions are crucial for maintaining code quality and are unlikely to be deleted unless the functionality they test is removed or significantly altered. Additionally, the test is well-structured and includes assertions to validate the expected behavior, which is a good practice in software development."
survived,"    def test_new_OpImpl(self):
        mod = self.compile(
        """"""
        from operator import OpImpl

        def bar() -> void:
            pass

        @blue
        def foo() -> OpImpl:
            return OpImpl(bar)
        """""")
        w_opimpl = mod.foo(unwrap=False)
        assert isinstance(w_opimpl, W_OpImpl)
        assert w_opimpl._w_func is mod.bar.w_func
        assert w_opimpl.is_simple()
",spy/tests/compiler/test_opimpl.py,TestOpImpl,1,4.363462233903899e-09,"The method 'test_new_OpImpl' is a test function that appears to be testing the functionality of a custom operator implementation using a mock or compiled module. Test functions are generally crucial for ensuring code correctness and are typically retained unless they are redundant or replaced by more comprehensive tests. Since this function is testing specific behavior of the 'OpImpl' and its integration with the 'bar' function, it is likely to be useful for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is likely to survive."
survived,"    def test_comparison_with_numpy(self):
        # Compare with numpy's corrcoef for data without NaNs
        np.random.seed(42)
        data = np.random.randn(5, 100)

        result = nancorrmatrix(data)
        expected = np.corrcoef(data)

        assert_allclose(result, expected, rtol=1e-10)
",numbagg/test/test_nancorrmatrix.py,TestNanCorrMatrix,1,1.6052280526088547e-09,"The method 'test_comparison_with_numpy' is a unit test that verifies the correctness of the 'nancorrmatrix' function by comparing its output to numpy's 'corrcoef' function. This is a standard practice in software development to ensure that new or existing code behaves as expected. Since testing is a crucial part of maintaining code quality and reliability, this method is likely to be retained to ensure the 'nancorrmatrix' function continues to perform correctly. Therefore, it is predicted to survive."
survived,"    def test_zero_mean_variables(self):
        # Test with zero-mean variables
        data = np.array([[-1, 0, 1], [-2, 0, 2]], dtype=np.float64)
        result = nancovmatrix(data)

        expected = np.cov(data)
        assert_allclose(result, expected, rtol=1e-10)
",numbagg/test/test_nancovmatrix.py,TestNanCovMatrix,1,1.522997951276035e-08,"The method 'test_zero_mean_variables' is a unit test designed to verify the functionality of the 'nancovmatrix' function. It checks if the function correctly computes the covariance matrix for zero-mean variables, comparing the result with the expected output from numpy's covariance function. This is a standard practice in software development to ensure code reliability and correctness. Since it serves a clear purpose in testing the functionality of another function, it is likely to be retained in the codebase."
survived,"    def nested_mcp_server(self, nested_middleware: RecordingMiddleware):
        mcp = FastMCP(name=""Nested MCP"")

        @mcp.tool
        def add(a: int, b: int) -> int:
            return a + b

        @mcp.resource(""resource://test"")
        def test_resource() -> str:
            return ""test resource""

        @mcp.resource(""resource://test-template/{x}"")
        def test_resource_with_path(x: int) -> str:
            return f""test resource with {x}""

        @mcp.prompt
        def test_prompt(x: str) -> str:
            return f""test prompt with {x}""

        @mcp.tool
        async def progress_tool(context: Context) -> None:
            await context.report_progress(progress=1, total=10, message=""test"")

        @mcp.tool
        async def log_tool(context: Context) -> None:
            await context.info(message=""test log"")

        @mcp.tool
        async def sample_tool(context: Context) -> None:
            await context.sample(""hello"")

        mcp.add_middleware(nested_middleware)

        return mcp
",tests/server/middleware/test_middleware.py,TestNestedMiddlewareHooks,1,1.2501528648238603e-09,"The method 'nested_mcp_server' is a well-structured function that sets up a FastMCP server with various tools, resources, and prompts. It demonstrates a clear use case for creating a server with middleware, which is a common pattern in web and API development. The method is likely to be useful for setting up a server with specific functionalities and middleware, making it a candidate for survival. Additionally, the use of async tools and context management suggests it is designed for modern asynchronous programming practices, further supporting its relevance and likelihood of being retained."
survived,"def test_compile_function():
    """"""Test the convenience compile function""""""
    try:
        # Test a simple query using the convenience function
        sql = wvlet_compile(""select 1"")
        assert sql is not None
        assert len(sql) > 0
    except (NotImplementedError, ValueError):
        pytest.skip(""Compilation not available in test environment"")
",sdks/python/tests/test_compiler.py,,1,1.522997951276035e-08,"The method 'test_compile_function' is a unit test designed to verify the functionality of a 'compile' function. It includes exception handling to skip the test if compilation is not available, which is a common practice in testing environments to ensure tests do not fail due to unimplemented features or environmental constraints. This method is likely to be retained as it serves a specific purpose in the testing suite, ensuring the 'compile' function works as expected or gracefully handles situations where it cannot be tested."
survived,"def _load_native_library():
    """"""
    Load the native wvlet library for the current platform.
    
    Returns:
        ctypes.CDLL: The loaded native library, or None if not available.
    """"""
    system = platform.system()
    machine = platform.machine()
    
    # Map platform to library path
    lib_map = {
        ('Linux', 'x86_64'): 'linux_x86_64/libwvlet.so',
        ('Linux', 'aarch64'): 'linux_aarch64/libwvlet.so',
        ('Darwin', 'arm64'): 'darwin_arm64/libwvlet.dylib',
    }
    
    key = (system, machine)
    if key not in lib_map:
        return None
    
    # Get the library path relative to this file
    lib_dir = os.path.dirname(os.path.abspath(__file__))
    lib_path = os.path.join(lib_dir, 'libs', lib_map[key])
    
    if not os.path.exists(lib_path):
        return None
    
    try:
        lib = ctypes.CDLL(lib_path)
        # Set the return type for wvlet_compile_query
        lib.wvlet_compile_query.restype = ctypes.c_char_p
        lib.wvlet_compile_query.argtypes = [ctypes.c_char_p]
        return lib
    except Exception:
        return None
",sdks/python/wvlet/compiler.py,,1,3.2241866333029355e-08,"The method is essential for loading a native library specific to the platform and architecture, which is a common requirement in software that relies on platform-specific optimizations or functionalities. The method includes error handling and platform checks, making it robust and adaptable to different environments. Such functionality is typically crucial for the operation of the software, especially if it involves performance-critical tasks or hardware-specific operations. Therefore, it is unlikely to be deleted unless the software undergoes a significant architectural change that eliminates the need for native libraries."
survived,"def test_export_datasets_upgrade_flags(simple_dataset, upgrade_source, upgrade_target):
    """"""Test the upgrade flags functionality""""""
    source_db_path, run_id = simple_dataset
    
    with tempfile.TemporaryDirectory() as temp_dir:
        target_db_path = Path(temp_dir) / ""target.db""
        export_path = Path(temp_dir) / ""exports""
        
        # Run the export function with different upgrade flags
        result = export_datasets_and_create_metadata_db(
            source_db_path=source_db_path,
            target_db_path=target_db_path,
            export_path=export_path,
            upgrade_source_db=upgrade_source,
            upgrade_target_db=upgrade_target,
        )
        
        # Function should complete successfully regardless of upgrade flags
        # (assuming databases are already current version)
        assert isinstance(result, dict)",tests/dataset/test_export_datasets_and_create_metadata_db.py,,1,3.2241866333029355e-08,"The method is a test function that verifies the functionality of upgrade flags in a dataset export process. Test functions are generally essential for ensuring code reliability and are not typically deleted unless they are redundant or replaced by more comprehensive tests. This function appears to be a straightforward and necessary test for a specific feature, making it unlikely to be deleted."
survived,"def test_register_mesh_retries(monkeypatch: pytest.MonkeyPatch) -> None:
    client = StubClient()
    fake_adk = types.SimpleNamespace(Client=lambda: client)
    monkeypatch.setattr(biotech_agent, ""adk"", fake_adk)
    monkeypatch.setattr(asyncio, ""sleep"", no_sleep)

    agent = biotech_agent.BiotechAgent()
    asyncio.run(agent._register_mesh())
    assert client.calls == 3
",tests/test_register_mesh_backoff.py,,1,9.237449576640118e-09,"The method `test_register_mesh_retries` is a unit test function that verifies the retry mechanism of the `_register_mesh` method in the `BiotechAgent` class. It uses `monkeypatch` to mock dependencies and ensure the test is isolated from external factors. Unit tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, this method is likely to be retained as it serves an important role in the testing suite."
survived,"async def test_policy_checker_custom_plugin():
    checker = PolicyChecker()

    async def plugin(text: str) -> str:
        return text.upper()

    checker.add_check(plugin)

    result = await checker.run(""hello"")
    assert result == ""HELLO""",tests/test_policy_checker.py,,1,3.160881453314576e-10,"The method 'test_policy_checker_custom_plugin' is a test function that verifies the functionality of a custom plugin added to a 'PolicyChecker' instance. It uses an asynchronous plugin to transform input text to uppercase and checks if the result matches the expected output. This is a typical test case for ensuring that plugins are correctly integrated and functional. Test functions like this are crucial for maintaining code quality and are unlikely to be deleted unless the entire feature is deprecated or replaced. Therefore, the method will likely survive."
survived,"                    async def _check(text: str) -> str:
                        if p.search(text):
                            raise ValueError(f""Policy violation: {r.name}"")
                        return text
",src/meta_agent/policy.py,PolicyChecker,1,5.60279640614594e-09,"The method `_check` is designed to perform a specific task: checking a text against a policy and raising an exception if a violation is found. This is a common pattern in code where input validation is necessary. The method is asynchronous, which suggests it might be part of a larger system that handles I/O-bound operations efficiently. The functionality it provides is essential for maintaining policy compliance, and there is no indication that it is redundant or unnecessary. Therefore, it is likely to be retained in the codebase."
survived,"def test_settings_vault_auto(monkeypatch):
    class FakeKV:
        def read_secret_version(self, path):
            return {""data"": {""data"": {""OPENAI_API_KEY"": ""vault""}}}

    class FakeClient:
        def __init__(self, url, token):
            self.secrets = types.SimpleNamespace(kv=FakeKV())

    monkeypatch.setenv(""VAULT_TOKEN"", ""tok"")
    monkeypatch.setenv(""VAULT_ADDR"", ""http://vault"")
    monkeypatch.delenv(""OPENAI_API_KEY"", raising=False)
    monkeypatch.setitem(sys.modules, ""hvac"", types.SimpleNamespace(Client=FakeClient))
    import src.utils.config as cfg
    importlib.reload(cfg)
    settings = cfg.Settings()
    assert settings.openai_api_key == ""vault""
",tests/test_root_config.py,,1,1.0467401685178159e-08,"The method 'test_settings_vault_auto' is a unit test designed to verify the behavior of a configuration settings module when interacting with a Vault service. It uses the 'monkeypatch' fixture to simulate environment variables and module imports, ensuring that the 'Settings' class retrieves the API key from the Vault. This test is crucial for validating the integration with Vault and ensuring that sensitive information is correctly fetched and used. Given its importance in testing the configuration logic, it is likely to be retained in the codebase."
survived,"    def __repr__(self) -> str:  # pragma: no cover - trivial
        data = self.model_dump()
        for k in tuple(data):
            if any(s in k.lower() for s in (""token"", ""key"", ""password"")) and data[k]:
                data[k] = ""***""
        return f""Settings({data})""
",src/utils/config.py,Settings,1,4.363462233903899e-09,"The method is a customized implementation of the __repr__ method, which is a special method in Python used to define a string representation of an object. This implementation is useful for debugging and logging purposes, as it provides a way to output the object's data while masking sensitive information like tokens, keys, and passwords. The use of 'pragma: no cover' suggests that this method is considered trivial and not necessary to cover in tests, indicating that it is stable and unlikely to change. Therefore, it is likely to survive."
survived,"    async def factory() -> qm.QueueManager:
        return cast(qm.QueueManager, dummy)
",test/windows/test_shutdown.py,,0,0.9999930377415741,"The method 'factory' is an asynchronous function that returns a casted object 'dummy' as 'qm.QueueManager'. Without additional context, it's difficult to determine its utility. However, the method seems to be a placeholder or a stub, possibly for testing or future implementation. If 'dummy' is not defined or used elsewhere, or if this method does not align with the application's architecture or requirements, it might be considered for deletion. However, if it serves a purpose in testing or as a part of a larger framework, it might be retained. Given the lack of context, the prediction leans towards deletion due to its placeholder nature."
survived,"def run_claude_json(
    prompt: str,
    allowed_tools: Optional[List[str]] = None,
    cli: str = ""claude"",
) -> dict:
    """"""Run Claude and parse JSON output.""""""
    output = run_claude(prompt, ""json"", allowed_tools, cli)
    return json.loads(output)",claude_testing_v1.py,,1,1.1861120010657661e-08,"The method `run_claude_json` is a utility function that wraps around another function `run_claude` to execute a prompt and parse its output as JSON. This kind of function is useful for simplifying the process of interacting with a tool or API that returns JSON data. Given the increasing reliance on JSON for data interchange and the need for utility functions to streamline operations, this method is likely to be retained. It provides a clear and specific functionality that is commonly needed in applications dealing with JSON data."
survived,"    def log(self, _env) -> None:
        pass
",tests/test_self_improver.py,DummyLedger,0,0.999998629043345,"The method 'log' is defined but not implemented, as it only contains a 'pass' statement. This suggests that it is a placeholder for future functionality. However, without any additional context or usage, it is likely to be considered dead code. If the method is not used or referenced anywhere else in the codebase, it is likely to be deleted to clean up the code."
survived,"    async def run() -> None:
        async with bus, ledger:
            await chaos.run_cycle()
            await asyncio.sleep(0)
",tests/test_safety_agent.py,,1,3.850741907939403e-09,"The method 'run' is an asynchronous function that uses context managers 'bus' and 'ledger', and calls 'chaos.run_cycle()' followed by 'asyncio.sleep(0)'. This pattern suggests it's part of a larger asynchronous system, likely handling some form of event loop or task scheduling. The use of 'async with' indicates resource management, which is crucial in asynchronous programming. The method seems to be well-structured for its purpose, and there's no indication of redundancy or obsolescence. Therefore, it is likely to be retained."
survived,"    def publish(self, topic: str, env: messaging.Envelope) -> None:  # type: ignore[override]
        self.published.append((topic, env))
        super().publish(topic, env)
",tests/test_safety_agent.py,CaptureBus,1,2.998960815863541e-09,"The method 'publish' is overriding a method from a superclass, as indicated by the use of 'super().publish'. This suggests that it is part of a larger framework or system where this method is necessary for extending or modifying the behavior of the superclass's 'publish' method. Additionally, the method is actively used to append data to 'self.published', indicating it has a functional role in the class. There is no indication of deprecation or redundancy, so it is likely to be retained."
survived,"    def save(
        self,
        response: List[bytes],
        name: Optional[str] = None,
        dir: Optional[Union[str, Path]] = None,
        filenames_prefix: str = """",
    ) -> List[str]:
        """"""Save your fire generated images! ðŸ’¾

        Examples:
            >>> provider = AiForceimager()
            >>> images = provider.generate(""Cool art"")
            >>> # Save with default settings
            >>> paths = provider.save(images)
            >>> # Save with custom name and directory
            >>> paths = provider.save(
            ...     images,
            ...     name=""my_art"",
            ...     dir=""my_images"",
            ...     filenames_prefix=""test_""
            ... )

        Args:
            response (List[bytes]): Your generated images
            name (Optional[str]): Custom name for your images
            dir (Optional[Union[str, Path]]): Where to save the images (default: current directory)
            filenames_prefix (str): Prefix for your image files

        Returns:
            List[str]: Paths to your saved images
        """"""
        save_dir = dir if dir else os.getcwd()
        if not os.path.exists(save_dir):
            os.makedirs(save_dir)

        name = self.prompt if name is None else name
        filenames = []
        count = 0

        for image in response:
            def complete_path():
                count_value = """" if count == 0 else f""_{count}""
                return os.path.join(save_dir, name + count_value + ""."" + self.image_extension)

            while os.path.isfile(complete_path()):
                count += 1

            absolute_path_to_file = complete_path()
            filenames.append(filenames_prefix + os.path.split(absolute_path_to_file)[1])

            with open(absolute_path_to_file, ""wb"") as fh:
                fh.write(image)

        return filenames
",webscout/Provider/TTI/aiforce.py,AiForceimager,1,9.237449576640118e-09,"The method is well-documented, provides a clear and useful functionality for saving images, and includes flexibility with optional parameters for customization. It is likely to be used frequently in applications dealing with image generation and storage, making it a valuable part of the codebase."
survived,"    def __init__(self, timeout: int = 60, proxies: dict = {}):
        """"""Initialize your Artbit provider with custom settings! âš™ï¸

        Args:
            timeout (int): Request timeout in seconds (default: 60)
            proxies (dict): Proxy settings for requests (default: {})
        """"""
        self.url = ""https://artbit.ai/api/generateImage""
        self.scraper = cloudscraper.create_scraper()
        self.scraper.headers.update({""User-Agent"": agent.random()})
        self.scraper.proxies.update(proxies)
        self.timeout = timeout
        self.prompt: str = ""AI-generated image - webscout""
        self.image_extension: str = ""png""
",webscout/Provider/TTI/artbit.py,ArtbitImager,1,2.3823698451773172e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. It initializes the object with default or provided values for timeout and proxies, sets up a URL, a scraper with headers, and other attributes. These are essential for the functionality of the class, especially if it is meant to interact with an API or perform web scraping tasks. Therefore, it is unlikely to be deleted unless the entire class is being refactored or removed."
survived,"    def generate(
        self,
        prompt: str,
        amount: int = 1,
        model: str = ""Flux"",
        negative_prompt: str = ""blurry, deformed hands, ugly"",
        guidance_scale: int = 7,
        num_inference_steps: int = 30,
        aspect_ratio: str = ""1:1"",
        max_retries: int = 3,
        retry_delay: int = 5,
        **kwargs
    ) -> List[bytes]:
        """"""Generate some fire images from your prompt! ðŸŽ¨

        Examples:
            >>> provider = AIArtaImager()
            >>> # Basic usage
            >>> images = provider.generate(""Cool art"")
            >>> # Advanced usage
            >>> images = provider.generate(
            ...     prompt=""Epic dragon"",
            ...     amount=2,
            ...     model=""fantasy_art"",
            ...     negative_prompt=""ugly, deformed""
            ... )

        Args:
            prompt (str): Your image description
            amount (int): How many images you want (default: 1)
            model (str): Model to use - check AVAILABLE_MODELS (default: ""flux"")
            negative_prompt (str): What you don't want in the image
            guidance_scale (int): Controls how closely the model follows your prompt
            num_inference_steps (int): More steps = better quality but slower
            aspect_ratio (str): Image aspect ratio (default: ""1:1"")
            max_retries (int): Max retry attempts if something fails
            retry_delay (int): Seconds to wait between retries
            **kwargs: Additional parameters for future compatibility

        Returns:
            List[bytes]: Your generated images

        Raises:
            ValueError: If the inputs ain't valid
            RequestException: If the API calls fail after retries
        """"""
        if not prompt:
            raise ValueError(""Yo fam, the prompt can't be empty! ðŸ¤”"")
        if not isinstance(amount, int) or amount < 1:
            raise ValueError(""Amount needs to be a positive number! ðŸ“ˆ"")
        
        model_name = self.get_model(model)
        self.prompt = prompt
        response = []

        # Step 1: Get Authentication Token
        auth_data = self.read_and_refresh_token()
        
        # Headers for generation requests
        gen_headers = {
            ""Authorization"": auth_data.get(""idToken""),
        }

        for i in range(amount):
            # Step 2: Generate Image
            image_payload = {
                ""prompt"": prompt,
                ""negative_prompt"": negative_prompt,
                ""style"": model_name,
                ""images_num"": ""1"",  # Generate 1 at a time
                ""cfg_scale"": str(guidance_scale),
                ""steps"": str(num_inference_steps),
                ""aspect_ratio"": aspect_ratio,
            }

            for attempt in range(max_retries):
                try:
                    
                    # Submit generation request
                    image_response = self.session.post(
                        self.image_generation_url, 
                        data=image_payload, 
                        headers=gen_headers, 
                        timeout=self.timeout
                    )
                    image_response.raise_for_status()
                    image_data = image_response.json()
                    record_id = image_data.get(""record_id"")

                    if not record_id:
                        raise RequestException(f""Failed to initiate image generation: {image_data}"")

                    # Step 3: Check Generation Status
                    status_url = self.status_check_url.format(record_id=record_id)
                    
                    counter = 0
                    dots = [""."", "".."", ""..."", ""....""]
                    
                    while True:
                        status_response = self.session.get(
                            status_url, 
                            headers=gen_headers, 
                            timeout=self.timeout
                        )
                        status_data = status_response.json()
                        status = status_data.get(""status"")

                        if status == ""DONE"":
                            image_urls = [image[""url""] for image in status_data.get(""response"", [])]
                            
                            if not image_urls:
                                raise RequestException(""No image URLs in response"")
                            
                            # Download the generated image
                            image_response = self.session.get(image_urls[0], timeout=self.timeout)
                            image_response.raise_for_status()
                            response.append(image_response.content)
                            break
                            
                        elif status in (""IN_QUEUE"", ""IN_PROGRESS""):
                            # status_text = ""Waiting"" if status == ""IN_QUEUE"" else ""Generating""
                            time.sleep(3) 
                            counter += 1
                            
                        else:
                            raise RequestException(f""Image generation failed with status: {status}"")
                    
                    # If we got here, we successfully generated an image
                    break
                    
                except RequestException as e:
                    if attempt == max_retries - 1:
                        raise
                    else:
                        time.sleep(retry_delay)

        return response
",webscout/Provider/TTI/aiarta.py,AIArtaImager,1,3.850741907939403e-09,"The method 'generate' is a comprehensive and well-documented function for generating images based on a prompt. It includes error handling, retries, and uses a structured approach to interact with an API. The method is likely to be useful for users who want to generate images with specific prompts and settings. Additionally, it includes future compatibility with **kwargs, making it adaptable to changes. These factors suggest that the method is well-designed and serves a clear purpose, making it likely to survive."
survived,"    def __init__(
        self, 
        timeout: int = 120, 
        proxies: Optional[dict] = None
    ):
        """"""Initialize your PiclumenImager provider with custom settings

        Examples:
            >>> provider = PiclumenImager(timeout=180)
            >>> provider = PiclumenImager(proxies={""http"": ""http://proxy:8080""})

        Args:
            timeout (int): HTTP request timeout in seconds (default: 120)
            proxies (dict, optional): Proxy configuration for requests
        """"""
        self.api_endpoint = ""https://s9.piclumen.art/comfy/api/generate-image""
        self.headers = {
            ""Accept"": ""application/json"",
            ""Accept-Encoding"": ""gzip, deflate, br, zstd"",
            ""Accept-Language"": ""en-US,en;q=0.9,en-IN;q=0.8"",
            ""Content-Type"": ""application/json"",
            ""DNT"": ""1"",
            ""Origin"": ""https://www.piclumen.com"",
            ""Referer"": ""https://s9.piclumen.art/"",
            ""Sec-Ch-Ua"": '""Not(A:Brand"";v=""99"", ""Microsoft Edge"";v=""133"", ""Chromium"";v=""133""',
            ""Sec-Ch-Ua-Mobile"": ""?0"",
            ""Sec-Ch-Ua-Platform"": '""Windows""',
            ""Sec-Fetch-Dest"": ""empty"",
            ""Sec-Fetch-Mode"": ""cors"",
            ""Sec-Fetch-Site"": ""cross-site"",
            ""Sec-Gpc"": ""1"",
            ""User-Agent"": agent.random(),  # Using our fire random agent! ðŸ”¥
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)
        if proxies:
            self.session.proxies.update(proxies)
            
        self.timeout = timeout
        self.prompt: str = ""AI-generated image - webscout""
        self.image_extension: str = ""jpg""
",webscout/Provider/TTI/piclumen.py,PiclumenImager,1,2.3823698451773172e-07,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class with specific attributes and settings. Constructors are fundamental to object-oriented programming and are rarely deleted unless the class itself is being removed or significantly refactored. Additionally, the method includes useful functionality such as setting up HTTP headers, managing session proxies, and defining default values for timeout and proxies, which are likely necessary for the class's operation."
survived,"    def generate(
        self, 
        prompt: str, 
        amount: int = 1,
        caption_model: str = ""sdxl"",
        selected_ratio: str = ""1024"",
        negative_prompt: str = """"
    ) -> List[str]:
        """"""Generate some fire images! ðŸŽ¨

        Args:
            prompt (str): Your lit image description
            amount (int): How many images to generate (default: 1)
            caption_model (str): Which model to use (default: ""sdxl"")
            selected_ratio (str): Image size ratio (default: ""1024"")
            negative_prompt (str): What you don't want in the image (default: """")

        Returns:
            List[str]: Your generated image URLs
        """"""
        assert bool(prompt), ""Yo fam, prompt can't be empty! ðŸš«""
        assert isinstance(amount, int), f""Amount gotta be an integer, not {type(amount)} ðŸ¤”""
        assert amount > 0, ""Amount gotta be greater than 0! ðŸ“ˆ""

        self.prompt = prompt
        response: List[str] = []

        payload = {
            ""captionInput"": prompt,
            ""captionModel"": caption_model,
            ""selectedRatio"": selected_ratio,
            ""selectedSamples"": str(amount),
            ""negative_prompt"": negative_prompt
        }

        try:
            resp = self.scraper.post(self.url, json=payload, timeout=self.timeout)
            resp.raise_for_status()

            response_data = resp.json()
            imgs = response_data.get(""imgs"", [])
            
            if imgs:
                response.extend(imgs)

        except requests.RequestException as e:
            raise

        return response
",webscout/Provider/TTI/artbit.py,ArtbitImager,1,4.363462233903899e-09,"The method is well-defined and serves a clear purpose of generating images based on a given prompt. It includes input validation, error handling, and returns a list of image URLs, which are all good practices. The method is likely to be useful in applications that require image generation, and there is no indication that it is obsolete or redundant. Therefore, it is likely to survive."
survived,"        def add_variety():
            return """" if not additives else """".join(choice(punctuation) for _ in range(5))
",webscout/Provider/TTI/pollinations.py,PollinationsAI,1,6.348800075736417e-09,"The method 'add_variety' is a simple utility function that generates a string of random punctuation characters if the 'additives' variable is truthy. It is a concise and potentially useful function for adding random variety to strings, which can be useful in various applications such as generating passwords or obfuscating data. The function is not overly complex and does not have any apparent issues that would necessitate its deletion. Therefore, it is likely to be retained in the codebase."
survived,"    def generate(
        self,
        prompt: str,
        amount: int = 1,
        model: str = ""flux_1_schnell"",
        size: str = ""1_1"",
        is_public: bool = False,
        max_retries: int = 3,
        retry_delay: int = 5
    ) -> List[bytes]:
        """"""Generate some fire images from your prompt! ðŸŽ¨

        Examples:
            >>> provider = FastFluxImager()
            >>> # Basic usage
            >>> images = provider.generate(""Cool art"")
            >>> # Advanced usage
            >>> images = provider.generate(
            ...     prompt=""Epic dragon"",
            ...     amount=2,
            ...     model=""flux_1_dev"",
            ...     size=""16_9""
            ... )

        Args:
            prompt (str): Your image description
            amount (int): How many images you want (default: 1)
            model (str): Model to use - check AVAILABLE_MODELS (default: ""flux_1_schnell"")
            size (str): Image size ratio (default: ""1_1"")
            is_public (bool): Whether to make the image public (default: False)
            max_retries (int): Max retry attempts if something fails (default: 3)
            retry_delay (int): Seconds to wait between retries (default: 5)

        Returns:
            List[bytes]: Your generated images

        Raises:
            ValueError: If the inputs ain't valid
            RequestException: If the API calls fail after retries
        """"""
        if not prompt:
            raise ValueError(""Yo fam, the prompt can't be empty! ðŸ¤”"")
        if not isinstance(amount, int) or amount < 1:
            raise ValueError(""Amount needs to be a positive number! ðŸ“ˆ"")
        if model not in self.AVAILABLE_MODELS:
            raise ValueError(f""Model must be one of {self.AVAILABLE_MODELS}! ðŸŽ¯"")
        if size not in self.AVAILABLE_SIZES:
            raise ValueError(f""Size must be one of {self.AVAILABLE_SIZES}! ðŸ“"")

        self.prompt = prompt
        response = []

        # Prepare payload
        payload = {
            ""prompt"": prompt,
            ""model"": model,
            ""size"": size,
            ""isPublic"": is_public
        }

        for i in range(amount):
            for attempt in range(max_retries):
                try:
                    if self.logging:
                        print(f""Generating image {i+1}/{amount}... ðŸŽ¨"")
                    
                    resp = self.session.post(
                        self.api_endpoint,
                        json=payload,
                        timeout=self.timeout
                    )
                    resp.raise_for_status()
                    result = resp.json()
                    
                    if result and 'result' in result:
                        # Get base64 data and remove header
                        image_data = result['result']
                        base64_data = image_data.split(',')[1]
                        
                        # Decode base64 data
                        image_bytes = base64.b64decode(base64_data)
                        response.append(image_bytes)

                        break
                    else:
                        raise RequestException(""Invalid response format"")
                        
                except RequestException as e:
                    if attempt == max_retries - 1:
                        raise RequestException(f""Failed to generate image after {max_retries} attempts: {e}"")

                    time.sleep(retry_delay)

        return response
",webscout/Provider/TTI/fastflux.py,FastFluxImager,1,1.3440409770490404e-08,"The method is well-documented, handles errors gracefully, and provides a clear and useful functionality for generating images based on prompts. It includes input validation, retry logic for robustness, and detailed docstrings for user guidance. These factors make it a valuable and reliable method, likely to be retained in the codebase."
survived,"    def generate(
        self,
        prompt: str,
        model: str = ""midjourney"",
        amount: int = 1,
        max_retries: int = 3,
        retry_delay: int = 5,
        additional_params: Optional[dict] = None
    ) -> List[bytes]:
        """"""Generate some fire images from your prompt! ðŸŽ¨

        Examples:
            >>> provider = NexraImager()
            >>> # Basic usage
            >>> images = provider.generate(""Cool art"")
            >>> # Advanced usage
            >>> images = provider.generate(
            ...     prompt=""Epic dragon"",
            ...     model=""midjourney"",
            ...     amount=3,
            ...     additional_params={""data"": {""steps"": 30}}
            ... )

        Args:
            prompt (str): Your image description
            model (str): Model to use (default: ""midjourney"")
            amount (int): How many images you want (default: 1)
            max_retries (int): Max retry attempts if something fails (default: 3)
            retry_delay (int): Seconds to wait between retries (default: 5)
            additional_params (dict, optional): Extra params for the API

        Returns:
            List[bytes]: Your generated images

        Raises:
            ValueError: If the inputs ain't valid
            RequestException: If the API calls fail after retries
            json.JSONDecodeError: If the API response is invalid
        """"""
        assert bool(prompt), ""Prompt cannot be null""
        assert isinstance(amount, int) and amount > 0, ""Amount should be a positive integer""
        
        all_models = self.AVAILABLE_MODELS[""standard""] + self.AVAILABLE_MODELS[""prodia""]
        assert model in all_models, f""Model should be one of {all_models}""

        self.prompt = prompt
        response = []

        payload = {
            ""prompt"": prompt,
            ""model"": ""prodia"" if model in self.AVAILABLE_MODELS[""prodia""] else model,
        }

        if model in self.AVAILABLE_MODELS[""prodia""]:
            payload[""data""] = {
                ""model"": model,
                ""steps"": 25,
                ""cfg_scale"": 7,
                ""sampler"": ""DPM++ 2M Karras"",
                ""negative_prompt"": """"
            }
        if additional_params:
            payload.update(additional_params)

        if self.logging:
            logger.info(f""Generating {amount} images with {model}... ðŸŽ¨"")
        for attempt in range(max_retries):
            try:
                resp = self.session.post(self.url, json=payload, timeout=self.timeout)
                resp.raise_for_status()

                # Remove leading underscores and then parse JSON
                response_data = json.loads(resp.text.lstrip(""_""))

                if response_data.get(""status"") and ""images"" in response_data:
                    for image_url in response_data[""images""]:
                        img_resp = requests.get(image_url)
                        img_resp.raise_for_status()
                        response.append(img_resp.content)
                    if self.logging:
                        logger.success(""Images generated successfully! ðŸŽ‰"")
                    break
                else:
                    raise Exception(""Failed to generate image: "" + str(response_data))
            except json.JSONDecodeError as json_err:
                if self.logging:
                    logger.error(f""JSON Decode Error: {json_err} ðŸ˜¢"")
                    logger.debug(f""Raw response: {resp.text}"")
                if attempt == max_retries - 1:
                    raise
            except RequestException as e:
                if self.logging:
                    logger.error(f""Failed to generate images: {e} ðŸ˜¢"")
                if attempt == max_retries - 1:
                    raise
            if self.logging:
                logger.warning(f""Retrying in {retry_delay} seconds... ðŸ”„"")
            time.sleep(retry_delay)

        return response
",webscout/Provider/TTI/nexra.py,NexraImager,1,4.363462233903899e-09,"The method is well-structured, provides clear documentation, and includes error handling for common issues such as invalid inputs and API failures. It also supports additional parameters for flexibility and uses logging for better traceability. These features make it robust and useful for generating images, which is a common task in many applications. Therefore, it is likely to survive."
survived,"        async def wrapped_run(*args: Any, **kwargs: Any) -> Any:
            result = await orig_run(*args, **kwargs)
            span_data = (
                getattr(result, ""span_graph"", None)
                or getattr(result, ""spans"", None)
                or getattr(result, ""trace"", None)
            )
            if span_data is not None:
                try:
                    await self.send(endpoint, span_data)  # type: ignore[arg-type]
                except Exception as exc:  # pragma: no cover - log only
                    logger.error(""Failed to send telemetry: %s"", exc)
            return result
",src/meta_agent/services/telemetry_client.py,TelemetryAPIClient,1,4.363462233903899e-09,"The method 'wrapped_run' is likely to survive because it is an asynchronous function that wraps around another function 'orig_run', adding functionality to handle telemetry data. It checks for span data in the result and attempts to send it to a specified endpoint, logging any exceptions that occur. This kind of functionality is useful for monitoring and logging purposes, which are important in production environments. The use of async/await also suggests modern, non-blocking design, which is a good practice in contemporary software development."
survived,"async def telemetry_client():
    with patch(""aiohttp.ClientSession"") as mock_session:
        response = AsyncMock()
        response.status = 200
        response.json = AsyncMock(return_value={""ok"": True})
        cm = AsyncMock()
        cm.__aenter__.return_value = response
        mock_session.return_value.post.return_value = cm
        client = TelemetryAPIClient({""trace"": EndpointConfig(""http://example.com"")})
        try:
            yield client
        finally:
            await client.close()
",tests/unit/test_telemetry_client.py,,1,5.905303995456778e-10,"The method 'telemetry_client' is likely to survive because it is an asynchronous context manager function that sets up a mock for testing purposes. It uses 'patch' to mock 'aiohttp.ClientSession', which is a common practice in testing to simulate HTTP requests without making actual network calls. The function is well-structured, using 'AsyncMock' to handle asynchronous operations, and it includes a 'finally' block to ensure resources are properly closed. These are all good practices in writing testable and maintainable code, suggesting that the method is useful and likely to be retained."
survived,"    def info(self, message: str, *, level: int = 1) -> None:
        """"""Output an informational message.""""""
        self._echo(message, fg=""cyan"", level=level)
",src/meta_agent/ux/cli_output.py,CLIOutput,1,1.2501528648238603e-09,"The method 'info' is a simple utility function that outputs an informational message with a specified color and level. It is a common pattern in logging or command-line interface applications to have such methods for standardized message output. The method is straightforward, has a clear purpose, and is likely to be useful in its context. There is no indication that it is redundant or problematic, so it is likely to be retained."
survived,"            async def step(self):
                return ""ok""
",tests/test_agents_registry.py,TestAgentRegistryFunctions.WrapAgent,1,1.1032560311263802e-09,"The method is a simple asynchronous function that returns a string ""ok"". It is functional and does not contain any errors or deprecated practices. It might be a placeholder or a simple implementation that serves a specific purpose in the code. Without additional context indicating that this method is unnecessary or redundant, there is no reason to delete it. Therefore, it is likely to survive."
survived,"    def test_cf_var_fallback(self):
        returns = [0.01, -0.02, 0.005, 0.015]
        mu = statistics.mean(returns)
        sig = statistics.pstdev(returns) or 1e-9
        expected = abs(mu + 2.326 * sig)
        with patch.object(finance_agent, ""np"", None, create=True), \
             patch.object(finance_agent, ""skew"", None, create=True), \
             patch.object(finance_agent, ""kurtosis"", None, create=True), \
             patch.object(finance_agent, ""erfcinv"", None, create=True):
            self.assertAlmostEqual(finance_agent._cf_var(returns), expected)
",tests/test_finance_utils.py,TestFinanceUtils,1,6.825604231969389e-08,"The method `test_cf_var_fallback` is a unit test designed to verify the behavior of the `_cf_var` function in the `finance_agent` module when certain dependencies (`np`, `skew`, `kurtosis`, `erfcinv`) are unavailable. This is a common practice in testing to ensure that the function can handle scenarios where external libraries or functions are not present, and it falls back to a default behavior. Such tests are crucial for maintaining robustness and reliability of the code, especially in environments where dependencies might not be guaranteed. Therefore, this method is likely to be retained as it serves an important role in ensuring the code's resilience."
survived,"            def inc(self):
                pass
",tests/test_base_helpers.py,TestPromMetrics.Dummy,0,0.9999999586006244,"The method 'inc' is defined but not implemented, as it only contains a 'pass' statement. Without any functionality, it doesn't contribute to the class or module it's part of. Unless there is a specific reason to keep a placeholder method (such as future implementation plans or interface requirements), it is likely to be deleted to clean up the code."
survived,"    def setUp(self):
        self.agent = EnergyAgent()
",tests/test_energy_agent_behavior.py,TestEnergyAgentBehavior,1,1.3440409770490404e-08,"The method `setUp` is a common method used in unit testing frameworks like `unittest` in Python. It is typically used to set up the test environment before each test method is run. The presence of `self.agent = EnergyAgent()` suggests that this method is initializing an instance of `EnergyAgent` for use in tests. This is a standard practice in test setup, and there is no indication that this method is obsolete or unnecessary. Therefore, it is likely to be retained in the code."
survived,"            async def step(self):
                return None
",tests/test_agents_registry.py,TestVersionOverride.AgentV2,0,0.9999996533672291,"The method 'step' is an asynchronous function that currently does nothing but return None. This suggests that it might be a placeholder for future implementation. However, without any additional context or usage, it doesn't provide any functionality. If the method is not used or planned to be implemented with actual logic, it is likely to be deleted in a codebase cleanup to avoid unnecessary code."
survived,"    def setUp(self):
        self._backup = AGENT_REGISTRY.copy()
        AGENT_REGISTRY.clear()
",tests/test_agents_registry.py,TestVersionOverride,1,2.3823698451773172e-07,"The method `setUp` is a common method used in unit testing frameworks like `unittest` in Python. It is typically used to set up the test environment before each test method is run. In this code, `setUp` is backing up the current state of `AGENT_REGISTRY` and then clearing it, which is a typical setup step to ensure tests run in a clean environment. This method is likely to be retained as it is a standard practice in testing to ensure tests do not interfere with each other by sharing state."
survived,"    def test_build_network(self):
        g = self.agent._build_network()
        self.assertEqual(len(g.nodes), 4)
        self.assertEqual(len(g.edges), 3)
",tests/test_supply_chain_agent.py,TestSupplyChainAgent,1,2.998960815863541e-09,"The method `test_build_network` is a unit test that verifies the functionality of the `_build_network` method of an `agent` object. It checks if the network built has exactly 4 nodes and 3 edges. This kind of test is crucial for ensuring that the network construction logic is working as expected. Unit tests are generally considered good practice in software development as they help in maintaining code quality and catching bugs early. Therefore, this method is likely to be retained as part of the test suite to ensure the reliability of the `_build_network` method."
survived,"    def setUp(self):
        self.agent = ManufacturingAgent()
",tests/test_manufacturing_agent.py,TestManufacturingAgent,1,7.582560422162384e-10,"The method `setUp` is a common method used in unit testing frameworks like `unittest` in Python. It is typically used to set up the test environment before each test case is run. The presence of `setUp` suggests that this code is part of a test suite, and such methods are generally not deleted unless the entire test suite is being refactored or removed. Since `setUp` is a standard and necessary part of test setup, it is likely to survive."
survived,"    def test_energy_calc(self):
        ops = [
            {""machine"": ""m1"", ""start"": 0, ""end"": 5},
            {""machine"": ""m1"", ""start"": 5, ""end"": 15},
        ]
        rate = {""m1"": 2.0}
        payload = self.agent._energy_calc(ops, rate)
        self.assertAlmostEqual(payload[""kwh""], 30.0)
        expected_co2 = 30.0 * self.agent.cfg.energy_rate_co2
        self.assertAlmostEqual(payload[""co2_kg""], expected_co2)
",tests/test_manufacturing_agent.py,TestManufacturingAgent,1,1.4166087846364157e-09,"The method `test_energy_calc` is a unit test designed to verify the functionality of the `_energy_calc` method in the `agent` class. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with calculations that could impact business logic or data integrity. The test checks both the energy calculation and the CO2 emissions calculation, which are likely important aspects of the system being tested. Given the importance of testing in software development, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered. Therefore, the method will likely survive."
survived,"    def test_quickstart_wrapper(self) -> None:
        """"""The demo quick_start script delegates to the repo quickstart.""""""
        script = Path(""alpha_factory_v1/demos/quick_start.sh"")
        self.assertTrue(script.exists())
        content = script.read_text()
        self.assertTrue(content.startswith(""#!/usr/bin/env bash""))
        self.assertIn(""../quickstart.sh"", content)
",tests/test_demos.py,TestDemos,1,2.3355930333443423e-09,"The method 'test_quickstart_wrapper' is a unit test that verifies the existence and content of a script file. It checks if the script file exists, if it starts with a specific shebang, and if it contains a specific string. These are typical checks to ensure that the script is correctly set up and linked. Such tests are crucial for maintaining the integrity of the codebase, especially in environments where scripts are used for automation or setup tasks. Therefore, this method is likely to be retained as it serves a valuable purpose in ensuring the reliability of the script it tests."
survived,"    async def _health() -> str:  # noqa: D401
        return ""ok""
",alpha_factory_v1/demos/macro_sentinel/agent_macro_entrypoint.py,,1,1.955568070542584e-08,"The method _health is a simple asynchronous function that returns a string 'ok'. It is likely a utility function used to check the health status of a service or application. Such functions are common in web services to provide a quick way to verify that the service is running correctly. Since it serves a basic but useful purpose, it is likely to be retained in the codebase."
survived,"    def test_montecarlo_hedge_basic(self):
        sim = simulation_core.MonteCarloSimulator(n_paths=500, horizon=5)
        factors = sim.simulate({
            ""yield_10y"": 4.0,
            ""yield_3m"": 4.5,
            ""stable_flow"": 10.0,
            ""es_settle"": 5000.0,
        })
        hedge = sim.hedge(factors, 1_000_000)
        self.assertIn(""es_notional"", hedge)
        self.assertIn(""dv01_usd"", hedge)
        self.assertIn(""metrics"", hedge)
        self.assertEqual(len(sim.scenario_table(factors)), 3)
",tests/test_macro_sentinel.py,TestMacroSentinel,1,6.825604231969389e-08,"The method `test_montecarlo_hedge_basic` is a unit test for a Monte Carlo simulation and hedging functionality. Unit tests are crucial for ensuring code reliability and correctness, especially in financial simulations where accuracy is critical. The method checks the output of the `hedge` function and validates the scenario table, which are important aspects of the simulation process. Given the importance of testing in software development, especially in complex systems like financial simulations, it is unlikely that this method will be deleted."
survived,"def _make_request(ip: str) -> Request:
    scope = {
        ""type"": ""http"",
        ""method"": ""GET"",
        ""path"": ""/"",
        ""headers"": [],
        ""client"": (ip, 0),
    }
    return Request(scope)  # type: ignore[arg-type]
",tests/test_rate_limiter_eviction.py,,1,4.944450477491054e-09,"The method `_make_request` is a utility function that constructs a `Request` object with a predefined scope. It is a simple and straightforward function that serves a specific purpose of creating a request with a given IP address. Such utility functions are often useful in testing or in scenarios where requests need to be programmatically generated. Unless there is a significant change in the requirements or the structure of the `Request` object, this method is likely to survive as it encapsulates a common operation that might be reused in different parts of the codebase."
survived,"    def __enrich_model__(cls) -> type[EnrichModel]:
        """"""
        Convert this SQLAlchemy model to an EnrichModel representation.

        This method introspects the SQLAlchemy model and creates a corresponding
        EnrichModel with fields and relationships based on the SQLAlchemy metadata.

        Returns:
            A dynamically created EnrichModel class
        """"""
        if not issubclass(cls, DeclarativeBase):
            raise TypeError(f""{cls.__name__} must inherit from SQLAlchemy DeclarativeBase"")

        # Get SQLAlchemy mapper
        mapper = inspect(cls)

        # Build field definitions for the EnrichModel
        field_definitions: dict[str, Any] = {}

        # Process columns
        for column_prop in mapper.column_attrs:
            column = column_prop.columns[0]
            field_name = column_prop.key

            # Skip fields marked with exclude in info
            if column.info.get(""exclude"", False):
                continue

            # Get Python type from SQLAlchemy column type
            python_type = _sqlalchemy_type_to_python(column.type)

            # Handle nullable columns
            if column.nullable:
                python_type = python_type | None

            # Get description from column info
            description = column.info.get(""description"", f""{field_name} field"")

            # Create Pydantic Field
            if column.default is not None or column.server_default is not None:
                # Has default value
                field_definitions[field_name] = (python_type, Field(description=description))
            else:
                # Required field
                field_definitions[field_name] = (python_type, Field(description=description))

        # Process relationships
        for rel_prop in mapper.relationships:
            field_name = rel_prop.key
            rel_info = rel_prop.info

            # Skip relationships marked with exclude
            if rel_info.get(""exclude"", False):
                continue

            # Get description
            description = rel_info.get(
                ""description"", f""Relationship to {rel_prop.mapper.class_.__name__}EnrichModel""
            )

            # Determine relationship type
            if rel_prop.uselist:
                # One-to-many or many-to-many relationship
                target_class_name = rel_prop.mapper.class_.__name__
                # Map to EnrichModel version of the class
                enrich_target_name = f""{target_class_name}EnrichModel""
                rel_type = list[enrich_target_name]  # Using string forward reference
            else:
                # One-to-one or many-to-one relationship
                target_class_name = rel_prop.mapper.class_.__name__
                # Map to EnrichModel version of the class
                enrich_target_name = f""{target_class_name}EnrichModel""
                rel_type = enrich_target_name

            # Create Relationship field
            field_definitions[field_name] = (rel_type, Relationship(description=description))

        # Get model documentation
        model_doc = cls.__doc__ or f""{cls.__name__} entity""

        # Create the EnrichModel class dynamically
        enrich_model_class = create_model(
            f""{cls.__name__}EnrichModel"",
            __base__=EnrichModel,
            __doc__=model_doc,
            **field_definitions,
        )

        # Store reference to original SQLAlchemy model
        # Use setattr to ensure it's properly set on the class
        enrich_model_class._sqlalchemy_model = cls

        return enrich_model_class
",src/enrichmcp/sqlalchemy/mixin.py,EnrichSQLAlchemyMixin,1,3.653482080241728e-08,"The method `__enrich_model__` is a utility function that converts a SQLAlchemy model into an EnrichModel representation. This is a specialized function that serves a specific purpose in the context of integrating SQLAlchemy models with Pydantic models. Such methods are typically retained because they encapsulate complex logic that is reused across different parts of an application, especially in systems that require dynamic model generation based on database schemas. The method is well-documented, checks for necessary conditions, and handles various aspects of model conversion, making it a valuable part of the codebase."
survived,"    def test_relationship_without_description(self):
        """"""Test relationship with no description gets a default one.""""""

        class Base(DeclarativeBase):
            pass

        class User(Base, EnrichSQLAlchemyMixin):
            __tablename__ = ""users""

            id: Mapped[int] = mapped_column(primary_key=True)
            posts: Mapped[list[""Post""]] = relationship()

        class Post(Base, EnrichSQLAlchemyMixin):
            __tablename__ = ""posts""

            id: Mapped[int] = mapped_column(primary_key=True)
            user_id: Mapped[int] = mapped_column(ForeignKey(""users.id""))

        UserEnrichModel = User.__enrich_model__()
        fields = UserEnrichModel.model_fields

        assert ""posts"" in fields
        assert isinstance(fields[""posts""].default, Relationship)
        assert fields[""posts""].default.description == ""Relationship to PostEnrichModel""
",tests/test_sqlalchemy_integration.py,TestRelationships,1,1.955568070542584e-08,"The method is a test case that verifies the functionality of a relationship without a description in a SQLAlchemy model. It ensures that a default description is provided, which is a useful feature to test. Test methods are generally not deleted unless they are redundant or the functionality they test is removed. Since this test checks for a specific feature (default description for relationships), it is likely to be retained as long as the feature exists."
survived,"    def test_model_documentation(self):
        """"""Test that model docstring is preserved.""""""

        class Base(DeclarativeBase):
            pass

        class Order(Base, EnrichSQLAlchemyMixin):
            """"""Order represents a customer purchase.""""""

            __tablename__ = ""orders""

            id: Mapped[int] = mapped_column(primary_key=True)
            total: Mapped[float] = mapped_column()

        OrderEnrichModel = Order.__enrich_model__()
        assert OrderEnrichModel.__doc__ == ""Order represents a customer purchase.""
",tests/test_sqlalchemy_integration.py,TestBasicModel,1,8.152020648014727e-09,"The method `test_model_documentation` is a unit test that verifies the preservation of a class docstring after some transformation or enrichment process. This is a common practice in software development to ensure that documentation remains intact and accurate, especially when using metaprogramming or mixins that might alter class behavior or structure. The test is simple, clear, and serves a specific purpose in maintaining code quality and documentation integrity. Therefore, it is likely to be retained as part of the test suite."
survived,"    def test_sqlalchemy_model_reference_stored(self):
        """"""Test that reference to original SQLAlchemy model is stored.""""""

        class Base(DeclarativeBase):
            pass

        class Order(Base, EnrichSQLAlchemyMixin):
            __tablename__ = ""orders""
            id: Mapped[int] = mapped_column(primary_key=True)

        OrderEnrichModel = Order.__enrich_model__()
        assert hasattr(OrderEnrichModel, ""_sqlalchemy_model"")
        assert OrderEnrichModel._sqlalchemy_model is Order
",tests/test_sqlalchemy_integration.py,TestEdgeCases,1,1.955568070542584e-08,"The method `test_sqlalchemy_model_reference_stored` is a unit test designed to verify that a reference to the original SQLAlchemy model is stored correctly in an enriched model. This is a specific functionality test that ensures the integrity and correctness of the model enrichment process. Such tests are crucial for maintaining the reliability of the codebase, especially when dealing with ORM models and their extensions. Therefore, it is unlikely to be deleted as it serves an important role in validating the behavior of the code."
survived,"    def test_simple_model_conversion(self):
        """"""Test converting a simple SQLAlchemy model to EnrichModel.""""""

        class Base(DeclarativeBase):
            pass

        class User(Base, EnrichSQLAlchemyMixin):
            """"""User entity for testing.""""""

            __tablename__ = ""users""

            id: Mapped[int] = mapped_column(primary_key=True, info={""description"": ""User ID""})
            username: Mapped[str] = mapped_column(info={""description"": ""Username""})
            email: Mapped[str] = mapped_column(info={""description"": ""Email address""})
            is_active: Mapped[bool] = mapped_column(
                default=True, info={""description"": ""Active status""}
            )

        # Convert to EnrichModel
        UserEnrichModel = User.__enrich_model__()

        # Check that it's a proper EnrichModel subclass
        assert issubclass(UserEnrichModel, EnrichModel)

        # Check fields exist
        fields = UserEnrichModel.model_fields
        assert ""id"" in fields
        assert ""username"" in fields
        assert ""email"" in fields
        assert ""is_active"" in fields

        # Check field types
        assert fields[""id""].annotation == int
        assert fields[""username""].annotation == str
        assert fields[""email""].annotation == str
        assert fields[""is_active""].annotation == bool

        # Check descriptions
        assert fields[""id""].description == ""User ID""
        assert fields[""username""].description == ""Username""
        assert fields[""email""].description == ""Email address""
        assert fields[""is_active""].description == ""Active status""
",tests/test_sqlalchemy_integration.py,TestBasicModel,1,3.653482080241728e-08,"The method `test_simple_model_conversion` is a unit test designed to verify the conversion of a SQLAlchemy model to an EnrichModel. It checks the subclass relationship, field existence, field types, and field descriptions, which are all essential aspects of ensuring the conversion process is correct. This test is crucial for maintaining the integrity of the model conversion functionality, making it unlikely to be deleted unless the entire conversion feature is removed or significantly refactored."
survived,"    def __init__(self):
        self.gen=POETGenerator()
        self.envs=[self.gen.propose() for _ in range(CFG.env_batch)]
        self.learners=[Learner(e) for e in self.envs]
        self.stop=False
        A2ABus.subscribe(""orch"",self._on_cmd)
        LOG.info(""Orchestrator online with %d envs"", CFG.env_batch)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,Orchestrator,1,7.73442280641062e-08,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class. It sets up important attributes like 'gen', 'envs', 'learners', and 'stop', and subscribes to a message bus, which are likely crucial for the class's functionality. Constructors are rarely deleted unless the class itself is being removed or significantly refactored, which is not indicated here."
survived,"    def _on_cmd(self,msg):
        if msg.get(""cmd"")==""new_env"":
            idx=random.randrange(len(self.envs))
            self.envs[idx]=self.gen.propose()
            self.learners[idx]=Learner(self.envs[idx])
            LOG.info(""Replaced env #%d"", idx)
        elif msg.get(""cmd"")==""stop"": self.stop=True
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,Orchestrator,1,3.850741907939403e-09,"The method '_on_cmd' is a private method (indicated by the underscore prefix) that handles specific commands ('new_env' and 'stop') received in a message. It is likely part of a larger system where it plays a role in managing environments and learners. The method is functional, concise, and serves a clear purpose within its context. There is no indication of redundancy or obsolescence, and it seems to be an integral part of the system's command handling. Therefore, it is likely to be retained."
survived,"    def __init__(self, cpu_sec:int=2, mem_mb:int=128):
        self.cpu_sec = cpu_sec
        self.mem_mb = mem_mb
",alpha_factory_v1/demos/meta_agentic_agi_v3/agents/agent_base.py,SafeExec,1,2.998960815863541e-09,"The method is a constructor for a class, initializing two attributes with default values. This is a common and necessary practice in object-oriented programming to set up initial state for objects. There is no indication that this method is redundant or harmful, and it provides flexibility by allowing default values to be overridden. Therefore, it is likely to be retained."
survived,"    def _estimate_cost(self, prompt_tokens:int, completion_tokens:int) -> float:
        price = float(os.getenv(""ALPHA_USD_PER_M"", 0.01)) # user override
        return ((prompt_tokens+completion_tokens)/1_000_000)*price
",alpha_factory_v1/demos/meta_agentic_agi_v3/agents/agent_base.py,Agent,1,4.363462233903899e-09,"The method '_estimate_cost' is a utility function that calculates the cost based on token usage and a price per million tokens. It is a simple, clear, and useful function for applications that need to estimate costs based on token usage, especially in contexts like API usage billing. The method is likely to be retained as it serves a specific purpose and is implemented correctly."
survived,"    def _obs(self):
        vec = np.zeros(self.size*self.size, dtype=np.float32)
        vec[self.agent[0]*self.size+self.agent[1]] = 1.0
        return vec
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,MiniWorld,1,7.582560422162384e-10,"The method '_obs' is a private method (indicated by the underscore) that seems to be part of a class dealing with a grid or matrix environment, possibly for a game or simulation. It creates a one-hot encoded vector representing the agent's position in a grid. This is a common technique in reinforcement learning and other AI applications to represent states. The method is simple, efficient, and serves a clear purpose in the context of such applications. Given the increasing interest and application of AI and reinforcement learning, this method is likely to be useful and relevant, thus it is likely to survive."
survived,"    def reset(self):
        self.agent = (0,0)
        return self._obs()
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,MiniWorld,1,1.522997951276035e-08,"The method 'reset' is a common and essential part of many classes, especially in contexts like simulations, games, or environments where an agent's state needs to be reinitialized. The method sets the agent's position to a starting point and returns an observation, which is likely a necessary step in the workflow of the class. Without this method, it would be difficult to restart or reset the state of the agent, which is often required in iterative processes or testing scenarios. Therefore, it is unlikely to be deleted as it serves a fundamental purpose."
survived,"    def log(self, event: str, **payload):
        with self.path.open(""a"", encoding=""utf-8"") as fp:
            json.dump({""ts"": _utcnow_ms(), ""event"": event, **payload}, fp, ensure_ascii=False)
            fp.write(""\n"")
",alpha_factory_v1/demos/meta_agentic_agi/agents/agent_base.py,LineageTracer,1,9.237449576640118e-09,"The method 'log' is a utility function that appends log entries to a file. It is a simple and effective way to record events with timestamps and additional payload data. The method uses standard libraries and practices, such as opening a file in append mode and using JSON for structured data storage. There is no indication of redundancy or inefficiency that would warrant its deletion. It is likely to be a useful part of a logging system, especially in applications where tracking events is crucial."
survived,"    def recurrent(self, h, a_onehot):
        r, h2 = self.dyn(h, a_onehot)
        v, p = self.pred(h2)
        return h2, r, v, p
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,MuZeroTiny,1,1.8189616842444243e-09,"The method 'recurrent' is likely to be Survived (1) because it appears to be a well-defined function that is part of a larger system, possibly a neural network or reinforcement learning model. The method takes in a hidden state 'h' and an action 'a_onehot', processes them through a dynamic model 'dyn', and then makes predictions using 'pred'. This kind of functionality is typical in machine learning models, where recurrent functions are used to update states and make predictions based on inputs. The method is concise, clear, and seems to serve a specific purpose within its context, which suggests it is useful and likely to be retained."
survived,"    def propose(self)->MiniWorld:
        size=random.randint(5,9)
        obstacles={(random.randint(1,size-2),random.randint(1,size-2)) for _ in range(random.randint(0,size))}
        env=MiniWorld(size,list(obstacles),(size-1,size-1))
        self.pool.append(env)
        return env
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,POETGenerator,1,4.944450477491054e-09,"The method 'propose' is likely to survive because it appears to be a functional part of a larger system, possibly a game or simulation environment. It generates a new instance of 'MiniWorld' with random obstacles and appends it to a pool, which suggests it is used to create diverse environments for testing or gameplay. The method is concise, uses standard Python libraries, and follows a logical structure, making it a useful utility in its context."
survived,"def test_llm_comment_online(monkeypatch):
    """"""`_llm_comment` should call OpenAIAgent when available.""""""
    mod = importlib.import_module(MODULE)

    class DummyAgent:
        def __init__(self, *args, **kwargs) -> None:  # pragma: no cover - args ignored
            pass

        async def __call__(self, prompt: str) -> str:
            self.prompt = prompt
            return ""online""

    with mock.patch.object(mod.local_llm, ""chat"", return_value=""bad"") as m_chat:
        monkeypatch.setattr(mod, ""OpenAIAgent"", DummyAgent)
        result = asyncio.run(mod._llm_comment(1.23))

    assert result == ""online""
    assert not m_chat.called
",tests/test_alpha_agi_business_3_v1.py,,1,3.2241866333029355e-08,"The method `test_llm_comment_online` is a unit test designed to verify the behavior of the `_llm_comment` function when the `OpenAIAgent` is available. It uses mocking to replace the `OpenAIAgent` with a `DummyAgent` and checks that the `_llm_comment` function returns 'online' and does not call the `local_llm.chat` method. This test is useful for ensuring that the `_llm_comment` function interacts correctly with the `OpenAIAgent` and does not fall back to the local LLM when the agent is available. Since this test is specific, well-defined, and tests a particular functionality, it is likely to be retained in the codebase to ensure the correct behavior of the `_llm_comment` function."
survived,"def test_main_subprocess() -> None:
    """"""Running the demo via ``python -m`` should output the Î”G message.""""""
    env = os.environ.copy()
    env[""OPENAI_API_KEY""] = ""dummy""
    result = subprocess.run(
        [
            sys.executable,
            ""-m"",
            ""alpha_factory_v1.demos.alpha_agi_business_3_v1"",
            ""--cycles"",
            ""1"",
        ],
        capture_output=True,
        text=True,
        env=env,
    )
    assert result.returncode == 0, result.stderr
    assert ""Î”G=0.03"" in (result.stdout + result.stderr)
",tests/test_alpha_agi_business_3_v1.py,,1,3.3982678079468468e-09,"The method `test_main_subprocess` is a test function that verifies the output of running a specific module using subprocess. It checks if the process completes successfully and if the expected output is present in the stdout or stderr. This is a typical pattern for testing command-line interfaces or scripts, ensuring that the integration works as expected. Since it serves a clear purpose in testing the functionality of a module, it is likely to be retained in the codebase."
survived,"def populated_db(temp_db_path):
    items = [
        {""id"": ""python-1"", ""text"": ""Python programming is fun"", ""tags"": [""python"", ""programming"", ""fun""]},
        {""id"": ""sql-1"", ""text"": ""SQL databases are powerful"", ""tags"": [""sql"", ""database"", ""programming""]},
        {""id"": ""testing-1"", ""text"": ""Testing code is important"", ""tags"": [""testing"", ""code"", ""programming""]},
        {""id"": ""regex-1"", ""text"": ""Regular expressions can be complex"", ""tags"": [""regex"", ""programming"", ""advanced""]},
        {""id"": ""learning-1"", ""text"": ""Learning new technologies is exciting"", ""tags"": [""learning"", ""technology"", ""fun""]},
    ]

    for item in items:
        command = AddCommand(
            id=item[""id""],
            text=item[""text""],
            tags=item[""tags""],
            db_path=temp_db_path,
        )
        add(command)

    return temp_db_path
",src/mcp_server_pocket_pick/tests/functionality/test_list_ids.py,,1,1.725782769012759e-08,"The method 'populated_db' is a utility function that populates a temporary database with predefined items. It is a straightforward and useful function for setting up test data or initializing a database with sample entries. Such functions are commonly used in development and testing environments to ensure that there is data to work with. The method is not overly complex, does not have any apparent issues, and serves a clear purpose. Therefore, it is likely to be retained in the codebase."
survived,"    def start(self, bus: object, ledger: object) -> None:
        self.task = asyncio.create_task(self.loop(bus, ledger))
",alpha_factory_v1/backend/orchestrator_utils.py,AgentRunner,1,1.6052280526088547e-09,"The method 'start' is a simple wrapper around creating an asyncio task. It is likely part of a larger class that manages asynchronous operations. The method is straightforward and serves a clear purpose in initializing an asynchronous loop with the given parameters. Unless there is a significant change in the design or requirements of the system, such methods are typically retained as they encapsulate the task creation logic neatly. Therefore, it is likely to survive."
survived,"    def log(self, env: messaging.Envelope) -> None:  # type: ignore[override]
        self.logged.append(env)
",tests/test_codegen_safety.py,DummyLedger,1,5.905303995456778e-10,"The method 'log' is a simple implementation that appends an envelope to a list called 'logged'. It is a straightforward and useful method for tracking or logging messages. There is no indication that it is redundant or unnecessary, and it serves a clear purpose in the context of message handling. Therefore, it is likely to be retained in the codebase."
survived,"    def __init__(self) -> None:
        self.logged: list[messaging.Envelope] = []
",tests/test_codegen_safety.py,DummyLedger,1,6.023574641292144e-08,"The method is a constructor for a class, initializing an instance variable 'logged' as an empty list. This is a common and necessary practice in object-oriented programming to set up initial state for objects. There is no indication that this method is redundant or unnecessary, as it serves a fundamental purpose in the class design. Therefore, it is unlikely to be deleted."
survived,"    def subscribe(self, _t: str, _h) -> None:  # pragma: no cover - dummy
        pass
",tests/test_codegen_safety.py,DummyBus,1,6.962258425838873e-06,"The method 'subscribe' is marked with a pragma directive 'no cover', indicating that it is intentionally left without implementation for testing purposes or as a placeholder. This suggests that the method is not currently in use or is awaiting future implementation. However, the presence of the method in the codebase implies that it might be part of a planned feature or interface. Without further context on the overall project or any indications of deprecation, it's reasonable to assume that the method is intended to be implemented in the future rather than deleted."
survived,"def _venv_python(venv: Path) -> Path:
    """"""Return the path to the Python interpreter inside *venv*.""""""
    if os.name == ""nt"":
        return venv / ""Scripts"" / ""python.exe""
    return venv / ""bin"" / ""python""
",alpha_factory_v1/quickstart.py,,1,2.998960815863541e-09,"The method '_venv_python' is a utility function that determines the path to the Python interpreter within a virtual environment, based on the operating system. This is a common requirement in Python projects that use virtual environments, as it allows scripts to execute with the correct interpreter. The method is simple, effective, and serves a clear purpose, making it unlikely to be deleted unless the project no longer requires virtual environment support or a different method of handling virtual environments is adopted."
survived,"def _ensure_offline():
    DATA_DIR.mkdir(exist_ok=True)
    for name, url in OFFLINE_URLS.items():
        path = DATA_DIR / name
        if path.exists():
            continue
        try:
            with urlopen(url, timeout=5) as r, open(path, ""wb"") as f:
                f.write(r.read())
        except Exception:
            row = _DEFAULT_ROWS[name]
            with open(path, ""w"", newline="""") as f:
                writer = csv.DictWriter(f, row.keys())
                writer.writeheader()
                writer.writerow(row)
",alpha_factory_v1/demos/macro_sentinel/data_feeds.py,,1,1.2501528648238603e-09,"The method `_ensure_offline` is likely to survive because it serves a critical function of ensuring that necessary data files are available offline. It checks if the files exist locally and attempts to download them if they do not. If the download fails, it falls back to writing default data. This functionality is important for applications that need to operate without a constant internet connection, ensuring robustness and reliability. The method also handles exceptions gracefully, which is a good practice in programming."
survived,"    def test_policy(self):
        if minimuzero is None:
            self.skipTest(""muZero demo deps missing"")
        agent = minimuzero.MiniMu()
        obs = agent.reset()
        policy = agent.policy(obs)
        self.assertEqual(len(policy), agent.action_dim)
        self.assertAlmostEqual(policy.sum(), 1.0, places=3)
",alpha_factory_v1/tests/test_muzero_demo.py,MiniMuTest,1,3.850741907939403e-09,"The method 'test_policy' is a unit test designed to verify the functionality of a policy method in a reinforcement learning agent. It checks if the policy output is of the correct length and if the probabilities sum to 1, which are essential checks for a valid policy. These are standard and necessary tests in machine learning and reinforcement learning contexts to ensure the agent behaves as expected. Therefore, the method is likely to be retained as it serves a critical role in validating the agent's behavior."
survived,"    def test_all_demos_have_readme(self):
        self.assertEqual(validate_demos.main(), 0)
",alpha_factory_v1/tests/test_validate_demos.py,TestValidateDemos,1,9.237449576640118e-09,"The method `test_all_demos_have_readme` is a unit test that checks if all demos have a README file by asserting that the `validate_demos.main()` function returns 0. This is a typical test to ensure documentation completeness, which is a common requirement in software projects. Since maintaining documentation is crucial for understanding and using demos, this test is likely to be retained to ensure quality and usability of the demos."
survived,"    def test_run_one_generation(self):
        env_fn = lambda: ce.CurriculumEnv(genome=ce.EnvGenome(max_steps=10), size=6)
        ev = me.MetaEvolver(env_fn, pop_size=4, elitism=1, parallel=False)
        ev.run_generations(1)
        self.assertGreaterEqual(len(ev.history), 1)
        self.assertIsNotNone(ev.best_genome)
",alpha_factory_v1/tests/test_aiga_meta_evolution.py,MetaEvolverTest,1,1.6052280526088547e-09,"The method 'test_run_one_generation' is a unit test designed to verify the functionality of the 'run_generations' method in the 'MetaEvolver' class. It checks that after running one generation, the history of evolutions is not empty and that there is a best genome identified. This is a typical test case to ensure that the evolutionary process is functioning as expected. Since it serves a clear purpose in validating the code's behavior, it is likely to be retained in the codebase."
survived,"            def __init__(self, *a, **k):
                self.calls = []
",alpha_factory_v1/tests/test_ping_agent.py,PingAgentTest.DummyMetric,1,3.2241866333029355e-08,"The method is a constructor for a class, indicated by the name `__init__`. Constructors are essential for initializing new objects in object-oriented programming. The presence of `self.calls = []` suggests that this constructor is setting up an instance variable, which is a common and necessary practice. Therefore, it is unlikely that this method will be deleted as it serves a fundamental role in the class's functionality."
survived,"    def test_step_publishes_heartbeat(self):
        asyncio.run(self.agent.setup())
        asyncio.run(self.agent.step())
        self.assertEqual(len(self.orc.messages), 1)
        topic, payload = self.orc.messages[0]
        self.assertEqual(topic, ""agent.ping"")
        self.assertEqual(payload[""agent""], self.agent.NAME)
",alpha_factory_v1/tests/test_ping_agent.py,PingAgentTest,1,4.1399375473943306e-08,"The method `test_step_publishes_heartbeat` is a unit test designed to verify the behavior of an agent's step function, specifically checking if it publishes a heartbeat message. Unit tests are crucial for ensuring code reliability and correctness, especially in asynchronous systems where behavior can be complex. The method is well-structured, using assertions to validate expected outcomes, which is a standard practice in testing. Given the importance of testing in software development, this method is likely to be retained to ensure the agent's functionality is correctly implemented and maintained."
survived,"            def set(self, *a, **k):
                self.calls.append(""set"")
",alpha_factory_v1/tests/test_ping_agent.py,PingAgentTest.DummyMetric,1,1.725782769012759e-08,"The method 'set' is a simple function that appends the string ""set"" to a list called 'calls'. Without additional context, such as the purpose of the 'calls' list or how this method fits into a larger class or module, it's difficult to determine its utility. However, the method is functional and could be part of a logging or tracking mechanism within a class. If the 'calls' list is used to track method invocations for debugging or logging purposes, this method is likely to be useful and thus survive. Without evidence of redundancy or lack of use, it is reasonable to predict that the method will survive."
survived,"    def evaluate(
        self,
        path: Path,
        timeout: int = 60,
        output_format: str = ""text"",
    ) -> str:
        """"""Run tests at ``path`` and return a formatted report.""""""
        self.logger.info(""Starting evaluation for %s"", path)
        result: CollectionResult = self.result_collector.execute_and_collect(
            path, timeout=timeout
        )
        return self.reporter.generate_report(result, output_format=output_format)",src/meta_agent/evaluation/harness.py,EvaluationHarness,1,6.69158608681505e-10,"The method 'evaluate' is a well-defined function that serves a clear purpose: it runs tests on a given path and returns a formatted report. It includes logging for tracking the evaluation process, uses a result collector to execute and collect results, and a reporter to generate the report in the specified format. These functionalities are essential for testing and reporting in software development, making the method useful and likely to be retained in the codebase."
survived,"def test_show_results_export_formats(tmp_path) -> None:
    ledger = tmp_path / ""audit.db""
    ledger.touch()
    with patch.object(cli.config.CFG, ""ledger_path"", ledger):
        with patch.object(cli.logging, ""Ledger"") as led_cls:
            led = led_cls.return_value
            led.tail.return_value = [SAMPLE_LEDGER_ROW]
            res_json = CliRunner().invoke(cli.main, [""show-results"", ""--export"", ""json""])
            res_csv = CliRunner().invoke(cli.main, [""show-results"", ""--export"", ""csv""])
    assert res_json.output.startswith(""["")
    assert ""ts,sender,recipient,payload"" in res_csv.output
",tests/test_cli_runner_ext.py,,1,2.2159489282323004e-08,"The method 'test_show_results_export_formats' is a unit test that verifies the functionality of exporting results in different formats (JSON and CSV) using a command-line interface. It uses temporary paths and mock objects to simulate the environment and dependencies, ensuring that the test is isolated and does not rely on external factors. The test checks that the JSON output starts with a '[' character, indicating a JSON array, and that the CSV output contains the expected header. These checks are essential for validating the correct behavior of the 'show-results' command with export options. Since the test is well-structured, uses mocking effectively, and tests a critical feature of the CLI, it is likely to be retained in the codebase to ensure the reliability of the export functionality."
survived,"def test_docker_compose_config() -> None:
    subprocess.run([""docker"", ""compose"", ""-f"", str(COMPOSE_FILE), ""config""], check=True, capture_output=True)",tests/test_macro_compose_config.py,,1,9.237449576640118e-09,"The method `test_docker_compose_config` is a simple utility function that runs a Docker Compose command to check the configuration of a Docker Compose file. This is a common task in development and CI/CD pipelines to ensure that the Docker Compose file is correctly configured before deployment. The method uses `subprocess.run` with `check=True` to raise an error if the command fails, which is a good practice for error handling. Additionally, capturing the output can be useful for logging or debugging purposes. Given its utility and correct implementation, it is likely to be retained in the codebase."
survived,"def _apply_csp(html: str, base: str) -> str:
    """"""Return ``html`` with an updated CSP meta tag using hashes for inline scripts.""""""
    hashes: list[str] = []
    for snippet in re.findall(r""<script(?![^>]*src)[^>]*>([\s\S]*?)</script>"", html):
        digest = hashlib.sha384(snippet.encode()).digest()
        hashes.append(""sha384-"" + base64.b64encode(digest).decode())
    csp = f""{base}; script-src 'self' 'wasm-unsafe-eval' {' '.join(hashes)}; style-src 'self' 'unsafe-inline'""
    return re.sub(
        r'<meta[^>]*http-equiv=""Content-Security-Policy""[^>]*>',
        f'<meta http-equiv=""Content-Security-Policy"" content=""{csp}"" />',
        html,
    )
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/manual_build.py,,1,1.725782769012759e-08,"The method '_apply_csp' is a utility function that updates the Content Security Policy (CSP) of an HTML document by adding hashes for inline scripts. This is a security feature that helps prevent certain types of attacks, such as cross-site scripting (XSS). Given the increasing importance of web security and the need to dynamically update CSPs in web applications, this method is likely to be useful and relevant. Therefore, it is more likely to be retained rather than deleted."
survived,"def doNeg(x):
    pass
",tests/rosetta/transpiler/Python/conditional-structures-4.py,,0,0.9999999006880476,"The method 'doNeg' is currently a placeholder with no implementation (indicated by the 'pass' statement). If this method is part of a larger codebase and there is no plan or need to implement it, it is likely to be deleted to clean up the code. However, if there is an intention to implement it in the future, it might survive. Without additional context, the lack of implementation suggests it is more likely to be deleted."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/concurrent-computing-1.py,,1,7.73442280641062e-08,"The method '_now' is a utility function that generates a pseudo-random number based on a seed if '_now_seeded' is True, or returns the current time in nanoseconds otherwise. This method is likely to be used in scenarios where a consistent pseudo-random number is needed for testing or simulation purposes. The use of global variables like '_now_seed' and '_now_seeded' suggests that this function is part of a larger system that manages state across multiple calls. Such utility functions are common in software systems for testing or deterministic behavior, and unless there is a specific reason to remove it (such as a change in requirements or a better alternative), it is likely to survive."
survived,"def main():
    l = newLife(80, 15)
    i = 0
    while i < 300:
        step(l)
        print(""\f"")
        print(lifeString(l))
        i = i + 1
",tests/rosetta/transpiler/Python/conways-game-of-life.py,,0,0.9999997617630155,"The method 'main' is likely to be deleted because it contains several issues that suggest it is not functioning as intended. Firstly, the function 'newLife' is called but not defined within the code snippet, which would lead to a NameError. Secondly, the use of '\f' in the print statement is unconventional and may not produce the intended output, as '\f' is a form feed character that is rarely used in modern programming. Additionally, the loop runs 300 iterations without any apparent condition to break or modify the loop based on the program's logic, which might not be efficient or necessary. These issues indicate that the code is either incomplete or not well-structured, leading to the likelihood of it being deleted or significantly revised."
survived,"def state(f, x, y):
    while y < 0:
        y = y + f.h
    while x < 0:
        x = x + f.w
    return f.s[y % f.h][x % f.w]
",tests/rosetta/transpiler/Python/conways-game-of-life.py,,1,5.60279640614594e-09,"The method 'state' is a utility function that adjusts the coordinates (x, y) to be within the bounds of a 2D grid defined by the dimensions of 'f' (f.h for height and f.w for width). It then returns the value at the adjusted coordinates from a 2D list 'f.s'. This method is likely to be useful in scenarios involving grid-based operations, such as games or simulations, where wrapping around the edges of the grid is necessary. The method is simple, efficient, and serves a clear purpose, making it likely to be retained in the codebase."
survived,"def cfNap(nTerms):
    f = []
    n = 0
    while n < nTerms:
        f = f + [newTerm(n, n - 1)]
        n = n + 1
    if nTerms > 0:
        f[0][""a""] = 2
    if nTerms > 1:
        f[1][""b""] = 1
    return f
",tests/rosetta/transpiler/Python/continued-fraction.py,,0,0.9999999715466527,"The method cfNap is likely to be deleted (0) because it contains several issues that make it inefficient and potentially incorrect. Firstly, the function newTerm is called but not defined within the code, which would lead to a NameError unless it is defined elsewhere. Secondly, the use of list concatenation with f = f + [newTerm(n, n - 1)] in a loop is inefficient, as it creates a new list each time, which is not optimal for performance. Additionally, the function modifies the first two elements of the list f based on the number of terms, but this logic is not clearly explained or justified, making the function's purpose unclear. These factors suggest that the method may not be useful or maintainable in its current form, leading to its potential deletion."
survived,"def main():
    inputs = [""0.9054054"", ""0.518518"", ""0.75""]
    for s in inputs:
        r = parseRational(s)
        print(s + "" = "" + str(r[""num""]) + ""/"" + str(r[""den""]))
",tests/rosetta/transpiler/Python/convert-decimal-number-to-rational.py,,0,0.9999999895325983,"The method 'main' is likely to be deleted (0) because it calls a function 'parseRational' which is not defined within the provided code snippet. Without the definition of 'parseRational', the 'main' method cannot function correctly, leading to potential errors or incomplete functionality. This lack of completeness and functionality makes it a candidate for deletion unless 'parseRational' is defined elsewhere in the codebase."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/constrained-random-points-on-a-circle-2.py,,1,1.522997951276035e-08,"The method _now() is a utility function that generates a pseudo-random number based on a seed if _now_seeded is True, otherwise it returns the current time in nanoseconds. This function is likely used for testing or simulating time-dependent behavior in a controlled manner. Such utility functions are often retained in codebases for their usefulness in testing and debugging, especially when dealing with time-dependent logic. Therefore, it is likely to be Survived."
survived,"def test_ios_panels_pyodide_fallback() -> None:
    if os.getenv(""SKIP_WEBKIT_TESTS""):
        pytest.skip(""WebKit unavailable"")
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri() + ""#s=1&p=3&g=3""
    try:
        with sync_playwright() as p:
            browser = p.webkit.launch()
            context = browser.new_context(user_agent=IOS_UA)
            page = context.new_page()
            page.route(""**/pyodide.js"", lambda route: route.abort())
            page.goto(url)
            page.wait_for_selector(""#controls"")
            page.wait_for_selector(""#simulator-panel"")
            page.wait_for_function(""window.gen >= 3"")
            page.wait_for_function(
                ""document.querySelectorAll('#evolution-panel table tr').length > 1""
            )
            page.wait_for_selector(""#toast.show"")
            assert ""Pyodide"" in page.inner_text(""#toast"")
            browser.close()
    except PlaywrightError as exc:
        pytest.skip(f""Playwright browser not installed: {exc}"")",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_ios_panels.py,,1,4.363462233903899e-09,"The method `test_ios_panels_pyodide_fallback` is a test function that uses Playwright to automate browser testing. It is designed to test the functionality of a web page in a WebKit browser environment, specifically simulating an iOS user agent. The function includes error handling to skip the test if certain conditions are not met, such as the absence of WebKit or Playwright. This indicates that the function is well-structured for its purpose and is likely part of a test suite that ensures the web application behaves correctly in specific scenarios. Given its utility in testing and the absence of any deprecated or obsolete practices, it is likely to be retained in the codebase."
survived,"def test_description_str_functions() -> None:
    field = FieldDescription(
        name=""id"",
        type=""int"",
        description=""Identifier"",
        mutable=True,
    )
    rel = RelationshipDescription(
        name=""owner"",
        target=""User"",
        description=""Item owner"",
    )
    entity = EntityDescription(
        name=""Item"",
        description=""A simple item"",
        fields=[field],
        relationships=[rel],
    )
    model = ModelDescription(title=""Demo"", description="""", entities=[entity])

    # Verify individual string representations
    assert str(field) == ""- **id** (int, mutable): Identifier""
    assert str(rel) == ""- **owner** \u2192 User: Item owner""
    entity_text = str(entity)
    assert ""## Item"" in entity_text
    assert ""### Fields"" in entity_text
    assert str(field) in entity_text
    assert ""### Relationships"" in entity_text
    assert str(rel) in entity_text

    model_text = str(model)
    assert ""# Data Model: Demo"" in model_text
    assert ""- [Item](#item)"" in model_text
    assert entity_text in model_text",tests/test_description_str.py,,1,1.955568070542584e-08,"The method `test_description_str_functions` is a unit test designed to verify the string representation of various description objects. It is a useful test to ensure that the `__str__` methods of these objects are correctly implemented and produce the expected output. Such tests are crucial for maintaining code quality and ensuring that any changes to the string representation logic do not break existing functionality. Therefore, this method is likely to be retained as part of the test suite to ensure ongoing correctness of the code."
survived,"    def config_init(cls) -> Tuple[SanskritPoetryEnvConfig, List[APIServerConfig]]:
        env_config = SanskritPoetryEnvConfig(
            group_size=8,
            use_wandb=True,
            rollout_server_url=""http://localhost:8000"",
            total_steps=1000,
            batch_size=32,
            steps_per_eval=50,
            max_token_length=512,
            wandb_name=""sanskrit_poetry"",
        )
        server_configs = [
            APIServerConfig(
                base_url=""http://localhost:9001"",
                api_key=""x"",
                num_requests_for_eval=64,
                model_name=""Qwen/Qwen3-1.7B"",
                server_type=""trl"",
            )
        ]
        return env_config, server_configs
",environments/sanskrit_poetry_env.py,SanskritPoetryEnv,1,1.6052280526088547e-09,"The method 'config_init' is a static method that initializes and returns configuration objects for a specific environment and server setup. It is well-defined, with clear parameters and return types, and it serves a specific purpose in setting up configurations for a Sanskrit poetry environment and API server. There is no indication of redundancy, inefficiency, or lack of use that would warrant its deletion. Therefore, it is likely to be retained in the codebase."
survived,"    def compute(self, completions: List[Any], **kwargs) -> List[float]:
        rewards: List[float] = []
        for completion in completions:
            text = self.get_content(completion)
            rewards.append(self._score_text(text))
        return rewards
",atroposlib/envs/reward_fns/chandas_meter_reward.py,ChandasMeterReward,1,8.592166611791576e-10,"The method 'compute' is likely to survive because it performs a clear and useful function: it processes a list of completions, extracts content from each, and calculates a score for each piece of content. This functionality is essential for tasks that involve evaluating or scoring text data, which is a common requirement in many applications. Additionally, the method is well-structured and uses type hints, which suggests good coding practices."
survived,"def test_cache_version_matches_package() -> None:
    repo = Path(__file__).resolve().parents[1]
    browser = repo / ""alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1""
    version = json.loads((browser / ""package.json"").read_text())[""version""]
    sw = (browser / ""dist"" / ""sw.js"").read_text()
    assert f'CACHE_VERSION=""{version}""' in sw or f""CACHE_VERSION = '{version}'"" in sw",tests/test_cache_version.py,,1,1.4166087846364157e-09,"The method `test_cache_version_matches_package` is a test function that checks if the cache version in a service worker file matches the version specified in a package.json file. This is a useful test to ensure consistency between the service worker and the package version, which is important for cache management and avoiding issues with outdated resources. Such tests are generally valuable in maintaining software quality and are unlikely to be removed unless the functionality they test is deprecated or the testing strategy changes significantly. Therefore, the method is likely to survive."
survived,"            def worker(seed: int) -> None:
                stub.discover_alpha(num=1, seed=seed, ledger=ledger, model=""gpt-4o-mini"")
",tests/test_cross_alpha_discovery.py,TestCrossAlphaDiscoveryStub,1,4.1399375473943306e-08,"The method 'worker' is a simple function that calls another method 'discover_alpha' on a 'stub' object. The function itself is straightforward and does not contain any complex logic or deprecated practices. It is likely part of a larger system where 'discover_alpha' is a crucial operation. Without any indication of redundancy or obsolescence, the method is likely to be retained for its utility in the system."
survived,"def run_scenario(scn: Scenario) -> list[forecast.TrajectoryPoint]:
    """"""Execute ``scn`` and return its trajectory.""""""

    secs = [sector.Sector(s.name, s.energy, s.entropy, s.growth, s.disrupted) for s in scn.sectors]
    return forecast.forecast_disruptions(
        secs,
        scn.horizon,
        scn.curve,
        k=scn.k,
        x0=scn.x0,
        pop_size=scn.pop_size,
        generations=scn.generations,
    )",src/simulation/replay.py,,1,5.905303995456778e-10,"The method 'run_scenario' is well-defined and appears to be a crucial part of a larger system that forecasts disruptions based on a given scenario. It takes a 'Scenario' object as input, processes its sectors, and returns a list of 'TrajectoryPoint' objects, which likely represent the forecasted trajectory of the scenario. The method is clear, concise, and uses type hints, which are good practices in modern Python programming. There is no indication of redundancy or obsolescence, suggesting that it is likely to be retained in the codebase."
survived,"    def delete_stale_entries(self, stale_after: timedelta) -> None:
        """"""Delete stale entries from the MongoDB cache.""""""
        threshold = datetime.now() - stale_after
        self.mongo_collection.delete_many(
            filter={""func"": self._func_str, ""time"": {""$lt"": threshold}}
        )",src/cachier/cores/mongo.py,_MongoCore,1,2.8453347280241004e-08,"The method 'delete_stale_entries' is a utility function designed to remove outdated entries from a MongoDB cache. This is a common requirement in applications that use caching to ensure that the cache does not grow indefinitely and that it only contains relevant data. The method is straightforward, uses a clear parameter to define what is considered 'stale', and leverages MongoDB's capabilities to efficiently delete entries. Such functionality is essential for maintaining the performance and relevance of cached data, making it unlikely to be deleted unless the caching strategy or database technology changes significantly."
survived,"    async def get_cash(self) -> float:
        """"""Return the available cash balance in the account currency.""""""
",alpha_factory_v1/backend/types.py,TradeBrokerProtocol,1,1.1032560311263802e-09,"The method `get_cash` is a straightforward and useful function that returns the available cash balance in the account currency. This is a common requirement in financial applications where users need to know their available balance. The method is asynchronous, which suggests it might be fetching data from a remote source or performing an operation that could take some time, making it suitable for modern applications that require non-blocking operations. There is no indication that this method is redundant or unnecessary, and it serves a clear purpose in the context of financial account management."
survived,"def _apply_env(args: argparse.Namespace) -> None:
    if args.dev:
        os.environ[""DEV_MODE""] = ""true""
    if args.port is not None:
        os.environ[""PORT""] = str(args.port)
    if args.metrics_port is not None:
        os.environ[""METRICS_PORT""] = str(args.metrics_port)
    if args.a2a_port is not None:
        os.environ[""A2A_PORT""] = str(args.a2a_port)
    if args.disable_tls:
        os.environ[""INSECURE_DISABLE_TLS""] = ""true""
    if args.kafka_broker is not None:
        os.environ[""ALPHA_KAFKA_BROKER""] = args.kafka_broker
    if args.cycle_seconds is not None:
        os.environ[""ALPHA_CYCLE_SECONDS""] = str(args.cycle_seconds)
    if args.max_cycle_sec is not None:
        os.environ[""MAX_CYCLE_SEC""] = str(args.max_cycle_sec)
    if args.enabled is not None:
        os.environ[""ALPHA_ENABLED_AGENTS""] = args.enabled
    if args.loglevel:
        os.environ[""LOGLEVEL""] = args.loglevel.upper()
",alpha_factory_v1/backend/main.py,,1,3.3982678079468468e-09,"The method '_apply_env' is a utility function that sets environment variables based on command-line arguments. This is a common pattern in applications that need to configure runtime behavior based on user input or configuration files. The method is straightforward, does not have any apparent issues, and serves a clear purpose in configuring the environment for the application. Such methods are typically retained as they are essential for the flexibility and configurability of the application."
survived,"def _parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description=""Alpha-Factory backend entry point"")
    parser.add_argument(""--dev"", action=""store_true"", help=""Enable development mode (DEV_MODE)"")
    parser.add_argument(""--preflight"", action=""store_true"", help=""Run environment checks and exit"")
    parser.add_argument(""--port"", type=int, help=""REST API port (PORT)"")
    parser.add_argument(""--metrics-port"", type=int, help=""Prometheus metrics port (METRICS_PORT)"")
    parser.add_argument(""--a2a-port"", type=int, help=""A2A gRPC port (A2A_PORT)"")
    parser.add_argument(""--disable-tls"", action=""store_true"", help=""Disable TLS for gRPC (INSECURE_DISABLE_TLS)"")
    parser.add_argument(""--kafka-broker"", help=""Kafka bootstrap servers (ALPHA_KAFKA_BROKER)"")
    parser.add_argument(""--cycle-seconds"", type=int, help=""Default agent cycle period (ALPHA_CYCLE_SECONDS)"")
    parser.add_argument(""--max-cycle-sec"", type=int, help=""Hard limit per agent run (MAX_CYCLE_SEC)"")
    parser.add_argument(""--enabled"", help=""Comma-separated list of enabled agents (ALPHA_ENABLED_AGENTS)"")
    parser.add_argument(""--loglevel"", default=""INFO"", help=""Logging level (LOGLEVEL)"")
    parser.add_argument(""--version"", action=""store_true"", help=""Print version and exit"")
    return parser.parse_args()
",alpha_factory_v1/backend/main.py,,1,3.3982678079468468e-09,"The method '_parse_args' is a utility function that sets up command-line argument parsing for a backend application. It uses the argparse library, which is a standard and widely used library in Python for handling command-line arguments. The method defines a variety of arguments that are likely essential for configuring the application's runtime behavior, such as enabling development mode, setting ports, and specifying logging levels. These functionalities are crucial for the flexibility and configurability of command-line applications, especially in a backend context where different environments and configurations are common. Therefore, this method is likely to be retained as it provides necessary functionality for the application."
survived,"    def register(self, *args, **kwargs):
        pass
",stubs/openai_agents/__init__.py,AgentRuntime,0,0.99999960721363,"The method 'register' is defined but not implemented, as it only contains a 'pass' statement. This suggests that it is a placeholder for future code. If the method is not used or implemented in the future, it is likely to be deleted to clean up the codebase. However, if it is intended to be implemented later, it might survive. Without additional context, the lack of implementation suggests it is more likely to be deleted."
survived,"    def Tool(*_a, **_kw):  # type: ignore
        def _decorator(func):
            return func

        return _decorator
",alpha_factory_v1/demos/self_healing_repo/agent_selfheal_entrypoint.py,,1,1.1253518384332553e-07,"The method 'Tool' is a decorator factory that returns a decorator function. It is a simple and flexible way to create decorators that can accept any number of positional and keyword arguments. The use of '*_a' and '**_kw' allows it to handle any arguments passed to it, making it versatile. The 'type: ignore' comment suggests that the developer is intentionally bypassing type checking, which might be necessary for certain dynamic use cases. This method is likely to survive because it provides a useful pattern for creating decorators in Python, which is a common requirement in many applications."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/load_yaml.py,Auto1,0,0.999915188952306,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually meant for checking membership in a collection like a list, set, or dictionary. This misuse of `__contains__` could lead to confusion and unexpected behavior, as it does not align with the standard behavior expected from this method. Therefore, it is likely that this method will be deleted or refactored to better fit its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/load_yaml.py,Auto2,0,0.9999546021442518,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method could lead to confusion and unexpected behavior, especially for users familiar with the conventional use of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/dataset_where_filter.py,Auto1,1,4.539785574814975e-05,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually implemented to check for membership in a collection like a list, set, or dictionary. However, if the class is designed to treat its attributes as keys in a collection, this implementation could be valid. Without additional context, it's difficult to determine if this is a misuse or a valid use case. Given the flexibility of Python and the potential for custom implementations, this method is likely to survive unless it causes confusion or errors in the intended use of the class."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/save_jsonl_stdout.py,Auto1,0,0.9999756997690634,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking for membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/group_by.py,Person,0,0.999983298584886,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"def stub_dependencies(monkeypatch):
    fpdf_mod = types.ModuleType('fpdf')
    class DummyFPDF:
        def add_page(self):
            pass
        def add_font(self, *args, **kwargs):
            pass
        def set_font(self, *args, **kwargs):
            pass
        def set_margins(self, *args, **kwargs):
            pass
        def multi_cell(self, *args, **kwargs):
            pass
        def set_draw_color(self, *args, **kwargs):
            pass
        def line(self, *args, **kwargs):
            pass
        def output(self, *args, **kwargs):
            pass
        y = 0
    fpdf_mod.FPDF = DummyFPDF
    monkeypatch.setitem(sys.modules, 'fpdf', fpdf_mod)

    docx_mod = types.ModuleType('docx')
    class DummyDocxDocument:
        def add_heading(self, *args, **kwargs):
            pass
        def add_paragraph(self, *args, **kwargs):
            pass
        def save(self, *args, **kwargs):
            pass
    docx_mod.Document = DummyDocxDocument
    monkeypatch.setitem(sys.modules, 'docx', docx_mod)

    import KindleClippings
    monkeypatch.setattr(KindleClippings, 'args', types.SimpleNamespace(format='txt'), raising=False)",tests/conftest.py,,1,2.646573631904765e-09,"The method `stub_dependencies` is likely to survive because it serves a useful purpose in testing environments. It creates dummy modules and classes to replace actual dependencies, allowing tests to run without requiring the actual libraries. This is a common practice in unit testing to isolate the code under test from external dependencies, making tests more reliable and faster. The use of `monkeypatch` to modify `sys.modules` and attributes is a standard technique in Python testing frameworks like pytest."
survived,"        def add_heading(self, *args, **kwargs):
            pass
",tests/conftest.py,DummyDocxDocument,0,0.9999989322969233,"The method `add_heading` is defined but not implemented, as it only contains a `pass` statement. This suggests that the method is either a placeholder for future implementation or it was intended to be implemented but never completed. If the method is not used anywhere in the codebase or if there is no plan to implement it, it is likely to be deleted. However, if it is part of an interface or abstract class where subclasses are expected to provide an implementation, it might survive. Without additional context, the lack of implementation leans towards deletion."
survived,"        def line(self, *args, **kwargs):
            pass
",tests/conftest.py,DummyFPDF,0,0.9999991684720096,"The method 'line' is defined but not implemented, as it only contains a 'pass' statement. This suggests that it is a placeholder for future code. If the method is not used or planned to be implemented, it is likely to be deleted to clean up the codebase. However, if it is part of an interface or abstract class, it might survive as a required method signature. Without additional context, the likelihood of deletion is higher."
survived,"def _save_result(result: ResultsResponse) -> None:
    path = _results_dir / f""{result.id}.json""
    path.write_text(result.json())
",src/interface/api_server.py,,1,2.646573631904765e-09,"The method _save_result is a utility function that saves a result object to a JSON file. It is a straightforward and useful function for persisting data, which is a common requirement in many applications. The method is simple, does not have any apparent issues, and serves a clear purpose. Therefore, it is likely to be retained in the codebase."
survived,"def _load_results() -> None:
    for f in _results_dir.glob(""*.json""):
        try:
            data = json.loads(f.read_text())
            res = ResultsResponse(**data)
        except Exception:
            continue
        _simulations[res.id] = res
",src/interface/api_server.py,,1,4.944450477491054e-09,"The method '_load_results' is likely to survive because it performs a specific and necessary function of loading JSON files from a directory, parsing them, and storing the results in a dictionary. This is a common pattern in data processing applications, and unless there is a significant change in the application's requirements or architecture, such utility functions are generally retained. Additionally, the method includes error handling, which makes it robust and less prone to failure, further supporting its continued use."
survived,"    def convert_type(self, node: ast.expr | None) -> str:
        if node is None:
            return ""any""
        if isinstance(node, ast.Name):
            mapping = {""int"": ""int"", ""str"": ""string"", ""bool"": ""bool"", ""float"": ""float""}
            return mapping.get(node.id, node.id)
        if isinstance(node, ast.Attribute):
            return node.attr
        if isinstance(node, ast.Subscript):
            if isinstance(node.value, ast.Attribute) and node.value.attr == ""Callable"":
                if isinstance(node.slice, ast.Tuple) and len(node.slice.elts) == 2:
                    args, ret = node.slice.elts
                    if isinstance(args, ast.List):
                        arg_types = [self.convert_type(e) for e in args.elts]
                    else:
                        arg_types = [self.convert_type(args)]
                    return (
                        ""fun("" + "", "".join(arg_types) + ""): "" + self.convert_type(ret)
                    )
        return ""any""
",tools/any2mochi/py/py2mochi.py,Converter,1,1.1861120010657661e-08,"The method 'convert_type' is a utility function that converts AST nodes to string representations of types. This is a common requirement in code analysis, transformation, or generation tasks, especially when dealing with Python's Abstract Syntax Tree (AST). The method handles various node types like 'Name', 'Attribute', and 'Subscript', which are essential for understanding and converting type annotations. Given its utility in parsing and converting type information, it is likely to be retained in the codebase."
survived,"    def visit_Assign(self, node: ast.Assign) -> None:
        if len(node.targets) != 1:
            return
        target = node.targets[0]
        if isinstance(target, ast.Name):
            name = self.name_map.get(target.id, target.id)
            if isinstance(node.value, ast.Constant) and node.value.value is None:
                return
            if (
                isinstance(node.value, ast.Call)
                and isinstance(node.value.func, ast.Name)
                and node.value.func.id == ""TypeVar""
            ):
                return
            if (
                isinstance(node.value, ast.Call)
                and isinstance(node.value.func, ast.Name)
                and node.value.func.id in self.dataclasses
                and not node.value.args
                and len(node.value.keywords) == 1
                and node.value.keywords[0].arg is None
                and isinstance(node.value.keywords[0].value, ast.Call)
                and isinstance(node.value.keywords[0].value.func, ast.Name)
                and node.value.keywords[0].value.func.id == ""_fetch""
            ):
                typ = node.value.func.id
                fetch_expr = self.convert_expr(node.value.keywords[0].value)
                self.seen_assigns.add(name)
                self.assign_values[name] = f""({fetch_expr}) as {typ}""
                var_kw = ""var"" if name == ""next"" else ""let""
                self.emit(f""{var_kw} {name}: {typ} = ({fetch_expr}) as {typ}"")
                return
            expr = self.convert_expr(node.value)
            if name in self.seen_assigns:
                if self.assign_values.get(name) == expr:
                    return
                self.assign_values[name] = expr
                self.emit(f""{name} = {expr}"")
                return
            self.seen_assigns.add(name)
            self.assign_values[name] = expr
            var_kw = ""var"" if name == ""next"" else ""let""
            self.emit(f""{var_kw} {name} = {expr}"")
            return
        if isinstance(target, ast.Attribute) and isinstance(target.value, ast.Name) and target.value.id == ""self"":
            self.emit(f""{target.attr} = {self.convert_expr(node.value)}"")
            return
",tools/any2mochi/py/py2mochi.py,Converter,1,1.4166087846364157e-09,"The method `visit_Assign` is a part of a larger codebase that likely deals with processing or transforming Python Abstract Syntax Trees (ASTs). The method handles assignment nodes, checking various conditions to determine how to process them. It includes logic for handling specific cases like `TypeVar`, dataclasses, and assignments to `self` attributes. This method is crucial for the functionality it provides in transforming or analyzing code, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained in the codebase."
survived,"    def _clear_tool_stats() -> None:
        clear_tool_stats()
",src/serena/dashboard.py,SerenaDashboardAPI,0,0.9999998362622821,"The method `_clear_tool_stats` is a simple wrapper around the function `clear_tool_stats`. It doesn't add any additional functionality or abstraction, making it redundant. Unless there is a specific reason for its existence, such as being part of an interface or a requirement for a design pattern, it is likely to be deleted to reduce unnecessary code."
survived,"def mount_gradio_app(app, ui, path=""/""):
    return app
",tests/test_agent_experience_entrypoint.py,,0,0.999891103056471,"The method 'mount_gradio_app' is a simple function that takes three parameters and returns the 'app' object. It doesn't perform any operations on the inputs or modify the 'app' in any way. This suggests that the function might be a placeholder or a stub for future development. However, without additional context, it's difficult to determine if this function is critical or if it will be expanded upon in the future. If the function is part of a larger framework or library where such a pattern is common, it might survive. But if it's not used or needed, it could be deleted. Given the lack of functionality, it leans towards being deleted unless it's part of a larger, necessary interface."
survived,"def test_rejects_symlink(tmp_path: Path, monkeypatch: pytest.MonkeyPatch) -> None:
    client = _make_client(tmp_path, monkeypatch)

    info = tarfile.TarInfo(""link"")
    info.type = tarfile.SYMTYPE
    info.linkname = ""../evil""
    payload = _make_tar(info)

    resp = client.post(""/mutate"", files={""tar"": (""bad.tar"", payload, ""application/x-tar"")})
    assert resp.status_code == 400
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_evolution_worker.py,,1,2.5109990926928157e-08,"The method 'test_rejects_symlink' is a unit test designed to ensure that the application correctly rejects tar files containing symbolic links. This is a common security measure to prevent directory traversal attacks. The test is well-structured, using pytest fixtures like 'tmp_path' and 'monkeypatch', and it checks for the expected HTTP 400 response status code, indicating a bad request. Such tests are crucial for maintaining application security and are unlikely to be deleted as they provide ongoing value in ensuring the robustness of the application against certain types of attacks."
survived,"    def _run_runtime(
        episodes: int, target: int, model: str | None = None, rewriter: str | None = None
    ) -> None:
        print(""openai-agents package is missing. Running offline demo..."")
        run(episodes=episodes, target=target, model=model, rewriter=rewriter)
",alpha_factory_v1/demos/alpha_agi_insight_v0/openai_agents_bridge.py,,1,2.8453347280241004e-08,"The method '_run_runtime' is a private method (indicated by the underscore prefix) and is likely intended for internal use within a module or class. It serves a specific purpose of running a demo when the 'openai-agents' package is missing. The method is functional, as it prints a message and calls another function 'run' with the provided parameters. Unless there is a significant change in the module's requirements or structure, such as the removal of the 'run' function or a change in how demos are handled, there is no immediate reason to delete this method. It is likely to survive as long as the functionality it provides is needed."
survived,"    def test_bridge_run_helper(self) -> None:
        import asyncio

        if has_oai:  # pragma: no cover - only run offline path
            self.skipTest(""openai-agents installed"")

        summary = asyncio.run(run_insight_search(episodes=1, target=1))
        self.assertIn(""sector"", summary)
",tests/test_alpha_agi_insight_bridge.py,TestAlphaAgiInsightBridge,1,1.3440409770490404e-08,"The method `test_bridge_run_helper` is a test method that checks the functionality of the `run_insight_search` function. It uses `asyncio.run` to execute an asynchronous function and verifies the output by asserting that the word 'sector' is in the summary. The method also includes a condition to skip the test if a certain package is installed. This indicates that the method is part of a test suite, likely for a larger application, and is useful for ensuring the correct behavior of the code. Test methods are generally not deleted unless they are redundant or replaced by more comprehensive tests. Therefore, this method is likely to be retained."
survived,"def test_call_attributes_read_only(client):
    @weave.op()
    def my_op():
        call = call_context.get_current_call()
        with pytest.raises(TypeError):
            call.attributes[""new""] = ""value""
        return 1

    my_op()
    calls = list(client.get_calls())
    assert len(calls) == 1
    assert ""new"" not in calls[0].attributes
",tests/trace/test_current_call.py,,1,1.8189616842444243e-09,"The method 'test_call_attributes_read_only' is a test function that verifies the immutability of the 'attributes' dictionary in a 'call' object. It uses a decorator '@weave.op()' which suggests it is part of a larger framework or library. The function is well-structured, uses assertions to validate behavior, and is likely part of a test suite to ensure the integrity of the system. Test functions like this are crucial for maintaining code quality and are typically not deleted unless the feature they test is removed or significantly changed. Therefore, the method is likely to survive."
survived,"def test_bundle_hash_stable(monkeypatch: pytest.MonkeyPatch) -> None:
    """"""Bundle hash should remain stable across invocations.""""""
    mod = importlib.import_module(MODULE)

    orchestrator = mod.Orchestrator()
    fin = mod.AgentFin()
    res = mod.AgentRes()
    ene = mod.AgentEne()
    gdl = mod.AgentGdl()
    model = mod.Model()

    monkeypatch.setattr(fin, ""latent_work"", lambda _b: 0.0)
    monkeypatch.setattr(res, ""entropy"", lambda _b: 1.0)
    monkeypatch.setattr(ene, ""market_temperature"", lambda _b: 1.0)

    calls: list[str] = []

    def _post(bundle_id: str, delta_g: float) -> None:
        calls.append(bundle_id)

    monkeypatch.setattr(orchestrator, ""post_alpha_job"", _post)

    async def _llm(_: float) -> str:
        return ""ok""

    monkeypatch.setattr(mod, ""_llm_comment"", _llm)

    monkeypatch.setattr(orchestrator, ""collect_signals"", lambda: dict([(""b"", 2), (""a"", 1)]))
    asyncio.run(mod.run_cycle_async(orchestrator, fin, res, ene, gdl, model, a2a_socket=None))

    monkeypatch.setattr(orchestrator, ""collect_signals"", lambda: dict([(""a"", 1), (""b"", 2)]))
    asyncio.run(mod.run_cycle_async(orchestrator, fin, res, ene, gdl, model, a2a_socket=None))

    assert len(calls) == 2
    assert calls[0] == calls[1]
",tests/test_alpha_agi_business_3_v1.py,,1,3.2241866333029355e-08,"The method `test_bundle_hash_stable` is a unit test designed to ensure that the bundle hash remains stable across different invocations. It uses the `monkeypatch` fixture from `pytest` to mock certain behaviors and dependencies, which is a common practice in testing to isolate the functionality being tested. The test checks that the same bundle ID is generated in two separate runs, indicating stability. This is a useful test for ensuring consistent behavior in the system, especially if the bundle hash is critical for operations. Therefore, it is likely to be retained as part of the test suite."
survived,"def main():
    parser = argparse.ArgumentParser(
        description=""Run hierarchical LDA on the BBC tech dataset""
    )
    parser.add_argument(
        ""--data-dir"",
        default=os.path.join(os.path.dirname(__file__), "".."", ""data"", ""bbc"", ""tech""),
        help=""Directory containing BBC .txt files"",
    )
    parser.add_argument(""--iterations"", type=int, default=100, help=""Number of Gibbs samples"")
    parser.add_argument(
        ""--display-topics"", type=int, default=50, help=""Report topics every N iterations""
    )
    parser.add_argument(
        ""--n-words"", type=int, default=5, help=""Number of words to display per topic""
    )
    parser.add_argument(
        ""--num-levels"", type=int, default=3, help=""Depth of the topic hierarchy""
    )
    parser.add_argument(""--alpha"", type=float, default=10.0, help=""Alpha hyperparameter"")
    parser.add_argument(""--gamma"", type=float, default=1.0, help=""Gamma hyperparameter"")
    parser.add_argument(""--eta"", type=float, default=0.1, help=""Eta hyperparameter"")
    parser.add_argument(""--seed"", type=int, default=0, help=""Random seed"")

    args = parser.parse_args()
    run_demo(args)
",scripts/run_bbc_demo.py,,1,2.8453347280241004e-08,"The method 'main' is a typical entry point for a Python script that uses the argparse library to handle command-line arguments. It is well-structured and provides a clear interface for configuring the execution of a hierarchical LDA model on a dataset. The use of argparse is standard practice for scripts that require user input for configuration, and the method is likely to be useful for users who need to run the script with different parameters. Therefore, it is unlikely to be deleted as it serves a crucial role in the script's functionality."
survived,"def run_demo(args):
    corpus = load_documents(args.data_dir)
    vocab, index = build_vocab(corpus)
    int_corpus = convert_corpus(corpus, index)

    hlda = HierarchicalLDA(
        int_corpus,
        vocab,
        alpha=args.alpha,
        gamma=args.gamma,
        eta=args.eta,
        num_levels=args.num_levels,
        seed=args.seed,
    )

    hlda.estimate(
        args.iterations,
        display_topics=args.display_topics,
        n_words=args.n_words,
        with_weights=False,
    )

    print(""\nFinal topic hierarchy:"")
    hlda.print_nodes(args.n_words, with_weights=False)

    return hlda
",scripts/run_hlda.py,,1,8.152020648014727e-09,"The method 'run_demo' is a complete and functional piece of code that performs a specific task: it loads documents, builds a vocabulary, converts the corpus, initializes a Hierarchical LDA model, estimates the model, and prints the final topic hierarchy. This method is likely to be useful in contexts where topic modeling is required, especially in research or applications involving natural language processing. The method is well-structured, and its functionality is clear, making it a valuable part of a codebase dealing with topic modeling. Therefore, it is likely to be retained."
survived,"    def select(self, gamma):
        ''' Selects an existing child or create a new one according to the CRP '''

        weights = np.zeros(len(self.children)+1)
        weights[0] = float(gamma) / (gamma+self.customers)
        i = 1
        for child in self.children:
            weights[i] = float(child.customers) / (gamma + self.customers)
            i += 1

        choice = self.random_state.multinomial(1, weights).argmax()
        if choice == 0:
            return self.add_child()
        else:
            return self.children[choice-1]
",src/hlda/sampler.py,NCRPNode,1,3.850741907939403e-09,"The method 'select' is a crucial part of a probabilistic model, likely implementing a Chinese Restaurant Process (CRP) or a similar stochastic process. It dynamically selects or creates a child based on the given 'gamma' parameter and the current state of 'children' and 'customers'. This kind of functionality is essential in models that require dynamic structure, such as non-parametric Bayesian models. The method is well-defined, uses numpy for efficient computation, and is likely integral to the functionality of the class it belongs to. Therefore, it is unlikely to be deleted."
survived,"def load_corpus(file_name):
    with open(file_name, 'rb') as f:
        corpus = []
        reader = csv.reader(f)
        for row in reader:
            doc = []
            for idx_and_word in row:
                stripped = idx_and_word.strip()
                tokens = stripped.split(' ')
                if len(tokens) == 2:
                    idx, word = tokens
                    doc.append(int(idx))
            corpus.append(doc)
        return corpus",src/hlda/sampler.py,,0,0.9999995549151272,"The method 'load_corpus' is likely to be deleted because it contains several issues that make it unreliable and potentially unusable. Firstly, the method attempts to read a file using the 'csv.reader' without importing the 'csv' module, which will result in a NameError. Secondly, the method assumes that each row in the CSV file contains strings that can be split into exactly two parts, which may not always be the case, leading to potential errors. Additionally, the method does not handle exceptions or edge cases, such as empty rows or invalid data formats. These issues suggest that the method is not robust or well-implemented, making it a candidate for deletion or significant revision."
survived,"def convert_corpus(corpus, index):
    new_corpus = []
    for doc in corpus:
        new_corpus.append([index[w] for w in doc])
    return new_corpus
",scripts/run_hlda.py,,1,2.5109990926928157e-08,"The method 'convert_corpus' is a utility function that transforms a list of documents (corpus) into a new format using a provided index mapping. This type of function is commonly used in text processing tasks, such as preparing data for machine learning models. The function is simple, efficient, and serves a clear purpose in data preprocessing, which is a crucial step in many applications. Therefore, it is likely to be retained as it provides essential functionality for converting text data into a numerical format that can be used for further analysis or model training."
survived,"    def setUp(self):
        self.patcher = unittest.mock.patch(
            'klongpy.sys_fn_kdb.qconnection',
            SimpleNamespace(QConnection=DummyQConnection, QFunction=type('QFunction', (), {}))
        )
        self.patcher.start()
",tests/test_sys_fn_kdb.py,TestKdbIPC,1,2.1024340680345882e-07,"The method is a setup method for a test case, using unittest.mock to patch a component. This is a common practice in unit testing to isolate the unit of work being tested from its dependencies. The method is likely to be used in a test class to prepare the test environment, and such methods are essential for ensuring tests run in a controlled and predictable manner. Therefore, it is unlikely to be deleted."
survived,"    def __init__(self, inst: DummyAgent) -> None:
        self.inst = inst
        self.next_ts = 1
",tests/test_orchestrator_rest.py,DummyRunner,1,3.653482080241728e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes or states. The presence of the 'inst' parameter suggests that this constructor is setting up an instance of the class with a 'DummyAgent' object, which is likely crucial for the class's functionality. Therefore, it is unlikely that this method will be deleted."
survived,"    def tearDown(self):
        """"""Close the Gym environment after each test.""""""
        self.mu.env.close()
",tests/test_muzero_planning.py,TestMiniMu,1,8.152020648014727e-09,"The method `tearDown` is a standard part of the unittest framework in Python, used to clean up after each test method is run. It ensures that resources are properly released, which is important for preventing resource leaks and ensuring that tests do not interfere with each other. The specific implementation here, closing a Gym environment, is a common practice when using environments that need to be reset or closed after use. Therefore, this method is likely to be retained as it follows best practices for test cleanup."
survived,"    def run_model(
        self,
        api_key: SecretStr,
        model_name: str,
        prompt: str,
        input_image: Optional[str],
        aspect_ratio: str,
        seed: Optional[int],
    ) -> str:
        client = ReplicateClient(api_token=api_key.get_secret_value())
        input_params = {
            ""prompt"": prompt,
            ""input_image"": input_image,
            ""aspect_ratio"": aspect_ratio,
        }
        if seed is not None:
            input_params[""seed""] = seed

        output: FileOutput | list[FileOutput] = client.run(  # type: ignore
            model_name,
            input=input_params,
            wait=False,
        )

        if isinstance(output, list) and output:
            first = output[0]
            if isinstance(first, FileOutput):
                return first.url
            return first
        if isinstance(output, FileOutput):
            return output.url
        if isinstance(output, str):
            return output
        return ""No output received""",autogpt_platform/backend/backend/blocks/flux_kontext.py,AIImageEditorBlock,1,1.2501528648238603e-09,"The method 'run_model' is a well-structured function that interacts with an external API to run a model and return the output. It handles different types of outputs and includes optional parameters, making it flexible and robust. The use of type hints and optional parameters suggests good coding practices. There is no indication that this method is obsolete or redundant, and it seems to serve a clear purpose in the context of interacting with a model API. Therefore, it is likely to be retained in the codebase."
survived,"    def path_retro_route():
        args = request.args
        data = rs.path_retro(
            origin=args[""origin""],
            dest=args[""dest""],
            currtime=int(args.get(""currtime"")) if args.get(""currtime"") else None,
            time_offset=int(args.get(""time_offset"")) if args.get(""time_offset"") else None,
            transfer_penalty=int(args.get(""transfer_penalty"", 0)),
            walking_speed=float(args.get(""walking_speed"", 1.0)),
        )
        return Response(data, mimetype=""application/json"")
",pygs/graphserver/ext/routeserver/routeserver.py,,1,1.6052280526088547e-09,"The method 'path_retro_route' is a functional part of a web application, likely a Flask route handler, that processes HTTP requests to calculate a path using the 'rs.path_retro' function. It extracts parameters from the request, processes them, and returns a JSON response. This functionality is essential for the application to handle specific routing requests, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained in the codebase."
survived,"    def add(self, text: str) -> None:
        vec = embed(text)
        if self.index is not None:
            self.index.add(vec)
        self.mean = (self.mean * self.count + vec[0]) / (self.count + 1)
        self.count += 1
",src/evaluators/novelty.py,NoveltyIndex,1,2.0611536181902033e-09,"The method 'add' is likely to survive because it performs a specific and useful function: it embeds a given text into a vector, adds it to an index if the index is not None, and updates the mean and count. This functionality is typical in applications involving text processing and vector embeddings, such as in machine learning or information retrieval systems. The method is concise and appears to be part of a larger class or system that manages text embeddings, which is a common requirement in modern software applications."
survived,"def test_verify_assets(tmp_path: Path, monkeypatch: pytest.MonkeyPatch) -> None:
    content = b""data""
    asset_path = tmp_path / ""file.txt""
    asset_path.write_bytes(content)
    digest = base64.b64encode(hashlib.sha384(content).digest()).decode()
    monkeypatch.setattr(fa, ""ASSETS"", {""file.txt"": ""cid""})
    monkeypatch.setattr(fa, ""CHECKSUMS"", {""file.txt"": f""sha384-{digest}""})
    assert fa.verify_assets(tmp_path) == []
    asset_path.write_text(""bad"")
    assert fa.verify_assets(tmp_path) == [""file.txt""]",tests/test_fetch_assets.py,,1,7.3382086014706e-07,The method 'test_verify_assets' is a test function that uses pytest's monkeypatching to simulate and verify the behavior of the 'verify_assets' function from the 'fa' module. It checks if the function correctly identifies when an asset's content does not match its expected checksum. This is a typical unit test pattern and is essential for ensuring the integrity of the 'verify_assets' function. Test functions like this are crucial for maintaining code quality and are unlikely to be deleted unless the functionality they test is removed or significantly changed.
survived,"    def Depends(*_a, **_kw):  # type: ignore
        return None
",alpha_factory_v1/backend/orchestrator.py,,0,0.9999724643101549,"The method 'Depends' is defined to accept any arguments and keyword arguments but simply returns None. This suggests that it is a placeholder or a stub, possibly used to satisfy an interface or to be overridden later. However, as it stands, it does not perform any meaningful operation. If it is not overridden or used in a meaningful way elsewhere in the code, it is likely to be considered redundant and could be deleted in future refactoring efforts."
survived,"    async def verify_token(
        credentials: HTTPAuthorizationCredentials = Depends(security),
    ) -> None:
        if credentials.credentials != token:
            raise HTTPException(status_code=403, detail=""Invalid token"")
",alpha_factory_v1/backend/orchestrator.py,,1,6.348800075736417e-09,"The method 'verify_token' is a simple utility function that checks if the provided token matches a predefined token. This is a common pattern in authentication processes to ensure that only authorized requests are processed. The method is concise, performs a necessary security check, and uses standard practices like raising an HTTPException when the token is invalid. Given its utility in securing endpoints, it is likely to be retained in the codebase."
survived,"def _no_missing(monkeypatch):
    monkeypatch.setattr(check_env, ""REQUIRED"", [])
    monkeypatch.setattr(check_env, ""OPTIONAL"", [])
    monkeypatch.setattr(check_env, ""warn_missing_core"", lambda: [])
",tests/test_check_env_wheelhouse.py,,1,3.0590235908148916e-07,"The method `_no_missing` is a utility function that uses `monkeypatch` to modify the `check_env` module's attributes for testing purposes. It sets the `REQUIRED` and `OPTIONAL` lists to empty and overrides the `warn_missing_core` function to return an empty list. This is likely used to simulate an environment where no required or optional dependencies are missing, which is useful for testing scenarios.

The method is specific to testing and does not perform any harmful or redundant operations. It is a common practice to use such methods in test suites to ensure that the code behaves correctly under controlled conditions. Therefore, it is unlikely to be deleted as it serves a clear purpose in the context of testing."
survived,"def _hamming_dist(a: bytes, b: bytes) -> int:
    diff = 0
    for x, y in zip(a, b):
        diff += (x ^ y).bit_count()
    diff += 8 * abs(len(a) - len(b))
    return diff
",tests/test_checksum.py,,1,1.4166087846364157e-09,"The method _hamming_dist is a utility function that calculates the Hamming distance between two byte sequences. This is a common operation in various fields such as data analysis, error detection, and cryptography. The implementation is efficient, using bitwise operations to count differing bits, and it handles sequences of different lengths by adding the appropriate number of bits to the difference. Given its utility and efficient implementation, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q16.py,Part,1,0.09534946811246837,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually used to check for membership in a collection like a list, set, or dictionary. However, if the class is designed to treat its attributes as keys in a collection-like manner, this implementation could be valid. Without additional context, it's hard to determine if this is a misuse or a valid use case. Given the potential for misuse, it might be considered for deletion, but it could also be retained if it fits the class's design."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q21.py,Supplier,0,0.9999930377415741,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or replaced with a more appropriate implementation that correctly checks for key membership."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q8.py,Auto1,0,0.9999970976877992,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the standard or expected behavior for `__contains__`, which should typically check for membership in a collection like a list, set, or dictionary. This misuse of `__contains__` is likely to lead to confusion and errors, as it does not align with the conventional use of the method. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q3.py,Customer,0,0.9999785550602307,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method is likely to lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership testing. Therefore, it is likely that this method will be deleted or significantly modified to align with its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q14.py,Lineitem,0,0.9999785550602307,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q7.py,Lineitem,0,0.9999910602998366,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q3.py,Auto1,1,1.892514738127224e-05,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually implemented to check for membership in a collection like a list, set, or dictionary. However, if the class is designed to treat its attributes as keys in a collection-like manner, this implementation could be valid. Without additional context, it's hard to determine if this is a misuse or a valid use case. Given the flexibility of Python and the potential for custom use cases, this method is likely to survive unless it is clearly misaligned with the intended use of the class."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q1.py,Lineitem,0,0.9999339478346898,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually meant for checking membership in collections like lists, sets, or dictionaries. This misuse of `__contains__` could lead to confusion and unexpected behavior, as it does not align with the standard behavior expected from this method. Therefore, it is likely that this method will be deleted or refactored to better fit its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q20.py,Part,0,0.9999546021442518,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q11.py,Nation,0,0.9999869928752253,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q23.py,Auto11,0,0.9999869928752253,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q26.py,Auto8,0,0.999983298584886,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose suggests that it is likely to be deleted or refactored to align with its conventional use."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q11.py,Auto10,1,2.5109990926928157e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a clear and functional purpose, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q24.py,Auto1,0,0.9999898700118929,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list or dictionary. Therefore, the method is likely to be deleted or rewritten to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q22.py,Auto8,0,0.999876605372333,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method's intended purpose could lead to confusion and unexpected behavior, making it a candidate for deletion or refactoring."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q23.py,Auto11,1,5.3157849718487075e-08,"The method is a simple implementation of the __getitem__ special method, which allows instances of the class to use the bracket notation (e.g., obj[key]) to access attributes. This is a common and useful pattern in Python, especially for classes that aim to mimic dictionary-like behavior. It provides a clear and concise way to access attributes dynamically, which can be very useful in various applications. Therefore, it is likely to be retained as it adds flexibility and utility to the class."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q27.py,Auto10,0,0.999983298584886,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q30.py,Auto11,1,4.1399375473943306e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method is straightforward, functional, and leverages Python's dynamic attribute access, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q29.py,Auto3,0,0.9998415637531546,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually implemented to check for membership in a collection like a list, set, or dictionary. Using `hasattr` could lead to confusion and unexpected behavior, as it doesn't align with the conventional use of `__contains__`. Therefore, it's likely that this method will be deleted or refactored to better fit its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q5.py,Auto2,0,0.9999898700118929,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually used to check for membership in a collection like a list, set, or dictionary. Therefore, this implementation is misleading and does not align with the expected behavior of `__contains__`, making it likely to be deleted or refactored."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q17.py,Auto8,1,1.955568070542584e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name, which can be useful for objects that need to provide dictionary-like access to their attributes. This method is simple, clear, and leverages Python's dynamic nature effectively. It is likely to be useful in many contexts where objects need to behave like dictionaries, making it a candidate for survival."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/job/compiler/py/q17.py,,1,3.3982678079468468e-09,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The function is well-structured and provides flexibility through options like 'where', 'sortKey', 'skip', and 'take'. Such utility functions are often retained in codebases because they encapsulate common patterns of data manipulation, making them reusable and reducing code duplication. Therefore, it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q12.py,Auto5,1,6.825604231969389e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q17.py,Auto4,0,0.9997694933225385,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually meant for checking membership in a collection like a list, set, or dictionary. This misuse of `__contains__` could lead to confusion and unexpected behavior, as it does not align with the standard behavior expected from this method. Therefore, it is likely that this method will be deleted or refactored to better fit its intended purpose."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q22.py,Auto3,1,1.725782769012759e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a flexible and Pythonic way to access object attributes, it is likely to be retained in the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q23.py,Auto10,1,2.998960815863541e-09,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be Survived as it serves a clear purpose and is implemented correctly."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q18.py,Auto1,1,1.3440409770490404e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python to allow more flexible and dynamic access to object properties. Therefore, this method is likely to be retained as it serves a clear purpose and follows Python's conventions for special methods."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q11.py,Auto1,0,0.9999038976006968,"The method is implementing the `__contains__` magic method, which is used to define behavior for the `in` keyword. However, the implementation is incorrect because `hasattr` checks for attributes, not for membership in a collection. Typically, `__contains__` should check if an item is present in a collection, like a list or dictionary, not if an object has an attribute. This misuse suggests a misunderstanding of the method's purpose, which could lead to its deletion or replacement with a correct implementation."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q2.py,Auto2,0,0.9999756997690634,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the implementation here uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be used for checking membership in a collection like a list, set, or dictionary. The misuse of `hasattr` suggests a misunderstanding of the method's purpose, which could lead to incorrect behavior when the method is used. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q18.py,Auto2,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is likely to survive because it provides a flexible way to access object attributes, which can be particularly useful in dynamic or reflective programming scenarios."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q19.py,Auto9,0,0.9999921107349486,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q11.py,Auto8,1,1.3440409770490404e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be retained as it serves a clear purpose and follows Python's design principles."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/job/compiler/py/q19.py,,1,1.955568070542584e-08,"The method '_key' is a utility function that is likely used internally within a class or module to generate a key for sorting purposes. It takes an iterable 'it', applies a function 'sortKey' from a dictionary 'opts' to it, and then checks if the result is a list, tuple, or dictionary. If so, it converts it to a string; otherwise, it returns the key as is. This method is simple, has a clear purpose, and is likely used in sorting operations, which are common in data processing. There is no indication of redundancy or obsolescence, suggesting it will survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q2.py,Auto3,1,1.3007124774680372e-05,"The method `__contains__` is intended to check if a container contains a specific item, typically using the `in` keyword. In this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not a typical use of `__contains__`, as it should check for membership rather than attribute existence. However, if the class is designed to treat its attributes as the items it contains, this could be a valid implementation. Without more context, it's hard to definitively say if this is a misuse or a creative use. Given that it might be a specific design choice, the method is likely to survive unless there's a clear indication that this behavior is incorrect for the intended use of the class."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q16.py,Auto3,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"def test_Q25_finds_male_horror_writer_with_violent_keywords():
    assert result == [
        Auto1(
            movie_budget=""Horror"",
            movie_votes=100,
            male_writer=""Mike"",
            violent_movie_title=""Scary Movie"",
        )
    ]
",tests/dataset/job/compiler/py/q25.py,,1,2.646573631904765e-09,"The method `test_Q25_finds_male_horror_writer_with_violent_keywords` is a test function, likely part of a test suite for a larger codebase. Test functions are generally not deleted unless they are redundant, incorrect, or the functionality they test is no longer relevant. Since this function seems to be testing a specific case (finding a male horror writer with violent keywords), it is likely still relevant to the codebase. Therefore, it is more likely to survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q20.py,Auto4,1,1.955568070542584e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q12.py,Auto6,0,0.9999898700118929,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or replaced with a more appropriate implementation that correctly checks for key membership."
survived,"def test_Q11_returns_min_company__link_type_and_title():
    assert result == [
        Auto1(
            from_company=""Best Film Co"",
            movie_link_type=""follow-up"",
            non_polish_sequel_movie=""Alpha"",
        )
    ]
",tests/dataset/job/compiler/py/q11.py,,1,2.5109990926928157e-08,"The method `test_Q11_returns_min_company__link_type_and_title` is a test function, likely part of a test suite for a larger codebase. Test functions are generally not deleted unless they are redundant, incorrect, or replaced by more comprehensive tests. This function appears to be testing a specific scenario or feature, which is important for ensuring the correctness of the code. Therefore, it is likely to be retained as part of the testing process."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q30.py,Auto8,1,1.955568070542584e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a clear and functional way to access object attributes, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q26.py,Auto7,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or replaced with a more appropriate implementation that correctly checks for key membership."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q23.py,Auto6,0,0.999988521231025,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose suggests that it is likely to be deleted or refactored to align with its conventional use."
survived,"def _min(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""min() expects list or group"")
    vals = [it for it in v if it is not None]
    if not vals:
        return 0
    return min(vals)
",tests/dataset/job/compiler/py/q19.py,,1,5.3157849718487075e-08,"The method '_min' is a utility function that calculates the minimum value from a list or a group with an 'Items' attribute. It includes error handling for non-list inputs and returns 0 for empty lists. Such utility functions are often useful in various contexts where data might be encapsulated in different structures. The method is simple, clear, and provides a specific functionality that can be reused across different parts of a codebase. Therefore, it is likely to be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q16.py,Auto7,0,0.999985261023967,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement the intended functionality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q22.py,Auto7,0,0.9999869928752253,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q17.py,Auto7,1,0.1645164710892692,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually used to check for membership in a collection like a list, set, or dictionary. However, if the class is designed to treat its attributes as a collection of keys, this implementation could be valid. Without additional context, it's difficult to determine if this is the intended use. If the class is indeed designed to treat its attributes as keys, the method might survive. Otherwise, it might be considered a misuse and be deleted or refactored."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q29.py,Auto8,1,2.5109990926928157e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name, which can be useful for objects that need to provide dictionary-like access to their attributes. This method is simple, clear, and leverages Python's dynamic nature effectively. It is likely to be useful in many scenarios where objects need to behave like dictionaries, especially in frameworks or libraries that require such flexibility. Therefore, it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q19.py,Auto12,1,6.348800075736417e-09,"The method is a simple implementation of the __getitem__ special method, which allows an object to use the bracket notation (obj[key]) to access its attributes. This is a common and useful pattern in Python, especially for classes that aim to mimic dictionary-like behavior. It provides a clear and concise way to access attributes dynamically, which can be very useful in various applications. There is no indication that this method is redundant or harmful, so it is likely to be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q18.py,Auto7,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use of `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, especially for users familiar with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q8.py,Auto3,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose is likely to lead to confusion and incorrect behavior when the method is used. Therefore, it is likely that this method will be deleted or refactored to align with its intended use."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q27.py,Auto8,1,8.152020648014727e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, this method is likely to be retained as it serves a clear purpose and follows Python's conventions for special methods."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q22.py,Auto6,0,0.9999785550602307,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use of `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to better fit its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q23.py,Auto1,0,0.9999339478346898,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use of `__contains__`, which is expected to check membership rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q12.py,Auto2,1,9.237449576640118e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python to allow more flexible and dynamic access to object properties. Therefore, this method is likely to be retained as it serves a clear purpose and follows Python's conventions for special methods."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q5.py,Auto6,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, especially for users who expect `in` to check for membership in a collection. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q15.py,Auto9,0,0.9999417087232136,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method is likely to lead to confusion and incorrect behavior when the method is used in the context of checking membership. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q20.py,Auto5,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not attribute existence. This misuse of the method could lead to confusion and unexpected behavior, especially for users familiar with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q28.py,Auto9,0,0.999985261023967,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list, set, or dictionary. Therefore, this implementation is likely incorrect and may lead to unexpected behavior, suggesting it should be deleted or significantly revised."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q25.py,Auto2,1,2.8453347280241004e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method is correctly implemented and serves a clear purpose, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q33.py,Auto7,0,0.999983298584886,"The method is implementing the `__contains__` method, which is used to define behavior for the `in` keyword. However, the implementation is incorrect because it uses `hasattr(self, key)`, which checks for the presence of an attribute, not a key in a collection. Typically, `__contains__` is used for checking membership in a collection like a list, set, or dictionary, where the key would be an element or a key in a dictionary. This method will likely be deleted or revised because it does not fulfill the expected behavior of `__contains__` for collections."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q27.py,Auto3,1,2.5109990926928157e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q19.py,Auto12,0,0.9999485577825553,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the standard or expected behavior for `__contains__`, which is usually used for membership testing in collections like lists, sets, or dictionaries. This misuse of `__contains__` could lead to confusion and unexpected behavior, as it does not align with the typical use case of checking for membership in a collection. Therefore, it is likely that this method will be deleted or refactored to better align with its intended purpose."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q31.py,Auto1,1,1.955568070542584e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q93.py,Auto2,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and incorrect functionality when the object is used in contexts expecting standard membership testing. Therefore, it is likely that this method will be deleted or significantly modified to align with its intended purpose."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q99.py,,1,4.6911638017642294e-08,"The method _key is a utility function that is used to generate a key for sorting purposes. It takes an iterable 'it' and applies a function 'sortKey' from the 'opts' dictionary to it. The method then checks if the result is a list, tuple, or dictionary, and converts it to a string if so. Otherwise, it returns the key as is. This method is likely to be used internally within a class or module to facilitate sorting operations based on custom criteria. Since it serves a specific purpose and is not overly complex or redundant, it is likely to be retained in the codebase."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q1.py,,1,8.76424914819242e-08,"The method _key is a utility function that is used to generate a key for sorting purposes. It takes an iterable 'it' and applies a function 'sortKey' from the 'opts' dictionary to it. The method then checks if the result is a list, tuple, or dictionary, and converts it to a string if so. Otherwise, it returns the key as is. This method is likely to be used internally within a class or module to facilitate sorting operations based on a customizable key. Such utility functions are common and useful in codebases that require flexible sorting mechanisms. Therefore, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q13.py,Auto1,0,0.9999980052698925,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement the intended functionality."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q94.py,WebReturn,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q26.py,Promotion,1,9.237449576640118e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python to allow more flexible and dynamic access to object properties. Therefore, this method is likely to be retained as it serves a clear purpose and is implemented correctly."
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q3.py,,1,7.194132978569833e-09,"The method '_group_by' is a utility function that groups elements of a list based on a key function. It is a common pattern in data processing and transformation tasks. The function is generic, flexible, and can handle various types of input, making it useful in many contexts. Unless there is a specific reason to remove it, such as redundancy or a better alternative, it is likely to be retained."
survived,"def _q0():
    _src = union_sales
    _rows = _query(_src, [], {""select"": lambda s: s})
    _groups = _group_by(
        _rows, lambda s: s.get(""manu"") if isinstance(s, dict) else getattr(s, ""manu"")
    )
    _items1 = _groups
    _items1 = sorted(
        _items1,
        key=lambda g: -_sum(
            [x.get(""price"") if isinstance(x, dict) else getattr(x, ""price"") for x in g]
        ),
    )
    return [
        Auto1(
            i_manufact_id=g.key,
            total_sales=_sum(
                [
                    x.get(""price"") if isinstance(x, dict) else getattr(x, ""price"")
                    for x in g
                ]
            ),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q33.py,,1,5.60279640614594e-09,"The method '_q0' is a private function (indicated by the underscore prefix) that processes sales data. It queries, groups, and sorts the data based on manufacturer and total sales. The method is likely part of a larger system that analyzes sales data, and its functionality seems specific and useful for that purpose. There is no indication that it is obsolete or redundant, so it is likely to be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q30.py,Customer,0,0.9999417087232136,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical use case for `__contains__`, which is expected to check membership rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, especially for users who expect `in` to check for membership in a collection rather than attribute existence. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"def test_TPCDS_Q67_simplified():
    assert result == 67
",tests/dataset/tpc-ds/compiler/py/q67.py,,1,2.699578619062706e-07,"The method `test_TPCDS_Q67_simplified` is a test function that asserts whether the variable `result` is equal to 67. This is a very basic test, and its survival depends on the context in which it is used. If this test is part of a larger suite that checks the correctness of a specific function or process, it is likely to survive as it serves a purpose in verifying expected outcomes. However, if `result` is not defined or this test does not align with any meaningful functionality, it might be deleted. Without additional context, it is reasonable to assume it serves a purpose in a test suite, so it is likely to survive."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q40.py,_Group,1,1.522997951276035e-08,"The method is a constructor for a class, initializing instance variables. It sets up the 'key' and two lists, 'Items' and 'items', which are references to the same list. This is a common pattern in Python to initialize object state, and there is no indication of redundancy or error. Therefore, it is likely to be retained."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q98.py,,1,6.348800075736417e-09,"The method '_key' is a utility function that is likely used internally within a class or module to generate a key for sorting purposes. It takes an iterable 'it', applies a sorting key function from 'opts', and ensures the key is a string if it's a complex data type. This kind of method is typically useful for customizing sorting behavior and is not overly complex or redundant. Therefore, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q37.py,Inventory,0,0.9999251538028718,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q43.py,Store,1,8.152020648014727e-09,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q61.py,Sale,0,0.9999984465026855,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q95.py,DateDim,1,8.152020648014727e-09,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q20.py,Auto1,0,0.9999417087232136,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q4.py,Auto3,0,0.999985261023967,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not fulfill its intended purpose of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q77.py,Auto2,0,0.9999962733608834,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key checking in a collection."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q52.py,StoreSale,0,0.9999994284997149,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, this implementation uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of `__contains__` is likely to lead to confusion and errors, as it does not align with the standard behavior expected from this method. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q23.py,Auto2,1,2.998960815863541e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python to allow more flexible and dynamic access to object properties. Therefore, this method is likely to be Survived."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q38.py,WebSale,1,1.2501528648238603e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python to allow more flexible and dynamic access to object properties. Therefore, this method is likely to be Survived."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q88.py,HouseholdDemographic,0,0.9999945777825671,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or replaced with a more appropriate implementation that correctly checks for key membership."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q7.py,Auto2,0,0.9999251538028718,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the implementation here uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method could lead to confusion and unexpected behavior, especially for users familiar with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q72.py,_Group,1,1.8189616842444243e-09,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation here is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q71.py,WebSale,1,1.1861120010657661e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a flexible and Pythonic way to access object attributes, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q76.py,Item,1,3.726639116582555e-06,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically for list or dictionary-like objects. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation if the intention is to allow attribute access via indexing. However, it might be considered unconventional or potentially confusing if the object is not clearly intended to behave like a dictionary or similar structure. Despite this, the method is functional and could be useful in certain contexts, so it is likely to survive unless there is a specific reason to remove it, such as a change in design requirements or a shift to a more conventional approach."
survived,"def test_TPCDS_Q39_simplified():
    assert summary == [Auto1(w_warehouse_sk=1, i_item_sk=1, cov=1.539600717839002)]
",tests/dataset/tpc-ds/compiler/py/q39.py,,1,1.725782769012759e-08,"The method `test_TPCDS_Q39_simplified` is a test function that uses an assertion to check if the variable `summary` matches a specific list containing an instance of `Auto1`. This is a typical pattern in unit testing to ensure that the code behaves as expected. The method is likely to survive because it serves a clear purpose in verifying the correctness of the code, which is essential for maintaining code quality and reliability."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q16.py,DateDim,1,1.4166087846364157e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern and does not have any apparent issues or redundancies that would warrant its deletion. Therefore, it is likely to survive."
survived,"def test_TPCDS_Q71_simplified():
    assert result == [
        Auto1(i_brand_id=10, i_brand=""BrandA"", t_hour=18, t_minute=0, ext_price=200.0),
        Auto1(i_brand_id=20, i_brand=""BrandB"", t_hour=8, t_minute=30, ext_price=150.0),
        Auto1(i_brand_id=10, i_brand=""BrandA"", t_hour=8, t_minute=30, ext_price=100.0),
    ]
",tests/dataset/tpc-ds/compiler/py/q71.py,,1,5.905303995456778e-10,"The method 'test_TPCDS_Q71_simplified' is a unit test function that checks if the 'result' variable matches a specific list of 'Auto1' objects. This is a typical pattern in test-driven development to ensure that a function or process produces the expected output. Since testing is a crucial part of software development to maintain code quality and reliability, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly changed. Therefore, the method will likely survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q97.py,Auto2,0,0.9999970976877992,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or replaced with a more appropriate implementation."
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q2.py,,1,1.522997951276035e-08,"The method '_group_by' is a utility function that groups elements of a list based on a key function. It is a common pattern in data processing and transformation tasks. The function is generic, flexible, and can handle various input types, making it useful in many scenarios. Unless there is a specific reason to remove it, such as redundancy or a better alternative, it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q31.py,WebSale,1,1.1861120010657661e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation, especially in cases where the object is designed to behave like a dictionary or to provide dynamic attribute access. Since it serves a clear purpose and is correctly implemented, it is likely to be retained in the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q91.py,CustomerAddres,1,5.905303995456778e-10,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be Survived."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q34.py,Auto2,1,1.3440409770490404e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q2.py,Auto4,0,0.9999687980937693,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list, set, or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate membership check."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q77.py,Auto7,1,1.522997951276035e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. Since it serves a clear purpose and is implemented correctly, it is likely to be retained in the code."
survived,"def _q0():
    _src = customer
    _rows = _query(
        _src,
        [
            {
                ""items"": store_sales,
                ""on"": lambda c, s: c.c_customer_sk == s.ss_customer_sk,
            },
            {""items"": date_dim, ""on"": lambda c, s, d: s.ss_sold_date_sk == d.d_date_sk},
        ],
        {""select"": lambda c, s, d: (c, s, d)},
    )
    _groups = _group_by(
        _rows,
        lambda c, s, d: Auto3(
            id=c.c_customer_id,
            first=c.c_first_name,
            last=c.c_last_name,
            login=c.c_login,
            year=d.d_year,
        ),
    )
    _items1 = _groups
    return [
        Auto2(
            customer_id=g.key[""id""],
            customer_first_name=g.key[""first""],
            customer_last_name=g.key[""last""],
            customer_login=g.key[""login""],
            dyear=g.key[""year""],
            year_total=_sum(
                [
                    (
                        x[1].ss_ext_list_price
                        - x[1].ss_ext_wholesale_cost
                        - x[1].ss_ext_discount_amt
                        + x[1].ss_ext_sales_price
                    )
                    / 2
                    for x in g
                ]
            ),
            sale_type=""s"",
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q4.py,,1,1.1861120010657661e-08,"The method '_q0' appears to be a part of a data processing pipeline, likely used for querying and aggregating customer sales data. It performs operations such as joining tables, grouping data, and calculating totals, which are common tasks in data analysis and reporting. These functionalities are essential in many business applications for generating insights and reports. Unless there is a significant change in the requirements or the method is replaced by a more efficient or updated version, it is likely to be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q27.py,CustomerDemographic,0,0.9999756997690634,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement the intended functionality."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q23.py,Item,1,9.237449576640118e-09,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, this method is likely to be retained as it provides a clear and useful functionality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q58.py,Auto2,0,0.9999687980937693,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose suggests that it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q75.py,Auto1,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list, set, or dictionary. Therefore, the method is likely to be deleted or rewritten to correctly implement membership checking."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q57.py,_Group,1,1.955568070542584e-08,"The method `__len__` is a special method in Python that is used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"def _sum(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""sum() expects list or group"")
    s = 0.0
    for it in v:
        if it is None:
            continue
        if isinstance(it, (int, float)):
            s += float(it)
        else:
            raise Exception(""sum() expects numbers"")
    return s
",tests/dataset/tpc-ds/compiler/py/q3.py,,1,2.3355930333443423e-09,"The method '_sum' is a utility function that calculates the sum of a list of numbers, with additional handling for objects that have an 'Items' attribute. It includes error handling for non-list inputs and non-numeric elements within the list. This function is useful for summing elements in a list while ensuring type safety and handling potential None values. Such utility functions are common in codebases for data processing tasks, and unless there is a specific reason to remove it (such as redundancy or a better alternative), it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q10.py,StoreSale,1,4.6911638017642294e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. This implementation uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a clear and functional purpose, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q3.py,Item,0,0.999998629043345,"The method is incorrectly implemented. The `__contains__` method is supposed to check for membership, typically in a collection or container, by returning True if the item is present and False otherwise. However, this implementation uses `hasattr`, which checks if an object has an attribute with the given name, not if the object contains the item. This is a misuse of the `__contains__` method, which is expected to work with iterable objects like lists, sets, or dictionaries. Therefore, this method is likely to be deleted or rewritten to correctly implement membership checking."
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q77.py,_Group,1,2.646573631904765e-09,"The method is a standard implementation of the __iter__ method in Python, which is used to make an object iterable. It returns an iterator over the 'Items' attribute of the object. This is a common and necessary method for classes that need to support iteration, and there is no indication that it is redundant or incorrect. Therefore, it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q27.py,StoreSale,1,3.653482080241728e-08,"The method is a simple implementation of the __getitem__ special method, which allows instances of the class to use the bracket notation (e.g., instance[key]) to access attributes. This is a common and useful pattern in Python, especially for classes that aim to mimic dictionary-like behavior. It provides a clear and concise way to access attributes dynamically, which can be very useful in various applications. Therefore, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q46.py,StoreSale,0,0.999983298584886,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q33.py,,1,9.237449576640118e-09,"The method '_group_by' is a utility function that groups elements of a list based on a key function. It is a common pattern in data processing and transformation tasks. The function is generic, flexible, and can handle various types of input, making it useful in many contexts. Unless there is a specific reason to remove it, such as redundancy or a better alternative, it is likely to be retained."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q79.py,_Group,1,2.998960815863541e-09,"The method `__len__` is a special method in Python that is used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q72.py,,1,5.043472052266442e-07,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It appears to be a utility function that could be part of a larger data processing or querying system. Such functions are often essential in applications that require dynamic data manipulation, especially in systems that mimic SQL-like operations in a non-SQL environment. Given its complexity and potential utility, it is more likely to be maintained and refined rather than deleted, unless it is replaced by a more efficient or simpler solution."
survived,"def test_TPCDS_Q76_simplified():
    assert result == [
        Auto1(
            channel=""store"",
            col_name=None,
            d_year=1998,
            d_qoy=1,
            i_category=""CatA"",
            sales_cnt=1,
            sales_amt=10.0,
        ),
        Auto1(
            channel=""web"",
            col_name=None,
            d_year=1998,
            d_qoy=1,
            i_category=""CatB"",
            sales_cnt=1,
            sales_amt=15.0,
        ),
        Auto1(
            channel=""catalog"",
            col_name=None,
            d_year=1998,
            d_qoy=1,
            i_category=""CatC"",
            sales_cnt=1,
            sales_amt=20.0,
        ),
    ]
",tests/dataset/tpc-ds/compiler/py/q76.py,,1,6.825604231969389e-08,"The method `test_TPCDS_Q76_simplified` is a test function that asserts the equality of a `result` variable with a list of `Auto1` objects. This is a typical pattern in unit testing where specific expected outcomes are compared against actual results to verify correctness. Since testing is a crucial part of software development to ensure code reliability and correctness, this method is likely to be retained as part of the test suite. It helps in validating that the function or process generating `result` is working as intended, especially in a data processing or analytics context like TPC-DS (a decision support benchmark)."
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q21.py,,1,1.4166087846364157e-09,"The method '_group_by' is likely to survive because it provides a useful utility function for grouping elements of a list based on a key function. This is a common requirement in data processing and manipulation tasks. The method is generic, allowing it to work with any type of list elements and key functions, making it versatile and reusable. Additionally, the use of a dictionary to maintain groups and a list to preserve order is an efficient approach. Unless there are significant changes in the requirements or a better alternative is introduced, this method is likely to remain useful."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q52.py,Item,1,1.725782769012759e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be retained as it serves a clear purpose and follows Python's design principles."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q35.py,Customer,0,0.999998790133938,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the typical or expected behavior for `__contains__`, which should check for membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may lead to confusion or errors when used, suggesting it should be deleted or revised."
survived,"def _q6():
    _src = catalog_returns
    _rows = _query(
        _src,
        [
            {
                ""items"": date_dim,
                ""on"": lambda cr, d: d.d_date_sk == cr.cr_returned_date_sk,
            }
        ],
        {""select"": lambda cr, d: (cr, d)},
    )
    _groups = _group_by(_rows, lambda cr, d: cr.cr_call_center_sk)
    _items7 = _groups
    return [
        Auto5(
            cr_call_center_sk=g.key,
            returns=_sum([x[0].cr_return_amount for x in g]),
            profit_loss=_sum([x[0].cr_net_loss for x in g]),
        )
        for g in _items7
    ]
",tests/dataset/tpc-ds/compiler/py/q77.py,,1,3.3982678079468468e-09,"The method '_q6' appears to be a utility function that processes data from a catalog returns dataset. It performs a query to join data based on a date key, groups the results by a call center key, and then calculates the total return amount and net loss for each group. This type of data processing function is common in data analysis and reporting tasks, and it seems to be well-structured for its purpose. Unless there is a significant change in the requirements or the data structure, this method is likely to be useful and thus survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q35.py,CustomerAddres,0,0.9999930377415741,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"def test_TPCDS_Q35_simplified():
    assert groups == [
        Auto1(
            ca_state=""CA"",
            cd_gender=""M"",
            cd_marital_status=""S"",
            cd_dep_count=1,
            cd_dep_employed_count=1,
            cd_dep_college_count=0,
            cnt=1,
        )
    ]
",tests/dataset/tpc-ds/compiler/py/q35.py,,1,7.194132978569833e-09,"The method `test_TPCDS_Q35_simplified` is a test function, likely part of a test suite for a larger codebase. Test functions are generally important for ensuring code correctness and are not typically deleted unless they are redundant or replaced by more comprehensive tests. The function checks for a specific condition using an assertion, which is a common practice in testing. Without additional context indicating that this test is obsolete or incorrect, it is reasonable to assume it will be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q33.py,CustomerAddres,1,4.6911638017642294e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is likely to be retained as it provides a flexible way to access object attributes, which can be particularly useful in dynamic or reflective programming scenarios."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q48.py,Store,0,0.9999599363048656,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to better fit its intended purpose."
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q22.py,_Group,1,1.9171715133907573e-10,"The method `__iter__` is a standard Python method used to make an object iterable. By returning an iterator over `self.Items`, it allows the object to be used in loops and other contexts that require iteration. This is a fundamental feature for many classes that manage collections of items, making it highly unlikely to be deleted unless the class design changes significantly. Therefore, the method will survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q73.py,DateDim,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually implemented to check for membership in a collection like a list, set, or dictionary. Therefore, this implementation might be considered incorrect or misleading, as it does not align with the expected behavior of `__contains__`. It is likely to be deleted or refactored to better fit the intended use of the method."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q74.py,Auto3,0,0.9999898700118929,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement the intended functionality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q23.py,Auto2,0,0.9994472214174237,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually meant for checking membership in a collection like a list, set, or dictionary. 

Using `hasattr` in this context might lead to confusion, as it does not align with the expected behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to better fit the intended use of `__contains__` in a collection context."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q93.py,StoreReturn,0,0.9999970976877992,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the standard or expected behavior for `__contains__`, which should typically check for membership in a collection like a list, set, or dictionary. This misuse of `__contains__` is likely to lead to confusion and errors, as it does not align with the conventional use of the method. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q3.py,Auto2,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the typical or expected behavior for `__contains__`, which should check for membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate membership check."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q38.py,StoreSale,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use of `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, especially for users familiar with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q38.py,Customer,1,7.194132978569833e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be retained as it serves a clear purpose and follows Python's design principles."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q24.py,_Group,1,2.8453347280241004e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes. The code snippet shows a typical pattern where an attribute is initialized and a list is created. There is no indication of redundancy or poor design that would warrant deletion. Therefore, it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q51.py,Auto2,1,5.3157849718487075e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, it is likely to be retained."
survived,"def test_TPCDS_Q28_buckets():
    assert result == Auto1(
        B1_LP=100.0, B1_CNT=1, B1_CNTD=1, B2_LP=80.0, B2_CNT=1, B2_CNTD=1
    )
",tests/dataset/tpc-ds/compiler/py/q28.py,,1,1.4166087846364157e-09,"The method `test_TPCDS_Q28_buckets` is a test function, likely part of a test suite for a larger codebase. Test functions are generally not deleted unless they are redundant, incorrect, or the functionality they are testing is no longer relevant. Since this function is asserting a specific result, it indicates that it is actively used to verify the correctness of some functionality related to `Auto1`. Without additional context suggesting that this test is obsolete or incorrect, it is reasonable to assume that it will survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q17.py,Auto2,1,2.8453347280241004e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. It is a simple and effective way to provide dynamic access to object attributes, which can be particularly useful in data handling or configuration classes. Therefore, this method is likely to be retained as it serves a clear purpose and is implemented correctly."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q91.py,,1,3.850741907939403e-09,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The function is well-structured and provides flexibility through the use of options like 'where', 'sortKey', 'skip', and 'take'. Such utility functions are often retained in codebases because they encapsulate common patterns of data manipulation, making them reusable and reducing code duplication. Therefore, it is likely to survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q74.py,DateDim,1,1.1861120010657661e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q57.py,DateDim,0,0.9999984465026855,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, this implementation uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of `__contains__` is likely to lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership testing. Therefore, it is likely to be deleted or replaced with a more appropriate implementation."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q7.py,,1,3.3982678079468468e-09,"The method '_key' is a utility function that is likely used internally within a module or class to generate a key for sorting purposes. It takes an iterable 'it', applies a sorting key function from 'opts', and ensures the key is a string if it's a complex data type. This kind of function is common in data processing or sorting operations, and unless the entire module or class is being refactored or removed, such utility functions are generally retained. Therefore, it is likely to survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q23.py,Item,0,0.9999485577825553,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the implementation here uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method could lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership checks. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q79.py,,1,2.0611536181902033e-09,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be used in various data processing scenarios, making it versatile and potentially useful in many contexts. The function is not overly specific to a single use case, which increases its chances of being retained in the codebase. Additionally, the function is well-structured and implements common data manipulation operations, which are often needed in software applications. Therefore, it is likely to survive."
survived,"def test_TPCDS_Q27_averages_by_state():
    assert result == [
        Auto1(
            i_item_id=""ITEM1"", s_state=""CA"", agg1=5.0, agg2=100.0, agg3=10.0, agg4=90.0
        )
    ]
",tests/dataset/tpc-ds/compiler/py/q27.py,,1,3.653482080241728e-08,"The method `test_TPCDS_Q27_averages_by_state` is a test function, which is typically used to verify the correctness of a specific piece of code. Test functions are generally important for maintaining code quality and ensuring that changes do not break existing functionality. Since this function is an assertion test, it is likely part of a test suite that checks the output of a function or process against expected results. Such tests are crucial for continuous integration and deployment processes, making it unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q4.py,WebSale,1,6.825604231969389e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. It is unlikely to be deleted unless the design of the class changes significantly, as it provides a flexible way to access attributes dynamically."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q13.py,HouseholdDemographics,0,0.9999930377415741,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"def _q0():
    _groups = {}
    _order = []
    for r in filtered:
        _k = Auto2()
        _ks = str(_k)
        g = _groups.get(_ks)
        if not g:
            g = _Group(_k)
            _groups[_ks] = g
            _order.append(_ks)
        g.Items.append(r)
    _items1 = [_groups[k] for k in _order]
    return [
        Auto1(
            avg_ss_quantity=_avg([x[""ss_quantity""] for x in g]),
            avg_ss_ext_sales_price=_avg([x[""ss_ext_sales_price""] for x in g]),
            avg_ss_ext_wholesale_cost=_avg([x[""ss_ext_wholesale_cost""] for x in g]),
            sum_ss_ext_wholesale_cost=_sum([x[""ss_ext_wholesale_cost""] for x in g]),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q13.py,,1,3.653482080241728e-08,"The method '_q0' appears to be a utility function that processes a collection of filtered data, groups it, and then computes various aggregate statistics for each group. The method is likely part of a larger codebase that deals with data processing or analysis. The use of helper functions like '_avg' and '_sum' suggests that these operations are essential for the intended functionality. Unless there is a significant change in the requirements or the method is replaced by a more efficient or comprehensive solution, it is likely to survive as it provides specific functionality that is not trivial to replace."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q11.py,WebSale,1,5.60279640614594e-09,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a flexible and Pythonic way to access object attributes, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q43.py,Auto2,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate method for checking key membership."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q76.py,Auto2,0,0.9999999123575085,"The method is likely to be deleted because it does not implement the expected behavior of the `__contains__` method. In Python, `__contains__` is used to check if a container contains a certain item, typically using the `in` keyword. The current implementation uses `hasattr`, which checks for the presence of an attribute, not an item in a collection. This could lead to confusion and incorrect behavior when the method is used, as it does not align with the standard use case of `__contains__`. Therefore, it is not fulfilling its intended purpose and is likely to be removed or rewritten."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q99.py,CallCenter,0,0.9999989322969233,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not fulfill its intended purpose of checking membership in a collection. Therefore, it is likely to be deleted or replaced with a more appropriate implementation."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q45.py,CustomerAddres,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a flexible and Pythonic way to access object attributes, it is likely to be retained in the code."
survived,"def test_TPCDS_Q47_simplified():
    assert result == [
        Auto1(d_year=2019, item=""C"", avg_monthly_sales=50.0, sum_sales=60.0),
        Auto1(d_year=2020, item=""A"", avg_monthly_sales=100.0, sum_sales=120.0),
    ]
",tests/dataset/tpc-ds/compiler/py/q47.py,,1,1.522997951276035e-08,"The method 'test_TPCDS_Q47_simplified' is a test function, which is typically used to verify the correctness of a specific piece of code. Test functions are generally not deleted unless they are redundant, incorrect, or replaced by a more comprehensive test. Since this function appears to be a straightforward test with a clear assertion, it is likely to be retained to ensure the functionality it tests remains correct."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q34.py,Store,0,0.999876605372333,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually meant for checking membership in a collection like a list, set, or dictionary. This misuse of `__contains__` could lead to confusion and unexpected behavior, as it does not align with the standard behavior expected from this method. Therefore, it is likely that this method will be deleted or refactored to better fit its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q27.py,DateDim,0,0.9999962733608834,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q50.py,Auto1,0,0.9999251538028718,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose suggests that it might be deleted or refactored to align with its conventional use."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q4.py,CatalogSale,0,0.9999991684720096,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys. However, this implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be used for membership testing in collections like lists, sets, or dictionaries. Therefore, this method is likely to be deleted or refactored to correctly implement membership testing."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q56.py,Auto2,1,3.653482080241728e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to behave like a dictionary or similar container, allowing attribute access via keys. Since this is a common and practical use case, the method is likely to be retained in the code."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q43.py,,1,1.725782769012759e-08,"The method '_key' is a utility function that is likely used internally within a class or module to generate a key for sorting purposes. It is a simple and straightforward function that converts the result of a 'sortKey' function into a string if it is a list, tuple, or dictionary. This kind of utility function is common in codebases where sorting or ordering of complex data structures is required. Since it serves a specific purpose and is not overly complex or redundant, it is likely to be retained in the codebase."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q76.py,,1,2.8453347280241004e-08,"The method '_key' is a utility function that is likely used internally within a class or module to generate a key for sorting purposes. It is a simple and straightforward function that converts the result of a 'sortKey' function into a string if it is a list, tuple, or dictionary. This kind of utility function is common in codebases where sorting or ordering of complex data structures is required. Since it serves a specific purpose and is not overly complex or redundant, it is likely to be retained in the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q98.py,Auto3,1,4.1399375473943306e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python to allow more flexible and dynamic access to object properties. Therefore, this method is likely to be retained as it provides a clear and useful functionality."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q6.py,_Group,1,1.2501528648238603e-09,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is correctly implemented to return the length of `self.Items`, which suggests that `self.Items` is likely a list or a similar collection. This is a standard and expected implementation for custom objects that need to support the `len()` function. Therefore, there is no reason to delete this method as it provides necessary functionality for the class."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q85.py,WebReturn,1,8.76424914819242e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a common and useful pattern for objects that need to provide dynamic attribute access. This method is likely to be useful in many contexts where objects need to behave like dictionaries or provide flexible attribute access. Therefore, it is likely to be retained."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q84.py,,1,2.646573631904765e-09,"The method '_key' is a utility function that is likely used internally to generate a key for sorting purposes. It converts the key to a string if it is a list, tuple, or dictionary, ensuring compatibility with sorting operations. Such utility functions are common in codebases for handling specific tasks and are often retained unless they are replaced by a more efficient or comprehensive solution. Without additional context indicating redundancy or obsolescence, it is reasonable to predict that this method will survive."
survived,"def test_TPCDS_Q25_aggregated_profit():
    assert result == [
        Auto1(
            i_item_id=""ITEM1"",
            i_item_desc=""Desc1"",
            s_store_id=""S1"",
            s_store_name=""Store1"",
            store_sales_profit=50.0,
            store_returns_loss=10.0,
            catalog_sales_profit=30.0,
        ),
        Auto1(
            i_item_id=""ITEM2"",
            i_item_desc=""Desc2"",
            s_store_id=""S1"",
            s_store_name=""Store1"",
            store_sales_profit=20.0,
            store_returns_loss=5.0,
            catalog_sales_profit=15.0,
        ),
    ]
",tests/dataset/tpc-ds/compiler/py/q25.py,,1,2.646573631904765e-09,"The method `test_TPCDS_Q25_aggregated_profit` is a test function, likely part of a test suite for a larger application. Test functions are generally not deleted unless they are redundant, incorrect, or the functionality they test is no longer relevant. Since this function appears to be testing specific expected results for a query or calculation related to TPC-DS (a decision support benchmark), it is likely important for ensuring the correctness of the system's behavior. Therefore, unless the functionality it tests is removed or significantly altered, the test is likely to survive."
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q27.py,_Group,1,1.6052280526088547e-09,"The method `__iter__` is a standard Python method used to make an object iterable. It is implemented correctly here by returning an iterator over `self.Items`. This is a common and necessary method for classes that need to support iteration, such as those representing collections or sequences. Therefore, it is unlikely to be deleted as it provides essential functionality for the class."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q53.py,StoreSale,1,1.1253518384332553e-07,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a flexible and Pythonic way to access object attributes, it is likely to be retained in the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q96.py,Store,1,2.2159489282323004e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via keys, similar to a dictionary. Since this method provides a clear and functional purpose, it is likely to be retained in the code."
survived,"def _q0():
    _groups = {}
    _order = []
    for r in revenue:
        _k = r.customer
        _ks = str(_k)
        g = _groups.get(_ks)
        if not g:
            g = _Group(_k)
            _groups[_ks] = g
            _order.append(_ks)
        g.Items.append(r)
    _items1 = [_groups[k] for k in _order]
    return [Auto3(customer=g.key, revenue=sum([x.amt for x in g])) for g in _items1]
",tests/dataset/tpc-ds/compiler/py/q54.py,,0,0.999998790133938,"The method '_q0' is likely to be deleted because it contains several issues that suggest it is not well-maintained or useful in its current form. Firstly, the method relies on undefined variables and classes such as 'revenue', '_Group', and 'Auto3', which indicates that it cannot function as intended without additional context or definitions. Secondly, the method uses a non-descriptive name '_q0', which does not convey its purpose or functionality, making it difficult for other developers to understand or maintain. Lastly, the method's logic appears to be a simple aggregation of revenue by customer, which is a common operation that might be better handled by more robust and well-tested libraries or functions. These factors suggest that the method is either incomplete, redundant, or not aligned with best practices, leading to its potential deletion."
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q91.py,_Group,1,2.646573631904765e-09,"The method is a standard implementation of the __iter__ method in Python, which is used to make an object iterable. It returns an iterator over the 'Items' attribute of the object. This is a common and necessary method for classes that need to support iteration, and there is no indication that it is redundant or incorrect. Therefore, it is likely to be retained."
survived,"def test_TPCDS_Q3_result():
    assert result == [
        Auto1(d_year=1998, brand_id=2, brand=""Brand2"", sum_agg=20.0),
        Auto1(d_year=1998, brand_id=1, brand=""Brand1"", sum_agg=10.0),
    ]
",tests/dataset/tpc-ds/compiler/py/q3.py,,1,1.4166087846364157e-09,"The method `test_TPCDS_Q3_result` is a unit test function that checks if the `result` variable matches a specific list of `Auto1` objects. Unit tests are crucial for ensuring code correctness and reliability, especially in larger projects. They help in identifying bugs early and ensure that changes in the code do not break existing functionality. Given the importance of testing in software development, it is likely that this method will be retained to maintain code quality."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q8.py,DateDim,1,1.0467401685178159e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be retained as it serves a clear purpose and is implemented correctly."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q10.py,Auto2,1,8.76424914819242e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q99.py,ShipMode,0,0.9999687980937693,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute in an object, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q5.py,Result,1,1.955568070542584e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q32.py,Item,0,0.9999417087232136,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, especially for users familiar with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q23.py,,1,2.2159489282323004e-08,"The method '_key' is a utility function that is likely used internally within a class or module to generate a key for sorting purposes. It is a simple and concise function that converts the result of a 'sortKey' function into a string if it is a list, tuple, or dictionary. This kind of utility function is common in codebases where sorting or ordering of complex data structures is required. Since it serves a specific purpose and is not overly complex or redundant, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q1.py,Customer,0,0.9999945777819207,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical use case for `__contains__`, which is expected to check membership rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"def distinct(xs):
    out = []
    for x in xs:
        if not x in out:
            out = out + [x]
    return out
",tests/dataset/tpc-ds/compiler/py/q38.py,,1,2.699578619062706e-07,"The method 'distinct' is a basic implementation of a function that removes duplicates from a list, returning a list of distinct elements. While the logic is correct, the implementation is inefficient due to the use of list concatenation in a loop, which results in O(n^2) time complexity. However, the method is functional and serves a common purpose, which is to filter out duplicates from a list. Therefore, it is likely to survive, although it could be optimized."
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q73.py,,1,1.4166087846364157e-09,"The method '_group_by' is a utility function that groups elements of a list based on a key function. This is a common and useful operation in data processing and manipulation, making it likely to be retained. The function is generic, flexible, and handles different types of input, which increases its utility. Additionally, it maintains the order of first occurrence of keys, which can be important in many applications. These factors suggest that the method will survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q8.py,Store,0,0.999988521231025,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q79.py,DateDim,0,0.9999945777819207,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys. However, this implementation uses `hasattr`, which checks if an object has an attribute with the given name. This is not the intended use of `__contains__`, as it should be used for membership testing in collections, not for checking attributes. Therefore, this method is likely to be deleted or replaced with a more appropriate implementation."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q35.py,CustomerDemographic,1,3.653482080241728e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a common and useful pattern for dynamic attribute access, especially in cases where the object is used like a dictionary or needs to provide flexible access to its attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q34.py,Auto3,1,1.3440409770490404e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation, especially in cases where the object is designed to behave like a dictionary or needs to provide dynamic access to its attributes. Therefore, it is likely to be retained as it serves a clear purpose and follows Python's conventions for special methods."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q44.py,Item,1,7.73442280641062e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation, especially in cases where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, the method is likely to be retained as it provides a flexible way to access object attributes."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q90.py,WebPage,1,8.76424914819242e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be retained because it provides a flexible way to access object properties, which can be particularly useful in dynamic or reflective programming scenarios."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q15.py,Auto2,1,1.3440409770490404e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a common and useful pattern for dynamic attribute access, especially in classes that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q57.py,Auto1,1,6.023574641292144e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"def test_TPCDS_Q14_cross_channel():
    assert result == [
        Auto1(
            channel=""store"",
            i_brand_id=1,
            i_class_id=1,
            i_category_id=1,
            sales=60.0,
            number_sales=1,
        )
    ]
",tests/dataset/tpc-ds/compiler/py/q14.py,,1,7.73442280641062e-08,"The method `test_TPCDS_Q14_cross_channel` is a test function, likely part of a test suite for a larger application. Test functions are generally not deleted unless they are redundant, incorrect, or replaced by more comprehensive tests. Since this function appears to be a straightforward test case with a clear assertion, it is likely to be retained to ensure the correctness of the code it is testing."
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q1.py,,1,6.348800075736417e-09,"The method '_group_by' is a utility function that groups elements of a list based on a key function. It is a common pattern in data processing and transformation tasks. The function is generic, flexible, and can handle various types of input, making it useful in many contexts. Additionally, it uses a dictionary to maintain groups and a list to preserve the order of keys, which is a practical approach for many applications. Given its utility and the lack of any apparent issues or redundancy, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q45.py,CustomerAddres,0,0.9999945777819207,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q27.py,Item,0,0.999876605372333,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually used to check for membership in a collection like a list, set, or dictionary. Therefore, this implementation might be misleading or incorrect for the intended use of `__contains__`, as it does not check for membership in a collection but rather for the existence of an attribute. This could lead to confusion or errors in code that expects `__contains__` to behave in the standard way. As a result, this method is likely to be deleted or refactored to better align with its intended purpose."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q18.py,CustomerAddres,1,4.1399375473943306e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, it is likely to be retained in the code."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q20.py,,1,8.152020648014727e-09,"The method '_key' is a utility function that is likely used internally within a module or class to generate a key for sorting purposes. It takes an iterable 'it', applies a sorting key function from 'opts', and ensures the key is a string if it's a complex data type. This kind of function is common in data processing or sorting operations, and unless the entire module or class is being refactored or removed, such utility functions are generally retained. Therefore, it is likely to survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q93.py,Auto1,0,0.999985261023967,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q23.py,_Group,1,8.76424914819242e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes. The code snippet shows a typical pattern of initializing instance variables, which is a common and necessary practice in class definitions. Therefore, it is unlikely that this method will be deleted as it serves a crucial role in the class's functionality."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q12.py,Auto3,1,9.237449576640118e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. Since it serves a clear purpose and is implemented correctly, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q27.py,CustomerDemo,0,0.9999687980937693,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q4.py,_Group,1,5.60279640614594e-09,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting initial values for their attributes. The code snippet shows a typical pattern of initializing attributes in a constructor, which is unlikely to be removed unless the entire class is refactored or removed. Therefore, the method is likely to survive."
survived,"def test_TPCDS_Q26_demographic_averages():
    assert result == [
        Auto1(i_item_id=""ITEM1"", agg1=10.0, agg2=100.0, agg3=5.0, agg4=95.0)
    ]
",tests/dataset/tpc-ds/compiler/py/q26.py,,1,3.653482080241728e-08,"The method `test_TPCDS_Q26_demographic_averages` is a unit test function, which is typically used to verify that a specific piece of code is working as expected. Unit tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. The presence of an assertion indicates that this test is checking the output of some function or process against an expected result. Since unit tests are an integral part of software development and quality assurance, it is unlikely that this method will be deleted unless it is replaced by a more comprehensive test or the functionality it tests is removed entirely. Therefore, the method is likely to survive."
survived,"def _q1():
    _groups = {}
    _order = []
    for s in catalog_sales:
        _k = s.item
        _ks = str(_k)
        g = _groups.get(_ks)
        if not g:
            g = _Group(_k)
            _groups[_ks] = g
            _order.append(_ks)
        g.Items.append(s)
    _items1 = [_groups[k] for k in _order]
    return [Auto2(item=g.key, total=sum([x.price for x in g])) for g in _items1]
",tests/dataset/tpc-ds/compiler/py/q56.py,,0,0.9999999895325983,"The method '_q1' is likely to be deleted (0) because it uses a non-descriptive name, which suggests it might be a temporary or internal function. Additionally, the method relies on external variables and classes ('catalog_sales', '_Group', 'Auto2') that are not defined within the code snippet, indicating it might be part of a larger refactoring or cleanup process. Without context, it seems like a utility function that could be replaced or integrated into a more comprehensive solution."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q79.py,Auto3,1,8.76424914819242e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a common and useful pattern for dynamic attribute access, especially in cases where the object is used like a dictionary or needs to provide flexible access to its attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the codebase."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q77.py,_Group,1,4.599055376537186e-10,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is correctly implemented to return the length of the `Items` attribute, assuming `Items` is a list or similar collection. This is a standard and useful implementation for custom classes that manage collections, allowing them to integrate seamlessly with Python's built-in functions. Therefore, it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q48.py,CustomerDemographic,1,5.3157849718487075e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a flexible and Pythonic way to access object attributes, it is likely to be retained in the code."
survived,"def _q2():
    _src = store_returns
    _rows = _query(
        _src,
        [
            {
                ""items"": date_dim,
                ""on"": lambda sr, d: d.d_date_sk == sr.sr_returned_date_sk,
            }
        ],
        {""select"": lambda sr, d: (sr, d)},
    )
    _groups = _group_by(_rows, lambda sr, d: sr.s_store_sk)
    _items3 = _groups
    return [
        Auto3(
            s_store_sk=g.key,
            returns=_sum([x[0].sr_return_amt for x in g]),
            profit_loss=_sum([x[0].sr_net_loss for x in g]),
        )
        for g in _items3
    ]
",tests/dataset/tpc-ds/compiler/py/q77.py,,1,1.1861120010657661e-08,"The method '_q2' is a private function (indicated by the underscore prefix) that seems to be part of a larger codebase dealing with data processing, specifically related to store returns. It performs a query, groups the results, and processes them into a list of 'Auto3' objects. The method appears to be functional and serves a specific purpose within its context. Unless there is a significant change in the codebase or its requirements, such as a shift in data processing strategy or a refactor that makes this method obsolete, it is likely to survive. The method is not overly complex and seems to be well-integrated into its current system."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q18.py,Item,0,0.999964643742472,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, especially for users familiar with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"def _sort_key(k):
    if hasattr(k, ""__dataclass_fields__""):
        return str(k)
    if isinstance(k, list):
        return tuple((_sort_key(x) for x in k))
    if isinstance(k, tuple):
        return tuple((_sort_key(x) for x in k))
    if isinstance(k, dict):
        return str(k)
    return k
",tests/dataset/tpc-ds/compiler/py/q55.py,,1,3.850741907939403e-09,"The method `_sort_key` is a utility function that provides a way to generate a consistent sorting key for various data types, including dataclasses, lists, tuples, and dictionaries. This kind of function is useful in scenarios where complex data structures need to be sorted in a consistent manner. The function is generic and handles multiple data types, making it versatile and reusable. Such utility functions are often retained in codebases because they solve a common problem and can be used in multiple places without modification. Therefore, it is likely to survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q75.py,WebSale,1,5.60279640614594e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. It is likely to be retained if the class is intended to provide such functionality, as it offers a flexible way to access attributes dynamically. Therefore, the method will likely survive."
survived,"def test_TPCDS_Q38_simplified():
    assert result == 1
",tests/dataset/tpc-ds/compiler/py/q38.py,,1,1.6052280526088547e-09,"The method `test_TPCDS_Q38_simplified` is a test function, likely part of a test suite for a larger codebase. Test functions are generally important for ensuring code correctness and are not typically deleted unless they are redundant or replaced by more comprehensive tests. The function contains an assertion, which is a common practice in testing to verify that the code behaves as expected. Without additional context indicating that this test is obsolete or incorrect, it is reasonable to assume it will be retained to maintain code quality."
survived,"def test_TPCDS_Q56_simplified():
    assert result == [Auto1(i_item_id=1, total_sales=60.0)]
",tests/dataset/tpc-ds/compiler/py/q56.py,,1,1.3440409770490404e-08,"The method `test_TPCDS_Q56_simplified` is a test function, likely part of a test suite for a larger application. Test functions are generally not deleted unless they are redundant, incorrect, or replaced by more comprehensive tests. The function is asserting a specific result, which suggests it is actively used to verify the correctness of a particular feature or query (TPCDS Q56). Without additional context indicating that this test is obsolete or incorrect, it is reasonable to assume it will be retained to ensure ongoing validation of the associated functionality."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q18.py,CustomerDemographic,1,1.3440409770490404e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation, especially in cases where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, it is likely to be retained as it provides a flexible way to access object attributes."
survived,"def _append(lst: list[T] | None, v: T) -> list[T]:
    out: list[T] = list(lst) if lst is not None else []
    out.append(v)
    return out
",tests/dataset/tpc-ds/compiler/py/q39.py,,1,2.998960815863541e-09,"The method is likely to survive because it provides a useful utility function that handles a common pattern: appending an element to a list that might be None. It uses type hints effectively, making it clear what types are expected and returned. The function is simple, clear, and addresses a specific need without any apparent issues or redundancies."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q14.py,DateDim,1,4.1399375473943306e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is likely to survive because it provides a flexible way to access object attributes, which can be particularly useful in dynamic or reflective programming scenarios."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q79.py,StoreSale,0,0.999985261023967,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q79.py,Customer,1,2.5109990926928157e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a common and useful pattern for dynamic attribute access, especially in cases where the object is used like a dictionary or needs to provide flexible access to its attributes. Therefore, this method is likely to be retained as it provides a clear and useful functionality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q72.py,Auto2,0,0.939913352771458,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually implemented to check for membership in a collection like a list, set, or dictionary. However, if the class is designed to treat its attributes as a collection of keys, this implementation could be valid. Without additional context on how this method is used within the class, it's difficult to definitively say it should be deleted. However, it is unconventional and might be misleading to other developers who expect `__contains__` to check for membership in a more traditional collection. Therefore, it is likely to be revised or deleted if it doesn't align with the intended use of the class."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q57.py,DateDim,1,1.3440409770490404e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, this method is likely to be retained as it provides a clear and useful functionality."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q24.py,Customer,1,2.5109990926928157e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be retained as it serves a clear purpose and follows Python's design principles."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q30.py,Auto1,1,8.76424914819242e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. This implementation uses `getattr` to dynamically retrieve an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method is functional, straightforward, and leverages Python's dynamic attribute access capabilities, it is likely to be retained in the codebase."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q91.py,_Group,1,3.466327708641819e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes. The code snippet shows a typical pattern of initializing instance variables, which is a common and necessary practice in class definitions. Therefore, it is unlikely that this method will be deleted."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q71.py,Item,1,1.3440409770490404e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, this method is likely to be retained as it provides a clear and useful functionality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q2.py,Auto1,0,0.999964643742472,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose is likely to lead to confusion and incorrect behavior when the method is used. Therefore, it is likely that this method will be deleted or refactored to align with its intended use."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q92.py,DateDim,1,1.522997951276035e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a simple and effective way to allow attribute access using keys, which can be particularly useful in classes that need to interface with code expecting dictionary-like objects. Therefore, this method is likely to be retained as it serves a clear purpose and is implemented correctly."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q46.py,Auto2,1,8.76424914819242e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful pattern for dynamic attribute access. This method is likely to be retained as it provides a flexible way to access object attributes and aligns with Python's dynamic nature."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q90.py,WebPage,0,0.999998790133938,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys. However, this implementation uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of `__contains__` is likely to lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership testing. Therefore, it is likely to be deleted or replaced with a more appropriate implementation."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q63.py,Sale,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. This implementation uses `getattr` to dynamically retrieve an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a clear and functional purpose, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q97.py,CatalogSale,0,0.9999687980937693,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate method for checking membership."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q74.py,StoreSale,0,0.9999957771647318,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of `__contains__` is likely to lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership testing. Therefore, it is likely to be deleted or refactored to align with its intended purpose."
survived,"def _q0():
    _src = store_sales
    _rows = _query(
        _src,
        [
            {
                ""items"": date_dim,
                ""on"": lambda ss, d: (
                    ss.ss_sold_date_sk == d.d_date_sk and d.d_year == 2002
                )
                and d.d_moy == 11,
            }
        ],
        {
            ""select"": lambda ss, d: (ss, d),
            ""where"": lambda ss, d: ss.ss_item_sk
            in [ci.ss_item_sk for ci in cross_items],
        },
    )
    _groups = _group_by(
        _rows, lambda ss, d: Auto3(brand_id=1, class_id=1, category_id=1)
    )
    _items1 = _groups
    return [
        Auto2(
            channel=""store"",
            sales=sum([x[0].ss_quantity * x[0].ss_list_price for x in g]),
            number_sales=len([_ for _ in g]),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q14.py,,1,4.944450477491054e-09,"The method '_q0' appears to be a specific query function that is tailored to extract and process sales data for a particular use case. It is designed to filter sales data for a specific date and item criteria, group the results, and then calculate sales metrics. This kind of function is typically part of a larger data processing or reporting system and is likely to be used in production or analysis environments. Unless there is a significant change in the requirements or the data structure, such methods are usually retained as they serve a specific purpose. Therefore, it is likely to survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q17.py,StoreReturn,1,1.1861120010657661e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern and does not have any apparent issues or redundancies that would necessitate its deletion. Therefore, it is likely to be retained in the code."
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q91.py,,1,2.998960815863541e-09,"The method '_group_by' is likely to survive because it provides a useful utility function for grouping elements of a list based on a key function. This is a common requirement in data processing and analysis tasks. The method is flexible, allowing for different types of input (lists, tuples, or single elements) and handles complex keys by converting them to a string representation. Additionally, it maintains the order of groups as they first appear, which can be important for certain applications. These features make it a valuable tool in many programming scenarios."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q58.py,Auto4,0,0.9999869928752253,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical use case for `__contains__`, which is expected to check membership rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q36.py,Store,1,2.5109990926928157e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in collections like lists or dictionaries. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid use case if the object is designed to allow attribute access via indexing, which can be useful in certain dynamic or flexible data structures. Since this method provides a specific functionality that might be required by the class, it is likely to be retained unless the design requirements change significantly."
survived,"def walrus_example():
    if (x := 10) > 5:
        print(x)",jac/jaclang/tests/fixtures/py_namedexpr.py,,1,3.653482080241728e-08,"The method 'walrus_example' demonstrates the use of the walrus operator (:=), which is a relatively new feature introduced in Python 3.8. This operator allows assignment and evaluation in a single expression, which can make code more concise and readable. The method itself is simple and serves as a basic example of this operator's usage. Given that it is a valid and functional example of a language feature, it is likely to be retained as a useful demonstration for educational purposes or as a reference for using the walrus operator."
survived,"    def __init__(self, message: str = """", response=None, body=None):
        super().__init__(message)
        self.response = response
        self.body = body
",openai/__init__.py,AuthenticationError,1,1.955568070542584e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes or default values. This particular constructor allows for the initialization of a message, response, and body, which are likely important for the functionality of the class it belongs to. Therefore, it is unlikely to be deleted unless the entire class is being refactored or removed."
survived,"def test_bundle_validator_success(tmp_path: Path) -> None:
    bundle_dir = create_sample_bundle(tmp_path)
    validator = BundleValidator(bundle_dir)
    result = validator.validate()
    assert result.success is True
    assert result.errors == []
",tests/test_bundle_validator.py,,1,4.363462233903899e-09,"The method 'test_bundle_validator_success' is a unit test function that checks the success of a bundle validation process. It is likely to be retained because it serves a critical role in ensuring that the 'BundleValidator' class functions correctly. Unit tests are essential for maintaining code quality and reliability, and this test specifically verifies that the validation process completes successfully without errors. Therefore, it is unlikely to be deleted."
survived,"    def process_result(
        self, request: Request, result: ExecutionResult, strict: bool = False
    ) -> GraphQLHTTPResponse:
        if self.result_override:
            return self.result_override(result)
        return super().process_result(request, result, strict)
",src/tests/http/clients/webob.py,GraphQLView,1,8.592166611791576e-10,"The method 'process_result' is likely to survive because it provides a mechanism to override the default result processing behavior, which can be useful for customization or extending functionality. The presence of a conditional check for 'self.result_override' suggests that this method is designed to be flexible and adaptable, which are desirable traits in software development. Additionally, it calls a superclass method, indicating that it is part of a larger framework or system, making it less likely to be removed without a significant redesign."
survived,"    def get_sub_response(self, request: Request) -> Response:
        return Response(status=200, content_type=""application/json"")
",src/graphql_server/webob/views.py,GraphQLView,1,2.8453347280241004e-08,"The method 'get_sub_response' is a simple utility function that returns a standard HTTP response with a status code of 200 and a content type of 'application/json'. This kind of method is often used in web applications to handle requests and provide responses in a consistent format. It is a basic and essential part of handling HTTP requests and responses, especially in RESTful APIs. Given its utility and simplicity, it is unlikely to be deleted unless the entire application architecture changes or if there is a significant refactor that changes how responses are handled."
survived,"    def __init__(
        self,
        enabled: set[str],
        dev_mode: bool,
        kafka_broker: str | None,
        cycle_seconds: int,
        max_cycle_sec: int,
    ) -> None:
        self.manager = AgentManager(
            enabled,
            dev_mode,
            kafka_broker,
            cycle_seconds,
            max_cycle_sec,
        )
",alpha_factory_v1/backend/agent_scheduler.py,AgentScheduler,1,3.2241866333029355e-08,"The method is a constructor (__init__) for a class, which is a fundamental part of object-oriented programming in Python. Constructors are essential for initializing new objects with specific attributes and are unlikely to be removed unless the class itself is being deprecated or refactored significantly. The presence of parameters like 'enabled', 'dev_mode', 'kafka_broker', 'cycle_seconds', and 'max_cycle_sec' suggests that this constructor is setting up an object with specific configurations, which is a common and necessary practice in software development."
survived,"    def close(self) -> None:
        if self.conn:
            self.conn.close()
            self.conn = None  # type: ignore[assignment]
",src/archive/solution_archive.py,SolutionArchive,1,9.237449576640118e-09,"The method 'close' is a standard practice for managing resources, especially in database connections or file handling. It ensures that the connection is properly closed and resources are released, preventing potential memory leaks or locked resources. The method also sets the connection attribute to None after closing, which is a good practice to avoid using a closed connection. This method is likely to be retained as it is essential for resource management."
survived,"    def _ensure(self) -> None:
        self.conn.execute(
            """"""
            CREATE TABLE IF NOT EXISTS solutions(
                sector TEXT,
                approach TEXT,
                score DOUBLE,
                band INTEGER,
                data TEXT,
                ts DOUBLE
            )
            """"""
        )
        self.conn.execute(
            ""CREATE INDEX IF NOT EXISTS idx_bins ON solutions(sector, approach, band)""
        )
        if isinstance(self.conn, sqlite3.Connection):
            self.conn.commit()
",src/archive/solution_archive.py,SolutionArchive,1,1.3440409770490404e-08,"The method '_ensure' is responsible for setting up a database table and an index if they do not already exist. This is a common and necessary operation in applications that interact with databases, ensuring that the required schema is in place before any data operations are performed. The method is well-structured, uses standard SQL commands, and includes a check to commit changes only if the connection is of the correct type. These factors suggest that the method is functional, necessary, and unlikely to be removed unless there is a significant change in the application's database handling strategy."
survived,"def vote_and_merge(repo: str | Path, diff: str, registry: StakeRegistry, agent_id: str = ""orch"") -> bool:
    """"""Apply patch and merge if tests pass and fitness improves.""""""
    repo_path = Path(repo).resolve()
    proposal = hashlib.sha1(diff.encode()).hexdigest()
    baseline = float((repo_path / ""metric.txt"").read_text().strip())
    ok, patched = apply_patch(repo_path, diff)
    if not ok:
        registry.vote(proposal, agent_id, False)
        shutil.rmtree(patched)
        return False
    new_score = float((patched / ""metric.txt"").read_text().strip())
    improved = new_score > baseline
    registry.vote(proposal, agent_id, improved)
    accepted = improved and registry.accepted(proposal)
    if accepted:
        for src_file in patched.rglob(""*""):
            if src_file.is_file():
                rel = src_file.relative_to(patched)
                dest = repo_path / rel
                dest.parent.mkdir(parents=True, exist_ok=True)
                shutil.copy2(src_file, dest)
        registry.archive_accept(agent_id)
    shutil.rmtree(patched)
    return accepted",src/self_evolution/harness.py,,1,3.3982678079468468e-09,"The method 'vote_and_merge' is a well-defined function that performs a specific task: applying a patch to a repository, evaluating its impact, and merging it if it meets certain criteria. It includes error handling, voting logic, and file operations, which are all essential for its purpose. The method is likely to be useful in scenarios where automated code review and merging are required, such as in continuous integration systems. Given its clear utility and the fact that it encapsulates a complete workflow, it is unlikely to be deleted."
survived,"    def refine(self) -> bool:
        logs = self._load_logs()
        bottleneck = self._detect_bottleneck(logs)
        if not bottleneck:
            return False
        diff = self._create_patch(bottleneck)
        accepted = harness.vote_and_merge(self.repo, diff, self.registry, agent_id=""meta"")
        if accepted:
            test_scribe.generate_test(self.repo, ""True"")
        return accepted",src/agents/meta_refinement_agent.py,MetaRefinementAgent,1,5.60279640614594e-09,"The method 'refine' appears to be a well-structured function that performs a series of logical steps to refine a process. It loads logs, detects bottlenecks, creates a patch, and attempts to merge it if a bottleneck is found. The method also generates a test if the patch is accepted. This indicates that the method is part of a larger system for improving or optimizing processes, likely in a software development or deployment context. The method's functionality is clear, purposeful, and likely valuable in its context, suggesting it is not redundant or obsolete. Therefore, it is likely to be retained in the codebase."
survived,"    def __call__(self, prompt: str) -> str:
        return ""ok""
",tests/resources/openai_agents.py,OpenAIAgent,1,4.4508487281649027e-07,"The method is a simple implementation of the __call__ method, which allows an instance of the class to be called as a function. It takes a string input and returns a fixed string ""ok"". While the method itself is functional, it lacks complexity and utility in its current form. However, it is not incorrect or harmful, and could serve as a placeholder or a simple example of using __call__. Therefore, it is likely to survive unless there is a specific reason to remove it, such as redundancy or a change in requirements."
survived,"    def __init__(self, *a: object, port: int = 5001, **_k: object) -> None:
        self.port = port
",tests/resources/openai_agents.py,AgentRuntime,1,6.348800075736417e-09,"The method is a constructor (__init__) for a class, which is a fundamental part of class definition in Python. Constructors are essential for initializing new objects and setting initial values for instance variables. The presence of parameters like *a and **_k suggests that the constructor is designed to be flexible, allowing for additional arguments and keyword arguments, which can be useful for various class instantiations. The method is not redundant or obsolete, and there is no indication that it should be removed. Therefore, it is likely to survive."
survived,"    def encode(self, texts, normalize_embeddings=True):
        import numpy as np

        return np.zeros((len(texts), 384), dtype=""float32"")",tests/resources/sentence_transformers.py,SentenceTransformer,0,0.9999957771647318,"The method 'encode' is a placeholder function that returns a zero matrix of shape (len(texts), 384) regardless of the input. It does not perform any actual encoding or transformation of the input 'texts'. This makes the method non-functional for its intended purpose of encoding text data. Without further implementation to process and encode the texts meaningfully, the method is not useful and is likely to be deleted or replaced with a functional version."
survived,"def makeAdder(n):
    def adder(x):
        return x + n
    return adder
",tests/human/x/python/closure.py,,1,1.725782769012759e-08,"The method 'makeAdder' is a higher-order function that returns a closure. It is a useful and common pattern in functional programming, allowing the creation of customized functions on the fly. This method is likely to be retained because it provides a flexible way to generate functions that add a specific number to their input, which can be very useful in various programming scenarios. The concept of closures is fundamental in many programming languages, and this implementation is a clear and concise example of that concept."
survived,"def test_critic_prompt_mutates() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri()
    with sync_playwright() as p:
        browser = p.chromium.launch()
        page = browser.new_page()
        page.goto(url)
        page.wait_for_selector(""#controls"")
        page.evaluate(""window.recordedPrompts = []"")
        page.evaluate(
            ""scoreGenome('foo', [new LogicCritic([], 'a'), new FeasibilityCritic([], 'b')], new JudgmentDB('jest'), 0.9)""
        )
        page.wait_for_function(""window.recordedPrompts.length > 0"")
        assert page.evaluate(""window.recordedPrompts.length"") > 0
        browser.close()",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_mutated_critic.py,,1,2.2159489282323004e-08,"The method `test_critic_prompt_mutates` is a test function that uses Playwright to automate a browser and test a specific functionality of a web application. It checks if the `recordedPrompts` array is populated after executing a function on the page. This kind of test is useful for ensuring that the web application behaves as expected, particularly in terms of UI interactions and JavaScript execution. Given the increasing importance of automated testing in software development, especially for web applications, this method is likely to be maintained or even expanded upon rather than deleted. Automated tests help in catching regressions and ensuring code quality, which are critical aspects of modern software development."
survived,"            def patched_curl_init(session_self, *args, **kwargs):
                if self._proxies and 'proxies' not in kwargs:
                    kwargs['proxies'] = self._proxies
                self._original_curl_session_init(session_self, *args, **kwargs)
",webscout/Provider/TTI/base.py,_GlobalProxyManager,0,0.9999999943972036,"The method 'patched_curl_init' is likely to be deleted because it references 'self._proxies' and 'self._original_curl_session_init', which are not defined within the method or passed as parameters. This suggests that the method is incomplete or incorrectly implemented. Additionally, the method seems to be a patch or a monkey-patch, which is often a temporary solution and might be removed once a more permanent fix is implemented."
survived,"        def patched_session_request(session_self, method, url, *a, **kw):
            if self._proxies and 'proxies' not in kw:
                kw['proxies'] = self._proxies
            return self._original_session_request(session_self, method, url, *a, **kw)
",webscout/Provider/TTI/base.py,_GlobalProxyManager,0,0.9999999995400946,"The method 'patched_session_request' is likely to be deleted (0) because it uses 'self', which is not defined within the method's scope. This suggests that the method might be incorrectly implemented or part of a larger class where 'self' should be passed as an argument. Without proper context or correction, this method will not function as intended, leading to potential removal or refactoring."
survived,"def _eval_node(node: ast.AST) -> float:
    if isinstance(node, ast.BinOp):
        left = _eval_node(node.left)
        right = _eval_node(node.right)
        if isinstance(node.op, ast.Add):
            return left + right
        if isinstance(node.op, ast.Sub):
            return left - right
        if isinstance(node.op, ast.Mult):
            return left * right
        if isinstance(node.op, ast.Div):
            return left / right
        if isinstance(node.op, ast.Pow):
            return left**right
        raise ValueError(""Unsupported operator"")
    if isinstance(node, ast.UnaryOp) and isinstance(node.op, ast.USub):
        return -_eval_node(node.operand)
    if isinstance(node, ast.Constant) and isinstance(node.value, (int, float)):
        return float(node.value)
    raise ValueError(""Unsupported expression"")
",tests/test_safe_eval_security.py,,1,1.1861120010657661e-08,"The method `_eval_node` is a utility function designed to evaluate an abstract syntax tree (AST) node representing a mathematical expression. It supports basic arithmetic operations and handles both binary and unary operations. This functionality is fundamental for evaluating expressions in a programmatic way, especially when dealing with dynamically generated or parsed code. The method is well-structured, covers a range of common operations, and raises appropriate errors for unsupported cases, making it robust and useful in contexts where AST evaluation is needed. Therefore, it is likely to be retained in the codebase."
survived,"def test_run_tests_success(monkeypatch, tmp_path):
    fake_manager = MagicMock()
    fake_manager.run_code_in_sandbox.return_value = (0, ""out"", ""err"")
    module = ExecutionModule(fake_manager)
    result = module.run_tests(tmp_path, timeout=5)
    assert isinstance(result, ExecutionResult)
    assert result.exit_code == 0
    assert result.stdout == ""out""
    assert result.stderr == ""err""
    fake_manager.run_code_in_sandbox.assert_called_with(
        code_directory=tmp_path,
        command=[""pytest"", ""-vv""],
        timeout=5,
    )
",tests/unit/test_execution_module.py,,1,8.152020648014727e-09,"The method 'test_run_tests_success' is a unit test function that verifies the behavior of the 'run_tests' method in the 'ExecutionModule' class. It uses mocking to simulate the behavior of dependencies and checks that the method returns the expected results. This is a typical and necessary practice in software development to ensure code reliability and correctness. Therefore, it is unlikely to be deleted as it serves an important role in maintaining code quality."
survived,"def dummy_lifecycle(*args, **kwargs):
    yield SimpleNamespace(job_key=""backup_database"")
",pioreactor/tests/test_backup_database.py,,1,2.998960815863541e-09,"The method 'dummy_lifecycle' is a generator function that yields a SimpleNamespace object with a job_key attribute. This suggests that it is part of a larger system or framework that uses this function to manage or track jobs, possibly in a job scheduling or task management context. The use of SimpleNamespace indicates that the function is designed to be flexible and easily extendable, which is a common practice in modern software development. Given these considerations, the method is likely to be useful and relevant in its context, suggesting it will survive."
survived,"def _local_available_space(path: str) -> int:
    """"""Return available bytes on the local filesystem.""""""
    statvfs = os.statvfs(path)
    return statvfs.f_frsize * statvfs.f_bavail
",pioreactor/actions/leader/backup_database.py,,1,8.152020648014727e-09,"The method '_local_available_space' is a utility function that calculates the available space on the local filesystem for a given path. This is a common requirement in many applications that need to manage disk usage or ensure there is enough space before performing operations that require disk storage. The function uses 'os.statvfs', which is a standard library function in Python, making it reliable and efficient for this purpose. Since it provides a useful and specific functionality, it is likely to be retained in the codebase."
survived,"def test_utc_now_timezone():
    assert utc_now().endswith(""+00:00"")",tests/test_agent_runner_utils.py,,1,8.152020648014727e-09,"The method `test_utc_now_timezone` is a test function that checks if the `utc_now()` function returns a string ending with ""+00:00"", which is the expected timezone offset for UTC. This is a valid and useful test to ensure that the `utc_now()` function is correctly returning the current time in UTC format. Test functions are generally not deleted unless they are redundant or replaced by more comprehensive tests. Since this test serves a clear purpose and there is no indication of redundancy or replacement, it is likely to be retained."
survived,"    async def _run_single_turn(
        cls,
        *,
        agent: Agent[TContext],
        all_tools: list[Tool],
        original_input: str | list[TResponseInputItem],
        generated_items: list[RunItem],
        hooks: RunHooks[TContext],
        context_wrapper: RunContextWrapper[TContext],
        run_config: RunConfig,
        should_run_agent_start_hooks: bool,
        tool_use_tracker: AgentToolUseTracker,
        previous_response_id: str | None,
    ) -> SingleStepResult:
        # Ensure we run the hooks before anything else
        if should_run_agent_start_hooks:
            await asyncio.gather(
                hooks.on_agent_start(context_wrapper, agent),
                (
                    agent.hooks.on_start(context_wrapper, agent)
                    if agent.hooks
                    else _coro.noop_coroutine()
                ),
            )

        system_prompt = await agent.get_system_prompt(context_wrapper)

        output_schema = cls._get_output_schema(agent)
        handoffs = cls._get_handoffs(agent)
        input = ItemHelpers.input_to_new_input_list(original_input)
        input.extend([generated_item.to_input_item() for generated_item in generated_items])

        new_response = await cls._get_new_response(
            agent,
            system_prompt,
            input,
            output_schema,
            all_tools,
            handoffs,
            context_wrapper,
            run_config,
            tool_use_tracker,
            previous_response_id,
        )

        return await cls._get_single_step_result_from_response(
            agent=agent,
            original_input=original_input,
            pre_step_items=generated_items,
            new_response=new_response,
            output_schema=output_schema,
            all_tools=all_tools,
            handoffs=handoffs,
            hooks=hooks,
            context_wrapper=context_wrapper,
            run_config=run_config,
            tool_use_tracker=tool_use_tracker,
        )
",src/agents/run.py,DefaultAgentRunner,1,3.3982678079468468e-09,"The method `_run_single_turn` is an asynchronous function that appears to be part of a larger system for handling agent interactions, possibly in a conversational AI or automated task execution context. It involves several complex operations such as running hooks, gathering inputs, and generating responses. The method is well-structured, making use of asynchronous operations to improve efficiency, which is crucial in real-time systems.

Given the complexity and the specific role this method plays in the system, it is unlikely to be deleted unless there is a significant overhaul of the system architecture. Such methods are typically core to the functionality they support, and unless the entire approach to handling agent interactions is changed, this method will likely survive.

Additionally, the method is designed to be flexible and extensible, as indicated by the use of hooks and context wrappers, which suggests it is intended to be a stable part of the system that can adapt to future changes or enhancements."
survived,"def main(argv: list[str] | None = None) -> None:
    parser = argparse.ArgumentParser(description=""Run alpha_agi_business_v1 locally"")
    parser.add_argument(
        ""--bridge"",
        action=""store_true"",
        help=""Launch OpenAI Agents bridge if available"",
    )
    args = parser.parse_args(argv)

    check_env.main([])

    if args.bridge:
        _start_bridge()

    alpha_agi_business_v1.main([])
",alpha_factory_v1/demos/alpha_agi_business_v1/run_business_v1_local.py,,1,1.0467401685178159e-08,"The method 'main' is a typical entry point for a Python script, especially when using the argparse library to handle command-line arguments. It is structured to parse arguments, check the environment, and conditionally start a bridge or run a main function. This is a common pattern in Python scripts intended to be run from the command line. There is no indication that this method is deprecated or redundant, and it serves a clear purpose in the script's functionality. Therefore, it is likely to be retained."
survived,"    def test_top_n(self):
        data = [
            {""alpha"": ""low"", ""score"": 1},
            {""alpha"": ""mid"", ""score"": 3},
            {""alpha"": ""high"", ""score"": 5},
        ]
        tmp = Path(""/tmp/opps3.json"")
        tmp.write_text(json.dumps(data), encoding=""utf-8"")
        self.temp_files.append(tmp)
        os.environ[""ALPHA_OPPS_FILE""] = str(tmp)
        os.environ[""ALPHA_TOP_N""] = ""2""
        self.env_vars[""ALPHA_OPPS_FILE""] = str(tmp)
        self.env_vars[""ALPHA_TOP_N""] = ""2""
        agent = biz.AlphaOpportunityAgent()
        self.assertEqual(agent._top_n, 2)
        self.assertEqual(agent._opportunities[0][""alpha""], ""high"")
        self.assertEqual(agent._opportunities[1][""alpha""], ""mid"")
",tests/test_alpha_opportunity_env.py,TestAlphaOpportunityEnv,1,1.1032560311263802e-09,"The method 'test_top_n' is a unit test designed to verify the functionality of the 'AlphaOpportunityAgent' class, specifically its ability to correctly identify the top N opportunities based on a score. This is a common and essential practice in software development to ensure code reliability and correctness. The method sets up a controlled environment, manipulates environment variables, and checks the expected behavior of the agent. Such tests are crucial for maintaining code quality and are unlikely to be deleted unless the functionality they test is removed or significantly altered. Therefore, the method is likely to survive."
survived,"    def _rewrite(match: re.Match[str]) -> str:
        url, anchor = match.group(1), match.group(2) or """"
        if url.startswith((""http://"", ""https://"", ""#"", ""mailto:"")):
            return match.group(0)
        target = (demo / url).resolve()
        try:
            rel = target.relative_to(REPO_ROOT)
        except ValueError:
            return match.group(0)
        return f""({github_base}{rel.as_posix()}{anchor})""
",scripts/generate_demo_docs.py,,1,3.653482080241728e-08,"The method '_rewrite' is a utility function that processes regex matches to rewrite URLs based on certain conditions. It checks if the URL starts with specific protocols and returns the original match if it does. Otherwise, it attempts to resolve the URL relative to a repository root and constructs a new URL with a GitHub base. This functionality is specific and useful for transforming URLs in a controlled manner, likely within a larger system that processes text or documentation. Given its specific utility and the lack of any indication that it is deprecated or redundant, it is likely to be retained in the codebase."
survived,"    async def handle(self, _env: orchestrator.messaging.Envelope) -> None:  # pragma: no cover - test helper
        pass
",tests/test_orchestrator.py,FailingAgent,0,0.7772998714925404,"The method 'handle' is marked with a pragma directive 'no cover', indicating that it is a test helper and not intended to be covered by unit tests. This suggests that the method is likely used for testing purposes or as a placeholder. However, the method is defined as 'async' and takes an argument, which implies it might be part of an asynchronous messaging or event handling system. If the system is still under development or if this method is part of a larger framework where it is expected to be implemented later, it might survive. However, if the method remains unimplemented and unused, it could be deleted in future refactoring efforts to clean up the codebase."
survived,"def test_start_aiga_demo_missing_docker(monkeypatch: pytest.MonkeyPatch) -> None:
    """"""A missing Docker binary should raise a clear error.""""""
    from alpha_factory_v1.demos.aiga_meta_evolution import start_aiga_demo as mod

    def boom(*_a, **_kw):
        raise FileNotFoundError(""docker"")

    monkeypatch.setattr(mod.subprocess, ""run"", boom)

    with pytest.raises(FileNotFoundError):
        mod.main()",tests/test_start_aiga_demo.py,,1,5.905303995456778e-10,"The method is a unit test designed to verify that a specific error is raised when a required dependency (Docker) is missing. This is a common and necessary practice in software development to ensure robustness and proper error handling. The test uses monkeypatching to simulate the absence of Docker, which is a valid and useful testing technique. Therefore, the method is likely to be retained as it serves an important purpose in the testing suite."
survived,"    def _random_ip(self) -> str:
        return self.rotate_ip()
",webscout/litagent/agent.py,LitAgent,0,0.9999994284997149,"The method `_random_ip` is a simple wrapper around the `rotate_ip` method, which suggests that it might be redundant unless it serves a specific purpose such as abstraction or future extension. Without additional context or usage, it seems unnecessary to have a separate method just to call another method. Therefore, it is likely to be deleted unless there is a specific design reason to keep it."
survived,"def _sha384(path: Path) -> str:
    return base64.b64encode(hashlib.sha384(path.read_bytes()).digest()).decode()
",scripts/check_insight_sri.py,,1,1.2501528648238603e-09,"The method `_sha384` is a utility function that computes the SHA-384 hash of a file's contents and returns it as a base64-encoded string. This is a common and useful operation in many applications, such as verifying file integrity or creating unique identifiers for files. The method is concise, uses standard libraries, and performs a clear, well-defined task. There is no indication that this method is redundant or obsolete, so it is likely to be retained."
survived,"def test_market_agent_logs_exception():
    cfg = config.Settings(bus_port=0, openai_api_key=""k"")
    bus = DummyBus(cfg)
    led = DummyLedger()
    agent = market_agent.MarketAgent(bus, led)
    agent.oai_ctx = DummyCtx()
    env = messaging.Envelope(""strategy"", ""market"", {""strategy"": ""foo""}, 0.0)
    with mock.patch.object(market_agent.log, ""warning"") as warn:
        asyncio.run(agent.handle(env))
        warn.assert_called_once()
",tests/test_agent_logging.py,,1,2.2159489282323004e-08,"The method `test_market_agent_logs_exception` is a unit test designed to verify that the `MarketAgent` logs a warning when handling a specific type of message envelope. Unit tests are crucial for ensuring code reliability and are typically retained in the codebase to maintain test coverage and facilitate future development. The presence of mocking and assertions indicates that this test is actively verifying behavior, which is a common practice in software development to prevent regressions. Therefore, it is unlikely that this method will be deleted."
survived,"    async def run(self, *a, **k):
        raise RuntimeError(""boom"")
",tests/test_agent_logging.py,DummyCtx,0,0.9999997897565932,"The method is designed to immediately raise a RuntimeError with the message ""boom"" whenever it is called. This behavior is not useful for any practical application unless it is specifically intended for testing error handling mechanisms. Since the method does not perform any meaningful operation and only raises an error, it is likely to be deleted unless it serves a specific purpose in a testing context."
survived,"def test_show_results_export_json(tmp_path) -> None:
    ledger = tmp_path / ""audit.db""
    ledger.touch()
    with patch.object(cli.config.CFG, ""ledger_path"", ledger):
        with patch.object(cli.logging, ""Ledger"") as led_cls:
            led = led_cls.return_value
            led.tail.return_value = [{""ts"": 1.0, ""sender"": ""a"", ""recipient"": ""b"", ""payload"": {""x"": 1}}]
            res = CliRunner().invoke(cli.main, [""show-results"", ""--export"", ""json""])
            assert res.output.startswith(""["")
",tests/test_cli.py,,1,2.2159489282323004e-08,"The method 'test_show_results_export_json' is a unit test designed to verify the functionality of exporting results in JSON format. It uses mocking to simulate the environment and dependencies, ensuring that the test is isolated and does not rely on external factors. The test checks if the output starts with a '[', which is a characteristic of JSON arrays, indicating that the export functionality is working as expected. Since this is a well-structured test that verifies a specific feature, it is likely to be retained to ensure the reliability of the codebase."
survived,"    def verify_merkle_root(self, expected: str, agent_id: str) -> None:
        """"""Slash ``agent_id`` when the ledger's Merkle root mismatches ``expected``.""""""
        actual = self.ledger.compute_merkle_root()
        if actual != expected:
            log.warning(""Merkle mismatch for %s"", agent_id)
            self.slash(agent_id)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/orchestrator.py,Orchestrator,1,6.348800075736417e-09,"The method 'verify_merkle_root' is a utility function that checks if the computed Merkle root of a ledger matches an expected value. If there is a mismatch, it logs a warning and calls a 'slash' method on the agent. This functionality is crucial for maintaining the integrity and security of a system that relies on Merkle trees, such as blockchain or distributed ledger technologies. The method is straightforward, performs a critical check, and has a clear purpose, making it unlikely to be removed unless the system's architecture changes significantly."
survived,"def test_accepts_normal_patch() -> None:
    diff = """"""--- a/src/foo.py
+++ b/src/foo.py
@@
-a
+b
""""""
    assert is_patch_valid(diff)",tests/test_patch_guard.py,,1,1.6052280526088547e-09,"The method `test_accepts_normal_patch` is a unit test that checks if a given patch is valid using the `is_patch_valid` function. This is a typical use case in software development to ensure that patches or changes to code are correctly formatted and applied. Unit tests are crucial for maintaining code quality and preventing regressions, so this method is likely to be retained as part of the test suite."
survived,"def test_select_parent_softmax() -> None:
    pop = [
        Candidate(1.0, 1.0),
        Candidate(0.5, 2.0),
        Candidate(2.0, 0.5),
    ]
    temp = 1.0
    expected = softmax(np.asarray([p.fitness * p.novelty for p in pop]) / temp)
    observed = sample_distribution(pop, temp)
    assert np.allclose(observed, expected, atol=0.02)
",tests/test_selector.py,,1,5.211412485172657e-10,"The method `test_select_parent_softmax` is a unit test function that verifies the behavior of a function `sample_distribution` against an expected result calculated using the softmax function. This is a typical pattern in test-driven development, where tests are written to ensure that code behaves as expected. The presence of this test suggests that the functionality it tests is important and likely to be maintained. Therefore, the method is likely to survive as it serves a critical role in ensuring the correctness of the code."
survived,"def sample_distribution(pop, temp, runs=20000):
    np.random.seed(42)
    counts = {id(ind): 0 for ind in pop}
    for _ in range(runs):
        ind = select_parent(pop, temp)
        counts[id(ind)] += 1
    return np.asarray([counts[id(ind)] / runs for ind in pop])
",tests/test_selector.py,,1,2.646573631904765e-09,"The method 'sample_distribution' is a utility function that simulates the selection of parents from a population based on a given temperature parameter. It is a common operation in genetic algorithms and evolutionary computation to understand the distribution of selections over multiple runs. The method is well-defined, uses a fixed random seed for reproducibility, and provides a clear output in the form of a numpy array. These characteristics make it a useful and reusable function in contexts where such simulations are needed. Therefore, it is likely to be retained in the codebase."
survived,"def test_metrics_curl() -> None:
    port = _free_port()
    proc = _start_server(port)
    url = f""http://127.0.0.1:{port}""
    try:
        _wait_ready(url)
        out = subprocess.check_output([""curl"", ""-sf"", f""{url}/metrics""])
        text = out.decode()
        assert ""api_requests_total"" in text
        assert ""api_request_seconds"" in text
    finally:
        proc.terminate()
        proc.wait(timeout=5)
",tests/test_metrics.py,,1,7.194132978569833e-09,"The method 'test_metrics_curl' is a test function that checks the availability and correctness of metrics exposed by a server. It uses a subprocess to make a curl request to the server's metrics endpoint and verifies the presence of specific metrics in the response. This is a common practice in testing to ensure that the server is correctly exposing metrics for monitoring purposes. The function is well-structured, uses a try-finally block to ensure resources are cleaned up, and checks for specific expected outputs, which are all good practices in test functions. Therefore, it is likely to be retained as part of the test suite."
survived,"    def _log(self, level: LogLevel, message: str):
        if not self._should_log(level):
            return
        record = self._format(level, message)
        for h in self.handlers:
            if level >= h.level:
                h.emit(record, level)
",webscout/litlogger/logger.py,Logger,1,7.05287985061473e-11,"The method '_log' is a private utility function that is likely part of a logging system. It checks if a message should be logged based on its level, formats the message, and then sends it to the appropriate handlers. This is a common pattern in logging frameworks to ensure that only relevant messages are processed and outputted. The method is well-structured and serves a clear purpose in the context of logging, making it unlikely to be deleted unless the entire logging system is refactored or removed. Therefore, it is predicted to survive."
survived,"    def warning(self, message: str):
        self.log(LogLevel.WARNING, message)
",webscout/litlogger/logger.py,Logger,1,2.1724399346070676e-10,"The method 'warning' is a simple utility function that wraps around another method 'log', providing a specific log level (WARNING) for the message. This kind of method is common in logging frameworks to simplify the logging process for different levels of severity. It enhances code readability and usability by allowing developers to log warnings without specifying the log level each time. Therefore, it is likely to be retained as it serves a useful purpose in the codebase."
survived,"        def decorator(func):
            return func
",alpha_factory_v1/demos/aiga_meta_evolution/openai_agents_bridge.py,,1,4.1399375473943306e-08,"The method is a simple decorator that returns the function it receives without any modification. While it doesn't add any functionality, it is a valid decorator pattern and might be used as a placeholder or for future extension. Such a method is often kept in codebases for potential future use or to maintain a consistent interface. Therefore, it is likely to survive."
survived,"    def test_import_with_agents_only(self, monkeypatch):
        stub = types.ModuleType(""agents"")
        stub.Agent = object
        stub.AgentRuntime = object
        stub.OpenAIAgent = object

        def _tool(*_a, **_k):
            def _decorator(func):
                return func

            return _decorator

        stub.Tool = _tool

        monkeypatch.setitem(sys.modules, ""agents"", stub)
        sys.modules.pop(""openai_agents"", None)

        orig_import = builtins.__import__

        def fake_import(name, globals=None, locals=None, fromlist=(), level=0):
            if name == ""openai_agents"":
                raise ModuleNotFoundError(name)
            return orig_import(name, globals, locals, fromlist, level)

        monkeypatch.setattr(builtins, ""__import__"", fake_import)

        for mod_name in MODULES:
            mod = importlib.reload(importlib.import_module(mod_name))
            self.assertIs(mod.OpenAIAgent, stub.OpenAIAgent)
",tests/test_aiga_agents_import.py,TestAigaAgentsImport,1,1.4166087846364157e-09,"The method 'test_import_with_agents_only' is a unit test designed to test the import behavior of a module when certain conditions are met. It uses monkeypatching to simulate the presence of a module named 'agents' and to control the import behavior of 'openai_agents'. This kind of test is useful for ensuring that the code behaves correctly when certain modules are missing or replaced. Since it is a test method, it is likely to be retained as part of the test suite to ensure code reliability and correctness. Therefore, it is predicted to survive."
survived,"    async def summary_failure_reason_for_max_retries(
        self,
        organization: Organization,
        task: Task,
        step: Step,
        page: Page | None,
        max_retries: int,
    ) -> str:
        html = """"
        screenshots: list[bytes] = []
        steps_results = []
        try:
            steps = await app.DATABASE.get_task_steps(
                task_id=task.task_id, organization_id=organization.organization_id
            )
            for step_cnt, cur_step in enumerate(steps[-max_retries:]):
                if cur_step.output and cur_step.output.actions_and_results:
                    action_result_summary: list[str] = []
                    step_result: dict[str, Any] = {
                        ""order"": step_cnt,
                    }
                    for action, action_results in cur_step.output.actions_and_results:
                        if len(action_results) == 0:
                            continue
                        last_result = action_results[-1]
                        if last_result.success:
                            continue
                        reason = last_result.exception_message or """"
                        action_result_summary.append(
                            f""{action.reasoning}(action_type={action.action_type}, result=failed, reason={reason})""
                        )
                    step_result[""actions_result""] = action_result_summary
                    steps_results.append(step_result)

            if page is not None:
                skyvern_frame = await SkyvernFrame.create_instance(frame=page)
                html = await skyvern_frame.get_content()
                screenshots = await SkyvernFrame.take_split_screenshots(page=page, url=page.url)

            prompt = prompt_engine.load_prompt(
                ""summarize-max-retries-reason"",
                navigation_goal=task.navigation_goal,
                navigation_payload=task.navigation_payload,
                steps=steps_results,
                page_html=html,
                max_retries=max_retries,
                local_datetime=datetime.now(skyvern_context.ensure_context().tz_info).isoformat(),
            )
            json_response = await app.LLM_API_HANDLER(
                prompt=prompt,
                screenshots=screenshots,
                step=step,
                prompt_name=""summarize-max-retries-reason"",
            )
            return json_response.get(""reasoning"", """")
        except Exception:
            LOG.warning(
                ""Failed to summarize the failure reason for max retries"",
                task_id=task.task_id,
                step_id=step.step_id,
            )
            if steps_results:
                last_step_result = steps_results[-1]
                return f""Retry Step {last_step_result['order']}: {last_step_result['actions_result']}""
            return """"
",skyvern/forge/agent.py,ForgeAgent,1,4.6911638017642294e-08,"The method 'summary_failure_reason_for_max_retries' is a comprehensive function that handles the summarization of failure reasons for tasks that have reached their maximum retry limit. It integrates with a database to fetch task steps, processes the results, and interacts with an external API to generate a summary. The method also includes error handling to provide fallback information if the main process fails. Given its complexity, integration with external systems, and error handling, it is likely to be a critical part of the system's functionality. Therefore, it is more likely to be maintained and improved rather than deleted."
survived,"    def __init__(self, html, parser):
        p = _Parser()
        p.feed(html)
        super().__init__(p.root.name, p.root.attrs)
        self.children = p.root.children
        for c in self.children:
            c.parent = self
",tests/conftest.py,BeautifulSoup,1,2.9023122007764653e-06,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting up initial states. The code provided shows a typical use of a constructor to parse HTML and set up a tree structure, which is a common task in web scraping or HTML parsing libraries. Therefore, it is unlikely that this method will be deleted as it serves a crucial role in the class's functionality."
survived,"    def handle_endtag(self, tag):
        if self.current.parent:
            self.current = self.current.parent
",tests/conftest.py,_Parser,1,1.2501528648238603e-09,"The method 'handle_endtag' is a part of HTML parsing, typically used in HTML parsers to handle the closing of HTML tags. This method is essential for maintaining the correct structure of the parsed HTML document by updating the current node to its parent when an end tag is encountered. Such functionality is fundamental in parsers and is unlikely to be removed unless the entire parsing approach is changed. Therefore, it is likely to survive."
survived,"def test_build_and_get_result_similar():
    scraper = AutoScraper()
    result = scraper.build(html=HTML, wanted_list=[""Banana""])
    assert result == [""Banana""]
    similar = scraper.get_result_similar(html=HTML, contain_sibling_leaves=True)
    assert similar == [""Banana"", ""Apple"", ""Orange""]",tests/unit/test_build.py,,1,3.850741907939403e-09,"The method 'test_build_and_get_result_similar' is a test function that verifies the functionality of the 'AutoScraper' class. It checks if the 'build' method correctly identifies the desired element ('Banana') and if the 'get_result_similar' method can find similar elements ('Banana', 'Apple', 'Orange'). This test is crucial for ensuring the scraper's accuracy and reliability in extracting data. Since testing is an essential part of software development to maintain code quality, this method is likely to be retained."
survived,"def test_similar_unique_false():
    scraper = AutoScraper()
    scraper.build(html=HTML_DUP, wanted_list=[""Banana""])
    result = scraper.get_result_similar(html=HTML_DUP, unique=False)
    assert result == [""Banana"", ""Banana""]
",tests/unit/test_additional_features.py,,1,1.1861120010657661e-08,"The method 'test_similar_unique_false' is a test function that checks the behavior of the 'AutoScraper' library when the 'unique' parameter is set to False. This is a valid test case to ensure that the scraper can return duplicate results when expected. Test functions are generally important for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is likely to be retained in the codebase."
survived,"def test_get_result_combined():
    scraper = AutoScraper()
    scraper.build(html=HTML, wanted_list=[""Banana""])
    similar, exact = scraper.get_result(html=HTML)
    assert exact == [""Banana""]
    assert similar == [""Banana""]",tests/unit/test_features.py,,1,5.3157849718487075e-08,"The method 'test_get_result_combined' is a unit test for the AutoScraper library, which is a tool used for web scraping. The test checks if the 'get_result' method correctly identifies and returns the desired data from the HTML. This is a fundamental test to ensure the scraper's functionality, and such tests are crucial for maintaining the reliability of the library. Therefore, it is unlikely to be deleted as it serves an important role in verifying the correctness of the code."
survived,"    def start_merkle_task(self, interval: int = 3600) -> None:
        if self._task is None:
            self._task = asyncio.create_task(self._loop(interval))
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/logging.py,Ledger,1,2.646573631904765e-09,"The method 'start_merkle_task' is a straightforward and useful method for initiating a recurring asynchronous task using asyncio. It checks if a task is already running and only creates a new one if none exists, which is a good practice to prevent multiple tasks from being created unnecessarily. This method is likely to be useful in scenarios where periodic tasks are needed, such as in server maintenance or data synchronization tasks. Therefore, it is likely to be retained in the codebase."
survived,"    def insert(self, index: int, new_child: Union['Tag', NavigableString, str]) -> None:
        """"""Insert a new child at the given index.""""""
        if isinstance(new_child, str):
            new_child = NavigableString(new_child)
        new_child.parent = self
        self.contents.insert(index, new_child)
",webscout/scout/element.py,Tag,1,9.736200303530205e-10,"The method 'insert' is a fundamental operation for modifying a data structure by adding elements at a specific position. It is a common method in many programming contexts, especially in data manipulation libraries. The method is well-defined, checks the type of the new child, and ensures the new child is properly linked to its parent. These characteristics make it a useful and necessary part of the class it belongs to, suggesting it will likely be retained."
survived,"def test_labels_allow_unsafe_true():
    runner = ScenarioRunner(uri=GMT_DIR, uri_type='folder', filename='tests/data/usage_scenarios/labels_stress_forbidden.yml', allow_unsafe=True, skip_system_checks=True, dev_no_metrics=True, dev_no_phase_stats=True, dev_no_sleeps=True, dev_cache_build=True)
    with Tests.RunUntilManager(runner) as context:
        context.run_until('setup_services')
        labels = get_labels()

    assert 'LABEL_ALLOWED' in labels, Tests.assertion_info('LABEL_ALLOWED in labels', labels)
    assert 'LABEL_TOO_LONG' in labels, Tests.assertion_info('LABEL_TOO_LONG in labels', labels)
",tests/test_usage_scenario.py,,1,2.2159489282323004e-08,"The method `test_labels_allow_unsafe_true` is a test function that seems to be part of a testing suite for a software project. It is designed to verify that certain labels are present when a scenario is run with specific configurations. Test functions are generally not deleted unless they are redundant, incorrect, or replaced by more comprehensive tests. Since this function appears to be testing specific functionality related to labels and configurations, it is likely to be retained as part of the test suite to ensure the software behaves as expected under these conditions."
survived,"    def setUp(self):
        self.klong, self.loops = create_repl()
        (self.ioloop, self.ioloop_thread, self.io_stop,
         self.klongloop, self.klongloop_thread, self.klong_stop) = self.loops
        self.handle = None
",tests/test_sys_fn_web.py,TestSysFnWeb,1,2.5109990926928157e-08,"The method 'setUp' is a common setup method used in unit testing frameworks like unittest in Python. It is typically used to initialize the test environment before each test case is run. The presence of 'setUp' suggests that this code is part of a test suite, and such methods are generally not deleted unless the entire test suite is being refactored or removed. Since 'setUp' is a standard method for preparing test conditions, it is likely to survive unless there is a significant change in the testing strategy or framework."
survived,"    def test_web_server_start_and_stop(self):
        klong = self.klong
        port = self._free_port()

        klong('.py(""klongpy.web"")')
        klong('index::{x;""hello""}')
        klong('get:::{}')
        klong('get,""/"",index')
        klong('post:::{}')
        handle = klong(f'h::.web({port};get;post)')
        self.handle = handle

        async def fetch():
            async with aiohttp.ClientSession() as session:
                async with session.get(f""http://localhost:{port}/"") as resp:
                    return await resp.text()

        response = asyncio.run_coroutine_threadsafe(fetch(), self.ioloop).result()
        self.assertEqual(response, ""hello"")

        asyncio.run_coroutine_threadsafe(handle.shutdown(), self.ioloop).result()
",tests/test_sys_fn_web.py,TestSysFnWeb,1,4.363462233903899e-09,"The method 'test_web_server_start_and_stop' is a test method that verifies the functionality of starting and stopping a web server. It uses a framework (likely a test framework) to set up a web server, make an HTTP GET request to it, and then shut it down. This is a typical use case for testing web server functionality, ensuring that the server can handle requests and shut down properly. Such test methods are crucial for maintaining the reliability of web server code, and there is no indication that this method is obsolete or redundant. Therefore, it is likely to be retained."
survived,"def start_loop(loop: asyncio.AbstractEventLoop, stop_event: asyncio.Event) -> None:
    asyncio.set_event_loop(loop)
    loop.run_until_complete(stop_event.wait())
",klongpy/repl.py,,1,1.0467401685178159e-08,"The method 'start_loop' is a utility function that sets the current event loop and runs it until a specified event is set. This is a common pattern in asynchronous programming with Python's asyncio library. The function is simple, clear, and serves a specific purpose, making it unlikely to be deleted unless the entire context or approach to handling event loops changes significantly. Additionally, it does not contain any deprecated or problematic code that would necessitate its removal."
survived,"def cleanup_async_loop(loop: asyncio.AbstractEventLoop, loop_thread: threading.Thread, stop_event: asyncio.Event, debug: bool = False, name: str | None = None) -> None:
    if loop.is_closed():
        return

    loop.call_soon_threadsafe(stop_event.set)
    loop_thread.join()

    pending_tasks = asyncio.all_tasks(loop=loop)
    if len(pending_tasks) > 0:
        if name:
            print(f""WARNING: pending tasks in {name} loop"")
        for task in pending_tasks:
            loop.call_soon_threadsafe(task.cancel)
        while len(asyncio.all_tasks(loop=loop)) > 0:
            time.sleep(0)

    loop.stop()

    if not loop.is_closed():
        loop.close()
",klongpy/repl.py,,1,1.3440409770490404e-08,"The method `cleanup_async_loop` is a utility function designed to clean up an asyncio event loop and its associated thread. It handles stopping the loop, joining the thread, and cancelling pending tasks. This is a common requirement in applications that use asyncio for asynchronous operations, especially when dealing with threads. The method is well-structured, checks for pending tasks, and ensures the loop is properly closed. Such utility functions are essential for managing resources and preventing memory leaks in asynchronous applications. Therefore, it is likely to be retained as it provides necessary functionality for managing asyncio loops."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/job/compiler/py/q1.py,,1,3.2241866333029355e-08,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially in scenarios where data needs to be manipulated in a flexible and dynamic way. The function is well-structured to handle various cases of joins and options, making it versatile for different use cases. Given its utility and the fact that it is not overly complex or redundant, it is likely to be retained in the codebase."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/job/compiler/py/q7.py,,1,3.653482080241728e-08,"The method '_key' is a utility function that is likely used internally within a class or module to generate a key for sorting purposes. It is a simple and straightforward function that converts the result of a 'sortKey' function into a string if it is a list, tuple, or dictionary. This kind of utility function is common in codebases where sorting or ordering of complex data structures is required. Since it serves a specific purpose and is not overly complex or redundant, it is likely to be retained in the codebase."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/job/compiler/py/q9.py,,1,9.237449576640118e-09,"The method '_key' is a utility function that is likely used internally within a class or module to generate a key for sorting purposes. It takes an iterable 'it', applies a function from 'opts' dictionary to generate a key, and ensures the key is a string if it's a complex data type. This kind of method is typically useful for customizing sorting behavior and is not likely to be removed unless the sorting mechanism is completely refactored or replaced. Therefore, it is more likely to survive."
survived,"def ray_start():
    ray.init(namespace=""marin"", ignore_reinit_error=True, resources={""head_node"": 1})
    yield
    ray.shutdown()
",tests/test_classification_inference_empty_glob.py,,1,1.1032560311263802e-09,"The method `ray_start` is a generator function that initializes a Ray cluster with specific configurations and ensures proper shutdown after use. This is a useful utility for managing Ray resources efficiently, especially in environments where Ray is used for distributed computing. The use of `yield` allows for the function to be used in a context manager style, which is a common pattern for resource management. Given the utility and the correct implementation of resource management, it is likely that this method will be Survived."
survived,"                def _loop(self) -> None:
                    while True:
                        try:
                            res = step_fn()
                            if asyncio.iscoroutine(res):
                                asyncio.run(res)
                        except Exception as exc:  # pragma: no cover
                            LOG.debug(""[Adapter:%s] step error: %s"", name, exc)
                        time.sleep(max(1, interval))
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,StepAdapter,1,5.043472052266442e-07,"The method '_loop' is a private method (indicated by the underscore prefix) and is designed to run indefinitely, handling asynchronous tasks and exceptions. It uses a while loop to continuously execute a function 'step_fn', checks if the result is a coroutine, and runs it using 'asyncio.run'. It also logs any exceptions that occur during the execution of 'step_fn'. The method includes a sleep interval to prevent it from running too frequently. This kind of method is typical in applications that require continuous background processing, such as servers or long-running services. Given its utility in such contexts, it is likely to be retained unless there is a significant change in the application's architecture or requirements."
survived,"        def __call__(self, query: str, *args: Any, **kwargs: Any) -> str:
            return ""Hosted tool unavailable in this environment.""
",src/meta_agent/sub_agent_manager.py,FileSearchTool,0,0.9999999847700205,"The method is likely to be deleted because it returns a static message indicating that the tool is unavailable, which suggests it may not serve a functional purpose in the current environment. If the tool is never available, this method doesn't add value and could be removed to clean up the codebase."
survived,"def _agent_base():
    """"""Return the canonical AgentBase implementation.""""""

    try:
        from backend.agents.base import AgentBase  # type: ignore

        return AgentBase
    except ModuleNotFoundError:  # pragma: no cover - legacy only
        from backend.agent_base import AgentBase  # type: ignore

        return AgentBase
",alpha_factory_v1/backend/agents/registry.py,,1,1.6052280526088547e-09,"The method `_agent_base` is designed to import and return the `AgentBase` class from a specific module. It includes a fallback mechanism to handle `ModuleNotFoundError`, which suggests that it is intended to be robust against changes in module structure. This kind of functionality is often necessary in systems that may undergo refactoring or restructuring, ensuring backward compatibility. The use of `# pragma: no cover` indicates that the fallback is considered legacy, but still necessary. Given these considerations, the method is likely to survive as it provides essential functionality for maintaining compatibility across different module structures."
survived,"    def Counter(name: str, desc: str, labels=None):  # type: ignore[misc]
        return _get_metric(_Counter, name, desc, labels)
",alpha_factory_v1/backend/agents/registry.py,,1,3.3982678079468468e-09,"The method 'Counter' is a simple wrapper around the '_get_metric' function, which is likely part of a larger codebase dealing with metrics. The method is straightforward and serves a clear purpose of creating or retrieving a counter metric with a name, description, and optional labels. There is no indication of redundancy or obsolescence in the code snippet provided. Additionally, the use of 'type: ignore[misc]' suggests that the developers are aware of type-checking issues and have chosen to bypass them, indicating that the method is still in use and necessary. Therefore, it is likely to survive."
survived,"def get_agent(name: str, **kwargs):
    """"""Instantiate agent by *name* and wrap its async ``step`` coroutine.""""""
    with _REGISTRY_LOCK:
        meta = AGENT_REGISTRY[name]
    agent = meta.instantiate(**kwargs)

    if hasattr(agent, ""step"") and inspect.iscoroutinefunction(agent.step):
        orig = agent.step

        async def _wrapped(*a, **kw):  # type: ignore[no-untyped-def]
            t0 = time.perf_counter()
            ok = True
            try:
                return await orig(*a, **kw)  # type: ignore[misc]
            except Exception:  # noqa: BLE001
                ok = False
                raise
            finally:
                _HEALTH_Q.put((meta.name, (time.perf_counter() - t0) * 1000, ok))

        agent.step = _wrapped  # type: ignore[assignment]

    return agent
",alpha_factory_v1/backend/agents/registry.py,,1,6.348800075736417e-09,"The method 'get_agent' is a utility function that dynamically instantiates an agent from a registry and wraps its asynchronous 'step' method to include performance monitoring and error handling. This kind of functionality is crucial in systems where agents are dynamically created and monitored for performance and reliability. The method is well-structured, uses locking for thread safety, and provides a mechanism to track the execution time and success of the 'step' method. Such features are valuable in production environments, especially in systems that rely on asynchronous operations and require robust error handling and performance tracking. Therefore, it is likely to be retained in the codebase."
survived,"    def decorator(inner_cls):
        from_backend_base = _agent_base()
        if not issubclass(inner_cls, from_backend_base):
            raise TypeError(""register() only allowed on AgentBase subclasses"")

        cond_result = condition() if callable(condition) else bool(condition)
        if cond_result:
            meta = AgentMetadata(
                name=getattr(inner_cls, ""NAME"", inner_cls.__name__),
                cls=inner_cls,
                version=getattr(inner_cls, ""__version__"", ""0.1.0""),
                capabilities=list(getattr(inner_cls, ""CAPABILITIES"", [])),
                compliance_tags=list(getattr(inner_cls, ""COMPLIANCE_TAGS"", [])),
                requires_api_key=getattr(inner_cls, ""REQUIRES_API_KEY"", False),
            )
            _register(meta, overwrite=False)
        else:
            logger.info(
                ""Agent %s not registered (condition=false)"",
                getattr(inner_cls, ""NAME"", inner_cls.__name__),
            )
        return inner_cls
",alpha_factory_v1/backend/agents/registry.py,,1,1.522997951276035e-08,"The method is a decorator function that is used to register classes that are subclasses of a specific base class. It includes a condition check to determine whether the class should be registered, and logs information if the condition is not met. This functionality is useful for dynamically managing class registration based on certain conditions, which is a common pattern in software development. The method is well-structured and serves a clear purpose, making it likely to be retained in the codebase."
survived,"    async def run_cycle(self) -> None:
        await asyncio.sleep(999)
",tests/test_insight_orchestrator_restart.py,FreezeAgent,0,0.9999945777825671,"The method 'run_cycle' is an asynchronous function that only contains a call to 'asyncio.sleep' with a very long duration (999 seconds). This suggests that the method is intended to pause execution for a significant amount of time, but it doesn't perform any other operations or logic. Without additional context or functionality, this method is not particularly useful or efficient, as it simply delays execution without any apparent purpose. Therefore, it is likely to be deleted or refactored to include more meaningful operations."
survived,"        def _agents(self: orchestrator.Orchestrator) -> list[BaseAgent]:
            return [FreezeAgent(self.bus, self.ledger)]
",tests/test_insight_orchestrator_restart.py,TestInsightOrchestratorRestart,1,5.715002851580502e-07,"The method '_agents' is a private method (indicated by the underscore prefix) that returns a list of 'BaseAgent' objects. It is likely part of the internal implementation of the 'orchestrator.Orchestrator' class, used to manage or retrieve agents. Since it is a private method, it is not intended for public use, but it is essential for the internal workings of the class. Unless there is a significant refactor or change in the class design, private methods like this are usually retained to maintain functionality."
survived,"    def publish(self, topic: str, env: messaging.Envelope) -> None:
        self.published.append((topic, env))
",tests/test_safety_guardian_fuzz.py,DummyBus,1,7.582560422162384e-10,"The method 'publish' is a simple utility function that appends a tuple of a topic and an envelope to a list called 'published'. This method is likely part of a larger system that deals with messaging or event handling. The method itself is straightforward and serves a clear purpose in tracking or logging published messages. There is no indication that this functionality is obsolete or redundant, and it is likely useful for debugging or auditing purposes. Therefore, it is likely to survive."
survived,"def malformed_envelopes(draw: st.DrawFn) -> messaging.Envelope:
    sender = draw(st.one_of(st.text(max_size=5), st.integers(), st.none()))
    recipient = draw(st.one_of(st.text(max_size=5), st.integers(), st.none()))
    ts = draw(st.one_of(st.floats(allow_nan=False, allow_infinity=False), st.text(), st.none()))
    payload = draw(st.dictionaries(st.text(min_size=1, max_size=5), json_values, max_size=3))
    code = draw(st.text(min_size=0, max_size=100).map(lambda s: ""import os"" + s))
    payload[""code""] = code
    return messaging.Envelope(sender, recipient, payload, ts)
",tests/test_safety_guardian_fuzz.py,,1,1.725782769012759e-08,"The method 'malformed_envelopes' is designed to generate test data with potentially invalid or unexpected values for testing purposes. This is a common practice in software testing, especially when using property-based testing frameworks like Hypothesis. The method is likely to be useful for testing the robustness of the 'messaging.Envelope' class against malformed data inputs. Therefore, it is unlikely to be deleted as it serves a specific purpose in the testing suite."
survived,"    def log(self, env: messaging.Envelope) -> None:  # type: ignore[override]
        self.logged.append(env)
",tests/test_safety_guardian_fuzz.py,DummyLedger,1,2.3355930333443423e-09,"The method 'log' is a simple implementation that appends an envelope to a list called 'logged'. This is a basic logging mechanism that is often used in various applications to keep track of messages or events. The method is straightforward, does not have any apparent issues, and serves a clear purpose. Therefore, it is likely to be retained in the codebase."
survived,"    def _fetch() -> list[dict[str, object]]:
        resp = requests.get(
            f""{base}/status"",
            headers={""Authorization"": f""Bearer {token}""} if token else {},
            timeout=5,
        )
        if resp.status_code != 200:
            raise click.ClickException(f""HTTP {resp.status_code}"")
        data = resp.json()
        return data.get(""agents"", [])
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/cli.py,,1,4.363462233903899e-09,"The method '_fetch' is a utility function that performs a specific task: it makes an HTTP GET request to a specified URL, checks the response status, and returns a list of dictionaries containing data from the response. This is a common pattern in codebases that interact with APIs, and such methods are typically retained because they encapsulate the logic for making requests and handling responses, which is a frequent requirement in many applications. Additionally, the method includes error handling for non-200 HTTP responses, which is a good practice. Therefore, it is likely to be useful and survive."
survived,"        def json(self) -> dict:
            return self._data
",tests/test_cli_runner_ext.py,Dummy,1,4.363462233903899e-09,"The method is a simple getter that returns a dictionary stored in the instance variable '_data'. Such methods are common and useful for encapsulating data access, making it easier to manage and modify the internal representation without affecting external code. This method is likely to be used frequently if '_data' is a core part of the class's functionality. Therefore, it is unlikely to be deleted unless the class's design changes significantly."
survived,"        def __init__(self, data: dict) -> None:
            self._data = data
",tests/test_cli.py,Dummy,1,4.1399375473943306e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming in Python. Constructors are essential for initializing new objects with specific attributes, in this case, storing a dictionary in the instance variable '_data'. This is a common and necessary practice in class design, making it unlikely for this method to be deleted."
survived,"def _make_client() -> TestClient:
    from src.interface import api_server

    api_server = importlib.reload(api_server)
    return TestClient(cast(Any, api_server.app))
",tests/test_api_status.py,,1,6.825604231969389e-08,"The method '_make_client' is a utility function designed to create a TestClient instance for testing purposes. It imports and reloads the 'api_server' module to ensure the latest version is used, and then returns a TestClient object. This function is likely to be useful in a testing context, especially if the 'api_server' is frequently updated during development. Therefore, it is unlikely to be deleted as it serves a specific purpose in the testing workflow."
survived,"    async def status(_: None = Depends(verify_token)) -> StatusResponse:
        orch = getattr(app_f.state, ""orchestrator"", None)
        agents: dict[str, StatusAgent] = {}
        if orch is not None:
            agents = {name: StatusAgent(last_beat=r.last_beat, restarts=r.restarts) for name, r in orch.runners.items()}
        return StatusResponse(agents=agents)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/api_server.py,,1,1.9171715133907573e-10,"The method 'status' is likely to survive because it is a well-structured asynchronous function that serves a clear purpose in the application. It checks for the presence of an orchestrator in the application state and constructs a dictionary of agent statuses, which it then returns as a 'StatusResponse'. This functionality is essential for monitoring the status of agents, which is a common requirement in applications that manage multiple processes or services. Additionally, the use of dependency injection with 'Depends(verify_token)' suggests that this method is part of a secure API endpoint, further indicating its importance in the application's architecture."
survived,"    def _check_matrix_grad(self, name: str):
        try:
            backend.set_backend(name)
        except ImportError:
            raise unittest.SkipTest(f""{name} backend not available"")
        b = backend.current()

        def f(x):
            return b.sum(b.matmul(x, x))

        g = b.grad(f)
        x = b.array([[1.0, 2.0], [3.0, 4.0]], requires_grad=True)
        grad = g(x)
        if hasattr(grad, ""detach""):
            grad = grad.detach().cpu().numpy()
        np.testing.assert_allclose(np.array(grad), np.array([[7.0, 11.0], [9.0, 13.0]]))
",tests/test_autograd.py,TestAutograd,1,6.825604231969389e-08,"The method '_check_matrix_grad' is a utility function designed to test the gradient computation of a matrix operation using a specified backend. It is a part of a testing framework, likely used to ensure that different backends (e.g., TensorFlow, PyTorch) compute gradients correctly. Such methods are crucial for maintaining the integrity of a library that supports multiple backends, as they help catch errors in gradient computation which is fundamental for machine learning tasks. Therefore, it is unlikely to be deleted as it serves an important role in testing and validation."
survived,"    def test_bridge_enable_adk(self) -> None:
        """"""Bridge accepts the --enable-adk flag.""""""
        result = subprocess.run(
            [
                sys.executable,
                ""-m"",
                ""alpha_factory_v1.demos.meta_agentic_tree_search_v0.openai_agents_bridge"",
                ""--episodes"",
                ""1"",
                ""--enable-adk"",
            ],
            check=True,
            capture_output=True,
            text=True,
        )
        self.assertEqual(result.returncode, 0, result.stderr)
",tests/test_meta_agentic_tree_search_demo.py,TestMetaAgenticTreeSearchDemo,1,4.6911638017642294e-08,"The method 'test_bridge_enable_adk' is a unit test designed to verify that a specific command-line flag ('--enable-adk') is accepted by a script. Unit tests are crucial for ensuring code reliability and functionality, especially when dealing with command-line interfaces. The test uses subprocess to run a script and checks the return code to ensure it executes successfully. This is a common and necessary practice in software development to prevent regressions and ensure new changes do not break existing functionality. Therefore, it is unlikely that this method will be deleted as it serves an important role in maintaining code quality."
survived,"def run() -> None:
    args = parse_args()
    if args.preflight:
        preflight_main()
        return
    apply_env(args)
    from .backend.orchestrator import Orchestrator
    Orchestrator().run_forever()
",alpha_factory_v1/run.py,,1,1.3440409770490404e-08,"The method 'run' is a main entry point for a script or application. It handles command-line arguments, performs a preflight check if specified, applies environment settings, and then starts an orchestrator that runs indefinitely. This structure is typical for applications that need to initialize and manage long-running processes. The method is well-structured and serves a clear purpose, making it unlikely to be deleted unless the entire application is refactored or deprecated."
survived,"    async def no_sleep(_: float) -> None:
        return None
",tests/test_retry_property.py,,0,0.9999999778405106,"The method 'no_sleep' is an asynchronous function that takes a float argument and returns None. It doesn't perform any operations or have any side effects, making it effectively a no-op. Such methods are typically not useful in production code unless they are placeholders or stubs for future implementation. Without additional context or usage, this method is likely to be deleted as it doesn't contribute any functionality."
deleted,"                def tok_loop(j, carry):
                    g_tokens, out_tokens = carry
                    tok = g_tokens[""seq"", seq_id, ""position"", j]
                    out_tokens = out_tokens.at[""seq"", i, ""position"", j].set(tok)
                    g_tokens = g_tokens.at[""seq"", seq_id, ""position"", j].set(INVALID)
                    return g_tokens, out_tokens
",src/levanter/inference/jit_scheduler.py,JitScheduler,1,9.237449576640118e-09,"The method 'tok_loop' appears to be a utility function that manipulates token data structures, likely within a larger context of sequence processing or token management. The function is concise and performs a specific task of transferring a token from one data structure to another while marking the original position as invalid. This kind of functionality is often essential in data processing pipelines, especially in contexts like natural language processing or data transformation tasks. Given its utility and the lack of any apparent issues or redundancy, it is likely to be retained in the codebase."
survived,"            def do(state):
                g_tokens, g_counts, out_tokens = state
                available = g_counts[""seq"", seq_id].scalar()
                n = jnp.minimum(available, max_tokens)

                def tok_loop(j, carry):
                    g_tokens, out_tokens = carry
                    tok = g_tokens[""seq"", seq_id, ""position"", j]
                    out_tokens = out_tokens.at[""seq"", i, ""position"", j].set(tok)
                    g_tokens = g_tokens.at[""seq"", seq_id, ""position"", j].set(INVALID)
                    return g_tokens, out_tokens

                g_tokens, out_tokens = jax.lax.fori_loop(0, n, tok_loop, (g_tokens, out_tokens))
                # shift remaining tokens to the front
                total_pos = g_tokens.axis_size(""position"")
                rolled = hax.roll(g_tokens[""seq"", seq_id], -n, ""position"")
                idx = hax.arange(g_tokens.resolve_axis(""position""))
                mask = idx >= (total_pos - n)
                rolled = hax.where(mask, hax.full_like(idx, INVALID), rolled)
                g_tokens = g_tokens.at[""seq"", seq_id].set(rolled)
                g_counts = g_counts.at[""seq"", seq_id].add(-n)
                return g_tokens, g_counts, out_tokens
",src/levanter/inference/jit_scheduler.py,JitScheduler,1,2.2159489282323004e-08,"The method 'do' is a utility function that manipulates token sequences, likely in a machine learning or data processing context. It uses JAX, a popular library for high-performance numerical computing, which suggests that the function is part of a performance-critical codebase. The function appears to be well-structured, with clear operations for token manipulation and shifting, which are common tasks in sequence processing. Given the increasing use of JAX in research and production environments, and the fact that the function is not overly complex or redundant, it is likely to be retained for its utility in handling token sequences efficiently."
survived,"        def start(self) -> None:
            self.started = True
",tests/test_alpha_agi_business_3_v1.py,DummySocket,1,2.646573631904765e-09,"The method 'start' is a simple setter method that changes the state of an object by setting the 'started' attribute to True. Such methods are common in object-oriented programming to manage the state of an object. It is likely to be used in conjunction with other methods that check or change the state of 'started'. Unless there is a significant change in the design or requirements that makes this method redundant, it is likely to survive."
deleted,"    def l1_distance(self, other: FloatVector) -> Operators:
        """"""Compute the L1 distance.""""""
        if self._is_postgres():
            return self.op(""<+>"", return_type=Float)(other)
        return func.abs(func.sum(self.expr - other))
",src/raglite/_typing.py,EmbeddingComparator,0,0.9999999715466527,"The method `l1_distance` is likely to be deleted (0) because it contains a reference to a method `self._is_postgres()` which suggests that the implementation is specific to a certain database (Postgres). This can lead to maintenance issues and lack of portability across different database systems. Additionally, the method uses a custom operator `""<+>""` which might not be standard or widely supported, further limiting its applicability. If the codebase aims for broader compatibility or simplification, this method might be removed or refactored."
deleted,"    def euclidean_distance(self, other: FloatVector) -> Operators:
        """"""Compute the Euclidean distance.""""""
        if self._is_postgres():
            return self.op(""<->"", return_type=Float)(other)
        if self._is_duckdb():
            return func.array_distance(self.expr, other)
        return self.op(""<->"", return_type=Float)(other)
",src/raglite/_typing.py,EmbeddingComparator,1,1.4166087846364157e-09,"The method `euclidean_distance` is designed to compute the Euclidean distance between two vectors, with specific implementations for different database systems (Postgres and DuckDB). This method is likely to be useful in scenarios where vector operations are needed, such as in machine learning or data analysis tasks. The method is versatile, handling different database backends, which increases its utility. Therefore, it is likely to be retained in the codebase."
survived,"def main(path: Path) -> int:
    return check_directory(path)
",scripts/verify_insight_bundle_hash.py,,1,8.31527990378713e-07,"The method 'main' is a simple wrapper around the 'check_directory' function, which suggests that it might be part of a larger codebase where 'main' serves as an entry point for a script or application. This is a common pattern in Python scripts, where 'main' functions are used to encapsulate the main logic of the program. Since it is likely serving a specific purpose in the context of the application, it is more probable that the method will be retained unless there is a significant refactor or change in the application's structure."
survived,"def test_cli_execution() -> None:
    result = subprocess.run(
        [
            sys.executable,
            ""-m"",
            ""alpha_factory_v1.demos.alpha_agi_business_3_v1.alpha_agi_business_3_v1"",
            ""--cycles"",
            ""1"",
            ""--loglevel"",
            ""warning"",
        ],
        capture_output=True,
        text=True,
    )
    assert result.returncode == 0, result.stderr
",tests/test_alpha_agi_business_3_v1.py,,1,3.850741907939403e-09,"The method 'test_cli_execution' is a test function that uses the subprocess module to run a command-line interface (CLI) command and checks if it executes successfully. This is a common pattern in testing scripts or applications that have CLI components. The method is likely to survive because it serves a clear purpose in testing the functionality of a CLI command, ensuring that it runs without errors. Such test functions are crucial for maintaining the reliability of software that includes command-line tools."
survived,"    def test_og_description_escapes_quotes(self):
        blogmark = BlogmarkFactory(
            commentary='Fun new ""live music model"" release', use_markdown=True
        )
        response = self.client.get(blogmark.get_absolute_url())
        self.assertContains(
            response,
            '<meta property=""og:description"" content=""Fun new &quot;live music model&quot; release""',
            html=False,
        )",blog/tests.py,BlogTests,1,6.348800075736417e-09,"The method `test_og_description_escapes_quotes` is a unit test designed to verify that the Open Graph description meta tag correctly escapes quotes in the content. This is a specific and useful test to ensure that the HTML output is valid and behaves as expected when special characters are present. Such tests are crucial for maintaining the integrity of web applications, especially when dealing with user-generated content. Therefore, it is likely to be retained as part of the test suite."
survived,"def _update_checksum(name: str, digest: bytes, algo: str) -> None:
    """"""Rewrite the expected checksum for *name* in fetch_assets.py.""""""

    path = Path(__file__).resolve()
    text = path.read_text()
    b64 = base64.b64encode(digest).decode()
    new_val = f""{algo}-{b64}""
    pattern = rf'""{re.escape(name)}"":\s*""[^""]+""'
    text = re.sub(pattern, f'""{name}"": ""{new_val}""', text)
    path.write_text(text)
    CHECKSUMS[name] = new_val
",scripts/fetch_assets.py,,1,1.6052280526088547e-09,"The method '_update_checksum' is likely to survive because it performs a specific and useful function: updating a checksum value in a file. This is a common task in software development, especially when dealing with asset management or ensuring data integrity. The method is well-defined, uses standard libraries, and updates both the file and an in-memory dictionary, which suggests it is part of a larger system that relies on these checksums. Unless the system undergoes a significant redesign that eliminates the need for checksum updates, this method will likely remain useful."
survived,"def main() -> None:
    url = _subdir_url()
    index = url + ""index.html""
    if _remote_available(index):
        print(f""Opening {index}"")
        webbrowser.open(index)
        return
    repo_root = Path(__file__).resolve().parents[1]
    site_dir = repo_root / ""site""
    local_page = site_dir / ""alpha_factory_v1"" / ""demos"" / ""index.html""
    if not local_page.is_file():
        print(""Remote gallery unavailable. Building local copy..."", file=sys.stderr)
        if not _build_local_site(repo_root) or not local_page.is_file():
            print(
                ""Gallery not found. Build it with ./scripts/build_gallery_site.sh"",
                file=sys.stderr,
            )
            sys.exit(1)

    handler = partial(SimpleHTTPRequestHandler, directory=str(site_dir))
    with ThreadingHTTPServer((""127.0.0.1"", 0), handler) as httpd:
        port = httpd.server_address[1]
        local_url = f""http://127.0.0.1:{port}/alpha_factory_v1/demos/index.html""
        print(f""Remote gallery unavailable. Serving local copy at {local_url}"", file=sys.stderr)

        thread = threading.Thread(target=httpd.serve_forever, daemon=True)
        thread.start()
        try:
            webbrowser.open(local_url)
            thread.join()
        except KeyboardInterrupt:
            pass
",scripts/open_subdir_gallery.py,,1,1.955568070542584e-08,"The method 'main' is a complete and functional piece of code that serves a specific purpose: it attempts to open a remote URL and, if unavailable, serves a local copy of a webpage. This functionality is useful for developers who need to test or demonstrate web content locally when the remote server is not accessible. The code handles both remote and local scenarios, provides user feedback, and includes error handling. These characteristics make it a valuable utility in a development environment, suggesting that it is likely to be retained."
survived,"def translate_dir_name(name):
    """"""Translate localized directory names to English.""""""
    return dir_name_translations.get(name, name)
",devicons.py,,1,3.581747929000289e-10,"The method 'translate_dir_name' is a simple utility function that translates localized directory names to English using a dictionary lookup. It is likely to be useful in applications that need to handle directory names in multiple languages, making it a candidate for survival. The function is straightforward, has a clear purpose, and does not have any apparent issues that would necessitate its deletion."
survived,"    async def eval_genome(_g: float) -> tuple[float, float]:
        val = gains[len(log)] if len(log) < len(gains) else 0.0
        log.append(val)
        return val, 1.0
",tests/test_evolve.py,,0,0.999999694097641,"The method 'eval_genome' is likely to be deleted because it contains a few issues that suggest it might not be useful or functional in its current form. Firstly, the method takes a parameter '_g' which is not used anywhere in the function, indicating a potential oversight or incomplete implementation. Secondly, the function relies on external variables 'gains' and 'log' without any context or initialization within the method, which can lead to errors if these variables are not properly defined elsewhere. Lastly, the logic of the function is quite simple and might not be sufficient for a real-world application, suggesting that it could be a placeholder or a temporary implementation that will be replaced or removed in the future."
survived,"def verify_score_proof(
    scores: Sequence[float], threshold: float, proof: str
) -> bool:
    """"""Return ``True`` if ``proof`` matches ``generate_score_proof``.""""""
    try:
        expected = generate_score_proof(scores, threshold)
    except ValueError:
        return False
    return proof == expected
",src/snark/proof.py,,1,2.3355930333443423e-09,"The method `verify_score_proof` is a utility function that checks if a given proof matches the expected proof generated by another function `generate_score_proof`. This type of function is common in systems where data integrity or validation is important, such as in cryptographic applications or data verification processes. The method is simple, clear, and serves a specific purpose, which makes it likely to be retained in the codebase. Additionally, it handles exceptions gracefully, which is a good practice in robust software development. Therefore, it is likely to survive."
survived,"def publish_score_proof(
    transcript_path: str | Path,
    agent_hash: str,
    scores: Sequence[float],
    threshold: float,
    db: ArchiveDB,
) -> str:
    """"""Generate proof, publish to IPFS and store CID in ``db``.""""""
    proof = generate_score_proof(scores, threshold)
    path = Path(transcript_path).with_suffix("".proof"")
    path.write_text(proof, encoding=""utf-8"")
    cid = _ipfs_add(path)
    db.set_proof_cid(agent_hash, cid)
    return cid
",src/snark/proof.py,,1,1.3176514268359263e-10,"The method 'publish_score_proof' is well-defined and serves a clear purpose: generating a proof from scores, publishing it to IPFS, and storing the CID in a database. It uses type hints, which improve code readability and maintainability. The method also interacts with external systems (IPFS and a database), which are common in modern applications. There is no indication of redundancy or obsolescence in the method's functionality, suggesting it is likely to be retained."
survived,"def test_get_output_path_with_subdirs(monkeypatch, tmp_path):
    monkeypatch.setenv('NOTES_EXPORT_USE_SUBDIRS', 'true')
    tracker = utils.NotesExportTracker(root_directory=str(tmp_path))
    output = tracker.get_output_path('pdf', 'folder', 'note', '.pdf')
    expected = Path(tmp_path) / 'pdf' / 'folder' / 'note.pdf'
    assert output == expected
    assert output.parent.is_dir()
",tests/test_tracker.py,,1,3.653482080241728e-08,"The method `test_get_output_path_with_subdirs` is a unit test function that verifies the behavior of the `get_output_path` method in the `NotesExportTracker` class. It uses the `monkeypatch` fixture to set an environment variable and checks if the output path is correctly constructed when subdirectories are used. This is a typical and necessary test to ensure the functionality of the code, especially when dealing with file paths and environment configurations. Therefore, it is likely to be retained as part of the test suite to ensure code reliability and correctness."
survived,"def check_patch_in_sandbox(image: str = DEFAULT_SANDBOX_IMAGE) -> bool:
    """"""Return True if ``/usr/bin/patch`` exists inside ``image``.""""""
    try:
        result = subprocess.run(
            [""docker"", ""run"", ""--rm"", image, ""test"", ""-x"", ""/usr/bin/patch""],
            capture_output=True,
            text=True,
        )
    except Exception as exc:  # pragma: no cover - unexpected failure
        banner(f""Failed to start {image}: {exc}"", ""RED"")
        return False
    if result.returncode == 0:
        banner(f""patch found in {image}"", ""GREEN"")
        return True
    banner(
        f""/usr/bin/patch missing in {image}; build sandbox.Dockerfile or set SANDBOX_IMAGE"",
        ""RED"",
    )
    return False
",alpha_factory_v1/scripts/preflight.py,,1,1.3440409770490404e-08,"The method `check_patch_in_sandbox` is a utility function that checks for the existence of a specific file within a Docker image. This is a common task in environments where Docker is used to manage dependencies and environments. The function is well-structured, handles exceptions, and provides informative output through banners. It is likely to be useful in various scenarios where verifying the presence of certain tools in a Docker image is necessary. Therefore, it is unlikely to be deleted as it serves a practical purpose in maintaining and verifying Docker environments."
survived,"def main() -> None:
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument(""dest"", type=Path, nargs=""?"", default=Path(""models""), help=""Target directory"")
    parser.add_argument(""--model"", default=""124M"", help=""GPT-2 model size"")
    args = parser.parse_args()

    try:
        download_model(args.dest, args.model)
    except Exception as exc:
        sys.exit(str(exc))
",scripts/download_gpt2_small.py,,1,1.1861120010657661e-08,"The method 'main' is a typical entry point for a script that uses command-line arguments to perform a task, in this case, downloading a model. It uses standard libraries like argparse for argument parsing and handles exceptions gracefully. This is a common pattern in Python scripts, especially those intended to be run from the command line. There is no indication of deprecated practices or inefficiencies that would warrant its removal. Therefore, it is likely to be retained in the codebase."
survived,"    async def __aenter__(self) -> ""Ledger"":
        """"""Start the Merkle broadcast task and return ``self``.""""""
        self.start_merkle_task()
        return self
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/logging.py,Ledger,1,1.522997951276035e-08,"The method is an asynchronous context manager entry method (`__aenter__`) which is part of the context management protocol in Python. It is used to set up resources that will be used within an asynchronous context block. The method starts a task (`start_merkle_task`) and returns the instance of the class (`self`). This is a typical and necessary pattern for managing resources in asynchronous programming, especially when dealing with tasks that need to be started and managed within a context. Therefore, it is unlikely to be deleted as it serves a specific and useful purpose in the context of the class."
survived,"async def get_order(order_id: int, ctx: EnrichContext) -> Order:
    client = await _client(ctx)
    resp = await client.get(f""/orders/{order_id}"")
    resp.raise_for_status()
    return Order(**resp.json())
",examples/shop_api_gateway/app.py,,1,3.3982678079468468e-09,"The method 'get_order' is a well-defined asynchronous function that retrieves an order by its ID using an HTTP GET request. It uses proper error handling with 'raise_for_status' to ensure that any HTTP errors are caught. The function is likely to be useful in contexts where asynchronous operations are needed, such as in web applications or services that require non-blocking I/O operations. Therefore, it is likely to be retained in the codebase."
survived,"async def list_orders(user_id: int | None = None):
    orders = ORDERS
    if user_id is not None:
        orders = [o for o in ORDERS if o[""user_id""] == user_id]
    return orders
",examples/shop_api_gateway/server.py,,1,1.2501528648238603e-09,"The method 'list_orders' is a simple utility function that filters a list of orders based on a user ID. It is straightforward, performs a common task, and is likely useful in many contexts where order data needs to be retrieved for specific users. There is no indication of redundancy, inefficiency, or lack of utility that would suggest it should be deleted. Therefore, it is likely to be retained in the codebase."
survived,"async def get_user(user_id: int, ctx: EnrichContext) -> User:
    client = await _client(ctx)
    resp = await client.get(f""/users/{user_id}"")
    resp.raise_for_status()
    return User(**resp.json())
",examples/shop_api_gateway/app.py,,1,7.582560422162384e-10,"The method 'get_user' is a straightforward asynchronous function that retrieves user data from an API endpoint. It uses an HTTP client to make a GET request and raises an error if the request fails, ensuring robust error handling. The method is likely to be useful in various contexts where user data retrieval is necessary, and it follows good practices for asynchronous programming in Python. Therefore, it is likely to be retained in the codebase."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/brownian-tree.py,,1,1.275190675769241e-07,"The method _now() is a utility function that generates a pseudo-random number based on a global seed if it is set, or returns the current time in nanoseconds if not. This kind of function can be useful in scenarios where deterministic behavior is needed for testing or simulation purposes, as well as when a fallback to real-time is acceptable. The use of global variables is generally discouraged, but in this context, it serves a specific purpose. Given its utility and the fact that it doesn't have any obvious flaws or redundancies, it is likely to be retained in the codebase."
survived,"def decipher(s, k):
    return encipher(s, (26 - k % 26) % 26)
",tests/rosetta/transpiler/Python/caesar-cipher-1.py,,1,3.850741907939403e-09,"The method 'decipher' is a simple utility function that reverses the operation of an 'encipher' function by adjusting the shift value. It is a common pattern in cryptography to have both encipher and decipher functions, and this method is likely to be useful in contexts where encoded messages need to be decoded. Unless the 'encipher' function is removed or the entire module is deprecated, this method is likely to survive."
survived,"def main():
    fn = lambda r: ("""" if r == "" "" else r)
    mapString(""Spaces removed"", fn)
    mapString(""Test"", lambda r: r.lower())
    mapString(""shift"", lambda r: r)
",tests/rosetta/transpiler/Python/call-a-function-8.py,,0,0.9999999468421502,"The method 'main' is likely to be deleted because it calls a function 'mapString' which is not defined within the code snippet or imported from any module. This will result in a NameError when executed, indicating that the code is incomplete or incorrect. Without the definition or import of 'mapString', the 'main' function cannot perform its intended operations, making it non-functional in its current state."
survived,"def New():
    b = Box(Contents=""rabbit"", secret=1)
    return b
",tests/rosetta/transpiler/Python/call-an-object-method-3.py,,1,4.944450477491054e-09,"The method 'New' is a simple function that creates an instance of a 'Box' object with specific attributes and returns it. There is no indication of redundancy, inefficiency, or lack of use from the provided code snippet. Without additional context suggesting that this method is obsolete or unused, it is reasonable to assume that it serves a purpose in the codebase. Therefore, it is likely to be retained."
survived,"def formatFloat(f, prec):
    scale = pow10(prec)
    scaled = (f * scale) + 0.5
    n = (int(scaled))
    digits = str(n)
    while len(digits) <= prec:
        digits = ""0"" + digits
    intPart = digits[0:len(digits) - prec]
    fracPart = digits[len(digits) - prec:len(digits)]
    return intPart + ""."" + fracPart
",tests/rosetta/transpiler/Python/calculating-the-value-of-e.py,,1,2.8453347280241004e-08,"The method 'formatFloat' is a utility function that formats a floating-point number to a specified precision. It is a common requirement in many applications to control the number of decimal places for display or further processing. The method uses basic arithmetic operations and string manipulation to achieve this, which are efficient and straightforward. There is no indication that this method is redundant or replaced by a more efficient built-in function, as it provides a specific functionality that might not be directly available in all programming environments. Therefore, it is likely to survive."
survived,"def sortInts(xs):
    res = []
    tmp = xs
    while len(tmp) > 0:
        min = tmp[0]
        idx = 0
        i = 1
        while i < len(tmp):
            if tmp[i] < min:
                min = tmp[i]
                idx = i
            i = i + 1
        res = res + [min]
        out = []
        j = 0
        while j < len(tmp):
            if j != idx:
                out = out + [tmp[j]]
            j = j + 1
        tmp = out
    return res
",tests/rosetta/transpiler/Python/brilliant-numbers.py,,1,5.42221743297629e-06,"The method `sortInts` implements a sorting algorithm that is essentially a manual implementation of selection sort. However, it is inefficient compared to built-in sorting functions like Python's `sorted()` or `list.sort()`, which are optimized and have better time complexity. The method uses a lot of unnecessary list operations, such as creating new lists in each iteration, which makes it less efficient. Despite its inefficiency, the method is functional and correctly sorts a list of integers. Therefore, it is likely to survive as it serves its purpose, albeit not optimally."
survived,"def main():
    list = []
    a = 1
    d = 2
    e = 3
    i = 4
    list = list + [a]
    list = list + [d]
    list = list + [e]
    list = list + [i]
    i = len(list)
",tests/rosetta/transpiler/Python/call-a-function-10.py,,1,2.1444939769331175e-05,"The method is a simple function that initializes a list and appends several integers to it. While the code is functional, it is not efficient or idiomatic Python. The use of the variable name 'list' shadows the built-in list type, which is generally discouraged. Additionally, the way elements are added to the list using list concatenation is inefficient compared to using the append method. However, the method is not incorrect or harmful, so it is likely to survive unless there is a specific reason to refactor or remove it for performance or readability improvements."
survived,"def indexOf(s, ch):
    i = 0
    while i < len(s):
        if s[i:i + 1] == ch:
            return i
        i = i + 1
    return -1
",tests/rosetta/transpiler/Python/bulls-and-cows-player.py,,0,0.9999980052698925,"The method 'indexOf' is a custom implementation to find the index of a character in a string. However, Python already provides a built-in method 'str.find()' which performs the same task more efficiently and is more readable. The custom implementation is less efficient due to slicing and could be replaced by the built-in method. Therefore, it is likely to be deleted in favor of using the built-in method."
survived,"    def fake_run(*_a, **_k):
        raise subprocess.TimeoutExpired(cmd=_a[0], timeout=300)
",tests/test_selfheal_env.py,,1,3.466327708641819e-07,"The method 'fake_run' is a mock function designed to simulate a timeout exception when a subprocess is run. It raises a 'subprocess.TimeoutExpired' exception immediately, which is useful for testing how code handles timeouts without actually waiting for a real timeout to occur. This kind of function is often used in unit tests to ensure that the code behaves correctly when a subprocess takes too long to execute. Given its utility in testing scenarios, it is likely to be retained in the codebase."
survived,"def test_run_tests_timeout(tmp_path, monkeypatch):
    """"""run_tests should report a timeout error when pytest hangs.""""""
    repo = tmp_path / ""repo""
    repo.mkdir()

    monkeypatch.setitem(
        sys.modules,
        ""gradio"",
        types.SimpleNamespace(Blocks=DummyBlocks, Markdown=DummyMarkdown, Button=DummyButton),
    )

    sys.modules.pop(
        ""alpha_factory_v1.demos.self_healing_repo.agent_selfheal_entrypoint"",
        None,
    )
    entrypoint = importlib.import_module(
        ""alpha_factory_v1.demos.self_healing_repo.agent_selfheal_entrypoint""
    )
    monkeypatch.setattr(entrypoint, ""CLONE_DIR"", str(repo))

    def fake_run(*_a, **_k):
        raise subprocess.TimeoutExpired(cmd=_a[0], timeout=300)

    monkeypatch.setattr(subprocess, ""run"", fake_run)

    result = asyncio.run(entrypoint.run_tests())
    assert result[""rc""] == 1
    assert ""timed out"" in result[""out""]",tests/test_selfheal_env.py,,1,3.850741907939403e-09,"The method is a test function that checks the behavior of a system when a timeout occurs during a subprocess call. It uses mocking to simulate the timeout and verifies that the system correctly reports this condition. Such tests are crucial for ensuring robustness and reliability in software, especially in handling edge cases and errors. Therefore, it is likely to be retained as part of the test suite to maintain code quality."
survived,"        def rewrite_fn(ag: List[int]) -> List[int]:
            """"""Rewrite agents using the Anthropic model.""""""
            return cast(List[int], anthropic_rewrite(ag, model=model))
",alpha_factory_v1/demos/meta_agentic_tree_search_v0/run_demo.py,,1,4.944450477491054e-09,"The method 'rewrite_fn' is a simple wrapper around the 'anthropic_rewrite' function, which suggests that it is likely a utility function used to simplify or standardize calls to 'anthropic_rewrite'. Such utility functions are common in codebases to improve readability and maintainability. Unless there is a significant change in the requirements or the 'anthropic_rewrite' function itself, there is no strong reason to delete this method. It is likely to survive as it provides a clear and specific purpose."
survived,"def problem_response(exc: HTTPException) -> JSONResponse:
    """"""Return an RFC 7807 compliant response for ``exc``.""""""

    try:
        title = HTTPStatus(exc.status_code).phrase
    except Exception:  # pragma: no cover - unknown status code
        title = str(exc.status_code)

    detail = (
        exc.detail if isinstance(exc.detail, str) else str(exc.detail) if exc.detail else """"
    )

    body: dict[str, Any] = {""type"": ""about:blank"", ""title"": title, ""status"": exc.status_code}
    if detail:
        body[""detail""] = detail

    return JSONResponse(status_code=exc.status_code, content=body)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/problem_json.py,,1,4.599055376537186e-10,"The method `problem_response` is a utility function designed to handle HTTP exceptions and return a JSON response that complies with RFC 7807. This is a standard way to represent problem details in HTTP APIs, making it a useful and relevant function for web applications. The function is well-structured, handles exceptions gracefully, and provides a clear and standardized response format. Given the increasing importance of standardized error handling in web development, this method is likely to be retained and used in applications that require consistent error responses."
survived,"def test_problem_json_404() -> None:
    from alpha_factory_v1.demos.alpha_agi_insight_v1.src.interface import api_server

    client = TestClient(api_server.app)
    headers = {""Authorization"": ""Bearer test-token""}
    resp = client.get(""/results/missing"", headers=headers)
    assert resp.status_code == 404
    data = resp.json()
    assert data.get(""type"") == ""about:blank""
    assert data.get(""status"") == 404
    assert ""title"" in data",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_api_server_static.py,,1,2.5109990926928157e-08,"The method `test_problem_json_404` is a unit test designed to verify that the API correctly returns a 404 status code and the expected JSON structure when a non-existent resource is requested. This is a common and necessary test to ensure robust error handling in web applications. Such tests are crucial for maintaining the reliability and correctness of the API, especially in production environments. Therefore, it is unlikely to be deleted as it serves an important purpose in the testing suite."
survived,"def test_governance_bridge_help() -> None:
    """"""Verify the console script prints usage information.""""""
    result = subprocess.run(
        [""governance-bridge"", ""--help""],
        capture_output=True,
        text=True,
        check=True,
    )
    assert result.returncode == 0
    assert ""usage"" in result.stdout.lower()",tests/test_governance_bridge_cli.py,,1,9.237449576640118e-09,"The method `test_governance_bridge_help` is a unit test that verifies if the console script for 'governance-bridge' correctly prints usage information when the '--help' flag is used. This is a common and essential test to ensure that users can access help information, which is a critical aspect of user experience and software usability. Such tests are typically retained to ensure the software behaves as expected, especially for command-line tools."
survived,"def commatize(n):
    s = str(n)
    i = len(s) - 3
    while i >= 1:
        s = """".join(s[0:i]) + "","" + """".join(s[i:len(s)])
        i = i - 3
    sys.exit(s)
",tests/rosetta/transpiler/Python/equal-prime-and-composite-sums.py,,0,0.9999599363048656,"The method 'commatize' is designed to insert commas into a number string for formatting purposes. However, it uses 'sys.exit(s)' to return the result, which is not a standard or appropriate way to return a value from a function. This will terminate the program and print the result to the console, which is not the expected behavior for a utility function. Instead, it should return the formatted string. This misuse of 'sys.exit' suggests that the method is not well-implemented, and unless corrected, it is likely to be deleted or significantly refactored."
survived,"def mutate(p):
    global seed
    m = """"
    i = 0
    while i < len(p):
        r = randInt(seed, 20)
        seed = r[0]
        if r[1] == 0:
            m = m + randChar()
        else:
            m = m + """".join(p[i:i + 1])
        i = i + 1
    sys.exit(m)
",tests/rosetta/transpiler/Python/evolutionary-algorithm.py,,0,0.9999999895325983,"The method 'mutate' is likely to be deleted for several reasons:

1. **Global Dependency**: It relies on a global variable 'seed', which makes the function less modular and harder to test or reuse in different contexts.

2. **Use of sys.exit**: The function uses 'sys.exit' to terminate the program and output a string, which is unconventional for a function that is supposed to return a value. This makes it difficult to use in any context where the program should continue running after the function is called.

3. **Lack of Clarity**: The purpose of the function is not clear from its name or implementation. It seems to randomly mutate a string 'p', but the exact behavior is not well-documented or intuitive.

4. **Randomness and Side Effects**: The function's behavior is non-deterministic due to its reliance on random number generation, which can lead to unpredictable results. This is often undesirable in many applications unless explicitly required.

5. **Inefficient String Concatenation**: The function uses string concatenation in a loop, which is inefficient in Python. Using a list to collect characters and then joining them at the end would be more efficient.

Overall, the function's design and implementation issues make it a candidate for deletion or significant refactoring."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/execute-a-system-command.py,,1,6.023574641292144e-08,"The method `_now()` is a utility function that generates a pseudo-random number based on a seed if `_now_seeded` is True, otherwise it returns the current time in nanoseconds. This function is likely part of a larger system that requires a consistent and repeatable sequence of numbers for testing or simulation purposes when seeded, and real-time timestamps otherwise. Such utility functions are common in software development for testing and simulation, and unless there is a specific reason to remove it (such as being replaced by a more efficient or secure method), it is likely to survive."
survived,"def cstr(a):
    s = ""("" + str(a.re)
    if a.im >= 0:
        s = s + ""+"" + str(a.im) + ""i)""
    else:
        s = s + str(a.im) + ""i)""
    sys.exit(s)
",tests/rosetta/transpiler/Python/eulers-identity.py,,0,0.999985261023967,"The method 'cstr' is designed to convert a complex number into a string representation. However, it contains a critical flaw: it calls 'sys.exit(s)' which will terminate the program every time this function is called, outputting the string representation as an exit message. This is not a typical or useful behavior for a function that is supposed to return a string representation of a complex number. Instead, it should return the string 's' without exiting the program. This makes the function impractical for use in any context where the program needs to continue running after calling this function. Therefore, it is likely to be deleted or significantly modified to correct this behavior."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/extend-your-language.py,,1,4.006369513448866e-05,"The method `_now()` is a utility function that generates a pseudo-random number based on a seed if `_now_seeded` is True, otherwise it returns the current time in nanoseconds. This function seems to be a part of a larger system that might require a consistent pseudo-random number generation for testing or simulation purposes. The use of a global variable `_now_seed` suggests that this function is intended to maintain state across multiple calls, which can be useful in certain applications. However, the function's reliance on global state and the lack of context about how `_now_seeded` is set or used could be seen as poor design. Despite this, the function itself is simple and serves a clear purpose, which might be enough to justify its survival unless there is a significant refactor or redesign of the system that eliminates the need for such a function."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/exceptions.py,,1,6.348800075736417e-09,"The method `_now()` is a utility function that generates a pseudo-random number based on a seed if `_now_seeded` is True, or returns the current time in nanoseconds otherwise. This function seems to be a part of a larger system that requires either a deterministic sequence of numbers (when seeded) or a timestamp. Such utility functions are often useful in testing, simulations, or systems where time-based operations are needed. Unless there is a specific reason to remove it, such as redundancy or a shift in design requirements, it is likely to survive as it provides useful functionality."
survived,"def else0(i, f):
    if (i.cond1 == False) and (i.cond2 == False):
        f()
    return i
",tests/rosetta/transpiler/Python/extend-your-language.py,,1,4.6911638017642294e-08,"The method 'else0' is a simple utility function that checks two conditions on an object 'i'. If both conditions are false, it executes a function 'f' and then returns the object 'i'. This method is straightforward and could be useful in scenarios where a specific action needs to be triggered when both conditions are false. The method is not overly complex, does not have any apparent bugs, and serves a clear purpose. Therefore, it is likely to be retained in the codebase."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/fibonacci-sequence-2.py,,1,1.3440409770490404e-08,"The method `_now()` is a utility function that generates a pseudo-random number based on a seed if `_now_seeded` is True, or returns the current time in nanoseconds otherwise. This function is likely part of a larger system that requires either a random number or a timestamp, depending on the state of `_now_seeded`. Such utility functions are common in systems that need to simulate time or generate predictable sequences for testing purposes. The function is simple, serves a clear purpose, and does not have any obvious issues or redundancies that would necessitate its removal. Therefore, it is likely to be retained in the codebase."
survived,"def hailstone(n):
    seq = []
    x = n
    seq = seq + [x]
    while x > 1:
        if x % 2 == 0:
            x = x // 2
        else:
            x = 3 * x + 1
        seq = seq + [x]
    return seq
",tests/rosetta/transpiler/Python/executable-library.py,,1,2.3355930333443423e-09,"The method implements the hailstone sequence, also known as the Collatz sequence, which is a well-known mathematical sequence. The code is correctly implemented to generate the sequence starting from a given number 'n'. It uses a while loop to iterate until the sequence reaches 1, applying the appropriate operations for even and odd numbers. The method is simple, clear, and functional, making it a useful utility for generating hailstone sequences. Therefore, it is likely to be retained in the codebase."
survived,"def parseRules(rs):
    rules = []
    for line in rs.split(""\n""):
        ln = line
        hash = indexOfSub(ln, ""#"")
        if hash >= 0:
            ln = ln[:hash]
        ln = trimSpace(ln)
        if len(ln) == 0:
            continue
        arrow = 0 - 1
        j = 0
        while j + 2 <= len(ln):
            if ln[j:j + 2] == ""->"":
                pre = j > 0 and (ln[j - 1:j] == "" "" or ln[j - 1:j] == ""\t"")
                post = j + 2 < len(ln) and (ln[j + 2:j + 3] == "" "" or ln[j + 2:j + 3] == ""\t"")
                if pre and post:
                    arrow = j
                    break
            j = j + 1
        if arrow < 0:
            arrow = indexOfSub(ln, ""->"")
        if arrow < 0:
            sys.exit({""ok"": False})
        pat = trimSpace(ln[:arrow])
        rest = trimSpace(ln[arrow + 2:len(ln)])
        term = False
        if len(rest) > 0 and rest[0:1] == ""."":
            term = True
            rest = rest[1:len(rest)]
        rep = rest
        rules = rules + [{""pat"": pat, ""rep"": rep, ""term"": term}]
    sys.exit({""ok"": True, ""rules"": rules})
",tests/rosetta/transpiler/Python/execute-a-markov-algorithm.py,,0,0.9999962733604392,"The method 'parseRules' is likely to be deleted because it contains several issues that make it inefficient and potentially problematic. Firstly, it uses a custom function 'indexOfSub' which is not defined within the code, making it unclear how it operates. Secondly, the method uses 'sys.exit' to terminate the program, which is not a good practice for a function that is supposed to parse and return data. Instead, it should return the parsed rules or raise an exception if something goes wrong. Additionally, the code uses a non-standard way of handling strings and spaces, which could be simplified using Python's built-in string methods. These issues suggest that the method is not well-designed and may be replaced or removed in favor of a more robust solution."
survived,"def pollardRho(n, c):
    def g(x, y):
        x2 = x * x
        x2 = x2 + c
        return x2 % y
    x = 2
    y = 2
    z = 1
    d = 0
    count = 0
    while True:
        x = g(x, n)
        y = g(g(y, n), n)
        d = absBig(x - y)
        d = d % n
        z = z * d
        count = count + 1
        if count == 100:
            d = gcd(z, n)
            if d != one:
                break
            z = one
            count = 0
    if d == n:
        sys.exit(zero)
    sys.exit(d)
",tests/rosetta/transpiler/Python/euclid-mullin-sequence.py,,0,0.9999999990263799,"The method is likely to be deleted because it contains several issues that make it non-functional and potentially problematic. Firstly, the function uses undefined variables such as 'absBig', 'gcd', 'one', 'zero', and 'sys', which would cause runtime errors. Additionally, the logic for the Pollard's Rho algorithm is not correctly implemented, as it should not use 'sys.exit' for returning values, and the loop structure is flawed. These issues suggest that the code is not ready for production use and would likely be removed or significantly revised."
survived,"def run(code):
    acc = 0
    i = 0
    while i < len(code):
        ch = code[i:i + 1]
        if ch == ""H"":
            print(""Hello, World!"")
        else:
            if ch == ""Q"":
                print(code)
            else:
                if ch == ""9"":
                    sing99()
                else:
                    if ch == ""+"":
                        acc = acc + 1
        i = i + 1
",tests/rosetta/transpiler/Python/execute-hq9+.py,,1,1.1253518384332553e-07,"The method 'run' is a simple interpreter for a subset of the esoteric programming language 'HQ9+'. It processes a string of commands and performs specific actions based on the characters 'H', 'Q', '9', and '+'. The method is functional and correctly implements the intended behavior of the language. It is unlikely to be deleted as it serves a clear purpose and is correctly implemented."
survived,"def else1(i, f):
    if i.cond1 and (i.cond2 == False):
        f()
    return i
",tests/rosetta/transpiler/Python/extend-your-language.py,,1,2.646573631904765e-09,"The method 'else1' is a simple utility function that checks two conditions on an object 'i' and calls a function 'f' if those conditions are met. It then returns the object 'i'. This kind of utility function is common in codebases for handling specific conditional logic and is unlikely to be deleted unless it is completely unused or replaced by a more efficient or clearer implementation. Since the function serves a clear purpose and is not overly complex, it is more likely to survive."
survived,"def padLeft(n, width):
    s = str(n)
    while len(s) < width:
        s = "" "" + s
    return s
",tests/rosetta/transpiler/Python/erd-s-selfridge-categorization-of-primes.py,,1,2.8453347280241004e-08,"The method 'padLeft' is a simple utility function that pads a given number with spaces on the left to ensure it reaches a specified width. This type of function is commonly used in formatting outputs, especially in console applications or when generating reports. It is a basic and useful function that serves a clear purpose, and there are no obvious issues with its implementation. Therefore, it is likely to be retained in the codebase."
survived,"def double(i):
    return i * 2
",tests/rosetta/transpiler/Python/ethiopian-multiplication.py,,1,3.2241866333029355e-08,The method 'double' is a simple and commonly used utility function that doubles the input value. Such functions are often retained in codebases because they encapsulate a basic operation that can be reused in various parts of a program. It is unlikely to be deleted unless it is completely unused or redundant due to similar existing functionality.
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/eulers-identity.py,,1,6.144172127844639e-06,"The method '_now' is a utility function that generates a pseudo-random number based on a global seed if '_now_seeded' is True, otherwise it returns the current time in nanoseconds. This function is not a standard or widely used method, and its utility is very specific to the context where it is used. Without additional context, it is difficult to determine its necessity. However, given that it provides a specific functionality (random number generation or time retrieval), it is likely to be retained if it serves a purpose in the codebase. Therefore, it is more likely to survive unless the project undergoes significant refactoring or the functionality is no longer needed."
survived,"def powInt(b, p):
    r = 1
    i = 0
    while i < p:
        r = r * b
        i = i + 1
    return r
",tests/rosetta/transpiler/Python/exponentiation-order.py,,0,0.9999995549151272,"The method 'powInt' is a basic implementation of calculating the power of a number using a loop. However, Python already has a built-in operator '**' and a function 'pow()' that perform this operation more efficiently and concisely. The method lacks error handling for negative powers and non-integer inputs, which are handled by the built-in functions. Given these factors, the method is likely to be considered redundant and unnecessary in most practical applications, leading to its deletion."
survived,"def primeFactors(n, primes):
    factors = []
    num = n
    i = 0
    while i < len(primes) and primes[i] * primes[i] <= num:
        p = primes[i]
        while num % p == 0:
            factors = factors + [p]
            num = num / p
        i = i + 1
    if num > 1:
        factors = factors + [num]
    return factors
",tests/rosetta/transpiler/Python/erd-s-selfridge-categorization-of-primes.py,,1,1.2501528648238603e-09,"The method 'primeFactors' is likely to survive because it performs a fundamental mathematical operation of finding the prime factors of a given number 'n' using a list of prime numbers 'primes'. The implementation is straightforward and efficient for its purpose, iterating over the list of primes and dividing the number until it is no longer divisible by the current prime. The method also handles the case where the remaining number is a prime itself. Such utility functions are commonly used in mathematical computations and number theory applications, making them valuable in various contexts."
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    k = 19
    print(""First "" + str(k) + "" terms of the Euclidâ€“Mullin sequence:"")
    print(2)
    prod = 2
    count = 1
    while count < k:
        z = prod + one
        t = smallestPrimeFactor(z)
        print(t)
        prod = prod * t
        count = count + 1
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/euclid-mullin-sequence.py,,0,0.9999999804443193,"The method is likely to be deleted because it contains several issues that suggest it is either incomplete or not functioning as intended. For instance, the variable 'one' is not defined, which will cause a runtime error. Additionally, the function 'smallestPrimeFactor' is called but not defined within the code, indicating that the code is not self-contained or complete. These issues suggest that the method is not ready for production use and may be removed or significantly revised."
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    data = fs.get(""input.txt"")
    fs[""output.txt""] = data
    print(fs.get(""output.txt""))
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/file-input-output-1.py,,0,0.9999994956527347,"The method is likely to be deleted (0) because it contains several issues that make it unsuitable for production use. Firstly, it uses a non-standard 'fs' object for file operations without any context or definition, which suggests it might be part of a larger, possibly proprietary or incomplete framework. Secondly, the method lacks error handling for file operations, which is critical for robustness. Thirdly, the use of resource and time measurement is not well integrated or explained, making the code difficult to maintain or extend. These factors suggest that the method is more of a placeholder or a prototype rather than a finalized, reliable piece of code."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/faulhabers-triangle.py,,1,4.944450477491054e-09,"The method '_now' is a utility function that generates a pseudo-random number based on a global seed if '_now_seeded' is True, otherwise it returns the current time in nanoseconds. This function is not directly related to any specific business logic or application functionality, making it a general-purpose utility. Such utility functions are often retained as they can be useful in various contexts, especially for testing or simulating time-dependent behavior. Therefore, it is likely to survive."
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    n = 10
    print("" Fibonacci: "" + show(gen([1, 1], n)))
    print(""Tribonacci: "" + show(gen([1, 1, 2], n)))
    print(""Tetranacci: "" + show(gen([1, 1, 2, 4], n)))
    print(""     Lucas: "" + show(gen([2, 1], n)))
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/fibonacci-n-step-number-sequences.py,,1,2.998960815863541e-09,"The method 'main' is a typical entry point for a Python script, and it includes functionality to benchmark memory usage and execution time, which is useful for performance analysis. It also demonstrates the generation of various sequences (Fibonacci, Tribonacci, Tetranacci, and Lucas), which are common mathematical sequences. The method is well-structured and serves a clear purpose, making it unlikely to be deleted unless the entire script is being refactored or removed. Therefore, it is more likely to survive."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/events.py,,1,5.3157849718487075e-08,"The method '_now' is a utility function that generates a pseudo-random number based on a global seed if '_now_seeded' is True, otherwise it returns the current time in nanoseconds. This method is likely to be retained because it provides a useful functionality for generating time-based or seeded random numbers, which can be useful in various applications such as testing, simulations, or time-stamping. The method is simple, does not have any apparent bugs, and serves a clear purpose."
survived,"def test_create_sse_app_sets_state():
    server = FastMCP(name=""StateTest"")
    app = create_sse_app(server, message_path=""/message"", sse_path=""/sse"")
    assert app.state.fastmcp_server is server",tests/server/test_app_state.py,,1,4.1399375473943306e-08,"The method `test_create_sse_app_sets_state` is a unit test function that checks if the `create_sse_app` function correctly sets the `fastmcp_server` attribute in the application's state. This is a typical and necessary test to ensure that the application is configured correctly, especially when dealing with server instances and state management. Unit tests are crucial for maintaining code quality and reliability, and this test serves a clear purpose in verifying the behavior of the `create_sse_app` function. Therefore, it is unlikely to be deleted as it contributes to the robustness of the codebase."
survived,"def test_sqlalchemy_lifespan_cleanup(tmp_path):
    db = tmp_path / ""db.sqlite""
    engine = create_async_engine(f""sqlite+aiosqlite:///{db}"")

    lifespan = sqlalchemy_lifespan(Base, engine, cleanup_db_file=True)
    app = EnrichMCP(""Test"", ""Desc"")

    async def run():
        async with lifespan(app) as ctx:
            session_factory = ctx[""session_factory""]
            async with session_factory() as session:
                await session.execute(text(""SELECT 1""))

    import asyncio

    asyncio.run(run())

    assert not db.exists()",tests/test_sqlalchemy_autogen_extra.py,,1,2.2159489282323004e-08,"The method 'test_sqlalchemy_lifespan_cleanup' is a test function that verifies the cleanup functionality of a database file after its use. It uses an asynchronous context manager to ensure that the database file is deleted after the test is run. This is a typical pattern in testing to ensure resources are properly cleaned up, and it is unlikely to be deleted unless the functionality it tests is no longer relevant or the testing framework changes significantly. Therefore, it is more likely to survive."
survived,"    def fake_import(name, globals=None, locals=None, fromlist=(), level=0):
        if name == missing:
            raise ModuleNotFoundError(name)
        return orig_import(name, globals, locals, fromlist, level)
",tests/test_agents_fallback.py,,1,3.1201906230699086e-05,"The method 'fake_import' is a custom implementation of the import mechanism, which raises a ModuleNotFoundError if a specific module ('missing') is attempted to be imported. This kind of functionality can be useful for testing purposes or for creating mock environments where certain modules are intentionally unavailable. However, the method relies on a variable 'missing' that is not defined within the method, which could lead to errors unless 'missing' is defined elsewhere in the code. Additionally, 'orig_import' is used but not defined in the provided code snippet, suggesting that it should be a reference to the original import function. Without these definitions, the method might not function correctly. Despite these issues, the method itself is a valid approach to customizing import behavior, which can be useful in certain contexts. Therefore, it is likely to survive if the surrounding code context is properly set up."
survived,"def test_devicon_directory_match():
    file = MockFile('Documents', is_directory=True)
    assert devicons.devicon(file) == 'ï'
",tests/test_devicons.py,,1,1.6052280526088547e-09,"The method `test_devicon_directory_match` is a unit test that checks if the `devicons.devicon` function correctly identifies a directory and returns the appropriate icon. Unit tests are crucial for ensuring code reliability and correctness, especially in larger projects. They help catch bugs early and ensure that changes do not break existing functionality. Therefore, this method is likely to be retained as part of the test suite to maintain code quality."
survived,"def test_get_context_propagates_errors():
    app = EnrichMCP(""Test API"", description=""desc"")

    with (
        patch.object(app.mcp, ""get_context"", side_effect=RuntimeError(""boom"")),
        pytest.raises(RuntimeError),
    ):
        app.get_context()",tests/test_core.py,,1,6.348800075736417e-09,"The method `test_get_context_propagates_errors` is a unit test designed to verify that the `get_context` method of the `app.mcp` object correctly propagates errors by raising a `RuntimeError`. This is a standard practice in testing to ensure that error handling is functioning as expected. Since this is a test method, it is unlikely to be deleted as it serves a crucial role in maintaining the robustness of the code by ensuring that exceptions are properly handled and propagated. Therefore, the method will survive."
survived,"    def resources(self) -> RayResources:
        return RayResources(cpu=1)
",marin/rl/envs/math_env.py,MathEnvConfig,1,4.0586521248284276e-10,"The method 'resources' is a simple method that returns a 'RayResources' object with a specified CPU allocation. This kind of method is typically used in resource management or scheduling contexts, such as in distributed computing frameworks like Ray. Given its simplicity and clear purpose, it is unlikely to be deleted unless the entire resource management approach is refactored or the 'RayResources' class itself is deprecated. Therefore, the method is likely to survive."
survived,"    def sink(groups):  # type: ignore[override]
        collected.extend(groups)
",tests/rl/test_math_env.py,,1,3.850741907939403e-09,"The method 'sink' is a simple function that takes an argument 'groups' and extends a list 'collected' with it. The function is straightforward and does not contain any complex logic or errors that would necessitate its deletion. Additionally, the use of 'type: ignore[override]' suggests that the developer is intentionally overriding a type check, which is a common practice when the developer is confident about the correctness of the code. Therefore, it is likely that this method will survive."
survived,"    def resources(self) -> RayResources:
        return RayResources(cpu=1)
",marin/rl/envs/openai_echo.py,ChatEchoEnvConfig,1,1.6052280526088547e-09,"The method 'resources' is a simple function that returns a 'RayResources' object with a CPU allocation of 1. This method is likely part of a larger system that manages resource allocation for tasks or jobs, possibly in a distributed computing environment like Ray. The method is straightforward and serves a clear purpose, which is to specify the resource requirements for a task. Unless there is a significant change in how resources are managed or allocated in the system, this method is likely to survive as it provides essential functionality."
survived,"async def discover_alpha(domain: str = ""finance"") -> str:
    return await identify_alpha(domain)
",alpha_factory_v1/demos/aiga_meta_evolution/workflow_demo.py,,1,1.3709566550544279e-06,"The method 'discover_alpha' is a simple asynchronous function that calls another function 'identify_alpha' with a default parameter. The function itself is not complex and serves a clear purpose of delegating the task to 'identify_alpha'. Without additional context on the usage or the implementation of 'identify_alpha', it's difficult to determine if this method is redundant or unnecessary. However, given that it provides a clear interface for discovering alpha in a specified domain, it is likely to be useful in contexts where such functionality is needed. Therefore, it is more likely to be retained unless the functionality is completely replaced or deemed unnecessary in the future."
survived,"    def set_env_var(self, key: str, value: str) -> None:
        """"""Helper to track environment variable overrides.""""""
        os.environ[key] = value
        self.env_vars[key] = value
",tests/test_alpha_opportunity_env.py,TestAlphaOpportunityEnv,1,9.736200303530205e-10,"The method 'set_env_var' is a utility function that sets an environment variable and tracks it in a dictionary. This is a common and useful functionality in many applications, especially those that need to manage configuration settings dynamically. The method is simple, clear, and serves a specific purpose without any apparent issues or redundancies. Therefore, it is likely to be retained in the codebase."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/bitmap-midpoint-circle-algorithm.py,,1,2.5109990926928157e-08,"The method `_now()` is a utility function that generates a pseudo-random number based on a seed if `_now_seeded` is True, otherwise it returns the current time in nanoseconds. This function is likely to be useful in scenarios where a consistent pseudo-random number generation is needed, or where the current time in nanoseconds is required. The function is simple, has a clear purpose, and does not have any obvious issues or redundancies that would warrant its deletion. Therefore, it is likely to be retained in the codebase."
survived,"def padStart(s, width, pad):
    out = s
    while len(out) < width:
        out = pad + out
    return out
",tests/rosetta/transpiler/Python/bernoulli-numbers.py,,1,3.850741907939403e-09,"The method 'padStart' is a utility function that adds padding to the start of a string until it reaches a specified width. This is a common requirement in formatting strings for display purposes, such as aligning text in tables or logs. The method is simple, effective, and does not rely on any external libraries, making it a useful addition to a codebase. Therefore, it is likely to be retained."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/blum-integer.py,,1,1.955568070542584e-08,"The method `_now()` is a utility function that generates a pseudo-random number based on a global seed if `_now_seeded` is True, otherwise it returns the current time in nanoseconds. This function is likely part of a larger system that requires either a random number or a timestamp, depending on the state of `_now_seeded`. Such utility functions are common in systems that need to simulate time or generate random numbers for testing or other purposes. The function is simple, serves a clear purpose, and does not have any obvious issues or redundancies that would necessitate its removal. Therefore, it is likely to be retained in the codebase."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/bioinformatics-sequence-mutation.py,,1,2.8453347280241004e-08,"The method `_now()` is a utility function that generates a pseudo-random number based on a global seed if it is set, or returns the current time in nanoseconds if not. This kind of function can be useful in scenarios where deterministic behavior is needed for testing or simulation purposes, by seeding the random number generator. The function is simple, has a clear purpose, and does not have any obvious issues or redundancies that would warrant its deletion. Therefore, it is likely to be retained in the codebase."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/convert-seconds-to-compound-duration.py,,1,2.8453347280241004e-08,"The method _now() is a utility function that generates a pseudo-random number based on a seed if _now_seeded is True, or returns the current time in nanoseconds if not. This kind of function can be useful in scenarios where deterministic pseudo-random numbers are needed for testing or simulation purposes. The function is simple, has a clear purpose, and does not have any obvious issues or redundancies that would warrant its deletion. Therefore, it is likely to be retained in the codebase."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/conditional-structures-2.py,,1,1.275190675769241e-07,"The method `_now()` is a utility function that generates a pseudo-random number based on a seed if `_now_seeded` is True, or returns the current time in nanoseconds otherwise. This function is likely part of a larger system that requires a consistent and repeatable sequence of numbers for testing or simulation purposes when seeded, and real-time timestamps otherwise. Such utility functions are common in software development for testing and simulation, and they provide useful functionality. Therefore, it is likely to be retained in the codebase."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/conways-game-of-life.py,,1,2.5109990926928157e-08,"The method `_now()` is a utility function that generates a pseudo-random number based on a global seed if `_now_seeded` is True, otherwise it returns the current time in nanoseconds. This function is likely part of a larger system that requires a consistent and repeatable pseudo-random number generation when seeded, which can be useful for testing or simulations. The function is simple, serves a clear purpose, and does not have any apparent issues or redundancies that would necessitate its removal. Therefore, it is likely to be retained in the codebase."
survived,"def test_start_stop_logging(caplog: Any) -> None:
    """"""Bus start and stop should emit informative log messages.""""""
    bus = messaging.A2ABus(config.Settings(bus_port=0, broker_url=""kafka:9092""))

    async def run() -> None:
        await bus.start()
        await bus.stop()

    with caplog.at_level(logging.INFO):
        asyncio.run(run())

    messages = [record.getMessage() for record in caplog.records]
    assert any(""A2ABus.start()"" in m for m in messages)
    assert any(""A2ABus.stop()"" in m for m in messages)",tests/test_messaging.py,,1,9.237449576640118e-09,"The method `test_start_stop_logging` is a test function that verifies the logging behavior of the `A2ABus` class when it starts and stops. It uses the `caplog` fixture to capture log messages and asserts that specific log messages are emitted. This is a typical pattern in testing to ensure that certain actions produce the expected log output, which is important for debugging and monitoring purposes. Since this is a test function that serves a clear purpose in verifying the functionality of logging, it is likely to be retained in the codebase."
survived,"def test_research_agent_adapters_invoked(monkeypatch) -> None:
    from alpha_factory_v1.demos.alpha_agi_insight_v1.src.utils import config, messaging
    from alpha_factory_v1.demos.alpha_agi_insight_v1.src.agents import research_agent

    class DummyLedger:
        def __init__(self, *_a, **_kw) -> None:
            pass

        def log(self, _env) -> None:  # type: ignore[override]
            pass

        def start_merkle_task(self, *_a, **_kw) -> None:
            pass

        async def stop_merkle_task(self) -> None:
            pass

        def close(self) -> None:
            pass

    settings = config.Settings(bus_port=0)
    bus = messaging.A2ABus(settings)
    agent = research_agent.ResearchAgent(bus, DummyLedger())

    adk_mock = type(""A"", (), {""heartbeat"": lambda self: None})()
    mcp_mock = type(""M"", (), {""heartbeat"": lambda self: None})()
    monkeypatch.setattr(agent, ""adk"", adk_mock, raising=False)
    monkeypatch.setattr(agent, ""mcp"", mcp_mock, raising=False)
    with patch.object(adk_mock, ""heartbeat"") as adk_hb, patch.object(mcp_mock, ""heartbeat"") as mcp_hb:
        asyncio.run(agent.run_cycle())
        adk_hb.assert_called_once()
        mcp_hb.assert_called_once()",tests/test_agents.py,,1,5.3157849718487075e-08,The method is a test function that uses monkeypatching to replace certain components with mock objects and then verifies that specific methods are called. This is a common practice in unit testing to ensure that the code behaves as expected. The function is well-structured for its purpose and does not contain any deprecated or redundant elements that would warrant deletion. It is likely to be maintained as part of the test suite to ensure the reliability of the 'research_agent' functionality.
survived,"    def __init__(self) -> None:
        import importlib

        mcp = importlib.import_module(""mcp"")
        self._group = mcp.ClientSessionGroup()
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/mcp_adapter.py,MCPAdapter,1,1.8553915987649156e-07,"The method is a constructor (__init__) for a class, which is a fundamental part of object-oriented programming in Python. Constructors are essential for initializing new objects and setting up initial states. The code imports a module and initializes an instance variable, which is typical behavior for a constructor. There is no indication of redundancy or obsolescence in this code snippet, so it is likely to be retained."
survived,"def _wait_results(
    url: str,
    sim_id: str,
    headers: dict[str, str],
    proc: subprocess.Popen[str],
    max_attempts: int = 60,
) -> dict[str, object]:
    delay = 0.05
    for _ in range(max_attempts):
        if proc.poll() is not None:
            output = proc.stdout.read() if proc.stdout else """"
            raise AssertionError(f""server exited with {proc.returncode}:\n{output}"")
        r = httpx.get(f""{url}/results/{sim_id}"", headers=headers)
        if r.status_code == 200:
            return r.json()
        time.sleep(delay)
        delay = min(delay * 1.5, 1.0)
    output = proc.stdout.read() if proc.stdout else """"
    raise AssertionError(f""results not ready\n{output}"")
",tests/test_api_server_subprocess.py,,1,1.8189616842444243e-09,"The method '_wait_results' is a utility function that waits for results from a server by repeatedly polling a URL. It handles subprocess termination and HTTP response checking, which are common tasks in asynchronous or distributed systems. The method is well-structured, with configurable parameters like 'max_attempts' and 'delay', making it flexible for different use cases. Such utility functions are often essential in systems that require synchronization between processes or services, and they are unlikely to be deleted unless the entire system architecture changes significantly. Therefore, it is more likely to survive."
survived,"def slugify(name: str) -> str:
    """"""Return a filesystem-friendly slug for ``name``.""""""
    slug = re.sub(r""[^A-Za-z0-9]+"", ""-"", name)
    return slug.strip(""-"").lower()
",generate_pdf_pages.py,,1,6.348800075736417e-09,"The method 'slugify' is a utility function that converts a given string into a 'slug', which is a URL or filesystem-friendly version of the string. This is a common requirement in web development and file management to ensure that names are safe for use in URLs or as filenames. The function uses regular expressions to replace non-alphanumeric characters with hyphens and converts the string to lowercase, which is a standard approach for slugification. Given its utility and the fact that it is implemented correctly, it is likely to be retained in the codebase."
survived,"  async def stop(self):
    """"""Stop the temperature controller and close the backend connection.""""""
    await self.deactivate()
    await super().stop()
",pylabrobot/temperature_controlling/temperature_controller.py,TemperatureController,1,1.0467401685178159e-08,"The method 'stop' is an asynchronous function that is responsible for stopping the temperature controller and closing the backend connection. It calls 'deactivate', which is likely a method to safely shut down or deactivate the controller, and then calls 'super().stop()' to ensure any additional stopping procedures defined in the superclass are executed. This method is crucial for resource management and ensuring that the system is properly shut down, which is important in preventing resource leaks or other issues. Therefore, it is likely to be retained in the codebase."
survived,"    def execute(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        k = payload.get(""k"") or 3
        analogies = [
            {""domain"": d, ""analogy"": f""{payload['problem']} ~ {d}""}
            for d in (payload.get(""seed_domains"") or [""math"", ""biology"", ""art""])[:k]
        ]
        prompts = [f""How would {a['domain']} approach it?"" for a in analogies]
        return {
            ""analogies"": analogies,
            ""suggested_prompts"": prompts,
        }",servers/server_clear_thought/tools/analogical_mapper.py,AnalogicalMapper,1,2.646573631904765e-09,"The method 'execute' is well-structured and serves a clear purpose: generating analogies and prompts based on a given problem and seed domains. It uses default values effectively and handles optional input gracefully. The method is likely to be useful in contexts where creative problem-solving or cross-domain thinking is encouraged. There are no apparent issues with the logic or implementation that would necessitate its deletion. Therefore, it is likely to be retained."
survived,"def random_confidences(n: int) -> List[float]:
    return [round(random.uniform(0.5, 1.0), 2) for _ in range(n)]",servers/server_clear_thought/core/utils.py,,1,1.8189616842444243e-09,"The method `random_confidences` generates a list of random float numbers between 0.5 and 1.0, rounded to two decimal places. This functionality is straightforward and useful in scenarios where random confidence scores are needed, such as in simulations or testing machine learning models. The method is simple, efficient, and does not have any apparent issues or redundancies that would warrant its deletion. Therefore, it is likely to be retained."
survived,"        async def policy(self, *_: object) -> object:
            return None
",alpha_factory_v1/demos/muzero_planning/agent_muzero_entrypoint.py,Agent,0,0.999999057755336,"The method 'policy' is an asynchronous function that takes any number of arguments but does not use them, and it returns None. This suggests that the method currently does not perform any meaningful operation. If this method is part of a larger codebase, it might be a placeholder for future implementation. However, if it remains unchanged and unused, it is likely to be deleted in the future as it does not contribute any functionality."
survived,"    def summary_line(self) -> str:
        """"""Return a one-line summary of collected metrics.""""""
        return (
            f""Telemetry: cost=${self.cost:.2f} ""
            f""tokens={self.token_count} ""
            f""latency={self.latency:.2f}s ""
            f""guardrails={self.guardrail_hits}""
        )",src/meta_agent/telemetry.py,TelemetryCollector,1,1.1861120010657661e-08,"The method 'summary_line' is a concise and useful utility function that formats and returns a summary string of various metrics. It is well-structured, easy to understand, and provides a clear output that can be used for logging or display purposes. Such methods are typically retained in codebases as they encapsulate functionality that is likely to be reused or needed for monitoring and reporting purposes."
survived,"async def test_send_retry_failure():
    with patch(""aiohttp.ClientSession"") as mock_session:
        resp = AsyncMock()
        resp.status = 500
        resp.text = AsyncMock(return_value=""bad"")
        cm = AsyncMock()
        cm.__aenter__.return_value = resp
        mock_session.return_value.post.return_value = cm
        mock_session.return_value.close = AsyncMock()

        client = TelemetryAPIClient(
            {""trace"": EndpointConfig(""http://example.com"")}, retries=1, backoff=0
        )
        with pytest.raises(Exception):
            await client.send(""trace"", {""d"": 1})
        assert mock_session.return_value.post.call_count == 2
        await client.close()",tests/unit/test_telemetry_client.py,,1,1.725782769012759e-08,"The method 'test_send_retry_failure' is a unit test designed to verify the retry logic of the 'TelemetryAPIClient' when a request fails with a 500 status code. It uses mocking to simulate the behavior of the 'aiohttp.ClientSession' and checks if the client retries the request once before raising an exception. This is a valid and useful test case for ensuring the robustness of the retry mechanism in the client. Therefore, it is likely to be retained in the codebase."
survived,"    def close(self) -> None:
        self.conn.close()",src/meta_agent/telemetry_db.py,TelemetryDB,1,6.023574641292144e-08,"The method 'close' is a straightforward implementation that calls the 'close' method on a connection object 'self.conn'. This is a common pattern in resource management, especially for database connections or file handles, to ensure that resources are properly released when they are no longer needed. Such methods are essential for preventing resource leaks and maintaining application stability. Therefore, it is unlikely to be deleted as it serves a critical function in resource management."
survived,"def test_has_network_with_proxy(monkeypatch: pytest.MonkeyPatch) -> None:
    """"""Ensure proxy variables are consulted for connectivity.""""""

    attempts: list[tuple[str, int]] = []

    class _Sock:
        def __enter__(self) -> ""_Sock"":
            return self

        def __exit__(self, *exc: object) -> None:
            pass

    def _connect(addr: tuple[str, int], timeout: float = 1.0) -> _Sock:
        attempts.append(addr)
        if addr[0] == ""proxy.local"":
            return _Sock()
        raise OSError

    monkeypatch.setenv(""HTTP_PROXY"", ""http://proxy.local:8080"")
    monkeypatch.setenv(""HTTPS_PROXY"", ""http://proxy.local:8080"")
    monkeypatch.setattr(check_env.socket, ""create_connection"", _connect)  # type: ignore[attr-defined]
    assert check_env.has_network() is True
    assert attempts[0] == (""proxy.local"", 8080)
",tests/test_check_env_network.py,,1,3.2241866333029355e-08,"The method 'test_has_network_with_proxy' is a unit test that verifies the functionality of a network connectivity check using proxy settings. It uses the 'monkeypatch' fixture from pytest to modify environment variables and mock socket connections. This is a common practice in testing to ensure that code behaves correctly under different configurations. Since testing is a crucial part of software development and this method is well-structured for its purpose, it is likely to be retained in the codebase."
survived,"def test_has_network_head_fallback(monkeypatch: pytest.MonkeyPatch) -> None:
    """"""Use urllib as fallback when socket connections fail.""""""

    def _connect(_addr: tuple[str, int], timeout: float = 1.0) -> None:
        raise OSError

    called: list[str] = []

    class _Resp:
        def __enter__(self) -> ""_Resp"":
            return self

        def __exit__(self, *exc: object) -> None:
            pass

    def _urlopen(req: object, timeout: float = 1.0) -> _Resp:
        called.append(getattr(req, ""full_url"", """"))
        return _Resp()

    monkeypatch.setenv(""HTTP_PROXY"", ""http://proxy.local:3128"")
    monkeypatch.setenv(""HTTPS_PROXY"", ""http://proxy.local:3128"")
    monkeypatch.setattr(check_env.socket, ""create_connection"", _connect)  # type: ignore[attr-defined]
    monkeypatch.setattr(urllib.request, ""urlopen"", _urlopen)
    assert check_env.has_network() is True
    assert called and called[0].startswith(""https://"")",tests/test_check_env_network.py,,1,1.0467401685178159e-08,"The method is a test function that uses the `monkeypatch` fixture from `pytest` to modify the behavior of network-related functions for testing purposes. It is designed to ensure that the `check_env.has_network()` function can fall back to using `urllib` when direct socket connections fail. This is a common pattern in testing to simulate network conditions and verify fallback mechanisms. Such test functions are typically retained as they are crucial for ensuring the robustness of network-related code. Therefore, it is likely to survive."
survived,"def binString(op, l, r):
    ls = exprString(l)
    rs = exprString(r)
    opstr = """"
    if op == OP_ADD:
        opstr = "" + ""
    else:
        if op == OP_SUB:
            opstr = "" - ""
        else:
            if op == OP_MUL:
                opstr = "" * ""
            else:
                opstr = "" / ""
    return ""("" + ls + opstr + rs + "")""
",tests/rosetta/transpiler/Python/24-game-solve.py,,1,2.4616969512093895e-10,"The method 'binString' is a utility function that converts a binary operation into a string representation. It is a straightforward and useful function for generating human-readable expressions from binary operations, which is a common requirement in many programming tasks, such as debugging, logging, or displaying expressions in a user interface. The method is well-structured and performs its task efficiently, making it unlikely to be deleted unless the entire codebase undergoes a significant refactor or the functionality is no longer needed. Therefore, it is predicted to survive."
survived,"def insert_back_link(pages: Iterable[Path]) -> None:
    """"""Ensure a 'Back to Gallery' link exists in each HTML page.""""""
    for page in pages:
        if not page.is_file():
            continue
        text = page.read_text(encoding=""utf-8"")
        if ""Back to Gallery"" in text:
            continue
        rel = Path(os.path.relpath(GALLERY_FILE, page.parent)).as_posix()
        link = f'<p><a href=""{rel}"">\u2b05\ufe0f Back to Gallery</a></p>'
        lines = text.splitlines()
        inserted = False
        for i, line in enumerate(lines):
            if ""assets/style.css"" in line:
                lines.insert(i, link)
                inserted = True
                break
        if not inserted:
            for i, line in enumerate(lines):
                if ""</body>"" in line.lower():
                    lines.insert(i, link)
                    inserted = True
                    break
        if not inserted:
            lines.append(link)
        page.write_text(""\n"".join(lines) + ""\n"", encoding=""utf-8"")
",scripts/generate_gallery_html.py,,1,5.60279640614594e-09,"The method 'insert_back_link' is likely to survive because it performs a useful and specific function: ensuring that a 'Back to Gallery' link is present in each HTML page. This is a common requirement for web navigation, and the method is implemented in a way that checks for existing links, determines the correct relative path, and inserts the link in a logical place within the HTML. The method is also robust, handling cases where the link needs to be inserted at different points in the HTML structure. These factors make it a valuable utility function in web development contexts."
survived,"def test_joins_octal_escape():
    s_in = """"""'\\40'.join(['a', 'b'])""""""
    expected_out = '""a\\40b""'
    out, count = code_editor.fstringify_static_joins(s_in, State())
    assert count > 0
    assert out == expected_out",test/test_edits.py,,1,2.8453347280241004e-08,"The method `test_joins_octal_escape` is a unit test designed to verify the functionality of the `fstringify_static_joins` method from the `code_editor` module. It checks if the method correctly processes a string with octal escape sequences. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with string manipulations and escape sequences. Therefore, this method is likely to be retained as it serves an important role in maintaining the integrity of the codebase."
survived,"def meta_rewrite(agents: List[int]) -> List[int]:
    """"""Return a modified copy of ``agents`` with a small random change.""""""
    new_agents = list(agents)
    idx = random.randrange(len(new_agents))
    new_agents[idx] += random.choice([-1, 1])
    return new_agents
",alpha_factory_v1/demos/meta_agentic_tree_search_v0/mats/meta_rewrite.py,,1,9.237449576640118e-09,"The method 'meta_rewrite' is a simple utility function that takes a list of integers, makes a small random change to one of the elements, and returns the modified list. This type of function is often useful in scenarios where slight variations are needed, such as in simulations, genetic algorithms, or testing. The function is straightforward, has a clear purpose, and is likely to be useful in various contexts. Therefore, it is likely to be retained."
survived,"async def _decode_byte_stream_async(
    byte_iterator: Iterable[bytes],
    encoding: EncodingType = 'utf-8',
    errors: str = 'replace',
    buffer_size: int = 8192
) -> AsyncGenerator[str, None]:
    """"""Asynchronous version of :func:`_decode_byte_stream`.""""""
    try:
        decoder = codecs.getincrementaldecoder(encoding)(errors=errors)
    except LookupError:
        decoder = codecs.getincrementaldecoder('utf-8')(errors=errors)

    buffer = bytearray(buffer_size)
    buffer_view = memoryview(buffer)

    async for chunk_bytes in byte_iterator:
        if not chunk_bytes:
            continue
        try:
            if len(chunk_bytes) <= buffer_size:
                buffer[:len(chunk_bytes)] = chunk_bytes
                text = decoder.decode(buffer_view[:len(chunk_bytes)], final=False)
            else:
                text = decoder.decode(chunk_bytes, final=False)
            if text:
                yield text
        except UnicodeDecodeError:
            yield f""[Encoding Error: Could not decode bytes with {encoding}]\n""

    try:
        final_text = decoder.decode(b'', final=True)
        if final_text:
            yield final_text
    except UnicodeDecodeError:
        yield f""[Encoding Error: Could not decode final bytes with {encoding}]\n""
",webscout/AIutel.py,,1,4.0586521248284276e-10,"The method `_decode_byte_stream_async` is a well-structured asynchronous function designed to decode byte streams into strings using a specified encoding. It handles errors gracefully by using a fallback encoding and provides informative error messages when decoding fails. The function is useful in scenarios where asynchronous processing of byte streams is required, such as reading data from a network or file in a non-blocking manner. Given the increasing importance of asynchronous programming in modern applications, this method is likely to be retained for its utility and robustness."
survived,"    async def stop(self) -> None:
        logger.info(
            ""A2ABus.stop() called: port=%s broker=%s"",
            self.settings.bus_port,
            self.settings.broker_url or ""disabled"",
        )
        if self._server:
            await self._server.stop(0)
            self._server = None
        if self._producer:
            await self._producer.stop()
            self._producer = None
        self._handshake_peers.clear()
        self._handshake_failures.clear()
        self._handshake_nonces.clear()",alpha_factory_v1/common/utils/messaging.py,A2ABus,1,7.194132978569833e-09,"The method 'stop' is an essential part of managing the lifecycle of a service or application, especially in asynchronous programming. It ensures that resources are properly released, connections are closed, and the system is left in a clean state. This is crucial for preventing resource leaks and ensuring that the application can be restarted or shut down gracefully. The presence of logging also indicates that this method is important for monitoring and debugging. Therefore, it is unlikely to be deleted."
survived,"    def __init__(self, **data: Any) -> None:  # pragma: no cover - exercised in tests
        super().__init__(**data)
        raw = os.getenv(""AGI_ISLAND_BACKENDS"")
        if raw and not data.get(""island_backends""):
            mapping = {}
            for part in raw.split("",""):
                if ""="" in part:
                    k, v = part.split(""="", 1)
                    mapping[k.strip()] = v.strip()
            if mapping:
                self.island_backends = mapping
        if not self.openai_api_key:
            _log.warning(""OPENAI_API_KEY missing â€“ offline mode enabled"")
            self.offline = True
        if self.offline:
            self.broadcast = False
        if not self.solana_wallet and self.solana_wallet_file:
            try:
                self.solana_wallet = Path(self.solana_wallet_file).read_text(encoding=""utf-8"").strip()
            except Exception as exc:  # pragma: no cover - optional
                _log.warning(""Failed to load wallet file %s: %s"", self.solana_wallet_file, exc)
        if self.bus_cert and self.bus_key:
            if not self.bus_token or self.bus_token == ""change_this_token"":
                raise ValueError(
                    ""AGI_INSIGHT_BUS_TOKEN must be set and cannot be 'change_this_token' when TLS is enabled""
                )
",alpha_factory_v1/common/utils/config.py,Settings,1,8.76424914819242e-08,"The method is a constructor (__init__) for a class, which is a fundamental part of object-oriented programming. It initializes the instance of the class with various configurations and environment variables. The method includes error handling, logging, and conditional logic to set up the instance correctly. These are all essential features for robust software development. Additionally, the use of environment variables and file reading suggests that this method is part of a larger system that relies on external configurations, making it unlikely to be removed without significant refactoring."
survived,"def init_config(env_file: str = "".env"") -> None:
    """"""Load environment variables and refresh :data:`CFG`.""""""

    _load_dotenv(env_file)
    _prefetch_vault()
    global CFG
    CFG = Settings()
",alpha_factory_v1/common/utils/config.py,,1,1.955568070542584e-08,"The method `init_config` is a utility function designed to load environment variables from a specified file and refresh a global configuration object `CFG`. This is a common pattern in applications that require configuration management, especially in environments where different settings are needed for development, testing, and production. The method is useful for initializing application settings and is likely to be used frequently in the codebase. Therefore, it is unlikely to be deleted as it serves a critical role in configuration management."
survived,"def _load_model(cfg: Settings | None = None) -> None:
    """"""Load a local model if available, otherwise use an echo stub.""""""
    global _MODEL, _CALL
    cfg = cfg or config.CFG
    model_path = os.getenv(""LLAMA_MODEL_PATH"", cfg.model_name)
    n_ctx = int(os.getenv(""LLAMA_N_CTX"", str(cfg.context_window)))

    def _wrap(fn: Callable[[str, Settings], str]) -> Callable[[str, Settings], str]:
        return fn

    if Llama is not None:
        try:
            _MODEL = Llama(model_path=model_path, n_ctx=n_ctx)

            def call_llama(prompt: str, s: Settings) -> str:
                out = cast(Any, _MODEL)(prompt, temperature=s.temperature)
                return cast(str, out[""choices""][0][""text""]).strip()

            _CALL = _wrap(call_llama)
            return
        except Exception as exc:  # pragma: no cover - model load failure
            _log.warning(""Failed to load Llama model: %s"", exc)
            _MODEL = None
    if AutoModelForCausalLM is not None:
        try:
            _MODEL = AutoModelForCausalLM.from_pretrained(model_path, model_type=""llama"")

            def call_ctrans(prompt: str, s: Settings) -> str:
                return cast(str, cast(Any, _MODEL)(prompt, temperature=s.temperature))

            _CALL = _wrap(call_ctrans)
            return
        except Exception as exc:  # pragma: no cover - model load failure
            _log.warning(""Failed to load ctransformers model: %s"", exc)
            _MODEL = None

    def call_stub(prompt: str, s: Settings) -> str:
        return f""[offline] {prompt}""

    _CALL = _wrap(call_stub)
",alpha_factory_v1/common/utils/local_llm.py,,1,2.2159489282323004e-08,"The method `_load_model` is designed to load a machine learning model, either a Llama model or a ctransformers model, and if neither can be loaded, it defaults to a stub function. This method is crucial for the functionality of any system relying on these models for processing prompts. The method includes error handling and logging, which are good practices for maintaining robustness. Given its importance in initializing the model and providing a fallback mechanism, it is unlikely to be deleted unless the entire system architecture changes significantly. Therefore, it is more likely to survive."
survived,"    def log(self, env: messaging.Envelope) -> None:
        """"""Hash ``env`` and append to the ledger.""""""
        with span(""ledger.log""):
            assert self.conn is not None
            if dataclasses.is_dataclass(env) and not isinstance(env, type):
                record = dataclasses.asdict(env)
            elif isinstance(env, pb.Envelope):
                record = json_format.MessageToDict(env, preserving_proto_field_name=True)
            else:
                record = env.__dict__
            data = json.dumps(record, sort_keys=True).encode()
            digest = blake3(data).hexdigest()
            payload_json = json.dumps(record.get(""payload"", {}))
            if self.db_type == ""postgres"":
                with self.conn, self.conn.cursor() as cur:
                    cur.execute(
                        ""INSERT INTO messages (ts, sender, recipient, payload, hash) VALUES (%s, %s, %s, %s, %s)"",
                        (env.ts, env.sender, env.recipient, payload_json, digest),
                    )
            else:
                with self.conn:
                    self.conn.execute(
                        ""INSERT INTO messages (ts, sender, recipient, payload, hash) VALUES (?, ?, ?, ?, ?)"",
                        (env.ts, env.sender, env.recipient, payload_json, digest),
                    )
",alpha_factory_v1/common/utils/logging.py,Ledger,1,4.944450477491054e-09,"The method 'log' is a crucial part of the system as it handles the logging of messages by hashing the envelope and appending it to a ledger. This is an essential function for maintaining a record of messages, ensuring data integrity, and supporting database operations. The method is well-structured, supports different database types, and uses efficient hashing and serialization techniques. These factors indicate that the method is likely to be retained in the codebase."
survived,"        async def sleeper():
            await asyncio.sleep(0)
",tests/test_api_server_service.py,,1,2.3823698451773172e-07,"The method 'sleeper' is an asynchronous function that uses 'await asyncio.sleep(0)'. This is a valid use of asyncio to yield control back to the event loop, allowing other tasks to run. Although it doesn't perform any significant operation, it can be useful in testing or as a placeholder for more complex asynchronous operations. Therefore, it is likely to be retained for its utility in asynchronous programming contexts."
survived,"def test_from_provider_logging(caplog):
    caplog.set_level(logging.INFO)
    from_provider(""ollama/llama3.2"")
    assert any(
        ""Initializing ollama provider"" in record.getMessage()
        for record in caplog.records
    )
    assert any(""Client initialized"" in record.getMessage() for record in caplog.records)",tests/test_logging.py,,1,5.60279640614594e-09,"The method 'test_from_provider_logging' is a test function that uses the 'caplog' fixture to verify logging behavior. It sets the logging level to INFO, calls the 'from_provider' function, and asserts that specific log messages are present in the captured logs. This is a typical pattern for testing logging in Python applications, ensuring that the expected log messages are produced during execution. Since this is a standard and useful test for verifying logging, it is likely to be retained in the codebase."
survived,"def test_memory_agent_env_var_cap(tmp_path: Path, monkeypatch: pytest.MonkeyPatch) -> None:
    mem_file = tmp_path / ""mem.log""
    monkeypatch.setenv(""AGI_INSIGHT_MEMORY_LIMIT"", ""2"")
    cfg = config.Settings(bus_port=0, memory_path=str(mem_file))
    bus = messaging.A2ABus(cfg)
    ledger = logging.Ledger(str(tmp_path / ""ledger.db""))
    agent = memory_agent.MemoryAgent(bus, ledger, str(mem_file))

    envs = [messaging.Envelope(""a"", ""memory"", {""i"": i}, 0.0) for i in range(3)]

    async def _run() -> None:
        async with bus, ledger:
            for env in envs:
                await agent.handle(env)

    asyncio.run(_run())

    entries = [json.loads(line) for line in mem_file.read_text(encoding=""utf-8"").splitlines()]
    assert [e[""i""] for e in entries] == [1, 2]",tests/test_memory_agent_file_persistence.py,,1,9.237449576640118e-09,"The method is a test function that verifies the behavior of a memory agent when a specific environment variable is set. It uses a temporary path and monkeypatching to simulate the environment, and it checks if the memory agent correctly handles the envelopes based on the memory limit. This is a typical use case for testing, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-h/compiler/py/q11.py,_Group,1,8.152020648014727e-09,"The method `__len__` is a special method in Python that is used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-h/compiler/py/q18.py,_Group,1,8.592166611791576e-10,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be useful and necessary for the class's functionality, leading to its survival."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-h/compiler/py/q3.py,_Group,1,1.6052280526088547e-09,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation here is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-h/compiler/py/q15.py,Auto1,1,4.1399375473943306e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. It is unlikely to be deleted unless the design of the class changes significantly, as it provides a flexible way to access object attributes."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-h/compiler/py/q3.py,Auto2,1,4.1399375473943306e-08,"The method is a simple implementation of the __getitem__ special method, which allows instances of the class to use the bracket notation (e.g., obj[key]) to access attributes. This is a common and useful pattern in Python, especially for classes that aim to mimic dictionary-like behavior. It provides a clear and concise way to access attributes dynamically, which can be very useful in various applications. Therefore, it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-h/compiler/py/q7.py,Auto2,1,6.023574641292144e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a flexible and Pythonic way to access object attributes, it is likely to be retained in the codebase."
survived,"async def test_basic_memory_mcp_use(tmp_path: Path) -> None:
    script = tmp_path / ""app.py""
    # Paths to the repository root and example memory module
    repo_root = Path(__file__).resolve().parents[1]
    examples_dir = repo_root / ""examples"" / ""basic_memory""
    script.write_text(
        textwrap.dedent(
            f'''
            import sys
            from pathlib import Path

            sys.path.insert(0, {str(repo_root / ""src"")!r})
            sys.path.insert(0, {str(examples_dir)!r})
            from memory import FileMemoryStore, MemoryNote, MemoryNoteSummary, MemoryProject
            from enrichmcp import EnrichMCP

            store = FileMemoryStore(Path(__file__).parent / ""data"")
            project = MemoryProject(""demo"", store)

            app = EnrichMCP(title=""Test"", description=""Desc"")

            @app.entity
            class Note(MemoryNote):
                """"""A note stored in the demo project.""""""

                pass

            @app.entity
            class NoteSummary(MemoryNoteSummary):
                """"""Minimal note representation.""""""

                pass

            @app.create
            async def create_note(
                title: str,
                content: str,
                tags: list[str] | None = None,
                note_id: str | None = None,
            ) -> Note:
                """"""Create or replace a note.""""""
                note = project.create_note(title, content, tags, note_id=note_id)
                return Note.model_validate(note.model_dump())

            @app.retrieve
            async def get_note(note_id: str) -> Note:
                """"""Get a note by ID.""""""
                note = project.get_note(note_id)
                if note is None:
                    raise ValueError(""note not found"")
                return Note.model_validate(note.model_dump())

            @app.retrieve
            async def list_notes(page: int = 1, page_size: int = 10) -> list[NoteSummary]:
                """"""List notes with pagination.""""""
                notes = project.list_notes(page, page_size)
                return [NoteSummary.model_validate(n.model_dump()) for n in notes]

            if __name__ == ""__main__"":
                app.run()
            '''
        )
    )

    config = {""mcpServers"": {""app"": {""command"": sys.executable, ""args"": [str(script)]}}}
    client = MCPClient(config=config)
    session = await client.create_session(""app"")

    create_result = await session.connector.call_tool(
        ""create_note"", {""title"": ""First"", ""content"": ""Hello"", ""tags"": []}
    )
    note = json.loads(create_result.content[0].text)

    update_result = await session.connector.call_tool(
        ""create_note"",
        {
            ""note_id"": note[""id""],
            ""title"": ""Updated"",
            ""content"": ""New text"",
            ""tags"": [""x""],
        },
    )
    updated = json.loads(update_result.content[0].text)
    assert updated[""title""] == ""Updated""

    get_result = await session.connector.call_tool(""get_note"", {""note_id"": note[""id""]})
    fetched = json.loads(get_result.content[0].text)
    assert fetched[""content""] == ""New text""

    await client.close_all_sessions()",tests/test_basic_memory_mcp_use.py,,1,3.0590235908148916e-07,"The method 'test_basic_memory_mcp_use' is a test function that is designed to verify the functionality of a memory management system using an asynchronous client-server model. It is a comprehensive test that covers creating, updating, and retrieving notes, which are essential operations for the system being tested. The method is well-structured, uses modern Python features like async/await, and is likely part of a test suite for ensuring the reliability of the memory management system. Given its role in testing critical functionality, it is unlikely to be deleted unless the entire system is deprecated or significantly refactored."
survived,"    def test_missing_agents_module(self) -> None:
        orig_import = builtins.__import__

        def fake_import(name, globals=None, locals=None, fromlist=(), level=0):
            if name == ""openai_agents"":
                raise ModuleNotFoundError(name)
            return orig_import(name, globals, locals, fromlist, level)

        with patch.object(builtins, ""__import__"", fake_import):
            sys.modules.pop(
                ""alpha_factory_v1.demos.cross_industry_alpha_factory.openai_agents_bridge"",
                None,
            )
            mod = importlib.import_module(""alpha_factory_v1.demos.cross_industry_alpha_factory.openai_agents_bridge"")
            self.assertFalse(mod._OPENAI_AGENTS_AVAILABLE)
            agent = mod.CrossIndustryAgent()
            runtime = mod.AgentRuntime(api_key=None)
            runtime.register(agent)
            samples = asyncio.run(mod.list_samples())
            self.assertEqual(samples, mod.SAMPLE_ALPHA)
",tests/test_cross_industry_bridge_runtime.py,TestCrossIndustryBridgeRuntime,1,4.363462233903899e-09,"The method 'test_missing_agents_module' is a unit test designed to verify the behavior of a module when a specific dependency ('openai_agents') is missing. This is a common practice in testing to ensure that the code handles missing dependencies gracefully. The method uses mocking to simulate the absence of the 'openai_agents' module and checks if the system behaves as expected. Such tests are crucial for robust software development, especially when dealing with external dependencies. Therefore, this method is likely to be retained as it serves an important purpose in ensuring the reliability of the code."
survived,"            def __init__(self, *a, **kw) -> None:  # noqa: D401 - simple stub
                pass
",alpha_factory_v1/demos/cross_industry_alpha_factory/openai_agents_bridge.py,AgentRuntime,1,3.927863699585036e-07,"The method is a constructor (__init__) that is currently a simple stub, meaning it doesn't perform any operations or initialize any attributes. However, it is common to have such stubs in place as placeholders for future development or to satisfy interface requirements. Since it doesn't negatively impact the functionality and might be used for future expansion, it is likely to survive."
survived,"    def setUp(self):
        self._registry_backup = AGENT_REGISTRY.copy()
        AGENT_REGISTRY.clear()
",tests/test_agents_registry.py,TestRegisterDecorator,1,2.699578619062706e-07,"The method `setUp` is a common method used in unit testing frameworks like `unittest` in Python. It is typically used to set up the test environment before each test method is run. The code provided shows that it backs up the current state of `AGENT_REGISTRY` and then clears it, which is a typical setup step to ensure tests run in a clean environment. This method is likely to be part of a test suite and is essential for ensuring tests do not interfere with each other. Therefore, it is unlikely to be deleted."
survived,"def test_run_evolution_evaluates_population() -> None:
    def fn(genome: list[float]) -> tuple[float, float]:
        x, y = genome
        return abs(x), abs(y)

    pop = mats.run_evolution(fn, 2, population_size=3, generations=1, seed=1)

    assert len(pop) == 3
    assert all(ind.fitness is not None for ind in pop)
",tests/test_mats.py,,1,8.592166611791576e-10,"The method `test_run_evolution_evaluates_population` is a unit test designed to verify the functionality of the `run_evolution` method from the `mats` module. It checks that the population size is correct and that each individual in the population has a fitness value assigned. This is a typical test case for evolutionary algorithms, ensuring that the basic mechanics of the algorithm are functioning as expected. Since it serves a clear purpose in validating the code, it is likely to be retained."
survived,"    async def run_once() -> None:
        async def _sleep(_: float) -> None:
            raise asyncio.CancelledError()

        with patch.object(asyncio, ""sleep"", _sleep):
            with contextlib.suppress(asyncio.CancelledError):
                await runner.loop(bus, led)
",tests/test_agent_runner.py,,1,7.194132978569833e-09,"The method 'run_once' is using a patched version of 'asyncio.sleep' that immediately raises a 'CancelledError'. This suggests that the method is designed to handle cancellation scenarios, possibly for testing purposes. The use of 'contextlib.suppress' to handle 'CancelledError' indicates that the method is robust against such exceptions. This pattern is common in testing asynchronous code to ensure it behaves correctly under cancellation. Therefore, the method is likely to be useful and relevant for testing and debugging, which suggests it will be Survived."
survived,"def test_stopping_criteria_reset():
    class MockProcessor:
        def __init__(self):
            self.tokenizer = type(
                ""DummyTokenizer"", (), {""pad_token"": None, ""eos_token"": ""[EOS]""}
            )()

        def encode(self, text, add_special_tokens=False):
            if ""[EOS]"" in text:
                return [32008]
            return [1]

    processor = MockProcessor()
    stopping_criteria = StoppingCriteria([2], processor)
    stopping_criteria.add_eos_token_ids(""[EOS]"")

    stopping_criteria.reset([5, 7])
    assert stopping_criteria.eos_token_ids == [5, 7]
    assert stopping_criteria(7) is True",mlx_vlm/tests/test_utils.py,,1,1.7603431343301488e-06,"The method `test_stopping_criteria_reset` is a unit test designed to verify the functionality of the `StoppingCriteria` class, specifically its ability to reset the `eos_token_ids`. Unit tests are crucial for ensuring code reliability and correctness, especially in complex systems. This test checks that the `reset` method correctly updates the `eos_token_ids` and that the stopping criteria function behaves as expected. Given the importance of testing in software development, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered."
survived,"    async def run(self, initial_prompt: Any) -> Any:
        result = initial_prompt
        for step in self.steps:
            user_id = step.user_id or self.default_user_id
            session_id = step.session_id or self.default_session_id
            llm = step.llm or self.default_llm
            sdk_context = step.sdk_context or self.sdk_context

            if step.mode == StepMode.SEQUENTIAL:
                result = await self._execute_runner(step.runner, result, user_id, session_id, llm, sdk_context)

            elif step.mode == StepMode.PARALLEL:
                runners: Iterable[Any] = step.runner if isinstance(step.runner, Iterable) else [step.runner]
                results = await asyncio.gather(
                    *[self._execute_runner(r, result, user_id, session_id, llm, sdk_context) for r in runners]
                )
                result = results

            elif step.mode == StepMode.CONDITIONAL:
                if step.condition is None or step.condition(result):
                    result = await self._execute_runner(step.runner, result, user_id, session_id, llm, sdk_context)

            elif step.mode == StepMode.LOOP:
                iterations = 0
                max_iter = step.max_iterations or 1
                while True:
                    result = await self._execute_runner(step.runner, result, user_id, session_id, llm, sdk_context)
                    iterations += 1
                    if step.condition and step.condition(result):
                        break
                    if iterations >= max_iter:
                        break
            else:
                raise ValueError(f""Unsupported step mode {step.mode}"")
        return result",swarmzero/workflow.py,Workflow,1,7.194132978569833e-09,"The method 'run' is a well-structured asynchronous function that handles different modes of execution (SEQUENTIAL, PARALLEL, CONDITIONAL, LOOP) for a series of steps. It uses asyncio for parallel execution and supports conditional and loop-based logic, making it versatile for various workflows. The method is likely part of a larger framework or system that requires such flexibility in executing tasks. Given its comprehensive design and utility, it is unlikely to be deleted unless the entire system undergoes a significant redesign or the method's functionality is replaced by a more efficient solution."
survived,"    async def init_async(self) -> None:  # pragma: no cover - optional hook
        """"""Launch background tasks once the event loop is running.""""""
        return None
",alpha_factory_v1/backend/agents/base.py,AgentBase,1,4.6911638017642294e-08,"The method `init_async` is an asynchronous method that is designed to launch background tasks once the event loop is running. The method is marked with `# pragma: no cover`, indicating that it is an optional hook and not covered by tests. This suggests that the method is intended to be used as a part of a larger framework or application where such hooks are common. The method is also well-documented, which is a good practice for maintainability. Given these factors, it is likely that the method will survive as it serves a specific purpose in the context of asynchronous programming."
survived,"        def _add(state):
            idx = state.head
            state.token_ids = state.token_ids.at[idx, :length].set(tokens[:length])
            state.lengths = state.lengths.at[idx].set(length)
            state.active = state.active.at[idx].set(True)
            state.head = (state.head + 1) % self.max_seqs
            return state
",src/levanter/inference/scheduler.py,JittedScheduler,1,1.955568070542584e-08,"The method '_add' is a private helper function, indicated by the underscore prefix, which suggests it is intended for internal use within a class or module. It appears to be a utility function for managing state, specifically updating token IDs, lengths, and active status in a cyclic manner based on a head index. Such methods are typically essential for the internal logic of a class, especially if they manage state or resources efficiently. Unless there is a significant change in the class design or the method is deemed redundant due to refactoring, it is likely to survive as it serves a specific purpose in maintaining the state."
survived,"    def decode_step(self, state, decode_fn):
        """"""Decode one token for the sequence at ``state.tail``.""""""
        import jax.numpy as jnp
        from jax import lax

        idx = state.tail
        tokens = state.token_ids[idx]
        length = state.lengths[idx]
        prev = tokens[length - 1]
        new_tok = decode_fn(prev)
        state.token_ids = state.token_ids.at[idx, length].set(new_tok)
        state.lengths = state.lengths.at[idx].set(length + 1)

        finished = jnp.logical_or(new_tok == self.eos, length + 1 >= self.max_len)

        def _finish(st):
            st.active = st.active.at[idx].set(False)
            st.tail = (st.tail + 1) % self.max_seqs
            return st

        state = lax.cond(finished, _finish, lambda s: s, state)
        return state
",src/levanter/inference/scheduler.py,JittedScheduler,1,5.60279640614594e-09,"The method 'decode_step' is a crucial part of a sequence decoding process, likely used in machine learning models for tasks such as language generation or translation. It handles the decoding of a single token, updates the state with the new token, and checks if the sequence is finished. This functionality is essential for models that generate sequences, and the method is well-structured, using JAX for efficient computation. Given the increasing use of JAX in machine learning for its performance benefits, this method is likely to be retained and used in future developments."
survived,"    def collect(self, state):
        """"""Return the decoded sequences as Python lists.""""""
        return [
            [int(t) for t in state.token_ids[i, : int(state.lengths[i])].tolist()]
            for i in range(self.max_seqs)
            if int(state.lengths[i]) > 0
        ]
",src/levanter/inference/scheduler.py,JittedScheduler,1,2.0611536181902033e-09,"The method 'collect' is a utility function that processes a given 'state' object to extract and decode sequences into Python lists. It is a straightforward and efficient implementation that uses list comprehensions to iterate over sequences and convert them into lists of integers. The method is clear, concise, and serves a specific purpose, making it unlikely to be deleted unless there is a significant change in the requirements or the structure of the 'state' object. Therefore, it is more likely to survive."
survived,"    def copy_tiles(self):
        """""" returns list of lists version """"""
        t = self.tiles

        return [[t[0][0], t[0][1], t[0][2], t[0][3]],
                [t[1][0], t[1][1], t[1][2], t[1][3]],
                [t[2][0], t[2][1], t[2][2], t[2][3]],
                [t[3][0], t[3][1], t[3][2], t[3][3]]]
",tests/rosetta/x/Python/15-puzzle-solver/15-puzzle-solver-2.py,Position,0,0.9999974387182097,"The method 'copy_tiles' is likely to be deleted because it performs a shallow copy of a 4x4 matrix (list of lists) in a very verbose and hardcoded manner. This approach is not flexible or scalable, and it can be easily replaced by more efficient and concise methods such as using list comprehension or the 'copy.deepcopy()' function from the 'copy' module. These alternatives are more adaptable to changes in the size of the matrix and are considered best practices in Python for copying nested lists."
survived,"def slide_solved_state(n):
    return tuple(i % (n*n) for i in range(1, n*n+1))
",tests/rosetta/x/Python/15-puzzle-solver/15-puzzle-solver-1.py,,1,3.653482080241728e-08,"The method `slide_solved_state` is a simple utility function that generates a tuple representing the solved state of an n x n sliding puzzle. It is a straightforward and efficient implementation that uses a mathematical approach to generate the sequence. The function is likely to be useful in contexts where sliding puzzles are relevant, such as in games or educational tools. Given its simplicity, correctness, and potential utility, it is unlikely to be deleted unless the entire context or application it belongs to is removed or significantly refactored."
survived,"    def h(p):
        ht = 0 # Walking distance between rows.
        vt = 0 # Walking distance between columns.
        d = 0
        for i, c in enumerate(p):
            if c == 0: continue
            g = goals[c]
            xi, yi = i % n, i // n
            xg, yg = g % n, g // n
            ht += 1 << (b*(n*yi+yg))
            vt += 1 << (b*(n*xi+xg))

            if yg == yi:
                for k in range(i + 1, i - i%n + n): # Until end of row.
                    if p[k] and goals[p[k]] // n == yi and goals[p[k]] < g:
                        d += 2

            if xg == xi:
                for k in range(i + n, n * n, n): # Until end of column.
                    if p[k] and goals[p[k]] % n == xi and goals[p[k]] < g:
                        d += 2

        d += wd[ht] + wd[vt]

        return d
",tests/rosetta/x/Python/15-puzzle-solver/15-puzzle-solver-1.py,,1,4.363462233903899e-09,"The method 'h' is a heuristic function used in pathfinding or puzzle-solving algorithms, such as A* or IDA*. It calculates a heuristic distance 'd' based on the positions of elements in a grid and their goal positions. The function uses bitwise operations to efficiently compute horizontal and vertical distances, and it adjusts the distance based on conflicts in rows and columns. This type of heuristic function is crucial for optimizing search algorithms, making it a valuable component in such implementations. Given its utility in improving algorithm efficiency, it is likely to be retained in the codebase."
survived,"def a_star(start_tiles, goal_tiles):
    """""" Based on https://en.wikipedia.org/wiki/A*_search_algorithm """"""

    start = new_position(start_tiles)
    goal = new_position(goal_tiles)

    # Process goal position for use in heuristic

    global hob
    hob = HeuristicObj(goal)

    # The set of currently discovered nodes that are not evaluated yet.
    # Initially, only the start node is known.
    # For the first node, the fscore is completely heuristic.

    start.fscore = hob.heuristic(start)
    openSet = PriorityQueue([start])

    # The cost of going from start to start is zero.

    start.gscore = 0

    num_popped = 0

    while openSet.queue_length > 0:
        current = openSet.pop()
        if current == None: # tried to pop but only found old fscore values
            break
        num_popped += 1
        if num_popped % 100000 == 0:
            print(str(num_popped)+"" positions examined"")

        if current == goal:
            return reconstruct_path(current)

        for neighbor in current.neighbors():

            # The distance from start to a neighbor
            # All nodes are 1 move from their neighbors

            tentative_gScore = current.gscore + 1

            # update gscore and fscore if this is shorter path
            # to the neighbor node

            if tentative_gScore < neighbor.gscore:
                neighbor.cameFrom = current
                neighbor.gscore = tentative_gScore
                neighbor.fscore = neighbor.gscore + hob.heuristic(neighbor)
                openSet.push(neighbor) # add to open set every time
",tests/rosetta/x/Python/15-puzzle-solver/15-puzzle-solver-2.py,,1,7.73442280641062e-08,"The method implements the A* search algorithm, which is a well-known and widely used algorithm for pathfinding and graph traversal. The code is structured correctly with a clear purpose, and it follows the standard approach for A* by maintaining open and closed sets, calculating g-scores and f-scores, and using a heuristic function. The method is likely to be useful in various applications that require pathfinding, such as games, robotics, and navigation systems. Therefore, it is unlikely to be deleted."
survived,"def test_export_tree(tmp_path):
    (tmp_path / ""doc1.txt"").write_text(""First document about cats."")
    (tmp_path / ""doc2.txt"").write_text(""Second document about dogs."")

    output_file = tmp_path / ""tree.json""
    args = argparse.Namespace(
        data_dir=str(tmp_path),
        iterations=1,
        display_topics=1,
        n_words=2,
        num_levels=3,
        alpha=1.0,
        gamma=1.0,
        eta=0.1,
        seed=0,
        export_tree=str(output_file),
    )

    run_hlda.run_demo(args)
    data = json.loads(output_file.read_text())

    assert data[""level""] == 0
    assert isinstance(data[""children""], list)",tests/test_export_tree_json.py,,1,6.825604231969389e-08,"The method 'test_export_tree' is a test function that verifies the functionality of exporting a hierarchical topic model tree to a JSON file. It sets up a temporary directory with sample text files, configures arguments for the 'run_hlda.run_demo' function, and checks the structure of the output JSON file. This method is likely to survive because it serves as a unit test, ensuring that the 'run_hlda.run_demo' function correctly exports the tree structure. Unit tests are crucial for maintaining code quality and verifying that changes do not break existing functionality."
survived,"def test_visualize_shardings_runs(capsys):
    mesh = jax.sharding.Mesh(
        np.array(jax.devices()).reshape(-1, 1, 1),
        (ResourceAxis.DATA, ResourceAxis.MODEL, ResourceAxis.REPLICA),
    )
    with axis_mapping(resource_map), mesh:
        arr = hax.ones((Dim1, Dim2, Dim3))
        visualize_shardings(arr)

    out = capsys.readouterr().out
    assert ""dim1"" in out and ""dim2"" in out and ""dim3"" in out
",tests/test_visualize_sharding.py,,1,5.60279640614594e-09,"The method `test_visualize_shardings_runs` is a test function that checks the output of the `visualize_shardings` function. It uses the `capsys` fixture to capture the standard output and asserts that certain strings are present in the output. This is a typical pattern for testing in Python, especially when using pytest. The function is likely to be useful for ensuring that the `visualize_shardings` function behaves as expected, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained in the codebase."
survived,"    def _show(x):
        if isinstance(x, NamedArray):
            arr = x.array
            axes = x.axes
        else:
            arr = x
            axes = None

        def cb(sh):
            if axes is not None:
                visualize_named_sharding(axes, sh)
            else:
                try:
                    jax.debug.visualize_sharding(arr.shape, sh)
                except Exception:
                    pass

        jax.debug.inspect_array_sharding(arr, callback=cb)
        return x
",src/haliax/debug.py,,1,1.1861120010657661e-08,"The method '_show' is designed to handle both NamedArray and regular array inputs, providing a visualization of their sharding. It includes error handling for cases where visualization might fail, which is a good practice. The method is useful for debugging and understanding how arrays are partitioned across devices, which is a common need in distributed computing environments. Given its utility in debugging and visualization, it is likely to be retained in the codebase."
survived,"            def history_plot(self):
                return {}
",tests/test_agent_aiga_entrypoint.py,TestAgentAIGAEntry.DummyEvolver,0,0.9999999981810384,"The method 'history_plot' is defined to return an empty dictionary. Without any additional context or functionality, it doesn't serve a clear purpose or provide any meaningful output. Methods that do not perform any operations or return useful data are often considered redundant and are likely candidates for deletion unless they are placeholders for future development. Therefore, it is likely that this method will be deleted."
survived,"    async def policy(self, obs, ctx):  # type: ignore[override]
        gens = int(obs.get(""generations"", 3)) if isinstance(obs, dict) else 3
        return await self.tools.run_meta_search(gens)
",alpha_factory_v1/demos/meta_agentic_agi/openai_agents_bridge.py,MetaSearchAgent,1,1.2501528648238603e-09,"The method 'policy' is an asynchronous function that takes two parameters, 'obs' and 'ctx'. It checks if 'obs' is a dictionary and attempts to retrieve the 'generations' key, defaulting to 3 if not present. It then calls 'run_meta_search' on 'self.tools' with the number of generations. The method seems to be well-structured and serves a clear purpose in running a meta search based on the input. There are no obvious issues or deprecated practices in the code, suggesting it is likely to be useful and relevant in its context. Therefore, it is likely to be Survived."
survived,"async def _llm_comment(delta_g: float) -> str:
    """"""Return a short LLM comment on ``delta_g`` if OpenAI Agents is available.""""""

    if OpenAIAgent is None:
        return ""LLM offline""

    agent = OpenAIAgent(
        model=os.getenv(""MODEL_NAME"", ""gpt-4o-mini""),
        api_key=os.getenv(""OPENAI_API_KEY""),
        base_url=(None if os.getenv(""OPENAI_API_KEY"") else ""http://ollama:11434/v1""),
    )
    try:
        return await agent(
            f""In one sentence, comment on Î”G={delta_g:.4f} for the business.""
        )
    except Exception as exc:  # pragma: no cover - network failures
        log.warning(""LLM comment failed: %s"", exc)
        return ""LLM error""
",alpha_factory_v1/demos/alpha_agi_business_3_v1/alpha_agi_business_3_v1.py,,1,3.850741907939403e-09,"The method is likely to survive because it provides a useful functionality by integrating with OpenAI's API to generate comments based on a given input. It includes error handling and fallback messages, which are good practices for maintaining robustness. Additionally, the use of environment variables for configuration suggests it is designed to be flexible and adaptable to different environments, increasing its utility."
survived,"async def checkpoint() -> str:
    EVOLVER.save()
    return ""checkpoint saved""
",alpha_factory_v1/demos/aiga_meta_evolution/openai_agents_bridge.py,,1,3.3982678079468468e-09,"The method 'checkpoint' is a simple asynchronous function that calls a 'save' method on an 'EVOLVER' object and returns a string indicating the action was successful. This function is likely to be useful in scenarios where periodic saving of state or progress is necessary, such as in long-running processes or simulations. The method is straightforward, performs a clear and useful action, and does not contain any apparent issues or redundancies. Therefore, it is likely to be retained in the codebase."
survived,"    def inner(y: int) -> int:
        return x + y
",tests/machine/x/python/nested_function.py,,0,0.9999982396568657,"The method 'inner' uses a variable 'x' that is not defined within its scope or passed as a parameter. This will lead to a NameError when the function is called unless 'x' is defined in the enclosing scope. Without additional context showing that 'x' is defined elsewhere, this function is likely to be considered incomplete or erroneous, leading to its deletion."
survived,"def main():
    parser = argparse.ArgumentParser(
        description=(""Run hierarchical LDA on the BBC tech dataset""),
    )
    parser.add_argument(
        ""--data-dir"",
        default=os.path.join(
            os.path.dirname(__file__),
            "".."",
            ""data"",
            ""bbc"",
            ""tech"",
        ),
        help=""Directory containing BBC .txt files"",
    )
    parser.add_argument(
        ""--iterations"",
        type=int,
        default=100,
        help=""Number of Gibbs samples"",
    )
    parser.add_argument(
        ""--display-topics"",
        type=int,
        default=50,
        help=""Report topics every N iterations"",
    )
    parser.add_argument(
        ""--n-words"",
        type=int,
        default=5,
        help=""Number of words to display per topic"",
    )
    parser.add_argument(
        ""--num-levels"",
        type=int,
        default=3,
        help=""Depth of the topic hierarchy"",
    )
    parser.add_argument(
        ""--alpha"",
        type=float,
        default=10.0,
        help=""Alpha hyperparameter"",
    )
    parser.add_argument(
        ""--gamma"",
        type=float,
        default=1.0,
        help=""Gamma hyperparameter"",
    )
    parser.add_argument(
        ""--eta"",
        type=float,
        default=0.1,
        help=""Eta hyperparameter"",
    )
    parser.add_argument(
        ""--seed"",
        type=int,
        default=0,
        help=""Random seed"",
    )

    args = parser.parse_args()
    run_hlda(args)
",examples/bbc_demo.py,,1,4.4508487281649027e-07,"The method is a main function that sets up an argument parser for a script that runs hierarchical LDA on a dataset. It is a typical setup for command-line tools in Python, providing flexibility and configurability for the user. Such methods are essential for scripts that are intended to be run with different parameters and are unlikely to be deleted unless the entire script is deprecated or replaced by a different approach."
survived,"def test_read_and_clear() -> None:
    bus = EventBus(None, True, max_queue_size=2)
    bus.publish(""x"", {""v"": 1})
    bus.publish(""x"", {""v"": 2})
    events = bus.read_and_clear(""x"")
    assert events == {""x"": [{""v"": 1}, {""v"": 2}]}
    assert bus.read_and_clear(""x"") == {}
",tests/test_eventbus.py,,1,6.825604231969389e-08,"The method 'test_read_and_clear' is a unit test for the 'read_and_clear' functionality of an EventBus class. It verifies that events are correctly published to a queue and that the 'read_and_clear' method retrieves and clears these events. This is a fundamental test to ensure the integrity of the event handling mechanism. Such tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is unlikely to be deleted as it serves an important role in the testing suite."
survived,"    async def start_consumer(self) -> None:
        if self._queues is None or self._consumer_task is not None:
            return
        self._consumer_task = asyncio.create_task(self._drain_loop())
",alpha_factory_v1/backend/agent_runner.py,EventBus,1,6.69158608681505e-10,"The method 'start_consumer' is an asynchronous method that checks if '_queues' is None or '_consumer_task' is not None before creating a new task with 'asyncio.create_task'. This is a common pattern in asynchronous programming to ensure that resources are managed correctly and tasks are not duplicated. The method is likely to be useful in managing consumer tasks in an asynchronous application, and there is no indication of it being deprecated or unnecessary. Therefore, it is likely to survive."
survived,"def test_open_logs_endpoint(client):
    with patch(""app.desktop.studio_server.settings_api.open_logs_folder"") as m:
        response = client.post(""/api/open_logs"")
        assert response.status_code == 200
        m.assert_called_once()",app/desktop/studio_server/test_settings_api.py,,1,2.998960815863541e-09,"The method 'test_open_logs_endpoint' is a unit test function that tests the '/api/open_logs' endpoint. It uses mocking to ensure that the 'open_logs_folder' function is called once when the endpoint is hit. This is a typical pattern in testing to verify that certain actions are performed, and it is crucial for maintaining code quality and ensuring that the application behaves as expected. Therefore, this method is likely to be retained as part of the test suite."
survived,"def open_logs_folder() -> None:
    log_dir = os.path.dirname(get_log_file_path(""dummy.log""))
    if sys.platform.startswith(""darwin""):
        subprocess.run([""open"", log_dir], check=True)
    elif sys.platform.startswith(""win""):
        os.startfile(log_dir)  # type: ignore[attr-defined]
    else:
        subprocess.run([""xdg-open"", log_dir], check=True)
",app/desktop/studio_server/settings_api.py,,1,3.850741907939403e-09,"The method `open_logs_folder` is a utility function that opens the directory containing log files in the default file explorer, depending on the operating system. This is a common and useful functionality for applications that generate logs, as it allows users to easily access and review log files. The method is implemented to handle different operating systems (macOS, Windows, and Linux), making it versatile and applicable in various environments. There is no indication that this method is redundant or obsolete, and it serves a practical purpose in application development and maintenance. Therefore, it is likely to be retained in the codebase."
survived,"    def __init__(self, llm_service: LLMService) -> None:
        self.llm_service = llm_service
",src/meta_agent/services/guardrail_router.py,LLMModelAdapter,1,5.3157849718487075e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting up initial states. This particular constructor takes an instance of LLMService as a parameter and assigns it to an instance variable, which is a common pattern for dependency injection. There is no indication that this constructor is redundant or unnecessary, so it is likely to be retained."
survived,"def test_runtime_port_env(monkeypatch: ""pytest.MonkeyPatch"") -> None:
    """"""AgentRuntime receives AGENTS_RUNTIME_PORT.""""""
    import importlib
    import sys
    import types

    captured: dict[str, int] = {}

    class DummyRuntime:
        def __init__(self, *a: object, port: int = 5001, **_k: object) -> None:
            captured[""port""] = port

        def register(self, *_a: object, **_k: object) -> None:
            pass

        def run(self) -> None:
            pass

    stub = types.ModuleType(""openai_agents"")
    stub.Agent = object
    stub.AgentRuntime = DummyRuntime
    stub.OpenAIAgent = object

    def _tool(*_a: object, **_k: object) -> Callable[[object], object]:
        def dec(f: object) -> object:
            return f

        return dec

    stub.Tool = _tool
    monkeypatch.setitem(sys.modules, ""openai_agents"", stub)
    monkeypatch.delitem(sys.modules, ""agents"", raising=False)
    monkeypatch.setenv(""AGENTS_RUNTIME_PORT"", ""6101"")

    mod = importlib.import_module(""alpha_factory_v1.demos.aiga_meta_evolution.alpha_opportunity_stub"")
    importlib.reload(mod)
    mod.main([])
    assert captured[""port""] == 6101",tests/test_alpha_opportunity_stub.py,,1,1.637377179507321e-07,"The method 'test_runtime_port_env' is a unit test function that uses the 'monkeypatch' fixture from pytest to modify the environment and test the behavior of a module. It is a specific test case that verifies if the 'AgentRuntime' correctly receives the 'AGENTS_RUNTIME_PORT' environment variable. Such test functions are crucial for ensuring code reliability and are typically not deleted unless the functionality they test is removed or significantly altered. Since the function is a test and not part of the main application logic, it is likely to be maintained as long as the tested functionality exists."
survived,"        def dec(f: object) -> object:
            return f
",tests/test_alpha_opportunity_stub.py,,1,1.637377179507321e-07,"The method 'dec' is a simple decorator that returns the function it receives as an argument without any modification. Such a decorator can be useful in scenarios where conditional decoration is needed or when a placeholder decorator is required during development. It doesn't perform any operations that would make it redundant or unnecessary, so it is likely to be retained for its potential utility in various contexts."
survived,"def test_stub_compiles() -> None:
    py_compile.compile(str(STUB), doraise=True)
",tests/test_alpha_opportunity_stub.py,,1,1.3440409770490404e-08,"The method `test_stub_compiles` is a simple test function that attempts to compile a Python file or module specified by `STUB`. The use of `py_compile.compile` with `doraise=True` ensures that any compilation errors will raise an exception, which is useful for testing purposes. This function is likely part of a test suite to ensure that the code in `STUB` is syntactically correct. Such a function is useful in a development environment to catch errors early and is a common practice in automated testing. Therefore, it is likely to be retained in the codebase."
survived,"def test_session_id_hashed() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri()

    with sync_playwright() as p:
        browser = p.chromium.launch()
        page = browser.new_page()
        page.goto(url)
        page.evaluate(
            ""window.OTEL_ENDPOINT='https://example.com';""
            ""window.confirm=() => true;""
            ""navigator.sendBeacon=(...a)=>{window.beacon=a;return true;}""
        )
        page.reload()
        page.wait_for_selector(""#controls"")
        page.click(""text=Share"")
        page.evaluate(""window.dispatchEvent(new Event('beforeunload'))"")
        payload = page.evaluate(""window.beacon[1]"")
        import json

        metrics = json.loads(payload)
        assert ""session"" in metrics
        assert isinstance(metrics[""session""], str)
        assert len(metrics[""session""]) == 64
        browser.close()
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_telemetry.py,,1,9.237449576640118e-09,"The method 'test_session_id_hashed' is a test function that verifies the behavior of a web page in a browser environment using Playwright. It checks if a session ID is correctly hashed and sent as a beacon. This kind of test is crucial for ensuring the integrity and security of session management in web applications. Given the importance of testing session handling and the use of a popular testing framework, it is likely that this method will be maintained as part of the test suite to ensure ongoing reliability and security of the application."
survived,"        def _decorator(func: object) -> object:
            return func
",tests/test_aiga_agents_import.py,,1,6.962258425838873e-06,"The method '_decorator' is a simple function that takes another function as an argument and returns it unchanged. This is a basic implementation of a decorator pattern, which is a common and useful technique in Python for extending the behavior of functions or methods. Although the current implementation does not modify the function, it serves as a placeholder for future enhancements. Therefore, it is likely to be retained for potential use or extension."
survived,"def _load_real_yaml():
    """"""Load the bundled PyYAML distribution if present.""""""
    path = (
        Path(__file__).resolve().parents[2]
        / "".venv/lib/python3.11/site-packages/yaml/__init__.py""
    )
    if not path.exists():
        return None
    spec = importlib.util.spec_from_file_location(""_pyyaml"", path)
    if spec and spec.loader:
        module = importlib.util.module_from_spec(spec)
        sys.modules.setdefault(""_pyyaml"", module)
        spec.loader.exec_module(module)
        return module
    return None
",src/yaml/__init__.py,,1,1.637377179507321e-07,"The method `_load_real_yaml` is designed to load a specific version of the PyYAML library from a virtual environment if it exists. This is a specialized utility function that checks for the existence of a file and dynamically imports it. Such functions are often used in environments where dependencies need to be managed manually or in a controlled manner, which is common in larger projects or when dealing with multiple versions of a library. The function is useful for ensuring that the correct version of a library is loaded, which can be critical for compatibility and functionality. Therefore, it is likely to be retained as it serves a specific purpose that is not easily replaced by standard library functions."
survived,"    def setUp(self) -> None:
        self.agent = EnergyAgent()
",tests/test_energy_agent.py,TestEnergyAgentSyncRun,1,8.152020648014727e-09,"The method `setUp` is a common method used in unit testing frameworks like `unittest` in Python. It is typically used to set up the test environment before each test method is run. The presence of `setUp` suggests that this code is part of a test suite, and such methods are generally not deleted unless the entire test suite is being refactored or removed. Since `setUp` is a standard and necessary part of setting up tests, it is likely to survive."
survived,"def _mutate(g):
    return g + random.uniform(-1, 1)
",tests/test_backtrack_boost.py,,1,2.0611536181902033e-09,"The method _mutate is a simple utility function that takes a parameter g and returns it after adding a random float between -1 and 1. This kind of function is often used in genetic algorithms or optimization problems to introduce variability. The function is straightforward, has a clear purpose, and is likely to be useful in contexts where mutation or random variation is needed. Therefore, it is likely to be retained in the codebase."
survived,"def _run(rate):
    random.seed(123)
    arch = InMemoryArchive()
    asyncio.run(arch.accept(Candidate(0.0, fitness=0.0, novelty=1.0)))
    asyncio.run(
        evolve(
            _mutate,
            _evaluate,
            arch,
            max_cost=0.1,
            backtrack_rate=rate,
        )
    )
    return [c.genome for c in arch.all()]
",tests/test_backtrack_boost.py,,1,2.998960815863541e-09,"The method '_run' is likely to be Survived (1) because it appears to be a functional part of a larger system that involves evolutionary algorithms. It initializes a random seed, sets up an in-memory archive, and runs an asynchronous evolution process with specified parameters. The method is structured and seems to serve a specific purpose in the context of the code, which is to evolve candidates and return their genomes. There is no indication of redundancy or obsolescence, suggesting it is an integral part of the system."
survived,"        async def evaluate(_g):
            events.append(current)
            return 0.0, 0.01
",tests/test_phase_order.py,TestPhaseOrder,1,6.825604231969389e-08,"The method 'evaluate' is an asynchronous function that takes a single parameter '_g'. It appends a variable 'current' to a list 'events' and returns a tuple (0.0, 0.01). The method seems to be part of a larger system, possibly for evaluating some conditions or metrics. Without additional context, it's difficult to determine its full utility, but the method is functional and does not contain any obvious issues or deprecated practices. Therefore, it is likely to be retained in the codebase."
survived,"def compose_stack() -> None:
    subprocess.run([
        ""docker"",
        ""compose"",
        ""-f"",
        str(COMPOSE_FILE),
        ""up"",
        ""-d"",
        ""agents"",
    ], check=True)
    try:
        yield
    finally:
        subprocess.run([
            ""docker"",
            ""compose"",
            ""-f"",
            str(COMPOSE_FILE),
            ""down"",
            ""-v"",
        ], check=False)
",tests/test_no_network.py,,0,0.9999999943972036,"The method is likely to be deleted because it contains a logical error. The function is defined to return None, but it uses a 'yield' statement, which is typically used in generator functions that return an iterator. This inconsistency suggests that the function may not work as intended, leading to its potential removal or significant modification."
survived,"    async def run() -> None:
        async with bus:
            await agent.handle(env)
",tests/test_memory_agent_persistence.py,,1,2.998960815863541e-09,"The method 'run' is an asynchronous function that uses an asynchronous context manager 'bus' and awaits an asynchronous method 'agent.handle(env)'. This indicates that the method is designed to handle asynchronous operations, which are increasingly common in modern programming for handling I/O-bound tasks efficiently. Given the trend towards asynchronous programming, especially in environments like web servers or applications that require non-blocking operations, this method is likely to be useful and relevant. Therefore, it is more likely to be retained in the codebase."
survived,"            def run_generations(self, *_a) -> None:
                pass
",tests/test_openai_bridge_runtime.py,TestAIGABridgeRuntime.DummyEvolver,0,0.9933071501716079,"The method `run_generations` is defined but not implemented, as it only contains a `pass` statement. This suggests that it might be a placeholder for future functionality. However, without any additional context or usage, it is difficult to determine its necessity. If the method is part of a larger class that is actively used and this method is intended to be implemented later, it might survive. But if it remains unused and unimplemented, it is likely to be deleted in future refactoring to clean up the codebase."
survived,"    def test_string_asarray(self):
        arr = self.core.kg_asarray(""hello"")
        self.assertTrue(self.backend.np.isarray(arr))
        self.assertEqual(arr.dtype, object)
        self.assertEqual("""".join(arr), ""hello"")
        import numpy as np
        self.assertIsInstance(arr, np.ndarray)
        self.assertFalse(isinstance(arr, torch.Tensor))
",tests/test_torch_backend.py,TestTorchBackend,1,1.0467401685178159e-08,"The method `test_string_asarray` is a unit test that verifies the functionality of converting a string into an array using a method `kg_asarray`. It checks if the result is a numpy array, has the correct data type, and reconstructs the original string correctly. These are standard checks for ensuring the integrity of the conversion process. Since testing is a crucial part of software development to ensure code reliability and correctness, this method is likely to be retained as part of the test suite."
survived,"        def register_agent(self, _agent):
            pass
",tests/test_business_bridge_offline.py,_Router,0,0.9999998555019682,"The method 'register_agent' is defined but not implemented, as it only contains a 'pass' statement. This suggests that the method is either a placeholder for future implementation or is not needed at all. Without any additional context or usage of this method in the code, it is likely to be deleted if it remains unimplemented, as it does not contribute any functionality."
survived,"    def _init_population(self):
        seed = Genome()
        self.population = [seed.mutate() for _ in range(self.pop_size)]
        self.best_genome = self.population[0]
",alpha_factory_v1/demos/aiga_meta_evolution/meta_evolver.py,MetaEvolver,1,1.0467401685178159e-08,"The method '_init_population' is a private method (indicated by the underscore prefix) that initializes a population of genomes for a genetic algorithm. It creates a seed genome and mutates it to fill the population list. This is a fundamental part of setting up a genetic algorithm, which is a common technique in optimization and machine learning. The method is likely to be essential for the functionality of the class it belongs to, as it sets up the initial state of the population. Therefore, it is unlikely to be deleted unless the entire approach or class is refactored or removed."
survived,"    def _init(self):
        for m in self.model:
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                nn.init.zeros_(m.bias)
",alpha_factory_v1/demos/aiga_meta_evolution/meta_evolver.py,EvoNet,1,4.1399375473943306e-08,"The method `_init` is a private method (indicated by the underscore prefix) that initializes the weights and biases of linear layers in a neural network model using Xavier uniform initialization and zero initialization, respectively. This is a common practice in deep learning to ensure that the model starts with weights that are neither too large nor too small, which helps in effective training. The method is useful and follows a standard approach for initializing neural network layers, which suggests it is likely to be retained in the codebase."
survived,"def test_escaped_newline(state):
    out, expected = try_on_file(
        ""escaped_newline.py"",
        partial(fstringify_code_by_line, state=state),
    )
    assert out == expected",test/integration/test_issue83.py,,1,9.237449576640118e-09,"The method 'test_escaped_newline' is a test function that checks the functionality of another function 'try_on_file'. It is likely part of a test suite to ensure code quality and correctness. Test functions are generally not deleted unless they are redundant or replaced by more comprehensive tests. Since this function seems to serve a specific purpose in testing code transformation, it is likely to be retained."
survived,"    def test_offline_fallback_base_url(self) -> None:
        """"""OpenAI bridge should use OLLAMA_BASE_URL when api key is empty.""""""

        def fake_openai_agent(*_a, **kwargs):
            return types.SimpleNamespace(base_url=kwargs.get(""base_url""))

        stub = types.ModuleType(""openai_agents"")
        stub.Agent = object
        stub.AgentRuntime = object
        stub.OpenAIAgent = fake_openai_agent

        env_stub = types.ModuleType(""curriculum_env"")
        env_stub.CurriculumEnv = object

        evo_stub = types.ModuleType(""meta_evolver"")
        evo_stub.MetaEvolver = object

        with patch.dict(
            sys.modules,
            {
                ""openai_agents"": stub,
                ""alpha_factory_v1.demos.aiga_meta_evolution.curriculum_env"": env_stub,
                ""alpha_factory_v1.demos.aiga_meta_evolution.meta_evolver"": evo_stub,
            },
        ), patch.dict(
            os.environ,
            {""OPENAI_API_KEY"": """", ""OLLAMA_BASE_URL"": ""http://example.com""},
            clear=False,
        ):
            mod = importlib.reload(
                importlib.import_module(
                    ""alpha_factory_v1.demos.aiga_meta_evolution.openai_agents_bridge""
                )
            )

            self.assertEqual(mod.LLM.base_url, ""http://example.com"")
",tests/test_openai_bridge_runtime.py,TestAIGABridgeRuntime,1,2.2159489282323004e-08,"The method is a unit test that verifies the behavior of a system when a specific environment variable is set. It uses mocking to simulate the environment and checks if the system correctly falls back to a base URL when the API key is empty. This is a common and useful test to ensure robustness in handling configuration settings, especially in environments where API keys might not be available. Such tests are crucial for maintaining code quality and ensuring that the system behaves as expected under different configurations. Therefore, it is likely to be retained."
survived,"def _base_url() -> str:
    return os.environ.get(
        ""HF_GPT2_BASE_URL"",
        ""https://huggingface.co/openai-community/gpt2/resolve/main"",
    ).rstrip(""/"")
",scripts/download_hf_gpt2.py,,1,1.8189616842444243e-09,"The method '_base_url' is a utility function that retrieves a base URL from an environment variable or defaults to a specific URL if the environment variable is not set. This is a common pattern in code to allow for configuration flexibility and is unlikely to be deleted unless the entire configuration approach changes. It is a simple, self-contained function that serves a clear purpose, making it more likely to survive."
survived,"def download_hf_gpt2(dest: Path | str = ""models/gpt2"", attempts: int = 3) -> None:
    dest_dir = Path(dest)
    base = _base_url()
    last_exc: Exception | None = None
    for name in _FILES:
        url = f""{base}/{name}""
        target = dest_dir / name
        if target.exists():
            print(f""{target} already exists, skipping"")
            continue
        for i in range(1, attempts + 1):
            try:
                print(f""Downloading {url} to {target} (attempt {i})"")
                _download(url, target)
                _verify(target)
                break
            except Exception as exc:  # noqa: PERF203
                last_exc = exc
                if i < attempts:
                    print(f""Attempt {i} failed: {exc}, retrying..."")
                else:
                    print(f""ERROR: could not download {url}: {exc}"")
                    if target.exists():
                        try:
                            target.unlink()
                        except Exception:
                            pass
    if last_exc:
        raise last_exc
",scripts/download_hf_gpt2.py,,1,3.3982678079468468e-09,"The method 'download_hf_gpt2' is a utility function designed to download files from a specified URL to a local directory. It includes error handling, retry logic, and file verification, which are all good practices for robust file downloading. The method is likely to be useful in various contexts where downloading and verifying files is necessary, especially in machine learning or data processing workflows. Additionally, the use of type hints and clear logging messages enhances its maintainability and usability. Therefore, it is likely to be retained in the codebase."
survived,"def main():
    a = 3
    b = ""four""
    print(str(a) + "" "" + str(b))
    res = swap(a, b)
    a = res[0]
    b = res[1]
    print(str(a) + "" "" + str(b))
",tests/rosetta/transpiler/Python/generic-swap.py,,0,0.9999599363048656,"The method 'main' is a simple function that demonstrates variable assignment, string conversion, and a call to a 'swap' function. However, the 'swap' function is not defined within the provided code, which would lead to a NameError when 'main' is executed. Without the definition of 'swap', the code is incomplete and non-functional. This lack of completeness and functionality suggests that the method is more likely to be deleted unless the missing 'swap' function is implemented."
survived,"def testall(list, recursive, toplevel):
    import sys
    import os
    for filename in list:
        if os.path.isdir(filename):
            print(filename + '/:', end=' ')
            if recursive or toplevel:
                print('recursing down:')
                import glob
                names = glob.glob(os.path.join(glob.escape(filename), '*'))
                testall(names, recursive, 0)
            else:
                print('*** directory (use -r) ***')
        else:
            print(filename + ':', end=' ')
            sys.stdout.flush()
            try:
                print(what(filename))
            except OSError:
                print('*** not found ***')
",metaflow/_vendor/imghdr/__init__.py,,0,0.9999998144608401,"The method 'testall' is likely to be deleted because it uses outdated practices and has several issues. Firstly, it uses the same name 'list' as a built-in Python type, which is not recommended. Secondly, the function imports modules inside the function body, which is generally discouraged as it can lead to inefficiencies and unexpected behaviors. Thirdly, the function relies on a function 'what' that is not defined within the code snippet, making it incomplete and potentially non-functional. Lastly, the function's design does not follow modern Python practices, such as using more robust error handling or leveraging newer libraries for file system operations. These factors suggest that the method is not well-suited for contemporary use and is likely to be removed or replaced with a more modern implementation."
survived,"def test_clone_polyfill(tmp_path: Path) -> None:
    script = tmp_path / ""run.mjs""
    script.write_text(
        f""globalThis.structuredClone = undefined;\n""
        f""import clone from '{CLONE_JS.resolve().as_posix()}';\n""
        ""const src = {a:1,b:{c:2}};\n""
        ""const out = clone(src);\n""
        ""out.b.c = 3;\n""
        ""console.log(src.b.c === 2 && out.b.c === 3);\n"",
        encoding=""utf-8"",
    )
    result = subprocess.run([""node"", script], capture_output=True, text=True, check=True)
    assert result.stdout.strip() == ""true""",tests/test_clone_polyfill.py,,1,2.2159489282323004e-08,"The method `test_clone_polyfill` is a test function that verifies the behavior of a polyfill for the `structuredClone` function in JavaScript. It creates a temporary script that uses the polyfill to clone an object and checks if the clone is deep, meaning changes to the nested objects in the clone do not affect the original object. This is a valid and useful test to ensure the polyfill works as expected, especially in environments where `structuredClone` is not natively available. Since it serves a clear purpose in testing the functionality of a polyfill, it is likely to be retained in the codebase."
survived,"def test_umap_fallback_random_coordinates() -> None:
    dist = Path(__file__).resolve().parents[1] / (
        ""alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/dist/index.html""
    )
    url = dist.as_uri()
    try:
        with sync_playwright() as p:
            browser = p.chromium.launch()
            page = browser.new_page()
            page.route(""**/pyodide.js"", lambda route: route.abort())
            page.goto(url)
            page.wait_for_selector(""#controls"")
            page.wait_for_selector(""#simulator-panel"")
            first = _run_sim(page)
            second = _run_sim(page)
            browser.close()
    except PlaywrightError as exc:
        pytest.skip(f""Playwright browser not installed: {exc}"")
    assert first != second
    assert all(len(pt) == 2 for pt in first)
",tests/test_umap_fallback.py,,1,6.023574641292144e-08,"The method 'test_umap_fallback_random_coordinates' is a test function that uses the Playwright library to automate a browser and test a web page. It is designed to ensure that a simulation run on a web page produces different results on consecutive runs, which is a valid test case for randomness or non-deterministic behavior. The function includes error handling to skip the test if Playwright is not installed, which is a good practice for test robustness. Given its purpose and implementation, it is likely to be useful for testing and is not redundant or obsolete. Therefore, it is likely to be retained in the codebase."
survived,"    def gen_trace_id(self) -> str:
        """"""Generate a new trace ID.""""""
        return f""trace_{uuid.uuid4().hex}""
",src/agents/tracing/setup.py,TraceProvider,1,7.582560422162384e-10,"The method 'gen_trace_id' is a simple utility function that generates a unique trace ID using the UUID library. Such utility functions are commonly used in applications for logging, tracing, or tracking purposes. The method is straightforward, has a clear purpose, and does not have any apparent issues or redundancies. Therefore, it is likely to be retained in the codebase."
survived,"    def test_gaussian_param_bounds_and_diversity(self) -> None:
        rng = random.Random(123)
        pop = [mats.Individual([rng.uniform(-0.05, 0.05) for _ in range(2)]) for _ in range(10)]
        base_div = _diversity(pop)
        op = GaussianParam(std=0.3, rng=rng)
        mutated = [mats.Individual(op(ind.genome)) for ind in pop]
        after_div = _diversity(mutated)
        for ind in mutated:
            for gene in ind.genome:
                self.assertGreaterEqual(gene, -1.0)
                self.assertLessEqual(gene, 1.0)
        self.assertGreater(after_div, base_div * 1.3)
",tests/test_mats_ops.py,TestMatsOps,1,4.944450477491054e-09,"The method 'test_gaussian_param_bounds_and_diversity' is a unit test designed to verify the behavior of a Gaussian parameter mutation operation on a population of individuals. It checks two main aspects: 1) that the mutated genes remain within specified bounds (-1.0 to 1.0), and 2) that the diversity of the population increases by at least 30% after mutation. These are important properties to ensure the robustness and effectiveness of the mutation operation in evolutionary algorithms. Since this test is crucial for validating the functionality and correctness of the mutation process, it is likely to be retained in the codebase."
survived,"def resolve_relative_path(target: str, base_path: str) -> str:
    """"""Resolve only the path component for a target.""""""
    path, _ = resolve_module(target, base_path)
    return path",jac/jaclang/utils/module_resolver.py,,1,2.998960815863541e-09,"The method 'resolve_relative_path' is a utility function that resolves the path component of a target relative to a base path. It is a simple and useful function that likely serves a specific purpose in the codebase, such as handling file paths or module paths. Unless there is a significant change in the codebase that makes this function obsolete or redundant, it is likely to survive. Additionally, the function is concise and does not have any apparent issues that would necessitate its deletion."
survived,"def infer_language(target: str, base_path: str) -> str:
    """"""Infer language for target relative to base path.""""""
    _, lang = resolve_module(target, base_path)
    return lang
",jac/jaclang/utils/module_resolver.py,,1,6.023574641292144e-08,"The method 'infer_language' is a simple utility function that infers the language of a target based on a base path. It relies on another function 'resolve_module' to obtain the language information. This type of function is generally useful in projects that involve multi-language support or require language detection based on file paths or module names. Since it serves a specific purpose and is likely part of a larger system, it is more likely to be retained unless the system undergoes a significant redesign or the functionality is no longer needed."
survived,"    def fake_import(name, globals=None, locals=None, fromlist=(), level=0):
        if name == ""openai_agents"":
            raise ModuleNotFoundError(name)
        return orig_import(name, globals, locals, fromlist, level)
",tests/test_llm_client_offline.py,,0,0.9990889485983344,"The method 'fake_import' is a custom implementation of the import mechanism, specifically designed to raise a ModuleNotFoundError when attempting to import a module named 'openai_agents'. This kind of function is typically used for testing purposes, to simulate the absence of certain modules. Such methods are often temporary and used in specific testing scenarios, which suggests that it might be deleted once its purpose is fulfilled. However, if the need to simulate the absence of 'openai_agents' is ongoing, it might be retained. Without more context, it's reasonable to predict that it could be deleted after its specific use case is addressed."
survived,"def test_macro_launcher_health_check(monkeypatch: pytest.MonkeyPatch) -> None:
    """"""Health gate should hit the expected endpoint.""""""
    curl_calls: list[list[str]] = []

    def fake_run(cmd: list[str], *a, **k) -> subprocess.CompletedProcess[str]:
        if cmd[0] == ""curl"":
            curl_calls.append(cmd)
        return subprocess.CompletedProcess(cmd, 0, """", """")

    monkeypatch.setattr(subprocess, ""run"", fake_run)
    monkeypatch.setenv(""OPENAI_API_KEY"", ""dummy-key"")

    mod = __import__(
        ""alpha_factory_v1.demos.macro_sentinel.macro_launcher"", fromlist=[""main""]
    )
    mod.main([])

    urls = "" "".join("" "".join(c) for c in curl_calls)
    assert ""http://localhost:7864/healthz"" in urls",tests/test_macro_launcher.py,,1,9.931195248674785e-08,"The method `test_macro_launcher_health_check` is a unit test function that uses the `monkeypatch` fixture from `pytest` to mock the behavior of the `subprocess.run` function and an environment variable. This is a common practice in testing to isolate the function being tested from external dependencies and side effects. The test checks if a specific endpoint is hit by asserting the presence of a URL in the list of curl calls. This is a valid and useful test for ensuring that the `macro_launcher` module's main function behaves as expected. Since it is a test function and serves a clear purpose in verifying the functionality of the code, it is unlikely to be deleted."
survived,"def test_macro_launcher_no_offline(monkeypatch: pytest.MonkeyPatch) -> None:
    """"""`OPENAI_API_KEY` disables the offline profile.""""""
    compose_calls: list[list[str]] = []

    def fake_run(cmd: list[str], *a, **k) -> subprocess.CompletedProcess[str]:
        if cmd[:2] == [""docker"", ""compose""]:
            compose_calls.append(cmd)
        return subprocess.CompletedProcess(cmd, 0, """", """")

    monkeypatch.setattr(subprocess, ""run"", fake_run)
    monkeypatch.setenv(""OPENAI_API_KEY"", ""dummy-key"")

    mod = __import__(
        ""alpha_factory_v1.demos.macro_sentinel.macro_launcher"", fromlist=[""main""]
    )
    mod.main([])

    cmd_str = "" "".join("" "".join(c) for c in compose_calls)
    assert ""--profile offline"" not in cmd_str
",tests/test_macro_launcher.py,,1,1.6052280526088547e-09,"The method `test_macro_launcher_no_offline` is a unit test that verifies a specific behavior of the `macro_launcher` module when the `OPENAI_API_KEY` environment variable is set. It uses `monkeypatch` to mock the `subprocess.run` method and checks that the `--profile offline` option is not included in the Docker compose commands. This test is useful for ensuring that the application behaves correctly under certain conditions, and it is likely to be maintained as long as the functionality it tests is relevant. Therefore, the method is likely to survive."
survived,"    async def run_cycle(self) -> None:
        await asyncio.sleep(0)
",tests/test_orchestrator.py,DummyAgent,0,0.9999999865595903,"The method 'run_cycle' is an asynchronous function that simply awaits a sleep of 0 seconds. This means it effectively does nothing and serves no practical purpose in its current form. Without any additional logic or context, it is likely to be considered redundant and removed in future iterations of the code."
survived,"def test_load_sectors_names(tmp_path: Path) -> None:
    path = tmp_path / ""s.json""
    path.write_text(json.dumps([""a"", ""b""]))
    secs = sector.load_sectors(path)
    assert [s.name for s in secs] == [""a"", ""b""]
",tests/test_sector_loader.py,,1,6.348800075736417e-09,"The method 'test_load_sectors_names' is a unit test function that verifies the functionality of the 'load_sectors' method from the 'sector' module. It checks if the method correctly loads sector names from a JSON file. Unit tests are crucial for ensuring code reliability and are typically maintained as long as the functionality they test is relevant. Since this test is directly tied to the functionality of loading sector names, it is likely to be retained as long as the 'load_sectors' method exists and is used. Therefore, the method will likely survive."
survived,"  def __init__(
    self,
    backend: IncubatorBackend,
    name: str,
    size_x: float,
    size_y: float,
    size_z: float,
    racks: List[PlateCarrier],
    loading_tray_location: Coordinate,
    rotation: Optional[Rotation] = None,
    category: Optional[str] = None,
    model: Optional[str] = None,
  ):
    Machine.__init__(self, backend=backend)
    self.backend: IncubatorBackend = backend  # fix type
    Resource.__init__(
      self,
      name=name,
      size_x=size_x,
      size_y=size_y,
      size_z=size_z,
      rotation=rotation,
      category=category,
      model=model,
    )
    self.loading_tray = PlateHolder(
      name=self.name + ""_tray"", size_x=127.76, size_y=85.48, size_z=0, pedestal_size_z=0
    )
    self.assign_child_resource(self.loading_tray, location=loading_tray_location)

    self._racks = racks
    for rack in self._racks:
      self.assign_child_resource(rack, location=None)
",pylabrobot/storage/incubator.py,Incubator,1,1.8553915987649156e-07,"The method is a constructor (__init__) for a class that initializes an object with several attributes and sets up relationships between components. Constructors are fundamental to object-oriented programming as they define how an object is created and initialized. This particular constructor is setting up a complex object with dependencies and child resources, which is a common pattern in software design. Therefore, it is unlikely to be deleted unless the entire class or its functionality is being removed or refactored, which is not indicated here."
survived,"  async def setup(self):
    await self.io.setup()
    await self.initialize()
    await self.wait_for_task_completion()
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend,1,1.955568070542584e-08,"The method 'setup' is an asynchronous method that calls three other asynchronous methods: 'self.io.setup()', 'self.initialize()', and 'self.wait_for_task_completion()'. This pattern is common in asynchronous programming where setup or initialization tasks need to be completed before proceeding. The method is likely to be essential for ensuring that the necessary setup and initialization steps are completed in the correct order before any further operations are performed. Therefore, it is unlikely to be deleted unless the entire setup process is refactored or the method's functionality is no longer needed."
survived,"  async def stop(self):
    await self.io.stop()
",pylabrobot/storage/cytomat/heraeus_cytomat_backend.py,HeraeusCytomatBackend,1,6.348800075736417e-09,"The method 'stop' is an asynchronous function that calls 'self.io.stop()'. Without additional context, it seems to be a straightforward method that serves a specific purpose, likely related to stopping an I/O operation. Such methods are typically essential for managing resources and ensuring proper shutdown of operations, especially in asynchronous programming. Unless there is a significant change in the design or architecture that makes this method redundant or unnecessary, it is likely to be retained."
survived,"  def racks(self) -> List[PlateCarrier]:
    assert self._racks is not None, ""Backend not set up?""
    return self._racks
",pylabrobot/storage/backend.py,IncubatorBackend,1,1.1032560311263802e-09,"The method 'racks' is a simple getter method that returns a list of 'PlateCarrier' objects stored in the '_racks' attribute. It includes an assertion to ensure that '_racks' is not None, which is a basic validation to prevent runtime errors. Getter methods like this are common and useful for encapsulating access to class attributes, especially when they include validation logic. Unless there is a significant change in the design that makes this method redundant or its functionality is moved elsewhere, it is likely to survive."
survived,"  def serialize(self) -> dict:
    return {
      **super().serialize(),
      ""port"": self.io.port,
    }
",pylabrobot/storage/cytomat/heraeus_cytomat_backend.py,HeraeusCytomatBackend,1,1.4166087846364157e-09,"The method `serialize` is a common pattern used in object-oriented programming to convert an object into a dictionary format, which is useful for serialization purposes such as saving to a file or sending over a network. The method extends a superclass's `serialize` method and adds additional information specific to the subclass, which is a typical and useful practice. There is no indication that this method is redundant or unnecessary, so it is likely to be retained."
survived,"  async def get_humidity(self) -> CytomatIncupationResponse:
    return await self.get_incubation_query(""ih"")
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend,1,2.1724399346070676e-10,"The method `get_humidity` is an asynchronous function that calls another method `get_incubation_query` with a specific parameter ""ih"". This suggests that it is part of a larger system, likely dealing with environmental or incubation data. The method is specific and likely serves a clear purpose within its context, such as retrieving humidity data from an incubation system. Without any indication of redundancy, deprecation, or replacement, it is reasonable to predict that this method will survive."
survived,"  async def get_incubation_query(
    self, query: Literal[""ic"", ""ih"", ""io"", ""it""]
  ) -> CytomatIncupationResponse:
    resp = await self.send_command(""ch"", query, """")
    nominal, actual = resp.split()
    return CytomatIncupationResponse(
      nominal_value=float(nominal.lstrip(""+"")), actual_value=float(actual.lstrip(""+""))
    )
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend,1,8.592166611791576e-10,"The method 'get_incubation_query' is an asynchronous function that sends a command and processes the response to return a structured result. It is well-defined, uses type hints, and seems to be part of a larger system that interacts with a device or service. There is no indication of it being deprecated or unnecessary, and it appears to serve a specific purpose in querying incubation data. Therefore, it is likely to be retained in the codebase."
survived,"  async def wait_for_transfer_station(self, occupied: bool = False):
    while (await self.read_plate_detection_xfer()) != occupied:
      await asyncio.sleep(1)
",pylabrobot/storage/cytomat/heraeus_cytomat_backend.py,HeraeusCytomatBackend,1,1.8189616842444243e-09,"The method 'wait_for_transfer_station' is a simple asynchronous loop that waits for a condition to be met. It is likely to be useful in scenarios where a process needs to wait for a transfer station to become occupied or unoccupied. The method is straightforward, uses asynchronous programming effectively, and does not have any apparent issues or redundancies that would warrant its deletion. Therefore, it is likely to be retained in the codebase."
survived,"  async def wait_for_task_completion(self, timeout=60) -> OverviewRegisterState:
    """"""
    Wait for the cytomat to finish the current task. This is done by checking the overview register
    until the busy bit is not set. If the cytomat is busy for too long, a TimeoutError is raised.
    If the error bit is set in the overview register, the error register is read and the corresponding
    error is raised.
    """"""
    start = time.time()
    while True:
      overview_register = await self.get_overview_register()
      if not overview_register.busy_bit_set:
        # only check for errors once the cytomat is done, so that the user has the chance to
        # handle the error and proceed if desired.
        if overview_register.error_register_set:
          error_register = await self.get_error_register()
          await self.reset_error_register()
          raise error_register_map[error_register]
        return overview_register
      await asyncio.sleep(1)
      if time.time() - start > timeout:
        raise TimeoutError(""Cytomat did not complete task in time"")
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend,1,4.944450477491054e-09,"The method 'wait_for_task_completion' is well-defined and serves a critical function in ensuring that a task is completed within a specified timeout period. It handles both the completion and error states effectively, providing a mechanism to raise appropriate errors if the task does not complete or if an error occurs. This kind of functionality is essential in asynchronous programming, especially when dealing with hardware or external systems where tasks may take variable amounts of time to complete. Therefore, it is likely to be retained in the codebase."
survived,"def _cytomat_rack(name: str, site_height: float, num_sites: int, model: str):
  start = 17.6  # roughly measured, not important right now
  return PlateCarrier(
    name=name,
    size_x=109,  # roughly measured, not important right now
    size_y=142,  # roughly measured, not important right now
    size_z=541,  # roughly measured, not important right now
    sites={
      i: PlateHolder(
        size_x=85.48,
        size_y=127.27,
        # the last site is always 50mm or taller.
        size_z=max(site_height, 50) if i == num_sites - 1 else site_height,
        name=f""{name}-{i + 1}"",
        pedestal_size_z=0,
      ).at(
        Coordinate(
          x=11.76,  # estimate
          y=0,  # estimate
          z=start + site_height * i,
        )
      )
      for i in range(num_sites)
    },
    model=model,
  )
",pylabrobot/storage/cytomat/racks.py,,1,1.3440409770490404e-08,"The method '_cytomat_rack' is a utility function that constructs and returns a 'PlateCarrier' object with specific configurations. It is likely part of a larger system dealing with laboratory equipment or similar setups. The method is well-defined, uses parameters effectively, and seems to serve a specific purpose in the context of the application. There is no indication of redundancy or obsolescence in the code provided, suggesting it is still relevant and useful. Therefore, it is likely to be retained in the codebase."
survived,"def test_merge_versions(tmp_path):
    reg = TemplateRegistry(base_dir=tmp_path)
    manager = TemplateSharingManager(reg)
    meta = _meta(""demo"")
    reg.register(meta, ""first"", version=""0.1.0"")
    reg.register(meta, ""second"", version=""0.2.0"")

    merged = manager.merge_versions(""demo"", ""0.1.0"", ""0.2.0"")
    assert merged.strip() == ""second""",tests/test_template_sharing.py,,1,3.581747929000289e-10,"The method 'test_merge_versions' is likely to be Survived (1) because it is a test function that verifies the functionality of merging template versions in a template management system. Test functions are crucial for ensuring code reliability and correctness, especially in systems that handle versioning and data management. The presence of assertions indicates that this test is used to validate expected behavior, which is an essential part of maintaining software quality."
survived,"    def export_template(self, slug: str, *, version: str = ""latest"") -> Dict[str, Any]:
        """"""Return a JSON-serialisable representation of a template.""""""
        content = self.registry.load_template(slug, version)
        if content is None:
            raise ValueError(f""Template {slug}@{version} not found"")
        slug_sanitized = slug.replace("" "", ""_"").lower()
        if version == ""latest"":
            manifest = self.registry._load_manifest()
            version = manifest.get(slug_sanitized, {}).get(""current_version"", ""0.1.0"")
        meta_path = (
            self.registry.templates_dir
            / slug_sanitized
            / f""v{version.replace('.', '_')}""
            / METADATA_FILE_NAME
        )
        metadata: Dict[str, Any] = {}
        try:
            with open(meta_path, ""r"", encoding=""utf-8"") as f:
                metadata = json.load(f)
        except (OSError, json.JSONDecodeError):
            pass
        return {""metadata"": metadata, ""content"": content}
",src/meta_agent/template_sharing.py,TemplateSharingManager,1,1.8189616842444243e-09,"The method 'export_template' is well-defined and serves a clear purpose: to return a JSON-serializable representation of a template. It includes error handling for missing templates and attempts to load metadata, which are both useful features. The method is likely part of a larger system that manages templates, and its functionality is essential for exporting template data. There is no indication that this method is redundant or obsolete, and it appears to be a necessary part of the system's functionality. Therefore, it is likely to be retained."
survived,"    def import_template(self, data: Dict[str, Any]) -> Optional[str]:
        """"""Import a template from an exported dictionary.""""""
        meta = data.get(""metadata"") or {}
        content = data.get(""content"", """")
        if not meta:
            raise ValueError(""Missing metadata"")
        metadata = TemplateMetadata(
            slug=meta[""slug""],
            title=meta.get(""title"", meta[""slug""]),
            description=meta.get(""description"", """"),
            category=meta.get(""category""),
            subcategory=meta.get(""subcategory""),
            complexity=meta.get(""complexity""),
            tags=meta.get(""tags"", []),
        )
        version = meta.get(""version"", ""0.1.0"")
        creator = TemplateCreator(self.registry)
        return creator.create(metadata, content, version=version, validate=False)
",src/meta_agent/template_sharing.py,TemplateSharingManager,1,2.1724399346070676e-10,"The method 'import_template' is likely to survive because it performs a specific and useful function: importing a template from a dictionary. It includes error handling for missing metadata, constructs a 'TemplateMetadata' object, and uses a 'TemplateCreator' to create the template. These operations suggest that the method is part of a larger system for managing templates, and its functionality is necessary for that system."
survived,"def unique_values(
    array: NamedArray,
    Unique: Axis,
    *,
    axis: AxisSelector | None = None,
    fill_value: ArrayLike | None = None,
) -> NamedArray:
    """"""Shortcut for :func:`unique` that returns only unique values.""""""

    return typing.cast(
        NamedArray,
        unique(
            array,
            Unique,
            axis=axis,
            fill_value=fill_value,
        ),
    )
",src/haliax/ops.py,,1,1.725782769012759e-08,"The method 'unique_values' is a simple wrapper around the 'unique' function, providing a more specific interface for returning only unique values from a NamedArray. It is likely to be retained because it offers a clear and concise way to achieve a common task, improving code readability and usability. Additionally, it uses type casting to ensure the return type is consistent, which is a good practice in typed languages."
survived,"def test_create_patch_no_entries(tmp_path: Path) -> None:
    repo = _make_repo(tmp_path)
    agent = MetaRefinementAgent(repo, tmp_path / ""logs"")
    patch = agent._create_patch([])
    assert ""optimise performance"" in patch
",tests/test_meta_refinement_agent.py,,1,3.653482080241728e-08,"The method `test_create_patch_no_entries` is a unit test function that checks the behavior of the `_create_patch` method when no entries are provided. It is a simple and straightforward test that ensures the functionality of the code it is testing. Such tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is likely to be retained in the codebase."
survived,"    def _generate_basic_docs(self, spec: ToolSpecification) -> str:
        """"""Return minimal documentation for a generated tool.""""""
        lines = [
            f""# {spec.name}"",
            """",
            spec.purpose,
            """",
            ""## Inputs"",
        ]
        for p in spec.input_parameters:
            req = ""(Required)"" if p.required else ""(Optional)""
            lines.append(f""- {p.name}: {p.description or 'No description'} {req}"")
        lines.append("""")
        lines.append(""## Output"")
        lines.append(str(spec.output_format))
        return ""\n"".join(lines)
",src/meta_agent/agents/tool_designer_agent.py,ToolDesignerAgent,1,7.582560422162384e-10,"The method `_generate_basic_docs` is a utility function that generates documentation for a tool based on its specification. It is a straightforward and useful method for creating consistent documentation, which is often a necessary part of software development. The method is likely to be used in contexts where tools are dynamically generated or need to be documented programmatically. Since it serves a clear purpose and is not overly complex, it is likely to be retained in the codebase."
survived,"def _cli_output(seed: int) -> list[dict]:
    with patch.object(cli.orchestrator, ""Orchestrator""):
        res = CliRunner().invoke(
            cli.main,
            [
                ""simulate"",
                ""--horizon"",
                ""1"",
                ""--offline"",
                ""--sectors"",
                ""1"",
                ""--pop-size"",
                ""1"",
                ""--generations"",
                ""1"",
                ""--seed"",
                str(seed),
                ""--curve"",
                ""linear"",
                ""--export"",
                ""json"",
            ],
        )
    return json.loads(res.output)
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_wasm_bridge.py,,1,3.850741907939403e-09,"The method '_cli_output' is a utility function that appears to be used for testing or simulating command-line interface (CLI) outputs. It uses the 'CliRunner' from the 'click' testing library to invoke a CLI command and returns the output as a JSON object. This kind of function is typically useful for automated testing or for running simulations in a controlled environment. Given its utility in testing and simulation, it is likely to be retained in the codebase unless the entire testing strategy changes or the CLI commands it tests are deprecated. Therefore, the method is predicted to survive."
survived,"  def test_middle_bits(self):
    self.assertEqual(getbits(0b11010110, 3, 5), 0b010)
",test/unit/test_helpers.py,TestGetBits,1,2.3355930333443423e-09,"The method `test_middle_bits` is a unit test for the function `getbits`. It checks if the function correctly extracts bits from a given position and length from a binary number. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with bit manipulation, which can be error-prone. Therefore, this method is likely to be retained as it serves an important role in verifying the functionality of the `getbits` function."
survived,"def _lambda8():
    draw.get(100)()
    draw.get(400)()
",tests/rosetta/transpiler/Python/cistercian-numerals.py,,0,0.9995121429603662,"The method _lambda8() is a private method indicated by the underscore prefix, suggesting it is intended for internal use within a module or class. The method calls two functions retrieved from a 'draw' object using the 'get' method with specific keys (100 and 400). Without additional context on what 'draw' is or what these functions do, it's difficult to assess the utility or necessity of this method. However, the method itself is very simple and lacks any error handling or documentation, which might suggest it is either a placeholder or a very specific utility function. If the 'draw' object and its methods are crucial to the application, this method might survive. However, if this is part of a refactoring process or if the functionality is deemed unnecessary, it might be deleted. Without more context, the prediction leans slightly towards deletion due to its simplicity and lack of context."
survived,"def _lambda5():
    draw.get(10)()
    draw.get(60)()
",tests/rosetta/transpiler/Python/cistercian-numerals.py,,1,3.5356257528032616e-05,"The method `_lambda5` is a private method (indicated by the underscore) and seems to be part of a larger codebase where `draw` is likely a dictionary or similar structure with callable objects. The method calls two functions stored in `draw` with keys 10 and 60. Without additional context, it's difficult to determine its utility, but the method itself is simple and doesn't contain any apparent errors or deprecated practices. If the `draw` object and its callable elements are still relevant and used elsewhere in the codebase, `_lambda5` is likely to survive. However, if `draw` or the specific keys are no longer relevant, `_lambda5` might be deleted. Given the lack of context, it's reasonable to assume it survives unless the surrounding codebase has changed significantly."
survived,"def _lambda0():
    draw.get(1)()
    draw.get(4)()
",tests/rosetta/transpiler/Python/cistercian-numerals.py,,0,0.9997040427747256,"The method _lambda0() is a private method indicated by the underscore prefix, suggesting it is intended for internal use within a module or class. The method calls two functions retrieved from a 'draw' object, which implies it might be part of a larger system where 'draw' is a dictionary or similar structure containing callable objects. Without additional context on the 'draw' object or the purpose of these calls, it's difficult to determine the method's utility. However, the method itself is very simple and lacks any error handling or documentation, which might suggest it is either a placeholder or a very specific utility function. If the 'draw' object is well-defined and this method is used in the codebase, it might survive. However, if it lacks usage or the 'draw' object is not properly defined, it might be deleted. Given the lack of context, the prediction leans towards deletion due to its simplicity and lack of context."
survived,"def _lambda3():
    draw.get(1)()
    draw.get(8)()
",tests/rosetta/transpiler/Python/cistercian-numerals.py,,0,0.9999785550602307,"The method _lambda3() is a private method (indicated by the underscore) and it directly calls two methods from the 'draw' object using the 'get' method with hardcoded indices 1 and 8. Without context on what 'draw' is or what these indices represent, it's difficult to determine the utility of this method. However, the method lacks flexibility and seems to be a placeholder or a very specific utility function. If the 'draw' object or the indices change, this method would need to be updated, indicating poor maintainability. Unless this method is part of a larger, necessary framework or system, it is likely to be deleted due to its limited use and hardcoded nature."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/consecutive-primes-with-ascending-or-descending-differences.py,,1,7.3382086014706e-07,"The method _now() is a utility function that generates a pseudo-random number based on a seed if _now_seeded is True, or returns the current time in nanoseconds otherwise. This function is useful for testing or scenarios where deterministic behavior is needed. It is unlikely to be deleted because it provides a specific functionality that can be useful in various contexts, such as simulations or testing environments where reproducibility is important."
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    v = 0
    printState(v)
    while True:
        s = state(v)
        if not s.inc:
            break
        v = v + 1
        printState(v)
    while True:
        s = state(v)
        if not s.dec:
            break
        v = v - 1
        printState(v)
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/gui-enabling-disabling-of-controls.py,,1,7.3382086014706e-07,"The method is a main function that appears to be part of a benchmarking or testing script. It measures memory usage and execution time, which are common tasks in performance testing. The function is likely to be retained because it serves a specific purpose in performance analysis, and such functions are typically kept for ongoing testing and optimization purposes."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/floyd-warshall-algorithm2.py,,1,1.0467401685178159e-08,"The method _now() is a utility function that generates a pseudo-random number based on a seed if _now_seeded is True, or returns the current time in nanoseconds if not. This function is likely part of a larger system that requires either a deterministic sequence of numbers (when seeded) or a timestamp. Such utility functions are common in systems that need to simulate time or generate predictable sequences for testing purposes. Given its utility and the fact that it doesn't have any apparent issues or redundancies, it is likely to be retained in the codebase."
survived,"def toFloat(i):
    return float(i)
",tests/rosetta/transpiler/Python/functional-coverage-tree.py,,1,2.998960815863541e-09,"The method 'toFloat' is a simple utility function that converts an input to a float. Such utility functions are common and useful in many programming scenarios where type conversion is needed. It is a straightforward implementation with no apparent issues or redundancies. Therefore, it is likely to be retained in the codebase."
survived,"def padLeft(s, w):
    out = s
    while len(out) < w:
        out = "" "" + out
    return out
",tests/rosetta/transpiler/Python/fusc-sequence.py,,1,1.637377179507321e-07,"The method 'padLeft' is a simple utility function that pads a given string 's' with spaces on the left until it reaches a specified width 'w'. This type of function is commonly used in formatting tasks, such as aligning text output in console applications. Despite its simplicity, it serves a clear purpose and can be useful in various contexts where text alignment is needed. Therefore, it is likely to be retained as it provides a basic yet useful functionality."
survived,"def clearGrid():
    g = []
    y = 0
    while y < height:
        row = []
        x = 0
        while x < width:
            row = row + ["" ""]
            x = x + 1
        g = g + [row]
        y = y + 1
    return g
",tests/rosetta/transpiler/Python/fractal-tree.py,,1,8.76424914819242e-08,"The method 'clearGrid' is a basic implementation to create a 2D grid filled with spaces. It is a utility function that can be useful in various applications such as games, simulations, or any scenario where a grid needs to be initialized. The method is straightforward and serves a clear purpose, which is to initialize a grid of a given size with empty spaces. Unless there is a more efficient or required way to initialize such a grid in the context where this code is used, there is no strong reason to delete it. It is likely to survive as it provides necessary functionality."
survived,"def add4(a3, a2, a1, a0, b3, b2, b1, b0):
    r0 = fa(a0, b0, False)
    r1 = fa(a1, b1, r0.c)
    r2 = fa(a2, b2, r1.c)
    r3 = fa(a3, b3, r2.c)
    return Add4Result(v=r3.c, s3=r3.s, s2=r2.s, s1=r1.s, s0=r0.s)
",tests/rosetta/transpiler/Python/four-bit-adder-1.py,,1,1.2501528648238603e-09,"The method 'add4' is a simple implementation of a 4-bit binary adder using a series of full adders (fa). It takes two 4-bit numbers as input and returns the result as an Add4Result object. The method is straightforward, performs a clear and useful function, and is likely part of a larger system dealing with binary arithmetic. There is no indication of redundancy or inefficiency that would warrant its deletion. Therefore, it is likely to be retained."
survived,"    def pathStr(p):
        s = """"
        first = True
        idx = 0
        while idx < len(p):
            x = p[idx]
            if not first:
                s = s + "" -> ""
            s = s + str(x)
            first = False
            idx = idx + 1
        return s
",tests/rosetta/transpiler/Python/floyd-warshall-algorithm.py,,1,2.8453347280241004e-08,"The method 'pathStr' is a utility function that converts a list of elements into a string representation with elements separated by ' -> '. This is a common task in programming, especially when dealing with paths or sequences that need to be displayed in a human-readable format. The method is simple, clear, and performs its intended function without any apparent issues. It is likely to be useful in various contexts where such a string representation is needed. Therefore, it is more likely to be retained in the codebase."
survived,"def _lambda1(n):
    s = 0.0
    k = 0
    while k <= n:
        s = s + extract(a, k) * extract(b, n - k)
        k = k + 1
    return s
",tests/rosetta/transpiler/Python/formal-power-series.py,,1,4.222831744425583e-06,"The method _lambda1 is a private helper function, as indicated by the underscore prefix, which suggests it is intended for internal use within a module or class. The function appears to perform a calculation involving two sequences or arrays 'a' and 'b', using an 'extract' function to access elements. Without additional context, such as the definition of 'extract' or the purpose of 'a' and 'b', it's difficult to determine if this function is redundant or inefficient. However, the function seems to implement a basic convolution operation, which is a common mathematical operation. Unless there is a more efficient or necessary alternative provided elsewhere in the code, this function is likely to be retained for its utility in performing this specific calculation."
survived,"def fd(a, ord):
    i = 0
    while i < ord:
        j = 0
        while j < len(a) - i - 1:
            a[j] = a[j + 1] - a[j]
            j = j + 1
        i = i + 1
    return a[0:len(a) - ord]
",tests/rosetta/transpiler/Python/forward-difference.py,,1,6.023574641292144e-08,"The method 'fd' is a function that performs a finite difference operation on a list 'a' for a specified number of times 'ord'. This type of function can be useful in numerical analysis and data processing tasks where differences between consecutive elements are needed. The function is simple, has a clear purpose, and does not have any obvious errors or inefficiencies that would warrant its deletion. Therefore, it is likely to be retained for its utility in specific applications."
survived,"def pad(s, w):
    t = s
    while len(t) < w:
        t = "" "" + t
    return t
",tests/rosetta/transpiler/Python/floyds-triangle.py,,1,8.152020648014727e-09,"The method 'pad' is a simple utility function that left-pads a string 's' with spaces until it reaches a specified width 'w'. This type of function is quite common and useful in formatting tasks, especially when dealing with text alignment in console applications or reports. The function is straightforward, performs a clear task, and does not have any obvious flaws or inefficiencies. Therefore, it is likely to be retained in the codebase as it serves a practical purpose."
survived,"def countLetters(s):
    cnt = 0
    i = 0
    while i < len(s):
        ch = s[i:i + 1]
        if ch >= ""A"" and ch <= ""Z"" or ch >= ""a"" and ch <= ""z"":
            cnt = cnt + 1
        i = i + 1
    return cnt
",tests/rosetta/transpiler/Python/four-is-the-number-of-letters-in-the-....py,,1,1.8189616842444243e-09,"The method 'countLetters' is a simple utility function that counts the number of alphabetic characters in a string. It is a basic yet useful function that can be used in various contexts where text processing is required. The logic is straightforward and does not have any apparent flaws or inefficiencies that would necessitate its deletion. Additionally, it serves a clear purpose and is likely to be reused in different parts of a codebase that deals with string manipulation. Therefore, it is likely to survive."
survived,"def spaces(n):
    return repeat("" "", n)
",tests/rosetta/transpiler/Python/functional-coverage-tree.py,,1,8.152020648014727e-09,"The method 'spaces' is a simple utility function that returns a string consisting of 'n' spaces. Such utility functions are often useful in formatting text, creating indents, or aligning output in a user interface. Since it serves a clear purpose and is likely to be used in various contexts where text formatting is required, it is more likely to be retained in the codebase."
survived,"def dayToRep(day):
    y = (day - 1) * 100 // 36525
    if repLeap(y):
        y = y - 1
    d = day - (y + 1) * 36525 // 100 + 365 + (y + 1) // 100 - (y + 1) // 400
    y = y + 1
    m = 1
    sc = 5
    if repLeap(y):
        sc = 6
    while d > 30:
        d = d - 30
        m = m + 1
        if m == 13:
            if d > sc:
                d = d - sc
                m = 1
                y = y + 1
                sc = 5
                if repLeap(y):
                    sc = 6
    return [d, m, y]
",tests/rosetta/transpiler/Python/french-republican-calendar.py,,0,0.9999994956527948,"The method 'dayToRep' is a custom date conversion function that seems to convert a day number into a representative date format. However, the code is not well-documented, and the logic is not clear or standard, which makes it difficult to understand its purpose or correctness. Additionally, the function relies on another function 'repLeap' which is not provided, making it incomplete. Without clear documentation or a standard use case, such custom date conversion functions are often replaced by more reliable and well-tested libraries. Therefore, it is likely to be deleted."
survived,"def repToDay(d, m, y):
    dd = d
    mm = m
    if mm == 13:
        mm = mm - 1
        dd = dd + 30
    if repLeap(y):
        dd = dd - 1
    return 365 * y + (y + 1) // 4 - (y + 1) // 100 + (y + 1) // 400 + 30 * mm + dd - 395
",tests/rosetta/transpiler/Python/french-republican-calendar.py,,0,0.9996200154435826,"The method 'repToDay' seems to be a utility function that converts a date represented by day, month, and year into a day count. However, the logic appears to be flawed or incomplete. For instance, the handling of month 13 and the adjustment for leap years are not standard, and the calculation of days does not align with typical date conversion logic. Additionally, the function relies on an undefined function 'repLeap', which suggests it might not be fully functional or tested. Without proper documentation or context, it is difficult to see its utility or correctness, which might lead to its deletion unless it is part of a larger, well-documented system where its purpose is clear."
survived,"def pow10(n):
    r = 1.0
    i = 0
    while i < n:
        r = r * 10.0
        i = i + 1
    return r
",tests/rosetta/transpiler/Python/formatted-numeric-output.py,,1,0.00010889694352893239,"The method 'pow10' is a simple implementation of calculating 10 raised to the power of 'n'. It uses a loop to multiply 10.0 by itself 'n' times. While this method is functional, it is not the most efficient or concise way to achieve this result in Python, as the built-in '**' operator or the 'math.pow' function can perform this operation more efficiently and with clearer syntax. However, the method is not incorrect or redundant, and it may be used in contexts where such a manual implementation is required or preferred for educational purposes. Therefore, it is likely to survive unless there is a strong emphasis on optimizing or refactoring the code to use more idiomatic Python constructs."
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    print(""The lengths of the first 201 words are:"")
    line = """"
    i = 1
    while i <= 201:
        if i % 25 == 1:
            if i != 1:
                print(line)
            line = pad(i, 3) + "":""
        r = wordLen(i)
        n = r[1]
        line = line + "" "" + pad(n, 2)
        i = i + 1
    print(line)
    print(""Length of sentence so far: "" + str(totalLength()))
    for n in [1000, 10000, 100000, 1000000, 10000000]:
        r = wordLen(n)
        w = r[0]
        l = r[1]
        print(""Word "" + pad(n, 8) + "" is \"""" + w + ""\"", with "" + str(l) + "" letters.  Length of sentence so far: "" + str(totalLength()))
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/four-is-the-number-of-letters-in-the-....py,,1,4.785094849865141e-06,"The method is a main function that appears to be part of a larger program, likely used for benchmarking or testing purposes. It includes functionality to measure memory usage and execution time, which are common in performance testing. The method is not overly complex and serves a clear purpose, making it unlikely to be deleted unless the entire benchmarking functionality is removed or replaced. Additionally, the method is self-contained and does not rely on external factors that might lead to its removal."
survived,"def test_trivial_maze_rejected(monkeypatch: pytest.MonkeyPatch) -> None:
    """"""Generator should reject easy mazes when thresholds active.""""""
    monkeypatch.setenv(""NO_LLM"", ""1"")
    monkeypatch.setenv(""ALPHA_ASI_SILENT"", ""1"")
    monkeypatch.setenv(""ALPHA_ASI_MAX_STEPS"", ""1"")
    monkeypatch.setenv(""ALPHA_ASI_MC_MIN"", ""0.2"")
    monkeypatch.setenv(""ALPHA_ASI_MC_MAX"", ""0.8"")
    module = ""alpha_factory_v1.demos.alpha_asi_world_model.alpha_asi_world_model_demo""
    if module in sys.modules:
        del sys.modules[module]
    mod = importlib.import_module(module)

    calls: list[float] = [1.0, 0.5]

    def fake_eval(self, env, policy, episodes):
        return calls.pop(0)

    monkeypatch.setattr(mod.POETGenerator, ""_mc_eval"", fake_eval)

    gen = mod.POETGenerator()
    env = gen.propose()
    assert env in gen.pool
    assert not calls  # second env accepted",tests/test_world_model_open_endedness.py,,1,3.466327708641819e-07,"The method 'test_trivial_maze_rejected' is a unit test function that uses the 'monkeypatch' fixture from pytest to modify the environment variables and behavior of a module for testing purposes. It is a specific test case designed to ensure that the POETGenerator correctly rejects trivial mazes based on certain thresholds. Such test functions are typically retained as they are crucial for verifying the correctness of the code and ensuring that changes do not introduce regressions. Therefore, it is unlikely to be deleted."
survived,"def test_tree_invariants_during_sampling():
    n_topics = 3
    vocab_size = 9
    doc_len = 20
    n_docs = 5
    corpus, vocab = generate_corpus(n_topics, vocab_size, doc_len, n_docs)

    hlda = HierarchicalLDA(corpus, vocab, alpha=1.0, gamma=1.0, eta=1.0,
                           num_levels=3, seed=0, verbose=False)

    total_nodes_history = []
    root_cust_history = []
    for _ in range(20):
        for d in range(n_docs):
            hlda.sample_path(d)
        for d in range(n_docs):
            hlda.sample_topics(d)
        total_nodes_history.append(hlda.root_node.total_nodes)
        root_cust_history.append(hlda.root_node.customers)
        for leaf in hlda.document_leaves.values():
            assert leaf.level == hlda.num_levels - 1
            node = leaf
            depth = 0
            while node.parent is not None:
                node = node.parent
                depth += 1
            assert depth == hlda.num_levels - 1

    assert all(cust == n_docs for cust in root_cust_history)
    diffs = np.diff(total_nodes_history)
    assert (diffs > 0).any() and (diffs < 0).any()",tests/test_synthetic_hlda.py,,1,3.927863699585036e-07,"The method is a test function that verifies the invariants of a hierarchical LDA model during sampling. It checks the structure and properties of the tree, ensuring that the model behaves as expected. Test functions are crucial for maintaining code quality and ensuring that changes do not introduce bugs. Therefore, it is likely to be retained as part of the test suite."
survived,"def get_secret(name: str, default: Optional[str] = None) -> Optional[str]:
    """"""Return ``name`` from the configured secret backend or environment.

    The backend is selected via ``AGI_INSIGHT_SECRET_BACKEND``. Supported values
    are ``vault``, ``aws`` and ``gcp``. When unset or empty, the environment
    variable ``name`` is returned. Any backend error logs a warning and falls
    back to ``os.getenv(name, default)``.
    """"""
    backend = os.getenv(""AGI_INSIGHT_SECRET_BACKEND"", """").lower()
    if not backend or backend == ""env"":
        return os.getenv(name, default)

    if backend == ""vault"":
        try:  # pragma: no cover - optional deps
            import importlib

            hvac = importlib.import_module(""hvac"")

            addr = os.environ[""VAULT_ADDR""]
            token = os.environ[""VAULT_TOKEN""]
            secret_path = os.getenv(f""{name}_PATH"", name)
            client = hvac.Client(url=addr, token=token)
            data = client.secrets.kv.read_secret_version(path=secret_path)
            return cast(Optional[str], data[""data""][""data""].get(name, default))
        except Exception as exc:  # noqa: BLE001
            _log.warning(""Vault secret '%s' failed: %s"", name, exc)
            return os.getenv(name, default)

    if backend == ""aws"":
        try:  # pragma: no cover - optional deps
            import importlib

            boto3 = importlib.import_module(""boto3"")

            region = os.getenv(""AWS_REGION"", ""us-east-1"")
            secret_id = os.getenv(f""{name}_SECRET_ID"", name)
            client = boto3.client(""secretsmanager"", region_name=region)
            resp = client.get_secret_value(SecretId=secret_id)
            return cast(Optional[str], resp.get(""SecretString"", default))
        except Exception as exc:  # noqa: BLE001
            _log.warning(""AWS secret '%s' failed: %s"", name, exc)
            return os.getenv(name, default)

    if backend == ""gcp"":
        try:  # pragma: no cover - optional deps
            import importlib

            secretmanager = importlib.import_module(""google.cloud.secretmanager"")

            project = os.environ[""GCP_PROJECT_ID""]
            secret_id = os.getenv(f""{name}_SECRET_ID"", name)
            client = secretmanager.SecretManagerServiceClient()
            secret_name = f""projects/{project}/secrets/{secret_id}/versions/latest""
            resp = client.access_secret_version(name=secret_name)
            return cast(str, resp.payload.data.decode(""utf-8""))
        except Exception as exc:  # noqa: BLE001
            _log.warning(""GCP secret '%s' failed: %s"", name, exc)
            return os.getenv(name, default)

    _log.warning(""Unknown secret backend '%s'"", backend)
    return os.getenv(name, default)
",src/utils/config.py,,1,4.363462233903899e-09,"The method `get_secret` is a utility function designed to retrieve secrets from various backends (Vault, AWS, GCP) or environment variables. It is a crucial part of applications that need to securely manage and access sensitive information. The function is well-structured, handles exceptions gracefully, and provides fallbacks to environment variables if the primary method fails. This makes it robust and versatile for different deployment environments. Given the importance of secret management in software applications, this method is likely to be retained and maintained rather than deleted."
survived,"def configure() -> None:
    """"""Initialise tracing and metrics if the SDK is installed.""""""
    global tracer, meter
    if trace is None:
        return

    endpoint = os.getenv(""OTEL_EXPORTER_OTLP_ENDPOINT"")
    if endpoint:
        span_exporter = OTLPSpanExporter(endpoint=endpoint)
        metric_exporter = OTLPMetricExporter(endpoint=endpoint)
    else:
        span_exporter = ConsoleSpanExporter()
        metric_exporter = ConsoleMetricExporter()

    resource = Resource.create({""service.name"": ""alpha-insight""})
    provider = TracerProvider(resource=resource)
    provider.add_span_processor(BatchSpanProcessor(span_exporter))
    trace.set_tracer_provider(provider)
    tracer = trace.get_tracer(""alpha_insight"")

    meter_provider = MeterProvider(
        resource=resource,
        metric_readers=[PeriodicExportingMetricReader(metric_exporter)],
    )
    metrics.set_meter_provider(meter_provider)
    meter = metrics.get_meter(""alpha_insight"")
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/tracing.py,,1,8.152020648014727e-09,"The method 'configure' is likely to survive because it serves a critical function in initializing tracing and metrics, which are essential for monitoring and debugging applications. The method checks for the presence of an environment variable to determine the appropriate exporters to use, ensuring flexibility and adaptability in different environments. Additionally, it sets up providers and processors for both tracing and metrics, which are fundamental components in observability frameworks. The presence of global variables 'tracer' and 'meter' also suggests that this method is integral to the application's operation, as these variables are likely used elsewhere in the codebase."
survived,"        def eval_fn(genome: list[float]) -> tuple[float, float, float]:
            x, y = genome
            return x**2, y**2, (x + y) ** 2
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/api_server.py,,1,3.850741907939403e-09,"The method 'eval_fn' is a simple function that takes a list of two floats and returns a tuple of three floats, each representing a mathematical operation on the input values. The function is straightforward, performs basic operations, and is likely to be useful in contexts where such evaluations are needed, such as genetic algorithms or optimization problems. There is no indication that this method is redundant or unnecessary, so it is likely to be retained."
survived,"    def test_env_override(self):
        data = [{""alpha"": ""env test""}]
        tmp = Path(""/tmp/opps.json"")
        tmp.write_text(json.dumps(data), encoding=""utf-8"")
        os.environ[""ALPHA_OPPS_FILE""] = str(tmp)
        try:
            agent = biz.AlphaOpportunityAgent()
            self.assertEqual(agent._opportunities, data)
        finally:
            del os.environ[""ALPHA_OPPS_FILE""]
            tmp.unlink()
",tests/test_alpha_opportunity_env.py,TestAlphaOpportunityEnv,1,3.850741907939403e-09,"The method `test_env_override` is a unit test designed to verify that the `AlphaOpportunityAgent` correctly reads and uses data from a file specified by an environment variable. This is a common and useful test pattern to ensure that environment variable overrides are functioning as expected. The method is well-structured, using a temporary file and cleaning up after itself by deleting the environment variable and the file. Such tests are crucial for maintaining the reliability of software that depends on environment configurations. Therefore, it is unlikely to be deleted as it serves an important purpose in the testing suite."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/str_builtin.py,,1,8.152020648014727e-09,"The method _fmt is a utility function that formats different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted for display or logging. Its simplicity and general applicability suggest that it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/cast_struct.py,,1,2.3355930333443423e-09,"The method _fmt is a utility function that formats different types of input values into strings. It handles lists by recursively formatting each element, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted consistently for output or logging. Its versatility and simplicity make it likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/query_sum_select.py,,1,3.3982678079468468e-09,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted for display or logging. Its simplicity and general applicability suggest that it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/len_string.py,,1,3.3982678079468468e-09,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted for display or logging. Its simplicity and general applicability suggest that it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/for_map_collection.py,,1,2.3355930333443423e-09,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted for display or logging. Its simplicity and general applicability suggest that it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/right_join.py,,1,3.3982678079468468e-09,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted for display or logging purposes. Since it provides a clear and reusable way to handle common formatting tasks, it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/basic_compare.py,,1,4.944450477491054e-09,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, and it converts floats that are whole numbers into integers before converting them to strings. This kind of utility function is often useful in data processing or logging tasks where consistent string representation is needed. Given its utility and the fact that it handles common data types, it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/avg_builtin.py,,1,2.0611536181902033e-09,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in many programming scenarios where data needs to be formatted for display or logging purposes. Since it provides a clear and useful functionality, it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/map_int_key.py,,1,7.194132978569833e-09,"The method _fmt is a utility function that formats different types of input values into strings. It handles lists by recursively formatting each element, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted consistently for output or logging. Its simplicity and general applicability make it likely to be retained in the codebase."
survived,"def ingest() -> pd.DataFrame:
    """"""Ingest headline metrics from the PostHog query API.""""""
    import requests
    from dagster import get_dagster_logger

    logger = get_dagster_logger()

    api_key = os.getenv(""POSTHOG_API_KEY"")
    project_id = os.getenv(""POSTHOG_PROJECT_ID"")
    if not api_key or not project_id:
        raise RuntimeError(
            ""POSTHOG_API_KEY and POSTHOG_PROJECT_ID env vars must be set""
        )

    host = os.getenv(""POSTHOG_HOST"", ""https://app.posthog.com"")
    url = f""{host}/api/projects/{project_id}/query""
    headers = {
        ""Authorization"": f""Bearer {api_key}"",
        ""Content-Type"": ""application/json"",
    }

    query = """"""
        SELECT
            count() AS events_yesterday,
            count(DISTINCT person_id) AS users_yesterday
        FROM events
        WHERE timestamp >= toStartOfDay(now() - INTERVAL 1 day)
          AND timestamp < toStartOfDay(now())
    """"""

    try:
        response = requests.post(
            url, headers=headers, json={""query"": query}, timeout=10
        )
        response.raise_for_status()
    except requests.RequestException as ex:
        logger.error(f""Failed to fetch PostHog data from {url}: {ex}"")
        return pd.DataFrame(columns=[""metric_timestamp"", ""metric_name"", ""metric_value""])

    data = response.json()

    rows = []
    ts = pd.Timestamp.utcnow().floor(""s"")
    results = data.get(""results"") or data.get(""data"")
    if results:
        first = results[0]
        if isinstance(first, dict):
            events = first.get(""events_yesterday"")
            users = first.get(""users_yesterday"")
        elif isinstance(first, list):
            columns = data.get(""columns"", [])
            try:
                events = first[columns.index(""events_yesterday"")]
            except (ValueError, IndexError):
                events = first[0]
            try:
                users = first[columns.index(""users_yesterday"")]
            except (ValueError, IndexError):
                users = first[1] if len(first) > 1 else None
        else:
            events = users = None

        if events is not None:
            rows.append(
                {
                    ""metric_timestamp"": ts,
                    ""metric_name"": ""posthog.events_yesterday"",
                    ""metric_value"": float(events),
                }
            )
        if users is not None:
            rows.append(
                {
                    ""metric_timestamp"": ts,
                    ""metric_name"": ""posthog.users_yesterday"",
                    ""metric_value"": float(users),
                }
            )

    df = pd.DataFrame(rows)
    df = df.dropna()
    df = df[[""metric_timestamp"", ""metric_name"", ""metric_value""]]
    return df",metrics/examples/posthog/posthog.py,,1,9.237449576640118e-09,"The method 'ingest' is a well-structured function that performs a specific task of querying data from the PostHog API and returning it as a pandas DataFrame. It includes error handling, logging, and environment variable checks, which are good practices for robust code. The function is likely to be useful in contexts where data ingestion from PostHog is required, and there are no apparent issues or deprecated practices that would necessitate its deletion. Therefore, it is likely to survive."
survived,"        def __init__(self, path: str) -> None:
            self.path = path
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_demo_cli.py,DummyArchive,1,5.905303995456778e-10,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. It initializes an instance of the class with a given path, which is likely essential for the class's functionality. Constructors are rarely deleted unless the class itself is being removed or significantly refactored, which is not indicated here. Therefore, it is likely to survive."
survived,"    def fake_run(models: list[str], top_n: int) -> None:
        click.echo(f""models:{','.join(models)} top:{top_n}"")
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_demo_cli.py,,1,1.6052280526088547e-09,"The method 'fake_run' is a simple utility function that prints out a formatted string using the 'click.echo' function. It is likely used for debugging or logging purposes. The method is straightforward, does not have any complex logic, and serves a clear purpose. Such utility functions are often retained in codebases for their simplicity and usefulness in providing quick feedback or logging information. Therefore, it is likely to survive."
survived,"def test_agents_status_requires_token(monkeypatch) -> None:
    monkeypatch.delenv(""API_TOKEN"", raising=False)
    with patch.object(cli.requests, ""get"") as get:
        res = CliRunner().invoke(cli.main, [""agents-status""])
    get.assert_not_called()
    assert res.exit_code == 1
    assert ""API_TOKEN not configured"" in res.output
",tests/test_demo_cli.py,,1,9.736200303530205e-10,"The method 'test_agents_status_requires_token' is a unit test that checks the behavior of a command-line interface (CLI) when an API token is not set. It uses the 'monkeypatch' fixture to temporarily remove the 'API_TOKEN' environment variable and then verifies that the CLI command 'agents-status' fails with an appropriate error message. This is a valid and useful test case to ensure that the application handles missing configuration correctly. Therefore, it is likely to be retained in the codebase."
survived,"def boom(a: int, b: int) -> bool:
    print(""boom"")
    return True
",tests/human/x/python/short_circuit.py,,0,0.999999694097641,"The method 'boom' is a simple function that prints 'boom' and returns True. It doesn't perform any meaningful computation or logic beyond this. In a real-world scenario, such a method might be considered redundant or unnecessary unless it is part of a larger system where this behavior is specifically required. Without additional context or usage, it is likely to be deleted as it doesn't provide any significant functionality."
survived,"def test_adk_summariser_runs(monkeypatch) -> None:
    calls: list[str] = []

    class StubADK:
        def __init__(self) -> None:
            pass

        @classmethod
        def is_available(cls) -> bool:
            return True

        def generate_text(self, prompt: str) -> str:
            calls.append(prompt)
            return ""sum""

    monkeypatch.setattr(base_agent, ""ADKAdapter"", StubADK)

    settings = config.Settings(bus_port=0)
    bus = DummyBus(settings)
    agent = adk_summariser_agent.ADKSummariserAgent(bus, DummyLedger())

    env = messaging.Envelope(""research"", ""summariser"", {""research"": ""r""}, 0.0)
    asyncio.run(agent.handle(env))
    asyncio.run(agent.run_cycle())

    assert calls == [""r""]
    assert bus.published
    topic, sent = bus.published[-1]
    assert topic == ""strategy""
    assert sent.payload[""summary""] == ""sum""",tests/test_adk_agent.py,,1,3.653482080241728e-08,"The method `test_adk_summariser_runs` is a unit test designed to verify the functionality of the `ADKSummariserAgent`. It uses a `monkeypatch` to replace the `ADKAdapter` with a stub class `StubADK` to simulate the behavior of the actual adapter. The test checks if the `generate_text` method is called with the correct prompt and if the agent publishes the expected summary. This test is crucial for ensuring that the summarizer agent behaves as expected, especially in a complex system where components interact with each other. Therefore, it is likely to be retained to maintain the integrity of the system's functionality."
survived,"    def __init__(self, bus: messaging.A2ABus, ledger: ""Ledger"") -> None:
        super().__init__(""summariser"", bus, ledger)
        self._records: list[str] = []
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/adk_summariser_agent.py,ADKSummariserAgent,1,8.592166611791576e-10,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class. Constructors are fundamental components of class definitions in object-oriented programming, and they are rarely deleted unless the entire class is being removed or refactored significantly. Since this method is responsible for setting up the initial state of an object, it is likely to survive."
survived,"        def __init__(self, sender: str = """", recipient: str = """", payload: dict | None = None, ts: float = 0.0) -> None:
            self.sender = sender
            self.recipient = recipient
            self.payload = payload or {}
            self.ts = ts
",tests/test_adk_agent.py,Envelope,1,1.955568070542584e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming in Python. It initializes the instance variables with default values and handles optional parameters effectively. This is a standard and necessary method for setting up objects, and there is no indication that it is redundant or unnecessary. Therefore, it is likely to be retained in the code."
survived,"        def __init__(self) -> None:
            pass
",tests/test_adk_agent.py,StubADK,0,0.9999999907625504,"The method is a constructor that does not perform any initialization or setup tasks, as it only contains a 'pass' statement. This makes it redundant and unnecessary in its current form. Typically, constructors are used to initialize object attributes or perform setup tasks, and having an empty constructor does not serve any purpose. Therefore, it is likely to be deleted in future code refactoring to clean up the codebase."
survived,"        def log(self, env) -> None:
            if env.payload.get(""event""):
                events.append(env.payload[""event""])
",tests/test_orchestrator_backoff.py,DummyLedger,1,5.8291276786344415e-05,"The method 'log' is a simple function that appends an event from the 'env' object to a list called 'events'. However, the method has a few issues: 'events' is not defined within the method or passed as a parameter, which will lead to a NameError. Additionally, the method lacks error handling for cases where 'env.payload' might not have the 'event' key. Despite these issues, the method's core functionality is straightforward and useful for logging events, which is a common requirement in many applications. Therefore, with minor improvements, it can be a valuable part of the codebase."
survived,"def add(a: int, b: int) -> int:
    """"""Add sums a and b.""""""
    return a + b
",runtime/ffi/python/testmod.py,,1,3.2241866333029355e-08,"The method 'add' is a simple and clear implementation of an addition function, which is a fundamental operation in programming. It is correctly typed with type hints, has a straightforward and correct implementation, and includes a docstring, albeit slightly incorrect in wording ('Add sums a and b' should be 'Adds a and b'). Such utility functions are commonly used and unlikely to be deleted unless they are redundant or replaced by a more comprehensive library function. However, given its simplicity and correctness, it is more likely to be retained for basic arithmetic operations."
survived,"    def test_no_cache_header_for_recent_content(self):
        recent_entry = EntryFactory(created=timezone.now())
        response = self.client.get(recent_entry.get_absolute_url())
        assert ""cache-control"" not in response.headers
",blog/tests.py,BlogTests,1,9.237449576640118e-09,"The method is a test case that checks if a 'cache-control' header is not present in the response for recently created content. This is a specific and useful test to ensure that recent content is not cached, which is a common requirement in web applications to ensure users see the most up-to-date information. Test methods like this are generally retained as they help maintain the integrity and correctness of the application."
survived,"def test_uncommon_extension_returns_default(monkeypatch):
    monkeypatch.setenv('XDG_DOWNLOAD_DIR', '/tmp/downloads')
    devicons = reload_devicons('es')
    file = MockFile('file.xyz')
    assert devicons.devicon(file) == 'î˜’'",tests/test_devicons.py,,1,8.592166611791576e-10,"The method `test_uncommon_extension_returns_default` is a unit test that checks if a file with an uncommon extension returns a default icon. This is a valid and useful test case to ensure that the system behaves correctly when encountering unknown file types. Unit tests are generally not deleted unless they are redundant or incorrect, and this test seems neither. Therefore, it is likely to survive."
survived,"def publish_root(*, db_path: str | Path | None = None, out_file: str | Path = ""archive_root.json"") -> str:
    """"""Publish today's Merkle root and store it in ``out_file``.""""""
    path = Path(db_path or os.getenv(""ARCHIVE_PATH"", ""archive.db""))
    arch = HashArchive(path)
    cid = arch.publish_daily_root()
    Path(out_file).write_text(json.dumps({""cid"": cid}), encoding=""utf-8"")
    return cid
",src/archive/cron.py,,1,1.1032560311263802e-09,"The method 'publish_root' is likely to survive because it performs a specific and useful function: it publishes a Merkle root and stores it in a specified output file. This functionality is relevant for applications that require cryptographic verification or data integrity checks, such as blockchain or distributed ledger technologies. The method is also well-defined, with clear input parameters and a return value, making it easy to use and integrate into larger systems. Additionally, it uses standard libraries and practices, which suggests it is maintainable and adaptable to future needs."
survived,"def test_snark_aggregate(tmp_path: Path) -> None:
    transcript = tmp_path / ""eval.json""
    entries = [
        {""hash"": ""a1"", ""score"": [1.0, 2.0]},
        {""hash"": ""b2"", ""score"": [0.3, 0.7]},
    ]
    transcript.write_text(json.dumps(entries), encoding=""utf-8"")

    proof = aggregate_proof(transcript, [(e[""hash""], e[""score""]) for e in entries])
    assert verify_aggregate_proof(
        transcript, [(e[""hash""], e[""score""]) for e in entries], proof
    )",tests/test_snark.py,,1,1.3709566550544279e-06,"The method 'test_snark_aggregate' is a test function, which is typically used to verify the correctness of code. Test functions are generally not deleted unless they are redundant, incorrect, or replaced by more comprehensive tests. This function appears to be testing the aggregation and verification of proofs, which is likely an important aspect of the system it is part of. Therefore, it is more likely to be maintained or updated rather than deleted."
survived,"def aggregate_proof(transcript_path: str | Path, items: Sequence[tuple[str, Sequence[float]]]) -> str:
    """"""Return aggregated proof for ``items`` using ``generate_proof``.""""""
    proofs = [generate_proof(transcript_path, h, s) for h, s in items]
    blob = "","".join(sorted(proofs)).encode()
    return hashlib.sha256(blob).hexdigest()
",src/utils/snark.py,,1,7.582560422162384e-10,"The method `aggregate_proof` is a utility function that aggregates proofs by generating them for each item and then creating a hash of the sorted proofs. This kind of functionality is often useful in applications that require data integrity and verification, such as blockchain or secure logging systems. The method is well-defined, uses standard libraries, and performs a clear and useful task. There is no indication that this method is obsolete or redundant, and it is likely to be useful in contexts where proof aggregation is needed. Therefore, it is likely to survive."
survived,"    def visit_Continue(self, node):
        self.emit(""continue"")
",tools/any2mochi/py_simple.py,Conv,1,6.348800075736417e-09,"The method `visit_Continue` is a simple visitor pattern implementation that emits the string ""continue"". This is a common pattern in code that processes abstract syntax trees (ASTs) or similar structures, where each node type has a corresponding visit method. The method is straightforward, does not contain any deprecated or problematic code, and serves a clear purpose in its context. Therefore, it is likely to be retained in the codebase."
survived,"    async def _health() -> str:  # noqa: D401
        return ""ok""
",alpha_factory_v1/backend/api_server.py,,1,3.653482080241728e-08,"The method _health is a simple asynchronous function that returns a string 'ok'. It is likely a utility function used to check the health status of a service or application. Such functions are common in web services to provide a quick way to verify that the service is running correctly. Since it serves a clear purpose and is straightforward, it is likely to be retained in the codebase."
survived,"    def _close(self) -> None:
        if not self._producer:
            return
        try:
            self._producer.flush()
            self._producer.close()
        except Exception:  # noqa: BLE001
            log.exception(""Kafka producer close failed"")
",alpha_factory_v1/backend/agent_manager.py,EventBus,1,1.3440409770490404e-08,"The method '_close' is a private method (indicated by the underscore prefix) that is responsible for safely closing a Kafka producer. It checks if the producer exists, attempts to flush and close it, and logs an exception if the operation fails. This is a common pattern for resource management in programming, ensuring that resources are properly released and errors are logged for debugging purposes. The method is likely to be essential for the stability and reliability of the application, especially in production environments where resource leaks can lead to significant issues. Therefore, it is unlikely to be deleted."
survived,"async def maybe_await(fn, *a, **kw):  # type: ignore
    return await fn(*a, **kw) if asyncio.iscoroutinefunction(fn) else await asyncio.to_thread(fn, *a, **kw)
",alpha_factory_v1/backend/agent_manager.py,,1,3.2241866333029355e-08,"The method 'maybe_await' is a utility function that handles both synchronous and asynchronous functions, making it versatile and useful in modern Python codebases that often deal with asynchronous programming. It checks if a function is a coroutine and awaits it if so, otherwise it runs the function in a separate thread. This kind of utility is valuable for writing cleaner and more flexible code, especially in environments where both sync and async functions are used. Therefore, it is likely to be retained in the codebase."
survived,"    async def start(self) -> None:
        """"""Launch heartbeat and regression guard tasks.""""""

        self._hb_task = asyncio.create_task(hb_watch(self.runners))
        self._reg_task = asyncio.create_task(regression_guard(self.runners))
",alpha_factory_v1/backend/agent_manager.py,AgentManager,1,1.3440409770490404e-08,"The method 'start' is an asynchronous function that initializes two tasks using asyncio's create_task method. These tasks are likely essential for the operation of the program, as they involve 'heartbeat' and 'regression guard' functionalities, which are common in systems that require monitoring and error checking. The method is well-defined, uses modern Python async features, and does not show any deprecated or redundant functionality. Therefore, it is unlikely to be deleted."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/join_multi.py,Item,1,7.73442280641062e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is likely to survive because it provides a flexible way to access object attributes, which can be particularly useful in dynamic or reflective programming scenarios."
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/group_by_sort.py,Item,1,5.60279640614594e-09,"The __repr__ method is a special method used to define a string representation of an object. In this case, it returns the string representation of the object's __dict__, which is a dictionary containing all the attributes of the object. This is a common and useful implementation of __repr__ as it provides a clear and detailed view of the object's state, which is helpful for debugging and logging purposes. Therefore, this method is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/group_by_conditional_sum.py,Item,1,2.5109990926928157e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It allows for flexible and dynamic attribute access, which can be particularly useful in scenarios where the attributes are not known at compile time or are dynamically generated. Therefore, this method is likely to be retained as it provides a meaningful and functional feature."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/left_join_multi.py,Item,1,1.1253518384332553e-07,"The method is a simple implementation of the __getitem__ special method, which allows instances of the class to use the bracket notation (e.g., obj[key]) to access attributes. This is a common and useful pattern in Python, especially for classes that aim to mimic dictionary-like behavior. It is likely to be retained as it provides a clear and concise way to access object attributes using keys, enhancing the flexibility and usability of the class."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/left_join.py,Order,1,1.1253518384332553e-07,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in collections like lists or dictionaries. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid use case if the object is designed to allow attribute access via indexing, which can be useful in certain dynamic or flexible data structures. Since this method provides a clear and potentially useful functionality, it is likely to be retained unless there are specific design reasons to remove it."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/group_by_join.py,Customer,1,1.955568070542584e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for cases where the object is designed to behave like a dictionary or similar container, allowing attribute access via keys. Since this method provides a clear and functional purpose, it is likely to be retained in the code."
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/sort_stable.py,Item,1,5.3157849718487075e-08,"The method `__repr__` is a special method in Python used to define a string representation of an object. The implementation provided here returns the string representation of the object's dictionary, which is a common and useful way to represent an object for debugging purposes. This method is likely to be retained because it provides a clear and concise way to inspect the internal state of an object, which is valuable for developers during debugging and logging."
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/right_join.py,Customer,1,1.1861120010657661e-08,"The __repr__ method is a special method used to define a string representation of an object. In this case, it returns the string representation of the object's __dict__, which is a dictionary containing all the attributes of the object. This is a common and useful implementation for debugging purposes, as it provides a clear and complete view of the object's state. Therefore, it is likely to be retained in the code."
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/group_by_conditional_sum.py,Item,1,9.237449576640118e-09,"The method `__repr__` is a special method in Python used to define a string representation of an object. The implementation provided here returns the string representation of the object's dictionary, which is a common and useful way to represent an object for debugging purposes. This method is likely to be retained because it provides a clear and concise way to inspect the internal state of an object, which is valuable for developers during development and debugging. Therefore, it is predicted to survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/group_items_iteration.py,Data,1,9.237449576640118e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern and does not have any apparent issues or redundancies that would warrant its deletion. Therefore, it is likely to be retained in the code."
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/group_by_having.py,Person,1,1.725782769012759e-08,"The method `__repr__` is a special method in Python used to define a string representation for instances of a class. The implementation provided here returns the string representation of the instance's dictionary, which is a common and useful way to represent an object for debugging purposes. This method is likely to be useful for developers to quickly inspect the attributes of an object, making it a valuable addition to the class. Therefore, it is likely to be retained."
survived,"def _mem_stub() -> object:
    vec = type(""Vec"", (), {""recent"": lambda *a, **k: [], ""search"": lambda *a, **k: []})()
    return type(""Mem"", (), {""vector"": vec})()
",tests/test_backend_orchestrator_dev.py,,1,6.475946147757848e-07,"The method _mem_stub is a utility function that creates and returns an instance of a dynamically created class 'Mem', which contains a 'vector' attribute. This 'vector' is an instance of another dynamically created class 'Vec', which has two methods 'recent' and 'search' that return empty lists. The method is likely used as a placeholder or mock object for testing purposes, providing a structure that mimics a more complex object without implementing its full functionality. Such utility functions are common in testing environments to simulate parts of a system that are not the focus of the test. Therefore, it is likely to survive as it serves a specific purpose in testing or development."
survived,"async def _shutdown() -> None:
    """"""Stop the orchestrator loop and wait for the thread to exit.""""""
    global orch, loop_thread
    if orch:
        orch.stop = True
    if loop_thread:
        loop_thread.join(timeout=1)
    orch = None
    loop_thread = None
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,,1,1.0467401685178159e-08,"The method '_shutdown' is a utility function designed to stop an orchestrator loop and ensure the associated thread exits cleanly. It is a necessary part of managing resources and ensuring that threads do not continue running unnecessarily, which can lead to resource leaks or other issues. The method is straightforward, performs a clear and necessary function, and does not appear to have any obvious flaws or redundancies. Therefore, it is likely to be retained in the codebase."
survived,"    def Tool(*_args, **_kw):  # type: ignore
        def _decorator(func):
            return func

        return _decorator
",alpha_factory_v1/demos/alpha_agi_business_v1/openai_agents_bridge.py,,1,6.348800075736417e-09,"The method 'Tool' is a decorator factory that returns a decorator function. It is a common pattern in Python to create decorators that can accept arguments. The use of '*_args' and '**_kw' allows it to accept any number of positional and keyword arguments, making it flexible. The 'type: ignore' comment suggests that the developer is intentionally ignoring type checking for this function, which might be due to its dynamic nature. This pattern is widely used and useful in many scenarios, so it is likely to survive."
survived,"def test_parse_diff_rejects_oversized(tmp_path: Path) -> None:
    repo_src = Path(""alpha_factory_v1/demos/self_healing_repo/sample_broken_calc"")
    repo = tmp_path / ""repo""
    shutil.copytree(repo_src, repo)

    long_lines = [""--- a/calc.py"", ""+++ b/calc.py"", ""@@""] + [""+x"" for _ in range(diff_utils.MAX_DIFF_LINES + 1)]
    big_diff = ""\n"".join(long_lines) + ""\n""

    assert diff_utils.parse_and_validate_diff(big_diff, repo_dir=str(repo)) is None",tests/test_diff_utils_apply.py,,1,4.363462233903899e-09,"The method 'test_parse_diff_rejects_oversized' is a unit test designed to verify that the 'parse_and_validate_diff' function correctly rejects diffs that exceed a certain size limit. This is a common and necessary test to ensure that the system can handle edge cases and prevent potential issues with oversized diffs. Unit tests are generally not deleted unless they are redundant, incorrect, or replaced by more comprehensive tests. Since this test serves a clear purpose in validating the behavior of the 'parse_and_validate_diff' function, it is likely to be retained."
survived,"async def test_sync_entra_groups(mock_get_members, mock_get_groups, neo4j_session):
    """"""Ensure groups and relationships load""""""
    # Load users first for membership relationships
    load_users(neo4j_session, transform_users(MOCK_ENTRA_USERS), TEST_TENANT_ID, TEST_UPDATE_TAG)

    await sync_entra_groups(
        neo4j_session,
        TEST_TENANT_ID,
        TEST_CLIENT_ID,
        TEST_CLIENT_SECRET,
        TEST_UPDATE_TAG,
        {""UPDATE_TAG"": TEST_UPDATE_TAG, ""TENANT_ID"": TEST_TENANT_ID},
    )

    expected_nodes = {
        (""11111111-1111-1111-1111-111111111111"", ""Security Team""),
        (""22222222-2222-2222-2222-222222222222"", ""Developers""),
    }
    assert check_nodes(neo4j_session, ""EntraGroup"", [""id"", ""display_name""]) == expected_nodes

    expected_rels = {
        (""11111111-1111-1111-1111-111111111111"", TEST_TENANT_ID),
        (""22222222-2222-2222-2222-222222222222"", TEST_TENANT_ID),
    }
    assert (
        check_rels(
            neo4j_session,
            ""EntraGroup"",
            ""id"",
            ""EntraTenant"",
            ""id"",
            ""RESOURCE"",
            rel_direction_right=False,
        )
        == expected_rels
    )

    expected_membership = {
        (""ae4ac864-4433-4ba6-96a6-20f8cffdadcb"", ""11111111-1111-1111-1111-111111111111""),
        (""11dca63b-cb03-4e53-bb75-fa8060285550"", ""11111111-1111-1111-1111-111111111111""),
    }
    assert (
        check_rels(
            neo4j_session,
            ""EntraUser"",
            ""id"",
            ""EntraGroup"",
            ""id"",
            ""MEMBER_OF"",
        )
        == expected_membership
    )
",tests/integration/cartography/intel/entra/test_groups.py,,1,2.2159489282323004e-08,"The method `test_sync_entra_groups` is a test function that verifies the functionality of loading groups and relationships into a Neo4j database. It uses mock data and assertions to ensure that the expected nodes and relationships are correctly created. Test functions like this are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is unlikely to be deleted as it serves an important role in the development and maintenance process."
survived,"def load_groups(
    neo4j_session: neo4j.Session,
    groups: List[Dict[str, Any]],
    update_tag: int,
    tenant_id: str,
) -> None:
    logger.info(f""Loading {len(groups)} Entra groups"")
    load(
        neo4j_session,
        EntraGroupSchema(),
        groups,
        lastupdated=update_tag,
        TENANT_ID=tenant_id,
    )
",cartography/intel/entra/groups.py,,1,1.2501528648238603e-09,"The method 'load_groups' is a utility function that loads a list of groups into a Neo4j database session. It is a straightforward function that logs the number of groups being loaded and then calls another function 'load' with the necessary parameters. This method is likely to be part of a larger system that interacts with a Neo4j database, and such utility functions are common in data processing pipelines. There is no indication that this method is obsolete or redundant, and it seems to serve a clear purpose in the context of data loading. Therefore, it is likely to be retained in the codebase."
survived,"    def single_for_current_platform(self) -> RuntimeDependency:
        deps = self.for_current_platform()
        if len(deps) != 1:
            raise RuntimeError(
                f""Expected exactly one runtime dependency for {PlatformUtils.get_platform_id().value}, found {len(deps)}""
            )
        return deps[0]
",src/solidlsp/language_servers/common.py,RuntimeDependencyCollection,1,8.592166611791576e-10,"The method 'single_for_current_platform' is a utility function that ensures there is exactly one runtime dependency for the current platform. It is a specific and useful function for scenarios where exactly one dependency is expected, and it provides a clear error message if this condition is not met. Such utility functions are often retained in codebases because they encapsulate common checks and error handling, making the code more robust and easier to maintain. Therefore, it is likely to survive."
survived,"def get_str_value(node: ast.AST) -> str:
    """"""Extract the string value from ``node`` which must be a str constant.""""""
    if isinstance(node, ast.Str):
        return node.s
    if isinstance(node, ast.Constant) and isinstance(node.value, str):
        return node.value
    raise TypeError(f""Expected string constant, got {type(node)}"")
",src/flynt/utils/utils.py,,1,6.348800075736417e-09,"The method `get_str_value` is a utility function designed to extract string values from AST nodes, specifically handling both `ast.Str` and `ast.Constant` types. This is a common requirement when working with Python's Abstract Syntax Tree (AST) module, especially for code analysis or transformation tasks. The method is straightforward, performs a specific task, and includes error handling for unexpected node types. Given its utility and the fact that it addresses a specific need in AST manipulation, it is likely to be retained in the codebase."
survived,"    def _visit_string_node(self) -> None:
        if self.in_fmt_value:
            self.string_in_string = True
",src/flynt/utils/utils.py,StringInStringVisitor,1,1.6052280526088547e-09,"The method `_visit_string_node` is a private method (indicated by the underscore prefix) and is likely part of a larger class or module. It checks a condition (`self.in_fmt_value`) and sets a flag (`self.string_in_string`) based on that condition. This suggests it is used for internal state management, possibly in a parsing or formatting context. Such methods are typically essential for the internal logic of a class and are not usually deleted unless the entire class or its functionality is being refactored or removed. Without additional context indicating a refactor or deprecation, it is reasonable to assume this method will survive."
survived,"def build_html(entries: list[tuple[str, str, str]]) -> str:
    head = """"""<!-- SPDX-License-Identifier: Apache-2.0 -->
<!DOCTYPE html>
<html lang=\""en\"">
<head>
  <meta charset=\""UTF-8\"">
  <meta name=\""viewport\"" content=\""width=device-width, initial-scale=1\"">
  <title>Alphaâ€‘Factory Demo Gallery</title>
  <link rel=\""stylesheet\"" href=\""stylesheets/cards.css\"">
  <style>
    body { font-family: Arial, sans-serif; margin: 0; padding: 2rem; background: #f7f7f7; }
    h1 { text-align: center; margin-bottom: 1rem; }
    p.subtitle { text-align: center; margin-bottom: 2rem; }
    a.demo-card { text-decoration: none; color: inherit; }
    .demo-card h3 { margin-top: 0.5rem; text-align: center; }
  </style>
</head>
<body>
  <h1>Alphaâ€‘Factory Demo Gallery</h1>
  <p class=\""subtitle\"">Select a demo to explore detailed instructions and watch it unfold in real time.</p>
  <div class=\""demo-grid\"">""""""
    lines = [head]
    for title, preview, link in entries:
        lines.append(f'    <a class=""demo-card"" href=""{html.escape(link)}"">')
        lines.append(f'      <img src=""{html.escape(preview)}"" alt=""{html.escape(title)}"">')
        lines.append(f""      <h3>{html.escape(title)}</h3>"")
        lines.append(""    </a>"")
    lines.append(""  </div>"")
    lines.append('  <p class=""snippet""><a href=""DISCLAIMER_SNIPPET/"">See docs/DISCLAIMER_SNIPPET.md</a></p>')
    lines.append(""</body>\n</html>\n"")
    return ""\n"".join(lines)
",scripts/generate_gallery_html.py,,1,1.3440409770490404e-08,"The method 'build_html' is a utility function that generates an HTML page from a list of entries. It is well-structured, uses standard HTML and CSS, and includes proper escaping for HTML content, which is crucial for security. The method is likely to be useful in various applications where dynamic HTML generation is needed. Therefore, it is likely to be retained."
survived,"    def init(self) -> None:
        """"""Initialize a new repository if one does not already exist.""""""
        if (self.repo_dir / "".git"").exists():
            return
        self.repo_dir.mkdir(parents=True, exist_ok=True)
        self._run(""init"")
        self._run(""config"", ""user.name"", ""meta-agent"")
        self._run(""config"", ""user.email"", ""meta-agent@example.com"")
        self._run(""branch"", ""-M"", ""main"")
",src/meta_agent/git_utils.py,GitManager,1,1.2501528648238603e-09,"The method 'init' is a crucial part of setting up a new repository. It checks if a '.git' directory exists to determine if the repository is already initialized, and if not, it creates the necessary directory structure and runs several commands to initialize the repository and set up user configurations. This functionality is essential for repository management and is unlikely to be removed unless there is a significant change in how repositories are initialized or managed. Therefore, the method is likely to survive."
survived,"    def push(self, remote: str = ""origin"", branch: str = ""main"") -> None:
        self._run(""push"", remote, f""HEAD:{branch}"")",src/meta_agent/git_utils.py,GitManager,1,2.998960815863541e-09,"The method 'push' is a simple utility function that wraps a common git operation, pushing changes to a remote repository. It is likely to be useful in a context where this operation is frequently needed, such as in a version control or CI/CD tool. The method is concise, uses default parameters for common use cases, and leverages an internal '_run' method to execute the command, suggesting it is part of a larger system. There is no indication that this method is obsolete or redundant, so it is likely to be retained."
survived,"def _make_cert(tmp: Path) -> tuple[str, str, bytes]:
    key = rsa.generate_private_key(public_exponent=65537, key_size=2048)
    cert = (
        x509.CertificateBuilder()
        .subject_name(x509.Name([x509.NameAttribute(NameOID.COMMON_NAME, ""localhost"")]))
        .issuer_name(x509.Name([x509.NameAttribute(NameOID.COMMON_NAME, ""localhost"")]))
        .public_key(key.public_key())
        .serial_number(x509.random_serial_number())
        .not_valid_before(datetime.utcnow())
        .not_valid_after(datetime.utcnow() + timedelta(days=1))
        .add_extension(x509.SubjectAlternativeName([x509.DNSName(""localhost"")]), False)
        .sign(key, hashes.SHA256())
    )
    cert_pem = cert.public_bytes(serialization.Encoding.PEM)
    key_pem = key.private_bytes(
        serialization.Encoding.PEM,
        serialization.PrivateFormat.TraditionalOpenSSL,
        serialization.NoEncryption(),
    )
    cert_path = tmp / ""cert.pem""
    key_path = tmp / ""key.pem""
    cert_path.write_bytes(cert_pem)
    key_path.write_bytes(key_pem)
    return str(cert_path), str(key_path), cert_pem
",tests/test_orchestrator_bus_tls_env.py,,1,1.522997951276035e-08,"The method '_make_cert' is a utility function that generates a self-signed certificate and private key, writes them to temporary files, and returns their paths along with the certificate bytes. This functionality is useful for testing purposes, especially in development environments where secure connections are needed without the overhead of obtaining a certificate from a certificate authority. The method is likely to survive because it provides a practical solution for generating certificates on-the-fly, which is a common requirement in many software development and testing scenarios."
survived,"def test_apply_diff_missing_patch(monkeypatch: pytest.MonkeyPatch) -> None:
    diff = """"""--- a/file.txt\n+++ b/file.txt\n@@\n-\n+ok\n""""""
    with tempfile.TemporaryDirectory() as repo:
        open(os.path.join(repo, ""file.txt""), ""w"").close()
        monkeypatch.setattr(_shutil, ""which"", lambda _cmd: None)
        success, output = diff_utils.apply_diff(diff, repo_dir=repo)
        assert not success
        assert output == ""patch command not found""
",tests/test_diff_utils_apply.py,,1,1.0467401685178159e-08,"The method 'test_apply_diff_missing_patch' is a unit test designed to verify the behavior of the 'apply_diff' function when the 'patch' command is not available. It uses the 'monkeypatch' fixture to simulate the absence of the 'patch' command by setting '_shutil.which' to return 'None'. The test then checks that 'apply_diff' returns 'success' as False and outputs the expected error message. This is a valid and useful test case for ensuring robustness in the 'apply_diff' function, especially in environments where the 'patch' command might not be installed. Therefore, the method is likely to be retained as it serves a clear purpose in the test suite."
survived,"def fields(s):
    words = []
    cur = """"
    i = 0
    while i < len(s):
        ch = s[i:i + 1]
        if ch == "" "" or ch == ""\t"" or ch == ""\n"":
            if len(cur) > 0:
                words = words + [cur]
                cur = """"
        else:
            cur = cur + ch
        i = i + 1
    if len(cur) > 0:
        words = words + [cur]
    return words
",tests/rosetta/transpiler/Python/compiler-virtual-machine-interpreter.py,,0,0.999999057755336,"The method 'fields' is a basic implementation of a string splitting function that separates words based on spaces, tabs, and newlines. While it is functional, it is not efficient or idiomatic in Python. The same functionality can be achieved more concisely and efficiently using Python's built-in 'split' method, which handles whitespace splitting by default. Therefore, this method is likely to be deleted in favor of using the built-in method, which is more optimized and easier to read."
survived,"def quibble(items):
    n = len(items)
    if n == 0:
        return ""{}""
    else:
        if n == 1:
            return ""{"" + items[0] + ""}""
        else:
            if n == 2:
                return ""{"" + items[0] + "" and "" + items[1] + ""}""
            else:
                prefix = """"
                for i in range(0, n - 1):
                    if i == n - 1:
                        break
                    if i > 0:
                        prefix = prefix + "", ""
                    prefix = prefix + items[i]
                return ""{"" + prefix + "" and "" + items[n - 1] + ""}""
",tests/rosetta/transpiler/Python/comma-quibbling.py,,1,2.3355930333443423e-09,"The method 'quibble' is a utility function that formats a list of items into a string representation with specific rules for different list lengths. It handles edge cases like empty lists, single-item lists, and lists with two or more items, providing a human-readable format. This kind of utility function is often useful in applications that require formatted output for user interfaces or reports. Since it serves a clear purpose and is implemented correctly, it is likely to be retained in the codebase."
survived,"def succ(c):
    return lambda f: lambda x: f(c(f)(x))
",tests/rosetta/transpiler/Python/church-numerals-1.py,,1,1.522997951276035e-08,"The method 'succ' is a higher-order function that returns a lambda function. It is a form of functional programming that can be used to create successor functions, often seen in Church numerals in lambda calculus. This kind of code is typically used in academic or theoretical contexts rather than practical applications. However, it is a valid and interesting piece of code that demonstrates a concept in computer science. Given its educational value and correctness, it is likely to be Survived."
survived,"def monthWithUniqueDay(b, list):
    for x in list:
        if x.month == b.month and dayUnique(x, list):
            return True
    return False
",tests/rosetta/transpiler/Python/cheryls-birthday.py,,0,0.9999998362622821,"The method 'monthWithUniqueDay' is likely to be deleted because it uses a parameter name 'list' which shadows the built-in Python type 'list'. This can lead to confusion and potential errors in the code. Additionally, the function relies on an undefined function 'dayUnique', which suggests that the code is incomplete or not self-contained, making it less useful or functional in its current state."
survived,"def sqrtApprox(x):
    guess = x
    i = 0
    while i < 20:
        guess = (guess + x / guess) / 2.0
        i = i + 1
    return guess
",tests/rosetta/transpiler/Python/cholesky-decomposition.py,,1,5.3157849718487075e-08,"The method 'sqrtApprox' is a basic implementation of the Newton-Raphson method for approximating the square root of a number. This method is a well-known and efficient algorithm for finding square roots, and it is often used in educational contexts to demonstrate iterative approximation techniques. The code is simple, clear, and performs its intended function effectively. There are no obvious issues or inefficiencies that would necessitate its deletion. Therefore, it is likely to be retained."
survived,"def id(x):
    return x
",tests/rosetta/transpiler/Python/church-numerals-2.py,,1,4.6911638017642294e-08,"The method 'id' is a simple identity function that returns its input without any modification. Such a function is often used in functional programming and can be useful in various contexts, such as when a function is required as an argument but no transformation is needed. It is a fundamental utility function that can be used in many scenarios, especially in higher-order functions or as a default parameter. Therefore, it is likely to be retained in the codebase."
survived,"def diagu(c1, c2, r):
    c = c1
    while c <= c2:
        n[r - c + c1][c] = ""x""
        c = c + 1
",tests/rosetta/transpiler/Python/cistercian-numerals.py,,0,0.9999785550602307,"The method 'diagu' appears to be a utility function that marks a diagonal line on a 2D grid 'n' with 'x'. However, the function lacks context, such as the definition of 'n' and how it is used. Without this context, it's difficult to determine its utility or correctness. Additionally, the function does not handle edge cases or input validation, which are important for robust code. Given these factors, the method is likely to be deleted unless it is part of a larger, well-defined system where its purpose is clear and necessary."
survived,"def demo(a):
    print(""A:"")
    printMat(a)
    l = cholesky(a)
    print(""L:"")
    printMat(l)
",tests/rosetta/transpiler/Python/cholesky-decomposition.py,,1,4.363462233903899e-09,"The method 'demo' is a simple demonstration function that prints a matrix 'a', performs a Cholesky decomposition on it, and then prints the resulting matrix 'L'. This function is likely used for educational or debugging purposes to show the steps of Cholesky decomposition. Such functions are often retained in codebases for testing, demonstration, or educational purposes, especially if they are part of a larger library or module that deals with matrix operations. Therefore, it is likely to survive."
survived,"def monthUnique(b, list):
    c = 0
    for x in list:
        if x.month == b.month:
            c = c + 1
    return c == 1
",tests/rosetta/transpiler/Python/cheryls-birthday.py,,0,0.9999995549151272,"The method 'monthUnique' is likely to be deleted because it has a few issues that make it less useful or efficient. Firstly, the method name and parameter names are not descriptive enough, which can lead to confusion about its purpose. Secondly, the method checks if there is exactly one occurrence of a specific month in a list of objects with a 'month' attribute, which is a very specific use case and may not be broadly applicable. Additionally, the method could be optimized by using a more efficient approach, such as using a generator expression with the 'sum' function. These factors suggest that the method may not be widely used or needed, leading to its potential deletion."
survived,"def isCircular(n):
    nn = n
    pow = 1
    while nn > 0:
        pow = pow * 10
        nn = nn // 10
    nn = n
    while True:
        nn = nn * 10
        f = nn // pow
        nn = nn + f * (1 - pow)
        if nn == n:
            break
        if not isPrime(nn):
            return False
    return True
",tests/rosetta/transpiler/Python/circular-primes.py,,0,0.9999984465026855,"The method is likely to be deleted because it contains several issues that make it unreliable and potentially incorrect. Firstly, the method name 'isCircular' suggests it checks if a number is circular, but the logic within the method is unclear and seems to be attempting to rotate digits of a number and check if all rotations are prime. However, the implementation is flawed due to incorrect handling of number rotations and the absence of the 'isPrime' function definition, which is crucial for the method's functionality. Additionally, the use of variable names like 'nn' and 'pow' without clear context or comments makes the code difficult to understand and maintain. These factors suggest that the method is not well-implemented and may be removed or significantly revised in future iterations."
survived,"def sqrtApprox(x):
    g = x
    i = 0
    while i < 40:
        g = (g + x / g) / 2.0
        i = i + 1
    return g
",tests/rosetta/transpiler/Python/circles-of-given-radius-through-two-points.py,,1,3.0590235908148916e-07,"The method 'sqrtApprox' is a simple implementation of the Newton-Raphson method for approximating the square root of a number. This method is a well-known and efficient algorithm for finding square roots, and it is often used in educational contexts to demonstrate iterative approximation techniques. The code is straightforward, does not have any apparent bugs, and serves a clear purpose. Therefore, it is likely to be retained in the codebase unless there is a specific reason to replace it with a more optimized or library-based solution."
survived,"def bigToString(a):
    s = """"
    i = len(a) - 1
    while i >= 0:
        s = s + str(a[i])
        i = i - 1
    return s
",tests/rosetta/transpiler/Python/chernicks-carmichael-numbers.py,,1,1.892514738127224e-05,"The method 'bigToString' is a simple utility function that converts a list of elements into a string by concatenating the string representation of each element in reverse order. While the function is functional, it is not optimized. It uses string concatenation in a loop, which is inefficient in Python due to the immutability of strings. A more efficient approach would be to use the 'join' method on a reversed list. However, the function is straightforward and serves a clear purpose, so it is likely to survive unless there is a specific need for optimization or if it is replaced by a more efficient implementation."
survived,"def bstr(b):
    months = ["""", ""January"", ""February"", ""March"", ""April"", ""May"", ""June"", ""July"", ""August"", ""September"", ""October"", ""November"", ""December""]
    return months[b.month] + "" "" + str(b.day)
",tests/rosetta/transpiler/Python/cheryls-birthday.py,,1,1.955568070542584e-08,"The method 'bstr' is a simple utility function that converts a date object 'b' into a string format of 'Month Day'. This is a common requirement in many applications where date formatting is needed. The method is straightforward, easy to understand, and serves a clear purpose. There are no apparent issues with the logic or implementation, and it uses a standard approach to achieve its goal. Therefore, it is likely to be retained in the codebase."
survived,"def crt(a, n):
    prod = 1
    i = 0
    while i < len(n):
        prod = prod * n[i]
        i = i + 1
    x = 0
    i = 0
    while i < len(n):
        ni = n[i]
        ai = a[i]
        p = prod // ni
        inv = modInv(p % ni, ni)
        x = x + ai * inv * p
        i = i + 1
    return x % prod
",tests/rosetta/transpiler/Python/chinese-remainder-theorem.py,,1,2.8453347280241004e-08,"The method implements the Chinese Remainder Theorem (CRT), which is a well-known algorithm in number theory used to solve systems of simultaneous congruences. This method is useful in various applications, including cryptography and computer algebra systems. The code appears to be correctly implementing the CRT by calculating the product of the moduli, iterating over each modulus to compute the partial product, and using the modular inverse to find the solution. Given its mathematical significance and correct implementation, it is likely to be retained."
survived,"def test_cli_output_error(monkeypatch):
    def fail(*args, **kwargs):
        raise OSError(""boom"")

    monkeypatch.setattr(click, ""secho"", fail)
    cli = CLIOutput()
    with pytest.raises(CLIOutputError):
        cli.info(""hello"")",tests/ux/test_cli_output.py,,1,2.2159489282323004e-08,"The method 'test_cli_output_error' is a unit test designed to verify the behavior of a CLI output function when an error occurs. It uses the 'monkeypatch' fixture to simulate an error by replacing 'click.secho' with a function that raises an 'OSError'. The test then checks if the 'CLIOutput' class correctly raises a 'CLIOutputError' when 'cli.info' is called. This is a valid and useful test case for ensuring robustness in error handling, and it follows good testing practices. Therefore, it is likely to be retained in the codebase."
survived,"def test_copy_to_clipboard(monkeypatch):
    copied = {}

    class Dummy:
        def copy(self, text):
            copied[""text""] = text

    monkeypatch.setitem(sys.modules, ""pyperclip"", Dummy())
    fb = UserFeedback()
    assert fb.copy_to_clipboard(""hello"")
    assert copied[""text""] == ""hello""",tests/ux/test_user_feedback.py,,1,1.444980317078884e-07,"The method 'test_copy_to_clipboard' is a unit test designed to verify the functionality of the 'copy_to_clipboard' method in the 'UserFeedback' class. It uses 'monkeypatch' to replace the 'pyperclip' module with a dummy class that simulates the clipboard copying behavior. This is a common practice in testing to isolate the function being tested and ensure it behaves as expected without relying on external dependencies. The test checks that the 'copy_to_clipboard' method correctly copies the text to the clipboard. Since this is a well-structured test that serves a clear purpose in verifying functionality, it is likely to be retained in the codebase."
survived,"    def copy_to_clipboard(self, text: str) -> bool:
        """"""Attempt to copy ``text`` to the clipboard; return True if successful.""""""
        try:
            import pyperclip  # type: ignore
        except Exception:
            return False
        try:
            pyperclip.copy(text)
            return True
        except Exception:
            return False",src/meta_agent/ux/user_feedback.py,UserFeedback,1,2.646573631904765e-09,"The method 'copy_to_clipboard' is likely to survive because it provides a useful utility function for copying text to the clipboard, which is a common requirement in many applications. The method is well-structured, handling exceptions for both the import of the 'pyperclip' module and the actual copying process, ensuring robustness. Additionally, it returns a boolean indicating success, which is a clear and useful feedback mechanism for the caller."
survived,"    def progress_iter(self, iterable: Iterable[T], *, description: str = ""Working"") -> Iterator[T]:
        """"""Yield items from ``iterable`` while displaying a progress bar.""""""
        with click.progressbar(iterable, label=description) as bar:
            for item in bar:
                yield item
",src/meta_agent/ux/user_feedback.py,UserFeedback,1,4.0586521248284276e-10,"The method `progress_iter` is a utility function that wraps an iterable with a progress bar using the `click` library. This is a common and useful pattern for providing user feedback during long-running operations. The method is simple, clear, and leverages an established library to enhance user experience. Such utility functions are often retained in codebases because they provide a non-intrusive way to add progress tracking to any iterable process. Therefore, it is likely to be Survived."
survived,"def test_notify_levels(capsys):
    fb = UserFeedback()
    fb.notify(""ok"", NotificationSeverity.SUCCESS)
    out, _ = capsys.readouterr()
    assert ""ok"" in click.unstyle(out)
",tests/ux/test_user_feedback.py,,1,1.1861120010657661e-08,"The method 'test_notify_levels' is a unit test function that checks the functionality of the 'notify' method in the 'UserFeedback' class. It uses the 'capsys' fixture to capture the output and asserts that the expected message is present. This is a typical pattern for testing output in Python, and there is no indication that this method is obsolete or incorrect. Therefore, it is likely to be retained for testing purposes."
survived,"def test_non_dominated_sort_assigns_ranks() -> None:
    pop = _small_population()
    fronts = mats._non_dominated_sort(pop)

    assert len(fronts) == 2
    first = {ind.fitness for ind in fronts[0]}
    second = {ind.fitness for ind in fronts[1]}
    assert first == {(1.0, 3.0), (2.0, 2.0), (3.0, 1.0)}
    assert second == {(4.0, 5.0), (5.0, 4.0)}
    assert {ind.rank for ind in fronts[0]} == {0}
    assert {ind.rank for ind in fronts[1]} == {1}
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_mats.py,,1,1.1032560311263802e-09,"The method `test_non_dominated_sort_assigns_ranks` is a unit test function that verifies the behavior of the `_non_dominated_sort` function. It checks if the function correctly assigns ranks to individuals in a population based on their fitness values. Unit tests are crucial for ensuring code reliability and correctness, especially in complex algorithms like non-dominated sorting used in evolutionary algorithms. Since this test is essential for validating the functionality of the sorting method, it is likely to be maintained as part of the test suite."
survived,"def test_replay_outputs_events(tmp_path: Path) -> None:
    """"""Replay should print formatted ledger rows.""""""
    path = tmp_path / ""audit.db""
    with logging.Ledger(str(path), broadcast=False) as led:
        led.log(messaging.Envelope(""a"", ""b"", {""x"": 1}, 0.0))
        led.log(messaging.Envelope(""b"", ""c"", {""y"": 2}, 1.0))

    with patch.object(cli.config.CFG, ""ledger_path"", str(path)):
        with patch.object(cli.time, ""sleep"", return_value=None):
            res = CliRunner().invoke(cli.main, [""replay""])

    lines = [ln.strip() for ln in res.output.splitlines() if ln.strip()]
    assert ""0.00 a -> b {\""x\"": 1}"" in lines[0]
    assert ""1.00 b -> c {\""y\"": 2}"" in lines[1]
",tests/test_demo_cli.py,,1,1.6052280526088547e-09,"The method `test_replay_outputs_events` is a unit test designed to verify the functionality of a replay feature in a logging or messaging system. It uses temporary paths, mocks, and assertions to ensure that the replay command outputs the expected formatted ledger rows. Unit tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, this method is likely to be retained as it serves an important role in the testing suite."
survived,"        def __init__(self, sender: str = """", recipient: str = """", payload: dict | None = None, ts: float = 0.0) -> None:
            self.sender = sender
            self.recipient = recipient
            self.payload = payload or {}
            self.ts = ts
",tests/test_adapters.py,Envelope,1,2.2159489282323004e-08,"The method is a constructor (__init__) for a class, which is essential for initializing object instances with specific attributes. It sets default values for the attributes and handles optional parameters effectively. Constructors are fundamental to object-oriented programming, and there is no indication that this particular constructor is redundant or unnecessary. Therefore, it is likely to be retained in the code."
survived,"    def fake_find_spec(name, *args, **kwargs):
        if name in {""numpy"", ""pandas""}:
            return None
        return orig_find_spec(name, *args, **kwargs)
",tests/test_check_env_core.py,,0,0.9999999715466527,"The method 'fake_find_spec' is a mock or a patch for the original 'find_spec' function, likely used for testing purposes. It specifically returns 'None' for 'numpy' and 'pandas', which suggests it is used to simulate the absence of these modules during testing. Such methods are typically temporary and used in a testing context, not in production code. Therefore, it is likely to be deleted after its purpose is served."
survived,"def test_search_no_collections(client):
    response = client.post(
        ""/search"",
        data={""user_query"": ""foo"", ""user_id"": ""user"", ""case_name"": ""case""},
    )
    assert response.status_code == 404",no-ocr-api/tests/test_api.py,,1,3.2241866333029355e-08,"The method 'test_search_no_collections' is a unit test designed to verify that a search request returns a 404 status code when no collections are found. This is a typical test case to ensure the application handles scenarios where the requested data is not available. Such tests are crucial for maintaining the robustness of the application by ensuring it behaves correctly under various conditions. Therefore, this method is likely to be retained as part of the test suite to ensure continued reliability of the search functionality."
survived,"def _run_script(tmp_path: Path, *, env: dict[str, str]) -> tuple[str, str]:
    docker_log = tmp_path / ""docker.log""
    curl_log = tmp_path / ""curl.log""
    bin_dir = tmp_path / ""bin""
    bin_dir.mkdir()

    docker_stub = bin_dir / ""docker""
    docker_stub.write_text(
        ""#!/usr/bin/env bash\n""
        ""echo \""$@\"" >> \""$DOCKER_LOG\""\n""
        ""if [ \""$1\"" = \""info\"" ]; then echo \""{}\""; fi\n""
        ""if [ \""$1\"" = \""version\"" ]; then echo \""24.0.0\""; fi\n""
        ""exit 0\n""
    )
    docker_stub.chmod(0o755)

    curl_stub = bin_dir / ""curl""
    curl_stub.write_text(
        ""#!/usr/bin/env bash\n""
        ""echo \""$@\"" >> \""$CURL_LOG\""\n""
        ""exit 0\n""
    )
    curl_stub.chmod(0o755)

    script_env = os.environ.copy()
    script_env.update(env)
    script_env.update(
        {
            ""PATH"": f""{bin_dir}:{script_env['PATH']}"",
            ""DOCKER_LOG"": str(docker_log),
            ""CURL_LOG"": str(curl_log),
        }
    )

    config = RUN_SCRIPT.parent / ""config.env""
    try:
        result = subprocess.run(
            [f""./{RUN_SCRIPT.name}""],
            cwd=RUN_SCRIPT.parent,
            env=script_env,
            capture_output=True,
            text=True,
        )
    finally:
        if config.exists():
            config.unlink()

    assert result.returncode == 0, result.stderr
    return docker_log.read_text(), curl_log.read_text()
",tests/test_macro_launcher.py,,1,3.850741907939403e-09,"The method '_run_script' is a utility function designed to simulate the execution of a script in a controlled environment. It creates temporary stubs for 'docker' and 'curl' commands, logs their invocations, and runs a script with a modified environment. This method is useful for testing purposes, especially in environments where the actual execution of 'docker' and 'curl' is not feasible or desired. Such utility functions are often retained in codebases for testing and debugging purposes, as they provide a way to verify the behavior of scripts without side effects. Therefore, it is likely to survive."
survived,"            def __init__(self, *a, **kw):
                pass
",alpha_factory_v1/demos/aiga_meta_evolution/utils.py,OpenAIAgent,0,0.9953904270578577,"The method is a constructor (__init__) that takes any number of positional and keyword arguments but does nothing with them. This is typically used as a placeholder or a base class constructor that doesn't need to initialize any attributes. If this is part of a larger class hierarchy where subclasses are expected to override this method, it might survive. However, if this is the only implementation and serves no purpose, it is likely to be deleted as it doesn't contribute any functionality."
survived,"async def test_run_demo_loop_conversation(monkeypatch, capsys):
    model = FakeModel()
    model.add_multiple_turn_outputs([[get_text_message(""hello"")], [get_text_message(""good"")]])

    agent = Agent(name=""test"", model=model)

    inputs = iter([""Hi"", ""How are you?"", ""quit""])
    monkeypatch.setattr(""builtins.input"", lambda _="" > "": next(inputs))

    await run_demo_loop(agent, stream=False)

    output = capsys.readouterr().out
    assert ""hello"" in output
    assert ""good"" in output
    assert model.last_turn_args[""input""] == [
        get_text_input_item(""Hi""),
        get_text_message(""hello"").model_dump(exclude_unset=True),
        get_text_input_item(""How are you?""),
    ]",tests/test_repl.py,,1,4.1399375473943306e-08,"The method is a test function for an asynchronous conversation loop, using a mock model and input. It is well-structured, uses standard testing practices like monkeypatching and capturing output, and includes assertions to verify the expected behavior. Such test functions are crucial for ensuring code reliability and are typically retained in codebases."
survived,"def test_feasibility_scores_monotonic() -> None:
    critic = FeasibilityCritic(DATA, seed=1)
    scores = [critic.score(item) for item in DATA]
    assert scores == sorted(scores)",tests/test_dual_critic.py,,1,1.1861120010657661e-08,"The method `test_feasibility_scores_monotonic` is a unit test function that checks if the scores generated by the `FeasibilityCritic` are in a non-decreasing order. This is a valid and useful test to ensure that the scoring mechanism behaves as expected, particularly if the scores are supposed to be monotonic. The function is simple, clear, and directly tests a specific property of the scoring system. Therefore, it is likely to be retained as part of the test suite to ensure the correctness of the scoring logic."
survived,"    def __init__(self, examples: Iterable[str] | None = None, *, seed: int | None = None) -> None:
        self.examples = list(examples) if examples is not None else load_examples()
        self.rng = random.Random(seed)
",src/evaluators/feasibility_critic.py,FeasibilityCritic,1,2.699578619062706e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes or default values. This particular constructor is flexible, allowing for optional parameters and default behavior, which makes it versatile and useful. Therefore, it is unlikely to be deleted as it serves a critical role in the class's functionality."
survived,"    def _open_serial() -> serial.Serial:
      return serial.Serial(
        port=self._port,
        baudrate=self.baudrate,
        bytesize=self.bytesize,
        parity=self.parity,
        stopbits=self.stopbits,
        write_timeout=self.write_timeout,
        timeout=self.timeout,
      )
",pylabrobot/io/serial.py,Serial,1,2.646573631904765e-09,"The method '_open_serial' is a private helper function designed to encapsulate the logic for opening a serial connection using the 'serial.Serial' class. It is likely to be used internally within a class to manage serial communication. Such methods are typically retained because they provide a clear, reusable way to handle specific tasks, in this case, setting up a serial connection with various parameters. Unless there is a significant change in the design or requirements that makes this method obsolete, it is likely to survive."
survived,"        def __init__(self):
            self.app = types.SimpleNamespace(middleware=lambda *_a, **_k: lambda f: f)
",tests/test_external_integrations.py,DummyRouter,1,1.3440409770490404e-08,"The method is a constructor for a class, and it initializes an attribute 'app' with a SimpleNamespace object. This is a common pattern in Python to create objects with dynamic attributes. The use of SimpleNamespace and lambda functions suggests that this code is part of a larger framework or application where middleware functions are dynamically added. Since constructors are essential for object instantiation and this code does not show any signs of being deprecated or redundant, it is likely to survive."
survived,"            def __init__(self, *args: object, **kwargs: object) -> None:
                pass
",tests/test_orchestrator_grpc.py,TestServeGrpc._Msg,0,0.9999994956527948,"The method is a constructor that takes any number of positional and keyword arguments but does nothing with them. This is typically a placeholder or a default implementation that might be intended for future expansion or to satisfy an interface requirement. However, as it currently stands, it doesn't serve any functional purpose. If the class doesn't require a constructor or if this is not overridden in subclasses, it is likely to be deleted in a code cleanup process."
survived,"    def test_verify_wheel(self) -> None:
        priv = Ed25519PrivateKey.generate()
        pub_b64 = base64.b64encode(
            priv.public_key().public_bytes(
                encoding=serialization.Encoding.Raw,
                format=serialization.PublicFormat.Raw,
            )
        ).decode()
        wheel = Path(""test.whl"")
        wheel.write_bytes(b""demo"")
        sig = base64.b64encode(priv.sign(b""demo"")).decode()
        sig_file = Path(""test.whl.sig"")
        sig_file.write_text(sig)
        orig_pub = agents_mod._WHEEL_PUBKEY
        orig_sigs = agents_mod._WHEEL_SIGS.copy()
        try:
            agents_mod._WHEEL_PUBKEY = pub_b64
            agents_mod._WHEEL_SIGS = {wheel.name: sig}
            self.assertTrue(agents_mod._verify_wheel(wheel))
        finally:
            agents_mod._WHEEL_PUBKEY = orig_pub
            agents_mod._WHEEL_SIGS = orig_sigs
            wheel.unlink()
            sig_file.unlink()
",tests/test_wheel_signature.py,TestWheelSignature,1,6.825604231969389e-08,"The method 'test_verify_wheel' is a unit test designed to verify the functionality of the '_verify_wheel' method in the 'agents_mod' module. It sets up a test environment by generating a private key, creating a wheel file and its corresponding signature, and then temporarily modifies the module's public key and signature dictionary to test the verification process. After the test, it cleans up by restoring the original state and deleting the test files. This method is crucial for ensuring the integrity and correctness of the '_verify_wheel' function, which is likely an important security feature. Therefore, it is unlikely to be deleted as it serves a critical role in maintaining the reliability of the code."
survived,"def _build_dsl(extra_args: List[str]) -> str:
    """"""Convert unknown CLI options to DSL fragment.""""""
    dsl_map: Dict[str, Union[str, List[str]]] = {}
    i = 0
    while i < len(extra_args):
        token = extra_args[i]
        if token.startswith(""--""):
            key = token[2:]
            value = ""true""
            if ""="" in key:
                key, value = key.split(""="", 1)
            elif i + 1 < len(extra_args) and not extra_args[i + 1].startswith(""--""):
                value = extra_args[i + 1]
                i += 1
            existing = dsl_map.get(key)
            if existing is None:
                dsl_map[key] = value
            else:
                if isinstance(existing, list):
                    existing.append(value)
                else:
                    dsl_map[key] = [existing, value]
        i += 1

    parts = []
    for key, value in dsl_map.items():
        if isinstance(value, list):
            value = "","".join(value)
        parts.append(f""[{key}:{value}]"")
    return """".join(parts)
",src/attachments/cli.py,,1,4.944450477491054e-09,"The method '_build_dsl' is a utility function that converts command-line interface (CLI) options into a domain-specific language (DSL) fragment. This is a common requirement in applications that need to parse and interpret command-line arguments. The function is well-structured, handles various cases of input, and constructs a meaningful output. Such utility functions are often essential for the functionality of CLI-based applications, making it unlikely to be deleted unless the entire CLI parsing mechanism is refactored or replaced."
survived,"def _get_evolver() -> MetaEvolver:
    """"""Return the lazily created MetaEvolver instance.""""""
    global EVOLVER
    if EVOLVER is None:
        EVOLVER = MetaEvolver(env_cls=CurriculumEnv, llm=LLM)
    return EVOLVER
",alpha_factory_v1/demos/aiga_meta_evolution/openai_agents_bridge.py,,1,3.850741907939403e-09,"The method _get_evolver() is a private utility function that ensures a singleton pattern for the MetaEvolver instance. It checks if the global variable EVOLVER is None and initializes it if necessary. This pattern is common in scenarios where resource-intensive objects need to be instantiated only once and reused. The method is likely to survive because it encapsulates the logic for lazy initialization, which is a useful and efficient design pattern in software development."
survived,"  def supports_active_cooling(self) -> bool:
    return False
",pylabrobot/heating_shaking/hamilton_backend.py,HamiltonHeaterShakerBackend,1,2.3355930333443423e-09,"The method `supports_active_cooling` is a simple method that returns a boolean value indicating whether active cooling is supported. It is likely part of a larger system where different components or configurations might have varying cooling capabilities. Such methods are typically retained because they provide a clear and straightforward way to check a specific capability of a system or component. Unless the entire feature related to cooling is being deprecated, this method is likely to survive."
survived,"  async def get_current_temperature(self) -> float:
    return self.temperature
",pylabrobot/temperature_controlling/temperature_controller_tests.py,_FakeBackend,1,1.8189616842444243e-09,"The method `get_current_temperature` is a simple asynchronous function that returns the current temperature stored in the `self.temperature` attribute. This method is likely to be useful in contexts where temperature data is being managed or monitored, such as in a weather application or a climate control system. Since it provides a basic and essential functionality of retrieving the current temperature, it is unlikely to be deleted unless the entire temperature management system is being refactored or removed. Therefore, the method is predicted to survive."
survived,"        def query_text(self, _):
            return {""embedding"": [0.0]}
",no-ocr-api/tests/test_ingest_search.py,FakeColPali,0,0.9999994956527948,"The method `query_text` is very minimal and only returns a static dictionary with an embedding key containing a list with a single float value. This suggests that the method is either a placeholder or a stub for future development. Without additional context or functionality, it doesn't provide any meaningful operation or utility. In many codebases, such methods are either expanded upon or removed if they are not used or needed. Given its current state, it is likely to be deleted unless it is part of a larger framework where this specific return value is required."
survived,"async def main() -> None:
    client = MCPClient(config={""mcpServers"": {""hello"": {""url"": ""http://localhost:8000""}}})
    session = await client.create_session(""hello"")
    result = await session.connector.call_tool(""hello_http"", {})
    print(result.content[0].text)
    await client.close_all_sessions()
",examples/hello_world_http/client.py,,1,1.955568070542584e-08,"The method 'main' is an asynchronous function that demonstrates a clear and structured use of an MCPClient to create a session, call a tool, and print the result. It also includes proper session management by closing all sessions at the end. This indicates good practice in asynchronous programming and resource management. Unless there are changes in the requirements or the MCPClient API, there is no reason to delete this method as it serves a functional purpose."
survived,"def test_mcp_invoke_tool_success(httpx_mock, stub_mcp):
    httpx_mock.add_response(url=""https://mcp.example/foo"", json={""ok"": True})
    adapter = MCPAdapter()
    result = asyncio.run(adapter.invoke_tool(""foo"", {""a"": 1}))
    assert result == {""ok"": True}
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_adapters.py,,1,1.0467401685178159e-08,"The method 'test_mcp_invoke_tool_success' is a unit test designed to verify the successful invocation of a tool using the MCPAdapter. Unit tests are crucial for ensuring code reliability and functionality, especially in a test-driven development environment. The method is well-structured, uses mocking to simulate HTTP responses, and checks the expected outcome, which are all good practices in software testing. Therefore, it is likely to be retained as part of the test suite to ensure the continued correctness of the MCPAdapter's behavior."
survived,"def stub_mcp(monkeypatch: pytest.MonkeyPatch):
    mod = types.ModuleType(""mcp"")

    class ClientSessionGroup:
        async def call_tool(self, name: str, args: dict[str, object]):
            async with httpx.AsyncClient() as client:
                resp = await client.post(f""https://mcp.example/{name}"", json=args)
                resp.raise_for_status()
                return resp.json()

    mod.ClientSessionGroup = ClientSessionGroup
    monkeypatch.setitem(sys.modules, ""mcp"", mod)
    yield mod
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_adapters.py,,1,1.522997951276035e-08,"The method 'stub_mcp' is a test utility function that uses the 'monkeypatch' fixture from pytest to create a mock module 'mcp' with a class 'ClientSessionGroup'. This class has an asynchronous method 'call_tool' that makes an HTTP POST request using 'httpx.AsyncClient'. The function is useful for testing purposes, allowing developers to simulate and test interactions with the 'mcp' module without making actual network requests. Such utility functions are typically retained in codebases as they facilitate testing and improve test coverage. Therefore, it is likely to survive."
survived,"def test_workbox_integrity() -> None:
    browser_dir = Path(__file__).resolve().parents[1]
    dist = browser_dir / ""dist""
    index = dist / ""index.html""
    expected = sha384(dist / ""workbox-sw.js"")
    url = index.as_uri()

    with sync_playwright() as p:
        browser = p.chromium.launch()
        page = browser.new_page()
        page.goto(url)
        page.wait_for_selector(""#controls"")
        integrity = page.get_attribute(""script[src='workbox-sw.js']"", ""integrity"")
        assert integrity == expected
        browser.close()",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_workbox_integrity.py,,1,1.8553915987649156e-07,"The method `test_workbox_integrity` is a test function that checks the integrity of a script file by comparing its hash with an expected value. This is a common practice in ensuring that files have not been tampered with, which is crucial for security. The method uses Playwright to automate a browser for this purpose, which is a modern and widely used tool for browser automation. Given the importance of security checks and the use of a modern tool, it is likely that this method will be maintained or updated rather than deleted."
survived,"def scenario(request) -> replay.Scenario:
    return request.getfixturevalue(request.param)",tests/conftest.py,,1,3.581747929000289e-10,"The method 'scenario' is a simple utility function that retrieves a fixture value based on a request parameter. It is likely part of a testing framework, possibly using pytest, where fixtures are commonly used. Such utility functions are generally useful for setting up test scenarios and are not typically removed unless they are replaced by a more efficient or standardized approach. Without any indication of deprecation or redundancy, it is reasonable to predict that this method will survive."
survived,"def _call(
    method: str,
    url: str,
    *,
    params: dict | None = None,
    json: dict | None = None,
    data: dict | bytes | None = None,
    headers: dict | None = None,
    timeout: float | None = None,
) -> Response:
    if params:
        query = _parse.urlencode(params, doseq=True)
        url += (""&"" if ""?"" in url else ""?"") + query

    body = None
    req_headers = {""User-Agent"": _UA, **(headers or {})}
    if json is not None:
        body = _json.dumps(json).encode()
        req_headers.setdefault(""Content-Type"", ""application/json"")
    elif data is not None:
        if isinstance(data, (bytes, bytearray)):
            body = data
        else:
            body = _parse.urlencode(data).encode()
            req_headers.setdefault(""Content-Type"", ""application/x-www-form-urlencoded"")

    req = _request.Request(url, data=body, headers=req_headers, method=method)
    try:
        with _request.urlopen(req, timeout=timeout) as resp:
            content = resp.read()
            resp_headers = dict(resp.headers.items())
            return Response(resp.getcode(), content, resp_headers, url)
    except _error.HTTPError as exc:
        content = exc.read()
        resp_headers = dict(exc.headers.items()) if hasattr(exc, ""headers"") else {}
        return Response(exc.code, content, resp_headers, url)
    except _error.URLError as exc:  # pragma: no cover - network issues
        if isinstance(getattr(exc, ""reason"", None), TimeoutError):
            raise Timeout(str(exc.reason))
        raise RequestException(str(exc))
",alpha_factory_v1/af_requests.py,,1,1.3440409770490404e-08,"The method '_call' is a well-structured utility function for making HTTP requests, handling both successful responses and errors. It supports various HTTP methods, allows for JSON and form data, and manages headers and timeouts. These features make it versatile and useful in many applications, suggesting it is likely to be retained in the codebase."
survived,"    def _zip_bytes(self, files):
        import io, zipfile

        buf = io.BytesIO()
        with zipfile.ZipFile(buf, ""w"") as zf:
            for name, data in files.items():
                zf.writestr(name, data)
        return buf.getvalue()
",alpha_factory_v1/tests/test_orchestrator_rest.py,UpdateModelTest,1,1.3440409770490404e-08,"The method '_zip_bytes' is a utility function that takes a dictionary of file names and their corresponding data, and compresses them into a zip archive in memory. This is a common and useful functionality for applications that need to handle file compression without writing to disk, such as web applications or services that process files on-the-fly. The method is efficient and uses standard libraries (io and zipfile), making it reliable and easy to maintain. Therefore, it is likely to be retained in the codebase."
survived,"    def load_weights(self, path):
        self.loaded = path
",alpha_factory_v1/tests/test_orchestrator_rest.py,DummyAgent,0,0.9999921107349486,"The method 'load_weights' is very minimal and only assigns a path to an instance variable 'self.loaded'. It lacks any functionality related to actually loading weights, such as reading from a file or handling errors. This makes it unlikely to be useful in its current form, suggesting it might be a placeholder or incomplete. Without further context or additional functionality, it is likely to be deleted or significantly modified in the future."
survived,"    def load_template(self, slug: str, version: str = ""latest"") -> Optional[str]:
        slug_sanitized = slug.replace("" "", ""_"").lower()
        manifest = self._load_manifest()
        entry = manifest.get(slug_sanitized)
        if not entry:
            return None
        if version == ""latest"":
            version = entry.get(""current_version"")
            if not version:
                return None
        version_data = entry.get(""versions"", {}).get(version)
        if not version_data:
            return None
        template_path = self.templates_dir / version_data[""path""]
        if not template_path.exists():
            return None
        return template_path.read_text(encoding=""utf-8"")
",src/meta_agent/template_registry.py,TemplateRegistry,1,1.1628233028868813e-10,"The method 'load_template' is well-structured and serves a clear purpose: loading a template based on a given slug and version. It includes input sanitization, checks for the existence of the template, and handles different versions, including a default to the 'latest' version. These features make it a useful utility function in a system that manages templates. There are no apparent issues or redundancies that would necessitate its deletion. Therefore, it is likely to be retained in the codebase."
survived,"    def list_templates(self) -> List[Dict[str, Any]]:
        manifest = self._load_manifest()
        templates = []
        for slug, entry in manifest.items():
            versions = [
                {""version"": v, **data}
                for v, data in sorted(
                    entry.get(""versions"", {}).items(),
                    key=lambda item: parse_version(item[0]),
                    reverse=True,
                )
            ]
            templates.append(
                {
                    ""slug"": slug,
                    ""current_version"": entry.get(""current_version""),
                    ""versions"": versions,
                }
            )
        return templates
",src/meta_agent/template_registry.py,TemplateRegistry,1,1.493094675974231e-10,"The method 'list_templates' is well-structured and performs a clear and useful function: it loads a manifest and processes it to return a list of templates with their versions sorted. This kind of functionality is common in applications that manage templates or configurations, and there is no indication of redundancy or inefficiency in the code. Therefore, it is likely to be retained in the codebase."
survived,"def test_versioning_diff_and_rollback(tmp_path):
    reg = TemplateRegistry(base_dir=tmp_path)
    meta = _meta()
    reg.register(meta, ""hello {{name}}"", version=""0.1.0"")
    reg.register(meta, ""hi {{name}}"", version=""0.2.0"")

    diff = reg.diff(""greet"", ""0.1.0"", ""0.2.0"")
    assert ""-hello {{name}}"" in diff
    assert ""+hi {{name}}"" in diff

    reg.rollback(""greet"", ""0.1.0"")
    assert reg.list_templates()[0][""current_version""] == ""0.1.0""
    assert reg.load_template(""greet"") == ""hello {{name}}""",tests/test_template_registry.py,,1,2.3355930333443423e-09,"The method 'test_versioning_diff_and_rollback' is a test function that verifies the functionality of versioning, diffing, and rollback in a template registry system. It is a crucial part of ensuring that the system behaves as expected when templates are registered, compared, and rolled back to previous versions. Test functions like this are essential for maintaining software quality and reliability, especially in systems that handle version control. Therefore, it is unlikely to be deleted as it serves an important role in the testing suite."
survived,"def _exec_trusted(code: str, inp_json: str) -> Tuple[str, str]:
    """"""Run *trusted* Python code in an isolated subprocess.""""""
    with tempfile.NamedTemporaryFile(""w+"", suffix="".py"", delete=False) as tmp:
        tmp.write(code)
        script = tmp.name

    def _target(q: _mp.Queue) -> None:
        _apply_limits()
        try:
            proc = subprocess.Popen(
                [sys.executable, script],
                stdin=subprocess.PIPE,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
            )
            try:
                out, err = proc.communicate(inp_json, timeout=SOFT_T)
            except subprocess.TimeoutExpired:
                proc.kill()
                out, err = proc.communicate()
            q.put((out, err))
        except Exception as exc:  # pragma: no cover
            q.put(("""", str(exc)))

    q: _mp.Queue = _mp.Queue()
    p = _mp.Process(target=_target, args=(q,))
    p.start()
    p.join(HARD_T)
    if p.is_alive():
        p.terminate()
    try:
        out, err = q.get_nowait()
    except Exception:
        out, err = """", ""RuntimeError: queue empty""
    finally:
        try:
            os.remove(script)
        except OSError:
            pass
    return out.strip(), err.strip()
",alpha_factory_v1/demos/meta_agentic_agi_v3/curriculum/azr_engine.py,,1,4.363462233903899e-09,"The method '_exec_trusted' is designed to execute trusted Python code in an isolated subprocess, which is a common requirement for running potentially unsafe code safely. It uses subprocesses to ensure isolation and applies time limits to prevent hanging processes. The method also handles exceptions and cleans up temporary files, which are good practices. These features make it a robust utility function for executing code safely, suggesting it is likely to be retained in the codebase."
survived,"    def propose(self, k: int = 4) -> List[Triplet]:
        prompt = self._build_prompt(k)
        raw = self.fm.chat(
            system=""You are AZRâ€‘Proposer, inventing new reasoning tasks."",
            user=prompt,
            temperature=self.temperature,
            max_tokens=2000,
        )
        triplets = [t for t in self._parse_triplets(raw) if self._validate(t)]
        self.log(f""[AZR] proposer: {len(triplets)}/{k} valid; T={self.temperature:.2f}"")
        return triplets
",alpha_factory_v1/demos/meta_agentic_agi_v3/curriculum/azr_engine.py,AZREngine,1,8.592166611791576e-10,"The method 'propose' is well-structured and serves a clear purpose within the context of the class it belongs to. It builds a prompt, interacts with a chat model to generate data, parses the data into triplets, validates them, and logs the results. Each step is logically connected and necessary for the method's functionality. Additionally, the method uses parameters and logging effectively, which are good practices in software development. There is no indication of redundancy or inefficiency that would warrant its deletion. Therefore, the method is likely to be retained."
survived,"def test_baseline_growth_and_disruption() -> None:
    sec = sector.Sector(""x"", energy=1.0, entropy=2.0, growth=0.1)
    traj = forecast.forecast_disruptions([sec], 2, curve=""linear"", pop_size=2, generations=1)
    first = traj[0].sectors[0]
    second = traj[1].sectors[0]
    assert first.energy == pytest.approx(1.1)
    assert not first.disrupted
    assert second.disrupted
    assert second.energy > 1.1 * 1.1
",tests/test_forecast.py,,1,1.725782769012759e-08,"The method `test_baseline_growth_and_disruption` is a unit test function that checks the behavior of a forecasting function in a specific scenario. It is likely to survive because:

1. **Purpose**: It serves a clear purpose by testing the functionality of the `forecast_disruptions` method, ensuring that the growth and disruption logic is working as expected.

2. **Clarity**: The test is straightforward and uses assertions to verify the expected outcomes, which is a common practice in software development to maintain code quality.

3. **Maintenance**: Unit tests are generally maintained and updated rather than deleted, as they are crucial for verifying that changes to the codebase do not introduce new bugs.

4. **No Redundancy**: There is no indication that this test is redundant or covered by other tests, which would be a reason for deletion.

Overall, the function is a typical example of a unit test that is likely to be retained to ensure the reliability of the code it tests."
survived,"def forecast_disruptions(
    sectors: Iterable[Sector],
    horizon: int,
    curve: str = ""logistic"",
    *,
    pop_size: int = 6,
    generations: int = 1,
) -> List[TrajectoryPoint]:
    """"""Simulate sector trajectories and disruption events.""""""

    secs = list(sectors)
    results: List[TrajectoryPoint] = []
    for year in range(1, horizon + 1):
        t = year / horizon
        cap = capability_growth(t, curve)
        affected: List[Sector] = []
        for sec in secs:
            if not sec.disrupted:
                sec.energy *= 1.0 + sec.growth
                if thermodynamic_trigger(sec, cap):
                    sec.disrupted = True
                    sec.energy += _innovation_gain(pop_size, generations)
                    affected.append(sec)
        snapshot = [Sector(s.name, s.energy, s.entropy, s.growth, s.disrupted) for s in secs]
        results.append(TrajectoryPoint(year, cap, snapshot))
    return results
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/simulation/forecast.py,,1,3.850741907939403e-09,"The method 'forecast_disruptions' is well-defined and serves a specific purpose of simulating sector trajectories and disruption events over a given horizon. It uses parameters like 'curve', 'pop_size', and 'generations' to model the growth and disruption of sectors, which suggests it is part of a larger simulation or forecasting system. The method is likely to be useful in scenarios where understanding the impact of disruptions on various sectors is important, such as in economic modeling or strategic planning. Given its clear utility and the fact that it is not overly complex or redundant, it is likely to be retained in the codebase."
survived,"def test_vmap():
    class Module(eqx.Module):
        weight: hax.NamedArray

        def __call__(self, x):
            return x + self.weight

        @staticmethod
        def init(weight):
            return Module(weight=weight)

    Block = hax.Axis(""block"", 4)
    E = hax.Axis(""E"", 10)

    weights = hax.random.uniform(jax.random.PRNGKey(0), (Block, E))
    m = Stacked.init(Block, Module)(weight=weights)

    x = hax.random.uniform(jax.random.PRNGKey(1), (E,))
    y = m.vmap(x)

    assert y.axes == (Block, E)
    assert hax.all(y == weights + x)
",tests/test_scan.py,,1,1.3440409770490404e-08,"The method `test_vmap` is a test function that appears to be testing the functionality of a vectorized map (vmap) operation using a custom module class. It is likely part of a test suite to ensure that the vmap operation works correctly with the given module and data structures. Test functions are generally not deleted unless they are redundant, incorrect, or replaced by more comprehensive tests. Since this function seems to be a valid and specific test case, it is likely to survive."
survived,"    def test_ledger_env_override(self) -> None:
        with tempfile.TemporaryDirectory() as tmp_home, tempfile.TemporaryDirectory() as tmp:
            target = Path(tmp) / ""ledger.json""
            env = {""HOME"": tmp_home, ""CROSS_ALPHA_LEDGER"": str(target)}
            with patch.dict(os.environ, env, clear=False):
                path = stub._ledger_path(None)
            self.assertEqual(path, target.resolve())
            self.assertTrue(path.parent.exists())
",alpha_factory_v1/tests/test_cross_industry_alpha.py,TestCrossIndustryAlpha,1,1.4166087846364157e-09,"The method `test_ledger_env_override` is a unit test designed to verify the behavior of a function when certain environment variables are set. It uses temporary directories to simulate different environments and checks if the function correctly resolves the path to a ledger file. This is a typical and necessary test to ensure that the function behaves correctly under different configurations. Since it is a test method, it is unlikely to be deleted unless the functionality it tests is removed or significantly changed. Therefore, it is more likely to survive."
survived,"    def json(self):
        return self._payload
",tests/test_openai_bridge_integration.py,DummyResponse,1,1.1032560311263802e-09,"The method is a simple getter for the '_payload' attribute, which is likely a common pattern in classes dealing with JSON data. It is straightforward and serves a clear purpose, making it unlikely to be removed unless the class design changes significantly. Additionally, methods that provide access to data in a specific format (like JSON) are often essential for interoperability and data handling, further supporting its survival."
survived,"def test_offline_reload_no_errors() -> None:
    repo = Path(__file__).resolve().parents[1]
    dist = repo / ""alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/dist""

    server, thread = _start_server(dist)
    host, port = server.server_address
    url = f""http://{host}:{port}/index.html""
    try:
        with sync_playwright() as p:
            browser = p.chromium.launch()
            context = browser.new_context()
            page = context.new_page()
            errors: list[str] = []
            page.on(""console"", lambda msg: errors.append(msg.text) if msg.type == ""error"" else None)
            page.on(""pageerror"", lambda err: errors.append(str(err)))

            page.goto(url)
            page.wait_for_selector(""#controls"")
            page.wait_for_function(""navigator.serviceWorker.ready"")

            context.set_offline(True)
            page.reload()
            page.wait_for_selector(""#controls"")
            context.set_offline(False)

            assert not errors, f""Console errors: {errors}""
            assert page.evaluate(""navigator.serviceWorker.controller !== null"")
            browser.close()
    except PlaywrightError as exc:
        pytest.skip(f""Playwright browser not installed: {exc}"")
    finally:
        server.shutdown()
        thread.join()",tests/test_sw_offline_reload.py,,1,6.348800075736417e-09,"The method `test_offline_reload_no_errors` is a test function that verifies the behavior of a web application when reloaded offline. It uses Playwright to automate browser actions and checks for console errors and service worker status. This kind of test is crucial for ensuring the robustness of web applications, especially those relying on service workers for offline capabilities. Given the importance of testing offline functionality in modern web applications, this method is likely to be maintained and not deleted."
survived,"def main():
    parser = argparse.ArgumentParser(
        description=""Run hierarchical LDA on the BBC sample dataset""
    )
    parser.add_argument(
        ""--data-dir"", default=""bbc/tech"", help=""Directory containing BBC .txt files""
    )
    parser.add_argument(""--iterations"", type=int, default=100, help=""Number of Gibbs samples"")
    parser.add_argument(
        ""--display-topics"", type=int, default=50, help=""Report topics every N iterations""
    )
    parser.add_argument(
        ""--n-words"", type=int, default=5, help=""Number of words to display per topic""
    )
    parser.add_argument(
        ""--num-levels"", type=int, default=3, help=""Depth of the topic hierarchy""
    )
    parser.add_argument(""--alpha"", type=float, default=10.0, help=""Alpha hyperparameter"")
    parser.add_argument(""--gamma"", type=float, default=1.0, help=""Gamma hyperparameter"")
    parser.add_argument(""--eta"", type=float, default=0.1, help=""Eta hyperparameter"")
    parser.add_argument(""--seed"", type=int, default=0, help=""Random seed"")

    args = parser.parse_args()
    run_demo(args)
",scripts/bbc_demo.py,,1,5.043472052266442e-07,"The method is a main function that sets up an argument parser for a script that runs hierarchical LDA on a dataset. It is a typical setup for command-line tools in Python, providing flexibility and configurability for the user. Such methods are generally useful and are likely to be retained unless the entire script is deprecated or replaced by a different approach."
survived,"def test_download_invocation(monkeypatch: pytest.MonkeyPatch, tmp_path: Path) -> None:
    calls: list[tuple[str, Path]] = []

    def fake_download(url: str, dest: Path) -> None:
        dest.parent.mkdir(parents=True, exist_ok=True)
        dest.write_text(""ok"")
        calls.append((url, dest))

    monkeypatch.setattr(dg, ""_download"", fake_download)
    monkeypatch.setattr(dg, ""_verify"", lambda *_: None)
    dg.download_hf_gpt2(dest=tmp_path)
    assert len(calls) == len(dg._FILES)
    assert calls[0][0].startswith(dg._base_url())
",tests/test_download_hf_gpt2.py,,1,5.60279640614594e-09,"The method 'test_download_invocation' is a unit test function that uses the 'monkeypatch' fixture from pytest to replace certain functions with mock implementations. This is a common practice in testing to isolate the function being tested and ensure it behaves correctly under controlled conditions. The function is well-structured, uses temporary paths to avoid side effects, and checks that the download function is called the expected number of times with the correct parameters. These are all good practices in testing, suggesting that the method is useful and likely to be retained in the codebase."
survived,"def test_download_error(tmp_path: Path, requests_mock: ""requests_mock.Mocker"") -> None:
    monkeypatch_files = [""dummy.txt""]
    url = f""{dg._base_url()}/dummy.txt""
    requests_mock.get(url, status_code=404)

    with pytest.MonkeyPatch.context() as m:
        m.setattr(dg, ""_FILES"", monkeypatch_files)
        with pytest.raises(Exception):
            dg.download_hf_gpt2(dest=tmp_path, attempts=1)",tests/test_download_hf_gpt2.py,,1,1.3440409770490404e-08,"The method 'test_download_error' is a unit test function that is designed to test the behavior of a function when a download error occurs (HTTP 404 error). Unit tests are generally not deleted unless they are redundant or replaced by a more comprehensive test. This test is useful for ensuring that the 'download_hf_gpt2' function handles errors correctly, which is an important aspect of robust software development. Therefore, it is likely to be retained."
survived,"def test_experience_launcher_live(tmp_path: Path, monkeypatch: pytest.MonkeyPatch) -> None:
    script = Path(""alpha_factory_v1/demos/era_of_experience/run_experience_demo.sh"")
    config = script.parent / ""config.env""
    docker_log = tmp_path / ""docker.log""
    curl_log = tmp_path / ""curl.log""
    bin_dir = tmp_path / ""bin""
    bin_dir.mkdir()

    docker_stub = bin_dir / ""docker""
    docker_stub.write_text(
        ""#!/usr/bin/env bash\n""
        'echo ""LIVE_FEED=$LIVE_FEED"" >> ""$DOCKER_LOG""\n'
        'echo ""$@"" >> ""$DOCKER_LOG""\n'
        'if [ ""$1"" = ""info"" ]; then echo ""{}""; fi\n'
        'if [ ""$1"" = ""version"" ]; then echo ""24.0.0""; fi\n'
        ""exit 0\n""
    )
    docker_stub.chmod(0o755)

    curl_stub = bin_dir / ""curl""
    curl_stub.write_text(
        ""#!/usr/bin/env bash\n""
        'echo ""$@"" >> ""$CURL_LOG""\n'
        'out=""""\n'
        ""for ((i=1;i<=$#;i++)); do\n""
        '  if [ ""${!i}"" = ""-o"" ]; then\n'
        ""    j=$((i+1))\n""
        ""    out=${!j}\n""
        ""  fi\n""
        ""done\n""
        'if [ -n ""$out"" ]; then echo sample > ""$out""; fi\n'
        'echo ""OK""\n'
    )
    curl_stub.chmod(0o755)

    env = os.environ.copy()
    env.update(
        {
            ""PATH"": f""{bin_dir}:{env['PATH']}"",
            ""SKIP_ENV_CHECK"": ""1"",
            ""SAMPLE_DATA_DIR"": str(tmp_path / ""samples""),
            ""DOCKER_LOG"": str(docker_log),
            ""CURL_LOG"": str(curl_log),
        }
    )
    env.pop(""OPENAI_API_KEY"", None)

    if config.exists():
        config.unlink()
    try:
        result = subprocess.run(
            [f""./{script.name}"", ""--live""], cwd=script.parent, env=env, capture_output=True, text=True
        )
        created = config.exists()
    finally:
        if config.exists():
            config.unlink()

    assert result.returncode == 0, result.stderr
    assert docker_log.exists()
    log = docker_log.read_text()
    assert ""--profile live-feed"" in log
    assert ""LIVE_FEED=1"" in log
    assert created",tests/test_experience_launcher.py,,1,1.522997951276035e-08,"The method `test_experience_launcher_live` is a test function that sets up a testing environment using temporary paths and monkeypatching to simulate the behavior of external commands like `docker` and `curl`. It verifies the execution of a script and checks the logs for expected outputs. This kind of test is crucial for ensuring that scripts and configurations work as intended in a controlled environment. Given its role in testing and validation, it is likely to be maintained as part of the test suite to ensure the reliability of the software."
survived,"    def test_gather_signals_returns_mapping(self) -> None:
        """"""``gather_signals`` should return all expected signal keys.""""""
        signals = alpha_report.gather_signals()
        self.assertIsInstance(signals, dict)
        for key in (""yield_curve"", ""supply_chain""):
            self.assertIn(key, signals)
",tests/test_alpha_report.py,TestBestAlpha,1,3.850741907939403e-09,"The method `test_gather_signals_returns_mapping` is a unit test that verifies the functionality of the `gather_signals` function. It checks if the function returns a dictionary and if specific keys are present in that dictionary. This is a typical and necessary test to ensure the function behaves as expected, especially in a codebase that relies on signal processing or data gathering. Unit tests are crucial for maintaining code quality and catching regressions, so this method is likely to be retained."
survived,"def _start_server(port: int, env: dict[str, str] | None = None) -> subprocess.Popen[bytes]:
    cmd = [
        sys.executable,
        ""-m"",
        ""src.interface.api_server"",
        ""--host"",
        ""127.0.0.1"",
        ""--port"",
        str(port),
    ]
    return subprocess.Popen(cmd, env=env or os.environ.copy())
",tests/test_metrics.py,,1,2.0611536181902033e-09,"The method _start_server is likely to survive because it is a utility function that encapsulates the logic for starting a server process. It is well-defined, using subprocess.Popen to execute a command that starts a server, which is a common requirement in many applications. The method is flexible, allowing for an optional environment variable dictionary, and it uses Python's type hinting to improve code readability and maintainability. These characteristics make it a useful and reusable piece of code that is unlikely to be removed unless there is a significant change in the application's architecture or requirements."
survived,"    def add_rule(self, rule: GuardrailRule) -> None:
        """"""Add a new rule to the configuration.""""""

        self.rules.append(rule)
",src/meta_agent/generators/guardrail_generator.py,GuardrailConfig,1,8.592166611791576e-10,"The method 'add_rule' is a simple and straightforward method that adds a new rule to a list of rules. It is likely to be a fundamental part of the class's functionality, especially if the class is designed to manage or configure rules. Such methods are typically essential for the operation of the class and are unlikely to be removed unless there is a significant redesign or change in the class's purpose. Therefore, it is predicted to survive."
survived,"    def from_dict(cls, data: dict) -> ""GuardrailConfig"":
        """"""Create a configuration from a dictionary.""""""

        return cls(**data)
",src/meta_agent/generators/guardrail_generator.py,GuardrailConfig,1,9.736200303530205e-10,"The method 'from_dict' is a common pattern used in Python to create an instance of a class from a dictionary. This is particularly useful for deserializing data, such as when reading from a JSON file or an API response. The method is simple, clear, and follows a widely accepted convention, making it likely to be retained in the codebase. Additionally, it uses Python's dynamic nature to unpack the dictionary into keyword arguments, which is efficient and concise. Therefore, it is likely to survive."
survived,"async def test_unknown_model_raises():
    adapter = MockAdapter()
    router = GuardrailModelRouter({""a"": adapter}, default_model=""a"")
    with pytest.raises(ValueError):
        await router.invoke(""hi"", model=""missing"")
",tests/test_guardrail_router.py,,1,9.237449576640118e-09,"The method is a test function designed to ensure that the GuardrailModelRouter raises a ValueError when an unknown model is specified. This is a valid and necessary test to ensure the robustness of the code, as it checks for proper error handling when an invalid model is requested. Such tests are crucial for maintaining code quality and preventing runtime errors. Therefore, the method is likely to be Survived."
survived,"def test_restart_crashed_agent(monkeypatch: mock.Mock) -> None:
    events: list[str | None] = []

    class DummyLedger:
        def __init__(self, *_a, **_kw) -> None:
            pass

        def log(self, env) -> None:  # type: ignore[override]
            events.append(env.payload.get(""event""))

        def start_merkle_task(self, *_a, **_kw) -> None:
            pass

        async def stop_merkle_task(self) -> None:
            pass

        def close(self) -> None:
            pass

    settings = config.Settings(bus_port=0)
    monkeypatch.setattr(orchestrator, ""Ledger"", DummyLedger)
    monkeypatch.setattr(
        orchestrator.Orchestrator, ""_init_agents"", lambda self: [BoomAgent(self.bus, self.ledger)]
    )

    async def loop_no_catch(self: orchestrator.AgentRunner, bus, ledger) -> None:
        await self.agent.run_cycle()

    async def restart_no_error(self: orchestrator.AgentRunner, bus, ledger) -> None:
        if self.task:
            self.task.cancel()
            with contextlib.suppress(Exception):
                await self.task
        self.agent = self.cls(bus, ledger)
        self.start(bus, ledger)
        self.last_beat = orchestrator.time.time()

    monkeypatch.setattr(orchestrator.AgentRunner, ""loop"", loop_no_catch)
    monkeypatch.setattr(orchestrator.AgentRunner, ""restart"", restart_no_error)

    orch = orchestrator.Orchestrator(settings)
    runner = orch.runners[""boom""]
    start_beat = runner.last_beat

    async def run() -> None:
        await orch.bus.start()
        runner.start(orch.bus, orch.ledger)
        orig_sleep = asyncio.sleep
        with mock.patch.object(
            orchestrator.asyncio,
            ""sleep"",
            new=lambda _t: orig_sleep(0.05),
        ):
            monitor = asyncio.create_task(orch._monitor())
            await orig_sleep(0.2)
            monitor.cancel()
            with contextlib.suppress(asyncio.CancelledError):
                await monitor
        if runner.task:
            runner.task.cancel()
            with contextlib.suppress(asyncio.CancelledError, BaseException):
                await runner.task
        await orch.bus.stop()

    asyncio.run(run())

    assert ""restart"" in events
    assert runner.last_beat > start_beat",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_orchestrator.py,,1,2.3823698451773172e-07,"The method 'test_restart_crashed_agent' is a test function that uses mocking to simulate the behavior of an orchestrator and its components. It is designed to test the restart functionality of an agent runner when an agent crashes. The method is well-structured, uses dependency injection via monkeypatching, and includes assertions to verify the expected behavior. Test functions like this are crucial for ensuring the reliability of software systems, especially in complex orchestrations. Therefore, it is likely to be retained as part of the test suite to ensure the robustness of the system."
survived,"def close() -> None:
    """"""Close the module-level ``mem`` instance.""""""
    mem.close()
",alpha_factory_v1/backend/memory_fabric.py,,1,5.905303995456778e-10,"The method 'close' is a simple utility function that calls the 'close' method on a module-level instance 'mem'. This kind of method is typically used to encapsulate resource cleanup operations, which are essential for managing resources like file handles, network connections, or in-memory data structures. Such methods are generally retained in codebases because they provide a clear and centralized way to release resources, which is crucial for preventing resource leaks and ensuring proper application shutdown. Therefore, it is likely to survive."
survived,"def test_hex_escape_sequence() -> None:
    chunks = ['{""a"": ""\\', 'x41""}']
    parsed = _stream_to_dict({}, chunks)
    assert parsed == {""a"": ""A""}
",api/core/utils/streams_test.py,,1,4.944450477491054e-09,"The method `test_hex_escape_sequence` is a unit test that verifies the functionality of the `_stream_to_dict` function, specifically its ability to correctly parse a JSON string containing a hexadecimal escape sequence. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with string parsing and encoding issues. Since this test serves a clear purpose in validating a specific behavior of the code, it is likely to be retained as part of the test suite to prevent regressions and ensure the function works as expected."
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/machine/x/python/q1.py,,1,4.944450477491054e-09,"The method '_group_by' is a utility function that groups elements of a list based on a key function. This is a common and useful operation in data processing and manipulation, making it likely to be retained. The function handles different types of input (lists, tuples, and single elements) and manages keys that are dictionaries by converting them to SimpleNamespace objects, which adds flexibility. These features suggest that the method is well-designed for its purpose and is likely to be used in various contexts, increasing its chances of survival."
survived,"def _get(obj, name):
    if obj is None:
        return None
    if isinstance(obj, dict):
        if name in obj:
            return obj[name]
    if hasattr(obj, name):
        return getattr(obj, name)
    if name == ""items"" and hasattr(obj, ""Items""):
        return getattr(obj, ""Items"")
    if isinstance(obj, (list, tuple)):
        for it in obj:
            try:
                return _get(it, name)
            except Exception:
                pass
    raise Exception(""field not found: "" + name)
",tests/machine/x/python/q3.py,,1,1.0467401685178159e-08,"The method '_get' is a utility function designed to retrieve a value from an object based on a given name. It handles various types of objects, including dictionaries, objects with attributes, and lists or tuples. This flexibility makes it a useful function for accessing nested data structures, which is a common requirement in many applications. The method also includes error handling to manage cases where the desired field is not found, which is a good practice. Given its utility and robustness, it is likely to be retained in the codebase."
survived,"def test_Q1_aggregates_revenue_and_quantity_by_returnflag___linestatus():
    assert result == [
        {
            ""returnflag"": ""N"",
            ""linestatus"": ""O"",
            ""sum_qty"": 53,
            ""sum_base_price"": 3000,
            ""sum_disc_price"": 950 + 1800,
            ""sum_charge"": 950 * 1.07 + 1800 * 1.05,
            ""avg_qty"": 26.5,
            ""avg_price"": 1500,
            ""avg_disc"": 0.07500000000000001,
            ""count_order"": 2,
        }
    ]
",tests/machine/x/python/q1.py,,1,1.3709566550544279e-06,"The method is a test function, which is typically used in software development to verify that a particular piece of code behaves as expected. Test functions are crucial for maintaining code quality and ensuring that changes do not introduce new bugs. The presence of an assert statement indicates that this function is checking the correctness of some aggregation logic. Since testing is a fundamental part of the development process, especially in environments that prioritize code reliability and correctness, it is unlikely that this method will be deleted unless it becomes obsolete or redundant due to changes in the codebase."
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/q2.py,Region,1,5.3157849718487075e-08,"The method `__repr__` is a special method in Python used to define a string representation of an object. The implementation provided here returns the string representation of the object's dictionary, which is a common and useful way to represent an object for debugging purposes. This method is likely to be retained because it provides a clear and concise way to inspect the internal state of an object, which is valuable for developers during development and debugging."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/machine/x/python/q1.py,,1,1.4166087846364157e-09,"The method '_key' is a utility function that is likely used internally within a module or class to generate a key for sorting purposes. It takes an iterable 'it', applies a sorting key function from 'opts', and ensures the key is a string if it's a complex data type. This kind of function is common in sorting operations and is unlikely to be deleted unless the sorting mechanism is completely refactored or replaced. Therefore, it is more likely to survive."
survived,"def _get(obj, name):
    if obj is None:
        return None
    if isinstance(obj, dict):
        if name in obj:
            return obj[name]
    if hasattr(obj, name):
        return getattr(obj, name)
    if name == ""items"" and hasattr(obj, ""Items""):
        return getattr(obj, ""Items"")
    if isinstance(obj, (list, tuple)):
        for it in obj:
            try:
                return _get(it, name)
            except Exception:
                pass
    raise Exception(""field not found: "" + name)
",tests/machine/x/python/q1.py,,1,4.363462233903899e-09,"The method '_get' is a utility function designed to retrieve a value from an object based on a given name. It handles various types of objects, including dictionaries, objects with attributes, and lists or tuples. This flexibility makes it a useful function for accessing nested data structures, which is a common requirement in many applications. The method also includes error handling to manage cases where the desired field is not found, which is a good practice. Given its utility and robustness, it is likely to be retained in the codebase."
survived,"def test_generate_branch_name_slugified() -> None:
    log = ""E   ValueError: something went wrong on operation""  # long line
    name = llm_client.generate_branch_name(log)
    assert name.startswith(""e-valueerror-something"")
    assert len(name) <= 30",tests/test_llm_client_utils.py,,1,1.0467401685178159e-08,"The method `test_generate_branch_name_slugified` is a test function that checks the behavior of the `generate_branch_name` method from an `llm_client` object. It verifies that the generated branch name starts with a specific prefix and does not exceed a certain length. This kind of test is crucial for ensuring that the `generate_branch_name` method works as expected, especially in terms of formatting and length constraints. Test functions are generally not deleted unless they are redundant or the functionality they test is no longer relevant. Since this test is straightforward and serves a clear purpose, it is likely to be retained."
survived,"    def test_stream_macro_events_respects_poll_interval(self) -> None:
        async def run_check() -> None:
            with (
                patch.dict(os.environ, {""POLL_INTERVAL_SEC"": ""2""}),
                patch(
                    ""alpha_factory_v1.demos.macro_sentinel.data_feeds.asyncio.sleep"",
                    new_callable=AsyncMock,
                ) as sleep_mock,
            ):
                it = data_feeds.stream_macro_events(live=False)
                await anext(it)
                await anext(it)
                sleep_mock.assert_awaited_with(2.0)

        asyncio.run(run_check())
",tests/test_macro_sentinel.py,TestMacroSentinel,1,6.023574641292144e-08,"The method 'test_stream_macro_events_respects_poll_interval' is a unit test designed to verify that the 'stream_macro_events' function respects a specified polling interval. Unit tests are generally not deleted unless they are redundant, incorrect, or the functionality they test is removed. Since this test is checking a specific behavior (poll interval) which is likely to remain relevant as long as the 'stream_macro_events' function exists, it is unlikely to be deleted."
survived,"    def _tool(*_a, **_k):
        def dec(func):
            return func

        return dec
",tests/test_aiga_service.py,,1,1.9947301075518807e-06,"The method _tool is a decorator factory that returns a decorator (dec) which, in turn, returns the function it decorates without modification. This pattern is often used to create decorators that can be extended or modified later. Since it doesn't currently alter the behavior of the decorated function, it might seem redundant. However, it provides a structure for future enhancements, making it potentially useful for future development. Therefore, it is likely to be retained for its potential utility."
survived,"def test_run_transfer_test_writes_csv(tmp_path, monkeypatch) -> None:
    db = tmp_path / ""arch.db""
    arch = Archive(db)
    arch.add({""name"": ""a""}, 0.1)
    arch.add({""name"": ""b""}, 0.9)
    out = tmp_path / ""results"" / ""transfer.csv""

    def fake_eval(agent, model):
        return agent.score + 1

    monkeypatch.setattr(tt, ""evaluate_agent"", fake_eval)

    tt.run_transfer_test([""m""], 1, archive_path=db, out_file=out)
    lines = out.read_text().splitlines()
    assert lines[0] == ""id,model,score""
    assert lines[1] == ""2,m,1.900""
",tests/test_transfer_test.py,,1,8.76424914819242e-08,"The method 'test_run_transfer_test_writes_csv' is a unit test function that verifies the functionality of writing a CSV file during a transfer test. It uses a temporary path and monkeypatching to simulate the environment and behavior of the 'evaluate_agent' function. This kind of test is crucial for ensuring that the code behaves as expected in different scenarios and that the output is correctly formatted. Since testing is an essential part of software development to maintain code quality and reliability, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly changed."
survived,"def run() -> None:
    n = 15
    total = sum(range(n))
    expected = n*(n-1)//2
    assert total == expected",benchmarks/swe_mini/task_015.py,,1,4.4508487281649027e-07,"The method 'run' is a simple function that calculates the sum of numbers from 0 to n-1 and checks if it matches the expected sum using the formula for the sum of an arithmetic series. This is a basic implementation that serves as a demonstration or test of the formula. It doesn't have any side effects or dependencies, and it correctly implements a mathematical concept. Therefore, it is likely to be retained as it is a valid and correct piece of code."
survived,"def run() -> None:
    parts = [""poly"", ""task"", ""2""]
    joined = ""-"".join(parts)
    assert joined.split(""-"")[2] == str(2)",benchmarks/poly_mini/task_002.py,,1,4.6911638017642294e-08,"The method 'run' is a simple function that joins a list of strings with a hyphen and then splits the resulting string to assert that the third element is '2'. This is a basic operation that demonstrates string manipulation and is likely used for educational or illustrative purposes. It doesn't have any apparent issues or redundancies that would necessitate its deletion. Therefore, it is likely to be retained in the codebase."
survived,"def run() -> None:
    n = 8
    total = sum(range(n))
    expected = n*(n-1)//2
    assert total == expected",benchmarks/swe_mini/task_008.py,,1,6.475946147757848e-07,"The method 'run' is a simple function that calculates the sum of numbers from 0 to n-1 and checks if it matches the expected sum using the formula for the sum of an arithmetic series. This is a basic test function that verifies the correctness of the sum calculation. It doesn't have any side effects or dependencies, and it serves as a simple example of using assertions for testing. Such utility functions are often kept in codebases for testing purposes, especially in educational or demonstration contexts. Therefore, it is likely to be retained."
survived,"def run() -> None:
    n = 11
    total = sum(range(n))
    expected = n*(n-1)//2
    assert total == expected",benchmarks/swe_mini/task_011.py,,1,1.522997951276035e-08,"The method 'run' is a simple function that calculates the sum of numbers from 0 to n-1 and checks if it matches the expected sum using the formula for the sum of an arithmetic series. This is a basic and correct implementation of a mathematical concept, and it serves as a good example or test case for verifying the sum formula. There is no indication that this method is incorrect or unnecessary, so it is likely to be retained."
survived,"def run() -> None:
    n = 2
    total = sum(range(n))
    expected = n*(n-1)//2
    assert total == expected",benchmarks/swe_mini/task_002.py,,1,6.825604231969389e-08,The method 'run' is a simple function that calculates the sum of a range of numbers and checks it against an expected value using an assertion. This function is straightforward and serves a specific purpose of validating the sum calculation for a given 'n'. It is likely to survive because it is a basic utility function that can be useful for testing or educational purposes. It doesn't have any apparent issues or redundancies that would necessitate its deletion.
survived,"def run() -> None:
    n = 12
    total = sum(range(n))
    expected = n*(n-1)//2
    assert total == expected",benchmarks/swe_mini/task_012.py,,1,5.043472052266442e-07,"The method 'run' is a simple function that calculates the sum of numbers from 0 to n-1 and checks if it matches the expected sum using the formula n*(n-1)//2. This is a basic implementation of a mathematical property and serves as a simple test or demonstration of the formula. The function is self-contained, has no side effects, and correctly implements the logic it is supposed to demonstrate. Therefore, there is no reason for it to be deleted as it is functional and serves its purpose."
survived,"def run() -> None:
    n = 14
    total = sum(range(n))
    expected = n*(n-1)//2
    assert total == expected",benchmarks/swe_mini/task_014.py,,1,6.023574641292144e-08,"The method 'run' is a simple function that calculates the sum of the first 'n' natural numbers and checks it against the expected formula result. This is a basic mathematical operation and serves as a good example of using assertions for validation. The function is straightforward, has no side effects, and is useful for educational purposes or as a utility function in larger codebases. Therefore, it is likely to be retained."
survived,"def run() -> None:
    parts = [""poly"", ""task"", ""5""]
    joined = ""-"".join(parts)
    assert joined.split(""-"")[2] == str(5)",benchmarks/poly_mini/task_005.py,,1,3.653482080241728e-08,"The method 'run' is a simple function that joins a list of strings with a hyphen and then splits the resulting string to assert that the third element is '5'. This is a basic operation that demonstrates string manipulation and is likely used for educational or illustrative purposes. It doesn't have any apparent issues or redundancies that would necessitate its deletion. Therefore, it is likely to be retained in the codebase."
survived,"def run() -> None:
    n = 17
    total = sum(range(n))
    expected = n*(n-1)//2
    assert total == expected",benchmarks/swe_mini/task_017.py,,1,3.2887477414614998e-06,"The method 'run' is a simple function that calculates the sum of numbers from 0 to n-1 and checks if it matches the expected sum using the formula n*(n-1)//2. This is a basic implementation of a mathematical property and serves as a simple test or demonstration of the formula. The function is self-contained, has no side effects, and correctly implements the logic it is supposed to demonstrate. Therefore, there is no reason to delete it unless it is deemed unnecessary in the context of the larger codebase. However, as a standalone function, it is correct and functional."
survived,"def _full_name(node: ast.AST) -> str:
    if isinstance(node, ast.Name):
        return node.id
    if isinstance(node, ast.Attribute):
        parent = _full_name(node.value)
        return f""{parent}.{node.attr}"" if parent else node.attr
    return """"
",src/self_edit/safety.py,,1,5.60279640614594e-09,"The method `_full_name` is a utility function that extracts the full name of a node in an abstract syntax tree (AST). This is a common requirement when working with ASTs, as it helps in understanding the structure and relationships within the code being analyzed. The function is well-defined, handles different node types, and provides a clear output. Such utility functions are often necessary for code analysis, refactoring tools, or linters, making them valuable in various applications. Therefore, it is likely to be retained in the codebase."
survived,"def test_self_healer_applies_patch(tmp_path, monkeypatch):
    repo_src = Path(__file__).parent / ""fixtures"" / ""self_heal_repo""
    repo_path = tmp_path / ""repo""
    shutil.copytree(repo_src, repo_path)
    subprocess.run([""git"", ""init""], cwd=repo_path, check=True)
    subprocess.run([""git"", ""add"", "".""], cwd=repo_path, check=True)
    subprocess.run([""git"", ""commit"", ""-m"", ""init""], cwd=repo_path, check=True)
    commit = subprocess.check_output([""git"", ""rev-parse"", ""HEAD""], cwd=repo_path, text=True).strip()

    workdir = tmp_path / ""work""
    healer = self_healer.SelfHealer(repo_url=str(repo_path), commit_sha=commit)
    healer.working_dir = str(workdir)

    patch = """"""--- a/calc.py
+++ b/calc.py
@@
-    return a - b
+    return a + b
""""""

    monkeypatch.setattr(llm_client, ""request_patch"", lambda *_: patch)
    monkeypatch.setattr(diff_utils, ""parse_and_validate_diff"", lambda diff: diff)
    monkeypatch.setattr(self_healer.SelfHealer, ""commit_and_push_fix"", lambda self: ""branch"")
    monkeypatch.setattr(self_healer.SelfHealer, ""create_pull_request"", lambda self, branch: 1)

    pr = healer.run()

    with open(workdir / ""calc.py"") as fh:
        content = fh.read()
    assert ""a + b"" in content
    assert ""1 passed"" in healer.test_results
    assert pr == 1",tests/test_self_healer_pipeline.py,,1,2.2159489282323004e-08,"The method 'test_self_healer_applies_patch' is a test function that verifies the functionality of a self-healing system. It uses fixtures, mocks, and assertions to ensure that the self-healer applies a patch correctly, commits the changes, and creates a pull request. This is a typical use case for a test function in a codebase that involves automated testing and continuous integration. Test functions are generally not deleted unless they are redundant or replaced by more comprehensive tests. Given that this function seems to be well-structured and serves a clear purpose, it is likely to be retained in the codebase."
survived,"    def test_list_agents_tool(self):
        with patch.object(bridge.requests, ""get"", return_value=DummyResponse([""a""])) as get:
            result = asyncio.run(bridge.list_agents())
        get.assert_called_once_with(""http://localhost:7860/agents"", timeout=5)
        self.assertEqual(result, [""a""])
",tests/test_inspector_bridge.py,TestInspectorAgent,1,1.4166087846364157e-09,"The method 'test_list_agents_tool' is a unit test for the 'list_agents' function in the 'bridge' module. It uses mocking to simulate the behavior of an HTTP GET request and checks if the 'list_agents' function returns the expected result. This is a standard practice in testing to ensure that the function behaves correctly without making actual network calls. The method is well-structured and serves a clear purpose in the testing suite, making it unlikely to be deleted unless the functionality it tests is removed or significantly changed."
survived,"def test_malicious_message_blocked(tmp_path) -> None:
    if not hasattr(struct_pb2.Struct, ""get""):
        def _get(self: struct_pb2.Struct, key: str, default=None):
            try:
                return self[key]
            except Exception:
                return default

        struct_pb2.Struct.get = _get  # type: ignore[attr-defined]

    cfg = config.Settings(bus_port=0)
    bus = messaging.A2ABus(cfg)
    ledger = logging.Ledger(str(tmp_path / ""ledger.db""), broadcast=False)

    mem = memory_agent.MemoryAgent(bus, ledger, str(tmp_path / ""mem.log""))
    guardian = safety_agent.SafetyGuardianAgent(bus, ledger)
    chaos = chaos_agent.ChaosAgent(bus, ledger, burst=1)

    async def run() -> None:
        async with bus, ledger:
            await chaos.run_cycle()
            await asyncio.sleep(0)

    asyncio.run(run())

    assert mem.records
    assert mem.records[-1][""status""] == ""blocked""",tests/test_safety_block.py,,1,5.043472052266442e-07,"The method 'test_malicious_message_blocked' is a test function that verifies the functionality of a system to block malicious messages. It sets up a testing environment with various agents and runs an asynchronous cycle to simulate the conditions under which a message might be blocked. The test then asserts that a record exists and that the last record's status is 'blocked'. This is a typical structure for a unit test in software development, and such tests are crucial for ensuring the reliability and security of the system. Therefore, it is unlikely that this method will be deleted as it serves an important role in maintaining the integrity of the system."
survived,"def bollinger_bands(
    prices: Sequence[float],
    window: int = 20,
    num_std: float = 2.0,
) -> tuple[float, float]:
    """"""Return the lower and upper Bollinger Bands.""""""

    if window <= 0:
        raise ValueError(""window must be positive"")
    if len(prices) < window:
        return (0.0, 0.0)

    if np is not None:
        arr = np.asarray(prices[-window:], dtype=float)
        mean = float(arr.mean())
        std = float(arr.std(ddof=1))
    else:
        slice_ = [float(p) for p in prices[-window:]]
        mean = sum(slice_) / window
        variance = sum((p - mean) ** 2 for p in slice_) / (window - 1)
        std = variance ** 0.5
    band = num_std * std
    return (mean - band, mean + band)
",alpha_factory_v1/backend/alpha_model.py,,1,5.60279640614594e-09,"The method 'bollinger_bands' is a well-defined function that calculates the Bollinger Bands, a popular technical analysis tool used in financial markets. It includes error handling for invalid input, such as a non-positive window size and insufficient data points. The function is versatile, using numpy if available for efficient computation, but also providing a fallback to pure Python calculations. This makes it robust and adaptable. Given its utility in financial analysis and the completeness of its implementation, it is likely to be retained in the codebase."
survived,"    def __init__(self, start_price: float = 100.0, volatility: float = 1.0) -> None:
        self.start_price = start_price
        self.volatility = volatility
        self.price = start_price
",alpha_factory_v1/backend/environments/market_sim.py,MarketEnv,1,3.466327708641819e-07,"The method is a constructor for a class, initializing important attributes such as start_price, volatility, and price. These attributes are likely essential for the functionality of the class, especially if it is related to financial calculations or simulations. Constructors are fundamental to class design, and unless there is a significant reason to remove it (such as a complete redesign of the class), it is unlikely to be deleted."
survived,"    async def __aexit__(self, *_exc) -> None:
        return None
",alpha_factory_v1/backend/market_data.py,SimulatedMarketData,0,0.9984988179739497,"The method `__aexit__` is part of the asynchronous context manager protocol in Python, which is used to define cleanup actions when exiting an async context. However, the current implementation of `__aexit__` is not performing any meaningful operation as it simply returns `None`. While this does not break any functionality, it does not add any value either. If the context manager does not require any cleanup actions, the method could be omitted entirely. However, if this is a placeholder for future implementation, it might be retained. Without additional context, it's likely that this method will be deleted or refactored to include actual cleanup logic."
survived,"    async def close(self) -> None:
        return None
",alpha_factory_v1/backend/market_data.py,SimulatedMarketData,0,0.9999994956527948,"The method 'close' is an asynchronous function that is supposed to perform some closing operations, but it currently does nothing and simply returns None. This makes the method redundant and unnecessary in its current form. Unless there is a specific reason to keep a placeholder for future implementation, it is likely to be deleted as it serves no functional purpose."
survived,"    async def close(self) -> None:
        await self.__aexit__(None, None, None)
",alpha_factory_v1/backend/market_data.py,PolygonMarketData,1,2.3355930333443423e-09,"The method 'close' is an asynchronous method that calls another asynchronous method '__aexit__'. This pattern is common in context managers to ensure proper cleanup of resources. The method is likely part of a class that implements asynchronous context management, which is a useful and modern feature in Python for handling asynchronous operations. Given the increasing use of asynchronous programming in Python, this method is likely to be retained as it provides a necessary functionality for resource management in asynchronous contexts."
survived,"    def __del__(self) -> None:
        self.close()
",alpha_factory_v1/backend/memory_graph.py,GraphMemory,1,3.2241866333029355e-08,"The method is a destructor in Python, which is automatically called when an object is about to be destroyed. The purpose of this method is to ensure that resources are properly released, in this case by calling the `close()` method. This is a common and necessary practice in resource management, especially for objects that handle external resources like files or network connections. Therefore, the method is likely to be retained as it serves an important function in resource cleanup."
survived,"    def test_act_runs_cycle(self):
        agent = DummyAgent()
        model = DummyModel('{""agent"":""dummy"",""reason"":""ok""}')
        planner = PlannerAgent(
            name=""planner"",
            model=model,
            memory=self.memory,
            gov=self.gov,
            domain_agents=[agent],
        )
        asyncio.run(planner.act([{""agent"": ""dummy""}]))
        self.assertTrue(agent.ran)
",alpha_factory_v1/tests/test_planner_agent.py,PlannerAgentTest,1,8.76424914819242e-08,"The method 'test_act_runs_cycle' is a unit test designed to verify the functionality of the 'act' method in the 'PlannerAgent' class. It sets up a dummy agent and model, runs the 'act' method, and asserts that the agent's 'ran' attribute is set to True, indicating that the agent has executed its cycle. This is a typical structure for a unit test, which is crucial for ensuring code reliability and correctness. Therefore, it is likely to be retained in the codebase to maintain test coverage and ensure that changes do not break existing functionality."
survived,"    def forward(self, h, a):
        x = torch.cat([h, a], -1)
        return self.r(x), torch.tanh(self.h(x))
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,Dyn,1,3.653482080241728e-08,"The method 'forward' is a typical implementation in neural network models, particularly in PyTorch, where 'forward' defines the forward pass of the network. The method concatenates two inputs, 'h' and 'a', and then applies two operations: a linear transformation 'self.r(x)' and a non-linear transformation 'torch.tanh(self.h(x))'. This is a standard practice in defining neural network layers and is essential for the model's functionality. Therefore, it is unlikely to be deleted as it is a core part of the model's operation."
survived,"    def __init__(self): super().__init__(""safety"")
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,BasicSafetyAgent,1,4.944450477491054e-09,"The method is a constructor for a class, and it calls the superclass's constructor with a specific argument ('safety'). This is a common pattern in object-oriented programming to ensure proper initialization of the class hierarchy. There is no indication that this method is redundant or incorrect, so it is likely to be retained in the codebase."
survived,"async def send_cmd(cmd:Dict[str,str]):
    A2ABus.publish(""orch"",cmd); return {""ok"":True}
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,,1,8.592166611791576e-10,"The method 'send_cmd' is a simple asynchronous function that takes a dictionary as an argument and publishes it to a bus using 'A2ABus.publish'. It then returns a success response. The method is straightforward, performs a clear task, and uses asynchronous programming, which is beneficial for non-blocking operations. There is no indication of redundancy or inefficiency in the code, and it likely serves a specific purpose in the system. Therefore, it is likely to be retained."
survived,"def run_cycle(orchestrator: Orchestrator, fin_agent: AgentFin, res_agent: AgentRes,
              ene_agent: AgentEne, gdl_agent: AgentGdl, model: Model) -> None:
    """"""Execute one evaluation + commitment cycle.""""""

    bundle = orchestrator.collect_signals()
    delta_h = fin_agent.latent_work(bundle)
    delta_s = res_agent.entropy(bundle)
    beta = ene_agent.market_temperature()
    delta_g = delta_h - (delta_s / beta)

    log.info(""Î”H=%s Î”S=%s Î²=%s â†’ Î”G=%s"", delta_h, delta_s, beta, delta_g)

    if delta_g < 0:
        orchestrator.post_alpha_job(id(bundle), delta_g)

    weight_update: Dict[str, Any] = {}
    if gdl_agent.provable(weight_update):
        model.commit(weight_update)
",alpha_factory_v1/demos/alpha_agi_business_3_v1/alpha_agi_business_3_v1.py,,1,2.3355930333443423e-09,"The method 'run_cycle' is likely to survive because it appears to be a well-structured and purposeful function within a larger system. It integrates multiple components (orchestrator, agents, model) to perform a specific task, which is executing an evaluation and commitment cycle. The method includes logging for monitoring and debugging, and it has conditional logic to handle different scenarios based on the calculated values. These characteristics suggest that the method is functional and valuable within its context, making it unlikely to be deleted."
survived,"def _call(
    method: str,
    url: str,
    *,
    params: dict | None = None,
    json: dict | None = None,
    data: dict | bytes | None = None,
    headers: dict | None = None,
    timeout: float | None = None,
) -> Response:
    if params:
        query = _parse.urlencode(params, doseq=True)
        url += (""&"" if ""?"" in url else ""?"") + query

    body = None
    req_headers = {""User-Agent"": _UA, **(headers or {})}
    if json is not None:
        body = _json.dumps(json).encode()
        req_headers.setdefault(""Content-Type"", ""application/json"")
    elif data is not None:
        if isinstance(data, (bytes, bytearray)):
            body = data
        else:
            body = _parse.urlencode(data).encode()
            req_headers.setdefault(""Content-Type"", ""application/x-www-form-urlencoded"")

    req = _request.Request(url, data=body, headers=req_headers, method=method)
    try:
        with _request.urlopen(req, timeout=timeout) as resp:
            content = resp.read()
            resp_headers = dict(resp.headers.items())
            return Response(resp.getcode(), content, resp_headers, url)
    except _error.HTTPError as exc:
        content = exc.read()
        resp_headers = dict(exc.headers.items()) if hasattr(exc, ""headers"") else {}
        return Response(exc.code, content, resp_headers, url)
    except _error.URLError as exc:  # pragma: no cover - network issues
        if isinstance(getattr(exc, ""reason"", None), TimeoutError):
            raise Timeout(str(exc.reason))
        raise RequestException(str(exc))
",alpha_factory_v1/requests.py,,1,1.522997951276035e-08,"The method '_call' is a utility function for making HTTP requests, handling both successful responses and errors. It is well-structured, supports various HTTP methods, and includes error handling for HTTP and URL errors. This makes it a versatile and robust function for network operations, which are common in many applications. Therefore, it is likely to be retained as it provides essential functionality for interacting with web services."
survived,"def main() -> None:
    parser = argparse.ArgumentParser(description=""Run Alpha-Factory on edge devices"")
    parser.add_argument(
        ""--agents"",
        default=""manufacturing,energy"",
        help=""Comma separated list of agents to enable"",
    )
    parser.add_argument(
        ""--cycle"",
        type=int,
        help=""Override agent cycle seconds"",
    )
    parser.add_argument(
        ""--loglevel"",
        default=""INFO"",
        help=""Logging verbosity"",
    )
    args = parser.parse_args()

    os.environ.setdefault(""DEV_MODE"", ""true"")
    os.environ[""ALPHA_ENABLED_AGENTS""] = args.agents
    os.environ[""LOGLEVEL""] = args.loglevel.upper()
    if args.cycle:
        os.environ[""ALPHA_CYCLE_SECONDS""] = str(args.cycle)

    from alpha_factory_v1.backend.orchestrator import Orchestrator
    Orchestrator().run_forever()
",edge_runner.py,,1,1.522997951276035e-08,"The method is likely to survive because it is a main entry point for a command-line application. It sets up argument parsing, configures environment variables, and initiates the main process by calling the Orchestrator's run_forever method. These are typical responsibilities of a main function in a script designed to be executed directly, indicating that it serves a crucial role in the application's operation."
survived,"def test_use_guards_sets_attribute():
    assert hasattr(GuardController.root, ""__guards__"")
    assert SimpleGuard in GuardController.root.__guards__
",tests/test_core/test_decorators/test_guard.py,,1,9.931195248674785e-08,"The method `test_use_guards_sets_attribute` is a test function, likely part of a test suite for a software project. Test functions are generally not deleted unless they are redundant, incorrect, or replaced by better tests. This function checks for the presence of an attribute and a specific element within it, which suggests it is verifying important functionality. Therefore, it is likely to be maintained as part of the test coverage."
survived,"    def can_activate(self, request: Request) -> bool:
        """"""Override this method with your authorization logic.""""""
        raise NotImplementedError
",nest/core/guards.py,BaseGuard,1,1.2098660619383578e-06,"The method `can_activate` is a placeholder meant to be overridden with specific authorization logic. It raises a `NotImplementedError`, indicating that it is intended to be implemented by subclasses. This pattern is common in abstract base classes or interfaces where specific behavior is expected to be defined by the user. Since it serves a clear purpose in a framework or library design, it is unlikely to be deleted unless the entire design pattern changes."
survived,"def choose_example(examples: dict[str, str], preselected: str | None = None) -> str:
    """"""Prompt the user to choose an example.""""""
    names = sorted(examples)
    if preselected and preselected in examples:
        return preselected

    print(""Available examples:"")
    for idx, name in enumerate(names, 1):
        print(f""  {idx}. {name}"")

    while True:
        choice = input(""Select example by number or name: "").strip()
        if choice in examples:
            return choice
        if choice.isdigit():
            index = int(choice) - 1
            if 0 <= index < len(names):
                return names[index]
        print(""Invalid selection, try again."")
",examples/openai_chat_agent/app.py,,1,1.1032560311263802e-09,"The method 'choose_example' is a utility function that allows users to select an example from a dictionary of examples. It provides a user-friendly interface by listing available options and accepting both numerical and name-based inputs. The function also handles invalid inputs gracefully by prompting the user to try again. This kind of functionality is common in interactive applications and scripts where user input is required to make a selection. Given its utility and the fact that it is well-implemented with error handling, it is likely to be retained in the codebase."
survived,"    def fail_secho(*args, **kwargs):
        raise OSError(""boom"")
",tests/integration/test_ux_interactions.py,,0,0.9999999987498471,"The method 'fail_secho' is designed to immediately raise an OSError with the message 'boom' whenever it is called. This makes the method non-functional for any practical use, as it does not perform any operations other than raising an exception. Such methods are typically used for testing purposes or as placeholders during development. However, in a production codebase, a method that only raises an exception without any conditional logic or additional functionality is likely to be removed unless it serves a specific purpose in error handling or testing. Therefore, it is predicted to be deleted."
survived,"def test_scan_via():
    class Module(eqx.Module):
        w: hax.NamedArray

        def with_output(self, x):
            out = x + self.w
            return out, 2 * self.w

        @staticmethod
        def init(named):
            return Module(w=named)

    Block = hax.Axis(""block"", 4)
    E = hax.Axis(""E"", 6)

    named = hax.random.uniform(jax.random.PRNGKey(0), (Block, E))
    m = Stacked.init(Block, Module)(named=named)

    x = hax.random.uniform(jax.random.PRNGKey(1), (E,))
    carry, outs = m.scan_via(Module.with_output)(x)

    expected_carry = x + hax.sum(named, Block)
    expected_outs = 2 * named

    assert hax.all(hax.isclose(carry, expected_carry))
    assert hax.all(hax.isclose(outs, expected_outs))",tests/test_scan.py,,1,3.0590235908148916e-07,"The method `test_scan_via` is a test function that verifies the behavior of a module using the `scan_via` method. It is a part of a testing suite, likely for a library or framework that involves named arrays and modules. Test functions are generally not deleted unless they are redundant, incorrect, or the functionality they test is deprecated. Since this function appears to be correctly testing the expected behavior of the `scan_via` method, it is likely to be retained to ensure the correctness of the module's functionality."
survived,"    def fake_import(name, globals=None, locals=None, fromlist=(), level=0):
        if name == ""openai_agents"":
            raise ModuleNotFoundError(name)
        return orig_import(name, globals, locals, fromlist, level)
",tests/test_governance_bridge_offline.py,,0,0.9999998144608401,"The method 'fake_import' is designed to intercept import statements and specifically raise a ModuleNotFoundError when the module 'openai_agents' is attempted to be imported. This kind of functionality is often used for testing purposes, to simulate the absence of a module or to prevent certain modules from being imported during execution. Such methods are typically temporary and used in specific testing scenarios. Given its specific use case and the fact that it alters the default behavior of the import system, it is likely to be deleted after its purpose is served, as it is not a general-purpose utility."
survived,"def _parse_args(argv: list[str] | None = None) -> argparse.Namespace:
    ap = argparse.ArgumentParser(
        description=""Expose the governance simulation via OpenAI Agents runtime""
    )
    ap.add_argument(
        ""--enable-adk"",
        action=""store_true"",
        help=""Expose agent via ADK gateway"",
    )
    return ap.parse_args(argv)
",alpha_factory_v1/demos/solving_agi_governance/openai_agents_bridge.py,,1,2.2159489282323004e-08,"The method `_parse_args` is a utility function that uses the `argparse` module to parse command-line arguments. This is a common and standard practice in Python for handling command-line interfaces. The function is well-defined, with a clear purpose of setting up an argument parser and returning the parsed arguments. It is likely to be used in a script or application that requires command-line interaction, which is a common requirement in many software projects. Therefore, the method is likely to be retained as it serves a useful purpose in the context of command-line argument parsing."
survived,"    def run(self) -> None:
        pass
",tests/test_openai_bridge_integration.py,_AgentRuntime,1,1.9947301075518807e-06,"The method 'run' is defined but not implemented, as it only contains a 'pass' statement. This suggests that the method is either a placeholder for future implementation or is intentionally left empty because it is meant to be overridden in a subclass. Without additional context, such as comments indicating future plans for this method or its role in a larger framework, it's difficult to determine its necessity. However, in many cases, such methods are placeholders in abstract classes or interfaces, suggesting they are likely to survive until they are properly implemented or overridden. Therefore, the method is predicted to survive."
survived,"def sum3(a: int, b: int, c: int) -> int:
    return a + b + c
",tests/human/py/fun_three_args.py,,1,4.363462233903899e-09,"The method 'sum3' is a simple utility function that takes three integers as input and returns their sum. Such utility functions are often useful in various programming scenarios where a quick sum of multiple numbers is needed. The function is straightforward, has a clear purpose, and is likely to be reused in different parts of a codebase. Therefore, it is more likely to be retained rather than deleted."
survived,"        async def __aenter__(self) -> ""AsyncClient"":
            return self
",alpha_factory_v1/demos/alpha_agi_business_v1/openai_agents_bridge.py,AsyncClient,1,3.160881453314576e-10,"The method is an implementation of the asynchronous context manager protocol in Python, specifically the __aenter__ method. This method is essential for using the 'async with' statement, which is a common pattern in asynchronous programming to ensure proper resource management. Since this is a fundamental part of managing asynchronous resources, it is unlikely to be deleted unless the entire class or its functionality is being removed or refactored. Therefore, the method will likely survive."
survived,"    async def list_runs(_: None = Depends(verify_token)) -> RunsResponse:
        return RunsResponse(ids=list(_simulations.keys()))
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/api_server.py,,1,5.211412485172657e-10,"The method 'list_runs' is a simple function that returns a list of simulation IDs. It uses dependency injection to verify a token, which is a common practice in web applications for security purposes. The function is straightforward, performs a necessary task, and adheres to good coding practices. There is no indication that it is obsolete or redundant, so it is likely to be retained."
survived,"    async def ws_progress(websocket: WebSocket) -> None:
        auth = websocket.headers.get(""authorization"")
        token = getattr(app_f.state, ""api_token"", API_TOKEN_DEFAULT)
        if not auth or not auth.startswith(""Bearer "") or auth.split("" "", 1)[1] != token:
            await websocket.close(code=1008)
            return
        await websocket.accept()
        _progress_ws.add(websocket)
        try:
            while True:
                await websocket.receive_text()
        except Exception:
            pass
        finally:
            _progress_ws.discard(websocket)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/api_server.py,,1,2.3355930333443423e-09,"The method 'ws_progress' is likely to survive because it implements a common pattern for handling WebSocket connections in an asynchronous manner. It includes authentication checks, connection acceptance, message receiving, and proper cleanup in the 'finally' block. These are all necessary components for managing WebSocket connections effectively. Additionally, the use of exception handling ensures that the method can handle unexpected errors gracefully, which is a good practice in production code."
survived,"def test_existing_results_dir_permissions(tmp_path: Path, monkeypatch: pytest.MonkeyPatch) -> None:
    """"""Ensure permissions are tightened when directory already exists.""""""
    path = tmp_path / ""results""
    path.mkdir(mode=0o755)
    monkeypatch.setenv(""SIM_RESULTS_DIR"", str(path))

    from alpha_factory_v1.demos.alpha_agi_insight_v1.src.interface import api_server

    api_server = importlib.reload(api_server)

    assert path.exists()
    assert (path.stat().st_mode & 0o777) == 0o700",tests/test_results_dir_permissions.py,,1,6.023574641292144e-08,"The method 'test_existing_results_dir_permissions' is a unit test function that checks if the permissions of a directory are correctly set when the directory already exists. It uses pytest's 'monkeypatch' to set an environment variable and checks the directory's permissions. This is a typical use case in testing to ensure security and correctness of file permissions, especially in environments where sensitive data might be stored. The function is well-defined, serves a clear purpose, and is likely part of a test suite that ensures the robustness of the application. Therefore, it is unlikely to be deleted as it contributes to the overall quality assurance of the software."
survived,"    def __len__(self):
        return len(self.Items)
",tests/machine/x/python/group_by_conditional_sum.py,_Group,1,1.725782769012759e-08,"The method `__len__` is a special method in Python that is used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"    def __len__(self):
        return len(self.Items)
",tests/machine/x/python/group_by.py,_Group,1,4.363462233903899e-09,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is correctly implemented to return the length of the `Items` attribute, which is presumably a list or similar collection. This is a standard and useful implementation for custom classes that manage collections, allowing them to integrate seamlessly with Python's built-in functions. Therefore, it is likely to be retained."
survived,"    def _save_cache(self) -> None:
        self.cache_path.write_text(json.dumps(self.cache, indent=2), encoding=""utf-8"")
",src/meta_agent/template_governance.py,TemplateGovernance,1,7.582560422162384e-10,"The method _save_cache is likely to survive because it performs a necessary function of saving the cache to a file. This is a common requirement in applications that need to persist data between sessions. The method is straightforward, uses standard library functions, and is implemented in a clean and efficient manner. There is no indication of redundancy or obsolescence in the code provided."
survived,"    def lint(self, content: str) -> List[str]:
        """"""Run Ruff linting on ``content`` and return issues.""""""
        proc = subprocess.run(
            [""ruff"", ""--quiet"", ""--stdin-filename"", ""template.py"", ""-""],
            input=content.encode(""utf-8""),
            capture_output=True,
        )
        output = proc.stdout.decode()
        return [line.strip() for line in output.splitlines() if line.strip()]
",src/meta_agent/template_governance.py,TemplateGovernance,1,5.905303995456778e-10,"The method 'lint' is a utility function that runs a linting tool (Ruff) on a given string of code and returns a list of issues found. This is a common and useful functionality in code editors and development environments to ensure code quality and adherence to style guidelines. The method is straightforward, uses subprocess to execute an external command, and processes the output effectively. There is no indication that this method is obsolete or redundant, and it serves a clear purpose in the context of code quality assurance. Therefore, it is likely to be retained."
survived,"def test_sign_and_verify(tmp_path: Path) -> None:
    cache = tmp_path / ""cache.json""
    gov = TemplateGovernance(secret=""key"", cache_path=cache)
    sig = gov.sign(""print('hi')\n"")
    assert sig
    assert gov.verify(""print('hi')\n"", sig)
    data = json.loads(cache.read_text())
    checksum = hashlib.sha256(""print('hi')\n"".encode()).hexdigest()
    assert data[checksum] == sig
",tests/test_template_governance.py,,1,9.931195248674785e-08,"The method 'test_sign_and_verify' is a unit test function that verifies the functionality of the 'sign' and 'verify' methods of the 'TemplateGovernance' class. It checks if the signing process generates a valid signature and if the verification process correctly validates the signature. Additionally, it ensures that the signature is stored correctly in a cache file. This test is crucial for ensuring the integrity and security of the signing and verification process, which are likely important features of the 'TemplateGovernance' class. Therefore, the method is likely to be retained as it serves an important role in maintaining code quality and reliability."
survived,"    async def step(self) -> None:
        await self.publish(""alpha.business"", {""msg"": ""company incorporated""})
",alpha_factory_v1/demos/alpha_agi_business_v1/alpha_agi_business_v1.py,IncorporatorAgent,1,7.194132978569833e-09,"The method 'step' is an asynchronous function that performs a specific task: publishing a message to a topic 'alpha.business'. This indicates that it is part of a larger system, likely involving event-driven architecture or message passing. Such methods are typically integral to the system's operation, especially if they are involved in communication or data processing workflows. Therefore, it is likely to be retained as it serves a clear purpose in the system's functionality."
survived,"def main() -> None:
    runtime = AgentRuntime(api_key=os.getenv(""OPENAI_API_KEY""))
    agent = MATSAgent()
    runtime.register(agent)
    try:
        from alpha_factory_v1.backend.adk_bridge import auto_register, maybe_launch

        auto_register([agent])
        maybe_launch()
    except Exception as exc:  # pragma: no cover - ADK optional
        print(f""ADK bridge unavailable: {exc}"")

    print(""Registered MATSAgent with runtime"")
    runtime.run()
",alpha_factory_v1/demos/meta_agentic_tree_search_v0/openai_agents_bridge.py,,1,3.2241866333029355e-08,"The method 'main' is a typical entry point for a Python script, and it includes essential functionality for setting up and running an agent. It handles the registration of the agent, attempts to integrate with an optional ADK bridge, and manages exceptions gracefully. This structure is common in applications that require modularity and optional components. The method is likely to be retained as it provides a clear and organized way to initialize and run the application, making it crucial for the operation of the system."
survived,"    def list_agents(_detail: bool = False) -> list[str]:
        return [""dummy""]
",tests/test_agent_manager_consumer.py,,1,1.1478768974997603e-05,"The method 'list_agents' is a simple function that returns a list containing a single string ""dummy"". It has a parameter '_detail' which is not used within the function, indicating that the function might be a placeholder or not fully implemented. However, without additional context on the usage or the surrounding code, it's difficult to definitively say it will be deleted. If the function is part of a larger codebase where it is used as a placeholder for future implementation or testing, it might survive. But if it's not used or needed, it could be deleted. Given the lack of context, I'll predict it will survive as it might be a placeholder for future development."
survived,"    def test_start_without_optional_dependencies(self) -> None:
        cfg = config.Settings(bus_port=0)
        with mock.patch.object(messaging, ""AIOKafkaProducer"", None), \
             mock.patch.object(messaging, ""grpc"", None):
            bus = messaging.A2ABus(cfg)
            asyncio.run(bus.start())
            asyncio.run(bus.stop())
",tests/test_message_bus.py,TestMessageBus,1,4.1399375473943306e-08,"The method 'test_start_without_optional_dependencies' is a test function that checks the behavior of the system when optional dependencies are not available. It uses mocking to simulate the absence of these dependencies and ensures that the system can start and stop without them. This is a valuable test case for ensuring robustness and flexibility in the system's operation, especially in environments where certain dependencies might not be present. Therefore, it is likely to be retained as part of the test suite to ensure continued reliability of the system under different configurations."
survived,"    def test_kafka_publish(self) -> None:
        events: list[object] = []

        class Prod:
            def __init__(self, bootstrap_servers: str) -> None:
                events.append(bootstrap_servers)

            async def start(self) -> None:
                events.append(""start"")

            async def send_and_wait(self, topic: str, data: bytes) -> None:
                events.append((topic, data))

            async def stop(self) -> None:
                events.append(""stop"")

        cfg = config.Settings(bus_port=0, broker_url=""k:1"")
        with mock.patch.object(messaging, ""AIOKafkaProducer"", Prod):
            bus = messaging.A2ABus(cfg)
            asyncio.run(bus.start())
            env = types.SimpleNamespace(sender=""a"", recipient=""b"", payload={}, ts=0.0)

            async def _send() -> None:
                bus.publish(""b"", env)
                await asyncio.sleep(0)

            asyncio.run(_send())
            asyncio.run(bus.stop())

        self.assertEqual(events[0:2], [""k:1"", ""start""])
        self.assertIn(""stop"", events)
        sent = [e for e in events if isinstance(e, tuple)][0]
        self.assertEqual(sent[0], ""b"")",tests/test_message_bus.py,TestMessageBus,1,5.60279640614594e-09,"The method `test_kafka_publish` is a unit test designed to verify the behavior of a Kafka publishing mechanism. It uses mocking to simulate the Kafka producer and checks that the correct sequence of events occurs during the publish process. This is a crucial part of ensuring the reliability and correctness of the messaging system, especially in systems that rely on asynchronous communication. Therefore, it is likely to be retained as part of the test suite to ensure ongoing code quality and functionality."
survived,"def main():
    trials = 1000
    for np in [10, 100]:
        print(""Results from "" + str(trials) + "" trials with "" + str(np) + "" prisoners:\n"")
        for strat in [""random"", ""optimal""]:
            doTrials(trials, np, strat)
",tests/rosetta/transpiler/Python/100-prisoners.py,,1,2.2159489282323004e-08,"The method 'main' is a typical entry point for a Python script, and it is structured to perform a series of trials with different strategies and numbers of prisoners. This kind of method is fundamental for running simulations or experiments in a controlled manner. It is likely to be retained because it serves a clear purpose in executing the core functionality of the script, which is to compare different strategies over a set number of trials. Without this method, the script would not be able to perform its intended function effectively."
survived,"def show_results() -> None:
    """"""Display the last ledger entries.""""""
    path = Path(config.Settings().ledger_path)
    if not path.exists():
        click.echo(""No results found"")
        return
    for line in path.read_text(encoding=""utf-8"").splitlines()[-10:]:
        click.echo(line)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/cli.py,,1,1.2501528648238603e-09,"The method 'show_results' is a utility function that reads and displays the last 10 entries from a ledger file. It includes error handling for the case where the file does not exist, providing user feedback. This functionality is useful for users who need to quickly view recent entries in a ledger, making it a practical and user-friendly feature. Therefore, it is likely to be retained in the codebase."
survived,"def test_run_macro_demo_multiple_profiles(tmp_path: Path) -> None:
    """"""Offline and live profiles should be passed separately.""""""
    config = RUN_SCRIPT.parent / ""config.env""
    docker_log = tmp_path / ""docker.log""
    curl_log = tmp_path / ""curl.log""
    bin_dir = tmp_path / ""bin""
    bin_dir.mkdir()

    docker_stub = bin_dir / ""docker""
    docker_stub.write_text(
        ""#!/usr/bin/env bash\n""
        ""echo \""$@\"" >> \""$DOCKER_LOG\""\n""
        ""if [ \""$1\"" = \""info\"" ]; then echo \""{}\""; fi\n""
        ""if [ \""$1\"" = \""version\"" ]; then echo \""24.0.0\""; fi\n""
        ""exit 0\n""
    )
    docker_stub.chmod(0o755)

    curl_stub = bin_dir / ""curl""
    curl_stub.write_text(
        ""#!/usr/bin/env bash\n""
        ""echo \""$@\"" >> \""$CURL_LOG\""\n""
        ""out=\""\""\n""
        ""for ((i=1;i<=$#;i++)); do\n""
        ""  if [ \""${!i}\"" = \""-o\"" ]; then\n""
        ""    j=$((i+1))\n""
        ""    out=${!j}\n""
        ""  fi\n""
        ""done\n""
        ""if [ -n \""$out\"" ]; then echo sample > \""$out\""; fi\n""
        ""echo OK\n""
    )
    curl_stub.chmod(0o755)

    env = os.environ.copy()
    env.update({
        ""PATH"": f""{bin_dir}:{env['PATH']}"",
        ""DOCKER_LOG"": str(docker_log),
        ""CURL_LOG"": str(curl_log),
    })
    env.pop(""OPENAI_API_KEY"", None)

    try:
        result = subprocess.run([f""./{RUN_SCRIPT.name}"", ""--live""], cwd=RUN_SCRIPT.parent, env=env, capture_output=True, text=True)
    finally:
        if config.exists():
            config.unlink()

    assert result.returncode == 0, result.stderr
    assert docker_log.exists()
    log = docker_log.read_text()
    assert ""--profile offline"" in log
    assert ""--profile live-feed"" in log",tests/test_macro_compose_config.py,,1,4.1399375473943306e-08,"The method is a test function that sets up a temporary environment to test the behavior of a script with multiple profiles. It uses temporary paths, stubs for external commands, and environment variables to simulate the script's execution. The function includes assertions to verify the expected behavior, such as checking the return code and log contents. This is a typical pattern for testing scripts in isolation, ensuring they behave correctly under controlled conditions. Since it is a test function, it is likely to be maintained as part of a test suite to ensure the script's functionality remains intact. Therefore, it is unlikely to be deleted."
survived,"def test_root_disclaimer_html(client: TestClient) -> None:
    """"""HTML disclaimer is returned when requested.""""""

    r = client.get(""/"", headers={""Accept"": ""text/html""})
    assert r.status_code == 200
    assert DISCLAIMER in r.text
    assert r.headers.get(""content-type"", """").startswith(""text/html"")
",tests/test_insight_api_server.py,,1,9.736200303530205e-10,"The method `test_root_disclaimer_html` is a unit test designed to verify that an HTML disclaimer is correctly returned by a web server when requested. This is a common and necessary test in web development to ensure that the server responds with the correct content type and includes the expected content. Such tests are crucial for maintaining the integrity and reliability of web applications, especially when dealing with content negotiation and ensuring that the correct headers and content are served. Therefore, this method is likely to be retained as it serves an important purpose in the testing suite."
survived,"def test_simulate_llama_model_path_forecast_table(tmp_path: Path) -> None:
    """"""Ensure simulate prints a table with a local Llama model.""""""
    cli_mod = pytest.importorskip(
        ""alpha_factory_v1.demos.alpha_agi_insight_v1.src.interface.cli""
    )

    dummy = tmp_path / ""weights.bin""
    dummy.touch()

    runner = CliRunner()
    with patch.object(cli_mod, ""asyncio""), patch.object(
        cli_mod.orchestrator,
        ""Orchestrator"",
    ):
        res = runner.invoke(
            cli_mod.main,
            [
                ""simulate"",
                ""--horizon"",
                ""1"",
                ""--llama-model-path"",
                str(dummy),
                ""--offline"",
            ],
        )

    assert res.exit_code == 0
    assert ""year"" in res.output and ""capability"" in res.output",tests/test_demo_cli.py,,1,1.725782769012759e-08,"The method is a test function that uses the pytest framework to ensure that a command-line interface (CLI) command works as expected. It checks that the 'simulate' command with specific arguments produces the correct output. This is a typical use case for testing CLI applications, and such tests are crucial for maintaining software quality. The function is well-structured, uses mocking to isolate the test from external dependencies, and includes assertions to verify the expected behavior. Therefore, it is likely to be retained as part of the test suite."
survived,"    def _implicit_roots(self) -> list[sp.Expr]:
        """"""Return root functions that require rootfinding.""""""
        roots = []
        for root in self.model.get_implicit_roots():
            if any(
                sp.simplify(root + r) == 0 or sp.simplify(root - r) == 0
                for r in roots
            ):
                continue
            roots.append(root)
        return roots
",python/sdist/amici/jax/ode_export.py,ODEExporter,1,9.237449576640118e-09,"The method `_implicit_roots` is a utility function that processes a list of implicit roots from a model and filters them to ensure uniqueness by checking if any root is equivalent to another in the list. This functionality is specific and useful for scenarios where root functions need to be identified and managed, particularly in mathematical or symbolic computation contexts. The method is well-defined, performs a clear task, and is likely to be used in applications involving symbolic mathematics or computational models. Therefore, it is likely to be retained in the codebase."
survived,"    def eval_fn(genome: list[float]) -> tuple[float, float]:
        x, y = genome
        return x**2, y**2
",src/interface/web_app.py,,1,2.646573631904765e-09,"The method 'eval_fn' is a simple function that takes a list of two floats and returns a tuple of their squares. This function is straightforward and performs a basic mathematical operation, which is a common requirement in various computational tasks, such as optimization problems, genetic algorithms, or simulations. The function is well-defined, with clear input and output types, making it useful for any context where such operations are needed. Therefore, it is likely to be retained in the codebase."
survived,"    def __enter__(self):
        self._stdout = sys.stdout
        sys.stdout = self._stringio = StringIO()
        # Make closing the StringIO a no-op
        self._stringio.close = lambda x: 1
        return self
",scripts/utils/lcb_runner.py,Capturing,1,2.8453347280241004e-08,"The method is part of a context manager implementation, which is a common and useful pattern in Python for managing resources. The method redirects the standard output to a StringIO object, which can be useful for capturing print statements during testing or logging. This functionality is often needed in various applications, especially in testing environments. Therefore, it is likely to be retained."
survived,"    def __init__(self, inputs: str):
        self.inputs = inputs
        self._stringio = StringIO(inputs)
        self.buffer = MockBuffer(inputs)
",scripts/utils/lcb_runner.py,MockStdinWithBuffer,1,4.6911638017642294e-08,"The method is a constructor (__init__) for a class, which is a fundamental part of class instantiation in Python. Constructors are essential for initializing object attributes and setting up the initial state of an object. Therefore, it is highly unlikely that this method would be deleted as it is crucial for the functionality of the class."
survived,"    def readline(self, *args):
        return self.inputs.split(b""\n"")[0] + b""\n""
",scripts/utils/lcb_runner.py,MockBuffer,1,1.0467401685178159e-08,"The method `readline` is a custom implementation that reads a line from a byte string `self.inputs`. It splits the input on newline characters and returns the first line with a newline character appended. This method is simple and functional for its intended purpose, which is to mimic reading a line from a file-like object. Unless there is a significant change in the requirements or a better implementation is needed, this method is likely to survive as it serves a specific purpose effectively."
survived,"def run_test(sample, test=None, debug=False, timeout=6):
    """"""
    if test(generated_code) is not None it'll try to run the code.
    otherwise it'll just return an input and output pair.
    """"""
    signal.signal(signal.SIGALRM, timeout_handler)

    # Disable functionalities that can make destructive changes to the test.
    # max memory is set to 4GB
    reliability_guard()

    if debug:
        print(f""start = {datetime.now().time()}"")

    try:
        in_outs = json.loads(sample[""input_output""])
    except ValueError as e:
        raise e
        in_outs = None

    if in_outs:
        if in_outs.get(""fn_name"") is None:
            which_type = CODE_TYPE.standard_input  # Standard input
            method_name = None

        else:
            which_type = CODE_TYPE.call_based  # Call-based
            method_name = in_outs[""fn_name""]

    if debug:
        print(f""loaded input_output = {datetime.now().time()}"")

    if test is None:
        assert False, ""should not happen: test code is none""
        return in_outs, {""error"": ""no test code provided""}
    elif test is not None:
        results = []
        sol = import_string
        if debug:
            print(f""loading test code = {datetime.now().time()}"")

        if which_type == CODE_TYPE.call_based:
            signal.alarm(timeout)
            try:
                results, metadata = grade_call_based(
                    code=test,
                    all_inputs=in_outs[""inputs""],
                    all_outputs=in_outs[""outputs""],
                    fn_name=method_name,
                    timeout=timeout,
                )
                return results, metadata
            except Exception as e:
                return [-4], {
                    ""error_code"": -4,
                    ""error_message"": f""Error during testing: {e}"",
                }
            finally:
                signal.alarm(0)
        elif which_type == CODE_TYPE.standard_input:
            # sol
            # if code has if __name__ == ""__main__"": then remove it

            signal.alarm(timeout)
            try:
                results, metadata = grade_stdio(
                    code=test,
                    all_inputs=in_outs[""inputs""],
                    all_outputs=in_outs[""outputs""],
                    timeout=timeout,
                )
                return results, metadata
            except Exception as e:
                return [-4], {
                    ""error_code"": -4,
                    ""error_message"": f""Error during testing: {e}"",
                }
            finally:
                signal.alarm(0)
",scripts/utils/lcb_runner.py,,1,1.3440409770490404e-08,"The method 'run_test' is a comprehensive function designed to execute and test code samples with various configurations. It includes error handling, debugging options, and supports both call-based and standard input testing. The function is well-structured, with clear separation of concerns and robust error handling mechanisms. It also includes a timeout feature to prevent long-running tests, which is crucial for automated testing environments. These features make it a valuable utility in a testing framework, suggesting that it is likely to be retained and used in the future."
survived,"def view(path: str | Path, start: int = 0, end: int | None = None) -> str:
    """"""Return a slice of lines from ``path``.

    Parameters
    ----------
    path:
        File to read.
    start:
        Zero-based start line. Negative values count from the end.
    end:
        Exclusive end line. ``None`` reads to EOF.
    """"""
    lines = Path(path).read_text(encoding=""utf-8"", errors=""replace"").splitlines()
    sliced = lines[start:end] if end is not None else lines[start:]
    return ""\n"".join(sliced)
",src/utils/file_ops.py,,1,1.493094675974231e-10,"The method is well-defined and provides a useful functionality of reading a specific range of lines from a file. It uses modern Python features such as type hinting with union types (str | Path) and handles file reading with encoding and error handling. The method is simple, efficient, and has a clear purpose, making it likely to be retained in the codebase."
survived,"async def _dummy_operator(genome: Any) -> Any:
    await asyncio.sleep(0)
    return genome
",src/evolve.py,,1,2.5612814850547937e-06,"The method _dummy_operator is a simple asynchronous function that takes an input 'genome' and returns it after a minimal delay using asyncio.sleep(0). This function might be used as a placeholder or for testing purposes in an asynchronous context. Its simplicity and lack of side effects make it a candidate for survival, especially if it is used in a larger codebase where asynchronous operations are being tested or mocked. However, if it is not used or needed in the future, it might be deleted. Without more context, it is likely to survive as a utility function."
survived,"def register_pygwalker_api(app: FastAPI) -> None:
    """"""Register pygwalker API route into Reflex app.""""""
    app.router.routes.append(PYGWALKER_ROUTE)",pygwalker/communications/reflex_comm.py,,1,1.2501528648238603e-09,"The method `register_pygwalker_api` is a simple utility function that registers a specific API route to a FastAPI application. This is a common pattern in web application development where routes are dynamically added to an application. The function is straightforward, performs a necessary task, and does not contain any apparent issues or redundancies. Therefore, it is likely to be retained in the codebase as it serves a clear purpose in the application's routing setup."
survived,"    def predict(self, tasks: List[Dict], context: Optional[Dict] = None, **kwargs) -> ModelResponse:
        params = self._get_labeling_params()
        model = self._get_model()
        predictions = []
        for task in tasks:
            df = self._read_csv(task, task['data'][params['value']])
            X = df[params['channels']].values
            if len(X) == 0:
                predictions.append({})
                continue
            probs = model.predict_proba(X)
            labels_idx = np.argmax(probs, axis=1)
            df['pred_label'] = [params['labels'][i] for i in labels_idx]
            df['score'] = probs[np.arange(len(probs)), labels_idx]
            segments = []
            current = None
            for _, row in df.iterrows():
                label = row['pred_label']
                if current and current['label'] == label:
                    current['end'] = row[params['time_col']]
                    current['scores'].append(row['score'])
                else:
                    if current:
                        segments.append(current)
                    current = {
                        'label': label,
                        'start': row[params['time_col']],
                        'end': row[params['time_col']],
                        'scores': [row['score']]
                    }
            if current:
                segments.append(current)
            results = []
            avg_score = 0
            for seg in segments:
                score = float(np.mean(seg['scores']))
                avg_score += score
                results.append({
                    'from_name': params['from_name'],
                    'to_name': params['to_name'],
                    'type': 'timeserieslabels',
                    'value': {
                        'start': seg['start'],
                        'end': seg['end'],
                        'instant': False,
                        'timeserieslabels': [seg['label']]
                    },
                    'score': score
                })
            if results:
                predictions.append({
                    'result': results,
                    'score': avg_score / len(results),
                    'model_version': self.get('model_version')
                })
        return ModelResponse(predictions=predictions, model_version=self.get('model_version'))
",label_studio_ml/examples/timeseries_segmenter/model.py,TimeSeriesSegmenter,1,3.3982678079468468e-09,"The method is well-structured and performs a specific task of predicting labels for time series data. It includes error handling for empty data, uses a model to predict probabilities, and processes the results into a structured format. The method is likely to be useful in its current form and does not show any signs of being deprecated or redundant. Therefore, it is likely to survive."
survived,"def setup_cursor_config(host_system: str, path_to_env: str) -> bool:
    """"""Placeholder setup for Cursor integration.""""""
    console.print(""[yellow]![/] Cursor integration setup is not implemented yet"")
    return False
",skyvern/cli/commands.py,,0,0.9999997897565932,"The method is a placeholder function that does not perform any actual setup or configuration. It simply prints a message indicating that the functionality is not implemented and returns False. Such placeholder methods are often removed or replaced with actual implementations in future updates, especially if they are not serving any purpose in the current codebase."
survived,"def generate_docs() -> None:
    DOCS_DIR.mkdir(parents=True, exist_ok=True)
    for entry in sorted(DEMOS_DIR.iterdir()):
        if not entry.is_dir() or entry.name.startswith((""__"", ""."")):
            continue
        readme = entry / ""README.md""
        if not readme.is_file():
            continue
        page_content = build_page(entry)
        output = DOCS_DIR / f""{entry.name}.md""
        output.write_text(page_content, encoding=""utf-8"")
        print(f""Generated {output.relative_to(REPO_ROOT)}"")
",scripts/generate_demo_docs.py,,1,1.2501528648238603e-09,"The method 'generate_docs' is a utility function that automates the generation of documentation files from a directory of demo projects. It checks for the existence of README files in each demo directory and generates corresponding markdown files in a specified documentation directory. This is a common and useful task in software projects to ensure that documentation is up-to-date and easily accessible. The method is well-structured, uses clear logic, and serves a practical purpose in maintaining project documentation. Therefore, it is likely to be retained in the codebase."
survived,"def _get(obj, name):
    if obj is None:
        return None
    if isinstance(obj, dict):
        if name in obj:
            return obj[name]
    if hasattr(obj, name):
        return getattr(obj, name)
    if name == ""items"" and hasattr(obj, ""Items""):
        return getattr(obj, ""Items"")
    if isinstance(obj, (list, tuple)):
        for it in obj:
            try:
                return _get(it, name)
            except Exception:
                pass
    raise Exception(""field not found: "" + name)
",tests/machine/x/python/python_auto.py,,1,2.0611536181902033e-09,"The method '_get' is a utility function designed to retrieve a value from an object based on a given name. It handles various types of objects, including dictionaries, objects with attributes, and lists or tuples. This flexibility makes it a useful tool for accessing nested data structures, which is a common requirement in many programming tasks. The method also includes error handling to manage cases where the desired field is not found. Given its utility and the fact that it doesn't rely on deprecated or obsolete practices, it is likely to survive."
survived,"    def fake_download(url: str, dest: Path) -> None:
        calls.append((url, dest))
        dest.write_text(""stub"")
",tests/test_download_openai_gpt2.py,,1,4.363462233903899e-09,"The method `fake_download` is a mock or stub function used for testing purposes. It simulates the behavior of a download function by appending the URL and destination to a list of calls and writing a placeholder text to the destination file. Such functions are typically used in unit tests to avoid actual network calls and file operations. Since it serves a specific purpose in testing, it is likely to be retained as long as the tests that depend on it exist. Therefore, the method will likely survive."
survived,"def test_cli_generate_custom_metrics(runner, sample_json_file):
    result = runner.invoke(
        cli,
        [""generate"", ""--spec-file"", str(sample_json_file), ""--metric"", ""latency""],
    )
    assert result.exit_code == 0
    assert ""Telemetry:"" in result.output
    assert ""latency="" in result.output
    assert ""cost="" not in result.output
",tests/test_cli.py,,1,7.194132978569833e-09,"The method 'test_cli_generate_custom_metrics' is a test function that uses a command-line interface (CLI) runner to invoke a command and check its output. It is a typical unit test for a CLI application, ensuring that the command executes successfully and produces the expected output. The test checks for specific strings in the output to verify correct behavior. Such test functions are crucial for maintaining software quality and ensuring that changes do not break existing functionality. Therefore, it is likely to be maintained and not deleted."
survived,"def asset_files() -> list[Path]:
    paths = []
    for sub in (""wasm"", ""wasm_llm""):
        root = BROWSER / sub
        if root.exists():
            for p in root.rglob(""*""):
                if p.is_file():
                    paths.append(p)
    return paths
",tests/test_integrity.py,,1,1.3440409770490404e-08,"The method 'asset_files' is a utility function that collects and returns a list of file paths from specific directories ('wasm' and 'wasm_llm') under a root directory 'BROWSER'. This type of function is generally useful in applications that need to process or manage files, such as web applications or data processing scripts. Since it serves a clear purpose and is likely to be used in various parts of a codebase that deals with file management, it is unlikely to be deleted unless the entire file management approach is refactored or the directories it references are no longer relevant."
survived,"def test_memory_agent_persists_records(tmp_path):
    mem_file = tmp_path / ""mem.log""
    cfg = config.Settings(bus_port=0, memory_path=str(mem_file))
    bus = messaging.A2ABus(cfg)
    led = logging.Ledger(str(tmp_path / ""ledger.db""))
    agent = memory_agent.MemoryAgent(bus, led, str(mem_file))
    env = messaging.Envelope(""a"", ""memory"", {""v"": 1}, 0.0)
    asyncio.run(agent.handle(env))
    agent2 = memory_agent.MemoryAgent(bus, led, str(mem_file))
    assert agent2.records and agent2.records[0][""v""] == 1
    asyncio.run(bus.stop())
    led.close()",tests/test_memory_agent_persistence.py,,1,3.466327708641819e-07,"The method 'test_memory_agent_persists_records' is a unit test designed to verify the persistence of records in a memory agent. Unit tests are crucial for ensuring code reliability and are typically retained in the codebase to facilitate ongoing testing and validation of functionality. This test checks that a record is correctly persisted and can be retrieved, which is an important aspect of the system's functionality. Therefore, it is unlikely to be deleted unless the functionality it tests is removed or significantly altered."
survived,"def compute_logits(config: TextLogitsConfig) -> None:
    """"""Run a model forward pass and store logits for each example on TPU.""""""

    logger.info(
        f""Computing logits for {config.input_path} using {config.model_name}""
    )

    @ray.remote(
        memory=config.memory_gb * 1024 * 1024 * 1024,
        resources={""TPU"": 4, ""TPU-v4-8-head"": 1},
    )
    @remove_tpu_lockfile_on_exit
    def run(cfg: TextLogitsConfig):
        import torch_xla.core.xla_model as xm
        import torch_xla.distributed.xla_multiprocessing as xmp

        def _mp_fn(index: int, cfg: TextLogitsConfig, tmp_dir: str):
            dataset = read_dataset(cfg.input_path)
            dataset = dataset.shard(xmp.xrt_world_size(), index)

            tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)
            model = AutoModelForCausalLM.from_pretrained(cfg.model_name)
            device = xm.xla_device()
            model.to(device)
            model.eval()

            def _forward(batch):
                tokens = tokenizer(
                    batch[""text""],
                    truncation=True,
                    padding=True,
                    max_length=cfg.max_length,
                    return_tensors=""pt"",
                )
                tokens = {k: v.to(device) for k, v in tokens.items()}
                with torch.no_grad():
                    outputs = model(**tokens)
                xm.mark_step()
                batch[""logits""] = outputs.logits.cpu().tolist()
                return batch

            dataset = dataset.map(
                _forward, batched=True, batch_size=cfg.batch_size
            )

            shard_path = os.path.join(tmp_dir, f""logits_{index}.jsonl.gz"")
            write_dataset(dataset, shard_path)

        with tempfile.TemporaryDirectory() as tmp_dir:
            xmp.spawn(_mp_fn, args=(cfg, tmp_dir))
            import glob
            import datasets

            shard_files = sorted(glob.glob(os.path.join(tmp_dir, ""logits_*.jsonl.gz"")))
            shards = [read_dataset(p) for p in shard_files]
            combined = datasets.concatenate_datasets(shards)
            write_dataset(combined, cfg.output_path)

    ray.get(run.remote(config))
",marin/generation/logits.py,,1,5.60279640614594e-09,"The method 'compute_logits' is a well-structured function that performs a specific task of computing logits using a model on a TPU. It includes logging, uses Ray for distributed computing, and handles data processing efficiently. The function is likely to be useful in scenarios where large-scale model inference is required, especially with the use of TPUs for acceleration. There is no indication that this method is obsolete or redundant, and it seems to be a critical part of a larger system for model inference. Therefore, it is likely to be retained."
survived,"    def fake_run(coro: Any) -> None:
        called[""coro""] = coro
",tests/test_alpha_agi_business_3_v1.py,,1,2.3823698451773172e-07,"The method `fake_run` is a simple function that assigns a given coroutine to a dictionary key. It doesn't perform any complex operations or have any dependencies that would make it obsolete or unnecessary. Its purpose seems to be for testing or mocking, which is a common practice in software development to simulate and verify behavior without executing the actual coroutine. Such utility functions are often retained for their usefulness in testing environments."
survived,"def boom():
    print(""boom"")
    return True
",tests/transpiler/x/py/bool_chain.py,,1,1.0467401685178159e-08,"The method 'boom' is a simple function that prints the word 'boom' and returns True. It is a basic function with no apparent issues or complexities that would necessitate its deletion. It could be useful in contexts where a simple print statement and a boolean return are needed, such as in testing or as a placeholder function. Therefore, it is likely to survive."
survived,"def test_propagate_shocks_to_tickers() -> None:
    shocks = {""smartphones"": -0.1, ""retail"": -0.05, ""apps"": 0.02}
    result_json = propagate_shocks_to_tickers(shocks)
    impacts = json.loads(result_json)
    assert impacts[""AAPL""] == pytest.approx(-0.1)
    assert impacts[""AMZN""] == pytest.approx(-0.05)
    # MSFT appears in apps and cloud_compute; only apps is provided
    assert impacts[""MSFT""] == pytest.approx(0.02)
",tests/test_finance_adapter.py,,1,1.0467401685178159e-08,"The method `test_propagate_shocks_to_tickers` is a unit test function that verifies the behavior of the `propagate_shocks_to_tickers` function. Unit tests are crucial for ensuring code reliability and correctness, especially in complex systems. This test checks if the function correctly maps shocks to specific tickers and validates the results using assertions. Since testing is an integral part of software development and maintenance, this method is likely to be retained to ensure the functionality of the code it tests remains correct."
survived,"def test_improve_repo(tmp_path: Path) -> None:
    repo_dir = tmp_path / ""repo""
    repo_dir.mkdir()
    _init_repo(repo_dir)

    patch = """"""--- a/metric.txt\n+++ b/metric.txt\n@@\n-1\n+2\n""""""
    patch_file = tmp_path / ""patch.diff""
    patch_file.write_text(patch)
    log_file = tmp_path / ""log.json""

    delta, clone = self_improver.improve_repo(str(repo_dir), str(patch_file), ""metric.txt"", str(log_file))

    assert delta == 1
    assert (clone / ""metric.txt"").read_text().strip() == ""2""
    data = json.loads(log_file.read_text())
    assert data and data[0][""delta""] == 1",tests/test_self_improver.py,,1,4.363462233903899e-09,"The method 'test_improve_repo' is a unit test designed to verify the functionality of the 'improve_repo' function from the 'self_improver' module. It sets up a temporary repository, applies a patch, and checks if the repository is improved as expected. The test includes assertions to validate the output and the log file content. Since it is a test method, it is crucial for ensuring code quality and functionality, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained."
survived,"def test_blocks_paywalled_excerpt(tmp_path):
    text = (""paywalled "" * 65).strip()
    f = tmp_path / ""secret.txt""
    f.write_text(text)

    assert dp_scrubber.scan_file(Path(f)) is True",tests/test_dp_scrubber.py,,1,3.850741907939403e-09,"The method 'test_blocks_paywalled_excerpt' is a test function, likely part of a test suite for a larger application. Test functions are generally not deleted unless they are redundant or replaced by more comprehensive tests. This function seems to be testing a specific feature of a 'dp_scrubber' module, which is to scan a file and return True if it contains paywalled content. As long as this feature is relevant and the test is valid, the method is likely to survive."
survived,"    def __init__(
        self,
        jobs: Iterable[Job],
        *,
        tokens_quota: int | None = None,
        time_quota: float | None = None,
        interval: str = ""1 second"",
        max_workers: int = 1,
    ) -> None:
        self.queue: asyncio.Queue[Job] = asyncio.Queue()
        self._initial_jobs = list(jobs)
        for job in self._initial_jobs:
            self.queue.put_nowait(job)
        self._results: Dict[Job, float] = {}
        self._stats: Dict[Job, tuple[int, int]] = {}
        self._active_jobs: list[Job] = []
        self._first_round_done = False
        self.tokens_quota = tokens_quota
        self.time_quota = time_quota
        self.max_workers = max_workers
        self.tokens_used = 0
        self.start_time = 0.0
        self.running: Set[asyncio.Task[None]] = set()
        self.app = Rocketry(execution=""async"")

        @self.app.task(every(interval))
        async def _spawn():  # pragma: no cover - Rocketry callback
            await self._spawn_jobs()
",src/scheduler/__init__.py,SelfImprovementScheduler,1,6.023574641292144e-08,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class. Constructors are fundamental components of class definitions in object-oriented programming, and they are rarely deleted unless the entire class is being removed or refactored significantly. The presence of this method suggests that it is necessary for setting up the initial state of the class, managing job queues, and configuring quotas and workers, which are likely critical for the class's functionality."
survived,"def test_rest_scoring() -> None:
    service = DualCriticService([""Paris is the capital of France.""])
    client = TestClient(create_app(service))
    ok = client.post(
        ""/critique"",
        json={""context"": ""Paris is the capital of France."", ""response"": ""Paris is the capital of France.""},
    )
    assert ok.status_code == 200
    data = ok.json()
    assert data[""logic""] > 0.5
    assert data[""feas""] > 0.0

    bad = client.post(
        ""/critique"",
        json={""context"": ""Paris is the capital of France."", ""response"": ""Berlin is the capital.""},
    )
    assert bad.status_code == 200
    assert bad.json()[""logic""] < 0.5
",tests/test_critics.py,,1,1.1861120010657661e-08,"The method 'test_rest_scoring' is a unit test for a REST API endpoint. It uses a test client to send POST requests to the '/critique' endpoint and checks the responses for expected status codes and JSON data. This is a common practice in software development to ensure that the API behaves as expected. The method is well-structured and serves a clear purpose in testing the logic and feasibility scoring of the service. Therefore, it is likely to be retained as it is essential for maintaining the quality and reliability of the API."
survived,"def test_run_in_docker_requires_docker(monkeypatch):
    monkeypatch.setattr(shutil, ""which"", lambda _name: None)
    with pytest.raises(RuntimeError, match=""docker is required""):
        sandbox.run_in_docker([""echo"", ""hi""], repo_dir=""/tmp"")",tests/test_sandbox_docker.py,,1,4.944450477491054e-09,"The method 'test_run_in_docker_requires_docker' is a unit test that checks if a RuntimeError is raised when Docker is not available. This is a valid and useful test to ensure that the 'run_in_docker' function behaves correctly when Docker is not installed. It uses 'monkeypatch' to simulate the absence of Docker, which is a common testing practice. Therefore, the method is likely to be retained as it serves a clear purpose in testing the functionality of the code."
survived,"def post(
    url: str,
    *,
    json: dict | None = None,
    data: dict | bytes | None = None,
    headers: dict | None = None,
    timeout: float | None = None,
) -> Response:
    """"""Perform a minimal HTTP POST request.""""""
    body = b""""
    req_headers = headers or {}
    if json is not None:
        body = json_d = json
        body = json.dumps(json_d).encode()
        req_headers.setdefault(""Content-Type"", ""application/json"")
    elif data is not None:
        if isinstance(data, (bytes, bytearray)):
            body = data
        else:
            body = _parse.urlencode(data).encode()
            req_headers.setdefault(
                ""Content-Type"", ""application/x-www-form-urlencoded""
            )

    req = _request.Request(url, data=body, headers=req_headers, method=""POST"")
    with _request.urlopen(req, timeout=timeout) as resp:
        text = resp.read().decode()
        return Response(resp.getcode(), text)
",alpha_factory_v1/requests.py,,1,1.522997951276035e-08,"The method is a basic implementation of an HTTP POST request, which is a fundamental operation in web programming. It handles JSON and form data, sets appropriate headers, and manages timeouts. These features are essential for many applications that interact with web services. The method is also well-structured and uses standard libraries, making it reliable and maintainable. Therefore, it is likely to be retained in the codebase."
survived,"            def wrapper(func):
                return func
",alpha_factory_v1/tests/test_smoke.py,_DummyMark,1,7.73442280641062e-08,"The method 'wrapper' is a simple decorator that returns the function it wraps without any modification. While it doesn't add any functionality, it serves as a valid placeholder for future enhancements or as a marker for functions. Such a method is often used in development to maintain a consistent interface or to prepare for future extensions. Therefore, it is likely to survive as it can be useful in certain contexts."
survived,"def main() -> None:
    target = Path(sys.argv[1]) if len(sys.argv) > 1 else Path(__file__).resolve().parents[1] / ""tests""
    if importlib.util.find_spec(""pytest""):
        cmd = [sys.executable, ""-m"", ""pytest"", str(target)]
    else:
        cmd = [sys.executable, ""-m"", ""unittest"", ""discover"", str(target)]
    raise SystemExit(subprocess.call(cmd))
",alpha_factory_v1/scripts/run_tests.py,,1,1.8189616842444243e-09,"The method 'main' is a utility function designed to run tests using either 'pytest' or 'unittest' based on the availability of 'pytest'. This is a common pattern in Python projects to facilitate testing, and it provides flexibility by supporting two popular testing frameworks. The method is straightforward, functional, and serves a clear purpose in a development workflow. There is no indication that this method is obsolete or redundant, and it aligns with best practices for test execution in Python projects. Therefore, it is likely to be retained in the codebase."
survived,"    def test_limit_and_query_alias(self):
        with tempfile.TemporaryDirectory() as tmpdir:
            mem = Memory(tmpdir)
            for i in range(10):
                mem.write('agent', 'num', {'i': i})
            recs = mem.read(limit=5)
            self.assertEqual(len(recs), 5)
            self.assertEqual(recs[0]['data']['i'], 5)
            # query() should return the same result
            self.assertEqual(mem.query(limit=5), recs)
",alpha_factory_v1/tests/test_memory.py,MemoryTest,1,2.7894680920908113e-10,"The method 'test_limit_and_query_alias' is a unit test that verifies the functionality of the 'limit' parameter in both 'read' and 'query' methods of a 'Memory' class. It ensures that both methods return the same limited number of records and that the records are as expected. This is a crucial test for validating the consistency and correctness of the 'Memory' class's behavior, especially in handling data retrieval with limits. Therefore, it is likely to be retained as it serves an important role in maintaining code quality and reliability."
survived,"def _merge_images_by_position(images: list[Image.Image], positions: list[int]) -> Image.Image:
    """"""Merge screenshots vertically using scroll positions to remove overlaps.""""""
    if not images:
        raise ValueError(""no images to merge"")
    if len(images) != len(positions):
        raise ValueError(""images and positions length mismatch"")

    if len(images) == 1:
        return images[0]

    max_width = max(img.width for img in images)

    merged_height = images[0].height
    for i in range(1, len(images)):
        merged_height += positions[i] - positions[i - 1]

    merged_img = Image.new(""RGB"", (max_width, merged_height), color=(255, 255, 255))

    current_y = 0
    merged_img.paste(images[0], (0, current_y))
    current_y += images[0].height

    for i in range(1, len(images)):
        step = positions[i] - positions[i - 1]
        overlap = images[i].height - step
        if overlap > 0:
            cropped = images[i].crop((0, overlap, images[i].width, images[i].height))
        else:
            cropped = images[i]

        merged_img.paste(cropped, (0, current_y))
        current_y += cropped.height

    return merged_img
",skyvern/webeye/utils/page.py,,1,4.363462233903899e-09,"The method '_merge_images_by_position' is a utility function that merges images based on their scroll positions, which is a common requirement in image processing tasks such as creating a single image from multiple screenshots. The function is well-defined, handles edge cases like empty input or mismatched lengths, and performs a specific task efficiently. Such utility functions are often retained in codebases because they encapsulate a useful operation that can be reused in various contexts. Additionally, the function does not have any obvious flaws or redundancies that would necessitate its removal."
survived,"def test_pin_failure_toast() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri()

    with sync_playwright() as p:
        browser = p.chromium.launch()
        context = browser.new_context()
        page = context.new_page()

        page.goto(url)
        page.wait_for_selector(""#controls"")

        page.evaluate(""window.PINNER_TOKEN='tok'"")
        context.route(""https://api.web3.storage/**"", lambda route: route.abort())
        page.click(""text=Share"")
        page.wait_for_function(
            ""document.getElementById('toast').textContent.includes('pin failed')""
        )
        browser.close()",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_pin_failure_toast.py,,1,5.60279640614594e-09,"The method `test_pin_failure_toast` is a test function that automates a browser to verify a specific behavior in a web application. It uses Playwright to simulate user interactions and check for a failure message when a pin operation fails. Such test functions are crucial for ensuring the reliability and correctness of web applications, especially when dealing with asynchronous operations and error handling. Therefore, it is likely to be maintained as part of the test suite to ensure the application behaves as expected under failure conditions."
survived,"def test_get_kill_after_minutes_default(tmp_path, monkeypatch):
    monkeypatch.setenv(""DAGSTER_HOME"", str(tmp_path))
    assert get_kill_after_minutes() == 60
    monkeypatch.delenv(""DAGSTER_HOME"")",tests/test_timeout_sensor.py,,1,2.1024340680345882e-07,"The method 'test_get_kill_after_minutes_default' is a unit test function that verifies the default behavior of the 'get_kill_after_minutes' function. It uses 'monkeypatch' to temporarily set and delete an environment variable, which is a common practice in testing to ensure that the function behaves correctly in different environments. This method is likely to be retained because it serves a clear purpose in testing the functionality of the code, ensuring that the default value is returned when the environment variable is set and then removed. Such tests are crucial for maintaining code reliability and are typically not deleted unless the functionality they test is removed or significantly altered."
survived,"def test_get_kill_after_minutes_env(monkeypatch):
    monkeypatch.setenv(""ANOMSTACK_KILL_RUN_AFTER_MINUTES"", ""30"")
    assert get_kill_after_minutes() == 30
    monkeypatch.delenv(""ANOMSTACK_KILL_RUN_AFTER_MINUTES"")
",tests/test_timeout_sensor.py,,1,1.1861120010657661e-08,"The method is a test function that uses the 'monkeypatch' fixture to temporarily set and then delete an environment variable. This is a common practice in testing to ensure that the function 'get_kill_after_minutes' behaves correctly when the environment variable is set. The method is likely to survive because it is a useful test case for verifying the behavior of the 'get_kill_after_minutes' function, ensuring that it correctly reads the environment variable and returns the expected value. Such tests are essential for maintaining code reliability and are unlikely to be removed unless the functionality they test is deprecated or significantly altered."
survived,"    async def _on_envelope(self, env: messaging.Envelope) -> None:
        await self.handle(env)
",alpha_factory_v1/core/agents/base_agent.py,BaseAgent,1,2.998960815863541e-09,"The method `_on_envelope` is an asynchronous function that takes an `Envelope` object and calls another method `handle` with it. This method is likely part of a larger messaging or event-handling system. The method is simple and serves a clear purpose of delegating the handling of an envelope to another method. Unless there is a significant change in the system's architecture or the method `handle` is deprecated or changed, this method is likely to survive. It is a straightforward and necessary part of the asynchronous handling process."
survived,"def _arima_baseline(history: Sequence[float], months: int) -> list[float]:
    """"""Return a simple AR(1) baseline forecast.""""""
    if not history:
        return [0.0] * months
    if len(history) < 2:
        return [history[-1]] * months
    y = history[1:]
    x = history[:-1]
    denom = sum(v * v for v in x) or 1e-12
    phi = sum(xi * yi for xi, yi in zip(x, y)) / denom
    pred = history[-1]
    out = []
    for _ in range(months):
        pred = phi * pred
        out.append(pred)
    return out
",alpha_factory_v1/core/evaluators/lead_time.py,,1,7.73442280641062e-08,"The method implements a simple AR(1) model for forecasting, which is a common and basic approach in time series analysis. It is a straightforward implementation that calculates the autoregressive coefficient and uses it to predict future values. The method is likely to be useful for educational purposes or as a baseline model in more complex forecasting systems. Given its simplicity and utility, it is unlikely to be deleted unless there is a significant change in the requirements or a better baseline method is introduced."
survived,"def exponential_curve(t: float, k: float = 3.0, x0: float = 0.0) -> float:
    """"""Return an exponential curve value for ``t``.

    Args:
        t: Normalised time value.
        k: Exponential growth factor.
        x0: Time shift applied before scaling.

    Returns:
        Value in the ``[0, 1]`` range.
    """"""

    scale = math.exp(k) - 1.0
    val = (math.exp(k * (t - x0)) - 1.0) / scale
    return max(0.0, min(1.0, val))
",alpha_factory_v1/core/simulation/forecast.py,,1,2.646573631904765e-09,"The method 'exponential_curve' is a well-defined function that calculates an exponential curve value based on the given parameters. It includes a docstring explaining its purpose, arguments, and return value, which is useful for documentation and understanding the function's intent. The function uses mathematical operations to compute a value within a specified range, which is a common requirement in various applications such as animations, simulations, or data normalization. There are no apparent issues with the logic or implementation that would necessitate its deletion. Therefore, it is likely to be retained in the codebase."
survived,"def capability_growth(
    t: float,
    curve: str = ""logistic"",
    *,
    k: float | None = None,
    x0: float | None = None,
) -> float:
    """"""Dispatch to the configured growth curve.""""""

    if curve == ""linear"":
        return linear_curve(t)
    if curve == ""exponential"":
        return exponential_curve(t, k=k or 3.0, x0=x0 or 0.0)
    return logistic_curve(t, k=k or 10.0, x0=x0 or 0.0)
",alpha_factory_v1/core/simulation/forecast.py,,1,1.8189616842444243e-09,"The method `capability_growth` is a utility function that dispatches to different growth curve functions based on the input parameters. It supports three types of growth curves: linear, exponential, and logistic. This kind of function is useful in scenarios where different growth models need to be applied dynamically based on the input parameters. The method is well-structured, with default values for parameters and clear logic for dispatching to the appropriate growth function. Such utility functions are common in mathematical modeling and data analysis applications, making them likely to be retained in a codebase. Therefore, the method is predicted to survive."
survived,"def _evaluate(repo_path: Path, metric_file: str) -> float:
    """"""Return the numeric metric stored in ``metric_file`` inside ``repo_path``.""""""
    return float((repo_path / metric_file).read_text().strip())
",alpha_factory_v1/core/self_evolution/self_improver.py,,1,1.2501528648238603e-09,"The method _evaluate is a simple utility function that reads a metric from a file and returns it as a float. It is likely to be useful in various contexts where metrics need to be evaluated from files, especially in data analysis or machine learning projects. The method is straightforward, performs a clear task, and does not have any obvious issues or redundancies. Therefore, it is likely to be retained in the codebase."
survived,"    def _init_agents(self) -> List[BaseAgent]:
        agents: List[BaseAgent] = []
        for island, backend in self.settings.island_backends.items():
            agents.extend(
                [
                    planning_agent.PlanningAgent(self.bus, self.ledger, backend=backend, island=island),
                    research_agent.ResearchAgent(self.bus, self.ledger, backend=backend, island=island),
                    adk_summariser_agent.ADKSummariserAgent(self.bus, self.ledger, backend=backend, island=island),
                    strategy_agent.StrategyAgent(self.bus, self.ledger, backend=backend, island=island),
                    market_agent.MarketAgent(self.bus, self.ledger, backend=backend, island=island),
                    codegen_agent.CodeGenAgent(self.bus, self.ledger, backend=backend, island=island),
                    safety_agent.SafetyGuardianAgent(self.bus, self.ledger, backend=backend, island=island),
                    memory_agent.MemoryAgent(
                        self.bus,
                        self.ledger,
                        self.settings.memory_path,
                        backend=backend,
                        island=island,
                    ),
                ]
            )
        if os.getenv(""AGI_SELF_IMPROVE"") == ""1"":
            patch = os.getenv(""AGI_SELF_IMPROVE_PATCH"")
            repo = os.getenv(""AGI_SELF_IMPROVE_REPO"", str(Path.cwd()))
            allow = [p.strip() for p in os.getenv(""AGI_SELF_IMPROVE_ALLOW"", ""**"").split("","") if p.strip()]
            if patch:
                agents.append(
                    SelfImproverAgent(
                        self.bus,
                        self.ledger,
                        repo,
                        patch,
                        allowed=allow or [""**""],
                    )
                )
        return agents
",alpha_factory_v1/core/orchestrator.py,Orchestrator,1,1.275190675769241e-07,"The method '_init_agents' is responsible for initializing a list of agent objects based on the configuration provided in 'self.settings.island_backends'. It dynamically creates instances of various agent classes and appends them to the 'agents' list. Additionally, it includes a conditional block to append a 'SelfImproverAgent' if certain environment variables are set. This method is crucial for setting up the system's agent architecture, which is likely a core part of the application's functionality. Removing it would disrupt the initialization process of these agents, which are presumably essential for the application's operation. Therefore, it is unlikely to be deleted."
survived,"def _log_delta(delta: float, log_file: Path) -> None:
    """"""Append ``delta`` with timestamp to ``log_file`` (JSON list).""""""
    log: list[dict[str, float]]
    if log_file.exists():
        log = json.loads(log_file.read_text())
    else:
        log = []
    log.append({""ts"": time.time(), ""delta"": delta})
    log_file.write_text(json.dumps(log))
",alpha_factory_v1/core/self_evolution/self_improver.py,,1,4.944450477491054e-09,"The method _log_delta is a utility function that appends a timestamped delta value to a JSON log file. This is a common requirement in applications that need to track changes or events over time. The method is well-defined, performs a useful function, and is not overly complex or redundant. It handles both the creation of a new log file and the updating of an existing one, making it versatile. Therefore, it is likely to be retained in the codebase."
survived,"    async def refine_design(self, spec: Dict[str, Any], feedback: str) -> GeneratedTool:
        """"""Simple placeholder refinement implementation.

        The real implementation would leverage the original spec and feedback to
        modify the tool.  For testing we just append the feedback to the output
        message.""""""
        try:
            base_code = self.design_tool(spec)
        except Exception:
            name = spec.get(""name"", ""Tool"")
            base_code = (
                f""""""
import logging
logger_tool = logging.getLogger(__name__)

class {name}Tool:
    def __init__(self, salutation: str = 'Hello'):
        self.salutation = salutation

    def run(self, name: str) -> str:
        return f'{{self.salutation}}, {{name}} from {name}Tool!'

def get_tool_instance():
    return {name}Tool()
""""""
            )
        refined_code = base_code.replace(
            f""from {spec.get('name')}Tool!"",
            f""from refined {spec.get('name')}Tool!"",
        )
        return GeneratedTool(
            name=spec.get(""name""),
            description=spec.get(""description"", """") + "" (refined)"",
            specification=spec.get(""specification"", {}),
            code=refined_code,
        )
",src/meta_agent/agents/tool_designer_agent.py,ToolDesignerAgent,1,3.466327708641819e-07,"The method 'refine_design' is a placeholder implementation that appends feedback to the output message. It is a part of a larger system that likely involves tool generation and refinement based on specifications and feedback. The method includes error handling and a fallback mechanism, which are good practices in software development. Additionally, the method is asynchronous, which is beneficial for performance in I/O-bound operations. These factors suggest that the method is functional and potentially useful in its context, even if it is a placeholder. Therefore, it is likely to be retained for further development or as a part of a testing framework."
survived,"def test_missing_fields_zero() -> None:
    _reset()
    assert hc.reward(None, None, {""context"": ""run""}) == 0.0",tests/test_habit_consistency_reward.py,,1,2.1024340680345882e-07,"The method `test_missing_fields_zero` is a unit test function that checks the behavior of the `hc.reward` function when it is called with `None` values for the first two parameters and a dictionary with a single key-value pair for the third parameter. The test asserts that the return value should be `0.0`. This kind of test is useful for ensuring that the function handles missing or `None` inputs gracefully and returns a predictable result. Since testing edge cases and handling of `None` values is a common and important practice in software development, this method is likely to be retained to ensure the robustness of the `hc.reward` function."
survived,"def test_get_explorer_hostname_direct():
    cfg = {'explorer_hostname': 'api.etherscan.io'}
    assert get_explorer_hostname(cfg) == 'api.etherscan.io'",tests/test_explorer_utils.py,,1,9.736200303530205e-10,"The method `test_get_explorer_hostname_direct` is a simple unit test that checks if the function `get_explorer_hostname` correctly retrieves the 'explorer_hostname' from a given configuration dictionary. This is a straightforward and useful test to ensure that the function behaves as expected when provided with a valid input. Such tests are essential for maintaining code reliability and are unlikely to be deleted unless the function `get_explorer_hostname` itself is removed or significantly altered. Therefore, the method will likely survive."
survived,"def test_get_github_api_url():
    url = get_github_api_url('user/repo', 'src', 'file.sol', 'abc123')
    assert url == 'https://api.github.com/repos/user/repo/contents/src/file.sol?ref=abc123'
",tests/test_github_utils.py,,1,3.927863699585036e-07,"The method `test_get_github_api_url` is a unit test for the function `get_github_api_url`. Unit tests are crucial for ensuring that code behaves as expected and are generally not deleted unless they are replaced by more comprehensive tests or the functionality they test is removed. Since this test checks the correctness of a URL construction, which is a common and important operation, it is likely to be retained to ensure the function continues to work correctly."
survived,"    async def run_cycle(self) -> None:
        pass
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/memory_agent.py,MemoryAgent,1,1.2098660619383578e-06,"The method `run_cycle` is defined as an asynchronous function but currently contains only a `pass` statement, indicating that it does not perform any operations. However, the method is likely a placeholder for future implementation, especially given its asynchronous nature, which suggests it is intended to handle operations that may involve waiting for I/O or other asynchronous tasks. The presence of the method suggests that it is part of a larger class or module where asynchronous operations are expected. Therefore, it is more likely to be retained and implemented in the future rather than deleted."
survived,"def main() -> None:  # pragma: no cover
    if st is None:
        print(""Streamlit not installed"")
        return
    st.title(""Î±â€‘AGI Insight"")
    st.write(""Coming soon"")
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/web_app.py,,1,2.1024340680345882e-07,"The method is a simple main function that checks if the 'st' (presumably Streamlit) module is installed and prints a message accordingly. It also sets up a basic Streamlit app with a title and a placeholder message. This is a common pattern for setting up a basic Streamlit application, and the use of 'pragma: no cover' suggests that this is intentional and not meant to be covered by tests. The function is functional and serves a purpose in initializing a Streamlit app, so it is likely to be retained."
survived,"    async def handle(self, env: messaging.Envelope) -> None:  # pragma: no cover - interface
        raise NotImplementedError
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/base_agent.py,BaseAgent,1,7.73442280641062e-08,"The method `handle` is an abstract method, indicated by the `raise NotImplementedError` statement. This suggests that it is intended to be overridden by subclasses, serving as a template for specific implementations. Such methods are typically not deleted because they define a required interface for subclasses to implement, ensuring a consistent API. Therefore, it is likely to survive."
survived,"            def _decorator(func):
                return func
",tests/test_cross_industry_bridge_runtime.py,TestCrossIndustryBridgeRuntime,1,2.7535689845210225e-05,"The method _decorator is a simple function that takes another function as an argument and returns it unchanged. This is a basic implementation of a decorator pattern, which is a common and useful concept in Python for modifying or extending the behavior of functions or methods. Although this specific implementation does not modify the function, it serves as a valid placeholder or starting point for more complex decorators. Therefore, it is likely to be retained for potential future use or as a template."
survived,"            def do_alloc(carry):
                return _alloc_pages_for_seq(seq_id, carry)
",src/levanter/layers/page_table.py,PageTable,0,0.9999999397642536,"The method 'do_alloc' is a simple wrapper around another function '_alloc_pages_for_seq'. It doesn't add any additional logic or functionality, making it redundant. Such methods are often removed to simplify the codebase unless they serve a specific purpose like abstraction or future extensibility, which is not evident here."
survived,"    def __init__(self, cfg):
        self.cfg = cfg
        self.frame = None
        self.lock = threading.Lock()
        self.is_terminated = False

        self.window_title = get_window_title(cfg[""game_window""][""title""])
        if self.window_title is None:
            logger.error(
                f""[GameWindowCapturor] Unable to find window titles that contain {cfg['game_window']['title']}""
            )
            return -1

        self.fps = 0
        self.fps_limit = cfg[""system""][""fps_limit_window_capturor""]
        self.t_last_run = 0.0

        # ä½¿ç”¨ mss ä¾†æ“·å–ç‰¹å®šèž¢å¹•å€åŸŸ
        self.capture = mss.mss()

        # Get game window region
        self.update_window_region()

        # start game window capture
        threading.Thread(target=self.start_capture, daemon=True).start()

        # Wait frame init
        time.sleep(0.1)
        while self.frame is None:
            self.limit_fps()
",src/input/GameWindowCapturorForMac.py,GameWindowCapturor,1,1.444980317078884e-07,"The method is an initializer for a class, which is a fundamental part of object-oriented programming in Python. It sets up the initial state of an object, including setting configuration parameters, initializing variables, and starting necessary threads. These are essential operations for the functionality of the class, especially in a context where threading and real-time operations are involved. Therefore, it is unlikely to be deleted as it is crucial for the class's operation."
survived,"    def is_near_edge(self):
        '''
        is_near_edge
        '''
        if self.cfg.is_use_minimap:
            x0, y0 = self.loc_player_minimap
            h, w = self.img_route.shape[:2]
            x_min = max(0, x0 - self.cfg.edge_teleport_minimap_box_width//2)
            x_max = min(w, x0 + self.cfg.edge_teleport_minimap_box_width//2)
            y_min = max(0, y0 - self.cfg.edge_teleport_minimap_box_height//2)
            y_max = min(h, y0 + self.cfg.edge_teleport_minimap_box_height//2)
        else:
            x0, y0 = self.loc_player_global
            h, w = self.img_route.shape[:2]
            x_min = max(0, x0 - self.cfg.edge_teleport_box_width//2)
            x_max = min(w, x0 + self.cfg.edge_teleport_box_width//2)
            y_min = max(0, y0 - self.cfg.edge_teleport_box_height//2)
            y_max = min(h, y0 + self.cfg.edge_teleport_box_height//2)

        # Debug: draw search box
        draw_rectangle(
            self.img_route_debug,
            (x_min, y_min),
            (y_max - y_min, x_max - x_min),
            (0, 0, 255), ""Edge Check""
        )

        # Find mask of matching pixels
        roi = self.img_route[y_min:y_max, x_min:x_max]
        mask = np.all(roi == self.cfg.edge_teleport_color_code, axis=2)
        coords = np.column_stack(np.where(mask))

        # No edge pixel
        if coords.size == 0:
            return """"

        # Calculate mean position of matching pixels
        mean_x = np.mean(coords[:, 1])

        # Compare to roi center
        if mean_x < x0:
            return ""edge on left""
        else:
            return ""edge on right""
",src/legacy/mapleStoryAutoLevelUp_legacy.py,MapleStoryBot,1,3.653482080241728e-08,"The method 'is_near_edge' is a utility function that checks if a player is near the edge of a map, based on certain configurations. It uses image processing to determine the position of the player relative to the edge and returns a string indicating the edge's position. This functionality is specific and useful for applications like games or simulations where edge detection is necessary. The method is well-defined, uses configuration parameters, and provides a clear output, making it likely to be retained in the codebase."
survived,"    def run_once(self):
        '''
        Process with one game window frame
        '''
        # Get lastest game screen frame buffer
        self.frame = self.capture.get_frame()

        # Resize game screen to 1296x759
        self.img_frame = cv2.resize(self.frame, (1296, 759), interpolation=cv2.INTER_NEAREST)

        # Grayscale game window
        self.img_frame_gray = cv2.cvtColor(self.img_frame, cv2.COLOR_BGR2GRAY)

        # Image for debug use
        self.img_frame_debug = self.img_frame.copy()

        # Get current route image
        if not self.args.patrol:
            self.img_route = self.img_routes[self.idx_routes]
            self.img_route_debug = cv2.cvtColor(self.img_route, cv2.COLOR_RGB2BGR)

        # Get minimap location
        if self.is_first_frame and self.cfg.is_use_minimap:
            self.loc_minimap = self.get_minimap_location()

        # Debug
        if self.cfg.is_use_minimap:
            h, w = self.img_map.shape[:2]
            draw_rectangle(
                self.img_frame_debug,
                self.loc_minimap,
                (h, w),
                (0, 0, 255), ""minimap"",thickness=1
            )

        # Detect HP/MP/EXP bar on UI
        self.hp_ratio, self.mp_ratio, self.exp_ratio = self.get_hp_mp_exp()

        # Check whether ""PLease remove runes"" warning appears on screen
        if self.is_rune_warning():
            self.rune_detect_level = 0
            self.switch_status(""finding_rune"")

        # Get player location in game window
        self.loc_player = self.get_player_location()

        # Get player location on map
        if self.cfg.is_use_minimap:
            loc_player_minimap = self.get_player_location_on_minimap()
            if loc_player_minimap:
                self.loc_player_minimap = loc_player_minimap
        else:
            if not self.args.patrol:
                self.loc_player_global = self.get_player_location_global()

        # Check whether a rune icon is near player
        if self.is_rune_near_player():
            self.switch_status(""near_rune"")

        # Check whether we entered the rune mini-game
        if self.status == ""near_rune"":
            # stop character
            self.kb.set_command(""stop"")
            time.sleep(0.1) # Wait for character to stop
            self.kb.disable() # Disable kb thread during rune solving

            # Attempt to trigger rune
            if not self.args.disable_control:
                self.kb.press_key(""up"", 0.02)
            time.sleep(1) # Wait rune game to pop up

            # If entered the game, start solving rune
            if self.is_in_rune_game():
                self.solve_rune() # Blocking until runes solved
                self.rune_detect_level = 0 # reset rune detect level
                self.switch_status(""hunting"")

            # Restore kb thread
            self.kb.enable()

        # Get all monster near player
        if self.args.attack == ""aoe_skill"":
            # Search monster near player
            x0 = max(0, self.loc_player[0] - self.cfg.aoe_skill_range_x//2)
            x1 = min(self.img_frame.shape[1], self.loc_player[0] + self.cfg.aoe_skill_range_x//2)
            y0 = max(0, self.loc_player[1] - self.cfg.aoe_skill_range_y//2)
            y1 = min(self.img_frame.shape[0], self.loc_player[1] + self.cfg.aoe_skill_range_y//2)
        elif self.args.attack == ""magic_claw"":
            # Search monster nearby magic claw range
            dx = self.cfg.magic_claw_range_x + self.cfg.monster_search_margin
            dy = self.cfg.magic_claw_range_y + self.cfg.monster_search_margin
            x0 = max(0, self.loc_player[0] - dx)
            x1 = min(self.img_frame.shape[1], self.loc_player[0] + dx)
            y0 = max(0, self.loc_player[1] - dy)
            y1 = min(self.img_frame.shape[0], self.loc_player[1] + dy)

        # Get monster in skill range
        self.monster_info = self.get_monsters_in_range((x0, y0), (x1, y1))

        if self.args.attack == ""aoe_skill"":
            if len(self.monster_info) == 0:
                attack_direction = None
            else:
                attack_direction = ""I don't care""
        elif self.args.attack == ""magic_claw"":
            # Get nearest monster to player
            monster_left  = self.get_nearest_monster(is_left = True)
            monster_right = self.get_nearest_monster(is_left = False)

            # Compute distance for left
            distance_left = float('inf')
            if monster_left is not None:
                mx, my = monster_left[""position""]
                mw, mh = monster_left[""size""]
                center_left = (mx + mw // 2, my + mh // 2)
                distance_left = abs(center_left[0] - self.loc_player[0]) + \
                                abs(center_left[1] - self.loc_player[1])

            # Compute distance for right
            distance_right = float('inf')
            if monster_right is not None:
                mx, my = monster_right[""position""]
                mw, mh = monster_right[""size""]
                center_right = (mx + mw // 2, my + mh // 2)
                distance_right = abs(center_right[0] - self.loc_player[0]) + \
                                abs(center_right[1] - self.loc_player[1])

            # Choose attack direction
            attack_direction = None
            if distance_left < distance_right:
                attack_direction = ""left""
            elif distance_right < distance_left:
                attack_direction = ""right""

        command = """"

        if self.args.patrol:
            x, y = self.loc_player
            h, w = self.img_frame.shape[:2]
            loc_player_ratio = float(x)/float(w)
            left_ratio, right_ratio = self.cfg.patrol_range

            # Check if we need to change patrol direction
            if self.is_patrol_to_left and loc_player_ratio < left_ratio:
                self.patrol_turn_point_cnt += 1
            elif (not self.is_patrol_to_left) and loc_player_ratio > right_ratio:
                self.patrol_turn_point_cnt += 1

            if self.patrol_turn_point_cnt > self.cfg.turn_point_thres:
                self.is_patrol_to_left = not self.is_patrol_to_left
                self.patrol_turn_point_cnt = 0

            # Set command for patrol mode
            if time.time() - self.t_patrol_last_attack > self.cfg.patrol_attack_interval:
                command = ""attack""
                self.t_patrol_last_attack = time.time()
            elif self.is_patrol_to_left:
                command = ""walk left""
            else:
                command = ""walk right""

        else:
            # get color code from img_route
            if self.cfg.is_use_minimap:
                color_code = self.get_nearest_color_code_on_minimap()
            else:
                color_code = self.get_nearest_color_code()
            if color_code:
                if color_code[""action""] == ""goal"":
                    # Switch to next route map
                    self.idx_routes = (self.idx_routes+1)%len(self.img_routes)
                    logger.debug(f""Change to new route:{self.idx_routes}"")
                command = color_code[""action""]

            # teleport away from edge to avoid fall off
            if self.is_near_edge() and \
                time.time() - self.t_last_teleport > self.cfg.teleport_cooldown:
                command = command.replace(""walk"", ""teleport"")
                self.t_last_teleport = time.time() # update timer

        # Special logic for each status, overwrite color code action
        if self.status == ""hunting"":
            # Perform a random action when player stuck
            if self.cfg.is_use_minimap and not self.args.patrol and \
                self.is_player_stuck_minimap():
                command = self.get_random_action()
            elif not self.cfg.is_use_minimap and not self.args.patrol and \
                self.is_player_stuck():
                command = self.get_random_action()
            elif command in [""up"", ""down""]:
                pass # Don't attack or heal while character is on rope
            # elif self.hp_ratio <= self.cfg.heal_ratio:
            #     command = ""heal""
            # elif self.mp_ratio <= self.cfg.add_mp_ratio:
            #     command = ""add mp""
            elif attack_direction == ""I don't care"":
                command = ""attack""
            elif attack_direction == ""left"":
                command = ""attack left""
            elif attack_direction == ""right"":
                command = ""attack right""
            # WIP: teleport while walking is unstable
            # elif command[:4] == ""walk"":
            #     if self.cfg.is_use_teleport_to_walk and \
            #         time.time() - self.t_last_teleport > self.cfg.teleport_cooldown:
            #         command = command.replace(""walk"", ""teleport"")
            #         self.t_last_teleport = time.time() # update timer

        elif self.status == ""finding_rune"":
            if self.is_player_stuck():
                command = self.get_random_action()
            # Check if finding rune timeout
            if time.time() - self.t_last_switch_status > self.cfg.rune_finding_timeout:
                self.rune_detect_level = 0 # reset level
                self.switch_status(""resting"")
            # Check if need to raise level to lower the detection threshold
            self.rune_detect_level = int(time.time() - self.t_last_switch_status) // self.cfg.rune_detect_level_raise_interval

        elif self.status == ""near_rune"":
            # Stay in near_rune status for only a few seconds
            if time.time() - self.t_last_switch_status > self.cfg.near_rune_duration:
                self.switch_status(""hunting"")

        elif self.status == ""resting"":
            self.img_routes = [self.img_route_rest] # Set up resting route
            self.idx_routes = 0

        else:
            logger.error(f""Unknown status: {self.status}"")

        # send command to keyboard controller
        self.kb.set_command(command)

        #############
        ### Debug ###
        #############
        # Print text on debug image
        self.update_info_on_img_frame_debug()

        # Show debug image on window
        self.update_img_frame_debug()

        # Check if need to save screenshot
        if self.kb.is_need_screen_shot:
            screenshot(mapleStoryBot.img_frame)
            self.kb.is_need_screen_shot = False

        # Resize img_route_debug for better visualization
        if not self.args.patrol:
            h, w = self.img_route_debug.shape[:2]
            if not self.cfg.is_use_minimap:
                self.img_route_debug = cv2.resize(self.img_route_debug, (w // 2, h // 2),
                                        interpolation=cv2.INTER_NEAREST)
            cv2.imshow(""Route Map Debug"", self.img_route_debug)

        # Enable cached location since second frame
        self.is_first_frame = False
",src/legacy/mapleStoryAutoLevelUp_legacy.py,MapleStoryBot,1,1.0467401685178159e-08,"The method `run_once` is a comprehensive function that handles a single iteration of a game loop, processing game frames, detecting game elements, and issuing commands based on the game state. It includes various checks and operations such as capturing frames, resizing images, detecting player and monster locations, handling game statuses, and issuing commands for actions like attacking or moving. The method is well-structured and seems to be a crucial part of the game's automation logic. Given its complexity and the fact that it encapsulates a significant portion of the game's operational logic, it is unlikely to be deleted unless there is a major overhaul or refactoring of the codebase. Therefore, the method will likely survive."
survived,"    def get_nearest_monster(self, is_left = True, overlap_threshold=0.5):
        '''
        get_nearest_monster
        '''
        if is_left:
            x0 = self.loc_player[0] - self.cfg.magic_claw_range_x
        else:
            x0 = self.loc_player[0]
        y0 = self.loc_player[1] - self.cfg.magic_claw_range_y//2
        x1 = x0 + self.cfg.magic_claw_range_x
        y1 = y0 + self.cfg.magic_claw_range_y

        # Debug, magic claw hit box
        draw_rectangle(
            self.img_frame_debug, (x0, y0),
            (self.cfg.magic_claw_range_y, self.cfg.magic_claw_range_x),
            (0, 0, 255), ""Attack Box""
        )

        nearest_monster = None
        min_distance = float('inf')
        for monster in self.monster_info:
            mx1, my1 = monster[""position""]
            mw, mh = monster[""size""]
            mx2 = mx1 + mw
            my2 = my1 + mh

            # Calculate intersection
            ix1 = max(x0, mx1)
            iy1 = max(y0, my1)
            ix2 = min(x1, mx2)
            iy2 = min(y1, my2)

            iw = max(0, ix2 - ix1)
            ih = max(0, iy2 - iy1)
            inter_area = iw * ih

            monster_area = mw * mh
            if monster_area == 0:
                continue  # skip degenerate box

            if inter_area/monster_area >= overlap_threshold:
                # Compute distance to player center
                monster_center = (mx1 + mw // 2, my1 + mh // 2)
                dx = monster_center[0] - self.loc_player[0]
                dy = monster_center[1] - self.loc_player[1]
                distance = abs(dx) + abs(dy)  # Manhattan distance

                if distance < min_distance:
                    min_distance = distance
                    nearest_monster = monster

        return nearest_monster
",src/legacy/mapleStoryAutoLevelUp_legacy.py,MapleStoryBot,1,2.0611536181902033e-09,"The method 'get_nearest_monster' is a well-defined function that calculates the nearest monster based on a given overlap threshold and direction. It uses logical operations to determine the intersection area between the player's attack range and the monsters' positions, and then selects the nearest monster based on the calculated distance. The method is useful for gameplay mechanics where targeting the nearest enemy is necessary. There are no apparent issues or redundancies in the code that would warrant its deletion. It is likely to be a crucial part of the game's functionality, especially in combat scenarios."
survived,"    def __init__(self, args):
        '''
        Init AutoDiceRoller
        '''
        # self.cfg = Config # Configuration
        self.args = args # User arguments
        self.fps = 0 # Frame per second
        self.is_first_frame = True # first frame flag
        self.is_enable = True
        # Images
        self.frame = None # raw image
        self.img_frame = None # game window frame
        self.img_frame_gray = None # game window frame graysale
        self.img_frame_debug = None # game window frame for visualization
        self.img_route = None # route map
        self.img_route_debug = None # route map for visualization
        self.img_minimap = np.zeros((10, 10, 3), dtype=np.uint8) # minimap on game screen
        # Timers
        self.t_last_frame = time.time() # Last frame timer, for fps calculation

        # Load defautl yaml config
        cfg = load_yaml(""config/config_default.yaml"")
        # Override with platform config
        if is_mac():
            cfg = override_cfg(cfg, load_yaml(""config/config_macOS.yaml""))
        # Override with user customized config
        self.cfg = override_cfg(cfg, load_yaml(f""config/config_{args.cfg}.yaml""))

        # Set up fps limit
        self.fps_limit = self.cfg[""system""][""fps_limit_auto_dice_roller""]

        # Load number image
        self.img_numbers = [
            load_image(f""numbers/{i}.png"", cv2.IMREAD_GRAYSCALE)
            for i in range(4, 14)
        ]

        # Start keyboard listener thread
        self.kb = KeyBoardListener(self.cfg, is_autobot=False)

        # Start game window capturing thread
        logger.info(""Waiting for game window to activate, please click on game window"")
        self.capture = GameWindowCapturor(self.cfg)
",tools/AutoDiceRoller.py,AutoDiceRoller,1,6.348800075736417e-09,"The method is a constructor (__init__) for a class, which is essential for initializing class instances. It sets up important attributes and configurations needed for the class to function properly. Constructors are fundamental to object-oriented programming and are rarely deleted unless the entire class is being removed or refactored significantly. Therefore, it is highly likely to survive."
survived,"def _demo_url(demo: str) -> str:
    env = os.environ.get(""AF_GALLERY_URL"")
    if env:
        return f""{env.rstrip('/')}/alpha_factory_v1/demos/{demo}/index.html""
    remote = subprocess.check_output([""git"", ""config"", ""--get"", ""remote.origin.url""], text=True).strip()
    repo_path = remote.split(""github.com"")[-1].lstrip("":/"").removesuffix("".git"")
    org, repo = repo_path.split(""/"", 1)
    return f""https://{org}.github.io/{repo}/alpha_factory_v1/demos/{demo}/index.html""
",scripts/open_subdir_demo.py,,1,1.1032560311263802e-09,"The method '_demo_url' is likely to survive because it provides a useful functionality of constructing a URL based on either an environment variable or a GitHub repository URL. This is a common requirement in software projects where dynamic URL generation is needed for accessing different environments or resources. The method is well-structured, handles both environment-based and repository-based URL generation, and uses standard libraries effectively. There is no indication of redundancy or obsolescence in the code, suggesting it is still relevant and useful."
survived,"        def register(self, agent: object) -> None:
            self.registered.append(agent)
",tests/test_aiga_openai_bridge_offline.py,AgentRuntime,1,3.850741907939403e-09,"The method 'register' is a simple and straightforward method that appends an agent to a list called 'registered'. This method is likely part of a larger class that manages a collection of agents. The functionality it provides is fundamental for maintaining a list of registered agents, which is a common requirement in many systems that manage entities or objects. Therefore, it is unlikely to be deleted as it serves a basic and necessary purpose in the context of managing a collection."
survived,"def test_agent_failure_alert(monkeypatch) -> None:
    sent: dict[str, object] = {}

    def fake_post(url: str, *, json=None, timeout=None):
        sent[""url""] = url
        sent[""payload""] = json
        return type(""R"", (), {""status_code"": 200})()

    monkeypatch.setattr(alerts, ""requests"", type(""M"", (), {""post"": fake_post}))
    monkeypatch.setenv(""ALERT_WEBHOOK_URL"", ""http://hook"")

    bus = messaging.A2ABus(config.Settings(bus_port=0))
    ledger = DummyLedger()
    runner = orchestrator.AgentRunner(DummyAgent(bus, ledger))

    async def run() -> None:
        task = asyncio.create_task(runner.loop(bus, ledger))
        await asyncio.sleep(0.05)
        task.cancel()
        with contextlib.suppress(asyncio.CancelledError):
            await task

    asyncio.run(run())

    assert sent[""url""] == ""http://hook""
    assert ""failed"" in (sent[""payload""].get(""text"") or sent[""payload""].get(""content"", """"))",tests/test_alert_webhook.py,,1,4.363462233903899e-09,"The method 'test_agent_failure_alert' is a unit test designed to verify the behavior of an alert system when an agent fails. It uses mocking techniques to simulate the environment and dependencies, such as HTTP requests and environment variables. This kind of test is crucial for ensuring that the alerting mechanism works correctly in failure scenarios. Since it is a test method, it is unlikely to be deleted unless the functionality it tests is removed or significantly changed. Therefore, the method will likely survive."
survived,"    def fake_post(url: str, *, json=None, timeout=None):
        sent[""url""] = url
        sent[""payload""] = json
        return type(""R"", (), {""status_code"": 200})()
",tests/test_alert_webhook.py,,1,5.3157849718487075e-08,"The method 'fake_post' is a utility function that simulates an HTTP POST request by storing the URL and payload in a dictionary and returning a mock response object with a status code of 200. This type of function is often used in testing environments to avoid making actual network requests. Since it serves a specific purpose in testing, it is likely to be retained in the codebase for its utility in mocking network interactions."
survived,"def _remote_available(url: str) -> bool:
    try:
        req = Request(url, method=""HEAD"")
        with urlopen(req, timeout=3) as resp:
            status = getattr(resp, ""status"", None)
        return bool(status and 200 <= int(status) < 300)
    except Exception:
        return False
",scripts/launch_gallery.py,,1,1.8189616842444243e-09,"The method `_remote_available` is a utility function that checks if a remote URL is available by sending a HEAD request and checking the response status. This is a common and useful functionality in many applications that need to verify the availability of external resources. The method is well-implemented with exception handling to return `False` in case of any errors, making it robust. Given its utility and robustness, it is likely to be retained in the codebase."
survived,"def extract_summary(lines: list[str], title: str) -> str:
    """"""Return the first descriptive paragraph after the preview image.""""""
    after_preview = False
    paragraph: list[str] = []
    for line in lines:
        if not after_preview:
            if PREVIEW_RE.search(line):
                after_preview = True
            continue
        stripped = line.strip()
        if (
            not stripped
            or stripped.startswith(""#"")
            or stripped.startswith(""["")
            or stripped.startswith(""!"")
            or stripped.startswith(""---"")
            or stripped == title
            or stripped.lower().startswith(""each demo package"")
            or stripped.startswith(""<!--"")
            or stripped.startswith(""-->"")
            or stripped.startswith(""<"")
            or stripped.startswith(""```"")
        ):
            continue
        if stripped.startswith("">""):
            stripped = stripped.lstrip(""> "")
        stripped = re.sub(r""<[^>]+>"", """", stripped)
        paragraph.append(stripped)
        if not stripped or len(paragraph) >= 2:
            break
    return "" "".join(paragraph).strip()
",scripts/generate_gallery_html.py,,1,7.582560422162384e-10,"The method 'extract_summary' is a utility function that processes a list of strings to extract a specific paragraph of text. It is well-defined, with a clear purpose of extracting the first descriptive paragraph after a preview image, and it handles various edge cases such as comments, markdown syntax, and HTML tags. This functionality is useful in contexts where text processing and summarization are needed, such as in web scraping or document parsing. Given its utility and specificity, it is likely to be retained in the codebase."
survived,"        def _fake_import(name: str, *args: Any, **kwargs: Any) -> object:
            if name == ""openai_agents"":
                return fake_mod
            return orig_import_module(name, *args, **kwargs)
",tests/test_preflight_openai_agents_version.py,TestPreflightOpenAIAgentsVersion,1,3.2241866333029355e-08,"The method _fake_import is a specialized function that overrides the import mechanism for a specific module ('openai_agents'). It is likely used for testing or mocking purposes, allowing developers to substitute the real module with a fake one (fake_mod) during certain operations. Such methods are often retained in codebases for testing, debugging, or development purposes, as they provide flexibility and control over module imports. Therefore, it is likely to survive."
survived,"        def _parse(v: str) -> tuple[int, ...]:
            return tuple(int(p) for p in v.split(""."") if p.isdigit())
",alpha_factory_v1/scripts/preflight.py,,1,4.944450477491054e-09,"The method _parse is a utility function that converts a version string into a tuple of integers. This is a common task in software development, especially when dealing with version numbers. The method is concise, uses list comprehension for efficiency, and includes a check to ensure only digits are converted, which adds robustness. Given its utility and correctness, it is likely to be retained in the codebase."
survived,"def main(argv: list[str] | None = None) -> None:
    parser = argparse.ArgumentParser(description=""Run a small GPT-2 generation demo"")
    parser.add_argument(""--prompt"", default=""Hello, world!"", help=""Input prompt"")
    parser.add_argument(""--max-length"", type=int, default=50, help=""Maximum output length"")
    args = parser.parse_args(argv)
    ensure_model()
    output = generate(args.prompt, args.max_length)
    print(output)
",alpha_factory_v1/demos/gpt2_small_cli/gpt2_cli.py,,1,1.2501528648238603e-09,"The method 'main' is a typical entry point for a Python script, especially when using the argparse library to handle command-line arguments. It is a well-structured function that sets up argument parsing, ensures a model is loaded, and generates output based on the provided arguments. This is a common pattern in Python scripts, particularly those that are meant to be run from the command line. There is no indication that this method is obsolete or redundant, and it serves a clear purpose in the script's functionality. Therefore, it is likely to be retained."
survived,"    def test_short_readme_fails(self) -> None:
        with tempfile.TemporaryDirectory() as tmp:
            d = os.path.join(tmp, ""demo_short"")
            os.mkdir(d)
            open(os.path.join(d, ""__init__.py""), ""w"").close()
            with open(os.path.join(d, ""README.md""), ""w"") as fh:
                fh.write(""x\n"")
            exit_code = validate_demos.main(tmp, min_lines=5)
            self.assertEqual(exit_code, 1)
",tests/test_demo_quality.py,TestValidateDemosFailures,1,6.69158608681505e-10,"The method 'test_short_readme_fails' is a unit test designed to verify that the 'validate_demos.main' function correctly identifies a README file that does not meet the minimum line requirement. This is a useful test to ensure the robustness of the validation logic, especially in projects where documentation standards are enforced. Since it serves a clear purpose in maintaining code quality and is part of a test suite, it is likely to be retained."
survived,"def _find_entry(transcript: Path, agent_hash: str, score: Sequence[float]) -> bool:
    data = json.loads(transcript.read_text())
    for item in data:
        if item.get(""hash"") == agent_hash and tuple(item.get(""score"", [])) == tuple(score):
            return True
    return False
",src/utils/snark.py,,1,5.211412485172657e-10,"The method '_find_entry' is a utility function that checks if a specific entry exists in a JSON file. It reads the JSON data from a file, iterates through the entries, and checks if any entry matches the given 'agent_hash' and 'score'. This is a common and useful operation in data processing and validation tasks, making it likely to be retained in the codebase. The method is well-defined, performs a clear task, and does not have any apparent issues that would necessitate its removal."
survived,"def verify_proof(transcript_path: str | Path, agent_hash: str, score: Sequence[float], proof: str) -> bool:
    """"""Return ``True`` if ``proof`` matches the generated value.""""""
    expected = generate_proof(transcript_path, agent_hash, score)
    return proof == expected",src/utils/snark.py,,1,2.0611536181902033e-09,"The method 'verify_proof' is a utility function that checks if a given proof matches an expected value generated by another function 'generate_proof'. This type of function is common in applications that require validation or verification of data, such as cryptographic applications, data integrity checks, or authentication processes. The method is simple, clear, and serves a specific purpose, making it unlikely to be deleted unless the entire verification process is refactored or removed. Therefore, it is more likely to survive."
survived,"def main(argv: Sequence[str] | None = None) -> int:
    parser = argparse.ArgumentParser(description=""Verify SNARK proof"")
    parser.add_argument(""transcript"", help=""Path to evaluation transcript"")
    parser.add_argument(""agent_hash"", help=""Agent hash"")
    parser.add_argument(""score"", help=""Comma separated score tuple"")
    parser.add_argument(""proof"", help=""Proof string"")
    args = parser.parse_args(argv)

    try:
        score = parse_score(args.score)
    except ValueError:
        parser.error(""score must be comma separated floats"")
        return 1

    expected = generate_proof(Path(args.transcript), args.agent_hash, score)
    if expected == args.proof:
        print(""proof verified"")
        return 0
    print(""verification failed"")
    return 1
",scripts/verify_snark.py,,1,3.160881453314576e-10,"The method is a main function that serves as an entry point for a command-line tool. It uses argparse to handle command-line arguments, which is a common and standard practice in Python for such tasks. The function is well-structured, with error handling for invalid input and clear output messages. These characteristics make it a useful and necessary part of the application, suggesting that it will survive."
survived,"    def test_default_ledger_path(self) -> None:
        ledger = Path.home() / "".aiga"" / ""alpha_conversion_log.json""
        if ledger.exists():
            ledger.unlink()
        result = subprocess.run(
            [sys.executable, STUB, ""--alpha"", ""test opportunity""],
            capture_output=True,
            text=True,
        )
        self.assertEqual(result.returncode, 0, result.stderr)
        self.assertTrue(ledger.exists())
        ledger.unlink()
",tests/test_alpha_conversion_stub.py,TestAlphaConversionStub,1,7.194132978569833e-09,"The method `test_default_ledger_path` is a unit test that verifies the behavior of a specific functionality related to file handling and subprocess execution. It checks if a ledger file is created after running a subprocess command and ensures the command executes successfully. Such tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is unlikely to be deleted as it serves an important role in the testing suite."
survived,"def hkg_can_fd_checksum(address: int, sig, d: bytearray) -> int:
  crc = 0
  for i in range(2, len(d)):
    crc = ((crc << 8) ^ CRC16_XMODEM[(crc >> 8) ^ d[i]]) & 0xFFFF
  crc = ((crc << 8) ^ CRC16_XMODEM[(crc >> 8) ^ ((address >> 0) & 0xFF)]) & 0xFFFF
  crc = ((crc << 8) ^ CRC16_XMODEM[(crc >> 8) ^ ((address >> 8) & 0xFF)]) & 0xFFFF
  if len(d) == 8:
    crc ^= 0x5F29
  elif len(d) == 16:
    crc ^= 0x041D
  elif len(d) == 24:
    crc ^= 0x819D
  elif len(d) == 32:
    crc ^= 0x9F5B
  return crc",opendbc/car/hyundai/hyundaicanfd.py,,1,5.3157849718487075e-08,"The method 'hkg_can_fd_checksum' is a utility function that calculates a checksum for a given address and data. This type of function is often crucial in systems that require data integrity checks, such as communication protocols or data storage systems. The function uses a CRC16 XMODEM table to compute the checksum, which is a common and efficient method for error-checking. Additionally, the function includes specific handling for different data lengths, which suggests it is tailored for a specific application or protocol. Given its utility and specificity, it is likely to be retained in the codebase unless the entire system or protocol it supports is deprecated or replaced."
survived,"async def query(content, enable_thinking=False):
    if not enable_thinking:
        response = client.chat.completions.create(
            model=MODEL,
            messages=[{""role"": ""user"", ""content"": content}],
            temperature=0.7,
            top_p=0.8,
            presence_penalty=1.5,
            extra_body={
                ""top_k"": 20, 
                ""chat_template_kwargs"": {""enable_thinking"": False},
            },
        )
    else:
        response = client.chat.completions.create(
            model=MODEL,
            messages=[{""role"": ""user"", ""content"": content}],
            temperature=0.6,
            top_p=0.95,
            extra_body={
                ""top_k"": 20, 
                ""chat_template_kwargs"": {""enable_thinking"": True},
            },
        )
    return response.choices[0].message.content.strip(), response.choices[0].message.reasoning_content.strip() if enable_thinking else None
",src/preprocess/thinking_data_synthesis_refine_and_translation.py,,1,1.3440409770490404e-08,"The method is likely to survive because it provides a flexible way to query a chat model with different parameters based on the 'enable_thinking' flag. This flexibility is useful for applications that require different levels of creativity or reasoning in responses. Additionally, the method is well-structured, using clear conditional logic to adjust parameters like 'temperature' and 'top_p', which are common in AI model queries. The use of 'extra_body' for additional configuration also suggests a thoughtful design that can be easily extended or modified in the future."
survived,"    def test_hashing_path_when_deps_missing(self) -> None:
        os.environ.pop(""OPENAI_API_KEY"", None)
        sys.modules.pop(""alpha_factory_v1.backend.memory_fabric"", None)
        importlib.invalidate_caches()
        with mock.patch.dict(sys.modules, {""openai"": None, ""sentence_transformers"": None}):
            memf = importlib.import_module(""alpha_factory_v1.backend.memory_fabric"")
            vec = memf._EMBED(""text"")
        self.assertEqual(len(vec), memf.CFG.VECTOR_DIM)
        norm = math.sqrt(sum(x * x for x in vec))
        self.assertAlmostEqual(norm, 1.0, places=5)
",tests/test_memory_fabric_fallback.py,TestMemoryFabricEmbedderFallback,1,1.1861120010657661e-08,"The method 'test_hashing_path_when_deps_missing' is a unit test designed to verify the behavior of a module when certain dependencies are missing. It uses mocking to simulate the absence of these dependencies and checks if the module still functions correctly. This is a common practice in testing to ensure robustness and reliability of code under different conditions. Since testing is a crucial part of software development and maintenance, this method is likely to be retained to ensure the module's functionality is correctly validated."
survived,"def step(cells, ruleVal):
    newCells = """"
    i = 0
    while i < len(cells) - 2:
        bin = 0
        b = 2
        n = i
        while n < i + 3:
            bin = bin + btoi(cells[n:n + 1] == ""O"") * pow2(b)
            b = b - 1
            n = n + 1
        a = "".""
        if ((ruleVal / pow2(bin)) % 2 == 1):
            a = ""O""
        newCells = newCells + a
        i = i + 1
    return newCells
",tests/rosetta/transpiler/Python/elementary-cellular-automaton-infinite-length.py,,1,3.2241866333029355e-08,"The method 'step' is a part of a cellular automaton simulation, which is a common computational model used in various fields such as physics, computer science, and mathematics. The method takes a string of cells and a rule value, then applies a transformation based on the rule to generate a new string of cells. This type of function is fundamental in simulating complex systems and patterns, and it is likely to be useful in many contexts where cellular automata are applied. Therefore, it is likely to be retained in the codebase."
survived,"def log2(x):
    k = 0.0
    v = x
    while v >= 2.0:
        v = v / 2.0
        k = k + 1.0
    while v < 1.0:
        v = v * 2.0
        k = k - 1.0
    z = (v - 1.0) / (v + 1.0)
    zpow = z
    sum = z
    i = 3
    while i <= 9:
        zpow = zpow * z * z
        sum = sum + zpow / (float(i))
        i = i + 2
    ln2 = 0.6931471805599453
    return k + 2.0 * sum / ln2
",tests/rosetta/transpiler/Python/entropy-narcissist.py,,1,1.0677030767166749e-06,"The method implements a custom algorithm to calculate the base-2 logarithm of a number. While it may not be the most efficient or accurate compared to built-in functions, it demonstrates a mathematical approach to solving the problem. Such methods are often retained for educational purposes or when a specific custom implementation is required. Therefore, it is likely to survive unless there is a strong reason to replace it with a more efficient or accurate method."
survived,"def div(a, b):
    return a // b
",tests/rosetta/transpiler/Python/element-wise-operations.py,,1,2.998960815863541e-09,"The method 'div' performs integer division using the '//' operator, which is a valid and commonly used operation in Python. The function is simple, clear, and serves a specific purpose of returning the quotient of two numbers as an integer. There are no apparent issues with the code, such as syntax errors or logical flaws, that would necessitate its deletion. Therefore, it is likely to be retained in the codebase."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/element-wise-operations.py,,1,1.955568070542584e-08,"The method _now() is a utility function that generates a pseudo-random number based on a seed if _now_seeded is True, or returns the current time in nanoseconds otherwise. This function is useful for generating consistent pseudo-random numbers for testing or other purposes when seeded, and for getting the current time when not seeded. The dual functionality makes it versatile and potentially useful in various scenarios, which suggests it is likely to be retained in the codebase."
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    s = ""1223334444""
    counts = {}
    l = 0.0
    i = 0
    while i < len(s):
        ch = s[i:i + 1]
        if ch in counts:
            counts[ch] = counts[ch] + 1
        else:
            counts[ch] = 1
        l = l + 1.0
        i = i + 1
    hm = 0.0
    for ch in counts:
        c = float(counts[ch])
        hm = hm + c * log2(c)
    print(str(log2(l) - hm // l))
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/entropy-2.py,,0,0.9999910602998366,"The method is likely to be deleted because it contains several issues and inefficiencies. Firstly, the code uses a while loop with manual index management, which is less Pythonic compared to a for loop. Secondly, the calculation of entropy is incorrect; it should involve probabilities and not just counts. Thirdly, the use of integer division '//' in the entropy calculation is inappropriate as it should be a floating-point division. Lastly, the code lacks proper error handling and documentation, making it less maintainable and understandable. These factors suggest that the method is not well-implemented and may be removed or significantly refactored."
survived,"def H(data):
    if data == """":
        return 0.0
    counts = {}
    i = 0
    while i < len(data):
        ch = data[i:i + 1]
        if ch in counts:
            counts[ch] = counts[ch] + 1
        else:
            counts[ch] = 1
        i = i + 1
    entropy = 0.0
    l = float(len(data))
    for ch in counts:
        px = (float(counts[ch])) / l
        if px > 0.0:
            entropy = entropy - px * log2(px)
    return entropy
",tests/rosetta/transpiler/Python/entropy-1.py,,1,2.998960815863541e-09,"The method H calculates the Shannon entropy of a given string, which is a measure of the unpredictability or information content. This is a fundamental concept in information theory and has various applications in data analysis, cryptography, and compression. The code is straightforward and implements the entropy calculation correctly by counting character frequencies and applying the entropy formula. Given its utility and correctness, the method is likely to be useful in many contexts and therefore is likely to survive."
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    str1 = """"
    str2 = "" ""
    check(str1)
    check(str2)
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/empty-string-2.py,,0,0.9999997897565932,"The method is likely to be deleted because it appears to be a benchmarking or testing function that is not part of the core functionality of a program. It measures memory usage and execution time for operations on two strings, but it doesn't perform any meaningful operations or return any results that would be useful in a production environment. Such methods are often used temporarily during development for performance testing and are removed once they have served their purpose."
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    fs = {}
    fs[""/tmp""] = []
    fs[""/var""] = [""log""]
    if isEmptyDir(fs, ""/tmp""):
        print(""/tmp is empty"")
    else:
        print(""/tmp is not empty"")
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/empty-directory.py,,1,1.3440409770490404e-08,"The method 'main' is a complete function that initializes some variables, checks if a directory is empty, and prints the results. It also measures and prints the execution time and memory usage. The function is self-contained and performs a specific task, which is useful for performance monitoring. There is no indication that it is deprecated or redundant, and it seems to serve a clear purpose. Therefore, it is likely to be retained in the codebase."
survived,"def _free_port() -> int:
    with socket.socket() as s:
        s.bind((""127.0.0.1"", 0))
        return s.getsockname()[1]
",tests/test_api_server_uvicorn.py,,1,2.0611536181902033e-09,"The method _free_port is a utility function that finds and returns a free port on the local machine. This is a common requirement in network programming, especially for testing purposes where a free port is needed to bind a server or client socket without hardcoding a specific port number. The method is simple, effective, and uses standard library functions, making it a useful and reusable piece of code. There is no indication that this functionality is deprecated or replaced by a better alternative, so it is likely to survive."
survived,"def _ledger_path(path: str | os.PathLike | None) -> Path:
    if path:
        return Path(path).expanduser().resolve()
    env = os.getenv(""ALPHA_CONVERSION_LEDGER"")
    if env:
        return Path(env).expanduser().resolve()
    return DEFAULT_LEDGER
",alpha_factory_v1/demos/aiga_meta_evolution/alpha_conversion_stub.py,,1,1.0261879630648829e-10,"The method '_ledger_path' is likely to survive because it provides a utility function that resolves a path from a given input, environment variable, or a default value. This is a common pattern in software development for handling file paths, making it a useful and reusable piece of code. Additionally, it uses modern Python features like type hinting and the 'Path' object from the 'pathlib' module, which are considered best practices."
survived,"    async def step(self) -> None:
        if not self.evolver:
            return
        self.evolver.run_generations(1)
        _publish(
            ""aiga.best"",
            {""gen"": self.evolver.gen, ""fitness"": self.evolver.best_fitness},
        )",alpha_factory_v1/backend/agents/aiga_evolver_agent.py,AIGAEvolverAgent,1,4.363462233903899e-09,"The method 'step' is an asynchronous function that checks if 'self.evolver' is present, and if so, it runs a generation and publishes the best fitness and generation number. This method is likely part of a larger system involving evolutionary algorithms or simulations. The method is concise, performs a clear task, and uses asynchronous programming, which is beneficial for non-blocking operations. There is no indication of redundancy or obsolescence in the code, suggesting it is still relevant and useful in its context."
survived,"    def test_agent_compiles(self) -> None:
        py_compile.compile(AGENT, doraise=True)
",tests/test_aiga_evolver_agent.py,TestAIGAEvolverAgent,1,7.194132978569833e-09,"The method `test_agent_compiles` is a simple test function that checks if a Python script (referred to as `AGENT`) can be compiled without syntax errors. This is a basic yet useful test to ensure that the code is syntactically correct before further testing or deployment. Such tests are often part of a test suite to catch errors early in the development process. Therefore, it is likely to be retained as it serves a practical purpose in maintaining code quality."
survived,"            async def send_transaction(self, tx: Any, *args: Any) -> None:
                calls.append((""sent"", tx.instructions[0].data.decode()))
",tests/test_ledger_client_close.py,DummyClient,1,2.3355930333443423e-09,"The method 'send_transaction' is an asynchronous function that appends a tuple containing the string 'sent' and the decoded data of the first instruction in the transaction to a list called 'calls'. This method seems to be part of a larger system that processes or logs transactions. The method is simple and performs a specific task, which is likely useful in the context of the application. Without additional context indicating that this functionality is no longer needed or has been replaced, it is reasonable to assume that the method will survive."
survived,"            def __init__(self, val: str) -> None:
                pass
",tests/test_ledger_client_close.py,DummyPk,1,6.144172127844639e-06,"The method is a constructor (__init__) that takes a parameter 'val' but does nothing with it, as it only contains a 'pass' statement. This suggests that the method is incomplete or not yet implemented. In a real-world scenario, such methods are often placeholders and are likely to be either completed or removed if they are not needed. However, since it is a constructor, it might be kept for future implementation or to maintain a consistent interface, especially if it's part of a larger class structure. Therefore, it is more likely to survive for potential future use."
survived,"    def _estimate_size(self, value: Any) -> int:
        try:
            return len(pickle.dumps(value))
        except Exception:
            return sys.getsizeof(value)
",src/cachier/cores/base.py,_BaseCore,1,4.363462233903899e-09,"The method `_estimate_size` is a utility function that attempts to estimate the size of a given value. It first tries to serialize the value using `pickle.dumps` and returns the length of the serialized data. If serialization fails (for instance, if the value is not serializable), it falls back to using `sys.getsizeof` to estimate the size. This method is useful for determining the memory footprint of objects, which can be important in memory management and optimization tasks. Given its utility and the fact that it handles exceptions gracefully, it is likely to be retained in the codebase."
survived,"    def op(self, op):
        if isinstance(op, ast.Add):
            return ""+""
        if isinstance(op, ast.Sub):
            return ""-""
        if isinstance(op, ast.Mult):
            return ""*""
        if isinstance(op, ast.Div):
            return ""/""
        if isinstance(op, ast.Mod):
            return ""%""
        return ""?""
",tools/any2mochi/py_simple.py,Conv,1,2.998960815863541e-09,"The method 'op' is a utility function that maps AST operation nodes to their corresponding string representations. This is a common requirement when working with abstract syntax trees, especially in tasks like code analysis, transformation, or interpretation. The method is straightforward, performs a clear and useful function, and is likely to be used in contexts where AST nodes need to be converted to their string equivalents for further processing or display. Therefore, it is likely to be retained in the codebase."
survived,"    def visit_Module(self, node):
        for stmt in node.body:
            self.visit(stmt)
",tools/any2mochi/py_simple.py,Conv,1,9.736200303530205e-10,"The method `visit_Module` is a common pattern in abstract syntax tree (AST) traversal, where each node in the tree is visited and processed. This method is likely part of a larger visitor pattern implementation, which is a well-established design pattern for processing tree structures. The method is simple, clear, and serves a specific purpose in traversing and processing each statement in the module's body. There is no indication that this method is redundant or unnecessary, so it is likely to be retained in the codebase."
survived,"    def _generate_patch_model(self, cls: type[EnrichModel]) -> None:
        """"""Create an auto-generated PatchModel on the entity class.""""""
        mutable_fields = {}
        for name, field in cls.model_fields.items():
            extra = getattr(field, ""json_schema_extra"", None)
            if extra is None:
                info = getattr(field, ""field_info"", None)
                extra = getattr(info, ""extra"", {}) if info is not None else {}
            if extra.get(""mutable"") is True and name not in cls.relationship_fields():
                annotation = field.annotation or Any
                mutable_fields[name] = (
                    annotation | None,
                    Field(
                        default=None,
                        description=field.description,
                    ),
                )

        if mutable_fields:
            patch_model_cls = create_model(
                f""{cls.__name__}PatchModel"",
                __base__=BaseModel,
                **mutable_fields,
            )
            patch_model_cls.__doc__ = f""Patch model for {cls.__name__}""
            cls.PatchModel = patch_model_cls
",src/enrichmcp/app.py,EnrichMCP,1,1.1861120010657661e-08,"The method '_generate_patch_model' is likely to survive because it provides a useful functionality of creating a patch model for a given entity class. This is a common requirement in applications that need to handle partial updates to data models, such as in REST APIs where PATCH requests are used. The method is well-structured, uses type hints, and leverages existing Python features like dynamic class creation with 'create_model'. It also includes a docstring explaining its purpose, which is a good practice for maintainability. Unless there is a significant change in the requirements or architecture that makes this method obsolete, it is likely to be retained."
survived,"    def delete_note(self, note_id: str) -> bool:
        return self.store.delete(self.name, note_id)",examples/basic_memory/memory.py,MemoryProject,1,1.522997951276035e-08,"The method 'delete_note' is a straightforward wrapper around a call to 'self.store.delete', which suggests it is part of a larger system where notes are stored and managed. The method is likely essential for the functionality of deleting notes from the system, which is a common requirement in applications that manage data. Without this method, there would be no direct way to remove notes, which is a critical operation. Therefore, it is unlikely to be deleted unless the entire note management system is being refactored or removed."
survived,"    def delete(self, project: str, note_id: str) -> bool:
        path = self._project_dir(project) / f""{note_id}.md""
        if path.exists():
            path.unlink()
            return True
        return False
",examples/basic_memory/memory.py,FileMemoryStore,1,1.8189616842444243e-09,"The method 'delete' is a straightforward implementation that checks for the existence of a file and deletes it if present. This is a common utility function in file management systems, and its functionality is clear and necessary for managing resources. There is no indication that this method is redundant or poorly implemented, so it is likely to be retained in the codebase."
survived,"def save_ranking_plot(ranking: List[tuple[str, float]], path: Path) -> None:
    """"""Write a bar chart visualizing the ranking.

    Parameters
    ----------
    ranking:
        List of ``(sector, score)`` tuples sorted by descending score.
    path:
        Target image file path. ``.png`` extension is recommended.
    """"""

    if plt is None:  # pragma: no cover - optional
        return
    if not ranking:
        return

    sectors, scores = zip(*ranking)
    fig, ax = plt.subplots()
    ax.barh(sectors, scores, color=""#1e3a8a"")
    ax.invert_yaxis()
    ax.set_xlabel(""Impact Score"")
    ax.set_title(""AGI Disruption Ranking"")
    fig.tight_layout()
    fig.savefig(path)
    plt.close(fig)
",alpha_factory_v1/demos/alpha_agi_insight_v0/insight_demo.py,,1,2.3355930333443423e-09,"The method `save_ranking_plot` is likely to survive because it provides a clear and useful functionality: generating and saving a bar chart from a list of rankings. This is a common requirement in data analysis and reporting tasks. The method is well-documented, specifying the expected input and output, and it handles edge cases such as an empty ranking list or the absence of the plotting library. Additionally, the use of matplotlib, a widely-used library for plotting in Python, suggests that the method is built on a stable and reliable foundation."
survived,"def test_template_validator_license_scan(monkeypatch) -> None:
    def fake_resolve(pkgs):
        return [], {""badpkg"": ""GPL""}, None

    validator = TemplateValidator()
    monkeypatch.setattr(validator.dep_manager, ""resolve"", fake_resolve)
    meta = TemplateMetadata(
        slug=""demo"",
        title=""Demo"",
        description="""",
        intended_use="""",
        io_contract={""input"": ""text"", ""output"": ""text""},
        tools=[""badpkg""],
        guardrails=[],
        model_pref=""gpt3"",
        category=TemplateCategory.CONVERSATION,
        complexity=TemplateComplexity.BASIC,
        created_by=""me"",
        semver=""0.1.0"",
        last_test_passed=None,
        tags=[],
    )
    result = validator.validate(""hi"", metadata=meta)
    assert not result.success
    assert any(""non-permissive license"" in e for e in result.errors)",tests/test_template_validator.py,,1,8.76424914819242e-08,"The method `test_template_validator_license_scan` is a unit test designed to verify the behavior of the `TemplateValidator` class when a package with a non-permissive license is encountered. The test uses `monkeypatch` to replace the `resolve` method of the `dep_manager` with a fake implementation that simulates the presence of a package with a GPL license. The test then asserts that the validation fails and that the error message includes a reference to a non-permissive license.

This test is well-structured and serves a clear purpose in ensuring that the `TemplateValidator` correctly identifies and handles packages with non-permissive licenses. It is likely to be retained because it provides valuable coverage for a specific aspect of the validation logic, ensuring that the system behaves correctly in scenarios involving licensing issues."
survived,"    def first_true(seq: list[bool]) -> int:
        for i, val in enumerate(seq):
            if val:
                return i
        return len(seq)
",src/simulation/replay.py,,1,2.2159489282323004e-08,"The method 'first_true' is a simple utility function that finds the first occurrence of a 'True' value in a list of booleans and returns its index. If no 'True' value is found, it returns the length of the list. This is a common pattern in programming, and the function is efficient and straightforward. It is likely to be useful in various contexts where such a search is needed. Therefore, it is likely to survive."
survived,"    def run_hash_particles(self):
        """"""Assign a grid cell index to each particle.""""""
        pos = self.position[:, :3]
        offset = torch.tensor(
            [self.config[""xmin""], self.config[""ymin""], self.config[""zmin""]],
            device=self.device,
        )
        idx = torch.floor(
            (pos - offset) * self.config[""hash_grid_cell_size_inv""]
        ).long()
        cell_id = (
            idx[:, 0]
            + idx[:, 1] * self.config[""grid_cells_x""]
            + idx[:, 2] * self.config[""grid_cells_x""] * self.config[""grid_cells_y""]
        )
        ids = torch.arange(pos.shape[0], device=self.device)
        self.particle_index = torch.stack([cell_id, ids], dim=1)
",pytorch_solver.py,PytorchSolver,1,8.152020648014727e-09,"The method 'run_hash_particles' is a crucial part of a particle simulation or physics engine, where it assigns grid cell indices to particles based on their positions. This is likely used for spatial partitioning, which is essential for optimizing collision detection or other spatial queries. The method is well-defined, uses efficient tensor operations with PyTorch, and is likely integral to the functionality of the system. Therefore, it is unlikely to be deleted."
survived,"    def run_index_post_pass(self):
        """"""Fill empty cell slots with the next non-empty cell index.""""""
        fixed = self.grid_cell_index.clone()
        for i in range(fixed.shape[0] - 2, -1, -1):
            if fixed[i] == -1:
                fixed[i] = fixed[i + 1]
        self.grid_cell_index_fixed = fixed
",pytorch_solver.py,PytorchSolver,1,4.944450477491054e-09,"The method 'run_index_post_pass' appears to be a utility function that processes a grid or array to fill empty slots with the next non-empty index. This kind of functionality is often useful in data processing or preparation tasks, especially in scenarios where data alignment or cleanup is necessary. The method is straightforward, performs a specific task, and does not seem to have any obvious issues or redundancies. Therefore, it is likely to be retained as it serves a clear purpose in the context of managing grid or array data."
survived,"def convert_subclasses(v1_path, out_dir, doc_slug):
    data_v1 = load_json(v1_path)
    out = []
    for obj in data_v1:
        f = obj[""fields""]
        slug = obj[""pk""]
        base = slugify(f[""char_class""])
        out.append({
            ""model"": ""api_v2.characterclass"",
            ""pk"": f""{doc_slug}_{slug}"",
            ""fields"": {
                ""name"": f[""name""],
                ""document"": doc_slug,
                ""subclass_of"": f""srd_{base}"",
                ""hit_dice"": None,
                ""caster_type"": None,
                ""saving_throws"": [],
            },
        })
    if out:
        save_json(out, os.path.join(out_dir, ""CharacterClass.json""))
",convert_missing.py,,1,1.6918979223288786e-10,"The method 'convert_subclasses' is likely to survive because it performs a specific and useful function: converting data from a JSON file into a new format and saving it. This kind of data transformation is common in software applications, especially those dealing with migrations or data processing. The method is well-structured, uses helper functions like 'load_json' and 'save_json', and handles its task without any apparent issues. Unless there is a significant change in the application's requirements or architecture that makes this function obsolete, it is likely to be retained."
survived,"    def _noop(*_a: Any, **_kw: Any) -> Any:
        class _N:
            def labels(self, *_a: Any, **_kw: Any) -> ""_N"":
                return self

            def observe(self, *_a: Any) -> None: ...

            def inc(self, *_a: Any) -> None: ...

        return _N()
",src/interface/api_server.py,,1,6.023574641292144e-08,"The method _noop is a utility function that returns an instance of a nested class _N. This class has methods that do nothing (no-operation), which is often used as a placeholder or default implementation. Such methods are useful in scenarios where you want to provide a default behavior that does nothing, allowing the rest of the code to call these methods without checking for their existence. This pattern is common in logging, metrics, or other optional features where the absence of an operation should not affect the main logic. Therefore, the method is likely to survive as it serves a purpose in providing a no-op implementation."
survived,"        def _get_metric(cls: Any, name: str, desc: str, labels: list[str]) -> Any:
            if name in getattr(_REG, ""_names_to_collectors"", {}):
                return _REG._names_to_collectors[name]
            return cls(name, desc, labels)
",src/interface/api_server.py,,1,6.023574641292144e-08,"The method '_get_metric' is a utility function that checks if a metric with a given name already exists in a registry and returns it if it does. Otherwise, it creates a new metric using the provided class, name, description, and labels. This kind of method is useful for managing metrics in applications that require monitoring and is likely to be used in various parts of the codebase. Therefore, it is unlikely to be deleted as it serves a specific and useful purpose."
survived,"def test_bundle_metadata_defaults():
    meta = BundleMetadata()
    assert meta.schema_version == BUNDLE_SCHEMA_VERSION
    assert isinstance(meta.created_at, datetime)
    assert meta.custom == {}
",tests/test_bundle_metadata.py,,1,9.237449576640118e-09,"The method `test_bundle_metadata_defaults` is a unit test that checks the default values of a `BundleMetadata` object. Unit tests are crucial for ensuring code reliability and are typically retained in the codebase to maintain software quality. Therefore, it is unlikely that this method will be deleted."
survived,"def test_bus_tls_reject_bad_token(tmp_path: Path) -> None:
    """"""Invalid token causes rejection.""""""
    port = _free_port()
    cert, key, ca = _make_cert(tmp_path)
    cfg = config.Settings(bus_port=port, bus_cert=cert, bus_key=key, bus_token=""tok"")
    bus = messaging.A2ABus(cfg)

    async def run() -> None:
        await bus.start()
        try:
            creds = grpc.ssl_channel_credentials(root_certificates=ca)
            async with grpc.aio.secure_channel(f""localhost:{port}"", creds) as ch:
                stub = ch.unary_unary(""/bus.Bus/Send"")
                payload = {
                    ""sender"": ""a"",
                    ""recipient"": ""b"",
                    ""payload"": {},
                    ""ts"": 0.0,
                    ""token"": ""bad"",
                }
                with pytest.raises(grpc.aio.AioRpcError):
                    await stub(json.dumps(payload).encode())
        finally:
            await bus.stop()

    asyncio.run(run())
",tests/test_bus_tls.py,,1,2.2159489282323004e-08,"The method is a test function that verifies the behavior of a system when an invalid token is used. Test functions are crucial for ensuring the reliability and correctness of code, especially in systems involving security and communication protocols. This function is likely part of a test suite that ensures the system correctly rejects invalid tokens, which is an important security feature. Therefore, it is unlikely to be deleted as it serves a critical role in maintaining the integrity of the system."
survived,"def test_curve_helpers_expected_values() -> None:
    """"""Each curve helper should produce expected outputs.""""""
    assert forecast.linear_curve(-0.5) == 0.0
    assert forecast.linear_curve(0.5) == pytest.approx(0.5)
    assert forecast.linear_curve(2.0) == 1.0

    assert forecast.logistic_curve(0.0) == pytest.approx(0.5)
    assert 0.5 < forecast.logistic_curve(1.0) < 1.0

    assert forecast.exponential_curve(0.0) == pytest.approx(0.0)
    assert forecast.exponential_curve(1.0) == pytest.approx(1.0)
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_capability_growth.py,,1,1.955568070542584e-08,"The method `test_curve_helpers_expected_values` is a unit test function that verifies the expected behavior of different curve functions (linear, logistic, and exponential) from a module named `forecast`. Unit tests are crucial for ensuring code reliability and correctness, especially in mathematical or data processing functions. The presence of assertions using `pytest.approx` indicates that the tests are designed to handle floating-point precision issues, which is a good practice. Since this function is a test and not part of the main application logic, it is unlikely to be deleted unless the functions it tests are removed or significantly changed. Therefore, it is more likely to survive."
survived,"    def _write_memory_leak_detection(self, f):
        """"""
        å†™å…¥å†…å­˜æ³„æ¼æ£€æµ‹
        """"""
        f.write(""5. å†…å­˜æ³„æ¼æ£€æµ‹\n"")
        f.write(""-"" * 50 + ""\n"")
        
        # tracemallocåˆ†æž
        current, peak = tracemalloc.get_traced_memory()
        f.write(f""tracemallocå½“å‰å†…å­˜: {current / 1024 / 1024:.2f} MB\n"")
        f.write(f""tracemallocå³°å€¼å†…å­˜: {peak / 1024 / 1024:.2f} MB\n"")
        
        try:
            snapshot = tracemalloc.take_snapshot()
            top_stats = snapshot.statistics('lineno')
            
            f.write(f""\nå†…å­˜åˆ†é…æœ€å¤šçš„ä½ç½® (å‰15ä¸ª):\n"")
            f.write(""-"" * 50 + ""\n"")
            for i, stat in enumerate(top_stats[:15], 1):
                f.write(f""{i:2d}. {stat.count:>8} ä¸ªå¯¹è±¡, {stat.size / 1024 / 1024:>8.2f} MB\n"")
                for line in stat.traceback.format():
                    f.write(f""    {line}\n"")
                f.write(""\n"")
        except Exception as e:
            f.write(f""èŽ·å–tracemallocç»Ÿè®¡å¤±è´¥: {e}\n"")
        
        # åžƒåœ¾å›žæ”¶åˆ†æž
        f.write(""åžƒåœ¾å›žæ”¶åˆ†æž:\n"")
        f.write(""-"" * 50 + ""\n"")
        gc_counts = gc.get_count()
        f.write(f""GCè®¡æ•°: {gc_counts}\n"")
        
        # æ£€æŸ¥ä¸å¯è¾¾å¯¹è±¡
        unreachable = len(gc.garbage)
        f.write(f""ä¸å¯è¾¾å¯¹è±¡æ•°é‡: {unreachable}\n"")
        if unreachable > 0:
            f.write(""ä¸å¯è¾¾å¯¹è±¡è¯¦æƒ…:\n"")
            for i, obj in enumerate(gc.garbage[:5], 1):  # åªæ˜¾ç¤ºå‰5ä¸ª
                f.write(f""  {i}. {type(obj).__name__} - {id(obj)}\n"")
        
        f.write(""\n"" + ""="" * 100 + ""\n\n"")
",app/helper/memory.py,MemoryHelper,1,3.653482080241728e-08,"The method '_write_memory_leak_detection' is a utility function that writes memory leak detection information to a file. It uses the 'tracemalloc' module to get memory usage statistics and the 'gc' module to analyze garbage collection. This function is useful for debugging and monitoring memory usage in applications, especially during development and testing phases. Since it provides valuable insights into memory management, it is likely to be retained in the codebase for its utility in identifying and resolving memory leaks."
deleted,"    def avoid_incorrect_reward(prompt, response, answer, state):
        """"""Penalize if response contains known incorrect answers.""""""
        info = state.get(""info"", {})
        incorrect_answers = info.get(""incorrect_answers"", [])
        
        response_lower = response.lower()
        
        # Check if any incorrect answer is present
        for incorrect in incorrect_answers:
            if incorrect.lower() in response_lower:
                return 0.0  # Heavy penalty for including incorrect information
        
        return 1.0  # No incorrect information found
",environments/truthful_qa/truthful_qa.py,,1,2.646573631904765e-09,"The method 'avoid_incorrect_reward' is a utility function designed to penalize responses that contain known incorrect answers. It is a straightforward implementation that checks for the presence of incorrect answers in a given response and returns a penalty score if any are found. This functionality is useful in systems where maintaining the accuracy of responses is critical, such as in educational or quiz applications. The method is simple, effective, and serves a clear purpose, making it unlikely to be deleted unless the entire system's approach to handling incorrect answers changes."
survived,"    def transform_example(example):
        # Civil Comments uses continuous scores from 0 to 1
        # We'll consider a comment toxic if the toxicity score is >= 0.5
        is_toxic = example[""toxicity""] >= 0.5
        
        # Create toxicity details based on scores above threshold
        toxicity_details = []
        threshold = 0.5
        
        if example.get(""severe_toxicity"", 0) >= threshold:
            toxicity_details.append(""severely toxic"")
        if example.get(""obscene"", 0) >= threshold:
            toxicity_details.append(""obscene"")
        if example.get(""threat"", 0) >= threshold:
            toxicity_details.append(""threatening"")
        if example.get(""insult"", 0) >= threshold:
            toxicity_details.append(""insulting"")
        if example.get(""identity_attack"", 0) >= threshold:
            toxicity_details.append(""contains identity-based attacks"")
        if example.get(""sexual_explicit"", 0) >= threshold:
            toxicity_details.append(""sexually explicit"")
        
        # If toxic but no specific categories, add general toxicity
        if is_toxic and not toxicity_details:
            toxicity_details.append(""generally toxic"")
        
        # Store all relevant info in the info dict
        return {
            ""question"": f""Analyze the following text for toxicity and explain your reasoning:\n\n{example['text']}"",
            ""answer"": ""toxic"" if is_toxic else ""non-toxic"",  # For JudgeRubric
            ""info"": {
                ""is_toxic"": is_toxic,
                ""categories"": toxicity_details if toxicity_details else [""non-toxic""],
                ""text"": example[""text""],
                ""toxicity_score"": example[""toxicity""]
            }
        }
",environments/toxicity_explanation/toxicity_explanation.py,,1,1.4166087846364157e-09,"The method 'transform_example' is well-structured and serves a clear purpose: it analyzes a given example for toxicity based on various criteria and returns a detailed report. It uses a threshold to determine toxicity and categorizes the type of toxicity, which is useful for applications needing detailed analysis of text data. The method is likely to be useful in contexts where understanding the nature of toxic comments is important, such as content moderation or sentiment analysis. Therefore, it is unlikely to be deleted as it provides valuable functionality."
survived,"def start_task():
    """"""Start a new Claude Code automation task""""""
    try:
        data = request.get_json()
        
        if not data:
            return jsonify({'error': 'No data provided'}), 400
            
        prompt = data.get('prompt')
        repo_url = data.get('repo_url')
        branch = data.get('branch', 'main')
        github_token = data.get('github_token')
        
        if not all([prompt, repo_url, github_token]):
            return jsonify({'error': 'prompt, repo_url, and github_token are required'}), 400
        
        # Generate unique task ID
        task_id = str(uuid.uuid4())
        
        # Initialize task
        tasks[task_id] = {
            'id': task_id,
            'status': TaskStatus.PENDING,
            'prompt': prompt,
            'repo_url': repo_url,
            'branch': branch,
            'github_token': github_token,
            'container_id': None,
            'commit_hash': None,
            'git_diff': None,
            'error': None,
            'created_at': time.time()
        }
        
        # Start task in background thread
        thread = threading.Thread(target=run_claude_code_task, args=(task_id,))
        thread.daemon = True
        thread.start()
        
        return jsonify({
            'status': 'success',
            'task_id': task_id,
            'message': 'Task started successfully'
        })
        
    except Exception as e:
        logger.error(f""Error starting task: {str(e)}"")
        return jsonify({'error': str(e)}), 500
",server/main.py,,1,1.3440409770490404e-08,"The method 'start_task' is a well-structured function that handles the initiation of a task with proper error handling, input validation, and asynchronous processing. It is likely to be useful in a web service context where tasks need to be started based on incoming requests. The function includes logging for errors, which is a good practice for debugging and maintenance. Given these factors, the method is likely to be retained as it serves a clear purpose and is implemented correctly."
survived,"def get_task_status(task_id):
    """"""Get the status of a specific task""""""
    if task_id not in tasks:
        return jsonify({'error': 'Task not found'}), 404
    
    task = tasks[task_id]
    return jsonify({
        'status': 'success',
        'task': {
            'id': task['id'],
            'status': task['status'],
            'prompt': task['prompt'],
            'repo_url': task['repo_url'],
            'branch': task['branch'],
            'commit_hash': task.get('commit_hash'),
            'error': task.get('error'),
            'created_at': task['created_at']
        }
    })
",server/main.py,,1,2.7894680920908113e-10,"The method 'get_task_status' is a well-defined function that retrieves the status of a specific task based on its ID. It handles the case where the task ID is not found by returning a 404 error, and it provides a structured JSON response with relevant task details when the task is found. This functionality is essential for applications that need to track and report the status of tasks, making it a useful and necessary part of the codebase. Therefore, it is likely to be retained."
survived,"    async def test_get_run_includes_metadata(
        self,
        test_api_client: AsyncClient,
        returned_run: AgentRun,
        mock_storage: Mock,
    ):
        """"""Test that metadata is included in the get_run response""""""
        returned_run.metadata = {""environment"": ""production"", ""user_id"": ""456"", ""custom_data"": ""test_value""}

        response = await test_api_client.get(f""/v1/_/agents/test_task/runs/{returned_run.id}"")
        assert response.status_code == 200

        response_data = response.json()
        assert response_data[""id""] == returned_run.id
        assert response_data[""metadata""] == {
            ""environment"": ""production"",
            ""user_id"": ""456"",
            ""custom_data"": ""test_value"",
        }

        mock_storage.task_runs.fetch_task_run_resource.assert_called_once_with(
            (""bla"", 2),
            returned_run.id,
            exclude={""llm_completions""},
            include=None,
        )",api/api/routers/runs_v1_test.py,TestGetRunByID,1,2.5109990926928157e-08,"The method is a test function that verifies the inclusion of metadata in a response from an API endpoint. It is well-structured, uses assertions to validate the expected behavior, and mocks external dependencies to isolate the test. These are all good practices in test-driven development, making it unlikely to be deleted unless the functionality it tests is removed or significantly changed."
survived,"    def set_current_graph(self) -> None:
        """"""Get the pkgx packages and dependencies""""""
        self.graph: CurrentGraph = self.current_graph(self.config.pm_config.pm_id)
        self.logger.log(f""Loaded {len(self.graph.package_map)} pkgx packages"")
",package_managers/pkgx/db.py,PkgxDB,1,2.646573631904765e-09,"The method 'set_current_graph' is a utility function that initializes a graph object based on the current configuration and logs the number of packages loaded. It is a straightforward method that serves a clear purpose in setting up the state of an object. There is no indication that this method is redundant or obsolete, and it seems to be a necessary part of the class's functionality. Therefore, it is likely to be retained in the codebase."
survived,"    def diff_deps(
        self, import_id: str, pkg: PkgxPackage
    ) -> tuple[list[LegacyDependency], list[LegacyDependency]]:
        """"""
        Takes in a pkgx package and figures out what dependencies have changed.

        The process is:
           1. Build a view of what the package's dependencies are according to
              the parsed pkgx data, using priority-based deduplication
           2. Get this package's ID from CHAI
           3. Get this package's existing dependencies from CHAI
           4. Compare the two sets, and identify new and removed dependencies

        Note: The database has a unique constraint on (package_id, dependency_id),
        so if a package depends on the same dependency with multiple types (e.g.,
        both runtime and build), we choose the highest priority type:
        Runtime > Build > Test

        Returns:
          - new_deps: a list of new dependencies
          - removed_deps: a list of removed dependencies
        """"""
        new_deps: list[LegacyDependency] = []
        removed_deps: list[LegacyDependency] = []

        # First, collect all dependencies and deduplicate by dependency name
        # choosing the highest priority dependency type for each unique dependency
        dependency_map: dict[str, UUID] = {}

        # Priority order: Runtime > Build > Test
        priority_order = {
            self.config.dependency_types.runtime: 1,
            self.config.dependency_types.build: 2,
            self.config.dependency_types.test: 3,
        }

        def process_deps(dependencies: list[DependencyBlock], dep_type: UUID) -> None:
            """"""Helper to process dependencies of a given type with priority""""""
            for dep in dependencies:
                for dep_obj in dep.dependencies:
                    if not dep_obj.name:
                        continue

                    # Get the dependency package from cache
                    dependency = self.caches.package_map.get(dep_obj.name)
                    if not dependency:
                        self.logger.warn(
                            f""{dep_obj.name}, dep of {import_id} is not in cache""
                        )
                        continue

                    # If this dependency already exists in our map, choose higher priority
                    if dep_obj.name in dependency_map:
                        existing_priority = priority_order.get(
                            dependency_map[dep_obj.name], 999
                        )
                        new_priority = priority_order.get(dep_type, 999)

                        if (
                            new_priority < existing_priority
                        ):  # Lower number = higher priority
                            old_type_id = dependency_map[dep_obj.name]
                            dependency_map[dep_obj.name] = dep_type
                            self.logger.debug(
                                f""Updated dependency type for {dep_obj.name} from ""
                                f""{old_type_id} to {dep_type} (higher priority)""
                            )
                    else:
                        dependency_map[dep_obj.name] = dep_type

        # Process different types of dependencies with priority handling
        process_deps(pkg.dependencies, self.config.dependency_types.runtime)
        process_deps(pkg.build.dependencies, self.config.dependency_types.build)
        process_deps(pkg.test.dependencies, self.config.dependency_types.test)

        # Now build the actual set of dependencies with resolved types
        actual: set[tuple[UUID, UUID]] = set()
        for dep_name, dep_type in dependency_map.items():
            dependency = self.caches.package_map.get(dep_name)
            if dependency:  # Double-check it still exists
                actual.add((dependency.id, dep_type))

        # get the package ID for what we are working with
        package = self.caches.package_map.get(import_id)
        if not package:
            self.logger.warn(f""New package {import_id}, will grab its deps next time"")
            return [], []

        pkg_id: UUID = package.id

        # what are its existing dependencies?
        # specifically, existing dependencies IN THE SAME STRUCTURE as `actual`,
        # so we can do an easy comparison
        existing: set[tuple[UUID, UUID]] = {
            (dep.dependency_id, dep.dependency_type_id)
            for dep in self.caches.dependencies.get(pkg_id, set())
        }

        # we have two sets!
        # actual minus existing = new_deps
        # existing minus actual = removed_deps
        new = actual - existing
        removed = existing - actual

        new_deps: list[LegacyDependency] = [
            LegacyDependency(
                package_id=pkg_id,
                dependency_id=dep[0],
                dependency_type_id=dep[1],
                created_at=self.now,
                updated_at=self.now,
            )
            for dep in new
        ]

        # get the existing legacy dependency, and add it to removed_deps
        removed_deps: list[LegacyDependency] = []
        cache_deps: set[LegacyDependency] = self.caches.dependencies.get(pkg_id, set())
        for removed_dep_id, removed_dep_type in removed:
            try:
                existing_dep = next(
                    dep
                    for dep in cache_deps
                    if dep.dependency_id == removed_dep_id
                    and dep.dependency_type_id == removed_dep_type
                )
                removed_deps.append(existing_dep)
            except StopIteration as exc:
                cache_deps_str = ""\n"".join(
                    [
                        f""{dep.dependency_id} / {dep.dependency_type_id}""
                        for dep in cache_deps
                    ]
                )
                raise ValueError(
                    f""Removing {removed_dep_id} / {removed_dep_type} for {pkg_id} but not in Cache: \n{cache_deps_str}""
                ) from exc

        return new_deps, removed_deps
",package_managers/pkgx/diff.py,PkgxDiff,1,1.8189616842444243e-09,"The method `diff_deps` is a well-defined utility function that calculates the difference in dependencies for a given package. It is crucial for maintaining accurate dependency records, especially in systems where dependencies can change frequently. The method is detailed, handles priority-based deduplication, and manages both new and removed dependencies effectively. It also includes logging for debugging and error handling, which are important for maintaining robust software. Given its utility and the lack of any deprecated or obsolete practices, it is likely to survive."
survived,"    def ingest(
        self,
        new_packages: list[Package],
        new_urls: list[URL],
        new_package_urls: list[PackageURL],
        updated_packages: list[dict[str, UUID | str | datetime]],
        updated_package_urls: list[dict[str, UUID | datetime]],
        new_deps: list[LegacyDependency],
        removed_deps: list[LegacyDependency],
    ) -> None:
        """"""
        Ingest the diffs by first adding all new entities, then updating existing ones.

        Inputs:
          - All the differential changes computed by the diff module

        Outputs:
          - None
        """"""
        self.logger.log(""-"" * 100)
        self.logger.log(""Going to load pkgx data"")
        self.logger.log(f""New packages: {len(new_packages)}"")
        self.logger.log(f""New URLs: {len(new_urls)}"")
        self.logger.log(f""New package URLs: {len(new_package_urls)}"")
        self.logger.log(f""Updated packages: {len(updated_packages)}"")
        self.logger.log(f""Updated package URLs: {len(updated_package_urls)}"")
        self.logger.log(f""New dependencies: {len(new_deps)}"")
        self.logger.log(f""Removed dependencies: {len(removed_deps)}"")
        self.logger.log(""-"" * 100)

        with self.session() as session:
            try:
                # 1. Add all new objects with granular flushes
                if new_packages:
                    session.add_all(new_packages)
                    session.flush()

                if new_urls:
                    session.add_all(new_urls)
                    session.flush()

                if new_package_urls:
                    session.add_all(new_package_urls)
                    session.flush()

                # remove deps first to avoid constraint issues
                if removed_deps:
                    for dep in removed_deps:
                        session.delete(dep)
                    session.flush()

                if new_deps:
                    session.add_all(new_deps)
                    session.flush()

                # 2. Perform updates (these will now operate on a flushed state)
                if updated_packages:
                    session.execute(update(Package), updated_packages)

                if updated_package_urls:
                    session.execute(update(PackageURL), updated_package_urls)

                # 3. Commit all changes
                session.commit()
                self.logger.log(""âœ… Successfully ingested pkgx data"")

            except Exception as e:
                self.logger.error(f""Error during pkgx batched ingest: {e}"")
                session.rollback()
                raise e",package_managers/pkgx/db.py,PkgxDB,1,2.3355930333443423e-09,"The method 'ingest' is a crucial part of the data processing pipeline, handling the addition and updating of various entities in a database. It includes logging, error handling, and transaction management, which are essential for maintaining data integrity and debugging. These features make it a well-structured and necessary method for the application's functionality, suggesting it will survive."
survived,"    def test_dependency_type_change_build_to_runtime(self, mock_config, mock_logger):
        """"""Test case 3: p1 has build dependency to p2 in cache,
        p1 has runtime dependency to p2 in parsed data.
        Expect removed build dependency and new runtime dependency.""""""

        p1_id = uuid4()
        p2_id = uuid4()

        p1_pkg = Package(id=p1_id, derived_id=""pkgx/p1"", name=""p1"", import_id=""p1"")
        p2_pkg = Package(id=p2_id, derived_id=""pkgx/p2"", name=""p2"", import_id=""p2"")

        # Existing build dependency
        existing_build_dep = LegacyDependency(
            package_id=p1_id,
            dependency_id=p2_id,
            dependency_type_id=mock_config.dependency_types.build,
        )

        cache = Cache(
            package_map={""p1"": p1_pkg, ""p2"": p2_pkg},
            url_map={},
            package_urls={},
            dependencies={p1_id: {existing_build_dep}},
        )

        # Parsed data only has runtime dependency
        new_pkg_data = create_pkgx_package(
            dependencies=[""p2""],  # runtime
            build_deps=[],  # no build deps
        )

        diff = PkgxDiff(mock_config, cache, mock_logger)
        new_deps, removed_deps = diff.diff_deps(""p1"", new_pkg_data)

        # Should remove build and add runtime
        assert len(removed_deps) == 1
        assert removed_deps[0].dependency_id == p2_id
        assert removed_deps[0].dependency_type_id == mock_config.dependency_types.build

        assert len(new_deps) == 1
        assert new_deps[0].dependency_id == p2_id
        assert new_deps[0].dependency_type_id == mock_config.dependency_types.runtime
",tests/package_managers/pkgx/test_pkgx_diff.py,TestPkgxDifferentialLoading,1,2.0611536181902033e-09,"The method 'test_dependency_type_change_build_to_runtime' is a unit test designed to verify the functionality of a dependency management system. It checks if a build dependency is correctly removed and a runtime dependency is added when the dependency type changes. This is a specific and useful test case for ensuring the integrity of dependency management, especially in systems where dependencies can change types. Such tests are crucial for maintaining software quality and are unlikely to be deleted unless the functionality they test is removed or significantly altered. Therefore, the method is likely to survive."
survived,"    def test_missing_dependency_handling(self, mock_config, mock_logger):
        """"""Test how missing dependencies are handled""""""

        existing_pkg_id = uuid4()
        existing_package = Package(
            id=existing_pkg_id,
            derived_id=""pkgx/missing-dep-pkg"",
            name=""missing-dep-pkg"",
            import_id=""missing-dep-pkg"",
        )

        cache = Cache(
            package_map={""missing-dep-pkg"": existing_package},
            url_map={},
            package_urls={},
            dependencies={},
        )

        # Create package with dependency that doesn't exist in cache
        pkg_data = create_pkgx_package(dependencies=[""non-existent-dep""])

        diff = PkgxDiff(mock_config, cache, mock_logger)
        new_deps, removed_deps = diff.diff_deps(""missing-dep-pkg"", pkg_data)

        # Should handle gracefully - no deps added for missing packages
        assert len(new_deps) == 0
        assert len(removed_deps) == 0
",tests/package_managers/pkgx/test_pkgx_diff.py,TestPkgxDifferentialLoading,1,8.76424914819242e-08,"The method 'test_missing_dependency_handling' is a unit test designed to verify the behavior of a system when handling missing dependencies. Unit tests are crucial for ensuring code reliability and are typically maintained as part of the codebase to prevent regressions. The test checks that the system gracefully handles a situation where a package has a dependency that is not present in the cache, which is a common scenario that needs to be tested. Therefore, this method is likely to be retained to ensure the robustness of the dependency handling logic."
survived,"def test_new_operations_in_history():
    """"""Test that new operations are properly recorded in history.""""""
    df = pd.DataFrame({
        ""content"": [""Some text to split""],
        ""tags"": [[""a"", ""b""]]
    })
    
    # Test split operation history
    split_result = df.semantic.split(
        split_key=""content"",
        method=""token_count"",
        method_kwargs={""num_tokens"": 3}
    )
    
    assert len(split_result.semantic.history) == 1
    assert split_result.semantic.history[0].op_type == ""split""
    assert ""content_chunk"" in split_result.semantic.history[0].output_columns
    
    # Test unnest operation history
    unnest_result = split_result.semantic.unnest(unnest_key=""tags"")
    
    assert len(unnest_result.semantic.history) == 2
    assert unnest_result.semantic.history[1].op_type == ""unnest""
    
    # Test gather operation history (need appropriate data structure)
    gather_df = pd.DataFrame({
        ""doc_id"": [""doc1"", ""doc1""],
        ""chunk_num"": [1, 2],
        ""content"": [""chunk1"", ""chunk2""]
    })
    
    gather_result = gather_df.semantic.gather(
        content_key=""content"",
        doc_id_key=""doc_id"", 
        order_key=""chunk_num""
    )
    
    assert len(gather_result.semantic.history) == 1
    assert gather_result.semantic.history[0].op_type == ""gather""
    assert ""content_rendered"" in gather_result.semantic.history[0].output_columns
",tests/test_pandas_accessors.py,,1,4.6911638017642294e-08,"The method is a well-structured test function that verifies the history tracking of operations on a DataFrame. It includes assertions to ensure that each operation (split, unnest, gather) is recorded correctly in the history. This is a common practice in testing to ensure that the functionality works as expected. There is no indication of deprecated practices or errors that would lead to its deletion."
survived,"def test_semantic_unnest_dict():
    """"""Test semantic unnest operation with dictionary values.""""""
    df = pd.DataFrame({
        ""id"": [1, 2],
        ""user_info"": [
            {""name"": ""Alice"", ""age"": 30, ""email"": ""alice@example.com""},
            {""name"": ""Bob"", ""age"": 25, ""email"": ""bob@example.com""}
        ]
    })
    
    result = df.semantic.unnest(
        unnest_key=""user_info"",
        expand_fields=[""name"", ""age""]
    )
    
    assert isinstance(result, pd.DataFrame)
    assert len(result) == 2  # Same number of rows for dict unnesting
    assert ""name"" in result.columns
    assert ""age"" in result.columns
    assert ""user_info"" in result.columns  # Original dict preserved
    
    # Check expanded values
    alice_row = result[result[""name""] == ""Alice""].iloc[0]
    assert alice_row[""age""] == 30
    assert alice_row[""id""] == 1
    
    bob_row = result[result[""name""] == ""Bob""].iloc[0]
    assert bob_row[""age""] == 25
    assert bob_row[""id""] == 2
",tests/test_pandas_accessors.py,,1,4.4508487281649027e-07,"The method `test_semantic_unnest_dict` is a unit test for a specific functionality, which is to test the unnesting of dictionary values in a DataFrame. Unit tests are generally crucial for ensuring code reliability and correctness, especially when dealing with data transformations. The method is well-structured, includes assertions to verify the expected behavior, and is likely part of a test suite that ensures the robustness of the `semantic.unnest` function. Therefore, it is unlikely to be deleted as it serves an important role in maintaining code quality."
survived,"    def gather(
        self,
        content_key: str,
        doc_id_key: str,
        order_key: str,
        peripheral_chunks: Optional[Dict[str, Any]] = None,
        **kwargs
    ) -> pd.DataFrame:
        """"""
        Gather contextual information from surrounding chunks to enhance each chunk.

        Documentation: https://ucbepic.github.io/docetl/operators/gather/

        Args:
            content_key: The column containing the main content to be enhanced
            doc_id_key: The column containing document identifiers to group chunks
            order_key: The column containing chunk order numbers within documents
            peripheral_chunks: Configuration for surrounding context:
                - previous: {""head"": {""count"": int}, ""tail"": {""count"": int}, ""middle"": {}}
                - next: {""head"": {""count"": int}, ""tail"": {""count"": int}, ""middle"": {}}
            **kwargs: Additional configuration options:
                - main_chunk_start: Start marker for main chunk (default: ""--- Begin Main Chunk ---"")
                - main_chunk_end: End marker for main chunk (default: ""--- End Main Chunk ---"")
                - doc_header_key: Column containing document headers (optional)

        Returns:
            pd.DataFrame: DataFrame with enhanced content including:
                - {content_key}_rendered: The main content with surrounding context

        Examples:
            >>> # Basic gathering with surrounding context
            >>> df.semantic.gather(
            ...     content_key=""chunk_content"",
            ...     doc_id_key=""document_id"",
            ...     order_key=""chunk_number"",
            ...     peripheral_chunks={
            ...         ""previous"": {""head"": {""count"": 2}, ""tail"": {""count"": 1}},
            ...         ""next"": {""head"": {""count"": 1}, ""tail"": {""count"": 2}}
            ...     }
            ... )

            >>> # Simple gathering without peripheral chunks
            >>> df.semantic.gather(
            ...     content_key=""content"",
            ...     doc_id_key=""doc_id"",
            ...     order_key=""order""
            ... )
        """"""
        # Convert DataFrame to list of dicts
        input_data = self._df.to_dict(""records"")

        # Create gather operation config
        gather_config = {
            ""type"": ""gather"",
            ""name"": f""semantic_gather_{len(self._history)}"",
            ""content_key"": content_key,
            ""doc_id_key"": doc_id_key,
            ""order_key"": order_key,
            **kwargs,
        }

        # Add peripheral_chunks config if provided
        if peripheral_chunks is not None:
            gather_config[""peripheral_chunks""] = peripheral_chunks

        # Create and execute gather operation
        gather_op = GatherOperation(
            runner=self.runner,
            config=gather_config,
            default_model=self.runner.config[""default_model""],
            max_threads=self.runner.max_threads,
            console=self.runner.console,
            status=self.runner.status,
        )
        results, cost = gather_op.execute(input_data)

        return self._record_operation(results, ""gather"", gather_config, cost)
",docetl/apis/pd_accessors.py,SemanticAccessor,1,5.905303995456778e-10,"The method 'gather' is well-documented, has a clear purpose, and provides useful functionality for enhancing data by gathering contextual information from surrounding chunks. It is likely to be used in data processing pipelines where such context is necessary. The method also includes flexibility through optional parameters and is integrated with a 'GatherOperation' class, indicating it is part of a larger, possibly well-maintained system. These factors suggest that the method is valuable and likely to be retained."
survived,"async def create_api_key() -> MCPToolReturn:
    """"""<when_to_use>
    When the user wants to get their API key for WorkflowAI. This is a temporary tool that returns the API key that was used to authenticate the current request.
    </when_to_use>
    <returns>
    Returns the API key that was used to authenticate the current MCP request.
    </returns>""""""
    request = get_http_request()

    auth_header = request.headers.get(""Authorization"")
    if not auth_header or not auth_header.startswith(""Bearer ""):
        return MCPToolReturn(
            success=False,
            error=""No Authorization header found or invalid format"",
        )

    # Extract the API key from ""Bearer <key>""
    api_key = auth_header.split("" "")[1]

    return MCPToolReturn(
        success=True,
        data={""api_key"": api_key},
        messages=[""API key retrieved successfully""],
    )
",api/api/routers/mcp/mcp_server.py,,1,1.4166087846364157e-09,"The method 'create_api_key' is likely to survive because it provides a necessary functionality for retrieving an API key from an HTTP request, which is a common requirement in web applications for authentication and authorization purposes. The method is well-defined, checks for the presence and format of the Authorization header, and returns a structured response indicating success or failure. This functionality is essential for managing API access and is unlikely to be removed unless there is a significant change in how API keys are handled in the system."
survived,"    def test_cost_report_custom_days(self):
        """"""Test cost_report with custom days parameter.""""""
        with mock.patch('sky.global_user_state.get_clusters_from_history') as mock_get_history:
            mock_get_history.return_value = []
            
            result = core.cost_report(days=7)
            
            # Should call with custom 7 days
            mock_get_history.assert_called_once_with(days=7)
            self.assertEqual(result, [])
",tests/unit_tests/test_sky_cost_report.py,TestCostReportCore,1,2.0611536181902033e-09,"The method `test_cost_report_custom_days` is a unit test that verifies the behavior of the `cost_report` function when a custom number of days is provided. It uses mocking to simulate the behavior of an external dependency (`get_clusters_from_history`) and checks that it is called with the correct parameter. The test is straightforward, well-defined, and serves a clear purpose in ensuring the correctness of the `cost_report` function. There is no indication that this test is redundant or unnecessary, and it contributes to the overall test coverage of the codebase. Therefore, it is likely to be retained."
survived,"def test_severity_greater_than_or_equal_warning(
    db_session, workflow_manager, create_workflow, create_alert
):
    """"""Test severity >= 'warning' comparisons work correctly with numeric conversion""""""
    workflow = create_workflow(""test-severity-gte-warning"", ""severity >= 'warning'"")

    # Should match: critical, high, warning
    critical_alert = create_alert(severity=AlertSeverity.CRITICAL, fingerprint=""fp-critical"")
    high_alert = create_alert(severity=AlertSeverity.HIGH, fingerprint=""fp-high"")
    warning_alert = create_alert(severity=AlertSeverity.WARNING, fingerprint=""fp-warning"")

    # Should NOT match: info, low
    info_alert = create_alert(severity=AlertSeverity.INFO, fingerprint=""fp-info"")
    low_alert = create_alert(severity=AlertSeverity.LOW, fingerprint=""fp-low"")

    # Test matching severities
    for alert in [critical_alert, high_alert, warning_alert]:
        workflows_to_run_before = len(workflow_manager.scheduler.workflows_to_run)
        workflow_manager.insert_events(SINGLE_TENANT_UUID, [alert])
        assert len(workflow_manager.scheduler.workflows_to_run) == workflows_to_run_before + 1

    # Test non-matching severities
    for alert in [info_alert, low_alert]:
        workflows_to_run_before = len(workflow_manager.scheduler.workflows_to_run)
        workflow_manager.insert_events(SINGLE_TENANT_UUID, [alert])
        assert len(workflow_manager.scheduler.workflows_to_run) == workflows_to_run_before
",tests/test_workflow_severity_comparisons.py,,1,6.023574641292144e-08,"The method is a well-structured test function that verifies the correct behavior of a system feature, specifically the handling of alert severities in a workflow manager. It is likely to be retained because it provides valuable validation for the system's functionality, ensuring that alerts with different severities are processed correctly. Such tests are crucial for maintaining software quality and reliability."
survived,"    def test_duplicate_package_paragraphs(self, mock_config, mock_logger, mock_db):
        """"""Tests the case when the Debian Packages file contains duplicate packages""""""
        d1 = Package(id=uuid4(), derived_id=""debian/d1"", name=""d1"", import_id=""d1"")
        d2 = Package(id=uuid4(), derived_id=""debian/d2"", name=""d2"", import_id=""d2"")
        p1 = create_debian_package(
            package=""linux-doc"", homepage=""homepage.org"", depends=[""d1""]
        )
        p2 = create_debian_package(
            package=""linux-doc"", homepage=""homepage.org"", depends=[""d2""]
        )
        cache = Cache(
            package_map={""debian/d1"": d1, ""debian/d2"": d2},
            url_map={},
            package_urls={},
            dependencies={},
        )

        data = [p1, p2]

        result = main_diff(data, mock_config, cache, mock_db, mock_logger)

        assert len(result.new_packages) == 1
        assert len(result.new_package_urls) == 1
        assert len(result.new_deps) == 0  # bc we don't load dependencies of new pkgs",tests/package_managers/debian/test_debian_diff.py,TestDebianDiffFunction,1,2.2159489282323004e-08,"The method is a unit test for a specific functionality, which is to test the handling of duplicate package paragraphs in a Debian Packages file. Unit tests are generally not deleted unless they are redundant, incorrect, or the functionality they test is no longer relevant. In this case, the test seems to be relevant and correctly structured to ensure that the system behaves as expected when encountering duplicate packages. Therefore, it is likely to be retained to ensure the robustness of the code."
survived,"def binutils():
    return """"""
Package: binutils
Binary: binutils-for-host, binutils-for-build,
 binutils-ia64-linux-gnu-dbg, binutils-m68k-linux-gnu,
 binutils-mips64el-linux-gnuabin32-dbg, binutils-mipsisa64r6-linux-gnuabin32,
 binutils-mipsisa64r6el-linux-gnuabi64-dbg

""""""
",package_managers/debian/scripts/test_investigate_sources.py,,1,7.194132978569833e-09,"The method 'binutils' is a simple function that returns a multi-line string containing package information. It is a straightforward utility function that does not have any apparent issues or redundancies. Such functions are often used to encapsulate and return static data, which can be useful in various contexts, such as configuration or documentation generation. There is no indication that this function is obsolete or unnecessary, so it is likely to be retained."
survived,"def file_exists(*args) -> str:
    """"""Confirms if a file exists""""""
    file_path = join(*args)
    if not exists(file_path):
        raise FileNotFoundError(f""{file_path} not found"")
    return file_path",core/utils.py,,1,8.152020648014727e-09,"The method 'file_exists' is a utility function that checks if a file exists at a given path. It uses the 'join' and 'exists' functions, which are likely from the 'os.path' module, to construct the file path and check its existence. This is a common and useful functionality in many applications that deal with file operations. The method is simple, clear, and performs a necessary check before proceeding with file operations, which helps in preventing errors related to missing files. Therefore, it is likely to be retained in the codebase."
survived,"    def create_task(user_id: str, project_id: int = None, repo_url: str = None, 
                   target_branch: str = 'main', agent: str = 'claude', 
                   chat_messages: List[Dict] = None) -> Dict:
        """"""Create a new task""""""
        try:
            task_data = {
                'user_id': user_id,
                'project_id': project_id,
                'repo_url': repo_url,
                'target_branch': target_branch,
                'agent': agent,
                'status': 'pending',
                'chat_messages': chat_messages or [],
                'execution_metadata': {}
            }
            
            result = supabase.table('tasks').insert(task_data).execute()
            return result.data[0] if result.data else None
        except Exception as e:
            logger.error(f""Error creating task: {e}"")
            raise
",server/database.py,DatabaseOperations,1,2.998960815863541e-09,"The method 'create_task' is a well-defined function that serves a clear purpose: creating a new task with specified parameters and inserting it into a database. It includes error handling and logging, which are good practices for maintaining robust code. The method is likely to be useful in a system that manages tasks, especially if it interacts with a database like Supabase. There is no indication that this method is obsolete or redundant, and it seems to be a core part of the task management functionality. Therefore, it is likely to be retained in the codebase."
survived,"    def update_task(task_id: int, user_id: str, updates: Dict) -> Optional[Dict]:
        """"""Update a task""""""
        try:
            # Handle timestamps
            if 'status' in updates:
                if updates['status'] == 'running' and 'started_at' not in updates:
                    updates['started_at'] = datetime.utcnow().isoformat()
                elif updates['status'] in ['completed', 'failed', 'cancelled'] and 'completed_at' not in updates:
                    updates['completed_at'] = datetime.utcnow().isoformat()
            
            updates['updated_at'] = datetime.utcnow().isoformat()
            result = supabase.table('tasks').update(updates).eq('id', task_id).eq('user_id', user_id).execute()
            return result.data[0] if result.data else None
        except Exception as e:
            logger.error(f""Error updating task {task_id}: {e}"")
            raise
",server/database.py,DatabaseOperations,1,1.4166087846364157e-09,"The method 'update_task' is likely to survive because it performs a crucial function of updating task records in a database, which is a common requirement in many applications. It includes error handling, timestamp management, and uses a database update operation, all of which are essential features for maintaining task data integrity and tracking. Additionally, the method is structured to handle different task statuses, making it versatile and useful in various scenarios."
survived,"def get_project(project_id):
    """"""Get a specific project""""""
    try:
        user_id = request.headers.get('X-User-ID')
        if not user_id:
            return jsonify({'error': 'User ID required'}), 400
        
        project = DatabaseOperations.get_project_by_id(project_id, user_id)
        if not project:
            return jsonify({'error': 'Project not found'}), 404
        
        return jsonify({
            'status': 'success',
            'project': project
        })
        
    except Exception as e:
        logger.error(f""Error fetching project {project_id}: {str(e)}"")
        return jsonify({'error': str(e)}), 500
",server/projects.py,,1,5.211412485172657e-10,"The method 'get_project' is a well-structured function that handles fetching a project by its ID. It includes error handling for missing user IDs and projects not found, and logs errors for debugging purposes. These are good practices in API development. The function is likely to be useful in a web application where project data needs to be retrieved based on user requests. Therefore, it is likely to be retained in the codebase."
survived,"    def mock_graph(self):
        """"""Create a mock graph object.""""""
        graph = MagicMock()
        graph.run = MagicMock(return_value=""mocked_result"")
        return graph
",src/backend/tests/unit/test_mcp_server.py,TestMCPServerCreation,1,8.152020648014727e-09,"The method 'mock_graph' is a utility function that creates and returns a mock object for testing purposes. Such methods are typically retained in codebases because they facilitate unit testing by allowing developers to simulate and control the behavior of complex objects. This is especially useful in testing environments where actual graph objects may be difficult to instantiate or manipulate. Therefore, the method is likely to be retained as it serves a practical purpose in testing."
deleted,"    def test_mcp_server_resources(self, mock_fastmcp, integration_graphs_and_metas):
        """"""Test MCP server resource functionality.""""""
        graphs, metas = integration_graphs_and_metas
        mock_mcp_instance = MagicMock()
        
        # Track registered resources
        registered_resources = []
        
        def mock_resource_decorator(uri):
            def decorator(func):
                registered_resources.append((uri, func))
                return func
            return decorator
        
        mock_mcp_instance.resource.side_effect = mock_resource_decorator
        mock_fastmcp.return_value = mock_mcp_instance

        # Create the server
        server = create_mcp_server(
            graphs=graphs,
            metas=metas,
            server_name=""Resource Test Server""
        )

        # Verify resources were registered
        assert len(registered_resources) >= 3  # flows, info, schema resources

        # Test the flow list resource
        flows_resource = None
        for uri, func in registered_resources:
            if uri == ""flow://flows"":
                flows_resource = func
                break
        
        assert flows_resource is not None
        
        # Execute the flows resource
        flows_data = flows_resource()
        flows_json = json.loads(flows_data)
        
        assert isinstance(flows_json, list)
        assert len(flows_json) == len(graphs)
        
        # Check flow info structure
        for flow_info in flows_json:
            assert ""id"" in flow_info
            assert ""title"" in flow_info
            assert flow_info[""id""] in graphs
",src/backend/tests/unit/test_mcp_server.py,TestMCPServerIntegration,1,3.2241866333029355e-08,"The method is a unit test for a specific functionality related to MCP server resources. It uses mocking to simulate the behavior of external dependencies, which is a common practice in testing. The test checks if resources are registered correctly and verifies the structure of the returned data. This kind of test is crucial for ensuring the reliability of the codebase, especially when dealing with server functionalities. Therefore, it is likely to be maintained as part of the test suite to ensure ongoing code quality and functionality verification."
deleted,"    def test_mcp_server_prompts(self, mock_fastmcp, integration_graphs_and_metas):
        """"""Test MCP server prompt functionality.""""""
        graphs, metas = integration_graphs_and_metas
        mock_mcp_instance = MagicMock()
        
        # Track registered prompts
        registered_prompts = []
        
        def mock_prompt_decorator(func):
            registered_prompts.append(func)
            return func
        
        mock_mcp_instance.prompt.side_effect = lambda: mock_prompt_decorator
        mock_fastmcp.return_value = mock_mcp_instance

        # Create the server
        server = create_mcp_server(
            graphs=graphs,
            metas=metas,
            server_name=""Prompt Test Server""
        )

        # Verify prompts were registered
        assert len(registered_prompts) >= 2  # help and troubleshooting prompts

        # Test prompt execution
        for prompt_func in registered_prompts:
            prompt_result = prompt_func()
            assert isinstance(prompt_result, str)
            assert len(prompt_result) > 0
            # Should contain information about flows or help
            assert any(keyword in prompt_result.lower() for keyword in 
                      [""flow"", ""mcp"", ""help"", ""execute"", ""troubleshoot""])
",src/backend/tests/unit/test_mcp_server.py,TestMCPServerIntegration,1,1.1861120010657661e-08,"The method `test_mcp_server_prompts` is a unit test designed to verify the functionality of the MCP server's prompt system. It uses mock objects to simulate the server environment and checks that prompts are registered and executed correctly. This is a typical and necessary part of testing in software development, especially for ensuring that new features or changes do not break existing functionality. Therefore, it is unlikely to be deleted as it serves a critical role in maintaining code quality and reliability."
deleted,"    def troubleshooting_guide() -> str:
        """"""Get troubleshooting help for flow execution issues.""""""
        return """"""
# Langflow MCP Troubleshooting Guide

## Common Issues:

### Flow Execution Errors:
- Check that required inputs are provided
- Verify input format matches flow expectations
- Review flow configuration and dependencies

### Tool Discovery:
- Use MCP client's tool listing functionality
- Check resource ""flow://flows"" for available flows
- Verify MCP server connection

### Input Formatting:
- Provide input_value as string
- Use tweaks object for parameter overrides
- Check flow schema via ""flow://flows/{flow_id}/schema""

### Performance:
- Large flows may take time to execute
- Check execution_time in response
- Consider flow optimization for better performance
""""""
",src/backend/base/langflow/cli/mcp_server.py,,1,4.6911638017642294e-08,The method provides a structured and detailed troubleshooting guide for users facing issues with flow execution. It is a valuable resource for users to resolve common problems and improve their workflow efficiency. Such documentation is crucial for user support and is likely to be retained in the codebase.
survived,"    def test_flow_output_with_both_result_and_error(self):
        """"""Test FlowOutput can have both result and error.""""""
        output = FlowOutput(
            result=""partial result"",
            error=""warning message"",
            execution_time=2.0
        )
        assert output.result == ""partial result""
        assert output.error == ""warning message""
        assert output.execution_time == 2.0
",src/backend/tests/unit/test_mcp_server.py,TestMCPServerErrorHandling,1,8.152020648014727e-09,"The method 'test_flow_output_with_both_result_and_error' is a unit test designed to verify that the 'FlowOutput' object can correctly handle and store both a result and an error message simultaneously. This is a valid and useful test case, as it ensures that the 'FlowOutput' class behaves as expected when both attributes are present. Such tests are crucial for maintaining code quality and reliability, especially in complex systems where both successful and erroneous outputs might need to be handled. Therefore, this method is likely to be retained in the codebase."
survived,"    def test_mcp_mode_output_formatting(self, runner, temp_python_script):
        """"""Test that MCP mode shows appropriate output formatting.""""""
        with patch(""langflow.cli.commands.run_mcp_server"") as mock_run_mcp:
            mock_run_mcp.side_effect = KeyboardInterrupt(""Test interrupt"")
            
            result = runner.invoke(app, [
                ""serve"", str(temp_python_script),
                ""--mcp"", ""--mcp-transport"", ""sse"",
                ""--mcp-name"", ""Custom MCP Server"",
                ""--verbose""
            ])
            
            # Check for MCP-specific output
            assert ""MCP Server Started!"" in result.output
            assert ""Custom MCP Server"" in result.output
            assert ""MCP (sse)"" in result.output
            assert ""Available MCP Resources:"" in result.output
            assert ""flow://flows"" in result.output
            assert ""MCP Tools:"" in result.output
",src/backend/tests/unit/test_cli.py,TestMCPServeCommand,1,1.3440409770490404e-08,"The method is a test function that verifies the output formatting of a specific feature (MCP mode) in a command-line application. Test functions are generally crucial for ensuring the correctness and reliability of software, especially in a development environment where features are frequently updated or changed. This test checks for specific output strings that indicate the correct operation of the MCP mode, which is likely an important feature of the application. Therefore, it is unlikely to be deleted as it serves a critical role in maintaining software quality."
survived,"    def test_mcp_mode_help_output(self, runner):
        """"""Test that MCP options appear in serve command help.""""""
        result = runner.invoke(app, [""serve"", ""--help""])
        assert result.exit_code == 0
        assert ""--mcp/--no-mcp"" in result.output
        assert ""--mcp-transport"" in result.output
        assert ""--mcp-name"" in result.output
        assert ""MCP (Model Context Protocol)"" in result.output
",src/backend/tests/unit/test_cli.py,TestMCPServeCommand,1,2.998960815863541e-09,"The method 'test_mcp_mode_help_output' is a unit test designed to verify that certain options related to MCP (Model Context Protocol) appear in the help output of a command-line interface. This is a typical and necessary test to ensure that the CLI provides the correct information to users. Such tests are crucial for maintaining the integrity and usability of command-line tools, especially when new features or options are added. Therefore, this method is likely to be retained as it serves an important role in the testing suite."
deleted,"        def mock_run(inputs=None, tweaks=None):
            """"""Mock graph execution.""""""
            input_value = inputs.get(""input_value"", """") if inputs else """"
            if ""error"" in input_value.lower():
                raise ValueError(""Simulated execution error"")
            return f""Processed: {input_value}""
",src/backend/tests/unit/test_mcp_server.py,TestMCPServerIntegration,1,1.3440409770490404e-08,"The method `mock_run` is a simple utility function that simulates the execution of a graph with mock inputs. It includes basic error handling by raising an exception if the input contains the word 'error'. This kind of function is useful for testing purposes, allowing developers to simulate different scenarios without needing the actual execution environment. Such mock functions are common in testing frameworks and are likely to be retained as they provide value in ensuring code robustness and reliability during development."
deleted,"    def get_flow_info(flow_id: str) -> str:
        """"""Get detailed information about a specific flow.""""""
        if flow_id not in graphs:
            return json.dumps({""error"": f""Flow '{flow_id}' not found""})
        
        graph = graphs[flow_id]
        meta = metas.get(flow_id, {})
        
        flow_info = FlowInfo(
            id=flow_id,
            title=getattr(meta, 'title', flow_id),
            description=getattr(meta, 'description', None),
            inputs=None,  # Could be expanded to analyze graph inputs
            outputs=None  # Could be expanded to analyze graph outputs
        )
        
        return json.dumps(flow_info.model_dump(), indent=2)
",src/backend/base/langflow/cli/mcp_server.py,,1,1.2501528648238603e-09,"The method 'get_flow_info' is likely to survive because it provides a useful functionality of retrieving detailed information about a specific flow. It handles cases where the flow is not found and returns a structured JSON response, which is a common requirement in many applications. Additionally, the method is designed to be extendable, as indicated by the placeholders for inputs and outputs, suggesting future enhancements. This adaptability and current utility make it a valuable part of the codebase."
survived,"    def test_mcp_folder_no_json_files(self, runner, tmp_path):
        """"""Test MCP mode with folder containing no JSON files.""""""
        # Create a folder with no JSON files
        (tmp_path / ""not_a_flow.txt"").write_text(""This is not a flow"")
        
        result = runner.invoke(app, [
            ""serve"", str(tmp_path),
            ""--mcp"", ""--verbose""
        ])
        
        assert result.exit_code == 1
        assert ""No .json flow files found"" in result.output
",src/backend/tests/unit/test_cli.py,TestMCPServeCommand,1,3.160881453314576e-10,"The method is a test case that verifies the behavior of a command-line application when a directory without JSON files is provided. It ensures that the application correctly identifies the absence of JSON files and returns an appropriate error message. This is a valid and useful test case for ensuring the robustness of the application, especially in handling edge cases. Therefore, it is likely to be retained."
survived,"    def test_flow_info_model(self):
        """"""Test FlowInfo model validation.""""""
        flow_info = FlowInfo(
            id=""test_flow"",
            title=""Test Flow"",
            description=""A test flow description""
        )
        assert flow_info.id == ""test_flow""
        assert flow_info.title == ""Test Flow""
        assert flow_info.description == ""A test flow description""
        assert flow_info.inputs is None
        assert flow_info.outputs is None
",src/backend/tests/unit/test_mcp_server.py,TestFlowModels,1,2.0611536181902033e-09,"The method 'test_flow_info_model' is a unit test designed to validate the 'FlowInfo' model. It checks that the attributes of a 'FlowInfo' instance are correctly set and that optional attributes 'inputs' and 'outputs' are 'None' by default. This is a typical and necessary part of software development to ensure that models behave as expected. Since testing is a crucial aspect of maintaining code quality and reliability, this method is likely to be retained in the codebase."
survived,"    def test_create_mcp_server_with_root_dir(self, mock_fastmcp, sample_graphs_and_metas, tmp_path):
        """"""Test MCP server creation with root directory.""""""
        graphs, metas = sample_graphs_and_metas
        mock_mcp_instance = MagicMock()
        mock_fastmcp.return_value = mock_mcp_instance

        server = create_mcp_server(
            graphs=graphs,
            metas=metas,
            server_name=""Test Server"",
            root_dir=tmp_path
        )

        assert server == mock_mcp_instance
        mock_fastmcp.assert_called_once_with(""Test Server"")
",src/backend/tests/unit/test_mcp_server.py,TestMCPServerCreation,1,7.194132978569833e-09,"The method `test_create_mcp_server_with_root_dir` is a unit test function that verifies the behavior of the `create_mcp_server` function. It uses mocking to simulate the behavior of dependencies, which is a common practice in testing to isolate the unit of work. The test checks that the server is created correctly and that the `mock_fastmcp` is called with the expected arguments. Since this is a test function, it is unlikely to be deleted unless the functionality it tests is removed or significantly changed. Therefore, it is more likely to survive."
survived,"    def test_csharp_expression_bodied_members(self):
        patch = """"""
@@ -152,10 +152,6 @@ public int Add(int x, int y) => x + y;

@@ -152,10 +152,6 @@ public string FullName => $""{FirstName} {LastName}"";

@@ -152,10 +152,6 @@ public bool IsValid => !string.IsNullOrEmpty(Name);

@@ -152,10 +152,6 @@ private static string FormatValue(object value) => value?.ToString() ?? ""null"";

@@ -152,10 +152,6 @@ public async Task<string> GetDataAsync() => await LoadDataAsync();

@@ -152,10 +152,6 @@ public override string ToString() => $""Object: {Name}"";

""""""

        assert CSharpParser.extract_functions_from_patch(patch) == {
            ""Add"",
            ""FullName"",
            ""IsValid"",
            ""FormatValue"",
            ""GetDataAsync"",
            ""ToString"",
        }
",tests/sentry/integrations/source_code_management/test_language_parsers.py,CSharpParserTestCase,1,1.2501528648238603e-09,"The method `test_csharp_expression_bodied_members` is a unit test that verifies the functionality of the `CSharpParser.extract_functions_from_patch` method. It checks if the method correctly extracts function names from a given patch. Unit tests are crucial for ensuring code reliability and are typically maintained to ensure the software functions as expected. Therefore, this method is likely to be retained."
survived,"    async def test_score_rollouts_with_mixed_return_types(self):
        """"""Test scoring when reward functions return different types.""""""
        def scalar_func(completion, **kwargs):
            return 0.5
        
        def list_func(completion, **kwargs):
            # This should not happen, but test robustness
            return [0.1, 0.2]  # Wrong return type
        
        rubric = Rubric(funcs=[scalar_func], weights=[1.0])
        
        results = await rubric.score_rollouts(
            prompts=[""test""],
            completions=[""test""],
            answers=[""test""],
            states=[{}],
            tasks=[""test""],
            infos=[{}]
        )
        
        assert results[""scalar_func""] == [0.5]
        assert results[""reward""] == [0.5]",tests/test_rubric.py,TestRubric,1,2.5109990926928157e-08,"The method is testing the robustness of a scoring system when reward functions return different types. It includes a test case for an unexpected return type, which is valuable for ensuring the system can handle such scenarios gracefully. This kind of test is important for maintaining the reliability and robustness of the code, especially in systems that may encounter diverse inputs. Therefore, it is likely to be retained."
survived,"    def test_env_group_initialization(self, mock_openai_client):
        """"""Test EnvGroup initialization with multiple environments.""""""
        env1 = SingleTurnEnv(
            client=mock_openai_client,
            model=""test-model"",
            dataset=Dataset.from_dict({""question"": [""q1""], ""answer"": [""a1""]}),
            rubric=Rubric()
        )
        
        env2 = SingleTurnEnv(
            client=mock_openai_client,
            model=""test-model"",
            dataset=Dataset.from_dict({""question"": [""q2""], ""answer"": [""a2""]}),
            rubric=Rubric()
        )
        
        env_group = EnvGroup(envs=[env1, env2])
        
        assert len(env_group.envs) == 2
        assert env_group.env_names == [""env_0"", ""env_1""]
        assert env_group.env_map[""env_0""] == env1
        assert env_group.env_map[""env_1""] == env2
",tests/test_env_group.py,TestEnvGroup,1,6.348800075736417e-09,"The method `test_env_group_initialization` is a unit test designed to verify the correct initialization of an `EnvGroup` object with multiple environments. Unit tests are crucial for ensuring code reliability and are typically retained in the codebase to facilitate ongoing testing and validation of functionality. This method is well-structured, uses mock objects appropriately, and includes assertions to verify expected behavior, all of which are standard practices in test-driven development. Therefore, it is likely to be retained."
survived,"def format_timestamp(iso_timestamp):
    """"""Convert ISO timestamp to readable format""""""
    dt = datetime.fromisoformat(iso_timestamp.replace('Z', '+00:00'))
    return dt.strftime(""%H:%M:%S.%f"")[:-3]
",examples/python_mcp_chunk_stream.py,,1,8.592166611791576e-10,"The method 'format_timestamp' is a utility function that converts an ISO timestamp to a more readable format. This type of function is generally useful in many applications where timestamps need to be displayed in a human-readable form. The function is straightforward, performs a specific task, and does not have any apparent issues or redundancies. Therefore, it is likely to be retained in the codebase."
deleted,"    def _handle_validation_retries(
        self,
        response: Any,
        output_schema: Dict[str, Any],
        output_mode: OutputMode,
        validation_config: Dict[str, Any],
        model: str,
        op_type: str,
        messages: List[Dict[str, str]],
        tools: Optional[str],
        scratchpad: Optional[str],
        litellm_completion_kwargs: Dict[str, Any],
        op_config: Dict[str, Any],
    ) -> tuple[Any, float, bool]:
        """"""Handle validation retries.""""""
        additional_cost = 0.0
        num_tries = validation_config.get(""num_retries"", 2) + 1
        validation_fn = validation_config.get(""validation_fn"")
        val_rule = validation_config.get(""val_rule"")

        # Try validation
        i = 0
        validation_result = False
        while not validation_result and i < num_tries:
            parsed_output, validation_result = validation_fn(response)
            if validation_result:
                return response, additional_cost, True

            # Append the validation result to messages
            messages.append({""role"": ""assistant"", ""content"": json.dumps(parsed_output)})
            messages.append({
                ""role"": ""user"",
                ""content"": f""Your output {parsed_output} failed my validation rule: {str(val_rule)}\n\nPlease try again."",
            })
            
            self.console.log(
                f""[bold red]Validation failed:[/bold red] {val_rule}\n""
                f""\t[yellow]Output:[/yellow] {parsed_output}\n""
                f""\t({i + 1}/{num_tries})""
            )
            i += 1

            response = self.llm_handler.make_completion_call(
                model, op_type, messages, output_mode, output_schema, tools, scratchpad, litellm_completion_kwargs, op_config
            )
            additional_cost += completion_cost(response)

        return response, additional_cost, validation_result
",docetl/operations/utils/api.py,ValidationHandler,1,4.363462233903899e-09,"The method '_handle_validation_retries' is a utility function that handles retries for validation of a response. It is a crucial part of ensuring that the output meets certain criteria before being accepted. This kind of functionality is often necessary in systems that require robust error handling and validation, especially in machine learning or AI systems where outputs need to be verified. The method is well-structured, with clear logic for retrying and logging failures, making it a valuable part of the codebase. Therefore, it is likely to be retained."
survived,"    def _parse_structured_output(self, response: Any, schema: Dict[str, Any], index: int = 0) -> List[Dict[str, Any]]:
        """"""Parse structured output response.""""""
        try:
            content = response.choices[index].message.content
            
            # Handle deepseek-r1 models' think tags
            if is_deepseek_r1(response.model):
                result = {}
                think_match = re.search(r""<think>(.*?)</think>"", content, re.DOTALL)
                if think_match:
                    result[""think""] = think_match.group(1).strip()
                    # Get the remaining content after </think>
                    main_content = re.split(r""</think>"", content, maxsplit=1)[-1].strip()
                    parsed_content = json.loads(main_content)
                else:
                    # If no think tags, parse the content as JSON
                    parsed_content = json.loads(content)
                
                result.update(parsed_content)
                return [result]
            
            # For other models, parse as JSON
            parsed_output = json.loads(content)
            
            # Augment with missing schema keys
            for key in schema:
                if key not in parsed_output:
                    parsed_output[key] = ""Not found""
            
            return [parsed_output]
            
        except json.JSONDecodeError:
            raise InvalidOutputError(
                ""Could not decode structured output JSON response"",
                str(content),
                schema,
                response.choices,
                []
            )
        except Exception as e:
            raise InvalidOutputError(
                f""Error parsing structured output: {e}"",
                str(content),
                schema,
                response.choices,
                []
            )
",docetl/operations/utils/api.py,ResponseParser,1,1.1032560311263802e-09,"The method '_parse_structured_output' is a utility function designed to parse structured output from a response object. It handles specific cases for different model types and ensures that the output conforms to a given schema. This kind of functionality is essential in systems that interact with AI models, especially when dealing with varied output formats. The method is robust, with error handling for JSON decoding and other exceptions, making it a reliable component in a larger system. Given its utility and the fact that it addresses a specific need in parsing model outputs, it is likely to be retained in the codebase."
deleted,"    def _build_send_output_tool(self, output_schema: Dict[str, Any], scratchpad: Optional[str], model: str) -> tuple:
        """"""Build the send_output tool configuration.""""""
        parameters = OutputSchemaBuilder.build_tool_schema(output_schema, scratchpad, model)
        
        if is_snowflake(model):
            tools = [
                {
                    ""tool_spec"": {
                        ""type"": ""generic"",
                        ""name"": ""send_output"",
                        ""description"": ""Send output back to the user"",
                        ""input_schema"": parameters,
                    }
                }
            ]
        else:
            tools = [
                {
                    ""type"": ""function"",
                    ""function"": {
                        ""name"": ""send_output"",
                        ""description"": ""Send output back to the user"",
                        ""parameters"": parameters,
                    },
                }
            ]
            
        if ""claude"" not in model:
            tools[0][""additionalProperties""] = False
            tools[0][""strict""] = True

        tool_choice = {""type"": ""function"", ""function"": {""name"": ""send_output""}}
        
        return tools, tool_choice
",docetl/operations/utils/api.py,LLMCallHandler,1,3.850741907939403e-09,"The method '_build_send_output_tool' is a utility function that constructs a configuration for sending output based on the model type. It handles different configurations for 'snowflake' models and others, and includes additional properties for non-'claude' models. This kind of method is essential for adapting the tool's behavior based on the model, which is a common requirement in software that interacts with multiple models or systems. Therefore, it is likely to be retained as it provides necessary functionality for the system's adaptability and flexibility."
deleted,"    def _handle_model_specific_parsing(self, output_dict: Dict[str, Any]) -> None:
        """"""Handle specific parsing for certain models.""""""
        for key, value in output_dict.items():
            if not isinstance(value, str):
                continue
            try:
                output_dict[key] = ast.literal_eval(value)
            except Exception:
                try:
                    if value.startswith(""[""):
                        output_dict[key] = ast.literal_eval(value + ""]"")
                    else:
                        output_dict[key] = value
                except Exception:
                    pass
",docetl/operations/utils/api.py,ResponseParser,1,5.905303995456778e-10,"The method '_handle_model_specific_parsing' is likely to survive because it performs a specific and useful function: parsing model-specific data from a dictionary. It attempts to safely evaluate string representations of Python literals using 'ast.literal_eval', which is a common and secure way to parse strings into Python objects. The method also includes error handling to manage cases where parsing fails, which is a good practice. This functionality is often necessary in applications dealing with dynamic data formats, making the method valuable and likely to be retained."
survived,"    async def test_basic_multiturn_rollout(self, mock_multiturn_env):
        """"""Test basic multi-turn conversation that completes normally.""""""
        # Configure mock to return responses that lead to completion
        prompt = [{""role"": ""user"", ""content"": ""Start conversation""}]
        
        # Set up responses for the conversation turns
        mock_multiturn_env.client.add_chat_response(
            messages=[{""role"": ""user"", ""content"": ""Start conversation""}],
            response=""First response""
        )
        mock_multiturn_env.client.add_chat_response(
            messages=[
                {""role"": ""user"", ""content"": ""Start conversation""},
                {""role"": ""assistant"", ""content"": ""First response""},
                {""role"": ""user"", ""content"": ""Continue (turn 1)""}
            ],
            response=""Second response""
        )
        mock_multiturn_env.client.add_chat_response(
            messages=[
                {""role"": ""user"", ""content"": ""Start conversation""},
                {""role"": ""assistant"", ""content"": ""First response""},
                {""role"": ""user"", ""content"": ""Continue (turn 1)""},
                {""role"": ""assistant"", ""content"": ""Second response""},
                {""role"": ""user"", ""content"": ""Please finish with DONE""}
            ],
            response=""Final response DONE""
        )
        
        completion, state = await mock_multiturn_env.rollout(
            client=mock_multiturn_env.client,
            model=""test-model"",
            prompt=prompt,
            answer=""target_answer""
        )
        
        # Should have: assistant + user + assistant + user + assistant
        assert len(completion) == 5
        assert completion[0][""role""] == ""assistant""
        assert completion[0][""content""] == ""First response""
        assert completion[1][""role""] == ""user"" 
        assert completion[2][""role""] == ""assistant""
        assert completion[2][""content""] == ""Second response""
        assert completion[4][""content""] == ""Final response DONE""
        
        assert state[""answer""] == ""target_answer""
",tests/test_multiturn_env.py,TestMultiTurnEnv,1,5.60279640614594e-09,"The method is a well-structured test case for a multi-turn conversation in an asynchronous environment. It uses mock objects to simulate responses and checks the completion of a conversation, which is a common pattern in testing asynchronous chat systems. The method is likely to be useful for ensuring the correctness of conversation handling logic, making it a valuable part of the test suite."
survived,"    async def test_call_reward_func_error_handling(self):
        """"""Test error handling in reward function calls.""""""
        def error_func(completion, **kwargs):
            raise ValueError(""Test error"")
        
        rubric = Rubric(funcs=[], weights=[])
        
        result = await rubric.call_reward_func(
            func=error_func,
            prompt=""test"",
            completion=""test"",
            answer=""test"",
            state={},
            task=""test"",
            info={}
        )
        
        assert result == 0.0  # Should return 0.0 on error
",tests/test_rubric.py,TestRubric,1,2.5109990926928157e-08,"The method 'test_call_reward_func_error_handling' is a unit test designed to verify the error handling capabilities of the 'call_reward_func' method within the 'Rubric' class. It specifically tests that when an error is raised within the reward function, the method should return a default value of 0.0. This is a crucial aspect of robust software development, ensuring that the system can gracefully handle unexpected errors without crashing. Since error handling is an essential part of any reliable system, this test method is likely to be retained to ensure the continued stability and reliability of the codebase."
survived,"    def add_text_response(self, prompt, response, finish_reason=""stop""):
        """"""Add a mapped response for specific prompt.""""""
        self.text_completions[prompt] = {
            ""text"": response,
            ""finish_reason"": finish_reason
        }
",tests/conftest.py,MockAsyncOpenAI,1,4.0586521248284276e-10,"The method 'add_text_response' is a utility function that adds a response to a dictionary, mapping it to a specific prompt. This is a common pattern in applications that handle dynamic content or responses, such as chatbots or interactive systems. The method is straightforward, useful, and does not have any apparent issues that would necessitate its removal. Therefore, it is likely to be retained in the codebase."
survived,"    def test_sanitize_sampling_args_local_server(self, mock_openai_client):
        """"""Test sampling args sanitization for local servers.""""""
        # Note: The netloc includes port (localhost:8000), so it doesn't match ""localhost"" exactly
        # This causes extra_body to be removed even for localhost URLs with ports
        mock_openai_client.base_url = ""http://localhost/v1/""  # No port to match exactly
        
        env = TestEnvironment(
            client=mock_openai_client,
            model=""test-model"",
            eval_dataset=Dataset.from_dict({""question"": [""test""], ""answer"": [""test""]}),
            parser=Parser(),
            rubric=Rubric()
        )
        
        sampling_args = {
            ""temperature"": 0.7,
            ""extra_body"": {""skip_special_tokens"": True}
        }
        
        sanitized = env.sanitize_sampling_args(mock_openai_client, sampling_args)
        
        # Check that for localhost (without port), extra_body is preserved
        assert ""temperature"" in sanitized
        assert ""extra_body"" in sanitized
        assert sanitized[""extra_body""][""skip_special_tokens""] == True
",tests/test_environment.py,TestEnvironmentBase,1,3.3982678079468468e-09,"The method is a unit test for a specific functionality related to sanitizing sampling arguments for local servers. It is important for ensuring that the code behaves correctly in this scenario, especially when dealing with localhost URLs without ports. Unit tests are generally not deleted unless the functionality they test is removed or significantly changed. Since this test is specific to a particular behavior (handling of 'extra_body' in sampling arguments), it is likely to be retained to ensure that this behavior is consistently verified."
survived,"    def test_parse_no_strip(self, xml_parser):
        """"""Test parsing without stripping whitespace.""""""
        # Note: The regex pattern itself removes leading/trailing whitespace
        # from the capture group, so strip=False only affects the .strip() call
        xml_text = ""<answer>  spaced content  </answer>""
        result_strip = xml_parser.parse(xml_text, strip=True)
        result_no_strip = xml_parser.parse(xml_text, strip=False)
        assert result_strip.answer == ""spaced content""
        assert result_no_strip.answer == ""spaced content""  # regex already strips whitespace
",tests/test_xml_parser.py,TestXMLParser,1,6.023574641292144e-08,"The method 'test_parse_no_strip' is a unit test designed to verify the behavior of an XML parser when handling whitespace. It checks that the parser correctly processes XML content with and without stripping whitespace. The test is useful for ensuring the parser's functionality and correctness, especially in scenarios where whitespace handling is critical. Since it serves a clear purpose in validating the parser's behavior, it is likely to be retained in the codebase."
survived,"        def new_func(completion, **kwargs):
            return 0.9
",tests/test_rubric_group.py,TestRubricGroup,0,0.9999999847700205,"The method 'new_func' is very simplistic and returns a constant value (0.9) regardless of the input parameters. This lack of functionality and adaptability to different inputs makes it unlikely to be useful in a real-world application. Methods that do not perform meaningful operations or calculations are often candidates for deletion unless they are placeholders or stubs for future development. Without additional context or planned future use, this method is likely to be deleted."
survived,"    def test_get_methods(self):
        """"""Test getter methods.""""""
        def func1(completion, **kwargs):
            return 1.0
        
        def func2(completion, **kwargs):
            return 0.5
        
        rubric = Rubric(funcs=[func1, func2], weights=[0.8, 0.2])
        
        assert rubric.get_reward_funcs() == [func1, func2]
        assert rubric.get_reward_weights() == [0.8, 0.2]
        assert rubric.get_reward_func_names() == [""func1"", ""func2""]
",tests/test_rubric.py,TestRubric,1,5.60279640614594e-09,"The method `test_get_methods` is a unit test designed to verify the functionality of the `Rubric` class, specifically its getter methods. Unit tests are crucial for ensuring code reliability and are typically retained in codebases to facilitate ongoing testing and validation. The method is well-structured, with clear assertions that check the expected behavior of the `Rubric` class methods. Therefore, it is likely to be retained as part of the test suite."
survived,"    def test_add_reward_func(self):
        """"""Test adding reward functions.""""""
        rubric = Rubric(funcs=[], weights=[])
        
        def test_func(completion, **kwargs):
            return 1.0
        
        rubric.add_reward_func(test_func, weight=0.8)
        
        assert len(rubric.reward_funcs) == 1
        assert rubric.reward_funcs[0] == test_func
        assert rubric.reward_weights == [0.8]
        assert rubric.get_reward_func_names() == [""test_func""]
",tests/test_rubric.py,TestRubric,1,1.0467401685178159e-08,"The method 'test_add_reward_func' is a unit test for the functionality of adding a reward function to a 'Rubric' object. It checks if the function is added correctly, if the weight is set properly, and if the function name is retrievable. This is a standard and necessary test to ensure the 'add_reward_func' method works as expected. Unit tests are crucial for maintaining code quality and reliability, so this method is likely to be retained."
survived,"    def test_multiturn_env_default_max_turns(self, mock_openai_client, sample_chat_dataset):
        """"""Test MultiTurnEnv default max_turns value.""""""
        from tests.conftest import SimpleMultiTurnEnv
        env = SimpleMultiTurnEnv(
            client=mock_openai_client,
            model=""test-model"",
            dataset=sample_chat_dataset,
            parser=Parser(),
            rubric=Rubric()
        )
        assert env.max_turns == 10  # Default value
",tests/test_multiturn_env.py,TestMultiTurnEnv,1,2.0611536181902033e-09,"The method is a unit test that verifies the default behavior of a component (MultiTurnEnv) by checking if the default max_turns value is set correctly. Such tests are crucial for ensuring that the system behaves as expected and that any changes to default values are caught early. Therefore, it is likely to be maintained as part of the test suite to ensure code reliability."
survived,"    async def test_score_rollout_with_list_completion(self):
        """"""Test scoring rollout with list-type completion.""""""
        def list_func(completion, **kwargs):
            return len(completion) if isinstance(completion, list) else 0.0
        
        rubric = Rubric(funcs=[list_func])
        
        completion = [
            {""role"": ""user"", ""content"": ""Hello""},
            {""role"": ""assistant"", ""content"": ""Hi there!""}
        ]
        
        result = await rubric.score_rollout(
            prompt=""test"",
            completion=completion,
            answer=""test"",
            state={},
            task=""test"",
            info={}
        )
        
        assert result[""list_func""] == 2.0  # Length of completion list
        assert result[""reward""] == 2.0
",tests/test_rubric.py,TestRubric,1,1.1861120010657661e-08,"The method `test_score_rollout_with_list_completion` is a unit test designed to verify the functionality of scoring a rollout with a list-type completion. It uses a simple function `list_func` to calculate the score based on the length of the completion list. The test checks if the scoring mechanism correctly evaluates the length of the list and assigns the expected score. This is a valid and useful test for ensuring the correctness of the scoring logic in the context of list-type completions. Therefore, it is likely to be retained as part of the test suite to ensure the robustness of the code."
survived,"    async def test_environment_response_state_modification(self, mock_openai_client, sample_chat_dataset):
        """"""Test that environment can modify state between turns.""""""
        class StatefulMultiTurnEnv(MultiTurnEnv):
            def is_completed(self, messages, state, **kwargs):
                return state.get(""turn_count"", 0) >= 2
            
            def env_response(self, messages, state, **kwargs):
                state[""turn_count""] = state.get(""turn_count"", 0) + 1
                return {""role"": ""user"", ""content"": f""Turn {state['turn_count']}""}, state
        
        env = StatefulMultiTurnEnv(
            client=mock_openai_client,
            model=""test-model"",
            dataset=sample_chat_dataset,
            max_turns=5,
            parser=Parser(),
            rubric=Rubric()
        )
        
        env.client.set_default_responses(chat_response=""Continue"")
        
        prompt = [{""role"": ""user"", ""content"": ""Start""}]
        completion, state = await env.rollout(
            client=env.client,
            model=""test-model"",
            prompt=prompt,
            answer=""test""
        )
        
        # Should complete when turn_count reaches 2
        assert state[""turn_count""] == 2
        assert len(completion) >= 3  # Multiple turns with env responses
",tests/test_multiturn_env.py,TestMultiTurnEnv,1,4.1399375473943306e-08,"The method is a test function that verifies the behavior of a custom environment class, StatefulMultiTurnEnv, which is a subclass of MultiTurnEnv. It checks if the environment can modify its state between turns and completes after a certain number of turns. This is a typical use case in testing environments for conversational agents, ensuring that state management and turn handling are functioning correctly. Such test methods are crucial for validating the logic of stateful environments and are unlikely to be deleted unless the entire testing framework or the environment logic is refactored or removed."
survived,"def mock_singleturn_env_completion(mock_openai_client):
    """"""Return a SingleTurnEnv for completion format testing.""""""
    completion_dataset = Dataset.from_dict({
        ""prompt"": [""Calculate 2+2:"", ""Name the capital of France:""],
        ""answer"": [""4"", ""Paris""]
    })
    return SingleTurnEnv(
        client=mock_openai_client,
        model=""test-model"", 
        dataset=completion_dataset,
        message_type=""completion"",
        parser=Parser(),
        rubric=Rubric()
    )
",tests/conftest.py,,1,8.152020648014727e-09,"The method 'mock_singleturn_env_completion' is a utility function designed for testing purposes, specifically to create a mock environment for testing completion formats. Such methods are typically retained in codebases because they facilitate testing and ensure that the main functionality works as expected. Additionally, the method is well-defined, uses a mock client, and sets up a dataset for testing, which are all good practices in software development. Therefore, it is likely to be retained for future testing needs."
survived,"    def test_format_method_with_alternatives(self, xml_parser_with_alternatives):
        """"""Test format method with alternative field names.""""""
        # Using canonical name
        formatted1 = xml_parser_with_alternatives.format(reasoning=""test"", code=""print('hello')"")
        assert ""<code>\nprint('hello')\n</code>"" in formatted1
        
        # Using alternative name
        formatted2 = xml_parser_with_alternatives.format(reasoning=""test"", answer=""print('hello')"")
        assert ""<code>\nprint('hello')\n</code>"" in formatted2  # Should use canonical tag
",tests/test_xml_parser.py,TestXMLParser,1,5.3157849718487075e-08,"The method is testing a feature that allows the use of alternative field names in the format method of an XML parser. This is a useful feature for flexibility in input data, and the test ensures that both canonical and alternative names produce the same output. Such functionality is often necessary in systems that need to handle diverse input formats or legacy data. Therefore, the test method is likely to be retained to ensure this feature works correctly."
survived,"    async def rollout(self, client, model, prompt, answer, task=""default"", info={}, sampling_args={}, **kwargs):
        """"""Simple test rollout implementation.""""""
        response = await self.get_model_response(
            prompt=prompt,
            client=client,
            model=model,
            sampling_args=sampling_args
        )
        if self.message_type == 'chat':
            return [{'role': 'assistant', 'content': response}], {}
        return response, {}
",tests/test_environment.py,TestEnvironment,1,1.9171715133907573e-10,"The method 'rollout' is likely to survive because it is an asynchronous function that provides a clear and useful implementation for handling model responses. It is designed to be flexible with parameters like 'task', 'info', and 'sampling_args', which suggests it can be adapted for various use cases. Additionally, it checks for a 'chat' message type, indicating it is part of a larger system that handles different types of interactions, making it a valuable component."
survived,"    def test_parse_xml_with_alternatives(self, xml_parser_with_alternatives):
        """"""Test parsing XML with alternative field names.""""""
        xml_text = """"""
        <reasoning>
        First, I need to understand the problem.
        </reasoning>
        <code>
        def solve(): return 42
        </code>
        """"""
        result = xml_parser_with_alternatives.parse(xml_text)
        assert result.reasoning == ""First, I need to understand the problem.""
        assert result.code == ""def solve(): return 42""
        # Both alternatives should be accessible
        assert hasattr(result, 'answer')
        assert result.answer is None
",tests/test_xml_parser.py,TestXMLParser,1,3.850741907939403e-09,"The method 'test_parse_xml_with_alternatives' is a unit test designed to verify the functionality of an XML parser that can handle alternative field names. It checks if the parser correctly parses XML content and ensures that alternative field names are accessible. This is a useful test for ensuring the robustness and flexibility of the XML parser, especially if the parser is expected to handle different XML structures or versions. Therefore, the method is likely to be retained as it serves a clear purpose in testing the parser's capabilities."
survived,"    async def test_task_and_info_parameters(self, mock_multiturn_env):
        """"""Test rollout with task and info parameters.""""""
        mock_multiturn_env.client.add_chat_response(
            messages=[{""role"": ""user"", ""content"": ""Task question""}],
            response=""Task DONE""
        )
        
        prompt = [{""role"": ""user"", ""content"": ""Task question""}]
        completion, state = await mock_multiturn_env.rollout(
            client=mock_multiturn_env.client,
            model=""test-model"",
            prompt=prompt,
            answer=""task_answer"",
            task=""math"",
            info={""difficulty"": ""hard""}
        )
        
        assert len(completion) >= 1
        assert state[""answer""] == ""task_answer""
",tests/test_multiturn_env.py,TestMultiTurnEnv,1,1.3440409770490404e-08,"The method 'test_task_and_info_parameters' is a unit test designed to verify the functionality of a specific feature in an asynchronous environment. It uses a mock environment to simulate a chat response and checks if the rollout function correctly processes the task and info parameters. Unit tests are crucial for ensuring code reliability and are typically maintained as long as the feature they test is relevant. Since this test is specific to a feature (handling task and info parameters) and does not show any signs of being obsolete or redundant, it is likely to be retained."
survived,"    async def test_error_handling_stops_rollout(self, mock_multiturn_env):
        """"""Test that errors stop the rollout immediately.""""""
        # Set up the mock to return an error response for the expected conversation
        mock_multiturn_env.client.add_chat_response(
            messages=[{""role"": ""user"", ""content"": ""Start conversation""}],
            response=""[ERROR] Something went wrong""
        )
        
        prompt = [{""role"": ""user"", ""content"": ""Start conversation""}]
        completion, state = await mock_multiturn_env.rollout(
            client=mock_multiturn_env.client,
            model=""test-model"",
            prompt=prompt,
            answer=""target_answer""
        )
        
        # Should stop immediately after error
        assert len(completion) == 1
        assert completion[0][""content""] == ""[ERROR] Something went wrong""
",tests/test_multiturn_env.py,TestMultiTurnEnv,1,4.944450477491054e-09,"The method is a unit test designed to verify that the system correctly handles errors by stopping the rollout process immediately. This is a crucial aspect of error handling in software systems, ensuring that errors do not propagate or cause further issues. The test is well-defined, uses mock objects to simulate the environment, and checks the expected behavior when an error occurs. Such tests are essential for maintaining robust and reliable software, especially in systems that involve complex interactions like chat environments. Therefore, it is likely to be retained as part of the test suite."
survived,"    async def test_call_reward_func_with_var_kwargs(self):
        """"""Test calling reward function that accepts **kwargs.""""""
        def kwargs_func(completion, **kwargs):
            return len(kwargs)
        
        rubric = Rubric(funcs=[], weights=[])
        
        result = await rubric.call_reward_func(
            func=kwargs_func,
            prompt=""test"",
            completion=""test"",
            answer=""test"",
            state={},
            task=""test"",
            info={}
        )
        
        # Should receive prompt, answer, state, task, info (completion used directly)
        assert result == 5
",tests/test_rubric.py,TestRubric,1,1.1861120010657661e-08,"The method 'test_call_reward_func_with_var_kwargs' is a test function that verifies the behavior of a reward function when called with variable keyword arguments. It is a useful test case to ensure that the 'call_reward_func' method in the 'Rubric' class correctly passes and handles keyword arguments. Test functions are generally retained as they are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, this method is likely to be retained."
survived,"    def add_chat_response(self, messages, response, finish_reason=""stop""):
        """"""Add a mapped response for specific messages.""""""
        # Convert messages to a hashable key
        key = self._messages_to_key(messages)
        self.chat_completions[key] = {
            ""content"": response,
            ""finish_reason"": finish_reason
        }
",tests/conftest.py,MockAsyncOpenAI,1,1.6918979223288786e-10,"The method 'add_chat_response' is likely to survive because it provides a clear and useful functionality within a class that manages chat responses. It converts messages into a hashable key and stores the response along with a finish reason, which is a common requirement in applications dealing with chat or conversation history. The method is well-defined, has a specific purpose, and does not contain any apparent issues that would necessitate its removal."
survived,"    def test_generate_sync_wrapper(self, mock_singleturn_env):
        """"""Test the synchronous generate wrapper.""""""
        inputs = {
            ""prompt"": [[{""role"": ""user"", ""content"": ""Hello""}]],
            ""answer"": [""Hi""],
            ""info"": [{}]
        }
        
        # Mock the rubric.score_rollouts method
        mock_singleturn_env.rubric.score_rollouts = AsyncMock(return_value={
            ""rewards"": [1.0],
            ""scores"": [{""correctness"": 1.0}]
        })
        
        results = mock_singleturn_env.generate(inputs)
        
        assert ""completion"" in results
        assert ""state"" in results
        assert ""rewards"" in results
",tests/test_singleturn_env.py,TestSingleTurnEnv,1,9.736200303530205e-10,"The method `test_generate_sync_wrapper` is a unit test designed to verify the functionality of a synchronous generate wrapper. Unit tests are crucial for ensuring code reliability and correctness, especially in complex systems. This test mocks a method and checks the output of a function, which is a common practice in testing to isolate the unit of work. Given the importance of testing in software development, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered. Therefore, the method is likely to survive."
survived,"            def env_response(self, messages, state, **kwargs):
                state[""turn_count""] = state.get(""turn_count"", 0) + 1
                return {""role"": ""user"", ""content"": f""Turn {state['turn_count']}""}, state
",tests/test_multiturn_env.py,TestMultiTurnEnv.StatefulMultiTurnEnv,1,8.592166611791576e-10,"The method 'env_response' is a simple function that increments a 'turn_count' in the 'state' dictionary and returns a message indicating the current turn. This functionality is straightforward and useful for tracking the number of interactions or turns in a conversation or game-like environment. It is likely to be a part of a larger system where tracking turns is necessary. Since it serves a clear purpose and is not overly complex or redundant, it is likely to be retained in the codebase."
survived,"    def test_singleturn_env_initialization_chat(self, mock_openai_client, sample_dataset):
        """"""Test SingleTurnEnv initialization with chat format.""""""
        env = SingleTurnEnv(
            client=mock_openai_client,
            model=""test-model"",
            dataset=sample_dataset,
            message_type=""chat"",
            system_prompt=""You are helpful."",
            parser=Parser(),
            rubric=Rubric()
        )
        assert env.message_type == ""chat""
        assert env.client == mock_openai_client
        assert env.model == ""test-model""
",tests/test_singleturn_env.py,TestSingleTurnEnv,1,1.1861120010657661e-08,"The method is a unit test for the initialization of the SingleTurnEnv class with specific parameters. It checks if the environment is correctly set up with the given message type, client, and model. Such tests are crucial for ensuring that the class behaves as expected when initialized with different configurations. Therefore, it is likely to be retained as part of the test suite to maintain code reliability and prevent regressions."
survived,"    def test_get_format_str_with_alternatives(self, xml_parser_with_alternatives):
        """"""Test format string with alternatives.""""""
        format_str = xml_parser_with_alternatives.get_format_str()
        assert ""code | answer"" in format_str
",tests/test_xml_parser.py,TestXMLParser,1,5.3157849718487075e-08,"The method 'test_get_format_str_with_alternatives' is a unit test designed to verify the functionality of the 'get_format_str' method from the 'xml_parser_with_alternatives' object. Unit tests are crucial for ensuring code reliability and are typically maintained as long as the functionality they test is relevant. Since the test is straightforward and checks a specific expected behavior, it is likely to be retained to ensure that any changes to the 'get_format_str' method do not break existing functionality."
survived,"def large_chai_graph() -> tuple[CHAI, dict[uuid.UUID, Decimal]]:
    """"""Creates a large CHAI graph with random edges and personalization.""""""
    G = CHAI()
    nodes = []
    initial_personalization_raw = {}

    # Create nodes
    for i in range(NUM_NODES):
        canon_id = uuid.uuid4()
        node = PackageNode(canon_id=canon_id)
        node.index = G.add_node(node)
        nodes.append(node)
        # Assign random initial weight for personalization
        initial_personalization_raw[canon_id] = Decimal(random.random())

    # Normalize personalization to sum to 1
    total_weight = sum(initial_personalization_raw.values())
    personalization = {
        uid: weight / total_weight
        for uid, weight in initial_personalization_raw.items()
    }
    assert (
        abs(sum(personalization.values()) - Decimal(1.0)) <= TOLERANCE
    ), f""Initial personalization should sum to 1 within tolerance: {sum(personalization.values())}""  # noqa: E501

    # Add random edges (potential cycles)
    node_indices = list(G.node_indices())
    for u_idx in node_indices:
        for v_idx in node_indices:
            if u_idx != v_idx and random.random() < EDGE_PROBABILITY:
                G.add_edge(u_idx, v_idx, None)  # Edge data is not used in distribute

    return G, personalization",tests/ranker/test_rx_graph.py,,1,2.2159489282323004e-08,"The method 'large_chai_graph' is a utility function that creates a graph with nodes and edges, and assigns random weights for personalization. This type of function is often used in graph-based algorithms or simulations, and the code appears to be well-structured and functional. It includes node creation, edge addition, and personalization weight normalization, which are common tasks in graph processing. The method is likely to be useful in contexts where graph structures are needed, such as in machine learning, network analysis, or simulations. Therefore, it is likely to be retained in the codebase."
survived,"def crate_with_dependencies():
    """"""
    Factory fixture to create Crate objects with specified dependencies.

    Returns a function that creates Crate objects.
    """"""

    def create_crate(crate_id=""1048221"", dependencies=None):
        latest_version = CrateLatestVersion(
            id=9337571,
            checksum=""some-checksum"",
            downloads=1000,
            license=""MIT"",
            num=""1.0.0"",
            published_by=None,
            published_at=""2023-01-01"",
        )

        if dependencies:
            latest_version.dependencies = dependencies
        else:
            latest_version.dependencies = []

        crate = Crate(
            id=int(crate_id),
            name=""main_pkg"",
            readme=""Test readme"",
            homepage="""",
            repository="""",
            documentation="""",
            source=None,
        )
        crate.latest_version = latest_version

        return crate

    return create_crate
",tests/package_managers/crates/test_diff_deps.py,,1,3.653482080241728e-08,"The method 'crate_with_dependencies' is a factory function that provides a convenient way to create 'Crate' objects with specified dependencies. This is a useful utility in testing or scenarios where creating objects with specific configurations is needed. It encapsulates the creation logic and allows for easy reuse and modification of the object creation process. Such utility functions are common in codebases that require object instantiation with varying parameters, especially in testing environments. Therefore, it is likely to be retained in the codebase."
survived,"def test_urls(ids):
    """"""Fixture providing test URL objects.""""""
    canonical_url = ""github.com/example/repo""
    non_canonical_url = ""https://github.com/example/repo""
    different_url = ""https://gitlab.com/example/repo""

    return {
        ""canonical"": URL(
            id=ids[""url1""],
            url=canonical_url,
            url_type_id=ids[""homepage_url_type""],
            created_at=datetime.now(),
            updated_at=datetime.now(),
        ),
        ""non_canonical"": URL(
            id=ids[""url2""],
            url=non_canonical_url,
            url_type_id=ids[""homepage_url_type""],
            created_at=datetime.now(),
            updated_at=datetime.now(),
        ),
        ""different"": URL(
            id=ids[""url3""],
            url=different_url,
            url_type_id=ids[""homepage_url_type""],
            created_at=datetime.now(),
            updated_at=datetime.now(),
        ),
    }
",tests/ranker/test_dedupe.py,,1,1.955568070542584e-08,"The method 'test_urls' is a fixture function that provides a set of test URL objects. It is useful for testing purposes, especially in a context where URL objects need to be created and manipulated in a consistent manner. The method is well-defined, serves a clear purpose, and is likely to be used in testing scenarios. Therefore, it is unlikely to be deleted as it provides utility in testing environments."
survived,"def homebrew_formula():
    """"""
    Factory fixture to create Actual homebrew formula objects.

    Returns a function that creates Actual objects.
    """"""

    def create_formula(
        formula_name,
        dependencies=None,
        build_dependencies=None,
        test_dependencies=None,
        recommended_dependencies=None,
        optional_dependencies=None,
    ):
        return Actual(
            formula=formula_name,
            description=""Test formula"",
            license=""MIT"",
            homepage="""",
            source="""",
            repository="""",
            dependencies=dependencies or [],
            build_dependencies=build_dependencies or [],
            test_dependencies=test_dependencies or [],
            recommended_dependencies=recommended_dependencies or [],
            optional_dependencies=optional_dependencies or [],
        )

    return create_formula
",tests/package_managers/homebrew/test_diff_dep.py,,1,5.60279640614594e-09,"The method 'homebrew_formula' is a factory function that returns another function 'create_formula'. This pattern is useful for creating objects with a specific structure, in this case, 'Actual' objects with various types of dependencies. The method is well-defined, flexible, and can be easily extended or modified to accommodate additional parameters or logic. It is likely to be useful in contexts where multiple 'Actual' objects need to be created with varying dependencies. Therefore, it is unlikely to be deleted as it provides a clear utility."
survived,"    def create_crate(crate_id=""1048221"", dependencies=None):
        latest_version = CrateLatestVersion(
            id=9337571,
            checksum=""some-checksum"",
            downloads=1000,
            license=""MIT"",
            num=""1.0.0"",
            published_by=None,
            published_at=""2023-01-01"",
        )

        if dependencies:
            latest_version.dependencies = dependencies
        else:
            latest_version.dependencies = []

        crate = Crate(
            id=int(crate_id),
            name=""main_pkg"",
            readme=""Test readme"",
            homepage="""",
            repository="""",
            documentation="""",
            source=None,
        )
        crate.latest_version = latest_version

        return crate
",tests/package_managers/crates/test_diff_deps.py,,1,1.522997951276035e-08,"The method 'create_crate' is a utility function that constructs and returns a 'Crate' object with a 'CrateLatestVersion' object as its latest version. It is a straightforward function that initializes objects with default or provided values, which is a common pattern in object-oriented programming. Such methods are typically retained as they encapsulate object creation logic, making the codebase cleaner and more maintainable. There is no indication of redundancy or obsolescence in the method, and it serves a clear purpose in the context of the code."
survived,"    def create_diff(package_map, dependencies=None, url_map=None, package_urls=None):
        cache = Cache(
            package_map=package_map,
            url_map=url_map or {},
            package_urls=package_urls or {},
            dependencies=dependencies or {},
        )
        return Diff(mock_config, cache)
",tests/package_managers/crates/test_diff_deps.py,,1,3.160881453314576e-10,"The method 'create_diff' is a utility function that initializes a 'Cache' object with several parameters and then returns a 'Diff' object. This method is likely to be useful in scenarios where a difference needs to be computed based on package maps and dependencies. The method is straightforward, has a clear purpose, and does not seem to have any issues that would warrant its removal. Therefore, it is likely to survive."
survived,"    def test_parse_source_data(self):
        """"""Test parsing a typical source entry from Sources file.""""""
        # Sample source data from a Sources file
        source_data = """"""Package: 0ad
Binary: 0ad, 0ad-dbg, 0ad-data, 0ad-data-common
Version: 0.0.26-1
Maintainer: Debian Games Team <pkg-games-devel@lists.alioth.debian.org>
Uploaders: Vincent Cheng <vcheng@debian.org>, Euan Kemp <euank@euank.com>
Build-Depends: debhelper-compat (= 13), cmake, dpkg-dev (>= 1.15.5), libboost-dev, libenet-dev (>= 1.3), libopenal-dev, libpng-dev, libsdl2-dev, libtiff5-dev, libvorbis-dev, libxcursor-dev, pkg-config, zlib1g-dev, libcurl4-gnutls-dev, libgloox-dev, libjsoncpp-dev, libminiupnpc-dev, libnspr4-dev, libnss3-dev, libsodium-dev, libwxgtk3.0-gtk3-dev | libwxgtk3.0-dev, python3, python3-dev, libxml2-dev, rust-gdb [amd64 i386 ppc64el]
Architecture: any all
Standards-Version: 4.5.1
Format: 3.0 (quilt)
Files:
 2fc0f38b8a4cf56fea7040fcf5f79ca3 2414 0ad_0.0.26-1.dsc
 35ca57e781448c69ba31323313e972af 31463733 0ad_0.0.26.orig.tar.xz
 f78de44c8a9c32e6be3ae99f2747c330 71948 0ad_0.0.26-1.debian.tar.xz
Vcs-Browser: https://salsa.debian.org/games-team/0ad
Vcs-Git: https://salsa.debian.org/games-team/0ad.git
Directory: pool/main/0/0ad
Priority: optional
Section: games
Testsuite: autopkgtest
Testsuite-Triggers: g++, pyrex


""""""
        # Parse the source data
        parser = DebianParser(source_data)
        sources = list(parser.parse())

        # Validate we have one source package
        assert len(sources) == 1
        source = sources[0]

        # Test basic fields
        assert source.package == ""0ad""
        assert source.version == ""0.0.26-1""

        # Test binary field
        assert isinstance(source.binary, list)  # Fixed: binary should be a list
        assert ""0ad"" in source.binary
        assert ""0ad-dbg"" in source.binary
        assert ""0ad-data"" in source.binary
        assert ""0ad-data-common"" in source.binary

        # Test maintainer parsing
        assert source.maintainer.name == ""Debian Games Team""
        assert source.maintainer.email == ""pkg-games-devel@lists.alioth.debian.org""

        # Test uploaders parsing
        assert len(source.uploaders) == 2
        assert source.uploaders[0].name == ""Vincent Cheng""
        assert source.uploaders[0].email == ""vcheng@debian.org""
        assert source.uploaders[1].name == ""Euan Kemp""
        assert source.uploaders[1].email == ""euank@euank.com""

        # Test build depends parsing
        assert len(source.build_depends) == 25
        assert any(dep.package == ""debhelper-compat"" for dep in source.build_depends)

        # Test other source fields
        assert source.format == ""3.0 (quilt)""
        assert source.vcs_browser == ""https://salsa.debian.org/games-team/0ad""
        assert source.vcs_git == ""https://salsa.debian.org/games-team/0ad.git""
        assert source.testsuite == ""autopkgtest""
        assert source.testsuite_triggers == ""g++, pyrex""
",tests/package_managers/debian/test_debian_parser.py,TestDebianParser,1,6.023574641292144e-08,"The method `test_parse_source_data` is a unit test designed to verify the functionality of a parser for Debian source data. It is well-structured, with clear assertions checking various aspects of the parsed data, such as package name, version, binary list, maintainer, uploaders, build dependencies, and other fields. This method is crucial for ensuring the reliability and correctness of the parsing logic, which is essential for any application dealing with Debian package data. As such, it is unlikely to be deleted because it serves an important role in maintaining code quality and preventing regressions."
survived,"    def get_url_type_by_name(name):
        if hasattr(mock_url_types, name):
            return getattr(mock_url_types, name)
        return None
",tests/conftest.py,,1,1.2501528648238603e-09,"The method `get_url_type_by_name` is a utility function that checks if a given attribute (name) exists in the `mock_url_types` object and returns its value if it exists. This is a common pattern used to safely access attributes in dynamic or mock objects, especially in testing scenarios. The method is simple, clear, and serves a specific purpose, which makes it likely to be retained in the codebase. It doesn't have any obvious flaws or redundancies that would necessitate its removal."
survived,"    def test_go_edge_cases(self):
        patch = """"""
@@ -152,10 +152,6 @@ func()

@@ -152,10 +152,6 @@ func _()

@@ -152,10 +152,6 @@ func (r *T) method_with_underscore()

@@ -152,10 +152,6 @@ var fn123 = func() {

@@ -152,10 +152,6 @@ camelCase := func() {

@@ -152,10 +152,6 @@ func MixedCase_With_Underscores()

""""""

        assert GoParser.extract_functions_from_patch(patch) == {
            ""_"",
            ""method_with_underscore"",
            ""fn123"",
            ""camelCase"",
            ""MixedCase_With_Underscores"",
        }",tests/sentry/integrations/source_code_management/test_language_parsers.py,GoParserTestCase,1,4.363462233903899e-09,"The method `test_go_edge_cases` is a unit test designed to verify the functionality of the `GoParser.extract_functions_from_patch` method. It checks if the method correctly identifies and extracts function names from a given patch string. This is a useful test case for ensuring the robustness of the function extraction logic, especially when dealing with various naming conventions and edge cases in Go code. Since testing is a crucial part of software development to ensure code quality and reliability, this method is likely to be retained as part of the test suite."
survived,"    def test_no_encryption(self, mock_smtp_class, context_manager):
        """"""Test SMTP without encryption.""""""
        # Create provider with no encryption config
        no_enc_config = ProviderConfig(
            description=""Test SMTP Provider"",
            authentication={
                ""smtp_server"": ""smtp.example.com"",
                ""smtp_port"": 25,
                ""encryption"": ""None"",
                ""smtp_username"": """",
                ""smtp_password"": """",
            },
        )
        smtp_provider = SmtpProvider(
            context_manager=context_manager,
            provider_id=""test_smtp_provider"",
            config=no_enc_config,
        )

        # Setup mock SMTP instance
        mock_smtp = MagicMock()
        mock_smtp_class.return_value = mock_smtp

        # Send email
        smtp_provider._notify(
            from_email=""sender@example.com"",
            from_name=""Test Sender"",
            to_email=""recipient@example.com"",
            subject=""Test No Encryption"",
            body=""No encryption test"",
        )

        # Verify SMTP was used without TLS
        mock_smtp_class.assert_called_once_with(""smtp.example.com"", 25)
        mock_smtp.starttls.assert_not_called()
        mock_smtp.login.assert_not_called()  # No credentials provided
        mock_smtp.sendmail.assert_called_once()
",tests/test_smtp_provider.py,TestSmtpProvider,1,1.1253518384332553e-07,"The method 'test_no_encryption' is a unit test designed to verify the behavior of an SMTP provider when no encryption is used. It is a specific test case that ensures the SMTP connection is established without TLS and without authentication, as expected for this configuration. Such test methods are typically retained in the codebase to ensure that the functionality they cover is working correctly and to prevent regressions. Therefore, it is unlikely to be deleted unless the feature it tests is removed or significantly changed."
survived,"    def force_full_scan(self, storage: str, mon_path: Path) -> bool:
        """"""
        å¼ºåˆ¶å…¨é‡æ‰«æå¹¶å¤„ç†æ‰€æœ‰æ–‡ä»¶ï¼ˆåŒ…æ‹¬å·²å­˜åœ¨çš„æ–‡ä»¶ï¼‰
        :param storage: å­˜å‚¨åç§°
        :param mon_path: ç›‘æŽ§è·¯å¾„
        :return: æ˜¯å¦æˆåŠŸ
        """"""
        try:
            logger.info(f""å¼€å§‹å¼ºåˆ¶å…¨é‡æ‰«æ: {storage}:{mon_path}"")

            # ç”Ÿæˆå¿«ç…§
            new_snapshot = StorageChain().snapshot_storage(
                storage=storage,
                path=mon_path,
                last_snapshot_time=0  # å…¨é‡æ‰«æï¼Œä¸ä½¿ç”¨å¢žé‡
            )

            if new_snapshot is None:
                logger.warn(f""èŽ·å– {storage}:{mon_path} å¿«ç…§å¤±è´¥"")
                return False

            file_count = len(new_snapshot)
            logger.info(f""{storage}:{mon_path} å…¨é‡æ‰«æå®Œæˆï¼Œå‘çŽ° {file_count} ä¸ªæ–‡ä»¶"")

            # å¤„ç†æ‰€æœ‰æ–‡ä»¶
            processed_count = 0
            for file_path, file_info in new_snapshot.items():
                try:
                    logger.info(f""å¤„ç†æ–‡ä»¶ï¼š{file_path}"")
                    file_size = file_info.get('size', 0) if isinstance(file_info, dict) else file_info
                    self.__handle_file(storage=storage, event_path=Path(file_path), file_size=file_size)
                    processed_count += 1
                except Exception as e:
                    logger.error(f""å¤„ç†æ–‡ä»¶ {file_path} å¤±è´¥: {e}"")
                    continue

            logger.info(f""{storage}:{mon_path} å…¨é‡æ‰«æå®Œæˆï¼Œå…±å¤„ç† {processed_count}/{file_count} ä¸ªæ–‡ä»¶"")

            # ä¿å­˜å¿«ç…§
            self.save_snapshot(storage, new_snapshot, file_count)

            return True

        except Exception as e:
            logger.error(f""å¼ºåˆ¶å…¨é‡æ‰«æå¤±è´¥: {storage}:{mon_path} - {e}"")
            return False
",app/monitor.py,Monitor,1,1.6052280526088547e-09,"The method 'force_full_scan' is likely to survive because it performs a critical function of scanning and processing files in a storage system. It includes comprehensive logging, error handling, and a clear return value indicating success or failure. These features suggest it is well-implemented and useful for maintaining the integrity and functionality of the system."
survived,"    def workflow_fork(self, share_id: int) -> Tuple[bool, str]:
        """"""
        å¤ç”¨åˆ†äº«çš„å·¥ä½œæµ
        """"""
        if not settings.WORKFLOW_STATISTIC_SHARE:  # ä½¿ç”¨ç‹¬ç«‹çš„å·¥ä½œæµåˆ†äº«å¼€å…³
            return False, ""å½“å‰æ²¡æœ‰å¼€å¯å·¥ä½œæµæ•°æ®å…±äº«åŠŸèƒ½""
        
        res = RequestUtils(proxies=settings.PROXY or {}, timeout=5, headers={
            ""Content-Type"": ""application/json""
        }).get_res(self._workflow_fork % share_id)
        if res is None:
            return False, ""è¿žæŽ¥MoviePilotæœåŠ¡å™¨å¤±è´¥""
        if res.ok:
            return True, """"
        else:
            return False, res.json().get(""message"")
",app/helper/workflow.py,WorkflowHelper,1,1.1032560311263802e-09,"The method 'workflow_fork' is likely to survive because it contains essential functionality for handling workflow sharing, which is a common feature in collaborative environments. The method checks a configuration setting, makes a network request, and handles responses appropriately, which are all necessary operations for its intended purpose. Additionally, the method includes error handling and returns informative messages, indicating it is well-structured and useful."
survived,"    def list(db):
        return db.query(Workflow).all()
",app/db/models/workflow.py,Workflow,0,0.9669140233989488,"The method is named 'list', which is a built-in Python function name, potentially causing confusion or errors. Renaming the method to something more descriptive would be a better practice. However, the method itself is functional and straightforward, simply querying all Workflow objects from the database. If the context allows for renaming, the method might survive with a new name. Otherwise, it might be deleted to avoid conflicts with the built-in 'list'."
survived,"def end_session():
    # type: () -> None
    return get_isolation_scope().end_session()",sentry_sdk/api.py,,1,2.3355930333443423e-09,"The method `end_session` is a simple wrapper around another method call `get_isolation_scope().end_session()`. It doesn't contain any complex logic or additional functionality. Such methods are often kept for abstraction purposes, to provide a clear API or to maintain a certain structure in the codebase. Unless there is a significant reason to remove this abstraction, such as performance issues or redundancy, it is likely to be retained. Therefore, the method is likely to survive."
survived,"    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key
        self.base_url = ""https://api.1inch.dev""
",python/src/plugins/1inch/goat_plugins/oneinch/service.py,OneInchService,1,7.73442280641062e-08,"The method is a constructor for a class, initializing important attributes like 'api_key' and 'base_url'. Constructors are essential for setting up instances of a class, and this one includes an optional parameter, which adds flexibility. There is no indication that this method is redundant or unnecessary, so it is likely to be retained."
survived,"    def __init__(self, api_key: str, base_url: str = ""https://api.neynar.com/v2/farcaster""):
        self.api_key = api_key
        self.base_url = base_url
",python/src/plugins/farcaster/goat_plugins/farcaster/service.py,FarcasterService,1,2.699578619062706e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes, such as 'api_key' and 'base_url' in this case. Since this is a basic and necessary method for setting up instances of a class, it is unlikely to be deleted unless the entire class is being refactored or removed, which is not indicated here."
survived,"def extract_zip(zip_path, extract_dir):
    """"""Extract a zip file to a directory.""""""
    print(f""Extracting {zip_path} to {extract_dir}..."")
    with zipfile.ZipFile(zip_path, ""r"") as zip_ref:
        zip_ref.extractall(extract_dir)
    print(f""Extraction complete: {extract_dir}"")
    return extract_dir
",tests/replay_parser_test.py,,1,2.998960815863541e-09,"The method 'extract_zip' is a straightforward utility function that performs a common task: extracting a zip file to a specified directory. It uses the standard library 'zipfile' module, which is a reliable and efficient way to handle zip files in Python. The function is simple, clear, and performs its task effectively without any unnecessary complexity. Additionally, it provides informative print statements to indicate the progress of the extraction process. Such utility functions are often useful in various applications and scripts, making it likely to be retained for its practicality and ease of use."
survived,"    def test_certificate_installation(self):
        """"""Test certificate installation creates temporary file and sets environment variables""""""
        test_cert = ""-----BEGIN CERTIFICATE-----\ntest\n-----END CERTIFICATE-----""
        
        with patch('tempfile.NamedTemporaryFile') as mock_temp_file, \
             patch.dict('os.environ', {}, clear=True):
            
            mock_file = mock_open()
            mock_temp_file.return_value.__enter__.return_value = mock_file.return_value
            mock_file.return_value.name = ""/tmp/test_cert.pem""
            
            from source_file.proxy import _install_ca_certificate
            
            result_path = _install_ca_certificate(test_cert)
            
            mock_file.return_value.write.assert_called_once_with(test_cert)
            mock_file.return_value.flush.assert_called_once()
            
            assert os.environ.get(""REQUESTS_CA_BUNDLE"") == ""/tmp/test_cert.pem""
            assert os.environ.get(""CURL_CA_BUNDLE"") == ""/tmp/test_cert.pem""
            assert os.environ.get(""SSL_CERT_FILE"") == ""/tmp/test_cert.pem""
",airbyte-integrations/connectors/source-file/unit_tests/test_proxy_certificate_support.py,TestProxyCertificateSupport,1,4.1399375473943306e-08,"The method 'test_certificate_installation' is a unit test designed to verify the functionality of a certificate installation process. It uses mocking to simulate the creation of a temporary file and the setting of environment variables, which are common practices in testing. The method is well-structured, with clear assertions to validate the expected behavior of the '_install_ca_certificate' function. Since it serves a clear purpose in ensuring the reliability of the certificate installation process, it is likely to be retained as part of the test suite to maintain code quality and prevent regressions."
survived,"    def is_small_company(self) -> bool:
        """"""Check if company has 5 or fewer employees.""""""
        return self.num_employees in [""1"", ""2-5""]
",pcweb/pages/pricing/header.py,QuoteFormState,1,1.4738976032926566e-05,"The method `is_small_company` is designed to determine if a company is small based on the number of employees. However, the implementation has a flaw: it checks if `self.num_employees` is in a list of strings, which is not a robust way to handle numerical data. Typically, `num_employees` would be an integer, and the check should be against numerical values, not strings. Despite this flaw, the method's purpose is clear and useful for determining company size, which is a common requirement in business logic. Therefore, the method is likely to be retained but may require refactoring to handle numerical data correctly."
survived,"    def __init__(self, options: RugCheckPluginOptions):
        super().__init__(""rugcheck"", [RugCheckService(options.jwt_token)])
",python/src/plugins/rugcheck/goat_plugins/rugcheck/__init__.py,RugCheckPlugin,1,9.931195248674785e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting up initial states. This particular constructor is initializing a superclass with specific parameters, which suggests it's part of a larger framework or system. Such methods are typically not deleted unless the entire class is being refactored or removed, which is not indicated here."
survived,"    async def generate_token_report_summary(self, parameters: dict):
        """"""Generate a report summary for the given token mint""""""
        mint = parameters[""mint""]
        return await self._make_request(f""/tokens/{mint}/report/summary"")",python/src/plugins/rugcheck/goat_plugins/rugcheck/service.py,RugCheckService,1,2.646573631904765e-09,"The method 'generate_token_report_summary' is likely to be Survived (1) because it is a well-defined asynchronous function that performs a specific task: generating a report summary for a given token mint. It uses a parameterized approach, making it flexible and reusable. Additionally, it leverages an internal method '_make_request' to perform its operation, indicating that it is part of a larger, possibly well-structured codebase. There are no obvious issues or deprecated practices in the code that would suggest it should be deleted."
deleted,"    def test_run_release_candidates_same_versions(self, mock_current_version, mock_master_version, version_increment_check, connector):
        mock_master_version.return_value = semver.Version.parse(""1.0.0-rc.1"")
        mock_current_version.return_value = semver.Version.parse(""1.0.0-rc.2"")
        
        result = version_increment_check._run(connector)
        
        assert result.status == CheckStatus.PASSED
        assert ""Version was properly incremented"" in result.message
",airbyte-ci/connectors/connectors_qa/tests/checks/test_version.py,TestVersionIncrementCheck,1,2.1724399346070676e-10,"The method 'test_run_release_candidates_same_versions' is a unit test designed to verify the behavior of a version increment check function. Unit tests are crucial for ensuring code reliability and correctness, especially in version control and release management scenarios. This test checks that the version increment logic correctly identifies a proper increment between two release candidate versions. Since maintaining and improving test coverage is a best practice in software development, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered. Therefore, the method is likely to survive."
survived,"    def _are_both_versions_release_candidates(self, master_version: semver.Version, current_version: semver.Version) -> bool:
        """"""Check if both versions are release candidates.""""""
        return bool(
            master_version.prerelease
            and current_version.prerelease
            and ""rc"" in master_version.prerelease
            and ""rc"" in current_version.prerelease
        )
",airbyte-ci/connectors/connectors_qa/src/connectors_qa/checks/version.py,VersionIncrementCheck,1,5.905303995456778e-10,"The method '_are_both_versions_release_candidates' is a utility function that checks if both provided version objects are release candidates. This is a specific and useful functionality, especially in environments where version control and release management are critical. The method is concise, clear, and performs a distinct check that could be reused in various parts of a codebase dealing with versioning. Therefore, it is likely to be retained as it serves a clear purpose."
deleted,"    def _is_version_not_incremented(self, master_version: semver.Version, current_version: semver.Version) -> bool:
        """"""Check if the version was not incremented.""""""
        return master_version >= current_version
",airbyte-ci/connectors/connectors_qa/src/connectors_qa/checks/version.py,VersionIncrementCheck,1,1.955568070542584e-08,"The method _is_version_not_incremented is a utility function that checks if a version has not been incremented by comparing two version objects. This is a common requirement in version control and release management systems to ensure that the current version is ahead of or equal to the master version. The method is simple, clear, and serves a specific purpose, making it likely to be useful in contexts where version comparison is needed. Therefore, it is likely to be retained in the codebase."
survived,"def compute_euler_angles_from_rotation_matrices(rotation_matrices):
    batch = rotation_matrices.shape[0]
    R = rotation_matrices
    sy = np.sqrt(R[:, 0, 0] * R[:, 0, 0] + R[:, 1, 0] * R[:, 1, 0])
    singular = sy < 1e-6

    x = np.arctan2(R[:, 2, 1], R[:, 2, 2])
    y = np.arctan2(-R[:, 2, 0], sy)
    z = np.arctan2(R[:, 1, 0], R[:, 0, 0])

    xs = np.arctan2(-R[:, 1, 2], R[:, 1, 1])
    ys = np.arctan2(-R[:, 2, 0], sy)
    zs = R[:, 1, 0] * 0

    out_euler = np.zeros((batch, 3))
    out_euler[:, 0] = x * (1 - singular) + xs * singular
    out_euler[:, 1] = y * (1 - singular) + ys * singular
    out_euler[:, 2] = z * (1 - singular) + zs * singular

    return out_euler
",face_recognition/6d_repnet_360/utils_6d_repnet_360/utils.py,,1,4.363462233903899e-09,"The method `compute_euler_angles_from_rotation_matrices` is a utility function that converts rotation matrices to Euler angles. This is a common requirement in fields like computer graphics, robotics, and aerospace engineering, where understanding and manipulating orientations is crucial. The function appears to be well-implemented, handling both regular and singular cases of rotation matrices. Given its utility and the fact that it addresses a specific mathematical conversion, it is likely to be retained in the codebase."
survived,"    def _perform_conversion(self, file_path: str, converter, format_msg: str) -> List[Tuple[str, Dict[str, Any]]]:
        """"""Perform the actual conversion using the specified converter.""""""
        pages_data = []
        try:
            result = converter.convert(file_path)
            markdown_content = result.document.export_to_markdown()
            
            metadata = {""source"": file_path}
            # Return the *DoclingDocument* object as third tuple element so downstream
            # chunkers that understand the element tree can use it.  Legacy callers that
            # expect only (markdown, metadata) can simply ignore the extra value.
            pages_data.append((markdown_content, metadata, result.document))
            print(f""Successfully converted {file_path} with docling {format_msg}."")
            return pages_data
        except Exception as e:
            print(f""Error processing {file_path} with docling: {e}"")
            return []",rag_system/ingestion/document_converter.py,DocumentConverter,1,7.73442280641062e-08,"The method '_perform_conversion' is a utility function that performs a specific task of converting a file using a given converter and returns the result in a structured format. It handles exceptions and logs errors, which are good practices for robust code. The method is likely to be used in various parts of a codebase where file conversion is needed, making it a reusable and valuable function. Therefore, it is unlikely to be deleted unless the entire conversion functionality is removed or significantly refactored."
survived,"    async def async_no_stream():
        try:
            print(""\nExecuting async_no_stream..."")
            async with asyncio.timeout(30):
                response = await aco.chat(message=""Hello from async no stream"", model=""command"", session=session)
                print(f""async_no_stream completed successfully with response: {response.text}"")
        except asyncio.TimeoutError:
            print(""Warning: async_no_stream timed out"")
            raise
        except Exception as e: 
            print(f""Error in async_no_stream: {str(e)}"")
            raise
",tests/core_manual_tests/providers/cohere_canary.py,,1,2.998960815863541e-09,"The method 'async_no_stream' is a well-structured asynchronous function that handles potential exceptions, including timeouts and general exceptions. It uses 'asyncio.timeout' to manage the execution time, which is a good practice for asynchronous operations. The method also logs the process, which is useful for debugging and monitoring. Given these factors, the method is likely to be useful and relevant in contexts where asynchronous operations with timeout management are needed. Therefore, it is likely to be retained in the codebase."
survived,"    async def async_stream(provider, session):
        try:
            print(""\nStarting async_stream call..."")
            async with asyncio.timeout(30):  # Add timeout to prevent hanging
                # Ensure provider has the current session
                provider.client = session
                # Create a new stream with the provider to ensure proper event tracking
                stream = await aco.chat_stream(
                    message=""Hello from async streaming"",
                    model=""command"",
                    session=session
                )
                print(""Stream created, starting iteration..."")
                async for chunk in stream:
                    print(f""Received async chunk: {chunk}"")
                print(""Stream completed successfully"")
        except asyncio.TimeoutError:
            print(""Warning: Async stream timed out"")
            raise
        except Exception as e:
            print(f""Error in async_stream: {str(e)}"")
            raise
",tests/core_manual_tests/providers/cohere_canary.py,,1,1.522997951276035e-08,"The method is well-structured and includes important features such as error handling and a timeout mechanism, which are crucial for robust asynchronous operations. The use of async/await is appropriate for the task, and the method provides informative logging, which is useful for debugging and monitoring. These characteristics make it a good candidate for survival in a codebase that values reliability and maintainability."
survived,"    async def async_stream():
        async_stream_response = await async_chat_client.create(
            model=""jamba-instruct"",
            system=""You are a helpful AI assistant"",
            messages=async_stream_messages,
            maxTokens=10,
            stream=True
        )
        async for chunk in async_stream_response:
            _ = chunk.choices[0].delta.content if hasattr(chunk.choices[0].delta, 'content') else ''
",tests/core_manual_tests/providers/ai21_canary.py,,1,9.736200303530205e-10,"The method 'async_stream' is likely to survive because it is an asynchronous function that handles streaming responses from an AI model, which is a common and useful pattern in modern applications. Asynchronous programming is increasingly important for handling I/O-bound tasks efficiently, and streaming allows for processing data in real-time as it is received. The method is well-structured for its purpose, making it a valuable component in applications that require interaction with AI models."
survived,"def test_dataset_creation(threads=1):
  """"""Test the dataset creation functions in slippi_db.""""""
  with tempfile.TemporaryDirectory() as temp_dir:
    root_dir, raw_dir, parsed_dir = setup_dataset_root(temp_dir)

    raw_files = download_test_dataset(raw_dir, temp_dir)
    print(f""Downloaded {len(raw_files)} files to {raw_dir}"")

    parse_local.run_parsing(
      root=root_dir,
      num_threads=threads,
      in_memory=True,
      reprocess=False,
      dry_run=False
    )

    parsed_pkl_path = os.path.join(root_dir, ""parsed.pkl"")
    assert os.path.exists(parsed_pkl_path), f""parsed.pkl not found at {parsed_pkl_path}""

    with open(parsed_pkl_path, ""rb"") as f:
      parsed_data = pickle.load(f)

    print(f""Parsed data contains {len(parsed_data)} entries"")

    invalid_entries = [entry for entry in parsed_data if not entry.get(""valid"", False)]
    non_training_entries = [entry for entry in parsed_data if not entry.get(""is_training"", False)]

    assert len(invalid_entries) == 0, f""Found {len(invalid_entries)} invalid entries""
    assert len(non_training_entries) == 0, f""Found {len(non_training_entries)} non-training entries""

    return parsed_data
",tests/dataset_creation_test.py,,1,1.0467401685178159e-08,"The method 'test_dataset_creation' is a test function that verifies the dataset creation process in the 'slippi_db'. It uses temporary directories, downloads test datasets, runs parsing, and checks the integrity of the parsed data. Such test functions are crucial for ensuring the correctness and reliability of data processing pipelines. Therefore, it is likely to be retained as part of the test suite to maintain code quality and prevent regressions."
survived,"            def handle_stream_chunk(chunk):
                if llm_event.returns is None:
                    llm_event.returns = chunk
                    llm_event.agent_id = check_call_stack_for_agent_id()
                    llm_event.model = getattr(chunk, 'model', 'gemini-1.5-flash')  # Default if not provided
                    llm_event.prompt = kwargs.get(""contents"", [])
                
                try:
                    if hasattr(chunk, 'text') and chunk.text:
                        accumulated_text.append(chunk.text)
                    
                    # Extract token counts if available
                    if hasattr(chunk, 'usage_metadata'):
                        usage = chunk.usage_metadata
                        llm_event.prompt_tokens = getattr(usage, 'prompt_token_count', None)
                        llm_event.completion_tokens = getattr(usage, 'candidates_token_count', None)
                    
                    # If this is the last chunk
                    if hasattr(chunk, 'finish_reason') and chunk.finish_reason:
                        llm_event.completion = ''.join(accumulated_text)
                        llm_event.end_timestamp = get_ISO_time()
                        self._safe_record(session, llm_event)
                
                except Exception as e:
                    logger.warning(
                        f""Unable to parse chunk for Gemini LLM call. Skipping upload to AgentOps\n""
                        f""Error: {str(e)}\n""
                        f""Chunk: {chunk}\n""
                        f""kwargs: {kwargs}\n""
                    )
",agentops/llms/providers/gemini.py,GeminiProvider,1,4.944450477491054e-09,"The method 'handle_stream_chunk' is likely to survive because it appears to be a well-structured and functional piece of code that processes chunks of data from a stream. It handles various attributes of the chunk, such as 'text', 'usage_metadata', and 'finish_reason', and updates an event object accordingly. The method also includes error handling to log warnings if an exception occurs, which is a good practice for robustness. Additionally, the method seems to be part of a larger system that records events, indicating its utility in the context it is used."
survived,"            def stream_handler(stream):
                for chunk in stream:
                    handle_stream_chunk(chunk)
                    yield chunk
",agentops/llms/providers/gemini.py,GeminiProvider,1,9.237449576640118e-09,"The method 'stream_handler' is a generator function that processes a stream by iterating over its chunks, handling each chunk with 'handle_stream_chunk', and then yielding the chunk. This pattern is common in scenarios where data is processed in a streaming fashion, such as reading large files or handling network data. The method is likely to be useful in contexts where memory efficiency and real-time processing are important. Therefore, it is likely to be retained in the codebase."
deleted,"    def undo_override(self):
        """"""Restore original Gemini methods.""""""
        if self.original_generate is not None:
            self.client.generate_content = self.original_generate",agentops/llms/providers/gemini.py,GeminiProvider,1,1.6052280526088547e-09,"The method `undo_override` is a utility function that restores the original state of a method if it has been overridden. This type of method is generally useful in scenarios where temporary changes are made to a system or object, and there is a need to revert those changes to maintain system integrity or for testing purposes. Such methods are often retained in codebases to ensure flexibility and reliability, especially in environments where dynamic method overriding is common. Therefore, it is likely to survive."
survived,"def jupiter(options: JupiterPluginOptions) -> JupiterPlugin:
    return JupiterPlugin(options)",python/src/plugins/jupiter/goat_plugins/jupiter/__init__.py,,1,1.2501528648238603e-09,"The method 'jupiter' is a simple factory function that takes an instance of 'JupiterPluginOptions' and returns a new 'JupiterPlugin' object initialized with those options. This is a common pattern in software design, especially in plugin-based architectures, where such factory functions are used to encapsulate the creation logic of objects. The method is likely to be useful for creating instances of 'JupiterPlugin' in a consistent manner, and unless there is a significant change in the design or requirements of the system, there is no reason to delete it. Therefore, it is predicted to survive."
survived,"    def __init__(self, context: PipelineContext) -> None:
        super().__init__(context)
",airbyte-ci/connectors/pipelines/pipelines/airbyte_ci/connectors/migrate_to_inline_schemas/pipeline.py,InlineSchemas,1,3.2241866333029355e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting up initial states. Therefore, it is unlikely to be deleted unless the entire class is being refactored or removed, which is not indicated here."
survived,"def copy_directory(src: Path, dest: Path) -> None:
    if dest.exists():
        shutil.rmtree(dest)
    shutil.copytree(src, dest)
",airbyte-ci/connectors/pipelines/pipelines/airbyte_ci/connectors/migrate_to_inline_schemas/pipeline.py,,1,2.0611536181902033e-09,"The method `copy_directory` is a straightforward utility function that copies the contents of one directory to another. It first checks if the destination directory exists and removes it if it does, then it uses `shutil.copytree` to copy the source directory to the destination. This is a common and useful operation in many applications, especially in file management and backup systems. The method is simple, clear, and performs a necessary task efficiently, which makes it likely to be retained in the codebase."
survived,"    def test_console_formatter_pause_resume_methods(self):
        """"""Test that ConsoleFormatter pause/resume methods work correctly.""""""
        formatter = event_listener.formatter
        
        original_paused_state = formatter._live_paused
        
        try:
            formatter._live_paused = False
            
            formatter.pause_live_updates()
            assert formatter._live_paused
            
            formatter.resume_live_updates()
            assert not formatter._live_paused
        finally:
            formatter._live_paused = original_paused_state
",tests/test_flow_human_input_integration.py,TestFlowHumanInputIntegration,1,4.599055376537186e-10,"The method 'test_console_formatter_pause_resume_methods' is a unit test designed to verify the functionality of the 'pause_live_updates' and 'resume_live_updates' methods of a 'ConsoleFormatter' object. Unit tests are generally crucial for ensuring code reliability and are typically retained in the codebase to facilitate ongoing testing and maintenance. Therefore, it is likely that this method will survive."
survived,"    def from_dict(cls, data: Dict[str, Any]) -> 'SecurityConfig':
        """"""
        Create a SecurityConfig from a dictionary.

        Args:
            data (Dict[str, Any]): Dictionary representation of a security config

        Returns:
            SecurityConfig: A new SecurityConfig instance
        """"""
        # Make a copy to avoid modifying the original
        data_copy = data.copy()

        fingerprint_data = data_copy.pop(""fingerprint"", None)
        fingerprint = Fingerprint.from_dict(fingerprint_data) if fingerprint_data else Fingerprint()

        return cls(fingerprint=fingerprint)",src/crewai/security/security_config.py,SecurityConfig,1,3.3982678079468468e-09,"The method 'from_dict' is a factory method that creates an instance of 'SecurityConfig' from a dictionary. This is a common pattern in Python for deserializing data, especially when dealing with configurations or data that might be stored in JSON or other dictionary-like formats. The method is useful for converting external data into an internal object representation, which is a frequent requirement in software applications. Given its utility in data handling and object creation, it is unlikely to be deleted unless the entire class or its usage pattern changes significantly."
survived,"    def __str__(self) -> str:
        """"""String representation of the fingerprint (the UUID).""""""
        return self.uuid_str
",src/crewai/security/fingerprint.py,Fingerprint,1,1.3440409770490404e-08,"The method is a simple and clear implementation of the __str__ method, which is a standard Python method used to define the string representation of an object. It returns a UUID string, which is likely a key attribute of the object. This method is useful for debugging and logging purposes, making it a valuable part of the class. Therefore, it is unlikely to be deleted."
survived,"    def __hash__(self) -> int:
        """"""Hash of the fingerprint (based on UUID).""""""
        return hash(self.uuid_str)
",src/crewai/security/fingerprint.py,Fingerprint,1,2.2159489282323004e-08,"The method `__hash__` is a standard Python method used to return a hash value of an object, which is essential for using objects as keys in dictionaries or adding them to sets. The implementation here is straightforward and relies on hashing a UUID string, which is a common practice for ensuring unique and consistent hash values. This method is likely to be crucial for the functionality of the class it belongs to, especially if instances of the class are intended to be used in hash-based collections. Therefore, it is unlikely to be deleted."
survived,"    def __eq__(self, other) -> bool:
        """"""Compare fingerprints by their UUID.""""""
        if isinstance(other, Fingerprint):
            return self.uuid_str == other.uuid_str
        return False
",src/crewai/security/fingerprint.py,Fingerprint,1,1.6052280526088547e-09,"The method is a standard implementation of the equality operator for a class, which is a common and necessary practice in object-oriented programming. It allows instances of the class to be compared based on a specific attribute, in this case, 'uuid_str'. This is a typical and useful method that enhances the functionality of the class, making it more versatile and easier to use in collections or comparisons. There is no indication that this method is redundant or incorrect, so it is likely to be retained."
survived,"def _record() -> AirbyteMessage:
    return AirbyteMessage(
        type=Type.RECORD, record=AirbyteRecordMessage(stream=TEST_STREAM, data=TEST_MESSAGE, emitted_at=0, namespace=TEST_NAMESPACE)
    )
",airbyte-integrations/connectors/destination-glassflow/integration_tests/integration_test.py,,1,5.3157849718487075e-08,"The method '_record' is a private helper function, indicated by the underscore prefix, which is commonly used in Python to denote that a method is intended for internal use within a module or class. The function is straightforward, returning an instance of 'AirbyteMessage' with specific parameters. This kind of utility function is often necessary for creating standardized message objects in data processing or integration tasks. Unless there is a significant change in the design or requirements of the system that makes this function obsolete, it is likely to be retained for its utility in creating consistent message objects."
survived,"def test_write_succeeds(client):
    stream = ""test""
    data = {""field1"": ""test-value"", ""field2"": ""test-value""}
    emitted_at = 0
    pipeline = _init_mocks(client)
    input_messages = [_record(stream=stream, data=data), _state()]
    destination = DestinationGlassflow()
    for m in destination.write(config=config, configured_catalog=_configured_catalog(), input_messages=input_messages):
        assert m.type == Type.STATE

    _, (args,), _ = pipeline.publish.mock_calls[0]
    assert args[""stream""] == stream
    assert args[""data""] == data
    assert args[""emitted_at""] == emitted_at
    pipeline.publish.assert_called()
",airbyte-integrations/connectors/destination-glassflow/unit_tests/unit_test.py,,1,3.850741907939403e-09,"The method 'test_write_succeeds' is a unit test function that verifies the behavior of a 'write' method in a 'DestinationGlassflow' class. It checks if the 'write' method correctly processes input messages and calls the 'publish' method with the expected arguments. Unit tests are crucial for ensuring code reliability and are typically retained in codebases to maintain software quality. Therefore, this method is likely to survive."
survived,"def test_set_primary_key(input_key, expected_output):
    """"""Test that set_primary_key properly converts and updates a single primary key override.""""""
    with patch.object(Source, ""_discover"", return_value=Mock()):
        source = Source(executor=Mock(), name=""test-source"")

        source.set_primary_key(""stream1"", input_key)

        assert source._primary_key_overrides == {""stream1"": expected_output}
",tests/unit_tests/sources/test_source_key_overrides.py,,1,1.8553915987649156e-07,"The method `test_set_primary_key` is a unit test designed to verify the functionality of the `set_primary_key` method in the `Source` class. Unit tests are crucial for ensuring code reliability and are typically retained to maintain code quality. Therefore, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered."
survived,"    def test_save_cache(self) -> None:
        """"""Test saving a cache.""""""
        loader = PickleLoader(""test"", self.save_path)
        
        # Create a cache
        cache = Cache(
            {""var1"": ""value1""}, 
            ""hash1"", 
            set(),
            ""Pure"",
            True,
            {}
        )
        
        # Save the cache
        loader.save_cache(cache)
        
        # Verify the file was created
        cache_path = loader.build_path(""hash1"", ""Pure"")
        assert os.path.exists(cache_path)
        
        # Load the cache and verify contents
        with open(cache_path, ""rb"") as f:
            loaded_cache = pickle.load(f)
        
        assert loaded_cache.hash == ""hash1""
        assert loaded_cache.cache_type == ""Pure""
        
        # Save another cache with different type
        cache2 = Cache(
            {""var2"": ""value2""}, 
            ""hash2"", 
            set(),
            ""Deferred"",
            True,
            {}
        )
        
        loader.save_cache(cache2)
        
        # Verify the second file was created
        cache2_path = loader.build_path(""hash2"", ""Deferred"")
        assert os.path.exists(cache2_path)",tests/_save/loaders/test_pickle_loader.py,TestPickleLoader,1,2.2159489282323004e-08,"The method 'test_save_cache' is a unit test designed to verify the functionality of saving cache objects using a PickleLoader. It includes assertions to check if the cache files are created and if the contents are correctly saved and loaded. This is a typical and necessary test to ensure the reliability of the caching mechanism. Since it serves a clear purpose in testing the functionality of the code, it is likely to be retained."
survived,"    def test_save_cache(self) -> None:
        """"""Test saving a cache.""""""
        loader = MemoryLoader(""test"")
        
        # Create and save a cache
        cache = Cache(
            {""var1"": ""value1""}, 
            ""hash1"", 
            set(),
            ""Pure"",
            True,
            {}
        )
        loader.save_cache(cache)
        
        # Verify it was saved
        assert loader.cache_hit(""hash1"", ""Pure"")
        
        # Save another cache with the same hash but different type
        cache2 = Cache(
            {""var2"": ""value2""}, 
            ""hash1"", 
            set(),
            ""Deferred"",
            True,
            {}
        )
        loader.save_cache(cache2)
        
        # Both should be accessible
        assert loader.cache_hit(""hash1"", ""Pure"")
        assert loader.cache_hit(""hash1"", ""Deferred"")
",tests/_save/loaders/test_memory_loader.py,TestMemoryLoader,1,1.8189616842444243e-09,"The method `test_save_cache` is a unit test designed to verify the functionality of saving caches with different types and ensuring they are accessible. Unit tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. This test checks multiple scenarios, such as saving caches with the same hash but different types, which is important for validating the behavior of the `MemoryLoader` class. Therefore, it is likely to be retained as part of the test suite."
survived,"def test_valid_schema(tmp_path):
    """"""Test that a valid schema does not raise any exceptions.""""""
    db_path = tmp_path / ""metadata.db""
    db = MetadataDB(str(db_path))
    db.store_metadata({
        ""run_hash"": ""test"",
        ""dataset_hash"": ""hash"",
        ""prompt_func"": ""def prompt_func(): pass"",
        ""model_name"": ""test-model"",
        ""response_format"": ""{}"",
        ""batch_mode"": False,
        ""timestamp"": ""2023-01-01T00:00:00Z"",
    })
",tests/test_db_schema.py,,1,6.348800075736417e-09,"The method 'test_valid_schema' is a unit test designed to verify that a valid schema does not raise exceptions when storing metadata in a database. Unit tests are crucial for ensuring code reliability and are typically retained in the codebase to maintain test coverage and facilitate future development. Therefore, it is unlikely that this method will be deleted unless the functionality it tests becomes obsolete or is replaced by a different testing approach."
survived,"    def send_transaction(self, transaction: SolanaTransaction) -> Dict[str, str]:
        """"""Send a transaction on the Solana chain.""""""
        # Get latest blockhash
        recent_blockhash = self.client.get_latest_blockhash()[""result""][""value""][""blockhash""]

        # Create transaction
        tx = Transaction()
        tx.recent_blockhash = recent_blockhash
        tx.fee_payer = self.keypair.public_key

        # Add instructions
        for instruction in transaction[""instructions""]:
            tx.add(instruction)

        # Add signers
        signers = [self.keypair]
        additional_signers = transaction.get(""accounts_to_sign"")
        if additional_signers is not None:
            signers.extend(additional_signers)

        # Sign and send transaction
        tx.sign(*signers)
        result = self.client.send_transaction(
            tx,
            *signers,
            opts={
                ""skip_preflight"": False,
                ""max_retries"": 10,
                ""preflight_commitment"": ""confirmed"",
            },
        )

        # Wait for confirmation
        self.client.confirm_transaction(
            result[""result""],
            commitment=""confirmed"",
        )

        return {""hash"": result[""result""]}
",python/src/wallets/solana/goat_wallets/solana/wallet.py,SolanaKeypairWalletClient,1,6.69158608681505e-10,"The method 'send_transaction' is likely to survive because it performs a critical function of sending transactions on the Solana blockchain, which is a fundamental operation for any blockchain-based application. The method is well-structured, follows a logical sequence of operations, and includes error handling through retries and preflight checks. Additionally, it uses standard practices such as signing transactions and waiting for confirmation, which are essential for ensuring the integrity and success of blockchain transactions. These factors make it a valuable and necessary component of any system interacting with the Solana blockchain."
survived,"def initialize_tool_with(mock_driver):
    tool = SeleniumScrapingTool()
    tool.driver = MagicMock(return_value=mock_driver)

    return tool
",tests/tools/selenium_scraping_tool_test.py,,1,8.152020648014727e-09,"The method 'initialize_tool_with' is a utility function that sets up a SeleniumScrapingTool with a mocked driver. This is useful for testing purposes, allowing developers to simulate interactions with a web driver without needing a real browser session. Such utility functions are common in test suites to facilitate unit testing and ensure code reliability. Given its utility in testing environments, it is likely to be retained in the codebase."
survived,"def test_scrape_without_css_selector(_mocked_chrome_driver):
    html_content = ""<html><body><div>test content</div></body></html>""
    mock_driver = mock_driver_with_html(html_content)
    tool = initialize_tool_with(mock_driver)

    result = tool._run(website_url=""https://example.com"")

    assert ""test content"" in result
    mock_driver.get.assert_called_once_with(""https://example.com"")
    mock_driver.find_element.assert_called_with(""tag name"", ""body"")
    mock_driver.close.assert_called_once()
",tests/tools/selenium_scraping_tool_test.py,,1,1.0467401685178159e-08,"The method 'test_scrape_without_css_selector' is a unit test designed to verify the functionality of a web scraping tool. It checks if the tool can correctly scrape content from a webpage without using a CSS selector. The test is well-structured, using mock objects to simulate the behavior of a web driver, and includes assertions to validate the expected behavior. Since testing is a crucial part of software development to ensure code reliability and correctness, this method is likely to be retained as part of the test suite to maintain code quality."
survived,"def test_tool_initialization():
    tool = SeleniumScrapingTool()

    assert tool.website_url is None
    assert tool.css_element is None
    assert tool.cookie is None
    assert tool.wait_time == 3
    assert tool.return_html is False
",tests/tools/selenium_scraping_tool_test.py,,1,1.725782769012759e-08,"The method 'test_tool_initialization' is a unit test designed to verify the default initialization state of a 'SeleniumScrapingTool' object. Unit tests are crucial for ensuring that code behaves as expected, especially after changes or refactoring. This test checks that the default values of the tool's attributes are correctly set, which is a fundamental aspect of software testing. Given the importance of testing in software development, this method is likely to be retained."
survived,"def main():
    url = input(f""{Colors.BLUE}Enter the website to crawl: {Colors.RESET}"")
    objective = input(f""{Colors.BLUE}Enter your objective: {Colors.RESET}"")
    
    print(f""{Colors.YELLOW}Initiating web crawling process...{Colors.RESET}"")
    map_website = find_relevant_page_via_map(objective, url, app, client)
    
    if map_website:
        print(f""{Colors.GREEN}Relevant pages identified. Proceeding with detailed analysis...{Colors.RESET}"")
        result = find_objective_in_top_pages(map_website, objective, app, client)
        
        if result:
            print(f""{Colors.GREEN}Objective successfully fulfilled. Extracted information:{Colors.RESET}"")
            print(f""{Colors.MAGENTA}{json.dumps(result, indent=2)}{Colors.RESET}"")
        else:
            print(f""{Colors.RED}Unable to fulfill the objective with the available content.{Colors.RESET}"")
    else:
        print(f""{Colors.RED}No relevant pages identified. Consider refining the search parameters or trying a different website.{Colors.RESET}"")
",examples/qwen3-web-crawler/qwen3_web_crawler.py,,1,6.023574641292144e-08,"The method 'main()' is a central part of a web crawling script, which is a common task in data collection and analysis. It includes user interaction, error handling, and logical flow to achieve a specific objective. The method is well-structured and provides meaningful feedback to the user, making it a useful component in web scraping applications. Given its utility and the fact that web crawling is a common requirement in many applications, it is likely to be retained."
survived,"    def test_call(
        self, mock_openai_class: MagicMock, mock_require_api_key: MagicMock
    ) -> None:
        """"""Test calling the openai class.""""""
        mock_require_api_key.return_value = ""test-key""
        mock_client = MagicMock()
        mock_openai_class.return_value = mock_client
        mock_response = MagicMock()
        mock_choice = MagicMock()
        mock_message = MagicMock()
        mock_message.content = ""Test response""
        mock_choice.message = mock_message
        mock_response.choices = [mock_choice]
        mock_client.chat.completions.create.return_value = mock_response

        model = openai(""gpt-4"")
        # Patch the _require_api_key property to return the test key directly
        with patch.object(model, ""_require_api_key"", ""test-key""):
            messages = [ChatMessage(role=""user"", content=""Test prompt"")]
            config = ChatModelConfig(
                max_tokens=100,
                temperature=0.7,
                top_p=0.9,
                frequency_penalty=0.5,
                presence_penalty=0.5,
            )

            result = model(messages, config)
            assert result == ""Test response""

            mock_openai_class.assert_called_once_with(
                api_key=""test-key"", base_url=None
            )
        mock_client.chat.completions.create.assert_called_once()
        call_args = mock_client.chat.completions.create.call_args[1]
        assert call_args[""model""] == ""gpt-4""
        assert len(call_args[""messages""]) == 2
        assert call_args[""messages""][0][""role""] == ""system""
        assert call_args[""messages""][0][""content""] == DEFAULT_SYSTEM_MESSAGE
        assert call_args[""messages""][1][""role""] == ""user""
        assert call_args[""messages""][1][""content""] == ""Test prompt""
        assert call_args[""max_tokens""] == 100
        assert call_args[""temperature""] == 0.7
        assert call_args[""top_p""] == 0.9
        assert call_args[""frequency_penalty""] == 0.5
        assert call_args[""presence_penalty""] == 0.5
        assert call_args[""stream""] is False
",tests/_ai/llm/_impl.py,TestOpenAI,1,2.5109990926928157e-08,"The method `test_call` is a unit test for a function that interacts with the OpenAI API. It uses mock objects to simulate the behavior of the OpenAI class and its methods, ensuring that the function behaves as expected without making actual API calls. This is a common practice in software development to test code in isolation and verify that it interacts correctly with external dependencies. Since testing is a crucial part of maintaining code quality and reliability, this method is likely to be retained in the codebase."
survived,"    def test_init(self) -> None:
        """"""Test initialization of the groq class.""""""
        model = groq(""llama3-70b-8192"")
        assert model.model == ""llama3-70b-8192""
        assert model.system_message == DEFAULT_SYSTEM_MESSAGE
        assert model.api_key is None
        assert model.base_url is None

        model = groq(
            ""llama3-70b-8192"",
            system_message=""Custom system message"",
            api_key=""test-key"",
            base_url=""https://example.com"",
        )
        assert model.model == ""llama3-70b-8192""
        assert model.system_message == ""Custom system message""
        assert model.api_key == ""test-key""
        assert model.base_url == ""https://example.com""
",tests/_ai/llm/_impl.py,TestGroq,1,8.152020648014727e-09,"The method `test_init` is a unit test designed to verify the initialization of a class, likely named `groq`. It checks that the class is correctly initialized with default values and with custom parameters. This is a fundamental part of testing to ensure that the class behaves as expected when instantiated. Such tests are crucial for maintaining code quality and reliability, especially when changes are made to the class in the future. Therefore, this method is likely to be retained as it serves an important role in the testing suite."
survived,"def test_google_require() -> None:
    """"""Test that google.require raises ModuleNotFoundError.""""""
    model = google(""gemini-pro"")
    messages = [ChatMessage(role=""user"", content=""Test prompt"")]
    config = ChatModelConfig()
    with pytest.raises(ModuleNotFoundError):
        model(messages, config)
",tests/_ai/llm/_impl.py,,1,4.1399375473943306e-08,"The method 'test_google_require' is a unit test designed to ensure that a specific error (ModuleNotFoundError) is raised when a certain condition is met. Unit tests are crucial for maintaining code quality and ensuring that changes do not introduce new bugs. This method is likely part of a test suite that verifies the behavior of the 'google' function or module. Since testing for exceptions is a common and necessary practice in software development, this method is likely to be retained as part of the codebase to ensure robustness and reliability."
survived,"    def test_require_api_key_missing(self, mock_get_context: MagicMock) -> None:
        """"""Test _require_api_key with missing key.""""""
        mock_context = MagicMock()
        mock_context.marimo_config = {""ai"": {""google"": {""api_key"": """"}}}
        mock_get_context.return_value = mock_context

        model = google(""gemini-pro"")
        with pytest.raises(ValueError):
            _ = model._require_api_key
",tests/_ai/llm/_impl.py,TestGoogle,1,4.1399375473943306e-08,"The method 'test_require_api_key_missing' is a unit test designed to verify the behavior of the '_require_api_key' method when the API key is missing. Unit tests are generally crucial for ensuring code reliability and are not typically deleted unless they are redundant or replaced by a more comprehensive testing strategy. This test specifically checks for a ValueError, which is a common practice to ensure that the code handles missing configurations properly. Therefore, it is likely to be retained as part of the test suite."
deleted,"    def test_marimo_strict_execution_error(self) -> None:
        error = MarimoStrictExecutionError(
            msg=""Strict execution error"",
            ref=""some_reference"",
            blamed_cell=""cell1"",
        )

        # Test properties
        assert error.type == ""strict-exception""
        assert error.describe() == ""Strict execution error""
        assert error.ref == ""some_reference""
        assert error.blamed_cell == ""cell1""
",tests/_messaging/test_errors.py,TestErrorClasses,1,4.944450477491054e-09,"The method `test_marimo_strict_execution_error` is a unit test for the `MarimoStrictExecutionError` class. It verifies that the properties of the error object are correctly set and that the `describe` method returns the expected message. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with error handling. Therefore, this method is likely to be retained as it contributes to the robustness of the codebase by validating the behavior of the `MarimoStrictExecutionError` class."
survived,"    def test_noop_stream(self) -> None:
        # Test that NoopStream implements Stream
        stream = NoopStream()

        # Should not raise any exceptions
        stream.write(""test_op"", {""key"": ""value""})
        stream.stop()

        # cell_id should be None by default
        assert stream.cell_id is None

        # Set cell_id
        stream.cell_id = ""test_cell""
        assert stream.cell_id == ""test_cell""
",tests/_messaging/test_types.py,TestStream,1,8.152020648014727e-09,"The method 'test_noop_stream' is a unit test designed to verify the behavior of the 'NoopStream' class. It checks that the class implements the 'Stream' interface correctly, does not raise exceptions on method calls, and allows setting and getting the 'cell_id' attribute. Unit tests are crucial for ensuring code reliability and are typically retained in the codebase to facilitate ongoing testing and validation. Therefore, this method is likely to be retained."
survived,"    def test_mime_bundle_or_tuple(self) -> None:
        # Test that MimeBundleOrTuple can be used as a type annotation
        def accepts_mime_bundle_or_tuple(
            bundle_or_tuple: MimeBundleOrTuple
        ) -> MimeBundleOrTuple:
            return bundle_or_tuple

        # Test with a bundle
        bundle: MimeBundle = {""text/plain"": ""Hello, world!""}
        assert accepts_mime_bundle_or_tuple(bundle) == bundle

        # Test with a tuple
        metadata = {""key"": ""value""}
        bundle_tuple: tuple[MimeBundle, Any] = (bundle, metadata)
        assert accepts_mime_bundle_or_tuple(bundle_tuple) == bundle_tuple",tests/_messaging/test_mimetypes.py,TestMimeTypes,1,9.237449576640118e-09,"The method 'test_mime_bundle_or_tuple' is a unit test designed to verify the functionality of a type annotation 'MimeBundleOrTuple'. It is a self-contained test that checks if the function 'accepts_mime_bundle_or_tuple' correctly handles both a 'MimeBundle' and a tuple containing a 'MimeBundle' and additional metadata. Since this test is useful for ensuring the correctness of the type handling and does not have any apparent issues or redundancies, it is likely to be retained in the codebase."
deleted,"    def test_is_unexpected_error(self) -> None:
        # These errors are expected/intentional
        assert not is_unexpected_error(MarimoAncestorPreventedError(
            msg="""", raising_cell=""cell1"", blamed_cell=None
        ))
        assert not is_unexpected_error(MarimoAncestorStoppedError(
            msg="""", raising_cell=""cell1""
        ))
        assert not is_unexpected_error(MarimoInterruptionError())

        # These errors are unexpected
        assert is_unexpected_error(MarimoExceptionRaisedError(
            msg="""", exception_type="""", raising_cell=None
        ))
        assert is_unexpected_error(MarimoSyntaxError(msg=""""))
        assert is_unexpected_error(UnknownError(msg=""""))
",tests/_messaging/test_errors.py,TestErrorUtilityFunctions,1,1.1861120010657661e-08,"The method 'test_is_unexpected_error' is a unit test function that verifies the behavior of the 'is_unexpected_error' function. It checks that certain error types are correctly identified as expected or unexpected. This is a typical and necessary part of software testing to ensure that the function behaves as intended. Since it serves a clear purpose in validating the functionality of error handling, it is unlikely to be deleted unless the functionality it tests is removed or significantly changed."
deleted,"    def test_delete_nonlocal_error(self) -> None:
        error = DeleteNonlocalError(
            name=""test_var"", cells=(""cell1"", ""cell2"")
        )

        # Test properties
        assert error.type == ""delete-nonlocal""
        assert ""test_var"" in error.describe()
        assert ""can't be deleted"" in error.describe()
",tests/_messaging/test_errors.py,TestErrorClasses,1,7.194132978569833e-09,"The method 'test_delete_nonlocal_error' is a unit test designed to verify the behavior of the 'DeleteNonlocalError' class. It checks that the error type is correctly set and that the description contains specific expected strings. This is a typical and necessary part of software development to ensure code reliability and correctness. Since it serves a clear purpose in testing the functionality of the 'DeleteNonlocalError' class, it is likely to be retained in the codebase."
survived,"def test_print_shutdown() -> None:
    """"""Test the print_shutdown function.""""""
    with patch(""marimo._server.print.print_"") as mock_print:
        with patch(""marimo._server.print.print_tabbed"") as mock_print_tabbed:
            with patch(""marimo._server.print._utf8"") as mock_utf8:
                mock_utf8.return_value = ""UTF8_EMOJI""
                print_shutdown()
                mock_print.assert_called()
                mock_print_tabbed.assert_called_once()
",tests/_server/test_print.py,,1,2.646573631904765e-09,"The method 'test_print_shutdown' is a unit test for the 'print_shutdown' function. Unit tests are crucial for ensuring code reliability and functionality, especially in larger projects. This test uses mocking to isolate the function being tested, which is a common and effective practice in unit testing. The presence of this test indicates that the 'print_shutdown' function is important enough to warrant verification of its behavior, suggesting that the test method is likely to be maintained as long as the function it tests remains relevant. Therefore, the method is likely to survive."
survived,"def test_read_toml_valid() -> None:
    with NamedTemporaryFile(mode=""w"", suffix="".toml"", delete=False) as f:
        f.write('value = ""test""')
        f.flush()

        reader = ConfigReader(f.name)
        fallback = TestConfig(value=""fallback"")
        result = reader.read_toml(TestConfig, fallback=fallback)
        assert result == TestConfig(value=""test"")

    os.unlink(f.name)",tests/_utils/config/test_config_reader.py,,1,4.1399375473943306e-08,"The method `test_read_toml_valid` is a unit test designed to verify the functionality of reading a TOML file using a `ConfigReader` class. It creates a temporary TOML file, writes a test value to it, and then checks if the `ConfigReader` correctly reads this value into a `TestConfig` object. The test also ensures that the fallback mechanism works by providing a fallback configuration. This test is essential for ensuring the reliability and correctness of the `ConfigReader` class, especially in handling TOML files. Therefore, it is likely to be retained as part of the test suite to maintain code quality and prevent regressions."
survived,"def test_multiple_conditional_tasks():
    """"""Test that having multiple conditional tasks in sequence works correctly.""""""
    task1 = Task(
        description=""Initial research task"",
        expected_output=""Research output"",
        agent=researcher,
    )
    
    def condition1(task_output: TaskOutput) -> bool:
        return ""success"" in task_output.raw.lower()
    
    def condition2(task_output: TaskOutput) -> bool:
        return ""proceed"" in task_output.raw.lower()
    
    task2 = ConditionalTask(
        description=""First conditional task"",
        expected_output=""Conditional output 1"",
        agent=writer,
        condition=condition1,
    )
    
    task3 = ConditionalTask(
        description=""Second conditional task"",
        expected_output=""Conditional output 2"",
        agent=writer,
        condition=condition2,
    )

    crew = Crew(
        agents=[researcher, writer],
        tasks=[task1, task2, task3],
    )

    # Mock different task outputs to test conditional logic
    mock_success = TaskOutput(
        description=""Mock success"",
        raw=""Success and proceed output"",
        agent=researcher.role,
    )
    
    # Set up mocks for task execution
    with patch.object(Task, ""execute_sync"", return_value=mock_success) as mock_execute:
        result = crew.kickoff()
        # Verify all tasks were executed (no IndexError)
        assert mock_execute.call_count == 3
        assert len(result.tasks_output) == 3
",tests/crew_test.py,,1,7.73442280641062e-08,The method is a test function that verifies the correct execution of multiple conditional tasks in sequence. It uses mock objects to simulate task outputs and checks that all tasks are executed as expected. This is a typical and useful test case in software development to ensure that conditional logic in task execution works correctly. Such test functions are generally retained as they are crucial for maintaining code quality and reliability.
survived,"def test_smart_wallet_balance(smart_api, test_wallet_options, test_keypair):
    """"""Test getting wallet balance.""""""
    # Create wallet and client
    wallet = smart_api.create_smart_wallet()
    client = SmartWalletClient(
        wallet[""address""],
        smart_api,
        test_wallet_options[""chain""],
        test_keypair,
        test_wallet_options[""provider""],
        test_wallet_options[""options""][""ensProvider""]
    )
    
    # Get balance
    balance = client.balance_of(wallet[""address""])
    assert ""value"" in balance
    assert ""symbol"" in balance
    assert balance[""symbol""] == ""ETH""
    assert ""decimals"" in balance
    assert balance[""decimals""] == 18
    assert ""name"" in balance
    assert balance[""name""] == ""Ethereum""
    assert ""in_base_units"" in balance
",python/src/wallets/crossmint/tests/test_smart_wallet.py,,1,3.2241866333029355e-08,"The method `test_smart_wallet_balance` is a unit test function that verifies the functionality of retrieving a wallet balance using a smart wallet API. It checks for the presence of expected fields in the balance response and validates their values. This is a crucial part of ensuring the reliability and correctness of the wallet balance feature in the application. Unit tests are essential for maintaining code quality and catching regressions, so this method is likely to be retained as part of the test suite."
survived,"def compare_transaction_responses(py_response: Dict[str, Any], ts_response: Dict[str, Any]) -> None:
    """"""Compare transaction responses between implementations.
    
    Args:
        py_response: Response from Python implementation
        ts_response: Response from TypeScript implementation
        
    Raises:
        AssertionError: If responses don't match
    """"""
    assert py_response[""status""] == ts_response[""status""], ""Transaction status doesn't match""
    assert py_response.get(""hash"") == ts_response.get(""hash""), ""Transaction hash doesn't match""
    
    # Compare onChain data if present
    if ""onChain"" in py_response or ""onChain"" in ts_response:
        py_onchain = py_response.get(""onChain"", {})
        ts_onchain = ts_response.get(""onChain"", {})
        assert py_onchain.get(""txId"") == ts_onchain.get(""txId""), ""Transaction IDs don't match""
",python/src/wallets/crossmint/tests/utils/helpers.py,,1,5.60279640614594e-09,"The method is a utility function that compares transaction responses from two different implementations (Python and TypeScript). It is useful for ensuring consistency and correctness between these implementations, which is a common requirement in software development, especially when dealing with transactions. The method is well-documented, has a clear purpose, and uses assertions to enforce expected behavior, making it a valuable tool for debugging and validation. Therefore, it is likely to be retained in the codebase."
survived,"def test_smart_wallet_batch_transactions(smart_api, test_wallet_options, test_keypair):
    """"""Test sending batch transactions.""""""
    # Create wallet and client
    wallet = smart_api.create_smart_wallet()
    client = SmartWalletClient(
        wallet[""address""],
        smart_api,
        test_wallet_options[""chain""],
        test_keypair,
        test_wallet_options[""provider""],
        test_wallet_options[""options""][""ensProvider""]
    )
    
    # Create batch of transactions
    transactions = [
        {
            ""to"": ""0x742d35Cc6634C0532925a3b844Bc454e4438f44e"",
            ""value"": 1000000000000000
        },
        {
            ""to"": ""0x742d35Cc6634C0532925a3b844Bc454e4438f44e"",
            ""value"": 2000000000000000
        }
    ]
    
    # Send batch
    tx = client.send_batch_of_transactions(transactions)
    assert tx[""status""] in [""success"", ""pending""]
    if tx[""status""] == ""success"":
        assert tx[""hash""].startswith(""0x"")
",python/src/wallets/crossmint/tests/test_smart_wallet.py,,1,4.1399375473943306e-08,"The method `test_smart_wallet_batch_transactions` is a test function that verifies the functionality of sending batch transactions using a smart wallet. Test functions are crucial for ensuring code reliability and correctness, especially in financial or blockchain applications where transactions are involved. The method is well-structured, with clear steps for creating a wallet, setting up a client, creating transactions, and asserting the expected outcomes. Given the importance of testing in software development and the specific focus on a critical feature (batch transactions), it is unlikely that this method will be deleted."
survived,"def test_smart_wallet_creation(smart_api):
    """"""Test smart wallet creation and retrieval.""""""
    # Create wallet
    wallet = smart_api.create_smart_wallet()
    assert wallet[""address""].startswith(""0x"")
    assert wallet[""type""] == ""evm-smart-wallet""
    
    # Verify retrieval
    retrieved = smart_api.get_wallet(wallet[""address""])
    compare_wallet_responses(wallet, retrieved)
",python/src/wallets/crossmint/tests/test_smart_wallet.py,,1,6.69158608681505e-10,"The method `test_smart_wallet_creation` is a unit test function that verifies the creation and retrieval of a smart wallet using a given API. It is a crucial part of ensuring the functionality and reliability of the smart wallet feature in the system. Unit tests are essential for maintaining code quality and catching bugs early in the development process. Therefore, this method is likely to be retained as it serves an important role in the testing suite."
survived,"def compare_approval_responses(py_response: Dict[str, Any], ts_response: Dict[str, Any]) -> None:
    """"""Compare approval responses between implementations.
    
    Args:
        py_response: Response from Python implementation
        ts_response: Response from TypeScript implementation
        
    Raises:
        AssertionError: If responses don't match
    """"""
    # Compare pending approvals if present
    if ""approvals"" in py_response or ""approvals"" in ts_response:
        py_approvals = py_response.get(""approvals"", {}).get(""pending"", [])
        ts_approvals = ts_response.get(""approvals"", {}).get(""pending"", [])
        assert len(py_approvals) == len(ts_approvals), ""Number of pending approvals doesn't match""
        
        for py_approval, ts_approval in zip(py_approvals, ts_approvals):
            assert py_approval.get(""message"") == ts_approval.get(""message""), ""Approval messages don't match""
            assert py_approval.get(""signer"") == ts_approval.get(""signer""), ""Approval signers don't match""
",python/src/wallets/crossmint/tests/utils/helpers.py,,1,4.944450477491054e-09,"The method is a utility function designed to compare two sets of approval responses from different implementations (Python and TypeScript). It checks for consistency in the number of pending approvals and their details, raising an AssertionError if discrepancies are found. This kind of function is useful for testing and validation purposes, ensuring that different implementations produce the same results. Such functions are typically retained as they are crucial for maintaining code quality and consistency across different platforms."
survived,"def test_custodial_wallet_raw_transaction(custodial_api, test_email, solana_connection):
    """"""Test sending raw transaction with custodial wallet.""""""
    # Create wallet and client
    wallet = custodial_api.create_custodial_wallet(test_email)
    client = CustodialSolanaWalletClient(
        wallet[""address""],
        custodial_api,
        solana_connection,
        {""email"": test_email}
    )
    
    # Create a simple message
    message = Message(
        instructions=[],  # Empty for test
        payer=Pubkey.from_string(wallet[""address""])
    )
    
    # Serialize and encode
    serialized = b58encode(bytes(message)).decode()
    
    # Send raw transaction
    tx = client.send_raw_transaction(serialized)
    assert tx[""status""] in [""success"", ""pending""]
    if tx[""status""] == ""success"":
        assert len(tx[""hash""]) > 0
",python/src/wallets/crossmint/tests/test_custodial_wallet.py,,1,3.653482080241728e-08,"The method 'test_custodial_wallet_raw_transaction' is a test function, likely part of a test suite for a larger application. Test functions are generally not deleted unless the feature they are testing is removed or significantly altered. Since this function is testing a specific feature (sending a raw transaction with a custodial wallet), it is likely to be maintained as long as the feature exists. Additionally, the function is well-structured and includes assertions to verify the expected behavior, indicating it is a useful part of the testing process."
survived,"def test_stream_text_representation_folder(sample_config):
    client = get_box_ccg_client(sample_config)
    stream = StreamTextRepresentationFolder(client, sample_config[""folder_id""])

    assert stream.folder_id == sample_config[""folder_id""]
    assert stream.client == client
    assert stream.primary_key == ""id""",airbyte-integrations/connectors/source-box-data-extract/unit_tests/test_streams.py,,1,6.348800075736417e-09,"The method 'test_stream_text_representation_folder' is a test function that verifies the correct initialization of a 'StreamTextRepresentationFolder' object. It checks if the 'folder_id', 'client', and 'primary_key' attributes are set correctly. Test functions are crucial for ensuring code reliability and are typically not deleted unless they are redundant or replaced by more comprehensive tests. Since this function serves a clear purpose in validating object initialization, it is likely to be retained."
survived,"def test_check_connection(mocker):
    source = SourceBoxDataExtract()
    logger_mock, config_mock = MagicMock(), MagicMock()
    assert source.check_connection(logger_mock, config_mock) == (False, ""Unable to connect to Box API with the provided credentials"")
",airbyte-integrations/connectors/source-box-data-extract/unit_tests/test_source.py,,1,9.931195248674785e-08,"The method 'test_check_connection' is a unit test for the 'check_connection' method of the 'SourceBoxDataExtract' class. Unit tests are crucial for ensuring that code behaves as expected and for catching regressions when code changes. This test specifically checks the behavior of the 'check_connection' method when it fails to connect to the Box API, which is an important scenario to validate. Therefore, it is unlikely that this method will be deleted as it serves a critical role in maintaining code quality and reliability."
survived,"    def read_records(
        self,
        sync_mode: SyncMode,
        cursor_field: Optional[List[str]] = None,
        stream_slice: Optional[Mapping[str, Any]] = None,
        stream_state: Optional[Mapping[str, Any]] = None,
    ) -> Iterable[StreamData]:
        logger.info(f""Extracting AI {self.prompt} for all files in folder {self.folder_id} {'recursively' if self.is_recursive else ''}"")
        items = box_folder_ai_extract(self.client, self.folder_id, prompt=self.prompt, is_recursive=self.is_recursive)
        for item in items:
            airbyte_item: StreamData = item.file.to_dict()
            airbyte_item[""text_representation""] = item.text_representation
            logger.info(f""Reading file {item.file.id} - {item.file.name}"")
            yield airbyte_item
",airbyte-integrations/connectors/source-box-data-extract/source_box_data_extract/source.py,StreamAIExtractFolder,1,4.944450477491054e-09,"The method 'read_records' is a core part of a data extraction process, which is essential for reading and processing data from a source. It is well-structured, uses logging for tracking progress, and yields data in a format that can be consumed by other parts of the system. These characteristics make it a valuable and necessary component in data processing pipelines, suggesting that it will likely be retained."
survived,"    def primary_key(self) -> Optional[Union[str, List[str], List[List[str]]]]:
        """"""
        :return: string if single primary key, list of strings if composite primary key, list of list of strings if composite primary key consisting of nested fields.
          If the stream has no primary keys, return None.
        """"""
        return ""id""
",airbyte-integrations/connectors/source-box-data-extract/source_box_data_extract/source.py,StreamAIExtractStructuredFolder,1,3.653482080241728e-08,"The method 'primary_key' is a utility function that provides a way to retrieve the primary key(s) of a data stream. It is useful for identifying unique records in a dataset, which is a common requirement in data processing and database management. The method is flexible, allowing for single, composite, and nested composite primary keys, and it returns None if no primary key is present. This functionality is essential for data integrity and management, making it unlikely to be deleted."
survived,"def add_extra_header_to_box_client(box_client: BoxClient) -> BoxClient:
    """"""
    Add extra headers to the Box client.

    Args:
        box_client (BoxClient): A Box client object.
        header (Dict[str, str]): A dictionary of extra headers to add to the Box client.

    Returns:
        BoxClient: A Box client object with the extra headers added.
    """"""
    header = {""x-box-ai-library"": ""airbyte""}
    return box_client.with_extra_headers(extra_headers=header)
",airbyte-integrations/connectors/source-box-data-extract/source_box_data_extract/box_api.py,,1,2.4616969512093895e-10,"The method 'add_extra_header_to_box_client' is likely to survive because it provides a useful functionality of adding extra headers to a Box client, which can be essential for customizing requests or adding metadata. The method is straightforward, has a clear purpose, and is implemented correctly by using the 'with_extra_headers' method of the BoxClient class. This kind of utility function is often needed in applications that interact with APIs, making it a valuable part of the codebase."
survived,"def test_create_coordinator_agent():
    """"""Test that the coordinator agent is created with the correct configuration.""""""
    science_agent = create_science_agent()
    tech_agent = create_tech_agent()
    
    coordinator = create_coordinator_agent([science_agent, tech_agent])
    
    assert coordinator.name == ""Coordinator""
    assert ""coordinator"" in coordinator.instructions.lower()
    assert len(coordinator.handoffs) == 2
",openai-agents-examples/02_multi_agent.py,,1,9.237449576640118e-09,"The method `test_create_coordinator_agent` is a unit test designed to verify the correct creation and configuration of a coordinator agent. It checks that the agent is created with the expected name, contains specific instructions, and has the correct number of handoffs. Such tests are crucial for ensuring the reliability and correctness of the code, especially in complex systems involving multiple agents. Therefore, it is likely to be retained as part of the test suite to maintain code quality."
survived,"def create_content_agent() -> Agent:
    """"""
    Create a content agent that writes engaging content.
    
    Returns:
        An Agent instance specialized in content writing.
    """"""
    instructions = """"""
    You are a content writing specialist who excels at creating engaging, informative content.
    Your task is to write high-quality content based on the provided outline and research.
    Use a conversational, engaging tone while maintaining accuracy and clarity.
    Include an attention-grabbing introduction, well-developed body paragraphs, and a compelling conclusion.
    Incorporate the research seamlessly into the content while maintaining a consistent voice.
    """"""
    
    return Agent(
        name=""ContentSpecialist"",
        instructions=instructions,
        model=""gpt-4o-mini"",
        handoff_description=""Use this agent to write engaging content based on an outline and research.""
    )
",openai-agents-examples/11_agent_orchestration.py,,1,8.592166611791576e-10,"The method `create_content_agent` is likely to survive because it encapsulates a clear and useful functionality: creating an agent specialized in content writing. This is a common requirement in many applications, especially those involving automated content generation or assistance. The method is well-documented, specifying the purpose and behavior of the agent, and it uses a structured approach to define the agent's instructions and model. Additionally, the use of a specific model ('gpt-4o-mini') suggests that this method is part of a larger system that utilizes AI models for various tasks, making it a valuable component of that system."
survived,"def test_run_conversation_with_context():
    """"""Test that the agent can maintain context across interactions.""""""
    import pytest
    
    # Skip this test if no API key is available
    if not os.environ.get(""OPENAI_API_KEY""):
        pytest.skip(""OPENAI_API_KEY not set"")
    
    # Run an initial query
    initial_prompt = ""Tell me about Mars""
    response, context = asyncio.run(run_conversation_with_context(initial_prompt))
    
    # Verify we got a non-empty response
    assert response
    assert len(response) > 0
    assert context is not None
    
    # Run a follow-up query that references the previous conversation
    follow_up_prompt = ""How long would it take to travel there?""
    follow_up_response, _ = asyncio.run(run_conversation_with_context(follow_up_prompt, context))
    
    # Verify the follow-up response acknowledges the previous context
    assert follow_up_response
    assert len(follow_up_response) > 0
    # The response should contain terms related to Mars travel
    assert any(term in follow_up_response.lower() for term in [""mars"", ""travel"", ""journey"", ""months""])
",openai-agents-examples/09_agent_with_context_management.py,,1,6.023574641292144e-08,"The method `test_run_conversation_with_context` is a test function designed to verify the functionality of maintaining context in a conversation with an AI agent. It is a crucial part of testing the robustness and reliability of the conversation system, especially when dealing with stateful interactions. The test checks if the system can handle follow-up queries that depend on previous context, which is a common requirement in conversational AI applications. Since this functionality is essential for ensuring the quality and correctness of the system, the test method is likely to be retained to ensure ongoing validation of this feature."
survived,"async def run_multi_agent_system(prompt: str) -> str:
    """"""
    Run the multi-agent system with the given prompt.
    
    Args:
        prompt: The user's query or prompt
        
    Returns:
        The final response from the appropriate specialist agent
    """"""
    # Create specialist agents
    science_agent = create_science_agent()
    tech_agent = create_tech_agent()
    
    # Create coordinator agent with specialists
    coordinator = create_coordinator_agent([science_agent, tech_agent])
    
    # Run the coordinator agent with the prompt
    result = await Runner.run(coordinator, prompt)
    
    # Return the final response
    return result.final_output
",openai-agents-examples/02_multi_agent.py,,1,8.592166611791576e-10,"The method 'run_multi_agent_system' is likely to survive because it is a well-structured asynchronous function that utilizes a multi-agent system to process a prompt and return a response. This approach is relevant in modern software development, especially in AI and machine learning applications where distributed processing and specialized agents are beneficial. The method is also clearly documented, making it maintainable and understandable for future developers."
survived,"def simulate_conversation(initial_prompt: str, follow_up_prompts: List[str]) -> List[str]:
    """"""
    Simulate a multi-turn conversation with context management.
    
    Args:
        initial_prompt: The first user prompt
        follow_up_prompts: List of follow-up prompts
        
    Returns:
        List of agent responses
    """"""
    responses = []
    context = None
    
    # Run the initial prompt
    response, context = asyncio.run(run_conversation_with_context(initial_prompt, context))
    responses.append(result.final_output)
    
    # Run each follow-up prompt with the updated context
    for prompt in follow_up_prompts:
        response, context = asyncio.run(run_conversation_with_context(prompt, context))
        responses.append(result.final_output)
    
    return responses
",openai-agents-examples/09_agent_with_context_management.py,,0,0.9999997300421382,"The method `simulate_conversation` is likely to be deleted because it contains several issues that suggest it is not functioning correctly. Firstly, the function uses `asyncio.run` to execute `run_conversation_with_context`, but the `result.final_output` is being appended to the responses list, which indicates a potential typo or misunderstanding, as `result` is not defined in the provided code. This suggests that the code may not run as intended. Additionally, the function does not handle exceptions or errors that might occur during asynchronous execution, which is crucial for robust code. These issues indicate that the method might be considered for deletion or significant revision."
survived,"def create_conversation_agent() -> Agent:
    """"""
    Create a conversation agent that can maintain context.
    
    Returns:
        An Agent instance that maintains conversation context.
    """"""
    instructions = """"""
    You are a helpful conversational assistant that maintains context across interactions.
    Remember details from previous parts of the conversation and refer back to them when relevant.
    Be friendly, informative, and engaging in your responses.
    If the user asks about something you discussed earlier, acknowledge that and build upon it.
    """"""
    
    return Agent(
        name=""ConversationAssistant"",
        instructions=instructions,
        model=""gpt-4o-mini"",
    )
",openai-agents-examples/09_agent_with_context_management.py,,1,2.998960815863541e-09,"The method 'create_conversation_agent' is likely to survive because it provides a clear and useful functionality by creating a conversational agent with context maintenance capabilities. This is a valuable feature in many applications, such as customer support or personal assistants, where maintaining context can significantly enhance user experience. Additionally, the method is well-documented, specifying its purpose and return type, which makes it easy to understand and integrate into larger systems."
survived,"def test_run_sync_agent():
    """"""Test that the agent can run synchronously and produce a response.""""""
    import pytest
    
    # Skip this test if no API key is available
    if not os.environ.get(""OPENAI_API_KEY""):
        pytest.skip(""OPENAI_API_KEY not set"")
    
    # Run a simple test query
    response = run_sync_agent(""What are some quick exercises I can do at my desk?"")
    
    # Verify we got a non-empty response
    assert response
    assert len(response) > 0
    # The response should contain relevant terms
    assert any(term in response.lower() for term in [""exercise"", ""stretch"", ""desk"", ""movement""])
",openai-agents-examples/03_sync_agent.py,,1,9.237449576640118e-09,"The method `test_run_sync_agent` is a test function that checks the functionality of a synchronous agent. It includes a check for an API key and uses assertions to verify the response. This is a typical structure for a test function in Python, especially when using pytest. Test functions are generally not deleted unless they are redundant or replaced by more comprehensive tests. Since this function is straightforward and serves a clear purpose in testing the agent's response, it is likely to be retained."
survived,"def create_agents_symlink():
    """"""Create a symlink from agents to openai.agents if needed.""""""
    try:
        import openai
        if hasattr(openai, 'agents'):
            # Create a symlink in site-packages
            site_packages = next(p for p in sys.path if 'site-packages' in p)
            agents_path = os.path.join(site_packages, 'agents')
            if not os.path.exists(agents_path):
                os.symlink(os.path.join(site_packages, 'openai', 'agents'), agents_path)
                print(f""Created symlink from {agents_path} to openai.agents"")
            else:
                print(f""Agents path already exists at {agents_path}"")
    except (ImportError, StopIteration, OSError) as e:
        print(f""Could not create symlink: {e}"")
",openai-agents-examples/fix_imports.py,,1,3.653482080241728e-08,"The method 'create_agents_symlink' is designed to create a symbolic link for the 'agents' directory within the 'openai' package if it doesn't already exist. This functionality is useful for ensuring that the 'agents' module can be accessed directly from 'site-packages', which can be important for compatibility or ease of access in certain environments. The method includes error handling for common issues such as missing imports or file system errors, making it robust. Given its utility in managing package paths and its error handling, it is likely to be retained in the codebase."
survived,"def main():
    """"""Main function to parse arguments and run the multi-agent system.""""""
    parser = argparse.ArgumentParser(description=""Multi-Agent Example"")
    parser.add_argument(""--prompt"", ""-p"", type=str, required=True, 
                        help=""The prompt to send to the multi-agent system"")
    
    args = parser.parse_args()
    
    # Ensure API key is available
    if not os.environ.get(""OPENAI_API_KEY""):
        console.print(Panel(""[bold red]Error: OPENAI_API_KEY environment variable not set[/bold red]""))
        sys.exit(1)
    
    try:
        # Run the multi-agent system and get response
        response = asyncio.run(run_multi_agent_system(args.prompt))
        
        # Display the response
        console.print(Panel(response, title=""Multi-Agent Response"", border_style=""green""))
    
    except Exception as e:
        console.print(Panel(f""[bold red]Error: {str(e)}[/bold red]""))
        sys.exit(1)
",openai-agents-examples/02_multi_agent.py,,1,1.1032560311263802e-09,"The method 'main()' is a crucial part of the script as it handles argument parsing, checks for necessary environment variables, and manages the execution of the multi-agent system. It also includes error handling to ensure the program exits gracefully in case of issues. These functionalities are essential for the script to operate correctly, making it unlikely that this method will be deleted."
survived,"def fix_imports_in_file(file_path):
    """"""Fix imports in a single file.""""""
    with open(file_path, 'r') as f:
        content = f.read()
    
    # First fix the Runner.run syntax error
    if 'from agents import Agent, Runner.run' in content:
        content = content.replace('from agents import Agent, Runner.run', 'from agents import Agent, Runner')
    
    if 'from agents import Agent, Runner.run_sync' in content:
        content = content.replace('from agents import Agent, Runner.run_sync', 'from agents import Agent, Runner')
    
    # Replace incorrect imports with correct ones based on documentation
    replacements = [
        ('from openai.agents import', 'from agents import'),
        ('import openai.agents', 'import agents'),
        ('from openai_agents import', 'from agents import'),
        ('import openai_agents', 'import agents'),
        ('from agents import Agent, run_agent', 'from agents import Agent, Runner'),
        ('from agents import Agent, run_agent_sync', 'from agents import Agent, Runner'),
        ('result = run_agent_sync', 'result = Runner.run_sync'),
        ('result = run_agent', 'result = Runner.run'),
        ('result = await run_agent_sync', 'result = await Runner.run_sync'),
        ('result = await run_agent', 'result = await Runner.run'),
        ('result.output', 'result.final_output'),
        ('return response, context', 'return result.final_output, result.context'),
        ('responses.append(response)', 'responses.append(result.final_output)'),
    ]
    
    new_content = content
    for old, new in replacements:
        new_content = new_content.replace(old, new)
    
    # Also update dependencies in the script header
    if '# dependencies = [' in new_content:
        # Update to use the correct package name and import path
        new_content = new_content.replace(
            '""openai-agents>=0.0.2"",', 
            '""openai>=1.66.0"",  # Includes agents module'
        )
        new_content = new_content.replace(
            '""openai>=1.66.0"",  # Includes agents module', 
            '""openai>=1.66.0"",  # Includes agents module'
        )
    
    if new_content != content:
        with open(file_path, 'w') as f:
            f.write(new_content)
        print(f""Fixed imports in {file_path}"")
    else:
        print(f""No changes needed in {file_path}"")
",openai-agents-examples/fix_imports.py,,1,9.237449576640118e-09,"The method 'fix_imports_in_file' is a utility function designed to correct import statements in a file. It is useful for maintaining code consistency and ensuring that the correct modules are imported, especially when there are changes in module paths or names. This kind of functionality is often needed in software development to handle refactoring or updates in dependencies. Therefore, it is likely to be retained as it serves a practical purpose in code maintenance."
survived,"def test_run_basic_agent():
    """"""Test that the agent can run and produce a response.""""""
    import pytest
    
    # Skip this test if no API key is available
    if not os.environ.get(""OPENAI_API_KEY""):
        pytest.skip(""OPENAI_API_KEY not set"")
    
    # Run a simple test query
    import asyncio
    response = asyncio.run(run_basic_agent(""What is 2+2?""))
    
    # Verify we got a non-empty response
    assert response
    assert len(response) > 0
    # The response should contain ""4"" somewhere
    assert ""4"" in response
",openai-agents-examples/01_basic_agent.py,,1,4.363462233903899e-09,"The method 'test_run_basic_agent' is a test function that checks the functionality of an agent by verifying its response to a simple query. It includes a check for an API key and uses assertions to ensure the response is valid and contains the expected result. This is a typical structure for a test function in Python, especially when using pytest. Since it serves a clear purpose in testing the agent's response and includes necessary checks, it is likely to be retained in the codebase."
survived,"async def test_update_files_endpoint():
    payload = {
        ""iat"": datetime.datetime.utcnow(),
        ""exp"": datetime.datetime.utcnow() + datetime.timedelta(days=1),
        ""subdomain"": ""abcd1234"",
    }
    token = jwt.encode(payload, ""test-secret"", algorithm=""HS256"")
    
    file_data = {
        ""index.html"": {
            ""raw"": ""SGVsbG8gV29ybGQ="",  # base64 encoded ""Hello World""
            ""headers"": [
                {""header"": ""Content-Type"", ""value"": ""text/plain""},
                {""header"": ""X-Custom"", ""value"": ""test""},
            ],
            ""status_code"": 200,
        }
    }
    
    with patch(""backend.app.config.jwt_secret"", ""test-secret""):
        response = client.post(
            ""/api/files"",
            params={""token"": token},
            json=file_data
        )
        
        assert response.status_code == 200
        
        mock_redis.set.assert_called_with(""files:abcd1234"", json.dumps(file_data))
",backend/tests/test_endpoints.py,,1,7.73442280641062e-08,"The method 'test_update_files_endpoint' is a unit test for an API endpoint that updates files. It uses mocking to simulate the environment and dependencies, such as JWT token generation and Redis storage. The test checks if the endpoint correctly processes the request and stores the data in Redis. This is a typical and necessary test for ensuring the functionality of an API, especially in a backend service. Given its importance in verifying the correct behavior of the endpoint, it is likely to be maintained and not deleted."
survived,"def test_get_random_subdomain():
    subdomain1 = get_random_subdomain()
    assert len(subdomain1) == config.subdomain_length
    assert all(c in config.subdomain_alphabet for c in subdomain1)
    
    custom_alphabet = ""ABC123""
    custom_length = 4
    subdomain2 = get_random_subdomain(custom_alphabet, custom_length)
    assert len(subdomain2) == custom_length
    assert all(c in custom_alphabet for c in subdomain2)
    
    subdomain3 = get_random_subdomain()
    assert subdomain1 != subdomain3  # This could theoretically fail but is extremely unlikely
",backend/tests/test_utils_extended.py,,1,3.850741907939403e-09,"The method 'test_get_random_subdomain' is a unit test function that verifies the behavior of the 'get_random_subdomain' function. It checks if the generated subdomain has the correct length and uses the correct alphabet, both for default and custom parameters. Additionally, it checks that two generated subdomains are not the same, which is a reasonable test for randomness. These are all valid and useful tests for ensuring the correctness of the 'get_random_subdomain' function. Therefore, the method is likely to be retained as it serves an important role in testing."
survived,"        async def send_message() -> str:
            """"""å‘é€è°ƒè¯•æ¶ˆæ¯åˆ°æµæ°´çº¿""""""
            try:
                data = await quart.request.get_json()
                session_type = data.get('session_type', 'person')
                content = data.get('content', '')
                
                if not content:
                    return self.http_status(400, -1, 'content is required')
                
                if session_type not in ['person', 'group']:
                    return self.http_status(400, -1, 'session_type must be person or group')
                
                webchat_adapter = None
                for bot in self.ap.platform_mgr.bots:
                    if hasattr(bot.adapter, '__class__') and bot.adapter.__class__.__name__ == 'WebChatAdapter':
                        webchat_adapter = bot.adapter
                        break
                
                if not webchat_adapter:
                    return self.http_status(404, -1, 'WebChat adapter not found')
                
                result = await webchat_adapter.send_debug_message(session_type, content)
                
                return self.success(data=result)
                
            except Exception as e:
                return self.http_status(500, -1, f'Internal server error: {str(e)}')
",pkg/api/http/controller/groups/debug/webchat.py,WebChatDebugRouterGroup,1,1.2501528648238603e-09,"The method 'send_message' is well-structured and serves a clear purpose of sending a debug message to a pipeline. It includes error handling, input validation, and checks for necessary conditions before proceeding with the main operation. The method is asynchronous, which is suitable for I/O operations like sending messages. It also provides meaningful HTTP status responses for different scenarios, which is a good practice for API methods. Given these factors, the method is likely to be useful and maintainable, leading to its survival."
survived,"    def unregister_listener(
        self,
        event_type: typing.Type[platform_events.Event],
        func: typing.Callable[[platform_events.Event, msadapter.MessagePlatformAdapter], typing.Awaitable[None]],
    ):
        """"""å–æ¶ˆæ³¨å†Œäº‹ä»¶ç›‘å¬å™¨""""""
        pass
",pkg/platform/sources/webchat.py,WebChatAdapter,1,3.927863699585036e-07,"The method `unregister_listener` is a placeholder function intended to remove an event listener. It is a common pattern in event-driven programming to have both registration and unregistration methods to manage event listeners. Although the method is currently not implemented (indicated by the `pass` statement), it is likely to be implemented in the future to complement the event registration process. This functionality is essential for managing resources and ensuring that listeners are not left active when they are no longer needed, which can lead to memory leaks or unintended behavior. Therefore, the method is likely to survive and be implemented rather than deleted."
survived,"    async def send_message(
        self,
        target_type: str,
        target_id: str,
        message: platform_message.MessageChain,
    ) -> dict:
        """"""å‘é€æ¶ˆæ¯åˆ°è°ƒè¯•ä¼šè¯""""""
        session_key = target_id
        
        if session_key not in self.debug_messages:
            self.debug_messages[session_key] = []
            
        message_data = {
            'id': len(self.debug_messages[session_key]) + 1,
            'type': 'bot',
            'content': str(message),
            'timestamp': datetime.now().isoformat(),
            'message_chain': [component.__dict__ for component in message]
        }
        
        self.debug_messages[session_key].append(message_data)
        
        await self.logger.info(f'WebChatå‘é€æ¶ˆæ¯åˆ° {session_key}: {message}')
        
        return {'success': True, 'message_id': message_data['id']}
",pkg/platform/sources/webchat.py,WebChatAdapter,1,3.850741907939403e-09,"The method 'send_message' is likely to survive because it performs a useful function of sending messages to a debug session, which is a common requirement in software development for testing and debugging purposes. The method is well-structured, uses asynchronous programming which is modern and efficient, and logs the message sending process, which is important for tracking and debugging. Additionally, it returns a success response with a message ID, which is useful for confirming the operation's success and for further processing."
survived,"    def __init__(self):
        self.client = typesense.Client(TYPESENSE_CONFIG)
",scripts/typesense_indexer.py,TypesenseIndexer,1,3.2241866333029355e-08,"The method is a constructor for initializing an instance of a class with a client attribute. This is a common pattern in object-oriented programming to set up necessary configurations or connections when an object is created. There is no indication that this method is redundant or unnecessary, as it serves a fundamental purpose in the class's functionality. Therefore, it is likely to be retained."
survived,"    def process_file(self, file_path: Path, docs_root: Path) -> Optional[Dict[str, Any]]:
        """"""Process a single markdown file.""""""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                post = frontmatter.load(f)
            
            metadata = post.metadata
            content = post.content
            
            rel_path = file_path.relative_to(docs_root)
            path_parts = list(rel_path.parts[:-1])  # Remove filename
            
            url_path = '/' + '/'.join(['docs'] + path_parts)
            if file_path.name != 'index.md':
                url_path += '/' + file_path.stem
            
            if url_path != '/' and url_path.endswith('/'):
                url_path = url_path.rstrip('/')
            
            title = metadata.get('title', '')
            if not title:
                headings = self.extract_headings(content)
                title = headings[0] if headings else file_path.stem.replace('-', ' ').replace('_', ' ').title()
            
            components = metadata.get('components', [])
            if isinstance(components, str):
                components = [components]
            
            headings = self.extract_headings(content)
            
            clean_content = self.clean_content(content)
            
            section = path_parts[0] if path_parts else 'docs'
            subsection = path_parts[1] if len(path_parts) > 1 else None
            
            document = {
                'title': title,
                'content': clean_content,
                'headings': headings,
                'path': str(rel_path),
                'url': url_path,
                'section': section,
            }
            
            if components:
                document['components'] = components
            
            if subsection:
                document['subsection'] = subsection
            
            return document
            
        except Exception as e:
            logger.error(f""Error processing {file_path}: {e}"")
            return None
",scripts/typesense_indexer.py,MarkdownProcessor,1,4.363462233903899e-09,"The method 'process_file' is a well-structured and comprehensive function that processes markdown files, extracts metadata, and constructs a document dictionary. It handles exceptions gracefully and logs errors, which is crucial for debugging and maintaining robust code. The method's functionality is essential for applications dealing with document processing, making it unlikely to be deleted unless the entire approach to file processing changes."
survived,"def test_solana_smart_wallet_with_email(smart_api, test_email, test_solana_wallet_options):
    """"""Test Solana smart wallet creation with email.""""""
    wallet = smart_api.create_wallet(
        wallet_type=WalletType.SOLANA_SMART_WALLET,
        linked_user=f""email:{test_email}""
    )
    assert wallet[""type""] == ""solana-smart-wallet""
    assert ""linkedUser"" in wallet
",python/src/wallets/crossmint/tests/test_solana_smart_wallet.py,,1,1.955568070542584e-08,"The method 'test_solana_smart_wallet_with_email' is a test function that verifies the creation of a Solana smart wallet with an email. It uses assertions to ensure the wallet type and linked user are correctly set. Test functions are generally important for maintaining code quality and ensuring that features work as expected. Since this function is part of a test suite, it is likely to be maintained and updated rather than deleted, as it helps in verifying the functionality of the smart wallet creation process."
survived,"def test_solana_smart_wallet_error_handling(smart_api):
    """"""Test error handling for Solana smart wallet operations.""""""
    # Test invalid wallet type
    with pytest.raises(Exception) as exc:
        smart_api.create_wallet(
            wallet_type=""invalid-wallet-type"",
            linked_user=""email:test@example.com""
        )
    assert ""error"" in str(exc.value).lower()
    
    # Test invalid transaction
    wallet = smart_api.create_wallet(
        wallet_type=WalletType.SOLANA_SMART_WALLET,
        linked_user=""email:test@example.com""
    )
    
    # Test with invalid transaction format
    invalid_tx = SolanaSmartWalletTransactionParams(
        transaction=""invalid-transaction""
    )
    with pytest.raises(Exception) as exc:
        smart_api.create_transaction_for_smart_wallet(
            wallet[""address""],
            invalid_tx,
            ""solana""
        )
    assert ""error"" in str(exc.value).lower() or ""invalid"" in str(exc.value).lower()
",python/src/wallets/crossmint/tests/test_solana_smart_wallet.py,,1,1.522997951276035e-08,"The method `test_solana_smart_wallet_error_handling` is a unit test designed to verify the error handling capabilities of a Solana smart wallet API. Unit tests are crucial for ensuring the reliability and robustness of software, especially in handling edge cases and invalid inputs. This test checks for proper exception raising and error messages when invalid wallet types and transactions are used. Such tests are typically retained in codebases to maintain software quality and prevent regressions. Therefore, it is likely to be retained."
survived,"def test_result_as_answer_in_tool_decorator():
    @tool(""Tool with result as answer"", result_as_answer=True)
    def my_tool_with_result_as_answer(question: str) -> str:
        """"""This tool will return its result as the final answer.""""""
        return question
    
    assert my_tool_with_result_as_answer.result_as_answer is True
    
    converted_tool = my_tool_with_result_as_answer.to_structured_tool()
    assert converted_tool.result_as_answer is True
    
    @tool(""Tool with default result_as_answer"")
    def my_tool_with_default(question: str) -> str:
        """"""This tool uses the default result_as_answer value.""""""
        return question
    
    assert my_tool_with_default.result_as_answer is False
    
    converted_tool = my_tool_with_default.to_structured_tool()
    assert converted_tool.result_as_answer is False",tests/tools/test_base_tool.py,,1,3.3982678079468468e-09,"The method `test_result_as_answer_in_tool_decorator` is a test function that verifies the behavior of a decorator `@tool` with respect to the `result_as_answer` attribute. It checks if the attribute is correctly set and maintained when converting the tool to a structured format. This kind of test is crucial for ensuring that the decorator behaves as expected, especially when dealing with configurations that affect the tool's output. Since it is a test function, it is likely to be retained as part of the test suite to ensure the reliability of the decorator functionality. Therefore, the method will survive."
survived,"    def __init__(self, name, price, category_id=None, description=None, sku=None, id=None):
        """"""Initialize a product.""""""
        self.id = id
        self.name = name
        self.price = price
        self.category_id = category_id
        self.description = description
        self.sku = sku
        self.created_at = datetime.now().isoformat()
        self.updated_at = self.created_at
",codebase-architectures/layered-architecture/models/product.py,Product,1,1.955568070542584e-08,"The method is a constructor (__init__) for a class, which is a fundamental part of object-oriented programming in Python. It is used to initialize the attributes of an instance of the class. Constructors are essential for setting up the initial state of an object, and there is no indication that this particular constructor is redundant or unnecessary. Therefore, it is unlikely to be deleted."
survived,"    def query(self, table_name, filter_func):
        """"""Query items from a table using a filter function.""""""
        if table_name not in self.data:
            Logger.warning(self.logger, f""Table '{table_name}' not found for query"")
            return []
        
        items = list(self.data[table_name].values())
        filtered_items = [item for item in items if filter_func(item)]
        Logger.debug(self.logger, f""Query returned {len(filtered_items)} items from '{table_name}'"")
        return filtered_items
",codebase-architectures/layered-architecture/data/database.py,InMemoryDatabase,1,2.3355930333443423e-09,"The method 'query' is a useful utility function for filtering data from a table based on a provided filter function. It includes error handling for cases where the table does not exist and logs the number of items returned, which are good practices. The method is likely to be retained as it provides a clear and efficient way to query data, which is a common requirement in data handling applications."
survived,"    def _execute_first_stage(self, input_stage):
        """"""Execute the input stage of the pipeline.""""""
        # This implementation assumes the input stage has load_data and validate_data methods
        result = input_stage.load_data(self.input_source, self.input_source_type)
        
        if result[""metadata""][""status""] != ""error"":
            if hasattr(self, ""required_fields""):
                result = input_stage.validate_data(required_fields=self.required_fields)
        
        return result
",codebase-architectures/pipeline-architecture/pipeline/pipeline_manager.py,DataProcessingPipeline,1,7.582560422162384e-10,"The method '_execute_first_stage' is likely to survive because it is a well-defined function that performs a specific task within a pipeline. It handles data loading and validation, which are common and necessary operations in data processing pipelines. The method is also flexible, checking for the presence of 'required_fields' before proceeding with validation, which suggests it is designed to be adaptable to different contexts. Additionally, the method includes error handling by checking the status in the metadata, which is a good practice in robust software development."
survived,"    def get_all_users():
        """"""Get all users.""""""
        return UserService.get_all_users()
",codebase-architectures/vertical-slice-architecture/features/users/api.py,UserAPI,0,0.999983298584886,"The method `get_all_users` is a simple wrapper around `UserService.get_all_users()`. If `UserService.get_all_users()` is a stable and reliable method, this wrapper might be considered redundant unless it adds some additional value, such as logging, error handling, or transformation of the data. Without these additional functionalities, the method might be seen as unnecessary and could be deleted to simplify the codebase."
survived,"    def logout(token: str) -> Dict:
        """"""
        Logout a user.
        
        Args:
            token: Authentication token
            
        Returns:
            Response with success status
        """"""
        success = logout_user(token)
        
        if success:
            return {
                ""status"": ""success"",
                ""message"": ""Logout successful"",
                ""data"": None
            }
        else:
            return {
                ""status"": ""error"",
                ""message"": ""Invalid token"",
                ""data"": None
            }
",codebase-architectures/atomic-composable-architecture/endpoints/user_api.py,UserAPI,1,3.850741907939403e-09,"The method is a straightforward implementation of a logout function, which is a common requirement in applications that manage user sessions. It checks the success of the logout operation and returns an appropriate response. The method is well-documented, with clear input and output specifications, making it useful and maintainable. There is no indication of redundancy or inefficiency that would warrant its deletion."
survived,"    def mark_as_read(token: str, notification_id: str) -> Dict:
        """"""
        Mark an alert as read.
        
        Args:
            token: Authentication token
            notification_id: The ID of the notification
            
        Returns:
            Response with success status or error message
        """"""
        # Validate token
        success, user_data = validate_user_token(token)
        if not success:
            return {
                ""status"": ""error"",
                ""message"": ""Invalid or expired token"",
                ""data"": None
            }
        
        # Mark as read
        success = mark_alert_as_read(user_data[""id""], notification_id)
        
        if success:
            return {
                ""status"": ""success"",
                ""message"": ""Alert marked as read"",
                ""data"": None
            }
        else:
            return {
                ""status"": ""error"",
                ""message"": ""Alert not found"",
                ""data"": None
            }
",codebase-architectures/atomic-composable-architecture/endpoints/alerts_api.py,AlertsAPI,1,6.69158608681505e-10,"The method 'mark_as_read' is a well-defined function that performs a common operation in applications that handle notifications. It includes token validation and updates the status of a notification, which are essential features for user interaction and notification management. The function is likely to be used frequently in applications that require marking notifications as read, making it a necessary part of the codebase. Therefore, it is unlikely to be deleted."
survived,"    def __init__(self):
        """"""Initialize the database.""""""
        self.data = {}
        self.logger = Logger.get_logger(""database"")
        Logger.info(self.logger, ""Database initialized"")
",codebase-architectures/layered-architecture/data/database.py,InMemoryDatabase,1,3.850741907939403e-09,"The method is a constructor (__init__) which is essential for initializing instances of a class. It sets up the initial state of the object by creating a data dictionary and a logger. Constructors are fundamental to object-oriented programming and are unlikely to be deleted unless the class itself is being removed or significantly refactored. Therefore, this method is likely to survive."
survived,"    def finalize(self):
        """"""
        Finalize the output stage.
        
        Returns:
            dict: Stage result with data and metadata
        """"""
        if self.metadata[""status""] not in [""error"", ""skipped""]:
            self.metadata[""status""] = ""completed""
            self.metadata[""completed_at""] = datetime.now().isoformat()
            
            # Calculate processing time if we have start time
            if ""started_at"" in self.metadata:
                start_time = datetime.fromisoformat(self.metadata[""started_at""])
                end_time = datetime.fromisoformat(self.metadata[""completed_at""])
                processing_time = (end_time - start_time).total_seconds()
                self.metadata[""processing_time_seconds""] = processing_time
        
        return self._create_result()
",codebase-architectures/pipeline-architecture/pipeline/output_stage.py,OutputStage,1,9.736200303530205e-10,"The method 'finalize' is likely to survive because it performs a crucial role in updating the status and metadata of a process. It ensures that the process is marked as completed, calculates the processing time, and returns the result. These functionalities are essential for tracking and managing the lifecycle of a process, making it unlikely to be removed unless there is a significant change in the system's architecture or requirements."
survived,"def get_timestamp():
    """"""Get the current timestamp.""""""
    return datetime.now().isoformat()
",codebase-architectures/vertical-slice-architecture/shared/utils.py,,1,5.3157849718487075e-08,"The method `get_timestamp` is a simple utility function that returns the current timestamp in ISO 8601 format. Such utility functions are commonly used in various applications for logging, tracking, or timestamping events. The function is straightforward, has a clear purpose, and is likely to be useful in many contexts. Therefore, it is unlikely to be deleted unless there is a specific reason to remove it, such as a change in requirements or a shift to a different method of obtaining timestamps."
survived,"def format_currency(amount):
    """"""Format a number as currency.""""""
    try:
        return f""${float(amount):.2f}""
    except (ValueError, TypeError):
        return ""N/A""
",codebase-architectures/pipeline-architecture/shared/utilities.py,,1,5.905303995456778e-10,"The method 'format_currency' is a simple utility function that formats a given number as a currency string. It includes error handling for invalid inputs, returning 'N/A' if the input cannot be converted to a float. This is a common and useful function in many applications that deal with financial data, making it likely to be retained. The function is concise, clear, and performs its intended task effectively, which are all indicators that it will survive."
survived,"    def to_dict(self):
        """"""Convert task to dictionary.""""""
        return {
            ""id"": self.id,
            ""title"": self.title,
            ""description"": self.description,
            ""user_id"": self.user_id,
            ""status"": self.status,
            ""created_at"": self.created_at,
            ""updated_at"": self.updated_at
        }
",codebase-architectures/vertical-slice-architecture/features/tasks/model.py,Task,1,5.905303995456778e-10,"The method `to_dict` is a common utility function used to convert an object into a dictionary representation. This is particularly useful for serialization, such as when preparing data to be sent over a network or saved to a file in a format like JSON. Given its utility in many applications, especially those involving data transfer or storage, it is likely to be retained in the codebase."
survived,"    def configure_input(self, source, source_type=""json"", required_fields=None):
        """"""
        Configure the input stage.
        
        Args:
            source: Path to the data file or raw data
            source_type: Type of data source (json, csv, raw)
            required_fields: List of required field names for validation
        """"""
        self.input_source = source
        self.input_source_type = source_type
        if required_fields:
            self.required_fields = required_fields
",codebase-architectures/pipeline-architecture/pipeline/pipeline_manager.py,DataProcessingPipeline,1,3.160881453314576e-10,"The method 'configure_input' is a utility function that sets up the input configuration for a data processing task. It is flexible, allowing for different source types and specifying required fields for validation. This kind of method is generally useful in data processing pipelines, making it likely to be retained in the codebase. Additionally, it is well-documented, which suggests it is intended for continued use."
survived,"def create_alert(user_id: str, message: str, level: str = ""info"", 
                data: Optional[Dict] = None) -> Dict:
    """"""
    Create an alert notification.
    
    Args:
        user_id: The ID of the user to alert
        message: The alert message
        level: Alert level (info, warning, error)
        data: Additional data for the alert
        
    Returns:
        The created notification
    """"""
    if data is None:
        data = {}
    
    data[""message""] = message
    
    notification = create_notification(
        user_id=user_id,
        notification_type=""alert"",
        data={
            **data,
            ""level"": level
        }
    )
    
    return notification",codebase-architectures/atomic-composable-architecture/modules/notifications.py,,1,9.736200303530205e-10,"The method 'create_alert' is likely to survive because it provides a clear and useful functionality for creating alert notifications. It is well-documented, specifying the purpose, arguments, and return value. The method is flexible, allowing for optional additional data and a default alert level, which makes it adaptable for various use cases. Furthermore, it leverages another function 'create_notification', suggesting it is part of a larger, possibly well-structured system. Unless there are changes in requirements or the system architecture that render this function obsolete, it is likely to remain useful."
survived,"    def from_dict(cls, data):
        """"""Create a product from dictionary.""""""
        product = cls(
            name=data[""name""],
            price=data[""price""],
            category_id=data.get(""category_id""),
            description=data.get(""description""),
            sku=data.get(""sku""),
            id=data.get(""id"")
        )
        product.created_at = data.get(""created_at"", product.created_at)
        product.updated_at = data.get(""updated_at"", product.updated_at)
        return product",codebase-architectures/layered-architecture/models/product.py,Product,1,1.3440409770490404e-08,"The method 'from_dict' is a common and useful pattern for creating instances of a class from a dictionary, especially in scenarios where data is often received in JSON format and needs to be converted into objects. This method is likely to be used in applications that deal with data serialization and deserialization, such as web applications or APIs. It provides a convenient way to instantiate objects with data that might come from external sources, like databases or API responses. Therefore, it is unlikely to be deleted as it serves a practical purpose in data handling."
survived,"    def _execute_stage(self, stage_instance, previous_result):
        """"""Execute a stage with the result from the previous stage.""""""
        # Determine which stage we're executing based on the instance type
        if hasattr(stage_instance, ""process""):
            # Processing stage
            result = stage_instance.process(previous_result)
            
            # Execute additional processing methods if configured
            if hasattr(self, ""processing_config""):
                config = self.processing_config
                
                # Calculate statistics if configured
                if config.get(""calculate_statistics""):
                    result = stage_instance.calculate_statistics(
                        numeric_fields=config.get(""numeric_fields"")
                    )
                
                # Apply filters if configured
                if ""filters"" in config:
                    for filter_config in config[""filters""]:
                        result = stage_instance.filter_data(
                            filter_config[""filter_func""],
                            filter_config.get(""description"")
                        )
                
                # Apply transformations if configured
                if ""transformations"" in config:
                    result = stage_instance.transform_fields(
                        config[""transformations""],
                        config.get(""transformation_description"")
                    )
            
            # Finalize the processing stage
            result = stage_instance.finalize()
            
        elif hasattr(stage_instance, ""prepare""):
            # Output stage
            result = stage_instance.prepare(previous_result)
            
            # Execute additional output methods if configured
            if hasattr(self, ""output_config""):
                config = self.output_config
                
                # Format as summary if configured
                if config.get(""format_summary"", False):
                    result = stage_instance.format_as_summary()
                
                # Format as detailed report if configured
                if config.get(""format_detailed"", False):
                    result = stage_instance.format_as_detailed_report()
                
                # Save to file if configured
                if ""save_to_file"" in config:
                    for save_config in config[""save_to_file""]:
                        result = stage_instance.save_to_file(
                            output_format=save_config.get(""format"", ""json""),
                            output_dir=save_config.get(""dir"", ""./output""),
                            filename=save_config.get(""filename"")
                        )
                
                # Print results if configured
                if config.get(""print_results""):
                    result = stage_instance.print_results(
                        output_type=config.get(""print_output_type"", ""summary"")
                    )
            
            # Finalize the output stage
            result = stage_instance.finalize()
            
        else:
            # Unknown stage type
            raise ValueError(f""Unknown stage type: {type(stage_instance).__name__}"")
        
        return result
",codebase-architectures/pipeline-architecture/pipeline/pipeline_manager.py,DataProcessingPipeline,1,2.2159489282323004e-08,"The method '_execute_stage' is well-structured and provides a comprehensive approach to executing different stages of a process, with flexibility for configuration. It handles both processing and output stages, includes error handling for unknown stage types, and allows for various configurations through 'processing_config' and 'output_config'. This makes it adaptable and useful in different scenarios, which are desirable traits in a method. Therefore, it is likely to be retained in the codebase."
survived,"    def __init__(self):
        """"""Initialize the output stage.""""""
        self.data = None
        self.analysis = None
        self.metadata = {
            ""stage"": ""output"",
            ""status"": ""initialized"",
            ""errors"": [],
            ""output_formats"": []
        }
",codebase-architectures/pipeline-architecture/pipeline/output_stage.py,OutputStage,1,1.1253518384332553e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming in Python. It initializes instance variables and sets up the initial state of an object. This is a standard practice and is necessary for the proper functioning of any class that requires initialization of its attributes. Therefore, it is unlikely to be deleted."
survived,"    def update_category(category_id, name=None, description=None):
        """"""Update a category.""""""
        try:
            category = CategoryService.update_category(category_id, name, description)
            if not category:
                return {
                    ""success"": False,
                    ""message"": f""Category with ID {category_id} not found""
                }
            return {
                ""success"": True,
                ""message"": ""Category updated successfully"",
                ""data"": category
            }
        except ValueError as e:
            Logger.warning(app_logger, f""Validation error in update_category: {str(e)}"")
            return {
                ""success"": False,
                ""message"": str(e)
            }
        except Exception as e:
            Logger.error(app_logger, f""Error in update_category: {str(e)}"", exc_info=True)
            return {
                ""success"": False,
                ""message"": ""An error occurred while updating the category""
            }
",codebase-architectures/layered-architecture/api/category_api.py,CategoryAPI,1,5.211412485172657e-10,"The method 'update_category' is likely to survive because it is a well-structured function that handles updating a category with error handling and logging. It provides clear feedback to the caller about the success or failure of the operation, which is essential for maintaining robust and user-friendly applications. Additionally, it uses a service layer (CategoryService) to perform the update, which is a good practice for separation of concerns."
survived,"    def to_response(self) -> Dict[str, Any]:
        """"""
        Convert the result to a response for Claude.
        
        Returns:
            Dictionary with result or error to send back to Claude
        """"""
        if self.success:
            return {""result"": self.data if self.data is not None else self.message}
        else:
            return {""error"": self.message}",example-agent-codebase-arch/layered-architecture/models/tool_models.py,FileOperationResult,1,3.850741907939403e-09,"The method `to_response` is a utility function that converts the result of an operation into a dictionary format, which is a common pattern in software development for creating API responses or handling data serialization. This method is straightforward, useful, and follows a clear logic to handle both success and error cases. It is likely to be retained as it provides a necessary functionality for converting internal results into a standardized response format, which is essential for communication with external systems or components like 'Claude'."
survived,"def display_token_usage(input_tokens: int, output_tokens: int) -> None:
    """"""
    Display token usage in a table.

    Args:
        input_tokens: Number of input tokens used
        output_tokens: Number of output tokens used
    """"""
    table = Table(title=""Token Usage"")
    table.add_column(""Type"", style=""cyan"")
    table.add_column(""Count"", style=""green"")
    
    table.add_row(""Input Tokens"", str(input_tokens))
    table.add_row(""Output Tokens"", str(output_tokens))
    table.add_row(""Total Tokens"", str(input_tokens + output_tokens))
    
    console.print(table)
",example-agent-codebase-arch/pipeline-architecture/main.py,,1,8.592166611791576e-10,"The method 'display_token_usage' is likely to survive because it provides a clear and useful functionality: displaying token usage in a formatted table. This is a common requirement in applications that deal with token-based systems, such as APIs or language models, where tracking and displaying token usage is important for monitoring and optimization purposes. The method is well-documented, with clear arguments and a straightforward implementation using a table format, which enhances readability and usability."
survived,"    def view_file(path: str, view_range=None) -> FileOperationResult:
        """"""
        View the contents of a file.

        Args:
            path: The path to the file to view
            view_range: Optional start and end lines to view [start, end]

        Returns:
            FileOperationResult with content or error message
        """"""
        try:
            # Normalize the path
            path = normalize_path(path)

            if not os.path.exists(path):
                error_msg = f""File {path} does not exist""
                console.log(f""[view_file] Error: {error_msg}"")
                return FileOperationResult(False, error_msg)

            with open(path, ""r"") as f:
                lines = f.readlines()

            if view_range:
                start, end = view_range
                # Convert to 0-indexed for Python
                start = max(0, start - 1)
                if end == -1:
                    end = len(lines)
                else:
                    end = min(len(lines), end)
                lines = lines[start:end]

            content = """".join(lines)

            # Display the file content (only for console, not returned to Claude)
            display_file_content(path, content)

            return FileOperationResult(True, f""Successfully viewed file {path}"", content)
        except Exception as e:
            error_msg = f""Error viewing file: {str(e)}""
            console.print(f""[red]{error_msg}[/red]"")
            console.log(f""[view_file] Error: {str(e)}"")
            console.log(traceback.format_exc())
            return FileOperationResult(False, error_msg)
",example-agent-codebase-arch/vertical-slice-architecture/features/file_operations/service.py,FileOperationService,1,2.0611536181902033e-09,"The method 'view_file' is well-structured and provides a useful functionality of viewing file contents with an optional range. It includes error handling, logging, and normalization of the file path, which are good practices. The method is likely to be used in applications where file content needs to be accessed and displayed, making it a valuable utility function. Therefore, it is likely to survive."
survived,"    def _str_replace(self, path: str, old_str: str, new_str: str) -> FileOperationResult:
        """"""
        Replace a specific string in a file.

        Args:
            path: The path to the file to modify
            old_str: The text to replace
            new_str: The new text to insert

        Returns:
            FileOperationResult with result or error message
        """"""
        try:
            # Normalize the path
            path = normalize_path(path)

            if not os.path.exists(path):
                error_msg = f""File {path} does not exist""
                console.log(f""[str_replace] Error: {error_msg}"")
                return FileOperationResult(False, error_msg)

            with open(path, ""r"") as f:
                content = f.read()

            if old_str not in content:
                error_msg = f""The specified string was not found in the file {path}""
                console.log(f""[str_replace] Error: {error_msg}"")
                return FileOperationResult(False, error_msg)

            new_content = content.replace(old_str, new_str, 1)

            with open(path, ""w"") as f:
                f.write(new_content)

            console.print(f""[green]Successfully replaced text in {path}[/green]"")
            console.log(f""[str_replace] Successfully replaced text in {path}"")
            return FileOperationResult(True, f""Successfully replaced text in {path}"")
        except Exception as e:
            error_msg = f""Error replacing text: {str(e)}""
            console.print(f""[red]{error_msg}[/red]"")
            console.log(f""[str_replace] Error: {str(e)}"")
            console.log(traceback.format_exc())
            return FileOperationResult(False, error_msg)
",example-agent-codebase-arch/pipeline-architecture/steps/processing_stage.py,ProcessingStage,1,1.0467401685178159e-08,"The method '_str_replace' is a utility function that performs a common and useful operation: replacing a string in a file. It includes error handling for file existence and string presence, and logs messages for both successful and unsuccessful operations. This functionality is often needed in file manipulation tasks, making it a valuable method to retain. Additionally, the method is well-documented and structured, which enhances its maintainability and usability in a codebase."
survived,"    def info(logger_name: str, message: str) -> None:
        """"""
        Log an info message.
        
        Args:
            logger_name: Name of the logger
            message: Message to log
        """"""
        console.log(f""[{logger_name}] [info] {message}"")
",example-agent-codebase-arch/layered-architecture/utils/logger.py,Logger,1,2.3355930333443423e-09,"The method 'info' is a simple utility function designed to log informational messages. It is straightforward, with a clear purpose and implementation. Such utility functions are commonly used in software projects to standardize logging practices. Unless there is a significant change in the logging framework or a shift in how logging is handled within the project, this method is likely to remain useful and relevant. Therefore, it is likely to survive."
deleted,"def file_exists(path: str) -> bool:
    """"""
    Check if a file exists.

    Args:
        path: The path to check

    Returns:
        True if the file exists, False otherwise
    """"""
    return os.path.exists(path) and os.path.isfile(path)",example-agent-codebase-arch/atomic-composable-architecture/atom/path_utils.py,,1,4.944450477491054e-09,"The method 'file_exists' is a utility function that checks if a file exists at a given path. This is a common and useful operation in many programming scenarios, such as validating file paths before attempting to read or write files. The method is simple, clear, and leverages the built-in 'os.path.exists' and 'os.path.isfile' functions, which are reliable and efficient. Therefore, there is no reason to delete this method as it serves a practical purpose and is implemented correctly."
survived,"def main():
    """"""Main entry point for the application.""""""
    # Set up argument parser
    parser = argparse.ArgumentParser(description=""Claude 3.7 File Editor Agent"")
    parser.add_argument(
        ""--prompt"",
        ""-p"",
        required=True,
        help=""The prompt for what file operations to perform"",
    )
    parser.add_argument(
        ""--max-loops"",
        ""-l"",
        type=int,
        default=15,
        help=""Maximum number of tool use loops (default: 15)"",
    )
    parser.add_argument(
        ""--thinking"",
        ""-t"",
        type=int,
        default=DEFAULT_THINKING_TOKENS,
        help=f""Maximum thinking tokens (default: {DEFAULT_THINKING_TOKENS})"",
    )
    parser.add_argument(
        ""--efficiency"",
        ""-e"",
        action=""store_true"",
        help=""Enable token-efficient tool use (beta feature)"",
    )
    args = parser.parse_args()

    console.print(Panel.fit(""Claude 3.7 File Editor Agent (Pipeline Architecture)""))
    console.print(f""\n[bold]Prompt:[/bold] {args.prompt}\n"")
    console.print(f""[dim]Thinking tokens: {args.thinking}[/dim]"")
    console.print(f""[dim]Max loops: {args.max_loops}[/dim]"")
    
    if args.efficiency:
        console.print(f""[dim]Token-efficient tools: Enabled[/dim]\n"")
    else:
        console.print(f""[dim]Token-efficient tools: Disabled[/dim]\n"")

    # For testing purposes, we'll just print a success message
    console.print(""[green]Successfully loaded the Pipeline Architecture implementation![/green]"")
    console.print(""[yellow]This is a mock implementation for testing the architecture structure.[/yellow]"")
    console.print(""[yellow]In a real implementation, this would connect to the Claude API.[/yellow]"")

    # Display mock token usage
    display_token_usage(1000, 500)
",example-agent-codebase-arch/pipeline-architecture/main.py,,1,3.653482080241728e-08,"The method 'main' is a well-structured entry point for a command-line application. It sets up an argument parser, handles command-line arguments, and provides informative console output. The method is essential for the application's functionality, especially for parsing user inputs and displaying relevant information. There is no indication that this method is redundant or unnecessary, and it appears to be a core part of the application's operation."
survived,"def display_token_usage(input_tokens: int, output_tokens: int) -> None:
    """"""
    Display token usage in a table.

    Args:
        input_tokens: Number of input tokens used
        output_tokens: Number of output tokens used
    """"""
    table = Table(title=""Token Usage"")
    table.add_column(""Type"", style=""cyan"")
    table.add_column(""Count"", style=""green"")
    
    table.add_row(""Input Tokens"", str(input_tokens))
    table.add_row(""Output Tokens"", str(output_tokens))
    table.add_row(""Total Tokens"", str(input_tokens + output_tokens))
    
    console.print(table)",example-agent-codebase-arch/vertical-slice-architecture/shared/utils.py,,1,8.592166611791576e-10,"The method 'display_token_usage' is likely to survive because it provides a clear and useful functionality: displaying token usage in a formatted table. This is a common requirement in applications that deal with token-based systems, such as APIs or language models, where tracking and displaying token usage is important for monitoring and optimization purposes. The method is well-documented, with clear arguments and a straightforward implementation using a table format, which enhances readability and usability."
survived,"def runner():
    return CliRunner()
",tests/cli/test_create_crew.py,,1,1.0467401685178159e-08,"The method 'runner' is a simple utility function that returns an instance of 'CliRunner'. This function is likely used to encapsulate the creation of 'CliRunner' objects, which can be useful for testing command-line interfaces. Such utility functions are common in codebases to avoid repetitive code and to provide a single point of modification if the instantiation logic changes. Therefore, it is likely to be retained in the codebase."
survived,"    def save_state(
        self,
        flow_uuid: str,
        method_name: str,
        state_data: Union[Dict[str, Any], BaseModel]
    ) -> None:
        """"""Persist the flow state after method completion.
        
        Args:
            flow_uuid: Unique identifier for the flow instance
            method_name: Name of the method that just completed
            state_data: Current state data (either dict or Pydantic model)
        """"""
        pass
",src/crewai/flow/persistence/base.py,FlowPersistence,1,1.0677030767166749e-06,"The method 'save_state' is a placeholder function with a clear purpose of persisting state data after a method completes. It includes detailed docstrings explaining its parameters and intended functionality. Although it currently lacks implementation, the method is likely part of a larger system where state persistence is crucial. Therefore, it is more probable that this method will be implemented in the future rather than deleted, as it serves a necessary role in maintaining the system's state consistency."
survived,"        def step_2(self):
            self.state.counter = 2
            self.state.message = ""Step 2""
",tests/test_flow_persistence.py,MultiStepFlow,1,4.944450477491054e-09,"The method 'step_2' is a simple setter method that updates the state of an object by setting a counter and a message. Such methods are typically used in state management or step-by-step processes. Unless there is a significant refactor or change in the design pattern that eliminates the need for step-based state management, this method is likely to survive. It is straightforward, serves a clear purpose, and is not overly complex, which are common reasons for methods to be retained."
survived,"def superfluid(options: Optional[SuperfluidPluginOptions] = None) -> SuperfluidPlugin:
    """"""
    Create a new instance of the Superfluid plugin.
    
    Args:
        options: Optional configuration options for the plugin
        
    Returns:
        A configured SuperfluidPlugin instance
    """"""
    return SuperfluidPlugin(options)",python/src/plugins/superfluid/goat_plugins/superfluid/__init__.py,,1,1.4166087846364157e-09,"The method 'superfluid' is a factory function that creates and returns an instance of 'SuperfluidPlugin'. It is well-documented, specifying the purpose, arguments, and return type. Such factory functions are common in software design for creating instances with optional configurations, making them useful for users who need to instantiate objects with specific settings. There is no indication of redundancy or obsolescence in the code, and it appears to be a straightforward and useful utility function. Therefore, it is likely to be retained in the codebase."
survived,"    def __init__(self, options: Optional[SuperfluidPluginOptions] = None):
        super().__init__(""superfluid"", [SuperfluidService()])
",python/src/plugins/superfluid/goat_plugins/superfluid/__init__.py,SuperfluidPlugin,1,1.1253518384332553e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting up initial states. The presence of a constructor is crucial for the proper functioning of the class, especially if it involves initializing services or setting up configurations, as seen with the 'SuperfluidService' in this code. Therefore, it is unlikely to be deleted."
survived,"    def get_member_flow_rate(self, wallet_client: EVMWalletClient, parameters: dict):
        result = wallet_client.read(
            {
                ""address"": parameters[""poolAddress""],
                ""abi"": POOL_ABI,
                ""functionName"": ""getMemberFlowRate"",
                ""args"": [parameters[""memberAddr""]],
            }
        )
        return result[""value""]
",python/src/plugins/superfluid/goat_plugins/superfluid/service.py,SuperfluidService,1,2.7894680920908113e-10,"The method 'get_member_flow_rate' is likely to survive because it performs a specific and useful function: it retrieves the flow rate of a member from a blockchain pool using a wallet client. This functionality is essential for applications that need to interact with smart contracts and manage or display user-specific data. The method is well-defined, uses parameters effectively, and leverages the wallet client's capabilities to interact with the blockchain, making it a valuable part of the codebase."
survived,"    async def JSONRpcFunc(self, parameters: dict):
        """"""Makes a POST request to the configured endpoint with the required JSON-RPC parameters.""""""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(self.endpoint, json=parameters) as response:
                    if not response.ok:
                        raise Exception(f""HTTP error! status: {response.status}, body: {await response.text()}"")
                    return await response.json()
        except Exception as e:
            raise Exception(f""Failed to call {self.endpoint}: {e}"")",python/src/plugins/jsonrpc/goat_plugins/jsonrpc/service.py,JSONRpcService,1,7.991959892315218e-11,"The method 'JSONRpcFunc' is a well-structured asynchronous function that performs a JSON-RPC call using aiohttp. It includes error handling for HTTP errors and exceptions during the request process, which is a good practice for network operations. The use of async/await is modern and efficient for I/O-bound operations, making it suitable for applications that require non-blocking network requests. Given these factors, the method is likely to be useful and relevant in many contexts, suggesting it will survive."
survived,"async def test_xai_raw_response_with_validator_async(model, mode):
    """"""Test that _raw_response works with validated models in async mode""""""
    client = instructor.from_provider(f""xai/{model}"", mode=mode, async_client=True)
    
    user = await client.chat.completions.create(
        response_model=UserValidated,
        max_retries=2,
        messages=[
            {
                ""role"": ""system"",
                ""content"": ""You are a helpful assistant that extracts information."",
            },
            {
                ""role"": ""user"",
                ""content"": ""Extract: Jason is 25 years old."",
            },
        ],
    )
    
    assert isinstance(user, UserValidated)
    assert user.name == ""JASON""
    assert user.age == 25
    assert hasattr(user, ""_raw_response""), (
        ""The raw response should be available from XAI""
    )
    assert user._raw_response is not None
",tests/llm/test_xai/test_raw_response.py,,1,1.3440409770490404e-08,"The method 'test_xai_raw_response_with_validator_async' is testing an important functionality of an asynchronous client in a machine learning or AI context. It ensures that the client can handle validated models and that the raw response is accessible, which is crucial for debugging and understanding the model's output. The method is well-structured, uses assertions to verify expected outcomes, and is likely part of a test suite that ensures the reliability of the system. Given the increasing importance of AI and machine learning, such testing methods are essential and are likely to be maintained rather than deleted."
survived,"    def validate_name(cls, v):
        if v.upper() != v:
            raise ValueError(
                ""Name should have all letters in uppercase. Make sure to use the `uppercase` form of the name""
            )
        return v
",tests/llm/test_xai/test_raw_response.py,UserValidated,1,1.955568070542584e-08,"The method 'validate_name' is a utility function that checks if a given string is in uppercase. This kind of validation is common in scenarios where data consistency is required, such as ensuring that all names in a database are stored in a uniform format. The method is simple, performs a specific task, and raises a clear error message if the condition is not met. There is no indication that this method is redundant or unnecessary, and it serves a clear purpose in data validation. Therefore, it is likely to be retained in the codebase."
survived,"    def get_context_window_size(self) -> int:
        return 8192
",tests/custom_llm_test.py,JWTAuthLLM,1,8.152020648014727e-09,"The method `get_context_window_size` is a simple getter method that returns a constant value of 8192. Such methods are typically retained in codebases because they encapsulate the logic for retrieving configuration or constant values, making the code more maintainable and easier to modify in the future if the constant value needs to change. Additionally, having a dedicated method for this purpose can improve code readability and provide a single point of change. Therefore, it is likely to survive."
