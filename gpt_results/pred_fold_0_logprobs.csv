status,method,filepath,class_name,predict,prob_deleted,reason
survived,"def test_keyword_only_param_removed():
    old_code = ""def func(*, a, b): pass""
    new_code = ""def func(*, b): pass""

    old_tree = ast.parse(old_code)
    new_tree = ast.parse(new_code)
    errors = check_signature_compatibility(old_tree.body[0], new_tree.body[0])

    assert len(errors) == 1
    assert errors[0].message == ""Keyword-only param 'a' was removed.""
    assert errors[0].param_name == ""a""
",tests/dev/test_check_function_signatures.py,,1,4.1399375473943306e-08,The method 'test_keyword_only_param_removed' is a test function that checks for the removal of a keyword-only parameter in a function signature. It is a useful test case for ensuring backward compatibility and detecting breaking changes in function signatures. Such test functions are typically retained to maintain code quality and prevent regressions.
survived,"def test_optional_keyword_only_became_required():
    old_code = ""def func(*, a=1): pass""
    new_code = ""def func(*, a): pass""

    old_tree = ast.parse(old_code)
    new_tree = ast.parse(new_code)
    errors = check_signature_compatibility(old_tree.body[0], new_tree.body[0])

    assert len(errors) == 1
    assert errors[0].message == ""Keyword-only param 'a' became required.""
    assert errors[0].param_name == ""a""
",tests/dev/test_check_function_signatures.py,,1,4.944450477491054e-09,"The method is a test function that checks for a specific change in function signature compatibility, which is a common requirement in software development to ensure backward compatibility. It is likely to be useful for developers to catch potential issues when function signatures change, especially in large codebases. Therefore, it is likely to be retained."
survived,"def get_changed_python_files(base_branch: str = ""master"") -> list[Path]:
    # In GitHub Actions PR context, we need to fetch the base branch first
    if is_github_actions():
        # Fetch the base branch to ensure we have it locally
        subprocess.check_call(
            [""git"", ""fetch"", ""origin"", f""{base_branch}:{base_branch}""],
        )

    result = subprocess.check_output(
        [""git"", ""diff"", ""--name-only"", f""{base_branch}...HEAD""], text=True
    )
    files = [s.strip() for s in result.splitlines()]
    return [Path(f) for f in files if f]
",dev/check_function_signatures.py,,1,2.0611536181902033e-09,"The method `get_changed_python_files` is likely to survive because it provides a useful utility function for determining which files have changed in a Git repository, specifically in the context of a GitHub Actions workflow. This is a common requirement in CI/CD pipelines to trigger specific actions based on file changes. The method is well-defined, uses standard subprocess calls to interact with Git, and filters the results to return a list of Path objects, which is a common and useful pattern in Python for handling file paths."
survived,"def test_complex_mixed_violations():
    old_code = ""def func(a, b=1, *, c, d=2): pass""
    new_code = ""def func(x, b, *, c=3, e): pass""

    old_tree = ast.parse(old_code)
    new_tree = ast.parse(new_code)
    errors = check_signature_compatibility(old_tree.body[0], new_tree.body[0])

    assert len(errors) == 3
    error_messages = [e.message for e in errors]
    assert any(""Positional param order/name changed: 'a' -> 'x'."" in msg for msg in error_messages)
    assert any(""Keyword-only param 'd' was removed."" in msg for msg in error_messages)
    assert any(""New required keyword-only param 'e' added."" in msg for msg in error_messages)
",tests/dev/test_check_function_signatures.py,,1,4.0586521248284276e-10,"The method 'test_complex_mixed_violations' is a unit test function that checks for specific signature compatibility errors between two versions of a function. It uses assertions to verify that the expected errors are detected. This is a typical pattern in test-driven development and is crucial for ensuring code quality and compatibility. Therefore, it is unlikely to be deleted as it serves an important role in validating code changes."
survived,"    def test_broadcasting_higher_dims(self, func):
        """"""Test that gufunc broadcasting works correctly for higher dimensional arrays.""""""
        np.random.seed(42)

        # 3D array: (2, 4, 10) -> broadcast dims (2,) + core dims (4, 10)
        data_3d = np.random.randn(2, 4, 10)
        result_3d = func(data_3d)
        assert result_3d.shape == (2, 4, 4)

        # 4D array: (2, 3, 4, 10) -> broadcast dims (2, 3) + core dims (4, 10)
        data_4d = np.random.randn(2, 3, 4, 10)
        result_4d = func(data_4d)
        assert result_4d.shape == (2, 3, 4, 4)

        # Check each broadcast element is valid
        for i in range(2):
            for j in range(3):
                matrix = result_4d[i, j]
                # Check symmetry
                assert_allclose(matrix, matrix.T, rtol=1e-10)

                if func == nancorrmatrix:
                    # Check diagonal is 1
                    assert_allclose(np.diag(matrix), np.ones(4), rtol=1e-10)
                    # Check bounds
                    assert np.all((matrix >= -1) & (matrix <= 1))
                else:
                    # Check diagonal (variance) is non-negative
                    assert np.all(np.diag(matrix) >= 0)

        # Verify correctness - each slice should match individual computation
        for i in range(2):
            single_result = func(data_3d[i])
            assert_allclose(result_3d[i], single_result, rtol=1e-10)
",numbagg/test/test_matrix_functions.py,TestMatrixFunctions,1,1.1253518384332553e-07,"The method is a well-structured test function that verifies the behavior of a function (likely a generalized ufunc) when applied to higher-dimensional arrays. It includes checks for expected output shapes, symmetry, and specific properties depending on the function being tested. Such test functions are crucial for ensuring the correctness of numerical computations, especially in scientific computing libraries like NumPy. Given its utility in validating important functionality, it is unlikely to be deleted."
survived,"    def test_different_dtypes(self):
        """"""Test consistency between float32 and float64.""""""
        data_f64 = np.array([[1, 2, 3, 4], [2, 4, 6, 8]], dtype=np.float64)
        data_f32 = data_f64.astype(np.float32)

        alpha = 0.5

        result_f64 = move_exp_nancorrmatrix(data_f64, alpha=alpha)
        result_f32 = move_exp_nancorrmatrix(data_f32, alpha=alpha)

        # Results should be close (within float32 precision)
        assert_allclose(result_f64, result_f32, rtol=1e-6)
",numbagg/test/test_move_exp_matrix_advanced.py,TestMoveExpMatrixAdvanced,1,3.850741907939403e-09,"The method `test_different_dtypes` is a unit test designed to ensure that the function `move_exp_nancorrmatrix` behaves consistently across different data types (float32 and float64). This is an important aspect of testing numerical functions, as it verifies that the function can handle different precisions without significant discrepancies in the results. Such tests are crucial for maintaining the reliability and robustness of numerical computations, especially in scientific and engineering applications. Therefore, this method is likely to be retained as it serves a valuable purpose in the testing suite."
survived,"    def test_numerical_stability_near_singular(self):
        """"""Test numerical stability with nearly linearly dependent variables.""""""
        np.random.seed(456)
        n_obs = 100
        a1 = np.random.randn(n_obs)
        # Create a2 that's almost identical to a1 but with detectable noise
        a2 = a1 + 1e-8 * np.random.randn(
            n_obs
        )  # Slightly larger noise for detectability

        data = np.array([a1, a2])

        corr_result = move_exp_nancorrmatrix(data, alpha=0.3)
        cov_result = move_exp_nancovmatrix(data, alpha=0.3)

        # Should not produce NaN or inf values
        assert np.all(np.isfinite(corr_result[-1]))
        assert np.all(np.isfinite(cov_result[-1]))

        # Correlation should be very close to 1
        final_corr = corr_result[-1]
        assert_allclose(final_corr[0, 1], 1.0, rtol=1e-4)

        # With the added noise, correlation should be slightly less than 1.0
        # But we'll be more lenient since exponential weighting might make it exactly 1.0
        assert final_corr[0, 1] <= 1.0
",numbagg/test/test_move_exp_matrix_advanced.py,TestMoveExpMatrixAdvanced,1,1.1861120010657661e-08,"The method tests the numerical stability of a function when dealing with nearly linearly dependent variables. It is a useful test to ensure that the functions `move_exp_nancorrmatrix` and `move_exp_nancovmatrix` handle edge cases without producing NaN or infinite values. Such tests are crucial for maintaining the robustness of numerical computations in software. Therefore, it is likely to be retained as part of the test suite."
survived,"    def test_covariance_consistency(self, alpha):
        """"""Test that move_exp_nancovmatrix matches move_exp_nancov for pairs.""""""
        np.random.seed(42)

        # Create two time series
        n_obs = 50
        a1 = np.random.randn(n_obs)
        a2 = np.random.randn(n_obs) * 2 + 1

        # Compute using non-matrix function
        cov_nonmatrix = move_exp_nancov(a1, a2, alpha=alpha)

        # Compute using matrix function
        data_matrix = np.array([a1, a2])
        cov_matrix_result = move_exp_nancovmatrix(data_matrix, alpha=alpha)

        # Extract the off-diagonal element (covariance between a1 and a2)
        cov_from_matrix = cov_matrix_result[:, 0, 1]

        # They should match
        assert_allclose(cov_nonmatrix, cov_from_matrix, rtol=1e-10)

        # Also check symmetry - (0,1) should equal (1,0)
        assert_allclose(
            cov_matrix_result[:, 0, 1], cov_matrix_result[:, 1, 0], rtol=1e-10
        )
",numbagg/test/test_move_exp_matrix_consistency.py,TestMoveExpMatrixConsistency,1,1.1861120010657661e-08,"The method is a unit test that verifies the consistency between two functions, `move_exp_nancov` and `move_exp_nancovmatrix`, ensuring they produce the same results for covariance calculations. Such tests are crucial for maintaining code reliability and correctness, especially when dealing with mathematical computations. Therefore, it is likely to be retained as part of the test suite to ensure ongoing accuracy and consistency of the functions it tests."
survived,"    def test_min_weight_consistency(self):
        """"""Test consistency with different min_weight values.""""""
        np.random.seed(111)

        # Create two time series
        n_obs = 25
        a1 = np.random.randn(n_obs)
        a2 = np.random.randn(n_obs) * 1.3

        alpha = 0.2  # Low alpha to test min_weight effects
        min_weight = 0.5

        # Compute using non-matrix functions
        cov_nonmatrix = move_exp_nancov(a1, a2, alpha=alpha, min_weight=min_weight)
        corr_nonmatrix = move_exp_nancorr(a1, a2, alpha=alpha, min_weight=min_weight)

        # Compute using matrix functions
        data_matrix = np.array([a1, a2])
        cov_matrix_result = move_exp_nancovmatrix(
            data_matrix, alpha=alpha, min_weight=min_weight
        )
        corr_matrix_result = move_exp_nancorrmatrix(
            data_matrix, alpha=alpha, min_weight=min_weight
        )

        # Extract off-diagonal elements
        cov_from_matrix = cov_matrix_result[:, 0, 1]
        corr_from_matrix = corr_matrix_result[:, 0, 1]

        # They should match
        assert_allclose(cov_nonmatrix, cov_from_matrix, rtol=1e-10)
        assert_allclose(corr_nonmatrix, corr_from_matrix, rtol=1e-10)
",numbagg/test/test_move_exp_matrix_consistency.py,TestMoveExpMatrixConsistency,1,8.76424914819242e-08,"The method is a unit test designed to ensure the consistency of results between two different implementations of moving exponential covariance and correlation calculations. It is a crucial part of maintaining code reliability and correctness, especially when dealing with numerical computations. Such tests are essential for validating that refactoring or optimization of code does not alter the expected outcomes. Therefore, it is unlikely to be deleted as it serves an important role in the software development process."
survived,"    def test_different_alphas(self, func):
        """"""Test behavior with different alpha values.""""""
        data = np.array([[1, 2, 3, 4, 5], [1, 4, 9, 16, 25]], dtype=np.float64)

        # High alpha (fast decay) vs low alpha (slow decay)
        result_high = func(data, alpha=0.9)
        result_low = func(data, alpha=0.1)

        # Both should have same shape
        assert result_high.shape == result_low.shape == (5, 2, 2)

        # Results should be different
        assert not np.allclose(result_high[-1], result_low[-1], rtol=1e-3)
",numbagg/test/test_move_exp_matrix.py,TestMoveExpMatrixFunctions,1,3.850741907939403e-09,"The method `test_different_alphas` is a unit test designed to verify the behavior of a function `func` when applied to a dataset with different alpha values. It checks that the function produces outputs of the same shape for different alpha values and that the results are not identical, which is a reasonable test for functions that involve decay or smoothing parameters. Since this test is useful for ensuring the correctness and robustness of the function being tested, it is likely to be retained in the codebase."
survived,"    def __init__(
        self,
        func: Callable,
        signature: tuple[list[tuple], str],
        **kwargs,
    ):
        self.signature = signature
        super().__init__(func, **kwargs)
",numbagg/decorators.py,ndmoveexpmatrix,1,2.646573631904765e-09,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. It initializes the object with a function and a signature, and it also calls the superclass's constructor. This is a typical pattern in Python for setting up class instances, and there is no indication that it is deprecated or unnecessary. Therefore, it is likely to survive."
survived,"    def test_scan_content_with_context(self, runner, temp_model_dir):
        """"""Test content search with context lines""""""
        result = runner.invoke(
            scan_app,
            [""content"", ""Hello"", ""--path"", str(temp_model_dir), ""--context"", ""5"", ""--format"", ""json""]
        )
        
        assert result.exit_code == 0
        output = json.loads(result.stdout)
        assert 'matches' in output
        if output['matches']:
            assert 'context' in output['matches'][0]
",tests/test_scan/test_cli.py,TestScanCLI,1,9.736200303530205e-10,"The method 'test_scan_content_with_context' is a unit test designed to verify the functionality of a content scanning application. It checks if the application correctly returns search results with context lines. This is a typical test case that ensures the application behaves as expected, especially when dealing with command-line interfaces and JSON outputs. Such test methods are crucial for maintaining software quality and are unlikely to be deleted unless the functionality they test is removed or significantly altered. Therefore, the method is likely to survive."
survived,"    def test_get_action_prompt(self):
        """"""Test action prompt retrieval""""""
        # Known action
        prompt = self.generator._get_action_prompt('add_type_hints')
        assert 'type hints' in prompt
        
        # Unknown action
        prompt = self.generator._get_action_prompt('unknown_action')
        assert prompt == 'Perform unknown_action on this file following best practices'
",tests/test_scan/test_generate_parallel.py,TestParallelYAMLGenerator,1,2.0611536181902033e-09,"The method `test_get_action_prompt` is a unit test designed to verify the behavior of the `_get_action_prompt` method in the `generator` object. It checks both a known action and an unknown action, ensuring that the method returns the expected prompts. Unit tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, this method is likely to be retained as it serves an important role in the testing suite."
survived,"    def _compare_metadata(self, model_data: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
        """"""Compare model metadata""""""
        metadata = {}
        
        for model, data in model_data.items():
            model_meta = {
                'has_config': data.get('config') is not None,
                'file_count': len(data.get('files', [])),
                'config_keys': list(data['config'].keys()) if data.get('config') else []
            }
            
            # Extract specific metadata if available
            if data.get('config'):
                config = data['config']
                important_keys = [
                    'model_type', 'architecture', 'license', 
                    'training_data', 'created_by', 'version'
                ]
                
                for key in important_keys:
                    if key in config:
                        model_meta[key] = config[key]
            
            metadata[model] = model_meta
        
        return metadata
",src/haconiwa/scan/comparator.py,ModelComparator,1,5.905303995456778e-10,"The method '_compare_metadata' is likely to survive because it provides a useful functionality of comparing and extracting metadata from a given dictionary of model data. It processes the input to extract relevant information such as configuration presence, file count, and specific configuration keys, which can be crucial for understanding and managing model metadata in various applications. The method is well-structured, and its purpose is clear, making it a valuable utility in contexts where model metadata needs to be analyzed or reported."
survived,"    def generate_project_wide(self,
                            action: str,
                            file_pattern: str = ""*.py"",
                            exclude_patterns: Optional[List[str]] = None) -> Dict[str, Any]:
        """"""Generate YAML for project-wide changes""""""
        
        from .scanner import ModelScanner
        
        scanner = ModelScanner(self.base_path)
        files = []
        
        # Find all matching files
        for file_path in scanner._iter_files([file_pattern]):
            if exclude_patterns:
                skip = False
                for pattern in exclude_patterns:
                    if pattern in str(file_path):
                        skip = True
                        break
                if skip:
                    continue
            
            files.append(str(file_path.relative_to(self.base_path)))
        
        # Generate tasks
        tasks = []
        for file_path in files[:50]:  # Limit to 50 files for safety
            prompt = self._get_action_prompt(action)
            tasks.append({
                'file': file_path,
                'prompt': prompt
            })
        
        config = {
            'provider': 'claude',
            'metadata': {
                'generated_at': datetime.now().isoformat(),
                'source': 'haconiwa scan generate-parallel-config',
                'action': action,
                'file_pattern': file_pattern,
                'total_tasks': len(tasks)
            },
            'tasks': tasks,
            'options': {
                'max_concurrent': 5,
                'timeout': 120,
                'allowed_tools': ['Read', 'Write', 'Edit', 'MultiEdit'],
                'permission_mode': 'confirmEach',
                'output_dir': f'./project-wide-{action}'
            }
        }
        
        return config
",src/haconiwa/scan/generate_parallel.py,ParallelYAMLGenerator,1,2.3355930333443423e-09,"The method 'generate_project_wide' is a utility function that generates a configuration for project-wide changes, specifically for generating YAML configurations. It includes functionality to scan files, apply exclusion patterns, and create tasks with specific prompts. This method is likely to be useful in scenarios where automated project-wide changes are needed, such as in large codebases or CI/CD pipelines. The method is well-structured, has a clear purpose, and includes safety measures like limiting the number of files processed. These factors suggest that the method is valuable and likely to be retained in the codebase."
survived,"    def _is_model_directory(self, path: Path) -> bool:
        """"""Check if a directory likely contains model-related files""""""
        model_indicators = [
            'model', 'models', 'checkpoint', 'weights',
            'config.json', 'model.json', 'tokenizer',
            '.pt', '.pth', '.onnx', '.pb', '.h5'
        ]
        
        path_str = str(path).lower()
        return any(indicator in path_str for indicator in model_indicators)
",src/haconiwa/scan/scanner.py,ModelScanner,1,2.0611536181902033e-09,"The method `_is_model_directory` is a utility function that checks if a given directory path likely contains model-related files by looking for specific keywords or file extensions. This is a common requirement in machine learning and data science projects where managing and identifying model directories is crucial. The method is simple, efficient, and serves a clear purpose, making it useful for various applications that involve model management. Therefore, it is likely to be retained in the codebase."
survived,"    def _compare_formats(self, model_data: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
        """"""Compare available model formats""""""
        formats = {}
        
        format_extensions = {
            '.pt': 'PyTorch',
            '.pth': 'PyTorch',
            '.onnx': 'ONNX',
            '.pb': 'TensorFlow',
            '.h5': 'Keras',
            '.tflite': 'TensorFlow Lite',
            '.safetensors': 'SafeTensors',
            '.gguf': 'GGUF',
            '.bin': 'Binary'
        }
        
        for model, data in model_data.items():
            model_formats = set()
            
            for file_info in data.get('files', []):
                file_path = Path(file_info['path'])
                if file_path.suffix in format_extensions:
                    model_formats.add(format_extensions[file_path.suffix])
            
            formats[model] = list(model_formats)
        
        return formats
",src/haconiwa/scan/comparator.py,ModelComparator,1,2.998960815863541e-09,"The method '_compare_formats' is a utility function that processes a dictionary of model data to identify and categorize the file formats of the models. It uses a predefined mapping of file extensions to format names and returns a dictionary that maps each model to a list of its available formats. This functionality is useful for applications that need to handle or display model formats, and it is likely to be a part of a larger system that deals with machine learning models. The method is well-defined, serves a clear purpose, and is not overly complex, making it unlikely to be deleted."
survived,"    def test_generate_prompt_for_file_fallback(self):
        """"""Test prompt generation fallback for unknown categories""""""
        prompt = self.generator._generate_prompt_for_file(
            'src/unknown/file.py',
            'add_tests',
            None
        )
        
        assert prompt == 'Create unit tests with pytest covering edge cases'
",tests/test_scan/test_generate_parallel.py,TestParallelYAMLGenerator,1,1.725782769012759e-08,"The method `test_generate_prompt_for_file_fallback` is a unit test designed to verify the behavior of the `_generate_prompt_for_file` method when it encounters an unknown category. This is a common scenario that needs to be tested to ensure the robustness of the code. The test checks if the method returns a default prompt, which is a reasonable fallback behavior. Since testing for edge cases and ensuring fallback mechanisms are in place is crucial for software reliability, this test method is likely to be retained to maintain code quality."
survived,"    def _should_ignore(self, path: Path) -> bool:
        """"""Check if path should be ignored""""""
        path_str = str(path)
        
        # Check whitelist first
        if self.whitelist:
            whitelisted = any(
                fnmatch.fnmatch(path_str, pattern) or 
                pattern in path_str 
                for pattern in self.whitelist
            )
            if not whitelisted:
                return True
        
        # Check ignore patterns
        for pattern in self.ignore_patterns:
            if fnmatch.fnmatch(path.name, pattern):
                return True
            if pattern in path_str:
                return True
        
        return False
",src/haconiwa/scan/scanner.py,ModelScanner,1,9.237449576640118e-09,"The method '_should_ignore' is a utility function that checks if a given path should be ignored based on whitelist and ignore patterns. This type of functionality is common in file handling and configuration management, where certain files or directories need to be excluded from processing. The method is well-defined, performs a specific task, and is likely to be useful in the context of the class it belongs to. Therefore, it is unlikely to be deleted unless the entire feature it supports is removed or significantly refactored."
survived,"    def test_different_alphas(self, func):
        """"""Test behavior with different alpha values.""""""
        # Exponential moving functions expect (obs, vars) format
        data = np.array([[1, 1], [2, 4], [3, 9], [4, 16], [5, 25]], dtype=np.float64)

        # High alpha (fast decay) vs low alpha (slow decay)
        result_high = func(data, alpha=0.9)
        result_low = func(data, alpha=0.1)

        # Both should have same shape
        assert result_high.shape == result_low.shape == (5, 2, 2)

        # Results should be different
        assert not np.allclose(result_high[-1], result_low[-1], rtol=1e-3)
",numbagg/test/test_matrix_functions.py,TestExponentialMatrices,1,1.0467401685178159e-08,"The method `test_different_alphas` is a unit test designed to verify the behavior of a function `func` when applied to data with different alpha values. It checks that the function produces outputs of the same shape for different alpha values and that the results are different, which are reasonable expectations for a test. The method is well-structured, serves a clear purpose, and is likely part of a test suite to ensure the correctness of the `func` implementation. There is no indication that this method is obsolete or redundant, and it provides valuable validation for the function being tested. Therefore, it is likely to be retained."
survived,"    def test_fixed_dimensional_conventions(self):
        """"""Test fixed dimensional conventions: (..., obs, vars) -> (..., obs, vars, vars).""""""
        np.random.seed(42)

        # Basic test: (obs, vars) -> (obs, vars, vars)
        data_moving = np.random.randn(100, 3)  # (obs, vars)
        corr_moving = move_nancorrmatrix(data_moving, window=10)
        cov_moving = move_nancovmatrix(data_moving, window=10)

        assert corr_moving.shape == (100, 3, 3)
        assert cov_moving.shape == (100, 3, 3)

        # Broadcasting test: (batch, obs, vars) -> (batch, obs, vars, vars)
        data_moving_3d = np.random.randn(2, 100, 3)  # (batch, obs, vars)
        corr_moving_3d = move_nancorrmatrix(data_moving_3d, window=10)

        assert corr_moving_3d.shape == (2, 100, 3, 3)
",numbagg/test/test_matrix_functions.py,TestMovingMatrices,1,4.1399375473943306e-08,"The method `test_fixed_dimensional_conventions` is a unit test designed to verify the behavior of functions `move_nancorrmatrix` and `move_nancovmatrix`. It checks if these functions correctly transform input data of certain dimensions into the expected output dimensions. This is a crucial part of ensuring the reliability and correctness of the code, especially in numerical and data processing libraries. Unit tests are generally not deleted unless they are redundant or replaced by more comprehensive tests. Since this test is specific and checks important functionality, it is likely to be retained."
survived,"    def test_broadcasting_higher_dims(self, func):
        """"""Test that exponential matrix functions broadcast correctly for higher dimensional arrays.""""""
        np.random.seed(42)

        # 3D array: (2, 20, 4) -> broadcast dims (2,) + core dims (20, 4) = (obs, vars)
        data_3d = np.random.randn(2, 20, 4)
        result_3d = func(data_3d, alpha=0.3)
        assert result_3d.shape == (2, 20, 4, 4)

        # 4D array: (2, 3, 15, 4) -> broadcast dims (2, 3) + core dims (15, 4) = (obs, vars)
        data_4d = np.random.randn(2, 3, 15, 4)
        result_4d = func(data_4d, alpha=0.3)
        assert result_4d.shape == (2, 3, 15, 4, 4)

        # Verify correctness - each slice should match individual computation
        for i in range(2):
            single_result = func(data_3d[i], alpha=0.3)
            assert_allclose(result_3d[i], single_result, rtol=1e-10, equal_nan=True)
",numbagg/test/test_matrix_functions.py,TestExponentialMatrices,1,1.1861120010657661e-08,"The method is a test function that verifies the broadcasting behavior of a function when applied to higher-dimensional arrays. It uses assertions to check the shape of the output and the correctness of the computation. This is a typical and necessary part of testing in software development, especially for numerical computations. The method is well-structured, uses random data for testing, and includes checks for both shape and value correctness. There is no indication of redundancy or obsolescence, and it serves a clear purpose in ensuring the reliability of the function being tested. Therefore, it is likely to be retained."
survived,"    async def test_bash_tool_windows_execution(
        self, mock_subprocess, mock_which, mock_platform
    ):
        """"""Test Windows command execution.""""""
        # Mock process
        mock_process = AsyncMock()
        mock_process.pid = 1234
        mock_process.returncode = 0
        mock_process.communicate.return_value = (b""Hello Windows"", b"""")
        mock_subprocess.return_value = mock_process

        bash_tool = BashTool()
        result = await bash_tool.execute(command=""echo Hello Windows"")

        assert result.success
        assert ""Hello Windows"" in result.output
        mock_subprocess.assert_called_once()
",tests/unit/test_windows_compatibility.py,TestWindowsCompatibility,1,2.646573631904765e-09,"The method 'test_bash_tool_windows_execution' is a unit test designed to verify the functionality of executing a command on Windows using a mocked subprocess. Unit tests are crucial for ensuring code reliability and are typically maintained as long as the functionality they test is relevant. Since this test is specifically checking the execution of a command on Windows, it is likely to be retained to ensure that the BashTool class behaves correctly in a Windows environment. Therefore, the method is expected to survive."
survived,"    def test_git_detection(self, mock_which):
        """"""Test Git executable detection.""""""
        # Test when Git is available
        mock_which.return_value = ""/usr/bin/git""
        assert shutil.which(""git"") is not None

        # Test when Git is not available
        mock_which.return_value = None
        assert shutil.which(""git"") is None
",tests/unit/test_windows_compatibility.py,TestCrossPlatformDetection,1,2.2159489282323004e-08,"The method `test_git_detection` is a unit test designed to verify the behavior of a function that checks for the presence of the Git executable. It uses mocking to simulate different scenarios: one where Git is available and one where it is not. This kind of test is essential for ensuring that the software behaves correctly in different environments, especially when dependencies like Git are involved. Since testing for the presence of external tools is a common requirement in many software projects, this method is likely to be useful and relevant, thus it will survive."
survived,"    def __del__(self) -> None:
        """"""Destructor to ensure database connections are closed.

        Automatically called when the ContextManager object is garbage collected.
        This provides a safety net to ensure SQLite connections are closed even
        if explicit cleanup is not performed.
        """"""
        try:
            self.close_all_connections()
        except Exception:  # nosec B110
            # Ignore errors during destructor
            pass
",ocode_python/core/context_manager.py,ContextManager,1,5.715002851580502e-07,"The method is a destructor (`__del__`) which is used to ensure that database connections are closed when the object is garbage collected. This is a common pattern to provide a safety net for resource management, especially in cases where explicit cleanup might not be performed. Although relying solely on destructors for resource management is not recommended due to the unpredictability of garbage collection, having a destructor as a backup is a reasonable practice. Therefore, the method is likely to be retained as it serves a useful purpose in resource management."
survived,"    def test_project_option(self):
        """"""Test --project option for all install commands.""""""
        commands_to_test = [
            [""claude-code"", ""server.py"", ""--project"", ""/path/to/project""],
            [""claude-desktop"", ""server.py"", ""--project"", ""/path/to/project""],
            [""cursor"", ""server.py"", ""--project"", ""/path/to/project""],
            [""mcp-json"", ""server.py"", ""--project"", ""/path/to/project""],
        ]

        for cmd_args in commands_to_test:
            command, bound, _ = install_app.parse_args(cmd_args)
            assert command is not None
            assert str(bound.arguments[""project""]) == ""/path/to/project""",tests/cli/test_install.py,TestInstallCommandParsing,1,3.3982678079468468e-09,"The method 'test_project_option' is a unit test designed to verify that the '--project' option is correctly parsed and applied for a set of install commands. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with command-line interfaces. This method is likely part of a test suite that ensures the software behaves as expected. Since testing is an essential part of software development and maintenance, this method is likely to be retained to ensure ongoing code quality."
survived,"async def summarise_conversations(
    conversations: List[Conversation],
    *,
    model: BaseSummaryModel,
    checkpoint_manager: Optional[CheckpointManager] = None
) -> List[ConversationSummary]:
    """"""Generate summaries for a list of conversations.
    
    This is a pure function that takes conversations and a summary model,
    and returns conversation summaries. Optionally uses checkpointing.
    
    The function works with any model that implements BaseSummaryModel,
    supporting heterogeneous backends (OpenAI, vLLM, Hugging Face, etc.)
    through polymorphism.
    
    Args:
        conversations: List of conversations to summarize
        model: Model to use for summarization (OpenAI, vLLM, local, etc.)
        checkpoint_manager: Optional checkpoint manager for caching
        
    Returns:
        List of conversation summaries
        
    Example:
        >>> openai_model = OpenAISummaryModel(api_key=""sk-..."")
        >>> checkpoint_mgr = CheckpointManager(""./checkpoints"")
        >>> summaries = await summarise_conversations(
        ...     conversations=my_conversations,
        ...     model=openai_model,
        ...     checkpoint_manager=checkpoint_mgr
        ... )
    """"""
    logger.info(f""Starting summarization of {len(conversations)} conversations using {type(model).__name__}"")
    
    # Try to load from checkpoint
    if checkpoint_manager:
        cached = checkpoint_manager.load_checkpoint(
            model.checkpoint_filename, 
            ConversationSummary
        )
        if cached:
            logger.info(f""Loaded {len(cached)} summaries from checkpoint"")
            return cached
    
    # Generate summaries
    logger.info(""Generating new summaries..."")
    summaries = await model.summarise(conversations)
    logger.info(f""Generated {len(summaries)} summaries"")
    
    # Save to checkpoint
    if checkpoint_manager:
        logger.info(f""Saving summaries to checkpoint: {model.checkpoint_filename}"")
        checkpoint_manager.save_checkpoint(model.checkpoint_filename, summaries)
    
    return summaries
",kura/v1/kura.py,,1,3.160881453314576e-10,"The method `summarise_conversations` is a well-structured and useful function for generating summaries of conversations using various models. It supports polymorphism, allowing it to work with different backends, and includes optional checkpointing for efficiency. These features make it versatile and efficient, which are desirable traits in software development. Additionally, the use of async and logging indicates modern and maintainable code practices. Therefore, it is likely to be retained in the codebase."
survived,"    def load_checkpoint(self, filename: str, model_class: type[T]) -> Optional[List[T]]:
        """"""Load data from a checkpoint file if it exists.
        
        Args:
            filename: Name of the checkpoint file
            model_class: Pydantic model class for deserializing the data
            
        Returns:
            List of model instances if checkpoint exists, None otherwise
        """"""
        if not self.enabled:
            return None
            
        checkpoint_path = self.get_checkpoint_path(filename)
        if os.path.exists(checkpoint_path):
            logger.info(f""Loading checkpoint from {checkpoint_path} for {model_class.__name__}"")
            with open(checkpoint_path, ""r"") as f:
                return [model_class.model_validate_json(line) for line in f]
        return None
",kura/v1/kura.py,CheckpointManager,1,2.646573631904765e-09,"The method 'load_checkpoint' is a utility function that provides a clear and useful functionality: loading data from a checkpoint file if it exists. It checks if the feature is enabled, constructs the checkpoint path, and reads the file if it exists, deserializing each line into instances of the provided model class. This is a common pattern in applications that need to persist and restore state, such as machine learning models or applications with complex state management. The method is well-documented, follows a logical flow, and uses standard practices like logging. There is no indication that this method is redundant or obsolete, and it serves a practical purpose in the context of applications that require checkpointing. Therefore, it is likely to be retained."
survived,"def _build_cluster_tree(clusters: List[Cluster]) -> dict[str, ClusterTreeNode]:
    """"""Build a tree structure from a list of clusters.
    
    Args:
        clusters: List of clusters to build tree from
        
    Returns:
        Dictionary mapping cluster IDs to tree nodes
    """"""
    node_id_to_cluster = {}

    # Create tree nodes
    for cluster in clusters:
        node_id_to_cluster[cluster.id] = ClusterTreeNode(
            id=cluster.id,
            name=cluster.name,
            description=cluster.description,
            count=len(cluster.chat_ids),
            children=[],
        )

    # Link parent-child relationships
    for cluster in clusters:
        if cluster.parent_id:
            node_id_to_cluster[cluster.parent_id].children.append(cluster.id)

    return node_id_to_cluster
",kura/v1/visualization.py,,1,1.4166087846364157e-09,"The method '_build_cluster_tree' is well-defined and serves a clear purpose of transforming a list of clusters into a tree structure, which is a common requirement in data processing and visualization tasks. The method is documented with a docstring explaining its functionality, arguments, and return value. It uses a straightforward approach to create nodes and establish parent-child relationships, which is efficient and easy to understand. There are no apparent issues or redundancies in the code that would necessitate its deletion. Therefore, it is likely to be retained in the codebase."
survived,"def visualise_pipeline_results(
    clusters: List[Cluster],
    *,
    style: str = ""enhanced"",
    console: Optional[Console] = None
) -> None:
    """"""Visualize clusters that are the result of a pipeline execution.
    
    Convenience function for visualizing clusters directly from pipeline results.
    
    Args:
        clusters: List of clusters from pipeline execution
        style: Visualization style (""basic"", ""enhanced"", or ""rich"")
        console: Rich Console instance (for rich style)
        
    Raises:
        ValueError: If invalid style is provided
    """"""
    if style == ""basic"":
        visualise_clusters(clusters)
    elif style == ""enhanced"":
        visualise_clusters_enhanced(clusters)
    elif style == ""rich"":
        visualise_clusters_rich(clusters, console=console)
    else:
        raise ValueError(f""Invalid style '{style}'. Must be one of: basic, enhanced, rich"") ",kura/v1/visualization.py,,1,1.1032560311263802e-09,"The method 'visualise_pipeline_results' is a utility function that provides a convenient way to visualize clusters resulting from a pipeline execution. It offers flexibility by allowing different visualization styles ('basic', 'enhanced', 'rich') and handles invalid input gracefully by raising a ValueError. Such utility functions are often useful in data processing and visualization workflows, making them likely to be retained in the codebase."
survived,"    def test_update_with_sample_weight(self):
        """"""Test update method with sample weights.""""""
        arms = make_arms(range(3))
        agent = ContextualAgent(arms, ThompsonSampling(), random_seed=42)
        steps = [(""identity"", FunctionTransformer())]

        pipeline = ContextualAgentPipeline(steps, agent)

        X = np.array([[1.0], [2.0]])
        y = np.array([1.0, 2.0])
        sample_weight = np.array([1.0, 0.1])

        # Pull to set arm_to_update
        pipeline.pull(X)

        # Should not raise
        pipeline.update(X, y, sample_weight=sample_weight)
",tests/test_agent_pipeline.py,TestContextualAgentPipeline,1,5.043472052266442e-07,"The method `test_update_with_sample_weight` is a unit test designed to verify the functionality of the `update` method in a pipeline that involves sample weights. Unit tests are crucial for ensuring code reliability and correctness, especially in complex systems like machine learning pipelines. This test checks that the `update` method can handle sample weights without errors, which is an important aspect of model training and evaluation. Therefore, it is unlikely to be deleted as it serves a critical role in maintaining the integrity of the codebase."
survived,"    def test_stateless_transformers(self):
        """"""Test stateless transformers work correctly.""""""

        def double_transform(X):
            return X * 2

        mock_learner = MockLearner()
        pipeline = LearnerPipeline(steps=[(""double"", FunctionTransformer(double_transform))], learner=mock_learner)

        X = np.array([[1, 2], [3, 4]])
        y = np.array([1, 2])

        # Should transform without any fitting
        pipeline.partial_fit(X, y)

        # Check that data was doubled before reaching learner
        received_X, received_y, _ = mock_learner.partial_fit_calls[0]
        np.testing.assert_array_equal(received_X, X * 2)
        np.testing.assert_array_equal(received_y, y)
",tests/test_learner_pipeline.py,TestLearnerPipelineTransformers,1,8.152020648014727e-09,"The method is a unit test for a specific functionality, ensuring that stateless transformers in a machine learning pipeline work as expected. It is well-structured, uses mock objects to isolate the test, and verifies the transformation logic. Such tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is likely to be retained."
survived,"    def _apply_transformers(self, X: X_contra) -> Any:
        """"""Apply transformers to input data.

        Transformers must be either stateless or already fitted.
        """"""
        if not self.steps:
            return X

        # Apply each transformer in sequence
        result = cast(Any, X)  # Cast to Any for sklearn calls
        for name, transformer in self.steps:
            try:
                result = transformer.transform(result)
            except Exception as e:
                # Provide helpful error for common case
                if hasattr(e, ""args"") and ""not fitted"" in str(e).lower():
                    raise RuntimeError(
                        f""Transformer '{name}' is not fitted. In online learning, ""
                        f""all transformers must be either stateless or pre-fitted ""
                        f""before use. Common stateless transformers include ""
                        f""FunctionTransformer. Stateful transformers like ""
                        f""StandardScaler must be fit on historical data before ""
                        f""creating the pipeline.""
                    ) from e
                raise
        return result
",bayesianbandits/pipelines/_learner.py,LearnerPipeline,1,2.646573631904765e-09,"The method '_apply_transformers' is a crucial part of a data processing pipeline, responsible for applying a sequence of transformers to input data. It includes error handling for a common issue where transformers are not fitted, providing a clear error message to guide the user. This functionality is essential for ensuring that data is correctly transformed before further processing, especially in machine learning workflows. The method is well-structured, with a clear purpose and robust error handling, making it unlikely to be removed unless there is a significant redesign of the system."
survived,"    def learner(self) -> Learner[Any]:
        """"""Access the final learner.""""""
        return self._learner
",bayesianbandits/pipelines/_learner.py,LearnerPipeline,1,7.582560422162384e-10,"The method 'learner' is a simple accessor method that returns a private attribute '_learner'. Such methods are typically retained in codebases because they provide a controlled way to access private data, which is a common practice in object-oriented programming to maintain encapsulation. Unless there is a significant refactor or change in design that makes this method redundant, it is likely to survive."
survived,"    def __repr__(self) -> str:
        """"""String representation.""""""
        steps_repr = [
            f""('{name}', {transformer.__class__.__name__})""
            for name, transformer in self.steps
        ]
        return f""ContextualAgentPipeline(steps=[{', '.join(steps_repr)}], final_agent={self._agent!r})""
",bayesianbandits/pipelines/_agent.py,ContextualAgentPipeline,1,8.592166611791576e-10,"The __repr__ method is a standard Python method used to provide a string representation of an object. It is useful for debugging and logging purposes, as it allows developers to see a clear and informative representation of the object. The method in question is well-implemented, providing a detailed view of the 'steps' and 'final_agent' attributes of the ContextualAgentPipeline class. Such methods are generally considered good practice and are unlikely to be removed unless the class itself is deprecated or significantly refactored. Therefore, it is likely to survive."
survived,"    def arms(self):
        """"""Get the arms from the wrapped agent.""""""
        return self._agent.arms
",bayesianbandits/pipelines/_agent.py,ContextualAgentPipeline,1,7.582560422162384e-10,"The method 'arms' is a simple getter method that accesses the 'arms' attribute of a wrapped agent. Such methods are typically retained as they provide a clear and encapsulated way to access internal attributes, which is a common practice in object-oriented programming to maintain encapsulation and abstraction. There is no indication that this method is redundant or unnecessary, so it is likely to be retained."
survived,"    def test_transform_multiple_steps(self):
        """"""Test transformation with multiple steps.""""""
        steps = [
            (""double"", FunctionTransformer(lambda x: x * 2)),
            (""add_one"", FunctionTransformer(lambda x: x + 1)),
        ]
        X = np.array([[1], [2]])
        result = _transform_data(X, steps)
        expected = np.array([[3], [5]])  # (x * 2) + 1
        np.testing.assert_array_equal(result, expected)
",tests/test_agent_pipeline.py,TestTransformData,1,1.3176514268359263e-10,"The method 'test_transform_multiple_steps' is a unit test that verifies the functionality of a data transformation process involving multiple steps. It is well-defined, uses clear and concise logic to test the transformation pipeline, and includes assertions to validate the expected outcome. Such tests are crucial for ensuring code reliability and correctness, especially in data processing tasks. Therefore, it is likely to be retained in the codebase."
survived,"        def failing_transform(X):
            raise ValueError(""Custom transformation error"")
",tests/test_agent_pipeline.py,TestErrorHandling,0,0.9999998555019682,"The method 'failing_transform' is designed to always raise an exception when called, which makes it non-functional for any practical use. Methods that are intentionally designed to fail without any conditional logic or alternative functionality are typically not useful in a codebase unless they are placeholders or meant for testing error handling. Since this method does not provide any utility or flexibility, it is likely to be deleted or replaced with a functional implementation."
survived,"    def test_empty_steps_allowed(self):
        """"""Test empty steps are allowed for non-contextual.""""""
        arms = make_arms(range(3))
        agent = Agent(arms, ThompsonSampling())

        # Should not raise
        pipeline = NonContextualAgentPipeline([], agent)
        assert len(pipeline) == 0
",tests/test_agent_pipeline.py,TestNonContextualAgentPipeline,1,1.0467401685178159e-08,"The method 'test_empty_steps_allowed' is a unit test that verifies the behavior of the 'NonContextualAgentPipeline' when initialized with an empty list of steps. This is a valid test case to ensure that the pipeline can handle empty steps without errors. Unit tests are generally not deleted unless they are redundant or incorrect, and this test seems to be neither. It is testing a specific scenario that could be important for the robustness of the code."
survived,"    def __init__(self):
        self.partial_fit_calls = []
        self.sample_calls = []
        self.predict_calls = []
        self.decay_calls = []
        self.random_state = None
",tests/test_learner_pipeline.py,MockLearner,1,5.60279640614594e-09,"The method is a constructor (__init__) for a class, which is essential for initializing object instances. It sets up initial states for the object by initializing several lists and a random state attribute. Constructors are fundamental to object-oriented programming, and removing them would prevent the proper instantiation of objects. Therefore, this method is likely to survive."
survived,"    def arm_to_update(self):
        """"""Get the arm to update from the wrapped agent.""""""
        return self._agent.arm_to_update
",bayesianbandits/pipelines/_agent.py,ContextualAgentPipeline,1,9.237449576640118e-09,"The method `arm_to_update` is a simple getter method that retrieves the `arm_to_update` attribute from a wrapped agent object. Such methods are typically retained because they encapsulate access to an object's properties, promoting encapsulation and potentially allowing for future modifications or extensions without altering the interface. Additionally, if the `_agent` object is a complex or external object, this method provides a clean and controlled way to access its properties. Therefore, it is likely to be retained."
survived,"    def test_repr_method(self):
        """"""Test __repr__ method.""""""
        pipeline = LearnerPipeline(steps=[(""scale"", StandardScaler())], learner=MockLearner())

        repr_str = repr(pipeline)
        assert ""LearnerPipeline"" in repr_str
        assert ""StandardScaler"" in repr_str
        assert ""MockLearner"" in repr_str",tests/test_learner_pipeline.py,TestLearnerPipelineProperties,1,6.825604231969389e-08,"The method `test_repr_method` is a unit test designed to verify the `__repr__` method of the `LearnerPipeline` class. It checks if the string representation of the pipeline object includes the expected components, such as 'LearnerPipeline', 'StandardScaler', and 'MockLearner'. This is a standard practice in testing to ensure that the `__repr__` method provides a meaningful and correct string representation of the object. Since testing the `__repr__` method is a common and useful practice in software development, it is likely that this method will be retained in the codebase."
survived,"def handle_reask_kwargs(
    kwargs: dict[str, Any],
    mode: Mode,
    response: Any,
    exception: Exception,
) -> dict[str, Any]:
    """"""Handle validation errors by reformatting the request for retry (reask).

    When a response fails validation (e.g., missing required fields, wrong types),
    this function prepares a new request that includes information about the error.
    This allows the LLM to understand what went wrong and correct its response.

    The reask logic is provider-specific because each provider has different ways
    of handling function/tool calls and different message formats.

    Args:
        kwargs (dict[str, Any]): The original request parameters that resulted in
            a validation error. Includes messages, tools, temperature, etc.
        mode (Mode): The provider/format mode that determines which reask handler
            to use. Each mode has a specific strategy for formatting error feedback.
        response (Any): The raw response from the LLM that failed validation.
            Type varies by provider:
            - OpenAI: ChatCompletion with tool_calls
            - Anthropic: Message with tool_use blocks
            - Google: GenerateContentResponse with function calls
        exception (Exception): The validation error that occurred. Usually a
            Pydantic ValidationError with details about which fields failed.

    Returns:
        dict[str, Any]: Modified kwargs for the retry request, typically including:
            - Updated messages with error context
            - Same tool/function definitions
            - Preserved generation parameters
            - Provider-specific formatting

    Reask Strategies by Provider:
        Each provider has a specific strategy for handling retries:

        **JSON Modes:**
        - Adds assistant message with failed attempt
        - Adds user message with error details

        **Tool Calls:**
        - Preserves tool definitions
        - Formats the errors as tool calls responses

    Note:
        This function is typically called internally by the retry logic when
        max_retries > 1. It ensures that each retry attempt includes context
        about previous failures, helping the LLM learn from its mistakes.
    """"""
    # Create a shallow copy of kwargs to avoid modifying the original
    kwargs_copy = kwargs.copy()

    # Organized by provider (matching process_response.py structure)
    REASK_HANDLERS = {
        # OpenAI modes
        Mode.FUNCTIONS: reask_default,
        Mode.TOOLS_STRICT: reask_tools,
        Mode.TOOLS: reask_tools,
        Mode.JSON_O1: reask_default,
        Mode.JSON: reask_md_json,
        Mode.MD_JSON: reask_md_json,
        Mode.JSON_SCHEMA: reask_md_json,
        Mode.PARALLEL_TOOLS: reask_tools,
        Mode.RESPONSES_TOOLS: reask_responses_tools,
        Mode.RESPONSES_TOOLS_WITH_INBUILT_TOOLS: reask_responses_tools,
        # Mistral modes
        Mode.MISTRAL_TOOLS: reask_mistral_tools,
        Mode.MISTRAL_STRUCTURED_OUTPUTS: reask_mistral_structured_outputs,
        # Anthropic modes
        Mode.ANTHROPIC_TOOLS: reask_anthropic_tools,
        Mode.ANTHROPIC_REASONING_TOOLS: reask_anthropic_tools,
        Mode.ANTHROPIC_JSON: reask_anthropic_json,
        Mode.ANTHROPIC_PARALLEL_TOOLS: reask_anthropic_tools,
        # Cohere modes
        Mode.COHERE_TOOLS: reask_cohere_tools,
        Mode.COHERE_JSON_SCHEMA: reask_cohere_tools,
        # Gemini/Google modes
        Mode.GEMINI_TOOLS: reask_gemini_tools,
        Mode.GEMINI_JSON: reask_gemini_json,
        Mode.GENAI_TOOLS: reask_genai_tools,
        Mode.GENAI_STRUCTURED_OUTPUTS: reask_genai_structured_outputs,
        # VertexAI modes
        Mode.VERTEXAI_TOOLS: reask_vertexai_tools,
        Mode.VERTEXAI_JSON: reask_vertexai_json,
        Mode.VERTEXAI_PARALLEL_TOOLS: reask_vertexai_tools,
        # Cerebras modes
        Mode.CEREBRAS_TOOLS: reask_cerebras_tools,
        Mode.CEREBRAS_JSON: reask_default,
        # Fireworks modes
        Mode.FIREWORKS_TOOLS: reask_fireworks_tools,
        Mode.FIREWORKS_JSON: reask_fireworks_json,
        # Writer modes
        Mode.WRITER_TOOLS: reask_writer_tools,
        Mode.WRITER_JSON: reask_writer_json,
        # Bedrock modes
        Mode.BEDROCK_TOOLS: reask_bedrock_tools,
        Mode.BEDROCK_JSON: reask_bedrock_json,
        # Perplexity modes
        Mode.PERPLEXITY_JSON: reask_perplexity_json,
        # OpenRouter modes
        Mode.OPENROUTER_STRUCTURED_OUTPUTS: reask_default,
        # XAI modes
        Mode.XAI_JSON: reask_xai_json,
        Mode.XAI_TOOLS: reask_xai_tools,
    }

    if mode in REASK_HANDLERS:
        return REASK_HANDLERS[mode](kwargs_copy, response, exception)
    else:
        return reask_default(kwargs_copy, response, exception)",instructor/process_response.py,,1,1.725782769012759e-08,"The method `handle_reask_kwargs` is a crucial part of a system that handles validation errors by preparing requests for retry. It is designed to work with various providers and modes, each having specific strategies for handling retries. This flexibility and provider-specific handling make it a valuable component in ensuring robust error handling and retry logic. Given its comprehensive design and the detailed documentation, it is unlikely to be deleted as it serves an essential function in improving the reliability and adaptability of the system."
survived,"    def _identify_new_files(self, feature_request: str, analysis: Dict[str, Any]) -> List[str]:
        """"""Identify new files that need to be created.""""""
        return [""new_feature.py""]
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,1,1.522997951276035e-08,"The method '_identify_new_files' is a simple utility function that returns a list containing a single string, 'new_feature.py'. It is likely part of a larger system where identifying new files is necessary for feature development or analysis. The method is straightforward, has a clear purpose, and does not contain any apparent issues or redundancies that would warrant its deletion. Therefore, it is likely to be retained in the codebase."
survived,"    def _identify_dependencies(self, feature_request: str, analysis: Dict[str, Any]) -> List[str]:
        """"""Identify new dependencies required.""""""
        return []
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,0,0.999999996149258,"The method '_identify_dependencies' is likely to be deleted because it currently does not perform any meaningful operation. It takes inputs but always returns an empty list, indicating that it is either incomplete or not needed. If it were necessary, it would likely contain logic to analyze the 'feature_request' and 'analysis' to determine dependencies. Without such logic, it serves no purpose in its current form."
deleted,"    def _analyze_naming_conventions(self, project_path: str, file_patterns: List[str]) -> Dict[str, Any]:
        """"""Analyze naming conventions used in the project.""""""
        conventions = {""style"": ""snake_case"", ""patterns"": [], ""exceptions"": []}
        # Implementation would analyze actual naming patterns
        return conventions
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,1,4.1399375473943306e-08,"The method `_analyze_naming_conventions` is a utility function that provides a specific analysis of naming conventions within a project. It is likely part of a larger codebase that deals with code quality or style analysis. Such methods are generally useful for maintaining code consistency and are often part of static analysis tools or IDE plugins. Since it returns a structured dictionary with style information, it is likely to be used in various parts of the application to enforce or report on naming conventions. Therefore, it is unlikely to be deleted unless the entire feature it supports is removed."
survived,"def test_agent_inheritance():
    """"""Test that ContextAgent properly inherits from Agent.""""""
    print(""\n Testing Agent Inheritance..."")
    
    try:
        from praisonaiagents import ContextAgent, Agent
        
        context_agent = ContextAgent()
        
        # Test inheritance
        assert isinstance(context_agent, Agent), ""ContextAgent should inherit from Agent""
        print("" ContextAgent properly inherits from Agent class"")
        
        # Test that base Agent properties exist
        assert hasattr(context_agent, 'name'), ""Should have name attribute""
        assert hasattr(context_agent, 'role'), ""Should have role attribute""
        assert hasattr(context_agent, 'goal'), ""Should have goal attribute""
        print("" ContextAgent has all required Agent attributes"")
        
        return True
        
    except Exception as e:
        print(f"" Inheritance test failed: {e}"")
        return False
",test_context_agent.py,,1,3.2241866333029355e-08,"The method `test_agent_inheritance` is a unit test function designed to verify the inheritance and attribute presence of a class `ContextAgent` from a base class `Agent`. Such test functions are crucial for ensuring code reliability and correctness, especially in object-oriented programming where inheritance is a key feature. The function is well-structured, includes exception handling, and provides clear output messages for success and failure cases. These characteristics make it a valuable part of a test suite, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained in the codebase."
survived,"    def _identify_integration_points(self, feature_request: str, analysis: Dict[str, Any]) -> List[str]:
        """"""Identify integration points with existing code.""""""
        return [""main_api"", ""data_layer""]
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,1,3.927863699585036e-07,"The method '_identify_integration_points' is a private method (indicated by the underscore prefix) that seems to serve a specific purpose of identifying integration points within a codebase. It returns a hardcoded list of integration points, which suggests it might be a placeholder or a simplified implementation. However, the method is straightforward, has a clear purpose, and could be useful in contexts where these specific integration points are relevant. Without additional context indicating that this method is obsolete or redundant, it is likely to survive as it provides a utility function that could be expanded or modified in the future."
survived,"def test_syntax_validation():
    """"""Test that all Python files have valid syntax.""""""
    print(""\n Testing Syntax Validation..."")
    
    try:
        import ast
        
        # Test the main ContextAgent file
        context_agent_file = project_root / ""praisonaiagents"" / ""agent"" / ""context_agent.py""
        
        with open(context_agent_file, 'r') as f:
            content = f.read()
        
        # Parse the file to check for syntax errors
        ast.parse(content)
        print("" context_agent.py has valid Python syntax"")
        
        # Test the examples
        example_files = [
            Path(__file__).parent / ""examples"" / ""python"" / ""agents"" / ""context-agent.py"",
            Path(__file__).parent / ""examples"" / ""python"" / ""concepts"" / ""context-engineering-workflow.py""
        ]
        
        for example_file in example_files:
            if example_file.exists():
                with open(example_file, 'r') as f:
                    content = f.read()
                ast.parse(content)
                print(f"" {example_file.name} has valid Python syntax"")
        
        return True
        
    except SyntaxError as e:
        print(f"" Syntax error found: {e}"")
        return False
    except Exception as e:
        print(f"" Syntax validation failed: {e}"")
        return False
",test_context_agent.py,,1,2.646573631904765e-09,"The method `test_syntax_validation` is a utility function designed to check the syntax of Python files within a project. It uses the `ast` module to parse files and catch syntax errors, which is a common and effective way to ensure code quality. This function is useful for automated testing and continuous integration processes, helping developers catch syntax errors early in the development cycle. Given its utility in maintaining code quality and preventing runtime errors, it is likely to be retained in the codebase."
survived,"    def generate_prp(self, feature_request: str, context_analysis: Dict[str, Any], documentation_links: List[str] = None) -> str:
        """"""
        Generate a Product Requirements Prompt (PRP) with comprehensive context.
        
        Args:
            feature_request (str): The feature to be implemented
            context_analysis (Dict[str, Any]): Analysis of the codebase context
            documentation_links (List[str]): Optional links to relevant documentation
            
        Returns:
            str: Complete PRP with rich context for implementation
        """"""
        if documentation_links is None:
            documentation_links = []
        
        prp = f""""""# Product Requirements Prompt (PRP)
## Context Engineering Enhanced Implementation Guide

### Feature Request
{feature_request}

### Comprehensive Context

#### Codebase Analysis
{self._format_prp_codebase_analysis(context_analysis)}

#### Implementation Blueprint
{self._generate_prp_implementation_blueprint(feature_request, context_analysis)}

#### Validation Framework
{self._generate_prp_validation_framework(feature_request)}

#### Documentation References
{self._format_prp_documentation(documentation_links)}

#### Success Criteria
{self._generate_prp_success_criteria(feature_request, context_analysis)}

### Implementation Instructions

This PRP provides comprehensive context for implementing: {feature_request}

**Context Engineering Principle**: This document contains all necessary context to enable 
first-try implementation success. Follow the patterns, respect the architecture, and 
use the validation framework to ensure quality.

#### Next Steps
1. Review the complete context above
2. Follow the implementation blueprint
3. Adhere to identified patterns and conventions
4. Execute validation framework to verify success
5. Integrate seamlessly with existing architecture

**Confidence Score**: 9/10 (High confidence due to comprehensive context analysis)
""""""
        
        return prp
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,1,2.0611536181902033e-09,"The method `generate_prp` is well-documented and provides a structured approach to generating a Product Requirements Prompt (PRP) with comprehensive context. It includes detailed sections for feature requests, codebase analysis, implementation blueprint, validation framework, documentation references, and success criteria. This method is likely to be useful for teams working on software development projects, as it helps ensure that all necessary information is considered before implementation. The method's design aligns with best practices in software engineering, such as providing clear instructions and a high confidence score. Therefore, it is likely to be retained in the codebase."
survived,"    def _get_default_context_tools(self) -> List[Any]:
        """"""Get default tools for Context Engineering operations.""""""
        return [
            self.analyze_codebase_patterns,
            self.generate_context_document,
            self.create_validation_loop,
            self.enhance_prompt_with_context,
            self.generate_prp,
            self.extract_documentation_patterns,
            self.analyze_test_patterns,
            self.create_implementation_blueprint
        ]
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,1,1.1861120010657661e-08,"The method '_get_default_context_tools' is a private method (indicated by the underscore prefix) that returns a list of tools related to context engineering operations. It is likely part of a larger system or framework that deals with code analysis and generation. The method is well-defined, has a clear purpose, and is likely used internally within the class or module to provide a set of default operations. There is no indication that it is obsolete or redundant, and it seems to serve a specific function within its context. Therefore, it is more likely to be retained rather than deleted."
survived,"    async def test_ai_text_summarizer_multiple_chunks(self):
        """"""Test that AITextSummarizerBlock correctly accumulates stats across multiple chunks.""""""
        import backend.blocks.llm as llm

        block = llm.AITextSummarizerBlock()

        # Track calls to simulate multiple chunks
        call_count = 0

        async def mock_llm_call(input_data, credentials):
            nonlocal call_count
            call_count += 1

            # Create a mock block with stats to merge from
            mock_structured_block = llm.AIStructuredResponseGeneratorBlock()
            mock_structured_block.execution_stats = NodeExecutionStats(
                input_token_count=25,
                output_token_count=15,
                llm_call_count=1,
            )

            # Simulate merge_llm_stats behavior
            block.merge_llm_stats(mock_structured_block)

            if ""final_summary"" in input_data.expected_format:
                return {""final_summary"": ""Final combined summary""}
            else:
                return {""summary"": f""Summary of chunk {call_count}""}

        block.llm_call = mock_llm_call  # type: ignore

        # Create long text that will be split into chunks
        long_text = "" "".join([""word""] * 1000)  # Moderate size to force ~2-3 chunks

        input_data = llm.AITextSummarizerBlock.Input(
            text=long_text,
            model=llm.LlmModel.GPT4O,
            credentials=llm.TEST_CREDENTIALS_INPUT,  # type: ignore
            max_tokens=100,  # Small chunks
            chunk_overlap=10,
        )

        # Run the block
        outputs = {}
        async for output_name, output_data in block.run(
            input_data, credentials=llm.TEST_CREDENTIALS
        ):
            outputs[output_name] = output_data

        # Block finished - now grab and assert stats
        assert block.execution_stats is not None
        assert call_count > 1  # Should have made multiple calls
        assert block.execution_stats.llm_call_count > 0
        assert block.execution_stats.input_token_count > 0
        assert block.execution_stats.output_token_count > 0

        # Check output
        assert ""summary"" in outputs
        assert outputs[""summary""] == ""Final combined summary""
",autogpt_platform/backend/backend/blocks/test/test_llm.py,TestLLMStatsTracking,1,2.2159489282323004e-08,"The method is a well-structured test case for an AI text summarizer, which is crucial for ensuring the functionality of the summarizer across multiple chunks. It includes mock functions to simulate real-world scenarios, checks for correct accumulation of statistics, and verifies the output. Such test cases are essential for maintaining code quality and reliability, especially in complex systems like AI models. Therefore, it is likely to be retained."
survived,"    async def test_stats_accumulation_with_retries(self):
        """"""Test that stats correctly accumulate across retries.""""""
        import backend.blocks.llm as llm

        block = llm.AIStructuredResponseGeneratorBlock()

        # Counter to track calls
        call_count = 0

        async def mock_llm_call(*args, **kwargs):
            nonlocal call_count
            call_count += 1

            # First call returns invalid format
            if call_count == 1:
                return llm.LLMResponse(
                    raw_response="""",
                    prompt=[],
                    response='{""wrong"": ""format""}',
                    tool_calls=None,
                    prompt_tokens=10,
                    completion_tokens=15,
                    reasoning=None,
                )
            # Second call returns correct format
            else:
                return llm.LLMResponse(
                    raw_response="""",
                    prompt=[],
                    response='{""key1"": ""value1"", ""key2"": ""value2""}',
                    tool_calls=None,
                    prompt_tokens=20,
                    completion_tokens=25,
                    reasoning=None,
                )

        block.llm_call = mock_llm_call  # type: ignore

        # Run the block with retry
        input_data = llm.AIStructuredResponseGeneratorBlock.Input(
            prompt=""Test prompt"",
            expected_format={""key1"": ""desc1"", ""key2"": ""desc2""},
            model=llm.LlmModel.GPT4O,
            credentials=llm.TEST_CREDENTIALS_INPUT,  # type: ignore
            retry=2,
        )

        outputs = {}
        async for output_name, output_data in block.run(
            input_data, credentials=llm.TEST_CREDENTIALS
        ):
            outputs[output_name] = output_data

        # Check stats - should accumulate both calls
        # For 2 attempts: attempt 1 (failed) + attempt 2 (success) = 2 total
        # but llm_call_count is only set on success, so it shows 1 for the final successful attempt
        assert block.execution_stats.input_token_count == 30  # 10 + 20
        assert block.execution_stats.output_token_count == 40  # 15 + 25
        assert block.execution_stats.llm_call_count == 2  # retry_count + 1 = 1 + 1 = 2
        assert block.execution_stats.llm_retry_count == 1
",autogpt_platform/backend/backend/blocks/test/test_llm.py,TestLLMStatsTracking,1,1.3440409770490404e-08,"The method is a well-structured test function that verifies the accumulation of statistics across retries in an asynchronous environment. It uses a mock function to simulate different responses and checks if the statistics are correctly accumulated. This is a common pattern in testing asynchronous code and handling retries, which is crucial for ensuring robustness in systems that rely on external calls. The method is likely to be useful for maintaining code quality and ensuring correct functionality, so it is unlikely to be deleted."
survived,"    async def test_ai_structured_response_block_tracks_stats(self):
        """"""Test that AIStructuredResponseGeneratorBlock correctly tracks stats.""""""
        import backend.blocks.llm as llm

        block = llm.AIStructuredResponseGeneratorBlock()

        # Mock the llm_call method
        async def mock_llm_call(*args, **kwargs):
            return llm.LLMResponse(
                raw_response="""",
                prompt=[],
                response='{""key1"": ""value1"", ""key2"": ""value2""}',
                tool_calls=None,
                prompt_tokens=15,
                completion_tokens=25,
                reasoning=None,
            )

        block.llm_call = mock_llm_call  # type: ignore

        # Run the block
        input_data = llm.AIStructuredResponseGeneratorBlock.Input(
            prompt=""Test prompt"",
            expected_format={""key1"": ""desc1"", ""key2"": ""desc2""},
            model=llm.LlmModel.GPT4O,
            credentials=llm.TEST_CREDENTIALS_INPUT,  # type: ignore  # type: ignore
        )

        outputs = {}
        async for output_name, output_data in block.run(
            input_data, credentials=llm.TEST_CREDENTIALS
        ):
            outputs[output_name] = output_data

        # Check stats
        assert block.execution_stats.input_token_count == 15
        assert block.execution_stats.output_token_count == 25
        assert block.execution_stats.llm_call_count == 1
        assert block.execution_stats.llm_retry_count == 0

        # Check output
        assert ""response"" in outputs
        assert outputs[""response""] == {""key1"": ""value1"", ""key2"": ""value2""}
",autogpt_platform/backend/backend/blocks/test/test_llm.py,TestLLMStatsTracking,1,3.653482080241728e-08,"The method is a well-structured test function that verifies the functionality of the AIStructuredResponseGeneratorBlock, specifically its ability to track statistics and produce the expected output. It uses mocking to simulate the behavior of the llm_call method, ensuring that the test is isolated and does not depend on external factors. The test checks both the statistics tracking and the correctness of the output, which are essential for validating the block's functionality. Since testing is a crucial part of software development, especially for ensuring the reliability of components, this method is likely to be retained."
survived,"    def _message(self) -> str:
        return (
            ""Usage of `set_active_model` is not allowed in mlflow, use `_set_active_model` instead.""
        )
",dev/clint/src/clint/rules/forbidden_set_active_model_usage.py,ForbiddenSetActiveModelUsage,1,1.955568070542584e-08,"The method _message is a private method (indicated by the underscore prefix) that returns a specific error message. It is likely used internally within the class or module to provide a consistent error message when a deprecated or disallowed function is used. Since it serves a specific purpose and is not intended for public use, it is unlikely to be deleted unless the functionality it supports is completely removed or refactored. Therefore, it is more likely to survive."
survived,"    def _find_artifact_path_index(index: ""SymbolIndex"", function_name: str) -> int | None:
        """"""
        Finds the index of the `artifact_path` argument in the function signature of `log_model`
        using the SymbolIndex.
        """"""
        if f := index.resolve(function_name):
            try:
                return f.all_args.index(""artifact_path"")
            except ValueError:
                return None
        return None",dev/clint/src/clint/rules/log_model_artifact_path.py,LogModelArtifactPath,1,3.3982678079468468e-09,"The method '_find_artifact_path_index' is a utility function that is likely used internally to find the position of a specific argument ('artifact_path') in a function's signature. This kind of functionality is often necessary for dynamic function handling or introspection, which are common in frameworks or libraries that deal with logging, serialization, or similar tasks. The method is concise, has a clear purpose, and is likely to be useful in its context. Therefore, it is more likely to be retained in the codebase."
survived,"    def _message(self) -> str:
        return f""Unordered parameters in docstring: {self.params}""",dev/clint/src/clint/rules/docstring_param_order.py,DocstringParamOrder,1,3.3982678079468468e-09,"The method '_message' is a private method (indicated by the underscore prefix) that returns a formatted string. It is likely used internally within a class to generate a specific error or log message related to unordered parameters in a docstring. Since it serves a specific purpose and is part of the internal logic of a class, it is unlikely to be deleted unless the functionality it supports is no longer needed or is refactored. Therefore, it is more likely to survive."
survived,"    def _message(self) -> str:
        return (
            ""Abstract method should only contain a single statement/expression, ""
            ""and it must be `pass`, `...`, or a docstring.""
        )
",dev/clint/src/clint/rules/invalid_abstract_method.py,InvalidAbstractMethod,1,2.5109990926928157e-08,"The method `_message` is a private method (indicated by the underscore prefix) that returns a specific string message. This method is likely used internally within a class to provide a consistent error or informational message related to abstract methods. Since it encapsulates a specific piece of functionality (returning a predefined message) and is likely used in multiple places within the class or module, it is useful for maintaining code consistency and readability. Therefore, it is likely to be retained in the codebase."
survived,"def _test_webhook(webhook_id: str):
    request_message = _get_request_message(TestWebhook())
    event = (
        WebhookEvent.from_proto(request_message.event)
        if request_message.HasField(""event"")
        else None
    )
    store = _get_model_registry_store()
    webhook = store.get_webhook(webhook_id=webhook_id)
    test_result = test_webhook(webhook=webhook, event=event)
    response_message = TestWebhook.Response(result=test_result.to_proto())
    return _wrap_response(response_message)
",mlflow/server/handlers.py,,1,3.850741907939403e-09,"The method '_test_webhook' is a utility function that tests a webhook by retrieving it from a store and simulating an event. This functionality is essential for ensuring that webhooks are correctly configured and functioning as expected. Such testing methods are crucial in development and production environments to validate integrations and prevent issues. Therefore, it is likely to be retained in the codebase."
survived,"    def w_spy_new(vm: 'SPyVM', w_cls: W_Type,
                 w_color: W_Object, w_static_type: W_Type,
                 w_val: W_Object) -> 'W_OpArg':
        """"""
        Create a new OpArg from SPy code:
        - color: 'red' or 'blue'
        - static_type: the static type of the argument
        - val: the value (optional for red OpArg, required for blue)
        """"""
        from spy.vm.str import W_Str
        # Check that w_color is a string
        w_type = vm.dynamic_type(w_color)
        if w_type is not B.w_str:
            raise SPyTypeError(f""OpArg color must be a string, got {w_type.fqn.human_name}"")

        color: Color = vm.unwrap_str(w_color)  # type: ignore
        if color not in ('red', 'blue'):
            raise SPyTypeError(f""OpArg color must be 'red' or 'blue', got '{color}'"")

        # Convert B.w_None to Python None
        if w_val is B.w_None:
            w_val2 = None
        else:
            w_val2 = w_val

        if color == 'blue' and w_val is None:
            raise SPyTypeError(""Blue OpArg requires a value"")

        loc = Loc.here(-2)  # approximate source location
        return W_OpArg(vm, color, w_static_type, w_val2, loc)
",spy/vm/opimpl.py,W_OpArg,1,1.1861120010657661e-08,"The method `w_spy_new` is a utility function that creates a new `OpArg` object based on specific conditions. It includes type checking and validation logic, which are crucial for ensuring the correct operation of the system it is part of. The method is well-documented, indicating its purpose and the parameters it handles. Such utility functions are often essential in systems that require strict type and value management, especially in environments like virtual machines or interpreters. Therefore, it is likely to be retained as it serves a specific and necessary function within the codebase."
survived,"    def definitions(
        self,
        curies: Iterable[CURIE],
        include_metadata=False,
        include_missing=False,
        lang: Optional[LANGUAGE_TAG] = None,
    ) -> Iterator[Tuple[CURIE, Optional[str], Dict]]:
        """"""
        Fetch definitions for multiple CURIEs from OLS.
        
        :param curies: The CURIEs to fetch definitions for
        :param include_metadata: Whether to include metadata (currently not supported)
        :param include_missing: Whether to include CURIEs with no definition
        :param lang: Optional language tag (not currently supported by this implementation)
        :return: Iterator of (CURIE, definition, metadata) tuples
        """"""
        for curie in curies:
            definition = self.definition(curie, lang)
            if definition is None and not include_missing:
                continue
            # Currently OLS doesn't provide metadata for definitions through the API
            # So we're just returning an empty dict
            yield curie, definition, {}
",src/oaklib/implementations/ols/ols_implementation.py,BaseOlsImplementation,1,2.8453347280241004e-08,"The method 'definitions' is a utility function that fetches definitions for CURIEs from an external service (OLS). It is a useful method for applications that need to retrieve and process definitions for multiple CURIEs. The method is well-documented, and its parameters allow for flexibility in usage, such as including missing definitions or specifying a language tag. Although some features like metadata and language support are not currently implemented, the method is still functional and provides a clear interface for future enhancements. Therefore, it is likely to be retained in the codebase."
survived,"def test_api_key_parameter_not_passed_when_none():
    """"""Test that api_key parameter is handled correctly when None.""""""
    from unittest.mock import patch, MagicMock

    # Mock the openai module
    with patch(""openai.OpenAI"") as mock_openai_class:
        mock_client = MagicMock()
        mock_openai_class.return_value = mock_client

        # Mock the from_openai import
        with patch(""instructor.from_openai"") as mock_from_openai:
            mock_instructor = MagicMock()
            mock_from_openai.return_value = mock_instructor

            # Test with None api_key
            from_provider(""openai/gpt-4"", api_key=None)

            # Verify OpenAI was called with None api_key
            mock_openai_class.assert_called_once()
            _, kwargs = mock_openai_class.call_args
            assert kwargs[""api_key""] is None
",tests/test_auto_client.py,,1,1.3440409770490404e-08,"The method is a unit test designed to verify that the 'api_key' parameter is correctly handled when it is 'None'. This is a common scenario that needs to be tested to ensure that the system behaves as expected when no API key is provided. The use of mocking to simulate the behavior of external dependencies (like the 'openai' module) is a standard practice in unit testing. Since this test is useful for ensuring the robustness of the code, it is likely to be retained."
survived,"    def test_large_matrix(self):
        # Test performance with larger matrix
        np.random.seed(42)
        data = np.random.randn(50, 1000)

        # Add some NaNs
        mask = np.random.rand(50, 1000) < 0.1
        data[mask] = np.nan

        result = nancorrmatrix(data)

        # Check basic properties
        assert result.shape == (50, 50)
        assert_allclose(np.diag(result), np.ones(50), rtol=1e-10)
        assert_allclose(result, result.T, rtol=1e-10)
        assert np.all((result >= -1) & (result <= 1) | np.isnan(result))",numbagg/test/test_nancorrmatrix.py,TestNanCorrMatrix,1,1.522997951276035e-08,"The method 'test_large_matrix' is a unit test designed to verify the performance and correctness of the 'nancorrmatrix' function when applied to a large matrix with missing values. It includes assertions to check the shape, diagonal values, symmetry, and value range of the resulting correlation matrix. These are standard checks for a correlation matrix, ensuring that the function behaves as expected even with missing data. Since this test is crucial for validating the functionality of 'nancorrmatrix', it is likely to be retained in the codebase to ensure ongoing reliability and correctness of the function."
survived,"    def test_single_observation(self):
        # Test with only one observation per variable
        data = np.array([[1], [2], [3]], dtype=np.float64)
        result = nancorrmatrix(data)

        # Should be NaN except diagonal
        expected = np.full((3, 3), np.nan)
        np.fill_diagonal(expected, 1.0)
        assert_array_equal(result, expected)
",numbagg/test/test_nancorrmatrix.py,TestNanCorrMatrix,1,5.3157849718487075e-08,"The method 'test_single_observation' is a unit test designed to verify the behavior of the 'nancorrmatrix' function when provided with a dataset containing only one observation per variable. This is a valid test case as it checks the function's ability to handle edge cases where correlation cannot be computed due to insufficient data. The test ensures that the function returns a matrix with NaN values except for the diagonal, which should be 1.0, indicating perfect correlation with itself. Such tests are crucial for robust software development, ensuring that functions behave correctly under various input scenarios. Therefore, this method is likely to be retained as it contributes to the overall reliability and correctness of the codebase."
survived,"def nancovmatrix(a, out):
    """"""
    Compute covariance matrix treating NaN as missing values.

    For 2D input, computes covariance between variables (rows) across observations (columns).
    Uses pairwise complete observations (like pandas.DataFrame.cov).
    """"""
    n_vars, n_obs = a.shape

    # Compute covariance matrix
    for i in range(n_vars):
        for j in range(i, n_vars):  # Only compute upper triangle
            # Find pairwise complete observations and compute sums in one pass
            sum_i = 0.0
            sum_j = 0.0
            count = 0

            for k in range(n_obs):
                val_i = a[i, k]
                val_j = a[j, k]
                if not np.isnan(val_i) and not np.isnan(val_j):
                    sum_i += val_i
                    sum_j += val_j
                    count += 1

            if count > 1:
                # Compute means using only pairwise complete observations
                mean_i = sum_i / count
                mean_j = sum_j / count

                # Compute covariance in second pass
                cov_sum = 0.0
                for k in range(n_obs):
                    val_i = a[i, k]
                    val_j = a[j, k]
                    if not np.isnan(val_i) and not np.isnan(val_j):
                        cov_sum += (val_i - mean_i) * (val_j - mean_j)

                # Use count - 1 for sample covariance
                out[i, j] = cov_sum / (count - 1)
                out[j, i] = out[i, j]  # Symmetric
            else:
                out[i, j] = np.nan
                out[j, i] = np.nan",numbagg/funcs.py,,0,0.9999997300421382,"The method is likely to be deleted (0) because it is a custom implementation of a covariance matrix calculation that handles NaN values, which is a functionality already provided by existing libraries like NumPy and Pandas. These libraries offer optimized and well-tested functions such as `numpy.cov` and `pandas.DataFrame.cov` that handle NaN values efficiently. Therefore, maintaining a custom implementation is unnecessary and could lead to potential errors or inefficiencies."
survived,"    def __call__(
        self,
        a: np.ndarray,
        axis: int | tuple[int, ...] | None = None,
        **kwargs,
    ):
        if axis is None:
            axis = -1

        if isinstance(axis, tuple):
            if len(axis) != 1:
                raise ValueError(
                    f""Matrix function requires exactly one axis, got {len(axis)}""
                )
            axis = axis[0]

        # Handle 1D input by treating it as a single variable
        if a.ndim == 1:
            a = a.reshape(1, -1)

        # Move the correlation axis to the last position
        a = np.moveaxis(a, axis, -1)

        gufunc = self.gufunc(target=self.target)
        # axes specifies which axes contain the core dimensions
        # For our signature ""(n,m)->(n,n)"":
        # - Input has 2 core dims: second-to-last (n) and last (m)
        # - Output has 2 core dims: last two dimensions (n,n)
        result = gufunc(a, axes=[(-2, -1), (-2, -1)], **kwargs)

        # Return result as-is, let numba handle the output shape
        return result
",numbagg/decorators.py,ndmatrix,1,9.931195248674785e-08,"The method is a special method (__call__) which is used to make an instance of a class callable like a function. This is a common and useful pattern in Python, especially in numerical and scientific computing libraries where objects often need to behave like functions. The method is well-structured, handles input validation, and uses numpy and numba for efficient computation, which are widely used libraries in the scientific computing community. Therefore, it is unlikely to be deleted as it provides a clear and useful functionality."
survived,"    async def test_list_tools_on_nested_server(
        self,
        mcp_server: FastMCP,
        nested_mcp_server: FastMCP,
        recording_middleware: RecordingMiddleware,
        nested_middleware: RecordingMiddleware,
    ):
        mcp_server.mount(nested_mcp_server, prefix=""nested"")

        async with Client(mcp_server) as client:
            await client.list_tools()

        assert recording_middleware.assert_called(times=3)
        assert recording_middleware.assert_called(method=""tools/list"", times=3)
        assert recording_middleware.assert_called(hook=""on_message"", times=1)
        assert recording_middleware.assert_called(hook=""on_request"", times=1)
        assert recording_middleware.assert_called(hook=""on_list_tools"", times=1)

        assert nested_middleware.assert_called(times=3)
        assert nested_middleware.assert_called(method=""tools/list"", times=3)
        assert nested_middleware.assert_called(hook=""on_message"", times=1)
        assert nested_middleware.assert_called(hook=""on_request"", times=1)
        assert nested_middleware.assert_called(hook=""on_list_tools"", times=1)
",tests/server/middleware/test_middleware.py,TestNestedMiddlewareHooks,1,7.194132978569833e-09,"The method `test_list_tools_on_nested_server` is a test function that verifies the behavior of a nested server setup using middleware. It checks if the middleware is called the expected number of times and with the correct parameters. This kind of test is crucial for ensuring that the server and middleware interactions are functioning as intended, especially in complex systems with nested components. Therefore, it is likely to be retained as part of the test suite to ensure ongoing reliability and correctness of the system."
survived,"    def add_middleware(self, middleware: MCPMiddleware) -> None:
        self.middleware.append(middleware)
",src/fastmcp/server/server.py,FastMCP,1,1.4166087846364157e-09,"The method 'add_middleware' is a simple utility function that appends a middleware object to a list. Such methods are typically essential for managing middleware components in a system, allowing for dynamic configuration and extension of functionality. This method is likely to be used frequently in applications that rely on middleware for processing requests or responses. Therefore, it is unlikely to be deleted as it serves a fundamental purpose in middleware management."
deleted,"    async def _middleware_read_resource(
        self,
        uri: AnyUrl | str,
    ) -> list[ReadResourceContents]:
        """"""
        Read a resource with middleware.
        """"""

        async def _handler(
            context: MiddlewareContext[mcp.types.ReadResourceRequestParams],
        ) -> list[ReadResourceContents]:
            return await self._read_resource(
                uri=context.message.uri,
            )

        # Convert string URI to AnyUrl if needed
        if isinstance(uri, str):
            from pydantic import AnyUrl

            uri_param = AnyUrl(uri)
        else:
            uri_param = uri

        mw_context = MiddlewareContext(
            message=mcp.types.ReadResourceRequestParams(uri=uri_param),
            source=""client"",
            type=""request"",
            method=""resources/read"",
            fastmcp_context=fastmcp.server.dependencies.get_context(),
        )
        return await self._apply_middleware(mw_context, _handler)
",src/fastmcp/server/server.py,FastMCP,1,3.2241866333029355e-08,"The method '_middleware_read_resource' is an asynchronous function that reads a resource using middleware. It includes a nested handler function and logic to convert a string URI to an AnyUrl type. The method is well-structured and serves a specific purpose in the context of middleware operations. Given its utility in handling resource reading with middleware, it is likely to be a crucial part of the system's functionality. Therefore, it is more likely to be maintained rather than deleted."
survived,"    async def test_list_resources(
        self, mcp_server: FastMCP, recording_middleware: RecordingMiddleware
    ):
        async with Client(mcp_server) as client:
            await client.list_resources()

        assert recording_middleware.assert_called(times=3)
        assert recording_middleware.assert_called(method=""resources/list"", times=3)
        assert recording_middleware.assert_called(hook=""on_message"", times=1)
        assert recording_middleware.assert_called(hook=""on_request"", times=1)
        assert recording_middleware.assert_called(hook=""on_list_resources"", times=1)
",tests/server/middleware/test_middleware.py,TestMiddlewareHooks,1,1.1861120010657661e-08,"The method 'test_list_resources' is a test function that verifies the behavior of the 'list_resources' method in an asynchronous context. It uses assertions to ensure that the 'recording_middleware' is called the expected number of times with the correct parameters. This kind of test is crucial for maintaining the integrity of the codebase by ensuring that changes do not break existing functionality. Therefore, it is likely to be retained as part of the test suite to ensure ongoing reliability and correctness of the 'list_resources' functionality."
survived,"    async def sample_tool(context: Context) -> None:
        await context.sample(""hello"")
",tests/server/middleware/test_middleware.py,,0,0.9999995549151272,"The method 'sample_tool' is an asynchronous function that takes a 'Context' object and calls its 'sample' method with the argument 'hello'. Without additional context on the usage or the framework, it's difficult to determine its utility. However, the method seems to be a simple example or placeholder function, possibly used for testing or demonstration purposes. If this is part of a larger codebase where 'sample' is a meaningful operation, it might survive. Otherwise, if it's not serving a clear purpose or is redundant, it could be deleted. Given the lack of context, I'll predict it will be deleted."
deleted,"    async def _middleware_list_tools(self) -> list[Tool]:
        """"""
        List all available tools, in the format expected by the low-level MCP
        server.

        """"""

        async def _handler(
            context: MiddlewareContext[mcp.types.ListToolsRequest],
        ) -> list[Tool]:
            tools = await self._list_tools()

            mcp_tools: list[Tool] = []
            for tool in tools:
                if self._should_enable_component(tool):
                    mcp_tools.append(tool)

            return mcp_tools

        with fastmcp.server.context.Context(fastmcp=self) as fastmcp_ctx:
            # Create the middleware context.
            mw_context = MiddlewareContext(
                message=mcp.types.ListToolsRequest(method=""tools/list""),
                source=""client"",
                type=""request"",
                method=""tools/list"",
                fastmcp_context=fastmcp_ctx,
            )

            # Apply the middleware chain.
            return await self._apply_middleware(mw_context, _handler)
",src/fastmcp/server/server.py,FastMCP,1,3.653482080241728e-08,"The method '_middleware_list_tools' is an asynchronous function that is part of a middleware system for listing tools. It is well-structured, uses context management, and applies a middleware chain, which suggests it is part of a larger, well-designed system. The method is likely to be useful for handling requests in a modular and scalable way, which is a common requirement in modern software systems. Therefore, it is unlikely to be deleted unless there is a significant change in the system architecture or requirements."
survived,"    def reset(self):
        """"""Clear all recorded calls.""""""
        self.calls.clear()
",tests/server/middleware/test_middleware.py,RecordingMiddleware,1,6.348800075736417e-09,"The method `reset` is a simple utility function that clears all recorded calls by invoking the `clear` method on `self.calls`. This is a common pattern in classes that track or log calls, allowing for the state to be reset without needing to recreate the object. Such methods are typically useful for testing, debugging, or reusing the object in different contexts without retaining previous state. Therefore, it is likely to be retained as it provides a clear and useful functionality."
survived,"def test_export_datasets_preserve_experiment_structure():
    """"""Test that experiment structure is preserved in the target database""""""
    with tempfile.TemporaryDirectory() as temp_dir:
        source_db_path = Path(temp_dir) / ""source.db""
        target_db_path = Path(temp_dir) / ""target.db""
        export_path = Path(temp_dir) / ""exports""
        
        # Create source database with multiple experiments
        source_conn = connect(source_db_path)
        
        # Create first experiment
        exp1 = load_or_create_experiment(
            experiment_name=""exp1"",
            sample_name=""sample1"",
            conn=source_conn
        )
        
        # Create second experiment
        exp2 = load_or_create_experiment(
            experiment_name=""exp2"",
            sample_name=""sample2"",
            conn=source_conn
        )
        
        # Create interdependencies
        x = ParamSpec(""x"", ""numeric"", unit=""V"")
        y = ParamSpec(""y"", ""numeric"", unit=""A"")
        interdeps = InterDependencies_(dependencies={y: (x,)})
        
        # Create datasets in both experiments
        datasets = []
        for exp in [exp1, exp2]:
            for i in range(2):  # 2 datasets per experiment
                dataset = DataSet(conn=source_conn, exp_id=exp.exp_id)
                dataset.set_interdependencies(interdeps)
                dataset.mark_started()
                
                # Add some data
                for j in range(5):
                    dataset.add_results([{""x"": j, ""y"": j * (i + 1)}])
                
                dataset.mark_completed()
                datasets.append(dataset)
        
        source_conn.close()
        
        # Run the export function
        result = export_datasets_and_create_metadata_db(
            source_db_path=source_db_path,
            target_db_path=target_db_path,
            export_path=export_path,
        )
        
        # Check that all datasets were processed
        assert len(result) == 4
        
        # Check that target database has all runs
        target_conn = connect(target_db_path)
        target_runs = get_runs(target_conn)
        assert len(target_runs) == 4
        target_conn.close()
",tests/dataset/test_export_datasets_and_create_metadata_db.py,,1,1.444980317078884e-07,"The method is a well-structured test function that verifies the preservation of experiment structure during dataset export. It uses temporary directories to avoid side effects, checks the integrity of the export process, and ensures that all datasets are correctly processed and transferred. Such test functions are crucial for maintaining software quality and are unlikely to be deleted unless the functionality they test is removed or significantly altered."
survived,"def _simple_dataset():
    """"""Create a simple dataset for testing""""""
    with tempfile.TemporaryDirectory() as temp_dir:
        db_path = Path(temp_dir) / ""test.db""
        
        # Create experiment and dataset
        exp = load_or_create_experiment(
            experiment_name=""test_exp"",
            sample_name=""test_sample"",
            conn=connect(db_path)
        )
        
        # Create interdependencies
        x = ParamSpec(""x"", ""numeric"", unit=""V"")
        y = ParamSpec(""y"", ""numeric"", unit=""A"")
        interdeps = InterDependencies_(dependencies={y: (x,)})
        
        # Create dataset
        dataset = DataSet(conn=exp.conn, exp_id=exp.exp_id)
        dataset.set_interdependencies(interdeps)
        dataset.mark_started()
        
        # Add some data
        for i in range(10):
            dataset.add_results([{""x"": i, ""y"": i**2}])
        
        dataset.mark_completed()
        
        yield db_path, dataset.run_id
",tests/dataset/test_export_datasets_and_create_metadata_db.py,,1,1.725782769012759e-08,"The method '_simple_dataset' is a utility function designed to create a simple dataset for testing purposes. It is a self-contained function that sets up a temporary database, creates an experiment, defines parameters and their interdependencies, and populates the dataset with sample data. Such utility functions are often used in testing environments to ensure that the main codebase functions correctly with sample data. Since it serves a specific purpose in testing and does not have any apparent issues or redundancies, it is likely to be retained in the codebase."
survived,"async def test_mcp_client_autogen_pagination(tmp_path: Path) -> None:
    script = tmp_path / ""app.py""
    script.write_text(
        textwrap.dedent(
            """"""
            from sqlalchemy import ForeignKey
            from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine
            from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column, relationship

            from enrichmcp import EnrichMCP
            from enrichmcp.sqlalchemy import (
                EnrichSQLAlchemyMixin,
                include_sqlalchemy_models,
                sqlalchemy_lifespan,
            )

            class Base(DeclarativeBase, EnrichSQLAlchemyMixin):
                pass

            class User(Base):
                __tablename__ = ""users""
                id: Mapped[int] = mapped_column(primary_key=True, info={""description"": ""ID""})
                name: Mapped[str] = mapped_column(info={""description"": ""Name""})
                orders: Mapped[list[""Order""]] = relationship(
                    back_populates=""user"", info={""description"": ""Orders""}
                )

            class Order(Base):
                __tablename__ = ""orders""
                id: Mapped[int] = mapped_column(primary_key=True, info={""description"": ""ID""})
                user_id: Mapped[int] = mapped_column(ForeignKey(""users.id""))
                user: Mapped[User] = relationship(
                    back_populates=""orders"", info={""description"": ""User""}
                )

            async def seed(session: AsyncSession) -> None:
                user = User(id=1, name=""Alice"")
                orders = [Order(id=i, user=user) for i in range(1, 4)]
                session.add_all([user, *orders])

            engine = create_async_engine(""sqlite+aiosqlite:///:memory:"")
            lifespan = sqlalchemy_lifespan(Base, engine, seed=seed)
            app = EnrichMCP(""Test"", ""Desc"", lifespan=lifespan)
            include_sqlalchemy_models(app, Base)

            if __name__ == ""__main__"":
                app.run()
            """"""
        )
    )

    config = {""mcpServers"": {""app"": {""command"": sys.executable, ""args"": [str(script)]}}}
    client = MCPClient(config=config)
    session = await client.create_session(""app"")

    result = await session.connector.call_tool(
        ""get_userenrichmodel_orders"",
        {""page"": 1, ""page_size"": 2, ""kwargs"": {""user_id"": 1}},
    )
    data = json.loads(result.content[0].text)
    assert len(data[""items""]) == 2
    assert data[""has_next""]

    result2 = await session.connector.call_tool(
        ""get_userenrichmodel_orders"",
        {""page"": 2, ""page_size"": 2, ""kwargs"": {""user_id"": 1}},
    )
    data2 = json.loads(result2.content[0].text)
    assert len(data2[""items""]) == 1
    assert not data2[""has_next""]

    await client.close_all_sessions()",tests/test_sqlalchemy_mcp_use.py,,1,9.931195248674785e-08,"The method `test_mcp_client_autogen_pagination` is a test function that verifies the pagination functionality of a client interacting with a database using SQLAlchemy and an asynchronous engine. It is a well-structured test that ensures the correct behavior of the pagination feature, which is crucial for handling large datasets efficiently. Test functions like this are essential for maintaining code quality and are unlikely to be deleted unless the feature they test is removed or significantly altered."
survived,"    async def register(self, *_, **__):
        self.calls += 1
        if self.calls < 3:
            raise biotech_agent.AdkClientError(""boom"")
",tests/test_register_mesh_backoff.py,StubClient,1,1.444980317078884e-07,"The method 'register' is designed to increment a call counter and raise an exception if the number of calls is less than 3. This behavior suggests it is part of a testing or retry mechanism, possibly to simulate or handle transient errors. The method's functionality seems specific and intentional, likely serving a purpose in the context of the application, such as testing error handling or implementing a retry logic. Therefore, it is more likely to be retained unless the surrounding code or requirements change significantly."
survived,"        async def run(self, *_: Any, **__: Any) -> Dict[str, Any]:
            return {""status"": ""error"", ""error"": ""agents SDK unavailable""}
",src/meta_agent/agents/guardrail_designer_agent.py,Agent,0,0.9999998555019682,"The method 'run' is likely to be deleted because it returns a hardcoded error message indicating that the 'agents SDK' is unavailable. This suggests that the method is not functional and does not perform any meaningful operation. If the SDK becomes available or if there is a need to handle this error differently, the method would need to be updated or removed."
survived,"def test_settings_repr_masks_secret(monkeypatch):
    monkeypatch.setenv(""OPENAI_API_KEY"", ""shh"")
    import src.utils.config as cfg
    importlib.reload(cfg)
    settings = cfg.Settings()
    rep = repr(settings)
    assert ""shh"" not in rep
    assert ""***"" in rep",tests/test_root_config.py,,1,9.237449576640118e-09,"The method 'test_settings_repr_masks_secret' is a unit test designed to ensure that sensitive information, such as API keys, is not exposed in the string representation of a settings object. This is a crucial security feature, as exposing such information could lead to unauthorized access and misuse. The test uses 'monkeypatch' to set an environment variable and then checks that the API key is masked in the representation. This kind of test is important for maintaining security best practices, and there is no indication that it is obsolete or incorrect. Therefore, it is likely to be retained."
survived,"        def read_secret_version(self, path):
            return {""data"": {""data"": {""OPENAI_API_KEY"": ""vault""}}}
",tests/test_root_config.py,FakeKV,1,3.2241866333029355e-08,"The method 'read_secret_version' is a simple function that returns a hardcoded dictionary with a nested structure. It doesn't perform any complex operations or interact with external systems, which makes it unlikely to be deleted unless the requirements change significantly. Additionally, the method name suggests it is part of a larger system dealing with secrets or configurations, which are typically stable components in software systems. Therefore, it is more likely to survive."
survived,"    def __init__(self) -> None:
        self.shutdown = asyncio.Event()
",test/windows/test_shutdown.py,DummyManager,1,2.8453347280241004e-08,"The method is a constructor for a class, initializing an instance variable 'shutdown' with an asyncio Event. This is a common pattern in asynchronous programming to manage shutdown signals or events. The method is essential for setting up the initial state of an object, and there is no indication that it is redundant or incorrect. Therefore, it is likely to be retained in the code."
survived,"    def close(self) -> None:
        pass
",tests/test_self_improver.py,DummyLedger,0,0.9999999943972036,"The method 'close' is defined but not implemented, as it only contains a 'pass' statement. This suggests that the method is a placeholder and does not perform any action. In many cases, such methods are either completed later or removed if they are deemed unnecessary. Without any additional context or usage of this method, it is likely to be deleted in future refactoring to clean up the code."
survived,"    def save(
        self,
        response: List[bytes],
        name: str = None,
        dir: str = os.getcwd(),
        filenames_prefix: str = """",
    ) -> List[str]:
        """"""Save your amazing images! 

        Args:
            response (List[bytes]): List of image data
            name (str, optional): Base name for saved files
            dir (str, optional): Where to save the images
            filenames_prefix (str, optional): Prefix for filenames

        Returns:
            List[str]: List of saved filenames
        """"""
        assert isinstance(response, list), f""Response should be of {list} not {type(response)}""
        name = self.prompt if name is None else name

        if not os.path.exists(dir):
            os.makedirs(dir)

        filenames = []
        count = 0
        for image in response:
            def complete_path():
                count_value = """" if count == 0 else f""_{count}""
                return os.path.join(dir, name + count_value + ""."" + self.image_extension)

            while os.path.isfile(complete_path()):
                count += 1

            absolute_path_to_file = complete_path()
            filenames.append(filenames_prefix + os.path.split(absolute_path_to_file)[1])

            with open(absolute_path_to_file, ""wb"") as fh:
                fh.write(image)
        return filenames
",webscout/Provider/TTI/pixelmuse.py,PixelMuseImager,1,9.237449576640118e-09,"The method 'save' is a utility function for saving image data to files, which is a common requirement in many applications dealing with image processing or generation. It provides flexibility with options for naming, directory selection, and filename prefixing. The method is well-documented, handles directory creation, and ensures unique filenames by checking for existing files. These features make it a useful and reusable component in various contexts, suggesting it is likely to be retained."
survived,"            def complete_path():
                count_value = """" if count == 0 else f""_{count}""
                return os.path.join(save_dir, filenames_prefix + name + count_value + ""."" + self.image_extension)
",webscout/Provider/TTI/magicstudio.py,MagicStudioImager,1,2.5109990926928157e-08,"The method 'complete_path' is a utility function that constructs a file path based on given parameters. It uses a conditional expression to append a count value to the filename if the count is not zero. This kind of functionality is common in file handling operations, especially when dealing with saving files with unique names to avoid overwriting. The method is concise, performs a specific task, and is likely to be useful in contexts where file path generation is needed. Therefore, it is likely to be retained in the codebase."
survived,"            def complete_path():
                count_value = """" if count == 0 else f""_{count}""
                return os.path.join(dir, name + count_value + ""."" + self.image_extension)
",webscout/Provider/TTI/freeaiplayground.py,FreeAIImager,0,0.9999999988967441,"The method 'complete_path' is likely to be deleted (0) because it references variables 'count', 'dir', 'name', and 'self.image_extension' that are not defined within the method or passed as parameters. This suggests that the method relies on external state, which can lead to errors or unexpected behavior if those variables are not properly managed. Without additional context or refactoring to make the method self-contained, it is prone to issues and may be removed or replaced with a more robust solution."
survived,"    def test_array_grad(self):
        klong = KlongInterpreter()
        klong('x::!5')
        klong('loss::{+/x*x}')
        r = klong('x  loss')
        self.assertTrue(np.allclose(r, np.array([0,2,4,6,8]), atol=1e-3))
",tests/test_autograd.py,TestAutograd,1,8.592166611791576e-10,"The method `test_array_grad` is a unit test for a specific functionality of the `KlongInterpreter`. It is testing the gradient calculation of a loss function defined in the Klong language. Unit tests are crucial for ensuring the correctness of code, especially in complex systems like interpreters or compilers. Since this test is verifying a specific feature, it is likely to be maintained to ensure that future changes do not break existing functionality. Therefore, the method is likely to survive."
survived,"def test_insight_invalid_token() -> None:
    _setup_simulations()
    client = _make_client()
    resp = client.post(""/insight"", json={}, headers={""Authorization"": ""Bearer bad""})
    assert resp.status_code == 403",tests/test_insight_endpoint.py,,1,9.736200303530205e-10,"The method `test_insight_invalid_token` is a unit test designed to verify that the system correctly handles an invalid token by returning a 403 status code. Unit tests are crucial for ensuring the reliability and security of software, especially in authentication scenarios. This test is specific, concise, and serves a clear purpose in the testing suite. Therefore, it is likely to be retained as part of the codebase to maintain the integrity of the authentication process."
survived,"async def test_send_http_error():
    with patch(""aiohttp.ClientSession"") as mock_session:
        resp = AsyncMock()
        resp.status = 500
        resp.text = AsyncMock(return_value=""bad"")
        cm = AsyncMock()
        cm.__aenter__.return_value = resp
        mock_session.return_value.post.return_value = cm
        client = TelemetryAPIClient({""trace"": EndpointConfig(""http://example.com"")})
        with pytest.raises(ValueError):
            await client.send(""trace"", {""d"": 1})
        await client.close()
",tests/unit/test_telemetry_client.py,,1,4.363462233903899e-09,"The method `test_send_http_error` is a unit test designed to test the behavior of the `TelemetryAPIClient` when it encounters an HTTP error (status 500) during a POST request. It uses mocking to simulate the HTTP client and response, and it checks that a `ValueError` is raised in this scenario. This is a typical and necessary test to ensure that the client handles errors correctly, which is crucial for robust error handling in applications. Therefore, the method is likely to be retained as it serves an important purpose in the test suite."
survived,"    def __post_init__(self) -> None:
        if self.auth_token:
            self.headers[""Authorization""] = f""Bearer {self.auth_token}""
        self.headers.setdefault(""Content-Type"", ""application/json"")
",src/meta_agent/services/telemetry_client.py,EndpointConfig,1,2.5109990926928157e-08,"The method `__post_init__` is a special method in Python used with data classes to perform additional initialization after the built-in `__init__` method. This method is useful for setting up or modifying attributes that depend on other attributes initialized by `__init__`. In this code, it checks if `auth_token` is present and sets the `Authorization` header accordingly, and ensures the `Content-Type` header is set to `application/json`. This functionality is essential for setting up HTTP headers correctly, especially in applications dealing with APIs. Therefore, the method is likely to be retained as it provides necessary setup for the class's operation."
survived,"async def test_send_success(telemetry_client):
    result = await telemetry_client.send(""trace"", {""data"": 1})
    assert result == {""ok"": True}
",tests/unit/test_telemetry_client.py,,1,3.2241866333029355e-08,"The method 'test_send_success' is a test function that checks the functionality of the 'send' method of a 'telemetry_client'. Test functions are crucial for ensuring code reliability and correctness, especially in asynchronous operations. This function is likely part of a test suite that verifies the behavior of the telemetry client, which is important for maintaining software quality. Therefore, it is unlikely to be deleted as it serves a critical role in testing."
survived,"            async def close(self) -> None:
                pass
",src/meta_agent/services/llm_service.py,AiohttpPlaceholder.ClientSession,1,1.275190675769241e-07,"The method `close` is defined as an asynchronous function but contains only a `pass` statement, meaning it currently does nothing. However, the presence of this method suggests that it is intended to be overridden or implemented in the future, especially in classes where resource management or cleanup is necessary. In many cases, such placeholder methods are kept to maintain a consistent interface or to allow subclasses to provide specific implementations. Therefore, it is likely to survive as it serves a structural purpose in the code."
survived,"        def __init__(self, *_, **__):
            pass
",src/meta_agent/services/telemetry_client.py,ClientSession,0,0.9999998362622821,"The method is a constructor (__init__) that takes arbitrary positional and keyword arguments but does nothing with them. This is typically not useful unless it's a placeholder for future development or part of a larger framework where the arguments are handled elsewhere. However, without any implementation or documentation indicating its purpose, it is likely to be considered redundant and removed in a cleanup process."
survived,"    def menu(self, prompt: str, options: Sequence[str]) -> str:
        """"""Display a numbered menu and return the selected option.""""""
        if not options:
            raise ValueError(""options must not be empty"")

        while True:
            print(prompt)
            for idx, opt in enumerate(options, 1):
                print(f""{idx}. {opt}"")
            choice = self.ask(""Choose an option:"")
            if choice.isdigit():
                selected = int(choice) - 1
                if 0 <= selected < len(options):
                    return options[selected]
            print(""Invalid choice, try again."")
",src/meta_agent/ux/interactive.py,Interactive,1,2.646573631904765e-09,"The method 'menu' is a utility function that provides a common and useful functionality: displaying a menu and allowing the user to select an option. This is a typical requirement in many command-line applications or scripts. The method is well-implemented, handling empty options with an exception and validating user input to ensure it is within the correct range. Such utility methods are often reused across different projects or parts of a project, making them valuable to retain. Therefore, it is likely to survive."
survived,"            async def step(self):
                return None
",tests/test_agents_registry.py,TestAgentRegistryFunctions.BAgent,0,0.9999962733608834,"The method 'step' is an asynchronous function that currently does nothing but return None. If this method is part of a larger codebase, it might be a placeholder for future implementation. However, if it remains unchanged and unused, it is likely to be deleted in future refactoring efforts to clean up the code. Without additional context on its intended use or any comments indicating future plans, the method seems redundant."
survived,"    def test_maxdd(self):
        returns = [0.1, -0.2, 0.05, -0.1]
        self.assertAlmostEqual(finance_agent._maxdd(returns), 0.244)
",tests/test_finance_utils.py,TestFinanceUtils,1,3.3982678079468468e-09,"The method `test_maxdd` is a unit test for the `_maxdd` function of a `finance_agent` object. Unit tests are crucial for ensuring that individual components of a codebase work as expected. The test checks if the `_maxdd` function correctly calculates the maximum drawdown from a list of returns, which is a common financial metric. Since testing is a fundamental part of software development and maintenance, it is unlikely that this method will be deleted unless the `_maxdd` function itself is removed or significantly altered. Therefore, the method is likely to survive."
survived,"    def test_wrap_mcp_digest(self):
        payload = {""a"": 1}
        mcp = self.agent._wrap_mcp(payload)
        self.assertEqual(mcp[""payload""], payload)
        raw = json.dumps(payload, separators=("","", "":""))
        import hashlib
        self.assertEqual(mcp[""digest""], hashlib.sha256(raw.encode()).hexdigest())
",tests/test_supply_chain_agent.py,TestSupplyChainAgent,1,1.0467401685178159e-08,"The method `test_wrap_mcp_digest` is a unit test designed to verify the functionality of the `_wrap_mcp` method in the `agent` object. It checks if the method correctly wraps a payload and computes its digest using SHA-256. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with data integrity and security features like hashing. Therefore, this method is likely to be retained as part of the test suite to ensure ongoing validation of the `_wrap_mcp` method's behavior."
survived,"async def get_order_items(order_id: int, ctx: EnrichContext) -> list[""OrderItemEnrichModel""]:
    """"""Get all items in a specific order.""""""
    session_factory = ctx.request_context.lifespan_context[""session_factory""]
    async with session_factory() as session:
        result = await session.execute(select(OrderItem).where(OrderItem.order_id == order_id))
        items = result.scalars().all()

        return [
            OrderItemEnrichModel(
                id=item.id,
                order_id=item.order_id,
                product_id=item.product_id,
                quantity=item.quantity,
                unit_price=item.unit_price,
                total_price=item.total_price,
            )
            for item in items
        ]
",examples/sqlalchemy_shop/app.py,,1,1.493094675974231e-10,"The method 'get_order_items' is likely to survive because it is a well-structured asynchronous function that retrieves order items from a database using SQLAlchemy. It uses modern Python features such as type hinting and asynchronous context management, which are considered best practices. Additionally, it provides a clear and specific functionality that is essential for applications dealing with order management, making it a valuable part of the codebase."
survived,"    def test_model_inheritance(self):
        """"""Test that the EnrichModel properly inherits from EnrichModel base.""""""

        class Base(DeclarativeBase):
            pass

        class Product(Base, EnrichSQLAlchemyMixin):
            __tablename__ = ""products""
            id: Mapped[int] = mapped_column(primary_key=True)
            name: Mapped[str] = mapped_column()

        ProductEnrichModel = Product.__enrich_model__()

        # Should be a proper EnrichModel with all its methods
        assert hasattr(ProductEnrichModel, ""model_dump"")
        assert hasattr(ProductEnrichModel, ""model_dump_json"")
        assert hasattr(ProductEnrichModel, ""relationship_fields"")
        assert hasattr(ProductEnrichModel, ""describe"")
",tests/test_sqlalchemy_integration.py,TestEdgeCases,1,2.8453347280241004e-08,"The method `test_model_inheritance` is a unit test that verifies the inheritance and functionality of a model class. It checks if the `ProductEnrichModel` has the expected methods, which are crucial for ensuring the model behaves correctly. Such tests are essential for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is unlikely to be deleted as it serves an important role in the development process."
survived,"async def get_order_item_product(
    order_item_id: int, ctx: EnrichContext
) -> Optional[""ProductEnrichModel""]:
    """"""Get the product for a specific order item.""""""
    session_factory = ctx.request_context.lifespan_context[""session_factory""]
    async with session_factory() as session:
        item = await session.get(OrderItem, order_item_id)
        if not item:
            return None

        # Load the product
        await session.refresh(item, [""product""])
        product = item.product

        return ProductEnrichModel(
            id=product.id,
            name=product.name,
            description=product.description,
            price=product.price,
            stock_quantity=product.stock_quantity,
            category=product.category,
            created_at=product.created_at,
        )
",examples/sqlalchemy_shop/app.py,,1,1.8189616842444243e-09,"The method `get_order_item_product` is likely to survive because it performs a specific and useful function within an application: retrieving and enriching product information for a given order item. This functionality is essential in many e-commerce or inventory management systems where understanding the details of a product associated with an order is crucial. The method is well-structured, uses asynchronous programming to handle database operations efficiently, and returns a well-defined model (`ProductEnrichModel`). These characteristics make it a valuable part of the codebase."
survived,"async def list_orders(
    ctx: EnrichContext, status: str | None = None, cursor: str | None = None, limit: int = 10
) -> CursorResult[OrderEnrichModel]:
    """"""List orders with cursor-based pagination.""""""
    session_factory = ctx.request_context.lifespan_context[""session_factory""]
    async with session_factory() as session:
        # Build query
        query = select(Order)

        # Apply status filter
        if status:
            query = query.where(Order.status == status)

        # Apply cursor (assuming cursor is the last order ID seen)
        if cursor:
            query = query.where(Order.id > int(cursor))

        # Order by ID for consistent cursor pagination
        query = query.order_by(Order.id).limit(limit + 1)

        result = await session.execute(query)
        orders = result.scalars().all()

        # Check if there are more results
        has_next = len(orders) > limit
        if has_next:
            orders = orders[:-1]  # Remove the extra item

        items = [
            OrderEnrichModel(
                id=order.id,
                order_number=order.order_number,
                user_id=order.user_id,
                status=order.status,
                total_amount=order.total_amount,
                created_at=order.created_at,
                updated_at=order.updated_at,
                shipping_address=order.shipping_address,
                notes=order.notes,
            )
            for order in orders
        ]

        next_cursor = str(orders[-1].id) if orders else None

        return CursorResult(
            items=items, next_cursor=next_cursor, page_size=limit, has_next=has_next
        )
",examples/sqlalchemy_shop/app.py,,1,5.905303995456778e-10,"The method 'list_orders' is a well-structured and useful function for listing orders with cursor-based pagination. It includes filtering by status, handles pagination efficiently, and returns a structured result. These features are essential for applications dealing with large datasets and requiring efficient data retrieval. The use of async and session management indicates modern and efficient design practices. Therefore, it is likely to be retained in the codebase."
survived,"    def test_nullable_columns(self):
        """"""Test that nullable columns are converted to Optional types.""""""

        class Base(DeclarativeBase):
            pass

        class Product(Base, EnrichSQLAlchemyMixin):
            __tablename__ = ""products""

            id: Mapped[int] = mapped_column(primary_key=True)
            name: Mapped[str] = mapped_column(nullable=False)
            description: Mapped[str | None] = mapped_column(
                nullable=True, info={""description"": ""Product description""}
            )
            price: Mapped[float | None] = mapped_column(nullable=True)

        ProductEnrichModel = Product.__enrich_model__()
        fields = ProductEnrichModel.model_fields

        # Non-nullable fields should not be Optional
        assert fields[""id""].annotation == int
        assert fields[""name""].annotation == str

        # Nullable fields should be Optional
        # Check if it's Optional by looking at the annotation
        desc_type = fields[""description""].annotation
        price_type = fields[""price""].annotation

        # In Python 3.10+, Optional[X] is Union[X, None]
        assert get_origin(desc_type) in {Union, types.UnionType}
        assert type(None) in get_args(desc_type)
        assert str in get_args(desc_type)

        assert get_origin(price_type) in {Union, types.UnionType}
        assert type(None) in get_args(price_type)
        assert float in get_args(price_type)
",tests/test_sqlalchemy_integration.py,TestBasicModel,1,4.1399375473943306e-08,"The method 'test_nullable_columns' is a unit test that verifies the correct conversion of nullable columns to Optional types in a SQLAlchemy model. It is a well-structured test that checks both nullable and non-nullable fields, ensuring that the model behaves as expected. This kind of test is crucial for maintaining the integrity of data models, especially when dealing with databases. Since it serves a clear purpose in validating the functionality of the code, it is unlikely to be deleted."
survived,"    def __init__(self, ledger_path: str | pathlib.Path):
        self.path = pathlib.Path(ledger_path)
        self.path.parent.mkdir(parents=True, exist_ok=True)
",alpha_factory_v1/demos/meta_agentic_agi/agents/agent_base.py,LineageTracer,1,3.2241866333029355e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. It initializes the object with a given path and ensures that the directory structure exists by creating any necessary parent directories. This is a common and useful pattern in file handling, making the method likely to be retained."
survived,"def mcts_policy(net: MuZeroTiny, obs: np.ndarray, simulations: int = 16) -> int:
    """"""Very small UCBbased MCTS on top of MuZeroTiny.""""""
    act_dim = 4
    with torch.no_grad():
        h, v0, p0 = net.initial(torch.tensor(obs, device=CFG.device, dtype=torch.float32))
    N = np.zeros(act_dim); W = np.zeros(act_dim)
    P = p0.exp().cpu().numpy()
    for _ in range(simulations):
        a = np.argmax(P * (np.sqrt(N.sum()+1e-8)/(1+N)))
        a_one = F.one_hot(torch.tensor(a), num_classes=act_dim).float().to(CFG.device)
        h2, r, v, p = net.recurrent(h, a_one)
        q = (r+v).item()
        N[a] += 1; W[a] += q
    best = int(np.argmax(W / (N+1e-8)))
    return best
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,,1,7.73442280641062e-08,"The method implements a Monte Carlo Tree Search (MCTS) policy for a neural network model, which is a common and useful approach in reinforcement learning and game AI. It uses Upper Confidence Bound (UCB) to balance exploration and exploitation, and integrates with a neural network (MuZeroTiny) to predict actions. This method is likely to be retained as it provides a specific and valuable functionality for decision-making processes in AI models."
survived,"    def __call__(self, prompt:str, **kw):
        return self.run(prompt, **kw)
",alpha_factory_v1/demos/meta_agentic_agi_v2/agents/agent_base.py,Agent,1,2.2159489282323004e-08,"The method `__call__` is a special method in Python that allows an instance of a class to be called as a function. This is a useful feature for classes that are designed to encapsulate a single function or behavior, making the class instances behave like functions. The implementation here is straightforward and leverages another method `run`, which suggests that the class is designed to process or handle prompts in some way. This pattern is common in Python, especially in libraries that deal with processing or transforming data, such as machine learning models or data processing pipelines. Therefore, the method is likely to be retained as it provides a clear and Pythonic way to use the class instances as callable objects."
survived,"    def loop(self):
        obs=[e.reset() for e in self.envs]
        for t in range(CFG.max_steps):
            if self.stop: break
            for i,(env,learner) in enumerate(zip(self.envs,self.learners)):
                a=learner.act(obs[i])
                nxt,r,done,_=env.step(a)
                learner.remember(obs[i],r)
                loss=learner.train_once()
                obs[i]=env.reset() if done else nxt
                if t%CFG.ui_tick==0 and i==0:
                    A2ABus.publish(""ui"",{""t"":t,""r"":r,""loss"":loss})
        LOG.info(""Orchestrator loop exit at t=%d"", t)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,Orchestrator,1,1.444980317078884e-07,"The method is a core part of a loop that orchestrates the interaction between environments and learners, handling actions, rewards, and training. It also includes logging and UI updates, which are essential for monitoring and debugging. These functionalities are crucial for the system's operation, making it unlikely to be deleted."
survived,"async def _startup():
    global orch
    orch=Orchestrator()
    threading.Thread(target=orch.loop,daemon=True).start()
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,,1,1.1861120010657661e-08,"The method _startup is an asynchronous function that initializes a global variable 'orch' with an instance of the Orchestrator class and starts a new daemon thread to run the 'loop' method of the Orchestrator. This setup is typical for initializing background processes or services in an application, which is a common requirement in many systems. The use of threading and asynchronous programming suggests that this method is part of a larger system that requires concurrent operations. Given its utility in setting up a background process, it is likely to be retained in the codebase unless the architecture of the application changes significantly."
survived,"    def __init__(self, hidden: int, act_dim: int):
        super().__init__(); self.r = nn.Linear(hidden+act_dim, 1); self.h = nn.Linear(hidden+act_dim, hidden)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,Dyn,1,1.275190675769241e-07,"The method is a constructor for a class, likely a neural network module, which initializes two linear layers. This is a common pattern in defining neural network architectures, where layers are initialized in the constructor. The use of `nn.Linear` suggests that this is part of a PyTorch model, and the method is essential for setting up the model's parameters. Therefore, it is unlikely to be deleted as it is crucial for the model's functionality."
survived,"def emit_helm(dir_:Path=Path(""helm_chart"")):
    dir_.mkdir(exist_ok=True)
    (dir_/""values.yaml"").write_text(HELM_VALUES)
    (dir_/""Chart.yaml"").write_text(""apiVersion: v2\nname: alpha-asi-demo\nversion: 0.1.0\n"")
    print(""Helm chart "",dir_)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,,1,1.1032560311263802e-09,"The method 'emit_helm' is a utility function that creates a directory for a Helm chart and writes necessary configuration files into it. This is a common task in software development, especially in environments that use Kubernetes for deployment. The method is straightforward, performs a useful function, and does not have any apparent issues or redundancies that would warrant its deletion. Therefore, it is likely to be retained in the codebase."
survived,"    def run(self, code: str, func_name: str, *args, **kw):
        loc: Dict[str,Any] = {}
        with self:
            exec(code, {}, loc)
        if func_name not in loc:
            raise AttributeError(f""{func_name} not found"")
        return loc[func_name](*args, **kw)
",alpha_factory_v1/demos/meta_agentic_agi_v3/agents/agent_base.py,SafeExec,1,6.348800075736417e-09,"The method 'run' is a utility function that dynamically executes a given code string and attempts to call a specified function from that code. This kind of functionality is often used in environments where dynamic code execution is necessary, such as in scripting engines, plugin systems, or educational tools. The method is well-defined, checks for the existence of the function before calling it, and uses a context manager (indicated by 'with self') which suggests some form of resource management or setup/teardown process. These characteristics make it a useful and flexible tool in certain applications, and there is no indication of it being deprecated or replaced by a better alternative. Therefore, it is likely to survive."
survived,"    def chat(self, msgs: List[Dict[str,str]], **kw) -> str:
        merged = dict(temperature=self.temperature, max_tokens=self.max_tokens, **kw)
        attempts = 0
        while True:
            GLOBAL_LIMITER.acquire(_str_tkn(json.dumps(msgs)))
            try:
                if self._backend == ""openai"":
                    rsp = self._client.chat.completions.create(model=self._model, messages=msgs, stream=False, **merged)
                    return rsp.choices[0].message.content
                if self._backend == ""anthropic"":
                    rsp = self._client.messages.create(model=self._model, messages=msgs, **merged)
                    return rsp.content[0].text
                if self._backend == ""gemini"":
                    return self._client.generate_content(msgs[-1][""content""], **merged).text
                if self._backend in (""mistral"",""llama""):
                    prompt = """".join(f""<{m['role']}> {m['content']}"" for m in msgs)+""\n<assistant> ""
                    out = self._client(prompt, max_tokens=self.max_tokens, temperature=self.temperature, stop=[""</assistant>""])
                    return out[""choices""][0][""text""].strip()
            except Exception as e:
                attempts += 1
                wait = min(60, 2**attempts)
                LOGGER.warning(""LM error %s; retry in %.1fs"", e, wait)
                time.sleep(wait)
",alpha_factory_v1/demos/meta_agentic_agi_v2/agents/agent_base.py,LMClient,1,4.6911638017642294e-08,"The method 'chat' is a core function that handles communication with different AI backends (openai, anthropic, gemini, mistral, llama) to generate chat responses. It includes error handling and retry logic, which are essential for robust operation in production environments. The method is versatile, supporting multiple backends and allowing for additional parameters through **kw. Such a method is likely to be retained as it provides critical functionality for interacting with AI models and is designed to be adaptable and resilient."
survived,"    def __init__(self,
                 name: str,
                 role: str = ""autonomousagent"",
                 provider: str | None = None,
                 objectives: Optional[ObjectiveWeights] = None,
                 lineage_dir: str | pathlib.Path = ""./lineage"",
                 rate_limit_tps: float = 3.0):
        self.name = name
        self.role = role
        self.id = f""{name}-{_sha(uuid.uuid4().hex)}""
        self.objectives = objectives or ObjectiveWeights()
        self.lm = LMClient(provider or os.getenv(""ALPHA_PROVIDER"", ""openai:gpt-4o""))
        self.tracer = LineageTracer(pathlib.Path(lineage_dir)/f""{self.id}.jsonl"")
        self.tracer.log(""init"", role=role, provider=self.lm.endpoint)
        GLOBAL_LIMITER._tps = rate_limit_tps
",alpha_factory_v1/demos/meta_agentic_agi_v3/agents/agent_base.py,Agent,1,1.3440409770490404e-08,"The method is a constructor (__init__) for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes and are unlikely to be removed unless the entire class is being refactored or removed. Additionally, the method includes several parameters with default values, making it flexible and useful for various scenarios. The use of type hints and default values also suggests that the code is well-maintained and designed for clarity and usability. Therefore, it is likely to survive."
survived,"def _sha(text: str) -> str:
    return hashlib.sha256(text.encode()).hexdigest()[:10]
",alpha_factory_v1/demos/meta_agentic_agi_v3/agents/agent_base.py,,1,4.944450477491054e-09,"The method '_sha' is a utility function that generates a SHA-256 hash of a given text and returns the first 10 characters of the hash. This type of function is commonly used for creating unique identifiers or checksums. It is a simple, efficient, and useful function that is likely to be used in various applications where a short hash is needed. Therefore, it is likely to be retained in the codebase."
survived,"    def __init__(self, name):
        super().__init__(""127.0.0.1"", 0)
        self.name = name
",tests/test_multi_contributor.py,FakeComm,1,3.2241866333029355e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. It initializes an instance of the class with a given name and calls the superclass's constructor with specific parameters. This is a common and necessary pattern in class design, making it unlikely to be deleted unless the entire class is being refactored or removed."
survived,"        def __init__(self, *args, **kwargs) -> None:  # pragma: no cover - args ignored
            pass
",tests/test_alpha_agi_business_3_v1.py,DummyAgent,0,0.9999687980937693,"The method is a constructor that does nothing and explicitly ignores its arguments. The use of 'pragma: no cover' suggests that the author does not intend for this method to be covered by tests, indicating it might be a placeholder or intentionally left blank for subclassing or future implementation. However, if it remains unused and unimplemented, it is likely to be deleted in the future to clean up the codebase."
survived,"def accordion(data=None, class_name=None, key=None):
    props = {
        ""data"": data,
        ""className"": class_name,
    }
    component_value = _component_func(comp=""accordion"", props=props, key=key)
    return component_value",streamlit_shadcn_ui/py_components/accordion.py,,1,4.944450477491054e-09,"The method 'accordion' is a simple wrapper function that constructs a dictionary of properties and passes them to another function '_component_func'. This pattern is common in frameworks that deal with UI components, such as React or similar libraries in Python. The method is likely part of a larger system for rendering UI components, and its simplicity and clear purpose suggest it is useful and not redundant. Therefore, it is likely to be retained in the codebase."
survived,"def test_load_vocab(tmp_path):
    vocab_file = tmp_path / ""vocab.csv""
    with open(vocab_file, ""w"", encoding=""utf-8"", newline="""") as f:
        writer = csv.writer(f)
        writer.writerow([0, "" hello""])
        writer.writerow([1, "" world ""])

    vocab = sampler.load_vocab(str(vocab_file))

    assert vocab == [""hello"", ""world""]
",tests/test_sampler_io.py,,1,2.5109990926928157e-08,"The method 'test_load_vocab' is a unit test designed to verify the functionality of the 'load_vocab' method from the 'sampler' module. It creates a temporary vocabulary file, writes sample data to it, and then checks if the 'load_vocab' method correctly processes this data by asserting the expected output. This is a typical and necessary practice in software development to ensure code reliability and correctness. Therefore, the method is likely to be retained as it serves an important role in testing."
survived,"def test_devicon_various_examples(name, expected):
    devicons = reload_devicons('es')
    assert devicons.devicon(MockFile(name)) == expected",tests/test_devicons.py,,1,1.275190675769241e-07,"The method `test_devicon_various_examples` is a test function that checks if the `devicon` method of the `devicons` object returns the expected result when given a `MockFile` with a specific name. Test functions are generally important for ensuring code correctness and are usually retained unless they are redundant or replaced by a more comprehensive testing framework. Since this function seems to be a straightforward unit test, it is likely to be retained unless there is a significant change in the testing strategy or framework."
survived,"    def close(self) -> None:  # pragma: no cover - dummy
        pass
",tests/test_codegen_safety.py,DummyLedger,1,5.715002851580502e-07,"The method 'close' is marked with a pragma directive 'no cover', indicating that it is intentionally left as a dummy or placeholder method. This suggests that the method is part of a larger interface or class structure where it is expected to be overridden or implemented in subclasses. Such methods are often retained to maintain a consistent API or to provide a default implementation that does nothing. Therefore, it is likely to survive as it serves a structural purpose in the code."
survived,"    def test_list_agents_flag(self):
        args = self._parse([""--list-agents""])
        self.assertTrue(args.list_agents)
",alpha_factory_v1/tests/test_edge_runner.py,EdgeRunnerParseTest,1,5.905303995456778e-10,"The method 'test_list_agents_flag' is a unit test that checks if the '--list-agents' flag is correctly parsed and set to True. This is a typical test case for command-line argument parsing, which is a common requirement in many applications. Such tests are crucial for ensuring that the application behaves as expected when different command-line options are used. Therefore, this method is likely to be retained as it serves an important role in maintaining the reliability of the software."
survived,"    def test_venv_python_posix(self):
        with mock.patch.object(os, 'name', 'posix'):
            self.assertEqual(
                quickstart._venv_python(Path('/tmp/venv')),
                Path('/tmp/venv/bin/python')
            )
",alpha_factory_v1/tests/test_quickstart.py,QuickstartUtilsTest,1,4.6911638017642294e-08,"The method `test_venv_python_posix` is a unit test that checks the functionality of the `_venv_python` method from the `quickstart` module. It uses `mock.patch.object` to simulate the environment as a POSIX system and verifies that the path to the Python executable in a virtual environment is correctly returned. This is a standard and useful test for ensuring cross-platform compatibility of the code, especially in environments where the path structure differs (e.g., POSIX vs. Windows). Since it is a straightforward and necessary test for validating functionality, it is likely to be retained in the codebase."
survived,"    def test_venv_python_windows(self):
        with mock.patch.object(os, 'name', 'nt'):
            path = PureWindowsPath('C:/v')
            self.assertEqual(
                quickstart._venv_python(path),
                path / 'Scripts' / 'python.exe'
            )
",alpha_factory_v1/tests/test_quickstart.py,QuickstartUtilsTest,1,1.522997951276035e-08,"The method `test_venv_python_windows` is a unit test designed to verify the behavior of the `_venv_python` function when executed in a Windows environment. It uses `mock.patch.object` to simulate the Windows OS environment by setting `os.name` to 'nt'. The test then checks if the function correctly constructs the path to the Python executable within a virtual environment on Windows. This is a valid and useful test case for ensuring cross-platform compatibility of the `_venv_python` function. Therefore, it is likely to be retained in the codebase as it serves a clear purpose in testing platform-specific functionality."
survived,"    def test_venv_pip_windows(self):
        with mock.patch.object(os, 'name', 'nt'):
            path = PureWindowsPath('C:/v')
            self.assertEqual(
                quickstart._venv_pip(path),
                path / 'Scripts' / 'pip.exe'
            )
",alpha_factory_v1/tests/test_quickstart.py,QuickstartUtilsTest,1,9.237449576640118e-09,"The method `test_venv_pip_windows` is a unit test designed to verify the behavior of the `_venv_pip` function on Windows systems. It uses `mock.patch.object` to simulate the Windows environment by setting `os.name` to 'nt'. The test then checks if the `_venv_pip` function correctly constructs the path to the `pip.exe` executable within a virtual environment. This is a valid and useful test for ensuring platform-specific functionality works as expected. Therefore, it is likely to be retained in the codebase."
survived,"    def __init__(self, env_id: str = ""CartPole-v1"") -> None:
        self.env = gym.make(env_id, render_mode=""rgb_array"")
        obs_dim = math.prod(self.env.observation_space.shape)
        self.action_dim = self.env.action_space.n
        self.net = MiniMuNet(obs_dim, self.action_dim)
",alpha_factory_v1/demos/muzero_planning/minimuzero.py,MiniMu,1,2.8453347280241004e-08,"The method is a constructor for a class, likely initializing an environment for a reinforcement learning task using OpenAI's Gym. It sets up the environment, calculates observation dimensions, action dimensions, and initializes a neural network. These are fundamental steps in setting up a reinforcement learning agent, and there is no indication of redundancy or obsolescence in the code. Therefore, it is likely to be retained."
survived,"    def test_reset_produces_valid_grid(self):
        env = ce.CurriculumEnv(genome=ce.EnvGenome(max_steps=10), size=6)
        obs, info = env.reset()
        self.assertEqual(obs.shape[0], env.observation_space.shape[0])
        self.assertIn(""genome_id"", info)
        self.assertLessEqual(info[""difficulty""], 10)
",alpha_factory_v1/tests/test_aiga_meta_evolution.py,CurriculumEnvTest,1,1.1861120010657661e-08,"The method 'test_reset_produces_valid_grid' is a unit test that checks the functionality of the 'reset' method in the 'CurriculumEnv' class. It verifies that the observation returned by 'reset' has the correct shape and that the 'info' dictionary contains a 'genome_id' and a 'difficulty' level that does not exceed 10. These checks are essential for ensuring the 'reset' method works as expected, which is crucial for the reliability of the 'CurriculumEnv' class. Therefore, this test method is likely to be retained to maintain code quality and reliability."
survived,"    def queue_job(self, job: Mapping[str, Any]) -> requests.Response:
        """"""POST the job to the orchestrator and return the HTTP response.""""""
        agent = job.get(""agent"")
        if not agent:
            raise ValueError(""Job must specify 'agent'"")
        url = f""{self.base_url}/agent/{agent}/trigger""
        resp = requests.post(url, json=job)
        resp.raise_for_status()
        return resp
",alpha_factory_v1/demos/alpha_agi_marketplace_v1/marketplace.py,MarketplaceClient,1,8.592166611791576e-10,"The method 'queue_job' is a well-defined function that performs a specific task of posting a job to an orchestrator and returning the HTTP response. It includes error handling for missing 'agent' in the job, constructs a URL dynamically based on the job's agent, and ensures the HTTP request is successful by raising an exception if the status is not successful. These characteristics make it a useful and robust method for interacting with an API, suggesting it is likely to be retained in the codebase."
survived,"            def observe(self, *a, **k):
                self.calls.append(""observe"")
",alpha_factory_v1/tests/test_ping_agent.py,PingAgentTest.DummyMetric,1,6.348800075736417e-09,"The method 'observe' is a simple function that appends the string ""observe"" to a list called 'calls'. This method is likely part of a larger class that tracks or logs method calls. The method is functional, does not contain any errors, and serves a clear purpose in the context of logging or tracking. Therefore, it is likely to be retained in the codebase."
survived,"    def tearDown(self):
        sys.modules.pop(""requests"", None)
",alpha_factory_v1/tests/test_requests_import.py,RequestsImportTest,1,4.1399375473943306e-08,"The method `tearDown` is used in testing frameworks to clean up after a test case has been executed. The specific code here is removing the 'requests' module from `sys.modules`, which can be useful to ensure that the module is re-imported fresh in subsequent tests, avoiding any side effects from previous tests. This is a common practice in testing to maintain test isolation and ensure reliability. Therefore, the method is likely to be retained as it serves a useful purpose in the context of testing."
survived,"    def test_fallback_when_package_missing(self):
        original = im.distribution
        def fake_distribution(name):
            raise im.PackageNotFoundError
        im.distribution = fake_distribution
        try:
            mod = importlib.import_module(""requests"")
            from alpha_factory_v1 import requests as shim
            self.assertIs(mod.get, shim.get)
            self.assertIs(mod.post, shim.post)
        finally:
            im.distribution = original
            sys.modules.pop(""requests"", None)
",alpha_factory_v1/tests/test_requests_import.py,RequestsImportTest,1,6.348800075736417e-09,"The method 'test_fallback_when_package_missing' is a unit test designed to verify the behavior of a system when a package is missing. It uses a mock to simulate a package not being found and checks if the system correctly falls back to an alternative implementation. This kind of test is crucial for ensuring robustness and reliability in software, especially in environments where dependencies might not always be available. Therefore, it is likely to be retained as part of the test suite to ensure the software handles such scenarios gracefully."
survived,"    def _download_vosk(args):
        download_vosk_model(args.url, args.dir)
",speech_recognition/cli.py,,1,2.0611536181902033e-09,"The method _download_vosk is a private helper function, indicated by the underscore prefix, which suggests it is intended for internal use within a module or class. Its purpose is to download a Vosk model using the provided URL and directory arguments. This function is likely part of a larger system that requires downloading models, and unless there is a significant change in the system's architecture or requirements, such utility functions are generally retained. Therefore, it is likely to survive."
survived,"def test_ws_progress_token_param() -> None:
    port = _free_port()
    proc = _start_server(port)
    url = f""http://127.0.0.1:{port}""
    headers = {""Authorization"": ""Bearer test-token""}
    try:
        _wait_running(url, headers)
        ws_url = f""ws://127.0.0.1:{port}/ws/progress?token=test-token""
        with websockets.connect(ws_url) as ws:
            pass
    finally:
        proc.terminate()
        proc.wait(timeout=5)",tests/test_api_server_subprocess.py,,1,2.3823698451773172e-07,"The method 'test_ws_progress_token_param' is a test function that sets up a WebSocket connection to a server and checks if it can connect using a token parameter. It is a useful test for ensuring that the WebSocket server correctly handles token-based authentication. Since it is a test function, it is likely to be maintained as long as the feature it tests is relevant and the codebase is actively developed. Therefore, it is more likely to be retained than deleted."
survived,"    def test_missing_optional_packages_ok(self) -> None:
        def fake_check_pkg(name: str) -> bool:
            # Required packages are always present
            if name in {""pytest"", ""prometheus_client""}:
                return True
            # Simulate all optional deps missing
            if name in preflight.OPTIONAL_DEPS:
                return False
            return True

        patches = [
            mock.patch.object(preflight, ""check_python"", return_value=True),
            mock.patch.object(preflight, ""check_cmd"", return_value=True),
            mock.patch.object(preflight, ""check_node"", return_value=True),
            mock.patch.object(preflight, ""check_docker_daemon"", return_value=True),
            mock.patch.object(preflight, ""check_docker_compose"", return_value=True),
            mock.patch.object(preflight, ""check_patch_in_sandbox"", return_value=True),
            mock.patch.object(preflight, ""check_pkg"", side_effect=fake_check_pkg),
            mock.patch.object(preflight, ""check_openai_agents_version"", return_value=True),
            mock.patch.object(preflight, ""ensure_dir"", return_value=None),
        ]
        with mock.patch.dict(os.environ, {""OPENAI_API_KEY"": """", ""ANTHROPIC_API_KEY"": """"}, clear=False):
            with contextlib.ExitStack() as stack:
                for p in patches:
                    stack.enter_context(p)
                # Should not raise SystemExit
                preflight.main([""--offline""])
",tests/test_preflight_optional_missing.py,TestPreflightOptionalMissing,1,7.73442280641062e-08,"The method `test_missing_optional_packages_ok` is a unit test designed to verify the behavior of a system when optional packages are missing. It uses mocking to simulate the environment and dependencies, ensuring that the system can handle the absence of optional packages without crashing. This is a common and useful test scenario in software development to ensure robustness and reliability. Since it serves a clear purpose in testing the system's resilience, it is unlikely to be deleted."
survived,"def test_trace_call_wb_run_step_query(client):
    full_wb_run_id = f""{client.entity}/{client.project}/test-run""
    from weave.trace import weave_client

    step_counter = iter(range(100))
    with (
        mock.patch.object(
            weave_client, ""safe_current_wb_run_id"", lambda: full_wb_run_id
        ),
        mock.patch.object(
            weave_client, ""safe_current_wb_run_step"", lambda: next(step_counter)
        ),
    ):
        call_spec = simple_line_call_bootstrap()

    server = get_client_trace_server(client)
    res = server.calls_query(
        tsi.CallsQueryReq(project_id=get_client_project_id(client))
    )
    steps = [c.wb_run_step for c in res.calls]
    assert set(steps) == set(range(call_spec.total_calls))

    query = tsi.Query(
        **{""$expr"": {""$eq"": [{""$getField"": ""wb_run_step""}, {""$literal"": 0}]}}
    )
    res = server.calls_query(
        tsi.CallsQueryReq(project_id=get_client_project_id(client), query=query)
    )
    assert len(res.calls) == 1

    max_step = call_spec.total_calls - 2
    range_query = tsi.Query(
        **{""$expr"": {""$gte"": [{""$getField"": ""wb_run_step""}, {""$literal"": max_step}]}}
    )
    res = server.calls_query(
        tsi.CallsQueryReq(project_id=get_client_project_id(client), query=range_query)
    )
    assert len(res.calls) == 2
",tests/trace/test_client_trace.py,,1,1.637377179507321e-07,"The method 'test_trace_call_wb_run_step_query' is a test function that appears to be part of a testing suite for a larger application. It uses mock objects and assertions to verify the behavior of a system, specifically related to querying call steps in a Weave client. Test functions are generally not deleted unless they are redundant or the functionality they test is no longer relevant. Since this function is actively testing specific behavior and using mock objects to simulate conditions, it is likely still relevant and useful for ensuring the correctness of the system."
survived,"def primesUpTo(n):
    sieve = []
    i = 0
    while i <= n:
        sieve = sieve + [True]
        i = i + 1
    p = 2
    while p * p <= n:
        if sieve[p]:
            m = p * p
            while m <= n:
                sieve[m] = False
                m = m + p
        p = p + 1
    res = []
    x = 2
    while x <= n:
        if sieve[x]:
            res = res + [x]
        x = x + 1
    return res
",tests/rosetta/transpiler/Python/consecutive-primes-with-ascending-or-descending-differences.py,,1,2.9023122007764653e-06,"The method 'primesUpTo' is a basic implementation of the Sieve of Eratosthenes algorithm to find all prime numbers up to a given number 'n'. While the code is functional, it is not optimized. For instance, it uses list concatenation in a loop, which is inefficient, and it initializes the sieve list with a while loop instead of using list comprehension. Despite these inefficiencies, the method correctly implements the algorithm and serves its purpose. Therefore, it is likely to survive as it provides a correct solution, albeit not the most efficient one."
survived,"def main():
    fb = Foodbox(items=[PeelFirst(value=""banana""), PeelFirst(value=""mango"")])
    f0 = fb.items[0]
    peelFirstEat(f0)
",tests/rosetta/transpiler/Python/constrained-genericity-4.py,,1,3.850741907939403e-09,"The method 'main' is a simple function that initializes a 'Foodbox' object with items and calls another function 'peelFirstEat' on one of the items. There is no indication that this method is redundant or unnecessary based on the provided code. It seems to serve a specific purpose in the context of the application, likely related to handling or processing food items. Without additional context suggesting that this method is obsolete or replaced, it is reasonable to predict that it will survive."
survived,"def main():
    example10()
",tests/rosetta/transpiler/Python/conditional-structures-10.py,,1,1.1253518384332553e-07,"The method 'main' is a very common entry point in many programming languages, including Python. It is often used to encapsulate the main logic of a program. The presence of 'example10()' within 'main()' suggests that 'example10()' is a function that is being called as part of the program's execution. Without additional context, such as the definition of 'example10()' or the overall purpose of the code, it's difficult to determine if 'main()' is redundant or unnecessary. However, given its conventional use as an entry point, it is more likely to be retained unless there is a specific reason to remove it, such as refactoring the code to a different structure or if 'example10()' is the only function and can be called directly. Therefore, without further context, 'main()' is likely to survive."
survived,"def doPos(x):
    pass
",tests/rosetta/transpiler/Python/conditional-structures-4.py,,0,0.9999999918479795,"The method 'doPos' is defined but not implemented, as it only contains a 'pass' statement. Without any functionality or documentation indicating future use, it is likely to be considered dead code. In many codebases, such methods are either implemented or removed to maintain code quality and clarity. Therefore, it is likely to be deleted unless there is a specific plan to implement it in the future."
survived,"    def __str__(self) -> str:
        lines = [f""## {self.name}"", self.description, """"]
        if self.fields:
            lines.append(""### Fields"")
            lines.extend(str(f) for f in self.fields)
            lines.append("""")
        if self.relationships:
            lines.append(""### Relationships"")
            lines.extend(str(r) for r in self.relationships)
            lines.append("""")
        return ""\n"".join(lines)
",src/enrichmcp/datamodel.py,EntityDescription,1,1.6052280526088547e-09,"The method `__str__` is a standard Python method used to define a string representation of an object. This implementation provides a structured and readable format for the object's attributes, including its name, description, fields, and relationships. Such a method is crucial for debugging, logging, and providing a human-readable output of the object state. The use of conditional checks for fields and relationships ensures that the output is concise and only includes relevant information. Therefore, this method is likely to be retained as it enhances the usability and maintainability of the code."
survived,"def test_evonet_no_relu_layers() -> None:
    g = me.Genome(layers=(4,), activation=""tanh"")
    net = me.EvoNet(2, 1, g)
    assert all(not isinstance(m, torch.nn.ReLU) for m in net.model)
",tests/test_evo_net_activation.py,,1,4.363462233903899e-09,"The method `test_evonet_no_relu_layers` is a unit test designed to verify that a neural network model created with a specific genome configuration does not include any ReLU activation layers. This is a valid and useful test to ensure that the model adheres to the expected architecture, especially when the activation function is explicitly set to 'tanh'. Such tests are crucial for maintaining the integrity of the model's design and functionality. Therefore, the method is likely to be retained as it serves a clear purpose in the testing suite."
survived,"def main() -> None:
    repo_root = Path(__file__).resolve().parent.parent
    manifest_path = repo_root / (""alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/build_assets.json"")
    manifest = json.loads(manifest_path.read_text())
    checksums = manifest.get(""checksums"", {})
    checksums.update(fa.CHECKSUMS)
    manifest[""checksums""] = {k: checksums[k] for k in sorted(checksums)}
    manifest_path.write_text(json.dumps(manifest, indent=2) + ""\n"")
    print(f""Updated {manifest_path}"")
",scripts/generate_build_manifest.py,,1,6.69158608681505e-10,"The method 'main' is performing a specific task of updating a JSON manifest file with checksums and writing it back to the file system. This is a common utility function in software projects where configuration or asset files need to be updated programmatically. The method is well-defined, has a clear purpose, and is likely to be useful in the context of the project it belongs to. There is no indication that this functionality is obsolete or redundant, and it seems to be a necessary part of the build or deployment process. Therefore, it is likely to be retained in the codebase."
survived,"    async def collect_trajectories(self, item):
        user_content = dict(item[0][0])[""content""]
        messages = []
        if self.config.system_prompt:
            messages.append({""role"": ""system"", ""content"": self.config.system_prompt})
        messages.append({""role"": ""user"", ""content"": user_content})
        prompt = self.tokenizer.apply_chat_template(messages, tokenize=False)
        completions = await self.server.completion(
            prompt=prompt,
            n=self.config.group_size,
            max_tokens=self.config.max_tokens,
            temperature=self.config.temperature,
            top_p=self.config.top_p,
        )
        trajectories = []
        for completion in completions.choices:
            completion_text = (
                completion.text if hasattr(completion, ""text"") else completion.message.content
            )
            msg_seq = []
            if self.config.system_prompt:
                msg_seq.append({""role"": ""system"", ""content"": self.config.system_prompt})
            msg_seq.append({""role"": ""user"", ""content"": user_content})
            msg_seq.append({""role"": ""assistant"", ""content"": completion_text})
            trajectories.append(msg_seq)
        return trajectories, []
",environments/sanskrit_poetry_env.py,SanskritPoetryEnv,1,9.736200303530205e-10,"The method 'collect_trajectories' is likely to survive because it appears to be a well-structured and functional piece of code that serves a specific purpose in an asynchronous context. It collects user input, applies a chat template, and retrieves completions from a server, which are then formatted into message sequences. This functionality is essential for applications involving chatbots or conversational AI, and there is no indication of redundancy or obsolescence in the code provided."
survived,"    def _score_text(self, text: str) -> float:
        if not self.classifier:
            return 0.0
        try:
            slp_text = iast_to_slp1(text)
            result = self.classifier.classify(slp_text)
            if not result:
                return 0.0
            predicted = getattr(result, ""name"", str(result)).lower()
            raw_score = getattr(result, ""score"", 1.0 if predicted == self.meter.lower() else 0.0)
            if predicted != self.meter.lower():
                raw_score = 1.0 - raw_score if raw_score <= 1.0 else 0.0
            return max(0.0, min(1.0, float(raw_score)))
        except Exception as e:  # pragma: no cover - runtime safeguard
            logger.error(""Error scoring text with chandas: %s"", e)
            return 0.0
",atroposlib/envs/reward_fns/chandas_meter_reward.py,ChandasMeterReward,1,2.7894680920908113e-10,"The method '_score_text' is likely to survive because it contains a well-defined functionality for scoring text based on a classifier's output. It includes error handling, which is a good practice for robustness, and it uses a logical flow to compute a score. The method is also specific in its purpose, which suggests it is part of a larger system where it plays a crucial role. Additionally, the use of logging for error reporting indicates that it is intended for production use, further supporting its survival."
survived,"    def __init__(self, meter: str = ""tristubh"", weight: float = 1.0, **kwargs):
        super().__init__(weight=weight, **kwargs)
        self.meter = meter
        try:
            from chandas import Classifier  # type: ignore

            if resource_filename is not None:
                data_path = resource_filename(""chandas"", ""data/data.json"")
                self.classifier = Classifier.from_json_file(data_path)
            else:
                self.classifier = Classifier.from_default_location()
        except Exception as e:  # pragma: no cover - optional dependency
            logger.error(""Failed to load chandas Classifier: %s"", e)
            self.classifier = None
",atroposlib/envs/reward_fns/chandas_meter_reward.py,ChandasMeterReward,1,8.152020648014727e-09,"The method is likely to survive because it includes a robust error handling mechanism with a try-except block, which ensures that the program does not crash if the optional dependency 'chandas' is not available. This makes the code more resilient and adaptable to different environments. Additionally, the use of default parameters and the ability to handle additional keyword arguments (kwargs) make the method flexible and easy to integrate into larger systems."
survived,"    def delete_stale_entries(self, stale_after: timedelta) -> None:
        """"""Delete stale entries from the SQL cache.""""""
        threshold = datetime.now() - stale_after
        with self._lock, self._Session() as session:
            session.execute(
                delete(CacheTable).where(
                    and_(
                        CacheTable.function_id == self._func_str,
                        CacheTable.timestamp < threshold,
                    )
                )
            )
            session.commit()",src/cachier/cores/sql.py,_SQLCore,1,1.1861120010657661e-08,"The method `delete_stale_entries` is a utility function that performs a specific task of cleaning up stale entries from a cache. This is a common requirement in systems that use caching to ensure that outdated data does not persist longer than necessary, which can lead to inefficiencies or incorrect data being served. The method is well-defined, uses a lock for thread safety, and commits the transaction to ensure changes are saved. Such methods are typically retained as they are essential for maintaining the integrity and performance of the cache system."
survived,"    def to_dict(self) -> Dict[str, Any]:
        """"""Return order as plain dictionary.""""""
        return asdict(self)
",alpha_factory_v1/backend/broker.py,Order,1,8.592166611791576e-10,"The method 'to_dict' is a utility function that converts an object into a dictionary representation. This is a common and useful method in Python, especially when dealing with data serialization, logging, or preparing data for APIs. The use of 'asdict' suggests that the object is a dataclass, which is a modern and popular way to define data structures in Python. Given its utility and the increasing use of dataclasses, this method is likely to be retained in the codebase."
survived,"    def span(self, agent_name: str, phase: str, **payload: Any) -> Generator[None, None, None]:
        """"""Context manager that records duration in ``payload['duration_ms']``.""""""
        start = _dt.datetime.utcnow()
        try:
            yield
        finally:
            duration = (_dt.datetime.utcnow() - start).total_seconds() * 1000
            payload[""duration_ms""] = round(duration, 3)
            self.record(agent_name, phase, payload)
",alpha_factory_v1/backend/tracer.py,Tracer,1,4.599055376537186e-10,"The method 'span' is a context manager that measures the duration of a code block and records it using the 'record' method. This functionality is useful for performance monitoring and logging, which are common requirements in software development. The method is well-defined, uses standard practices, and provides a clear utility. Therefore, it is likely to be retained in the codebase."
survived,"        def _decorator(func):
            return func
",alpha_factory_v1/demos/self_healing_repo/agent_selfheal_entrypoint.py,,1,5.043472052266442e-07,"The method _decorator is a simple function that takes another function as an argument and returns it unchanged. This is a basic implementation of a decorator pattern, which is a common and useful technique in Python for extending or modifying the behavior of functions or methods. Since decorators are widely used and this implementation does not introduce any errors or inefficiencies, it is likely to be retained in the codebase for potential future use or as a placeholder for more complex functionality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/group_by_multi_join_sort.py,Order,0,0.9999898700118929,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/group_by_conditional_sum.py,Auto1,0,0.9999687980937693,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose suggests that it is likely to be deleted or refactored to align with its conventional use."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/outer_join.py,Order,0,0.9999962733608834,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not fulfill its intended purpose of checking membership in a collection. Therefore, it is likely to be deleted or replaced with a more appropriate implementation."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/inner_join.py,Auto1,0,0.9999869928752253,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/join_multi.py,Customer,0,0.9999599363048656,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose is likely to lead to confusion and incorrect behavior when the method is used. Therefore, it is likely that this method will be deleted or significantly modified to align with its intended use."
survived,"def load_gitignore_as_context_rules(file_path: Path) -> List[str]:
    """"""Load .gitignore rules and convert to Jinni-style context rules.""""""
    raw_lines = load_rules_from_file(file_path)
    converted: List[str] = []
    for line in raw_lines:
        stripped = line.strip()
        if not stripped or stripped.startswith('#'):
            continue
        if stripped.startswith('!'):
            # Git's negation means include; keep without '!'
            converted.append(stripped[1:])
        else:
            # Regular gitignore entry is an exclusion -> prefix '!'
            converted.append('!' + stripped)
    return converted
",jinni/config_system.py,,1,9.736200303530205e-10,"The method `load_gitignore_as_context_rules` is a utility function that converts .gitignore rules into a different format, which can be useful for applications that need to interpret or manipulate these rules in a specific way. The function is well-defined, performs a clear and useful task, and there is no indication that it is obsolete or redundant. Additionally, handling .gitignore files is a common requirement in many development environments, suggesting that this function is likely to remain relevant."
survived,"def test_length_limit():
    long_title = 'A' * 300
    assert len(remove_chars(long_title)) == 245",tests/test_remove_chars.py,,1,9.237449576640118e-09,"The method `test_length_limit` is a test function that checks if the `remove_chars` function correctly limits the length of a string to 245 characters. This is a typical unit test that ensures the functionality of another function, which is a common practice in software development to maintain code quality and reliability. Since testing is an essential part of the development process, this method is likely to be retained to ensure the `remove_chars` function behaves as expected."
survived,"def test_trim_invalid_characters():
    assert remove_chars('???Title???') == 'Title'
    assert remove_chars('!@#My Book!!!') == 'My Book'
    assert remove_chars('Book (Edition)') == 'Book - Edition'
",tests/test_remove_chars.py,,1,1.2098660619383578e-06,"The method `test_trim_invalid_characters` is a test function that checks the functionality of a method `remove_chars`. It is likely part of a test suite to ensure that `remove_chars` correctly processes strings by removing or replacing certain characters. Test functions are generally important for maintaining code quality and ensuring that changes do not introduce bugs. Therefore, it is unlikely that this method will be deleted unless the functionality it tests is no longer needed or has been replaced by another method."
survived,"def test_parse_clippings_creates_files(tmp_path):
    clippings = Path(__file__).with_name(""My Clippings.txt"")
    out_dir = tmp_path / ""out""
    parse_clippings(str(clippings), str(out_dir), format=""txt"")

    expected_files = [
        remove_chars(""Example Title: The Beginning (John Doe)"") + "".txt"",
        remove_chars(""Another Book? & Something & Else (Jane Smith)"") + "".txt"",
    ]
    assert sorted(os.listdir(out_dir)) == sorted(expected_files)

    contents1 = (out_dir / expected_files[0]).read_text(encoding=""utf8"")
    assert ""This is a highlight text."" in contents1

    contents2 = (out_dir / expected_files[1]).read_text(encoding=""utf8"")
    assert ""Interesting highlight & note?"" in contents2",tests/test_parse_clippings.py,,1,5.60279640614594e-09,"The method is a test function that verifies the functionality of the `parse_clippings` function. It checks if the function correctly creates files with expected names and contents based on the input clippings file. Test functions are crucial for ensuring code reliability and are typically retained unless the functionality they test is deprecated or removed. Since there is no indication that the `parse_clippings` function is being deprecated, the test function is likely to survive."
survived,"    def visit_Pass(self, node: ast.Pass) -> None:
        pass
",tools/any2mochi/py/py2mochi.py,Converter,1,8.939700163274874e-06,"The method `visit_Pass` is a placeholder method that does nothing when visiting a `Pass` node in an abstract syntax tree (AST). It is likely part of a larger visitor pattern implementation for traversing ASTs. Such methods are often included to handle specific node types even if no action is needed, ensuring that the traversal is complete and can be extended later if needed. Therefore, it is likely to be retained for completeness and potential future use."
survived,"    async def seed(session: AsyncSession) -> None:
        nonlocal seed_called
        session.add(User(id=1))
        seed_called = True
",tests/test_lifespan.py,,0,0.9999993524053853,"The method is likely to be deleted because it contains a nonlocal variable 'seed_called' which is not defined within the function or passed as a parameter. This indicates a potential design flaw or incomplete implementation. Additionally, the function's purpose is unclear as it only adds a single user with a hardcoded ID, which is not a typical use case for a seeding function that usually populates a database with initial data. Without further context or usage, this method seems redundant or improperly implemented."
survived,"        def observe(self, *_a) -> None:
            pass
",tests/test_agent_experience_entrypoint.py,DummyAgent,1,6.144172127844639e-06,"The method 'observe' is defined but not implemented, as it only contains a 'pass' statement. This suggests that it is a placeholder for future functionality or is meant to be overridden in a subclass. If the class is intended to be used as a base class or if the method is expected to be implemented later, it will likely survive. However, if there is no plan to implement this method or if it is not used in any subclass, it might be deleted. Without additional context, it's more likely to survive as a placeholder or abstract method."
survived,"    def Dataframe(self, *a, **k):
        pass
",tests/test_agent_experience_entrypoint.py,DummyBlocks,0,0.9999998724809324,"The method 'Dataframe' is defined with a 'pass' statement, meaning it currently has no functionality. Without any implementation, it doesn't serve any purpose in the code. Unless there is a specific plan to implement this method in the future, it is likely to be deleted as it doesn't contribute to the functionality of the class or module it belongs to."
survived,"    def __init__(self, *a, **k):
        pass
",tests/test_selfheal_env.py,DummyMarkdown,0,0.999988521231025,"The method is a constructor that takes any number of positional and keyword arguments but does nothing with them. This is often used as a placeholder or a base class constructor that is meant to be overridden by subclasses. However, if it remains unused or unmodified, it doesn't serve any functional purpose. Without additional context or usage, it is likely to be removed in future iterations to clean up the code."
survived,"def test_run_tests_respects_config(tmp_path, monkeypatch):
    repo = tmp_path / ""repo""
    repo.mkdir()
    (repo / ""calc.py"").write_text(
        ""def add(a, b):\n    return a + b\n"",
        encoding=""utf-8"",
    )
    (repo / ""test_calc.py"").write_text(
        ""import calc\n\n"" ""def test_add():\n    assert calc.add(1, 2) == 3\n"",
        encoding=""utf-8"",
    )

    env_file = tmp_path / ""config.env""
    env_file.write_text(
        f""OPENAI_MODEL=my-model\nMODEL_NAME=my-model\nCLONE_DIR={repo}\n"",
        encoding=""utf-8"",
    )
    cfg.init_config(str(env_file))

    monkeypatch.setitem(
        sys.modules,
        ""gradio"",
        types.SimpleNamespace(Blocks=DummyBlocks, Markdown=DummyMarkdown, Button=DummyButton),
    )

    agent_args = {}

    class FakeAgent:
        def __init__(self, *a, **kw):
            agent_args.update(kw)

        def __call__(self, *_a, **_k):
            return ""ok""

    stub = types.SimpleNamespace(
        Agent=lambda *a, **k: object(),
        OpenAIAgent=FakeAgent,
        Tool=lambda *a, **k: (lambda f: f),
    )
    monkeypatch.setitem(sys.modules, ""openai_agents"", stub)
    monkeypatch.setitem(
        sys.modules,
        ""patcher_core"",
        types.SimpleNamespace(
            generate_patch=lambda *_a, **_k: """",
            apply_patch=lambda *_a, **_k: None,
        ),
    )

    sys.modules.pop(
        ""alpha_factory_v1.demos.self_healing_repo.agent_selfheal_entrypoint"",
        None,
    )
    path = Path(__file__).resolve().parents[1] / ""alpha_factory_v1/demos/self_healing_repo/agent_selfheal_entrypoint.py""
    spec = importlib.util.spec_from_file_location(
        ""alpha_factory_v1.demos.self_healing_repo.agent_selfheal_entrypoint"", path
    )
    entrypoint = importlib.util.module_from_spec(spec)
    entrypoint.apply_patch_and_retst = lambda *_a, **_k: None
    assert spec.loader
    sys.modules[spec.name] = entrypoint
    spec.loader.exec_module(entrypoint)
    monkeypatch.setattr(entrypoint, ""CLONE_DIR"", str(repo))

    result = asyncio.run(entrypoint.run_tests())
    assert result[""rc""] == 0
    assert agent_args.get(""model"") == ""my-model""",tests/test_selfheal_env.py,,1,9.237449576640118e-09,"The method `test_run_tests_respects_config` is a well-structured test function that verifies the integration of configuration settings with a testing framework. It uses temporary paths and monkeypatching to simulate the environment and dependencies, ensuring that the test is isolated and does not affect the actual environment. The function checks if the configuration is respected by asserting the expected results. This kind of test is crucial for ensuring that the system behaves correctly under different configurations, making it a valuable part of the test suite. Therefore, it is likely to be retained."
survived,"    def click(self, *a, **kw):
        pass
",tests/test_selfheal_env.py,DummyButton,1,5.144221744469598e-05,"The method 'click' is defined but not implemented, as it only contains a 'pass' statement. This suggests that it is a placeholder for future functionality or is meant to be overridden in a subclass. If the method is part of a larger framework or library where subclasses are expected to provide specific implementations, it is likely to survive. However, if it is not used or overridden anywhere, it might be considered dead code and could be deleted. Without additional context, it's more likely to survive as a placeholder or abstract method."
survived,"    def _safe_open(*_: Any, **__: Any) -> None:
        raise PermissionError(""File operations are not permitted"")
",backend/tools/analysis_tools.py,,1,1.1253518384332553e-07,"The method _safe_open is designed to raise a PermissionError whenever it is called, indicating that file operations are not permitted. This suggests that the method is intentionally used as a safeguard to prevent file operations in certain contexts. Such methods are often used in environments where security or data integrity is a concern, and they serve a specific purpose. Therefore, it is likely that this method will be retained in the codebase to enforce these restrictions."
survived,"def get_metric(factory: Callable[..., Any], name: str, desc: str, labels: list[str] | None = None) -> Any:
    """"""Return an existing metric or create a new one.

    This avoids depending on ``REGISTRY._names_to_collectors`` which may
    change between ``prometheus_client`` versions.
    """"""
    metric = METRICS.get(name)
    if metric is not None:
        return metric
    metric = factory(name, desc, labels) if labels is not None else factory(name, desc)
    METRICS[name] = metric
    return metric",alpha_factory_v1/backend/metrics_registry.py,,1,5.905303995456778e-10,"The method 'get_metric' is likely to survive because it provides a useful utility function for managing metrics. It abstracts the creation and retrieval of metrics, which is a common requirement in applications that need to monitor performance or other metrics. The method also handles backward compatibility by avoiding direct dependency on internal structures of the 'prometheus_client', making it more robust to changes in the library. This kind of functionality is often essential in systems that rely on metrics for monitoring and alerting, thus increasing its likelihood of being retained."
survived,"def test_workbox_hash_mismatch(tmp_path: Path) -> None:
    repo = Path(__file__).resolve().parents[1]
    src = repo / ""alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/dist""
    dist = tmp_path / ""dist""
    shutil.copytree(src, dist)
    sw_file = dist / ""service-worker.js""
    text = sw_file.read_text()
    text = re.sub(r""(WORKBOX_SW_HASH = '\)[^']+(\')"", r""\1sha384-invalid\2"", text)
    sw_file.write_text(text)

    server, thread = _start_server(dist)
    host, port = server.server_address
    url = f""http://{host}:{port}/index.html""
    try:
        with sync_playwright() as p:
            browser = p.chromium.launch()
            context = browser.new_context()
            page = context.new_page()
            page.goto(url)
            page.wait_for_selector(""#controls"")
            page.wait_for_function(
                ""document.getElementById('toast').textContent.includes('offline mode disabled')""
            )
            assert page.evaluate(""navigator.serviceWorker.controller"") is None
            browser.close()
    except PlaywrightError as exc:
        pytest.skip(f""Playwright browser not installed: {exc}"")
    finally:
        server.shutdown()
        thread.join()",tests/test_workbox_integrity.py,,1,1.3440409770490404e-08,"The method 'test_workbox_hash_mismatch' is a test function that verifies the behavior of a service worker when there is a hash mismatch. It is a part of a test suite, likely using pytest, to ensure the robustness of the application against certain conditions. Test functions are generally not deleted unless they are redundant, irrelevant, or replaced by more comprehensive tests. This function seems to serve a specific purpose in testing the application's response to a hash mismatch, which is a valid and useful test case. Therefore, it is likely to be retained."
survived,"def _make_tar(member: tarfile.TarInfo) -> bytes:
    buf = io.BytesIO()
    with tarfile.open(mode=""w"", fileobj=buf) as tf:
        tf.addfile(member)
    return buf.getvalue()
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_evolution_worker.py,,1,2.3355930333443423e-09,"The method '_make_tar' is a utility function that creates a tar archive from a given tarfile.TarInfo object and returns it as bytes. This is a useful function for packaging files into a tar format, which is a common requirement in many applications, especially those dealing with file compression and distribution. The method is straightforward, uses standard libraries, and serves a clear purpose. There is no indication that this functionality is obsolete or redundant, so it is likely to be retained."
survived,"    def update(self, *args: Any, **kwargs: Any) -> None:  # type: ignore[override]
        if self.__dict__.get(""_frozen"", False):
            raise TypeError(""Cannot modify attributes after call start"")
        for k, v in dict(*args, **kwargs).items():
            self[k] = v
",weave/trace/weave_client.py,AttributesDict,1,1.725782769012759e-08,"The method 'update' is a common utility function used to update the attributes of an object. It includes a mechanism to prevent updates if the object is in a 'frozen' state, which is a useful feature for maintaining object integrity. The method is flexible, accepting both positional and keyword arguments, and it overrides a base class method, which is indicated by the 'type: ignore[override]' comment. This suggests that the method is intentionally designed to fit into a larger class structure. Given its utility and the careful design to handle object state, it is likely to be retained in the codebase."
survived,"def _check_ollama(url: str) -> None:
    """"""Verify an Ollama server is reachable.""""""
    base = url.rstrip(""/"")
    if base.endswith(""/v1""):
        base = base[:-3]
    try:
        request.urlopen(f""{base}/api/tags"", timeout=3)
    except Exception as exc:  # pragma: no cover - network check
        raise RuntimeError(
            f""Ollama not reachable at {base}. ""
            ""Install it from https://ollama.com and run 'ollama serve'.""
        ) from exc
",alpha_factory_v1/demos/macro_sentinel/agent_macro_entrypoint.py,,1,2.646573631904765e-09,"The method `_check_ollama` is a utility function designed to verify the reachability of an Ollama server. It performs a network check by attempting to open a URL and raises a RuntimeError if the server is not reachable. This kind of functionality is often essential in applications that rely on external services, as it helps in diagnosing connectivity issues and providing user-friendly error messages. Given its utility in ensuring the application can communicate with the Ollama server, it is likely to be retained in the codebase. Therefore, the method will survive."
survived,"def test_get_macros():
    context = Context(paths=[""examples/sushi""])
    lsp_context = LSPContext(context)

    file_path = next(key for key in lsp_context.map.keys() if key.name == ""active_customers.sql"")
    with open(file_path, ""r"", encoding=""utf-8"") as f:
        file_content = f.read()

    file_uri = URI.from_path(file_path)
    completions = LSPContext.get_completions(lsp_context, file_uri, file_content)

    assert ""each"" in completions.macros
    assert ""add_one"" in completions.macros
",tests/lsp/test_completions.py,,1,3.850741907939403e-09,"The method 'test_get_macros' is a unit test designed to verify the functionality of the 'get_completions' method within the 'LSPContext' class. It checks if specific macros ('each' and 'add_one') are present in the completions returned by the method. This test is crucial for ensuring that the macro completion feature works as expected, which is likely an important part of the system's functionality. Since testing is a critical aspect of software development for maintaining code quality and reliability, this method is likely to be retained in the codebase."
survived,"    def add_path(self):
        ''' Adds a document to a path starting from this node '''
        node = self
        node.customers += 1
        for level in range(1, self.num_levels):
            node = node.parent
            node.customers += 1
",src/hlda/sampler.py,NCRPNode,0,0.9999993524053853,"The method 'add_path' is likely to be deleted because it modifies the 'customers' attribute of nodes in a way that seems to be incorrect or incomplete. The method assumes that the node has a 'parent' attribute and that the 'num_levels' attribute is defined, but it does not handle cases where these assumptions might not hold true. Additionally, the method lacks error handling and does not provide a clear mechanism for adding a document to a path, as suggested by its name. This could lead to confusion and potential errors in the codebase, making it a candidate for deletion or significant refactoring."
survived,"    def calculate_word_likelihood(self, node_weights, node, weight, level_word_counts, new_topic_weights, level):

        # first calculate the likelihood of the words at this level, given this topic
        node_weight = 0.0
        word_counts = level_word_counts[level]
        total_words = 0

        for w in word_counts:
            count = word_counts[w]
            for i in range(count): # why ?????????
                node_weight += log( (self.eta + node.word_counts[w] + i) /
                                    (self.eta_sum + node.total_words + total_words) )
                total_words += 1

        # propagate that weight to the child nodes
        for child in node.children:
            self.calculate_word_likelihood(node_weights, child, weight + node_weight,
                                           level_word_counts, new_topic_weights, level+1)

        # finally if this is an internal node, add the weight of a new path
        level += 1
        while level < self.num_levels:
            node_weight += new_topic_weights[level]
            level += 1

        node_weights[node] += node_weight
",src/hlda/sampler.py,HierarchicalLDA,1,4.363462233903899e-09,"The method 'calculate_word_likelihood' is a recursive function that calculates the likelihood of words in a hierarchical structure, propagating weights through child nodes and adjusting for new paths. This type of function is crucial in probabilistic models, such as topic modeling or hierarchical clustering, where calculating likelihoods is essential for model accuracy and convergence. The method is well-structured, with clear steps for calculating and propagating weights, and it appears to be part of a larger system that relies on these calculations. Therefore, it is likely to be retained as it serves a specific and important purpose in the context of the application."
survived,"    def calculate_doc_likelihood(self, node_weights, level_word_counts):

        # calculate the weight for a new path at a given level
        new_topic_weights = np.zeros(self.num_levels)
        for level in range(1, self.num_levels):  # skip the root

            word_counts = level_word_counts[level]
            total_tokens = 0

            for w in word_counts:
                count = word_counts[w]
                for i in range(count):  # why ?????????
                    new_topic_weights[level] += log((self.eta + i) / (self.eta_sum + total_tokens))
                    total_tokens += 1

        self.calculate_word_likelihood(node_weights, self.root_node, 0.0, level_word_counts, new_topic_weights, 0)
",src/hlda/sampler.py,HierarchicalLDA,0,0.9999999006880476,"The method 'calculate_doc_likelihood' is likely to be deleted because it contains a comment with multiple question marks (""# why ????????""), indicating confusion or uncertainty about the logic. This suggests that the code may not be fully understood or correctly implemented. Additionally, the method lacks comments explaining its purpose or the logic behind the calculations, making it difficult to maintain or modify. Without clear documentation or understanding, such methods are often candidates for deletion or refactoring."
survived,"    def print_nodes(self, n_words, with_weights):
        self.print_node(self.root_node, 0, n_words, with_weights)
",src/hlda/sampler.py,HierarchicalLDA,1,1.3440409770490404e-08,"The method 'print_nodes' is a simple wrapper around another method 'print_node', which suggests it is part of a larger class structure dealing with nodes, possibly in a tree or graph. The method signature indicates it provides functionality to print nodes with certain parameters (n_words and with_weights), which could be useful for debugging or displaying data structures. Without additional context suggesting it's redundant or replaced by another method, it's likely to be retained for its utility in visualizing or debugging the structure."
survived,"    def estimate(self, num_samples, display_topics=50, n_words=5, with_weights=True):

        print('HierarchicalLDA sampling\n')
        for s in range(num_samples):

            sys.stdout.write('.')

            for d in range(len(self.corpus)):
                self.sample_path(d)

            for d in range(len(self.corpus)):
                self.sample_topics(d)

            if (s > 0) and ((s+1) % display_topics == 0):
                print(f"" {s+1}"")
                self.print_nodes(n_words, with_weights)
",src/hlda/sampler.py,HierarchicalLDA,1,6.825604231969389e-08,"The method 'estimate' is a core part of the functionality for a Hierarchical LDA (Latent Dirichlet Allocation) model, which is used for topic modeling. It involves sampling paths and topics for documents in a corpus, which are essential steps in the iterative process of fitting the model. The method also includes a mechanism to display topics at regular intervals, which is useful for monitoring the progress of the model training. Given its central role in the model's operation and its utility in providing feedback during the training process, it is unlikely to be deleted."
survived,"def test_notebook_ignored_without_flag(tmp_path):
    """"""Without the notebook flag ipynb files were previously skipped.""""""
    nb = tmp_path / ""t.ipynb""
    _write_notebook(nb)
    result = _fstringify_file(str(nb), State())
    assert result is None
    with open(nb) as fh:
        data = json.load(fh)
    assert ""format(1)"" in """".join(data[""cells""][0][""source""])
",test/integration/test_api.py,,1,4.1399375473943306e-08,"The method 'test_notebook_ignored_without_flag' is a test function that verifies the behavior of a system when handling Jupyter notebook files without a specific flag. Test functions are generally crucial for ensuring code reliability and correctness, especially in projects that involve file handling and specific conditions like flags. The presence of this test suggests that the functionality it covers is important to the system's operation, and removing it could lead to untested code paths and potential bugs. Therefore, it is likely to be retained to maintain the integrity of the testing suite."
survived,"def test_attention_paged_decode_ragged_fill_in_chunks():
    B = Axis(""batch"", 2)
    Pos = Axis(""position"", 8)
    Embed = Axis(""embed"", 16)

    cfg = AttentionConfig(Embed=Embed, num_heads=2, num_kv_heads=2, attn_backend=AttentionBackend.VANILLA)
    attn_key, x_key = jrandom.split(jrandom.PRNGKey(0))
    attn = Attention.init(cfg, key=attn_key)
    x = hax.random.normal(x_key, (B, Pos, Embed)) * 0.2
    full_out = attn(x, AttentionMask.causal(), key=jrandom.PRNGKey(1))

    def padded(start, stop):
        pos = hax.arange(Pos, dtype=jnp.int32, start=start)
        return hax.where(pos >= stop, -1, pos)

    cache = _build_page_cache(cfg, B, Pos)

    chunk_sizes = [[4, 2], [0, 1], [0, 1], [2, 1], [1, 2], [1, 1]]
    off0 = off1 = 0
    outputs0 = []
    outputs1 = []
    for step0, step1 in chunk_sizes:
        pos_ids = hax.stack(""batch"", [padded(off0, off0 + step0), padded(off1, off1 + step1)])

        x0 = x[B, 0, ""position"", off0 : off0 + step0]
        x1 = x[B, 1, ""position"", off1 : off1 + step1]

        x_q = hax.full((B, Pos, Embed), 100, dtype=x.dtype)
        x_q = x_q.at[B, 0, ""position"", 0:step0].set(x0)
        x_q = x_q.at[B, 1, ""position"", 0:step1].set(x1)

        output, cache = _jit_paged_decode(attn, x_q, pos_ids=pos_ids, cache=cache)
        outputs0.append(output[B, 0, ""position"", hax.dslice(0, step0)])
        outputs1.append(output[B, 1, ""position"", hax.dslice(0, step1)])
        off0 += step0
        off1 += step1

    outputs0_cat = hax.concatenate(""position"", outputs0)
    outputs1_cat = hax.concatenate(""position"", outputs1)

    assert_trees_all_close(full_out[B, 0].array, outputs0_cat.array, atol=1e-4, rtol=1e-4)
    assert_trees_all_close(full_out[B, 1].array, outputs1_cat.array, atol=1e-4, rtol=1e-4)

    decoded_arr = hax.stack(""batch"", [outputs0_cat, outputs1_cat])
    assert_trees_all_close(full_out.array, decoded_arr.array, atol=1e-4, rtol=1e-4)",tests/test_attention.py,,1,1.955568070542584e-08,"The method is a test function for a specific feature related to attention mechanisms in a neural network. Test functions are crucial for ensuring the correctness and reliability of code, especially in complex systems like neural networks. This function tests the attention mechanism's ability to handle paged decoding with ragged inputs, which is a specific and potentially complex feature. Removing this test could lead to undetected bugs or regressions in the attention mechanism's functionality. Therefore, it is likely to be retained to maintain the robustness of the codebase."
survived,"def test_attention_paged_decode_matches_full_ar():
    B = Axis(""batch"", 1)
    Pos = Axis(""position"", 4)
    Embed = Axis(""embed"", 8)

    cfg = AttentionConfig(Embed=Embed, num_heads=2, num_kv_heads=2, rope=None, attn_backend=AttentionBackend.VANILLA)
    attn_key, x_key = jrandom.split(jrandom.PRNGKey(0))
    attn = Attention.init(cfg, key=attn_key)

    x = hax.random.normal(x_key, (B, Pos, Embed)) * 0.2
    full_out = attn(x, AttentionMask.causal(), key=jrandom.PRNGKey(1))

    cache = _build_page_cache(cfg, B, Pos)
    out_chunks = []
    for i in range(Pos.size):
        x_tok = x[Pos, hax.dslice(i, 1)]
        sub_pos = x_tok.resolve_axis(""position"")
        pos_ids_tok = hax.arange(sub_pos, start=i)
        out_tok, cache = _jit_paged_decode(attn, x_tok, pos_ids_tok, cache)
        out_chunks.append(out_tok.array)

    decoded_arr = jnp.concatenate(out_chunks, axis=1)
    assert_trees_all_close(full_out.array, decoded_arr, atol=1e-4, rtol=1e-4)
",tests/test_attention.py,,1,6.825604231969389e-08,The method is a test function that verifies the correctness of a paged decoding process against a full attention decoding process. It is crucial for ensuring the reliability and accuracy of the attention mechanism in a neural network model. Such test functions are essential for maintaining code quality and are unlikely to be deleted unless the functionality they test is removed or significantly altered.
survived,"def test_no_pep585_generics():
    viols = []
    for root, _, files in os.walk(os.path.dirname(os.path.dirname(__file__))):
        for file in files:
            if file.endswith('.py') and not file.startswith('test_'):
                path = os.path.join(root, file)
                with open(path, 'r', encoding='utf-8') as f:
                    source = f.read()
                try:
                    tree = ast.parse(source)
                except SyntaxError:
                    continue
                for node in ast.walk(tree):
                    if isinstance(node, ast.Subscript) and isinstance(node.value, ast.Name):
                        if node.value.id in ALLOWED_BUILTINS:
                            viols.append(f""{path}:{node.lineno}"")
    assert not viols, ""PEP585 generics found: "" + "", "".join(viols)",tests/test_no_pep585.py,,1,1.275190675769241e-07,"The method 'test_no_pep585_generics' is a test function designed to ensure that certain Python files do not use PEP 585 generics. It walks through the directory structure, reads Python files, parses them into an abstract syntax tree (AST), and checks for specific patterns that indicate the use of PEP 585 generics. If such patterns are found, it records the file and line number. The function then asserts that no such patterns were found, failing the test if any are detected.

This function is useful for maintaining code standards and ensuring compatibility with older Python versions that do not support PEP 585. It is a specific test case that serves a clear purpose in a codebase that needs to avoid PEP 585 generics, likely for compatibility reasons.

Given its utility in enforcing coding standards and ensuring compatibility, it is likely to be retained in the codebase, especially if the project has a requirement to avoid PEP 585 generics."
survived,"    def test_broadcast_success(self) -> None:
        led = self._ledger()
        env = messaging.Envelope(""a"", ""b"", {""v"": 1}, 0.0)
        led.log(env)
        root = led.compute_merkle_root()
        captured, DummyClient, DummyTx, DummyInstr, DummyPk = self._dummy_classes()
        with (
            mock.patch.object(insight_logging, ""AsyncClient"", DummyClient, create=True),
            mock.patch.object(insight_logging, ""Transaction"", DummyTx, create=True),
            mock.patch.object(insight_logging, ""TransactionInstruction"", DummyInstr, create=True),
            mock.patch.object(insight_logging, ""PublicKey"", DummyPk, create=True),
        ):
            asyncio.run(led.broadcast_merkle_root())
        self.assertEqual(captured[""url""], ""http://rpc.test"")
        self.assertEqual(captured[""root""], root)
",tests/test_merkle_broadcast.py,TestMerkleBroadcast,1,1.522997951276035e-08,"The method `test_broadcast_success` is a unit test designed to verify the functionality of broadcasting a Merkle root. It uses mock objects to simulate the behavior of external dependencies, which is a common practice in testing to ensure the test is isolated and reliable. The method checks if the broadcasted URL and root match expected values, indicating it is a valid and useful test case. Since it serves a clear purpose in ensuring the correctness of the broadcasting functionality, it is likely to be retained in the codebase."
survived,"    def _ledger(self):
        tmp = tempfile.TemporaryDirectory()
        led = orchestrator.Ledger(os.path.join(tmp.name, ""l.db""), rpc_url=""http://rpc.test"", broadcast=True)
        self.addCleanup(tmp.cleanup)
        return led
",tests/test_merkle_broadcast.py,TestMerkleBroadcast,1,2.8453347280241004e-08,"The method '_ledger' is likely to survive because it is a utility function that sets up a temporary ledger using a temporary directory and ensures cleanup after use. This is a common pattern in testing and resource management to avoid side effects and ensure resources are properly released. The method is functional, concise, and serves a clear purpose in managing temporary resources."
deleted,"def create_app(graphdb_filename, config_filename):
    handler_definitions = yaml.safe_load(open(config_filename))

    edge_events = list(get_handler_instances(handler_definitions, ""edge_handlers""))
    vertex_events = list(get_handler_instances(handler_definitions, ""vertex_handlers""))
    vertex_reverse_geocoders = list(
        get_handler_instances(handler_definitions, ""vertex_reverse_geocoders"")
    )

    print(""edge event handlers:"")
    for e in edge_events:
        print(f""   {e}"")
    print(""vertex event handlers:"")
    for v in vertex_events:
        print(f""   {v}"")
    print(""vertex reverse geocoders:"")
    for g in vertex_reverse_geocoders:
        print(f""   {g}"")

    rs = RouteServer(graphdb_filename, vertex_events, edge_events, vertex_reverse_geocoders)
    app = Flask(__name__)

    @app.route(""/bounds"")
    def bounds():
        cb = request.args.get(""callback"")
        data = rs.bounds(jsoncallback=cb)
        mimetype = ""application/javascript"" if cb else ""application/json""
        return Response(data, mimetype=mimetype)

    @app.route(""/vertices"")
    def vertices():
        return Response(rs.vertices(), mimetype=""text/plain"")

    @app.route(""/get_vertex_id"")
    def get_vertex_id():
        lat = float(request.args[""lat""])
        lon = float(request.args[""lon""])
        return Response(rs.get_vertex_id(lat, lon), mimetype=""application/json"")

    @app.route(""/path"")
    def path_route():
        args = request.args
        data = rs.path(
            origin=args[""origin""],
            dest=args[""dest""],
            currtime=int(args.get(""currtime"")) if args.get(""currtime"") else None,
            time_offset=int(args.get(""time_offset"")) if args.get(""time_offset"") else None,
            transfer_penalty=int(args.get(""transfer_penalty"", 0)),
            walking_speed=float(args.get(""walking_speed"", 1.0)),
            hill_reluctance=float(args.get(""hill_reluctance"", 1.5)),
            turn_penalty=float(args.get(""turn_penalty"")) if args.get(""turn_penalty"") else None,
            walking_reluctance=float(args.get(""walking_reluctance"")) if args.get(""walking_reluctance"") else None,
            max_walk=float(args.get(""max_walk"")) if args.get(""max_walk"") else None,
            jsoncallback=args.get(""callback""),
        )
        mimetype = ""application/javascript"" if args.get(""callback"") else ""application/json""
        return Response(data, mimetype=mimetype)

    @app.route(""/geompath"")
    def geompath_route():
        args = request.args
        data = rs.geompath(
            lat1=float(args[""lat1""]),
            lon1=float(args[""lon1""]),
            lat2=float(args[""lat2""]),
            lon2=float(args[""lon2""]),
            currtime=int(args.get(""currtime"")) if args.get(""currtime"") else None,
            time_offset=int(args.get(""time_offset"")) if args.get(""time_offset"") else None,
            transfer_penalty=int(args.get(""transfer_penalty"", 0)),
            walking_speed=float(args.get(""walking_speed"", 1.0)),
            hill_reluctance=float(args.get(""hill_reluctance"", 1.5)),
            turn_penalty=float(args.get(""turn_penalty"")) if args.get(""turn_penalty"") else None,
            walking_reluctance=float(args.get(""walking_reluctance"")) if args.get(""walking_reluctance"") else None,
            max_walk=float(args.get(""max_walk"")) if args.get(""max_walk"") else None,
            jsoncallback=args.get(""callback""),
        )
        mimetype = ""application/javascript"" if args.get(""callback"") else ""application/json""
        return Response(data, mimetype=mimetype)

    @app.route(""/path_retro"")
    def path_retro_route():
        args = request.args
        data = rs.path_retro(
            origin=args[""origin""],
            dest=args[""dest""],
            currtime=int(args.get(""currtime"")) if args.get(""currtime"") else None,
            time_offset=int(args.get(""time_offset"")) if args.get(""time_offset"") else None,
            transfer_penalty=int(args.get(""transfer_penalty"", 0)),
            walking_speed=float(args.get(""walking_speed"", 1.0)),
        )
        return Response(data, mimetype=""application/json"")

    @app.route(""/path_raw"")
    def path_raw_route():
        args = request.args
        currtime = int(args.get(""currtime"")) if args.get(""currtime"") else None
        data = rs.path_raw(args[""origin""], args[""dest""], currtime)
        return Response(data, mimetype=""text/plain"")

    @app.route(""/path_raw_retro"")
    def path_raw_retro_route():
        args = request.args
        currtime = int(args[""currtime""])
        data = rs.path_raw_retro(args[""origin""], args[""dest""], currtime)
        return Response(data, mimetype=""text/plain"")

    return app
",pygs/graphserver/ext/routeserver/routeserver.py,,1,5.60279640614594e-09,"The method 'create_app' is a crucial part of setting up a Flask application with various routes for handling requests related to a route server. It defines multiple endpoints that are likely essential for the application's functionality, such as retrieving bounds, vertices, and paths. The method is well-structured and serves a clear purpose in initializing the application with necessary configurations and handlers. There is no indication that this method is redundant or obsolete, and it appears to be actively used in the application setup. Therefore, it is likely to be retained."
survived,"    def bounds():
        cb = request.args.get(""callback"")
        data = rs.bounds(jsoncallback=cb)
        mimetype = ""application/javascript"" if cb else ""application/json""
        return Response(data, mimetype=mimetype)
",pygs/graphserver/ext/routeserver/routeserver.py,,1,3.3982678079468468e-09,"The method 'bounds' is a simple function that handles a request, retrieves a callback parameter, and returns a response with the appropriate MIME type based on the presence of the callback. This is a common pattern in web development, especially for handling JSONP requests. The method is functional, concise, and serves a clear purpose. There is no indication of redundancy, inefficiency, or obsolescence in the code. Therefore, it is likely to be retained in the codebase."
survived,"    def path_raw_route():
        args = request.args
        currtime = int(args.get(""currtime"")) if args.get(""currtime"") else None
        data = rs.path_raw(args[""origin""], args[""dest""], currtime)
        return Response(data, mimetype=""text/plain"")
",pygs/graphserver/ext/routeserver/routeserver.py,,1,2.646573631904765e-09,"The method 'path_raw_route' is a simple function that handles a web request, extracts parameters, and returns a response. It is likely to survive because it performs a specific task of routing requests and returning data, which is a common requirement in web applications. The function is straightforward, uses standard practices, and does not contain any deprecated or problematic code that would necessitate its deletion."
survived,"    def path_route():
        args = request.args
        data = rs.path(
            origin=args[""origin""],
            dest=args[""dest""],
            currtime=int(args.get(""currtime"")) if args.get(""currtime"") else None,
            time_offset=int(args.get(""time_offset"")) if args.get(""time_offset"") else None,
            transfer_penalty=int(args.get(""transfer_penalty"", 0)),
            walking_speed=float(args.get(""walking_speed"", 1.0)),
            hill_reluctance=float(args.get(""hill_reluctance"", 1.5)),
            turn_penalty=float(args.get(""turn_penalty"")) if args.get(""turn_penalty"") else None,
            walking_reluctance=float(args.get(""walking_reluctance"")) if args.get(""walking_reluctance"") else None,
            max_walk=float(args.get(""max_walk"")) if args.get(""max_walk"") else None,
            jsoncallback=args.get(""callback""),
        )
        mimetype = ""application/javascript"" if args.get(""callback"") else ""application/json""
        return Response(data, mimetype=mimetype)
",pygs/graphserver/ext/routeserver/routeserver.py,,1,2.998960815863541e-09,"The method 'path_route' is a typical web service endpoint function that processes HTTP request parameters to compute a path using a routing service. It handles various parameters like origin, destination, and several optional parameters for customizing the routing behavior. The function also supports JSONP by checking for a 'callback' parameter, which is a common pattern in web APIs to support cross-domain requests. This functionality is essential for applications that require dynamic routing based on user input, and the method is well-structured to handle these requirements. Therefore, it is likely to be retained in the codebase."
survived,"def _get_model() -> SentenceTransformer:
    if SentenceTransformer is None:
        raise ImportError(""sentence-transformers missing"")
    global _MODEL
    if _MODEL is None:
        _MODEL = SentenceTransformer(""all-MiniLM-L6-v2"")
    return _MODEL
",src/evaluators/novelty.py,,1,3.3982678079468468e-09,"The method '_get_model' is a utility function designed to initialize and return a global instance of a SentenceTransformer model. This is a common pattern in code where a resource-intensive object is initialized once and reused, which is efficient and reduces overhead. The method also includes error handling for missing dependencies, which is a good practice. Given these factors, the method is likely to be useful and efficient in its context, suggesting it will survive."
survived,"def _non_dominated_sort(values: Sequence[Sequence[float]]) -> tuple[list[int], list[list[int]]]:
    n = len(values)
    ranks = [0] * n
    S = [set() for _ in range(n)]
    dominated = [0] * n
    for i, a in enumerate(values):
        for j, b in enumerate(values):
            if i == j:
                continue
            if all(ai <= bj for ai, bj in zip(a, b)) and any(ai < bj for ai, bj in zip(a, b)):
                S[i].add(j)
            elif all(bj <= ai for ai, bj in zip(a, b)) and any(bj < ai for ai, bj in zip(a, b)):
                dominated[i] += 1
        if dominated[i] == 0:
            ranks[i] = 0
    fronts = [[i for i, d in enumerate(dominated) if d == 0]]
    i = 0
    while i < len(fronts):
        nxt: list[int] = []
        for p in fronts[i]:
            for q in S[p]:
                dominated[q] -= 1
                if dominated[q] == 0:
                    ranks[q] = i + 1
                    nxt.append(q)
        if nxt:
            fronts.append(nxt)
        i += 1
    return ranks, fronts
",src/simulation/surrogate_fitness.py,,1,4.944450477491054e-09,"The method implements a non-dominated sorting algorithm, which is a fundamental part of multi-objective optimization problems, such as those solved by evolutionary algorithms like NSGA-II. This algorithm is crucial for sorting solutions based on Pareto dominance, which is widely used in optimization and machine learning fields. The code is well-structured, uses clear logic to determine dominance, and efficiently organizes solutions into fronts. Given its utility and correctness, it is unlikely to be deleted."
survived,"def load_capsule_facts(base: str | Path | None = None) -> MutableMapping[str, CapsuleFacts]:
    """"""Return mapping of sector name to :class:`CapsuleFacts`.""""""

    base_path = Path(base or Path(__file__).parent)
    facts: MutableMapping[str, CapsuleFacts] = {}
    for entry in base_path.iterdir():
        if not entry.is_dir():
            continue
        yaml_path = entry / ""facts.yml""
        if not yaml_path.exists():
            continue
        try:
            data = yaml.safe_load(yaml_path.read_text(encoding=""utf-8"")) or {}
        except Exception:
            continue
        facts[entry.name] = CapsuleFacts(
            market_size=float(data.get(""market_size"", 0.0)),
            efficiency_gain=float(data.get(""efficiency_gain"", 0.0)),
            llm_score=(float(data.get(""llm_score"")) if data.get(""llm_score"") is not None else None),
        )
    return facts
",src/capsules/__init__.py,,1,8.592166611791576e-10,"The method `load_capsule_facts` is likely to survive because it provides a useful functionality of loading and parsing YAML files into a structured format, which is a common requirement in many applications. The method is well-structured, handles exceptions, and uses type hints, making it robust and maintainable. Additionally, it uses modern Python features like type annotations and the Pathlib module, indicating it is up-to-date with current Python practices."
survived,"    def score(self, facts: CapsuleFacts, efficiency_gain: float) -> float:
        """"""Return the impact score.""""""
        base = facts.market_size * efficiency_gain
        if facts.llm_score is not None:
            base *= 1.0 + self.llm_weight * facts.llm_score
        return base
",src/capsules/__init__.py,ImpactScorer,1,2.4616969512093895e-10,"The method 'score' is likely to survive because it performs a specific and useful calculation by combining market size, efficiency gain, and an optional LLM score to produce an impact score. This functionality is relevant for applications that need to evaluate the potential impact of certain factors on market dynamics. The method is concise, well-defined, and its purpose is clear, making it a valuable part of the codebase."
survived,"def test_cli_inline_requires_filename(capsys):
    """"""cli() should exit with an error when --inline is passed without a filename.""""""
    with pytest.raises(SystemExit) as exc:
        cli(inline_args=[""--inline""])
    captured = capsys.readouterr()
    assert captured.err.strip() == ""Error: Inline mode requires a filename""
    assert exc.value.code != 0
",tests/test_json_repair.py,,1,5.211412485172657e-10,"The method 'test_cli_inline_requires_filename' is a test function that checks if the command-line interface (CLI) behaves correctly when the '--inline' argument is passed without a filename. It uses pytest to assert that the program exits with an error, which is a valid and necessary test case to ensure the robustness of the CLI. Such test functions are crucial for maintaining software quality and are unlikely to be deleted unless the functionality they test is removed or significantly altered. Therefore, the method will survive."
survived,"    def __init__(self) -> None:
        self.inst = object()
        self.next_ts = 0
        self.period = 1
        self.last_beat = time.time()
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_backend_rest_auth.py,DummyRunner,1,7.73442280641062e-08,"The method is a constructor (__init__) for a class, which is essential for initializing object instances in Python. It sets up initial values for instance variables, which are likely used elsewhere in the class. Constructors are fundamental to object-oriented programming in Python, and removing them would prevent the proper instantiation of objects. Therefore, it is highly unlikely that this method will be deleted."
survived,"def test_mutate_rejects_traversal(server: str) -> None:
    """"""Tarball members must not escape the extraction directory.""""""
    import io
    import tarfile

    buf = io.BytesIO()
    with tarfile.open(fileobj=buf, mode=""w"") as tf:
        info = tarfile.TarInfo(name=""../evil.txt"")
        data = b""bad""
        info.size = len(data)
        tf.addfile(info, io.BytesIO(data))
    buf.seek(0)

    with httpx.Client(base_url=server) as client:
        files = {""tar"": (""bad.tar"", buf.read())}
        r = client.post(""/mutate"", files=files)
        assert r.status_code == 400",tests/test_evolution_worker.py,,1,4.363462233903899e-09,"The method 'test_mutate_rejects_traversal' is a unit test designed to ensure that a server endpoint correctly handles tarball extraction by rejecting attempts to escape the extraction directory. This is a security-related test, checking for path traversal vulnerabilities, which is a critical aspect of web application security. Such tests are essential for maintaining the integrity and security of the application, especially when dealing with file uploads. Therefore, it is unlikely that this method will be deleted as it serves an important purpose in the application's test suite."
survived,"            def run(self) -> None:
                pass
",tests/test_alpha_opportunity_stub.py,TestAlphaOpportunityStub.DummyRuntime,1,3.726639116582555e-06,"The method 'run' is defined but not implemented, as it only contains a 'pass' statement. This suggests that the method is either a placeholder for future implementation or is intentionally left empty because it is meant to be overridden in a subclass. In many object-oriented programming practices, especially in Python, methods like this are used as abstract methods in base classes to enforce that subclasses provide their own implementation. Therefore, the method is likely to survive as it serves a structural purpose in the code design."
survived,"def test_env_validation_fails(env_var: str, value: str, message: str) -> None:
    browser_dir = Path(__file__).resolve().parents[1]
    script = browser_dir / ""build"" / ""env_validate.js""
    env = os.environ.copy()
    env[env_var] = value
    res = subprocess.run(
        [""node"", str(script)],
        cwd=browser_dir,
        env=env,
        capture_output=True,
        text=True,
    )
    assert res.returncode == 1
    assert message in res.stderr",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_env_validate.py,,1,4.363462233903899e-09,"The method 'test_env_validation_fails' is a test function that checks if a specific environment variable validation fails as expected. It uses subprocess to run a Node.js script and asserts that the script returns an error code and a specific error message. This is a typical pattern for testing environment validation logic, ensuring that incorrect configurations are properly caught and reported. Such test functions are crucial for maintaining robust software, especially when dealing with environment configurations. Therefore, it is likely to be retained as part of the test suite."
survived,"def _meta() -> TemplateMetadata:
    return TemplateMetadata(
        slug=""demo"",
        title=""Demo Template"",
        description=""Simple demo"",
        category=TemplateCategory.CONVERSATION,
        complexity=TemplateComplexity.BASIC,
        tags=[""demo""],
    )
",tests/test_template_creator.py,,1,2.0611536181902033e-09,"The method '_meta' is a private method (indicated by the underscore prefix) that returns a 'TemplateMetadata' object. It is well-defined, with clear parameters and a straightforward purpose. The method is likely part of a larger system that uses metadata for templates, which is a common pattern in software design. Since it serves a specific purpose and is not overly complex, it is likely to be retained in the codebase unless the entire system undergoes a significant redesign or the metadata structure changes drastically. Therefore, the method is predicted to survive."
survived,"def test_creator_register(tmp_path) -> None:
    reg = TemplateRegistry(base_dir=tmp_path)
    creator = TemplateCreator(reg)
    path = creator.create(_meta(), ""hi {{name}}"", version=""0.1.0"")
    assert path
    assert reg.load_template(""demo"") == ""hi {{name}}""",tests/test_template_creator.py,,1,2.7894680920908113e-10,"The method 'test_creator_register' is a unit test function that verifies the functionality of the 'TemplateCreator' and 'TemplateRegistry' classes. It checks if a template can be created and registered correctly. Unit tests are crucial for ensuring code reliability and are typically maintained as long as the functionality they test is relevant. Therefore, this method is likely to survive."
survived,"def _free_port() -> int:
    s = socket.socket()
    s.bind((""localhost"", 0))
    port = int(s.getsockname()[1])
    s.close()
    return port
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_ledger_local_validator.py,,1,5.211412485172657e-10,"The method _free_port is a utility function that finds and returns a free port on the localhost. This is a common requirement in network programming, especially for testing purposes where a free port is needed to bind a server or client socket without hardcoding a specific port number. The method is simple, effective, and does not have any apparent issues or redundancies. Therefore, it is likely to be useful in various scenarios where dynamic port allocation is needed, suggesting that it will survive."
survived,"def validator() -> str:
    port = _free_port()
    cid = subprocess.check_output(
        [
            ""docker"",
            ""run"",
            ""-d"",
            ""-p"",
            f""{port}:8899"",
            ""solanalabs/solana:edge"",
            ""solana-test-validator"",
            ""--quiet"",
        ]
    ).decode().strip()
    url = f""http://localhost:{port}""
    try:
        if not _wait_rpc(url):
            subprocess.run([""docker"", ""logs"", cid], check=False)
            raise RuntimeError(""validator not ready"")
        yield url
    finally:
        subprocess.run([""docker"", ""rm"", ""-f"", cid], check=False)
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_ledger_local_validator.py,,1,7.582560422162384e-10,"The method 'validator' is a utility function that sets up a Docker container running a Solana test validator. It uses subprocess to execute Docker commands, manages the lifecycle of the container, and ensures the validator is ready before yielding the URL. This functionality is crucial for testing and development environments where a Solana validator is needed. The method is well-structured, handling exceptions and cleaning up resources, which are good practices. Given its utility and proper implementation, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q18.py,Customer,0,0.9999756997690634,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical or expected behavior for `__contains__`, which is usually used for membership testing in collections like lists, sets, or dictionaries. This misuse of the method could lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership testing. Therefore, it is likely to be deleted or refactored to align with its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q5.py,Auto1,0,0.999997438718515,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually meant for checking membership in a collection like a list, set, or dictionary. Therefore, this implementation is likely incorrect for its intended purpose and may lead to confusion or errors when used. It is more appropriate to use `__contains__` to check for membership in a collection rather than checking for attributes. Thus, this method is likely to be deleted or refactored."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q21.py,Order,0,0.9999785550602307,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list, set, or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate membership check."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q15.py,Supplier,0,0.999985261023967,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q8.py,Nation,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method is likely to lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership testing. Therefore, it is likely that this method will be deleted or significantly modified to align with its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q15.py,Lineitem,0,0.999998629043345,"The method is incorrectly implemented. The `__contains__` method is supposed to check for membership, typically in a collection or container, and return a boolean indicating whether the specified key or item is present. However, the current implementation uses `hasattr`, which checks if an object has an attribute with the given name, not if a key is present in a collection. This is a misuse of the `__contains__` method, which is expected to work with collections like lists, sets, or dictionaries, not object attributes. Therefore, this method is likely to be deleted or rewritten to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q14.py,Auto1,0,0.9999785550602307,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q7.py,Auto2,0,0.9999869928752253,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q5.py,Supplier,0,0.9999999634651793,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the standard or expected behavior for `__contains__`, which should typically check for membership in a collection like a list, set, or dictionary. Therefore, this implementation is likely to be confusing and not useful in its current form, leading to its deletion."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q2.py,Auto2,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute in an object, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q20.py,Partsupp,0,0.9999869928752253,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q4.py,Auto1,0,0.9999756997690634,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q18.py,Auto2,1,0.029312231016345752,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually meant for checking membership in a collection like a list, set, or dictionary. However, if the class is designed to treat its attributes as keys in a collection-like manner, this implementation could be valid. Without additional context, it's difficult to determine if this is a misuse or a valid use case. Given the ambiguity, the method might survive if the class is specifically designed to use attributes as keys, but it could also be deleted if this is not the intended use."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q17.py,Part,0,0.9999989322969233,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not fulfill its intended purpose of checking membership in a collection. Therefore, it is likely to be deleted or replaced with a more appropriate implementation."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q12.py,Order,0,0.9999938558278723,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q5.py,Region,0,0.9999687980937693,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use of `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely to be deleted or refactored to better fit its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q16.py,Auto8,0,0.9999962733608834,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute in an object, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking for membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement the intended functionality."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q25.py,Auto3,1,1.275190675769241e-07,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a common and useful pattern for dynamic attribute access, especially in cases where the object is used like a dictionary or needs to provide flexible access to its attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q31.py,Auto2,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not fulfill its intended purpose. Therefore, it is likely to be deleted or replaced with a more appropriate implementation that correctly checks for key presence in a collection."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q33.py,Auto5,0,0.9999910602998366,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/job/compiler/py/q27.py,,1,5.60279640614594e-09,"The method '_key' is a utility function that is likely used internally within a class or module to generate a key for sorting purposes. It takes an iterable 'it', applies a function 'sortKey' from a dictionary 'opts' to it, and ensures the result is a string if it's a list, tuple, or dictionary. This kind of method is common in data processing or sorting operations, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q23.py,Auto3,0,0.9999756997690634,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q26.py,Auto1,1,0.000804086001803591,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually used to check for membership in a collection like a list, set, or dictionary. However, if the intention is to check for attributes specifically, this implementation is valid, albeit unconventional. It might survive if the class is designed to treat attributes as keys in a collection-like manner. Without more context, it's hard to definitively say it will be deleted, but it is unconventional."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q22.py,Auto1,0,0.9999599363048656,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list, set, or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate method for checking membership."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q25.py,Auto9,1,2.2159489282323004e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a flexible and Pythonic way to access object attributes, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q11.py,Auto5,1,2.3355930333443423e-09,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python, especially in classes that aim to mimic dictionary behavior or provide flexible attribute access. Therefore, this method is likely to be Survived."
survived,"def _min(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""min() expects list or group"")
    vals = [it for it in v if it is not None]
    if not vals:
        return 0
    return min(vals)
",tests/dataset/job/compiler/py/q28.py,,1,2.8453347280241004e-08,"The method '_min' is a utility function that calculates the minimum value from a list or a group with an 'Items' attribute. It handles cases where the input is not a list by raising an exception and filters out 'None' values before computing the minimum. This functionality is useful and not redundant with built-in functions, as it adds specific handling for objects with 'Items' attributes and 'None' values. Therefore, it is likely to be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q1.py,Auto7,0,0.9999599363048656,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually meant for checking membership in a collection like a list, set, or dictionary. Therefore, this implementation is misleading and does not align with the expected behavior of `__contains__`. It is likely to be deleted or refactored to correctly implement membership checking."
survived,"def _min(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""min() expects list or group"")
    vals = [it for it in v if it is not None]
    if not vals:
        return 0
    return min(vals)
",tests/dataset/job/compiler/py/q15.py,,1,5.043472052266442e-07,"The method _min is a utility function that attempts to find the minimum value in a list or a group-like object with an 'Items' attribute. It includes error handling for non-list inputs and returns 0 for empty lists. This function is likely to survive because it provides a specific utility that might be used in various contexts where such a minimum value calculation is needed. Additionally, it handles edge cases like empty lists and non-list inputs, which makes it robust for different scenarios."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q12.py,Auto3,0,0.9999785550602307,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q21.py,Auto2,0,0.9999952149051502,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not fulfill its intended purpose of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q29.py,Auto13,0,0.9999962733608834,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys. However, this implementation uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of `__contains__` is likely to lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership testing. Therefore, it is likely to be deleted or refactored to align with expected behavior."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q24.py,Auto4,1,2.5109990926928157e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. It is a simple and effective way to provide dictionary-like access to object attributes, which can be particularly useful in dynamic or flexible data structures. Therefore, this method is likely to be retained as it serves a clear purpose and is correctly implemented."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q19.py,Auto11,0,0.9999785550602307,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q24.py,Auto11,1,6.348800075736417e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern and does not have any apparent issues or redundancies that would warrant its deletion. Therefore, it is likely to be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q18.py,Auto2,1,5.144221744469598e-05,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually meant for checking membership in a collection like a list, set, or dictionary. However, if the class is designed to treat its attributes as a collection of keys, this implementation could be valid. Without additional context, it's difficult to determine if this is the intended use. If the class is indeed using its attributes as a collection, this method could survive. Otherwise, it might be considered for deletion or refactoring to better fit the intended use of `__contains__`. Given the ambiguity, it is more likely to survive if the class design supports this usage."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q4.py,Auto2,0,0.9999921107349486,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not fulfill its intended purpose. Therefore, it is likely to be deleted or replaced with a more appropriate implementation that correctly checks for key presence in a collection."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q9.py,Auto8,0,0.9999546021442518,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical or expected behavior for `__contains__`, which is usually used for membership testing in collections like lists, sets, or dictionaries. This misuse of the method could lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership testing. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q22.py,Auto4,1,4.1399375473943306e-08,"The method is a simple implementation of the __getitem__ special method, which allows instances of the class to use the bracket notation (e.g., obj[key]) to access attributes. This is a common and useful pattern in Python, especially for classes that aim to mimic dictionary-like behavior. It provides a clear and concise way to access attributes dynamically, which can be very useful in various applications. There is no indication that this method is redundant or harmful, so it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q19.py,Auto3,1,3.653482080241728e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for cases where the object is designed to behave like a dictionary or similar container, allowing attribute access via keys. Since this method provides a flexible way to access object attributes and is a common pattern in Python, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q21.py,Auto10,0,0.9999756997690634,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q33.py,Auto8,1,9.931195248674785e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. It is a simple and effective way to provide dynamic access to object attributes, which can be particularly useful in data handling or configuration classes. Therefore, this method is likely to be retained as it serves a clear purpose and follows Python's conventions for special methods."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q23.py,Auto7,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of an item in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement the intended functionality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q9.py,Auto4,0,0.999983298584886,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which is usually used for membership testing in collections like lists, sets, or dictionaries. This misuse of `__contains__` could lead to confusion and unexpected behavior, as it does not align with the standard use case of checking membership in a collection. Therefore, it is likely to be deleted or refactored to better fit its intended purpose."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q11.py,Auto2,1,1.0467401685178159e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q15.py,Auto4,0,0.999983298584886,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q31.py,Auto6,1,2.2159489282323004e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name, which is a valid and useful pattern for objects that need to provide dictionary-like access to their attributes. This method is likely to survive because it provides a flexible way to access object attributes and is a common pattern in Python for objects that need to behave like dictionaries."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q11.py,Auto4,1,8.76424914819242e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is likely to survive because it provides a flexible way to access object attributes, which can be particularly useful in dynamic or reflective programming scenarios."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q31.py,Auto8,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list or dictionary. Therefore, the method is likely to be deleted or rewritten to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q20.py,Auto1,0,0.999985261023967,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q17.py,Auto5,1,4.944450477491054e-09,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a clear and useful functionality, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q24.py,Auto9,0,0.9999967112522585,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement the intended functionality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q13.py,Auto4,1,2.4300230936537083e-05,"The method `__contains__` is intended to check if a container contains a certain item, typically using the `in` keyword. In this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not a typical use of `__contains__`, as it should check for membership rather than attribute existence. However, if the class is designed to treat its attributes as the items it contains, this could be a valid implementation. Without more context, it's hard to definitively say if this is a misuse or a creative use. Given that it might be a specific design choice, the method is likely to survive unless it causes confusion or errors in the intended use case."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q12.py,Auto6,1,4.1399375473943306e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a common and useful pattern for dynamic attribute access, especially in cases where the object is used like a dictionary or needs to provide flexible access to its attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q25.py,Auto6,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a common and useful pattern for dynamic attribute access, especially in classes that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q4.py,Auto3,0,0.9999869928752253,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use of `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely to be deleted or refactored to better fit its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q22.py,Auto9,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be used for checking membership in a collection like a list, set, or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate method for checking membership."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q25.py,Auto4,1,3.653482080241728e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method is functional, concise, and leverages Python's dynamic attribute access capabilities, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q6.py,Auto4,0,0.9999970976877992,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q26.py,Auto10,0,0.9999599363048656,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list, set, or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate method for checking membership."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q28.py,Auto10,1,1.1861120010657661e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, this method is likely to be retained as it provides a clear and useful functionality."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q24.py,Auto9,1,3.653482080241728e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. It is likely to be retained because it provides a flexible and Pythonic way to access object attributes, enhancing the usability of the class."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q13.py,Auto3,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the subscript notation (e.g., `obj[key]`). In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, it is unlikely to be deleted as it provides a meaningful and functional feature."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q5.py,Auto1,0,0.9999687980937693,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q29.py,Auto4,0,0.9999921107349486,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list, set, or dictionary. Therefore, this implementation is likely incorrect and may lead to unexpected behavior, suggesting it should be deleted or significantly revised."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q16.py,Auto8,1,2.8453347280241004e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method is implementing a standard Python protocol and is useful for enhancing the flexibility and usability of the class, it is likely to be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q3.py,Auto1,0,0.9999785550602307,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q29.py,Auto2,1,1.0467401685178159e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. This implementation uses `getattr` to dynamically retrieve an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q31.py,Auto4,1,3.653482080241728e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a clear and useful functionality, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q19.py,Auto6,0,0.9999962733608834,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the standard or expected behavior for `__contains__`, which should typically check for membership in a collection like a list, set, or dictionary. This misuse of `__contains__` is likely to lead to confusion and errors, as it does not align with the conventional use of the method. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q29.py,Auto4,1,1.3440409770490404e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern and does not have any apparent issues or redundancies that would warrant its deletion. Therefore, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q30.py,Auto8,0,0.9999898700118929,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q21.py,Auto8,1,1.955568070542584e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, this method is likely to be retained as it provides a clear and useful functionality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q15.py,Auto7,0,0.9999930377415741,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q13.py,Auto5,1,7.194132978569833e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. It is likely to be retained if the class is intended to provide such functionality, as it offers a flexible way to access attributes dynamically. Therefore, the method will likely survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q12.py,Auto1,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q11.py,Auto10,0,0.999985261023967,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the typical or expected behavior for `__contains__`, which should check for membership in a collection like a list or dictionary. Therefore, this method is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q2.py,Auto5,0,0.9999687980937693,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, especially for users familiar with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q26.py,Auto6,1,6.023574641292144e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the codebase."
survived,"def _min(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""min() expects list or group"")
    vals = [it for it in v if it is not None]
    if not vals:
        return 0
    return min(vals)
",tests/dataset/job/compiler/py/q22.py,,1,1.8553915987649156e-07,"The method '_min' is a utility function that provides a custom implementation of the 'min' function with additional checks. It first checks if the input has an 'Items' attribute and uses it if available. It then ensures the input is a list, raising an exception if not. It filters out 'None' values before computing the minimum. This method is useful in scenarios where the input might not be a straightforward list or might contain 'None' values. Such utility functions are often retained in codebases for their specific handling of edge cases and input validation, making them valuable for robust data processing."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q76.py,Auto1,1,1.3440409770490404e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a clear and functional purpose, it is likely to be retained in the code."
survived,"def _q4():
    _src = customer
    _rows = _query(
        _src,
        [
            {
                ""items"": web_sales,
                ""on"": lambda c, ws: c.c_customer_sk == ws.ws_bill_customer_sk,
            },
            {
                ""items"": date_dim,
                ""on"": lambda c, ws, d: ws.ws_sold_date_sk == d.d_date_sk,
            },
        ],
        {""select"": lambda c, ws, d: (c, ws, d)},
    )
    _groups = _group_by(
        _rows,
        lambda c, ws, d: Auto3(
            id=c.c_customer_id,
            first=c.c_first_name,
            last=c.c_last_name,
            login=c.c_login,
            year=d.d_year,
        ),
    )
    _items5 = _groups
    return [
        Auto2(
            customer_id=g.key[""id""],
            customer_first_name=g.key[""first""],
            customer_last_name=g.key[""last""],
            customer_login=g.key[""login""],
            dyear=g.key[""year""],
            year_total=_sum(
                [
                    (
                        x[1].ws_ext_list_price
                        - x[1].ws_ext_wholesale_cost
                        - x[1].ws_ext_discount_amt
                        + x[1].ws_ext_sales_price
                    )
                    / 2
                    for x in g
                ]
            ),
            sale_type=""w"",
        )
        for g in _items5
    ]
",tests/dataset/tpc-ds/compiler/py/q4.py,,1,6.348800075736417e-09,"The method '_q4' is a complex query function that processes customer sales data, groups it by customer and year, and calculates a 'year_total' for each group. This type of function is typically essential for data analysis and reporting purposes, especially in business intelligence contexts. It is unlikely to be deleted because it serves a critical role in extracting and summarizing data, which is a common requirement in many applications. Additionally, the function appears to be well-structured and uses meaningful abstractions, suggesting it is part of a well-maintained codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q82.py,Item,0,0.9999910602998366,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"def test_TPCDS_Q32_simplified():
    assert result == 20.0
",tests/dataset/tpc-ds/compiler/py/q32.py,,0,0.9999999956365377,"The method `test_TPCDS_Q32_simplified` is a test function that contains an assertion checking if `result` equals 20.0. However, the function lacks any setup or context for the variable `result`, making it unclear where `result` is defined or how it is computed. Without this context, the test is not functional as it stands. Typically, test functions should include setup code to define and compute the variables they are testing. Given this lack of context and functionality, it is likely that this method will be deleted or significantly modified to include the necessary setup for `result`. Therefore, the prediction is that the method will be Deleted."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q36.py,Auto2,1,7.194132978569833e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be retained as it serves a clear purpose and is implemented correctly."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q73.py,StoreSale,1,4.6911638017642294e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q77.py,CatalogReturn,1,9.931195248674785e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q42.py,DateDim,0,0.999964643742472,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate method for checking key membership."
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q70.py,,1,3.850741907939403e-09,"The method '_group_by' is a utility function that groups elements of a list based on a key function. It is a common pattern in data processing and transformation tasks. The function is generic, flexible, and can handle various input types, making it useful in many scenarios. Additionally, it uses a dictionary to maintain groups and a list to preserve the order of keys, which are efficient and practical approaches. There is no indication of redundancy or obsolescence in the code, suggesting it will likely be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q19.py,StoreSale,0,0.9999938558278723,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"def distinct(xs):
    out = []
    for x in xs:
        if not x in out:
            out = out + [x]
    return out
",tests/dataset/tpc-ds/compiler/py/q95.py,,1,1.275190675769241e-07,"The method 'distinct' is designed to return a list of unique elements from the input list 'xs'. However, the implementation is inefficient because it uses list concatenation in a loop, which results in O(n^2) time complexity. This can be improved by using a set to track seen elements, which would reduce the time complexity to O(n). Despite the inefficiency, the method correctly achieves its purpose of returning distinct elements, and such methods are often retained for their simplicity and correctness, even if they are not optimal. Therefore, it is likely to survive."
survived,"def abs(x):
    if x >= 0.0:
        return x
    return -x
",tests/dataset/tpc-ds/compiler/py/q57.py,,0,0.9999991684720096,"The method is a simple implementation of the absolute value function, which is a fundamental mathematical operation. However, Python already has a built-in function `abs()` that performs the same operation more efficiently and is optimized for various data types. Redefining such a common function can lead to confusion and potential errors in larger codebases, especially since it overrides the built-in function. Therefore, it is likely that this method will be deleted in favor of using the built-in `abs()` function."
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q20.py,,1,5.60279640614594e-09,"The method is likely to survive because it implements a useful functionality of grouping elements from a list based on a key function. This is a common requirement in data processing tasks. The method handles different types of input elements (lists, tuples, and single items) and manages keys that are dictionaries by converting them to a SimpleNamespace, which is a practical approach. The use of a dictionary to store groups and a list to maintain order is efficient and well-structured. Unless there are significant changes in requirements or a better alternative is introduced, this method is likely to remain useful."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q67.py,StoreSale,1,1.1861120010657661e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a simple and effective way to allow attribute access using keys, which can be particularly useful in classes that need to interface with code expecting dictionary-like objects. Therefore, this method is likely to be retained as it provides a clear and functional purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q25.py,Store,0,0.9999687980937693,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking for membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q94.py,WebSale,0,0.9999756997690634,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys. However, this implementation uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which is usually used for membership testing in collections like lists, sets, or dictionaries. Therefore, this implementation is likely incorrect for its intended purpose and may be deleted or replaced with a more appropriate implementation."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q93.py,StoreReturn,1,5.3157849718487075e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, it is likely to be retained in the code."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q18.py,_Group,1,4.6911638017642294e-08,"The method is a constructor (__init__) for a class, which is a fundamental part of class instantiation in Python. Constructors are essential for initializing object attributes and are unlikely to be deleted unless the class itself is being removed or refactored significantly. Additionally, the method is correctly setting up instance variables, which suggests it is functioning as intended."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q99.py,,1,1.955568070542584e-08,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The function is not overly specific to a particular use case, making it versatile and reusable in different contexts. Additionally, the function is well-structured and implements common data manipulation patterns, which are often needed in various applications. Therefore, it is likely to be retained for its utility and flexibility."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q17.py,Item,1,3.653482080241728e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a flexible and Pythonic way to access object attributes, it is likely to be retained in the code."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q35.py,_Group,1,3.3982678079468468e-09,"The method `__len__` is a special method in Python that is used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q29.py,_Group,1,5.60279640614594e-09,"The method `__len__` is a special method in Python that is used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q6.py,DateDim,0,0.9999869928752253,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q84.py,IncomeBand,1,6.69158608681505e-10,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, this method is likely to be Survived."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q90.py,,1,8.152020648014727e-09,"The method '_key' is a utility function that is likely used internally within a class or module to generate a key for sorting purposes. It takes an iterable 'it', applies a sorting key function from 'opts', and ensures the key is a string if it's a complex data type. This kind of function is common in data processing and sorting tasks, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained."
survived,"def test_TPCDS_Q74_simplified():
    assert result == [
        Auto1(customer_id=1, customer_first_name=""Alice"", customer_last_name=""Smith"")
    ]
",tests/dataset/tpc-ds/compiler/py/q74.py,,1,1.725782769012759e-08,"The method `test_TPCDS_Q74_simplified` is a test function, likely part of a test suite for a larger application. Test functions are generally not deleted unless they are redundant, incorrect, or the functionality they test is no longer relevant. Since this function is asserting a specific result, it indicates that it is testing a particular behavior or output of the system. Unless the functionality being tested is removed or significantly altered, the test is likely to survive to ensure the system behaves as expected."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q71.py,Auto2,1,6.825604231969389e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name, which can be useful for objects that need to provide dictionary-like access to their attributes. This is a valid and potentially useful implementation, especially in cases where the object is designed to act like a dictionary or needs to provide flexible attribute access. Therefore, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q7.py,CustomerDemographic,1,4.6911638017642294e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a simple and effective way to allow attribute access via keys, which can be particularly useful in data handling or configuration classes. Therefore, this method is likely to be retained as it serves a clear purpose and is implemented correctly."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q76.py,Auto1,0,0.9999599363048656,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate method for checking key membership."
survived,"def _q0():
    _src = store_sales
    _rows = _query(
        _src,
        [
            {
                ""items"": item,
                ""on"": lambda ss, i: ss.item == i.i_item_sk and i.i_manager_id == 1,
            },
            {""items"": date_dim, ""on"": lambda ss, i, d: ss.sold_date == d.d_date_sk},
        ],
        {""select"": lambda ss, i, d: (ss, i, d)},
    )
    _groups = _group_by(_rows, lambda ss, i, d: Auto2(brand_id=i.i_brand_id))
    _items1 = _groups
    return [
        Auto1(brand_id=g.key[""brand_id""], ext_price=sum([x[0].price for x in g]))
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q55.py,,1,3.653482080241728e-08,"The method '_q0' is a private function (indicated by the underscore prefix) that performs a specific query operation on a dataset. It uses a combination of filtering, joining, and grouping operations to process the data. The method is likely part of a larger codebase that deals with data analysis or reporting. Since it is a utility function that encapsulates a specific data processing logic, it is likely to be retained as long as the functionality it provides is needed. Unless there is a significant change in the data processing requirements or the method is replaced by a more efficient or updated approach, it is likely to survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q64.py,StoreReturn,0,0.9999339478346898,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose suggests that it might be deleted or refactored to align with its conventional use."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q77.py,CatalogReturn,1,5.144221744469598e-05,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually implemented to check for membership in a collection like a list, set, or dictionary. However, if the class is designed to treat its attributes as keys in a collection, this implementation could be valid. Without additional context, it's hard to determine if this is a misuse or a valid use case. Given the flexibility of Python and the potential for custom implementations, this method is likely to survive unless it causes confusion or errors in the intended use of the class."
survived,"def _q0():
    _groups = {}
    _order = []
    for a in active:
        _k = Auto2(
            gender=a[""cd_gender""],
            marital=a[""cd_marital_status""],
            education=a[""cd_education_status""],
            purchase=a[""cd_purchase_estimate""],
            credit=a[""cd_credit_rating""],
            dep=a[""cd_dep_count""],
            depemp=a[""cd_dep_employed_count""],
            depcol=a[""cd_dep_college_count""],
        )
        _ks = str(_k)
        g = _groups.get(_ks)
        if not g:
            g = _Group(_k)
            _groups[_ks] = g
            _order.append(_ks)
        g.Items.append(a)
    _items1 = [_groups[k] for k in _order]
    return [
        Auto1(
            cd_gender=g.key[""gender""],
            cd_marital_status=g.key[""marital""],
            cd_education_status=g.key[""education""],
            cnt1=len([_ for _ in g]),
            cd_purchase_estimate=g.key[""purchase""],
            cnt2=len([_ for _ in g]),
            cd_credit_rating=g.key[""credit""],
            cnt3=len([_ for _ in g]),
            cd_dep_count=g.key[""dep""],
            cnt4=len([_ for _ in g]),
            cd_dep_employed_count=g.key[""depemp""],
            cnt5=len([_ for _ in g]),
            cd_dep_college_count=g.key[""depcol""],
            cnt6=len([_ for _ in g]),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q10.py,,1,5.60279640614594e-09,"The method '_q0' is a utility function that processes a list of 'active' items, groups them based on certain attributes, and returns a list of 'Auto1' objects with aggregated data. This kind of functionality is common in data processing and transformation tasks, especially when dealing with datasets that need to be grouped and summarized. The method is likely part of a larger system that requires this kind of data manipulation, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q36.py,_Group,1,1.637377179507321e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes. The code snippet shows a typical pattern of initializing instance variables, which is a common and necessary practice in Python classes. Therefore, it is unlikely that this method will be deleted."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q72.py,DateDim,1,4.1399375473943306e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. It is a simple and effective way to provide dictionary-like access to object attributes, which can be particularly useful in dynamic or flexible data structures. Therefore, this method is likely to be retained as it serves a clear purpose and is correctly implemented."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q48.py,StoreSale,1,9.237449576640118e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be retained as it serves a clear purpose and is implemented correctly."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q91.py,CallCenter,1,1.725782769012759e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be retained as it serves a clear purpose and follows Python's design principles."
survived,"def _q2():
    _src = inventory
    _rows = _query(
        _src,
        [{""items"": date_dim, ""on"": lambda inv, d: inv.inv_date_sk == d.d_date_sk}],
        {
            ""select"": lambda inv, d: (inv, d),
            ""where"": lambda inv, d: d.d_date >= ""2000-03-15"",
        },
    )
    _groups = _group_by(
        _rows, lambda inv, d: Auto3(w=inv.inv_warehouse_sk, i=inv.inv_item_sk)
    )
    _items3 = _groups
    return [
        Auto2(
            w=g.key[""w""], i=g.key[""i""], qty=sum([x[0].inv_quantity_on_hand for x in g])
        )
        for g in _items3
    ]
",tests/dataset/tpc-ds/compiler/py/q21.py,,1,2.8453347280241004e-08,"The method '_q2' is a private function (indicated by the underscore prefix) that performs a specific query operation on an inventory dataset. It uses helper functions like '_query' and '_group_by', which suggests it is part of a larger codebase or library. The method is well-defined, performs a clear task of filtering and grouping inventory data, and returns a structured result. Unless there is a significant change in the requirements or the codebase, such utility functions are typically retained for their functionality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q69.py,WebSale,0,0.9999785550602307,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use of `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, especially for users familiar with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q29.py,,1,6.023574641292144e-08,"The method '_key' is a utility function that is likely used internally to generate a key for sorting purposes. It takes an iterable 'it', applies a sorting key function from 'opts', and ensures the key is a string if it's a complex data type. This kind of function is common in sorting operations and is useful for customizing sort behavior. Since it serves a specific purpose and is not overly complex or redundant, it is likely to be retained in the codebase."
survived,"def _q0():
    _src = catalog_sales
    _rows = _query(
        _src,
        [
            {
                ""items"": customer,
                ""on"": lambda cs, c: cs.cs_bill_customer_sk == c.c_customer_sk,
            },
            {
                ""items"": customer_address,
                ""on"": lambda cs, c, ca: c.c_current_addr_sk == ca.ca_address_sk,
            },
            {
                ""items"": date_dim,
                ""on"": lambda cs, c, ca, d: cs.cs_sold_date_sk == d.d_date_sk,
            },
        ],
        {
            ""select"": lambda cs, c, ca, d: (cs, c, ca, d),
            ""where"": lambda cs, c, ca, d: (
                (
                    (
                        ca.ca_zip[0:5]
                        in [
                            ""85669"",
                            ""86197"",
                            ""88274"",
                            ""83405"",
                            ""86475"",
                            ""85392"",
                            ""85460"",
                            ""80348"",
                            ""81792"",
                        ]
                        or ca.ca_state in [""CA"", ""WA"", ""GA""]
                    )
                    or cs.cs_sales_price > 500
                )
                and d.d_qoy == 1
            )
            and d.d_year == 2000,
        },
    )
    _groups = _group_by(_rows, lambda cs, c, ca, d: Auto2(zip=ca.ca_zip))
    _items1 = _groups
    _items1 = sorted(_items1, key=lambda g: g.key[""zip""])
    return [
        Auto1(ca_zip=g.key[""zip""], sum_sales=sum([x[0].cs_sales_price for x in g]))
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q15.py,,1,7.194132978569833e-09,"The method '_q0' is a complex query function that joins multiple tables and filters data based on specific conditions. It is likely part of a larger data processing or reporting system. The method is well-structured, uses lambda functions for flexibility, and performs operations like grouping and sorting, which are common in data analysis tasks. Given its functionality and the fact that it is not overly complex or redundant, it is likely to be useful in its context and therefore will survive."
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q36.py,,1,2.646573631904765e-09,"The method '_group_by' is likely to survive because it provides a useful utility function for grouping elements of a list based on a key function. This is a common requirement in data processing and manipulation tasks. The method is generic, allowing it to be used with various types of data and key functions, which increases its applicability. Additionally, the use of a dictionary to maintain groups and a list to preserve order is a well-established pattern that balances efficiency and functionality. Unless there are significant changes in the requirements or a better alternative is introduced, this method is likely to remain useful."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q10.py,Auto1,1,1.1861120010657661e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is used as a dictionary-like structure, allowing for flexible and dynamic access to its attributes. Therefore, it is likely to be retained in the code."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q70.py,,1,2.8453347280241004e-08,"The method '_key' is a utility function that is likely used internally within a class or module to generate a key for sorting purposes. It takes an iterable 'it', applies a sorting key function from 'opts', and ensures the key is a string if it's a complex data type. This kind of method is typically useful for customizing sorting behavior and is not likely to be removed unless the entire sorting mechanism is refactored or replaced. Therefore, it is more likely to survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q94.py,WebSite,1,2.5109990926928157e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, it is likely to be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q62.py,WebSale,0,0.999876605372333,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually meant for checking membership in a collection like a list, set, or dictionary. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior expected from `__contains__`. Therefore, it is likely that this method will be deleted or refactored to better fit its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q71.py,StoreSale,0,0.999988521231025,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys. However, this implementation uses `hasattr`, which checks if an object has an attribute with the given name. This is not the intended use of `__contains__`, as it should be checking membership in a collection, not attributes of an object. This misuse of the method suggests it may be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q96.py,HouseholdDemographics,0,0.9999546021442518,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the typical or expected behavior for `__contains__`, which should be checking membership in a collection like a list, set, or dictionary. Therefore, this implementation is likely incorrect for its intended purpose and may be deleted or replaced with a more appropriate implementation."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q4.py,,1,6.825604231969389e-08,"The method '_key' is a utility function that is likely used internally within a class or module to generate a key for sorting purposes. It is a simple and straightforward function that converts the result of a 'sortKey' function into a string if it is a list, tuple, or dictionary. This kind of utility function is common in codebases where sorting or ordering of complex data structures is required. Since it serves a specific purpose and is not overly complex or redundant, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q76.py,WebSale,0,0.9999038976006968,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually meant for checking membership in a collection like a list, set, or dictionary. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior expected from `__contains__`. Therefore, it is likely that this method will be deleted or refactored to better fit its intended purpose."
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q43.py,_Group,1,3.160881453314576e-10,"The method `__iter__` is a standard Python method used to make an object iterable. It is implemented here to return an iterator over `self.Items`, which suggests that `self.Items` is a collection (like a list or a set). This is a common and useful pattern in Python, allowing objects to be used in loops and other iterable contexts. There is no indication that this method is redundant or unnecessary, so it is likely to be retained."
survived,"def test_TPCDS_Q37_simplified():
    assert result == [Auto1(i_item_id=""I1"", i_item_desc=""Item1"", i_current_price=30.0)]
",tests/dataset/tpc-ds/compiler/py/q37.py,,1,9.736200303530205e-10,"The method `test_TPCDS_Q37_simplified` is a unit test function that checks if the `result` matches a specific expected output. Unit tests are crucial for ensuring code correctness and reliability, especially in larger projects. They help in identifying bugs early and ensure that changes do not break existing functionality. Given the importance of testing in software development, this method is likely to be retained."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q51.py,,1,1.3440409770490404e-08,"The method '_key' is a utility function that is likely used internally within a class or module to generate a key for sorting purposes. It takes an iterable 'it', applies a sorting key function from 'opts', and ensures the key is a string if it's a complex data type. This kind of method is typically useful for customizing sorting behavior and is unlikely to be removed unless the entire sorting mechanism is refactored or replaced. Therefore, it is more likely to survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q55.py,StoreSale,1,2.8453347280241004e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is likely to survive because it provides a flexible way to access object attributes, which can be particularly useful in dynamic or reflective programming scenarios."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q84.py,StoreReturn,0,0.999985261023967,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q54.py,_Group,1,4.363462233903899e-09,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation here is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q52.py,_Group,1,3.850741907939403e-09,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation here is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q13.py,Store,1,1.725782769012759e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q46.py,Auto3,1,1.3440409770490404e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, this method is likely to be retained as it provides a clear and useful functionality."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q77.py,WebSale,1,1.8553915987649156e-07,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. It is likely to be retained because it provides a flexible and Pythonic way to access object attributes dynamically, which can be very useful in many applications."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q99.py,Warehouse,0,0.999985261023967,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q34.py,HouseholdDemographic,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, especially for users familiar with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q92.py,DateDim,1,9.61023993032045e-05,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually used to check for membership in a collection like a list, set, or dictionary. However, if the class is designed to treat its attributes as a collection of keys, this implementation could be valid. Without additional context, it's difficult to determine if this is the intended use. If the class is indeed designed to treat its attributes as keys, this method could survive. Otherwise, it might be considered for deletion or modification to better fit the typical use of `__contains__`. Given the ambiguity, it is more likely to survive if the class context supports this usage."
survived,"def _sum(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""sum() expects list or group"")
    s = 0.0
    for it in v:
        if it is None:
            continue
        if isinstance(it, (int, float)):
            s += float(it)
        else:
            raise Exception(""sum() expects numbers"")
    return s
",tests/dataset/tpc-ds/compiler/py/q33.py,,1,5.3157849718487075e-08,"The method '_sum' is a utility function that calculates the sum of a list of numbers. It includes error handling for non-list inputs and non-numeric elements within the list. This function is likely to survive because it provides a basic yet essential functionality that can be reused in various contexts where summing a list of numbers is required. Additionally, it handles edge cases like None values and non-numeric types, making it robust and versatile."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q50.py,_Group,1,1.444980317078884e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes. The code snippet shows a typical pattern where an attribute is initialized and a list is created. This is a common and necessary practice in class design, so it is unlikely to be deleted."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q63.py,_Group,1,3.0590235908148916e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes. The code snippet shows a typical pattern of initializing instance variables, which is a common and necessary practice in class definitions. Therefore, it is unlikely that this method will be deleted."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q18.py,Auto2,1,6.023574641292144e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name, which can be useful for objects that need to provide dictionary-like access to their attributes. This is a valid and potentially useful implementation, especially in cases where the object is designed to act like a dictionary or needs to provide flexible attribute access. Therefore, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q16.py,CatalogSale,0,0.9999974387182097,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. In this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not a typical or correct implementation for `__contains__`, as it should check for membership in a collection rather than the presence of an attribute. This misuse of `__contains__` is likely to lead to confusion and incorrect behavior when the method is used. Therefore, it is likely to be deleted or replaced with a more appropriate implementation."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q24.py,CustomerAddress,0,0.9999952149051502,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q89.py,StoreSale,0,0.9324533140223229,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually implemented to check for membership in a collection like a list, set, or dictionary. However, if the class is designed to treat its attributes as a collection of keys, this implementation could be valid. Without additional context on how this method is used within the class, it's difficult to definitively say it should be deleted. However, it is unconventional and might be misleading to other developers who expect `__contains__` to check for membership in a more traditional collection. Therefore, it is likely to be revised or deleted if it doesn't align with the intended use of the class."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q11.py,StoreSale,1,1.1861120010657661e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be retained as it serves a clear purpose and is implemented correctly."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q74.py,,1,2.998960815863541e-09,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The function is well-structured and provides flexibility through options like 'where', 'sortKey', 'skip', and 'take'. Such utility functions are often retained in codebases because they encapsulate common patterns of data manipulation that can be reused across different parts of an application. Therefore, it is likely to survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q48.py,StoreSale,0,0.9999687980937693,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical use case for `__contains__`, which is expected to check membership rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q10.py,_Group,1,8.152020648014727e-09,"The method is a constructor for a class, initializing the instance variables 'key', 'Items', and 'items'. It is a standard practice to have an __init__ method in a class to set up initial state, and there is no indication that this method is redundant or incorrect. Therefore, it is likely to be retained."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q77.py,,1,1.3440409770490404e-08,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It appears to be a utility function that could be part of a larger data processing or querying system. Such functions are often essential in applications that require dynamic data manipulation, especially in database-like operations. The method is generic and flexible, allowing for various operations based on the options provided, which makes it a valuable tool in many contexts. Therefore, it is likely to be retained for its utility and versatility."
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q71.py,,1,2.998960815863541e-09,"The method '_group_by' is likely to survive because it provides a useful utility function for grouping elements of a list based on a key function. This is a common requirement in data processing and manipulation tasks. The method is generic, allowing it to be used with various types of data and key functions, which increases its applicability. Additionally, the use of a dictionary to maintain groups and a list to preserve order is a well-established pattern that balances efficiency and functionality. Unless there are significant changes in the requirements or a better alternative is introduced, this method is likely to remain useful."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q35.py,Auto1,0,0.999985261023967,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not attribute existence. This misuse of the method's intended purpose is likely to lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership checks. Therefore, it is likely that this method will be deleted or significantly modified to align with its intended use."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q51.py,,1,1.522997951276035e-08,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It appears to be a utility function that could be part of a larger data processing or querying system. Such functions are often essential in applications that require dynamic data manipulation, especially in systems that mimic SQL-like operations in a non-SQL environment. The function is versatile, handling various join types and options, which suggests it is designed to be reused across different parts of an application. Therefore, it is likely to be retained as it provides significant functionality that would be cumbersome to replicate or replace."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q77.py,CatalogSale,0,0.9999756997690634,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement the intended functionality."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q30.py,_Group,1,7.73442280641062e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes. The code snippet shows a typical pattern where an attribute is initialized and a list is created. This is a common and necessary practice in class design, so it is unlikely to be deleted."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q50.py,Auto2,1,3.653482080241728e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. It is a simple and effective way to provide dynamic access to object attributes, which can be particularly useful in data handling or configuration classes. Therefore, this method is likely to be retained as it serves a clear purpose and is implemented correctly."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q95.py,WebSale,0,0.9999921107349486,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q12.py,DateDim,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. It is unlikely to be deleted unless the design of the class changes significantly, as it provides a flexible way to access object attributes."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q42.py,StoreSale,0,0.9999756997690634,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not fulfill its intended purpose. Therefore, it is likely to be deleted or replaced with a more appropriate implementation that correctly checks for key presence in a collection."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q43.py,Auto3,1,1.3440409770490404e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name, which can be useful for objects that need to provide dictionary-like access to their attributes. This method is simple, clear, and leverages Python's dynamic nature effectively. It is likely to be useful in many contexts where objects need to behave like dictionaries, making it a candidate for survival."
survived,"def test_TPCDS_Q50_simplified():
    assert result == [
        Auto1(s_store_name=""Main"", d30=1, d31_60=1, d61_90=1, d91_120=1, d_gt_120=1)
    ]
",tests/dataset/tpc-ds/compiler/py/q50.py,,1,7.582560422162384e-10,"The method `test_TPCDS_Q50_simplified` is a unit test function, which is typically used to verify that a specific piece of code works as expected. Unit tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Given the importance of testing in software development, it is unlikely that this method will be deleted unless it is replaced by a more comprehensive test or the functionality it tests is removed entirely. Therefore, the method is likely to survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q51.py,Auto2,0,0.9999982396568657,"The method is likely to be deleted because it does not correctly implement the expected behavior of the `__contains__` method. In Python, `__contains__` is used to check if a container contains a certain item, typically using the `in` keyword. The current implementation uses `hasattr`, which checks for the presence of an attribute, not whether an item is in a collection. This could lead to incorrect behavior and misunderstandings about the class's functionality."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q29.py,DateDim,1,2.8453347280241004e-08,"The method is a simple implementation of the __getitem__ special method, which allows instances of the class to use the bracket notation (e.g., instance[key]) to access attributes. This is a common and useful pattern in Python, especially for classes that aim to mimic dictionary-like behavior. It provides a clear and concise way to access attributes dynamically, which can be very useful in various applications. Therefore, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q87.py,CatalogSale,1,9.237449576640118e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to support dictionary-like access to their attributes. Since it provides a clear and functional purpose, it is likely to be retained in the code."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q3.py,_Group,1,6.69158608681505e-10,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be useful and necessary for the class, and it will survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q16.py,Auto1,1,1.522997951276035e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, this method is likely to be retained as it provides a useful functionality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q15.py,CustomerAddres,0,0.9999952149051502,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"def _q0():
    _src = sales_detail
    _rows = _query(
        _src,
        [
            {
                ""items"": item,
                ""on"": lambda sd, i: i.i_item_sk
                == (
                    sd.get(""i_item_sk"")
                    if isinstance(sd, dict)
                    else getattr(sd, ""i_item_sk"")
                ),
            }
        ],
        {
            ""select"": lambda sd, i: (sd, i),
            ""where"": lambda sd, i: i.i_category == ""Electronics"",
        },
    )
    _groups = _group_by(
        _rows,
        lambda sd, i: Auto4(
            year=sd.get(""d_year"") if isinstance(sd, dict) else getattr(sd, ""d_year""),
            brand_id=i.i_brand_id,
            class_id=i.i_class_id,
            category_id=i.i_category_id,
            manuf_id=i.i_manufact_id,
        ),
    )
    _items1 = _groups
    return [
        Auto3(
            d_year=g.key[""year""],
            i_brand_id=g.key[""brand_id""],
            i_class_id=g.key[""class_id""],
            i_category_id=g.key[""category_id""],
            i_manufact_id=g.key[""manuf_id""],
            sales_cnt=_sum(
                [
                    (
                        x[0].get(""quantity"")
                        if isinstance(x[0], dict)
                        else getattr(x[0], ""quantity"")
                    )
                    for x in g
                ]
            ),
            sales_amt=_sum(
                [
                    (
                        x[0].get(""amount"")
                        if isinstance(x[0], dict)
                        else getattr(x[0], ""amount"")
                    )
                    for x in g
                ]
            ),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q75.py,,1,5.60279640614594e-09,"The method '_q0' appears to be a data processing function that queries and groups sales data based on certain criteria. It uses helper functions like '_query', '_group_by', and '_sum', which suggests it is part of a larger codebase focused on data analysis or reporting. The method is specific in its functionality, targeting 'Electronics' category sales and aggregating data by year, brand, class, category, and manufacturer. Such methods are typically essential in data processing pipelines and are unlikely to be deleted unless the entire data processing approach is refactored or replaced. Therefore, it is more likely to survive."
survived,"def test_TPCDS_Q7_result():
    assert result == [Auto1(i_item_id=""I1"", agg1=5.0, agg2=10.0, agg3=2.0, agg4=8.0)]
",tests/dataset/tpc-ds/compiler/py/q7.py,,1,5.60279640614594e-09,"The method `test_TPCDS_Q7_result` is a test function that asserts a specific expected result. Test functions are generally important for ensuring code correctness and are usually retained unless they are redundant or replaced by more comprehensive tests. Since this function is performing a specific assertion, it is likely to be useful for validating the behavior of the code it is testing. Therefore, it is more likely to be retained."
survived,"def _avg(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""avg() expects list or group"")
    if not v:
        return 0
    s = 0.0
    for it in v:
        if isinstance(it, (int, float)):
            s += float(it)
        else:
            raise Exception(""avg() expects numbers"")
    return s / len(v)
",tests/dataset/tpc-ds/compiler/py/q13.py,,1,9.736200303530205e-10,"The method '_avg' is a utility function that calculates the average of a list of numbers. It includes error handling for cases where the input is not a list or contains non-numeric values. This kind of utility function is commonly used in data processing tasks and is generally useful in various contexts. The method is well-defined, performs a clear task, and includes error handling, making it a candidate for survival in a codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q20.py,CatalogSale,1,1.0467401685178159e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern and does not have any apparent issues or redundancies that would warrant its deletion. Therefore, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q4.py,Customer,0,0.999876605372333,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose is likely to lead to confusion and errors, suggesting that the method should be deleted or re-implemented correctly."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q13.py,,1,9.237449576640118e-09,"The method '_key' is a utility function that is likely used for sorting purposes, as indicated by the name and the use of 'sortKey'. It converts the key to a string if it is a list, tuple, or dictionary, which is a common practice to ensure consistent sorting behavior. This method is simple, performs a specific task, and does not have any apparent issues or redundancies. Therefore, it is likely to be retained in the codebase."
survived,"def test_TPCDS_Q57_simplified():
    assert result == []
",tests/dataset/tpc-ds/compiler/py/q57.py,,0,0.9999994956527948,"The method `test_TPCDS_Q57_simplified` is a test function that contains a single assertion checking if `result` is an empty list. Without additional context or setup, this test is not very useful or informative. It lacks any setup, execution, or teardown steps that are typically part of a meaningful test. Additionally, the test does not provide any context or explanation for what `result` is or why it should be empty. This makes the test less valuable for maintaining or improving code quality. Therefore, it is likely to be deleted unless further context or functionality is added to make it a meaningful test."
survived,"def test_TPCDS_Q91_returns():
    assert result == Auto1(
        Call_Center=""CC1"", Call_Center_Name=""Main"", Manager=""Alice"", Returns_Loss=10.0
    )
",tests/dataset/tpc-ds/compiler/py/q91.py,,1,1.1861120010657661e-08,"The method `test_TPCDS_Q91_returns` is a unit test function, which is typically used to verify that a specific piece of code works as expected. Unit tests are crucial for maintaining code quality and ensuring that changes do not introduce new bugs. The presence of an assertion within the function indicates that it is checking the correctness of some functionality, likely related to a TPC-DS query result. Since unit tests are an integral part of software development and maintenance, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered. Therefore, the method is more likely to survive."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q79.py,_Group,1,1.0467401685178159e-08,"The method is a constructor for a class, initializing instance variables. It sets up a key and two lists, 'Items' and 'items', which are references to the same list. This is a common pattern in Python to initialize object state, and there is no indication of redundancy or error. Therefore, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q43.py,Auto1,1,3.653482080241728e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q43.py,DateDim,1,2.2159489282323004e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method is functional, straightforward, and serves a clear purpose, it is likely to be retained in the codebase."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q42.py,,1,2.2159489282323004e-08,"The method '_key' is a utility function that is likely used internally within a class or module to generate a key for sorting purposes. It takes an iterable 'it', applies a function from 'opts' dictionary to generate a key, and ensures the key is a string if it's a complex data type. This kind of utility function is common in codebases for sorting or organizing data, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained."
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q74.py,_Group,1,5.211412485172657e-10,"The method is a standard implementation of the __iter__ method in Python, which is used to make an object iterable. This is a common and necessary method for classes that need to support iteration, such as those representing collections or sequences. Since it is a fundamental part of making a class iterable, it is unlikely to be deleted unless the class itself is being removed or significantly refactored. Therefore, the method will likely survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q96.py,TimeDim,0,0.999964643742472,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use of `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, especially for users who expect `in` to check for membership in a collection. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q79.py,_Group,1,9.736200303530205e-10,"The method `__iter__` is a standard Python method used to make an object iterable. It is implemented here to return an iterator over `self.Items`, which suggests that `self.Items` is a collection (like a list or a set). This is a common and useful pattern in Python, allowing objects to be used in loops and other iterable contexts. There is no indication that this method is redundant or unnecessary, so it is likely to be retained."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q18.py,_Group,1,2.0611536181902033e-09,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q7.py,StoreSale,1,1.1861120010657661e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"def test_TPCDS_Q48_simplified():
    assert result == 35
",tests/dataset/tpc-ds/compiler/py/q48.py,,0,0.9999962733608834,"The method `test_TPCDS_Q48_simplified` is a test function that contains an assertion checking if `result` equals 35. However, the function lacks context, such as the definition or calculation of `result`, making it unclear if the test is valid or useful. Without additional context or setup, this test is not meaningful, as it doesn't verify any specific functionality or behavior of a system. Therefore, it is likely to be deleted unless further context is provided to make it a valid test case."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q10.py,Customer,0,0.9999957771647318,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical use case for `__contains__`, which is expected to check membership rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q77.py,Auto1,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, especially for users familiar with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q91.py,Auto2,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation, especially in cases where the object is designed to behave like a dictionary or needs dynamic attribute access. There is no indication that this method is redundant or incorrect, so it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q46.py,HouseholdDemographic,1,6.825604231969389e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. It is a simple and effective way to provide dynamic access to object attributes, which can be particularly useful in data handling or configuration classes. Therefore, this method is likely to be retained as it serves a clear purpose and is implemented correctly."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q83.py,SrItem,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q78.py,S,1,1.1253518384332553e-07,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is likely to be retained because it provides a flexible way to access object attributes and is consistent with Python's design philosophy of allowing objects to behave like built-in types when appropriate."
survived,"def _q2():
    _src = customer
    _rows = _query(
        _src,
        [
            {
                ""items"": catalog_sales,
                ""on"": lambda c, cs: c.c_customer_sk == cs.cs_bill_customer_sk,
            },
            {
                ""items"": date_dim,
                ""on"": lambda c, cs, d: cs.cs_sold_date_sk == d.d_date_sk,
            },
        ],
        {""select"": lambda c, cs, d: (c, cs, d)},
    )
    _groups = _group_by(
        _rows,
        lambda c, cs, d: Auto3(
            id=c.c_customer_id,
            first=c.c_first_name,
            last=c.c_last_name,
            login=c.c_login,
            year=d.d_year,
        ),
    )
    _items3 = _groups
    return [
        Auto2(
            customer_id=g.key[""id""],
            customer_first_name=g.key[""first""],
            customer_last_name=g.key[""last""],
            customer_login=g.key[""login""],
            dyear=g.key[""year""],
            year_total=_sum(
                [
                    (
                        x[1].cs_ext_list_price
                        - x[1].cs_ext_wholesale_cost
                        - x[1].cs_ext_discount_amt
                        + x[1].cs_ext_sales_price
                    )
                    / 2
                    for x in g
                ]
            ),
            sale_type=""c"",
        )
        for g in _items3
    ]
",tests/dataset/tpc-ds/compiler/py/q4.py,,1,3.653482080241728e-08,"The method '_q2' is a complex query function that processes customer sales data by joining multiple tables and performing calculations. It is likely part of a larger data processing or reporting system. Such methods are typically retained because they encapsulate important business logic and data processing tasks. Unless there is a significant change in the system architecture or the method is replaced by a more efficient or updated version, it is unlikely to be deleted."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q36.py,Auto1,1,7.194132978569833e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python to allow more flexible and dynamic access to object properties. Therefore, this method is likely to be retained as it serves a clear purpose and is implemented correctly."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q56.py,_Group,1,2.3823698451773172e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes. The code snippet shows a typical pattern where a key is assigned, and a list is initialized. This is a common and necessary practice in class design, so it is unlikely to be deleted."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q3.py,,1,5.715002851580502e-07,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It appears to be a utility function that could be part of a larger data processing or querying library. Such functions are often essential for handling data transformations and are unlikely to be deleted unless they are replaced by a more efficient or simpler implementation. Given its complexity and utility, it is more likely to be refactored or optimized rather than deleted."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q57.py,Auto5,1,1.444980317078884e-07,"The method is a simple implementation of the __getitem__ special method, which allows instances of the class to use the bracket notation (e.g., obj[key]) to access attributes. This is a common and useful pattern in Python, especially for classes that aim to mimic dictionary-like behavior. It provides a clear and concise way to access attributes dynamically, which can be very useful in various applications. Therefore, it is likely to be retained as it serves a practical purpose."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q13.py,,1,6.348800075736417e-09,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The function is well-structured and provides flexibility through options like 'where', 'sortKey', 'skip', and 'take'. Such utility functions are often retained in codebases because they encapsulate common patterns of data manipulation, making them reusable and reducing code duplication. Therefore, it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q77.py,WebReturn,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q34.py,_Group,1,8.76424914819242e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes. The code snippet shows a typical pattern where an attribute is initialized and a list is created. This is a common and necessary practice in class design, so it is unlikely to be deleted."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q3.py,Auto2,1,2.5109990926928157e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"def _q0():
    _groups = {}
    _order = []
    for r in records:
        _k = Auto3(
            d_year=r.d_year, i_category_id=r.i_category_id, i_category=r.i_category
        )
        _ks = str(_k)
        g = _groups.get(_ks)
        if not g:
            g = _Group(_k)
            _groups[_ks] = g
            _order.append(_ks)
        g.Items.append(r)
    _items1 = [_groups[k] for k in _order]
    return [
        Auto1(
            d_year=g.key[""d_year""],
            i_category_id=g.key[""i_category_id""],
            i_category=g.key[""i_category""],
            sum_ss_ext_sales_price=sum([x.price for x in g]),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q42.py,,1,7.194132978569833e-09,"The method '_q0' is a private method (indicated by the underscore prefix) that processes a collection of records to group them by certain attributes and then computes a summary for each group. This type of method is often used in data processing tasks, and its functionality seems specific and useful for the context it is designed for. It is unlikely to be deleted unless the entire data processing logic is refactored or replaced. Additionally, the method appears to be well-structured and serves a clear purpose, which further supports its survival."
survived,"def test_TPCDS_Q78_simplified():
    assert result == [
        Auto1(
            ss_sold_year=1998,
            ss_item_sk=1,
            ss_customer_sk=1,
            ratio=1.25,
            store_qty=10,
            store_wholesale_cost=50.0,
            store_sales_price=100.0,
            other_chan_qty=8,
            other_chan_wholesale_cost=40.0,
            other_chan_sales_price=80.0,
        )
    ]
",tests/dataset/tpc-ds/compiler/py/q78.py,,1,2.3355930333443423e-09,"The method `test_TPCDS_Q78_simplified` is a test function, which is typically used to verify the correctness of a specific piece of code. Test functions are generally not deleted unless they are redundant, incorrect, or replaced by a more comprehensive test. Since this function appears to be a straightforward assertion test, it is likely to be retained to ensure the expected behavior of the code it is testing. Therefore, the method will likely survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q15.py,Customer,1,0.14804720367010532,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually implemented to check for membership in a collection like a list, set, or dictionary. However, if the class is designed to treat its attributes as a collection of keys, this implementation could be valid. Without additional context, it's difficult to determine if this is the intended use. If the class is indeed designed to treat its attributes as keys, the method might survive. Otherwise, it might be considered incorrect and subject to deletion or modification."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q55.py,_Group,1,1.4166087846364157e-09,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be useful and necessary for the class's functionality, leading to its survival."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q76.py,Auto3,0,0.9999785550602307,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the typical or expected behavior for `__contains__`, which should check for membership in a collection like a list, set, or dictionary. Therefore, this implementation is likely incorrect for its intended purpose and may be deleted or replaced with a more appropriate implementation."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q70.py,Auto2,1,3.2241866333029355e-08,"The method is a simple implementation of the __getitem__ special method, which allows instances of the class to use the bracket notation (e.g., obj[key]) to access attributes. This is a common and useful pattern in Python, especially for classes that aim to mimic dictionary-like behavior. It provides a clear and concise way to access attributes dynamically, which can be very useful in various applications. There is no indication that this method is redundant or harmful, so it is likely to be retained."
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q72.py,,1,7.194132978569833e-09,"The method '_group_by' is likely to survive because it provides a useful utility function for grouping elements of a list based on a key function. This is a common requirement in data processing and manipulation tasks. The method is flexible, handling both individual elements and tuples/lists, and it maintains the order of first appearance of each group, which can be important for certain applications. Additionally, the use of a dictionary to store groups ensures efficient lookups, and the method is generic, allowing it to be used with various data types. These factors contribute to its potential usefulness and likelihood of being retained."
survived,"def _sum(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""sum() expects list or group"")
    s = 0.0
    for it in v:
        if it is None:
            continue
        if isinstance(it, (int, float)):
            s += float(it)
        else:
            raise Exception(""sum() expects numbers"")
    return s
",tests/dataset/tpc-ds/compiler/py/q25.py,,1,2.998960815863541e-09,"The method '_sum' is a utility function that calculates the sum of a list of numbers, handling cases where the input might be an object with an 'Items' attribute or contain None values. It raises exceptions for invalid inputs, ensuring robustness. Such utility functions are often useful in various contexts, especially when dealing with data that might not always be in the expected format. Therefore, it is likely to be retained for its utility and error handling capabilities."
survived,"def _sum(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""sum() expects list or group"")
    s = 0.0
    for it in v:
        if it is None:
            continue
        if isinstance(it, (int, float)):
            s += float(it)
        else:
            raise Exception(""sum() expects numbers"")
    return s
",tests/dataset/tpc-ds/compiler/py/q95.py,,1,1.725782769012759e-08,"The method '_sum' is a utility function that calculates the sum of a list of numbers, with additional handling for objects that have an 'Items' attribute. It includes error handling for non-list inputs and non-numeric elements within the list. This kind of utility function is often useful in various applications where data might be encapsulated in objects or require validation before processing. Given its utility and the fact that it handles edge cases, it is likely to be retained in the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q88.py,TimeDim,1,2.2159489282323004e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python to allow more flexible and dynamic access to object properties. Therefore, this method is likely to be retained as it provides a clear and functional purpose."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q37.py,Inventory,1,3.2241866333029355e-08,"The method is a simple implementation of the __getitem__ special method, which allows instances of the class to use the bracket notation (e.g., obj[key]) to access attributes. This is a common and useful pattern in Python, especially for classes that aim to mimic dictionary-like behavior. It provides a clear and concise way to access attributes dynamically, which can be very useful in various applications. Therefore, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q72.py,HouseholdDemographic,1,2.2159489282323004e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the subscript notation (e.g., `obj[key]`). In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q1.py,Store,0,0.999964643742472,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually meant for checking membership in a collection like a list, set, or dictionary. However, if the class is designed to treat its attributes as keys in a collection, this implementation could be valid. Without additional context, it's difficult to determine if this is a misuse or a valid use case. Given the ambiguity, the method might survive if the class is specifically designed to work this way, but it could also be deleted if it doesn't align with the intended use of `__contains__`. However, since it doesn't follow the conventional use of `__contains__`, it is more likely to be deleted."
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q26.py,,1,2.2159489282323004e-08,"The method '_group_by' is a utility function that groups elements of a list based on a key function. Such utility functions are commonly used in data processing and transformation tasks. The method is generic, flexible, and can handle various input types, making it a valuable tool in many programming scenarios. Unless there is a specific reason to remove it, such as redundancy or a better alternative, it is likely to be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q41.py,Item,0,0.9998415637531546,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually meant for checking membership in a collection like a list, set, or dictionary. This misuse of `__contains__` could lead to confusion and unexpected behavior, as it does not align with the standard behavior expected from this method. Therefore, it is likely that this method will be deleted or refactored to better fit its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q19.py,DateDim,0,0.9999957771647318,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q33.py,StoreSale,1,2.646573631904765e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name, which can be useful for objects that need to provide dictionary-like access to their attributes. This method is simple, clear, and serves a specific purpose, making it likely to be retained in the codebase unless the design requirements change significantly. Therefore, it is predicted to survive."
survived,"def _count(v):
    if isinstance(v, list):
        return len(v)
    if hasattr(v, ""Items""):
        return len(v.Items)
    raise Exception(""count() expects list or group"")
",tests/dataset/tpc-ds/compiler/py/q34.py,,1,2.8453347280241004e-08,"The method _count is a utility function designed to count elements in either a list or an object with an 'Items' attribute. It is a simple and straightforward function that provides a useful operation for counting elements in different types of collections. The method is likely to survive because it serves a clear purpose, is not overly complex, and handles two common cases (lists and objects with 'Items'). Additionally, it raises an exception for unsupported types, which is a good practice for error handling. Unless there is a significant change in the requirements or the context in which this function is used, it is likely to remain useful."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q54.py,CustomerAddres,0,0.999876605372333,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose is likely to lead to confusion and errors, suggesting that the method should be deleted or re-implemented correctly."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q37.py,DateDim,0,0.9999756997690634,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check membership rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to better fit its intended purpose."
survived,"def test_TPCDS_Q10_demographics_count():
    assert result == [
        Auto1(
            cd_gender=""F"",
            cd_marital_status=""M"",
            cd_education_status=""College"",
            cnt1=1,
            cd_purchase_estimate=5000,
            cnt2=1,
            cd_credit_rating=""Good"",
            cnt3=1,
            cd_dep_count=1,
            cnt4=1,
            cd_dep_employed_count=1,
            cnt5=1,
            cd_dep_college_count=0,
            cnt6=1,
        )
    ]
",tests/dataset/tpc-ds/compiler/py/q10.py,,1,8.152020648014727e-09,"The method `test_TPCDS_Q10_demographics_count` is a test function, which is typically used to verify the correctness of a specific piece of code. Test functions are generally not deleted unless they are redundant, incorrect, or the functionality they are testing is no longer relevant. Since this function appears to be a valid test case checking the equality of a result with an expected output, it is likely to be maintained as part of the test suite to ensure code reliability."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q21.py,Item,1,1.9947301075518807e-06,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in collections like lists or dictionaries. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid use case if the object is designed to allow attribute access via indexing. However, this implementation assumes that the key provided is always a valid attribute name, which might not always be the case. Despite this limitation, the method is functional and serves a specific purpose, so it is likely to be retained unless the design requirements change significantly."
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q53.py,_Group,1,5.60279640614594e-09,"The method is a standard implementation of the __iter__ method in Python, which is used to make an object iterable. It returns an iterator over the 'Items' attribute of the object. This is a common and necessary method for classes that need to support iteration, and there is nothing incorrect or redundant about it. Therefore, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q21.py,DateDim,0,0.9999546021442518,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method is likely to lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership testing. Therefore, it is likely that this method will be deleted or significantly modified to align with its intended purpose."
survived,"def _sum(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""sum() expects list or group"")
    s = 0.0
    for it in v:
        if it is None:
            continue
        if isinstance(it, (int, float)):
            s += float(it)
        else:
            raise Exception(""sum() expects numbers"")
    return s
",tests/dataset/tpc-ds/compiler/py/q45.py,,1,5.3157849718487075e-08,"The method '_sum' is a utility function that calculates the sum of a list of numbers. It includes error handling for non-list inputs and non-numeric elements within the list. This function is likely to survive because it provides a basic yet essential functionality that is commonly needed in various applications. Additionally, it includes error handling, which makes it robust and reliable for use in different contexts."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q23.py,StoreSale,1,3.653482080241728e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q10.py,CustomerDemographic,1,6.348800075736417e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the indexing syntax (e.g., `obj[key]`). In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern and does not have any apparent issues that would necessitate its deletion. Therefore, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q29.py,CatalogSale,0,0.9999756997690634,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, especially for users familiar with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q8.py,_Group,1,5.60279640614594e-09,"The method `__len__` is a special method in Python that is used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"def _q2():
    _groups = {}
    _order = []
    for g in grouped:
        _k = Auto4(cat=g.cat, call=g.call)
        _ks = str(_k)
        g = _groups.get(_ks)
        if not g:
            g = _Group(_k)
            _groups[_ks] = g
            _order.append(_ks)
        g.Items.append(g)
    _items1 = [_groups[k] for k in _order]
    return [
        Auto3(
            cat=gg.key[""cat""],
            call=gg.key[""call""],
            avg_sales=(
                sum([x.sum_sales for x in gg]) / len([x.sum_sales for x in gg])
                if [x.sum_sales for x in gg]
                else 0
            ),
        )
        for gg in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q57.py,,1,1.8553915987649156e-07,"The method `_q2()` appears to be a utility function that processes a collection of grouped data, creating instances of `Auto3` with calculated average sales. The method is likely part of a larger codebase dealing with data processing or analysis. The function is not overly complex, and its purpose is clear, suggesting it is useful for its intended application. Unless there is a significant change in the requirements or the structure of the data being processed, there is no immediate reason to delete this method. It seems to fulfill a specific role in the codebase, which is to aggregate and compute average sales data."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q71.py,,1,2.2159489282323004e-08,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be used in various data processing scenarios, especially when dealing with in-memory data manipulation. The function is generic and flexible, allowing for different types of joins and operations based on the options provided. Such utility functions are often retained in codebases because they encapsulate common data processing patterns and can be reused across different parts of an application. Therefore, it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q27.py,CustomerDemographic,1,5.3157849718487075e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is used as a dictionary-like structure, allowing for flexible and dynamic access to its attributes. Therefore, it is likely to be retained in the code."
survived,"def test_TPCDS_Q34_simplified():
    assert result == [
        Auto1(
            c_last_name=""Smith"",
            c_first_name=""John"",
            c_salutation=""Mr."",
            c_preferred_cust_flag=""Y"",
            ss_ticket_number=1,
            cnt=16,
        )
    ]
",tests/dataset/tpc-ds/compiler/py/q34.py,,1,1.725782769012759e-08,"The method `test_TPCDS_Q34_simplified` is a test function, which is typically used to verify the correctness of a specific piece of code. Test functions are generally important for maintaining code quality and ensuring that changes do not introduce bugs. The presence of an assertion indicates that this function is checking for expected behavior, which is a crucial part of software development and maintenance. Therefore, it is likely to be retained as part of the test suite."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q19.py,Item,1,0.14804719615221756,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually implemented to check for membership in a collection like a list, set, or dictionary. However, if the class is designed to treat its attributes as keys in a collection, this implementation could be valid. Without additional context, it's difficult to determine if this is the intended use. If the class is indeed designed to treat its attributes as keys, the method might survive. Otherwise, it might be considered incorrect and subject to deletion or modification."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q55.py,StoreSale,0,0.9999785550602307,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement the intended functionality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q25.py,Auto2,0,0.999983298584886,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"def _q0():
    _src = customer
    _rows = _query(
        _src,
        [
            {
                ""items"": customer_address,
                ""on"": lambda c, ca: c.c_current_addr_sk == ca.ca_address_sk,
            },
            {
                ""items"": customer_demographics,
                ""on"": lambda c, ca, cd: c.c_current_cdemo_sk == cd.cd_demo_sk,
            },
        ],
        {
            ""select"": lambda c, ca, cd: (c, ca, cd),
            ""where"": lambda c, ca, cd: c.c_customer_sk in purchased,
        },
    )
    _groups = _group_by(
        _rows,
        lambda c, ca, cd: Auto2(
            state=ca.ca_state,
            gender=cd.cd_gender,
            marital=cd.cd_marital_status,
            dep=cd.cd_dep_count,
            emp=cd.cd_dep_employed_count,
            col=cd.cd_dep_college_count,
        ),
    )
    _items1 = _groups
    return [
        Auto1(
            ca_state=g.key[""state""],
            cd_gender=g.key[""gender""],
            cd_marital_status=g.key[""marital""],
            cd_dep_count=g.key[""dep""],
            cd_dep_employed_count=g.key[""emp""],
            cd_dep_college_count=g.key[""col""],
            cnt=len(g),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q35.py,,1,2.5109990926928157e-08,"The method '_q0' is a complex query function that seems to be part of a larger data processing or analytics system. It performs operations such as joining tables, filtering data, and grouping results based on certain criteria. These operations are common in data processing tasks, especially in business intelligence or customer analytics applications. The method is likely to be useful for generating insights or reports based on customer data, which is a valuable functionality in many systems. Therefore, it is likely to be retained unless there is a significant change in the system's requirements or architecture."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q58.py,Auto3,1,2.5109990926928157e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name, which can be useful for objects that need to provide dictionary-like access to their attributes. This method is simple, clear, and serves a specific purpose, making it likely to be retained in the codebase unless the design requirements change significantly."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q13.py,Store,0,0.9999599363048656,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list, set, or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate implementation that checks for key membership in a collection."
survived,"def population_df(pop: list[Any]) -> pd.DataFrame:
    """"""Return a DataFrame for effectiveness vs. risk vs. complexity.""""""

    return pd.DataFrame(
        {
            ""effectiveness"": [p.fitness[0] for p in pop],
            ""risk"": [p.fitness[1] for p in pop],
            ""complexity"": [p.fitness[2] for p in pop],
            ""rank"": [p.rank for p in pop],
        }
    )
",src/interface/web_app.py,,1,2.998960815863541e-09,"The method `population_df` is a utility function that converts a list of objects into a pandas DataFrame, which is a common and useful operation in data analysis and manipulation. The function is well-defined, concise, and serves a clear purpose by organizing data into a structured format that can be easily used for further analysis or visualization. Given the widespread use of pandas in data science and the utility of transforming data into DataFrames, this method is likely to be retained in the codebase."
survived,"    def __init__(self):
        self.completions = _ChatCompletions()
",openai/__init__.py,_Chat,1,1.955568070542584e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming in Python. Constructors are essential for initializing new objects and setting up initial states. There is no indication that this constructor is redundant or unnecessary, as it initializes an instance variable 'completions'. Therefore, it is unlikely to be deleted."
survived,"    def _run_tests(self, errors: List[str]) -> None:
        env = os.environ.copy()
        env[""PYTHONPATH""] = str(self.bundle_dir)
        result = subprocess.run(
            [""pytest"", ""tests"", ""-c"", ""/dev/null"", ""-x""],
            cwd=self.bundle_dir,
            capture_output=True,
            text=True,
            env=env,
        )
        if result.returncode != 0:
            errors.append(""tests failed"")
",src/meta_agent/bundle_validator.py,BundleValidator,1,1.6052280526088547e-09,"The method `_run_tests` is a utility function designed to run tests using `pytest` and append an error message to a list if the tests fail. This method is likely to survive because it serves a specific purpose in the context of a larger system, particularly in automated testing or continuous integration workflows. It is a straightforward implementation that leverages existing tools (`pytest` and `subprocess`) to achieve its goal, making it both useful and efficient. Unless there is a significant change in the testing strategy or the tools used, this method is likely to remain relevant and necessary."
survived,"    def _validate_agent(self, errors: List[str]) -> None:
        try:
            py_compile.compile(str(self.bundle_dir / ""agent.py""), doraise=True)
        except py_compile.PyCompileError as exc:
            errors.append(f""agent.py failed to compile: {exc.msg}"")
",src/meta_agent/bundle_validator.py,BundleValidator,1,2.1724399346070676e-10,"The method `_validate_agent` is likely to survive because it performs a crucial validation step by attempting to compile a Python file and appending an error message if the compilation fails. This is a common and necessary operation in many systems to ensure that code is syntactically correct before execution. The method is simple, clear, and serves a specific purpose, making it unlikely to be removed unless the entire validation process is refactored or replaced."
survived,"    def create_response(
        self,
        response_data: GraphQLHTTPResponse,
        sub_response: Response,
        is_strict: bool,
    ) -> Response:
        sub_response.text = self.encode_json(response_data)
        sub_response.content_type = (
            ""application/graphql-response+json"" if is_strict else ""application/json""
        )
        return sub_response
",src/graphql_server/webob/views.py,GraphQLView,1,1.2501528648238603e-09,"The method 'create_response' is likely to survive because it performs a specific and useful function: it formats a GraphQL HTTP response based on the strictness of the content type. This is a common requirement in web applications that deal with GraphQL APIs, where responses need to be correctly formatted and encoded. The method is concise, clear, and serves a distinct purpose, making it a valuable part of the codebase."
survived,"    def render_graphql_ide(
        self, request: Request, request_data: GraphQLRequestData
    ) -> Response:
        return Response(
            text=request_data.to_template_string(self.graphql_ide_html),
            content_type=""text/html"",
            status=200,
        )
",src/graphql_server/webob/views.py,GraphQLView,1,1.4166087846364157e-09,"The method 'render_graphql_ide' is a utility function that converts GraphQL request data into an HTML response. This is a common requirement in web applications that provide a GraphQL IDE or playground for developers to test their queries. The method is straightforward, performs a specific task, and is likely part of a larger framework or application that supports GraphQL. Given the increasing popularity of GraphQL and the need for developer tools, this method is likely to be retained as it serves a useful purpose."
survived,"    async def start(self) -> None:
        """"""Start heartbeat and regression checks.""""""
        await self.manager.start()
",alpha_factory_v1/backend/agent_scheduler.py,AgentScheduler,1,2.998960815863541e-09,"The method 'start' is an asynchronous method that initiates heartbeat and regression checks by calling 'self.manager.start()'. This suggests that it is part of a larger system where starting these checks is a necessary operation. The method is likely to be essential for the functionality of the system, especially if it involves monitoring or maintaining system health. Therefore, it is unlikely to be deleted unless the entire system or its architecture changes significantly."
survived,"    def __init__(self, ledger: Ledger, *, rng: random.Random | None = None) -> None:
        self.ledger = ledger
        self._rng = rng or random.Random()
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/mutators/llm_mutator.py,LLMMutator,1,1.8189616842444243e-09,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class. Constructors are fundamental components of class definitions in object-oriented programming and are unlikely to be removed unless the class itself is being deprecated or refactored significantly. Therefore, this method will survive."
survived,"def test_query_speed_and_histogram(tmp_path) -> None:
    arch = SolutionArchive(tmp_path / ""sol.duckdb"")
    for i in range(10000):
        arch.add(""sec"", ""app"", float(i % 100), {""i"": i})
    start = time.perf_counter()
    res = arch.query(sector=""sec"")
    duration = time.perf_counter() - start
    assert len(res) == 10000
    assert duration < 0.2
    hist = arch.diversity_histogram()
    assert hist[(""sec"", ""app"")] == 10000",tests/test_solution_archive.py,,1,2.646573631904765e-09,"The method 'test_query_speed_and_histogram' is a test function that verifies the performance and correctness of the 'SolutionArchive' class. It checks if the query method can handle a large number of entries efficiently and if the diversity histogram is accurate. Test functions are crucial for ensuring code reliability and are typically retained unless the functionality they test is removed or significantly altered. Since this function serves a clear purpose in validating performance and correctness, it is likely to be retained."
survived,"    def __init__(self, path: str | Path) -> None:
        self.path = Path(path)
        if duckdb is not None:
            self.conn = duckdb.connect(str(self.path))
        else:  # pragma: no cover - fallback
            self.conn = sqlite3.connect(str(self.path))
        self._ensure()
",src/archive/solution_archive.py,SolutionArchive,1,2.8453347280241004e-08,"The method is a constructor (__init__) for a class, which is a fundamental part of object-oriented programming in Python. Constructors are essential for initializing new objects and setting up initial state. This particular constructor is responsible for setting up a database connection using either DuckDB or SQLite, which is a common pattern for applications that need to interact with databases. The use of type hints and the fallback mechanism for database connection further indicate that this method is well-designed and likely to be retained in the codebase. Therefore, it is unlikely to be deleted."
survived,"    def __init__(self, repo: str | Path, log_dir: str | Path, registry: StakeRegistry | None = None) -> None:
        self.repo = Path(repo)
        self.log_dir = Path(log_dir)
        self.registry = registry or StakeRegistry()
        if ""meta"" not in self.registry.stakes:
            self.registry.set_stake(""meta"", 1.0)
",src/agents/meta_refinement_agent.py,MetaRefinementAgent,1,7.73442280641062e-08,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class. It sets up important attributes like 'repo', 'log_dir', and 'registry', and ensures that a default stake is set if not already present. Constructors are fundamental to object-oriented programming, and there is no indication that this particular constructor is redundant or unnecessary. Therefore, it is unlikely to be deleted."
survived,"    def _create_patch(self, bottleneck: str) -> str:
        goal = f""optimise around {bottleneck}""
        metric = self.repo / ""metric.txt""
        if metric.exists():
            try:
                current = int(float(metric.read_text().strip()))
            except Exception:
                current = 0
            new_val = current + 1
            diff = (
                ""--- a/metric.txt\n""
                ""+++ b/metric.txt\n""
                ""@@\n""
                f""-{current}\n""
                f""+{new_val}\n""
            )
            return diff
        return propose_diff(str(metric), goal)
",src/agents/meta_refinement_agent.py,MetaRefinementAgent,1,6.348800075736417e-09,"The method '_create_patch' is likely to be Survived (1) because it contains a clear and specific functionality that is useful for generating a patch or diff for a file named 'metric.txt'. It handles file reading, error catching, and string formatting to create a diff, which are common and necessary operations in software development, especially in version control and optimization tasks. The method is well-structured and serves a practical purpose, making it unlikely to be removed unless the entire approach to handling metrics changes."
survived,"def test_mutate_rejects_traversal(server: str) -> None:
    import io
    import tarfile

    buf = io.BytesIO()
    with tarfile.open(fileobj=buf, mode=""w"") as tf:
        info = tarfile.TarInfo(name=""../evil.txt"")
        data = b""bad""
        info.size = len(data)
        tf.addfile(info, io.BytesIO(data))
    buf.seek(0)

    with httpx.Client(base_url=server) as client:
        files = {""tar"": (""bad.tar"", buf.read())}
        r = client.post(""/mutate"", files=files)
        assert r.status_code == 400",tests/test_evolution_worker_safe_extract.py,,1,3.2241866333029355e-08,"The method 'test_mutate_rejects_traversal' is a test function designed to ensure that a server correctly rejects a tar file containing a file path traversal attempt. This is a security-related test, which is crucial for maintaining the integrity and security of the server. Such tests are important to prevent vulnerabilities and ensure that the server behaves as expected when faced with potentially malicious input. Therefore, it is unlikely that this method will be deleted, as it serves an important role in the security testing of the application."
survived,"    def run(self) -> None:
        pass
",tests/resources/openai_agents.py,AgentRuntime,0,0.9999977396747258,"The method 'run' is defined but not implemented, as it only contains a 'pass' statement. This suggests that it is a placeholder for future code. If this method is part of a larger class or module that is still under development, it might be retained for future implementation. However, if the method remains unimplemented and unused, it is likely to be deleted in a cleanup process to maintain code quality. Without additional context, it's more likely to be deleted if it remains unused."
survived,"def add(a: int, b: int) -> int:
    return a + b
",tests/human/python/fun_call.py,,1,3.850741907939403e-09,"The method 'add' is a simple and fundamental utility function that performs addition of two integers. Such basic arithmetic operations are commonly used in various applications and are unlikely to be removed unless they are redundant or replaced by a more efficient or necessary implementation. However, given its simplicity and utility, it is more likely to be retained as it serves a clear purpose."
survived,"def test_capability_growth_curves() -> None:
    """"""Capability growth curves should map time into [0,1].""""""
    t = 0.5
    linear = forecast.capability_growth(t, curve=""linear"")
    logistic = forecast.capability_growth(t, curve=""logistic"")
    exponential = forecast.capability_growth(t, curve=""exponential"")
    assert linear == pytest.approx(forecast.linear_curve(t))
    assert logistic == pytest.approx(forecast.logistic_curve(10 * t))
    assert exponential == pytest.approx(forecast.exponential_curve(t))
    assert logistic > linear > exponential
    assert 0.0 <= exponential <= 1.0
    assert 0.0 <= linear <= 1.0
    assert 0.0 <= logistic <= 1.0
",tests/test_forecast.py,,1,2.3355930333443423e-09,"The method `test_capability_growth_curves` is a unit test designed to verify the behavior of the `capability_growth` function with different curve types. It checks that the output of the function is within the expected range [0,1] and compares it against specific curve implementations. This is a typical and necessary part of software testing to ensure the correctness of the code. Since it serves a clear purpose in validating the functionality of the code, it is likely to be retained."
survived,"    def test_create_parse_plan_invalid_segment(self):
        with self.assertRaises(ParseException) as cm:
            hl7.parser.create_parse_plan(""PID|^~\\&|GHH LAB"")
        self.assertIn(""must be one of MSH, FHS or BHS"", cm.exception.args[0])",tests/test_parse.py,ParsePlanTest,1,8.152020648014727e-09,"The method is a unit test designed to verify that the `create_parse_plan` function raises a `ParseException` when given an invalid segment. This is a valid and useful test case to ensure the robustness of the `create_parse_plan` function. It checks that the function correctly handles invalid input by raising the appropriate exception, which is a common and necessary practice in software testing. Therefore, the method is likely to be retained as it contributes to the overall quality and reliability of the codebase."
survived,"def test_index_html_has_closing_tags() -> None:
    browser_dir = Path(__file__).resolve().parents[1]
    html = (browser_dir / ""dist"" / ""index.html"").read_text().splitlines()
    assert html[-2].strip() == ""</body>""
    assert html[-1].strip() == ""</html>""
    joined = ""\n"".join(html)
    assert ""window.PINNER_TOKEN"" in joined",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_closing_tags.py,,1,2.0611536181902033e-09,"The method `test_index_html_has_closing_tags` is a test function that checks the integrity of an HTML file by ensuring it has the correct closing tags and contains a specific token. This is a useful test to ensure that the HTML file is properly structured and includes necessary elements for functionality. Such tests are important for maintaining code quality and preventing runtime errors due to malformed HTML. Therefore, it is likely to be retained in the codebase."
survived,"    def setUp(self):
        os.environ[""VECTOR_STORE_USE_SQLITE""] = ""true""
        os.environ.pop(""PGHOST"", None)
        self.fabric = memf.MemoryFabric()
        memf._MET_V_SRCH = None
",tests/test_memory_fabric_sqlite.py,TestMemoryFabricSQLiteClose,1,8.31527990378713e-07,"The method `setUp` is a common method used in unit testing frameworks like `unittest` in Python. It is typically used to set up the test environment before each test case is run. The code provided is setting environment variables and initializing an object, which are typical tasks performed in a `setUp` method. This method is likely part of a test suite and is essential for preparing the test environment, so it is unlikely to be deleted unless the entire test suite is being refactored or removed."
survived,"    def test_search_text_glob_with_special_chars(self):
        """"""Glob patterns containing regex special characters should match literally.""""""
        content = """"""
        def func_square():
            print(""value[42]"")

        def func_curly():
            print(""value{bar}"")
        """"""

        matches_square = search_text(r""*\[42\]*"", content=content, is_glob=True)
        assert len(matches_square) == 1
        assert ""[42]"" in matches_square[0].lines[0].line_content

        matches_curly = search_text(""*{bar}*"", content=content, is_glob=True)
        assert len(matches_curly) == 1
        assert ""{bar}"" in matches_curly[0].lines[0].line_content
",test/serena/test_text_utils.py,TestSearchText,1,2.5109990926928157e-08,"The method 'test_search_text_glob_with_special_chars' is a unit test designed to verify the functionality of a search function that uses glob patterns. It specifically tests the handling of special characters in glob patterns, ensuring they match literally. This is a common and necessary test case to ensure the robustness of the search functionality, especially when dealing with patterns that could be misinterpreted as regex. Since it serves a clear purpose in validating the correct behavior of the search function, it is likely to be retained in the codebase."
survived,"def test_skip_backup_when_worker_has_no_space(tmp_path):
    db_path = tmp_path / ""db.sqlite""
    config[""storage""][""database""] = str(db_path)

    conn = sqlite3.connect(db_path)
    conn.execute(""CREATE TABLE t(id INTEGER)"")
    conn.commit()
    conn.close()

    output = tmp_path / ""backup.sqlite""

    with (
        patch(
            ""pioreactor.actions.leader.backup_database.long_running_managed_lifecycle"",
            dummy_lifecycle,
        ),
        patch(
            ""pioreactor.actions.leader.backup_database.create_logger"",
            return_value=MagicMock(),
        ),
        patch(
            ""pioreactor.actions.leader.backup_database.get_active_workers_in_inventory"",
            return_value=[""worker1""],
        ),
        patch(
            ""pioreactor.actions.leader.backup_database._remote_available_space"",
            return_value=0,
        ),
        patch(
            ""pioreactor.actions.leader.backup_database.rsync"",
        ) as mock_rsync,
    ):
        backup_database(str(output), force=True, backup_to_workers=1)
        mock_rsync.assert_not_called()",pioreactor/tests/test_backup_database.py,,1,9.237449576640118e-09,"The method is a test function that verifies the behavior of a backup process when there is no space available on the worker. It uses mocking to simulate the environment and checks that the rsync function is not called when there is no space. This is a valid and useful test case to ensure the backup process handles space constraints correctly. Therefore, it is likely to be retained."
survived,"def test_tracehub_broadcast():
    event = asyncio.run(_run_broadcast())
    assert event[""label""] == ""hi""
    assert event[""type""] == ""tool_call""
",tests/test_trace_hub.py,,1,2.8453347280241004e-08,"The method `test_tracehub_broadcast` is a test function that uses assertions to verify the behavior of the `_run_broadcast` function. Test functions are generally important for ensuring code reliability and correctness, especially in a development environment where continuous integration and testing are crucial. Since this function is part of a test suite, it is likely to be maintained and updated rather than deleted, as it helps in validating the functionality of the code it tests."
survived,"def _require_openai_agents() -> None:
    """"""Ensure the ``openai_agents`` package is available.

    Attempts an automatic install via :mod:`check_env` when the package is
    missing so the bridge remains usable in fresh environments or Colab
    runtimes. Any installation errors are surfaced to the user.
    """"""

    try:  # soft dependency
        import openai_agents  # type: ignore
    except ModuleNotFoundError:  # pragma: no cover - optional dep
        try:
            import check_env

            print(""  openai_agents missing  attempting auto-install"")
            check_env.main([""--auto-install""])
        except Exception as exc:  # pragma: no cover - install failed
            sys.stderr.write(
                f""\n  openai_agents not installed and auto-install failed: {exc}\n""
            )
            sys.stderr.write(""   Install manually with 'pip install openai-agents'\n"")
            sys.exit(1)
        try:
            import openai_agents  # type: ignore  # noqa: F401
        except ModuleNotFoundError:
            sys.stderr.write(
                ""\n  openai_agents still missing after auto-install.\n""
            )
            sys.stderr.write(""   Install manually with 'pip install openai-agents'\n"")
            sys.exit(1)
",alpha_factory_v1/demos/alpha_agi_business_v1/openai_agents_bridge.py,,1,8.152020648014727e-09,"The method `_require_openai_agents` is designed to ensure that the `openai_agents` package is available by attempting an automatic installation if it is not found. This is a useful utility function for environments where dependencies might not be pre-installed, such as in fresh environments or cloud-based runtimes like Google Colab. The method provides a fallback mechanism to handle missing dependencies gracefully, which is a common requirement in dynamic or user-driven environments. Given its utility in ensuring smooth operation and user experience, it is likely to be retained in the codebase."
survived,"def main() -> None:
    runtime = AgentRuntime(api_key=None)
    agent = CrossIndustryAgent()
    runtime.register(agent)
    try:
        from alpha_factory_v1.backend.adk_bridge import auto_register, maybe_launch

        auto_register([agent])
        maybe_launch()
    except Exception as exc:  # pragma: no cover - ADK optional
        print(f""ADK bridge unavailable: {exc}"")

    print(""Registered CrossIndustryAgent with runtime"")
    runtime.run()
",alpha_factory_v1/demos/cross_industry_alpha_factory/openai_agents_bridge.py,,1,4.599055376537186e-10,"The method is likely to survive because it contains a well-structured implementation of a main function that initializes and registers an agent with a runtime. It also includes error handling for optional components, which is a good practice. The code is clear, functional, and does not contain any deprecated or obsolete practices that would warrant deletion."
survived,"def _read_log(limit: int) -> List[Dict[str, str]]:
    path = _ledger_path(None)
    try:
        data = json.loads(Path(path).read_text())
        if isinstance(data, dict):
            data = [data]
        return data[-limit:]
    except Exception:  # pragma: no cover - missing or invalid log
        return []
",alpha_factory_v1/demos/cross_industry_alpha_factory/openai_agents_bridge.py,,1,8.76424914819242e-08,"The method '_read_log' is a utility function that reads a log file and returns the last 'limit' number of entries. It handles exceptions gracefully by returning an empty list if any error occurs, such as a missing or invalid log file. This kind of functionality is often useful in applications that need to process or display recent log entries, making it a candidate for survival. Additionally, the use of type hints and exception handling suggests that the code is well-structured and likely to be maintained."
survived,"    def test_cross_industry_bridge_compiles(self):
        """"""Ensure the cross-industry demo bridge compiles.""""""
        path = Path('alpha_factory_v1/demos/cross_industry_alpha_factory/openai_agents_bridge.py')
        py_compile.compile(path, doraise=True)
",tests/test_openai_bridge.py,TestOpenAIBridge,1,8.152020648014727e-09,"The method `test_cross_industry_bridge_compiles` is a unit test that ensures a specific Python script compiles without syntax errors. This is a basic but important test to ensure that the code is syntactically correct before running more complex tests or deploying the code. Such tests are generally useful in a development environment to catch errors early in the development process. Therefore, it is likely to be retained as part of the test suite."
survived,"    def setUp(self) -> None:
        self.temp_files: list[Path] = []
        self.env_vars: dict[str, str] = {}
",tests/test_alpha_opportunity_env.py,TestAlphaOpportunityEnv,1,6.825604231969389e-08,"The method `setUp` is a common method used in unit testing frameworks like `unittest` in Python. It is typically used to set up any state or configuration needed before each test method is run. The presence of `self.temp_files` and `self.env_vars` suggests that this method is preparing a list for temporary files and a dictionary for environment variables, which are likely used in the tests. This setup is crucial for ensuring that each test runs in a clean and controlled environment. Therefore, it is unlikely that this method will be deleted as it serves an important purpose in the testing lifecycle."
survived,"def _start_server(directory: Path):
    handler = partial(http.server.SimpleHTTPRequestHandler, directory=str(directory))
    server = http.server.ThreadingHTTPServer((""localhost"", 0), handler)
    thread = threading.Thread(target=server.serve_forever, daemon=True)
    thread.start()
    return server, thread
",tests/test_pwa_offline.py,,1,1.725782769012759e-08,"The method _start_server is a utility function that sets up a simple HTTP server using Python's built-in http.server module. It is a useful function for quickly starting a server to serve files from a specified directory, which can be particularly handy for development and testing purposes. The use of threading allows the server to run in the background without blocking the main program. Given its utility and the fact that it leverages standard library components effectively, it is likely to be retained in the codebase."
survived,"def test_stream_options_injected_for_openai_base_url_sync() -> None:
    captured = {}

    def dummy_fn(completion, **kwargs):
        captured.update(kwargs)
        return ""ok""

    wrapped = create_wrapper_sync(OpSettings())(dummy_fn)

    wrapped(DummyCompletion(""https://api.openai.com""), stream=True)

    assert captured.get(""stream_options"") == {""include_usage"": True}
",tests/integrations/openai/test_openai_sdk.py,,1,8.152020648014727e-09,"The method `test_stream_options_injected_for_openai_base_url_sync` is a test function that checks if the `stream_options` are correctly injected when a specific URL is used. It uses a dummy function and a wrapper to simulate the behavior and asserts the expected outcome. Test functions are generally not deleted unless they are redundant or incorrect. Since this test seems to be correctly checking a specific functionality, it is likely to be retained."
survived,"def test_dslice_oob_read_and_write():
    Seq = hax.Axis(""seq"", 5)
    from haliax import ds

    arr = hax.arange((Seq,), dtype=int)
    out = arr[{""seq"": ds(3, 4)}]
    ref = jnp.take(arr.array, jnp.arange(3, 7), mode=""fill"", fill_value=0)
    assert jnp.array_equal(out.array, ref)

    upd = hax.arange((Seq.resize(4),), dtype=int)
    updated = arr.at[{""seq"": ds(3, 4)}].set(upd)
    ref_upd = arr.array.at[jnp.arange(3, 7)].set(upd.array, mode=""drop"")
    assert jnp.array_equal(updated.array, ref_upd)
",tests/core_test.py,,1,6.825604231969389e-08,"The method 'test_dslice_oob_read_and_write' is a test function, which is typically used to verify the correctness of code. Test functions are generally retained in codebases to ensure that the functionality they are testing continues to work as expected. This function appears to be testing the behavior of a slicing operation and an update operation on a data structure, likely to ensure that out-of-bounds reads and writes are handled correctly. Since maintaining test coverage is important for software reliability, it is unlikely that this method will be deleted."
survived,"def test_improve_repo_cleanup(tmp_path: Path) -> None:
    repo_dir = tmp_path / ""repo""
    repo_dir.mkdir()
    _init_repo(repo_dir)

    patch = """"""--- a/metric.txt\n+++ b/metric.txt\n@@\n-1\n+2\n""""""
    patch_file = tmp_path / ""patch.diff""
    patch_file.write_text(patch)
    log_file = tmp_path / ""log.json""

    delta, clone = self_improver.improve_repo(
        str(repo_dir), str(patch_file), ""metric.txt"", str(log_file), cleanup=True
    )

    assert delta == 1
    assert not clone.exists()
",tests/test_self_improver.py,,1,1.8553915987649156e-07,"The method 'test_improve_repo_cleanup' is a unit test function that verifies the behavior of the 'improve_repo' function from the 'self_improver' module. It checks if the repository is correctly cleaned up after applying a patch. The test is well-structured, uses temporary paths to avoid side effects, and includes assertions to validate the expected outcomes. Since it is a test function, it is crucial for ensuring the reliability and correctness of the code it tests. Therefore, it is unlikely to be deleted unless the functionality it tests is removed or significantly changed."
survived,"async def file_rename_on_frame(frame_id: int, src: str, dst: str, timeout: int = 60):
    """"""Rename a file or directory on the frame via agent.""""""
    payload = {
        ""type"": ""cmd"",
        ""name"": ""file_rename"",
        ""args"": {""src"": src, ""dst"": dst},
    }
    fut, _ = queue_command(frame_id, payload)
    return await asyncio.wait_for(fut, timeout=timeout)
",backend/app/ws/agent_ws.py,,1,1.8189616842444243e-09,"The method 'file_rename_on_frame' is a well-defined asynchronous function that performs a specific task of renaming a file or directory on a frame via an agent. It uses a payload to send a command and waits for the operation to complete with a specified timeout. This functionality is likely to be useful in scenarios where file management is required in an asynchronous environment, such as in web applications or services that handle file operations. The method is also flexible with a default timeout parameter, making it adaptable to different use cases. Therefore, it is likely to be retained in the codebase."
survived,"def _rich_table(headers: Iterable[str], rows: Iterable[Iterable[Any]]) -> None:
    if console and Table:
        table = Table(show_header=True, header_style=""bold cyan"")
        for h in headers:
            table.add_column(str(h))
        for row in rows:
            table.add_row(*[str(v) for v in row])
        console.print(table)
    else:
        click.echo(_plain_table(headers, rows))
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/cli.py,,1,2.7894680920908113e-10,"The method '_rich_table' is likely to survive because it provides a useful functionality of displaying data in a formatted table using the 'rich' library, which is a popular and modern way to enhance console output. The method also includes a fallback to a plain table display using 'click', ensuring it remains functional even if 'rich' is not available. This adaptability and enhancement of user experience make it a valuable method to retain."
survived,"    def slash(self, agent_id: str) -> None:
        """"""Burn 10% of ``agent_id`` stake.""""""
        self.registry.burn(agent_id, 0.1)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/orchestrator.py,Orchestrator,1,1.6052280526088547e-09,"The method 'slash' is a straightforward implementation that calls another method 'burn' on a 'registry' object, passing an 'agent_id' and a fixed percentage (0.1) to burn. This method is likely part of a larger system dealing with stakes or tokens, and the functionality it provides is clear and specific. Unless there is a change in the system's requirements or the method is found to be redundant, it is likely to be retained. Therefore, it will survive."
survived,"    def total(self) -> float:
        """"""Return total stake across all agents.""""""
        return float(sum(self.stakes.values()))
",src/governance/stake_registry.py,StakeRegistry,1,3.850741907939403e-09,"The method 'total' is a simple utility function that calculates the sum of values in a dictionary and returns it as a float. It is likely to be useful in contexts where the total stake needs to be calculated frequently, such as in financial applications or simulations involving multiple agents. The method is straightforward, efficient, and serves a clear purpose, making it unlikely to be deleted unless the entire functionality it supports is removed or significantly refactored."
survived,"def test_archive_migration(TestArchiveMigration) -> None:
    entries = [
        {""hash"": ""a"", ""parent"": None, ""score"": 0.3, ""novelty"": 0.1, ""is_live"": True, ""ts"": 1.0},
        {""hash"": ""b"", ""parent"": ""a"", ""score"": 0.4, ""novelty"": 0.2, ""is_live"": False, ""ts"": 2.0},
    ]
    db = TestArchiveMigration(entries)
    assert db.get(""a"") is not None
    assert db.get(""b"").parent == ""a""",tests/test_archive.py,,1,3.3982678079468468e-09,"The method `test_archive_migration` is a test function that verifies the behavior of the `TestArchiveMigration` class. It checks if the entries are correctly initialized and if the parent-child relationship is maintained. Test functions are crucial for ensuring code reliability and are typically retained unless the functionality they test is deprecated or the testing framework changes. Since there is no indication that the functionality is obsolete or the testing framework is changing, it is likely that this method will survive."
survived,"    def get(self, h: str) -> ArchiveEntry | None:
        with Session(self.engine) as session:
            row = session.get(_ArchiveRow, h)
            if row is None:
                return None
            return ArchiveEntry(
                hash=row.hash,
                parent=row.parent,
                score=row.score,
                novelty=row.novelty,
                is_live=row.is_live,
                ts=row.ts,
            )
",src/archive/db.py,ArchiveDB,1,1.2501528648238603e-09,"The method 'get' is a typical implementation of a data retrieval function using an ORM (Object-Relational Mapping) pattern. It is designed to fetch a record from a database using a session and return an object of type 'ArchiveEntry'. This is a common and necessary operation in applications that interact with databases, as it encapsulates the logic for retrieving and converting database rows into application-level objects. The method is straightforward, follows good practices, and there is no indication of redundancy or obsolescence. Therefore, it is likely to be retained in the codebase."
survived,"def select_parent(population: Sequence[Any], temp: float) -> Any:
    """"""Return a candidate chosen via softmax of ``fitness * novelty``.

    Args:
        population: Sequence of candidates exposing ``fitness`` and ``novelty`` attributes.
        temp: Softmax temperature. Higher values yield a more uniform distribution.

    Returns:
        The selected candidate from ``population``.
    """"""
    if not population:
        raise ValueError(""population is empty"")
    if temp <= 0:
        raise ValueError(""temp must be positive"")

    scores = np.asarray([float(getattr(ind, ""fitness"")) * float(getattr(ind, ""novelty"")) for ind in population])
    logits = scores / temp
    weights = np.exp(logits - np.max(logits))
    probs = weights / weights.sum()

    index = int(np.random.choice(len(population), p=probs))
    return population[index]",src/archive/selector.py,,1,4.363462233903899e-09,"The method `select_parent` is well-defined and serves a specific purpose in evolutionary algorithms by selecting a candidate based on a combination of fitness and novelty. It includes error handling for edge cases, such as an empty population or non-positive temperature, which indicates robustness. The use of softmax for probabilistic selection is a common and effective approach in such contexts. Therefore, there is no apparent reason for this method to be deleted, as it is functional, useful, and follows good coding practices."
survived,"def secure_run(cmd: Sequence[str]) -> subprocess.CompletedProcess[str]:
    """"""Execute ``cmd`` under ``firejail`` or ``docker`` constraints.

    The sandbox runs with seccomp, ``2`` CPU cores, ``2``GB of RAM and a
    ``120``second timeout. When the command exceeds the timeout a
    :class:`SandboxTimeout` is raised.
    """"""

    timeout = 120
    firejail = shutil.which(""firejail"")
    if firejail:
        full_cmd = [
            firejail,
            ""--quiet"",
            ""--net=none"",
            ""--private"",
            ""--seccomp"",
            ""--rlimit-as=2147483648"",
            ""--rlimit-cpu=120"",
            *cmd,
        ]
    else:
        docker = shutil.which(""docker"")
        if docker:
            full_cmd = [
                docker,
                ""run"",
                ""--rm"",
                ""--network=none"",
                ""--cpus=2"",
                ""--memory=2g"",
                ""--security-opt"",
                ""seccomp=unconfined"",
                ""python:3.11-slim"",
                *cmd,
            ]
        else:
            full_cmd = list(cmd)
    try:
        return subprocess.run(
            full_cmd,
            text=True,
            capture_output=True,
            timeout=timeout,
        )
    except subprocess.TimeoutExpired as exc:  # pragma: no cover - runtime failure
        raise SandboxTimeout(str(exc)) from exc",src/utils/secure_run.py,,1,2.998960815863541e-09,"The method 'secure_run' is likely to survive because it provides a secure way to execute commands with resource constraints using either 'firejail' or 'docker'. This is a valuable functionality for running potentially unsafe code in a controlled environment, which is a common requirement in many applications. The method is well-documented, handles exceptions, and provides a fallback if neither 'firejail' nor 'docker' is available, making it robust and versatile."
survived,"def test_detect_backtrack(tmp_path) -> None:
    db_path = tmp_path / ""arch.db""
    db = ArchiveDB(db_path)
    db.add(ArchiveEntry(""a"", None, 0.5, 0.0, True, 0.0))
    db.add(ArchiveEntry(""b"", ""a"", 0.6, 0.0, True, 1.0))
    db.add(ArchiveEntry(""c"", ""b"", 0.4, 0.0, True, 2.0))
    counts = ab.count_backtracks(db_path)
    assert any(c > 0 for c in counts)",tests/test_analyse_backtrack.py,,1,1.637377179507321e-07,"The method `test_detect_backtrack` is a unit test function that is designed to test the functionality of detecting backtracks in a database. It uses a temporary path to create a database, adds entries to it, and then checks if the backtrack count is greater than zero. This is a typical structure for a test function, and unless the functionality it tests is removed or significantly altered, the test itself is likely to be retained. Test functions are generally kept as long as they are relevant to the codebase, as they help ensure the correctness of the code."
survived,"def test_suspicious_output_logs(monkeypatch, tmp_path, caplog):
    fake_client = MagicMock()
    fake_client.ping.return_value = None
    container = MagicMock()
    container.wait.return_value = {""StatusCode"": 0}
    container.logs.side_effect = [b""Traceback error"", b""""]
    fake_client.containers.run.return_value = container

    monkeypatch.setattr(sm.docker, ""from_env"", lambda: fake_client)
    manager = SandboxManager()
    code_dir = tmp_path / ""code""
    code_dir.mkdir()
    with caplog.at_level(""WARNING"", logger=""meta_agent.sandbox.sandbox_manager""):
        manager.run_code_in_sandbox(code_dir, [""python""])
    assert any(""Suspicious output"" in r.getMessage() for r in caplog.records)",tests/unit/test_sandbox_manager.py,,1,7.194132978569833e-09,"The method 'test_suspicious_output_logs' is a unit test designed to verify that the logging mechanism correctly identifies and logs 'Suspicious output' when a container logs a 'Traceback error'. This is a specific test case that ensures the functionality of the logging system in the presence of error messages. Such tests are crucial for maintaining the reliability and robustness of the system, especially in error handling scenarios. Therefore, it is likely to be retained as part of the test suite to ensure ongoing quality assurance."
survived,"def pytest_pyfunc_call(pyfuncitem):
    test_func = pyfuncitem.obj
    if inspect.iscoroutinefunction(test_func):
        asyncio.run(test_func(**pyfuncitem.funcargs))
        return True
    return None",pytest_asyncio.py,,1,8.592166611791576e-10,"The method `pytest_pyfunc_call` is a custom hook implementation for pytest, which is a widely used testing framework in Python. This method is designed to handle coroutine functions, which are becoming increasingly common with the rise of asynchronous programming in Python. The method checks if the test function is a coroutine and runs it using `asyncio.run`, which is a standard way to execute asynchronous code. This functionality is essential for testing asynchronous code, and as such, it is likely to be retained or even further developed to support more features. Therefore, the method is likely to survive."
survived,"def pytest_configure(config):
    config.addinivalue_line(
        ""markers"", ""asyncio: mark a test as running with asyncio""
    )
",pytest_asyncio.py,,1,2.2159489282323004e-08,"The method `pytest_configure` is used to add a custom marker to pytest, which is a common practice to extend pytest's functionality. The marker 'asyncio' is used to indicate that a test should be run with asyncio, which is useful for testing asynchronous code. This is a standard and useful feature for those working with asynchronous programming in Python, and there is no indication that this functionality is deprecated or unnecessary. Therefore, it is likely to be retained."
survived,"    def __init__(self, stream=None, level: LogLevel = LogLevel.DEBUG):
        super().__init__(level)
        self.stream = stream or os.sys.stdout
",webscout/litlogger/handlers.py,ConsoleHandler,1,7.73442280641062e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting up initial states. This particular constructor sets up logging with a specified stream and log level, which is a common requirement in many applications. Therefore, it is unlikely to be deleted as it serves a crucial purpose in the class design."
survived,"    def trace(self, message: str):
        self.log(LogLevel.TRACE, message)
",webscout/litlogger/logger.py,Logger,1,1.8189616842444243e-09,"The method 'trace' is a simple utility function that logs a message at the TRACE level. Such methods are common in logging frameworks to provide detailed information about the application's execution for debugging purposes. Since logging is a crucial part of software development for monitoring and debugging, this method is likely to be retained as it serves a specific purpose in the logging mechanism."
survived,"    def error(self, message: str):
        self.log(LogLevel.ERROR, message)
",webscout/litlogger/logger.py,Logger,1,6.69158608681505e-10,"The method 'error' is a simple utility function that logs an error message using a predefined log level. Such methods are common in logging frameworks to provide a convenient way to log messages at different severity levels. Since logging is a fundamental part of software development for debugging and monitoring, this method is likely to be retained as it provides a clear and specific function within the logging system."
survived,"    def fake_fetch(url):
        raise RuntimeError(""fail"")
",libs/core/kiln_ai/adapters/test_remote_config.py,,0,0.999999997664407,"The method `fake_fetch` is designed to always raise a `RuntimeError` with the message ""fail"" whenever it is called. This makes it non-functional for any practical use, as it does not perform any operations other than raising an exception. Such methods are typically used for testing purposes, to simulate failure scenarios. However, in a production codebase, a method that only raises an exception without any conditional logic or additional functionality is likely to be removed or replaced with a more useful implementation. Therefore, the method is predicted to be deleted."
survived,"def test_load_from_url():
    sample = [built_in_models[0].model_dump(mode=""json"")]

    class FakeResponse:
        def raise_for_status(self):
            pass

        def json(self):
            return {""model_list"": sample}

    with patch(
        ""kiln_ai.adapters.remote_config.requests.get"", return_value=FakeResponse()
    ):
        models = load_from_url(""http://example.com/models.json"")
    assert [m.model_dump(mode=""json"") for m in models] == sample
",libs/core/kiln_ai/adapters/test_remote_config.py,,1,3.581747929000289e-10,"The method 'test_load_from_url' is a unit test designed to verify the functionality of the 'load_from_url' function. It uses mocking to simulate a network request and checks if the function correctly processes the response. Unit tests are crucial for ensuring code reliability and are typically maintained as long as the functionality they test is relevant. Since this test is directly tied to the 'load_from_url' function, it is likely to survive unless the function itself is removed or significantly altered."
survived,"def load_from_url(url: str) -> List[KilnModel]:
    response = requests.get(url, timeout=10)
    response.raise_for_status()
    data = response.json()
    if isinstance(data, list):
        model_data = data
    else:
        model_data = data.get(""model_list"", [])
    return [KilnModel.model_validate(item) for item in model_data]
",libs/core/kiln_ai/adapters/remote_config.py,,1,6.69158608681505e-10,"The method 'load_from_url' is likely to survive because it performs a common and useful task of fetching data from a URL, handling the response, and processing the data into a list of KilnModel objects. This functionality is essential in many applications that require data retrieval from web services or APIs. Additionally, the method includes error handling with 'raise_for_status', which is a good practice for robust code. Unless there are changes in the requirements or the KilnModel class, this method is likely to remain useful."
survived,"def main() -> None:
    parser = argparse.ArgumentParser()
    parser.add_argument(""path"", help=""output path"")
    args = parser.parse_args()
    dump_builtin_config(args.path)
",libs/core/kiln_ai/adapters/remote_config.py,,1,2.699578619062706e-07,"The method 'main' is a simple command-line interface (CLI) setup using the argparse module, which is a common and useful pattern in Python scripts. It parses a single argument 'path' and then calls a function 'dump_builtin_config' with this path. This kind of method is typically used in scripts that are intended to be run from the command line to perform a specific task, such as dumping configuration data to a specified path. Since this is a standard and useful pattern for creating CLI tools in Python, it is likely to be retained unless there is a specific reason to remove it, such as a change in the way the script is intended to be used or a refactor that consolidates this functionality elsewhere."
survived,"        def fake_import(name, globals=None, locals=None, fromlist=(), level=0):
            if name == ""openai_agents"":
                raise ModuleNotFoundError(name)
            return orig_import(name, globals, locals, fromlist, level)
",tests/test_aiga_agents_import.py,TestAigaAgentsImport,0,0.9980732656706854,"The method 'fake_import' is a custom implementation of the import mechanism, specifically designed to raise a ModuleNotFoundError when attempting to import a module named 'openai_agents'. This kind of function is typically used for testing purposes, to simulate the absence of certain modules. Such methods are often temporary and used in specific testing scenarios, which suggests that it might not be a permanent part of the codebase. However, the method itself is functional and serves a specific purpose, which could justify its retention if the testing scenario is still relevant. Without more context on the overall project and its testing needs, it's difficult to definitively predict its deletion. However, given its specific and limited use case, it is more likely to be deleted once its purpose is fulfilled."
survived,"def test_set_rule_aliases():
    scraper = AutoScraper()
    scraper.build(html=HTML, wanted_list=[""Banana""])
    rule_id = scraper.stack_list[0][""stack_id""]
    scraper.set_rule_aliases({rule_id: ""fruit""})
    result = scraper.get_result_similar(html=HTML, group_by_alias=True, contain_sibling_leaves=True)
    assert result == {""fruit"": [""Banana"", ""Apple"", ""Orange""]}
",tests/unit/test_additional_features.py,,1,1.0467401685178159e-08,"The method 'test_set_rule_aliases' is a test function that verifies the functionality of setting rule aliases in the AutoScraper library. It is a useful test to ensure that the aliasing feature works correctly, which is important for organizing and retrieving scraped data efficiently. Since it serves a clear purpose in testing a specific feature of the library, it is likely to be maintained as part of the test suite to ensure ongoing reliability of the codebase."
survived,"    def findParent(self):
        return self.parent
",tests/conftest.py,_Node,1,1.2501528648238603e-09,"The method 'findParent' is a simple getter method that returns the 'parent' attribute of an object. Such methods are typically retained in codebases because they encapsulate access to an object's properties, which is a good practice in object-oriented programming. This method is likely to be used in various parts of the code where the 'parent' attribute needs to be accessed, making it useful and necessary for maintaining encapsulation and potentially for future modifications or extensions. Therefore, it is likely to survive."
survived,"def test_regex_name_extraction():
    scraper = AutoScraper()
    scraper.build(html=HTML_PAGE_1, wanted_list=[re.compile(r"".*PlayStation.*Console.*"")])
    result = scraper.get_result_exact(html=HTML_PAGE_1)
    assert any(""PlayStation"" in r for r in result)
",tests/integration/test_real_world.py,,1,2.5109990926928157e-08,"The method 'test_regex_name_extraction' is a unit test function that uses the AutoScraper library to extract data from HTML using a regular expression. It is a specific test case that checks if the scraper can correctly identify and extract elements containing 'PlayStation' from a given HTML page. This is a useful test for ensuring the functionality of the scraper when dealing with regex-based extraction. Since it serves a clear purpose in validating the scraper's capabilities, it is likely to be maintained as part of the test suite."
survived,"def test_keep_blank_returns_empty():
    scraper = AutoScraper()
    scraper.build(html=HTML_COMPLEX, wanted_list=[""/shop""])
    html_blank = HTML_COMPLEX.replace('href=""/shop""', 'href=""""')
    result = scraper.get_result_exact(html=html_blank, keep_blank=True)
    assert result == [""""]
",tests/integration/test_complex_features.py,,1,1.2501528648238603e-09,"The method 'test_keep_blank_returns_empty' is a unit test designed to verify the functionality of the 'AutoScraper' class, specifically the 'get_result_exact' method with the 'keep_blank' parameter set to True. This test ensures that when a link is replaced with an empty string, the scraper correctly returns a list containing an empty string. This is a valid and useful test case to ensure the scraper handles blank links as expected. Therefore, the method is likely to be retained as it serves a specific purpose in testing the scraper's functionality."
survived,"def test_attr_fuzz_ratio():
    html_base = '<div><a class=""btn-primary"" href=""/item"">Buy</a></div>'
    html_variant = '<div><a class=""btn-prime"" href=""/item"">Buy</a></div>'
    scraper = AutoScraper()
    scraper.build(html=html_base, wanted_list=[""Buy""])
    res = scraper.get_result_exact(html=html_variant, attr_fuzz_ratio=0.8)
    assert res == [""Buy""]",tests/integration/test_complex_features.py,,1,2.3355930333443423e-09,"The method 'test_attr_fuzz_ratio' is a test function that checks the functionality of the 'AutoScraper' library, specifically the 'attr_fuzz_ratio' parameter. This parameter likely allows for some flexibility in matching attributes, which is a useful feature for web scraping when dealing with slight variations in HTML. The test is straightforward and serves a clear purpose in ensuring that the scraper can handle attribute variations. Since it is a test function, it is unlikely to be deleted unless the feature it tests is removed or significantly changed. Therefore, the method will likely survive."
survived,"def test_keep_blank_for_missing_rating():
    scraper = AutoScraper()
    scraper.build(html=HTML_PAGE_1, wanted_list=[""4.8""])
    html_no_rating = HTML_PAGE_2.replace(""5.0"", """")
    res = scraper.get_result_exact(html=html_no_rating, keep_blank=True)
    assert res == [""""]
",tests/integration/test_real_world.py,,1,2.646573631904765e-09,"The method 'test_keep_blank_for_missing_rating' is a unit test designed to verify the functionality of the 'AutoScraper' library, specifically the 'get_result_exact' method with the 'keep_blank' parameter set to True. This test ensures that when a rating is missing from the HTML, the scraper returns a blank string as expected. Unit tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, this method is likely to be retained as it serves an important role in validating the behavior of the code."
survived,"def test_grouping_and_rule_removal():
    scraper = AutoScraper()
    wanted = [
        ""Sony PlayStation 4 PS4 Pro 1TB 4K Console - Black"",
        ""US $349.99"",
        ""4.8"",
        ""See details"",
    ]
    scraper.build(html=HTML_PAGE_1, wanted_list=wanted)
    grouped = scraper.get_result_exact(html=HTML_PAGE_2, grouped=True)
    unwanted = [r for r, v in grouped.items() if v == [""See details""]]
    scraper.remove_rules(unwanted)
    result = scraper.get_result_exact(html=HTML_PAGE_2)
    assert result == [
        ""Acer Predator Helios 300 15.6'' 144Hz FHD Laptop i7-9750H 16GB 512GB GTX 1660 Ti"",
        ""US $1,229.49"",
        ""5.0"",
    ]
",tests/integration/test_real_world.py,,1,1.2501528648238603e-09,"The method `test_grouping_and_rule_removal` is a test function that verifies the functionality of the `AutoScraper` class, specifically focusing on grouping results and removing unwanted rules. Test functions are generally crucial for ensuring code reliability and correctness, especially in automated testing environments. Since this function is part of a test suite, it is unlikely to be deleted unless the feature it tests is removed or significantly altered. Therefore, the method will likely survive."
survived,"    def log(self, env: messaging.Envelope) -> None:
        """"""Hash ``env`` and append to the ledger.""""""

        data = json.dumps(env.__dict__, sort_keys=True).encode()
        digest = blake3(data).hexdigest()
        with self.conn:
            self.conn.execute(
                ""INSERT INTO messages (ts, sender, recipient, payload, hash) VALUES (?, ?, ?, ?, ?)"",
                (env.ts, env.sender, env.recipient, json.dumps(env.payload), digest),
            )
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/logging.py,Ledger,1,4.599055376537186e-10,"The method 'log' is likely to survive because it performs a crucial function of hashing and logging messages into a database. This is a common requirement in systems that need to maintain a record of messages for auditing, tracking, or security purposes. The use of a cryptographic hash function (blake3) ensures data integrity, and the method is implemented in a straightforward manner, making it both useful and maintainable."
survived,"def test_show_results_table(tmp_path) -> None:
    ledger = tmp_path / ""audit.db""
    ledger.touch()
    with patch.object(cli.config.CFG, ""ledger_path"", ledger):
        with patch.object(cli.logging, ""Ledger"") as led_cls:
            led = led_cls.return_value
            led.tail.return_value = [{""ts"": 1.0, ""sender"": ""a"", ""recipient"": ""b"", ""payload"": {""x"": 1}}]
            res = CliRunner().invoke(cli.main, [""show-results""])
            assert ""sender"" in res.output
            assert ""a"" in res.output",tests/test_demo_cli.py,,1,2.646573631904765e-09,"The method 'test_show_results_table' is a unit test function that verifies the functionality of a command-line interface (CLI) command. It uses temporary paths and mock objects to simulate the environment and behavior of the CLI. The test checks if the output of the 'show-results' command contains expected values. This is a typical and necessary part of software testing to ensure code reliability and correctness. Therefore, it is unlikely to be deleted as it serves an important purpose in the development process."
survived,"def _pretty_table(headers: Iterable[str], rows: Iterable[Iterable[Any]]) -> str:
    cols = [list(map(str, col)) for col in zip(*([headers] + list(rows)))]
    widths = [max(len(item) for item in col) for col in cols]
    line = ""-+-"".join(""-"" * w for w in widths)
    header = "" | "".join(h.ljust(widths[i]) for i, h in enumerate(headers))
    data_lines = ["" | "".join(str(val).ljust(widths[i]) for i, val in enumerate(row)) for row in rows]
    return ""\n"".join([header, line, *data_lines])
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/cli.py,,1,2.646573631904765e-09,"The method '_pretty_table' is a utility function that formats data into a readable table format. Such functions are generally useful for displaying data in a structured way, which is a common requirement in many applications. The method is well-defined, takes in headers and rows, and outputs a formatted string. There is no indication that this method is obsolete or redundant, and it serves a clear purpose. Therefore, it is likely to be retained in the codebase."
survived,"    def find_previous_sibling(self, name=None, attrs={}, **kwargs) -> Optional[Tag]:
        """"""Find the previous sibling matching given criteria.""""""
        if not self._soup.parent:
            return None

        siblings = self._soup.parent.contents
        try:
            current_index = siblings.index(self._soup)
            for sibling in reversed(siblings[:current_index]):
                if isinstance(sibling, Tag):
                    if (name is None or sibling.name == name) and all(
                        sibling.get(k) == v for k, v in attrs.items()
                    ):
                        return sibling
        except ValueError:
            pass
        return None
",webscout/scout/core/scout.py,Scout,1,2.998960815863541e-09,"The method `find_previous_sibling` is a utility function that searches for a previous sibling element in a parsed HTML structure that matches certain criteria. This is a common requirement when navigating and manipulating HTML documents, especially in web scraping tasks. The method is well-defined, checks for edge cases (like the absence of a parent), and uses a straightforward approach to find the desired sibling. Such functionality is essential for libraries dealing with HTML parsing, like BeautifulSoup, and is likely to be retained unless there is a significant change in the library's design or a more efficient method is introduced. Therefore, the method is likely to survive."
survived,"def test_workflow_with_json_parameter(
    model_manager: ModelManager,
    dogs_image: np.ndarray,
) -> None:
    workflow_init_parameters = {
        ""workflows_core.model_manager"": model_manager,
        ""workflows_core.api_key"": None,
        ""workflows_core.step_execution_mode"": StepExecutionMode.LOCAL,
    }
    execution_engine = ExecutionEngine.init(
        workflow_definition=JSON_PARSER_WORKFLOW,
        init_parameters=workflow_init_parameters,
        max_concurrent_steps=WORKFLOWS_MAX_CONCURRENT_STEPS,
    )

    result = execution_engine.run(
        runtime_parameters={
            ""image"": dogs_image,
            ""config"": ""{\""model_id\"": \""yolov8n-640\""}"",
        }
    )

    assert len(result) == 1
    assert set(result[0].keys()) == {""json_parser"", ""model_predictions""}
    assert result[0][""json_parser""] == ""yolov8n-640""
    assert isinstance(result[0][""model_predictions""], sv.Detections)",tests/workflows/integration_tests/execution/test_workflow_json_parser_config.py,,1,6.825604231969389e-08,"The method 'test_workflow_with_json_parameter' is a test function that verifies the integration of a workflow with JSON parameters. It is likely part of a test suite to ensure that the workflow execution engine correctly processes input parameters and produces expected results. Test functions are generally not deleted unless they are redundant or replaced by more comprehensive tests. Since this function appears to be specific and checks for particular conditions, it is likely to be retained to ensure the reliability of the system."
survived,"def cleanup_repl(loops, debug: bool = False) -> None:
    io_loop, io_thread, io_stop, klong_loop, klong_thread, klong_stop = loops
    cleanup_async_loop(io_loop, io_thread, io_stop, debug=debug, name='io_loop')
    cleanup_async_loop(klong_loop, klong_thread, klong_stop, debug=debug, name='klong_loop')",klongpy/repl.py,,1,8.152020648014727e-09,"The method 'cleanup_repl' is a utility function that is likely used to clean up resources related to asynchronous loops. It takes a tuple of loops and a debug flag, and calls another function 'cleanup_async_loop' to perform the cleanup. This kind of utility function is generally useful in managing resources and ensuring proper shutdown of asynchronous operations, which is a common requirement in many applications. Therefore, it is likely to be retained as it serves a practical purpose in resource management."
survived,"        async def fetch():
            async with aiohttp.ClientSession() as session:
                async with session.get(f""http://localhost:{port}/"") as resp:
                    return await resp.text()
",tests/test_sys_fn_web.py,TestSysFnWeb,1,7.582560422162384e-10,"The method 'fetch' is a simple asynchronous function that uses 'aiohttp' to make an HTTP GET request to a local server. This is a common pattern in asynchronous programming in Python, especially for I/O-bound operations like network requests. The method is well-structured, using context managers to ensure resources are properly managed, and it returns the response text, which is a typical use case for such functions. Given the increasing popularity of asynchronous programming and the utility of making HTTP requests in this manner, it is likely that this method will be Survived."
survived,"def _get(obj, name):
    if obj is None:
        return None
    if isinstance(obj, dict):
        if name in obj:
            return obj[name]
    if hasattr(obj, name):
        return getattr(obj, name)
    if name == ""items"" and hasattr(obj, ""Items""):
        return getattr(obj, ""Items"")
    if isinstance(obj, (list, tuple)):
        for it in obj:
            try:
                return _get(it, name)
            except Exception:
                pass
    raise Exception(""field not found: "" + name)
",tests/dataset/job/compiler/py/q1.py,,1,9.237449576640118e-09,"The method '_get' is a utility function designed to retrieve a value from an object based on a given name. It handles various types of objects, including dictionaries, objects with attributes, and lists or tuples. This flexibility makes it a useful function for accessing nested data structures, which is a common requirement in many applications. The method also includes error handling to manage cases where the desired field is not found, enhancing its robustness. Given its utility and adaptability, it is likely to be retained in the codebase."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/job/compiler/py/q10.py,,1,5.60279640614594e-09,"The method '_key' is a utility function that is likely used internally within a module or class to generate a key for sorting purposes. It takes an iterable 'it', applies a 'sortKey' function from the 'opts' dictionary, and ensures the key is a string if it's a complex data type. This kind of function is common in sorting operations and is unlikely to be deleted unless the sorting mechanism is completely refactored or the 'opts' dictionary is removed. Therefore, it is more likely to survive."
survived,"def _min(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""min() expects list or group"")
    vals = [it for it in v if it is not None]
    if not vals:
        return 0
    return min(vals)
",tests/dataset/job/compiler/py/q5.py,,1,5.715002851580502e-07,"The method '_min' is a utility function that attempts to find the minimum value in a list or a similar iterable structure. It first checks if the input has an 'Items' attribute, which it uses if present. It then ensures the input is a list, raising an exception if not. The function filters out 'None' values before computing the minimum, returning 0 if the list is empty after filtering. This method is likely to survive because it provides a useful and specific functionality that handles edge cases like 'None' values and non-list inputs, which can be common in data processing tasks."
survived,"def test_Q8_returns_the_pseudonym_and_movie_title_for_Japanese_dubbing():
    assert result == [
        {""actress_pseudonym"": ""Y. S."", ""japanese_movie_dubbed"": ""Dubbed Film""}
    ]
",tests/dataset/job/compiler/py/q8.py,,1,2.8453347280241004e-08,"The method is a test function, which is typically used in unit testing to verify that a specific piece of code behaves as expected. Test functions are generally not deleted unless they are redundant, incorrect, or replaced by more comprehensive tests. Since this function appears to be a straightforward test case checking the output of a function related to Japanese dubbing, it is likely to be useful for ensuring the correctness of that functionality. Therefore, it is more likely to be retained."
survived,"def _min(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""min() expects list or group"")
    vals = [it for it in v if it is not None]
    if not vals:
        return 0
    return min(vals)
",tests/dataset/job/compiler/py/q10.py,,1,3.0590235908148916e-07,"The method '_min' is a utility function that attempts to find the minimum value in a list or a similar iterable structure. It first checks if the input has an 'Items' attribute, which it uses if present. It then ensures the input is a list, raising an exception if not. The method filters out 'None' values before computing the minimum, returning 0 if the list is empty after filtering. This function is quite specific and may not be widely applicable, but it serves a clear purpose and handles edge cases like empty lists and 'None' values. Unless there is a more efficient or standardized way to achieve this in the codebase, the method is likely to survive."
survived,"    def patched_run(app: Any, host: str, port: int, log_level: str = ""info"", **kw: Any) -> None:
        nonlocal server, thread
        config = uvicorn.Config(app, host=host, port=port, log_level=log_level, **kw)
        server = uvicorn.Server(config)
        thread = threading.Thread(target=server.run, daemon=True)
        thread.start()
        for _ in range(50):
            if server.started:
                break
            time.sleep(0.1)
",tests/test_adk_gateway.py,,1,3.2241866333029355e-08,"The method 'patched_run' is a utility function that sets up and runs a server in a separate thread using Uvicorn, a popular ASGI server for Python web applications. This method is useful for developers who need to run a server in a non-blocking way, allowing other operations to continue in the main thread. Given its utility in web application development, especially for testing or running applications in a development environment, it is likely to be retained. The method is well-structured, uses non-blocking threading, and includes a mechanism to check if the server has started, which are all good practices in server management."
survived,"def register_agent(meta: AgentMetadata, *, overwrite: bool = False) -> None:
    """"""Public hook for dynamically-generated agents to self-register.""""""
    _register(meta, overwrite=overwrite)
",alpha_factory_v1/backend/agents/registry.py,,1,5.905303995456778e-10,"The method 'register_agent' is a public hook designed for dynamically-generated agents to self-register. It provides a clear and specific functionality that is likely essential for the system's operation, especially if the system involves dynamic agent management. The presence of the 'overwrite' parameter also suggests that this method is designed with flexibility in mind, allowing for updates to existing registrations. These factors indicate that the method is well-considered and serves a necessary role, making it unlikely to be deleted."
survived,"    def as_dict(self) -> Dict:
        return {
            ""name"": self.name,
            ""version"": self.version,
            ""capabilities"": self.capabilities,
            ""compliance"": self.compliance_tags,
            ""requires_api_key"": self.requires_api_key,
        }
",alpha_factory_v1/backend/agents/registry.py,AgentMetadata,1,8.592166611791576e-10,"The method 'as_dict' is a utility function that converts an object's attributes into a dictionary format. This is a common and useful pattern in programming, especially for serialization, logging, or data manipulation purposes. It provides a clear and structured way to access the object's data, which is often needed in various applications. Given its utility and the fact that it doesn't seem to have any issues or redundancies, it is likely to be retained in the codebase."
survived,"    def close(self) -> None:  # pragma: no cover - dummy
        pass
",tests/test_safety_guardian_fuzz.py,DummyLedger,1,6.475946147757848e-07,"The method 'close' is marked with a pragma directive 'no cover', indicating that it is intentionally left as a dummy or placeholder method. This suggests that the method is not currently in use or is meant to be overridden in a subclass. However, it is common to have such placeholder methods in base classes or interfaces to ensure that subclasses implement them. Therefore, it is likely to survive as it serves a structural purpose in the code, even if it is not currently implemented."
survived,"    def start_merkle_task(self, *a, **kw) -> None:  # pragma: no cover - dummy
        pass
",tests/test_safety_guardian_fuzz.py,DummyLedger,0,0.9999999715466527,"The method `start_merkle_task` is marked with a comment `# pragma: no cover - dummy`, indicating that it is a placeholder or a stub. This suggests that the method is not currently implemented and is not intended to be covered by tests. Such methods are often temporary and may be removed or replaced once the actual implementation is provided. Therefore, it is likely that this method will be deleted in the future when the real functionality is developed."
survived,"    def subscribe(self, topic: str, handler) -> None:  # pragma: no cover - dummy
        pass
",tests/test_safety_guardian_fuzz.py,DummyBus,0,0.9999997300421382,"The method 'subscribe' is marked with a pragma directive 'no cover', indicating that it is a placeholder or a dummy implementation. This suggests that the method is not currently functional and is likely intended to be implemented in the future. However, without any implementation, it does not serve any purpose in its current state. If the method remains unimplemented for an extended period, it might be considered for deletion unless there is a clear plan to implement it soon. Therefore, the method is more likely to be deleted if it continues to remain a dummy."
survived,"def load_sectors(path: str | os.PathLike[str], *, energy: float = 1.0, entropy: float = 1.0) -> list[Sector]:
    """"""Load sector definitions from a JSON file.

    The file may contain a list of strings representing sector names or a list
    of objects with ``name`` and optional ``energy``, ``entropy`` and ``growth``
    fields. The ``energy`` and ``entropy`` arguments provide defaults when these
    values are omitted.
    """"""
    with open(path, ""r"", encoding=""utf-8"") as f:
        data = json.load(f)

    sectors: list[Sector] = []
    for entry in data:
        if isinstance(entry, str):
            sectors.append(Sector(entry, energy, entropy))
        elif isinstance(entry, dict):
            sectors.append(
                Sector(
                    entry.get(""name"", """"),
                    float(entry.get(""energy"", energy)),
                    float(entry.get(""entropy"", entropy)),
                    float(entry.get(""growth"", 0.05)),
                    bool(entry.get(""disrupted"", False)),
                )
            )
        else:
            raise ValueError(f""Invalid sector entry: {entry!r}"")
    return sectors",alpha_factory_v1/demos/alpha_agi_insight_v1/src/simulation/sector.py,,1,1.4166087846364157e-09,"The method 'load_sectors' is well-defined and serves a clear purpose of loading sector definitions from a JSON file. It handles different types of input data (strings and dictionaries) and provides default values for missing fields, which makes it robust and flexible. Additionally, it includes error handling for invalid entries. These characteristics make it a useful utility function that is likely to be retained in the codebase."
survived,"    async def status(_: None = Depends(verify_token)) -> StatusResponse:
        """"""Return orchestrator agent stats.""""""

        orch = cast(Any, app_f.state.orchestrator)
        if orch is None:
            raise HTTPException(status_code=503, detail=""Orchestrator not running"")
        items = [
            AgentStatus(name=r.agent.name, last_beat=r.last_beat, restarts=r.restarts) for r in orch.runners.values()
        ]
        return StatusResponse(agents=items)
",src/interface/api_server.py,,1,5.905303995456778e-10,"The method 'status' is likely to survive because it provides a crucial functionality of returning the orchestrator agent stats, which is important for monitoring and managing the orchestrator's state. It includes error handling for when the orchestrator is not running, ensuring robustness. Additionally, it uses modern Python features like async and type hints, indicating it is up-to-date with current coding practices."
survived,"            def update(state):
                g_tokens, g_counts = state
                pos = g_counts[""seq"", seq_id].scalar()
                g_tokens = g_tokens.at[""seq"", seq_id, ""position"", pos].set(tokens[""position"", i])
                g_counts = g_counts.at[""seq"", seq_id].add(1)
                return g_tokens, g_counts
",src/levanter/inference/jit_scheduler.py,JitScheduler,1,1.0467401685178159e-08,"The method 'update' appears to be a utility function that updates a state consisting of 'g_tokens' and 'g_counts'. It modifies these structures based on the current position and token information. The method is concise, performs a clear task, and is likely part of a larger system that processes sequences or tokens. Such utility functions are common in data processing or machine learning pipelines, where state updates are frequent. Unless there is a significant change in the system's requirements or architecture, this method is likely to be retained as it serves a specific purpose efficiently."
survived,"        def sendjson(self, *_a: object, **_kw: object) -> None:  # pragma: no cover - unused
            pass
",tests/test_alpha_agi_business_3_v1.py,DummySocket,0,0.9999952149051502,"The method `sendjson` is marked with a pragma comment `# pragma: no cover - unused`, indicating that it is not currently used in the codebase. This suggests that the method is not essential for the current functionality of the application. Additionally, the method body is simply a `pass` statement, meaning it does not perform any operations. Without any implementation or usage, it is likely to be considered dead code and may be removed in future refactoring efforts to clean up the codebase."
survived,"        def stop(self) -> None:
            self.stopped = True
",tests/test_alpha_agi_business_3_v1.py,DummySocket,1,6.348800075736417e-09,"The method 'stop' is a simple setter method that changes the state of an object by setting the 'stopped' attribute to True. Such methods are common in object-oriented programming to control the state of an object, especially in scenarios involving threads, processes, or any stateful operations. The method is likely to be used in conjunction with other methods that check the 'stopped' attribute to determine if an operation should continue or halt. Therefore, it is a useful method for managing object state and is unlikely to be deleted unless the entire class design changes significantly."
survived,"def test_frontier_60fps() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri() + ""#seed=1&pop=5000&gen=1""

    with sync_playwright() as p:
        browser = p.chromium.launch()
        page = browser.new_page()
        page.goto(url)
        page.wait_for_selector(""#fps-meter"")
        page.wait_for_timeout(2000)
        fps_text = page.inner_text(""#fps-meter"")
        fps = float(fps_text.split()[0])
        assert fps >= 60.0
        browser.close()
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_plot_perf.py,,1,4.599055376537186e-10,"The method 'test_frontier_60fps' is a test function that uses Playwright to automate a browser and check if a web page maintains a frame rate of at least 60 frames per second. This is a specific and useful test for performance validation of web applications, especially those involving animations or dynamic content. Such tests are crucial for ensuring a smooth user experience and are likely to be retained in a codebase to prevent performance regressions. Therefore, the method is likely to survive."
survived,"    def get_col_spec(self, **kwargs: Any) -> str:
        return f""FLOAT[{self.dim}]"" if self.dim is not None else ""FLOAT[]""
",src/raglite/_typing.py,DuckDBVec,1,1.2501528648238603e-09,"The method `get_col_spec` is a simple utility function that returns a string representation of a column specification based on the presence of the `dim` attribute. It is straightforward, performs a clear task, and is likely used in a context where column specifications are dynamically generated based on object attributes. Such utility methods are common in codebases dealing with database schemas or data processing, and they are generally useful for maintaining flexibility and readability in the code. Therefore, it is likely to be retained."
survived,"def _sha384(path: Path) -> str:
    digest = hashlib.sha384(path.read_bytes()).digest()
    return ""sha384-"" + base64.b64encode(digest).decode()
",tests/test_docs_bundle_hash.py,,1,1.8189616842444243e-09,"The method _sha384 is a utility function that computes the SHA-384 hash of a file's contents and returns it in a specific format. This type of function is generally useful for ensuring data integrity and security, which are common requirements in software development. The function is concise, uses standard libraries, and performs a clear, useful task. Therefore, it is likely to be retained in the codebase."
survived,"        def avg_latency(d: dict[str, float]) -> float:
            return d[""lat""] / d[""count""] if d[""count""] else -1.0
",alpha_factory_v1/core/agents/meta_refinement_agent.py,MetaRefinementAgent,1,1.4166087846364157e-09,"The method 'avg_latency' is a simple utility function that calculates the average latency from a dictionary containing 'lat' and 'count' keys. It handles the division by zero case by returning -1.0 if 'count' is zero. This is a common pattern in code where average calculations are needed, and the method is straightforward and efficient. There is no indication that this method is obsolete or redundant, and it serves a clear purpose. Therefore, it is likely to be retained in the codebase."
survived,"    def test_shutdown_called_on_exit(self) -> None:
        orchestrator._OAI._runtime = None
        orchestrator._OAI._hooked = False
        stub = mock.MagicMock()
        handlers = []
        with mock.patch.object(orchestrator, ""AgentRuntime"", return_value=stub, create=True):
            with mock.patch.object(orchestrator.atexit, ""register"", side_effect=lambda h: handlers.append(h)) as reg:
                self.assertIs(orchestrator._OAI.runtime(), stub)
                reg.assert_called_once()
        self.assertEqual(len(handlers), 1)
        handlers[0]()
        stub.shutdown.assert_called_once()
",tests/test_oai_runtime.py,TestOAIRuntime,1,4.944450477491054e-09,"The method is a unit test that verifies the behavior of a shutdown mechanism in an orchestrator system. It uses mocking to simulate and test the behavior of the system when it exits. The method is well-structured, uses standard testing practices, and is likely part of a test suite. Test methods are generally not deleted unless they are redundant or replaced by more comprehensive tests. Therefore, it is likely to survive."
survived,"def test_safety_agent_halts_on_large_loss(monkeypatch):
    monkeypatch.setenv(""NO_LLM"", ""1"")
    monkeypatch.delenv(""OPENAI_API_KEY"", raising=False)
    monkeypatch.setenv(""ALPHA_ASI_SILENT"", ""1"")
    monkeypatch.setenv(""ALPHA_ASI_MAX_STEPS"", ""1"")
    mod = _reload_module(monkeypatch)
    mod.A2ABus._subs = {}
    safety = mod.BasicSafetyAgent()
    msgs: list[dict] = []
    mod.A2ABus.subscribe(""orch"", lambda m: msgs.append(m))
    safety.handle({""loss"": 5000.0})
    assert {""cmd"": ""stop""} in msgs
",tests/test_world_model_safety.py,,1,1.725782769012759e-08,"The method 'test_safety_agent_halts_on_large_loss' is a unit test designed to verify that a safety agent correctly issues a stop command when a large loss is detected. This is a critical safety feature, and the test ensures that the system behaves as expected under these conditions. Unit tests are generally retained as they are essential for maintaining code quality and reliability. Therefore, this method is likely to survive."
survived,"def test_auto_attach_detects_files_and_prepends_prompt():
    """"""auto_attach should detect file references and prepend the prompt.""""""
    prompt = ""Summarize sample.txt""
    root_dir = ""src/attachments/data""
    ctx = auto_attach(prompt, root_dir=root_dir)

    # Should return an Attachments-like object with the sample file
    assert isinstance(ctx, Attachments)
    assert len(ctx) == 1
    assert ctx[0].path.endswith(""sample.txt"")

    combined = ctx.text
    assert combined.startswith(prompt)
    # After the prompt, the file content should appear
    after_prompt = combined[len(prompt):].lstrip()
    assert after_prompt.startswith(""Welcome to the Attachments Library!"")",tests/test_api_methods.py,,1,5.3157849718487075e-08,"The method is a test function that verifies the behavior of the `auto_attach` function. Test functions are generally crucial for ensuring code reliability and correctness, especially in a development environment. This particular test checks if the `auto_attach` function correctly detects file references and prepends the prompt, which is likely an important feature of the system being tested. Therefore, it is unlikely to be deleted as it serves a critical role in maintaining the integrity of the codebase."
survived,"async def run_cycle_async(
    orchestrator: Orchestrator,
    fin_agent: AgentFin,
    res_agent: AgentRes,
    ene_agent: AgentEne,
    gdl_agent: AgentGdl,
    model: Model,
) -> None:
    """"""Execute one evaluation + commitment cycle.""""""

    bundle = orchestrator.collect_signals()
    delta_h = fin_agent.latent_work(bundle)
    delta_s = res_agent.entropy(bundle)
    beta = ene_agent.market_temperature()
    if abs(beta) < 1e-9:
        log.warning("" is zero; skipping cycle"")
        return
    delta_g = delta_h - (delta_s / beta)

    log.info(""H=%s S=%s =%s  G=%s"", delta_h, delta_s, beta, delta_g)

    comment = await _llm_comment(delta_g)
    log.info(""LLM: %s"", comment)

    if delta_g < 0:
        orchestrator.post_alpha_job(id(bundle), delta_g)

    weight_update: Dict[str, Any] = {}
    if gdl_agent.provable(weight_update):
        model.commit(weight_update)
",alpha_factory_v1/demos/alpha_agi_business_3_v1/alpha_agi_business_3_v1.py,,1,9.237449576640118e-09,"The method 'run_cycle_async' is a well-structured asynchronous function that performs a series of operations involving multiple agents and a model. It collects signals, calculates values, logs information, and makes decisions based on the results. The method is likely part of a larger system that requires these operations to be performed asynchronously. Given its clear purpose, integration with other components, and use of asynchronous programming, it is likely to be useful and relevant in its context. Therefore, it is more likely to be retained in the codebase."
survived,"    def test_missing_spec_allowed_with_flag(self) -> None:
        """"""Allow basic fallback when __spec__ is None.""""""
        fake_mod = types.SimpleNamespace(
            __version__=""0.0.17"",
            __spec__=None,
            OpenAIAgent=object,
        )

        def _fake_import(name: str, *args: Any, **kwargs: Any) -> object:
            if name == ""openai_agents"":
                return fake_mod
            return importlib.import_module(name, *args, **kwargs)

        def _fake_find_spec(name: str, *args: Any, **kwargs: Any) -> object:
            if name == ""openai_agents"":
                return object()
            if name == ""agents"":
                return None
            return importlib.util.find_spec(name, *args, **kwargs)

        def _raise() -> bool:
            raise AssertionError(""check_openai_agents_version should not run"")

        with (
            mock.patch(""importlib.import_module"", side_effect=_fake_import),
            mock.patch(""importlib.util.find_spec"", side_effect=_fake_find_spec),
            mock.patch.object(check_env, ""REQUIRED"", []),
            mock.patch.object(check_env, ""OPTIONAL"", [""openai_agents""]),
            mock.patch.object(check_env, ""warn_missing_core"", lambda: []),
            mock.patch.object(check_env, ""check_openai_agents_version"", _raise),
        ):
            self.assertEqual(check_env.main([""--allow-basic-fallback""]), 0)
",tests/test_check_env_openai_agents_version.py,TestCheckEnvOpenAIAgentsVersion,1,1.275190675769241e-07,"The method 'test_missing_spec_allowed_with_flag' is a unit test designed to verify the behavior of a system when a specific condition is met (i.e., when the '__spec__' attribute is None). It uses mocking to simulate the environment and dependencies, ensuring that the 'check_openai_agents_version' function is not called. This test is valuable for ensuring the robustness of the system under specific conditions and is likely part of a larger test suite. As such, it serves a clear purpose in maintaining code quality and is unlikely to be deleted."
survived,"    def __init__(self, agent: object) -> None:
        self.cls: Callable[..., object] = type(agent)
        self.agent = agent
        self.period = getattr(agent, ""CYCLE_SECONDS"", 1.0)
        self.capabilities = getattr(agent, ""CAPABILITIES"", [])
        self.last_beat = time.time()
        self.restarts = 0
        self.task: asyncio.Task[None] | None = None
        self.error_count = 0
        self.restart_streak = 0
",alpha_factory_v1/backend/agent_supervisor.py,AgentRunner,1,1.8189616842444243e-09,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class. It sets up important attributes such as 'cls', 'agent', 'period', 'capabilities', 'last_beat', 'restarts', 'task', 'error_count', and 'restart_streak'. These attributes are likely crucial for the functionality of the class, especially if it involves asynchronous tasks or monitoring an agent's state. Constructors are fundamental to object-oriented programming, and unless there is a significant reason to refactor or remove the class itself, the constructor will survive."
survived,"def main(demo: str) -> None:
    url = _demo_url(demo)
    if _remote_available(url):
        print(f""Opening {url}"")
        webbrowser.open(url)
        return

    repo_root = Path(__file__).resolve().parents[1]
    site_dir = repo_root / ""site"" / demo
    local_page = site_dir / ""index.html""
    if not local_page.is_file():
        print(""Remote page unavailable. Building local copy..."", file=sys.stderr)
        if not _build_local_site(repo_root) or not local_page.is_file():
            print(
                f""Demo {demo} not found. Build the gallery with ./scripts/build_gallery_site.sh"",
                file=sys.stderr,
            )
            sys.exit(1)

    handler = partial(SimpleHTTPRequestHandler, directory=str(site_dir))
    with ThreadingHTTPServer((""127.0.0.1"", 0), handler) as httpd:
        port = httpd.server_address[1]
        local_url = f""http://127.0.0.1:{port}/index.html""
        print(f""Serving local copy at {local_url}"", file=sys.stderr)
        thread = threading.Thread(target=httpd.serve_forever, daemon=True)
        thread.start()
        try:
            webbrowser.open(local_url)
            thread.join()
        except KeyboardInterrupt:
            pass
",scripts/open_demo.py,,1,3.3982678079468468e-09,"The method 'main' is a utility function that attempts to open a demo page either from a remote URL or by serving a local copy. It handles both remote availability and local fallback scenarios, which are common requirements in development environments. The function is well-structured, uses standard libraries, and provides clear error messages and instructions for building the local site if needed. These characteristics make it a useful and robust function for developers working with demo sites, suggesting it is likely to be retained in the codebase."
survived,"def main() -> None:
    run([""python"", ""alpha_factory_v1/scripts/preflight.py""])
    run([""node"", str(BROWSER_DIR / ""build/version_check.js"")])
    run([""python"", ""scripts/check_python_deps.py""])
    run([""python"", ""check_env.py"", ""--auto-install""])
    run([""python"", ""scripts/verify_disclaimer_snippet.py""])
    run([""python"", ""-m"", ""alpha_factory_v1.demos.validate_demos""])
    run([""python"", ""scripts/publish_demo_gallery.py""])
    run([""python"", ""scripts/verify_workbox_hash.py"", ""site/alpha_agi_insight_v1""])

    try:
        import importlib.util

        if importlib.util.find_spec(""playwright"") is not None:
            with subprocess.Popen(
                [sys.executable, ""-m"", ""http.server"", ""--directory"", ""site"", ""8000""],
                cwd=REPO_ROOT,
            ) as proc:
                try:
                    run([""python"", ""scripts/verify_insight_offline.py""])
                finally:
                    proc.terminate()
        else:
            print(""Playwright not found; skipping offline re-check"", file=sys.stderr)
    except Exception:
        print(""Playwright not found; skipping offline re-check"", file=sys.stderr)
",scripts/edge_human_knowledge_pages_sprint.py,,1,1.8553915987649156e-07,"The method 'main' is a comprehensive script that orchestrates a series of checks and validations, likely as part of a build or deployment process. It includes running various scripts, checking dependencies, and verifying configurations. The presence of error handling and conditional logic (e.g., checking for 'playwright') suggests it is designed to be robust and adaptable to different environments. Such scripts are typically essential in development workflows to ensure consistency and reliability, especially in larger projects. Therefore, it is unlikely to be deleted unless the entire workflow is significantly restructured or replaced."
survived,"    async def kill_switch(request: Request, _: None = Depends(verify_token)) -> dict[str, str]:
        token = request.headers.get(""X-Kill-Token"")
        if token is None:
            data = await request.json()
            token = data.get(""token"")
        if token not in _kill_tokens:
            raise HTTPException(status_code=403, detail=""Invalid kill token"")
        _pending_votes[token] = time.time()
        if len(_pending_votes) >= 2:
            task = getattr(app_f.state, ""orch_task"", None)
            if task:
                task.cancel()
                with contextlib.suppress(asyncio.CancelledError):
                    await task
                app_f.state.orch_task = None
                app_f.state.orchestrator = None
            alerts.send_alert(""Kill-switch activated  orchestrator disabled"")
            _pending_votes.clear()
            return {""status"": ""disabled""}
        return {""status"": f""{len(_pending_votes)}/2 confirmations""}
",src/interface/api_server.py,,1,1.955568070542584e-08,"The method 'kill_switch' is a critical function that provides a mechanism to disable an orchestrator based on a token verification process. It includes security checks, such as verifying a kill token, and ensures that the orchestrator is only disabled after receiving a certain number of confirmations. This functionality is essential for maintaining control over the orchestrator in potentially harmful situations. Given its importance in managing system operations and security, it is unlikely to be deleted."
survived,"def test_pareto_rank_deterministic() -> None:
    pop = [
        Candidate(0.8, 40, 10),
        Candidate(0.9, 45, 20),
        Candidate(0.6, 60, 15),
    ]
    rng = random.Random(0)
    selections = [select_parent(pop, epsilon=0.0, rng=rng) for _ in range(100)]
    assert all(s is not pop[1] for s in selections)
",tests/test_sim_selector.py,,1,2.0611536181902033e-09,"The method `test_pareto_rank_deterministic` is a unit test function that verifies the behavior of a selection mechanism in a genetic algorithm or similar optimization process. It checks that a specific candidate (pop[1]) is never selected when a deterministic selection process is used (epsilon=0.0). This kind of test is crucial for ensuring the correctness of the selection logic, especially in algorithms that rely on stochastic processes. Since testing is a fundamental part of software development to ensure code reliability and correctness, this method is likely to be retained."
survived,"    def op(_g: str) -> str:
        return ""asdf qwer zxcv""  # nonsense thesis
",tests/test_reviewer_agent.py,,0,0.9999999804443193,"The method 'op' is a simple function that takes a string input and returns a hardcoded string 'asdf qwer zxcv'. This function does not perform any meaningful operation on the input parameter '_g', making it essentially a placeholder or a stub. In a real-world scenario, such a function would likely be considered redundant or unnecessary unless it serves a specific purpose in a larger context, such as testing or as a temporary implementation. Without additional context indicating its necessity, it is likely to be deleted as it does not contribute any functional value."
survived,"def lead_signal_improvement(
    history: Sequence[float],
    forecast: Sequence[float],
    *,
    months: int = 6,
    threshold: float | None = None,
) -> float:
    """"""Return relative lead-time improvement over the baseline.""""""
    base = _arima_baseline(history, months)
    thr = threshold if threshold is not None else (history[-1] if history else 0.0)

    def first_cross(seq: Sequence[float]) -> int:
        for i, v in enumerate(seq, 1):
            if v >= thr:
                return i
        return months + 1

    base_idx = first_cross(base)
    cand_idx = first_cross(forecast[:months])
    if base_idx <= cand_idx:
        return 0.0
    return (base_idx - cand_idx) / base_idx
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/evaluators/lead_time.py,,1,1.8189616842444243e-09,"The method 'lead_signal_improvement' is a utility function that calculates the relative lead-time improvement of a forecast over a baseline. It is a specific and useful function for comparing forecast performance, especially in time series analysis. The method is well-defined, has a clear purpose, and includes a default behavior for the threshold parameter. Such utility functions are often retained in codebases as they provide specific functionality that can be reused across different parts of a project. Unless there is a significant change in the requirements or a better alternative is introduced, this method is likely to survive."
survived,"def generate_score_proof(scores: Sequence[float], threshold: float) -> str:
    """"""Return proof that the weighted score exceeds ``threshold``.""""""
    # hidden evaluator weights
    weighted = 0.7 * scores[0] + 0.3 * scores[1]
    if weighted < threshold:
        raise ValueError(""score below threshold"")
    h = _hash_scores(scores)
    blob = json.dumps({""hash"": h, ""threshold"": threshold}, separators=("","", "":"")).encode()
    return sha256(blob).hexdigest()
",src/snark/proof.py,,1,1.4166087846364157e-09,"The method 'generate_score_proof' is likely to survive because it performs a specific and useful function: it calculates a weighted score from a sequence of scores and checks if it exceeds a given threshold. If the score is below the threshold, it raises an exception, which is a common pattern for error handling. Additionally, it generates a hash as proof, which could be useful for verification purposes. The method is well-defined, has a clear purpose, and uses standard libraries like json and hashlib, making it a practical utility function."
survived,"def test_get_output_path_without_subdirs(monkeypatch, tmp_path):
    monkeypatch.setenv('NOTES_EXPORT_USE_SUBDIRS', 'false')
    tracker = utils.NotesExportTracker(root_directory=str(tmp_path))
    output = tracker.get_output_path('pdf', 'folder', 'note', '.pdf')
    expected = Path(tmp_path) / 'pdf' / 'note.pdf'
    assert output == expected
    assert output.parent.is_dir()",tests/test_tracker.py,,1,1.955568070542584e-08,"The method 'test_get_output_path_without_subdirs' is a unit test function that verifies the behavior of the 'get_output_path' method from the 'NotesExportTracker' class. It uses 'monkeypatch' to set an environment variable and 'tmp_path' to create a temporary directory for testing. The test checks if the output path is correctly formed when subdirectories are not used. This is a typical and necessary test to ensure the functionality of the code, especially when dealing with file paths and environment configurations. Therefore, it is likely to be retained as part of the test suite."
survived,"def test_uses_subdirs_true(monkeypatch, tmp_path):
    monkeypatch.setenv('NOTES_EXPORT_USE_SUBDIRS', 'true')
    tracker = utils.NotesExportTracker(root_directory=str(tmp_path))
    assert tracker._uses_subdirs() is True
",tests/test_tracker.py,,1,8.76424914819242e-08,"The method 'test_uses_subdirs_true' is a unit test function that checks if the 'NotesExportTracker' class correctly interprets the environment variable 'NOTES_EXPORT_USE_SUBDIRS' when set to 'true'. This is a common practice in testing to ensure that environment-dependent behavior is correctly implemented. The use of 'monkeypatch' and 'tmp_path' suggests that this test is part of a larger test suite, likely using pytest, which is a popular testing framework in Python. Given the importance of testing in software development, especially for environment-dependent features, it is unlikely that this method will be deleted unless the feature it tests is removed or significantly altered."
survived,"    def fake_run(*_a, **_k):
        return subprocess.CompletedProcess([], 1, """", """")
",tests/test_preflight_sandbox.py,,1,7.73442280641062e-08,"The method 'fake_run' is a mock function that simulates the behavior of a subprocess call by returning a 'CompletedProcess' object with predefined values. This is useful for testing purposes where actual subprocess execution is not desired. Such mock functions are common in testing environments to ensure code can be tested without side effects. Therefore, it is likely to be retained for its utility in testing scenarios."
survived,"def download_model(dest: Path, model: str = ""124M"") -> None:
    """"""Download GPT-2 weights using the official helper script.""""""
    with tempfile.TemporaryDirectory() as tmpdir:
        tmp_path = Path(tmpdir)
        subprocess.run([""git"", ""clone"", ""--depth"", ""1"", OPENAI_REPO, str(tmp_path)], check=True)
        script = tmp_path / ""download_model.py""
        subprocess.run([sys.executable, str(script), model], cwd=tmp_path, check=True)
        target = dest / model
        target.mkdir(parents=True, exist_ok=True)
        shutil.copytree(tmp_path / ""models"" / model, target, dirs_exist_ok=True)
",scripts/download_gpt2_small.py,,1,6.348800075736417e-09,"The method 'download_model' is a utility function that automates the process of downloading GPT-2 model weights using a helper script from a cloned repository. This functionality is useful for users who need to set up GPT-2 models for various applications, and it abstracts away the complexity of manually downloading and setting up the model files. Given the ongoing interest and use of GPT-2 models in various applications, this method is likely to be retained as it provides a convenient and efficient way to handle model downloads."
survived,"async def get_order(order_id: int):
    order = next((o for o in ORDERS if o[""id""] == order_id), None)
    if not order:
        raise HTTPException(status_code=404, detail=""Order not found"")
    return order",examples/shop_api_gateway/server.py,,1,2.0611536181902033e-09,"The method 'get_order' is a straightforward function that retrieves an order by its ID from a list of orders. It uses asynchronous programming, which is beneficial for I/O-bound operations, and raises an HTTPException if the order is not found, which is a common practice in web applications to handle errors gracefully. The method is simple, efficient, and follows good practices for error handling and asynchronous operations. Therefore, it is likely to be retained in the codebase."
survived,"def degrees2compasspoint(h):
    return compassPoint[cpx(h)]
",tests/rosetta/transpiler/Python/box-the-compass.py,,1,1.725782769012759e-08,"The method 'degrees2compasspoint' is a simple utility function that converts a degree value to a compass point using a predefined mapping. Such utility functions are commonly used in applications involving navigation, mapping, or any system that requires directionality. Unless there is a significant change in the requirements or the method is replaced by a more efficient or comprehensive solution, it is likely to be retained for its utility."
survived,"def cpx(h):
    x = int(((h / 11.25) + 0.5))
    x = x % 32
    if x < 0:
        x = x + 32
    return x
",tests/rosetta/transpiler/Python/box-the-compass.py,,1,1.725782769012759e-08,"The method 'cpx' is a simple mathematical function that takes an input 'h', performs a series of arithmetic operations, and returns a result. The function is straightforward, does not rely on any deprecated or external libraries, and does not have any apparent issues or inefficiencies. It is likely to be useful in contexts where such a calculation is needed, such as in converting angles or similar transformations. Therefore, there is no strong reason for this method to be deleted."
survived,"def padRight(s, w):
    out = s
    i = len(s)
    while i < w:
        out = out + "" ""
        i = i + 1
    return out
",tests/rosetta/transpiler/Python/box-the-compass.py,,1,3.0590235908148916e-07,"The method 'padRight' is a simple utility function that pads a given string 's' with spaces on the right until it reaches a specified width 'w'. This type of function is commonly used in formatting text output, especially in console applications or when generating reports. Despite its simplicity, it serves a clear purpose and can be useful in various contexts where text alignment is needed. Therefore, it is likely to be retained as it provides a basic yet essential functionality."
survived,"def indexOf(s, ch):
    i = 0
    while i < len(s):
        if s[i:i + 1] == ch:
            return i
        i = i + 1
    return -1
",tests/rosetta/transpiler/Python/box-the-compass.py,,0,0.9999982396568657,"The method 'indexOf' is a custom implementation to find the index of a character in a string. However, Python already provides a built-in method 'str.find()' which performs the same task more efficiently and is more readable. The custom method does not offer any additional functionality or performance benefits over the built-in method. Therefore, it is likely to be deleted in favor of using the built-in 'find' method."
survived,"def padLeft(n, width):
    s = str(n)
    while len(s) < width:
        s = "" "" + s
    return s
",tests/rosetta/transpiler/Python/blum-integer.py,,1,8.939700163274874e-06,"The method 'padLeft' is a simple utility function that pads a number with spaces on the left to ensure it reaches a specified width. This type of function is commonly used in formatting tasks, such as preparing data for display in a table or aligning text output. While there are more modern and efficient ways to achieve this in Python (such as using string formatting methods like f-strings or the 'str.zfill' method for zero-padding), the function itself is straightforward and serves a clear purpose. It is likely to survive because it provides a basic functionality that can be useful in various contexts, especially in legacy code or for educational purposes."
survived,"def zeroval(ival):
    x = ival
    x = 0
    return x
",tests/rosetta/transpiler/Python/call-a-function-11.py,,0,0.9999999895325983,"The method 'zeroval' takes an input 'ival', assigns it to a local variable 'x', then immediately sets 'x' to 0, and returns 0. This function does not utilize the input value in any meaningful way, making it redundant. It essentially always returns 0 regardless of the input, which is not a useful operation in most contexts. Therefore, it is likely to be deleted as it does not serve a practical purpose."
survived,"def isPrime(n):
    if n < 2:
        return False
    if n % 2 == 0:
        return n == 2
    if n % 3 == 0:
        return n == 3
    d = 5
    while d * d <= n:
        if n % d == 0:
            return False
        d = d + 2
        if n % d == 0:
            return False
        d = d + 4
    return True
",tests/rosetta/transpiler/Python/brazilian-numbers.py,,1,7.194132978569833e-09,"The method is a well-known algorithm for checking if a number is prime. It efficiently handles small numbers and uses a loop to check divisibility for larger numbers, skipping even numbers after checking for divisibility by 2 and 3. This method is useful in many applications where prime number checking is needed, and it is implemented in a way that is both efficient and easy to understand. Therefore, it is likely to be retained in the codebase."
survived,"def makePatterns():
    digits = [""1"", ""2"", ""3"", ""4"", ""5"", ""6"", ""7"", ""8"", ""9""]
    pats = []
    i = 0
    while i < len(digits):
        j = 0
        while j < len(digits):
            if j != i:
                k = 0
                while k < len(digits):
                    if k != i and k != j:
                        l = 0
                        while l < len(digits):
                            if l != i and l != j and l != k:
                                pats = pats + [digits[i] + digits[j] + digits[k] + digits[l]]
                            l = l + 1
                    k = k + 1
            j = j + 1
        i = i + 1
    return pats
",tests/rosetta/transpiler/Python/bulls-and-cows-player.py,,1,8.76424914819242e-08,"The method 'makePatterns' generates all possible 4-digit combinations from a list of digits without repeating any digit in a combination. This is a valid and functional method for generating permutations of a specific length from a set of elements. The method is straightforward and serves a clear purpose, which is often useful in various applications such as generating codes or testing permutations. Therefore, it is likely to survive as it provides a specific utility that can be reused or adapted for different contexts."
survived,"def decipher(s, k):
    return encipher(s, (26 - k % 26) % 26)
",tests/rosetta/transpiler/Python/caesar-cipher-2.py,,1,3.581747929000289e-10,"The method 'decipher' is a simple utility function that reverses the operation of an 'encipher' function by adjusting the shift value. It is a common pattern in cryptography to have both encipher and decipher functions, and this method is likely part of a larger system that requires both operations. The method is concise, performs a clear and necessary function, and is unlikely to be removed unless the entire cryptographic system is deprecated or replaced. Therefore, it is likely to survive."
survived,"def commatize(n):
    s = str(n)
    i = len(s) - 3
    while i >= 1:
        s = """".join(s[0:i]) + "","" + """".join(s[i:len(s)])
        i = i - 3
    return s
",tests/rosetta/transpiler/Python/brilliant-numbers.py,,1,3.2241866333029355e-08,"The method 'commatize' is a utility function that formats a number by inserting commas at every thousandth place, which is a common requirement in many applications for better readability of large numbers. This functionality is useful and not provided by default in many programming languages, including Python, without using additional libraries or modules. Therefore, the method is likely to be retained as it provides a practical and straightforward solution to a common problem."
survived,"def indexOf(s, ch):
    i = 0
    while i < len(s):
        if s[i:i + 1] == ch:
            return i
        i = i + 1
    return -1
",tests/rosetta/transpiler/Python/caesar-cipher-2.py,,0,0.9999945777819207,"The method 'indexOf' is a custom implementation to find the index of a character in a string. However, Python already provides a built-in method 'str.find()' which performs the same task more efficiently and is more readable. The custom method does not offer any additional functionality or performance benefits over the built-in method. Therefore, it is likely to be deleted in favor of using the built-in 'find' method."
survived,"def main():
    add2 = mkAdd(2)
    add3 = mkAdd(3)
    print(str(add2(5)) + "" "" + str(add3(6)))
    partial = partialSum(13)
    print(str(partial(5)))
",tests/rosetta/transpiler/Python/call-a-function-12.py,,1,8.939693769056794e-06,"The method 'main' is a typical entry point for Python scripts and is often used to demonstrate or test functionality. The code within 'main' appears to be testing the functionality of two functions, 'mkAdd' and 'partialSum', by creating closures and printing their results. Without additional context, such as whether 'mkAdd' and 'partialSum' are defined elsewhere in the codebase, it's difficult to determine if 'main' is fully functional. However, the presence of 'main' suggests an intention to use it as a test or demonstration, which is a common practice in Python scripts. Therefore, it is likely to be retained for its utility in testing or demonstrating the functionality of the code."
survived,"def toContinued(r):
    a = r.numerator
    b = r.denominator
    res = []
    while True:
        res = res + [int((a // b))]
        t = a % b
        a = b
        b = t
        if a == 1:
            break
    if len(res) % 2 == 0:
        res[len(res) - 1] = res[len(res) - 1] - 1
        res = res + [1]
    return res
",tests/rosetta/transpiler/Python/calkin-wilf-sequence.py,,1,5.60279640614594e-09,"The method 'toContinued' is a utility function that converts a rational number into its continued fraction representation. This is a mathematical operation that can be useful in various computational and mathematical contexts, such as number theory, approximations, and algorithms that require precise representations of fractions. The function is well-defined, performs a specific task, and does not have any apparent issues or redundancies that would warrant its deletion. Therefore, it is likely to be retained in the codebase."
survived,"def osm(args, tolerant, dryrun):
    """"""Compile one or more OSM files into an OSM database.""""""
    if len(args) < 2:
        raise click.UsageError(""OSM file(s) and destination database required"")
    *osm_files, osmdb_filename = args
    osm_to_osmdb(osm_files, osmdb_filename, tolerant, dryrun)
",pygs/graphserver/cli.py,,1,1.1032560311263802e-09,"The method 'osm' is a utility function that compiles OSM files into a database. It checks for the correct number of arguments and then calls another function to perform the conversion. This functionality is specific and useful for applications dealing with OSM data, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained in the codebase."
survived,"def test_retry_on_rate_limit(thread_and_agent, monkeypatch):
    thread, agent = thread_and_agent
    thread._run.last_error = Mock()
    thread._run.last_error.message = ""Rate limit is exceeded. Try again in 2 seconds.""

    called = []

    def fake_sleep(sec):
        called.append(sec)

    monkeypatch.setattr(time, ""sleep"", fake_sleep)

    result = thread._try_run_failed_recovery(
        error_attempts=0,
        recipient_agent=agent,
        additional_instructions=None,
        event_handler=None,
        tool_choice=None,
        response_format=None,
        parent_run_id=None,
    )

    assert result is True
    thread._create_run.assert_called_once()
    assert called and called[0] == 2",tests/test_thread_retry.py,,1,4.363462233903899e-09,"The method 'test_retry_on_rate_limit' is a unit test designed to verify the behavior of a retry mechanism when a rate limit error occurs. It uses mocking to simulate the conditions under which the retry should happen, specifically checking that the system waits for the specified time before retrying. This is a common and necessary test to ensure robustness in systems that interact with rate-limited APIs. The test is well-structured, uses mocking effectively, and checks the expected behavior, making it a valuable part of the test suite. Therefore, it is likely to be retained."
survived,"            def run(self) -> None:
                import asyncio

                if self._agent is None:
                    raise RuntimeError(""No agent registered"")
                asyncio.run(self._runner.run(self._agent, """"))
",alpha_factory_v1/demos/meta_agentic_tree_search_v0/openai_agents_bridge.py,_FallbackAgentRuntime,1,4.944450477491054e-09,"The method 'run' is a simple and straightforward implementation that checks if an agent is registered and then uses asyncio to run a runner with the agent. This method is likely to be essential for the functionality of the class it belongs to, as it seems to be a core part of executing some asynchronous operation with an agent. There is no indication that this method is redundant or unnecessary, and it follows a clear and logical structure. Therefore, it is likely to be retained in the codebase."
survived,"def primeSieve(n):
    sieve = []
    i = 0
    while i <= n:
        sieve = sieve + [False]
        i = i + 1
    sieve[0] = True
    sieve[1] = True
    p = 2
    while p * p <= n:
        if not sieve[p]:
            m = p * p
            while m <= n:
                sieve[m] = True
                m = m + p
        p = p + 1
    sys.exit(sieve)
",tests/rosetta/transpiler/Python/equal-prime-and-composite-sums.py,,0,0.9999998362622821,"The method 'primeSieve' is likely to be deleted because it contains several issues that make it inefficient and incorrect for practical use. Firstly, it uses a list to represent the sieve, but it initializes the list with a while loop and concatenation, which is inefficient compared to using list comprehension or direct initialization. Secondly, the method uses 'sys.exit' to return the sieve, which is not a standard way to return values from a function and will terminate the program instead of returning the result. These issues suggest that the method is not well-implemented and is likely to be replaced or removed in favor of a more efficient and correct implementation."
survived,"def binom(n, k):
    if k < 0 or k > n:
        sys.exit(0)
    kk = k
    if kk > n - kk:
        kk = n - kk
    res = 1
    i = 0
    while i < kk:
        res = res * ((n - i))
        i = i + 1
        res = res // (i)
    sys.exit(res)
",tests/rosetta/transpiler/Python/evaluate-binomial-coefficients.py,,0,0.9999994284997149,"The method is likely to be deleted because it uses `sys.exit()` to return a value, which is not a standard or recommended practice in Python. Typically, functions should return values using the `return` statement, allowing the caller to handle the result appropriately. Using `sys.exit()` terminates the program, which is not suitable for a function that is supposed to compute and return a binomial coefficient. This makes the function less reusable and not suitable for integration into larger systems."
survived,"def pad2(x):
    s = str(x)
    if len(s) < 2:
        s = "" "" + s
    sys.exit(s)
",tests/rosetta/transpiler/Python/feigenbaum-constant-calculation.py,,0,0.9999339478346898,"The method 'pad2' is a simple utility function that pads a single-digit number with a space to ensure it is at least two characters long. However, it uses 'sys.exit()' to return the result, which is unconventional and not practical for a utility function. This approach terminates the program, which is not the intended behavior for a function that should simply return a formatted string. This misuse of 'sys.exit()' suggests that the method is not well-designed for its purpose, making it likely to be deleted or significantly refactored in future iterations."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/extensible-prime-generator.py,,1,2.2159489282323004e-08,"The method `_now()` is a utility function that generates a pseudo-random number based on a seed if `_now_seeded` is True, otherwise it returns the current time in nanoseconds. This function seems to be a part of a larger system that requires a consistent and repeatable sequence of numbers when seeded, which is a common requirement in simulations or testing environments. The function is simple, serves a clear purpose, and does not have any apparent issues or redundancies that would necessitate its deletion. Therefore, it is likely to be retained in the codebase."
survived,"def add(a, b):
    sys.exit(Complex(re=a.re + b.re, im=a.im + b.im))
",tests/rosetta/transpiler/Python/eulers-identity.py,,0,0.9999938558278723,"The method `add` is intended to perform addition of two complex numbers, but it uses `sys.exit` to return the result, which is not a standard or appropriate way to return values from a function. This is likely a mistake or misunderstanding of how to return values in Python. Instead, the function should simply return the result of the addition. Due to this incorrect implementation, the method is likely to be deleted or significantly modified to correct the logic."
survived,"def copyInts(xs):
    out = []
    for v in xs:
        out = out + [v]
    return out
",tests/rosetta/transpiler/Python/faces-from-a-mesh.py,,1,6.962258425838873e-06,"The method 'copyInts' is a simple function that takes a list 'xs' and returns a new list 'out' containing the same elements. However, the implementation is inefficient because it uses list concatenation in a loop, which results in O(n^2) time complexity due to the creation of a new list at each iteration. A more efficient approach would be to use the 'append' method, which would maintain O(n) time complexity. Despite this inefficiency, the function is functional and correctly performs its intended task. Therefore, it is likely to survive unless there is a strong emphasis on optimizing performance in the context where this function is used."
survived,"def expF(b, p):
    neg = False
    if p < 0:
        neg = True
        p = -p
    r = 1.0
    pow = b
    while p > 0:
        if p % 2 == 1:
            r = r * pow
        pow = pow * pow
        p = p // 2
    if neg:
        r = 1.0 / r
    return r
",tests/rosetta/transpiler/Python/exponentiation-operator.py,,1,1.0467401685178159e-08,"The method 'expF' is a custom implementation of the power function, which calculates b raised to the power of p. It handles both positive and negative exponents, using an efficient algorithm known as exponentiation by squaring. This method is likely to survive because it provides a fundamental mathematical operation that is commonly used in various applications. Additionally, the implementation is efficient and handles edge cases like negative exponents, making it a useful utility function."
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    print(""The listed extensions are:"")
    print(extensions)
    tests = [""MyData.a##"", ""MyData.tar.Gz"", ""MyData.gzip"", ""MyData.7z.backup"", ""MyData..."", ""MyData"", ""MyData_v1.0.tar.bz2"", ""MyData_v1.0.bz2""]
    for t in tests:
        res = fileExtInList(t)
        ok = bool(res[0])
        ext = str(res[1])
        print(pad(t, 20) + "" => "" + str(ok) + ""  (extension = "" + ext + "")"")
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/file-extension-is-in-extensions-list.py,,1,9.237449576640118e-09,"The method 'main()' is a standalone function that seems to be part of a larger script or application. It performs a series of operations including benchmarking memory and time usage, printing a list of file extensions, and checking if certain test file names have extensions in a list. The function is well-structured and provides useful output for debugging or analysis purposes. There is no indication that this function is redundant or obsolete, and it appears to serve a specific purpose in the context of the application. Therefore, it is likely to be retained in the codebase."
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    k = 0.07
    tempRoom = 20.0
    tempObject = 100.0
    fcr = newCoolingRateDy(k, tempRoom)
    analytic = newTempFunc(k, tempRoom, tempObject)
    for step in [2.0, 5.0, 10.0]:
        print(""Step size = "" + fmtF(step, 0, 1))
        print("" Time Euler's Analytic"")
        temp = tempObject
        time = 0.0
        while time <= 100.0:
            line = fmtF(time, 5, 1) + "" "" + fmtF(temp, 7, 3) + "" "" + fmtF(analytic(time), 7, 3)
            print(line)
            temp = eulerStep(fcr, time, temp, step)
            time = time + step
        print("""")
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/euler-method.py,,1,2.1024340680345882e-07,"The method is a complete and functional implementation of a main function that performs a simulation of cooling rates using Euler's method and an analytic solution. It includes performance benchmarking and outputs results in a structured format. The code is well-structured and serves a clear purpose, making it unlikely to be deleted."
survived,"def showDistribution(sizes):
    bins = []
    i = 0
    while i < 12:
        bins = bins + [0]
        i = i + 1
    total = 0
    for sz in sizes:
        total = total + sz
        idx = 0
        if sz > 0:
            idx = log10floor(sz) + 1
        bins[idx] = bins[idx] + 1
    print(""File size distribution:\n"")
    i = 0
    while i < len(bins):
        prefix = ""  ""
        if i > 0:
            prefix = ""+ ""
        print(prefix + ""Files less than 10 ^ "" + str(i) + "" bytes : "" + str(bins[i]))
        i = i + 1
    print(""                                  -----"")
    print(""= Total number of files         : "" + str(len(sizes)))
    print(""  Total size of files           : "" + commatize(total) + "" bytes"")
",tests/rosetta/transpiler/Python/file-size-distribution.py,,0,0.9999995549151272,"The method 'showDistribution' is likely to be deleted because it contains several issues that make it inefficient and potentially incorrect. Firstly, the method uses a hardcoded loop to initialize the 'bins' list, which is not flexible. Secondly, the function 'log10floor' is used without being defined or imported, which will cause an error. Thirdly, the method of calculating the index for the bins is not clear and might not work as intended. Lastly, the function 'commatize' is also used without definition or import, leading to another error. These issues suggest that the method is not well-implemented and might be removed or significantly refactored."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/fibonacci-n-step-number-sequences.py,,1,2.1024340680345882e-07,"The method `_now()` is a utility function that generates a pseudo-random number based on a global seed if `_now_seeded` is True, otherwise it returns the current time in nanoseconds. This function is useful for testing or scenarios where deterministic behavior is needed. It is unlikely to be deleted because it serves a specific purpose in controlling randomness and time-based operations, which are common requirements in software development."
survived,"def indexOf(s, ch):
    i = 0
    while i < len(s):
        if s[i:i + 1] == ch:
            sys.exit(i)
        i = i + 1
    sys.exit(-1)
",tests/rosetta/transpiler/Python/euler-method.py,,0,0.9999999530883621,"The method `indexOf` is likely to be deleted because it uses `sys.exit()` to return the index of a character in a string, which is not a standard or appropriate way to handle such functionality. Typically, a function like this should return the index directly rather than terminating the program. This approach makes the function unusable in most contexts where you would want to handle the result programmatically. Additionally, Python's built-in `str.index()` or `str.find()` methods already provide this functionality in a more conventional and useful manner."
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    err = foo()
    if len(err) > 0:
        print(""Recovered from "" + err)
    print(""glad that's over."")
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/exceptions.py,,0,0.9999998144608401,"The method is likely to be deleted (0) because it contains several issues that suggest it is not well-maintained or useful in its current form. Firstly, the function 'foo()' is called but not defined within the code snippet, indicating a missing dependency or incomplete code. Secondly, the error handling is minimal and not robust, as it only checks if the error string is non-empty and prints a message. Thirdly, the use of '_now()' suggests a custom or undefined function for time measurement, which is not standard or explained. Lastly, the memory usage calculation seems incorrect as it multiplies by 1024 without clear context. These issues suggest the method is either incomplete or not functioning as intended, leading to its potential deletion."
survived,"def newCoolingRate(k):
    sys.exit(lambda dt: -k * dt)
",tests/rosetta/transpiler/Python/euler-method.py,,0,0.9999999586006244,"The method 'newCoolingRate' is designed to exit the program using 'sys.exit', which is not a typical or useful behavior for a function that is supposed to calculate a cooling rate. The use of 'sys.exit' suggests that the function is not intended to return a value or perform a meaningful calculation, but rather to terminate the program, which is not a desirable behavior for a utility function. Additionally, the lambda function inside 'sys.exit' is not executed, making the function ineffective for its intended purpose. Therefore, this method is likely to be deleted or refactored."
survived,"def sinApprox(x):
    term = x
    sum = x
    n = 1
    while n <= 10:
        denom = float(((2 * n) * (2 * n + 1)))
        term = -term * x * x / denom
        sum = sum + term
        n = n + 1
    sys.exit(sum)
",tests/rosetta/transpiler/Python/eulers-identity.py,,0,0.9999687980937693,"The method sinApprox is a simple implementation of a sine function approximation using a Taylor series expansion. However, it contains a critical flaw: it uses sys.exit(sum) to return the result, which is not a standard or appropriate way to return a value from a function. This will terminate the program and is not suitable for a function that is supposed to compute and return a value. Instead, it should use 'return sum' to return the computed value. This flaw makes the function unusable in its current form, leading to its likely deletion or significant modification."
survived,"def indexOf(s, ch):
    i = 0
    while i < len(s):
        if s[i:i + 1] == ch:
            sys.exit(i)
        i = i + 1
    sys.exit(0 - 1)
",tests/rosetta/transpiler/Python/feigenbaum-constant-calculation.py,,0,0.9999756997690634,"The method is likely to be deleted because it uses sys.exit() to return the index, which is not a standard or recommended way to return values from a function. This approach terminates the entire program, which is not desirable for a function that is supposed to find the index of a character in a string. Instead, it should return the index directly using the return statement. Additionally, the method does not handle cases where the character is not found in a user-friendly manner, as it exits the program with a negative value. These issues make the method impractical for use in most applications."
survived,"    def log(self, env: messaging.Envelope) -> None:  # pragma: no cover - stub
        pass
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_codegen_safety.py,DummyLedger,1,7.3382086014706e-07,"The method `log` is currently a stub, indicated by the `pass` statement and the `# pragma: no cover - stub` comment. This suggests that the method is intended to be implemented in the future, as it is a placeholder for functionality that is yet to be defined. The presence of the method signature indicates that there is an intention to use this method, likely for logging purposes related to the `messaging.Envelope` parameter. Therefore, it is more likely that this method will be implemented rather than deleted, as it serves a potential purpose in the codebase."
survived,"def test_skip_unsafe_execution(monkeypatch) -> None:
    cfg = config.Settings(bus_port=0)
    bus = DummyBus(cfg)
    ledger = DummyLedger()
    agent = codegen_agent.CodeGenAgent(bus, ledger)

    called = False

    def fake_exec(code: str) -> tuple[str, str]:
        nonlocal called
        called = True
        return """", """"

    monkeypatch.setattr(codegen_agent, ""is_code_safe"", lambda c: False)
    monkeypatch.setattr(agent, ""execute_in_sandbox"", fake_exec)

    env = messaging.Envelope(sender=""market"", recipient=""codegen"", ts=0.0)
    env.payload.update({""analysis"": ""x""})
    asyncio.run(agent.handle(env))
    assert not called",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_codegen_safety.py,,1,2.5109990926928157e-08,"The method 'test_skip_unsafe_execution' is a unit test designed to verify that the 'CodeGenAgent' does not execute code deemed unsafe. It uses monkeypatching to simulate the behavior of the 'is_code_safe' function and the 'execute_in_sandbox' method. The test checks that the 'execute_in_sandbox' method is not called when the code is unsafe, which is a critical safety feature. Such tests are essential for ensuring the robustness and security of the system, especially when dealing with code execution. Therefore, it is likely to be retained as part of the test suite."
survived,"    async def run(self) -> None:
        iteration = 0
        while not await self._should_stop():
            if self._max_iters is not None and iteration >= self._max_iters:
                break

            # ------------------------------------------------------------------
            # Sample a problem (reuse the dataset when exhausted).
            # ------------------------------------------------------------------
            if self._example_idx >= len(self._examples):
                self._rng.shuffle(self._examples)
                self._example_idx = 0
            example = self._examples[self._example_idx]
            self._example_idx += 1

            user_prompt: str = example[""prompt""]
            gt_answer: str = example[""answer""]

            # ------------------------------------------------------------------
            # Call inference server.
            # ------------------------------------------------------------------
            completion = self._client.chat.completions.create(
                model=self._model,
                messages=[
                    {""role"": ""user"", ""content"": user_prompt},
                ],
            )

            assistant_msg: str = completion.choices[0].message.content

            # ------------------------------------------------------------------
            # Reward calculation.
            # ------------------------------------------------------------------
            parsed = validate_format(assistant_msg + "">"")  # util expects trailing >
            is_valid = parsed[""is_valid""]
            extracted_answer = parsed[""answer""]
            is_correct = grade_answer(extracted_answer, gt_answer) if is_valid else False
            reward = float(is_correct)

            # ------------------------------------------------------------------
            # Build rollout & emit.
            # ------------------------------------------------------------------
            turns = [
                Turn(
                    message=user_prompt,
                    role=""user"",
                    logprobs=None,
                    reward=None,
                    inference_metadata={},
                ),
                Turn(
                    message=assistant_msg,
                    role=""assistant"",
                    logprobs=None,  # logprobs not available via OpenAI client
                    reward=reward,
                    inference_metadata={
                        ""model"": self._model,
                        ""finish_reason"": completion.choices[0].finish_reason,
                    },
                ),
            ]
            rollout = Rollout(turns=turns, metadata={""problem"": user_prompt})
            group = RolloutGroup(
                id=f""math-{iteration}"",
                source=""math_env"",
                created=time.time(),
                rollouts=[rollout],
                metadata={""valid_format"": is_valid, ""correct"": is_correct},
            )

            self._rollout_sink([group])

            iteration += 1
            await asyncio.sleep(0)  # yield control to Ray scheduler
",marin/rl/envs/math_env.py,MathEnv,1,7.194132978569833e-09,"The method is well-structured and serves a clear purpose in an asynchronous environment. It handles iterations, shuffles examples, interacts with an inference server, calculates rewards, and emits rollouts. These functionalities are essential for a system that requires continuous learning or testing, such as a reinforcement learning setup. The method is likely part of a larger system that relies on these operations, making it unlikely to be deleted."
survived,"    def resources(self) -> RayResources:
        """"""Return Ray resource specs (CPU/GPU/TPU etc.) needed per replica.""""""
",marin/rl/config.py,AbstractEnvConfig,1,1.0467401685178159e-08,"The method `resources` is a simple getter function that returns the resource specifications needed per replica in a Ray-based system. This is a fundamental part of managing resources in distributed computing environments, especially when using frameworks like Ray that require explicit resource management. Such methods are crucial for ensuring that the system can allocate the necessary resources for tasks efficiently. Therefore, it is unlikely that this method will be deleted as it serves an essential purpose in resource management."
survived,"    async def act(self) -> Dict[str, Any]:  # type: ignore[override]
        return {""action"": ""noop""}
",alpha_factory_v1/demos/era_of_experience/stub_agents.py,ExperienceAgent,1,9.42244663976186e-07,"The method 'act' is an asynchronous function that returns a dictionary with a single key-value pair, where the key is 'action' and the value is 'noop'. This suggests that the method is intended to perform a 'no operation' action, which might be used as a placeholder or default behavior in a larger system. The use of 'type: ignore[override]' indicates that this method might be overriding a method from a superclass but intentionally ignoring type checking for this override. This could be useful in scenarios where the method signature is intentionally different from the expected one in the superclass, possibly due to specific design choices or constraints.

Given that the method is simple, non-intrusive, and potentially serves a specific purpose (like a default or placeholder action), it is likely to survive unless the overall design of the system changes significantly or the method's purpose is no longer needed."
survived,"def main(argv: list[str] | None = None) -> None:
    args = _parse_args(argv)
    payload: dict[str, object] = {""action"": args.action}
    if args.job:
        payload[""job""] = json.loads(Path(args.job).read_text(encoding=""utf-8""))
    headers = {}
    api_key = os.getenv(""OPENAI_API_KEY"")
    if api_key:
        headers[""Authorization""] = f""Bearer {api_key}""
    url = f""{args.host}/v1/agents/business_helper/invoke""
    resp = requests.post(url, json=payload, headers=headers, timeout=10)
    try:
        print(json.dumps(resp.json(), indent=2))
    except Exception:
        print(resp.text)
",alpha_factory_v1/demos/alpha_agi_business_v1/examples/openai_agent_client.py,,1,1.2501528648238603e-09,"The method is a main function that serves as an entry point for a script. It handles command-line arguments, prepares a payload for an API request, and sends the request to a specified URL. This is a common pattern for scripts that interact with APIs, and it is unlikely to be deleted unless the entire script is deprecated or replaced. The function is well-structured, uses environment variables for sensitive data, and includes error handling, which are good practices in software development. Therefore, it is likely to survive."
survived,"def pulse_source(
    token: str,
    start_date: str,
    end_date: Optional[str] = None,
    metrics: Optional[Iterable[str]] = None,
    topsites: Optional[bool] = None,
    ip_version: Optional[str] = None,
) -> Iterable[dlt.sources.DltResource]:
    """"""Create resources for Internet Society Pulse metrics.

    Args:
        token: Bearer token for the API.
        start_date: First date of the data range (YYYY-MM-DD).
        end_date: Last date of the data range.
        metrics: Subset of metrics to fetch. Defaults to all available metrics.
        topsites: Optional flag used by some endpoints.
        ip_version: IP version parameter used by some endpoints.
    """"""
    if metrics is None:
        metrics = GLOBAL_METRICS.keys()

    headers = {""Authorization"": f""Bearer {token}""}

    resources: List[EndpointResource] = []
    for name in metrics:
        path = GLOBAL_METRICS.get(name)
        if not path:
            continue

        endpoint: Dict[str, Any] = {
            ""path"": path,
            ""params"": {
                ""start_date"": ""{incremental.start_value}"",
            },
            ""incremental"": {
                ""cursor_path"": ""date"",
                ""start_param"": ""start_date"",
                ""end_param"": ""end_date"",
                ""initial_value"": start_date,
                ""end_value"": end_date,
                ""range_start"": ""closed"",
                ""range_end"": ""closed"",
            },
            ""paginator"": ""single_page"",
        }

        if end_date is not None:
            endpoint[""params""][""end_date""] = end_date
        if topsites is not None and name in {""http"", ""https""}:
            endpoint[""params""][""topsites""] = topsites
        if ip_version is not None and name in {""roa"", ""rov"", ""tls"", ""tls13""}:
            endpoint[""params""][""ip_version""] = ip_version

        resources.append({""name"": name, ""endpoint"": endpoint})

    config: RESTAPIConfig = {
        ""client"": {
            ""base_url"": ""https://pulse.internetsociety.org/api/"",
            ""headers"": headers,
        },
        ""resource_defaults"": {
            ""write_disposition"": ""merge"",
            ""primary_key"": ""date"",
        },
        ""resources"": resources,
    }

    yield from rest_api_resources(config)",ingestr/src/pulse/__init__.py,,1,2.3355930333443423e-09,"The method `pulse_source` is a well-defined function that provides a structured way to create resources for Internet Society Pulse metrics. It includes detailed parameter handling, such as optional parameters for metrics, topsites, and IP version, and constructs API endpoints dynamically based on these inputs. The function is useful for fetching data from a specific API and is likely part of a larger data processing or ETL pipeline. Given its clear utility, structured design, and adaptability to different input parameters, it is likely to be retained in the codebase."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/bitwise-io-1.py,,1,2.8453347280241004e-08,"The method `_now()` is a utility function that generates a pseudo-random number based on a seed if `_now_seeded` is True, or returns the current time in nanoseconds otherwise. This function seems to be part of a larger system that requires either a deterministic sequence of numbers (when seeded) or a timestamp. Such utility functions are often useful in testing, simulations, or systems that require both random and time-based values. Unless there is a specific reason to remove it, such as redundancy or a shift in system requirements, it is likely to be retained."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/binary-search.py,,1,8.152020648014727e-09,"The method `_now()` is a utility function that generates a pseudo-random number based on a seed if `_now_seeded` is True, otherwise it returns the current time in nanoseconds. This function seems to be a part of a larger system that requires either a deterministic sequence of numbers (when seeded) or the current time. Such utility functions are often useful in testing or in systems where time-based or pseudo-random values are needed. Unless there is a significant change in the requirements or a better alternative is found, this method is likely to survive."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/bitcoin-address-validation.py,,1,6.348800075736417e-09,"The method '_now' is a utility function that generates a pseudo-random number based on a seed if '_now_seeded' is True, or returns the current time in nanoseconds otherwise. This kind of function is useful in scenarios where deterministic behavior is needed for testing or simulation purposes, and non-deterministic behavior is needed in other cases. The function is simple, serves a clear purpose, and does not have any obvious issues or redundancies that would warrant its deletion. Therefore, it is likely to be retained in the codebase."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/constrained-genericity-1.py,,1,2.2159489282323004e-08,"The method _now() is a utility function that generates a pseudo-random number based on a seed if _now_seeded is True, otherwise it returns the current time in nanoseconds. This function is likely part of a larger system that requires either a random number or a timestamp, depending on the state of _now_seeded. The function is simple, serves a clear purpose, and does not have any obvious issues or redundancies that would warrant its deletion. Therefore, it is likely to be retained in the codebase."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/copy-stdin-to-stdout-2.py,,1,6.825604231969389e-08,"The method `_now()` is a utility function that generates a pseudo-random number based on a seed if `_now_seeded` is True, or returns the current time in nanoseconds otherwise. This function seems to be a part of a larger system that requires either a deterministic sequence of numbers (when seeded) or a timestamp. Such utility functions are often useful in testing, simulations, or systems where both random and time-based values are needed. Unless there is a specific reason to remove it, such as redundancy or a shift in design requirements, it is likely to be retained."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/count-in-factors.py,,1,3.850741907939403e-09,"The method `_now()` is a utility function that generates a pseudo-random number based on a seed if `_now_seeded` is True, or returns the current time in nanoseconds otherwise. This function seems to be a part of a larger system that requires either a deterministic sequence of numbers (when seeded) or a timestamp. Such utility functions are often useful in testing, simulations, or systems where both random and time-based values are needed. Unless there is a significant change in the requirements or a better alternative is introduced, this method is likely to survive as it serves a specific purpose."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/conditional-structures-4.py,,1,2.1024340680345882e-07,"The method _now() is a utility function that generates a pseudo-random number based on a seed if _now_seeded is True, otherwise it returns the current time in nanoseconds. This function is likely part of a larger system that requires a consistent and repeatable sequence of numbers for testing or simulation purposes when seeded, and real-time timestamps otherwise. Such utility functions are common in software development for testing and simulation, and they provide useful functionality. Therefore, it is unlikely to be deleted unless the entire system's requirements change significantly."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/continued-fraction.py,,1,3.3982678079468468e-09,"The method _now() is a utility function that generates a pseudo-random number if a global variable _now_seeded is set, otherwise it returns the current time in nanoseconds. This function is not inherently harmful or redundant, and it serves a specific purpose of providing a seeded random number generator or a timestamp. Such utility functions are common in codebases for testing or specific application logic. Without additional context indicating that this function is no longer needed or has been replaced, it is likely to survive."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/constrained-genericity-3.py,,1,1.2098660619383578e-06,"The method _now() is a utility function that generates a pseudo-random number based on a seed if _now_seeded is True, or returns the current time in nanoseconds if not. This function is useful for testing or scenarios where deterministic behavior is needed. It is unlikely to be deleted because it serves a specific purpose in providing a controlled random number generation or time-based value, which can be crucial for debugging or testing purposes."
survived,"def test_refinement_proposes_cycle_adjustment(tmp_path: Path) -> None:
    repo = _make_repo(tmp_path)
    logs = tmp_path / ""logs""
    logs.mkdir()
    (logs / ""log.json"").write_text(
        ""\n"".join(['{""agent"":""demo"",""latency_ms"":6000,""ts"":0}', '{""agent"":""demo"",""latency_ms"":7000,""ts"":1}']),
        encoding=""utf-8"",
    )

    reg = StakeRegistry()
    reg.set_stake(""meta"", 1.0)

    with patch.object(harness, ""vote_and_merge"") as vote:
        agent = MetaRefinementAgent(repo, logs, reg)
        agent.refine()

    called_diff = vote.call_args.args[1]
    assert ""increase cycle"" in called_diff",tests/test_meta_refinement_agent.py,,1,6.825604231969389e-08,"The method 'test_refinement_proposes_cycle_adjustment' is a unit test that verifies the behavior of a system when certain conditions are met. It sets up a temporary repository, writes log data, and uses a mock to test the 'refine' method of 'MetaRefinementAgent'. The test checks if the 'vote_and_merge' method is called with a specific argument indicating a cycle adjustment. This is a typical pattern for testing functionality in software development, ensuring that the system behaves as expected. Since testing is a crucial part of maintaining software quality, this method is likely to be retained to ensure the system's reliability."
survived,"def _read(name: str) -> str:
    return (FIXTURES / name).read_text()
",tests/test_patch_validation.py,,1,1.1032560311263802e-09,"The method _read is a simple utility function that reads the content of a file given its name. It uses the pathlib library to construct the file path and read the text content. Such utility functions are common and useful in many codebases for handling file operations in a clean and concise manner. Unless there is a significant change in the requirements or the method is replaced by a more efficient or necessary alternative, it is likely to survive."
survived,"def _wait_results(
    url: str,
    sim_id: str,
    headers: dict[str, str],
    proc: subprocess.Popen[str],
    max_attempts: int = 60,
) -> dict[str, object]:
    delay = 0.05
    for _ in range(max_attempts):
        if proc.poll() is not None:
            out, err = proc.communicate()
            raise AssertionError(
                f""server exited with {proc.returncode}:\n{out}{err}""
                if err
                else f""server exited with {proc.returncode}:\n{out}""
            )
        r = httpx.get(f""{url}/results/{sim_id}"", headers=headers)
        if r.status_code == 200:
            data = r.json()
            if data.get(""population"") is not None:
                return data
        time.sleep(delay)
        delay = min(delay * 1.5, 1.0)
    raise AssertionError(""Timed out waiting for results"")
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_api_server_subprocess.py,,1,2.646573631904765e-09,"The method '_wait_results' is a utility function that waits for a server process to complete and retrieves results from a specified URL. It includes error handling for server exit and timeout scenarios, making it robust for its intended purpose. The method is likely to be useful in scenarios where asynchronous processing is involved, and results need to be polled from a server. Given its utility and the fact that it handles common issues like server exit and timeouts, it is likely to be retained in the codebase."
survived,"def test_get_version_writes_file():
    repo_root = Path(__file__).resolve().parents[1]
    version_file = repo_root / ""_scm_version.py""
    try:
        version = get_version(root=repo_root, write_to=version_file)
        assert version_file.exists()
        content = version_file.read_text()
        assert version in content
        assert re.match(r""\d+\.\d+\.\d+"", version)
    finally:
        if version_file.exists():
            version_file.unlink()",tests/test_version_scm.py,,1,2.8453347280241004e-08,"The method 'test_get_version_writes_file' is a test function that verifies the behavior of the 'get_version' function. It checks if the version file is created, contains the correct version, and matches a version pattern. The function also ensures cleanup by deleting the file after the test. This is a well-structured test that serves a clear purpose in validating the functionality of version management in a codebase. Test functions like this are crucial for maintaining code quality and are unlikely to be deleted unless the functionality they test is removed or significantly changed."
survived,"def test_self_improve_template_parses(tmp_path, monkeypatch):
    data = {""system"": ""sys"", ""user"": ""usr""}
    path = tmp_path / ""tpl.yaml""
    path.write_text(yaml.safe_dump(data), encoding=""utf-8"")
    monkeypatch.setenv(""SELF_IMPROVE_TEMPLATE"", str(path))
    config.init_config()
    cfg = config.Settings()
    assert cfg.self_improve.system == ""sys""
    assert cfg.self_improve.user == ""usr""",tests/test_prompts.py,,1,3.850741907939403e-09,"The method 'test_self_improve_template_parses' is a unit test function that verifies the parsing of a YAML template file into a configuration object. It uses temporary file paths and environment variable patching to ensure the test is isolated and does not affect the actual environment. This is a common practice in testing to ensure code reliability and correctness. Since testing is a crucial part of software development and maintenance, this method is likely to be retained to ensure the functionality it tests remains correct over time."
survived,"def test_comparative_advantage():
    client = get_client()
    resp = client.post(
        ""/comparative-advantage/execute"",
        json={""skills"": {""a"": 1}, ""tasks"": {""t1"": [""a""]}},
    )
    assert resp.status_code == 200
    data = resp.json()
    assert set(data.keys()) == {""advantage_map""}
",servers/server_clear_thought/tests/test_new_tools.py,,1,3.850741907939403e-09,"The method `test_comparative_advantage` is a unit test function that checks the functionality of an API endpoint. It uses a client to send a POST request to the `/comparative-advantage/execute` endpoint with a JSON payload. The test then asserts that the response status code is 200 and that the response JSON contains a key `advantage_map`. This is a typical structure for a test function in a codebase that uses automated testing to ensure the correctness of API endpoints. Such test functions are crucial for maintaining code quality and are unlikely to be deleted unless the functionality they test is removed or significantly changed. Therefore, the method is likely to survive."
survived,"def test_existing_tool_example():
    app = create_app()
    client = TestClient(app)
    resp = client.post(""/existing-tool-example/execute"", json={""text"": ""hi""})
    assert resp.status_code == 200
    assert resp.json() == {""echoed"": ""hi""}",servers/server_clear_thought/tests/test_existing_tools.py,,1,8.592166611791576e-10,"The method 'test_existing_tool_example' is a unit test for an existing tool's functionality. It uses a test client to send a POST request to a specific endpoint and checks if the response is as expected. This is a common practice in software development to ensure that code changes do not break existing functionality. Since testing is a crucial part of maintaining software quality and reliability, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly changed. Therefore, the method will likely survive."
survived,"    def execute(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        voi_score = sum(payload[""payoffs""]) / (len(payload[""uncertainties""]) or 1)
        questions = [f""Resolve {u}?"" for u in payload[""uncertainties""]]
        return {
            ""voi_score"": round(voi_score, 2),
            ""high_impact_questions"": questions,
        }",servers/server_clear_thought/tools/value_of_information.py,ValueOfInformation,1,5.211412485172657e-10,"The method 'execute' is well-structured and performs a clear function: it calculates a 'voi_score' based on the 'payoffs' and generates a list of questions from 'uncertainties'. The method handles potential division by zero by using 'or 1' and returns a dictionary with the calculated score and questions. This functionality is useful for processing and analyzing data, making it likely to be retained in the codebase."
survived,"    async def json(self):
        return {}
",src/aiohttp/__init__.py,Response,1,9.931195248674785e-08,"The method is a simple asynchronous function that returns an empty dictionary. It is likely a placeholder or a base implementation meant to be overridden or extended in subclasses. The method itself is functional and does not contain any errors or deprecated practices. Therefore, unless there is a significant change in the requirements or the design of the system that makes this method obsolete, it is likely to survive."
survived,"    def start_timer(self) -> None:
        """"""Start the latency timer.""""""
        self._start = time.perf_counter()
",src/meta_agent/telemetry.py,TelemetryCollector,1,3.160881453314576e-10,"The method 'start_timer' is a simple utility function that initializes a timer using 'time.perf_counter()'. This is a common and useful functionality in many applications where performance measurement or latency tracking is needed. The method is straightforward, has a clear purpose, and does not have any apparent issues or redundancies that would warrant its removal. Therefore, it is likely to be retained in the codebase."
survived,"def test_summary_line():
    t = TelemetryCollector()
    t.start_timer()
    t.stop_timer()
    line = t.summary_line()
    assert ""Telemetry:"" in line
    assert ""cost=$"" in line
    assert ""tokens=0"" in line",tests/unit/test_telemetry_collector.py,,1,5.043472052266442e-07,"The method 'test_summary_line' is a unit test for the 'summary_line' method of the 'TelemetryCollector' class. It checks if the summary line contains specific expected substrings. Unit tests are crucial for ensuring code reliability and are typically retained to maintain code quality. Therefore, it is unlikely that this method will be deleted."
survived,"def test_with_retry_sync(monkeypatch: pytest.MonkeyPatch) -> None:
    monkeypatch.setattr(retry, ""backoff"", None)
    monkeypatch.setattr(retry.time, ""sleep"", lambda *_: None)
    calls = {""n"": 0}

    def func() -> str:
        calls[""n""] += 1
        if calls[""n""] < 2:
            raise ValueError(""fail"")
        return ""ok""

    wrapped = retry.with_retry(func, max_tries=2)
    assert wrapped() == ""ok""
    assert calls[""n""] == 2
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_retry.py,,1,8.152020648014727e-09,"The method 'test_with_retry_sync' is a unit test function that tests the retry functionality of a function wrapped with a retry mechanism. It uses monkeypatching to modify the behavior of the retry mechanism for testing purposes. This kind of test is essential for ensuring that the retry logic works as expected, especially in scenarios where transient errors might occur. Since testing retry logic is a common requirement in software development, this method is likely to be retained as part of the test suite to ensure the reliability of the retry functionality."
survived,"def test_storage_access_toast() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri()

    with sync_playwright() as p:
        browser = p.chromium.launch()
        context = browser.new_context(storage_state=None)
        context.add_init_script(""document.hasStorageAccess = () => Promise.resolve(false)"")
        page = context.new_page()
        page.goto(url)
        page.wait_for_selector(""#controls"")
        page.wait_for_function(
            ""document.getElementById('toast').textContent.includes('no storage access')""
        )
        browser.close()",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_storage_access_toast.py,,1,5.60279640614594e-09,"The method `test_storage_access_toast` is a test function that uses Playwright to automate a browser and verify a specific behavior on a webpage. It checks if a toast message indicating 'no storage access' appears, which is a valid and useful test case for web applications that need to handle storage access permissions. Given the increasing importance of privacy and storage access in web applications, this test is likely to remain relevant. Therefore, the method is likely to be retained as part of the test suite."
survived,"  def _format_param(self, value: Any) -> Any:
    """"""Format parameters for logging.""""""
    if isinstance(value, Resource):
      return value.name
    try:
      if isinstance(value, Sequence) and len(value) > 0 and isinstance(value[0], Resource):
        return [v.name for v in value]
    except Exception:
      pass
    return value
",pylabrobot/liquid_handling/liquid_handler.py,LiquidHandler,1,4.944450477491054e-09,"The method '_format_param' is a utility function designed to format parameters for logging purposes. It checks if the input value is an instance of 'Resource' and returns its name, or if it's a sequence of 'Resource' instances, it returns a list of their names. This functionality is useful for logging and debugging, especially in systems where resources are represented by objects with a 'name' attribute. The method is concise, serves a clear purpose, and handles exceptions gracefully. Therefore, it is likely to be retained in the codebase."
survived,"def test_evolve_tool() -> None:
    """"""Invoke ``evolve`` once and verify ``best_alpha`` output.""""""
    mod = importlib.import_module(""alpha_factory_v1.demos.aiga_meta_evolution.openai_agents_bridge"")
    runtime = mod.AgentRuntime(api_key=None)
    agent = mod.EvolverAgent()
    runtime.register(agent)

    asyncio.run(mod.evolve(1))
    result = asyncio.run(mod.best_alpha())
    assert ""architecture"" in result",tests/test_aiga_agents_bridge.py,,1,8.76424914819242e-08,"The method `test_evolve_tool` is a unit test designed to verify the functionality of the `evolve` and `best_alpha` methods from the `alpha_factory_v1.demos.aiga_meta_evolution.openai_agents_bridge` module. Unit tests are crucial for ensuring code reliability and are typically maintained as part of the codebase to prevent regressions. The test checks if the `best_alpha` method returns a result containing the key 'architecture', which is a specific and meaningful validation. Therefore, it is likely to be retained to ensure the continued correctness of the `evolve` functionality."
survived,"def _construct_payload(action: str, job_path: str | None) -> dict[str, object]:
    """"""Return request payload for ``action``.

    Parameters
    ----------
    action:
        Name of the helper action to invoke via ``business_helper``.
    job_path:
        Optional path to a JSON file with additional job parameters.

    The resulting dictionary is posted as JSON to the ``/invoke`` endpoint of
    the OpenAI Agents runtime. When ``job_path`` is provided the file contents
    are loaded and included under the ``job`` key.
    """"""

    payload: dict[str, object] = {""action"": action}
    if job_path:
        try:
            job_json = json.loads(Path(job_path).read_text(encoding=""utf-8""))
            payload[""job""] = job_json
        except Exception as exc:  # pragma: no cover - malformed file
            raise SystemExit(f""Failed to load job JSON: {exc}"")
    return payload
",alpha_factory_v1/demos/alpha_agi_business_v1/examples/openai_agent_client.py,,1,6.224144622520382e-11,"The method '_construct_payload' is well-defined and serves a clear purpose in constructing a payload for a specific action, potentially with additional job parameters from a JSON file. It includes error handling for file reading and JSON parsing, which is crucial for robustness. The use of type hints and a docstring enhances its readability and maintainability. Given these factors, the method is likely to be useful in its context and is not overly complex or redundant, suggesting it will be Survived."
survived,"    def tail(self, count: int = 10) -> List[dict[str, object]]:
        """"""Return the last ``count`` ledger entries.""""""

        assert self.conn is not None
        if self.db_type == ""postgres"":
            with self.conn.cursor() as cur:
                cur.execute(
                    ""SELECT ts, sender, recipient, payload FROM messages ORDER BY id DESC LIMIT %s"",
                    (count,),
                )
                rows = cur.fetchall()
        else:
            cur = self.conn.execute(
                ""SELECT ts, sender, recipient, payload FROM messages ORDER BY id DESC LIMIT ?"",
                (count,),
            )
            rows = cur.fetchall()
        result: List[dict[str, object]] = []
        for ts, sender, recipient, payload in reversed(rows):
            try:
                data = json.loads(payload)
            except Exception:
                data = payload
            result.append({""ts"": ts, ""sender"": sender, ""recipient"": recipient, ""payload"": data})
        return result
",alpha_factory_v1/common/utils/logging.py,Ledger,1,5.905303995456778e-10,"The method 'tail' is a useful utility function that retrieves the last 'count' number of ledger entries from a database. It supports both PostgreSQL and other databases by using different SQL syntax for each. The method is well-structured, handles exceptions when parsing JSON payloads, and returns a list of dictionaries, which is a common and useful data structure for further processing. There is no indication of redundancy or obsolescence in the method, and it serves a clear purpose in data retrieval. Therefore, it is likely to be retained in the codebase."
survived,"            def call_llama(prompt: str, s: Settings) -> str:
                out = cast(Any, _MODEL)(prompt, temperature=s.temperature)
                return cast(str, out[""choices""][0][""text""]).strip()
",alpha_factory_v1/common/utils/local_llm.py,,1,4.944450477491054e-09,"The method 'call_llama' is a simple utility function that takes a prompt and settings, and returns a processed string. It is likely to be a part of a larger system that interacts with a model, possibly for generating text or similar tasks. Such utility functions are generally useful and reusable, especially if the system relies on model interactions. Unless there is a significant change in the system architecture or the model interaction method, this function is likely to survive."
survived,"def chat(prompt: str, cfg: Settings | None = None) -> str:
    """"""Return a completion using the local model or a simple echo.""""""
    cfg = cfg or config.CFG
    if _CALL is None:
        _load_model(cfg)
    assert _CALL is not None
    try:
        with span(""local_llm.chat""):
            return _CALL(prompt, cfg)
    except Exception as exc:  # pragma: no cover - runtime error
        _log.exception(""Local chat failed: %s"", exc)
        return f""[offline] {prompt}""",alpha_factory_v1/common/utils/local_llm.py,,1,3.581747929000289e-10,"The method 'chat' is likely to survive because it is a core function that provides a key feature of the application: generating a response using a local model. It includes error handling to ensure robustness, and it uses configuration settings to allow flexibility. These characteristics suggest it is a well-designed and essential part of the system."
survived,"    def subscribe(self, topic: str, handler: Callable[[EnvelopeLike], Awaitable[None] | None]) -> None:
        self._subs.setdefault(topic, []).append(handler)
",alpha_factory_v1/common/utils/messaging.py,A2ABus,1,2.646573631904765e-09,"The method 'subscribe' is a fundamental part of a publish-subscribe pattern, which is a common design pattern in software development. It allows for decoupling of components by enabling them to communicate through a central event bus or message broker. The method is likely to be used for registering handlers that respond to specific topics, which is a core functionality in systems that rely on event-driven architecture. Given its utility and the fact that it is a simple, clear implementation, it is likely to be retained in the codebase."
survived,"    def rest_task(self) -> Optional[asyncio.Task]:
        return self._rest_task
",alpha_factory_v1/backend/services/api_server_service.py,APIServer,1,3.160881453314576e-10,"The method 'rest_task' is a simple getter for the '_rest_task' attribute. Such methods are typically retained in codebases as they provide a controlled way to access private or protected attributes, which is a common practice in object-oriented programming to maintain encapsulation. Unless there is a significant refactor or change in design that makes this method redundant, it is likely to survive."
survived,"        def publish(self, topic, msg):
            events.append((topic, msg))
",tests/test_kafka_service.py,DummyBus,1,5.60279640614594e-09,"The method 'publish' is a simple function that appends a tuple of 'topic' and 'msg' to a list called 'events'. This method is likely part of a larger system where events are being logged or queued for processing. The method itself is straightforward and serves a clear purpose of recording events, which is a common requirement in many applications. Without additional context suggesting that this functionality is no longer needed or has been replaced, it is reasonable to assume that this method will survive."
survived,"    async def stop(self) -> None:  # pragma: no cover - close handled by EventBus
        return None
",alpha_factory_v1/backend/services/kafka_service.py,KafkaService,1,1.3709566550544279e-06,"The method 'stop' is marked with a pragma comment 'no cover', indicating that it is intentionally excluded from test coverage. This suggests that the method is considered necessary for the code's functionality, even if it is not directly tested. Additionally, the method is asynchronous, which might be part of a larger asynchronous system where stopping or closing operations are handled by an event bus. This implies that the method serves a specific purpose in the system's architecture, likely related to resource management or cleanup. Therefore, it is unlikely to be deleted as it is part of the system's design, even if it currently returns None."
survived,"def test_memory_agent_file_cap(tmp_path: Path) -> None:
    mem_file = tmp_path / ""mem.log""
    cfg = config.Settings(bus_port=0, memory_path=str(mem_file))
    bus = messaging.A2ABus(cfg)
    ledger = logging.Ledger(str(tmp_path / ""ledger.db""))
    agent = memory_agent.MemoryAgent(bus, ledger, str(mem_file), memory_limit=2)

    envs = [messaging.Envelope(""a"", ""memory"", {""v"": i}, 0.0) for i in range(3)]

    async def _run() -> None:
        async with bus, ledger:
            for env in envs:
                await agent.handle(env)

    asyncio.run(_run())

    entries = [json.loads(line) for line in mem_file.read_text(encoding=""utf-8"").splitlines()]
    assert [e[""v""] for e in entries] == [1, 2]

    agent2 = memory_agent.MemoryAgent(bus, ledger, str(mem_file), memory_limit=2)
    assert [r[""v""] for r in agent2.records] == [1, 2]
",tests/test_memory_agent_file_persistence.py,,1,4.1399375473943306e-08,"The method `test_memory_agent_file_cap` is a unit test designed to verify the functionality of a memory agent's file capacity handling. It checks that the memory agent correctly limits the number of records stored in a file to a specified memory limit. This is a crucial test to ensure that the memory agent behaves as expected when the memory limit is reached, which is an important aspect of the system's functionality. Unit tests are generally not deleted unless the functionality they test is removed or significantly altered. Since this test is directly tied to the functionality of memory management, it is likely to be retained as long as the memory agent feature exists."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-h/compiler/py/q21.py,Auto1,1,8.76424914819242e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a flexible and Pythonic way to access object attributes, it is likely to be retained in the codebase."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-h/compiler/py/q9.py,_Group,1,3.3982678079468468e-09,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation here is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-h/compiler/py/q20.py,_Group,1,2.646573631904765e-09,"The method `__len__` is a special method in Python that is used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"def test_safari_offline_reload() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri()

    try:
        with sync_playwright() as p:
            browser = p.webkit.launch()
            context = browser.new_context(
                user_agent=(
                    ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) ""
                    ""AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.6 Safari/605.1.15""
                )
            )
            page = context.new_page()
            errors: list[str] = []
            page.on(""console"", lambda msg: errors.append(msg.text) if msg.type == ""error"" else None)
            page.on(""pageerror"", lambda err: errors.append(str(err)))

            page.goto(url)
            page.wait_for_selector(""#controls"")
            page.wait_for_function(""navigator.serviceWorker.ready"")

            context.set_offline(True)
            page.reload()
            page.wait_for_selector(""#controls"")
            context.set_offline(False)

            assert not errors, f""Console errors: {errors}""
            assert page.evaluate(""navigator.serviceWorker.controller !== null"")
            browser.close()
    except PlaywrightError as exc:
        pytest.skip(f""Playwright browser not installed: {exc}"")",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_safari_offline.py,,1,1.0467401685178159e-08,"The method 'test_safari_offline_reload' is a test function that checks the behavior of a web page when reloaded offline in a Safari-like environment using Playwright. It is a specific test case that ensures the service worker is controlling the page and that no console errors occur during the offline reload. Such test functions are typically retained as they are crucial for ensuring the reliability and correctness of web applications under different conditions. Additionally, the use of Playwright for browser automation is a common practice in modern testing frameworks, making this method relevant and likely to be maintained."
survived,"        def __init__(self) -> None:
            self.random = _RandomNormal()
",src/meta_agent/embedding_models.py,_NPStub,1,1.444980317078884e-07,"The method is a constructor for a class, indicated by the name `__init__`. Constructors are essential for initializing new objects and setting up initial states or attributes. The presence of `self.random = _RandomNormal()` suggests that this constructor is setting up an instance variable `random` with an instance of `_RandomNormal`. This is a typical and necessary operation in object-oriented programming to ensure that each instance of the class has its own `random` attribute. Therefore, it is unlikely that this method will be deleted as it is fundamental to the class's functionality."
survived,"            def _decorator(func):
                return func
",alpha_factory_v1/demos/cross_industry_alpha_factory/openai_agents_bridge.py,,1,7.73442280641062e-08,"The method _decorator is a simple function that takes another function as an argument and returns it unchanged. This is a common pattern used in Python for decorators, even though this specific implementation does not modify the function in any way. Such a method is often used as a placeholder or a base for more complex decorators. Since it is a valid and potentially useful pattern, especially in the context of building more complex decorators, it is likely to be Survived."
survived,"            async def step(self):
                return None
",tests/test_agents_registry.py,TestAgentRegistryFunctions.DummyAgent,0,0.9999970976877992,"The method 'step' is an asynchronous function that currently does nothing but return None. If this method is part of a larger codebase, it might be a placeholder for future implementation. However, if it remains unchanged and unused, it is likely to be deleted in future refactoring efforts to clean up the code. Without additional context on its intended use or any comments indicating future plans, the method seems redundant."
survived,"    def __init__(self):
        super().__init__()
        self.calls = 0
",tests/test_agent_base.py,DummyAgent,1,1.3440409770490404e-08,"The method is a constructor (__init__) which is a fundamental part of class instantiation in Python. It initializes the object and sets up initial state, in this case, initializing a 'calls' attribute to 0. Such methods are essential for object-oriented programming and are unlikely to be deleted unless the class itself is being removed or significantly refactored."
survived,"    def test_run_cycle_publishes(self):
        agent = PingAgent()
        agent.orchestrator = DummyOrch()
        asyncio.run(agent.setup())
        asyncio.run(agent.run_cycle())
        asyncio.run(agent.teardown())
        self.assertEqual(len(agent.orchestrator.published), 1)
        topic, payload = agent.orchestrator.published[0]
        self.assertEqual(topic, ""agent.ping"")
        self.assertIn(""agent"", payload)
        self.assertEqual(payload[""agent""], agent.NAME)
",tests/test_ping_agent.py,TestPingAgent,1,1.0467401685178159e-08,"The method `test_run_cycle_publishes` is a unit test designed to verify the behavior of the `PingAgent` class. It checks that the `run_cycle` method correctly publishes a message to the orchestrator. Unit tests are crucial for ensuring code reliability and are typically maintained or expanded rather than deleted. The test is well-structured, using assertions to validate expected outcomes, which is a standard practice in software development to ensure code correctness. Therefore, it is likely to be retained."
survived,"    async def run_cycle(self) -> None:  # pragma: no cover - default wrapper
        """"""Single orchestrator cycle  runs :meth:`step` once.""""""
        await self.step()
",alpha_factory_v1/backend/agents/base.py,AgentBase,1,9.237449576640118e-09,"The method `run_cycle` is a simple asynchronous wrapper that calls another method `step`. It is marked with `# pragma: no cover`, indicating that it is intentionally excluded from test coverage, which suggests that it is considered stable or trivial. The method is likely part of a larger framework or system where such orchestration methods are common and necessary for managing asynchronous operations. Since it serves a clear purpose and is part of a typical design pattern in asynchronous programming, it is unlikely to be removed unless there is a significant redesign of the system."
survived,"    def test_sha_deterministic(self):
        payload = {""a"": 1, ""b"": 2}
        expected = energy_agent.hashlib.sha256(
            energy_agent.json.dumps(payload, separators=("","", "":"")).encode()
        ).hexdigest()
        self.assertEqual(energy_agent._sha(payload), expected)
",tests/test_energy_utils.py,TestEnergyUtils,1,1.275190675769241e-07,"The method 'test_sha_deterministic' is a unit test designed to verify the deterministic behavior of a SHA-256 hashing function. It compares the hash of a JSON payload generated by the '_sha' method with an expected hash value. This is a standard practice in software development to ensure that functions behave as expected. Since testing is a crucial part of maintaining code quality and reliability, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered."
survived,"    def __init__(self) -> None:
        self.calls = 0
",tests/test_agent_runner.py,DummyAgent,1,4.6911638017642294e-08,"The method is a constructor for a class, indicated by the name `__init__`. Constructors are essential for initializing new objects in object-oriented programming. The presence of the `self.calls` attribute suggests that this constructor is setting up an initial state for instances of the class, which is a fundamental part of class design. Therefore, it is unlikely that this method will be deleted as it serves a critical role in object initialization."
survived,"def test_run_evolution_different_seeds() -> None:
    def fn(genome: list[float]) -> tuple[float, float]:
        x, y = genome
        return x**2, y**2

    pop1 = mats.run_evolution(fn, 2, population_size=3, generations=1, seed=1)
    pop2 = mats.run_evolution(fn, 2, population_size=3, generations=1, seed=2)

    assert [ind.genome for ind in pop1] != [ind.genome for ind in pop2]",tests/test_mats.py,,1,2.3355930333443423e-09,"The method `test_run_evolution_different_seeds` is a unit test designed to verify that the `run_evolution` function produces different results when initialized with different random seeds. This is a common and important test to ensure that the function's behavior is non-deterministic and sensitive to the seed value, which is a critical aspect of evolutionary algorithms. Since this test serves a clear purpose in validating the functionality of the `run_evolution` method, it is likely to be retained in the codebase."
survived,"def test_env_value_escaped(tmp_path: Path) -> None:
    browser_dir = Path(__file__).resolve().parents[1]
    target = tmp_path / ""browser""
    shutil.copytree(browser_dir, target)
    token = ""foo</script>bar""
    (target / "".env"").write_text(f""PINNER_TOKEN={token}\n"")
    subprocess.check_call([""npm"", ""run"", ""build""], cwd=target)

    html_text = (target / ""dist"" / ""index.html"").read_text()
    assert token not in html_text
    assert ""window.PINNER_TOKEN=atob("" in html_text

    url = (target / ""dist"" / ""index.html"").as_uri()
    with sync_playwright() as p:
        browser = p.chromium.launch()
        page = browser.new_page()
        page.goto(url)
        page.wait_for_selector(""#controls"")
        assert page.evaluate(""window.PINNER_TOKEN"") == token
        browser.close()",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_env_escaping.py,,1,3.2241866333029355e-08,"The method 'test_env_value_escaped' is a test function that verifies the correct handling of environment variables in a web application build process. It ensures that sensitive tokens are not directly exposed in the HTML output and are instead encoded. This is a crucial security measure in web development to prevent XSS attacks and protect sensitive information. The function uses a temporary path to simulate the build process, checks the HTML output for proper encoding, and uses Playwright to simulate a browser environment for further validation. Such tests are essential for maintaining the security and integrity of web applications, making it unlikely to be deleted."
survived,"async def test_parallel():
    outputs = []

    async def r1(prompt, **kwargs):
        outputs.append(""r1"")
        return prompt + ""-r1""

    async def r2(prompt, **kwargs):
        outputs.append(""r2"")
        return prompt + ""-r2""

    wf = Workflow(
        name=""wf"",
        steps=[WorkflowStep(runner=[r1, r2], mode=StepMode.PARALLEL)],
    )

    result = await wf.run(""x"")
    assert sorted(outputs) == [""r1"", ""r2""]
    assert sorted(result) == [""x-r1"", ""x-r2""]
",tests/test_workflow.py,,1,6.69158608681505e-10,"The method 'test_parallel' is testing a parallel execution of two asynchronous functions 'r1' and 'r2' within a workflow. This is a common pattern in modern programming, especially with the rise of asynchronous programming and parallel processing to improve performance. The method is well-structured, uses async/await syntax correctly, and includes assertions to verify the expected behavior. There is no indication that this method is obsolete or redundant, and it serves a clear purpose in testing the parallel execution feature of the workflow. Therefore, it is likely to be retained."
survived,"async def test_sequential_defaults():
    called = {}

    async def runner(prompt, user_id=None, session_id=None, llm=None, sdk_context=None):
        called['params'] = (user_id, session_id, llm, sdk_context)
        return prompt + ""-done""

    wf = Workflow(
        name=""wf"",
        instruction=""instr"",
        description=""desc"",
        default_llm=""llm"",
        sdk_context=SDKContext(""./swarmzero_config_test.toml""),
        default_user_id=""u"",
        default_session_id=""s"",
        steps=[WorkflowStep(runner=runner)],
    )

    result = await wf.run(""hi"")
    assert result == ""hi-done""
    assert called[""params""][:3] == (""u"", ""s"", ""llm"")
    assert isinstance(called[""params""][3], SDKContext)
",tests/test_workflow.py,,1,2.5109990926928157e-08,"The method `test_sequential_defaults` is a test function that verifies the behavior of a workflow system. It checks if the default parameters are correctly passed to the runner function and if the workflow produces the expected result. Test functions like this are crucial for ensuring the reliability and correctness of code, especially in systems that involve asynchronous operations and multiple components. Therefore, it is unlikely to be deleted as it serves an important role in maintaining code quality."
survived,"    async def _run() -> None:
        await agents[0].run_cycle()
        assert plan_msgs, ""planning agent did not emit research plan""

        await agents[1].handle(plan_msgs[0])
        assert strat_msgs, ""research agent did not emit strategy payload""

        await agents[2].handle(strat_msgs[0])
        assert market_msgs, ""strategy agent did not emit market analysis""

        await agents[3].handle(market_msgs[0])
        assert code_msgs, ""market agent did not emit code generation task""

        await agents[4].handle(code_msgs[0])
        assert safety_in, ""codegen agent did not emit safety event""

        await agents[5].handle(safety_in[0])
        assert memory_msgs, ""safety agent did not emit memory payload""

        await mem_agent.handle(memory_msgs[0])
        assert mem_agent.records, ""memory agent did not store payload""
        ledger.close()
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_agents.py,,1,7.73442280641062e-08,"The method '_run' is an asynchronous function that coordinates a sequence of operations involving multiple agents. Each agent is expected to emit a specific message that is then handled by the next agent in the sequence. The method includes assertions to ensure that each step in the process is completed successfully, which is crucial for debugging and maintaining the integrity of the workflow. Given its structured approach to handling asynchronous operations and its role in ensuring the correct flow of data between agents, this method is likely to be essential for the system's operation. Therefore, it is unlikely to be deleted."
survived,"async def test_example_runs(example):
    example_path = Path(__file__).resolve().parents[1] / ""examples"" / example
    db_path = example_path.parent / ""shop.db""
    if db_path.exists():
        db_path.unlink()

    params = StdioServerParameters(command=sys.executable, args=[str(example_path)])
    async with ClientSessionGroup() as group:
        session = await group.connect_to_server(params)
        await session.list_tools()

    # Clean up database file if created by shop_api_sqlite example
    if db_path.exists():
        db_path.unlink()",tests/test_examples.py,,1,5.60279640614594e-09,"The method 'test_example_runs' is an asynchronous test function that checks if a given example script runs correctly. It sets up the environment by ensuring any pre-existing database file is removed, runs the example script, and then cleans up by removing the database file if it was created. This method is useful for automated testing and ensuring that example scripts function as expected without leaving residual files. Given its utility in testing and maintaining code quality, it is likely to be retained."
survived,"def test_scatter_add():
    B, S, V = Axis(""batch"", 2), Axis(""seq"", 3), Axis(""vocab"", 5)
    x = hax.zeros((B, S, V))
    idx = hax.arange((B, S), dtype=jnp.int32) % V.size
    ones = hax.ones((B, S))
    y = x.at[{V: idx}].add(ones)
    ref = jnp.zeros((2, 3, 5)).at[jnp.arange(2)[:, None], jnp.arange(3)[None, :], idx.array].add(1.0)
    assert jnp.array_equal(y.array, ref)
",tests/test_scatter_gather.py,,1,1.3440409770490404e-08,"The method 'test_scatter_add' is a unit test function that verifies the functionality of a scatter-add operation using a hypothetical library 'hax'. It creates a zero-initialized tensor 'x', computes indices 'idx', and adds ones to 'x' at specified indices. It then compares the result with a reference tensor 'ref' using an assertion. This test is crucial for ensuring the correctness of the scatter-add operation, which is a common operation in many numerical computing tasks. Since it is a test function, it is likely to be maintained as long as the functionality it tests is relevant and the library 'hax' is in use. Therefore, the method is likely to survive."
survived,"def test_noncontig_selectors():
    B, X, Z, Y = Axis(""batch"", 2), Axis(""x"", 4), Axis(""z"", 6), Axis(""y"", 5)
    a = hax.arange((B, X, Z, Y))
    ix = hax.arange((B,), dtype=jnp.int32) % X.size
    iy = hax.arange((B,), dtype=jnp.int32) % Y.size
    out = a[""x"", ix, ""y"", iy]
    assert out.axes == (B, Z)
    ref = a.array[jnp.arange(2), ix.array, :, iy.array]
    assert jnp.array_equal(out.array, ref)
",tests/test_scatter_gather.py,,1,4.4508487281649027e-07,"The method 'test_noncontig_selectors' is a test function that verifies the behavior of a specific feature in a codebase, likely related to handling non-contiguous selectors in a multi-dimensional array. Test functions are crucial for ensuring code correctness and stability, especially in complex systems. They help catch bugs and regressions when changes are made to the code. Therefore, it is unlikely that this method will be deleted as it serves an important role in maintaining the integrity of the codebase."
survived,"def test_selector_adds_new_axis():
    B, S, V, T = Axis(""batch"", 2), Axis(""seq"", 3), Axis(""vocab"", 5), Axis(""step"", 4)
    logits = hax.arange((B, S, V))
    idx = hax.arange((B, T), dtype=jnp.int32) % V.size
    out = logits[""vocab"", idx]
    assert set(out.axes) == {B, S, T}
    ref = jnp.transpose(_ref_gather(logits, V, idx), (0, 2, 1))
    assert jnp.array_equal(out.array, ref)
",tests/test_scatter_gather.py,,1,6.023574641292144e-08,"The method 'test_selector_adds_new_axis' is a unit test function that verifies the behavior of a specific feature in a codebase, likely related to tensor operations or a library that deals with multi-dimensional arrays. Unit tests are crucial for ensuring code correctness and preventing regressions. This test checks if a new axis is correctly added and if the output matches a reference implementation. Such tests are typically retained to maintain code quality and reliability."
survived,"    def num_completion_tokens(self) -> int:
        return len(self.token_ids) - self.num_prompt_tokens
",src/levanter/inference/sequence.py,Sequence,1,3.581747929000289e-10,"The method `num_completion_tokens` is a simple utility function that calculates the number of completion tokens by subtracting the number of prompt tokens from the total number of token IDs. This kind of method is often useful in contexts where token management is important, such as in natural language processing tasks or when working with APIs that require token counting (e.g., OpenAI's GPT models). Since it provides a clear and necessary functionality, it is likely to be retained in the codebase."
survived,"        def _finish(st):
            st.active = st.active.at[idx].set(False)
            st.tail = (st.tail + 1) % self.max_seqs
            return st
",src/levanter/inference/scheduler.py,JittedScheduler,1,3.0590235908148916e-07,"The method '_finish' is a private method (indicated by the underscore) and seems to be part of a larger class or module that manages some kind of state object 'st'. The method modifies the 'active' attribute of 'st' and updates 'st.tail', which suggests it is performing necessary state management tasks. Without additional context, such as the rest of the class or module, it's difficult to determine if this method is redundant or if its functionality is covered elsewhere. However, given that it performs specific state updates, it is likely an integral part of the class's functionality. Therefore, it is more likely to be retained unless there is a refactor that changes how state is managed."
survived,"    def __len__(self) -> int:
        return len(self.token_ids)
",src/levanter/inference/sequence.py,Sequence,1,4.944450477491054e-09,"The method `__len__` is a standard Python special method used to define the behavior of the `len()` function for instances of a class. It is a common and useful method that allows objects to be used in a more Pythonic way, enabling them to be compatible with Python's built-in functions and idioms. The implementation here is straightforward and correctly returns the length of `self.token_ids`, which suggests that `self.token_ids` is a list or similar iterable. There is no indication that this method is redundant or incorrect, so it is likely to be retained."
survived,"    def generate(
        self, prompts: List[str] | List[List[int]], sampling_params: SamplingParams | List[SamplingParams]
    ) -> List[dict]:
        if not isinstance(sampling_params, list):
            sampling_params = [sampling_params] * len(prompts)

        prompt_ids_list: List[List[int]] = [
            self.tokenizer.encode(p, add_special_tokens=False) if isinstance(p, str) else list(p)
            for p in prompts
        ]

        if len(prompt_ids_list) > MAX_SEQS:
            raise ValueError(f""Too many prompts: got {len(prompt_ids_list)}, max {MAX_SEQS}"")

        max_prompt = max(len(p) for p in prompt_ids_list)
        max_tokens = max(sp.max_tokens for sp in sampling_params)
        page_size = _round_preferred(max_prompt + max_tokens)
        page_table = PageTable.init(
            max_pages=MAX_SEQS,
            max_seqs=MAX_SEQS,
            page_size=page_size,
            max_pages_per_seq=1,
        )
        seq_ids = []
        for _ in prompt_ids_list:
            page_table, seq_id = page_table.assign_seq_id_to_seq()
            seq_ids.append(seq_id)
        cache = self.model.initial_cache(page_table, dtype=self.trainer_cfg.mp.compute_dtype)

        scheduler = Scheduler(self.eos)
        seq_objs = []
        for p, sp, seq_id in zip(prompt_ids_list, sampling_params, seq_ids):
            seq = Sequence(p, sp, seq_id=seq_id)
            seq_objs.append(seq)
            scheduler.add(seq)

        outputs = {}
        while not scheduler.is_finished():
            seqs, is_prefill = scheduler.schedule()
            token_ids = []
            for seq in seqs:
                if is_prefill and seq.status is SequenceStatus.WAITING:
                    tok, cache, page_table = self._prefill(seq, cache, page_table)
                    seq.status = SequenceStatus.RUNNING
                else:
                    tok, cache, page_table = self._decode(seq, cache, page_table, len(seq))
                token_ids.append(tok)
            scheduler.postprocess(seqs, token_ids)
            for seq in seqs:
                if seq.is_finished:
                    outputs[seq.seq_id] = seq.token_ids
        return [
            {""text"": self.tokenizer.decode(out, skip_special_tokens=True), ""token_ids"": out}
            for _, out in sorted(outputs.items())
        ]
",src/levanter/inference/llm_engine.py,LLMEngine,1,2.998960815863541e-09,"The method 'generate' is a core part of a text generation system, handling the conversion of prompts into tokenized sequences, managing the scheduling of sequences, and decoding them into outputs. It is well-structured, uses type hints, and handles various edge cases like too many prompts. Such a method is essential for the functionality of a text generation model and is unlikely to be removed unless there is a significant redesign of the system."
survived,"    def postprocess(self, seqs: List[Sequence], token_ids: List[int]) -> None:
        for seq, token_id in zip(seqs, token_ids):
            seq.append_token(int(token_id))
            if (
                (not seq.sampling_params.ignore_eos and token_id == self.eos)
                or seq.num_completion_tokens >= seq.sampling_params.max_tokens
            ):
                seq.status = SequenceStatus.FINISHED
",src/levanter/inference/scheduler.py,Scheduler,1,3.3982678079468468e-09,"The method 'postprocess' is likely to be Survived (1) because it performs a crucial role in processing sequences by appending tokens and determining the completion status of each sequence. This functionality is essential in many applications involving sequence generation or processing, such as natural language processing tasks. The method is well-structured, with clear logic for handling end-of-sequence conditions and token limits, making it a valuable part of the codebase."
survived,"def gen_wd_table(n):
    goal = [[0] * i + [n] + [0] * (n - 1 - i) for i in range(n)]
    goal[-1][-1] = n - 1
    goal = tuple(sum(goal, []))

    table = {}
    to_visit = [(goal, 0, n-1)]
    while to_visit:
        cfg, cost, e = to_visit.pop(0)
        enccfg = encode_cfg(cfg, n)
        if enccfg in table: continue
        table[enccfg] = cost

        for d in [-1, 1]:
            if 0 <= e + d < n:
                for c in range(n):
                    if cfg[n*(e+d) + c] > 0:
                        ncfg = list(cfg)
                        ncfg[n*(e+d) + c] -= 1
                        ncfg[n*e + c] += 1
                        to_visit.append((tuple(ncfg), cost + 1, e+d))

    return table
",tests/rosetta/x/Python/15-puzzle-solver/15-puzzle-solver-1.py,,1,7.194132978569833e-09,"The method `gen_wd_table` appears to be a utility function that generates a table of configurations and their associated costs for a given problem. It uses a breadth-first search approach to explore possible configurations and stores them in a dictionary. The function is self-contained, does not rely on external dependencies, and seems to serve a specific purpose in a larger system. Unless there is a significant change in the requirements or the problem it addresses becomes obsolete, there is no immediate reason to delete this method. It is likely to be retained as part of the codebase."
survived,"    def __repr__(self):
        # printable version of self

        return str(self.tiles[0])+'\n'+str(self.tiles[1])+'\n'+str(self.tiles[2])+'\n'+str(self.tiles[3])+'\n'
",tests/rosetta/x/Python/15-puzzle-solver/15-puzzle-solver-2.py,Position,1,2.5109990926928157e-08,"The __repr__ method is a special method used to define a string representation of an object. In this case, it returns a string that represents the object by concatenating the string representations of the first four elements of the 'tiles' attribute, each followed by a newline character. This method is useful for debugging and logging purposes, as it provides a human-readable representation of the object. Since it serves a clear purpose and follows the expected behavior of a __repr__ method, it is likely to be retained in the code."
survived,"def slide_randomize(p, neighbours):
    for _ in range(len(p) ** 2):
        _, p, _ = random.choice(list(neighbours(p)))
    return p
",tests/rosetta/x/Python/15-puzzle-solver/15-puzzle-solver-1.py,,0,0.9999999865595903,"The method 'slide_randomize' is likely to be deleted (0) because it has a few issues that make it less useful or efficient. Firstly, the method uses a nested loop structure that iterates over the square of the length of 'p', which can be computationally expensive for large inputs. Secondly, the method relies on 'random.choice' and 'neighbours(p)', but without knowing the implementation of 'neighbours', it's unclear if this operation is meaningful or efficient. Additionally, the method's purpose is not clear from its name or implementation, which can lead to confusion and maintenance challenges. These factors suggest that the method might be considered for deletion or significant refactoring."
survived,"def find_zero(tiles):
    """""" file the 0 tile """"""
    for row in range(4):
        for col in range(4):
            if tiles[row][col] == 0:
                return (row, col)
",tests/rosetta/x/Python/15-puzzle-solver/15-puzzle-solver-2.py,,1,4.944450477491054e-09,"The method 'find_zero' is a simple utility function that searches for the first occurrence of the number 0 in a 4x4 grid (list of lists) and returns its position as a tuple (row, col). This is a common operation in grid-based puzzles or games, such as the 15-puzzle, where finding the position of the empty space (represented by 0) is necessary for making moves. The function is straightforward, efficient, and serves a clear purpose, making it likely to be retained in the codebase."
survived,"    def _search(self, g, bound):
        self.nodes_evaluated += 1

        node = self.path[-1]
        f = g + self.h(node)
        if f > bound: return f
        if self.is_goal(node): return self.FOUND

        m = None # Lower bound on cost.
        for cost, n, descr in self.neighbours(node):
            if n in self.is_in_path: continue

            self.path.append(n)
            self.is_in_path.add(n)
            self.path_descrs.append(descr)
            t = self._search(g + cost, bound)

            if t == self.FOUND: return self.FOUND
            if m is None or (t is not None and t < m): m = t

            self.path.pop()
            self.path_descrs.pop()
            self.is_in_path.remove(n)

        return m
",tests/rosetta/x/Python/15-puzzle-solver/15-puzzle-solver-1.py,IDAStar,1,5.905303995456778e-10,"The method '_search' is a recursive function that appears to be part of an iterative deepening A* (IDA*) search algorithm. It is a core component of the algorithm, responsible for exploring nodes, evaluating paths, and determining if the goal has been reached. Such methods are typically essential for the functionality of search algorithms in AI and pathfinding applications. Given its importance in the algorithm's operation, it is unlikely to be deleted unless the entire algorithm is being refactored or replaced. Therefore, the method is likely to survive."
survived,"    def Init(logger:logging.Logger, moonrakerConfigFilePath:Optional[str], isCompanionMode:bool):
        MoonrakerCredentialManager._Instance = MoonrakerCredentialManager(logger, moonrakerConfigFilePath, isCompanionMode)
",moonraker_octoeverywhere/moonrakercredentialmanager.py,MoonrakerCredentialManager,1,1.522997951276035e-08,"The method 'Init' is a static method that initializes a singleton instance of 'MoonrakerCredentialManager'. This pattern is common in scenarios where a single instance of a class is needed throughout the application, such as managing credentials or configurations. The method is likely to be used during the setup or configuration phase of an application that interacts with Moonraker, a 3D printer management system. Given its role in initializing a critical component, it is unlikely to be deleted unless the entire architecture or design pattern changes significantly. Therefore, it is more likely to survive."
survived,"    def test_sanity_check_patch_nonexistent(self):
        with tempfile.TemporaryDirectory() as repo:
            open(os.path.join(repo, ""file.py""), ""w"").close()
            bad_patch = """"""--- a/missing.py
+++ b/missing.py
@@
-print('x')
+print('y')
""""""
            with self.assertRaises(ValueError):
                patcher_core._sanity_check_patch(bad_patch, pathlib.Path(repo))
",tests/test_self_healing_patcher.py,TestPatcherCore,1,9.237449576640118e-09,"The method 'test_sanity_check_patch_nonexistent' is a unit test designed to verify that the '_sanity_check_patch' function in the 'patcher_core' module correctly raises a 'ValueError' when a patch is applied to a nonexistent file. This is a valid and useful test case to ensure the robustness of the patching functionality, especially in handling erroneous inputs. Therefore, it is likely to be retained as part of the test suite to maintain code quality and reliability."
survived,"    def test_meta_bridge_compiles(self):
        """"""Ensure the meta-agentic demo bridge compiles.""""""
        path = Path('alpha_factory_v1/demos/meta_agentic_agi/openai_agents_bridge.py')
        py_compile.compile(path, doraise=True)
",tests/test_openai_bridge.py,TestOpenAIBridge,1,4.363462233903899e-09,"The method 'test_meta_bridge_compiles' is a unit test that checks if a specific Python script compiles without syntax errors. This is a basic and useful test to ensure that the code is syntactically correct before running more complex tests or deploying the code. Such tests are generally considered good practice in software development as they help catch errors early in the development process. Therefore, it is likely to be retained."
survived,"def summarise_with_agent(mean_coop: float, *, agents: int, rounds: int, delta: float, stake: float) -> str:
    """"""Return a natural-language summary of a simulation result.

    If the ``openai`` package and an API key are available, the summary is
    generated with an LLM via the OpenAI Agents SDK.  Otherwise a simple
    fallback string is returned.
    """"""

    base_msg = (
        ""Simulation with {agents} agents, {rounds} rounds, delta={delta}, stake={stake} ""
        ""yielded mean cooperation  {coop:.3f}.""
    ).format(agents=agents, rounds=rounds, delta=delta, stake=stake, coop=mean_coop)

    try:  # optional dependency
        import openai

        client = openai.OpenAI(api_key=os.getenv(""OPENAI_API_KEY""))
        completion = client.chat.completions.create(
            model=""gpt-4o"",
            messages=[
                {""role"": ""system"", ""content"": ""Summarise AGIALPHA governance simulation results.""},
                {""role"": ""user"", ""content"": base_msg},
            ],
            max_tokens=60,
        )
        return completion.choices[0].message.content.strip()
    except Exception:
        return base_msg
",alpha_factory_v1/demos/solving_agi_governance/governance_sim.py,,1,1.3440409770490404e-08,"The method 'summarise_with_agent' is likely to survive because it provides a useful functionality of summarizing simulation results using natural language. It has a fallback mechanism in case the OpenAI API is not available, ensuring that it can still return a meaningful output. Additionally, the use of an external API to enhance the summary with a language model adds value to the method, making it more versatile and appealing for users who have access to the OpenAI API."
survived,"    def test_basic_convergence(self) -> None:
        coop = run_sim(agents=50, rounds=500, delta=0.85, stake=2.5, seed=1)
        self.assertGreater(coop, 0.7)
",tests/test_governance_sim.py,TestGovernanceSim,1,1.6052280526088547e-09,"The method 'test_basic_convergence' is a unit test that checks the convergence of a simulation function 'run_sim'. It asserts that the result of the simulation is greater than 0.7, which is a valid test case to ensure the simulation behaves as expected. There is no indication that this test is redundant or incorrect, and it serves a purpose in verifying the functionality of the 'run_sim' function. Therefore, it is likely to be retained."
survived,"    def reset(self) -> None:
        """"""Return to generation zero with a fresh population.""""""
        self._init_population()
        self.gen = 0
        self.history.clear()
        self._archive.clear()
        self._best_fitness = -math.inf
        self.best_genome = self.population[0]
        self._last_scores.clear()
",alpha_factory_v1/demos/aiga_meta_evolution/meta_evolver.py,MetaEvolver,1,1.4166087846364157e-09,"The method 'reset' is likely to survive because it serves a clear and useful purpose in the context of evolutionary algorithms or genetic programming. It resets the state of the object to its initial conditions, which is essential for starting a new run or experiment. This functionality is crucial for testing, debugging, and running multiple iterations of an algorithm without creating a new instance of the class each time. The method is well-defined, with clear steps to reset various attributes, indicating it is thoughtfully implemented and necessary for the class's functionality."
survived,"def add(a, b):
    return a + b
",tests/machine/x/python/fun_call.py,,1,2.0611536181902033e-09,"The method 'add' is a simple and fundamental utility function that performs addition of two numbers. Such basic arithmetic operations are commonly used in various programming tasks and are unlikely to be removed unless they are redundant or replaced by a more efficient or necessary implementation. Given its simplicity and utility, it is more likely to be retained in the codebase."
survived,"def inc(x: int) -> int:
    return x + k
",tests/machine/x/python/pure_global_fold.py,,0,0.999999922655772,"The method 'inc' is likely to be deleted because it references a variable 'k' that is not defined within the function or passed as a parameter. This will result in a NameError when the function is called, making it non-functional in its current state. Without additional context or corrections, such as defining 'k' or passing it as an argument, the function cannot operate as intended."
survived,"def _free_port() -> int:
    s = socket.socket()
    s.bind((""localhost"", 0))
    port = s.getsockname()[1]
    s.close()
    return port
",tests/test_agents.py,,1,4.1399375473943306e-08,"The method _free_port is a utility function that finds and returns an available port on the localhost. This is a common requirement in network programming, especially for testing purposes where a free port is needed to bind a service temporarily. The method is simple, effective, and does not have any apparent issues or redundancies that would warrant its deletion. It is likely to be useful in various scenarios where dynamic port allocation is necessary."
survived,"    def test_cpu_alignment(self):
        sw = SmithWatermanGPU()
        score, _ = sw.align(""ACACACTA"", ""AGCACACA"")
        self.assertEqual(score, 17)
",src/test/python/test_gpu_smith_waterman.py,TestSmithWatermanGPU,1,8.152020648014727e-09,"The method `test_cpu_alignment` is a unit test for the `SmithWatermanGPU` class, specifically testing the `align` method. Unit tests are crucial for ensuring code correctness and are typically retained in the codebase to verify that changes do not break existing functionality. The test checks if the alignment score is as expected, which is a common practice in software development to maintain code quality. Therefore, it is unlikely that this method will be deleted."
survived,"    def _plot_nicely(self, mat, title, xlabel, ylabel, outfile=None):
        fig = plt.figure()
        ax = fig.add_subplot(111)
        im = ax.matshow(mat)
        ax.set_title(title)
        ax.set_xlabel(xlabel)
        ax.set_ylabel(ylabel)
        ax.set_aspect(2)
        ax.set_aspect(""auto"")
        plt.colorbar(im)
        if outfile is not None:
            plt.savefig(outfile)
        plt.show()
",examples/synthetic_data.py,HldaDataGenerator,1,1.1032560311263802e-09,"The method '_plot_nicely' is a utility function for plotting matrices with matplotlib. It includes features like setting titles, labels, aspect ratios, and saving the plot to a file. These are common and useful functionalities in data visualization tasks, especially in data analysis and machine learning projects. The method is well-structured and provides flexibility with the 'outfile' parameter for saving plots, which is a desirable feature. Therefore, it is likely to be retained in the codebase."
survived,"    def labels(self, *a, **kw):
        return self
",tests/test_eventbus.py,_M,0,0.9999995549151272,"The method 'labels' is defined to take any number of positional and keyword arguments but simply returns the instance itself without performing any operations. This suggests that the method is likely a placeholder or a stub, which might be intended for future implementation or to fulfill an interface requirement. However, as it currently stands, it doesn't provide any functionality. If the method is not used or needed in its current form, it is likely to be deleted in future iterations of the code to clean up unnecessary code."
survived,"    def inc(self, *a, **kw):
        pass
",tests/test_eventbus.py,_M,0,0.9999999468421502,"The method 'inc' is defined but not implemented, as it only contains a 'pass' statement. This suggests that it is either a placeholder for future implementation or it is not needed. Without any additional context or usage of this method in the code, it is likely to be deleted in future refactoring to clean up the codebase."
survived,"    def read_and_clear(self, topic: str | None = None) -> Dict[str, list[Dict[str, Any]]]:
        """"""Return queued events and clear the buffers (dev mode helper).""""""
        if self._queues is None:
            return {}
        topics = [topic] if topic else list(self._queues)
        result: Dict[str, list[Dict[str, Any]]] = {}
        for t in topics:
            q = self._queues.get(t)
            if not q:
                continue
            items: list[Dict[str, Any]] = []
            while not q.empty():
                try:
                    items.append(q.get_nowait())
                except asyncio.QueueEmpty:
                    break
            if items:
                result[t] = items
        return result
",alpha_factory_v1/backend/agent_runner.py,EventBus,1,8.76424914819242e-08,"The method 'read_and_clear' is a utility function that serves a specific purpose in a development environment by reading and clearing event queues. It is a helper function that is likely used for testing or debugging purposes, which are common needs in software development. Such methods are typically retained in codebases because they provide valuable functionality for developers to monitor and manage the state of the application during development. Additionally, the method is well-defined, handles edge cases (like empty queues), and returns a structured result, making it a useful tool. Therefore, it is likely to be retained in the codebase."
survived,"async def test_guardrails_called_in_order():
    adapter = MockAdapter()
    router = GuardrailModelRouter({""a"": adapter}, default_model=""a"")
    order: list[str] = []

    async def input_guardrail(prompt: str):
        order.append(f""in:{prompt}"")

    async def output_guardrail(output: str):
        order.append(f""out:{output}"")

    router.add_input_guardrail(input_guardrail)
    router.add_output_guardrail(output_guardrail)

    res = await router.invoke(""test"")

    assert res == ""test:ok""
    assert order == [""in:test"", ""out:test:ok""]",tests/test_guardrail_router.py,,1,1.1032560311263802e-09,"The method 'test_guardrails_called_in_order' is a test function that verifies the order of execution for input and output guardrails in an asynchronous context. It uses a mock adapter and a router to simulate the process, and then checks if the guardrails are called in the correct order. This is a typical unit test pattern to ensure that the system behaves as expected. Such test functions are crucial for maintaining code quality and are unlikely to be deleted unless the functionality they test is removed or significantly altered. Therefore, the method will likely survive."
survived,"    def _check_mixed_args_grad(self, name: str):
        """"""Verify gradient of the dot product xy with respect to each argument.""""""
        try:
            backend.set_backend(name)
        except ImportError:
            raise unittest.SkipTest(f""{name} backend not available"")
        b = backend.current()

        def f(x, y):
            return b.sum(b.mul(x, y))

        gx = b.grad(f, wrt=0)
        gy = b.grad(f, wrt=1)
        x = b.array([1.0, 2.0, 3.0], requires_grad=True)
        y = b.array([4.0, 5.0, 6.0], requires_grad=True)
        gradx = to_numpy(gx(x, y))
        grady = to_numpy(gy(x, y))
        np.testing.assert_allclose(np.array(gradx), np.array([4.0, 5.0, 6.0]))
        np.testing.assert_allclose(np.array(grady), np.array([1.0, 2.0, 3.0]))
",tests/test_autograd.py,TestAutograd,1,1.522997951276035e-08,"The method '_check_mixed_args_grad' is a utility function designed to verify the gradient computation of a dot product operation with respect to its arguments using a specified backend. This is a common requirement in machine learning frameworks where different backends (like TensorFlow, PyTorch, etc.) might be used for computation. The method includes error handling for unavailable backends and uses assertions to ensure the gradients are computed correctly. Such utility functions are crucial for testing and ensuring the reliability of gradient computations across different backends, which is a fundamental aspect of machine learning libraries. Therefore, it is likely to be retained as it serves an important purpose in the context of backend compatibility and correctness verification."
survived,"def update_pyodide(version: str) -> None:
    base_url = f""https://cdn.jsdelivr.net/pyodide/v{version}/full""
    root = Path(__file__).resolve().parent
    fetch_assets = root / ""fetch_assets.py""
    text = fetch_assets.read_text()

    text = re.sub(r""DEFAULT_PYODIDE_BASE_URL = \""[^\""]+\"""", f'DEFAULT_PYODIDE_BASE_URL = ""{base_url}""', text)
    text = re.sub(r""# Updated to Pyodide [^\n]+"", f""# Updated to Pyodide {version}"", text)

    files = [""pyodide.js"", ""pyodide.asm.wasm""]
    checksums: Dict[str, str] = {}
    for name in files:
        data = fetch(f""{base_url}/{name}"")
        checksums[name] = f""sha384-{sha384_b64(data)}""

    for name, checksum in checksums.items():
        pattern = rf'""{name}"":\s*""[^""]+""'
        text = re.sub(pattern, f'""{name}"": ""{checksum}""', text)

    fetch_assets.write_text(text)

    subprocess.run([sys.executable, str(root / ""generate_build_manifest.py"")], check=True)
",scripts/update_pyodide.py,,1,1.725782769012759e-08,"The method 'update_pyodide' is a utility function that updates the Pyodide version in a local script by modifying URLs and checksums. It is a specific and useful function for maintaining the correct version of Pyodide in a project. Such utility functions are often retained as they serve a clear purpose in version management and automation, which are common needs in software projects. Additionally, the function is well-structured and uses standard libraries and practices, making it unlikely to be removed unless the entire project undergoes a significant change in how it handles Pyodide updates."
survived,"def download(cid: str, path: Path) -> None:
    url = f""{GATEWAY}/{cid}""
    path.parent.mkdir(parents=True, exist_ok=True)
    with _session().get(url, timeout=60) as resp:
        resp.raise_for_status()
        path.write_bytes(resp.content)
",scripts/fetch_assets.py,,1,6.348800075736417e-09,"The method 'download' is a utility function that downloads content from a URL constructed using a given 'cid' and saves it to a specified file path. This is a common and useful functionality in many applications that deal with file downloads from the internet. The method is well-structured, uses a session for the HTTP request, handles exceptions with 'raise_for_status', and ensures the directory exists before writing the file. These are all good practices in Python programming. Therefore, it is likely to be retained in the codebase."
survived,"def _session() -> requests.Session:
    retry = Retry(total=5, backoff_factor=1)
    adapter = HTTPAdapter(max_retries=retry)
    s = requests.Session()
    s.mount(""https://"", adapter)
    s.mount(""http://"", adapter)
    return s
",scripts/fetch_assets.py,,1,1.4166087846364157e-09,"The method '_session' is a utility function that creates and configures a requests.Session object with retry logic. This is a common pattern used to handle transient network issues by retrying requests a specified number of times. The method is useful for ensuring more robust HTTP requests in applications that rely on network communication. Given its utility and the fact that it encapsulates a common best practice, it is likely to be retained in the codebase."
survived,"    def _tool(*_a: object, **_k: object) -> Callable[[object], object]:
        def dec(f: object) -> object:
            return f

        return dec
",tests/test_alpha_opportunity_stub.py,,1,2.3823698451773172e-07,"The method '_tool' is a decorator factory that returns a decorator 'dec'. The 'dec' function simply returns the function it decorates without modifying it. This pattern is often used to create decorators that can be extended later with additional functionality. Since it is a utility function that can be useful for future development, it is likely to be retained in the codebase."
survived,"        def __init__(self, *a: object, port: int = 5001, **_k: object) -> None:
            captured[""port""] = port
",tests/test_alpha_opportunity_stub.py,DummyRuntime,1,6.825604231969389e-08,"The method is a constructor (__init__) for a class, which is a fundamental part of class definition in Python. Constructors are essential for initializing new objects and setting initial values for instance variables. The presence of parameters with default values, such as 'port', suggests that this constructor is designed to be flexible and accommodate different initialization scenarios. Additionally, the use of *a and **_k indicates that the constructor can handle a variable number of arguments, making it versatile. These characteristics make it unlikely for the method to be deleted, as it serves a crucial role in object instantiation and configuration."
survived,"def test_offline_queue_flushes_on_reconnect() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri()

    with sync_playwright() as p:
        browser = p.chromium.launch()
        page = browser.new_page()
        page.goto(url)
        page.evaluate(
            ""window.OTEL_ENDPOINT='https://example.com';""
            ""window.confirm=() => true;""
            ""Object.defineProperty(navigator,'onLine',{get:()=>false,configurable:true});""
            ""navigator.sendBeacon=()=>false;""
        )
        page.reload()
        page.wait_for_selector(""#controls"")
        page.click(""text=Share"")
        page.evaluate(""window.dispatchEvent(new Event('beforeunload'))"")
        assert page.evaluate(""JSON.parse(localStorage.getItem('telemetryQueue')).length > 0"")
        page.evaluate(
            ""navigator.sendBeacon=(...a)=>{(window.sent=window.sent||[]).push(a);return true;}""
            ""Object.defineProperty(navigator,'onLine',{get:()=>true});""
            ""window.dispatchEvent(new Event('online'));""
        )
        page.wait_for_function(""window.sent && window.sent.length > 0"")
        assert page.evaluate(""localStorage.getItem('telemetryQueue')"") == ""[]""
        browser.close()",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_telemetry.py,,1,7.73442280641062e-08,The method `test_offline_queue_flushes_on_reconnect` is a test function that verifies the behavior of a web application when it transitions from offline to online mode. It uses the Playwright library to automate a browser and simulate offline and online states. The test checks if the telemetry queue is correctly flushed when the application reconnects to the internet. This is a crucial functionality test for applications that need to handle offline data and ensure it is sent once connectivity is restored. Such tests are important for maintaining application reliability and are unlikely to be deleted unless the feature itself is deprecated or the testing framework changes.
survived,"def test_has_network_all_fail(monkeypatch: pytest.MonkeyPatch) -> None:
    """"""Return False when none of the hosts are reachable.""""""

    attempts = []

    def _connect(_addr: tuple[str, int], timeout: float = 1.0) -> None:
        attempts.append(_addr)
        raise OSError

    monkeypatch.setattr(check_env.socket, ""create_connection"", _connect)  # type: ignore[attr-defined]
    assert check_env.has_network() is False
    assert len(attempts) >= 3",tests/test_check_env_network.py,,1,5.60279640614594e-09,"The method 'test_has_network_all_fail' is a unit test designed to verify that the 'has_network' function returns False when none of the hosts are reachable. It uses the 'monkeypatch' fixture to replace the 'create_connection' method with a mock that always raises an OSError, simulating a network failure. This is a valid and useful test case for ensuring the robustness of the 'has_network' function under failure conditions. Therefore, it is likely to be retained in the codebase as it contributes to the overall test coverage and reliability of the software."
survived,"def pg_container():
    cid = subprocess.check_output([
        ""docker"",
        ""run"",
        ""-d"",
        ""-e"",
        ""POSTGRES_USER=insight"",
        ""-e"",
        ""POSTGRES_PASSWORD=insight"",
        ""-e"",
        ""POSTGRES_DB=insight"",
        ""-p"",
        ""55432:5432"",
        ""postgres:16-alpine"",
    ]).decode().strip()
    try:
        for _ in range(30):
            res = subprocess.run(
                [""docker"", ""exec"", cid, ""pg_isready"", ""-U"", ""insight""],
                capture_output=True,
            )
            if res.returncode == 0:
                break
            time.sleep(1)
        else:
            subprocess.run([""docker"", ""logs"", cid], check=False)
            raise RuntimeError(""postgres not ready"")
        yield cid
    finally:
        subprocess.run([""docker"", ""rm"", ""-f"", cid], check=False)
",tests/test_postgres_ledger.py,,1,5.60279640614594e-09,"The method 'pg_container' is a utility function that manages the lifecycle of a PostgreSQL Docker container. It starts a container, waits for it to be ready, and ensures cleanup by removing the container after use. This is a common pattern for managing temporary resources in a controlled environment, especially useful in testing or development setups. The method is well-structured, handles exceptions, and ensures resources are cleaned up, which are good practices in software development. Given its utility and adherence to good practices, it is likely to be retained."
survived,"def test_ledger_postgres_persistence(pg_container):
    os.environ.update(
        {
            ""PGHOST"": ""localhost"",
            ""PGPORT"": ""55432"",
            ""PGUSER"": ""insight"",
            ""PGPASSWORD"": ""insight"",
            ""PGDATABASE"": ""insight"",
        }
    )
    ledger = Ledger(""/tmp/ignore.db"", db=""postgres"", broadcast=False)
    env = messaging.Envelope(""a"", ""b"", {""v"": 1}, 0.0)
    ledger.log(env)
    ledger.close()

    conn = psycopg2.connect(host=""localhost"", port=55432, user=""insight"", password=""insight"", dbname=""insight"")
    with conn, conn.cursor() as cur:
        cur.execute(""SELECT count(*) FROM messages"")
        count = cur.fetchone()[0]
    conn.close()
    assert count == 1",tests/test_postgres_ledger.py,,1,1.522997951276035e-08,"The method 'test_ledger_postgres_persistence' is a unit test function that verifies the persistence of messages in a PostgreSQL database using a Ledger object. It sets up the environment variables for the database connection, logs a message, and then checks if the message count in the database is as expected. This is a typical test case for ensuring database operations work correctly, which is crucial for applications relying on data persistence. Therefore, it is likely to be maintained as part of the test suite to ensure ongoing functionality and reliability of the database interactions."
survived,"def test_restart_unsubscribes_handler() -> None:
    bus = messaging.A2ABus(orchestrator.config.Settings(bus_port=0))
    ledger = _Ledger()
    agent = DummyBaseAgent(bus, ledger)
    runner = orchestrator.AgentRunner(agent)

    async def _run() -> tuple[int, int]:
        bus.publish(""dummy"", messaging.Envelope(""a"", ""dummy"", {}, 0.0))
        await asyncio.sleep(0)
        before = agent.count
        await runner.restart(bus, ledger)
        new_agent = runner.agent  # type: ignore[assignment]
        bus.publish(""dummy"", messaging.Envelope(""a"", ""dummy"", {}, 0.0))
        await asyncio.sleep(0)
        return before, getattr(new_agent, ""count"")

    before, after = asyncio.run(_run())

    assert before == 1
    assert agent.count == 1
    assert after == 1
    assert len(bus._subs.get(""dummy"", [])) == 1",tests/test_agent_runner.py,,1,4.363462233903899e-09,"The method `test_restart_unsubscribes_handler` is a test function that verifies the behavior of a system when an agent is restarted. It checks that the message count remains consistent and that the subscription to a message type ('dummy') is maintained. This is a typical unit test to ensure system reliability and correct behavior after a restart. Such tests are crucial for maintaining software quality and are unlikely to be deleted unless the functionality they test is removed or significantly altered. Therefore, the method is likely to survive."
survived,"    async def handle(self, _env: messaging.Envelope) -> None:
        self.count += 1
",tests/test_agent_runner.py,DummyBaseAgent,1,1.0467401685178159e-08,"The method 'handle' is an asynchronous function that increments a counter 'self.count' each time it is called. This kind of method is typically used in event-driven or message-handling systems to keep track of the number of messages processed. Since it serves a clear purpose in tracking message handling, it is likely to be useful in the context it is used. Therefore, it is more likely to be retained rather than deleted."
survived,"    async def _run() -> tuple[int, int]:
        bus.publish(""dummy"", messaging.Envelope(""a"", ""dummy"", {}, 0.0))
        await asyncio.sleep(0)
        before = agent.count
        await runner.restart(bus, ledger)
        new_agent = runner.agent  # type: ignore[assignment]
        bus.publish(""dummy"", messaging.Envelope(""a"", ""dummy"", {}, 0.0))
        await asyncio.sleep(0)
        return before, getattr(new_agent, ""count"")
",tests/test_agent_runner.py,,1,2.998960815863541e-09,"The method '_run' is likely to survive because it is an asynchronous function that performs a sequence of operations involving message publishing and agent state checking. It uses asyncio for asynchronous operations, which is a common and modern approach in Python for handling I/O-bound tasks. The method seems to be part of a larger system involving a bus, messaging, and an agent, indicating it has a specific role in the system's functionality. Unless there are changes in the system's architecture or requirements that render this method obsolete, it is likely to be retained."
survived,"    def start_merkle_task(self, *_a: object, **_kw: object) -> None:  # pragma: no cover - test helper
        pass
",tests/test_agent_runner.py,_Ledger,1,4.363462233903899e-09,"The method `start_merkle_task` is marked with a comment `# pragma: no cover - test helper`, indicating that it is a test helper function. Such functions are often used to facilitate testing and may not be covered by unit tests directly. However, they are crucial for setting up test scenarios or mocking behavior. Since it serves a specific purpose in the testing framework, it is likely to be retained as long as the tests that depend on it are relevant. Therefore, the method is likely to survive."
survived,"def test_apply_patch_rollback_on_failure(tmp_path: Path, monkeypatch: mock.MagicMock) -> None:
    target = tmp_path / ""hello.txt""
    target.write_text(""hello\n"", encoding=""utf-8"")

    def fake_run(cmd, cwd):
        return 1, ""patch failed""

    monkeypatch.setattr(patcher_core, ""_run"", fake_run)
    with pytest.raises(RuntimeError):
        patcher_core.apply_patch(_DEF_DIFF, repo_path=str(tmp_path))

    assert target.read_text(encoding=""utf-8"") == ""hello\n""
    assert not (tmp_path / ""hello.txt.bak"").exists()
",tests/test_patcher_core_additional.py,,1,1.955568070542584e-08,"The method `test_apply_patch_rollback_on_failure` is a unit test designed to verify the behavior of a patch application function when a patch fails. It uses mocking to simulate a failure scenario and checks that the original file remains unchanged and no backup file is created. This is a valid and useful test case for ensuring the robustness of the patch application logic. Therefore, it is likely to be retained in the codebase as it helps maintain code quality and reliability."
survived,"    def fake_run(cmd, cwd):
        return 1, ""patch failed""
",tests/test_patcher_core_additional.py,,1,1.444980317078884e-07,"The method 'fake_run' is a simple function that simulates running a command and always returns a fixed output. It is likely used for testing purposes to simulate a failure scenario. Such methods are often useful in testing environments to ensure that error handling and other logic work correctly when a command fails. Therefore, it is likely to be retained in the codebase for testing purposes."
survived,"def test_import_with_agents_only(monkeypatch: pytest.MonkeyPatch) -> None:
    stub = types.ModuleType(""agents"")
    stub.Agent = object
    stub.AgentRuntime = object

    class DummyOpenAI:
        def __init__(self, *args: object, **kwargs: object) -> None:
            pass

    stub.OpenAIAgent = DummyOpenAI

    def _tool(*_a: object, **_k: object) -> object:
        def _decorator(func: object) -> object:
            return func

        return _decorator

    stub.Tool = _tool

    monkeypatch.setitem(sys.modules, ""agents"", stub)
    sys.modules.pop(""openai_agents"", None)

    orig_import = builtins.__import__

    def fake_import(name: str, globals=None, locals=None, fromlist=(), level=0):
        if name == ""openai_agents"":
            raise ModuleNotFoundError(name)
        if name == ""alpha_opportunity_stub"":
            return importlib.import_module(""alpha_factory_v1.demos.aiga_meta_evolution.alpha_opportunity_stub"")
        if name == ""alpha_conversion_stub"":
            return importlib.import_module(""alpha_factory_v1.demos.aiga_meta_evolution.alpha_conversion_stub"")
        return orig_import(name, globals, locals, fromlist, level)

    monkeypatch.setattr(builtins, ""__import__"", fake_import)

    for mod_name in MODULES:
        mod = importlib.reload(importlib.import_module(mod_name))
        assert mod.OpenAIAgent is stub.OpenAIAgent",tests/test_aiga_agents_import.py,,1,1.725782769012759e-08,"The method 'test_import_with_agents_only' is a test function that uses monkeypatching to simulate the presence of certain modules and classes for testing purposes. It is likely part of a test suite to ensure that the code behaves correctly when certain modules are not available or are replaced with stubs. Test functions are generally not deleted unless they are redundant, irrelevant, or replaced by more comprehensive tests. Since this function appears to serve a specific purpose in testing module imports and handling, it is likely to be retained."
survived,"    def _model_dump(self: BaseModel, *args: Any, **kwargs: Any) -> Any:
        return self.dict(*args, **kwargs)
",src/meta_agent/__init__.py,,1,5.043472052266442e-07,"The method `_model_dump` is a simple utility function that calls the `dict` method on a `BaseModel` instance, passing any arguments and keyword arguments it receives. This is a common pattern in object-oriented programming to provide a more descriptive or context-specific method name for an existing functionality. Since it doesn't introduce any new functionality or complexity, and simply acts as a wrapper, it is likely to be retained for clarity and convenience purposes. Such methods are often used to maintain a consistent interface or to provide a more intuitive method name for specific use cases."
survived,"def _diversity(values):
    if len(values) < 2:
        return 0.0
    d = 0.0
    c = 0
    for i in range(len(values)):
        for j in range(i + 1, len(values)):
            d += abs(values[i] - values[j])
            c += 1
    return d / c
",tests/test_backtrack_boost.py,,1,4.944450477491054e-09,"The method '_diversity' calculates the average pairwise difference between elements in a list, which is a measure of diversity. This function is simple, clear, and performs a specific task that could be useful in various contexts where diversity or variability of a dataset is needed. It handles edge cases, such as when the list has fewer than two elements, by returning 0.0, which is a reasonable default. Given its utility and correctness, it is likely to be retained in the codebase."
survived,"async def _evaluate(g):
    await asyncio.sleep(0)
    return g, 0.01
",tests/test_backtrack_boost.py,,1,4.222835268240621e-06,"The method `_evaluate` is an asynchronous function that takes a single argument `g`, awaits a non-blocking sleep for 0 seconds, and then returns a tuple containing `g` and a constant value `0.01`. This method seems to be a placeholder or a simplified version of a more complex evaluation function. The use of `asyncio.sleep(0)` is a common pattern to yield control back to the event loop, which can be useful in asynchronous programming to ensure other tasks can run. However, the method's utility depends on its context within the larger codebase.

If `_evaluate` is part of a testing or educational example, or if it is used in a context where the constant return value is meaningful, it might be retained. However, if the method is not used or if its functionality is too trivial for the application's needs, it might be deleted or replaced with a more meaningful implementation.

Given the lack of context, the method is likely to be retained if it serves a specific purpose in the codebase, such as a placeholder for future development or a simple utility function. Therefore, I predict it will survive."
survived,"    def set_state(self, key: str, value: str) -> None:
        """"""Store ``key`` as ``value`` in the ``state`` table.""""""
        with Session(self.engine) as session:
            session.merge(_StateRow(key=key, value=value))
            session.commit()",src/archive/db.py,ArchiveDB,1,7.582560422162384e-10,"The method 'set_state' is a straightforward implementation for storing a key-value pair in a database table named 'state'. It uses a session to merge the data and commit the transaction, which is a common pattern in database operations. The method is clear, concise, and performs a necessary function for applications that require state management. There are no apparent issues or redundancies in the code, and it follows standard practices for database interactions. Therefore, it is likely to be retained in the codebase."
survived,"async def _phase_loop(
    operator: Callable[[Any], Any],
    evaluate: Callable[[Any], Awaitable[tuple[float, float]]],
    archive: InMemoryArchive,
    *,
    phase: Phase,
    max_cost: float | None = None,
    wallclock: float | None = None,
    backtrack_rate: float = 0.0,
    phase_hook: Optional[Callable[[Phase], None]] = None,
) -> None:
    if not archive.all():
        await archive.accept(Candidate(genome=0.0, fitness=0.0, novelty=1.0, cost=0.0))

    spent = 0.0
    start = time.time()

    while True:
        if max_cost is not None and spent >= max_cost:
            break
        if wallclock is not None and time.time() - start >= wallclock:
            break

        population = archive.all()
        parent = backtrack_boost(population, population, backtrack_rate)
        genome = operator(parent.genome)
        if phase_hook:
            phase_hook(phase)
        fitness, cost = await evaluate(genome)
        child = Candidate(genome=genome, fitness=fitness, novelty=random.random(), cost=cost)
        await archive.accept(child)
        metrics.dgm_children_total.inc()
        spent += cost
",src/evolve.py,,1,3.3982678079468468e-09,"The method `_phase_loop` is an asynchronous function that appears to be part of an evolutionary algorithm or optimization process. It handles the main loop of a phase, managing the population of candidates, evaluating them, and updating an archive. The method is well-structured, with clear parameters for controlling the loop's execution, such as `max_cost` and `wallclock`. It also includes hooks for additional functionality (`phase_hook`) and uses metrics for tracking (`metrics.dgm_children_total.inc()`). These features suggest that the method is integral to the system's operation and is likely to be maintained and used in the future. Therefore, it is unlikely to be deleted."
survived,"async def self_mod_phase(
    operator: Callable[[Any], Any],
    evaluate: Callable[[Any], Awaitable[tuple[float, float]]],
    archive: InMemoryArchive,
    *,
    max_cost: float | None = None,
    wallclock: float | None = None,
    backtrack_rate: float = 0.0,
    phase_hook: Optional[Callable[[Phase], None]] = None,
) -> None:
    await _phase_loop(
        operator,
        evaluate,
        archive,
        phase=Phase.SELF_MOD,
        max_cost=max_cost,
        wallclock=wallclock,
        backtrack_rate=backtrack_rate,
        phase_hook=phase_hook,
    )
",src/evolve.py,,1,3.850741907939403e-09,"The method 'self_mod_phase' is an asynchronous function that appears to be part of a larger system, likely related to some form of optimization or evolutionary algorithm, given the use of terms like 'operator', 'evaluate', 'archive', and 'phase'. The function is well-structured, uses type hints, and is designed to be flexible with optional parameters. It calls another function '_phase_loop', suggesting that it is part of a modular design. There is no indication that this method is obsolete or redundant, and it seems to serve a specific purpose within its context. Therefore, it is likely to be maintained and used in the future."
survived,"def _write_heatmap(data: Dict[str, Dict[str, float]]) -> None:
    if plt is None or np is None:
        return

    patches = list(data.keys())
    cols = INNOVATIONS
    arr = np.zeros((len(patches), len(cols)))
    for i, p in enumerate(patches):
        baseline = data[p][""baseline""]
        for j, c in enumerate(cols):
            arr[i, j] = baseline - data[p][c]
    fig, ax = plt.subplots(figsize=(2 + len(cols), 1 + len(patches)))
    im = ax.imshow(arr, cmap=""viridis"")
    ax.set_xticks(np.arange(len(cols)))
    ax.set_xticklabels(cols)
    ax.set_yticks(np.arange(len(patches)))
    ax.set_yticklabels(patches)
    for i in range(arr.shape[0]):
        for j in range(arr.shape[1]):
            ax.text(j, i, f""{arr[i, j]:.2f}"", ha=""center"", va=""center"", color=""white"")
    fig.colorbar(im, ax=ax, label="" pass rate"")
    plt.tight_layout()
    HEATMAP_OUT.parent.mkdir(parents=True, exist_ok=True)
    plt.savefig(HEATMAP_OUT)
",src/tools/ablation_runner.py,,1,2.2159489282323004e-08,"The method '_write_heatmap' is a utility function that generates a heatmap from a given data structure and saves it as an image file. This type of function is generally useful for visualizing data, especially in data analysis and reporting contexts. The function is well-structured, uses standard libraries like matplotlib and numpy, and includes features like color mapping and text annotations, which are valuable for interpreting the heatmap. Unless there is a significant change in the requirements or the libraries used, such a function is likely to be retained in the codebase."
survived,"def test_pareto_front_after_five_generations() -> None:
    def fn(genome: list[float]) -> tuple[float, float]:
        x, y = genome
        return x**2, y**2

    pop = mats.run_evolution(
        fn,
        2,
        population_size=20,
        generations=5,
        seed=42,
        scenario_hash=""test"",
    )
    front = mats.pareto_front(pop)
    assert len(front) >= 10",tests/test_mats.py,,1,1.637377179507321e-07,"The method `test_pareto_front_after_five_generations` is a unit test designed to verify the functionality of a Pareto front calculation after running an evolutionary algorithm for five generations. Unit tests are crucial for ensuring code reliability and correctness, especially in complex systems like evolutionary algorithms. This test checks that the Pareto front contains at least 10 solutions, which is a reasonable assertion to validate the diversity and effectiveness of the evolutionary process. Given its role in maintaining code quality, it is unlikely to be deleted unless the functionality it tests is removed or significantly altered."
survived,"def _build_tree(records: List[Dict[str, Any]]) -> Dict[str, Any]:
    tree: Dict[str, Any] = {""name"": ""Start"", ""children"": []}
    best_score = float(""-inf"")
    best_path: List[str] = []
    for rec in records:
        path = rec.get(""path"")
        if not isinstance(path, list):
            continue
        score = float(rec.get(""score"", 0))
        _add_path(tree, path)
        if score > best_score:
            best_score = score
            best_path = [""Start""] + path
    tree[""bestPath""] = best_path
    return tree
",alpha_factory_v1/demos/alpha_agi_insight_v1/tools/export_tree.py,,1,6.69158608681505e-10,"The method `_build_tree` is a utility function that constructs a tree-like data structure from a list of records, each containing a path and a score. It also identifies the path with the highest score. This functionality is quite specific and useful for applications that need to process hierarchical data or visualize paths with scores. The method is well-defined, with clear input and output, and it handles edge cases like missing or non-list paths. Such utility functions are often retained in codebases because they encapsulate a specific logic that might be reused or extended in the future. Therefore, it is likely to survive."
survived,"    def test_index_3d_wildcard(self):
        """"""Indexing into 3D array with wildcard""""""
        expr = '[[[1 2] [3 4]] [[5 6] [7 8]]]:@[1 0 []]'
        self.assert_eval_cmp(expr, '[5 6]')",tests/test_numpy_slice.py,TestNumpySliceBehavior,1,9.736200303530205e-10,"The method 'test_index_3d_wildcard' is a unit test function that appears to be testing a specific functionality of indexing into a 3D array using a wildcard. The presence of a docstring and the use of an assertion method ('self.assert_eval_cmp') suggest that this is part of a test suite, likely for a larger codebase. Test methods are generally retained as they are crucial for ensuring code correctness and preventing regressions. Therefore, it is likely to survive."
survived,"    def test_index_column_wildcard(self):
        """"""Select entire third column using wildcard""""""
        self.assert_eval_cmp('[[1 2 3] [4 5 6]]:@[[] 2]', '[3 6]')
",tests/test_numpy_slice.py,TestNumpySliceBehavior,1,2.2159489282323004e-08,"The method 'test_index_column_wildcard' is a test case that appears to be part of a larger test suite. It is designed to verify the functionality of selecting an entire column from a 2D array using a wildcard. Test methods are generally not deleted unless they are redundant, incorrect, or replaced by a more comprehensive test. Since this method seems to serve a specific purpose in testing a feature, it is likely to be retained unless the feature itself is removed or significantly altered."
survived,"def test_auto_rebuild_on_drift(tmp_path) -> None:
    reg = TemplateRegistry(base_dir=tmp_path)
    reg.register(_meta(""foo""), ""hello foo"")

    index = TemplateIndex(reg)
    index.rebuild()

    # modify template to trigger checksum mismatch
    tpl_path = reg.templates_dir / ""foo"" / ""v0_1_0"" / ""template.yaml""
    tpl_path.write_text(""hi foo"", encoding=""utf-8"")

    index.ensure_up_to_date()
    results = index.search(""hi foo"")
    assert results and results[0][""slug""] == ""foo""",tests/test_template_index.py,,1,9.237449576640118e-09,"The method 'test_auto_rebuild_on_drift' is a test function that verifies the functionality of an auto-rebuild feature when a template file is modified. It is a part of a test suite, likely for a larger application, and is crucial for ensuring that the system behaves correctly when templates are changed. Test functions are generally not deleted unless they are redundant or the feature they test is removed. Since this test checks an important feature (auto-rebuild on drift), it is likely to be retained to ensure ongoing reliability of the system."
survived,"    def test_high_delta_promotes_cooperation(self):
        coop = run_sim(agents=20, rounds=100, delta=0.8, stake=2.5, seed=0)
        self.assertGreaterEqual(coop, 0.8)
",alpha_factory_v1/tests/test_governance_sim.py,GovernanceSimTest,1,2.2159489282323004e-08,"The method `test_high_delta_promotes_cooperation` is a unit test that checks if a simulation with a high delta value promotes cooperation among agents. The test is straightforward and checks an important aspect of the simulation model, ensuring that the cooperation level is at least 0.8 when the delta is set to 0.8. This is a valid and useful test to verify the behavior of the simulation under specific conditions. Therefore, it is likely to be retained as it serves a clear purpose in validating the model's functionality."
survived,"    def _thread_eval(self):
        with ThreadPoolExecutor() as pool:
            results = list(pool.map(self._simulate, self.population))
        return self._post_eval(results)
",alpha_factory_v1/demos/aiga_meta_evolution/meta_evolver.py,MetaEvolver,1,8.152020648014727e-09,"The method _thread_eval is likely to survive because it uses a ThreadPoolExecutor to efficiently manage and execute tasks concurrently, which is a common and effective pattern in Python for handling I/O-bound operations. The method is also structured to return the results of these operations after processing, indicating it is part of a larger, likely useful workflow."
survived,"    def __init__(
        self,
        env_cls: Callable,
        pop_size: int = 32,
        elitism: int = 2,
        parallel: bool = True,
        checkpoint_dir: pathlib.Path = CHKPT_DIR,
        llm: Callable[[str], str] | None = None,
    ):
        self.env_cls, self.pop_size, self.elitism = env_cls, pop_size, elitism
        self.parallel = parallel
        self.ckpt_dir = checkpoint_dir
        self.llm = llm
        self.rng = random.Random(int(""A1GA"", 16))
        self.gen = 0
        self.history: List[Tuple[int, float]] = []
        self._archive: List[np.ndarray] = []
        self._best_fitness = -math.inf
        self.best_genome: Genome | None = None
        self._last_scores: List[float] = []
        self._init_population()
        if self.parallel and _HAS_RAY and not ray.is_initialized():
            ray.init(ignore_reinit_error=True, _temp_dir=str(self.ckpt_dir / ""ray""))
        LOG.info(""Evolver ready  pop=%d device=%s"", self.pop_size, Device)
",alpha_factory_v1/demos/aiga_meta_evolution/meta_evolver.py,MetaEvolver,1,6.825604231969389e-08,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class with specific attributes and configurations. Constructors are fundamental to object-oriented programming and are rarely deleted unless the class itself is being removed or significantly refactored. The presence of various parameters and initializations suggests that this constructor is crucial for setting up the environment and configurations for the class's functionality."
survived,"    def _save(self):
        data = {
            ""gen"": self.gen,
            ""pop"": [g.to_json() for g in self.population],
            ""hist"": self.history,
            ""arc"": [a.tolist() for a in self._archive[-256:]],
            ""seed"": self.rng.random(),
            ""sha"": self.population_sha(),
            ""best_fitness"": self._best_fitness,
            ""best_genome"": self.best_genome.to_json() if self.best_genome else None,
            ""ts"": datetime.now(timezone.utc).isoformat()
        }
        p = CHKPT_DIR / f""gen_{self.gen:04d}.json.tmp""
        p.write_text(json.dumps(data)); p.replace(p.with_suffix(""""))
",alpha_factory_v1/demos/aiga_meta_evolution/meta_evolver.py,MetaEvolver,1,2.646573631904765e-09,"The method '_save' is likely to survive because it performs a crucial function of saving the state of an object to a JSON file. This is important for persistence, debugging, and recovery purposes. The method is well-structured, using standard libraries and practices for file handling and JSON serialization. Additionally, it includes a timestamp and handles potential None values gracefully, indicating thoughtful design. These factors suggest that the method is functional and useful, making it unlikely to be deleted."
survived,"    def forward(self, x: torch.Tensor):
        act_fn = _ACT[self.genome.activation]
        h = x
        for layer in self.model[:-1]:
            if isinstance(layer, nn.Linear):
                h = act_fn(layer(h))
                if self.genome.hebbian:
                    with torch.no_grad():
                        dw = 0.03 * torch.bmm(h.unsqueeze(2), x.unsqueeze(1))
                        self.hFast = (self.hFast + dw.mean(0)).clamp(-0.02, 0.02)
                        layer.weight.data += self.hFast
            else:
                h = layer(h)
        return self.model[-1](h)
",alpha_factory_v1/demos/aiga_meta_evolution/meta_evolver.py,EvoNet,1,1.955568070542584e-08,"The method is likely to survive because it implements a forward pass for a neural network with a specific focus on applying Hebbian learning updates to the weights of linear layers. This approach is not commonly found in standard neural network implementations, indicating a specialized use case that could be valuable for certain types of neural network training or research. Additionally, the method is well-structured, using PyTorch's tensor operations efficiently, and it includes a mechanism to handle different activation functions and a condition for applying Hebbian learning, which suggests it is part of a larger, well-thought-out system."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/gamma-function.py,,1,6.825604231969389e-08,"The method _now() is a utility function that generates a pseudo-random number based on a global seed if it is set, or returns the current time in nanoseconds if not. This kind of function can be useful in scenarios where deterministic behavior is needed for testing or simulation purposes. The use of a global seed allows for repeatable results, which is a common requirement in testing environments. Since the function provides a clear utility and does not have any apparent issues or redundancies, it is likely to be retained in the codebase."
survived,"def ln(x):
    k = 0.0
    v = x
    while v >= 2.0:
        v = v / 2.0
        k = k + 1.0
    while v < 1.0:
        v = v * 2.0
        k = k - 1.0
    z = (v - 1.0) / (v + 1.0)
    zpow = z
    sum = z
    i = 3
    while i <= 9:
        zpow = zpow * z * z
        sum = sum + zpow / (float(i))
        i = i + 2
    ln2 = 0.6931471805599453
    return (k * ln2) + 2.0 * sum
",tests/rosetta/transpiler/Python/gamma-function.py,,1,8.76424914819242e-08,The method implements a logarithm function using a series expansion and some transformations to handle different ranges of input values. It is a mathematical function that is generally useful and does not have any obvious issues or redundancies that would warrant its deletion. The method is likely to survive as it provides a specific utility that can be used in various applications requiring logarithmic calculations.
survived,"def test_png(h, f):
    """"""Verify if the image is a PNG.""""""
    if h.startswith(b'\211PNG\r\n\032\n'):
        return 'png'
",metaflow/_vendor/imghdr/__init__.py,,1,3.850741907939403e-09,"The method 'test_png' is a simple utility function that checks if a given file header 'h' starts with the PNG signature. This is a common and useful function for validating file types, especially in applications dealing with image processing or file uploads. The method is straightforward, performs a specific task, and does not have any apparent issues or redundancies that would warrant its deletion. Therefore, it is likely to be retained in the codebase."
survived,"    def render(self, task):
        from .convert_to_native_type import TaskToDict
        import base64

        png_bytes = base64.b64decode(
            ""iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR4nGNgYGBgAAAABQABRDE8UwAAAABJRU5ErkJggg==""
        )
        img_src = TaskToDict().parse_image(png_bytes)
        return f""<html><img src='{img_src}' /></html>""",metaflow/plugins/cards/card_modules/test_cards.py,TestImageCard,1,2.3355930333443423e-09,"The method 'render' is likely to survive because it performs a specific task of rendering an image from a base64 encoded string, which is a common requirement in web applications. The method is straightforward, uses a helper class 'TaskToDict' to parse the image, and returns a valid HTML string. There is no indication of redundancy or inefficiency that would necessitate its deletion."
survived,"def _run_sim(page):
    page.evaluate(""document.querySelector('#simulator-panel #sim-seeds').value='1'"")
    page.evaluate(f""document.querySelector('#simulator-panel #sim-gen').value={DEF_GEN}"")
    page.evaluate(""document.querySelector('#simulator-panel #sim-pop').value=3"")
    page.click(""#simulator-panel #sim-start"")
    page.wait_for_function(""window.pop && window.pop[0] && window.pop[0].umap"")
    coords = page.evaluate(""window.pop.map(p=>p.umap)"")
    page.click('#simulator-panel #sim-cancel')
    return coords
",tests/test_umap_fallback.py,,1,3.2241866333029355e-08,"The method '_run_sim' is a utility function that automates interactions with a web page using a headless browser automation tool, likely for testing or data extraction purposes. It sets values in a form, starts a simulation, waits for a condition, retrieves data, and then cancels the simulation. Such methods are typically useful in automated testing frameworks or data collection scripts. Given its specific functionality and the increasing reliance on automated testing and data extraction in software development, it is likely to be retained unless the underlying web page or the automation framework changes significantly."
survived,"    def lookup_artist(name: str) -> str | None:
        url = f""https://api.lidarr.audio/api/v0.4/search?type=artist&query=\""{urllib.parse.quote_plus(name)}\""""
        resp = session.get(url, headers=headers)
        if resp.status_code == 200 and resp.text not in ("""", ""[]""):
            data = resp.json()
            if isinstance(data, list):
                return data[0].get(""id"")
            return data.get(""id"")
        return None
",arr_gui.py,,1,4.599055376537186e-10,"The method 'lookup_artist' is likely to survive because it performs a useful function of querying an API to retrieve an artist's ID based on their name. This is a common task in applications that deal with music data, and the method is implemented in a straightforward manner using standard libraries and practices. Additionally, it includes error handling for the HTTP response, which is a good practice in API calls. Unless there are changes in the API or the method is no longer needed in the application, there is no immediate reason for it to be deleted."
survived,"def sonarr_import(csv_path: str, cfg: configparser.ConfigParser) -> None:
    baseurl = cfg[""sonarr""][""baseurl""]
    urlbase = cfg[""sonarr""].get(""urlbase"", """")
    api_key = cfg[""sonarr""][""api_key""]
    root = cfg[""sonarr""][""rootfolderpath""]
    profile = cfg[""sonarr""][""qualityProfileId""]
    search = cfg.getboolean(""sonarr"", ""searchForShow"", fallback=False)

    headers = {""Content-type"": ""application/json"", ""X-Api-Key"": api_key}
    session = requests.Session()

    with open(csv_path, encoding=""utf-8"") as f:
        reader = csv.DictReader(f)
        for row in reader:
            title = row.get(""title"")
            year = row.get(""year"")
            imdbid = row.get(""imdbid"")
            if imdbid:
                url = f""{baseurl}{urlbase}/api/v3/series/lookup?term=imdb:{imdbid}""
            else:
                term = urllib.parse.quote_plus(f""{title} {year}"" if year else title)
                url = f""{baseurl}{urlbase}/api/v3/series/lookup?term={term}""
            rsp = session.get(url, headers=headers)
            if rsp.status_code != 200 or rsp.text in ("""", ""[]""):
                messagebox.showwarning(""Sonarr"", f""{title} not found"")
                continue
            data = rsp.json()
            if isinstance(data, list):
                data = data[0]
            payload = {
                ""title"": data.get(""title""),
                ""tvdbId"": data.get(""tvdbId""),
                ""year"": data.get(""year""),
                ""titleSlug"": data.get(""titleSlug""),
                ""qualityProfileId"": int(profile),
                ""rootFolderPath"": root,
                ""monitored"": True,
                ""seasonFolder"": True,
                ""images"": data.get(""images"", []),
                ""seasons"": data.get(""seasons"", []),
                ""addOptions"": {""searchForMissingEpisodes"": search},
            }
            add_url = f""{baseurl}{urlbase}/api/v3/series""
            session.post(add_url, headers=headers, json=payload)
",arr_gui.py,,1,9.237449576640118e-09,"The method 'sonarr_import' is a utility function designed to import series data into Sonarr from a CSV file. It is well-structured, uses standard libraries, and performs a specific task that is likely useful for users who manage their media libraries with Sonarr. The method handles API requests, processes CSV data, and interacts with Sonarr's API, which are common tasks for automation scripts. Given its functionality and the fact that it is not overly complex or redundant, it is likely to be retained in the codebase."
survived,"    def __init__(self, std: float = 0.1, bounds: tuple[float, float] = (-1.0, 1.0), rng: random.Random | None = None) -> None:
        self.std = std
        self.bounds = bounds
        self.rng = rng or random.Random()
",src/simulation/mats_ops.py,GaussianParam,1,3.850741907939403e-09,"The method is a constructor for a class, which is a fundamental part of object-oriented programming in Python. It initializes the instance variables with default values and allows for optional customization through parameters. This is a standard and necessary practice for setting up objects, and there is no indication that it is redundant or incorrect. Therefore, it is likely to survive."
survived,"        def json(self) -> dict:
            return self._data
",tests/test_selfheal_entrypoint_offline.py,DummyResp,1,4.6911638017642294e-08,"The method is a simple getter that returns a dictionary stored in the instance variable '_data'. Such methods are common in classes that handle data serialization or API responses, where converting an object to a JSON-compatible dictionary is necessary. This method is likely to be useful for accessing the internal data in a structured format, which is a common requirement in many applications. Therefore, it is unlikely to be deleted unless the class design changes significantly."
survived,"def test_demo_index_loads(demo_dir: Path) -> None:
    url = (demo_dir / ""index.html"").resolve().as_uri()
    try:
        with sync_playwright() as p:
            browser = p.chromium.launch()
            page = browser.new_page()
            page.goto(url)
            page.wait_for_selector(""body"")
            assert page.query_selector(""h1""), ""h1 element missing""
            browser.close()
    except PlaywrightError as exc:
        pytest.skip(f""Playwright browser not installed: {exc}"")",tests/test_docs_demos.py,,1,1.3176514268359263e-10,"The method 'test_demo_index_loads' is a test function that checks if an HTML file loads correctly in a browser using Playwright. It is a useful test for ensuring that the 'index.html' file in the 'demo_dir' directory is accessible and contains an 'h1' element. The function also handles exceptions by skipping the test if Playwright is not installed, which is a good practice for test robustness. Given its utility in testing web page loading and structure, it is likely to be retained in the codebase."
survived,"    def test_entries_feed_includes_subscribe_note(self):
        EntryFactory()
        response = self.client.get(""/atom/entries/"")
        self.assertIn(
            ""You are only seeing the entries from my blog. Subscribe to"",
            response.content.decode(),
        )
",blog/tests.py,BlogTests,1,8.152020648014727e-09,"The method 'test_entries_feed_includes_subscribe_note' is a unit test that checks if a specific note is included in the response content of an HTTP GET request to '/atom/entries/'. This is a valid and useful test to ensure that the subscribe note is present in the feed, which is likely an important feature for user engagement. Therefore, the method is likely to be retained as it serves a clear purpose in testing the functionality of the application."
survived,"    def tearDown(self) -> None:
        agents_mod._WHEEL_PUBKEY = self.orig_pub
        self.tmpdir.cleanup()
",tests/test_verify_wheel_sig.py,VerifyWheelSigTests,1,2.7894680920908113e-10,"The method `tearDown` is a standard part of the unittest framework in Python, used to clean up after each test method is run. It is essential for ensuring that tests do not interfere with each other by resetting any changes made during a test. The presence of `tearDown` in a test suite is a common practice and is unlikely to be removed unless the entire testing framework is being refactored or replaced. Therefore, it is expected to survive."
survived,"    def __init__(self, bus: orchestrator.messaging.A2ABus, ledger: orchestrator.Ledger) -> None:
        super().__init__(""dummy"", bus, ledger)
",tests/test_orchestrator.py,DummyAgent,1,2.0611536181902033e-09,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting up initial states. The use of '__init__' is standard in Python for this purpose, and it is unlikely to be removed unless the entire class is being refactored or removed. Therefore, the method will survive."
survived,"def test_publish_kafka_disabled() -> None:
    events: list[messaging.Envelope] = []

    async def handler(env: messaging.Envelope) -> None:
        events.append(env)

    cfg = config.Settings(bus_port=0)
    with mock.patch.object(messaging, ""AIOKafkaProducer"", None):
        bus = messaging.A2ABus(cfg)
        bus.subscribe(""x"", handler)

        async def run() -> None:
            async with bus:
                env = messaging.Envelope(""a"", ""x"", {""ok"": True}, 0.0)
                bus.publish(""x"", env)
                await asyncio.sleep(0)

        asyncio.run(run())

    assert len(events) == 1
    assert events[0].payload[""ok""] is True",tests/test_message_bus.py,,1,8.152020648014727e-09,"The method 'test_publish_kafka_disabled' is a unit test designed to verify the behavior of a messaging system when Kafka is disabled. It uses mocking to replace the Kafka producer with None, ensuring that the test does not depend on an actual Kafka instance. The test checks that a message is successfully published and received by a handler, even when Kafka is disabled. This is a valid and useful test case for ensuring the robustness of the messaging system in different configurations. Therefore, it is likely to be retained in the codebase."
survived,"    def test_init_with_dsn_no_pg(self):
        mem = mv.VectorMemory(dsn=""postgres://user:pass@localhost/db"")
        self.assertEqual(mem.backend, ""numpy"")
",tests/test_memory_vector.py,TestVectorMemoryOffline,1,8.76424914819242e-08,"The method `test_init_with_dsn_no_pg` is a unit test that checks the initialization of a `VectorMemory` object with a DSN (Data Source Name) for a PostgreSQL database. The test asserts that the backend is set to 'numpy', which suggests that the method is testing a fallback or default behavior when PostgreSQL is not available or not used. This kind of test is important for ensuring that the system behaves correctly under different configurations and is likely to be retained as part of the test suite to ensure robustness and reliability of the code."
survived,"        def _tool(*_a, **_k):
            def _decorator(func):
                return func

            return _decorator
",tests/test_openai_bridge.py,TestOpenAIBridge,1,4.1399375473943306e-08,"The method _tool is a decorator factory that returns a decorator function (_decorator) which, in turn, returns the original function without any modifications. This pattern is often used to create decorators that can be extended or modified later. Since the method is functional and could be useful for future extensions, it is likely to be retained in the codebase."
survived,"  async def take_in_plate(self, plate: Plate, site: PlateHolder):
    """"""Place a plate from the transfer station into storage at the given site.""""""
    m, n = self._site_to_m_n(site)
    await self._send_command(f""WR DM0 {m}"")  # carousel pos
    await self._send_command(f""WR DM5 {n}"")  # handler level
    await self._send_command(""ST 1904"")  # plate to storage
    await self._wait_ready()
    await self._send_command(""ST 1903"")  # terminate access
",pylabrobot/storage/cytomat/heraeus_cytomat_backend.py,HeraeusCytomatBackend,1,1.6052280526088547e-09,"The method 'take_in_plate' is an essential part of the system's functionality, as it handles the process of placing a plate into storage. It involves specific commands to control the hardware, such as setting the carousel position and handler level, and ensuring the system is ready before terminating access. This functionality is crucial for the operation of the system, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained."
survived,"  def serialize(self):
    return {
      **Machine.serialize(self),
      **Resource.serialize(self),
      ""backend"": self.backend.serialize(),
      ""racks"": [rack.serialize() for rack in self._racks],
      ""loading_tray_location"": serialize(self.loading_tray.location),
    }
",pylabrobot/storage/incubator.py,Incubator,1,1.6052280526088547e-09,"The method 'serialize' is likely to survive because it is a utility function that converts an object into a serializable format, which is a common requirement in software development for data interchange, storage, or logging. The method is also well-structured, leveraging existing 'serialize' methods from other components, indicating it is part of a larger, cohesive system. Such methods are typically essential for the functionality of applications that need to handle complex data structures."
survived,"  async def open_door(self):
    pass
",pylabrobot/storage/backend.py,IncubatorBackend,1,5.043472052266442e-07,"The method `open_door` is an asynchronous function that currently does nothing as it only contains a `pass` statement. However, the method name suggests a clear purpose, which is to handle the action of opening a door, possibly in an asynchronous context. This implies that the method is likely a placeholder for future implementation where asynchronous operations (like I/O operations) might be necessary. Given its descriptive name and potential use case, it is more likely to be retained and implemented in the future rather than deleted."
survived,"  async def set_shaking_frequency(
    self, frequency: int, shakers: Optional[List[int]] = None
  ) -> List[str]:
    shakers = shakers or [1, 2]
    assert all(shaker in [1, 2] for shaker in shakers), ""Shaker index must be 1 or 2""
    return [await self.send_command(""se"", f""pb 2{idx-1}"", f""{frequency:04}"") for idx in shakers]
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend,1,2.646573631904765e-09,"The method 'set_shaking_frequency' is well-defined and serves a specific purpose of setting the frequency for shakers. It includes input validation to ensure that only valid shaker indices are used, and it uses asynchronous programming to handle potentially time-consuming operations efficiently. These characteristics make it a useful and efficient method, suggesting it is likely to be retained in the codebase."
survived,"  async def open_door(self):
    await self._send_command(""ST 1901"")
    await self._wait_ready()
",pylabrobot/storage/cytomat/heraeus_cytomat_backend.py,HeraeusCytomatBackend,1,1.1032560311263802e-09,"The method 'open_door' is an asynchronous function that sends a command to open a door and waits for the system to be ready. This functionality is likely essential for the operation of a system that involves door control, such as a smart home system or an automated facility. Since it performs a specific and necessary action, it is unlikely to be deleted unless the entire system is being deprecated or significantly redesigned. Therefore, the method is predicted to survive."
survived,"  async def action_exposed_to_storage(self, site: PlateHolder) -> OverviewRegisterState:
    """"""Return with MTP from exposed to storage, move to wait, close door""""""
    return await self.send_action(""mv"", ""hs"", self._site_to_firmware_string(site))
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend,1,6.69158608681505e-10,"The method 'action_exposed_to_storage' is an asynchronous function that sends an action command to move a site to storage. It is a specific utility function that likely serves a particular purpose in the context of the application, such as managing or controlling hardware or a process. Since it is a specialized function, it is less likely to be deleted unless the entire feature or module it supports is deprecated. Therefore, it is more likely to survive."
survived,"  async def get_temperature(self) -> float:
    return await self.backend.get_temperature()
",pylabrobot/storage/incubator.py,Incubator,1,5.60279640614594e-09,"The method 'get_temperature' is a simple asynchronous function that retrieves temperature data from a backend service. It is likely to survive because it serves a clear purpose in fetching temperature data, which is a common requirement in many applications. Additionally, the use of asynchronous programming is a modern approach that enhances performance by allowing other operations to run while waiting for the temperature data, making it efficient and relevant."
survived,"  async def action_storage_to_exposed(self, site: PlateHolder) -> OverviewRegisterState:
    """"""Move from wait to storage, load MTP, transport to exposed""""""
    return await self.send_action(""mv"", ""sh"", self._site_to_firmware_string(site))
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend,1,1.4166087846364157e-09,"The method 'action_storage_to_exposed' is an asynchronous function that performs a specific action by sending a command to move an item from storage to an exposed state. It is likely part of a larger system that manages or controls hardware or processes, as indicated by the use of 'send_action' and the context of moving items. The method is concise, has a clear purpose, and is likely to be useful in its context. There is no indication that it is redundant or obsolete, so it is likely to be retained."
survived,"  async def action_wait_to_transfer(self) -> OverviewRegisterState:
    """"""Open door, place on transfer, return to wait, close door""""""
    return await self.send_action(""mv"", ""wt"", """")
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend,1,2.3355930333443423e-09,"The method 'action_wait_to_transfer' is a concise and clear implementation of an asynchronous action that involves sending a command to move to a 'wait to transfer' state. It is likely part of a larger system that manages state transitions, possibly in a robotics or automation context. The method is well-defined, uses an appropriate async pattern, and has a clear docstring explaining its purpose. There is no indication of redundancy or obsolescence, and it seems to fulfill a specific role within its system. Therefore, it is likely to be retained."
survived,"  def test_serialization(self):
    i = Incubator(
      name=""test_tc"",
      size_x=10,
      size_y=10,
      size_z=10,
      backend=IncubatorChatterboxBackend(),
      loading_tray_location=Coordinate(0, 0, 0),
      racks=[],
    )

    serialized = i.serialize()
    deserialized = Incubator.deserialize(serialized)
    self.assertEqual(i, deserialized)",pylabrobot/storage/incubator_tests.py,IncubatorTests,1,4.944450477491054e-09,"The method `test_serialization` is a unit test that verifies the serialization and deserialization functionality of the `Incubator` class. It ensures that an `Incubator` object can be serialized into a format and then accurately deserialized back into an object that is equal to the original. This is a crucial test for maintaining data integrity during serialization processes, which are common in software systems that require data persistence or communication between different components. Given its importance in ensuring the reliability of these processes, it is likely to be retained in the codebase."
survived,"def cytomat_rack_38mm_13(name: str):
  return _cytomat_rack(name=name, site_height=38, num_sites=13, model=""cytomat_rack_38mm_13"")
",pylabrobot/storage/cytomat/racks.py,,1,1.6052280526088547e-09,"The method `cytomat_rack_38mm_13` is a simple wrapper function that calls another function `_cytomat_rack` with specific parameters. This kind of function is often used to simplify the interface for users by providing a more specific or convenient way to call a more general function. Since it serves a clear purpose and likely contributes to code readability and usability, it is likely to be retained unless the underlying function `_cytomat_rack` is removed or significantly changed. Therefore, the method is predicted to survive."
survived,"  async def stop_shaking(self):
    await self.backend.stop_shaking()
",pylabrobot/storage/incubator.py,Incubator,1,1.6052280526088547e-09,"The method `stop_shaking` is an asynchronous function that calls another asynchronous method `stop_shaking` on a `backend` object. This suggests that the method is part of a larger system where stopping a shaking action is a necessary feature. Without additional context, such as the method being deprecated or replaced, there is no indication that this method should be deleted. It likely serves a specific purpose in the system's functionality, such as controlling a device or a simulation, and thus is expected to survive."
survived,"    def render(
        self,
        slug: str,
        *,
        version: str = ""latest"",
        context: Optional[Dict[str, Any]] = None,
    ) -> str:
        """"""Render a template and all of its dependencies.""""""
        name = slug if version == ""latest"" else f""{slug}@{version}""
        template = self.env.get_template(name)
        return template.render(context or {})
",src/meta_agent/template_mixer.py,TemplateMixer,1,1.1861120010657661e-08,"The method 'render' is a utility function that is likely used to render templates with specific versions and contexts. This is a common requirement in web applications and template rendering engines. The method is well-defined, with clear parameters and a straightforward implementation. It is unlikely to be deleted as it provides essential functionality for rendering templates, which is a core part of many applications."
survived,"def test_template_validator_performance_fail() -> None:
    validator = TemplateValidator()
    case = TemplateTestCase(context={}, expected_output=""Hello"")
    result = validator.validate(""Hello"", [case], max_render_seconds=0.0)
    assert not result.success
    assert any(""too slow"" in e for e in result.errors)",tests/test_template_validator.py,,1,4.6911638017642294e-08,"The method `test_template_validator_performance_fail` is a unit test designed to check the performance of a `TemplateValidator` by ensuring it fails when the rendering takes too long. This is a common practice in testing to ensure that performance constraints are respected. The method is well-structured, uses assertions to validate the expected behavior, and is likely part of a larger test suite. Such methods are typically retained as they are crucial for maintaining code quality and performance standards."
survived,"    def __init__(self, env: Optional[Environment] = None) -> None:
        self.env = env or Environment()
",src/meta_agent/template_validator.py,TemplateValidator,1,1.444980317078884e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting up initial states. This particular constructor also provides a default value for the 'env' parameter, ensuring that the 'env' attribute is always initialized with an instance of 'Environment'. Such functionality is crucial for the robustness and flexibility of the class. Therefore, it is unlikely to be deleted."
survived,"def test_export_import_and_rating(tmp_path):
    reg = TemplateRegistry(base_dir=tmp_path)
    manager = TemplateSharingManager(reg)
    reg.register(_meta(""greet""), ""hello"", version=""0.1.0"")

    exported = manager.export_template(""greet"")
    assert exported[""content""] == ""hello""

    reg2 = TemplateRegistry(base_dir=tmp_path / ""other"")
    manager2 = TemplateSharingManager(reg2)
    manager2.import_template(exported)
    assert reg2.load_template(""greet"") == ""hello""

    manager.add_rating(""greet"", 5)
    manager.add_rating(""greet"", 3)
    count, avg = manager.get_rating(""greet"")
    assert count == 2 and avg == 4.0

    top = manager.showcase()
    assert top and top[0][0] == ""greet""
",tests/test_template_sharing.py,,1,1.725782769012759e-08,"The method 'test_export_import_and_rating' is a comprehensive test function that verifies multiple functionalities of a template management system, including exporting, importing, and rating templates. It ensures that templates can be correctly exported and imported between different registries, and it also tests the rating system by adding ratings and checking the average. Such test functions are crucial for maintaining the integrity and reliability of the system, especially when dealing with data transfer and user feedback mechanisms. Therefore, it is likely to be retained as it provides valuable test coverage."
survived,"    def add_rating(self, slug: str, rating: int) -> None:
        """"""Store a user rating (1-5) for a template.""""""
        if rating < 1 or rating > 5:
            raise ValueError(""Rating must be between 1 and 5"")
        ratings = self._load_ratings()
        key = slug.replace("" "", ""_"").lower()
        ratings.setdefault(key, []).append(rating)
        self._save_ratings(ratings)
",src/meta_agent/template_sharing.py,TemplateSharingManager,1,1.2501528648238603e-09,"The method 'add_rating' is a utility function that allows users to add a rating to a template identified by a 'slug'. It includes input validation to ensure the rating is within the acceptable range (1-5), and it handles the storage of ratings by loading existing ratings, updating them, and saving them back. This functionality is essential for applications that involve user feedback or ratings, making it a valuable method. Therefore, it is likely to be retained in the codebase."
survived,"    def call_stub(prompt: str) -> str:
        return f""[offline] {prompt}""
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/local_llm.py,,1,9.42244663976186e-07,"The method 'call_stub' is a simple utility function that takes a string input and returns a formatted string with a prefix '[offline]'. This kind of method is often used for testing or as a placeholder for more complex functionality that might be implemented later. It is not uncommon for such methods to be retained in codebases for testing purposes or as part of a larger system where offline or stubbed responses are needed. Therefore, it is likely to survive unless there is a specific reason to remove it, such as a change in the system architecture or a move to a different testing strategy."
survived,"    def __init__(self, *a, **k):
        pass
",tests/test_selfheal_import_stubs.py,DummyButton,0,0.9999994284997149,"The method is an initializer for a class, but it doesn't perform any operations or initialize any attributes. While it technically serves as a placeholder, it doesn't add any functionality or value to the class. In most cases, such methods are either removed or replaced with meaningful initializations. Therefore, it is likely to be deleted unless there is a specific reason to keep it as a placeholder."
survived,"def test_agents_status_outputs_names() -> None:
    runner = CliRunner()
    from unittest.mock import patch

    with patch.object(cli.orchestrator, ""Orchestrator"") as orch_cls:  # type: ignore[attr-defined]
        orch = orch_cls.return_value
        runner_obj = type(
            ""Runner"",
            (),
            {""agent"": type(""Agent"", (), {""name"": ""AgentZ""})()},
        )()
        orch.runners = {""AgentZ"": runner_obj}
        result = runner.invoke(cli.main, [""agents-status""])
    assert result.exit_code == 0
    assert ""AgentZ"" in result.output",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_demo_cli.py,,1,2.8453347280241004e-08,"The method 'test_agents_status_outputs_names' is a unit test that uses mocking to simulate the behavior of a CLI command. It checks if the command 'agents-status' correctly outputs the name of an agent ('AgentZ'). The test is well-structured, uses the 'unittest.mock' library to patch dependencies, and verifies the expected output. Such tests are crucial for ensuring the reliability of CLI tools, especially when dealing with complex systems. Therefore, it is likely to be retained as it serves a clear purpose in the codebase."
survived,"def cleanup_ledger_dir() -> None:
    """"""Remove the default ledger directory created during tests.""""""
    yield
    ledger = Path(""ledger"")
    if ledger.exists():
        shutil.rmtree(ledger, ignore_errors=True)",tests/conftest.py,,0,0.9999999634651793,"The method `cleanup_ledger_dir` is likely to be deleted because it is not functioning as intended. The method is defined as a generator function (due to the use of `yield`), but it does not yield any values or perform any operations before or after the `yield` statement. Additionally, the cleanup operation (removing the directory) is placed after the `yield`, which means it will not execute unless the generator is iterated over, which is not typical for a cleanup function. This suggests a misunderstanding or error in implementation, making it a candidate for deletion or significant revision."
survived,"def generate_basic_tests(spec: ToolSpecification) -> str:
    """"""Generate minimal pytest code exercising the generated tool.""""""
    param_assignments = []
    for param in spec.input_parameters:
        value = _example_value(param.type_)
        param_assignments.append(f""{param.name}={value}"")
    args = "", "".join(param_assignments)
    test_code = f""""""
import importlib

def test_call():
    mod = importlib.import_module('tool')
    func = getattr(mod, '{spec.name}')
    func({args})
""""""
    return test_code",src/meta_agent/generators/test_generator.py,,1,1.9171715133907573e-10,"The method 'generate_basic_tests' is a utility function that generates basic test code for a given tool specification. It is useful for automating the creation of test cases, which is a common requirement in software development to ensure code quality and functionality. The method is straightforward, does not have any apparent issues, and serves a clear purpose. Therefore, it is likely to be retained in the codebase."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/count-the-coins-2.py,,1,1.1253518384332553e-07,"The method _now() is a utility function that generates a pseudo-random number based on a global seed if it is set, or returns the current time in nanoseconds if not. This kind of function can be useful in scenarios where deterministic behavior is needed for testing or debugging, or when a unique timestamp is required. The use of a global seed allows for repeatable results, which is a common requirement in testing environments. Given its utility and the fact that it doesn't have any apparent issues or redundancies, it is likely to be retained in the codebase."
survived,"def add(a, b):
    return newFps(lambda n: extract(a, n) + extract(b, n))
",tests/rosetta/transpiler/Python/formal-power-series.py,,0,0.9999999943972036,"The method 'add' is likely to be deleted because it references 'newFps' and 'extract', which are not defined within the provided code snippet. Without these definitions, the function cannot operate as intended, leading to potential errors or undefined behavior. This lack of context or supporting code suggests that the method is incomplete or incorrectly implemented, making it a candidate for deletion unless further context is provided."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/formatted-numeric-output.py,,1,2.5109990926928157e-08,"The method _now() is a utility function that generates a pseudo-random number based on a global seed if it is set, or returns the current time in nanoseconds if not. This kind of function can be useful in scenarios where deterministic behavior is needed for testing or simulation purposes, by seeding the random number generator. The function is simple, does not have any apparent bugs, and serves a clear purpose. Therefore, it is likely to be retained in the codebase."
survived,"def say(n):
    t = """"
    if n < 0:
        t = ""negative ""
        n = -n
    if n < 20:
        return t + small[n]
    else:
        if n < 100:
            t = tens[n // 10]
            s = n % 10
            if s > 0:
                t = t + ""-"" + small[s]
            return t
        else:
            if n < 1000:
                t = small[n // 100] + "" hundred""
                s = n % 100
                if s > 0:
                    t = t + "" "" + say(s)
                return t
    sx = """"
    i = 0
    nn = n
    while nn > 0:
        p = nn % 1000
        nn = nn // 1000
        if p > 0:
            ix = say(p) + illions[i]
            if sx != """":
                ix = ix + "" "" + sx
            sx = ix
        i = i + 1
    return t + sx
",tests/rosetta/transpiler/Python/four-is-magic.py,,1,8.76424914819242e-08,"The method 'say' is a utility function that converts numbers into their English word representation. This type of functionality is often useful in various applications such as text-to-speech systems, educational software, or any application that requires number-to-word conversion. The method is well-structured to handle numbers in different ranges, including negative numbers, and uses recursion effectively for numbers larger than 1000. Given its utility and the fact that it is a complete implementation, it is likely to be retained in the codebase."
survived,"def newBoard():
    b = []
    r = 0
    while r < rows:
        row = []
        c = 0
        while c < cols:
            if _now() % 2 == 0:
                row = row + [""T""]
            else:
                row = row + ["" ""]
            c = c + 1
        b = b + [row]
        r = r + 1
    return b
",tests/rosetta/transpiler/Python/forest-fire.py,,0,0.9999970976874533,"The method 'newBoard' is likely to be deleted because it contains several issues that make it inefficient and potentially problematic. Firstly, the use of '_now()' within the loop suggests a reliance on a function or variable that is not defined within the provided code, which could lead to errors. Secondly, the method uses a non-Pythonic way of constructing lists by repeatedly using concatenation, which is less efficient than using list comprehensions or the 'append' method. Additionally, the method's logic for filling the board with 'T' or ' ' based on the current time is not clearly explained or justified, making it difficult to understand its purpose or utility. These factors suggest that the method may not be robust or useful in its current form, leading to its potential deletion."
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    cleaning = newNode(""cleaning"", 1, 0.0)
    addChildren(h1_bathrooms, [h1_bathroom1, h1_bathroom2, h1_outside])
    addChildren(h1_living_rooms, [h1_lounge, h1_dining, h1_conservatory, h1_playroom])
    addChildren(house1, [h1_bedrooms, h1_bathrooms, h1_attic, h1_kitchen, h1_living_rooms, h1_basement, h1_garage, h1_garden])
    addChildren(h2_bedrooms, [h2_suite1, h2_suite2, h2_bedroom3, h2_bedroom4])
    addChildren(h2_upstairs, [h2_bedrooms, h2_bathroom, h2_toilet, h2_attics])
    addChildren(h2_living_rooms, [h2_lounge, h2_dining, h2_conservatory, h2_playroom])
    addChildren(h2_groundfloor, [h2_kitchen, h2_living_rooms, h2_wet_room, h2_garage, h2_garden, h2_hot_tub])
    addChildren(h2_basement, [h2_cellars, h2_wine_cellar, h2_cinema])
    addChildren(house2, [h2_upstairs, h2_groundfloor, h2_basement])
    addChildren(cleaning, [house1, house2])
    topCoverage = computeCoverage(cleaning)
    print(""TOP COVERAGE = "" + formatFloat(topCoverage, 6))
    print("""")
    print(""NAME HIERARCHY                 | WEIGHT | COVERAGE |"")
    show(cleaning, 0)
    setCoverage(h2_cinema, 1.0)
    diff = computeCoverage(cleaning) - topCoverage
    print("""")
    print(""If the coverage of the Cinema node were increased from 0.75 to 1"")
    print(""the top level coverage would increase by "" + formatFloat(diff, 6) + "" to "" + formatFloat(topCoverage + diff, 6))
    setCoverage(h2_cinema, 0.75)
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/functional-coverage-tree.py,,1,3.927863699585036e-07,"The method is a main function that appears to be part of a larger program, likely for managing or analyzing hierarchical data structures related to house cleaning. It includes performance benchmarking and outputs results in a structured format. The function is well-structured, serves a clear purpose, and provides useful output, making it unlikely to be deleted unless the entire program is refactored or replaced."
survived,"def totalLength():
    tot = 0
    i = 0
    while i < len(words):
        tot = tot + len(words[i])
        if i < len(words) - 1:
            tot = tot + 1
        i = i + 1
    return tot
",tests/rosetta/transpiler/Python/four-is-the-number-of-letters-in-the-....py,,0,0.999998629043345,"The method 'totalLength' is likely to be deleted because it relies on a variable 'words' that is not defined within the function or passed as a parameter. This makes the function non-functional in its current state, as it will raise a NameError when called. Additionally, the logic of the function is quite simple and can be replaced with a more concise and efficient implementation using Python's built-in functions, such as 'sum(len(word) for word in words) + len(words) - 1'."
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    grid = clearGrid()
    ftree(grid, float((width // 2)), float((height - 1)), length, 0.0, depth)
    print(render(grid))
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/fractal-tree.py,,1,9.237449576640118e-09,"The method 'main' is a complete and functional piece of code that performs a series of operations: it initializes some benchmarking variables, processes a grid, and outputs the results. It includes performance measurement and output in JSON format, which is useful for logging or debugging. There is no indication that this method is redundant or obsolete, and it seems to serve a clear purpose in the context of the application. Therefore, it is likely to be retained."
survived,"def floorf(x):
    y = int(x)
    return float(y)
",tests/rosetta/transpiler/Python/formal-power-series.py,,0,0.9999999895325983,"The method `floorf` is a simple implementation of flooring a floating-point number to the nearest lower integer and returning it as a float. However, Python's standard library already provides a more robust and efficient way to achieve this using the `math.floor` function, which is widely used and optimized. Additionally, the `math.floor` function directly returns an integer, which is often more useful than converting it back to a float. Given these factors, the custom `floorf` method is likely to be considered redundant and unnecessary, leading to its deletion."
survived,"def extract(f, n):
    while len(f.coeffs) <= n:
        idx = len(f.coeffs)
        v = f.compute(idx)
        f = dataclasses.replace(f, coeffs=f.coeffs + [v])
    return f.coeffs[n]
",tests/rosetta/transpiler/Python/formal-power-series.py,,1,4.363462233903899e-09,"The method 'extract' is likely to be Survived (1) because it appears to be a utility function that computes and caches coefficients for a given function 'f' until the nth coefficient is available. This kind of functionality is useful in scenarios where lazy evaluation or memoization is needed, which are common in performance optimization tasks. The method is simple, clear, and serves a specific purpose, making it a candidate for retention in a codebase."
survived,"def fourIsMagic(n):
    s = say(n)
    s = capitalize(s)
    t = s
    while n != 4:
        n = len(s)
        s = say(n)
        t = t + "" is "" + s + "", "" + s
    t = t + "" is magic.""
    return t
",tests/rosetta/transpiler/Python/four-is-magic.py,,1,1.1253518384332553e-07,"The method 'fourIsMagic' is a playful implementation of a known sequence where numbers are described in words, and the length of the description is used to generate the next number, eventually leading to the number 4, which is described as 'four is magic'. This is a fun and educational piece of code that demonstrates a unique property of the English language and numbers. Such methods are often appreciated for their creativity and educational value, making it likely to survive."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/floyds-triangle.py,,1,2.8453347280241004e-08,"The method '_now' is a utility function that generates a pseudo-random number based on a global seed if '_now_seeded' is True, or returns the current time in nanoseconds otherwise. This function is likely part of a larger system that requires a consistent and repeatable sequence of numbers for testing or simulation purposes. The use of a global seed allows for reproducibility, which is a common requirement in many applications. The function is simple, serves a clear purpose, and does not have any obvious issues or redundancies that would necessitate its removal. Therefore, it is likely to be retained in the codebase."
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    p = sinCos()
    print(""sin:"" + partialSeries(p.sin))
    print(""cos:"" + partialSeries(p.cos))
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/formal-power-series.py,,1,2.5109990926928157e-08,"The method 'main' is a typical entry point for a Python script, and it includes functionality to measure and print performance metrics such as execution time and memory usage. This kind of functionality is often useful for performance monitoring and debugging, especially in scripts that perform computational tasks. Additionally, the method is well-structured and uses standard libraries like 'resource' and 'json', which are commonly used in Python for such purposes. Therefore, it is likely to be retained in the codebase."
survived,"def floydWarshall(graph):
    n = len(graph)
    dist = []
    next = []
    i = 0
    while i < n:
        drow = []
        nrow = []
        j = 0
        while j < n:
            drow = drow + [graph[i][j]]
            if graph[i][j] < INF and i != j:
                nrow = nrow + [j]
            else:
                nrow = nrow + [-1]
            j = j + 1
        dist = dist + [drow]
        next = next + [nrow]
        i = i + 1
    k = 0
    while k < n:
        i = 0
        while i < n:
            j = 0
            while j < n:
                if dist[i][k] < INF and dist[k][j] < INF:
                    alt = dist[i][k] + dist[k][j]
                    if alt < dist[i][j]:
                        dist[i][j] = alt
                        next[i][j] = next[i][k]
                j = j + 1
            i = i + 1
        k = k + 1
    return FWResult(dist=dist, next=next)
",tests/rosetta/transpiler/Python/floyd-warshall-algorithm2.py,,1,4.363462233903899e-09,"The method implements the Floyd-Warshall algorithm, which is a well-known algorithm for finding shortest paths in a weighted graph with positive or negative edge weights (but no negative cycles). This algorithm is fundamental in computer science and is widely used in various applications, such as network routing and urban traffic planning. The code is correctly structured to initialize the distance and next matrices, and it iteratively updates these matrices to find the shortest paths between all pairs of nodes. Given its correctness and utility, the method is likely to be retained in the codebase."
survived,"def _lambda3(n):
    if n == 0:
        return 0.0
    return extract(a, n - 1) / (float(n))
",tests/rosetta/transpiler/Python/formal-power-series.py,,1,3.466327708641819e-07,"The method _lambda3 is a private helper function, indicated by the underscore prefix, which suggests it is intended for internal use within a module or class. The function performs a simple mathematical operation: it returns 0.0 if the input is 0, otherwise, it divides the result of an 'extract' function by the float of the input number. Without additional context, such as the definition of 'extract' or how this function is used, it's difficult to determine its utility. However, the function itself is straightforward and could be useful in contexts where such a calculation is needed. Therefore, unless the surrounding codebase has changed significantly or this function is no longer needed, it is likely to survive."
survived,"    def fake_eval(self, env, policy, episodes):
        return calls.pop(0)
",tests/test_world_model_open_endedness.py,,0,0.9999999907625504,"The method `fake_eval` is a simple function that returns the first element from a list called `calls`. It doesn't perform any meaningful evaluation or processing related to the parameters `env`, `policy`, or `episodes`. This suggests that the method is likely a placeholder or a mock function used for testing purposes. Such methods are often temporary and are removed once the actual implementation is in place. Therefore, it is likely to be deleted in the future."
survived,"    async def step(self) -> None:
        await self.publish(""alpha.risk"", {""risk"": ""risk level nominal""})
",alpha_factory_v1/demos/alpha_agi_business_v1/alpha_agi_business_v1.py,AlphaRiskAgent,1,7.194132978569833e-09,"The method 'step' is an asynchronous function that publishes a message to a topic 'alpha.risk'. This kind of functionality is common in systems that use message brokers or event-driven architectures, which are prevalent in modern software development. The method is simple, clear, and serves a specific purpose, which is to send a risk level notification. There is no indication that this method is redundant or unnecessary, and it likely plays a role in a larger system that relies on such notifications. Therefore, it is likely to be retained."
survived,"        async def __aexit__(self, *_a: object, **_k: object) -> None:
            self.closed = True
",tests/test_alpha_agi_business_3_v1.py,DummyADK,1,1.725782769012759e-08,"The method is an implementation of the asynchronous context manager's exit method, which is a standard part of Python's asynchronous programming model. It sets an attribute 'closed' to True, which is a common pattern to indicate that the resource has been properly closed or cleaned up. This method is likely to be used in conjunction with an '__aenter__' method to manage resources asynchronously. Since it follows a standard pattern and serves a clear purpose, it is likely to be retained in the codebase."
survived,"        async def run(self, _msg: str) -> None:
            pass
",tests/test_alpha_agi_business_3_v1.py,DummyADK,1,7.3382086014706e-07,"The method 'run' is an asynchronous method that currently does nothing as it only contains a 'pass' statement. However, it is likely a placeholder for future implementation. In many cases, such methods are retained in the codebase to be filled in later as the application develops or as part of an interface that requires this method to be defined. Therefore, it is more likely to survive unless the entire class or interface it belongs to is removed or refactored."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/print_hello.py,,1,5.60279640614594e-09,"The method _fmt is a utility function that formats different types of input values into strings. It handles lists by recursively formatting each element, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted consistently, such as logging, displaying data, or preparing data for serialization. Its versatility and simplicity make it likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/left_join_multi.py,,1,5.60279640614594e-09,"The method _fmt is a utility function that formats different types of input values into strings. It handles lists by recursively formatting each element, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in many programming scenarios where data needs to be formatted for display or logging. Its simplicity and general applicability suggest that it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/substring_builtin.py,,1,1.0467401685178159e-08,"The method _fmt is a utility function that formats different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted for display or logging. Its simplicity and general applicability suggest that it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/load_yaml.py,,1,1.1861120010657661e-08,"The method _fmt is a utility function that formats different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted for display or logging. Its simplicity and general applicability suggest that it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/string_in_operator.py,,1,1.1861120010657661e-08,"The method _fmt is a utility function that formats different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted for display or logging. Its simplicity and general applicability suggest that it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/cross_join_filter.py,,1,8.152020648014727e-09,"The method _fmt is a utility function that formats different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in many contexts where data needs to be formatted for display or logging. Its simplicity and general applicability suggest that it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/string_contains.py,,1,1.1861120010657661e-08,"The method _fmt is a utility function that formats different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted for display or logging. Its simplicity and general applicability suggest that it is likely to be retained in the codebase."
survived,"def classify(n: int) -> str:
    if n == 0:
        return ""zero""
    elif n == 1:
        return ""one""
    else:
        return ""many""
",tests/human/x/python/match_full.py,,1,1.6052280526088547e-09,"The method 'classify' is a simple utility function that categorizes an integer into three distinct categories: 'zero', 'one', and 'many'. This kind of function is often useful in various programming scenarios where specific actions are needed based on the value of an integer. The function is straightforward, easy to understand, and does not have any apparent issues or redundancies. Therefore, it is likely to be retained in the codebase as it serves a clear purpose."
survived,"    def boom(*args, **kwargs):
        raise RuntimeError(""boom"")
",tests/test_fetch_assets.py,,0,0.9999999928058669,"The method 'boom' is designed to immediately raise a RuntimeError with the message 'boom' whenever it is called. This makes the function unusable for any practical purpose, as it will always result in an exception. Such methods are typically not useful in production code unless they are placeholders or meant for testing error handling. Without additional context indicating a specific use case, this method is likely to be deleted as it serves no functional purpose."
survived,"def test_tree_visualization(tmp_path: Path) -> None:
    browser_dir = Path(__file__).resolve().parents[1]
    target = tmp_path / ""browser""
    shutil.copytree(browser_dir, target)
    subprocess.check_call([""npm"", ""run"", ""build""], cwd=target)

    url = (target / ""dist"" / ""index.html"").as_uri()
    tree_path = Path(__file__).resolve().parents[4] / ""docs"" / ""alpha_agi_insight_v1"" / ""tree.json""
    tree = json.loads(tree_path.read_text())

    def count_nodes(node: Mapping[str, Any]) -> int:
        return 1 + sum(count_nodes(c) for c in node.get(""children"", []))

    node_count = count_nodes(tree)
    best_path = tree.get(""bestPath"", [])

    with sync_playwright() as p:
        browser = p.chromium.launch()
        context = browser.new_context()
        page = context.new_page()
        page.goto(url)
        page.wait_for_selector(""#tree-container"")
        page.wait_for_selector(""#tree-container .node"")

        count_initial = page.eval_on_selector_all(""#tree-container .node"", ""els => els.length"")
        page.wait_for_timeout(1000)
        count_later = page.eval_on_selector_all(""#tree-container .node"", ""els => els.length"")
        assert count_later > count_initial

        context.route(""**"", lambda route: route.abort())
        page.wait_for_function(f""document.querySelectorAll('#tree-container .node').length >= {node_count}"")
        page.wait_for_timeout(len(best_path) * 800 + 500)
        highlighted = page.evaluate(
            ""Array.from(document.querySelectorAll('#tree-container circle[fill='#d62728']'))""
            "".map(n => n.parentNode.querySelector('text').textContent)""
        )
        assert highlighted == best_path
        browser.close()",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_tree_visualization.py,,1,2.5109990926928157e-08,"The method 'test_tree_visualization' is a test function that appears to be part of a testing suite for a web application. It uses Playwright to automate a browser to test the visualization of a tree structure. The function checks if the number of nodes in the visualization increases over time and verifies that the highlighted nodes match a 'bestPath'. This kind of test is crucial for ensuring the correctness of the web application's functionality, especially in a complex UI component like a tree visualization. Therefore, it is likely to be maintained as part of the test suite to ensure ongoing reliability of the application."
survived,"def test_localstorage_failure_disables_telemetry() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri()

    with sync_playwright() as p:
        browser = p.chromium.launch()
        page = browser.new_page()
        errors: list[str] = []
        page.on(""pageerror"", lambda err: errors.append(str(err)))
        page.goto(url)
        page.evaluate(
            ""window.OTEL_ENDPOINT='https://example.com';""
            ""window.confirm=() => true;""
            ""Object.defineProperty(localStorage,'setItem',{value:()=>{throw new Error('fail');},configurable:true});""
        )
        page.reload()
        page.wait_for_selector(""#controls"")
        page.evaluate(""window.dispatchEvent(new Event('beforeunload'))"")
        assert not errors
        browser.close()",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_telemetry.py,,1,2.5109990926928157e-08,"The method is a test function that checks if telemetry is disabled when localStorage fails. It uses Playwright to automate a browser and simulate a failure in localStorage. This is a specific test case that ensures the application behaves correctly under certain conditions. Test functions are generally not deleted unless they are redundant or replaced by more comprehensive tests. Since this test serves a clear purpose in verifying application behavior, it is likely to be retained."
survived,"    def test_exception_logged(self):
        saved = wm_mod._kafka
        wm_mod._kafka = DummyKafka()
        with mock.patch.object(wm_mod._LOG, ""exception"") as log_exc:
            wm_mod._kafka_send(""test.topic"", {""x"": 1})
            log_exc.assert_called_once()
            msg, topic_arg = log_exc.call_args.args
            self.assertIn(""Kafka emit failed"", msg)
            self.assertEqual(topic_arg, ""test.topic"")
        wm_mod._kafka = saved
",tests/test_world_model_kafka.py,TestKafkaSend,1,2.0611536181902033e-09,"The method 'test_exception_logged' is a unit test designed to verify that an exception is logged correctly when a Kafka message send operation fails. It uses mocking to simulate the behavior of the Kafka client and the logging mechanism. This is a typical pattern in unit testing to ensure that error handling and logging are functioning as expected. Since this is a test method, it is unlikely to be deleted unless the functionality it tests is removed or significantly changed. Therefore, the method will likely survive."
survived,"    def produce(self, topic, payload):
        raise RuntimeError(""boom"")
",tests/test_world_model_kafka.py,DummyKafka,0,0.999915188952306,"The method 'produce' is designed to raise a RuntimeError with a specific message ('boom') whenever it is called. This indicates that the method is not intended to perform any functional operation but rather to signal an error condition. Such methods are often placeholders or stubs used during development or testing to simulate error conditions. If the method is not replaced with a functional implementation or if the error signaling is no longer needed, it is likely to be deleted. However, if the method serves a specific purpose in testing error handling, it might be retained. Without additional context, the method seems more likely to be deleted as it doesn't perform any useful operation."
survived,"    def test_invalid_env_fallback(self) -> None:
        env = {""PORT"": ""foo"", ""CYCLE"": ""bar"", ""METRICS_PORT"": ""baz"", ""A2A_PORT"": ""qux""}
        with patch.dict(os.environ, env, clear=True):
            args = edge_runner.parse_args([])
        self.assertEqual(args.port, 8000)
        self.assertIsNone(args.cycle)
        self.assertIsNone(args.metrics_port)
        self.assertIsNone(args.a2a_port)
",tests/test_edge_runner_parse.py,TestParseArgs,1,7.194132978569833e-09,"The method 'test_invalid_env_fallback' is a unit test designed to verify that the application correctly falls back to default values when invalid environment variables are provided. Unit tests are crucial for ensuring code reliability and are typically retained unless they are redundant or replaced by more comprehensive tests. Since this test checks for specific behavior (fallback to defaults), it is likely to be useful for maintaining code quality."
survived,"        def generate_text(self, prompt: str) -> str:
            calls.append(prompt)
            return ""sum""
",tests/test_adk_agent.py,StubADK,0,0.9999998362622821,"The method 'generate_text' is likely to be deleted because it does not perform any meaningful text generation. It simply appends the prompt to a list called 'calls' and returns the static string 'sum', which does not align with the expected functionality of generating text based on the prompt. This suggests that the method is either incomplete or incorrectly implemented, making it a candidate for deletion or significant revision."
survived,"    async def run_cycle(self) -> None:
        """"""Generate and emit an ADK summary when data is available.""""""
        with span(""summariser.run_cycle""):
            if not self._records or not self.adk:
                return
            try:
                summary = self.adk.generate_text(""\n"".join(self._records))
            except Exception:
                return
            await self.emit(""strategy"", {""summary"": summary})
            self._records.clear()
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/adk_summariser_agent.py,ADKSummariserAgent,1,9.736200303530205e-10,"The method 'run_cycle' is likely to survive because it performs a crucial function of generating and emitting a summary when data is available. It includes error handling to ensure robustness and uses asynchronous operations, which are beneficial for performance in I/O-bound tasks. The method is well-structured, with clear conditions for execution and cleanup operations, indicating it is a well-thought-out part of the system."
survived,"    async def fake_sleep(sec: float):
        delays.append(sec)
        await orig_sleep(0)
",tests/test_orchestrator_backoff.py,,1,7.73442280641062e-08,"The method 'fake_sleep' is a utility function that is likely used for testing purposes. It modifies the behavior of an existing sleep function by appending the sleep duration to a list and then calling the original sleep function with a zero-second delay. This kind of function is useful for testing asynchronous code without actually waiting for the specified duration, which can speed up test execution. Such utility functions are often retained in codebases for testing and debugging purposes, making it more likely to survive."
survived,"    async def step(self) -> None:
        return None
",tests/test_skill_test_route.py,SimpleAgent,0,0.9999999928058669,"The method 'step' is an asynchronous function that does not perform any operations or return any meaningful value. It simply returns None, which makes it redundant and unnecessary in its current form. Without any additional context or future plans to implement functionality within this method, it is likely to be deleted as it serves no purpose."
survived,"def tesla_setup_signal(sig: Signal, dbc_name: str, line_num: int) -> None:
    if sig.name.endswith(""Counter""):
        sig.type = SignalType.COUNTER
    elif sig.name.endswith(""Checksum""):
        sig.type = SignalType.TESLA_CHECKSUM
        sig.calc_checksum = tesla_checksum
",opendbc/can/packer.py,,1,5.60279640614594e-09,"The method `tesla_setup_signal` is a utility function that configures a `Signal` object based on its name. It sets the type of the signal to either `COUNTER` or `TESLA_CHECKSUM` and assigns a checksum calculation function if applicable. This kind of setup function is useful in systems dealing with automotive signals, especially in contexts where signals need to be processed or validated based on their type. Given its specific utility and the fact that it encapsulates a clear and necessary functionality, it is likely to be retained in the codebase."
survived,"def set_signal_type(sig: Signal, chk: Optional[ChecksumState], dbc_name: str, line_num: int) -> None:
    sig.calc_checksum = None
    if chk:
        if chk.setup_signal:
            chk.setup_signal(sig, dbc_name, line_num)
        if sig.name == 'CHECKSUM':
            sig.type = chk.checksum_type
            sig.calc_checksum = chk.calc_checksum
        elif sig.name == 'COUNTER':
            sig.type = SignalType.COUNTER
",opendbc/can/packer.py,,1,1.4166087846364157e-09,"The method 'set_signal_type' is likely to survive because it performs a specific and necessary function in setting the signal type based on the checksum state and signal name. It is well-structured, with clear conditions for setting the signal type and checksum calculation. The method is also flexible, allowing for different behaviors based on the presence of a checksum state and the signal's name. This kind of functionality is essential in systems dealing with signals and checksums, making it unlikely to be removed unless there is a significant change in the system's requirements or architecture."
survived,"    def test_cache_header_for_old_content(self):
        old_date = timezone.now() - datetime.timedelta(days=181)
        entry = EntryFactory(created=old_date)
        response = self.client.get(entry.get_absolute_url())
        assert response.headers[""cache-control""] == ""s-maxage=%d"" % (
            24 * 60 * 60
        )
",blog/tests.py,BlogTests,1,3.3982678079468468e-09,"The method 'test_cache_header_for_old_content' is a unit test that checks if the cache-control header is set correctly for content older than 180 days. This is a specific and useful test case for ensuring that caching behavior is correctly implemented for old content, which is a common requirement in web applications to optimize performance and resource usage. The method is straightforward, uses a factory to create test data, and performs a simple assertion. There is no indication of redundancy or obsolescence, and it serves a clear purpose in the codebase. Therefore, it is likely to be retained."
survived,"def test_propose_diff_smoke(tmp_path: Path) -> None:
    target = tmp_path / ""demo.py""
    target.write_text(""def demo():\n    return 1\n"", encoding=""utf-8"")
    diff = propose_diff(str(target), ""extra feature"")
    patcher_core.apply_patch(diff, repo_path=tmp_path)
    assert ""extra feature"" in target.read_text(encoding=""utf-8"")
    subprocess.check_call([sys.executable, ""-m"", ""py_compile"", str(target)])
",tests/test_diff_mutation.py,,1,1.8189616842444243e-09,"The method `test_propose_diff_smoke` is a test function that verifies the functionality of proposing and applying a diff to a Python file. It creates a temporary file, writes a simple function to it, proposes a diff with an 'extra feature', applies the patch, and checks if the patch was applied correctly by asserting the presence of 'extra feature' in the file. It also compiles the file to ensure there are no syntax errors. This is a typical test case that ensures the integrity and correctness of the diff application process. Such test functions are crucial for maintaining code quality and are unlikely to be deleted unless the functionality they test is removed or significantly changed. Therefore, the method is likely to be Survived."
survived,"    async def _skill_test(request: Request, name: str) -> Any:
        payload = await request.json()
        if name not in runners:
            raise HTTPException(404, ""Agent not found"")
        inst = runners[name].inst
        if not hasattr(inst, ""skill_test""):
            raise HTTPException(501, ""Agent does not support skill_test"")
        return await inst.skill_test(payload)  # type: ignore[func-returns-value]
",alpha_factory_v1/backend/api_server.py,,1,3.160881453314576e-10,"The method '_skill_test' is likely to survive because it is an asynchronous function that handles a specific request related to 'skill_test'. It includes error handling for cases where the agent is not found or does not support the 'skill_test' method, which indicates it is designed to handle specific scenarios robustly. Additionally, it uses modern Python features like async/await, which are increasingly common in web applications for handling I/O-bound operations efficiently. Unless there is a significant change in the application's requirements or architecture, this method is likely to remain useful."
survived,"    async def maybe_step(self) -> None:
        if time.time() < self.next_ts:
            return
        self._calc_next()

        async def _cycle() -> None:
            t0 = time.time()
            span_cm = tracer.start_as_current_span(self.name) if tracer else contextlib.nullcontext()
            with span_cm:
                try:
                    await asyncio.wait_for(maybe_await(self.inst.run_cycle), timeout=self._max_cycle_sec)
                except asyncio.TimeoutError:
                    MET_ERR.labels(self.name).inc()
                    log.error(""%s run_cycle exceeded %ss budget  skipped"", self.name, self._max_cycle_sec)
                except Exception as exc:  # noqa: BLE001
                    MET_ERR.labels(self.name).inc()
                    log.exception(""%s.run_cycle crashed: %s"", self.name, exc)
                finally:
                    dur_ms = (time.time() - t0) * 1_000
                    MET_LAT.labels(self.name).observe(dur_ms)
                    self.last_beat = time.time()
                    self._publish(""agent.cycle"", {""agent"": self.name, ""latency_ms"": dur_ms, ""ts"": utc_now()})

        self.task = asyncio.create_task(_cycle())
",alpha_factory_v1/backend/agent_manager.py,AgentRunner,1,5.60279640614594e-09,"The method 'maybe_step' is an asynchronous function that manages the execution of a task with error handling, logging, and metrics collection. It uses modern Python features like async/await and context managers, which are considered best practices. The method is well-structured, with clear separation of concerns, and it integrates with tracing and metrics systems, indicating it is part of a larger, well-maintained codebase. These factors suggest that the method is likely to be useful and relevant, leading to its survival."
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/save_jsonl_stdout.py,Person,1,3.2241866333029355e-08,"The __repr__ method is a special method used to define a string representation of an object. In this case, it returns the string representation of the object's __dict__, which is a dictionary containing all the attributes of the object. This is a common and useful implementation for debugging purposes, as it provides a clear and complete view of the object's state. Therefore, it is likely to be retained in the code."
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/right_join.py,Order,1,2.998960815863541e-09,"The method `__repr__` is a special method in Python used to define a string representation of an object. The implementation provided here returns the string representation of the object's dictionary, which is a common and useful way to represent an object for debugging purposes. This implementation is straightforward and serves a clear purpose, making it likely to be retained in the codebase unless there are specific requirements for a more customized representation. Therefore, it is likely to survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/dataset_sort_take_limit.py,Product,1,4.6911638017642294e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a common and useful pattern for dynamic attribute access. This method is likely to be useful in scenarios where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, it is likely to be retained in the code."
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/order_by_map.py,Data,1,3.850741907939403e-09,"The method `__repr__` is a special method in Python used to define a string representation of an object. The implementation provided here returns the string representation of the object's dictionary, which is a common and useful way to represent the internal state of an object for debugging purposes. This implementation is straightforward and serves a clear purpose, making it likely to be retained in the codebase."
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/group_by_multi_join_sort.py,Nation,1,1.522997951276035e-08,"The method `__repr__` is a special method in Python used to define a string representation of an object. The implementation provided here returns the string representation of the object's dictionary, which is a common and useful way to represent an object for debugging purposes. This method is likely to be retained because it provides a clear and concise way to inspect the internal state of an object, which is valuable for developers during debugging and logging."
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/cross_join.py,Customer,1,3.3982678079468468e-09,"The __repr__ method is a special method used to define a string representation of an object. In this case, it returns the string representation of the object's dictionary, which is a common and useful way to provide a detailed view of the object's attributes for debugging purposes. This implementation is straightforward and serves a clear purpose, making it likely to be retained in the codebase."
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/group_by_join.py,Order,1,1.3440409770490404e-08,"The __repr__ method is a special method used to define a string representation of an object. In this case, it returns the string representation of the object's __dict__, which is a dictionary containing all the attributes of the object. This is a common and useful implementation for debugging purposes, as it provides a clear and detailed view of the object's state. Therefore, it is likely to be retained in the code."
survived,"    def list_agents(_detail: bool = False) -> list[str]:  # noqa: D401
        return [""dummy"", ""fail""]
",tests/test_backend_orchestrator_dev.py,,1,1.725782769012759e-08,"The method 'list_agents' is a simple function that returns a hardcoded list of strings. It is unlikely to be deleted because it serves a basic purpose of providing a list of agent names, which could be useful in various contexts. Even though the list is currently hardcoded, it might be a placeholder for future dynamic content or used for testing purposes. Therefore, it is more likely to survive."
survived,"    def get_agent(name: str) -> object:  # noqa: D401
        agent = DummyAgent() if name == ""dummy"" else FailingAgent()

        if hasattr(agent, ""step"") and inspect.iscoroutinefunction(agent.step):
            orig = agent.step

            async def _wrapped(*a: object, **kw: object) -> object:
                t0 = time.perf_counter()
                ok = True
                try:
                    return await orig(*a, **kw)
                except Exception:
                    ok = False
                    raise
                finally:
                    _HEALTH_Q.put((name, (time.perf_counter() - t0) * 1000, ok))

            agent.step = _wrapped
        return agent
",tests/test_backend_orchestrator_dev.py,,1,1.3176514268359263e-10,"The method 'get_agent' is likely to survive because it provides a useful functionality of returning an agent object based on the input name, and it wraps the 'step' method of the agent with additional functionality to measure execution time and handle exceptions. This kind of functionality is often needed in systems that require monitoring and logging of agent performance, making it a valuable method to retain."
survived,"def _gen_certs(tmp: Path) -> tuple[str, str, bytes, str]:
    root = Path(__file__).resolve().parents[1]
    script = root / ""alpha_factory_v1"" / ""demos"" / ""alpha_agi_insight_v1"" / ""infrastructure"" / ""gen_bus_certs.sh""
    subprocess.run([""bash"", str(script)], cwd=tmp, check=True, capture_output=True)
    cert = tmp / ""certs"" / ""bus.crt""
    key = tmp / ""certs"" / ""bus.key""
    token = ""change_this_token""
    ca = cert.read_bytes()
    return str(cert), str(key), ca, token
",tests/test_bus_ssl_gen.py,,1,9.237449576640118e-09,"The method `_gen_certs` is likely to survive because it performs a specific and useful function: generating certificates by running a shell script and returning the paths and contents of the generated certificate and key files. This functionality is essential in many systems that require secure communications, and the method is well-structured to achieve this task. Additionally, the use of subprocess to run a script and handle outputs is a common pattern in Python for interacting with system-level operations, indicating that the method is designed with a clear purpose and utility."
survived,"def test_memory_agent_file_persistence(tmp_path: Path) -> None:
    mem_file = tmp_path / ""mem.log""
    cfg = config.Settings(bus_port=0, memory_path=str(mem_file))
    bus = messaging.A2ABus(cfg)
    ledger = logging.Ledger(str(tmp_path / ""ledger.db""))
    agent = memory_agent.MemoryAgent(bus, ledger, str(mem_file))

    envs = [messaging.Envelope(""a"", ""memory"", {""idx"": i}, 0.0) for i in range(3)]

    async def _run() -> None:
        for env in envs:
            await agent.handle(env)

    asyncio.run(_run())

    entries = [json.loads(line) for line in mem_file.read_text(encoding=""utf-8"").splitlines()]
    assert [e[""idx""] for e in entries] == list(range(3))

    agent2 = memory_agent.MemoryAgent(bus, ledger, str(mem_file))
    assert [r[""idx""] for r in agent2.records] == list(range(3))

    asyncio.run(bus.stop())
    ledger.close()",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_memory_agent_file_persistence.py,,1,3.927863699585036e-07,"The method `test_memory_agent_file_persistence` is a unit test designed to verify the persistence of memory agent data to a file. It is crucial for ensuring that the memory agent's state can be saved and restored correctly, which is an important feature in many applications. Unit tests like this are typically retained in codebases to ensure ongoing reliability and correctness of the functionality they test. Therefore, it is unlikely to be deleted unless the feature it tests is removed or significantly altered."
survived,"def _free_port() -> int:
    s = socket.socket()
    s.bind((""localhost"", 0))
    port = s.getsockname()[1]
    s.close()
    return port
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_bus_secure.py,,1,1.522997951276035e-08,"The method _free_port is a utility function that finds and returns an available port on the localhost. This is a common requirement in network programming, especially for testing purposes where a free port is needed to bind a service temporarily. The method is simple, effective, and does not have any apparent issues or redundancies. It is likely to be useful in various scenarios where dynamic port allocation is needed, thus it is unlikely to be deleted."
survived,"def test_simulate_invalid_option() -> None:
    """"""Invoke simulate with an invalid export option.""""""
    res = CliRunner().invoke(
        cli.main,
        [""simulate"", ""--horizon"", ""1"", ""--offline"", ""--export"", ""xml""],
    )
    assert res.exit_code != 0
    assert ""Invalid value for '--export'"" in res.output",tests/test_demo_cli.py,,1,7.582560422162384e-10,"The method 'test_simulate_invalid_option' is a unit test designed to verify that the CLI application correctly handles an invalid export option. It uses the 'CliRunner' to invoke the command and checks that the exit code is non-zero and that the output contains an error message indicating an invalid export option. This is a standard practice in testing to ensure robustness and error handling in applications. Since it serves a clear purpose in validating the application's behavior, it is likely to be retained."
survived,"def test_compute_merkle_root(tmp_path: Path) -> None:
    ledger = Ledger(str(tmp_path / ""l.db""), broadcast=False)
    envs = [
        messaging.Envelope(""a"", ""b"", {""v"": 1}, 0.0),
        messaging.Envelope(""b"", ""c"", {""v"": 2}, 1.0),
        messaging.Envelope(""c"", ""d"", {""v"": 3}, 2.0),
    ]
    for env in envs:
        ledger.log(env)
    computed = ledger.compute_merkle_root()
    hashes = []
    for env in envs:
        data = json.dumps(asdict(env), sort_keys=True).encode()
        hashes.append(insight_logging.blake3(data).hexdigest())  # type: ignore[attr-defined]
    manual = insight_logging._merkle_root(hashes)
    assert computed == manual
",tests/test_logging.py,,1,1.522997951276035e-08,"The method is a test function that verifies the correctness of the `compute_merkle_root` method in the `Ledger` class. It is a well-structured test that uses a temporary path to create a ledger, logs some envelopes, computes the Merkle root, and compares it with a manually calculated one. This is a typical and necessary part of software development to ensure code reliability and correctness. Therefore, it is likely to be retained as part of the test suite."
survived,"def test_broadcast_merkle_root_logs_root_when_disabled(
    tmp_path: Path, caplog: pytest.LogCaptureFixture
) -> None:
    ledger = Ledger(str(tmp_path / ""l.db""), broadcast=False)
    env = messaging.Envelope(""a"", ""b"", {""v"": 1}, 0.0)
    ledger.log(env)
    root = ledger.compute_merkle_root()

    caplog.set_level(logging.INFO)

    dummy = mock.Mock(side_effect=AssertionError(""AsyncClient should not be used""))
    with mock.patch.object(insight_logging, ""AsyncClient"", dummy):
        asyncio.run(ledger.broadcast_merkle_root())

    assert not dummy.called
    assert any(f""Merkle root {root}"" in r.getMessage() for r in caplog.records)",tests/test_logging.py,,1,6.348800075736417e-09,"The method `test_broadcast_merkle_root_logs_root_when_disabled` is a unit test function that verifies the behavior of the `broadcast_merkle_root` method when broadcasting is disabled. It checks that the Merkle root is logged and that the `AsyncClient` is not used. This is a valid and useful test case to ensure that the system behaves correctly under specific conditions. There is no indication that this test is redundant or obsolete, and it serves a clear purpose in the test suite. Therefore, it is likely to be retained."
survived,"    def add_remote(self, name: str, url: str) -> None:
        self._run(""remote"", ""add"", name, url)
",src/meta_agent/git_utils.py,GitManager,1,1.2501528648238603e-09,"The method 'add_remote' is a simple utility function that wraps a command to add a remote repository in a version control system, likely Git. It is straightforward, performs a specific task, and is likely used in a larger context where managing remote repositories is necessary. Such utility functions are common and useful in software that interacts with version control systems, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained."
survived,"    def __init__(self) -> None:
        self.completions = _ChatCompletions()
",src/meta_agent/services/openai_stub.py,_Chat,1,1.444980317078884e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting up initial states. Therefore, it is unlikely that this method will be deleted as it serves a critical purpose in the class structure."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/100-doors-2.py,,1,1.444980317078884e-07,"The method _now() is a utility function that generates a pseudo-random number based on a seed if _now_seeded is True, or returns the current time in nanoseconds otherwise. This function is likely part of a larger system that requires either a random number generator or a timestamp. The use of global variables like _now_seed and _now_seeded suggests that this function is part of a module that manages state across multiple calls. Such utility functions are common in systems that need to simulate time or generate reproducible random sequences for testing purposes. Therefore, it is likely to be retained as it serves a specific purpose in the system."
survived,"def plus(m, n):
    return lambda f: compose(m(f), n(f))
",tests/rosetta/transpiler/Python/church-numerals-2.py,,1,7.73442280641062e-08,"The method 'plus' is a higher-order function that returns a lambda function. It takes two arguments, 'm' and 'n', which are expected to be functions themselves. The lambda function returned by 'plus' takes a function 'f' as an argument and applies 'compose' to the results of 'm(f)' and 'n(f)'. This pattern is common in functional programming and can be useful in scenarios where function composition is needed. Since the method is well-defined and serves a specific purpose, it is likely to be retained in the codebase."
survived,"def add(c, d):
    return lambda f: lambda x: c(f)(d(f)(x))
",tests/rosetta/transpiler/Python/church-numerals-1.py,,1,2.699578619062706e-07,"The method 'add' is a higher-order function that returns a lambda function. It takes two arguments, 'c' and 'd', and returns a function that takes another function 'f' and applies 'c' and 'd' to 'f' with 'x'. This kind of functional programming approach is often used in scenarios where functions need to be composed or combined in a flexible manner. Such patterns are common in functional programming and can be useful in various contexts, especially in languages that support first-class functions. Therefore, the method is likely to be retained as it provides a unique and potentially useful functionality."
survived,"def zero():
    return lambda f: id
",tests/rosetta/transpiler/Python/church-numerals-2.py,,0,0.9999999895325983,"The method 'zero' is a higher-order function that returns a lambda function. However, the lambda function simply returns the 'id' function, which is not particularly useful or meaningful in most contexts. The method lacks a clear purpose or application, making it likely to be considered redundant or unnecessary in a codebase. Without a specific use case or further functionality, it is likely to be deleted."
survived,"def primeFactors(n):
    factors = []
    x = n
    while x % 2 == 0:
        factors = factors + [2]
        x = int((x // 2))
    p = 3
    while p * p <= x:
        while x % p == 0:
            factors = factors + [p]
            x = int((x // p))
        p = p + 2
    if x > 1:
        factors = factors + [x]
    return factors
",tests/rosetta/transpiler/Python/composite-numbers-k-with-no-single-digit-factors-whose-factors-are-all-substrings-of-k.py,,1,6.023574641292144e-08,"The method 'primeFactors' is a standard implementation for finding the prime factors of a given number 'n'. It efficiently handles both even and odd numbers, and correctly returns a list of prime factors. The logic is sound and the method is useful for mathematical computations, making it unlikely to be deleted. It is a fundamental algorithm that is often used in various applications, such as cryptography, number theory, and computer science education."
survived,"def modInv(a, m):
    r = egcd(a, m)
    if r[0] != 1:
        return 0
    x = r[1]
    if x < 0:
        return x + m
    return x
",tests/rosetta/transpiler/Python/chinese-remainder-theorem.py,,1,8.76424914819242e-08,"The method 'modInv' is a utility function that calculates the modular inverse of 'a' under modulo 'm'. This is a common mathematical operation used in various algorithms, particularly in cryptography and number theory. The function uses the extended Euclidean algorithm (presumably implemented in 'egcd') to find the inverse. The logic checks if the greatest common divisor is 1, which is necessary for the inverse to exist, and adjusts the result to be positive if needed. Such utility functions are often retained in codebases due to their usefulness in solving modular arithmetic problems."
survived,"def printMat(m):
    i = 0
    while i < len(m):
        line = """"
        j = 0
        while j < len(m[i]):
            line = line + str(m[i][j])
            if j < len(m[i]) - 1:
                line = line + "" ""
            j = j + 1
        print(line)
        i = i + 1
",tests/rosetta/transpiler/Python/cholesky-decomposition.py,,1,1.3709568184771895e-06,"The method 'printMat' is a simple utility function that prints a 2D matrix in a formatted way. It uses basic loops to iterate over the matrix and constructs a string for each row before printing it. While the method is functional, it is not the most efficient or Pythonic way to achieve this task. In Python, list comprehensions and the 'join' method are typically used for such operations, making the code more concise and readable. However, the method is not incorrect or redundant, and it serves its purpose without any errors. Therefore, it is likely to survive unless there is a specific need to refactor it for efficiency or readability."
survived,"def parseIntStr(str):
    i = 0
    neg = False
    if len(str) > 0 and str[0:1] == ""-"":
        neg = True
        i = 1
    n = 0
    digits = {""0"": 0, ""1"": 1, ""2"": 2, ""3"": 3, ""4"": 4, ""5"": 5, ""6"": 6, ""7"": 7, ""8"": 8, ""9"": 9}
    while i < len(str):
        n = n * 10 + digits[str[i:i + 1]]
        i = i + 1
    if neg:
        n = -n
    return n
",tests/rosetta/transpiler/Python/compiler-virtual-machine-interpreter.py,,1,1.1861120010657661e-08,"The method 'parseIntStr' is a utility function that converts a string representation of an integer into an actual integer. This is a common requirement in programming, especially when dealing with input data that is often in string format. The function handles negative numbers and uses a dictionary to map string digits to their integer values, which is a straightforward and efficient approach. Such utility functions are generally useful and are likely to be retained unless there is a more efficient or standardized library function available that performs the same task. However, since this function is simple and effective, it is likely to survive."
survived,"def convexHull(ps):
    ps = sortPoints(ps)
    h = []
    for pt in ps:
        while len(h) >= 2 and ccw(h[len(h) - 2], h[len(h) - 1], pt) == False:
            h = h[:len(h) - 1]
        h = h + [pt]
    i = len(ps) - 2
    t = len(h) + 1
    while i >= 0:
        pt = ps[i]
        while len(h) >= t and ccw(h[len(h) - 2], h[len(h) - 1], pt) == False:
            h = h[:len(h) - 1]
        h = h + [pt]
        i = i - 1
    return h[:len(h) - 1]
",tests/rosetta/transpiler/Python/convex-hull.py,,1,3.3982678079468468e-09,"The method implements a well-known algorithm for computing the convex hull of a set of points, which is a fundamental problem in computational geometry. The code appears to be a correct implementation of the Graham scan algorithm, which is efficient and widely used. Such algorithms are essential in various applications, including computer graphics, geographic information systems, and robotics. Therefore, the method is likely to be useful and relevant, leading to its survival."
survived,"        def __init__(self, app: FastAPI, window: int = 60) -> None:
            super().__init__(app)
            self.window = window
            self.window_start = time.time()
            self.req_count = 0
            self.resp_429 = 0
",src/interface/api_server.py,MetricsMiddleware,1,3.653482080241728e-08,"The method is a constructor for a class that initializes important attributes such as 'window', 'window_start', 'req_count', and 'resp_429'. These attributes are likely used for rate limiting or tracking requests in a FastAPI application. Constructors are essential for setting up the initial state of an object, and this one appears to be well-structured for its purpose. Therefore, it is unlikely to be deleted."
survived,"    def __init__(
        self,
        cli_output: CLIOutput | None = None,
        log: logging.Logger | None = None,
    ) -> None:
        from .cli_output import CLIOutput  # local import to avoid circular

        self.cli_output = cli_output or CLIOutput()
        self.logger = log or logger
",src/meta_agent/ux/error_handler.py,ErrorHandler,1,1.637377179507321e-07,"The method is a constructor (__init__) for a class, which is a fundamental part of object-oriented programming in Python. Constructors are essential for initializing new objects and setting up initial states. The use of type hints and default values for parameters also indicates good coding practices. Additionally, the method includes a local import to avoid circular dependencies, which is a thoughtful design consideration. These factors suggest that the method is well-structured and serves a necessary purpose, making it unlikely to be deleted."
survived,"    def list_files(self) -> List[str]:
        files: List[str] = []
        for path in self.bundle_dir.rglob(""*""):
            if (
                path.is_file()
                and path.name != ""bundle.json""
                and "".git"" not in path.parts
            ):
                files.append(str(path.relative_to(self.bundle_dir)))
        return files
",src/meta_agent/bundle.py,Bundle,1,1.4166087846364157e-09,"The method 'list_files' is a utility function that collects and returns a list of file paths from a directory, excluding certain files and directories. This is a common and useful functionality in many applications, especially those dealing with file management or processing. The method is well-defined, uses clear logic to filter out unwanted files, and returns a list of file paths relative to a specified directory. There is no indication that this method is redundant or unnecessary, and it serves a clear purpose. Therefore, it is likely to be retained in the codebase."
survived,"    def __enter__(self) -> ""Ledger"":
        """"""Return ``self`` for context manager support.""""""
        return self
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/logging.py,Ledger,1,2.5109990926928157e-08,"The method `__enter__` is a standard part of implementing a context manager in Python. It is used to define what happens when the context manager is entered, and it typically returns the object itself (in this case, `self`). This is a common and necessary method for any class that is intended to be used with the `with` statement. Therefore, it is unlikely to be deleted as it serves a specific and important purpose in the context manager protocol."
survived,"        async def invoke_tool(self, name: str, args: dict[str, object] | None = None) -> object:
            args = args or {}
            self.called.append((name, args))
            return {""ok"": True}
",tests/test_adapters.py,StubMCP,1,1.4166087846364157e-09,"The method 'invoke_tool' is a simple utility function that logs the invocation of a tool by appending the tool's name and arguments to a list called 'called'. It then returns a dictionary indicating success. This method is likely to be useful for tracking tool usage and ensuring that the correct tools are being invoked with the correct arguments. Since it serves a clear purpose and is straightforward, it is likely to be retained in the codebase."
survived,"    def _raise(_name: str):
        raise ModuleNotFoundError
",tests/test_adapters.py,,0,0.9999999006880476,"The method `_raise` is a private method (indicated by the underscore) that takes a string parameter `_name` but does not use it in any meaningful way. It simply raises a `ModuleNotFoundError` without any context or message. This makes the method not very useful or informative for debugging or error handling. Additionally, the method does not provide any functionality beyond raising a generic exception, which can be done directly without the need for a separate method. Therefore, it is likely to be deleted as it does not add value to the codebase."
survived,"        def __init__(self) -> None:
            self.instructions: list[object] = []
",tests/test_safety_guardian_property.py,DummyTx,1,7.194132978569833e-09,"The method is a constructor (__init__) in Python, which is essential for initializing new objects of a class. It is a fundamental part of object-oriented programming in Python and is unlikely to be deleted unless the entire class is being removed or refactored. Since the code snippet shows a typical use of __init__ to initialize an instance variable, it is expected to survive."
survived,"def _dummy_classes():
    captured: dict[str, str] = {}

    class DummyClient:
        def __init__(self, url: str) -> None:
            captured[""url""] = url

        async def send_transaction(self, tx: object, *args: object) -> None:
            captured[""data""] = tx.instructions[0].data.decode()

        async def close(self) -> None:  # pragma: no cover - dummy
            pass

    class DummyTx:
        def __init__(self) -> None:
            self.instructions: list[object] = []

        def add(self, instr: object) -> ""DummyTx"":
            self.instructions.append(instr)
            return self

    class DummyInstr:
        def __init__(self, program_id: object, data: bytes, keys: list[object]):
            self.data = data

    class DummyPk:
        def __init__(self, val: str) -> None:  # pragma: no cover - dummy
            pass

    return captured, DummyClient, DummyTx, DummyInstr, DummyPk
",tests/test_safety_guardian_property.py,,1,8.152020648014727e-09,"The method `_dummy_classes` is a utility function that defines and returns a set of dummy classes for testing purposes. These classes are likely used to mock or simulate behavior in a controlled environment, such as unit tests. The presence of `pragma: no cover` comments suggests that these classes are not intended to be covered by test coverage tools, reinforcing their role as test utilities. Such utility functions are common in codebases to facilitate testing without relying on external dependencies or complex setups. Therefore, it is likely that this method will survive as it serves a useful purpose in testing and development."
survived,"def test_run_macro_demo_health_check(tmp_path: Path) -> None:
    """"""Health gate should hit the expected endpoint.""""""
    _, curl_log = _run_script(tmp_path, env={""OPENAI_API_KEY"": ""dummy-key""})
    assert ""http://localhost:7864/healthz"" in curl_log",tests/test_macro_launcher.py,,1,3.3982678079468468e-09,"The method `test_run_macro_demo_health_check` is a test function that checks if a health check endpoint is correctly hit. It uses a temporary path and a dummy API key to run a script and then asserts that the expected endpoint URL is present in the log. This is a typical test case for ensuring that a service is running correctly and is crucial for maintaining the reliability of the system. Therefore, it is likely to be retained as part of the test suite."
survived,"    def task(*_a, **_kw):
        def decorator(func):
            return func

        return decorator
",stubs/google_adk/__init__.py,,1,3.726639116582555e-06,"The method 'task' is a decorator factory that returns a decorator which does nothing but return the original function. This pattern is often used as a placeholder or for future extension where additional functionality might be added to the decorator. Since it doesn't currently add any functionality, it might seem redundant, but it is a common practice to have such scaffolding in place for future development. Therefore, it is likely to be retained for potential future use or as a placeholder."
survived,"def _sa_to_enrich(instance: Any, model_cls: type) -> Any:
    data: dict[str, Any] = {}
    for name in model_cls.model_fields:
        if name in model_cls.relationship_fields():
            continue
        if hasattr(instance, name):
            data[name] = getattr(instance, name)
    return model_cls(**data)
",src/enrichmcp/sqlalchemy/auto.py,,1,8.152020648014727e-09,"The method '_sa_to_enrich' is a utility function that converts an instance of a class into another model class by copying over attributes that are not part of relationship fields. This type of method is useful in data transformation and object-relational mapping scenarios, which are common in software development. The method is well-defined, performs a specific task, and does not have any apparent issues or redundancies that would warrant its deletion. Therefore, it is likely to be retained in the codebase."
survived,"    def fn(genome: list[float]) -> tuple[float]:
        time.sleep(0.2)
        return (sum(genome),)
",tests/test_experiments.py,,1,7.3382086014706e-07,"The method 'fn' is a simple function that takes a list of floats as input and returns a tuple containing the sum of the list. The function includes a sleep delay of 0.2 seconds, which might be unnecessary for its primary purpose. However, the function itself is straightforward and functional, providing a clear output based on its input. Unless there are specific performance concerns or the sleep delay is deemed unnecessary, the function is likely to survive as it performs its intended task correctly."
survived,"    def health(self) -> str:
        """"""Return ``'ok'`` if the orchestrator is healthy.""""""
        url = f""{self.base_url}/healthz""
        resp = requests.get(url)
        resp.raise_for_status()
        return resp.text
",alpha_factory_v1/demos/alpha_agi_marketplace_v1/marketplace.py,MarketplaceClient,1,4.1399375473943306e-08,"The method 'health' is a simple utility function that checks the health status of an orchestrator by making an HTTP GET request to a health endpoint. This is a common pattern in software systems to ensure that services are running correctly. The method is straightforward, performs a necessary function, and is likely to be used in monitoring or maintenance tasks. Therefore, it is unlikely to be deleted unless the system architecture changes significantly or the health check mechanism is replaced by another method."
survived,"    def __init__(self, target: int = 5, market_data: List[int] | None = None) -> None:
        super().__init__(target=target)
        self.market_data = list(market_data) if market_data else []
",alpha_factory_v1/demos/meta_agentic_tree_search_v0/mats/env.py,LiveBrokerEnv,1,7.194132978569833e-09,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. It initializes the object with a default target value and an optional market_data list. This is a common pattern in Python to ensure that objects are created with a consistent state. The use of type hints and default values makes the code more readable and maintainable. Therefore, it is unlikely that this method will be deleted as it serves a crucial role in the class's functionality."
survived,"def test_chinese_labels() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri()

    with sync_playwright() as p:
        browser = p.chromium.launch()
        context = browser.new_context(locale=""zh-CN"")
        page = context.new_page()
        page.goto(url)
        page.wait_for_selector(""#controls"")
        label_text = page.locator(""#controls label"").first.inner_text()
        assert """" in label_text
        browser.close()
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_chinese_locale.py,,1,1.1032560311263802e-09,"The method 'test_chinese_labels' is a test function that uses Playwright to automate a browser and check if a specific label on a webpage contains the Chinese word ''. This is a specific and useful test for ensuring that the webpage correctly displays Chinese labels, which is important for internationalization and localization testing. Such tests are crucial for maintaining the quality of web applications in different languages. Therefore, this method is likely to be retained as it serves a clear purpose in the testing suite."
survived,"def health() -> dict[str, str]:
    return {""status"": ""ok""}",backend/main.py,,1,2.3355930333443423e-09,"The method 'health' is a simple utility function that returns a dictionary with a status message. Such functions are often used in applications to provide a quick health check or status report, especially in web services or APIs. Given its simplicity and utility, it is likely to be retained in the codebase as it serves a clear purpose without any apparent issues or complexity."
survived,"def main(argv: List[str] | None = None) -> None:
    parser = argparse.ArgumentParser(description=""Process files with Attachments DSL"")
    parser.add_argument(""paths"", nargs=""*"", help=""Files, URLs or directories to process"")
    parser.add_argument(""-c"", ""--cwd"", help=""Change working directory before processing"")
    parser.add_argument(""-q"", ""--quiet"", action=""store_true"", help=""Silence verbose logs"")
    parser.add_argument(
        ""-y"",
        ""--copy"",
        action=""store_true"",
        help=""Copy result text to clipboard using to_clipboard_text"",
    )
    parser.add_argument(""--prompt"", default="""", help=""Prompt when copying to clipboard"")

    args, extra = parser.parse_known_args(argv)

    if args.cwd:
        os.chdir(args.cwd)

    set_verbose(not args.quiet)

    dsl_fragment = _build_dsl(extra)
    paths = args.paths or ["".""]
    paths_with_dsl = [p + dsl_fragment for p in paths]

    try:
        ctx = Attachments(*paths_with_dsl)
        if args.copy:
            adapt.to_clipboard_text(ctx, prompt=args.prompt)
        else:
            output = str(ctx)
            if output:
                print(output)
    except Exception as exc:
        print(f""Error running attachments CLI: {exc}"", file=sys.stderr)
        sys.exit(1)
",src/attachments/cli.py,,1,3.850741907939403e-09,"The method 'main' is a typical entry point for a command-line interface (CLI) application. It uses argparse to handle command-line arguments, which is a common and well-supported practice in Python. The method is structured to handle various options like changing the working directory, silencing logs, and copying output to the clipboard. These features suggest that the method is functional and useful for its intended purpose. There is no indication of deprecated practices or inefficiencies that would necessitate its removal. Therefore, it is likely to be retained in the codebase."
survived,"  def supports_active_cooling(self) -> bool:
    return False
",pylabrobot/heating_shaking/inheco_backend.py,InhecoThermoShakeBackend,0,0.9859363760560113,"The method `supports_active_cooling` is a simple implementation that returns a constant boolean value `False`. This suggests that the method is not currently supporting any dynamic logic or configuration that might change its return value. However, the method is clear and self-explanatory, indicating its purpose directly through its name. If the system or application this method is part of does not require active cooling or if this feature is not planned to be supported in the future, the method might be considered redundant and could be deleted. On the other hand, if the system might support active cooling in the future, keeping this method could be useful for future expansion. Without additional context on the system's requirements or future plans, it's challenging to definitively predict its deletion. However, given the simplicity and the static nature of the method, it leans towards being potentially unnecessary unless future plans justify its existence."
survived,"  def supports_active_cooling(self) -> bool:
    return False
",pylabrobot/temperature_controlling/opentrons_backend.py,OpentronsTemperatureModuleBackend,1,2.998960815863541e-09,"The method `supports_active_cooling` is a simple method that returns a boolean value indicating whether active cooling is supported. It is likely part of a larger system or class that deals with cooling mechanisms. The method is straightforward and does not have any apparent issues or redundancies that would necessitate its removal. Additionally, it provides a clear and specific piece of information that could be useful in decision-making processes within the system. Therefore, it is likely to be retained as it serves a purpose in the context it is used."
survived,"  def __init__(self, temperature: float = 25.0):
    super().__init__()
    self.temperature = temperature
    self.set_called = False
",pylabrobot/temperature_controlling/temperature_controller_tests.py,_FakeBackend,1,4.1399375473943306e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with default or specified values. The presence of a constructor is crucial for the proper functioning of a class, especially if it involves setting initial states or properties, as seen with the 'temperature' attribute here. Therefore, it is unlikely to be deleted."
survived,"        def eval_fn(genome: list[float]) -> tuple[float, float, float]:
            x, y = genome
            return x**2, y**2, (x + y) ** 2
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/cli.py,,1,4.363462233903899e-09,"The method 'eval_fn' is a simple function that takes a list of two floats and returns a tuple of three floats, each representing a mathematical operation on the input values. The function is straightforward, performs basic operations, and is likely to be useful in contexts where such evaluations are needed, such as genetic algorithms or optimization problems. There is no indication that this function is redundant or unnecessary, so it is likely to be retained."
survived,"                        def select(self, *_):
                            return self
",no-ocr-api/tests/test_ingest_search.py,FakeTable.Limiter.Selector,0,0.9997040427747256,"The method 'select' is a placeholder that does not perform any meaningful operation other than returning the instance itself. It takes any number of arguments but does nothing with them. This kind of method is often used as a stub or a part of a fluent interface pattern. However, without additional context or functionality, it doesn't add value to the class. If the class is intended to be a part of a larger framework or library where such a method is expected, it might survive. Otherwise, if it's not serving any purpose, it is likely to be deleted."
survived,"def test_apply_diff_failure_returns_output():
    with tempfile.TemporaryDirectory() as repo:
        open(os.path.join(repo, ""file.txt""), ""w"").close()
        success, output = diff_utils.apply_diff(""bad diff"", repo_dir=repo)
        assert not success
        assert ""patch"" in output.lower()
",tests/test_diff_utils_apply.py,,1,1.0467401685178159e-08,"The method 'test_apply_diff_failure_returns_output' is a unit test designed to verify the behavior of the 'apply_diff' function when it encounters a failure. It uses a temporary directory to simulate a repository environment and checks that the function returns a failure status and an appropriate error message. This is a standard practice in testing to ensure robustness and error handling in code. Since testing for failure cases is crucial for maintaining code quality, this method is likely to be retained as part of the test suite."
survived,"def test_transform_image_missing_cv2(monkeypatch) -> None:
    img = Image.new(""RGB"", (10, 10), ""red"")

    monkeypatch.setattr(""mistral_common.tokens.tokenizers.multimodal.is_cv2_installed"", lambda: False)

    with pytest.raises(ImportError) as exc_info:
        transform_image(img, (16, 16))

    assert ""pip install mistral-common[opencv]"" in str(exc_info.value)",tests/test_multimodal.py,,1,1.8189616842444243e-09,"The method is a unit test designed to check the behavior of the `transform_image` function when the `cv2` library is not installed. It uses `monkeypatch` to simulate the absence of `cv2` and expects an `ImportError` to be raised with a specific message. This is a valid and useful test case to ensure that the function handles missing dependencies correctly. Therefore, it is likely to be retained in the codebase."
survived,"        async def start(self) -> None:
            return None
",tests/test_bus_large_payloads_property.py,Prod,0,0.9999999936511998,"The method 'start' is an asynchronous function that does not perform any operations or return any meaningful value. It simply returns None, which makes it redundant and unnecessary in its current form. Without any additional context or usage, it is likely to be deleted as it does not contribute to the functionality of the code."
survived,"def test_adk_generate_text_success(httpx_mock, stub_adk):
    httpx_mock.add_response(url=""https://adk.example/generate"", json={""text"": ""ok""})
    adapter = ADKAdapter()
    result = adapter.generate_text(""hi"")
    assert result == ""ok""
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_adapters.py,,1,6.69158608681505e-10,"The method `test_adk_generate_text_success` is a unit test designed to verify the functionality of the `generate_text` method in the `ADKAdapter` class. Unit tests are crucial for ensuring code reliability and are typically maintained as long as the functionality they test is relevant. Since this test checks the successful response of a text generation feature, it is likely to be retained to ensure that the feature continues to work as expected. Therefore, the method will survive."
survived,"    def api_name(self) -> str:
        return {
            FluxKontextModelName.PRO: ""black-forest-labs/flux-kontext-pro"",
            FluxKontextModelName.MAX: ""black-forest-labs/flux-kontext-max"",
        }[self]
",autogpt_platform/backend/backend/blocks/flux_kontext.py,FluxKontextModelName,1,8.76424914819242e-08,"The method `api_name` is a simple utility function that maps an enumeration value to a corresponding string. This type of method is often useful in codebases for maintaining clean and readable code, especially when dealing with multiple configurations or settings. It is unlikely to be deleted because it provides a clear and concise way to retrieve API names based on model types, which is a common requirement in software dealing with multiple configurations or versions."
survived,"def main(config: SampleLmConfig):
    levanter.initialize(config)
    tokenizer = load_tokenizer(config.tokenizer)

    vocab_size = len(tokenizer)
    Vocab = round_axis_for_partitioning(Axis(""vocab"", vocab_size), config.trainer.compute_axis_mapping)

    key = jrandom.PRNGKey(0)

    with config.trainer.device_mesh, hax.axis_mapping(config.trainer.parameter_axis_mapping):
        model = _load_model(config, Vocab, key=key)
        assert isinstance(model, LlamaLMHeadModel), ""Only LlamaLMHeadModel supported""

        sampler = Sampler(Vocab)

        prompt_ids = tokenizer.encode(config.prompt, add_special_tokens=False)
        prompt_axis = Axis(""position"", len(prompt_ids))
        prompt_tokens = hax.NamedArray(jnp.array(prompt_ids, dtype=jnp.int32), axes=(prompt_axis,))

        page_table = PageTable.init(
            max_pages=1,
            max_seqs=1,
            page_size=len(prompt_ids) + config.max_new_tokens,
            max_pages_per_seq=1,
        )
        page_table, seq_id = page_table.assign_seq_id_to_seq()
        cache = model.initial_cache(page_table, dtype=jnp.float32)

        page_table, binfo = page_table.allocate_for_seqs(
            updated_seqs=hax.named([seq_id], ""seq""),
            new_counts=hax.named([len(prompt_ids)], ""seq""),
            tokens=hax.named([seq_id] * len(prompt_ids), prompt_axis),
        )
        state = KvPageState.from_batch(binfo, cache)
        pos_ids = hax.arange(prompt_axis, dtype=jnp.int32)
        _, state = model.decode(prompt_tokens, state, pos_ids)

        generated = list(prompt_ids)
        temps = hax.full(Axis(""batch"", 1), config.temperature, dtype=jnp.float32)

        for i in range(config.max_new_tokens):
            page_table, binfo = page_table.allocate_for_seqs(
                updated_seqs=hax.named([seq_id], ""seq""),
                new_counts=hax.named([1], ""seq""),
                tokens=hax.named([seq_id], Axis(""position"", 1)),
            )
            state = KvPageState.from_batch(binfo, state.cache)
            pos_id = hax.arange(Axis(""position"", 1), start=len(generated))
            logits, state = model.decode(
                hax.NamedArray(jnp.array([generated[-1]], dtype=jnp.int32), axes=(Axis(""position"", 1),)),
                state,
                pos_id,
            )
            logits = logits[""position"", 0]
            tok, _ = sampler(logits, temps, key=jrandom.PRNGKey(i + 1))
            next_token = int(tok.array)
            generated.append(next_token)

        text = tokenizer.decode(generated, skip_special_tokens=True)
        print(text)
",src/levanter/main/sample_lm.py,,1,6.825604231969389e-08,"The method is a complete implementation of a text generation process using a language model. It includes initialization, tokenization, model loading, and a loop for generating new tokens based on a prompt. The method is well-structured and functional, providing a clear use case for generating text with a language model. It is unlikely to be deleted as it serves a specific purpose and is a core part of the functionality for text generation."
survived,"    def text(self) -> str:
        try:
            return self.content.decode()
        except UnicodeDecodeError:
            return self.content.decode(""latin1"", errors=""replace"")
",alpha_factory_v1/af_requests.py,Response,1,2.0611536181902033e-09,"The method is likely to survive because it provides a robust way to decode byte content into a string. It first attempts to decode using the default encoding, and if a UnicodeDecodeError occurs, it falls back to decoding with 'latin1' and replaces any problematic characters. This approach ensures that the method can handle a variety of byte inputs without failing, which is a valuable feature in many applications."
survived,"    def ok(self) -> bool:
        return self.status_code < 400
",alpha_factory_v1/af_requests.py,Response,1,1.2501528648238603e-09,"The method 'ok' is a simple utility function that checks if the HTTP status code is less than 400, which is a common way to determine if a request was successful (status codes below 400 are generally considered successful). This method is useful for quickly assessing the success of an HTTP request, and such utility methods are often retained in codebases for their simplicity and utility. Therefore, it is likely to survive."
survived,"    def json(self):
        return _json.loads(self.text)
",alpha_factory_v1/af_requests.py,Response,1,2.998960815863541e-09,"The method 'json' is a simple utility function that parses a JSON string into a Python object using the '_json.loads' function. This is a common and useful operation when dealing with JSON data, especially in web development and API interactions. The method is straightforward and does not have any apparent issues or redundancies that would warrant its deletion. It is likely to be retained as it provides essential functionality for handling JSON data."
survived,"    def search(
        self,
        query: str,
        *,
        category: str | None = None,
        tags: Optional[List[str]] = None,
        limit: int = 5,
    ) -> List[TemplateMatch]:
        """"""Return templates matching the query and optional filters.""""""
        if not self._index:
            self.build_index()
        tokens = [t.lower() for t in query.split() if t]
        results: List[TemplateMatch] = []
        for item in self._index:
            meta = item.get(""metadata"", {})
            if category and meta.get(""category"") != category:
                continue
            if tags and not all(t in meta.get(""tags"", []) for t in tags):
                continue
            haystack = "" "".join(
                [
                    item.get(""content"", """"),
                    meta.get(""title"", """"),
                    meta.get(""description"", """"),
                    meta.get(""slug"", """"),
                    "" "".join(meta.get(""tags"", [])),
                ]
            ).lower()
            score = sum(1 for tok in tokens if tok in haystack)
            if score:
                preview = item.get(""content"", """")[:100].strip()
                results.append(
                    TemplateMatch(
                        slug=item[""slug""],
                        version=item[""version""],
                        score=float(score),
                        preview=preview,
                        metadata=meta,
                    )
                )
        results.sort(key=lambda r: r.score, reverse=True)
        return results[:limit]",src/meta_agent/template_search.py,TemplateSearchEngine,1,4.363462233903899e-09,"The method 'search' is well-structured and provides a useful functionality for searching templates based on a query and optional filters like category and tags. It includes a scoring mechanism to rank results, which is a common and valuable feature in search functionalities. The method also handles cases where the index might not be built yet, ensuring robustness. Given these factors, the method is likely to be retained as it provides essential functionality for template searching."
survived,"def test_search_filters(tmp_path):
    reg = TemplateRegistry(base_dir=tmp_path)
    reg.register(_meta(""foo"", TemplateCategory.CONVERSATION), ""foo content"")
    reg.register(_meta(""bar"", TemplateCategory.REASONING), ""bar content"")

    engine = TemplateSearchEngine(reg)
    res_cat = engine.search(""content"", category=TemplateCategory.CONVERSATION.value)
    assert len(res_cat) == 1 and res_cat[0].slug == ""foo""

    res_tag = engine.search(""content"", tags=[""bar""])
    assert len(res_tag) == 1 and res_tag[0].slug == ""bar""

    res_none = engine.search(""content"", tags=[""missing""])
    assert res_none == []",tests/test_template_search.py,,1,4.6911638017642294e-08,"The method 'test_search_filters' is a unit test designed to verify the functionality of a template search engine. It checks if the search engine can correctly filter templates based on category and tags. This is a crucial part of ensuring the search functionality works as expected, which is important for any application relying on template management. Since testing is a fundamental part of software development to maintain code quality and functionality, this method is likely to be retained in the codebase."
survived,"def _meta(slug: str, category: TemplateCategory) -> TemplateMetadata:
    return TemplateMetadata(
        slug=slug,
        title=slug.title(),
        description=f""Template {slug}"",
        category=category,
        complexity=TemplateComplexity.BASIC,
        tags=[slug],
    )
",tests/test_template_search.py,,1,7.194132978569833e-09,"The method '_meta' is a utility function that constructs and returns a 'TemplateMetadata' object using the provided 'slug' and 'category'. It is a straightforward and useful function for creating metadata objects, which are likely used elsewhere in the codebase. The function is well-defined, with clear parameters and a specific return type, making it a candidate for survival unless the entire metadata handling approach is refactored or deprecated."
survived,"def test_search_basic(tmp_path):
    reg = TemplateRegistry(base_dir=tmp_path)
    reg.register(_meta(""greet"", TemplateCategory.CONVERSATION), ""hello world"")
    reg.register(_meta(""calc"", TemplateCategory.REASONING), ""1 + 1"")

    engine = TemplateSearchEngine(reg)
    results = engine.search(""hello"")
    assert results
    assert results[0].slug == ""greet""
    assert ""hello"" in results[0].preview
",tests/test_template_search.py,,1,8.152020648014727e-09,"The method 'test_search_basic' is a unit test designed to verify the functionality of a template search engine. It checks if the search engine can correctly find and return a registered template based on a search query. Unit tests are crucial for ensuring code reliability and are typically maintained as long as the functionality they test is relevant. Since this test is directly tied to the core functionality of searching templates, it is likely to be retained unless the underlying system undergoes significant changes that render the test obsolete."
survived,"    def __init__(self, registry: Optional[TemplateRegistry] = None) -> None:
        self.registry = registry or TemplateRegistry()
        self._index: List[Dict[str, Any]] = []
",src/meta_agent/template_search.py,TemplateSearchEngine,1,1.1253518384332553e-07,"The method is a constructor (__init__) for a class, which is a fundamental part of class definition in Python. Constructors are essential for initializing new objects and setting up initial state, making them unlikely to be deleted unless the entire class is being refactored or removed. Additionally, the code is straightforward and follows common practices, suggesting it is functioning as intended."
survived,"def test_insight_helm_template_renders_env_vars() -> None:
    result = subprocess.run(
        [""helm"", ""template"", ""insight"", str(CHART_DIR), ""-f"", str(VALUES_FILE)],
        check=True,
        cwd=CHART_DIR,
        capture_output=True,
        text=True,
    )
    rendered = result.stdout
    assert ""OPENAI_API_KEY"" in rendered
    assert ""AGI_INSIGHT_OFFLINE"" in rendered
    assert ""AGI_INSIGHT_BUS_PORT"" in rendered
    assert ""AGI_INSIGHT_LEDGER_PATH"" in rendered",tests/test_insight_helm_template.py,,1,4.944450477491054e-09,"The method `test_insight_helm_template_renders_env_vars` is a test function that verifies if certain environment variables are rendered correctly in a Helm template. This is a common requirement in DevOps and CI/CD pipelines to ensure that configurations are correctly applied. The function uses subprocess to run a Helm command and checks the output for specific environment variables, which is a typical pattern for testing infrastructure as code. Since testing infrastructure configurations is crucial for maintaining reliable deployments, this method is likely to be retained."
survived,"    def _target(q: _mp.Queue) -> None:
        _apply_limits()
        try:
            proc = subprocess.Popen(
                [sys.executable, script],
                stdin=subprocess.PIPE,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
            )
            try:
                out, err = proc.communicate(inp_json, timeout=SOFT_T)
            except subprocess.TimeoutExpired:
                proc.kill()
                out, err = proc.communicate()
            q.put((out, err))
        except Exception as exc:  # pragma: no cover
            q.put(("""", str(exc)))
",alpha_factory_v1/demos/meta_agentic_agi_v3/curriculum/azr_engine.py,,1,2.0611536181902033e-09,"The method '_target' is a private helper function that is likely used internally within a module to handle subprocess execution with a timeout and error handling. It is designed to run a script in a separate process, capture its output, and handle timeouts and exceptions. This functionality is essential for robust process management, especially in applications that need to execute external scripts or commands. The use of a queue to return results is a common pattern in concurrent programming. Given its utility and the fact that it is a private method (indicated by the underscore prefix), it is unlikely to be deleted unless the entire module or its approach to subprocess management is refactored. Therefore, the method will likely survive."
survived,"    def solve(self, tasks: Sequence[Triplet]) -> List[TaskResult]:
        results: List[TaskResult] = []
        for t in tasks:
            start = time.time()
            stdout, stderr = _exec_trusted(t.program, t.inp)
            lat = time.time() - start
            solved = stderr == """" and stdout.strip() == t.out.strip()
            complexity = _complexity(t.program)
            results.append(TaskResult(t, solved, lat, stdout, stderr, complexity))
        return results
",alpha_factory_v1/demos/meta_agentic_agi_v3/curriculum/azr_engine.py,AZREngine,1,5.905303995456778e-10,"The method 'solve' is likely to survive because it appears to be a well-structured and functional piece of code that performs a specific task: executing a sequence of tasks and collecting results. It handles execution timing, output comparison, and complexity analysis, which are common requirements in task execution systems. Additionally, it uses type annotations, which improve code readability and maintainability. Unless there are changes in requirements or a significant refactor of the system, this method is likely to remain useful."
survived,"    def start(self, bus: messaging.A2ABus, ledger: Ledger) -> None:
        self.task = asyncio.create_task(self.loop(bus, ledger))
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/orchestrator.py,AgentRunner,1,1.0467401685178159e-08,"The method 'start' is a common pattern for initializing or starting asynchronous tasks in Python, especially when using asyncio. The method is straightforward, creating an asyncio task that runs a loop with the provided bus and ledger parameters. There is no indication of deprecated practices or inefficiencies in this snippet. Therefore, it is likely to be retained in the codebase."
survived,"            def abort(self, *_a, **_kw):
                raise RuntimeError(""denied"")
",tests/test_insight_orchestrator_features.py,TestMessaging.Ctx,1,2.8453347280241004e-08,"The method 'abort' is a simple utility function that raises a RuntimeError with a specific message. Such methods are often used for error handling or to intentionally stop execution under certain conditions. The method is straightforward, does not have any apparent issues, and serves a clear purpose. Therefore, it is likely to be retained in the codebase unless the overall design or error handling strategy changes significantly."
survived,"    def setUp(self) -> None:
        self.tmp = tempfile.TemporaryDirectory()
        self.settings = config.Settings(bus_port=0, ledger_path=os.path.join(self.tmp.name, ""ledger.db""))
        self.orch = orchestrator.Orchestrator(self.settings)
",tests/test_insight_orchestrator_features.py,TestInsightOrchestrator,1,1.553497314502234e-06,"The method 'setUp' is a common setup method used in testing frameworks like unittest in Python. It is typically used to initialize the test environment before each test case is run. The method creates a temporary directory and sets up necessary configurations for the orchestrator. This is a standard practice in test setups to ensure isolation and cleanliness of test environments. Since this is a crucial part of the testing process, it is unlikely to be deleted unless the entire testing framework or approach is changed."
survived,"    def baz(x: Float[""b""]):  # type: ignore  # noqa: F722
        pass
",tests/test_dtype_typing.py,,0,0.9999810748526188,"The method 'baz' is defined with a type hint that uses a non-standard annotation 'Float[""b""]'. This is not a valid type hint in Python, as Python's type hinting system does not support such syntax. The 'type: ignore' comment is used to suppress type checking errors, and 'noqa: F722' is used to ignore specific linting errors. However, the method itself does not perform any operations and is essentially a placeholder. Without any functionality or valid type annotations, this method is likely to be deleted unless it is intended to be implemented later or serves a specific purpose in the codebase."
survived,"def run_demo(args):
    corpus = load_documents(args.data_dir)
    vocab, index = build_vocab(corpus)
    int_corpus = convert_corpus(corpus, index)

    hlda = HierarchicalLDA(
        int_corpus,
        vocab,
        alpha=args.alpha,
        gamma=args.gamma,
        eta=args.eta,
        num_levels=args.num_levels,
        seed=args.seed,
    )

    hlda.estimate(
        args.iterations,
        display_topics=args.display_topics,
        n_words=args.n_words,
        with_weights=False,
    )

    print(""\nFinal topic hierarchy:"")
    hlda.print_nodes(args.n_words, with_weights=False)

    return hlda
",scripts/bbc_demo.py,,1,4.944450477491054e-09,"The method `run_demo` is a complete and functional piece of code that demonstrates the process of running a Hierarchical LDA (hLDA) model on a given corpus. It includes loading documents, building a vocabulary, converting the corpus into an integer format, initializing the hLDA model, estimating the model, and printing the final topic hierarchy. This method is likely to be useful for users who want to understand or demonstrate the capabilities of hLDA, making it a valuable part of a codebase that deals with topic modeling. Therefore, it is unlikely to be deleted."
survived,"def _to_mochi(v: Any) -> str:
    if v is None:
        return ""null""
    if isinstance(v, bool):
        return ""true"" if v else ""false""
    if isinstance(v, (int, float)):
        return str(v)
    if isinstance(v, str):
        return ""\"""" + v.replace(""\\"", ""\\\\"").replace(""\"""", ""\\\"""") + ""\""""
    if isinstance(v, Sequence) and not isinstance(v, (str, bytes, bytearray)):
        return ""["" + "", "".join(_to_mochi(x) for x in v) + ""]""
    if isinstance(v, dict):
        items = "", "".join(f'{_to_mochi(k)}: {_to_mochi(val)}' for k, val in v.items())
        return ""{"" + items + ""}""
    raise TypeError(f""unsupported value type: {type(v).__name__}"")",tools/libmochi/python/libmochi.py,,1,5.60279640614594e-09,"The method `_to_mochi` is a utility function that converts various Python data types into a specific string format. It handles `None`, `bool`, `int`, `float`, `str`, `Sequence`, and `dict` types, providing a comprehensive conversion mechanism. This kind of function is useful for serialization or data transformation tasks, which are common in many applications. The function is well-structured, covers a wide range of data types, and includes error handling for unsupported types. These characteristics make it a valuable and reusable piece of code, suggesting it is likely to be retained."
survived,"def run(code: str, mochi_bin: str = ""mochi"") -> str:
    """"""Execute Mochi source code and return its standard output.""""""
    return _run(code, mochi_bin)
",tools/libmochi/python/libmochi.py,,1,2.646573631904765e-09,"The method 'run' is a simple wrapper around the '_run' function, providing a default value for the 'mochi_bin' parameter. This method is likely to be useful for users who want to execute Mochi source code without worrying about specifying the binary path every time. It enhances usability and convenience, which are important factors for code survival. Unless there are changes in the underlying '_run' function or the way Mochi code execution is handled, this method is likely to survive."
survived,"    def fake_download(url: str, dest: Path) -> None:
        dest.parent.mkdir(parents=True, exist_ok=True)
        dest.write_text(""ok"")
        calls.append((url, dest))
",tests/test_download_hf_gpt2.py,,1,1.3440409770490404e-08,"The method 'fake_download' is a mock function used for testing purposes. It simulates downloading a file by creating the necessary directory structure and writing a simple text to the destination file. This kind of function is often used in unit tests to avoid actual network calls and file operations, making tests faster and more reliable. Since it serves a specific purpose in testing, it is likely to be retained in the codebase as long as there are tests that require simulating downloads. Therefore, the method will likely survive."
survived,"def parse_requirements(path: Path) -> list[str]:
    """"""Parse a requirements file, resolving ``-r`` inclusions.""""""
    requirements: list[str] = []
    for line in path.read_text().splitlines():
        line = line.strip()
        if not line or line.startswith(""#""):
            continue
        if line.startswith(""-r ""):
            nested = (path.parent / line.split(maxsplit=1)[1]).resolve()
            requirements.extend(parse_requirements(nested))
        else:
            requirements.append(line)
    return requirements
",pioreactor/tests/test_requirements_sync.py,,1,2.646573631904765e-09,"The method 'parse_requirements' is a utility function designed to parse a requirements file, which is a common task in Python projects for managing dependencies. It handles comments, empty lines, and nested requirements files, making it a comprehensive solution for this task. Such functionality is essential for many Python projects, especially those using virtual environments or dependency management tools. Therefore, it is likely to be retained in the codebase."
survived,"def test_llama_paged_decode_ragged_fill_in_chunks():
    B = Axis(""batch"", 2)
    Pos = Axis(""position"", 8)
    Embed = Axis(""embed"", 8)
    Vocab = Axis(""vocab"", 64)

    cfg = LlamaConfig(
        seq_len=Pos.size,
        hidden_dim=Embed.size,
        intermediate_dim=16,
        num_layers=2,
        num_heads=2,
        num_kv_heads=2,
        rope=None,
        gradient_checkpointing=False,
        scan_layers=True,
        attn_backend=AttentionBackend.VANILLA,
    )

    model_key, input_key = jrandom.split(jrandom.PRNGKey(0))
    model = LlamaLMHeadModel.init(Vocab=Vocab, config=cfg, key=model_key)

    input_ids = hax.random.randint(input_key, (B, Pos), 0, Vocab.size)
    full_out = model.activations(input_ids, attn_mask=AttentionMask.causal(), key=jrandom.PRNGKey(1))

    pt = PageTable.init(max_pages=8, max_seqs=2, page_size=4, max_pages_per_seq=4)
    pt, seq1 = pt.assign_seq_id_to_seq()
    pt, seq2 = pt.assign_seq_id_to_seq()
    layer_caches = model.transformer.initial_cache(pt, dtype=jnp.float32)

    x = model.embeddings.embed(input_ids)
    x0 = x[B, 0]
    x1 = x[B, 1]

    chunk_sizes = [[4, 2], [0, 1], [0, 1], [2, 1], [1, 2], [1, 1]]
    off0 = off1 = 0
    outputs0 = []
    outputs1 = []

    seq_axis = Axis(""seq"", 2)
    for step0, step1 in chunk_sizes:
        tok_axis = Axis(""position"", step0 + step1)
        updated = hax.named([seq1, seq2], seq_axis)
        new_counts = hax.named([step0, step1], seq_axis)
        tokens = hax.named([seq1] * step0 + [seq2] * step1, tok_axis)
        pt, binfo = pt.allocate_for_seqs(updated, new_counts, tokens)
        state = KvPageState.from_batch(binfo, layer_caches)

        x_chunk = hax.concatenate(
            ""position"",
            [x0[Pos, hax.dslice(off0, step0)], x1[Pos, hax.dslice(off1, step1)]],
        )
        pos_ids = hax.named(list(range(off0, off0 + step0)) + list(range(off1, off1 + step1)), tok_axis)
        with jax.disable_jit():
            output, state = _jit_paged_decode(model.transformer, x_chunk, pos_ids, state)
        layer_caches = state.cache
        outputs0.append(output[""position"", hax.dslice(0, step0)])
        outputs1.append(output[""position"", hax.dslice(step0, step1)])

        assert_trees_all_close(
            full_out[B, 0, ""position"", hax.dslice(off0, step0)].array,
            outputs0[-1].array,
            atol=1e-4,
            rtol=1e-4,
        )
        assert_trees_all_close(
            full_out[B, 1, ""position"", hax.dslice(off1, step1)].array,
            outputs1[-1].array,
            atol=1e-4,
            rtol=1e-4,
        )

        off0 += step0
        off1 += step1

    outputs0_cat = hax.concatenate(""position"", outputs0)
    outputs1_cat = hax.concatenate(""position"", outputs1)
    decoded_arr = hax.stack(""batch"", [outputs0_cat, outputs1_cat])
    assert_trees_all_close(full_out.array, decoded_arr.array, atol=1e-4, rtol=1e-4)",tests/test_llama_decode.py,,1,1.637377179507321e-07,"The method `test_llama_paged_decode_ragged_fill_in_chunks` is a test function, which is typically used to verify the correctness of a specific functionality in the code. Test functions are generally not deleted unless the functionality they are testing is removed or significantly changed. Since this function is testing a specific aspect of the Llama model's decoding process, it is likely to be retained as long as the model and its decoding process remain relevant in the codebase."
survived,"        def __init__(self) -> None:
            self.spans: list[str] = []
",tests/test_metrics.py,DummyTracer,1,1.725782769012759e-08,"The method is a constructor for a class, initializing an instance variable 'spans' as an empty list of strings. This is a common and necessary practice in object-oriented programming to set up initial state for an object. There is no indication that this method is redundant or incorrect, so it is likely to be retained."
survived,"def test_metrics_endpoint_subprocess() -> None:
    port = _free_port()
    proc = _start_server(port)
    url = f""http://127.0.0.1:{port}""
    try:
        _wait_ready(url)
        resp = httpx.get(f""{url}/metrics"")
        assert resp.status_code == 200
        text = resp.text
        assert ""api_requests_total"" in text
        assert ""api_request_duration_seconds"" in text
        assert text.startswith(""# HELP"")
    finally:
        proc.terminate()
        proc.wait(timeout=5)
",tests/test_metrics.py,,1,3.850741907939403e-09,"The method `test_metrics_endpoint_subprocess` is a test function that verifies the functionality of a metrics endpoint. It uses a subprocess to start a server, checks the server's readiness, and then makes an HTTP GET request to the `/metrics` endpoint. The function asserts that the response status is 200 and that certain expected metrics are present in the response text. Finally, it ensures that the subprocess is terminated properly. This method is likely to be retained because it serves a clear purpose in testing the metrics endpoint, ensuring that the server is correctly exposing metrics, which is crucial for monitoring and observability in production systems."
survived,"        def set_meter_provider(self, _provider: Any) -> None:  # noqa: D401 - simple stub
            pass
",tests/test_metrics.py,DummyMetrics,1,1.637377179507321e-07,"The method `set_meter_provider` is a simple stub with no implementation, indicated by the `pass` statement. It is also marked with a `# noqa: D401` comment, suggesting that it is intentionally left as a stub, possibly for future implementation or to satisfy an interface requirement. Such methods are often placeholders and may be retained for future development or to maintain compatibility with an interface. Therefore, it is likely to survive."
survived,"async def test_input_guardrail_exception_propagates():
    adapter = MockAdapter()
    router = GuardrailModelRouter({""a"": adapter}, default_model=""a"")

    async def bad_guard(_prompt: str):
        raise RuntimeError(""bad"")

    router.add_input_guardrail(bad_guard)

    with pytest.raises(RuntimeError):
        await router.invoke(""x"")
    assert not adapter.prompts
",tests/test_guardrail_router.py,,1,6.69158608681505e-10,"The method `test_input_guardrail_exception_propagates` is a test function that checks if an exception raised by an input guardrail is properly propagated. It uses a mock adapter and a router to simulate the behavior. The test is straightforward and serves a clear purpose in ensuring the robustness of the input guardrail mechanism. Such test functions are typically retained as they are crucial for maintaining code quality and reliability by verifying that exceptions are handled as expected. Therefore, the method is likely to be Survived."
survived,"    async def run_cycle(self) -> None:
        if self.first:
            self.first = False
            raise RuntimeError(""boom"")
        await asyncio.sleep(0)
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_orchestrator.py,BoomAgent,0,0.999999694097641,"The method 'run_cycle' is likely to be deleted because it contains a logic that raises a RuntimeError on its first execution, which seems to be a placeholder or a debugging mechanism rather than a functional part of the code. Additionally, the method does not perform any meaningful operation after the exception is raised, making it redundant in its current form."
survived,"        def close(self) -> None:
            pass
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_orchestrator.py,DummyLedger,0,0.9999251538028718,"The method 'close' is defined but not implemented, as it only contains a 'pass' statement. This suggests that the method is a placeholder for future implementation or is meant to be overridden in a subclass. If the class is intended to be abstract or part of a framework where subclasses are expected to provide specific behavior, the method might survive. However, if this is a concrete class and the method is never implemented or used, it might be deleted. Without additional context, it's more likely to be deleted if it remains unused."
survived,"def test_publish_to_async_subscriber() -> None:
    """"""Envelopes published to a subscribed coroutine should be delivered.""""""
    bus = messaging.A2ABus(config.Settings(bus_port=0))
    received: list[messaging.Envelope] = []

    async def handler(env: messaging.Envelope) -> None:
        received.append(env)

    bus.subscribe(""x"", handler)
    env = messaging.Envelope(""a"", ""x"", {""v"": 42}, 0.0)

    async def run() -> None:
        bus.publish(""x"", env)
        await asyncio.sleep(0)  # allow handler task to run

    asyncio.run(run())
    assert len(received) == 1
    assert received[0].payload[""v""] == 42",tests/test_messaging.py,,1,1.1861120010657661e-08,"The method is a test function that verifies the functionality of publishing messages to an asynchronous subscriber. It is well-structured, uses asyncio for asynchronous operations, and includes assertions to validate the expected behavior. Such test functions are crucial for ensuring the reliability of messaging systems, and there is no indication of it being obsolete or redundant. Therefore, it is likely to be retained."
survived,"    async def run() -> None:
        bus.publish(""x"", env)
        await asyncio.sleep(0)  # allow handler task to run
",tests/test_messaging.py,,1,1.955568070542584e-08,"The method 'run' is an asynchronous function that publishes a message to a bus and then immediately yields control back to the event loop with 'await asyncio.sleep(0)'. This pattern is often used to ensure that other tasks in the event loop have a chance to run, which can be important in concurrent programming. The method is simple, non-blocking, and follows a common pattern in asynchronous programming, making it likely to be useful in contexts where message publishing and task scheduling are needed. Therefore, it is likely to be retained."
survived,"    async def run_cycle(self) -> None:
        await asyncio.sleep(999)
",tests/test_agents.py,FreezeAgent,0,0.9999999865595903,"The method 'run_cycle' is an asynchronous function that only contains a single line of code: 'await asyncio.sleep(999)'. This line causes the function to pause for 999 seconds, which is a very long time for a sleep operation. The method does not perform any meaningful operation or computation, nor does it interact with any other part of a system or application. Without additional context or functionality, this method is not useful and is likely to be considered dead code. Therefore, it is likely to be deleted in future iterations of the codebase."
survived,"        def __init__(self) -> None:  # noqa: D401 - simple stub
            for name, default in self.__class__.__dict__.items():
                if name.startswith(""_"") or name == ""Config"" or callable(default):
                    continue
                value = os.getenv(name, default)
                if isinstance(default, bool):
                    value = str(value).lower() in {""1"", ""true"", ""yes"", ""on""}
                elif isinstance(default, int) and default is not None:
                    try:
                        value = int(value)
                    except Exception:
                        value = default
                self.__dict__[name] = value
",alpha_factory_v1/backend/memory_fabric.py,BaseSettings,1,1.955568070542584e-08,"The method is a constructor (__init__) which is essential for initializing instances of a class. It contains logic to set instance variables based on environment variables or default values, which is a common pattern for configuration management. This functionality is crucial for the class to operate correctly, especially in environments where configuration might change based on deployment settings. Therefore, it is unlikely to be deleted."
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/q1.py,Lineitem,1,4.363462233903899e-09,"The method `__repr__` is a special method in Python used to define a string representation of an object. The implementation provided returns the string representation of the object's dictionary, which is a common and useful way to provide a detailed view of the object's attributes for debugging purposes. This implementation is straightforward and serves a clear purpose, making it likely to be retained in the code."
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/q2.py,Nation,1,4.944450477491054e-09,"The method `__repr__` is a special method in Python used to define a string representation of an object. The implementation provided returns the string representation of the object's dictionary, which is a common and useful way to implement `__repr__` for debugging purposes. This allows developers to easily see the attributes and their values for an instance of the class. Since this implementation is straightforward, useful, and follows a common pattern, it is likely to be retained in the code."
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/machine/x/python/q3.py,_Group,1,2.646573631904765e-09,"The method is a standard implementation of the __iter__ method in Python, which allows an object to be iterable. This is a common and necessary feature for many classes that manage collections of items, as it enables the use of the object in loops and other iterable contexts. There is no indication that this method is redundant or unnecessary, so it is likely to be retained."
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/q2.py,Part,1,2.8453347280241004e-08,"The method `__repr__` is a special method in Python used to define a string representation of an object. The implementation provided here returns the string representation of the object's dictionary, which is a common and useful way to represent an object for debugging purposes. This method is likely to be retained because it provides a clear and concise way to inspect the internal state of an object, which is valuable for developers during debugging and logging."
survived,"def test_multi_env_reporting(monkeypatch: pytest.MonkeyPatch) -> None:
    """"""Aggregated metrics should reflect all environments.""""""
    monkeypatch.setenv(""NO_LLM"", ""1"")
    monkeypatch.setenv(""ALPHA_ASI_MAX_STEPS"", ""1"")
    monkeypatch.setenv(""ALPHA_ASI_UI_TICK"", ""1"")
    monkeypatch.setenv(""ALPHA_ASI_ENV_BATCH"", ""2"")

    mod = importlib.import_module(
        ""alpha_factory_v1.demos.alpha_asi_world_model.alpha_asi_world_model_demo""
    )

    class DummyEnv:
        def __init__(self, reward: float) -> None:
            self.reward = reward

        def reset(self):
            return None

        def step(self, _a: int):
            return None, self.reward, True, {}

    class DummyLearner:
        def __init__(self, loss: float) -> None:
            self.loss = loss

        def act(self, _obs):
            return 0

        def remember(self, _obs, _reward) -> None:
            pass

        def train_once(self) -> float:
            return self.loss

    mod.A2ABus._subs = {}
    orch = mod.Orchestrator()
    orch.envs = [DummyEnv(1.0), DummyEnv(0.0)]
    orch.learners = [DummyLearner(0.2), DummyLearner(0.4)]

    msgs: list[dict] = []
    mod.A2ABus.subscribe(""ui"", lambda m: msgs.append(m))

    orch.loop()

    assert msgs
    msg = msgs[-1]
    assert msg[""t""] == 0
    assert msg[""r""] == pytest.approx(0.5)
    assert msg[""loss""] == pytest.approx(0.3)",tests/test_world_model_demo.py,,1,6.825604231969389e-08,"The method `test_multi_env_reporting` is a unit test function that uses the `monkeypatch` fixture from pytest to set environment variables and test the behavior of a module. It is a well-structured test that verifies the aggregation of metrics across multiple environments and learners. Such test functions are crucial for ensuring the correctness of code, especially in complex systems. Therefore, it is unlikely to be deleted as it serves an important role in maintaining code quality."
survived,"    def test_to_csv_sort_by_duration(self):
        """"""Ensure sorting by dataclass field like 'duration' works.""""""
        input = dedent_strip(""""""
            Activity;Predecessor;Duration
            A;-;2
            B;-;5
            C;-;3
        """""")

        project_schedule = ProjectSchedule.create(parse_schedule_input_data(input))
        csv_output = project_schedule.to_csv(sort_by=""duration"")
        durations = [line.split("";"")[1] for line in csv_output.splitlines()[1:]]
        self.assertEqual(durations, [""2"", ""3"", ""5""])
",src/schedule/tests/test_schedule.py,TestSchedule,1,7.582560422162384e-10,"The method 'test_to_csv_sort_by_duration' is a unit test designed to verify the functionality of sorting by the 'duration' field in a CSV output. This is a common and useful feature in data processing and testing its correctness is important to ensure the reliability of the 'to_csv' method. The test is well-structured, using a clear input and checking the output against expected results. There is no indication that this functionality is obsolete or unnecessary, so the method is likely to be retained."
survived,"def test_pack_empty_tree():
    tree = {}
    offsets, packed = pack_pytree(tree, dtype=jnp.float32)
    assert packed.size == 0
    rebuilt = unpack_pytree(offsets, packed)
    assert rebuilt == tree",tests/test_pack_tree.py,,1,6.348800075736417e-09,"The method 'test_pack_empty_tree' is a unit test designed to verify the behavior of the 'pack_pytree' and 'unpack_pytree' functions when given an empty tree as input. Unit tests are crucial for ensuring code reliability and correctness, especially in complex systems. This test checks that packing an empty tree results in a packed object of size 0 and that unpacking it returns the original empty tree. Such tests are typically retained to maintain code quality and prevent regressions, so it is likely to survive."
survived,"def test_cli_transfer_test_invokes(monkeypatch) -> None:
    called = {}

    def fake_run(models, top_n):
        called[""models""] = models
        called[""top_n""] = top_n

    monkeypatch.setattr(tt, ""run_transfer_test"", fake_run)

    res = CliRunner().invoke(cli.main, [""transfer-test"", ""--models"", ""x,y"", ""--top-n"", ""2""])
    assert res.exit_code == 0
    assert called == {""models"": [""x"", ""y""], ""top_n"": 2}",tests/test_transfer_test.py,,1,2.3355930333443423e-09,"The method 'test_cli_transfer_test_invokes' is a unit test function that uses the 'monkeypatch' fixture to replace the 'run_transfer_test' function with a fake implementation. This is a common practice in testing to isolate the function being tested and ensure it behaves correctly when invoked. The test checks that the CLI command 'transfer-test' is called with the correct arguments and that the 'run_transfer_test' function is invoked with the expected parameters. This is a valid and useful test for ensuring the CLI behaves as expected, and there is no indication that it should be deleted."
survived,"def run() -> None:
    parts = [""poly"", ""task"", ""13""]
    joined = ""-"".join(parts)
    assert joined.split(""-"")[2] == str(13)",benchmarks/poly_mini/task_013.py,,1,3.2241866333029355e-08,"The method 'run' is a simple function that joins a list of strings with a hyphen and then splits the resulting string to assert that the third element is '13'. This is a basic operation that demonstrates string manipulation and is likely used for educational or testing purposes. It doesn't have any apparent issues or redundancies that would necessitate its deletion. Therefore, it is likely to be retained in the codebase."
survived,"def is_code_safe(code: str) -> bool:
    """"""Return ``True`` if ``code`` appears safe.""""""
    lowered = code.lower()
    for pat in _DENY_PATTERNS:
        if re.search(pat, lowered):
            return False

    try:
        tree = ast.parse(code)
    except SyntaxError:
        return False

    for node in ast.walk(tree):
        if isinstance(node, ast.Call):
            name = _full_name(node.func)
            if name in _BANNED_CALLS:
                return False
            if name == ""open"" and node.args:
                arg = node.args[0]
                if isinstance(arg, ast.Constant) and isinstance(arg.value, str):
                    if arg.value.startswith(""/etc""):
                        return False
    return True
",src/self_edit/safety.py,,1,1.2501528648238603e-09,"The method 'is_code_safe' is a utility function that checks if a given code string is safe by analyzing its syntax tree and looking for patterns or function calls that are considered unsafe. This kind of functionality is crucial in environments where code execution security is a concern, such as in code editors, online compilers, or any system that executes user-provided code. The method is well-structured, uses standard libraries like 're' and 'ast', and implements a clear logic to determine code safety. Given its utility and the fact that it addresses a common security need, it is likely to be retained."
survived,"def _read(name: str) -> str:
    return (FIXTURES / name).read_text()
",tests/test_safety_filter.py,,1,1.1032560311263802e-09,"The method _read is a simple utility function that reads the content of a file given its name. It uses the pathlib library to construct the file path and read the text content. This is a common and useful operation in many applications, especially those dealing with file I/O. The method is concise, clear, and leverages Python's standard library effectively. There is no indication that this method is redundant or unnecessary, and it serves a clear purpose in the context of file handling. Therefore, it is likely to be retained in the codebase."
survived,"    def resume(self) -> None:
        """"""Resume execution after a pause.""""""
        self.paused_at = None
        self.next_ts = 0
",alpha_factory_v1/backend/agent_runner.py,AgentRunner,1,2.646573631904765e-09,"The method 'resume' is a simple utility function that resets the state of an object by setting 'paused_at' to None and 'next_ts' to 0. This kind of method is often useful in scenarios where an object can be paused and resumed, such as in a game, a simulation, or a process that can be temporarily halted. The method is straightforward and serves a clear purpose, making it likely to be retained in the codebase."
survived,"def get_default_tools() -> List[Any]:
    """"""Return the hardened default tool-chain.

    The selection is recalculated each time to honour environment variables
    that may change at runtime.  The returned list is safe to mutate.
    """"""
    base: List[Any] = [
        FileSearchTool(max_num_results=5),
        WebSearchTool(),
        run_pytest,
    ]

    # Remote tools (ComputerTool runs in OpenAI's sandbox) need an API key.
    if SDK_AVAILABLE and os.getenv(""OPENAI_API_KEY""):
        base.append(ComputerTool())

    # PythonTool executes *locally*  only enable if user opts in explicitly.
    if SDK_AVAILABLE and os.getenv(""ALPHAFAC_ALLOW_LOCAL_CODE"") == ""1"":
        base.append(PythonTool())

    return base
",alpha_factory_v1/backend/agent_factory.py,,1,1.2501528648238603e-09,"The method `get_default_tools` is designed to dynamically generate a list of tools based on the current environment variables and the availability of certain SDKs. This flexibility is crucial for adapting to different runtime conditions, such as the presence of API keys or user preferences for local code execution. The method is well-documented, indicating its purpose and the conditions under which different tools are included. This adaptability and clarity in purpose suggest that the method is useful and likely to be retained in the codebase."
survived,"    def test_bollinger_bands(self):
        prices = [1, 2, 3, 4, 5]
        lower, upper = am.bollinger_bands(prices, window=4, num_std=1)
        self.assertLess(lower, upper)
",alpha_factory_v1/tests/test_alpha_model.py,AlphaModelTest,1,2.2159489282323004e-08,"The method `test_bollinger_bands` is a unit test for the `bollinger_bands` function, which is likely part of a financial analysis library. Unit tests are crucial for ensuring the correctness of code, especially in financial applications where accuracy is critical. The test checks that the lower band is less than the upper band, which is a fundamental property of Bollinger Bands. This is a valid and necessary test to ensure the function behaves as expected. Therefore, it is unlikely to be deleted."
survived,"def serve() -> None:
    """"""Run the RPC server with `uvicorn`.""""""

    uvicorn.run(""backend.rpc_server:app"", host=RPC_HOST, port=RPC_PORT)
",alpha_factory_v1/backend/rpc_server.py,,1,8.592166611791576e-10,"The method 'serve' is a simple utility function that starts an RPC server using 'uvicorn'. It is likely to be a crucial part of the application's infrastructure, especially if the application relies on RPC for communication. Such methods are typically essential for the operation of the server and are not removed unless there is a significant change in the architecture or technology stack. Therefore, it is likely to survive."
survived,"    def reset(self) -> float:
        """"""Reset the environment and return the starting price.""""""
        self.price = self.start_price
        return self.price
",alpha_factory_v1/backend/environments/market_sim.py,MarketEnv,1,8.592166611791576e-10,"The method 'reset' is a simple and clear implementation that resets an environment to its initial state by setting the price to a starting value and returning it. This is a common pattern in environments, especially in simulations or games, where resetting to a known state is necessary for consistency and repeatability. The method is likely to be useful in contexts where the environment needs to be restarted, such as in testing or iterative processes. Therefore, it is likely to survive."
survived,"    def __init__(self, resp: str):
        self.resp = resp
",alpha_factory_v1/tests/test_planner_agent.py,DummyModel,1,1.1253518384332553e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming in Python. Constructors are essential for initializing new objects with specific attributes. The presence of a constructor is crucial for the proper functioning of a class, especially if it needs to initialize instance variables. Therefore, it is unlikely that this method will be deleted."
survived,"            def handle(self, _msg):  # noqa
                LOG.debug(""[Stub:%s]  %s"", cls_name, _msg)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,Stub,1,3.2241866333029355e-08,"The method 'handle' is a simple logging function that logs a message with a specific format. It uses the 'LOG.debug' method to log the message, which is a common practice in software development for debugging purposes. The method is likely to be useful for tracking the flow of messages or events in the application, especially during development or troubleshooting. Since logging is a fundamental part of maintaining and debugging software, this method is likely to be retained in the codebase."
survived,"    def __init__(self, name: str):
        self.name = name
        A2ABus.subscribe(name, self._on)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,Agent,1,1.637377179507321e-07,"The method is a constructor (__init__) which is essential for initializing instances of a class. Constructors are fundamental to object-oriented programming and are unlikely to be deleted unless the class itself is being removed or significantly refactored. Additionally, the method includes a subscription to an event or message bus, indicating it plays a role in the class's functionality. Therefore, it is more likely to be retained."
survived,"    def _password_for_db(self, password: str) -> str:
        """"""Return the password value to store in the local DB.""""""
        return password
",app/services/media/jellyfin.py,JellyfinClient,0,0.9999945777819207,"The method '_password_for_db' is a simple utility function that returns the password as is, without any transformation or encryption. In a real-world application, storing passwords in plain text is a significant security risk. Best practices dictate that passwords should be hashed and salted before being stored in a database to protect against unauthorized access. Given the importance of security in software development, this method is likely to be deleted or significantly modified to incorporate proper password handling techniques."
survived,"def test_guard_added_to_route_dependencies():
    router = GuardController.get_router()
    route = router.routes[0]
    deps = route.dependencies
    assert len(deps) == 1
    assert isinstance(deps[0].dependency, SimpleGuard)",tests/test_core/test_decorators/test_guard.py,,1,2.5109990926928157e-08,"The method `test_guard_added_to_route_dependencies` is a unit test that checks if a guard is correctly added to the route dependencies. It verifies that the first route in the router has exactly one dependency and that this dependency is an instance of `SimpleGuard`. This is a typical test case to ensure that the routing logic is functioning as expected, particularly in frameworks that use dependency injection or middleware patterns. Such tests are crucial for maintaining the integrity of the codebase as they help catch regressions and ensure that new changes do not break existing functionality. Therefore, this method is likely to be retained as part of the test suite."
survived,"def test_patcher_core_cli(tmp_path: Path, monkeypatch: pytest.MonkeyPatch) -> None:
    repo = tmp_path / ""repo""
    tests_dir = repo / ""tests""
    tests_dir.mkdir(parents=True)

    # buggy source file
    (repo / ""calc.py"").write_text(""def add(a, b):\n    return a - b\n"", encoding=""utf-8"")

    # failing test
    (tests_dir / ""test_calc.py"").write_text(
        ""from calc import add\n\ndef test_add():\n    assert add(1, 2) == 3\n"",
        encoding=""utf-8"",
    )

    # patch to fix the bug
    patch_file = tmp_path / ""fix.diff""
    patch_file.write_text(
        """"""--- a/calc.py
+++ b/calc.py
@@ -1,2 +1,2 @@
 def add(a, b):
-    return a - b
+    return a + b
\ No newline at end of file
"""""",
        encoding=""utf-8"",
    )

    import openai_agents

    class StubAgent:
        def __init__(self, *a, **k):
            self.patch_file = os.environ.get(""PATCH_FILE"")

        def __call__(self, _prompt: str) -> str:
            return Path(self.patch_file).read_text() if self.patch_file else """"

    monkeypatch.setattr(openai_agents, ""OpenAIAgent"", StubAgent)

    env = os.environ.copy()
    env[""PATCH_FILE""] = str(patch_file)

    result = subprocess.run(
        [
            sys.executable,
            ""-m"",
            ""alpha_factory_v1.demos.self_healing_repo.patcher_core"",
            ""--repo"",
            str(repo),
        ],
        capture_output=True,
        text=True,
        env=env,
    )

    assert result.returncode == 0, result.stdout + result.stderr
    combined = result.stdout + result.stderr
    assert ""Patch fixed the tests"" in combined",tests/test_patcher_core_cli.py,,1,2.5109990926928157e-08,"The method 'test_patcher_core_cli' is a test function that verifies the functionality of a patching system. It sets up a temporary repository with a buggy source file and a failing test, applies a patch to fix the bug, and checks if the patch successfully fixes the tests. This is a typical use case for testing a self-healing or patching system, which is a valuable feature in software development. The method is well-structured, uses standard testing practices, and is likely to be useful for ensuring the reliability of the patching system. Therefore, it is likely to be retained in the codebase."
survived,"def test_offline_pwa_and_share() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri()

    with sync_playwright() as p:
        browser = p.chromium.launch()
        context = browser.new_context()
        page = context.new_page()

        page.goto(url)
        page.wait_for_selector(""#controls"")

        # Service worker should be ready
        page.wait_for_function(""navigator.serviceWorker && navigator.serviceWorker.controller || navigator.serviceWorker.ready"")

        # Go offline and reload
        context.route(""**"", lambda route: route.abort())
        page.reload()
        page.wait_for_selector(""#controls"")

        # Stub Web3Storage to avoid network
        page.evaluate(
            f""window.PINNER_TOKEN='tok'; window.Web3Storage = class {{ async put() {{ return '{CID}'; }} }}""
        )

        page.click(""text=Share"")
        page.wait_for_selector(""#toast.show"")
        assert CID in page.inner_text(""#toast"")
        browser.close()",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_pwa_offline.py,,1,1.725782769012759e-08,"The method 'test_offline_pwa_and_share' is a test function that automates the testing of a Progressive Web App (PWA) using Playwright. It checks the offline capabilities and sharing functionality of the app. This type of test is crucial for ensuring the reliability and performance of web applications, especially those that need to function offline. Automated tests like this are generally maintained and updated rather than deleted, as they provide ongoing value in verifying application behavior. Therefore, the method is likely to be retained."
survived,"    async def policy(self, obs, ctx):  # type: ignore[override]
        if isinstance(obs, dict):
            return await self.tools.run_sim(
                int(obs.get(""agents"", 100)),
                int(obs.get(""rounds"", 1000)),
                float(obs.get(""delta"", 0.8)),
                float(obs.get(""stake"", 2.5)),
            )
        return await self.tools.run_sim()
",alpha_factory_v1/demos/solving_agi_governance/openai_agents_bridge.py,GovernanceSimAgent,1,1.2501528648238603e-09,"The method is likely to survive because it is an asynchronous function that handles different types of input (a dictionary or other) and calls another method 'run_sim' with appropriate parameters. It is well-structured to handle its task and uses type hinting to improve code readability and maintainability. Additionally, it uses default values for the simulation parameters, which makes it flexible and robust."
survived,"def boom(a, b):
    print(""boom"")
    return True
",tests/transpiler/x/py/short_circuit.py,,1,4.785094849865141e-06,"The method 'boom' is a simple function that prints 'boom' and returns True. It doesn't perform any complex operations or have any dependencies that would make it obsolete or unnecessary. Its survival depends on its usage context. If it's part of a larger codebase where this functionality is needed, it will likely survive. However, if it's not used or needed, it might be deleted. Without additional context, it's reasonable to assume it could survive as a utility function."
survived,"    def _decorator(func):
        return func
",tests/test_openai_bridge_integration.py,,0,0.9999417087232136,"The method _decorator is a simple function that takes another function as an argument and returns it unchanged. This is a basic implementation of a decorator pattern, but it doesn't add any additional functionality or modification to the function it decorates. While it is syntactically correct, its utility is limited unless it is intended to be a placeholder for future enhancements. Without additional context or usage, it is likely to be considered redundant and may be removed in a codebase focused on efficiency and clarity."
survived,"def makeAdder(n):
    def adder(x):
        return x + n
    return adder
",tests/human/py/closure.py,,1,6.348800075736417e-09,"The method 'makeAdder' is a higher-order function that returns a closure. It is a useful and common pattern in functional programming, allowing the creation of customized functions on the fly. This method is likely to be retained because it provides a flexible way to generate new functions with specific behavior, which can be very useful in various programming scenarios."
survived,"    def _save_result(result: ResultsResponse) -> None:
        path = _results_dir / f""{result.id}.json""
        path.write_text(result.json())
        _simulations[result.id] = result
        while len(_simulations) > _max_results:
            old_id, _ = _simulations.popitem(last=False)
            with contextlib.suppress(FileNotFoundError):
                (_results_dir / f""{old_id}.json"").unlink()
        global _latest_id
        _latest_id = result.id
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/api_server.py,,1,3.850741907939403e-09,"The method '_save_result' is responsible for saving a result to a file, managing a cache of results, and updating a global variable. It is a utility function that handles important tasks such as file I/O and cache management, which are common in applications that deal with data persistence and memory management. The method is well-structured, performs necessary operations, and does not contain any obvious issues or redundancies that would warrant its removal. Therefore, it is likely to be retained in the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/q1.py,Auto2,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to survive because it provides a flexible way to access object properties, which can be particularly useful in dynamic or reflective programming scenarios."
survived,"    def __len__(self):
        return len(self.Items)
",tests/machine/x/python/group_by_having.py,_Group,1,8.592166611791576e-10,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation here is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"    def __len__(self):
        return len(self.Items)
",tests/machine/x/python/group_by_multi_join.py,_Group,1,2.998960815863541e-09,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"def _expected_moe_linear_output(moe: MoELinear, x: hax.NamedArray, group_sizes: hax.NamedArray):
    dim_numbers = jax.lax.RaggedDotDimensionNumbers(
        (
            ((x.axis_indices(moe.In),), (moe.weight.axis_indices(moe.In),)),
            ((), ()),
        ),
        x.axis_indices(hax.axis.without_axes(x.axes, moe.In)),
        (moe.weight.axis_indices(moe.Experts),),
    )
    out_raw = jax.lax.ragged_dot_general(
        lhs=x.array,
        rhs=moe.weight.array,
        group_sizes=group_sizes.array,
        ragged_dot_dimension_numbers=dim_numbers,
    )
    out_axes = hax.replace_axis(x.axes, moe.In, moe.Out)
    out = hax.named(out_raw, out_axes)
    if moe.bias is not None:
        out = out + moe.bias
    return out
",tests/test_moe_linear.py,,1,6.825604231969389e-08,"The method '_expected_moe_linear_output' is a specialized function that calculates the expected output of a mixture of experts (MoE) linear layer using JAX's ragged dot product. This function is likely part of a larger library or framework dealing with neural networks or machine learning models. Given its specific purpose and the fact that it uses advanced features like ragged dot products and named arrays, it is unlikely to be deleted unless the entire framework or approach is deprecated. Such functions are typically retained as they provide essential functionality for model computations."
survived,"def test_moe_linear_out_first_property():
    E, In, Out = hax.make_axes(E=2, In=4, Out=3)
    moe = MoELinear.init(E, In, Out, key=jrandom.PRNGKey(0), out_first=True)
    assert moe.out_first
    assert moe.weight.axes[:3] == (E, Out, In)

    moe2 = MoELinear.init(E, In, Out, key=jrandom.PRNGKey(1), out_first=False)
    assert not moe2.out_first
    assert moe2.weight.axes[:3] == (E, In, Out)
",tests/test_moe_linear.py,,1,9.736200303530205e-10,"The method `test_moe_linear_out_first_property` is a unit test that verifies the behavior of the `MoELinear` class when initialized with different `out_first` parameters. It checks that the `out_first` attribute and the order of axes in the `weight` attribute are set correctly. This is a typical and necessary test to ensure that the class behaves as expected under different configurations. Since it serves a clear purpose in testing the functionality of the `MoELinear` class, it is likely to be retained in the codebase."
survived,"        def pct(p):
            return data[int(n*p/100)] if n else 0
",alpha_factory_v1/demos/macro_sentinel/simulation_core.py,MonteCarloSimulator,1,4.1399375473943306e-08,"The method 'pct' is a simple utility function that calculates a percentile value from a dataset. It is concise and performs a specific task efficiently. Such utility functions are often useful in data analysis and statistical calculations, making them likely to be retained in codebases where data processing is required. The function is also straightforward and does not have any apparent issues or inefficiencies that would necessitate its removal."
survived,"        def reset(self, *, seed=None):
            return [0.0]*4, {}
",alpha_factory_v1/demos/muzero_planning/minimuzero.py,_StubEnv,1,4.944450477491054e-09,"The method 'reset' is a simple function that returns a list of four zeros and an empty dictionary. It is likely a part of a larger class, possibly related to a simulation or environment reset in reinforcement learning. The method is straightforward and does not contain any deprecated or problematic code patterns. Without additional context suggesting it is obsolete or replaced by a more efficient method, there is no clear reason for it to be deleted. Therefore, it is likely to survive."
survived,"    def _run_search_helper(episodes: int, target: int) -> str:
        """"""Execute the search loop and return a summary string.""""""
        run(episodes=episodes, target=target)
        return f""completed {episodes} episodes toward target {target}""
",alpha_factory_v1/demos/meta_agentic_tree_search_v0/openai_agents_bridge.py,,1,2.3355930333443423e-09,"The method '_run_search_helper' is a private helper function, indicated by the underscore prefix, which suggests it is intended for internal use within a module or class. It performs a specific task of running a search loop and returning a summary string. The method is concise, has a clear purpose, and is likely used by other parts of the code to encapsulate the logic of running a search and generating a summary. There is no indication that this method is redundant or unnecessary, and it seems to serve a useful purpose in the context of the code. Therefore, it is likely to be retained."
survived,"def test_llm_offline_pipeline() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri()

    with sync_playwright() as p:
        browser = p.chromium.launch()
        page = browser.new_page()
        page.goto(url)
        page.wait_for_selector(""#controls"")

        out = page.evaluate(""window.llmChat('hello')"")
        assert not out.startswith('[offline]')
        browser.close()
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_browser_ui.py,,1,3.850741907939403e-09,"The method `test_llm_offline_pipeline` is a test function that uses Playwright to automate a browser and test a specific functionality of a web application. It checks if a local HTML file can be opened and if a JavaScript function `llmChat` returns a response that does not start with '[offline]'. This kind of test is useful for ensuring that the offline capabilities of a web application are functioning correctly. Given the increasing importance of offline functionality in web applications, this test is likely to be relevant and useful for maintaining the quality of the application. Therefore, it is likely to be retained."
survived,"    def start_background_tasks() -> None:
        pass
",tests/test_agent_manager_consumer.py,,0,0.9999997300421382,"The method 'start_background_tasks' is currently a placeholder with no implementation (indicated by 'pass'). If this method is part of a larger codebase, it might be intended for future development where background tasks will be initiated. However, if it remains unimplemented for an extended period, it could be considered for deletion during code cleanup to reduce clutter. Without additional context on its intended use or any comments indicating future plans, it's more likely to be deleted if it stays as is."
survived,"        async def stop_consumer(self) -> None:
            nonlocal stopped
            stopped = True
",tests/test_agent_manager_consumer.py,DummyBus,1,1.725782769012759e-08,"The method 'stop_consumer' is a simple asynchronous function that sets a nonlocal variable 'stopped' to True. This method is likely part of a larger class or module that manages a consumer process, and the 'stopped' variable is used to signal that the consumer should stop its operation. The method is straightforward and serves a clear purpose in controlling the state of the consumer. Without additional context suggesting that this method is redundant or replaced by another mechanism, it is reasonable to assume that it will be retained as it provides necessary functionality for stopping the consumer process."
survived,"def test_manager_starts_and_stops_bus_consumer(monkeypatch: pytest.MonkeyPatch) -> None:
    started = False
    stopped = False

    class DummyBus:
        def __init__(self, *_a: object, **_k: object) -> None:
            pass

        async def start_consumer(self) -> None:
            nonlocal started
            started = True

        async def stop_consumer(self) -> None:
            nonlocal stopped
            stopped = True

        def publish(self, *_a: object, **_kw: object) -> None:
            pass

    async def dummy_run_cycle() -> None:
        return None

    class DummyAgent:
        NAME = ""dummy""
        CYCLE_SECONDS = 0.0
        run_cycle = dummy_run_cycle

    def list_agents(_detail: bool = False) -> list[str]:
        return [""dummy""]

    def get_agent(name: str) -> DummyAgent:
        assert name == ""dummy""
        return DummyAgent()

    def start_background_tasks() -> None:
        pass

    monkeypatch.setattr(""alpha_factory_v1.backend.agent_manager.EventBus"", DummyBus)
    monkeypatch.setattr(""backend.agents.list_agents"", list_agents)
    monkeypatch.setattr(""backend.agents.get_agent"", get_agent)
    monkeypatch.setattr(""backend.agents.start_background_tasks"", start_background_tasks)
    monkeypatch.setattr(""alpha_factory_v1.backend.agent_runner.get_agent"", get_agent)

    mgr = AgentManager({""dummy""}, True, None, 60, 30)

    async def _run() -> None:
        await mgr.start()
        await mgr.stop()

    asyncio.run(_run())

    assert started
    assert stopped",tests/test_agent_manager_consumer.py,,1,5.60279640614594e-09,The method is a well-structured test function that uses monkeypatching to replace certain components with dummy implementations for testing purposes. It verifies that the start and stop methods of a bus consumer are called correctly. This is a common pattern in testing asynchronous code and ensures that the AgentManager interacts with the bus as expected. The method is likely to survive because it is a useful test for ensuring the correct behavior of the system.
survived,"    def test_disabled_when_deps_missing(self) -> None:
        with mock.patch.object(mod, ""MetaEvolver"", None), \
             mock.patch.object(mod, ""CurriculumEnv"", None):
            agent = mod.AIGAEvolverAgent()
            self.assertIsNone(agent.evolver)
            asyncio.run(agent.step())
",tests/test_aiga_evolver_agent_logic.py,TestEvolverAgentLogic,1,3.2241866333029355e-08,"The method `test_disabled_when_deps_missing` is a unit test that checks the behavior of the `AIGAEvolverAgent` when certain dependencies (`MetaEvolver` and `CurriculumEnv`) are missing. This is a valid and useful test case to ensure that the system behaves correctly under these conditions. It uses mocking to simulate the absence of these dependencies and verifies that the `evolver` attribute is `None` and that the `step` method can be run without errors. Such tests are crucial for robust software development, especially in environments where dependencies might not always be available. Therefore, this method is likely to be retained in the codebase."
survived,"    def test_step_publishes_best(self) -> None:
        class Dummy:
            def __init__(self) -> None:
                self.gen = 2
                self.best_fitness = 0.5

            def run_generations(self, _n: int) -> None:
                pass

        with mock.patch.object(mod, ""MetaEvolver"", lambda *a, **k: Dummy()), \
             mock.patch.object(mod, ""CurriculumEnv"", object), \
             mock.patch.object(mod, ""_publish"") as pub:
            agent = mod.AIGAEvolverAgent()
            asyncio.run(agent.step())
            pub.assert_called_with(""aiga.best"", {""gen"": 2, ""fitness"": 0.5})",tests/test_aiga_evolver_agent_logic.py,TestEvolverAgentLogic,1,9.237449576640118e-09,"The method `test_step_publishes_best` is a unit test designed to verify that the `step` method of the `AIGAEvolverAgent` class correctly publishes the best generation and fitness values. It uses mocking to replace certain components with dummy objects, ensuring the test is isolated from external dependencies. This is a common practice in testing to ensure that the method under test behaves as expected. Since this method is a test and not part of the production code, it is unlikely to be deleted unless the functionality it tests is removed or significantly altered. Therefore, it is more likely to survive."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/100-prisoners.py,,1,7.194132978569833e-09,"The method _now() is a utility function that generates a pseudo-random number based on a seed if _now_seeded is True, or returns the current time in nanoseconds if not. This function is useful for generating consistent pseudo-random numbers for testing or other purposes when seeded, and for getting the current time otherwise. Such utility functions are often retained in codebases for their usefulness in testing and time-related operations. Therefore, it is likely to survive."
survived,"def shuffle(xs):
    arr = xs
    i = 99
    while i > 0:
        j = _now() % (i + 1)
        tmp = arr[i]
        arr[i] = arr[j]
        arr[j] = tmp
        i = i - 1
    return arr
",tests/rosetta/transpiler/Python/100-prisoners.py,,0,0.9999998144608401,"The method is likely to be deleted because it contains several issues that make it unreliable and potentially unsafe for use. Firstly, the function uses a fixed size of 100 for the array, which means it will fail or behave unpredictably if the input list 'xs' is not exactly 100 elements long. Secondly, the use of '_now()' to generate a random index is not a standard or reliable method for shuffling, as it depends on the current time, which is not random. This could lead to predictable patterns in the shuffle, especially if called in quick succession. Additionally, '_now()' is not defined within the code, suggesting a missing or incorrect implementation. These issues make the function unsuitable for practical use, leading to its likely deletion."
survived,"    def test_selects_supply_chain_bottleneck(self) -> None:
        signals = {
            ""yield_curve"": ""yield curve normal"",
            ""supply_chain"": ""flows 12m usd  POTENTIAL BOTTLENECK"",
        }
        self.assertEqual(alpha_report.best_alpha(signals), signals[""supply_chain""])
",tests/test_alpha_report.py,TestBestAlpha,1,9.736200303530205e-10,"The method 'test_selects_supply_chain_bottleneck' is a unit test that checks if the 'best_alpha' function correctly identifies the 'supply_chain' signal as the best alpha when it indicates a potential bottleneck. This is a valid and useful test case for ensuring the functionality of the 'best_alpha' method, especially in scenarios where supply chain issues are critical. Therefore, the method is likely to be retained as it serves a clear purpose in validating the behavior of the code."
survived,"def test_sync_parallel_tools_or(client):
    client = instructor.from_anthropic(
        client, mode=instructor.Mode.ANTHROPIC_PARALLEL_TOOLS
    )
    resp = client.chat.completions.create(
        model=""claude-3-5-haiku-latest"",
        messages=[
            {""role"": ""system"", ""content"": ""You must always use tools""},
            {
                ""role"": ""user"",
                ""content"": ""What is the weather in toronto and dallas and who won the super bowl?"",
            },
        ],
        response_model=Iterable[Union[Weather, GoogleSearch]],
    )
    assert len(list(resp)) == 3
",tests/llm/test_anthropic/test_parallel.py,,0,0.9999898700082703,"The method 'test_sync_parallel_tools_or' is likely to be deleted because it contains several issues that suggest it is not functioning as intended. Firstly, the method uses a client object that is not fully defined within the code snippet, which makes it unclear how the 'instructor.from_anthropic' function is supposed to work. Secondly, the 'response_model' parameter in 'client.chat.completions.create' is set to 'Iterable[Union[Weather, GoogleSearch]]', but there is no context or definition for 'Weather' or 'GoogleSearch', making it unclear what types of responses are expected. Lastly, the assertion 'assert len(list(resp)) == 3' assumes a specific number of responses without any explanation or context, which could lead to failures if the response count changes. These issues suggest that the method is either incomplete or not robust enough for production use, leading to its potential deletion."
survived,"def test_time_dependent_discontinuity(tmp_path):
    """"""Models with time dependent discontinuities are handled.""""""

    from amici.antimony_import import antimony2sbml
    from amici.sbml_import import SbmlImporter
    from amici.jax.petab import DEFAULT_CONTROLLER_SETTINGS

    ant_model = """"""
    model time_disc
        x' = piecewise(1, time - sin(time) - 1 < 0, 2)
        x = 0
    end
    """"""

    sbml = antimony2sbml(ant_model)
    importer = SbmlImporter(sbml, from_file=False)
    importer.sbml2jax(""time_disc"", output_dir=tmp_path)

    module = amici._module_from_path(""time_disc"", tmp_path / ""__init__.py"")
    model = module.Model()

    p = jnp.array([1.0])
    x0_full = model._x0(0.0, p)
    tcl = model._tcl(x0_full, p)
    x0 = model._x_solver(x0_full)
    ts = jnp.array([0.0, 1.0, 2.0])

    assert len(model._root_cond_fns(p)) > 0
    assert model._known_discs(p).size == 0

    ys, _ = model._solve(
        p,
        ts,
        tcl,
        x0,
        diffrax.Tsit5(),
        diffrax.PIDController(**DEFAULT_CONTROLLER_SETTINGS),
        1000,
        diffrax.DirectAdjoint(),
    )

    assert ys.shape[0] == ts.shape[0]
",python/tests/test_jax.py,,1,6.023574641292144e-08,"The method is a test function that checks the handling of time-dependent discontinuities in a model. It is likely part of a test suite for a scientific or mathematical library. Test functions are generally retained as they are crucial for ensuring the correctness and reliability of the codebase. Additionally, the function is well-structured and uses relevant libraries and methods, indicating it is actively used and maintained."
survived,"    async def simulate(req: SimRequest) -> dict[str, str]:
        sim_id = secrets.token_hex(8)
        asyncio.create_task(_background_run(sim_id, req))
        return {""id"": sim_id}
",src/interface/api_server.py,,1,9.736200303530205e-10,"The method 'simulate' is an asynchronous function that generates a unique simulation ID and starts a background task. This is a common pattern in asynchronous programming, especially in web applications where non-blocking operations are crucial. The use of 'asyncio.create_task' to run a background task is a modern and efficient way to handle asynchronous operations. The method is likely to be useful in scenarios where simulations or long-running tasks need to be initiated without blocking the main thread. Therefore, it is likely to be retained in the codebase."
survived,"def test_nsga2_step_evolves_population() -> None:
    random.seed(0)
    pop = [mats.Individual([0.0, 0.0]) for _ in range(4)]

    def fn(genome):
        x, y = genome
        return x ** 2, y ** 2

    new = mats.nsga2_step(pop, fn, mu=4)
    assert len(new) == 4
    assert all(ind.fitness is not None for ind in new)
    genomes = {tuple(ind.genome) for ind in new}
    assert len(genomes) >= 1",tests/test_mats.py,,1,1.2501528648238603e-09,"The method `test_nsga2_step_evolves_population` is a unit test function designed to test the functionality of the `nsga2_step` method from the `mats` module. It sets up a population, defines a fitness function, and checks that the new population has the expected properties. This is a typical structure for a unit test, which is crucial for ensuring code reliability and correctness. Since unit tests are essential for maintaining code quality and are not typically removed unless the functionality they test is deprecated or replaced, it is likely that this method will be Survived (1)."
survived,"def test_replay_missing(tmp_path) -> None:
    with patch.object(cli.config, ""Settings"") as settings:
        settings.return_value.ledger_path = tmp_path / ""led.txt""
        out = CliRunner().invoke(cli.main, [""replay""])
        assert ""No ledger"" in out.output
",tests/test_cli.py,,1,1.3440409770490404e-08,"The method 'test_replay_missing' is a unit test that checks the behavior of a CLI application when a ledger file is missing. It uses mocking to simulate the absence of the ledger file and asserts that the output contains the expected error message. This is a valid and useful test case for ensuring the robustness of the application, especially in handling error scenarios. Therefore, it is likely to be retained in the codebase."
survived,"    def __init__(self, inputs: str):
        self.inputs = inputs.encode(""utf-8"")  # Convert to bytes
",scripts/utils/lcb_runner.py,MockBuffer,1,1.955568070542584e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. It initializes an instance of the class with a given input, converting the input string to bytes. This is a common and necessary operation when dealing with string data that needs to be processed or transmitted in byte format. There is no indication that this method is redundant or unnecessary, so it is likely to be retained."
survived,"    def add(self, meta: dict[str, Any], score: float) -> None:
        with sqlite3.connect(self.path) as cx:
            cx.execute(""INSERT INTO agents(meta, score) VALUES (?, ?)"", (json.dumps(meta), score))
",src/archive.py,Archive,1,1.2501528648238603e-09,"The method 'add' is a straightforward implementation of inserting data into a SQLite database. It uses a context manager to handle the database connection, which is a good practice for ensuring that the connection is properly closed after the operation. The use of parameterized queries helps prevent SQL injection attacks. The method is simple, efficient, and follows good coding practices, making it likely to be retained in the codebase."
survived,"        async def _spawn():  # pragma: no cover - Rocketry callback
            await self._spawn_jobs()
",src/scheduler.py,SelfImprovementScheduler,1,4.944450477491054e-09,"The method _spawn is an asynchronous function that is likely used as a callback for a task scheduler or job manager, as indicated by the comment 'Rocketry callback'. The use of 'pragma: no cover' suggests that this method is intentionally excluded from test coverage, possibly because it is a private method or its functionality is tested indirectly through other means. The method name and its asynchronous nature imply it is part of a larger system for managing asynchronous tasks or jobs. Given these factors, it is likely that this method is integral to the system's operation and will be retained, hence it will survive."
survived,"    def replace_task(self, *, path: str, pattern: str, repl: str) -> dict[str, int]:
        return {""count"": replace(path, pattern, repl)}",src/self_edit/tools.py,FileToolsADK,1,5.3157849718487075e-08,"The method 'replace_task' is a simple wrapper around a function 'replace', which is not defined within the provided code. Without knowing the implementation of 'replace', it's difficult to assess the full utility of 'replace_task'. However, the method itself is straightforward and provides a clear interface for replacing patterns in a file or string, returning the count of replacements made. This kind of utility function is often useful in various applications, especially in data processing or text manipulation tasks. Unless there is a significant reason to remove it, such as redundancy or a better alternative, it is likely to be retained."
survived,"        def task(**_kw):
            return _StubDecor()
",src/self_edit/tools.py,adk,1,6.144172127844639e-06,"The method 'task' is a simple function that takes any number of keyword arguments and returns an instance of '_StubDecor'. Without additional context, it's difficult to determine its utility or relevance. However, the use of a leading underscore in '_StubDecor' suggests it might be intended for internal use or as a placeholder. If '_StubDecor' is a meaningful class or function elsewhere in the code, 'task' could be a useful utility function. Without further context, it's hard to definitively say if it will be deleted, but given its simplicity and potential utility, it might survive."
survived,"def test_edit_and_view(temp_file: Path) -> None:
    temp_file.write_text(""a\nb\nc\n"")
    edit(temp_file, 1, 2, ""X"")
    assert temp_file.read_text() == ""a\nX\nc""
    assert view(temp_file, 0, 2) == ""a\nX""
",tests/test_self_edit_tools.py,,1,1.725782769012759e-08,"The method 'test_edit_and_view' is a test function that checks the functionality of 'edit' and 'view' functions. Test functions are crucial for ensuring code reliability and correctness, especially in a development environment where changes are frequent. This function is likely part of a test suite that verifies the behavior of file editing and viewing operations. Since testing is an integral part of software development and maintenance, this method is likely to be retained to ensure the associated functions work as expected."
survived,"def replace(path: str | Path, pattern: str, repl: str) -> int:
    """"""Regex replace ``pattern`` with ``repl`` inside ``path``.""""""
    p = _safe_path(path)
    text = p.read_text(encoding=""utf-8"", errors=""replace"")
    new_text, n = re.subn(pattern, repl, text, flags=re.MULTILINE)
    if n:
        p.write_text(new_text, encoding=""utf-8"")
    return n
",src/self_edit/tools.py,,1,3.160881453314576e-10,"The method 'replace' is a utility function that performs a regex-based find-and-replace operation on the contents of a file specified by 'path'. It is a useful and common operation in many programming tasks, especially for text processing and data cleaning. The function is well-defined, using standard libraries and practices, such as handling file paths safely and managing text encoding. These factors make it a valuable function that is likely to be retained in the codebase."
survived,"async def _op(genome):
    return genome + 1
",tests/test_evolve.py,,1,3.927863699585036e-07,"The method _op is a simple asynchronous function that takes a parameter 'genome' and returns its value incremented by 1. This function is straightforward and could be useful in contexts where asynchronous operations are needed, such as in web servers or applications that require non-blocking operations. Since it performs a basic arithmetic operation, it is unlikely to be deleted unless it is redundant or unused in the codebase. However, without additional context on its usage, it's difficult to definitively predict its future. Given its potential utility, it is more likely to survive."
survived,"    def all(self) -> Sequence[Candidate]:
        return list(self._items)
",src/evolve.py,InMemoryArchive,1,2.0611536181902033e-09,"The method 'all' is a simple and straightforward implementation that returns a list of items from a private attribute '_items'. This method is likely to be useful for accessing the collection of 'Candidate' objects stored within the class. It follows a common pattern for providing access to internal collections in a controlled manner. There is no indication that this method is redundant or problematic, so it is likely to be retained."
survived,"def main() -> int:
    repo_root = Path(__file__).resolve().parents[1]
    req_txt = repo_root / ""requirements.txt""
    lock_file = repo_root / ""requirements.lock""

    with tempfile.TemporaryDirectory() as tmpdir:
        out_path = Path(tmpdir) / ""requirements.lock""
        pip_compile = shutil.which(""pip-compile"")
        if pip_compile:
            cmd = [pip_compile]
        else:
            cmd = [sys.executable, ""-m"", ""piptools"", ""compile""]
        cmd += [""--quiet"", ""--generate-hashes"", str(req_txt), ""-o"", str(out_path)]
        result = subprocess.run(cmd, capture_output=True, text=True)
        sys.stdout.write(result.stdout)
        sys.stderr.write(result.stderr)
        if result.returncode != 0:
            return result.returncode
        if out_path.read_bytes() != lock_file.read_bytes():
            sys.stderr.write(
                ""requirements.lock is outdated. Run 'pip-compile --quiet --generate-hashes requirements.txt'\n""
            )
            return 1
    return 0
",scripts/verify_requirements_lock.py,,1,1.0467401685178159e-08,"The method is a utility function that automates the process of checking if the 'requirements.lock' file is up-to-date with the 'requirements.txt' file. This is a common task in software development to ensure dependency consistency. The function uses standard libraries and tools like 'pip-compile', 'subprocess', and 'tempfile', which are reliable and widely used. The logic is clear and serves a practical purpose in maintaining project dependencies. Therefore, it is likely to be retained in the codebase."
survived,"    def parse_kwargs():
        param = dict()
        for k, v in args.kwargs:
            if v.isdigit():
                param[k] = int(v)
            elif v == 'True' or v == 'true':
                param[k] = True
            elif v == 'False' or v == 'false':
                param[k] = False
            elif isfloat(v):
                param[k] = float(v)
            else:
                param[k] = v
        return param
",label_studio_ml/examples/timeseries_segmenter/_wsgi.py,,0,0.9999997897565932,"The method `parse_kwargs` is likely to be deleted because it contains several issues that make it non-functional and potentially problematic. Firstly, the method attempts to iterate over `args.kwargs`, which is not a standard way to access keyword arguments in Python. Typically, keyword arguments are accessed via `**kwargs` in function definitions, and `args` is not defined in the provided code, leading to a NameError. Additionally, the method relies on a function `isfloat` which is not defined within the code, leading to another potential error. These issues suggest that the method is not currently usable in its present form, and without corrections, it is more likely to be removed or replaced with a functional implementation."
survived,"        def __init__(self, base_url=None, api_key=None):
            pass
",no-ocr-api/tests/test_utils.py,FakeOpenAI,1,2.4300230936537083e-05,"The method is a constructor for a class, typically used to initialize object attributes. However, in its current form, it does not perform any initialization or store the parameters `base_url` and `api_key`. Despite this, constructors are fundamental to class definitions, and even if currently unused, it is likely to be retained for future use or to maintain a consistent class interface. Therefore, it is unlikely to be deleted."
survived,"def extract_title(readme: Path) -> str:
    """"""Return a reasonable title for the given README.""""""
    lines = readme.read_text(encoding=""utf-8"").splitlines()
    # Search the first 50 lines for a level-one heading
    for line in lines[:50]:
        m = TITLE_RE.match(line.strip())
        if m:
            return m.group(1).strip()
    # Fallback to folder name if no heading found early in the file
    return readme.parent.name.replace(""_"", "" "").title()
",scripts/generate_demo_docs.py,,1,2.1724399346070676e-10,"The method 'extract_title' is a utility function that extracts a title from a README file, which is a common requirement in many projects. It attempts to find a level-one heading within the first 50 lines of the README, which is a reasonable approach since titles are usually placed at the beginning of documents. If no title is found, it defaults to using the folder name, ensuring that a title is always returned. This functionality is useful and well-implemented, making it likely to be retained in the codebase."
survived,"    def test_missing_file(self):
        with mock.patch.dict(os.environ, {'GRAFANA_TOKEN': 'x'}):
            with self.assertRaises(SystemExit):
                with mock.patch.object(import_dashboard.sys, 'argv', ['imp.py', '/nope']):
                    import_dashboard.main()
",alpha_factory_v1/tests/test_scripts_import_dashboard.py,ImportDashboardScriptTest,1,1.0467401685178159e-08,"The method `test_missing_file` is a unit test that checks the behavior of the `import_dashboard.main()` function when a non-existent file path is provided as an argument. It uses mocking to simulate the environment and command-line arguments, and it expects the function to raise a `SystemExit` exception. This is a valid and useful test case for ensuring that the program handles missing files correctly. Therefore, it is likely to be retained in the codebase as it contributes to the robustness of the application by verifying error handling."
survived,"    def __init__(
        self,
        name: str | None = None,
        instructions: str | None = None,
        tools: list | None = None,
    ) -> None:
        self.name = name or """"
        self.instructions = instructions or """"
        self.tools = tools or []
",src/agents/__init__.py,Agent,1,2.5109990926928157e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. It initializes the instance variables with default values if none are provided, ensuring that the object is always in a valid state. This is a common and necessary pattern in Python, especially with the use of type hints for better code clarity and error checking. Therefore, it is unlikely to be deleted."
survived,"    def mocker():
        return MockerFixture()
",src/pytest_mock/__init__.py,,0,0.999999694097641,"The method `mocker` is a simple function that returns an instance of `MockerFixture`. Without additional context, such as the purpose of `MockerFixture` or how this function is used, it's difficult to determine its utility. However, if `MockerFixture` is a commonly used fixture in testing frameworks or libraries, this function could be useful for simplifying test setup. If `MockerFixture` is not widely used or if this function is redundant, it might be deleted. Given the lack of context, I'll predict it will be deleted."
survived,"def expo(*_args: Any, **_kwargs: Any) -> float:
    return 0.0
",src/backoff/__init__.py,,0,0.9999999847700205,"The method 'expo' is defined to take any number of positional and keyword arguments but always returns a constant value of 0.0, regardless of the input. This suggests that the method does not perform any meaningful computation or utilize the arguments in any way. Such a method is likely to be considered redundant or unnecessary in a codebase, as it does not fulfill any functional purpose. Therefore, it is likely to be deleted in future iterations of the code."
survived,"def select_autoescape(*_args: Any, **_kwargs: Any) -> bool:
    return False
",src/jinja2/__init__.py,,1,3.2887477414614998e-06,"The method 'select_autoescape' is a simple function that takes any number of arguments and keyword arguments but always returns False. This suggests that it is a placeholder or a default implementation that might be overridden or extended in a subclass or a different context. However, without additional context on its usage or the surrounding codebase, it's difficult to determine its importance or relevance. If this function is part of a larger framework or library where autoescaping is a feature that can be toggled, this method might be crucial for disabling autoescaping. Therefore, it is likely to survive unless there is a significant refactor or change in the framework's design that makes this function obsolete."
survived,"def pytest_configure(config):  # pragma: no cover - register fixture
    @pytest.fixture
    def mocker():
        return MockerFixture()

    config.pluginmanager.register(sys.modules[__name__])",src/pytest_mock/__init__.py,,1,2.0611536181902033e-09,"The method `pytest_configure` is a hook function used in pytest to configure the test environment. It registers a fixture `mocker` which returns a `MockerFixture` object. This is a common pattern in pytest to set up fixtures that can be used across multiple test cases. The use of `pragma: no cover` suggests that this part of the code is intentionally excluded from test coverage metrics, likely because it's a setup function rather than a testable unit of logic. Given its role in setting up the test environment, it is unlikely to be deleted unless the testing framework or strategy changes significantly. Therefore, it is more likely to survive."
survived,"    def test_seed_reproducibility(self) -> None:
        try:
            import numpy as np  # noqa: F401
            import pandas as pd  # noqa: F401
        except ModuleNotFoundError:
            self.skipTest(""numpy/pandas not available"")

        sim = simulation_core.MonteCarloSimulator(n_paths=3, horizon=2, seed=42)
        obs = {
            ""yield_10y"": 4.0,
            ""yield_3m"": 4.5,
            ""stable_flow"": 10.0,
            ""es_settle"": 5000.0,
        }
        factors = sim.simulate(obs)
        expected = [0.989483, 1.02894, 0.998621]
        for f, e in zip(factors, expected):
            self.assertAlmostEqual(f, e, places=6)
        self.assertAlmostEqual(sim.var(factors), -0.009602935809998603)
        self.assertAlmostEqual(sim.cvar(factors), -0.010516713095912844)
",tests/test_simulation_core.py,TestSimulationCore,1,5.60279640614594e-09,"The method 'test_seed_reproducibility' is a unit test designed to verify the reproducibility of a simulation when a specific seed is used. It checks if the output of the simulation matches expected values, which is a common practice in testing to ensure consistency and correctness of the code. Such tests are crucial for maintaining the reliability of the software, especially in scientific and financial computations where reproducibility is key. Therefore, this method is likely to be retained as it serves an important purpose in the codebase."
survived,"def make_client() -> TestClient:
    return TestClient(cast(Any, api.app))
",tests/test_metrics_exposure.py,,1,4.363462233903899e-09,"The method 'make_client' is a utility function that creates and returns an instance of 'TestClient'. This is a common pattern in testing frameworks to facilitate testing of web applications. The function is simple, clear, and serves a specific purpose in the context of testing. There is no indication that it is deprecated or redundant, and it is likely to be useful for testing purposes. Therefore, it is likely to be retained in the codebase."
survived,"def _rescan_loop() -> None:  # pragma: no cover
    while True:
        try:
            discover_hot_dir()
        except Exception:  # noqa: BLE001
            logger.exception(""Hot-dir rescan failed"")
        time.sleep(_RESCAN_SEC)
",alpha_factory_v1/backend/agents/health.py,,1,5.3157849718487075e-08,"The method _rescan_loop is a private method (indicated by the underscore prefix) that is designed to run indefinitely, continuously rescanning a directory at a set interval. It includes exception handling to log any errors that occur during the rescan process. This kind of method is typically used in applications that require constant monitoring or updating of certain resources, such as file directories. The use of a try-except block to handle exceptions and the logging of errors suggest that this method is intended to be robust and reliable. Additionally, the use of 'pragma: no cover' indicates that this method is not intended to be covered by unit tests, which is common for methods that involve infinite loops or are difficult to test in isolation. Given these considerations, it is likely that this method is essential for the application's functionality and will be retained."
survived,"def test_no_placeholder() -> None:
    files = asset_files()
    assert files, ""no wasm assets found""
    for path in files:
        data = path.read_bytes()
        assert b""placeholder"" not in data.lower(), f""placeholder found in {path}""",tests/test_integrity.py,,1,1.3440409770490404e-08,"The method 'test_no_placeholder' is a test function that checks if any of the asset files contain the word 'placeholder'. It is a simple yet useful test to ensure that no placeholder text is left in the files, which could be a common oversight during development. Such tests are often crucial in maintaining code quality and ensuring that the final product does not contain any unfinished or temporary content. Therefore, this method is likely to be retained as part of the test suite."
survived,"def _set_seed(val: int) -> None:
    global _SEED
    _SEED = val
    random.seed(val)
    np.random.seed(val)
    torch.manual_seed(val)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,,1,1.0467401685178159e-08,"The method '_set_seed' is a utility function that sets a global seed for random number generation across multiple libraries (random, numpy, and torch). This is a common practice in machine learning and data science to ensure reproducibility of experiments. The function is simple, clear, and serves a useful purpose, making it unlikely to be deleted unless there is a significant change in how seeds are managed across these libraries."
survived,"def test_governance_bridge_adk_runtime(tmp_path: Path) -> None:
    """"""Launch governance-bridge with ADK enabled and verify logs.""""""
    stub = tmp_path / ""google_adk.py""
    stub.write_text(
        """"""
class Router:
    def __init__(self):
        self.app = type('app', (), {'middleware': lambda *a, **k: lambda f: f})()
    def register_agent(self, agent):
        pass
class Agent: ...
class AgentException(Exception):
    pass
""""""
    )

    env = os.environ.copy()
    env[""PYTHONPATH""] = f""{tmp_path}:{env.get('PYTHONPATH', '')}""
    env[""ALPHA_FACTORY_ENABLE_ADK""] = ""true""

    proc = subprocess.Popen(
        [""governance-bridge"", ""--enable-adk"", ""--port"", ""0""],
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        text=True,
        env=env,
    )
    try:
        time.sleep(2)
        proc.terminate()
        out, _ = proc.communicate(timeout=5)
    finally:
        if proc.poll() is None:
            proc.kill()
            proc.wait(timeout=5)

    assert ""Registered GovernanceSimAgent"" in out
    assert ""ADK"" in out",tests/test_governance_bridge_adk_runtime.py,,1,1.955568070542584e-08,"The method `test_governance_bridge_adk_runtime` is a test function that verifies the functionality of a system component by launching a subprocess and checking its output. Test functions are generally crucial for ensuring code reliability and are often maintained or expanded rather than deleted. The function is well-structured, uses temporary paths for isolation, and checks for specific log outputs, indicating it serves a clear purpose in the testing suite."
survived,"        def create_task(self, coro: Any) -> None:
            self.coro = coro
",tests/test_alpha_agi_business_3_v1.py,DummyLoop,0,0.999988521231025,"The method 'create_task' is very minimal and only assigns a coroutine to an instance variable 'coro'. It lacks functionality such as actually creating or managing a task, which is typically expected from a method with this name. Without additional context or functionality, it seems incomplete and not useful in its current form, suggesting it might be deleted or refactored in the future."
survived,"def test_run_cycle_uses_asyncio_run(monkeypatch: pytest.MonkeyPatch) -> None:
    """"""`run_cycle` should call ``asyncio.run`` when no loop is running.""""""
    mod = importlib.import_module(MODULE)

    monkeypatch.setattr(asyncio, ""get_running_loop"", lambda: (_ for _ in ()).throw(RuntimeError()))

    called: dict[str, Any] = {}

    def fake_run(coro: Any) -> None:
        called[""coro""] = coro

    monkeypatch.setattr(asyncio, ""run"", fake_run)

    async def dummy_cycle(*_a: object, **_k: object) -> None:
        pass

    monkeypatch.setattr(mod, ""run_cycle_async"", dummy_cycle)

    mod.run_cycle(mod.Orchestrator(), mod.AgentFin(), mod.AgentRes(), mod.AgentEne(), mod.AgentGdl(), mod.Model())

    assert called.get(""coro"") is not None
    assert getattr(called[""coro""], ""cr_code"", None) is dummy_cycle.__code__
",tests/test_alpha_agi_business_3_v1.py,,1,4.6911638017642294e-08,"The method `test_run_cycle_uses_asyncio_run` is a unit test function that verifies the behavior of the `run_cycle` function in a specific module. It uses the `monkeypatch` fixture from `pytest` to mock certain behaviors of the `asyncio` module and the module being tested. This is a common practice in testing to isolate the function under test and ensure it behaves as expected under certain conditions. The function is well-structured, uses appropriate testing techniques, and serves a clear purpose in the test suite. Therefore, it is likely to be retained in the codebase as it contributes to the reliability and correctness of the software."
survived,"def load_sector_equity_map(path: str | Path = _MAP_PATH) -> Dict[str, list[str]]:
    """"""Return the sector-to-equity mapping from ``path``.""""""

    mapping: Dict[str, list[str]] = {}
    with Path(path).open(newline="""", encoding=""utf-8"") as fh:
        reader = csv.DictReader(fh)
        for row in reader:
            sector = (row.get(""sector"") or """").strip()
            ticker = (row.get(""ticker"") or """").strip()
            if not sector or not ticker:
                continue
            mapping.setdefault(sector, []).append(ticker)
    return mapping
",src/finance/adapter.py,,1,2.1724399346070676e-10,"The method `load_sector_equity_map` is a utility function that reads a CSV file and returns a dictionary mapping sectors to lists of equity tickers. This is a common and useful functionality in financial applications where such mappings are frequently needed for analysis or reporting. The method is well-defined, uses standard libraries, and handles potential issues like missing data gracefully. There is no indication that this method is obsolete or redundant, and it serves a clear purpose. Therefore, it is likely to be retained in the codebase."
survived,"def improve_repo(repo_url: str, patch_file: str, metric_file: str, log_file: str) -> Tuple[float, Path]:
    """"""Clone ``repo_url``, apply ``patch_file`` and log score delta.

    Returns the score delta and path to the cloned repository.
    """"""
    if git is None:
        raise RuntimeError(""GitPython is required"")
    repo_dir = Path(tempfile.mkdtemp(prefix=""selfimprover-""))
    repo = git.Repo.clone_from(repo_url, repo_dir)
    baseline = _evaluate(repo_dir, metric_file)
    repo.git.apply(patch_file)
    repo.index.add([metric_file])
    repo.index.commit(""apply patch"")
    new_score = _evaluate(repo_dir, metric_file)
    delta = new_score - baseline
    _log_delta(delta, Path(log_file))
    return delta, repo_dir",alpha_factory_v1/demos/alpha_agi_insight_v1/src/self_improver.py,,1,5.60279640614594e-09,"The method 'improve_repo' is a utility function that automates the process of cloning a repository, applying a patch, and evaluating the impact of the patch on a given metric. This is a common task in software development, especially in continuous integration and testing environments. The method is well-defined, with clear inputs and outputs, and it handles errors (e.g., missing GitPython) appropriately. It also provides useful functionality by logging the score delta, which can be valuable for tracking changes over time. Given its utility and the fact that it doesn't have any obvious flaws or redundancies, it is likely to be retained in the codebase."
survived,"def _data_dir() -> pathlib.Path:
    """"""Return offline CSV directory from env or default.""""""
    return pathlib.Path(os.getenv(""OFFLINE_DATA_DIR"", str(_DEFAULT_DATA_DIR)))
",alpha_factory_v1/demos/macro_sentinel/data_feeds.py,,1,4.0586521248284276e-10,"The method '_data_dir' is a utility function that retrieves a directory path for offline CSV data, either from an environment variable or a default path. This is a common pattern in software development for managing configuration and is unlikely to be removed unless the entire configuration management approach changes. It is a simple, clear, and useful function that provides flexibility in specifying data directories, which is often needed in various environments (development, testing, production). Therefore, it is likely to survive."
survived,"def test_load_translations_unknown(monkeypatch):
    monkeypatch.delenv('DEVICONS_LANG', raising=False)
    assert devicons.load_translations('unknown') == {}",tests/test_translations.py,,1,1.0467401685178159e-08,"The method `test_load_translations_unknown` is a test function that uses the `monkeypatch` fixture to modify the environment variable `DEVICONS_LANG`. It then asserts that calling `devicons.load_translations` with the argument `'unknown'` returns an empty dictionary. This is a valid and useful test case for ensuring that the `load_translations` function behaves correctly when given an unknown language code. Test functions are generally not deleted unless they are redundant or replaced by more comprehensive tests. Since this test is specific and checks for a particular edge case, it is likely to be retained."
survived,"def main() -> int:
    if os.getenv(""ALLOW_PRIVATE_TEXT"") == ""1"":
        return 0

    flagged: List[str] = []
    for path in staged_files():
        if scan_file(path):
            flagged.append(str(path))

    if flagged:
        sys.stderr.write(
            ""Private or pay-walled text detected in:\n"" + ""\n"".join(flagged) + ""\n""
        )
        sys.stderr.write(""Set ALLOW_PRIVATE_TEXT=1 to override.\n"")
        return 1
    return 0
",scripts/dp_scrubber.py,,1,1.4166087846364157e-09,"The method is well-structured and serves a clear purpose: it checks for private or pay-walled text in staged files and returns an appropriate exit code based on the presence of such text. This functionality is useful in a development or deployment pipeline to ensure sensitive information is not inadvertently committed. The method also provides a way to override this check via an environment variable, which adds flexibility. Given its utility and the fact that it doesn't have any apparent issues or redundancies, it is likely to be retained."
survived,"    def allocate(
        self,
        top_children: Sequence[str],
        other_children: Sequence[str],
        *,
        dry_run: bool = False,
    ) -> Mapping[str, int]:
        """"""Return GPU allocation for ``top_children`` and ``other_children``.""""""
        price = self.price_fetcher(self.region)
        hourly_budget = self.budget_per_day / 24
        result: dict[str, int] = {}
        spent = 0.0
        for child in top_children:
            cost = 8 * price
            if spent + cost <= hourly_budget:
                result[child] = 8
                spent += cost
                if dry_run:
                    _log.info(
                        ""Allocate 8A10 to %s: cost %.2f/h (remaining %.2f/h)"",
                        child,
                        cost,
                        hourly_budget - spent,
                    )
            else:
                if dry_run:
                    _log.info(
                        ""Skip %s: need %.2f/h, remaining %.2f/h"",
                        child,
                        cost,
                        hourly_budget - spent,
                    )
        for child in other_children:
            cost = price
            if spent + cost <= hourly_budget:
                result[child] = 1
                spent += cost
                if dry_run:
                    _log.info(
                        ""Allocate 1A10 to %s: cost %.2f/h (remaining %.2f/h)"",
                        child,
                        cost,
                        hourly_budget - spent,
                    )
            else:
                if dry_run:
                    _log.info(
                        ""Skip %s: need %.2f/h, remaining %.2f/h"",
                        child,
                        cost,
                        hourly_budget - spent,
                    )
        if dry_run:
            _log.info(""Total hourly cost: %.2f of %.2f"", spent, hourly_budget)
        return result
",src/scheduler/spot_gpu.py,SpotGPUAllocator,1,2.5109990926928157e-08,"The method 'allocate' is a well-defined function that provides a specific utility: allocating GPU resources based on a budget. It includes logging for dry runs, which is useful for debugging and planning. The method is likely to be used in scenarios where resource allocation is critical, such as in cloud computing or data processing tasks. Its functionality is clear, and it serves a practical purpose, making it unlikely to be deleted unless the entire system it supports is deprecated or replaced."
survived,"def test_dry_run_respects_budget(caplog: pytest.LogCaptureFixture) -> None:
    alloc = SpotGPUAllocator(price_fetcher=lambda r: 0.5)
    caplog.set_level(logging.INFO)
    result = alloc.allocate([""a"", ""b""], [""c""], dry_run=True)
    assert result == {""a"": 8, ""b"": 8}
    msgs = [r.getMessage() for r in caplog.records]
    assert any(""Total hourly cost"" in m for m in msgs)
    end_msg = [m for m in msgs if ""Total hourly cost"" in m][0]
    assert ""8.00"" in end_msg and ""8.33"" in end_msg
    assert any(""Skip c"" in m for m in msgs)",tests/test_spot_gpu.py,,1,5.60279640614594e-09,"The method 'test_dry_run_respects_budget' is a unit test function that verifies the behavior of the 'SpotGPUAllocator' class when performing a dry run allocation. It checks that the allocation respects the budget by asserting the expected results and logging messages. Unit tests are crucial for ensuring code reliability and are typically retained in the codebase to maintain software quality. Therefore, this method is likely to be retained."
survived,"    async def stop_merkle_task(self) -> None:
        if self._task:
            self._task.cancel()
            try:
                await self._task
            except asyncio.CancelledError:  # pragma: no cover - expected
                pass
            self._task = None
",src/archive/service.py,ArchiveService,1,3.3982678079468468e-09,"The method 'stop_merkle_task' is well-structured and serves a clear purpose: it cancels an ongoing asynchronous task if it exists. This is a common pattern in asynchronous programming to ensure that resources are properly managed and tasks are not left running unnecessarily. The method also handles the potential 'CancelledError' exception, which is a good practice to ensure that the cancellation process is smooth and does not lead to unhandled exceptions. Given its utility and proper error handling, it is likely to be retained in the codebase."
survived,"def _parse_spec(spec: str) -> tuple[str, str]:
    if "":"" in spec:
        path, goal = spec.split("":"", 1)
    else:
        parts = spec.split(maxsplit=1)
        if len(parts) != 2:
            raise ValueError(""spec must contain 'path goal'"")
        path, goal = parts
    return path.strip(), goal.strip()
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/mutators/code_diff.py,,1,2.7894680920908113e-10,"The method '_parse_spec' is a utility function designed to parse a string into a tuple of two strings, 'path' and 'goal'. It handles two formats: one with a colon separator and another with a space separator. This kind of functionality is common in parsing configurations or command-line arguments, making it a useful and reusable piece of code. The method is well-defined, handles errors appropriately, and is likely to be used in various contexts where such parsing is needed. Therefore, it is likely to survive."
survived,"def test_latency_benchmark(benchmark: Any) -> None:
    service = DualCriticService([""alpha""])

    def run() -> None:
        service.score(""alpha"", ""alpha"")

    result = benchmark(run)
    p95 = 0.0
    if getattr(result, ""stats"", None) and result.stats[""data""]:
        p95 = quantiles(result.stats[""data""], n=20)[18]
    assert p95 >= 0.0",tests/test_critics.py,,1,3.3982678079468468e-09,"The method `test_latency_benchmark` is a test function that uses a benchmarking tool to measure the latency of a service. It is a specific test case that checks the 95th percentile latency of a service's scoring function. Such test functions are typically kept in the codebase to ensure performance benchmarks are met and to catch regressions in service performance. Therefore, it is likely to be Survived (1) as it serves a useful purpose in performance testing."
survived,"def _free_port() -> int:
    s = socket.socket()
    s.bind((""localhost"", 0))
    port = s.getsockname()[1]
    s.close()
    return port
",tests/test_critics.py,,1,2.2159489282323004e-08,"The method _free_port is a utility function that finds and returns a free port on the localhost. This is a common requirement in network programming, especially for testing purposes where a free port is needed to bind a server or service temporarily. The method is simple, effective, and does not have any apparent issues or redundancies that would warrant its deletion. It is likely to be useful in various scenarios where dynamic port allocation is necessary, thus it is more likely to be retained."
survived,"    def run() -> None:
        service.score(""alpha"", ""alpha"")
",tests/test_critics.py,,1,1.553497314502234e-06,"The method 'run' is a simple wrapper around a call to 'service.score' with hardcoded arguments. Without additional context, such as the purpose of 'service.score' or the flexibility required in its usage, it's difficult to determine its utility. However, if 'service.score' is a critical function and the arguments 'alpha' are frequently used defaults, this method could be useful for simplifying calls. If the method is part of a larger codebase where such calls are common, it might be retained for convenience. Otherwise, if the method lacks flexibility or is redundant, it might be deleted. Given the limited context, I'll predict it will be Survived (1) as it could serve a specific purpose in its current form."
survived,"        async def _critique(req: CritiqueRequest = Body(...)) -> Any:  # noqa: D401
            result = self.score(req.context, req.response)
            return JSONResponse(result)
",src/critics/dual_critic_service.py,DualCriticService,1,5.60279640614594e-09,"The method '_critique' is an asynchronous function that takes a 'CritiqueRequest' object as input and returns a JSON response with the result of a scoring operation. The method is likely to be part of a larger system that processes critique requests, possibly in a web service or API context. The use of asynchronous programming suggests that it is designed to handle multiple requests efficiently, which is a common requirement in modern web applications. The method appears to be well-structured and serves a clear purpose, making it likely to be retained in the codebase."
survived,"    def logic_score(self, context: str, response: str) -> float:
        """"""Return a naive logic score based on substring matching.""""""
        if not context or not response:
            return 0.0
        return 1.0 if response.lower() in context.lower() else 0.0
",src/critics/dual_critic_service.py,DualCriticService,1,1.955568070542584e-08,"The method 'logic_score' is a simple utility function that calculates a logic score based on substring matching between two strings. It is straightforward and serves a specific purpose, which is to determine if one string is a substring of another. This kind of functionality can be useful in various text processing or natural language processing tasks where a quick check for substring presence is needed. The method is not overly complex, does not have any apparent bugs, and fulfills a clear purpose. Therefore, it is likely to be retained in the codebase."
survived,"def __dir__() -> list[str]:  # pragma: no cover - environment driven
    """"""Return module attributes for ``dir()`` calls.""""""

    return sorted(list(globals().keys()) + __all__)",alpha_factory_v1/__init__.py,,1,2.1024340680345882e-07,"The method `__dir__` is a special method in Python that is used to customize the behavior of the `dir()` function. In this code, it is implemented to return a sorted list of global keys combined with `__all__`, which is a common pattern to control what is exposed when `dir()` is called on a module. The use of `# pragma: no cover` suggests that this method is environment-driven and might not be covered by tests, but it is still a valid and useful implementation. Therefore, it is likely to be retained in the codebase."
survived,"        def sendjson(self, *_a: object, **_kw: object) -> None:  # pragma: no cover - unused
            pass
",tests/test_alpha_agi_business_3_v1.py,DummySock,0,0.9999998874648162,"The method 'sendjson' is currently not implemented and is marked with a pragma directive 'no cover', indicating that it is intentionally left out of test coverage. This suggests that the method is either a placeholder for future implementation or is not needed in the current context. Without any implementation or usage, it is likely to be considered dead code. Therefore, it is more likely to be deleted unless there is a specific plan to implement it in the future."
survived,"            def add(self, instr: object) -> ""DummyTx"":
                self.instructions.append(instr)
                return self
",tests/test_insight_orchestrator_features.py,TestLedger.DummyTx,1,1.1032560311263802e-09,"The method 'add' is a simple utility function that appends an instruction to a list and returns the instance itself, allowing for method chaining. This is a common pattern in Python and is generally useful for building up a sequence of operations. There is no indication that this method is redundant or harmful, and it serves a clear purpose in managing a collection of instructions. Therefore, it is likely to be retained."
survived,"            async def send_transaction(self, tx: object, *args: object) -> None:
                captured[""root""] = tx.instructions[0].data.decode()
",tests/test_insight_orchestrator_features.py,TestLedger.DummyClient,1,6.348800075736417e-09,"The method 'send_transaction' is an asynchronous function that takes a transaction object and captures the data from the first instruction of the transaction. This functionality seems specific and useful for certain operations, such as logging or processing transaction data. Since it performs a specific task that might be integral to the application's operation, it is likely to be retained unless there is a significant change in the application's requirements or architecture."
survived,"def get_kill_after_minutes() -> int:
    """"""Return minutes after which to kill a running task.""""""
    return _load_config_timeout_minutes()
",anomstack/sensors/timeout.py,,0,0.9999898700118929,"The method `get_kill_after_minutes` is a simple wrapper around another function `_load_config_timeout_minutes`. It doesn't add any additional logic or functionality, making it redundant unless it serves a purpose such as providing a more descriptive name or acting as an interface. If `_load_config_timeout_minutes` is directly accessible and the descriptive name isn't necessary, this method might be considered for deletion. However, if it serves a purpose in terms of code readability or abstraction, it might be retained. Without more context, it's likely to be deleted due to its redundancy."
survived,"def test_authorize_button_state_mismatch(monkeypatch):
    st.session_state.clear()
    client = OAuth2(""id"", ""secret"", ""auth"", ""token"")
    oauth = OAuth2Component(client=client)

    monkeypatch.setattr(oauth.client, ""get_authorization_url"", AsyncMock(return_value=""http://auth""))
    monkeypatch.setattr(oauth.client, ""get_access_token"", AsyncMock(return_value={""access_token"": ""tok""}))
    monkeypatch.setattr(""streamlit_oauth._generate_state"", lambda key=None: ""GOOD"")
    monkeypatch.setattr(""streamlit_oauth._authorize_button"", lambda **kwargs: {""code"": ""CODE"", ""state"": ""BAD""})

    with pytest.raises(StreamlitOauthError):
        oauth.authorize_button(""Login"", ""http://cb"", ""scope"", key=""k"")
",tests/test_oauth_component.py,,1,1.725782769012759e-08,"The method 'test_authorize_button_state_mismatch' is a unit test designed to verify the behavior of the 'authorize_button' method when there is a state mismatch. It uses mocking to simulate the OAuth2 flow and checks if the correct exception is raised when the state does not match. This is a crucial test to ensure the security and correctness of the OAuth2 implementation, as state mismatches can lead to security vulnerabilities. Therefore, this test method is important for maintaining the integrity of the authentication process and is likely to be retained in the codebase."
survived,"    def test_fitness_reward_parses_sleep(self) -> None:
        evt = {""payload"": {""activity"": ""Sleep 7 h 45 m""}}
        val = demo._fitness_reward(evt)
        self.assertIsInstance(val, float)
",tests/test_era_experience.py,TestEraOfExperience,1,1.725782769012759e-08,"The method `test_fitness_reward_parses_sleep` is a unit test designed to verify the functionality of the `_fitness_reward` method in the `demo` module. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with data parsing and processing. This test checks if the method correctly interprets a sleep activity and returns a float value, which is a common requirement in fitness applications. Given the importance of testing in software development, this method is likely to be retained to maintain code quality and prevent future regressions."
survived,"    def forward(
        self, query: torch.Tensor, key: torch.Tensor, value: torch.Tensor, *, return_attn: bool = True, **kwargs
    ):
        if ""need_weights"" in kwargs:
            return_attn = kwargs.pop(""need_weights"")
        bsz, seq_len, _ = query.size()

        q = self.wq(query)
        k = self.wk(key)
        v = self.wv(value)

        q = self.split_heads(q, bsz)
        k = self.split_heads(k, bsz)
        v = self.split_heads(v, bsz)

        cos = self.cos_cached[:, :, :seq_len, :].to(q.dtype)
        sin = self.sin_cached[:, :, :seq_len, :].to(q.dtype)
        q = apply_rotary_pos_emb(q, cos, sin)
        k = apply_rotary_pos_emb(k, cos, sin)

        scores = torch.matmul(q, k.transpose(-2, -1)) / (self.head_dim ** 0.5)
        attn = F.softmax(scores, dim=-1)
        context = torch.matmul(attn, v)
        context = context.permute(0, 2, 1, 3).contiguous()
        context = context.view(bsz, seq_len, self.d_model)
        output = self.dense(context)

        if return_attn:
            return output, attn
        return output",src/model/u2tokenizer/rope.py,RotaryMultiheadAttention,1,7.194132978569833e-09,"The method is a typical implementation of a forward pass for a transformer-like model, specifically handling attention mechanisms. It includes key operations such as query, key, and value projections, splitting heads, applying rotary positional embeddings, computing attention scores, and returning the context. The method is well-structured and includes a useful feature to optionally return attention weights, which is often needed for interpretability in models. There are no apparent issues or redundancies that would necessitate its deletion. Instead, it provides essential functionality for models using attention mechanisms."
survived,"    def _reset_parameters(self):
        nn.init.xavier_uniform_(self.wq.weight)
        nn.init.xavier_uniform_(self.wk.weight)
        nn.init.xavier_uniform_(self.wv.weight)
        nn.init.xavier_uniform_(self.dense.weight)
        if self.wq.bias is not None:
            nn.init.zeros_(self.wq.bias)
        if self.wk.bias is not None:
            nn.init.zeros_(self.wk.bias)
        if self.wv.bias is not None:
            nn.init.zeros_(self.wv.bias)
        if self.dense.bias is not None:
            nn.init.zeros_(self.dense.bias)
",src/model/u2tokenizer/rope.py,RotaryMultiheadAttention,1,2.646573631904765e-09,"The method `_reset_parameters` is responsible for initializing the weights and biases of a neural network layer using Xavier uniform initialization and setting biases to zero. This is a common practice in neural network training to ensure that the model starts with weights that are neither too large nor too small, which helps in achieving better convergence during training. Since this method is crucial for setting up the initial state of the model's parameters, it is unlikely to be deleted unless the entire model architecture is being refactored or replaced. Therefore, it is expected to survive."
survived,"def linear_curve(t: float) -> float:
    return max(0.0, min(1.0, t))
",alpha_factory_v1/core/simulation/forecast.py,,1,1.8189616842444243e-09,"The method 'linear_curve' is a simple utility function that clamps a given float 't' between 0.0 and 1.0. Such functions are often useful in various applications, such as normalizing values, ensuring inputs remain within a specific range, or for graphical purposes. The function is straightforward, has a clear purpose, and is likely to be used in multiple contexts where value clamping is necessary. Therefore, it is likely to be retained in the codebase."
survived,"def span(name: str) -> ContextManager[Any]:
    """"""Return a context manager for ``name``.""""""
    if tracer:
        return cast(ContextManager[Any], tracer.start_as_current_span(name))
    return nullcontext()
",alpha_factory_v1/core/utils/tracing.py,,1,1.6052280526088547e-09,"The method 'span' is a utility function that provides a context manager for tracing operations. It checks if a tracer is available and uses it to start a span, otherwise it defaults to a null context. This kind of functionality is useful in applications that require tracing for monitoring or debugging purposes. Given the increasing importance of observability in software systems, such methods are likely to be retained and used. Therefore, the method will survive."
survived,"        def labels(self, *_a: Any, **_kw: Any) -> ""_N"":
            return self
",alpha_factory_v1/core/utils/tracing.py,_N,1,1.8189616842444243e-09,"The method 'labels' is a simple method that returns the instance itself. This pattern is often used in fluent interfaces or builder patterns where methods return the object to allow method chaining. The method does not perform any complex operations or have side effects, making it unlikely to be removed unless the entire class design changes. Therefore, it is likely to survive."
survived,"def test_repeat_within_day_high_score() -> None:
    _reset()
    res1 = {""context"": ""run 5k"", ""time"": ""2025-04-22T07:00:00Z""}
    res2 = {""context"": ""run 5k"", ""time"": ""2025-04-23T06:00:00Z""}
    hc.reward(None, None, res1)
    value = hc.reward(None, None, res2)
    assert 0.0 <= value <= 1.0
    assert value > 0.5
",tests/test_habit_consistency_reward.py,,1,9.237449576640118e-09,"The method `test_repeat_within_day_high_score` is a unit test designed to verify the behavior of a function `hc.reward` when called with two different timestamps. The test checks that the reward value is between 0.0 and 1.0 and specifically greater than 0.5. This kind of test is crucial for ensuring the correct functionality of the `reward` method, especially in scenarios where the timing of events is significant. Since it is a test method, it is unlikely to be deleted unless the functionality it tests is removed or significantly altered. Therefore, the method will likely survive."
survived,"def test_learning_event_in_range() -> None:
    state = DummyState()
    result = {""context"": ""duolingo spanish lesson"", ""duration"": 1800}
    value = ed.reward(state, None, result)
    assert isinstance(value, float)
    assert 0.0 <= value <= 1.0
",tests/test_education_reward.py,,1,2.3355930333443423e-09,"The method `test_learning_event_in_range` is a unit test that checks the functionality of the `ed.reward` method. It verifies that the method returns a float value within the expected range (0.0 to 1.0). Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with functions that return values within specific constraints. Therefore, this method is likely to be retained as it serves an important role in validating the behavior of the `ed.reward` function."
survived,"async def test_broadcast_merkle_root_devnet() -> None:
    if os.getenv(""PYTEST_NET_OFF"") == ""1"" or not await _devnet_available():
        pytest.skip(""network disabled or devnet unreachable"")
    tmp = tempfile.TemporaryDirectory()
    ledger = Ledger(os.path.join(tmp.name, ""l.db""), rpc_url=""https://api.devnet.solana.com"", broadcast=True)
    env = messaging.Envelope(""a"", ""b"", {""v"": 1}, 0.0)
    ledger.log(env)
    try:
        await ledger.broadcast_merkle_root()
    finally:
        await ledger.stop_merkle_task()
        ledger.close()
        tmp.cleanup()",tests/test_devnet_broadcast.py,,1,2.699578619062706e-07,"The method `test_broadcast_merkle_root_devnet` is an asynchronous test function that checks the broadcasting of a Merkle root to a devnet. It includes environment checks, resource management, and cleanup procedures, which are typical for robust test functions. The function is likely to be useful for ensuring the correct operation of the broadcasting feature in a development network environment. Given its utility in testing and validation, it is more likely to be maintained rather than deleted."
survived,"    def log(self, env: messaging.Envelope) -> None:  # type: ignore[override]
        self.logged.append(env)
",tests/test_safety_guardian_property.py,DummyLedger,1,8.592166611791576e-10,"The method 'log' is a simple implementation that appends an envelope to a list called 'logged'. It is a straightforward logging mechanism that is likely used for tracking or debugging purposes. Such methods are generally useful in development and production environments for monitoring and are unlikely to be removed unless the logging mechanism is completely overhauled or replaced. Therefore, it is more likely to survive."
survived,"        async def grab_two() -> float:
            gen = demo.experience_stream()
            t1 = time.perf_counter()
            await anext(gen)
            t2 = time.perf_counter()
            await anext(gen)
            t3 = time.perf_counter()
            return (t2 - t1 + t3 - t2) / 2
",tests/test_era_experience.py,TestEraOfExperience,1,2.998960815863541e-09,"The method 'grab_two' is likely to be Survived (1) because it is a well-structured asynchronous function that measures the time taken to retrieve two items from an asynchronous generator. This kind of utility function can be useful for performance monitoring or benchmarking asynchronous operations, which is a common requirement in modern software development. The function is concise, uses standard library functions, and follows good practices for asynchronous programming."
survived,"def test_dist_self_contained() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri()
    with sync_playwright() as p:
        browser = p.chromium.launch()
        page = browser.new_page()
        page.goto(url)
        page.wait_for_selector(""#controls"")
        attrs = page.eval_on_selector_all(
            ""script[src], link[href]"",
            ""els => els.map(e => e.getAttribute('src') || e.getAttribute('href'))"",
        )
        assert all("".."" not in a for a in attrs)
        browser.close()",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_dist_self_contained.py,,1,3.3982678079468468e-09,"The method `test_dist_self_contained` is a test function that checks if all script and link elements in a specific HTML file are self-contained, meaning they do not reference any parent directories ("".."" in their paths). This is a useful test to ensure that the distribution package is correctly packaged without external dependencies. The function uses Playwright to automate a browser for this purpose, which is a common practice in modern web testing. Given its utility in ensuring the integrity of a web distribution package, it is likely to be retained in the codebase."
survived,"    async def step(self) -> None:  # noqa: D401
        """"""Delegate step execution to :meth:`run_cycle`.""""""
        await self.run_cycle()
",alpha_factory_v1/backend/agents/smart_contract_agent.py,SmartContractAgent,1,3.3982678079468468e-09,"The method 'step' is a simple asynchronous function that delegates its execution to another method 'run_cycle'. It is likely part of a larger class or module where 'run_cycle' is defined. The method is straightforward and serves a clear purpose, which is to encapsulate the call to 'run_cycle' in an asynchronous context. There is no indication that this method is redundant or unnecessary, as it provides a clear entry point for executing 'run_cycle' asynchronously. Therefore, it is likely to be retained in the codebase."
survived,"    async def emit(self, recipient: str, payload: Any) -> None:
        env = messaging.Envelope(self.name, recipient, payload, time.time())
        self.ledger.log(env)
        self.bus.publish(recipient, env)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/base_agent.py,BaseAgent,1,5.60279640614594e-09,"The method 'emit' is a straightforward implementation of a messaging system where it creates an envelope with the given recipient and payload, logs it, and then publishes it to a bus. This method is likely to be essential for the functionality of the system, as it handles the core task of message transmission. There are no apparent issues with the code, and it seems to be a necessary part of the system's operation. Therefore, it is likely to be retained."
survived,"def evaluate(pop: Population, fn: Callable[[List[float]], Tuple[float, float]]) -> None:
    for ind in pop:
        ind.fitness = fn(ind.genome)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/simulation/mats.py,,1,2.0611536181902033e-09,"The method 'evaluate' is a simple and clear implementation that assigns a fitness value to each individual in a population based on a given function. This is a common operation in genetic algorithms and evolutionary computation, where evaluating the fitness of individuals is crucial for selection and evolution processes. The method is generic and can be applied to various types of problems, making it versatile and useful. Therefore, it is likely to be retained in the codebase."
survived,"    async def run_cycle(self) -> None:
        pass
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/safety_agent.py,SafetyGuardianAgent,1,1.7603431343301488e-06,"The method `run_cycle` is defined as an asynchronous function but currently contains only a `pass` statement, meaning it does not perform any operations. However, the method is likely a placeholder for future implementation, especially given its asynchronous nature, which suggests it is intended to handle operations that may involve waiting for I/O or other asynchronous tasks. The presence of the method indicates that it is part of a larger class or module where asynchronous operations are expected. Therefore, it is more likely to be retained and implemented in the future rather than deleted."
survived,"async def _main() -> None:  # pragma: no cover - CLI helper
    orch = Orchestrator()
    await orch.run_forever()
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/orchestrator.py,,1,1.725782769012759e-08,"The method _main is an asynchronous function that serves as a CLI helper, indicated by the comment 'pragma: no cover'. This suggests that the function is not intended to be covered by unit tests, which is common for entry-point functions or scripts. The function creates an instance of an Orchestrator and calls its run_forever method, which implies it is designed to run continuously, likely as part of a larger application or service. Since it serves a specific purpose in the application's architecture, it is unlikely to be deleted unless the entire application structure changes or the functionality is no longer needed. Therefore, it is more likely to survive."
survived,"def _non_dominated_sort(pop: Population) -> List[Population]:
    fronts: List[Population] = []
    S = {id(ind): [] for ind in pop}
    n = {id(ind): 0 for ind in pop}
    for p in pop:
        for q in pop:
            if p is q:
                continue
            if all(pf <= qf for pf, qf in zip(p.fitness, q.fitness)):  # type: ignore[arg-type]
                if any(pf < qf for pf, qf in zip(p.fitness, q.fitness)):  # type: ignore[arg-type]
                    S[id(p)].append(q)
            elif all(qf <= pf for pf, qf in zip(p.fitness, q.fitness)):  # type: ignore[arg-type]
                if any(qf < pf for pf, qf in zip(p.fitness, q.fitness)):  # type: ignore[arg-type]
                    n[id(p)] += 1
        if n[id(p)] == 0:
            p.rank = 0
            if not fronts:
                fronts.append([])
            fronts[0].append(p)
    i = 0
    while i < len(fronts):
        nxt: Population = []
        for p in fronts[i]:
            for q in S[id(p)]:
                n[id(q)] -= 1
                if n[id(q)] == 0:
                    q.rank = i + 1
                    nxt.append(q)
        if nxt:
            fronts.append(nxt)
        i += 1
    return fronts
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/simulation/mats.py,,1,1.522997951276035e-08,"The method '_non_dominated_sort' is a key component in multi-objective optimization algorithms, particularly in evolutionary algorithms like NSGA-II. It is responsible for sorting a population into different fronts based on dominance, which is crucial for selecting the best solutions in a multi-objective context. This functionality is fundamental for the operation of such algorithms, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained in the codebase."
survived,"    def clients(self) -> List[GeminiClientWrapper]:
        """"""Return managed clients.""""""
        return self._clients
",app/services/pool.py,GeminiClientPool,1,8.592166611791576e-10,"The method 'clients' is a simple getter method that returns a list of managed clients. Getter methods are generally useful for encapsulation and providing controlled access to class attributes. Since this method is straightforward and serves a clear purpose, it is likely to be retained in the codebase unless there is a significant change in design or architecture that makes it redundant. Therefore, it is predicted to survive."
survived,"    def test_save_equity_cache_logs_error(self) -> None:
        with patch(""pathlib.Path.write_text"", side_effect=IOError(""boom"")) as mock_write:
            with patch.object(rm._LOG, ""debug"") as mock_log:
                rm._save_equity_cache([1.0, 2.0])
                mock_log.assert_called()
            mock_write.assert_called()
",tests/test_risk_management.py,TestRiskManagementCache,1,1.522997951276035e-08,"The method 'test_save_equity_cache_logs_error' is a unit test designed to verify that an error is logged when an IOError occurs during the execution of '_save_equity_cache'. This is a typical and necessary test to ensure that the logging mechanism works correctly in error scenarios. Such tests are crucial for maintaining robust error handling in software, and they are unlikely to be deleted unless the functionality they test is removed or significantly altered. Therefore, the method is likely to survive."
survived,"    def update_window_region(self):
        '''
        Update window region
        '''
        self.region = get_window_region(self.window_title)
        if self.region is None:
            text = f""Cannot find window: {self.window_title}""
            logger.error(text)
            raise RuntimeError(text)
",src/input/GameWindowCapturorForMac.py,GameWindowCapturor,1,2.4616969512093895e-10,"The method 'update_window_region' is likely to survive because it performs a critical function of updating the window region based on the window title. It includes error handling to log and raise an exception if the window cannot be found, which is important for debugging and maintaining the robustness of the application. The method is concise, clear, and serves a specific purpose, making it a valuable part of the codebase."
survived,"    def is_in_rune_game(self):
        '''
        is_in_rune_game
        '''
        # Get lastest game screen frame buffer
        self.frame = self.capture.get_frame()
        # Resize game screen to 1296x759
        self.img_frame = cv2.resize(self.frame, (1296, 759), interpolation=cv2.INTER_NEAREST)

        # Crop arrow detection box
        x, y = self.cfg.arrow_box_start_point
        size = self.cfg.arrow_box_size
        img_roi = self.img_frame[y:y+size, x:x+size]

        # Check if arrow exist on screen
        best_score = float('inf')
        for direc, arrow_list in self.img_arrows.items():
            for img_arrow in arrow_list:
                _, score, _ = find_pattern_sqdiff(
                                img_roi, img_arrow,
                                mask=get_mask(img_arrow, (0, 255, 0)))
                if score < best_score:
                    best_score = score

        draw_rectangle(
            self.img_frame_debug, (x, y), (size, size),
            (0, 0, 255), str(round(best_score, 2))
        )

        if best_score < self.cfg.arrow_box_diff_thres:
            logger.info(f""Arrow screen detected with score({score})"")
            return True
        return False
",src/legacy/mapleStoryAutoLevelUp_legacy.py,MapleStoryBot,1,2.0611536181902033e-09,"The method 'is_in_rune_game' is likely to survive because it appears to be a well-defined function with a clear purpose: detecting if a specific game screen is active by analyzing the presence of an arrow. It uses image processing techniques to achieve this, which is a common requirement in game automation or testing scenarios. The method is also structured with logging for debugging purposes, indicating its utility in a larger system. Unless the entire feature it supports is deprecated, this method is likely to remain useful."
survived,"        def latest_log(self) -> str:
            return self.llm(""hi"") if self.llm else ""done""
",tests/test_aiga_openai_bridge_offline.py,DummyEvolver,1,2.3355930333443423e-09,"The method 'latest_log' is a simple utility function that checks if the 'llm' attribute is present and callable, and if so, calls it with the argument 'hi'. If 'llm' is not present or callable, it returns the string 'done'. This method is straightforward and provides a clear functionality that could be useful in various contexts where checking and calling a method conditionally is needed. Therefore, it is likely to be retained in the codebase."
survived,"    def log(self, env) -> None:  # type: ignore[override]
        self.events.append(env.payload.get(""event""))
",tests/test_alert_webhook.py,DummyLedger,1,8.152020648014727e-09,"The method 'log' is a simple function that appends an event from the 'env' object to the 'events' list. It is likely part of a larger system where logging events is necessary for tracking or debugging purposes. The use of 'type: ignore[override]' suggests that this method is intentionally overriding a method from a superclass, and the developer is aware of the type mismatch but has chosen to ignore it. This indicates that the method serves a specific purpose and is intentionally designed this way. Therefore, it is likely to be retained in the codebase."
survived,"def _build_local_site(repo_root: Path) -> bool:
    script = repo_root / ""scripts"" / ""build_gallery_site.sh""
    if not script.is_file():
        return False
    try:
        subprocess.run([str(script)], check=True)
    except Exception:
        return False
    return True
",scripts/launch_gallery.py,,1,1.1032560311263802e-09,"The method '_build_local_site' is likely to survive because it performs a specific and useful function: it checks for the existence of a script file and attempts to run it. This is a common pattern in build or deployment scripts, and unless there is a significant change in the way the system handles these operations, this method will remain relevant. Additionally, it handles exceptions gracefully, which is a good practice in scripting."
survived,"    def test_mdot(self):
        a = np.eye(2)
        b = np.array([[2, 0], [0, 2]])
        result = common.mdot(a, b)
        np.testing.assert_array_equal(result, b)
",tests/test_common.py,TestCommonFunctions,1,1.0467401685178159e-08,"The method `test_mdot` is a unit test for the `common.mdot` function, which appears to be a matrix multiplication operation. The test checks if the multiplication of an identity matrix `a` with another matrix `b` results in `b`, which is a valid and important test case for matrix operations. Unit tests are crucial for ensuring code reliability and correctness, especially in mathematical operations. Therefore, this method is likely to be retained as part of the test suite to ensure the `mdot` function works as expected."
survived,"    def test_anorm(self):
        vec = np.array([3.0, 4.0])
        self.assertAlmostEqual(common.anorm(vec), 5.0)
        self.assertAlmostEqual(common.anorm2(vec), 25.0)
",tests/test_common.py,TestCommonFunctions,1,2.8453347280241004e-08,"The method `test_anorm` is a unit test that checks the functionality of two methods, `common.anorm` and `common.anorm2`. It verifies that `common.anorm` correctly calculates the Euclidean norm (or magnitude) of a vector, and `common.anorm2` calculates the squared norm. These are fundamental operations in numerical computing and linear algebra, and having tests for them is crucial to ensure their correctness. Since the test is straightforward and tests essential functionality, it is likely to be retained in the codebase."
survived,"def test_agents_list_offline(non_network: None) -> None:
    """"""Verify /agents lists all required demo agents.""""""
    os.environ[""NO_LLM""] = ""1""
    os.environ.setdefault(""ALPHA_ASI_SILENT"", ""1"")
    os.environ.setdefault(""ALPHA_ASI_MAX_STEPS"", ""1"")

    mod = importlib.import_module(""alpha_factory_v1.demos.alpha_asi_world_model.alpha_asi_world_model_demo"")
    client = TestClient(cast(Any, mod.app))

    resp = client.get(""/agents"")
    assert resp.status_code == 200
    agents = resp.json()
    expected = {
        ""PlanningAgent"",
        ""ResearchAgent"",
        ""StrategyAgent"",
        ""MarketAnalysisAgent"",
        ""CodeGenAgent"",
        ""SafetyAgent"",
    }
    assert expected.issubset(set(agents))",tests/test_world_model_demo.py,,1,1.725782769012759e-08,"The method `test_agents_list_offline` is a test function that verifies the functionality of an endpoint in a web application. It sets up the environment, imports the necessary module, and uses a test client to make a GET request to the `/agents` endpoint. The response is then checked to ensure it contains the expected agents. This is a typical structure for a unit test in a web application, and such tests are crucial for ensuring the reliability and correctness of the application. Therefore, it is likely to be retained as part of the test suite."
survived,"    def test_new_version_ok(self) -> None:
        fake_mod = types.SimpleNamespace(__version__=""0.0.15"")
        orig_import_module = importlib.import_module
        orig_find_spec = importlib.util.find_spec

        def _fake_import(name: str, *args: Any, **kwargs: Any) -> object:
            if name == ""openai_agents"":
                return fake_mod
            return orig_import_module(name, *args, **kwargs)

        def _fake_find_spec(name: str, *args: Any, **kwargs: Any) -> object:
            if name == ""openai_agents"":
                return object()
            return orig_find_spec(name, *args, **kwargs)

        with (
            mock.patch(""importlib.import_module"", side_effect=_fake_import),
            mock.patch(""importlib.util.find_spec"", side_effect=_fake_find_spec),
        ):
            self.assertTrue(preflight.check_openai_agents_version())
",tests/test_preflight_openai_agents_version.py,TestPreflightOpenAIAgentsVersion,1,1.6052280526088547e-09,"The method 'test_new_version_ok' is a unit test designed to verify the behavior of the 'preflight.check_openai_agents_version()' function. It uses mocking to simulate the presence of a specific version of a module ('openai_agents') and checks if the function under test behaves correctly with this mocked version. This is a common practice in testing to ensure that code behaves as expected under controlled conditions. Since testing is a crucial part of software development to ensure code reliability and correctness, this method is likely to be retained as part of the test suite."
survived,"def temp_path():
    path = REPO_ROOT / ""tmp_tools_undo.txt""
    try:
        yield path
    finally:
        if path.exists():
            path.unlink()
",tests/test_tools_undo.py,,1,5.60279640614594e-09,"The method 'temp_path' is a generator function that creates a temporary file path and ensures its cleanup after use. This is a common pattern for managing temporary resources, ensuring that no leftover files remain after the operation. Such utility functions are often useful in various scenarios where temporary files are needed, such as testing or temporary data processing. Therefore, it is likely to be retained in the codebase."
survived,"def _record_history(p: Path) -> None:
    """"""Save the current contents of ``p`` for undo.""""""
    _EDIT_HISTORY.append((p, p.read_text(encoding=""utf-8"", errors=""replace"")))
",src/self_edit/tools.py,,1,2.646573631904765e-09,"The method _record_history is a private utility function indicated by the underscore prefix, suggesting it's intended for internal use within a module or class. Its purpose is to append the current contents of a file (specified by the path 'p') to a global list '_EDIT_HISTORY'. This functionality is useful for implementing an undo feature, which is a common requirement in applications that allow file editing. Since the method serves a clear purpose and is likely part of a larger system that requires tracking changes for undo operations, it is unlikely to be deleted unless the entire undo feature is removed or refactored. Therefore, the method is predicted to survive."
survived,"def test_undo_multiple_edits(temp_path: Path) -> None:
    temp_path.write_text(""alpha\nbeta\n"")
    replace_str(temp_path, ""alpha"", ""A"")
    first = temp_path.read_text()
    edit(temp_path, 1, 2, ""B"")
    assert undo_last_edit() is True
    assert temp_path.read_text() == first
    assert undo_last_edit() is True
    assert temp_path.read_text() == ""alpha\nbeta\n""
    replace(temp_path, ""A"", ""alpha"")
    insert_after(temp_path, ""alpha"", ""gamma"")
    assert ""gamma"" in temp_path.read_text()
    assert undo_last_edit() is True
    assert ""gamma"" not in temp_path.read_text()
    assert undo_last_edit() is False
    assert temp_path.read_text() == ""alpha\nbeta\n""
    assert view_lines(temp_path, 1, 2) == ""alpha\nbeta""",tests/test_tools_undo.py,,1,2.8453347280241004e-08,"The method 'test_undo_multiple_edits' is a test function that verifies the functionality of undoing multiple edits on a file. It is a well-structured test case that checks various scenarios of editing and undoing changes to ensure the correctness of the undo functionality. Such test cases are crucial for maintaining the reliability of the codebase, especially when dealing with file operations that can have significant consequences if not handled correctly. Therefore, it is unlikely to be deleted as it serves an important role in validating the behavior of the code."
survived,"    def list_entries(self) -> List[Tuple[int, str, str, int]]:
        with sqlite3.connect(self.db_path) as cx:
            rows = list(cx.execute(""SELECT id, path, cid, pinned FROM tarballs ORDER BY id""))
        return [(int(r[0]), str(r[1]), str(r[2]), int(r[3])) for r in rows]
",src/archive/hash_archive.py,HashArchive,1,6.69158608681505e-10,"The method 'list_entries' is a straightforward database query method that retrieves data from a SQLite database and returns it in a structured format. It is likely to survive because it performs a necessary function of fetching and formatting data, which is a common requirement in applications that interact with databases. The method is also well-structured, using context management for database connections and comprehensions for data processing, which are good practices in Python programming."
survived,"def publish_proof(
    transcript_path: str | Path,
    agent_hash: str,
    score: Sequence[float],
    db: ""ArchiveDB"",
) -> str:
    """"""Generate proof, publish to IPFS and store CID in ``db``.""""""
    proof = generate_proof(transcript_path, agent_hash, score)
    proof_path = Path(transcript_path).with_suffix("".proof"")
    proof_path.write_text(proof, encoding=""utf-8"")
    cid = _ipfs_add(proof_path)
    db.set_state(f""snark:{agent_hash}"", cid)
    return cid
",src/utils/snark.py,,1,1.1032560311263802e-09,"The method 'publish_proof' is likely to survive because it performs a specific and useful function: generating a proof, publishing it to IPFS, and storing the CID in a database. This functionality is relevant for applications that require decentralized storage and verification, such as blockchain or distributed ledger technologies. The method is well-defined, uses type hints for clarity, and interacts with external systems (IPFS and a database), indicating it is part of a larger, potentially critical system."
survived,"    def set_proof_cid(self, agent_hash: str, cid: str) -> None:
        """"""Store the IPFS CID of the SNARK proof for ``agent_hash``.""""""
        self.set_state(f""snark:{agent_hash}"", cid)
",src/archive/db.py,ArchiveDB,1,2.2159489282323004e-08,"The method 'set_proof_cid' is a simple setter function that stores a given CID (Content Identifier) associated with an agent hash in a state. This is a common pattern in systems that interact with IPFS (InterPlanetary File System) or similar decentralized storage systems. The method is likely to be useful for maintaining a mapping between agent hashes and their corresponding proof CIDs, which is essential for data retrieval and verification processes. Therefore, it is likely to be retained in the codebase."
survived,"    def get_proof_cid(self, agent_hash: str) -> str | None:
        """"""Return the stored proof CID for ``agent_hash`` if present.""""""
        return self.get_state(f""snark:{agent_hash}"")",src/archive/db.py,ArchiveDB,1,1.1861120010657661e-08,"The method `get_proof_cid` is a simple utility function that retrieves a stored proof CID based on an `agent_hash`. It is likely to be useful in contexts where proofs are stored and need to be retrieved by a unique identifier. The method is straightforward, has a clear purpose, and is likely to be used in various parts of the codebase where proof retrieval is necessary. Therefore, it is unlikely to be deleted unless the entire functionality it supports is deprecated or refactored."
survived,"def _gen_crc8_table(poly: int) -> list[int]:
  table = []
  for i in range(256):
    crc = i
    for _ in range(8):
      if crc & 0x80:
        crc = ((crc << 1) ^ poly) & 0xFF
      else:
        crc = (crc << 1) & 0xFF
    table.append(crc)
  return table
",opendbc/car/crc.py,,1,2.5109990926928157e-08,"The method _gen_crc8_table is a utility function that generates a CRC-8 table based on a given polynomial. This type of function is often used in applications that require error-checking and data integrity verification, such as communication protocols and data storage systems. The function is well-defined, performs a specific task, and is likely to be useful in contexts where CRC-8 checksums are needed. Therefore, it is unlikely to be deleted as it serves a practical purpose."
survived,"    def test_invalid_env_ports_default(self) -> None:
        env = {""PORT"": ""0"", ""METRICS_PORT"": ""-1"", ""A2A_PORT"": ""0""}
        with patch.dict(os.environ, env, clear=True):
            args = edge_runner.parse_args([])
        self.assertEqual(args.port, 8000)
        self.assertIsNone(args.metrics_port)
        self.assertIsNone(args.a2a_port)
",tests/test_edge_runner_cli.py,TestParseArgs,1,9.736200303530205e-10,"The method `test_invalid_env_ports_default` is a unit test designed to verify the behavior of a function when environment variables are set to invalid port numbers. It checks that the default values are used when invalid ports are provided. This is a useful test to ensure robustness and correct handling of edge cases in the application. Since it serves a clear purpose in validating the application's behavior under specific conditions, it is likely to be retained in the codebase."
survived,"    def test_invalid_numeric_fallback(self) -> None:
        env = {
            ""DEV_MODE"": ""true"",
            ""PORT"": ""foo"",
            ""METRICS_PORT"": ""bar"",
            ""A2A_PORT"": ""baz"",
            ""ALPHA_CYCLE_SECONDS"": ""qux"",
            ""MAX_CYCLE_SEC"": ""zap"",
            ""ALPHA_MODEL_MAX_BYTES"": ""oops"",
        }
        with mock.patch.dict(os.environ, env, clear=True):
            orch = importlib.reload(
                importlib.import_module(""alpha_factory_v1.backend.orchestrator"")
            )
        self.assertEqual(orch.PORT, 8000)
        self.assertEqual(orch.METRICS_PORT, 0)
        self.assertEqual(orch.A2A_PORT, 0)
        self.assertEqual(orch.CYCLE_DEFAULT, 60)
        self.assertEqual(orch.MAX_CYCLE_SEC, 30)
        self.assertEqual(orch.MODEL_MAX_BYTES, 64 * 1024 * 1024)
",tests/test_orchestrator_env.py,TestOrchestratorEnv,1,4.0586521248284276e-10,"The method 'test_invalid_numeric_fallback' is a unit test designed to verify that the system correctly falls back to default values when invalid numeric values are provided in the environment variables. This is a crucial aspect of ensuring robustness and reliability in software, as it prevents the application from crashing or behaving unpredictably due to incorrect configurations. Unit tests like this are essential for maintaining code quality and are unlikely to be deleted unless the functionality they test is removed or significantly altered. Therefore, the method is likely to survive."
survived,"    def generate_report(self, result: CollectionResult, output_format: str = ""text"") -> str:
        """"""Generate a formatted report for a result.""""""
        summary = self.summarize(result)
        if output_format == ""json"":
            return self.to_json(summary)
        if output_format == ""html"":
            return self.to_html(summary)
        return self.to_text(summary)",src/meta_agent/evaluation/reporting.py,ReportingModule,1,2.7894680920908113e-10,"The method 'generate_report' is likely to survive because it provides a flexible way to generate reports in different formats (text, JSON, HTML), which is a common requirement in many applications. The method is well-structured, with clear responsibilities for each output format, making it easy to maintain and extend if new formats are needed in the future. Additionally, the use of a default parameter value for 'output_format' enhances its usability."
survived,"def test_execute_and_collect_logs(monkeypatch, tmp_path, caplog):
    fake_exec = MagicMock()
    fake_exec.run_tests.return_value = ExecutionResult(0, ""out"", ""err"")
    module = ResultCollectionModule(fake_exec)
    with caplog.at_level(""INFO"", logger=""meta_agent.evaluation.result_collection""):
        module.execute_and_collect(tmp_path)
    assert any(
        ""Executing and collecting results"" in r.getMessage() for r in caplog.records
    )",tests/unit/test_result_collection_module.py,,1,3.3982678079468468e-09,"The method 'test_execute_and_collect_logs' is a unit test function that uses mocking and logging to verify the behavior of the 'execute_and_collect' method in the 'ResultCollectionModule'. It is a well-structured test that checks if the logging occurs as expected during the execution of the method. Unit tests are crucial for ensuring code reliability and are typically not deleted unless they are redundant or replaced by more comprehensive tests. Therefore, this method is likely to be retained."
survived,"    def __init__(self) -> None:
        self.logger = logging.getLogger(__name__)
",src/meta_agent/evaluation/reporting.py,ReportingModule,1,4.4508487281649027e-07,"The method is a constructor for a class, initializing a logger object. Constructors are essential for setting up initial states of objects in object-oriented programming. This method is likely to be used frequently to ensure that each instance of the class has its own logger. Therefore, it is unlikely to be deleted."
survived,"def evolve(state, ruleNum):
    out = []
    p = 0
    while p < 10:
        b = 0
        q = 7
        while q >= 0:
            st = state
            b = b + st[0] * pow2(q)
            next = []
            i = 0
            while i < n:
                lidx = i - 1
                if lidx < 0:
                    lidx = n - 1
                left = st[lidx]
                center = st[i]
                ridx = i + 1
                if ridx >= n:
                    ridx = 0
                right = st[ridx]
                index = left * 4 + center * 2 + right
                next = next + [ruleBit(ruleNum, index)]
                i = i + 1
            state = next
            q = q - 1
        out = out + [b]
        p = p + 1
    return out
",tests/rosetta/transpiler/Python/elementary-cellular-automaton-random-number-generator.py,,0,0.9999999865595903,"The method 'evolve' is likely to be deleted because it contains several issues that make it non-functional and difficult to understand. Firstly, the variable 'n' is used without being defined, which will cause a runtime error. Additionally, the function 'pow2' is called but not defined within the code, leading to another error. The logic for updating the 'state' and calculating 'b' is also unclear and seems incorrect, as it relies on undefined or improperly used variables and functions. These issues suggest that the code is not in a usable state and would require significant revision to function correctly, making it a candidate for deletion."
survived,"def entropy(data):
    if data == """":
        return 0.0
    counts = {}
    i = 0
    while i < len(data):
        ch = data[i:i + 1]
        if ch in counts:
            counts[ch] = counts[ch] + 1
        else:
            counts[ch] = 1
        i = i + 1
    e = 0.0
    l = float(len(data))
    for ch in counts:
        px = (float(counts[ch])) / l
        if px > 0.0:
            e = e - px * log2(px)
    return e
",tests/rosetta/transpiler/Python/entropy-narcissist.py,,1,1.725782769012759e-08,"The method calculates the entropy of a given string, which is a measure of the unpredictability or information content. This is a fundamental concept in information theory and has various applications in data analysis, cryptography, and machine learning. The code is straightforward and performs its task efficiently, making it a useful utility function. Therefore, it is likely to be retained in the codebase."
survived,"def outputState(state):
    line = """"
    i = 0
    while i < len(state):
        if state[i:i + 1] == ""1"":
            line = line + ""#""
        else:
            line = line + "" ""
        i = i + 1
    print(line)
",tests/rosetta/transpiler/Python/elementary-cellular-automaton.py,,1,2.4616969512093895e-10,"The method 'outputState' is a simple function that takes a string 'state' and converts it into a visual representation using '#' for '1' and ' ' for any other character. This kind of function is often used in visualizing binary states or patterns, which can be useful in various applications such as debugging, visualizing data, or creating simple text-based graphics. The function is straightforward, does not have any apparent bugs, and serves a clear purpose. Therefore, it is likely to be retained in the codebase."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/egyptian-division.py,,1,2.2159489282323004e-08,"The method _now() is a utility function that generates a pseudo-random number based on a seed if _now_seeded is True, otherwise it returns the current time in nanoseconds. This function seems to be a part of a larger system that might require deterministic behavior for testing or simulation purposes when seeded, and real-time behavior otherwise. Such utility functions are often retained in codebases for their flexibility and utility in different scenarios. Unless there is a specific reason to remove it, such as redundancy or a shift in design requirements, it is likely to survive."
survived,"def printMatrix(heading, m):
    print(heading)
    i = 0
    while i < len(m):
        print(rowString(m[i]))
        i = i + 1
",tests/rosetta/transpiler/Python/element-wise-operations.py,,1,9.237449576640118e-09,"The method 'printMatrix' is a simple utility function that prints a heading followed by each row of a matrix. It is a straightforward and useful function for displaying matrices, which is a common requirement in many applications, especially those involving data processing or mathematical computations. The function is not overly complex, does not have any apparent bugs, and serves a clear purpose. Therefore, it is likely to be retained in the codebase."
survived,"def mul(a, b):
    return a * b
",tests/rosetta/transpiler/Python/element-wise-operations.py,,1,1.0467401685178159e-08,"The method 'mul' is a simple and efficient implementation of a multiplication function, which is a fundamental operation in programming. It is likely to be used frequently in various contexts where multiplication is needed. There is no redundancy or inefficiency in the code, and it serves a clear purpose. Therefore, it is unlikely to be deleted."
survived,"def mul(p, n):
    r = zero()
    q = p
    k = n
    while k > 0:
        if k % 2 == 1:
            r = add(r, q)
        q = dbl(q)
        k = k // 2
    return r
",tests/rosetta/transpiler/Python/elliptic-curve-arithmetic.py,,1,3.2241866333029355e-08,"The method 'mul' implements a multiplication algorithm using a combination of addition and doubling, which is a common technique known as the ""Russian Peasant Multiplication"" or ""Exponentiation by Squaring"". This method is efficient for multiplying large numbers or in contexts where addition and doubling are more efficient operations than direct multiplication. The method is likely to be useful in various computational scenarios, especially in cryptographic algorithms or systems dealing with large integers. Therefore, it is likely to be retained in the codebase."
survived,"def test_fstringify_files_charcount(tmp_path, monkeypatch):
    source = ""'{}'.format(1)\n""
    f = tmp_path / ""a.py""
    f.write_text(source)

    captured = {}

    def fake_print_report(state, found_files, changed_files, total_cc_new, total_cc_original, total_expr, total_time):
        captured[""new""] = total_cc_new
        captured[""orig""] = total_cc_original

    monkeypatch.setattr(api, ""_print_report"", fake_print_report)

    state = State()
    api.fstringify_files([str(f)], state)

    assert captured[""orig""] == len(source)
    assert captured[""new""] == len(""f'{1}'\n"")",test/integration/test_api.py,,1,2.3823698451773172e-07,"The method `test_fstringify_files_charcount` is a unit test function that verifies the functionality of the `fstringify_files` method from the `api` module. It checks if the character count of the source code before and after conversion to f-strings is as expected. This is a typical test case that ensures the correctness of a specific feature, which is crucial for maintaining code quality and reliability. Therefore, it is unlikely to be deleted as it serves an important role in the testing suite."
survived,"    def test_best_only_sorting(self):
        data = [
            {""alpha"": ""low"", ""score"": 1},
            {""alpha"": ""high"", ""score"": 5}
        ]
        tmp = Path(""/tmp/opps2.json"")
        tmp.write_text(json.dumps(data), encoding=""utf-8"")
        os.environ[""ALPHA_OPPS_FILE""] = str(tmp)
        os.environ[""ALPHA_BEST_ONLY""] = ""1""
        try:
            agent = biz.AlphaOpportunityAgent()
            self.assertEqual(agent._opportunities[0][""alpha""], ""high"")
        finally:
            del os.environ[""ALPHA_OPPS_FILE""]
            del os.environ[""ALPHA_BEST_ONLY""]
            tmp.unlink()
",tests/test_alpha_opportunity_env.py,TestAlphaOpportunityEnv,1,4.944450477491054e-09,"The method 'test_best_only_sorting' is a unit test that verifies the functionality of sorting opportunities based on a specific condition. It sets up a temporary environment, creates a JSON file with test data, and checks if the 'AlphaOpportunityAgent' correctly identifies the highest scoring opportunity. This is a typical and necessary test to ensure the correct behavior of the sorting logic in the application. Therefore, it is likely to be retained as part of the test suite to maintain code quality and reliability."
survived,"def main() -> None:
    runtime = AgentRuntime(api_key=None)
    agent = AlphaDiscoveryAgent()
    runtime.register(agent)
    print(""Registered AlphaDiscoveryAgent with runtime"")
    runtime.run()
",alpha_factory_v1/demos/aiga_meta_evolution/alpha_opportunity_stub.py,,1,9.237449576640118e-09,"The method is a simple main function that initializes and registers an agent with a runtime, then runs the runtime. This is a typical setup for an application using an agent-based architecture. The method is straightforward, does not contain any deprecated or problematic code, and serves a clear purpose in the context of initializing and running an agent. Therefore, it is likely to be retained in the codebase."
survived,"def main() -> None:
    ap = argparse.ArgumentParser(description=""Launch the AI-GA meta-evolution demo"")
    ap.add_argument(""--pull"", action=""store_true"", help=""pull signed image instead of building"")
    ap.add_argument(""--gpu"", action=""store_true"", help=""enable NVIDIA runtime"")
    ap.add_argument(""--logs"", action=""store_true"", help=""tail container logs after start-up"")
    ap.add_argument(""--reset"", action=""store_true"", help=""remove volumes and images"")
    ap.add_argument(""--stop"", action=""store_true"", help=""stop running containers"")
    args = ap.parse_args()

    dc = docker_compose_cmd()
    compose = dc + [""--project-name"", PROJECT, ""--env-file"", str(CONFIG_ENV), ""-f"", str(COMPOSE_YAML)]

    os.chdir(ROOT_DIR)
    ensure_env_file()

    if args.reset:
        run(compose + [""down"", ""-v"", ""--rmi"", ""all""])
        return
    if args.stop:
        run(compose + [""down""])
        return

    if args.pull:
        run([""docker"", ""pull"", GHCR_IMAGE])

    gpu_args = [""--compatibility"", ""--profile"", ""gpu""] if args.gpu else []
    extra = [""--no-build""] if args.pull else []
    run(compose + gpu_args + [""up"", ""-d"", *extra])

    print(""Dashboard  http://localhost:7862"")
    print(""OpenAPI   http://localhost:8000/docs"")
    print(""Stop      start_aiga_demo.py --stop"")

    if args.logs:
        subprocess.run(compose + [""logs"", ""-f""])
",alpha_factory_v1/demos/aiga_meta_evolution/start_aiga_demo.py,,1,1.2501528648238603e-09,"The method 'main' is a well-structured command-line interface for managing Docker containers using Docker Compose. It provides several useful options for users, such as pulling images, enabling GPU support, viewing logs, resetting, and stopping containers. These functionalities are essential for managing containerized applications efficiently. The code is clear, uses standard libraries, and follows good practices for command-line applications. There is no indication that this method is obsolete or redundant, and it serves a practical purpose in managing Docker environments. Therefore, it is likely to be retained in the codebase."
survived,"            def __init__(self, val: str) -> None:
                pass
",tests/test_ledger_broadcast.py,DummyPk,0,0.9999993524053853,"The method is a constructor that takes a parameter 'val' but does nothing with it, as it only contains a 'pass' statement. This suggests that the method is not currently serving any functional purpose. Unless there is a specific reason to keep it as a placeholder for future development, it is likely to be deleted to clean up the codebase."
survived,"            def __init__(self, program_id: Any, data: bytes, keys: list[Any]):
                self.data = data
",tests/test_ledger_client_close.py,DummyInstr,1,6.825604231969389e-08,"The method is a constructor (__init__) for a class, which is a fundamental part of object-oriented programming in Python. Constructors are essential for initializing new objects with specific attributes. The presence of parameters like 'program_id', 'data', and 'keys' suggests that this constructor is designed to set up an object with these attributes, which is a common and necessary practice. Therefore, it is unlikely that this method will be deleted."
survived,"def test_broadcast_merkle_root_closes_client() -> None:
    with tempfile.TemporaryDirectory() as tmp:
        ledger = Ledger(os.path.join(tmp, ""l.db""), rpc_url=""http://rpc.test"", broadcast=True)
        env = messaging.Envelope(sender=""a"", recipient=""b"", payload={""v"": 1}, ts=0.0)
        ledger.log(env)
        root = ledger.compute_merkle_root()

        calls: list[tuple[str, Any]] = []

        class DummyClient:
            def __init__(self, url: str) -> None:
                calls.append((""url"", url))

            async def send_transaction(self, tx: Any, *args: Any) -> None:
                calls.append((""sent"", tx.instructions[0].data.decode()))

            async def close(self) -> None:
                calls.append((""closed"", True))

        class DummyTx:
            def __init__(self) -> None:
                self.instructions: list[Any] = []

            def add(self, instr: Any) -> ""DummyTx"":
                self.instructions.append(instr)
                return self

        class DummyInstr:
            def __init__(self, program_id: Any, data: bytes, keys: list[Any]):
                self.data = data

        class DummyPk:
            def __init__(self, val: str) -> None:
                pass

        with (
            mock.patch.dict(
                sys.modules,
                {
                    ""solana"": ModuleType(""solana""),
                    ""solana.rpc"": ModuleType(""solana.rpc""),
                    ""solana.rpc.async_api"": ModuleType(""solana.rpc.async_api""),
                },
            ),
            mock.patch(""solana.rpc.async_api.AsyncClient"", DummyClient, create=True),
            mock.patch.object(insight_logging, ""AsyncClient"", DummyClient, create=True),
            mock.patch.object(insight_logging, ""Transaction"", DummyTx, create=True),
            mock.patch.object(insight_logging, ""TransactionInstruction"", DummyInstr, create=True),
            mock.patch.object(insight_logging, ""PublicKey"", DummyPk, create=True),
        ):
            asyncio.run(ledger.broadcast_merkle_root())

        assert (""sent"", root) in calls
        assert (""closed"", True) in calls",tests/test_ledger_client_close.py,,1,1.0677030767166749e-06,"The method is a test function that verifies the behavior of broadcasting a Merkle root and ensuring the client is closed after the operation. It uses mock objects to simulate the environment and dependencies, which is a common practice in testing. The function is well-structured for its purpose and does not contain any deprecated or redundant code. It is likely to be maintained as it provides a necessary test for the functionality of the ledger's broadcasting mechanism."
survived,"    def _verify_checksum(self, mnemonic_ids):
        from shamir_mnemonic.share import Share
        try:
            Share.from_mnemonic("" "".join(self.id_to_word(i) for i in mnemonic_ids))
            return True
        except Exception:
            return False
",btcrecover/btcrseed.py,WalletSLIP39Seed,1,2.646573631904765e-09,"The method '_verify_checksum' is a utility function that checks the validity of a mnemonic by attempting to create a Share object from it. This is a common operation in systems dealing with mnemonic phrases, such as cryptocurrency wallets or secure data storage solutions. The method is straightforward, uses a try-except block to handle exceptions, and returns a boolean indicating the success of the operation. Such utility functions are often necessary for validation purposes and are unlikely to be removed unless the entire system undergoes a significant redesign or the method is replaced by a more efficient or secure alternative. Therefore, it is likely to survive."
survived,"    def return_verified_password_or_false(self, mnemonic_ids_list):
        for count, mnemonic_ids in enumerate(mnemonic_ids_list, 1):
            if None not in mnemonic_ids and self._verify_checksum(mnemonic_ids):
                return mnemonic_ids, count
        return False, count
",btcrecover/btcrseed.py,WalletSLIP39Seed,1,4.944450477491054e-09,"The method 'return_verified_password_or_false' is likely to survive because it performs a specific and useful function: it iterates over a list of mnemonic IDs, checks for the presence of 'None', and verifies a checksum. If a valid mnemonic ID is found, it returns the ID along with its position in the list. This functionality is clear, concise, and potentially useful in contexts where mnemonic verification is needed. Additionally, the method handles cases where no valid mnemonic is found by returning 'False', which is a reasonable approach for error handling."
survived,"    def mochi(self, line, cell):
        """"""Run Mochi code contained in the cell.""""""
        with tempfile.NamedTemporaryFile(""w"", suffix="".mochi"", delete=False) as f:
            f.write(cell)
            fname = f.name
        try:
            cmd = [""mochi"", ""run"", fname]
            proc = subprocess.run(cmd, capture_output=True, text=True)
            if proc.stdout:
                sys.stdout.write(proc.stdout)
            if proc.stderr:
                sys.stderr.write(proc.stderr)
            if proc.returncode != 0:
                raise RuntimeError(f""mochi exited with status {proc.returncode}"")
        finally:
            os.unlink(fname)
",tools/notebook/mochi_magic.py,MochiMagics,1,4.1399375473943306e-08,"The method 'mochi' is a utility function designed to execute Mochi code from a given cell. It uses temporary files to store the code, runs it using a subprocess, and handles output and errors. This functionality is specific and useful for environments where Mochi code execution is needed, such as in a Jupyter notebook with a Mochi kernel. The method is well-structured, handling both standard output and errors, and ensures cleanup of temporary files. Given its specific utility and proper implementation, it is likely to be retained in the codebase."
survived,"    def __init__(self):
        self.lines = []
        self.indent = 0
",tools/any2mochi/py_simple.py,Conv,1,8.152020648014727e-09,"The method is a constructor for a class, initializing two attributes: 'lines' as an empty list and 'indent' as an integer set to 0. This is a common pattern in object-oriented programming to set up initial state for an object. There is no indication that this method is redundant or incorrect, so it is likely to be retained as part of the class's functionality."
survived,"    def delete(
        self,
        func: Callable[..., Any] | None = None,
        *,
        name: str | None = None,
        description: str | None = None,
    ) -> Callable[..., Any] | DecoratorCallable:
        """"""Register a delete operation.""""""

        def decorator(fn: Callable[..., Any]) -> Callable[..., Any]:
            return self.resource(fn, name=name, description=description)

        if func is not None:
            return decorator(func)
        return cast(""DecoratorCallable"", decorator)
",src/enrichmcp/app.py,EnrichMCP,1,3.850741907939403e-09,"The method 'delete' is a utility function designed to register a delete operation, likely in a web framework or API context. It provides a decorator pattern to easily associate a function with a delete operation, which is a common requirement in RESTful services. The method is flexible, allowing optional parameters for 'name' and 'description', enhancing its usability. Given its utility and the commonality of such patterns in modern software development, it is likely to be retained in the codebase."
survived,"async def update_customer(customer_id: int, patch: Customer.PatchModel) -> Customer:
    """"""Update an existing customer.""""""
    customer = CUSTOMERS[customer_id]
    data = patch.dict(exclude_unset=True)
    updated = customer.copy(update=data)
    CUSTOMERS[customer_id] = updated
    return updated
",examples/mutable_crud/app.py,,1,4.0586521248284276e-10,"The method 'update_customer' is a straightforward and essential function for updating customer information in a database or data structure. It uses asynchronous programming, which is beneficial for performance in I/O-bound applications. The method is well-defined, using a patch model to update only the necessary fields, and it returns the updated customer object. These characteristics make it a useful and efficient function in a system that manages customer data, suggesting it will likely be retained."
survived,"    async def create_item(name: str) -> Item:
        """"""Create item.""""""
        return Item(id=1, name=name)
",tests/test_mutability.py,,1,3.850741907939403e-09,"The method 'create_item' is a simple asynchronous function that creates and returns an 'Item' object with a given name. It is straightforward and serves a clear purpose, which is to instantiate an 'Item' with a specified name. There is no indication of redundancy, inefficiency, or lack of utility in the provided code snippet. Therefore, it is likely to be retained in the codebase."
survived,"    def _project_dir(self, project: str) -> Path:
        path = self.root / project
        path.mkdir(parents=True, exist_ok=True)
        return path
",examples/basic_memory/memory.py,FileMemoryStore,1,2.3355930333443423e-09,"The method '_project_dir' is a utility function that constructs a directory path for a given project and ensures that the directory exists by creating it if necessary. This is a common and useful functionality in many applications that deal with file system operations, especially in project management or data organization contexts. The method is simple, effective, and does not have any apparent issues or redundancies that would warrant its deletion. Therefore, it is likely to be retained in the codebase."
survived,"    def list(self, project: str, page: int, page_size: int) -> list[MemoryNoteSummary]:
        """"""Return a paginated list of notes for ``project``.""""""
",examples/basic_memory/memory.py,MemoryStore,1,1.4166087846364157e-09,"The method 'list' is a straightforward implementation of a paginated list retrieval function, which is a common requirement in many applications dealing with large datasets. It is well-documented, specifying the parameters and their types, and it returns a list of 'MemoryNoteSummary' objects, which suggests it is part of a larger system managing notes or similar entities. There is no indication of redundancy, inefficiency, or obsolescence in the method's design or purpose. Therefore, it is likely to be retained in the codebase."
survived,"def has_network() -> bool:
    """"""Return ``True`` if DNS resolution for ``pypi.org`` succeeds.""""""
    try:
        socket.gethostbyname(""pypi.org"")
        return True
    except OSError:
        return False
",check_env.py,,1,2.998960815863541e-09,"The method `has_network` is a simple utility function that checks for network connectivity by attempting to resolve the DNS for `pypi.org`. This is a common requirement in many applications to ensure that network operations can proceed. The method is straightforward, efficient, and serves a clear purpose. There is no indication that this functionality is obsolete or redundant, and it is likely to be useful in various contexts where network availability needs to be verified. Therefore, it is likely to be retained in the codebase."
survived,"        def _fake_find_spec(name: str, *args: Any, **kwargs: Any) -> object:
            if name == module_name:
                return object()
            if name in {""openai_agents"", ""agents""}:
                return None
            return orig_find_spec(name, *args, **kwargs)
",tests/test_check_env_openai_agents_version.py,TestCheckEnvOpenAIAgentsVersion,1,3.2241866333029355e-08,"The method '_fake_find_spec' is a utility function that seems to be used for mocking or altering the behavior of a module finding mechanism, likely for testing purposes. It checks if the module name matches a specific name and returns a generic object, or if it matches certain other names, it returns None. Otherwise, it delegates to an original function 'orig_find_spec'. This kind of function is often used in testing environments to simulate or control the behavior of module loading. Since it serves a specific purpose in testing or mocking, it is likely to be retained as long as the testing framework or the need for such a mock exists. Therefore, it is more likely to be Survived."
survived,"    def test_missing_version_fails(self) -> None:
        for name in (""openai_agents"", ""agents""):
            with self.subTest(module=name):
                self.assertNotEqual(self._run_check(name, None), 0)
",tests/test_check_env_openai_agents_version.py,TestCheckEnvOpenAIAgentsVersion,1,7.194132978569833e-09,"The method 'test_missing_version_fails' is a unit test that checks if a certain condition fails when a version is missing. It uses a subTest to iterate over different module names and asserts that the result of '_run_check' with a 'None' version is not equal to 0. This is a valid and useful test case to ensure that the system behaves correctly when a version is missing, which is a common edge case. Therefore, it is likely to be retained in the codebase."
survived,"    def test_new_version_ok(self) -> None:
        for name in (""openai_agents"", ""agents""):
            with self.subTest(module=name):
                self.assertEqual(self._run_check(name, ""0.0.15""), 0)
",tests/test_check_env_openai_agents_version.py,TestCheckEnvOpenAIAgentsVersion,1,3.653482080241728e-08,"The method `test_new_version_ok` is a unit test method that uses `subTest` to iterate over a tuple of module names and checks if the `_run_check` method returns 0 for version ""0.0.15"". This is a typical pattern in unit testing to ensure that a function behaves as expected for different inputs. The method is likely to be retained because it serves a clear purpose in testing the functionality of `_run_check` across different modules, ensuring code reliability and correctness."
survived,"    def test_old_version_fails(self) -> None:
        for name in (""openai_agents"", ""agents""):
            with self.subTest(module=name):
                self.assertNotEqual(self._run_check(name, ""0.0.13""), 0)
",tests/test_check_env_openai_agents_version.py,TestCheckEnvOpenAIAgentsVersion,1,1.0467401685178159e-08,"The method `test_old_version_fails` is a unit test designed to ensure that a specific function `_run_check` does not return 0 when called with certain module names and a specific version number. This kind of test is crucial for maintaining backward compatibility and ensuring that older versions of modules are not mistakenly considered valid or functional. Since testing for compatibility and correct behavior of software versions is a common and necessary practice in software development, it is unlikely that this method will be deleted. It serves an important role in the testing suite by verifying that outdated versions fail as expected."
survived,"    def _run_check(self, module_name: str, version: str | None) -> int:
        fake_mod = types.SimpleNamespace()
        if version is not None:
            fake_mod.__version__ = version
        orig_import_module = importlib.import_module
        orig_find_spec = importlib.util.find_spec

        def _fake_import(name: str, *args: Any, **kwargs: Any) -> object:
            if name == module_name:
                return fake_mod
            return orig_import_module(name, *args, **kwargs)

        def _fake_find_spec(name: str, *args: Any, **kwargs: Any) -> object:
            if name == module_name:
                return object()
            if name in {""openai_agents"", ""agents""}:
                return None
            return orig_find_spec(name, *args, **kwargs)

        with (
            mock.patch(""importlib.import_module"", side_effect=_fake_import),
            mock.patch(""importlib.util.find_spec"", side_effect=_fake_find_spec),
            mock.patch.object(check_env, ""REQUIRED"", []),
            mock.patch.object(check_env, ""OPTIONAL"", [module_name]),
            mock.patch.object(check_env, ""warn_missing_core"", lambda: []),
        ):
            return check_env.main([])
",tests/test_check_env_openai_agents_version.py,TestCheckEnvOpenAIAgentsVersion,1,1.725782769012759e-08,"The method '_run_check' is a utility function that uses mocking to simulate the presence or absence of a module and its version. This is a common pattern in testing environments to ensure that code behaves correctly under different conditions. The method is not overly complex, is well-contained, and serves a specific purpose in testing or checking environments. There is no indication that it is deprecated or redundant, and it seems to be a useful part of a testing suite. Therefore, it is likely to be retained."
survived,"def warn_missing_core() -> None:
    missing = [pkg for pkg in CORE if importlib.util.find_spec(pkg) is None]
    if missing:
        print(""WARNING: Missing core packages:"", "", "".join(missing))
",check_env.py,,1,4.363462233903899e-09,"The method 'warn_missing_core' is a utility function that checks for the presence of core packages and prints a warning if any are missing. This is a useful function for ensuring that all necessary dependencies are available, which is a common requirement in many software projects. The function is simple, effective, and serves a clear purpose, making it likely to be retained in the codebase."
survived,"def lead_time(truth: list[bool], pred: list[bool]) -> float:
    """"""Return ``pred`` onset minus ``truth`` onset.""""""
    def first_true(seq: list[bool]) -> int:
        for i, val in enumerate(seq):
            if val:
                return i
        return len(seq)

    return first_true(pred) - first_true(truth)
",src/simulation/replay.py,,1,1.725782769012759e-08,"The method is a utility function that calculates the difference in onset times between two boolean sequences. It is a simple and clear implementation that serves a specific purpose, which is useful in various contexts such as time series analysis or event detection. The function is well-defined, with a clear docstring explaining its purpose. There are no apparent issues with the logic or implementation, and it is likely to be useful in scenarios where such calculations are needed. Therefore, it is likely to be retained."
survived,"    def run_compute_pressure_force_acceleration(self):
        """"""Compute pressure forces and update acceleration.""""""
        pos = self.sorted_position[:, :3]
        i_idx = torch.repeat_interleave(
            torch.arange(pos.shape[0], device=self.device),
            self.neighbor_map.shape[1],
        )
        j_idx = self.neighbor_map.reshape(-1)
        mask = j_idx >= 0
        i_idx = i_idx[mask]
        j_idx = j_idx[mask]
        diff = pos[i_idx] - pos[j_idx]
        dist = diff.norm(dim=1)
        dir = diff / (dist.unsqueeze(1) + 1e-12)
        grad = (
            self.config[""mass_mult_gradWspikyCoefficient""]
            * (self.config[""h""] - dist).clamp(min=0) ** 2
        ).unsqueeze(1) * dir
        pres = (
            self.pressure[i_idx] / (self.rho[i_idx] ** 2)
            + self.pressure[j_idx] / (self.rho[j_idx] ** 2)
        ).unsqueeze(1)
        force = -pres * grad
        acc = torch.zeros_like(self.sorted_position)
        acc.scatter_add_(0, i_idx.unsqueeze(1).expand(-1, 3), force)
        gravity = torch.tensor(
            [
                self.config.get(""gravity_x"", 0.0),
                self.config.get(""gravity_y"", -9.8),
                self.config.get(""gravity_z"", 0.0),
            ],
            device=self.device,
        )
        acc[:, :3] += gravity
        self.acceleration = acc
",pytorch_solver.py,PytorchSolver,1,7.194132978569833e-09,"The method 'run_compute_pressure_force_acceleration' is a core part of a physics simulation, likely related to fluid dynamics or particle systems. It calculates pressure forces and updates acceleration, which are essential operations in such simulations. The method is well-structured, uses efficient tensor operations, and includes necessary physical constants like gravity. These factors suggest that the method is crucial for the functionality of the system and is unlikely to be removed unless there is a significant change in the system's requirements or architecture."
survived,"def test_simple_flow():
    pos = torch.tensor(
        [[0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.4, 1.0], [2.0, 2.0, 2.0, 1.0]]
    )
    vel = torch.zeros_like(pos)
    cfg = {
        ""xmin"": 0.0,
        ""ymin"": 0.0,
        ""zmin"": 0.0,
        ""hash_grid_cell_size_inv"": 1.0,
        ""grid_cells_x"": 4,
        ""grid_cells_y"": 4,
        ""grid_cells_z"": 4,
        ""grid_cell_count"": 64,
        ""h"": 0.5,
        ""mass_mult_Wpoly6Coefficient"": 1.0,
        ""mass_mult_gradWspikyCoefficient"": 1.0,
        ""rho0"": 1.0,
        ""delta"": 1.0,
        ""time_step"": 0.01,
    }
    solver = PytorchSolver(pos, vel, cfg)
    solver.run_hash_particles()
    solver.run_sort()
    solver.run_index()
    solver.run_index_post_pass()
    solver.run_find_neighbors()
    solver.run_compute_density()
    solver.run_compute_pressure()
    solver.run_compute_pressure_force_acceleration()
    solver.run_integrate()

    # the first two particles should be neighbours
    neigh0 = solver.neighbor_map[0]
    assert 1 in neigh0[:2]
    assert solver.position.shape == pos.shape
    # velocities should change due to gravity
    assert torch.allclose(solver.velocity[0, 1], torch.tensor(-0.098), atol=1e-3)",tests/test_pytorch_solver.py,,1,1.1861120010657661e-08,"The method 'test_simple_flow' is a test function that verifies the behavior of a particle simulation using a solver. It checks for expected neighbor relationships and changes in velocity due to gravity. Such test functions are crucial for ensuring the correctness of the simulation logic and are typically retained in the codebase to prevent regressions. Therefore, it is likely to survive."
survived,"    def run_index(self):
        """"""Compute starting index in the sorted array for each grid cell.""""""
        num_cells = self.config[""grid_cell_count""]
        counts = torch.bincount(self.particle_index[:, 0], minlength=num_cells)
        start = torch.cumsum(
            torch.cat(
                [torch.zeros(1, device=self.device, dtype=torch.long), counts[:-1]]
            ),
            dim=0,
        )
        index = torch.where(counts > 0, start, torch.full_like(start, -1))
        index = torch.cat(
            [index, torch.tensor([self.particle_index.shape[0]], device=self.device)]
        )
        self.grid_cell_index = index
",pytorch_solver.py,PytorchSolver,1,6.69158608681505e-10,"The method 'run_index' is a utility function that calculates the starting index for each grid cell in a sorted array. It uses PyTorch operations to efficiently compute these indices, which are likely used in further computations or simulations involving grid cells and particles. The method is well-defined, uses efficient tensor operations, and is likely integral to the functionality of the class it belongs to. There is no indication that it is redundant or obsolete, and it seems to serve a specific purpose in the context of the code. Therefore, it is likely to be retained."
survived,"def convert_backgrounds(v1_path, out_dir, doc_slug):
    bgs = load_json(v1_path)
    out_bg = []
    out_bgb = []
    for bg in bgs:
        f = bg[""fields""]
        slug = bg[""pk""]
        pk = f""{doc_slug}_{slug}""
        out_bg.append({
            ""model"": ""api_v2.background"",
            ""pk"": pk,
            ""fields"": {""name"": f[""name""], ""desc"": f[""desc""], ""document"": doc_slug},
        })
        mapping = [
            (""skill_proficiencies"", ""Skill Proficiencies"", ""skill_proficiency""),
            (""tool_proficiencies"", ""Tool Proficiencies"", ""tool_proficiency""),
            (""languages"", ""Languages"", ""language""),
            (""equipment"", ""Equipment"", ""equipment""),
        ]
        for key, name, typ in mapping:
            val = f.get(key)
            if val:
                out_bgb.append({
                    ""model"": ""api_v2.backgroundbenefit"",
                    ""pk"": f""{pk}_{slugify(name)}"",
                    ""fields"": {""name"": name, ""desc"": val, ""type"": typ, ""parent"": pk},
                })
        if f.get(""feature"") or f.get(""feature_desc""):
            out_bgb.append({
                ""model"": ""api_v2.backgroundbenefit"",
                ""pk"": f""{pk}_{slugify(f.get('feature','feature'))}"",
                ""fields"": {""name"": f.get(""feature"", ""Feature""), ""desc"": f.get(""feature_desc"", """"), ""type"": ""feature"", ""parent"": pk},
            })
        if f.get(""suggested_characteristics""):
            out_bgb.append({
                ""model"": ""api_v2.backgroundbenefit"",
                ""pk"": f""{pk}_suggested-characteristics"",
                ""fields"": {""name"": ""Suggested Characteristics"", ""desc"": f[""suggested_characteristics""], ""type"": ""suggested_characteristics"", ""parent"": pk},
            })
    if out_bg:
        save_json(out_bg, os.path.join(out_dir, ""Background.json""))
    if out_bgb:
        save_json(out_bgb, os.path.join(out_dir, ""BackgroundBenefit.json""))
",convert_missing.py,,1,2.646573631904765e-09,"The method 'convert_backgrounds' is likely to survive because it appears to be a well-structured and functional piece of code. It performs a specific task of converting background data from a JSON file into a different format and saving it to new JSON files. The method includes data processing, mapping, and file saving operations, which are common and necessary tasks in data transformation workflows. Additionally, the code is modular and uses helper functions like 'load_json', 'save_json', and 'slugify', indicating good coding practices. Unless there are changes in requirements or the method becomes obsolete due to architectural changes, it is likely to be retained."
survived,"            def inc(self, *_a: Any) -> None: ...
",src/interface/api_server.py,_N,1,6.605216531020474e-05,"The method 'inc' is defined with a generic signature that accepts any number of arguments of any type, but it does not have an implementation (indicated by the ellipsis '...'). This suggests that the method is either a placeholder or intended to be overridden in a subclass. Without further context, it's difficult to determine its utility. However, methods that are placeholders or meant to be overridden are common in abstract classes or interfaces. If this is part of such a structure, it is likely to survive. If it is not used or overridden anywhere, it might be deleted. Given the lack of context, I'll predict it will survive as it might be part of a larger design pattern."
survived,"    async def _metrics() -> Response:
        if ""generate_latest"" not in globals():
            raise HTTPException(status_code=503, detail=""prometheus_client not installed"")
        return PlainTextResponse(generate_latest(), media_type=CONTENT_TYPE_LATEST)
",src/interface/api_server.py,,1,2.646573631904765e-09,"The method '_metrics' is an asynchronous function that checks if 'generate_latest' is available in the global namespace. If not, it raises an HTTPException indicating that 'prometheus_client' is not installed. This is a useful utility function for monitoring and metrics collection, especially in web applications that use Prometheus for monitoring. The function is well-defined, serves a specific purpose, and handles a potential error case gracefully. Therefore, it is likely to be retained in the codebase."
survived,"def test_settings_offline_enabled_when_missing_key(monkeypatch):
    monkeypatch.delenv(""OPENAI_API_KEY"", raising=False)
    importlib.reload(config)
    s = config.Settings()
    assert s.offline",tests/test_config_settings.py,,1,1.6052280526088547e-09,"The method `test_settings_offline_enabled_when_missing_key` is a test function that checks the behavior of a configuration setting when a specific environment variable is missing. Test functions are generally not deleted unless they are redundant or replaced by a more comprehensive test. This function is likely to be useful for ensuring that the application behaves correctly in the absence of the `OPENAI_API_KEY`. Therefore, it is likely to survive."
survived,"def test_codegen_agent_emits_to_safety(monkeypatch) -> None:
    cfg = config.Settings(bus_port=0)
    bus = DummyBus(cfg)
    led = DummyLedger()
    agent = codegen_agent.CodeGenAgent(bus, led)
    monkeypatch.setattr(agent, ""execute_in_sandbox"", lambda code: ("""", """"))
    env = messaging.Envelope(""market"", ""codegen"", {""analysis"": ""x""}, 0.0)
    asyncio.run(agent.handle(env))
    assert bus.published[-1][0] == ""safety""",tests/test_agent_handle_methods.py,,1,1.8553915987649156e-07,"The method 'test_codegen_agent_emits_to_safety' is a unit test designed to verify that the 'CodeGenAgent' correctly publishes a message to the 'safety' channel after handling an envelope. This is a specific test case that ensures the functionality of the 'CodeGenAgent' is working as expected. Unit tests are generally not deleted unless the functionality they are testing is removed or significantly altered. Since this test is verifying a specific behavior of the 'CodeGenAgent', it is likely to be retained as long as the 'CodeGenAgent' and its related functionality exist."
survived,"def test_bundle_metadata_custom_fields_preserved():
    data = {
        ""schema_version"": BUNDLE_SCHEMA_VERSION,
        ""meta_agent_version"": ""0.1.0"",
        ""foo"": ""bar"",
        ""custom"": {""x"": 1},
    }
    meta = BundleMetadata(**data)
    assert meta.meta_agent_version == ""0.1.0""
    assert meta.custom == {""x"": 1}
    assert getattr(meta, ""foo"") == ""bar""",tests/test_bundle_metadata.py,,1,2.998960815863541e-09,"The method `test_bundle_metadata_custom_fields_preserved` is a unit test designed to verify that custom fields in a data structure are preserved when creating an instance of `BundleMetadata`. This is a typical use case in software testing to ensure that the functionality of preserving custom fields works as expected. Since this is a test method, it is likely to be retained as part of the test suite to ensure ongoing code quality and correctness. Therefore, it is predicted to survive."
survived,"    def generate(
        self,
        agent_code: str,
        tests: Optional[Mapping[str, str]] = None,
        requirements: Optional[Sequence[str]] = None,
        readme: str = """",
        guardrails_manifest: str = """",
        templates: Optional[Mapping[str, str]] = None,
    ) -> BundleMetadata:
        """"""Generate bundle files and return metadata.""""""

        checksums: dict[str, str] = {}

        checksums[""agent.py""] = self._write_file(""agent.py"", agent_code)

        tests = tests or {}
        if not tests:
            (self.bundle_dir / ""tests"").mkdir(parents=True, exist_ok=True)
        for name, content in tests.items():
            checksums[f""tests/{name}""] = self._write_file(Path(""tests"") / name, content)

        req_content = ""\n"".join(requirements or [])
        checksums[""requirements.txt""] = self._write_file(""requirements.txt"", req_content)

        checksums[""README.md""] = self._write_file(""README.md"", readme)

        (self.bundle_dir / ""traces"").mkdir(parents=True, exist_ok=True)

        (self.bundle_dir / ""guardrails"").mkdir(parents=True, exist_ok=True)
        if guardrails_manifest:
            checksums[""guardrails/manifest.json""] = self._write_file(
                ""guardrails/manifest.json"", guardrails_manifest
            )

        for rel, content in (templates or {}).items():
            checksums[str(rel)] = self._write_file(rel, content)

        metadata = BundleMetadata(meta_agent_version=__version__)
        metadata.custom[""checksums""] = checksums
        with open(self.bundle_dir / ""bundle.json"", ""w"", encoding=""utf-8"") as f:
            json.dump(json.loads(metadata.model_dump_json()), f, indent=2)
        return metadata",src/meta_agent/bundle_generator.py,BundleGenerator,1,1.4166087846364157e-09,"The method 'generate' is a comprehensive function that handles the creation of a bundle of files, including agent code, tests, requirements, and other necessary files. It also manages directories and writes metadata to a JSON file. This functionality is essential for packaging and deploying software components, making it a crucial part of a software development workflow. The method is well-structured, uses optional parameters effectively, and provides a clear output in the form of 'BundleMetadata'. Given its utility and the fact that it doesn't have any apparent issues or redundancies, it is likely to be retained in the codebase."
survived,"    def __init__(self, bundle_dir: str | Path) -> None:
        self.bundle_dir = Path(bundle_dir)
",src/meta_agent/bundle_generator.py,BundleGenerator,1,1.637377179507321e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting up initial state. There is no indication that this constructor is redundant or unnecessary, as it is setting an instance variable 'bundle_dir'. Therefore, it is unlikely to be deleted."
survived,"    def _write_detailed_memory_maps(self, f):
        """"""
        
        """"""
        f.write(""3. \n"")
        f.write(""-"" * 50 + ""\n"")
        
        process = psutil.Process()
        memory_maps = process.memory_maps()
        
        # 
        perm_stats = {}
        file_stats = {}
        
        for mmap in memory_maps:
            size_mb = mmap.size / 1024 / 1024
            perms = mmap.perms
            
            # 
            if perms not in perm_stats:
                perm_stats[perms] = {'count': 0, 'size': 0}
            perm_stats[perms]['count'] += 1
            perm_stats[perms]['size'] += size_mb
            
            # 
            if mmap.path:
                if mmap.path not in file_stats:
                    file_stats[mmap.path] = {'count': 0, 'size': 0}
                file_stats[mmap.path]['count'] += 1
                file_stats[mmap.path]['size'] += size_mb
        
        f.write("":\n"")
        f.write(f""{'':<10} {'':<8} {'(MB)':<12}\n"")
        f.write(""-"" * 35 + ""\n"")
        for perms, stats in sorted(perm_stats.items(), key=lambda x: x[1]['size'], reverse=True):
            f.write(f""{perms:<10} {stats['count']:<8} {stats['size']:<12.2f}\n"")
        
        f.write(f""\n (10):\n"")
        f.write(f""{'':<50} {'(MB)':<12}\n"")
        f.write(""-"" * 70 + ""\n"")
        for path, stats in sorted(file_stats.items(), key=lambda x: x[1]['size'], reverse=True)[:10]:
            if len(path) > 47:
                path = path[:44] + ""...""
            f.write(f""{path:<50} {stats['size']:<12.2f}\n"")
        
        f.write(""\n"" + ""="" * 100 + ""\n\n"")
",app/helper/memory.py,MemoryHelper,1,1.725782769012759e-08,"The method '_write_detailed_memory_maps' is a utility function that provides a detailed analysis of memory mappings for a process. It categorizes memory maps by permissions and file paths, and writes this information to a file. This kind of functionality is useful for debugging, performance analysis, or system monitoring, which are common tasks in software development and maintenance. Therefore, it is likely to be retained in the codebase as it serves a specific and useful purpose."
deleted,"        def filter_difficulty(example):
            answer_length = len(example[""info""][""best_answer""].split())
            if difficulty == ""easy"":
                return answer_length < 10
            elif difficulty == ""medium"":
                return 10 <= answer_length < 30
            else:  # hard
                return answer_length >= 30
",environments/truthful_qa/truthful_qa.py,,1,1.0467401685178159e-08,"The method 'filter_difficulty' is a utility function that categorizes examples based on the length of the 'best_answer' field. This kind of functionality is often useful in data processing tasks where examples need to be filtered or categorized based on certain criteria. The method is straightforward, performs a clear task, and is likely to be used in various contexts where data needs to be filtered by difficulty. Therefore, it is likely to be retained in the codebase."
survived,"    def parse_judge_scores(prompt, completion, answer, state, **kwargs) -> float:
        # Call the judge to get evaluation
        judge_response = rubric.judge(prompt, completion, answer, state, **kwargs)
        try:
            import json
            # Extract JSON from the response
            response_text = judge_response.strip()
            # Try to find JSON object in the response
            start_idx = response_text.find('{')
            end_idx = response_text.rfind('}') + 1
            if start_idx >= 0 and end_idx > start_idx:
                json_text = response_text[start_idx:end_idx]
                scores = json.loads(json_text)
                return float(scores.get(""overall_score"", 0.0))
        except Exception as e:
            # If parsing fails, return 0
            pass
        return 0.0
",environments/toxicity_explanation/toxicity_explanation.py,,1,4.363462233903899e-09,"The method 'parse_judge_scores' is likely to survive because it performs a specific and useful function: extracting and parsing a JSON object from a response to obtain a score. It includes error handling to ensure robustness, returning a default score if parsing fails. This functionality is valuable in scenarios where automated evaluation or scoring is needed, and the method is designed to handle potential exceptions gracefully."
survived,"def run_claude_code_task(task_id):
    """"""Run Claude Code automation in a container""""""
    try:
        task = tasks[task_id]
        task['status'] = TaskStatus.RUNNING
        
        logger.info(f""Starting Claude Code task {task_id}"")
        
        # Escape special characters in prompt for shell safety
        escaped_prompt = task['prompt'].replace('""', '\\""').replace('$', '\\$').replace('`', '\\`')
        
        # Create container environment variables
        env_vars = {
            'ANTHROPIC_API_KEY': os.getenv('ANTHROPIC_API_KEY'),
        }
        
        # Create the command to run in container
        container_command = f'''
set -e
echo ""Setting up repository...""

# Clone repository
git clone -b {task['branch']} {task['repo_url']} /workspace/repo
cd /workspace/repo

# Configure git
git config user.email ""claude-code@automation.com""
git config user.name ""Claude Code Automation""

echo ""Starting Claude Code with prompt...""

# Run Claude Code with the prompt
echo ""{escaped_prompt}"" | claude

# Check if there are changes
if git diff --quiet; then
    echo ""No changes made""
    exit 1
fi

# Commit changes
git add .
git commit -m ""Claude Code: {escaped_prompt[:100]}""

# Get commit hash and diff
echo ""COMMIT_HASH=$(git rev-parse HEAD)""
echo ""=== GIT DIFF START ===""
git diff HEAD~1 HEAD
echo ""=== GIT DIFF END ===""
'''
        
        # Run container with Claude Code
        container = docker_client.containers.run(
            'claude-code-automation:latest',
            command=['bash', '-c', container_command],
            environment=env_vars,
            detach=True,
            remove=True,
            working_dir='/workspace',
            network_mode='bridge'  # Ensure proper networking
        )
        
        task['container_id'] = container.id
        
        # Wait for container to finish with timeout
        try:
            result = container.wait(timeout=300)  # 5 minute timeout
            logs = container.logs().decode('utf-8')
        except Exception as e:
            logger.error(f""Container timeout or error: {str(e)}"")
            task['status'] = TaskStatus.FAILED
            task['error'] = f""Container execution timeout or error: {str(e)}""
            return
        
        if result['StatusCode'] == 0:
            # Parse output to extract commit hash and diff
            lines = logs.split('\n')
            commit_hash = None
            git_diff = []
            capturing_diff = False
            
            for line in lines:
                if line.startswith('COMMIT_HASH='):
                    commit_hash = line.split('=', 1)[1]
                elif line == '=== GIT DIFF START ===':
                    capturing_diff = True
                elif line == '=== GIT DIFF END ===':
                    capturing_diff = False
                elif capturing_diff:
                    git_diff.append(line)
            
            task['status'] = TaskStatus.COMPLETED
            task['commit_hash'] = commit_hash
            task['git_diff'] = '\n'.join(git_diff)
            
            logger.info(f""Task {task_id} completed successfully"")
            
        else:
            task['status'] = TaskStatus.FAILED
            task['error'] = f""Container exited with code {result['StatusCode']}: {logs}""
            logger.error(f""Task {task_id} failed: {task['error']}"")
            
    except Exception as e:
        task['status'] = TaskStatus.FAILED
        task['error'] = str(e)
        logger.error(f""Task {task_id} failed with exception: {str(e)}"")
",server/main.py,,1,3.3982678079468468e-09,"The method 'run_claude_code_task' is a well-structured function that handles a specific task of running a code automation process in a container. It includes error handling, logging, and manages the task status effectively. The method is likely to be useful in scenarios where automated code execution and version control are required. There are no apparent issues or redundancies that would necessitate its deletion. Therefore, it is likely to be retained in the codebase."
survived,"    async def test_latest_run_includes_metadata(
        self,
        test_api_client: AsyncClient,
        returned_run: AgentRun,
    ):
        """"""Test that metadata is included in the RunV1 response""""""
        returned_run.metadata = {""environment"": ""test"", ""user_id"": ""123"", ""custom_field"": ""value""}

        response = await test_api_client.get(""/v1/_/agents/bla/runs/latest"")
        assert response.status_code == 200

        response_data = response.json()
        assert response_data[""id""] == returned_run.id
        assert response_data[""metadata""] == {
            ""environment"": ""test"",
            ""user_id"": ""123"",
            ""custom_field"": ""value"",
        }
",api/api/routers/runs_v1_test.py,TestLatestRun,1,3.653482080241728e-08,"The method is a test function that verifies if metadata is correctly included in the response of a specific API endpoint. Test functions are crucial for ensuring the reliability and correctness of code, especially in API development. This function is likely part of a test suite that ensures the API behaves as expected, which is an essential part of software development and maintenance. Therefore, it is unlikely to be deleted."
survived,"def create_pkgx_package(
    distributables: list[str] | None = None,
    dependencies: list[str] | None = None,
    build_deps: list[str] | None = None,
    test_deps: list[str] | None = None,
) -> PkgxPackage:
    """"""Helper to create PkgxPackage instances for testing""""""

    # Create distributable blocks
    distributable_blocks = []
    if distributables:
        for url in distributables:
            distributable_blocks.append(Distributable(url=url))

    # Create dependency objects
    dep_objects = [
        DependencyBlock(
            platform=""all"",
            dependencies=[
                Dependency(name=dep, semver=""*"") for dep in (dependencies or [])
            ],
        )
    ]
    build_dep_objects = [
        DependencyBlock(
            platform=""all"",
            dependencies=[
                Dependency(name=dep, semver=""*"") for dep in (build_deps or [])
            ],
        )
    ]
    test_dep_objects = [
        DependencyBlock(
            platform=""all"",
            dependencies=[
                Dependency(name=dep, semver=""*"") for dep in (test_deps or [])
            ],
        )
    ]

    # Create version object
    version = Version()

    return PkgxPackage(
        distributable=distributable_blocks,
        versions=version,
        dependencies=dep_objects,
        build=DependencyBlock(platform=""linux"", dependencies=build_dep_objects),
        test=DependencyBlock(platform=""linux"", dependencies=test_dep_objects),
    )
",tests/package_managers/pkgx/test_pkgx_diff.py,,1,5.60279640614594e-09,"The method 'create_pkgx_package' is a utility function designed to create instances of 'PkgxPackage' for testing purposes. It is a helper function that simplifies the creation of package instances by handling the construction of distributable blocks and dependency objects. Such utility functions are often useful in testing environments to streamline the setup of test cases. Since it serves a specific purpose in the context of testing, it is likely to be retained as long as the testing framework or the 'PkgxPackage' class is in use. Therefore, the method is predicted to survive."
survived,"def canonicalize(url: str) -> str:
    return normalize_url(url)
",package_managers/pkgx/url.py,,0,0.9999999715466527,"The method `canonicalize` is a simple wrapper around the `normalize_url` function, which suggests that it might be redundant unless it serves a specific purpose such as providing a more descriptive name or being part of a larger interface. Without additional context or usage, it seems likely that this method could be considered unnecessary and thus deleted, especially if `normalize_url` is directly accessible and used elsewhere."
survived,"    def test_sort_by_quality_index_asc(self):
        """"""Test sorting by quality index (lowest first).""""""
        models: list[ConciseModelResponse | ConciseLatestModelResponse] = [
            create_test_model(""model1"", quality_index=50),
            create_test_model(""model2"", quality_index=100),
            create_test_model(""model3"", quality_index=75),
        ]

        sorted_models = sort_models(models, ""quality_index"", ""asc"")

        assert [m.id for m in sorted_models] == [""model1"", ""model3"", ""model2""]
",api/api/routers/mcp/_utils/model_sorting_test.py,TestSortModels,1,1.2501528648238603e-09,"The method `test_sort_by_quality_index_asc` is a unit test that verifies the functionality of sorting models by their quality index in ascending order. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with sorting algorithms or data manipulation. This test is well-defined, checks a specific functionality, and contributes to the overall robustness of the codebase. Therefore, it is likely to be retained as part of the test suite."
survived,"    async def rollback(self):
        # Drop the new index
        await self._drop_index_if_exists(self._organization_collection, ""unique_api_key_id"")

        # Recreate the old index with the problematic partial filter expression
        await self._organization_collection.create_index(
            [(""api_keys.id"", 1)],
            name=""org_settings_api_key_id_index"",
            unique=True,
            background=True,
            partialFilterExpression={""api_keys"": {""$exists"": True}},
        )",api/core/storage/mongo/migrations/migrations/m2025_05_06_fix_api_key_id_index.py,FixAPIKeyIdIndexMigration,1,2.4616969512093895e-10,"The method 'rollback' is performing a critical operation of reverting a database index to a previous state. This is often necessary in scenarios where a new index causes issues or does not perform as expected. The method is essential for maintaining database integrity and ensuring that the application can revert to a stable state if needed. Such rollback functions are common in database management and are unlikely to be removed unless the entire indexing strategy is changed or the database schema is significantly altered. Therefore, the method is likely to survive."
survived,"    def test_speed_index(self, speed_data: SpeedData, expected_index: int):
        mapping = {
            Model.O3_2025_04_16_MEDIUM_REASONING_EFFORT: _md(speed_data=SpeedData(index=600)),
        }
        assert speed_data.speed_index(mapping) == expected_index
",api/core/domain/models/model_data_test.py,TestModelDataSpeedIndex,1,1.6052280526088547e-09,"The method `test_speed_index` is a unit test function that checks if the `speed_index` method of a `SpeedData` object returns the expected index when given a specific mapping. Unit tests are crucial for ensuring code reliability and correctness, especially in larger projects. This method is likely part of a test suite that verifies the functionality of the `SpeedData` class or related components. Since testing is an essential part of software development and maintenance, this method is expected to survive."
survived,"    def custom_llm_provider(self) -> Optional[str]:
        return ""perplexity""
",litellm/llms/perplexity/chat/transformation.py,PerplexityChatConfig,1,2.998960815863541e-09,"The method 'custom_llm_provider' is a simple function that returns a string 'perplexity'. It is likely a placeholder or a configuration method for specifying a language model provider. Since it is a straightforward method with a clear purpose, it is unlikely to be deleted unless the functionality it provides is no longer needed or is replaced by a more comprehensive configuration system. Therefore, it is more likely to survive."
survived,"    def test_perplexity_reasoning_effort_parameter_mapping(self, model, reasoning_effort):
        """"""
        Test that reasoning_effort parameter is correctly mapped for Perplexity Sonar reasoning models
        """"""
        # Set up local model cost map
        os.environ[""LITELLM_LOCAL_MODEL_COST_MAP""] = ""True""
        litellm.model_cost = litellm.get_model_cost_map(url="""")

        # Get provider and optional params
        _, provider, _, _ = litellm.get_llm_provider(model=model)
        
        optional_params = get_optional_params(
            model=model,
            custom_llm_provider=provider,
            reasoning_effort=reasoning_effort,
        )
        
        # Verify that reasoning_effort is preserved in optional_params for Perplexity
        assert ""reasoning_effort"" in optional_params
        assert optional_params[""reasoning_effort""] == reasoning_effort
",tests/llm_translation/test_perplexity_reasoning.py,TestPerplexityReasoning,1,6.023574641292144e-08,"The method 'test_perplexity_reasoning_effort_parameter_mapping' is a unit test designed to verify that the 'reasoning_effort' parameter is correctly mapped in the optional parameters for Perplexity Sonar reasoning models. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with parameter mappings and configurations. This test checks the integrity of the parameter handling, which is an important aspect of software development. Therefore, it is likely to be retained as part of the test suite to ensure ongoing code quality."
survived,"    def test_perplexity_non_reasoning_models_dont_support_reasoning(self):
        """"""
        Test that non-reasoning Perplexity models don't support reasoning
        """"""
        from litellm.utils import supports_reasoning
        
        # Set up local model cost map
        os.environ[""LITELLM_LOCAL_MODEL_COST_MAP""] = ""True""
        litellm.model_cost = litellm.get_model_cost_map(url="""")
        
        non_reasoning_models = [
            ""perplexity/sonar"",
            ""perplexity/sonar-pro"",
            ""perplexity/llama-3.1-sonar-large-128k-chat"",
            ""perplexity/mistral-7b-instruct"",
        ]
        
        for model in non_reasoning_models:
            # These models should not support reasoning (should return False or raise exception)
            try:
                result = supports_reasoning(model, None)
                # If it doesn't raise an exception, it should return False
                assert result is False, f""{model} should not support reasoning""
            except Exception:
                # If it raises an exception, that's also acceptable behavior
                pass
",tests/llm_translation/test_perplexity_reasoning.py,TestPerplexityReasoning,1,1.725782769012759e-08,"The method is a unit test that verifies the behavior of non-reasoning models in a specific library. It is well-defined, has a clear purpose, and is likely part of a test suite to ensure the correctness of the library's functionality. Such tests are crucial for maintaining software quality and are typically retained unless the functionality they test is deprecated or the library undergoes significant changes."
survived,"def test_semantic_unnest_list():
    """"""Test semantic unnest operation with list values.""""""
    df = pd.DataFrame({
        ""id"": [1, 2],
        ""tags"": [[""python"", ""pandas"", ""data""], [""ml"", ""ai""]]
    })
    
    result = df.semantic.unnest(unnest_key=""tags"")
    
    assert isinstance(result, pd.DataFrame)
    assert len(result) == 5  # 3 + 2 tags
    assert all(result.columns == [""id"", ""tags""])
    
    # Check that each tag becomes a separate row
    expected_tags = [""python"", ""pandas"", ""data"", ""ml"", ""ai""]
    actual_tags = result[""tags""].tolist()
    assert set(actual_tags) == set(expected_tags)
    
    # Check that original data is preserved
    python_rows = result[result[""tags""] == ""python""]
    assert len(python_rows) == 1
    assert python_rows.iloc[0][""id""] == 1
",tests/test_pandas_accessors.py,,1,1.725782769012759e-08,"The method is a test function for a specific feature (semantic unnest operation) in a DataFrame, which is a common operation in data manipulation. It is well-structured, includes assertions to verify the correctness of the operation, and checks both the structure and content of the resulting DataFrame. Such test functions are crucial for ensuring the reliability of data processing functions, and there is no indication that this functionality is deprecated or unnecessary. Therefore, it is likely to be retained."
survived,"    def test_cost_report_with_corrupted_resources_data(self):
        """"""Test cost report handles corrupted/unpicklable resources data.""""""
        mock_cluster_record = {
            'name': 'corrupted-cluster',
            'status': None,
            'num_nodes': 1,
            'resources': mock.Mock(),
            'total_cost': 0.0,
            'launched_at': 1640995200,
            'duration': 1800,
            'cluster_hash': 'def456',
            'usage_intervals': [(1640995200, 1640997000)],
            'user_hash': 'user456',
            'user_name': 'testuser2',
            'workspace': 'default',
        }
        
        # Mock resources with missing/invalid attributes
        mock_cluster_record['resources'].instance_type = None
        mock_cluster_record['resources'].cloud = None
        
        with mock.patch('sky.global_user_state.get_clusters_from_history', 
                      return_value=[mock_cluster_record]):
            
            # Should handle gracefully and not crash
            result = core.cost_report(days=30)
            self.assertIsInstance(result, list)
",tests/unit_tests/test_sky_cost_report.py,TestHistoricalClusterRobustness,1,1.6052280526088547e-09,"The method is a test case that ensures the system can handle corrupted or unpicklable resources data without crashing. It is important for maintaining robustness and reliability in the system, especially when dealing with external data sources that might not always be well-formed. Test cases like this are crucial for identifying potential issues and ensuring the system behaves correctly under edge cases. Therefore, it is likely to be retained."
survived,"def test_severity_greater_than_info_bug_fix(
    db_session, workflow_manager, create_workflow, create_alert
):
    """"""
    Test the specific bug case from GitHub issue #5086:
    severity > 'info' should match 'warning', 'high', and 'critical' severities
    
    Before fix: This would fail because 'high' < 'info' lexicographically (h < i)
    After fix: This works because high (4) > info (2) numerically
    """"""
    # Create a workflow with the exact CEL expression from the bug report
    workflow = create_workflow(
        ""test-severity-gt-info-bug"", 
        ""severity > 'info' && source.contains('prometheus')""
    )

    # These alerts should match (severity > info)
    high_alert = create_alert(
        severity=AlertSeverity.HIGH, 
        fingerprint=""fp-high""
    )
    critical_alert = create_alert(
        severity=AlertSeverity.CRITICAL, 
        fingerprint=""fp-critical""
    )
    warning_alert = create_alert(
        severity=AlertSeverity.WARNING, 
        fingerprint=""fp-warning""
    )

    # These alerts should NOT match
    info_alert = create_alert(
        severity=AlertSeverity.INFO, 
        fingerprint=""fp-info""
    )
    low_alert = create_alert(
        severity=AlertSeverity.LOW, 
        fingerprint=""fp-low""
    )

    # Test high severity alert (should match)
    workflows_to_run_before = len(workflow_manager.scheduler.workflows_to_run)
    workflow_manager.insert_events(SINGLE_TENANT_UUID, [high_alert])
    assert len(workflow_manager.scheduler.workflows_to_run) == workflows_to_run_before + 1
    assert workflow_manager.scheduler.workflows_to_run[-1][""workflow_id""] == workflow.id

    # Test critical severity alert (should match)
    workflows_to_run_before = len(workflow_manager.scheduler.workflows_to_run)
    workflow_manager.insert_events(SINGLE_TENANT_UUID, [critical_alert])
    assert len(workflow_manager.scheduler.workflows_to_run) == workflows_to_run_before + 1
    assert workflow_manager.scheduler.workflows_to_run[-1][""workflow_id""] == workflow.id

    # Test warning severity alert (should match)
    workflows_to_run_before = len(workflow_manager.scheduler.workflows_to_run)
    workflow_manager.insert_events(SINGLE_TENANT_UUID, [warning_alert])
    assert len(workflow_manager.scheduler.workflows_to_run) == workflows_to_run_before + 1
    assert workflow_manager.scheduler.workflows_to_run[-1][""workflow_id""] == workflow.id

    # Test info severity alert (should NOT match)
    workflows_to_run_before = len(workflow_manager.scheduler.workflows_to_run)
    workflow_manager.insert_events(SINGLE_TENANT_UUID, [info_alert])
    assert len(workflow_manager.scheduler.workflows_to_run) == workflows_to_run_before

    # Test low severity alert (should NOT match)
    workflows_to_run_before = len(workflow_manager.scheduler.workflows_to_run)
    workflow_manager.insert_events(SINGLE_TENANT_UUID, [low_alert])
    assert len(workflow_manager.scheduler.workflows_to_run) == workflows_to_run_before
",tests/test_workflow_severity_comparisons.py,,1,3.2241866333029355e-08,The method is a test case that verifies a specific bug fix related to severity comparison in alerts. It is crucial for ensuring that the bug fix works as intended and that future changes do not reintroduce the bug. Test cases like this are typically retained to maintain software quality and prevent regressions.
survived,"def multiline_binary():
    """"""Fixture for binary fields, specifically multi-lines ones""""""
    return """"""
Package: binutils
Binary: binutils-for-host, binutils-for-build,
 binutils-ia64-linux-gnu-dbg, binutils-m68k-linux-gnu,
 binutils-mips64el-linux-gnuabin32-dbg, binutils-mipsisa64r6-linux-gnuabin32,
 binutils-mipsisa64r6el-linux-gnuabi64-dbg

""""""
",tests/package_managers/debian/test_debian_parser.py,,1,1.955568070542584e-08,"The method 'multiline_binary' is a simple fixture function that returns a multi-line string. It is likely used in testing or configuration scenarios where such a string is needed. The function is straightforward, has a clear purpose, and does not contain any errors or deprecated practices. Therefore, it is likely to be retained in the codebase."
survived,"    def test_build_package_to_source_mapping_no_binary_list(
        self, tmp_path, mock_logger
    ):
        """"""Test building mapping when source has no explicit binary list""""""

        # Create a test sources file with no Binary field
        sources_content = """"""Package: single-source
Vcs-Git: https://github.com/test/single-source.git
Homepage: https://example.com/single-source
""""""

        sources_file = tmp_path / ""sources""
        sources_file.write_text(sources_content)

        # Build mapping
        mapping = build_package_to_source_mapping(str(sources_file), mock_logger)

        # Verify mapping - should use source package name as binary name
        assert len(mapping) == 1
        assert ""single-source"" in mapping
        assert mapping[""single-source""].package == ""single-source""
        # URLs are normalized by the parser - expect normalized format
        assert mapping[""single-source""].vcs_git == ""github.com/test/single-source""
",tests/package_managers/debian/test_debian_sources.py,TestPackageSourceMapping,1,1.637377179507321e-07,"The method is a unit test for a specific functionality, which is to verify the behavior of the `build_package_to_source_mapping` function when the source file does not contain an explicit binary list. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with edge cases or specific scenarios. This test helps maintain the integrity of the code by checking that the mapping function correctly defaults to using the source package name as the binary name when no binary list is provided. Such tests are typically retained to ensure ongoing code quality and to prevent regressions in future code changes."
survived,"    def _generate_chai_urls(self, debian_data: DebianData) -> list[URLKey]:
        """"""Generate URLs for a debian package""""""
        urls = []

        # Homepage URL
        if debian_data.homepage:
            urls.append(URLKey(debian_data.homepage, self.config.url_types.homepage))

        # Source URL
        source_url = (
            debian_data.vcs_git if debian_data.vcs_git else debian_data.vcs_browser
        )
        if source_url:
            urls.append(URLKey(source_url, self.config.url_types.source))

        # Repository URL
        if is_github_url(source_url):
            urls.append(URLKey(source_url, self.config.url_types.repository))

        return urls",package_managers/debian/diff.py,DebianDiff,1,1.8189616842444243e-09,"The method `_generate_chai_urls` is likely to survive because it serves a clear and useful purpose: generating a list of URLs related to a Debian package. It checks for the presence of a homepage, source, and repository URLs, and appends them to a list with appropriate types. This functionality is essential for applications that need to manage or display package information, and there is no indication that this method is redundant or obsolete. Additionally, the method is well-structured and follows a logical flow, making it maintainable and understandable."
survived,"    def ingest_wrapper(self, diff_result: DiffResult) -> None:
        """"""Wrapper for the main ingest function to handle DiffResult""""""
        final_new_urls = list(diff_result.new_urls.values())
        self.ingest(
            diff_result.new_packages,
            final_new_urls,
            diff_result.new_package_urls,
            diff_result.new_deps,
            diff_result.removed_deps,
            diff_result.updated_packages,
            diff_result.updated_package_urls,
        )",package_managers/debian/db.py,DebianDB,1,1.3176514268359263e-10,"The method 'ingest_wrapper' is a wrapper function that simplifies the process of calling the 'ingest' method with the appropriate parameters extracted from a 'DiffResult' object. This kind of method is useful for encapsulating logic and making the code more readable and maintainable. It doesn't seem to have any issues or redundancies that would warrant its deletion. Therefore, it is likely to survive."
survived,"    def test_enrich_package_with_explicit_source(self, mock_logger):
        """"""Test enriching package that has explicit source reference""""""

        # Create package data with explicit source reference
        package_data = create_debian_package(
            package=""binary-pkg"",
            description=""A binary package"",
        )
        package_data.source = ""source-pkg""

        # Create source mapping
        source_data = create_debian_package(
            package=""source-pkg"",
            vcs_git=""github.com/test/source-pkg"",  # Already normalized format
            homepage=""example.com/source-pkg"",  # Already normalized format
            build_depends=[""build-dep1"", ""build-dep2""],
        )
        source_mapping = {""binary-pkg"": source_data}

        # Enrich package
        enriched = enrich_package_with_source(package_data, source_mapping, mock_logger)

        # Verify enrichment
        assert enriched.package == ""binary-pkg""
        assert enriched.description == ""A binary package""
        assert enriched.vcs_git == ""github.com/test/source-pkg""
        assert enriched.homepage == ""example.com/source-pkg""
        assert len(enriched.build_depends) == 2

        build_depend_names = [item.package for item in enriched.build_depends]
        assert build_depend_names == [""build-dep1"", ""build-dep2""]
",tests/package_managers/debian/test_debian_sources.py,TestPackageSourceMapping,1,2.5109990926928157e-08,"The method `test_enrich_package_with_explicit_source` is a unit test function that verifies the functionality of enriching a package with its source information. It is well-structured, uses mock data, and includes assertions to validate the expected behavior. Such test methods are crucial for ensuring code reliability and are typically retained in the codebase to facilitate ongoing testing and development. Therefore, it is likely to be retained."
survived,"    def test_dependency_type_priority_new_package(
        self, mock_config, mock_logger, mock_db
    ):
        """"""
        Scenario:
          - p1 has no dependencies to p2 in cache
          - p1 has both runtime and build dependencies to p2 in parsed data

        Expect one new runtime dependency (priority over build).
        """"""

        p1_id = uuid4()
        p2_id = uuid4()

        p1_pkg = Package(id=p1_id, derived_id=""debian/p1"", name=""p1"", import_id=""p1"")
        p2_pkg = Package(id=p2_id, derived_id=""debian/p2"", name=""p2"", import_id=""p2"")

        cache = Cache(
            package_map={""debian/p1"": p1_pkg, ""debian/p2"": p2_pkg},
            url_map={},
            package_urls={},
            dependencies={},  # No existing dependencies
        )

        # Parsed data has both runtime and build dependencies to p2
        new_pkg_data = create_debian_package(
            package=""p1"",
            depends=[""p2""],  # runtime
            build_depends=[""p2""],  # build
        )

        diff = DebianDiff(mock_config, cache, mock_db, mock_logger)
        new_deps, removed_deps = diff.diff_deps(""debian/p1"", new_pkg_data)

        # Should only create one new dependency - runtime (higher priority)
        assert len(removed_deps) == 0
        assert len(new_deps) == 1
        assert new_deps[0].dependency_id == p2_id
        assert new_deps[0].dependency_type_id == mock_config.dependency_types.runtime
",tests/package_managers/debian/test_debian_diff.py,TestDebianDifferentialLoading,1,2.5109990926928157e-08,"The method is a unit test that verifies the behavior of a system when handling package dependencies. It checks that when a package has both runtime and build dependencies, the runtime dependency is prioritized. This is a specific and useful test case for ensuring correct dependency management in a package management system. Such tests are crucial for maintaining software quality and ensuring that changes do not introduce regressions. Therefore, it is likely to be retained as part of the test suite."
survived,"def save_tasks():
    """"""Save tasks to file for persistence""""""
    try:
        with open(TASKS_FILE, 'w') as f:
            json.dump(tasks, f, indent=2, default=str)
        logger.info(f"" Saved {len(tasks)} tasks to {TASKS_FILE}"")
    except Exception as e:
        logger.warning(f"" Failed to save tasks: {e}"")
",server/utils.py,,1,1.1628233028868813e-10,"The method 'save_tasks' is likely to survive because it performs a crucial function of saving tasks to a file, which is essential for data persistence. This functionality is important in applications where task data needs to be retained across sessions. Additionally, the method includes error handling and logging, which are good practices for maintaining robust code."
survived,"    def create_project(user_id: str, name: str, description: str, repo_url: str, 
                      repo_name: str, repo_owner: str, settings: Dict = None) -> Dict:
        """"""Create a new project""""""
        try:
            project_data = {
                'user_id': user_id,
                'name': name,
                'description': description,
                'repo_url': repo_url,
                'repo_name': repo_name,
                'repo_owner': repo_owner,
                'settings': settings or {},
                'is_active': True
            }
            
            result = supabase.table('projects').insert(project_data).execute()
            return result.data[0] if result.data else None
        except Exception as e:
            logger.error(f""Error creating project: {e}"")
            raise
",server/database.py,DatabaseOperations,1,3.160881453314576e-10,"The method 'create_project' is likely to survive because it performs a fundamental operation of creating a project in a database, which is a common requirement in many applications. The method is well-structured, handles exceptions, and logs errors, making it robust and maintainable. Additionally, it uses a flexible parameter for settings, allowing for future extensibility."
survived,"    def get_task_by_id(task_id: int, user_id: str) -> Optional[Dict]:
        """"""Get a specific task by ID for a user""""""
        try:
            result = supabase.table('tasks').select('*').eq('id', task_id).eq('user_id', user_id).execute()
            return result.data[0] if result.data else None
        except Exception as e:
            logger.error(f""Error fetching task {task_id}: {e}"")
            raise
",server/database.py,DatabaseOperations,1,2.0611536181902033e-09,"The method 'get_task_by_id' is a utility function that retrieves a specific task from a database for a given user. It is a common operation in applications that manage user-specific data, such as task management systems. The method is well-defined, handles exceptions, and logs errors, which are good practices in software development. Additionally, it uses a popular database interaction pattern with Supabase, making it relevant and useful for developers using this stack. Therefore, it is likely to be retained in the codebase."
survived,"    def sort_by_duration(self) -> None:
        """"""Sort tasks by estimated duration (longest first) for optimal concurrent execution.""""""
        task_durations = []
        for task_path in self._tasks:
            try:
                task_paths_obj = TaskPaths(task_path)
                task = Task.from_yaml(task_paths_obj.task_config_path)
                duration = task.effective_estimated_duration_sec
            except Exception as e:
                self._logger.warning(
                    f""Failed to load task {task_path.name}: {e}. Using fallback duration.""
                )
                duration = 210.0
            task_durations.append((task_path, duration))

        task_durations.sort(key=lambda x: x[1], reverse=True)
        self._tasks = [task_path for task_path, _ in task_durations]

        # Log the task execution order
        table_data = []
        for i, (task_path, duration) in enumerate(task_durations, 1):
            task_name = task_path.name
            minutes = int(duration // 60)
            seconds = int(duration % 60)
            duration_str = f""{minutes}m {seconds}s""

            try:
                task_paths_obj = TaskPaths(task_path)
                task = Task.from_yaml(task_paths_obj.task_config_path)
                if task.estimated_duration_sec is not None:
                    source = ""historical""
                else:
                    source = ""calculated""
            except Exception:
                source = ""fallback""

            table_data.append([i, task_name, duration_str, source])

        headers = [""#"", ""Task Name"", ""Duration"", ""Source""]
        table = tabulate(table_data, headers=headers, tablefmt=""grid"")

        self._logger.info(""Processing tasks in duration order (longest first):"")
        self._logger.info(f""\n{table}"")
        self._logger.info(f""Total tasks: {len(task_durations)}"")",terminal_bench/dataset/dataset.py,Dataset,1,4.0586521248284276e-10,"The method 'sort_by_duration' is well-structured and serves a clear purpose: sorting tasks by their estimated duration for optimal execution. It includes error handling, logging, and uses a fallback mechanism for durations that cannot be determined. These features make it robust and useful in a task management context. Additionally, the method provides detailed logging of the task order and duration source, which is valuable for debugging and monitoring. Given these factors, the method is likely to be retained in the codebase."
survived,"    def _set_dummy_api_key(self, monkeypatch, request):
        # MCP mode doesn't require API key, so we don't set it
        # This allows us to test MCP functionality without API key requirements
        pass
",src/backend/tests/unit/test_cli.py,TestMCPServeCommand,1,2.699578619062706e-07,"The method _set_dummy_api_key is designed to bypass the need for an API key in a specific testing scenario (MCP mode). It is a utility function used for testing purposes, which is a common practice in software development to ensure that certain functionalities can be tested without external dependencies. Since it serves a specific purpose in the testing framework, it is likely to be retained as long as the testing scenario it supports remains relevant."
deleted,"        def mock_resource_decorator(uri):
            def decorator(func):
                registered_resources.append((uri, func))
                return func
            return decorator
",src/backend/tests/unit/test_mcp_server.py,TestMCPServerIntegration,1,1.6052280526088547e-09,"The method 'mock_resource_decorator' is a utility function that acts as a decorator to register resources with a URI. This is a common pattern in web frameworks and is useful for dynamically associating functions with specific endpoints. Such functionality is often needed in web applications for routing purposes. Therefore, it is likely to be retained as it provides a useful and reusable mechanism for resource registration."
deleted,"    def test_mcp_server_tool_execution_success(self, mock_fastmcp, integration_graphs_and_metas):
        """"""Test successful tool execution through MCP server.""""""
        graphs, metas = integration_graphs_and_metas
        mock_mcp_instance = MagicMock()
        
        # Track registered tools
        registered_tools = []
        
        def mock_tool_decorator(func):
            registered_tools.append(func)
            return func
        
        mock_mcp_instance.tool.side_effect = lambda: mock_tool_decorator
        mock_fastmcp.return_value = mock_mcp_instance

        # Create the server
        server = create_mcp_server(
            graphs=graphs,
            metas=metas,
            server_name=""Integration Test Server""
        )

        # Verify tools were registered
        assert len(registered_tools) == len(graphs)

        # Test tool execution (simulate calling one of the registered tools)
        if registered_tools:
            tool_func = registered_tools[0]
            flow_input = FlowInput(input_value=""test input"")
            
            # Mock the graph execution context
            with patch(""time.time"", side_effect=[0, 1.5]):  # Mock execution time
                result = tool_func(flow_input)
            
            assert isinstance(result, FlowOutput)
            assert ""Processed: test input"" in str(result.result)
            assert result.execution_time == 1.5
            assert result.error is None
",src/backend/tests/unit/test_mcp_server.py,TestMCPServerIntegration,1,2.998960815863541e-09,"The method 'test_mcp_server_tool_execution_success' is a unit test designed to verify the successful execution of a tool through an MCP server. Unit tests are generally not deleted unless they are redundant, testing deprecated functionality, or replaced by more comprehensive tests. This test appears to be well-structured, testing the registration and execution of tools, and verifying the output and execution time. It is likely to be useful for ensuring the correct behavior of the MCP server tool execution, thus it is expected to survive."
survived,"    def test_mcp_valid_transports(self, runner, temp_python_script):
        """"""Test that valid MCP transports are accepted.""""""
        valid_transports = [""stdio"", ""sse"", ""websocket""]
        
        for transport in valid_transports:
            # We just test that the validation passes and the command would start
            # We'll use a timeout or patch to avoid actually starting the server
            with patch(""langflow.cli.commands.run_mcp_server"") as mock_run_mcp:
                mock_run_mcp.side_effect = KeyboardInterrupt(""Test interrupt"")
                
                result = runner.invoke(app, [
                    ""serve"", str(temp_python_script),
                    ""--mcp"", ""--mcp-transport"", transport,
                    ""--verbose""
                ])
                
                # Should either exit cleanly (0) or with KeyboardInterrupt handling
                assert result.exit_code in [0, 1]
                # Should show MCP mode is enabled
                assert f""MCP mode enabled with {transport} transport"" in result.output
",src/backend/tests/unit/test_cli.py,TestMCPServeCommand,1,4.363462233903899e-09,"The method is a test function that verifies the acceptance of valid MCP transports. It is well-structured, uses mocking to avoid starting a server, and checks for expected outcomes. Such test functions are crucial for ensuring code reliability and are unlikely to be deleted unless the feature it tests is removed."
survived,"    def test_mcp_server_keyboard_interrupt(self, runner, temp_python_script):
        """"""Test graceful handling of keyboard interrupt in MCP server.""""""
        with patch(""langflow.cli.commands.run_mcp_server"") as mock_run_mcp:
            mock_run_mcp.side_effect = KeyboardInterrupt(""User interrupt"")
            
            result = runner.invoke(app, [
                ""serve"", str(temp_python_script),
                ""--mcp"", ""--verbose""
            ])
            
            assert result.exit_code == 0
            assert ""MCP server stopped"" in result.output
",src/backend/tests/unit/test_cli.py,TestMCPServeCommand,1,1.0467401685178159e-08,"The method is a test case designed to ensure that the MCP server handles keyboard interrupts gracefully. It uses mocking to simulate a KeyboardInterrupt and checks if the server stops correctly, which is a crucial aspect of robust server behavior. Test cases like this are essential for maintaining software quality and reliability, especially in handling unexpected user actions. Therefore, it is likely to be retained as part of the test suite."
deleted,"            def flow_tool(input_data: FlowInput) -> FlowOutput:
                f""""""Execute the {flow_name} flow.
                
                {flow_desc}
                """"""
                try:
                    # Import here to avoid circular imports
                    import time
                    
                    start_time = time.time()
                    
                    # Execute the flow
                    # Note: This follows the same pattern as the REST API execution
                    result = graph_obj.run(
                        inputs={""input_value"": input_data.input_value},
                        tweaks=input_data.tweaks or {}
                    )
                    
                    execution_time = time.time() - start_time
                    
                    return FlowOutput(
                        result=result,
                        execution_time=execution_time
                    )
                    
                except Exception as e:
                    return FlowOutput(
                        result=None,
                        error=str(e)
                    )
",src/backend/base/langflow/cli/mcp_server.py,,1,3.850741907939403e-09,"The method 'flow_tool' is a well-structured function that executes a flow and handles exceptions gracefully. It imports necessary modules, measures execution time, and returns a structured output. These characteristics make it a useful utility in a codebase, especially if it is part of a larger system that relies on flow execution. There is no indication of redundancy or obsolescence in the code, suggesting it will likely be retained."
survived,"    def test_create_mcp_server_basic(self, mock_fastmcp, sample_graphs_and_metas):
        """"""Test basic MCP server creation.""""""
        graphs, metas = sample_graphs_and_metas
        mock_mcp_instance = MagicMock()
        mock_fastmcp.return_value = mock_mcp_instance

        server = create_mcp_server(
            graphs=graphs,
            metas=metas,
            server_name=""Test MCP Server""
        )

        # Verify FastMCP was called with correct name
        mock_fastmcp.assert_called_once_with(""Test MCP Server"")
        assert server == mock_mcp_instance

        # Verify tools were registered (one for each flow)
        assert mock_mcp_instance.tool.call_count == len(graphs)

        # Verify resources were registered
        assert mock_mcp_instance.resource.call_count >= 3  # At least 3 resources

        # Verify prompts were registered
        assert mock_mcp_instance.prompt.call_count >= 2  # At least 2 prompts
",src/backend/tests/unit/test_mcp_server.py,TestMCPServerCreation,1,1.1032560311263802e-09,"The method `test_create_mcp_server_basic` is a unit test designed to verify the functionality of the `create_mcp_server` function. Unit tests are crucial for ensuring code reliability and correctness, especially in complex systems. This test checks multiple aspects of the server creation process, such as the correct instantiation of the server, the registration of tools, resources, and prompts. Given its role in maintaining code quality and preventing regressions, it is unlikely to be deleted unless the functionality it tests is removed or significantly altered. Therefore, the method is likely to survive."
survived,"    def _transform_messages(
        self, messages: List[AllMessageValues], model: str, is_async: bool = False
    ) -> Union[List[AllMessageValues], Coroutine[Any, Any, List[AllMessageValues]]]:
        """"""
        Moonshot AI does not support content in list format.
        """"""
        messages = handle_messages_with_content_list_to_str_conversion(messages)
        if is_async:
            return super()._transform_messages(
                messages=messages, model=model, is_async=True
            )
        else:
            return super()._transform_messages(
                messages=messages, model=model, is_async=False
            )
",litellm/llms/moonshot/chat/transformation.py,MoonshotChatConfig,1,2.3355930333443423e-09,"The method '_transform_messages' is likely to survive because it provides a specific functionality of transforming messages, which is essential for the operation of the system. It handles both synchronous and asynchronous operations, making it versatile. Additionally, it includes a call to a helper function 'handle_messages_with_content_list_to_str_conversion', indicating that it performs necessary preprocessing. The method is also part of a class hierarchy, as indicated by the use of 'super()', suggesting it is an integral part of the class's functionality."
survived,"def parse_args() -> tuple[RunConfig, TauBenchTrainingConfig, argparse.Namespace]:
    """"""Parse command line arguments for RL training""""""
    parser = argparse.ArgumentParser(description=""Train an agent on tau-bench using ART RL"")
    
    # tau-bench arguments (reuse from original run.py)
    parser.add_argument(""--num-trials"", type=int, default=1)
    parser.add_argument(
        ""--env"", type=str, choices=[""retail"", ""airline""], default=""retail""
    )
    parser.add_argument(
        ""--model"",
        type=str,
        help=""The model to use for the agent"",
        required=True,
    )
    parser.add_argument(
        ""--model-provider"",
        type=str,
        choices=provider_list,
        help=""The model provider for the agent"",
        required=True,
    )
    parser.add_argument(
        ""--user-model"",
        type=str,
        default=""gpt-4o"",
        help=""The model to use for the user simulator"",
    )
    parser.add_argument(
        ""--user-model-provider"",
        type=str,
        choices=provider_list,
        help=""The model provider for the user simulator"",
    )
    parser.add_argument(
        ""--agent-strategy"",
        type=str,
        default=""tool-calling"",
        choices=[""tool-calling"", ""act"", ""react"", ""few-shot""],
    )
    parser.add_argument(
        ""--temperature"",
        type=float,
        default=0.0,
        help=""The sampling temperature for the action model"",
    )
    parser.add_argument(
        ""--task-split"",
        type=str,
        default=""train"",  # Default to train for RL
        choices=[""train"", ""test"", ""dev""],
        help=""The split of tasks to run"",
    )
    parser.add_argument(""--start-index"", type=int, default=0)
    parser.add_argument(""--end-index"", type=int, default=100, help=""End index for training tasks"")
    parser.add_argument(""--task-ids"", type=int, nargs=""+"", help=""(Optional) run only the tasks with the given IDs"")
    parser.add_argument(""--log-dir"", type=str, default=""rl_results"")
    parser.add_argument(""--seed"", type=int, default=10)
    parser.add_argument(""--shuffle"", type=int, default=0)
    parser.add_argument(""--user-strategy"", type=str, default=""llm"", choices=[item.value for item in UserStrategy])
    parser.add_argument(""--few-shot-displays-path"", type=str, help=""Path to a jsonlines file containing few shot displays"")
    
    # RL-specific arguments
    parser.add_argument(""--model-name"", type=str, required=True, help=""Name for the trainable model"")
    parser.add_argument(""--base-model"", type=str, default=""Qwen/Qwen2.5-14B-Instruct"", help=""Base model for training"")
    parser.add_argument(""--trajectories-per-group"", type=int, default=6, help=""Number of trajectories per group"")
    parser.add_argument(""--groups-per-step"", type=int, default=8, help=""Number of groups per training step"")
    parser.add_argument(""--learning-rate"", type=float, default=1.2e-5, help=""Learning rate for training"")
    parser.add_argument(""--eval-steps"", type=int, default=30, help=""Evaluate every N steps"")
    parser.add_argument(""--val-set-size"", type=int, default=100, help=""Validation set size"")
    parser.add_argument(""--training-dataset-size"", type=int, default=1000, help=""Training dataset size"")
    parser.add_argument(""--num-epochs"", type=int, default=1, help=""Number of training epochs"")
    
    args = parser.parse_args()
    print(args)
    
    # Create RunConfig for tau-bench
    run_config = RunConfig(
        model_provider=args.model_provider,
        user_model_provider=args.user_model_provider,
        model=args.model,
        user_model=args.user_model,
        num_trials=args.num_trials,
        env=args.env,
        agent_strategy=args.agent_strategy,
        temperature=args.temperature,
        task_split=args.task_split,
        start_index=args.start_index,
        end_index=args.end_index,
        task_ids=args.task_ids,
        log_dir=args.log_dir,
        max_concurrency=1,  # RL training is sequential
        seed=args.seed,
        shuffle=args.shuffle,
        user_strategy=args.user_strategy,
        few_shot_displays_path=args.few_shot_displays_path,
    )
    
    # Create training config
    training_config = TauBenchTrainingConfig(
        trajectories_per_group=args.trajectories_per_group,
        groups_per_step=args.groups_per_step,
        learning_rate=args.learning_rate,
        eval_steps=args.eval_steps,
        val_set_size=args.val_set_size,
        training_dataset_size=args.training_dataset_size,
        num_epochs=args.num_epochs,
    )
    
    return run_config, training_config, args
",dev/tau-bench/run_rl.py,,1,4.6911638017642294e-08,"The method `parse_args` is a well-structured function for parsing command line arguments, which is a common requirement in many applications, especially those involving machine learning or data processing tasks. It uses the argparse library, which is a standard and efficient way to handle command line arguments in Python. The function is comprehensive, covering a wide range of parameters that are likely necessary for configuring a reinforcement learning training session. Additionally, it returns a tuple of configurations, which is a clean and organized way to pass around configuration data. Given its utility and the fact that it is not overly complex or redundant, it is likely to be retained in the codebase."
survived,"    async def test_a_generate_with_score_rollouts(self, mock_openai_client, sample_dataset):
        """"""Test async generate with scoring enabled.""""""
        env = SimpleEnvironment(
            client=mock_openai_client,
            model=""test-model"",
            dataset=sample_dataset,
            parser=Parser(),
            rubric=Rubric()
        )
        
        # Mock the rubric scoring
        env.rubric.score_rollouts = AsyncMock(return_value={
            ""reward"": [1.0]
        })
        
        inputs = {
            ""prompt"": [[{""role"": ""user"", ""content"": ""Hello""}]],
            ""answer"": [""Hi""]
        }
        
        results = await env.a_generate(inputs, score_rollouts=True)
        
        assert ""completion"" in results
        assert ""state"" in results
        assert ""reward"" in results
        assert results[""reward""] == [1.0]
",tests/test_environment.py,TestEnvironmentBase,1,6.023574641292144e-08,"The method `test_a_generate_with_score_rollouts` is a unit test for an asynchronous function that generates outputs with scoring enabled. It uses mocking to simulate the behavior of external dependencies, which is a common practice in testing. The test checks if the generated results contain expected keys and values, ensuring the function works as intended. Since testing is a crucial part of software development to ensure code reliability and correctness, this method is likely to be retained to maintain the integrity of the codebase."
survived,"    def test_make_dataset(self, mock_openai_client, sample_dataset):
        """"""Test creating a dataset from evaluation results.""""""
        env = SimpleEnvironment(
            client=mock_openai_client,
            model=""test-model"",
            dataset=sample_dataset,
            parser=Parser(),
            rubric=Rubric()
        )
        
        results = {
            ""prompt"": [[{""role"": ""user"", ""content"": ""Hello""}]],
            ""completion"": [[{""role"": ""assistant"", ""content"": ""Hi""}]],
            ""answer"": [""Hi""],
            ""reward"": [1.0],
            ""task"": [""default""],
            ""state"": [{""custom_field"": ""value""}]
        }
        
        dataset = env.make_dataset(results, state_columns=[""custom_field""])
        
        assert len(dataset) == 1
        assert ""prompt"" in dataset.column_names
        assert ""completion"" in dataset.column_names
        assert ""answer"" in dataset.column_names
        assert ""reward"" in dataset.column_names
        assert ""task"" in dataset.column_names
        assert ""custom_field"" in dataset.column_names",tests/test_environment.py,TestEnvironmentBase,1,7.194132978569833e-09,"The method 'test_make_dataset' is a unit test for the 'make_dataset' function in the 'SimpleEnvironment' class. Unit tests are crucial for ensuring that code functions correctly and as expected. This test checks that the dataset is created with the correct columns and that the length of the dataset is as expected. Since testing is a fundamental part of software development to maintain code quality and reliability, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly changed. Therefore, the method will likely survive."
survived,"    def test_process_chat_format(self, mock_openai_client, sample_dataset):
        """"""Test processing chat format conversations.""""""
        env = SimpleEnvironment(
            client=mock_openai_client,
            model=""test-model"",
            dataset=sample_dataset,
            parser=Parser(),
            rubric=Rubric()
        )
        
        # Create a mock tokenizer
        mock_tokenizer = Mock()
        mock_tokenizer.apply_chat_template = Mock(side_effect=lambda messages, tokenize=False, add_generation_prompt=True: 
            ""User: What is 2+2?Assistant:"" if add_generation_prompt else ""User: What is 2+2?Assistant: 4"")
        mock_tokenizer.encode = Mock(side_effect=lambda text: list(range(len(text.split()))))
        
        prompt = [{""role"": ""user"", ""content"": ""What is 2+2?""}]
        completion = [{""role"": ""assistant"", ""content"": ""4""}]
        
        prompt_ids, prompt_mask, completion_ids, completion_mask = env.process_chat_format(
            prompt, completion, mock_tokenizer, mask_env_responses=False
        )
        
        assert isinstance(prompt_ids, list)
        assert isinstance(prompt_mask, list)
        assert isinstance(completion_ids, list) 
        assert isinstance(completion_mask, list)
        assert len(prompt_ids) == len(prompt_mask)
        assert len(completion_ids) == len(completion_mask)
        assert all(m == 0 for m in prompt_mask)  # Prompt mask should be all 0s
        assert all(m == 1 for m in completion_mask)  # Completion mask should be all 1s
",tests/test_environment.py,TestEnvironmentBase,1,7.73442280641062e-08,"The method 'test_process_chat_format' is a unit test designed to verify the functionality of the 'process_chat_format' method in a specific environment setup. It uses mock objects to simulate the behavior of dependencies, which is a common practice in testing to isolate the unit of work. The test checks for correct data types and expected values, ensuring the method behaves as intended. Since testing is a crucial part of software development to ensure code reliability and correctness, this method is likely to be retained as part of the test suite."
survived,"    def test_get_env_for_task(self, mock_openai_client):
        """"""Test getting environment for a specific task.""""""
        env1 = SingleTurnEnv(
            client=mock_openai_client,
            model=""test-model"",
            dataset=Dataset.from_dict({""question"": [""q1""], ""answer"": [""a1""]}),
            rubric=Rubric()
        )
        
        env2 = SingleTurnEnv(
            client=mock_openai_client,
            model=""test-model"",
            dataset=Dataset.from_dict({""question"": [""q2""], ""answer"": [""a2""]}),
            rubric=Rubric()
        )
        
        env_group = EnvGroup(envs=[env1, env2], env_names=[""math"", ""code""])
        
        assert env_group.get_env_for_task(""math"") == env1
        assert env_group.get_env_for_task(""code"") == env2
        # Unknown task returns first environment as fallback
        assert env_group.get_env_for_task(""unknown"") == env1
",tests/test_env_group.py,TestEnvGroup,1,8.76424914819242e-08,"The method `test_get_env_for_task` is a unit test designed to verify the functionality of the `get_env_for_task` method in the `EnvGroup` class. It checks if the correct environment is returned for known tasks and if a default environment is returned for unknown tasks. This is a typical and necessary test to ensure the robustness of the `get_env_for_task` method, especially in handling edge cases like unknown tasks. As such, it is unlikely to be deleted unless the functionality it tests is removed or significantly altered, which is not indicated here."
deleted,"    def _parse_custom_tools(self, tool_calls: List[ChatCompletionMessageToolCall], tools: List[Dict[str, str]]) -> List[Dict[str, Any]]:
        """"""Parse responses from custom tools.""""""
        results = []
        for tool_call in tool_calls:
            for tool in tools:
                if tool_call.function.name == tool[""function""][""name""]:
                    try:
                        function_args = (
                            json.loads(tool_call.function.arguments)
                            if isinstance(tool_call.function.arguments, str)
                            else tool_call.function.arguments
                        )
                    except json.JSONDecodeError:
                        return [{}]
                    
                    # Execute the function defined in the tool's code
                    local_scope = {}
                    exec(tool[""code""].strip(), globals(), local_scope)
                    function_result = local_scope[tool[""function""][""name""]](**function_args)
                    function_args.update(function_result)
                    results.append(function_args)
        return results
",docetl/operations/utils/api.py,ResponseParser,1,2.4616969512093895e-10,"The method '_parse_custom_tools' is likely to survive because it serves a specific purpose of parsing and executing custom tool functions based on provided tool calls and tool definitions. It handles JSON parsing, dynamic code execution, and result aggregation, which are useful functionalities in a system that integrates with external tools or plugins. Additionally, the method includes error handling for JSON decoding, which is a good practice. Unless there are significant changes in the system's requirements or architecture that render this functionality obsolete, the method is likely to be retained."
deleted,"    def build_tool_schema(output_schema: Dict[str, Any], scratchpad: Optional[str] = None, model: str = """") -> Dict[str, Any]:
        """"""Build a tool schema from an output schema.""""""
        props = {key: convert_val(value) for key, value in output_schema.items()}
        
        if scratchpad is not None:
            props[""updated_scratchpad""] = {""type"": ""string""}

        parameters = {""type"": ""object"", ""properties"": props}
        parameters[""required""] = list(props.keys())

        # Some models don't support additionalProperties
        if ""gemini"" not in model and ""claude"" not in model:
            parameters[""additionalProperties""] = False

        return parameters
",docetl/operations/utils/api.py,OutputSchemaBuilder,1,1.9171715133907573e-10,"The method 'build_tool_schema' is likely to survive because it performs a useful function of converting an output schema into a tool schema, which is a common requirement in software development. The method is well-structured, with clear logic for handling optional parameters and model-specific conditions. Additionally, it uses standard Python libraries and practices, making it adaptable and maintainable. There is no indication of deprecated practices or inefficiencies that would necessitate its removal."
deleted,"    def handle_validation(
        self,
        response: Any,
        output_schema: Dict[str, Any],
        output_mode: OutputMode,
        validation_config: Optional[Dict[str, Any]],
        gleaning_config: Optional[Dict[str, Any]],
        model: str,
        op_type: str,
        messages: List[Dict[str, str]],
        tools: Optional[str] = None,
        scratchpad: Optional[str] = None,
        litellm_completion_kwargs: Dict[str, Any] = {},
        op_config: Dict[str, Any] = {},
        verbose: bool = False,
    ) -> tuple[Any, float, bool]:
        """"""Handle validation and gleaning processes.""""""
        total_cost = completion_cost(response)
        
        if gleaning_config:
            response, additional_cost, validated = self._handle_gleaning(
                response, output_schema, output_mode, gleaning_config, model, op_type, 
                messages, tools, scratchpad, litellm_completion_kwargs, op_config, verbose
            )
            total_cost += additional_cost
        elif validation_config:
            response, additional_cost, validated = self._handle_validation_retries(
                response, output_schema, output_mode, validation_config, model, op_type,
                messages, tools, scratchpad, litellm_completion_kwargs, op_config
            )
            total_cost += additional_cost
        else:
            validated = True
            
        return response, total_cost, validated
",docetl/operations/utils/api.py,ValidationHandler,1,5.60279640614594e-09,"The method 'handle_validation' is a comprehensive function that manages both validation and gleaning processes based on the provided configurations. It is well-structured, with clear handling of different scenarios (gleaning, validation retries, and default validation). The method is likely part of a larger system that requires such functionality, and it appears to be flexible and adaptable to different configurations. Given its utility and the fact that it doesn't have any apparent issues or redundancies, it is likely to be retained in the codebase."
deleted,"    def _make_tool_call(
        self, 
        model: str, 
        messages: List[Dict[str, str]], 
        output_schema: Dict[str, Any], 
        tools: Optional[str],
        scratchpad: Optional[str],
        extra_kwargs: Dict[str, Any]
    ) -> Any:
        """"""Make a tool-based call.""""""
        # Determine if we should use tools
        props = {key: convert_val(value) for key, value in output_schema.items()}
        use_tools = not (
            len(props) == 1
            and list(props.values())[0].get(""type"") == ""string""
            and scratchpad is None
            and (""sagemaker"" in model or is_deepseek_r1(model))
        )

        if tools is None and use_tools:
            tools_config, tool_choice = self._build_send_output_tool(output_schema, scratchpad, model)
        elif tools is not None:
            tools_config, tool_choice = self._build_custom_tools(tools)
        else:
            tools_config, tool_choice = None, None

        try:
            if tools_config is not None:
                return completion(
                    model=model,
                    messages=messages,
                    tools=tools_config,
                    tool_choice=tool_choice,
                    **extra_kwargs,
                )
            else:
                return completion(
                    model=model,
                    messages=messages,
                    **extra_kwargs,
                )
        except Exception as e:
            self._handle_model_error(model, e)
",docetl/operations/utils/api.py,LLMCallHandler,1,5.3157849718487075e-08,"The method '_make_tool_call' is a utility function that encapsulates the logic for making a tool-based call, which is a common requirement in systems that interact with models and tools. It includes logic for determining when to use tools, building tool configurations, and handling exceptions. This functionality is essential for systems that need to dynamically decide on tool usage based on input parameters and model characteristics. The method is well-structured, with clear separation of concerns, making it likely to be retained for its utility in managing complex interactions with models and tools."
survived,"    def __init__(self):
        self.chat_completions = {}  # Maps conversation history to responses
        self.text_completions = {}  # Maps prompts to responses
        self.default_chat_response = ""This is a test response""
        self.default_text_response = ""This is a test completion""
        self.base_url = ""http://localhost/v1/""  # For testing URL parsing
        
        # Create mock structure
        self.chat = MagicMock()
        self.completions = MagicMock()
        self.chat.completions = MagicMock()
        
        # Set up async methods
        self.chat.completions.create = AsyncMock(side_effect=self._handle_chat_completion)
        self.completions.create = MagicMock(side_effect=self._handle_text_completion)
",tests/conftest.py,MockAsyncOpenAI,1,2.699578619062706e-07,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class. It sets up important attributes and mock structures that are likely used in testing or simulating behavior. Constructors are fundamental to object-oriented programming and are rarely deleted unless the entire class is being refactored or removed."
survived,"    async def test_score_rollouts_with_default_infos(self):
        """"""Test scoring rollouts with default empty infos.""""""
        def simple_func(completion, **kwargs):
            return 1.0
        
        rubric = Rubric(funcs=[simple_func], weights=[1.0])
        
        results = await rubric.score_rollouts(
            prompts=[""test""],
            completions=[""test""],
            answers=[""test""],
            states=[{}],
            tasks=[""test""],
            infos=[{}]  # Explicitly provide infos to match other lists
        )
        
        assert ""simple_func"" in results
        assert results[""simple_func""] == [1.0]
",tests/test_rubric.py,TestRubric,1,2.0611536181902033e-09,"The method 'test_score_rollouts_with_default_infos' is a test function that verifies the behavior of the 'score_rollouts' method when provided with default empty 'infos'. It is a part of a test suite, likely for a larger application or library, and serves to ensure that the 'score_rollouts' function works correctly under specific conditions. Test functions are crucial for maintaining code quality and reliability, and there is no indication that this test is redundant or incorrect. Therefore, it is likely to be retained."
survived,"        def list_func(completion, **kwargs):
            return len(completion) if isinstance(completion, list) else 0.0
",tests/test_rubric.py,TestRubric,1,7.73442280641062e-08,"The method 'list_func' is a simple utility function that checks if the input 'completion' is a list and returns its length if true, otherwise returns 0.0. This function is straightforward and serves a clear purpose, which is to safely handle inputs that may or may not be lists. Such utility functions are often useful in larger codebases to ensure type safety and prevent errors. Therefore, it is likely to be retained as it provides a basic yet useful functionality."
survived,"        def kwargs_func(completion, **kwargs):
            return len(kwargs)
",tests/test_rubric.py,TestRubric,1,2.0611536181902033e-09,"The method 'kwargs_func' is a simple utility function that takes a variable number of keyword arguments and returns the count of these arguments. Such functions are often useful in scenarios where the number of parameters is not fixed, allowing for flexible function calls. This kind of utility is common in Python programming for handling dynamic inputs, making it likely to be retained in codebases where flexibility is needed. Therefore, the method is likely to survive."
survived,"        def func2(completion, **kwargs):
            return 0.5
",tests/test_rubric_group.py,TestRubricGroup,0,0.999999694097641,"The method 'func2' is very simplistic and does not utilize its parameters effectively. It takes a 'completion' argument and arbitrary keyword arguments (**kwargs), but it does not use them in any meaningful way within the function body. Instead, it simply returns a constant value of 0.5. This lack of functionality and the fact that it doesn't perform any operations based on its inputs suggest that it is not serving a useful purpose in its current form. Therefore, it is likely to be deleted unless it is part of a larger framework where this behavior is specifically required."
survived,"    def test_get_assistant_messages(self, basic_parser):
        """"""Test extraction of assistant messages from completion.""""""
        completion = [
            {""role"": ""user"", ""content"": ""Hello""},
            {""role"": ""assistant"", ""content"": ""Hi there""},
            {""role"": ""user"", ""content"": ""How are you?""},
            {""role"": ""assistant"", ""content"": ""I'm doing well""}
        ]
        assistant_messages = basic_parser.get_assistant_messages(completion)
        assert len(assistant_messages) == 2
        assert assistant_messages[0][""content""] == ""Hi there""
        assert assistant_messages[1][""content""] == ""I'm doing well""
",tests/test_parser.py,TestParser,1,9.736200303530205e-10,"The method `test_get_assistant_messages` is a unit test designed to verify the functionality of the `get_assistant_messages` method from the `basic_parser` object. It checks if the method correctly extracts messages with the role 'assistant' from a given list of message dictionaries. This is a common and necessary test to ensure that the parsing logic works as expected, especially in applications involving chat or dialogue systems. Since testing is a crucial part of software development to maintain code quality and reliability, this method is likely to be retained."
survived,"    def test_format_reward_function_good_format(self, think_parser):
        """"""Test format reward function with well-formatted content.""""""
        reward_func = think_parser.get_format_reward_func()
        
        completion = [
            {""role"": ""assistant"", ""content"": ""<think>Let me think</think>Final answer""}
        ]
        reward = reward_func(completion)
        assert reward == 1.0
",tests/test_think_parser.py,TestThinkParser,1,1.9171715133907573e-10,"The method 'test_format_reward_function_good_format' is a unit test that verifies the functionality of the 'format reward function' in a parser. It checks if the function correctly assigns a reward of 1.0 to a well-formatted completion. Unit tests are crucial for ensuring code reliability and are typically retained in codebases to maintain software quality. Therefore, this method is likely to be Survived (1)."
survived,"    def test_singleturn_env_initialization_completion(self, mock_openai_client):
        """"""Test SingleTurnEnv initialization with completion format.""""""
        completion_dataset = Dataset.from_dict({
            ""prompt"": [""Calculate 2+2:"", ""What is the capital?""],
            ""answer"": [""4"", ""It depends on the country""]
        })
        
        env = SingleTurnEnv(
            client=mock_openai_client,
            model=""test-model"",
            dataset=completion_dataset,
            message_type=""completion"",
            parser=Parser(),
            rubric=Rubric()
        )
        assert env.message_type == ""completion""
",tests/test_singleturn_env.py,TestSingleTurnEnv,1,2.998960815863541e-09,The method is a unit test for the initialization of the SingleTurnEnv class with a specific configuration. It verifies that the message_type is set correctly to 'completion'. This is a basic and necessary test to ensure that the environment is initialized as expected with the given parameters. Such tests are crucial for maintaining code quality and are unlikely to be deleted unless the functionality they test is removed or significantly altered.
survived,"    def test_rubric_group_score_rollouts_single_rubric(self):
        """"""Test scoring rollouts with a single rubric (edge case).""""""
        # Note: This test is skipped because RubricGroup.score_rollouts() has a bug
        pass
",tests/test_rubric_group.py,TestRubricGroup,0,0.9999998144608401,"The method is currently not functional due to a known bug in the RubricGroup.score_rollouts() method, as indicated by the comment. Since it is skipped and not actively contributing to the test suite, it is likely to be deleted unless the bug is fixed and the test becomes relevant again."
survived,"    async def test_call_reward_func_with_all_args(self):
        """"""Test calling reward function with all possible arguments.""""""
        def comprehensive_func(prompt, completion, answer, state, task, info, **kwargs):
            return len(completion) + len(answer) + len(task)
        
        rubric = Rubric(funcs=[], weights=[])
        
        result = await rubric.call_reward_func(
            func=comprehensive_func,
            prompt=""test prompt"",
            completion=""test completion"",
            answer=""test answer"",
            state={""key"": ""value""},
            task=""test task"",
            info={""info_key"": ""info_value""}
        )
        
        # len(""test completion"") + len(""test answer"") + len(""test task"")
        expected = len(""test completion"") + len(""test answer"") + len(""test task"")
        assert result == expected
",tests/test_rubric.py,TestRubric,1,9.736200303530205e-10,"The method is a well-structured test function that verifies the behavior of a reward function when called with all possible arguments. It uses an asynchronous call to test the functionality, which is a modern and efficient approach. The test checks if the result matches the expected value, ensuring the function works as intended. There is no indication of redundancy or obsolescence, and it serves a clear purpose in validating the reward function's behavior. Therefore, it is likely to be retained."
survived,"    def test_think_parser_with_custom_extractor(self, think_parser_with_extractor):
        """"""Test ThinkParser with custom extraction function.""""""
        assert isinstance(think_parser_with_extractor, ThinkParser)
",tests/test_think_parser.py,TestThinkParser,1,4.363462233903899e-09,"The method `test_think_parser_with_custom_extractor` is a unit test that checks if the `think_parser_with_extractor` is an instance of `ThinkParser`. This is a basic and valid test case that ensures the object is of the expected type, which is a common practice in testing to verify that the setup or the object creation is correct. There is no indication that this test is redundant or incorrect, so it is likely to be retained."
survived,"    def test_multiturn_env_initialization(self, mock_multiturn_env):
        """"""Test MultiTurnEnv initialization.""""""
        assert mock_multiturn_env.max_turns == 3
        assert mock_multiturn_env.message_type == 'chat'  # Default from parent
",tests/test_multiturn_env.py,TestMultiTurnEnv,1,2.5109990926928157e-08,"The method `test_multiturn_env_initialization` is a unit test function that checks the initialization of a `MultiTurnEnv` object. It verifies that the `max_turns` attribute is set to 3 and the `message_type` is set to 'chat'. This is a typical test case to ensure that the environment is initialized with the correct default values. Such test methods are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is likely to be retained in the codebase."
survived,"    def capture_ingest(new_canons, new_canon_packages, updated_canon_packages):
        ingest_calls.append((new_canons, new_canon_packages, updated_canon_packages))
",tests/ranker/test_dedupe.py,,1,2.3355930333443423e-09,"The method 'capture_ingest' is a simple function that appends its arguments to a list called 'ingest_calls'. This function is likely part of a larger system where capturing and logging data is necessary for tracking or debugging purposes. Since it serves a clear purpose in data collection and does not have any apparent issues or redundancies, it is likely to be retained in the codebase."
survived,"    def chaos(self) -> None:
        """"""Run chaos-client to discover subdomains from Chaos database.""""""
        if self.htb or self.is_ip_address(self.site):
            return
        
        if not self.pdcp_api_key:
            self.print(""Chaos"", ""PDCP_API_KEY not found in environment, skipping"", Colors.WARNING)
            return
        
        self.print(""Chaos"", ""Querying ProjectDiscovery Chaos database"")
        
        chaos_cmd = (
            f""chaos -d {self.site} ""
            f""-key {self.pdcp_api_key} ""
            f""{'-silent' if not self.verbose else ''} ""
            f""-o {self.dir_path}/chaos_subdomains.txt""
        )
        self.cmd(chaos_cmd)
        
        self.ask_to_add(self.read(""chaos_subdomains.txt""))
",main.py,HaxUnit,1,2.0611536181902033e-09,"The method 'chaos' is a utility function that integrates with an external service (Chaos database) to discover subdomains. It includes checks for necessary conditions (like the presence of an API key) and provides feedback to the user. Such methods are typically useful in a larger application context, especially in security or network analysis tools. The method is well-structured, handles potential issues (like missing API keys), and performs a specific, useful task. Therefore, it is likely to be retained in the codebase."
survived,"    def test_go_simple(self):
        patch = """"""
@@ -152,10 +152,6 @@ func Hello(name string) string

@@ -152,10 +152,6 @@ func (r *Receiver) MethodName() error

@@ -152,10 +152,6 @@ func (r Receiver) ValueMethod() string

@@ -152,10 +152,6 @@ var myFunc = func() {

@@ -152,10 +152,6 @@ myFunc := func() {

@@ -152,10 +152,6 @@ func Calculate(x, y int) int

@@ -152,10 +152,6 @@ func ProcessData() (string, error)

@@ -152,10 +152,6 @@ func noParams()

""""""

        assert GoParser.extract_functions_from_patch(patch) == {
            ""Hello"",
            ""MethodName"",
            ""ValueMethod"",
            ""myFunc"",
            ""Calculate"",
            ""ProcessData"",
            ""noParams"",
        }
",tests/sentry/integrations/source_code_management/test_language_parsers.py,GoParserTestCase,1,4.6911638017642294e-08,"The method `test_go_simple` is a unit test that verifies the functionality of the `GoParser.extract_functions_from_patch` method. It checks if the method correctly extracts function names from a given patch string. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with parsing logic. Since this method is a test case, it is likely to be maintained to ensure the parser works as expected. Therefore, it is unlikely to be deleted."
survived,"    def test_simple_with_go(self):
        data = [
            {""filename"": ""foo.py"", ""changes"": 100, ""status"": ""modified""},
            {""filename"": ""bar.js"", ""changes"": 100, ""status"": ""modified""},
            {""filename"": ""baz.py"", ""changes"": 100, ""status"": ""added""},
            {""filename"": ""main.go"", ""changes"": 100, ""status"": ""modified""},
            {""filename"": ""service.go"", ""changes"": 50, ""status"": ""modified""},
            {""filename"": ""handler.rb"", ""changes"": 100, ""status"": ""modified""},
        ]
        responses.add(
            responses.GET,
            self.gh_path.format(pull_number=self.pr.key),
            status=200,
            json=data,
        )

        pr_files = self.open_pr_comment_workflow.safe_for_comment(repo=self.gh_repo, pr=self.pr)
        assert pr_files == [
            {""filename"": ""foo.py"", ""changes"": 100, ""status"": ""modified""},
            {""filename"": ""bar.js"", ""changes"": 100, ""status"": ""modified""},
            {""filename"": ""main.go"", ""changes"": 100, ""status"": ""modified""},
            {""filename"": ""service.go"", ""changes"": 50, ""status"": ""modified""},
            {""filename"": ""handler.rb"", ""changes"": 100, ""status"": ""modified""},
        ]
",tests/sentry/integrations/github/tasks/test_open_pr_comment.py,TestSafeForComment,1,4.944450477491054e-09,"The method `test_simple_with_go` is a test function that verifies the behavior of a system when handling pull request files with various extensions and statuses. It uses a mock response to simulate a GitHub API call and checks if the system correctly filters out files with the status 'added'. This is a typical unit test pattern, and such tests are crucial for ensuring code reliability and correctness. Therefore, it is unlikely to be deleted as it serves an important role in maintaining the quality of the codebase."
survived,"    def test_empty_from_name(self, mock_smtp_class, smtp_provider):
        """"""Test sending email with empty from_name.""""""
        # Setup mock SMTP instance
        mock_smtp = MagicMock()
        mock_smtp_class.return_value = mock_smtp

        # Send email with empty from_name
        smtp_provider._notify(
            from_email=""sender@example.com"",
            from_name="""",
            to_email=""recipient@example.com"",
            subject=""Test Subject"",
            html=""<p>Test</p>"",
        )

        # Verify email was sent
        mock_smtp.sendmail.assert_called_once()
        call_args = mock_smtp.sendmail.call_args
        
        # Verify the From header contains only email
        email_content = call_args[0][2]
        assert ""From: sender@example.com"" in email_content
        assert ""Test Sender"" not in email_content
",tests/test_smtp_provider.py,TestSmtpProvider,1,1.0467401685178159e-08,"The method 'test_empty_from_name' is a unit test designed to verify the behavior of an email sending function when the 'from_name' is empty. This is a valid and useful test case to ensure that the email sending functionality handles cases where the sender's name is not provided, which is a realistic scenario. The test uses mocking to simulate the SMTP behavior and checks that the email is sent correctly with the expected headers. Such tests are crucial for maintaining the robustness of the email sending feature, especially in production environments. Therefore, this method is likely to be retained as part of the test suite."
survived,"    def context_manager(self):
        """"""Create a mock context manager.""""""
        return ContextManager(tenant_id=""test_tenant"", workflow_id=""test_workflow"")
",tests/test_smtp_provider.py,TestSmtpProvider,1,5.905303995456778e-10,"The method 'context_manager' is a simple utility function that returns an instance of 'ContextManager' with predefined parameters. It is likely used to facilitate testing or to provide a consistent context for operations within the application. Such utility functions are often retained because they encapsulate repetitive setup logic, making the codebase cleaner and more maintainable. Unless there is a significant change in the application's architecture or the 'ContextManager' class itself, this method is likely to survive."
survived,"    def test_send_html_email(self, mock_smtp_class, smtp_provider):
        """"""Test sending an HTML email.""""""
        # Setup mock SMTP instance
        mock_smtp = MagicMock()
        mock_smtp_class.return_value = mock_smtp

        # Send HTML email
        result = smtp_provider._notify(
            from_email=""sender@example.com"",
            from_name=""Test Sender"",
            to_email=""recipient@example.com"",
            subject=""Test HTML Subject"",
            html=""<p>This is an <strong>HTML</strong> email</p>"",
        )

        # Verify SMTP was called correctly
        mock_smtp_class.assert_called_once_with(""smtp.example.com"", 587)
        mock_smtp.starttls.assert_called_once()
        mock_smtp.login.assert_called_once_with(""test@example.com"", ""testpassword"")
        
        # Verify email was sent
        mock_smtp.sendmail.assert_called_once()
        call_args = mock_smtp.sendmail.call_args
        assert call_args[0][0] == ""sender@example.com""
        assert call_args[0][1] == ""recipient@example.com""
        
        # Verify the email content contains HTML
        email_content = call_args[0][2]
        assert ""Content-Type: text/html"" in email_content
        assert ""<p>This is an <strong>HTML</strong> email</p>"" in email_content
        
        # Verify return value
        assert result == {
            ""from"": ""sender@example.com"",
            ""to"": ""recipient@example.com"",
            ""subject"": ""Test HTML Subject"",
            ""html"": ""<p>This is an <strong>HTML</strong> email</p>"",
        }
",tests/test_smtp_provider.py,TestSmtpProvider,1,9.931195248674785e-08,"The method `test_send_html_email` is a unit test for verifying the functionality of sending an HTML email using a mocked SMTP provider. It checks various aspects such as SMTP connection, login, email sending, and the content of the email. This is a typical and necessary test to ensure that the email sending functionality works as expected, especially when dealing with HTML content. Therefore, it is unlikely to be deleted as it serves an important role in maintaining the reliability of the email sending feature."
survived,"    def reset_snapshot(self, storage: str) -> bool:
        """"""
        
        :param storage: 
        :return: 
        """"""
        try:
            cache_file = self._snapshot_cache_dir / f""{storage}_snapshot.json""
            if cache_file.exists():
                cache_file.unlink()
                logger.info(f"": {storage}"")
                return True
            logger.debug(f"": {storage}"")
            return True
        except Exception as e:
            logger.error(f"": {storage} - {e}"")
            return False
",app/monitor.py,Monitor,1,5.60279640614594e-09,"The method 'reset_snapshot' is likely to survive because it performs a specific and useful function: resetting a snapshot by deleting a cache file if it exists. This is a common operation in systems that rely on caching mechanisms to ensure that the next scan or operation starts with a fresh baseline. The method includes logging for both successful and unsuccessful operations, which is important for debugging and monitoring. Additionally, it handles exceptions gracefully, returning False if an error occurs, which is a good practice for robustness. These factors suggest that the method is well-implemented and serves a necessary purpose, making it unlikely to be deleted."
survived,"    async def test_delete_api_key_user_with_empty_id_fails(
        self,
        test_api_client: AsyncClient,
        mock_user_org_dep: Mock,
        mock_api_keys_service: Mock,
        mock_user_dep: Mock,
    ):
        """"""Test that users with empty user_id are still unauthorized.""""""
        # Setup non-anonymous organization
        mock_user_org_dep.return_value.org_id = ""org_123""
        mock_user_org_dep.return_value.is_anonymous = False

        # Mock user with empty user_id (invalid user)
        mock_user_dep.return_value = Mock(user_id="""")

        # Should not even attempt to delete
        response = await test_api_client.delete(""/_/api/keys/test_key_id"")

        assert response.status_code == 401
        assert response.json() == {""detail"": ""You are not authorized to delete this API key""}
        # Delete should not be called since authorization failed first
        mock_api_keys_service.delete_key.assert_not_called()
",api/api/routers/api_keys_test.py,TestDeleteAPIKey,1,3.653482080241728e-08,"The method is a test case that ensures the API behaves correctly when an unauthorized action is attempted. It checks that a user with an empty user_id cannot delete an API key and that the appropriate error response is returned. This is a valid and necessary test to ensure security and proper authorization checks in the system. Therefore, it is unlikely to be deleted as it serves an important purpose in maintaining the integrity of the API."
survived,"    async def test_delete_api_key_with_user_auth_success(
        self,
        test_api_client: AsyncClient,
        mock_user_org_dep: Mock,
        mock_api_keys_service: Mock,
        mock_user_dep: Mock,
    ):
        """"""Test successful deletion with user authentication.""""""
        # Setup non-anonymous organization
        mock_user_org_dep.return_value.org_id = ""org_123""
        mock_user_org_dep.return_value.is_anonymous = False

        # Mock user authentication
        mock_user_dep.return_value = Mock(user_id=""user123"")

        # Mock successful deletion
        mock_api_keys_service.delete_key.return_value = True

        response = await test_api_client.delete(""/_/api/keys/test_key_id"")

        assert response.status_code == 204
        mock_api_keys_service.delete_key.assert_called_once_with(""test_key_id"")",api/api/routers/api_keys_test.py,TestDeleteAPIKey,1,1.1861120010657661e-08,"The method is a unit test for a specific functionality, which is the deletion of an API key with user authentication. Unit tests are generally not deleted unless they are redundant, testing deprecated functionality, or replaced by a more comprehensive test. This test appears to be well-defined, testing a specific case of successful deletion with user authentication, and is likely to be useful for ensuring the correctness of the API's behavior. Therefore, it is likely to be retained."
survived,"def print_results(python_results: List[BenchmarkResult], rust_results: List[BenchmarkResult]):
    """"""Print benchmark results in a table.""""""
    table = Table(title=""Benchmark Results"")
    
    table.add_column(""Endpoint"", style=""cyan"")
    table.add_column(""Implementation"", style=""magenta"")
    table.add_column(""Concurrency"", style=""blue"")
    table.add_column(""Requests/s"", style=""green"")
    table.add_column(""Avg Latency (ms)"", style=""yellow"")
    table.add_column(""Median Latency (ms)"", style=""yellow"")
    table.add_column(""Max Latency (ms)"", style=""red"")
    table.add_column(""Errors"", style=""red"")
    
    endpoints = set(r.name for r in python_results + rust_results)
    concurrencies = set(r.concurrency for r in python_results + rust_results)
    
    for endpoint in endpoints:
        for concurrency in sorted(concurrencies):
            py_result = next((r for r in python_results if r.name == endpoint and r.concurrency == concurrency), None)
            rust_result = next((r for r in rust_results if r.name == endpoint and r.concurrency == concurrency), None)
            
            if py_result:
                table.add_row(
                    endpoint,
                    ""Python"",
                    str(py_result.concurrency),
                    f""{py_result.rps:.2f}"",
                    f""{py_result.avg_latency:.2f}"",
                    f""{py_result.median_latency:.2f}"",
                    f""{py_result.max_latency:.2f}"",
                    str(py_result.errors)
                )
            
            if rust_result:
                table.add_row(
                    endpoint,
                    ""Rust"",
                    str(rust_result.concurrency),
                    f""{rust_result.rps:.2f}"",
                    f""{rust_result.avg_latency:.2f}"",
                    f""{rust_result.median_latency:.2f}"",
                    f""{rust_result.max_latency:.2f}"",
                    str(rust_result.errors)
                )
            
            if py_result and rust_result:
                speedup = rust_result.rps / py_result.rps if py_result.rps > 0 else float('inf')
                latency_improvement = py_result.avg_latency / rust_result.avg_latency if rust_result.avg_latency > 0 else float('inf')
                
                table.add_row(
                    """",
                    f""[bold]Rust vs Python[/bold]"",
                    """",
                    f""[bold]{speedup:.2f}x[/bold]"",
                    f""[bold]{latency_improvement:.2f}x[/bold]"",
                    """",
                    """",
                    """"
                )
                
                table.add_row("""", """", """", """", """", """", """", """")
    
    console.print(table)
",benchmarks/benchmark.py,,1,3.850741907939403e-09,"The method 'print_results' is a utility function that formats and displays benchmark results in a table format. It is useful for comparing performance metrics between Python and Rust implementations, which is a common task in performance analysis and optimization. The method is well-structured, uses a clear and informative table format, and provides additional insights like speedup and latency improvement. These features make it a valuable tool for developers and analysts, increasing its likelihood of being retained in the codebase."
survived,"    def to_dict(self) -> Dict:
        """"""Convert result to dictionary.""""""
        return {
            ""name"": self.name,
            ""concurrency"": self.concurrency,
            ""requests"": self.requests,
            ""duration"": self.duration,
            ""rps"": self.rps,
            ""avg_latency"": self.avg_latency,
            ""median_latency"": self.median_latency,
            ""min_latency"": self.min_latency,
            ""max_latency"": self.max_latency,
            ""stdev_latency"": self.stdev_latency,
            ""errors"": self.errors
        }
",benchmarks/benchmark.py,BenchmarkResult,1,3.160881453314576e-10,"The method `to_dict` is a utility function that converts an object's attributes into a dictionary format. This is a common and useful pattern in programming, especially for serialization, logging, or data manipulation purposes. The method is straightforward, well-defined, and serves a clear purpose, making it unlikely to be removed unless the class structure changes significantly or a more efficient serialization method is adopted. Therefore, it is likely to survive."
survived,"    async def get_token_trades(self, parameters: dict):
        """"""Get trades for a specific token from Nansen""""""
        url = f""{self.base_url}/token/dex_trades""
        params = {
            ""address"": parameters[""address""],
            ""start_date"": parameters[""start_date""],
            ""end_date"": parameters[""end_date""]
        }
        async with aiohttp.ClientSession() as session:
            async with session.get(url, params=params, headers={""api-key"": self.api_key}) as response:
                if not response.ok:
                    raise Exception(f""HTTP error! status: {response.status} {await response.text()}"")
                return await response.json()
",python/src/plugins/nansen/goat_plugins/nansen/service.py,NansenService,1,9.736200303530205e-10,"The method 'get_token_trades' is likely to survive because it performs a specific and useful function: fetching token trade data from an external API. It is well-structured, uses asynchronous programming to handle I/O operations efficiently, and includes error handling for HTTP requests. These characteristics make it a valuable part of a codebase that interacts with external services, especially in applications dealing with financial data or blockchain analytics."
survived,"    async def get_smart_money_status(self, parameters: dict):
        """"""Get the flows of tokens associated with smart money addresses""""""
        url = f""{self.base_url}/token_flows""
        params = {
            ""start_date"": parameters[""start_date""],
            ""end_date"": parameters[""end_date""]
        }
        if parameters.get(""token_address""):
            params[""token_address""] = parameters[""token_address""]
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url, params=params, headers={""api-key"": self.api_key}) as response:
                if not response.ok:
                    raise Exception(f""HTTP error! status: {response.status} {await response.text()}"")
                return await response.json()
",python/src/plugins/nansen/goat_plugins/nansen/service.py,NansenService,1,2.4616969512093895e-10,"The method 'get_smart_money_status' is likely to survive because it provides a useful functionality of fetching token flows associated with smart money addresses, which is valuable for financial analysis and decision-making. The method is well-structured, uses asynchronous programming for efficiency, and includes error handling for HTTP requests, making it robust and reliable."
survived,"    async def get_token_details(self, parameters: dict):
        """"""Get details for a specific token from Nansen""""""
        url = f""{self.base_url}/token?address={parameters['address']}""
        async with aiohttp.ClientSession() as session:
            async with session.get(url, headers={""api-key"": self.api_key}) as response:
                if not response.ok:
                    raise Exception(f""HTTP error! status: {response.status} {await response.text()}"")
                return await response.json()
",python/src/plugins/nansen/goat_plugins/nansen/service.py,NansenService,1,2.7894680920908113e-10,"The method 'get_token_details' is likely to survive because it performs a specific and useful function: fetching token details from an external API. It uses asynchronous programming, which is efficient for I/O-bound operations like network requests. The method is well-structured, with error handling for HTTP errors, making it robust. Additionally, it leverages aiohttp, a popular library for asynchronous HTTP requests in Python, indicating modern and efficient design."
survived,"    async def get_recently_verified_tokens(self, parameters: dict):
        """"""Get recently verified tokens from RugCheck""""""
        return await self._make_request(""/stats/verified"")
",python/src/plugins/rugcheck/goat_plugins/rugcheck/service.py,RugCheckService,1,3.850741907939403e-09,"The method 'get_recently_verified_tokens' is an asynchronous function that retrieves recently verified tokens from a service called RugCheck. It uses a helper method '_make_request' to perform the actual request. The method is straightforward and serves a clear purpose, which is likely useful for users who need to access this specific data. There is no indication that this functionality is redundant or obsolete, and it seems to be a part of a larger system that interacts with RugCheck. Therefore, it is likely to be retained."
deleted,"    def test_run_version_incremented(self, mock_current_version, mock_master_version, version_increment_check, connector):
        mock_master_version.return_value = semver.Version.parse(""0.9.0"")
        mock_current_version.return_value = semver.Version.parse(""1.0.0"")
        
        result = version_increment_check._run(connector)
        
        assert result.status == CheckStatus.PASSED
        assert ""Version was properly incremented"" in result.message
",airbyte-ci/connectors/connectors_qa/tests/checks/test_version.py,TestVersionIncrementCheck,1,7.582560422162384e-10,"The method `test_run_version_incremented` is a unit test designed to verify that a version increment check works correctly. It uses mock objects to simulate the current and master versions, and then checks if the version increment logic passes as expected. Unit tests are crucial for ensuring code reliability and are typically maintained as long as the functionality they test is relevant. Since version management is a common and ongoing requirement in software development, this test is likely to remain relevant and useful. Therefore, the method is predicted to survive."
survived,"def run_test_polars_code(reasoning: str, polars_python_code: str, csv_path: str) -> str:
    """"""Executes test Polars Python code and returns results.

    The agent uses this to validate code before finalizing it.
    Results are only shown to the agent, not the user.
    The code should use Polars' lazy evaluation (LazyFrame) for better performance.

    Args:
        reasoning: Explanation of why we're running this test code
        polars_python_code: The Polars Python code to test. Should use pl.scan_csv() for lazy evaluation.
        csv_path: Path to the CSV file

    Returns:
        Code execution results as a string

    Example:
        result = run_test_polars_code(
            ""Testing average age calculation"",
            '''
            # Calculate average age using lazy evaluation
            result = df.select(pl.col(""age"").mean().alias(""avg_age"")).collect()
            print(""Average age:"", float(result[0, ""avg_age""]))
            ''',
            ""data.csv""
        )
    """"""
    try:
        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
            # Ensure code is properly indented
            indented_code = ""\n"".join(""    "" + line if line.strip() else line 
                                    for line in polars_python_code.splitlines())
            
            script = '''import polars as pl
import sys

# Read the CSV file using lazy evaluation
df = pl.scan_csv(""{csv_path}"")

try:
{code}
    
    # If no result was explicitly printed, try to collect and display
    if 'result' not in locals():
        if any(var for var in locals().values() if isinstance(var, (pl.LazyFrame, pl.DataFrame))):
            result = next(var for var in reversed(list(locals().values())) 
                      if isinstance(var, (pl.LazyFrame, pl.DataFrame)))
            if isinstance(result, pl.LazyFrame):
                result = result.collect()
        else:
            result = df.collect()
    
    # Convert result to string for display
    if isinstance(result, pl.DataFrame):
        print(result.select(pl.all()).write_csv(None))
    else:
        print(str(result))
except Exception as e:
    print(""Error: "" + str(e), file=sys.stderr)
    sys.exit(1)
'''
            script_content = script.format(csv_path=csv_path, code=indented_code)
            f.write(script_content)
            temp_file = f.name

        result = subprocess.run(['uv', 'run', '--with', 'polars', temp_file], 
                              capture_output=True, text=True)
        os.unlink(temp_file)

        if result.returncode != 0:
            return f""Error: {result.stderr}""

        console.log(f""[blue]Test Code Tool[/blue] - Reasoning: {reasoning}"")
        console.log(f""[dim]Code:\n{polars_python_code}[/dim]"")
        return result.stdout
    except Exception as e:
        console.log(f""[red]Error running test code: {str(e)}[/red]"")
        return str(e)
",sfa_polars_csv_agent_openai_v2.py,,1,5.60279640614594e-09,"The method is well-documented, has a clear purpose, and provides a useful functionality for testing Polars code with lazy evaluation. It handles exceptions, logs output, and uses temporary files effectively. These factors suggest it is a robust and useful method that is likely to be retained."
deleted,"def test_scrape_url_with_parse_pdf_true():
    if TEST_API_KEY:
        app = FirecrawlApp(api_url=API_URL, api_key=TEST_API_KEY)
        response = app.scrape_url('https://arxiv.org/pdf/astro-ph/9301001.pdf', parse_pdf=True)
        assert response is not None
        assert 'markdown' in response
        assert len(response['markdown']) > 100
",apps/python-sdk/firecrawl/__tests__/v1/e2e_withAuth/test.py,,1,1.725782769012759e-08,"The method `test_scrape_url_with_parse_pdf_true` is a unit test designed to verify the functionality of the `scrape_url` method in the `FirecrawlApp` class. It checks if the method can successfully scrape a PDF from a given URL and return a response containing a 'markdown' key with content of a certain length. This test is crucial for ensuring that the `scrape_url` method works as expected when parsing PDFs, which is likely a core feature of the application. Therefore, the test method is important for maintaining the integrity of the codebase and is likely to be retained."
survived,"def plot_pose_cube(img, yaw, pitch, roll, tdx=None, tdy=None, size=150.):
    p = pitch * np.pi / 180
    y = -(yaw * np.pi / 180)
    r = roll * np.pi / 180
    if tdx != None and tdy != None:
        face_x = tdx - 0.50 * size
        face_y = tdy - 0.50 * size

    else:
        height, width = img.shape[:2]
        face_x = width / 2 - 0.5 * size
        face_y = height / 2 - 0.5 * size

    x1 = size * (cos(y) * cos(r)) + face_x
    y1 = size * (cos(p) * sin(r) + cos(r) * sin(p) * sin(y)) + face_y
    x2 = size * (-cos(y) * sin(r)) + face_x
    y2 = size * (cos(p) * cos(r) - sin(p) * sin(y) * sin(r)) + face_y
    x3 = size * (sin(y)) + face_x
    y3 = size * (-cos(y) * sin(p)) + face_y

    cv2.line(img, (int(face_x), int(face_y)), (int(x1), int(y1)), (0, 0, 255), 3)
    cv2.line(img, (int(face_x), int(face_y)), (int(x2), int(y2)), (0, 0, 255), 3)
    cv2.line(img, (int(x2), int(y2)), (int(x2 + x1 - face_x), int(y2 + y1 - face_y)), (0, 0, 255), 3)
    cv2.line(img, (int(x1), int(y1)), (int(x1 + x2 - face_x), int(y1 + y2 - face_y)), (0, 0, 255), 3)
    cv2.line(img, (int(face_x), int(face_y)), (int(x3), int(y3)), (255, 0, 0), 2)
    cv2.line(img, (int(x1), int(y1)), (int(x1 + x3 - face_x), int(y1 + y3 - face_y)), (255, 0, 0), 2)
    cv2.line(img, (int(x2), int(y2)), (int(x2 + x3 - face_x), int(y2 + y3 - face_y)), (255, 0, 0), 2)
    cv2.line(img, (int(x2 + x1 - face_x), int(y2 + y1 - face_y)),
             (int(x3 + x1 + x2 - 2 * face_x), int(y3 + y2 + y1 - 2 * face_y)), (255, 0, 0), 2)
    cv2.line(img, (int(x3 + x1 - face_x), int(y3 + y1 - face_y)),
             (int(x3 + x1 + x2 - 2 * face_x), int(y3 + y2 + y1 - 2 * face_y)), (0, 255, 0), 2)
    cv2.line(img, (int(x2 + x3 - face_x), int(y2 + y3 - face_y)),
             (int(x3 + x1 + x2 - 2 * face_x), int(y3 + y2 + y1 - 2 * face_y)), (0, 255, 0), 2)
    cv2.line(img, (int(x3), int(y3)), (int(x3 + x1 - face_x), int(y3 + y1 - face_y)), (0, 255, 0), 2)
    cv2.line(img, (int(x3), int(y3)), (int(x3 + x2 - face_x), int(y3 + y2 - face_y)), (0, 255, 0), 2)

    return img
",face_recognition/6d_repnet_360/utils_6d_repnet_360/utils.py,,1,1.3440409770490404e-08,"The method 'plot_pose_cube' is a utility function that draws a 3D cube on an image to represent the pose of a face based on yaw, pitch, and roll angles. This is a common task in computer vision applications, particularly in facial recognition and augmented reality. The function is well-defined, uses standard libraries like OpenCV and NumPy, and serves a specific purpose in visualizing 3D orientation. Such functions are typically retained in codebases as they provide essential visualization capabilities for debugging and presentation purposes."
survived,"def cross_product(u, v):
    batch = u.shape[0]
    i = u[:, 1] * v[:, 2] - u[:, 2] * v[:, 1]
    j = u[:, 2] * v[:, 0] - u[:, 0] * v[:, 2]
    k = u[:, 0] * v[:, 1] - u[:, 1] * v[:, 0]

    out = torch.cat((i.view(batch, 1), j.view(batch, 1), k.view(batch, 1)), 1)

    return out
",face_recognition/6d_repnet_360/utils_6d_repnet_360/utils.py,,1,2.998960815863541e-09,"The method 'cross_product' is a utility function that calculates the cross product of two vectors, which is a fundamental operation in vector mathematics and is widely used in various fields such as physics, computer graphics, and engineering. The function is implemented using PyTorch, which is a popular library for tensor computations, indicating that it is likely used in a machine learning or scientific computing context. The method is well-defined, performs a specific and useful operation, and there are no apparent issues with its implementation. Therefore, it is likely to be retained in the codebase."
survived,"def get_pt2d_from_mat(mat_path):
    mat = sio.loadmat(mat_path)
    pt2d = mat['pt2d']
    return pt2d
",face_recognition/6d_repnet_360/utils_6d_repnet_360/utils.py,,1,1.6052280526088547e-09,"The method 'get_pt2d_from_mat' is a simple utility function that loads a MATLAB file and extracts a specific variable ('pt2d') from it. This type of function is commonly used in data processing tasks where MATLAB files are involved. The function is straightforward, performs a clear task, and is likely to be useful in contexts where MATLAB data needs to be accessed in Python. Therefore, it is likely to be retained in the codebase."
survived,"def py_cpu_nms(dets, thresh):
    x1 = dets[:, 0]
    y1 = dets[:, 1]
    x2 = dets[:, 2]
    y2 = dets[:, 3]
    scores = dets[:, 4]

    areas = (x2 - x1 + 1) * (y2 - y1 + 1)
    order = scores.argsort()[::-1]

    keep = []
    while order.size > 0:
        i = order[0]
        keep.append(i)
        xx1 = np.maximum(x1[i], x1[order[1:]])
        yy1 = np.maximum(y1[i], y1[order[1:]])
        xx2 = np.minimum(x2[i], x2[order[1:]])
        yy2 = np.minimum(y2[i], y2[order[1:]])

        w = np.maximum(0.0, xx2 - xx1 + 1)
        h = np.maximum(0.0, yy2 - yy1 + 1)
        inter = w * h
        ovr = inter / (areas[i] + areas[order[1:]] - inter)

        inds = np.where(ovr <= thresh)[0]
        order = order[inds + 1]

    return keep
",face_recognition/6d_repnet_360/utils_6d_repnet_360/functions.py,,1,1.955568070542584e-08,"The method `py_cpu_nms` is an implementation of the Non-Maximum Suppression (NMS) algorithm, which is a crucial part of many computer vision tasks, particularly in object detection. NMS is used to filter out overlapping bounding boxes based on their scores, retaining only the most relevant ones. This method is widely used in various machine learning and deep learning frameworks for tasks like face detection, object detection, etc. Given its importance and utility in these domains, it is unlikely that this method will be deleted. Instead, it might be optimized or adapted for specific use cases, but the core functionality will remain relevant."
survived,"    def _convert_pdf_to_markdown(self, pdf_path: str) -> List[Tuple[str, Dict[str, Any]]]:
        """"""Convert PDF with OCR detection logic.""""""
        # Quick heuristic: if the PDF already contains a text layer, skip OCR for speed
        def _pdf_has_text(path: str) -> bool:
            try:
                doc = fitz.open(path)
                for page in doc:
                    if page.get_text(""text"").strip():
                        return True
            except Exception:
                pass
            return False

        use_ocr = not _pdf_has_text(pdf_path)
        converter = self.converter_ocr if use_ocr else self.converter_no_ocr
        ocr_msg = ""(OCR enabled)"" if use_ocr else ""(no OCR)""

        print(f""Converting {pdf_path} to Markdown using docling {ocr_msg}..."")
        return self._perform_conversion(pdf_path, converter, ocr_msg)
",rag_system/ingestion/document_converter.py,DocumentConverter,1,2.0611536181902033e-09,"The method '_convert_pdf_to_markdown' is a utility function that provides a specific functionality of converting PDF files to Markdown format, with an optimization to skip OCR if the PDF already contains a text layer. This is a useful feature for applications dealing with document processing, as it can save processing time and resources. The method is well-defined, with a clear purpose and implementation, making it likely to be retained in the codebase."
survived,"                def __init__(self, provider, session, init_timestamp, kwargs):
                    self.provider = provider
                    self.session = session
                    self.init_timestamp = init_timestamp
                    self.kwargs = kwargs
                    self.stream = None
                    # Create a new LLM event for this stream
                    self.llm_event = LLMEvent(init_timestamp=init_timestamp, params=kwargs)
                    if session is not None:
                        self.llm_event.session_id = session.session_id
",agentops/llms/providers/cohere.py,CohereProvider.StreamWrapper,1,8.76424914819242e-08,"The method is a constructor (__init__) for a class, which is essential for initializing new instances of the class. It sets up important attributes such as 'provider', 'session', 'init_timestamp', and 'kwargs', and also initializes a 'stream' attribute and an 'llm_event'. Constructors are fundamental to object-oriented programming as they ensure that objects are created with a valid state. Therefore, it is unlikely that this method will be deleted."
survived,"def test_parallel_dataset_creation():
  """"""Test dataset creation with parallel processing.""""""
  threads = 4
  parsed_data = test_dataset_creation(threads=threads)

  print(f""Successfully processed dataset with {threads} threads"")
  return parsed_data
",tests/dataset_creation_test.py,,1,3.653482080241728e-08,"The method 'test_parallel_dataset_creation' is a test function that verifies the functionality of dataset creation using parallel processing. Test functions are generally important for ensuring code reliability and correctness, especially when dealing with parallel processing which can introduce concurrency issues. The method is likely to be retained as it serves a purpose in validating the code's behavior under specific conditions."
survived,"    def __init__(self, options: JupiterPluginOptions):
        super().__init__(""jupiter"", [JupiterService(options.api_key)])
",python/src/plugins/jupiter/goat_plugins/jupiter/__init__.py,JupiterPlugin,1,1.3440409770490404e-08,"The method is a constructor for a class that initializes an instance with specific options. Constructors are fundamental to class instantiation and are rarely deleted unless the class itself is being removed or significantly refactored. Since this method is essential for setting up the class with the necessary services, it is likely to survive."
survived,"    def supports_chain(self, chain) -> bool:
        return chain['type'] == 'solana'
",python/src/plugins/spl_token/goat_plugins/spl_token/__init__.py,SplTokenPlugin,1,1.6052280526088547e-09,"The method `supports_chain` is a simple utility function that checks if a given chain is of type 'solana'. This kind of method is often useful in applications that need to handle multiple blockchain types and require a way to filter or process only specific ones. Given the increasing popularity and use of blockchain technologies, such utility functions are likely to be retained to ensure code modularity and readability. Therefore, the method is likely to survive."
survived,"    def test_change_tracking_format(self, mock_post):
        mock_response = MagicMock()
        mock_response.status_code = 200
        mock_response.json.return_value = {
            'success': True,
            'data': {
                'markdown': 'Test markdown content',
                'changeTracking': {
                    'previousScrapeAt': '2023-01-01T00:00:00Z',
                    'changeStatus': 'changed',
                    'visibility': 'visible'
                }
            }
        }
        mock_post.return_value = mock_response

        app = FirecrawlApp(api_key=os.environ.get('FIRECRAWL_API_KEY', 'dummy-api-key-for-testing'))
        result = app.scrape_url('https://example.com', {
            'formats': ['markdown', 'changeTracking']
        })

        args, kwargs = mock_post.call_args
        self.assertEqual(kwargs['json']['formats'], ['markdown', 'changeTracking'])
        
        self.assertEqual(result['changeTracking']['previousScrapeAt'], '2023-01-01T00:00:00Z')
        self.assertEqual(result['changeTracking']['changeStatus'], 'changed')
        self.assertEqual(result['changeTracking']['visibility'], 'visible')
",apps/python-sdk/tests/test_change_tracking.py,TestChangeTracking,1,1.6052280526088547e-09,"The method `test_change_tracking_format` is a unit test designed to verify the functionality of the `scrape_url` method in the `FirecrawlApp` class. It uses mocking to simulate an API response and checks if the method correctly processes the response data. This is a typical and necessary part of software testing to ensure code reliability and correctness. As such, it is unlikely to be deleted unless the functionality it tests is removed or significantly altered, which is not indicated here."
survived,"    def test_change_tracking_options(self, mock_post):
        mock_response = MagicMock()
        mock_response.status_code = 200
        mock_response.json.return_value = {
            'success': True,
            'data': {
                'markdown': 'Test markdown content',
                'changeTracking': {
                    'previousScrapeAt': '2023-01-01T00:00:00Z',
                    'changeStatus': 'changed',
                    'visibility': 'visible',
                    'diff': {
                        'text': '@@ -1,1 +1,1 @@\n-old content\n+new content',
                        'json': {
                            'files': [{
                                'from': None,
                                'to': None,
                                'chunks': [{
                                    'content': '@@ -1,1 +1,1 @@',
                                    'changes': [{
                                        'type': 'del',
                                        'content': '-old content',
                                        'del': True,
                                        'ln': 1
                                    }, {
                                        'type': 'add',
                                        'content': '+new content',
                                        'add': True,
                                        'ln': 1
                                    }]
                                }]
                            }]
                        }
                    },
                    'json': {
                        'title': {
                            'previous': 'Old Title',
                            'current': 'New Title'
                        }
                    }
                }
            }
        }
        mock_post.return_value = mock_response

        app = FirecrawlApp(api_key=os.environ.get('FIRECRAWL_API_KEY', 'dummy-api-key-for-testing'))
        result = app.scrape_url('https://example.com', {
            'formats': ['markdown', 'changeTracking'],
            'changeTrackingOptions': {
                'modes': ['git-diff', 'json'],
                'schema': {'type': 'object', 'properties': {'title': {'type': 'string'}}}
            }
        })

        args, kwargs = mock_post.call_args
        self.assertEqual(kwargs['json']['formats'], ['markdown', 'changeTracking'])
        self.assertEqual(kwargs['json']['changeTrackingOptions']['modes'], ['git-diff', 'json'])
        
        self.assertEqual(result['changeTracking']['diff']['text'], '@@ -1,1 +1,1 @@\n-old content\n+new content')
        self.assertEqual(result['changeTracking']['json']['title']['previous'], 'Old Title')
        self.assertEqual(result['changeTracking']['json']['title']['current'], 'New Title')",apps/python-sdk/tests/test_change_tracking.py,TestChangeTracking,1,7.73442280641062e-08,"The method `test_change_tracking_options` is a unit test that verifies the functionality of change tracking options in a scraping application. It uses a mock response to simulate the behavior of an external API and checks if the application correctly processes the response. This is a typical use case for unit tests, which are essential for ensuring code reliability and correctness. Therefore, the method is likely to be retained as it serves a critical role in testing the application's functionality."
survived,"def test_deprecated_async_warning(mock_isinstance):
    """"""Test that using _async parameter raises a deprecation warning.""""""
    mock_model = MagicMock()
    mock_model.generate_content = MagicMock()
    mock_model.generate_content_async = MagicMock()
    
    with pytest.warns(DeprecationWarning, match=""'_async' is deprecated. Use 'use_async' instead.""):
        client = from_vertexai(
            mock_model, 
            _async=True
        )
",tests/llm/test_vertexai/test_deprecated_async.py,,0,0.999999922655772,"The method is testing for a deprecation warning, which suggests that the feature it is testing (_async parameter) is being phased out. This indicates that the method itself is likely to be deleted in the future as the feature it tests becomes obsolete."
survived,"def test_default_bucket():
    # Verify DEFAULT_BUCKET covers appropriate ranges for both fast APIs and LLM workloads
    from bentoml._internal.utils.metrics import DEFAULT_BUCKET

    # Test smallest bucket
    assert DEFAULT_BUCKET[0] == 0.005  # 5ms for fast APIs

    # Test largest finite bucket
    assert DEFAULT_BUCKET[-2] == 180.0  # 180s for LLM workloads

    # Test infinity is present
    assert DEFAULT_BUCKET[-1] == float(""inf"")

    # Test monotonic increase
    for i in range(len(DEFAULT_BUCKET) - 1):
        assert DEFAULT_BUCKET[i] < DEFAULT_BUCKET[i + 1]
",tests/unit/_internal/utils/test_metrics.py,,1,7.194132978569833e-09,"The method 'test_default_bucket' is a unit test designed to verify the properties of the 'DEFAULT_BUCKET' from the 'bentoml._internal.utils.metrics' module. It checks specific values and properties of the bucket, such as the smallest and largest finite values, the presence of infinity, and the monotonic increase of the bucket values. These are standard checks to ensure the integrity and correctness of the 'DEFAULT_BUCKET' configuration. Since this is a straightforward and necessary test to validate the functionality of a critical component, it is likely to be retained in the codebase."
survived,"    def test_pause_resume_exception_handling(self):
        """"""Test that resume is called even if exception occurs during human input.""""""
        from crewai.agents.agent_builder.base_agent_executor_mixin import CrewAgentExecutorMixin
        
        executor = CrewAgentExecutorMixin()
        executor.crew = MagicMock()
        executor.crew._train = False
        executor._printer = MagicMock()
        
        formatter = event_listener.formatter
        
        original_paused_state = formatter._live_paused
        
        try:
            with patch.object(formatter, 'pause_live_updates') as mock_pause, \
                 patch.object(formatter, 'resume_live_updates') as mock_resume, \
                 patch('builtins.input', side_effect=KeyboardInterrupt(""Test exception"")):
                
                with pytest.raises(KeyboardInterrupt):
                    executor._ask_human_input(""Test result"")
                
                mock_pause.assert_called_once()
                mock_resume.assert_called_once()
        finally:
            formatter._live_paused = original_paused_state
",tests/test_flow_human_input_integration.py,TestFlowHumanInputIntegration,1,7.73442280641062e-08,"The method is a unit test designed to ensure that the 'resume' method is called even if an exception occurs during human input. This is a critical aspect of exception handling and resource management, ensuring that the system can recover gracefully from interruptions. Such tests are essential for robust software development, especially in systems that require human interaction. Therefore, it is unlikely to be deleted as it serves an important purpose in maintaining the reliability of the code."
survived,"    def test_pause_live_updates_when_already_paused(self):
        """"""Test pausing when already paused does nothing.""""""
        formatter = ConsoleFormatter()
        
        mock_live = MagicMock(spec=Live)
        formatter._live = mock_live
        formatter._live_paused = True
        
        formatter.pause_live_updates()
        
        mock_live.stop.assert_not_called()
        assert formatter._live_paused
",tests/utilities/test_console_formatter_pause_resume.py,TestConsoleFormatterPauseResume,1,1.0467401685178159e-08,"The method 'test_pause_live_updates_when_already_paused' is a unit test that verifies the behavior of the 'pause_live_updates' method when the updates are already paused. It ensures that the 'stop' method on the 'Live' mock object is not called and that the '_live_paused' attribute remains True. This is a valid and useful test case to ensure the correct functionality of the 'pause_live_updates' method, especially in scenarios where it might be called redundantly. Therefore, it is likely to be retained as part of the test suite."
survived,"def safe_path_join(*parts: str, root: Union[str, Path, None] = None) -> str:
    """"""
    Safely join path components and ensure the result is within allowed boundaries.

    Parameters
    ----------
    *parts : str
        Variable number of path components to join.
    root : Union[str, Path, None], optional
        Root directory to use as base. If None, uses current working directory.

    Returns
    -------
    str
        String representation of the resolved path.

    Raises
    ------
    ValueError
        If the resulting path would be outside the root directory
        or if any path component is invalid.
    """"""
    if not parts:
        raise ValueError(""No path components provided"")

    try:
        # Convert all parts to strings and clean them
        clean_parts = [str(part).strip() for part in parts if part]
        if not clean_parts:
            raise ValueError(""No valid path components provided"")

        # Establish root directory
        root_path = Path(root).resolve() if root else Path.cwd()
        
        # Join and resolve the full path
        full_path = Path(root_path, *clean_parts).resolve()
        
        # Check if the resolved path is within root
        if not str(full_path).startswith(str(root_path)):
            raise ValueError(
                f""Invalid path: Potential directory traversal. Path must be within {root_path}""
            )
            
        return str(full_path)
        
    except Exception as e:
        if isinstance(e, ValueError):
            raise
        raise ValueError(f""Invalid path components: {str(e)}"")
",src/crewai/flow/path_utils.py,,1,1.3440409770490404e-08,"The method 'safe_path_join' is a utility function designed to safely join path components while ensuring the resulting path does not escape a specified root directory. This is a common requirement in applications that handle file paths, especially in web applications or systems where security is a concern. The method includes error handling for invalid inputs and potential directory traversal attacks, making it robust and useful in various scenarios. Given its utility and the fact that it addresses a specific security concern, it is likely to be retained in the codebase."
survived,"    def from_dict(cls, data: Dict[str, Any]) -> 'Fingerprint':
        """"""
        Create a Fingerprint from a dictionary representation.

        Args:
            data (Dict[str, Any]): Dictionary representation of a fingerprint

        Returns:
            Fingerprint: A new Fingerprint instance
        """"""
        if not data:
            return cls()

        fingerprint = cls(metadata=data.get(""metadata"", {}))

        # For consistency with existing stored fingerprints, we need to manually set these
        if ""uuid_str"" in data:
            object.__setattr__(fingerprint, 'uuid_str', data[""uuid_str""])
        if ""created_at"" in data and isinstance(data[""created_at""], str):
            object.__setattr__(fingerprint, 'created_at', datetime.fromisoformat(data[""created_at""]))

        return fingerprint",src/crewai/security/fingerprint.py,Fingerprint,1,2.646573631904765e-09,"The method 'from_dict' is a factory method that creates an instance of the 'Fingerprint' class from a dictionary. This is a common pattern in Python for deserializing objects from a dictionary format, which is often used in scenarios where data is received in JSON format and needs to be converted into an object. The method handles optional fields and ensures that the 'uuid_str' and 'created_at' attributes are set correctly if they are present in the input dictionary. This functionality is useful and aligns with common practices in object-oriented programming, making it likely to be retained in the codebase."
deleted,"    async def init_runtime_embeddings_model(
        self,
        model_info: persistence_model.EmbeddingsModel | sqlalchemy.Row[persistence_model.EmbeddingsModel] | dict,
    ):
        """""" Embeddings """"""
        if isinstance(model_info, sqlalchemy.Row):
            model_info = persistence_model.EmbeddingsModel(**model_info._mapping)
        elif isinstance(model_info, dict):
            model_info = persistence_model.EmbeddingsModel(**model_info)

        requester_inst = self.requester_dict[model_info.requester](ap=self.ap, config=model_info.requester_config)

        await requester_inst.initialize()

        runtime_embeddings_model = requester.RuntimeEmbeddingsModel(
            model_entity=model_info,
            token_mgr=token.TokenManager(
                name=model_info.uuid,
                tokens=model_info.api_keys,
            ),
            requester=requester_inst,
        )

        return runtime_embeddings_model
",pkg/provider/modelmgr/modelmgr.py,ModelManager,1,7.582560422162384e-10,"The method 'init_runtime_embeddings_model' is likely to survive because it is a well-structured and necessary part of the system's functionality. It initializes a runtime embeddings model, which is crucial for applications that rely on embeddings for tasks such as natural language processing or recommendation systems. The method handles different types of input (a SQLAlchemy Row or a dictionary) and sets up necessary components like a requester instance and a token manager, indicating its importance in the system's architecture."
deleted,"    async def create_embeddings_model(self, model_data: dict) -> str:
        model_data['uuid'] = str(uuid.uuid4())

        await self.ap.persistence_mgr.execute_async(sqlalchemy.insert(persistence_model.EmbeddingsModel).values(**model_data))

        embeddings_model = await self.get_embeddings_model(model_data['uuid'])

        await self.ap.model_mgr.load_embeddings_model(embeddings_model)

        return model_data['uuid']
",pkg/api/http/service/model.py,EmbeddingsModelsService,1,3.160881453314576e-10,"The method 'create_embeddings_model' is likely to survive because it performs a series of essential operations for creating and managing an embeddings model. It generates a unique identifier, persists the model data asynchronously, retrieves the model, and loads it into a manager. These steps are crucial for applications that rely on embeddings models, indicating that the method serves a significant purpose in the system."
deleted,"    async def get_embeddings_model_by_uuid(self, uuid: str) -> requester.RuntimeEmbeddingsModel:
        """"""uuid Embeddings """"""
        for model in self.embeddings_models:
            if model.model_entity.uuid == uuid:
                return model
        raise ValueError(f'Embeddings model {uuid} not found')
",pkg/provider/modelmgr/modelmgr.py,ModelManager,1,6.348800075736417e-09,"The method `get_embeddings_model_by_uuid` is a utility function that retrieves an embeddings model from a list based on a unique identifier (UUID). This is a common pattern in software development for managing collections of objects, especially when dealing with models or entities that need to be accessed by a unique key. The method is straightforward, efficient, and provides a clear error message if the model is not found, which is useful for debugging and user feedback. There is no indication that this method is redundant or could be replaced by a more efficient approach, given the context provided. Therefore, it is likely to be retained in the codebase."
deleted,"    def validate_one_of_millisecs_selector(self) -> ""WaitAction"":
        if (self.milliseconds is None) == (self.selector is None):
            raise ValueError(""Exactly one of milliseconds or selector must be provided"")
        return self
",apps/python-sdk/firecrawl/firecrawl.py,WaitAction,1,4.363462233903899e-09,"The method 'validate_one_of_millisecs_selector' is a validation method that ensures either 'milliseconds' or 'selector' is provided, but not both or neither. This is a common pattern in code to enforce correct usage of a class or function. Such validation methods are crucial for maintaining data integrity and preventing logical errors. Therefore, it is likely to be retained as it serves an important purpose in the code."
survived,"def test_get_configured_catalog_without_overrides(mock_catalog, mock_stream):
    """"""Test that get_configured_catalog uses source-defined keys when no overrides exist.""""""
    with patch.object(Source, ""_discover"", return_value=mock_catalog):
        source = Source(executor=Mock(), name=""test-source"")

        catalog = source.get_configured_catalog()

        assert len(catalog.streams) == 1
        configured_stream = catalog.streams[0]
        assert configured_stream.cursor_field == [""original_cursor""]
        assert configured_stream.primary_key == [[""original_pk""]]
",tests/unit_tests/sources/test_source_key_overrides.py,,1,3.0590235908148916e-07,"The method `test_get_configured_catalog_without_overrides` is a unit test that verifies the behavior of the `get_configured_catalog` method in the `Source` class. Unit tests are crucial for ensuring code reliability and are typically maintained as long as the functionality they test is relevant. Since this test checks that the method uses source-defined keys when no overrides exist, it is likely to be important for maintaining the integrity of the `get_configured_catalog` method. Therefore, it is unlikely to be deleted unless the functionality it tests is removed or significantly altered."
survived,"def test_get_configured_catalog_composite_primary_key(mock_catalog, mock_stream):
    """"""Test that get_configured_catalog correctly handles composite primary keys.""""""
    mock_stream.source_defined_primary_key = [[""pk1"", ""pk2""]]
    with patch.object(Source, ""_discover"", return_value=mock_catalog):
        source = Source(
            executor=Mock(),
            name=""test-source"",
            primary_key_overrides={""test_stream"": [""custom_pk1"", ""custom_pk2""]},
        )

        catalog = source.get_configured_catalog()

        assert len(catalog.streams) == 1
        configured_stream = catalog.streams[0]
        assert configured_stream.primary_key == [[""custom_pk1"", ""custom_pk2""]]
",tests/unit_tests/sources/test_source_key_overrides.py,,1,2.699578619062706e-07,"The method is a unit test for a specific functionality, which is to ensure that the `get_configured_catalog` method correctly handles composite primary keys. Unit tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is unlikely to be deleted unless the functionality it tests is removed or significantly changed."
survived,"def test_set_cursor_keys():
    """"""Test that set_cursor_keys properly updates the cursor key overrides.""""""
    with patch.object(Source, ""_discover"", return_value=Mock()):
        source = Source(executor=Mock(), name=""test-source"")

        source.set_cursor_keys(kwargs={""stream1"": ""cursor1""})
        assert source._cursor_key_overrides == {""stream1"": ""cursor1""}

        source.set_cursor_keys(kwargs={""stream2"": ""cursor2""})
        assert source._cursor_key_overrides == {
            ""stream1"": ""cursor1"",
            ""stream2"": ""cursor2"",
        }

        source.set_cursor_keys(kwargs={""stream1"": ""new_cursor1""})
        assert source._cursor_key_overrides == {
            ""stream1"": ""new_cursor1"",
            ""stream2"": ""cursor2"",
        }
",tests/unit_tests/sources/test_source_key_overrides.py,,1,2.8453347280241004e-08,"The method 'test_set_cursor_keys' is a unit test designed to verify the functionality of the 'set_cursor_keys' method in the 'Source' class. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with key-value updates like cursor keys in this case. The test checks multiple scenarios to ensure that the cursor keys are updated correctly, which is important for maintaining the integrity of the data processing logic. Therefore, this method is likely to be retained as it serves an important role in the testing suite."
survived,"    def test_tool(input_text: str) -> str:
        """"""A test tool.""""""
        return f""Result: {input_text}""
",tests/tools/test_tool_usage_limit.py,,1,5.60279640614594e-09,"The method 'test_tool' is a simple utility function that takes a string input and returns it with a prefix 'Result: '. It is a basic and generic function that can be useful in various contexts for testing or formatting purposes. Such utility functions are often retained because they provide a straightforward and reusable way to handle string manipulation tasks. There is no indication that this function is redundant or obsolete, so it is likely to survive."
survived,"    def test_cache_hit_miss(self) -> None:
        """"""Test cache hit and miss.""""""
        loader = PickleLoader(""test"", self.save_path)
        
        # No file exists yet
        assert not loader.cache_hit(""hash1"", ""Pure"")
        
        # Create a cache file
        cache_path = loader.build_path(""hash1"", ""Pure"")
        cache = Cache(
            {""var1"": ""value1""}, 
            ""hash1"", 
            set(),
            ""Pure"",
            True,
            {}
        )
        
        with open(cache_path, ""wb"") as f:
            pickle.dump(cache, f)
        
        # Now it should hit
        assert loader.cache_hit(""hash1"", ""Pure"")
        
        # Different hash should miss
        assert not loader.cache_hit(""hash2"", ""Pure"")
        
        # Different cache type should miss
        assert not loader.cache_hit(""hash1"", ""Deferred"")
        
        # Empty file should miss
        empty_path = loader.build_path(""empty"", ""Pure"")
        with open(empty_path, ""wb"") as f:
            pass
        assert not loader.cache_hit(""empty"", ""Pure"")
",tests/_save/loaders/test_pickle_loader.py,TestPickleLoader,1,2.8453347280241004e-08,"The method 'test_cache_hit_miss' is a unit test designed to verify the functionality of the 'cache_hit' method in the 'PickleLoader' class. Unit tests are crucial for ensuring code reliability and are typically retained in the codebase to facilitate ongoing testing and validation of functionality. This method is well-structured, covers multiple scenarios (cache hit, cache miss due to different hash, cache miss due to different type, and cache miss due to empty file), and is likely to be useful for maintaining the integrity of the caching mechanism. Therefore, it is unlikely to be deleted."
survived,"    def save_cache(self, cache: Cache) -> None:
        key = f""{cache.cache_type}_{cache.hash}""
        self.saved_caches[key] = cache
",tests/_save/loaders/test_loader.py,MockPersistenceLoader,1,4.599055376537186e-10,"The method 'save_cache' is a straightforward implementation that saves a cache object into a dictionary using a unique key. This functionality is essential for managing cached data, which is a common requirement in many applications to improve performance and efficiency. The method is simple, clear, and serves a specific purpose without any apparent issues or redundancies. Therefore, it is likely to be retained in the codebase."
survived,"    def teardown_method(self) -> None:
        """"""Clean up the temporary directory.""""""
        self.temp_dir.cleanup()
",tests/_save/loaders/test_pickle_loader.py,TestPickleLoader,1,2.2159489282323004e-08,"The method `teardown_method` is a common pattern in testing frameworks like pytest, where it is used to clean up resources after a test method has been executed. This method is essential for ensuring that tests do not interfere with each other by leaving behind temporary files or directories. Since it serves a crucial role in maintaining test isolation and resource management, it is unlikely to be deleted."
survived,"    def test_load_cache(self) -> None:
        """"""Test loading a cache.""""""
        loader = MemoryLoader(""test"")
        
        # Create and save a cache
        # Use string directly instead of Name constructor
        stateful_refs = set()
        cache = Cache(
            {""var1"": ""value1""}, 
            ""hash1"", 
            stateful_refs,
            ""Pure"",
            True,
            {}
        )
        loader.save_cache(cache)
        
        # Load the cache
        loaded_cache = loader.load_cache(""hash1"", ""Pure"")
        assert loaded_cache.hash == ""hash1""
        assert loaded_cache.cache_type == ""Pure""
        assert loaded_cache.hit is True
        
        # Should raise for non-existent cache
        with pytest.raises(LoaderError, match=""Unexpected cache miss""):
            loader.load_cache(""nonexistent"", ""Pure"")
",tests/_save/loaders/test_memory_loader.py,TestMemoryLoader,1,4.944450477491054e-09,"The method `test_load_cache` is a unit test designed to verify the functionality of loading a cache using a `MemoryLoader`. It includes assertions to check the correct behavior of the `load_cache` method and handles exceptions for non-existent caches. Unit tests are crucial for ensuring code reliability and are typically retained in the codebase to maintain software quality. Therefore, this method is likely to be retained."
survived,"    def test_lru_eviction(self) -> None:
        """"""Test LRU cache eviction.""""""
        loader = MemoryLoader(""test"", max_size=2)
        
        # Create and save 3 caches
        for i in range(3):
            # Use string directly instead of Name constructor
            cache = Cache(
                {f""var{i}"": f""value{i}""}, 
                f""hash{i}"", 
                set(),
                ""Pure"",
                True,
                {}
            )
            loader.save_cache(cache)
        
        # The first one should be evicted
        assert not loader.cache_hit(""hash0"", ""Pure"")
        assert loader.cache_hit(""hash1"", ""Pure"")
        assert loader.cache_hit(""hash2"", ""Pure"")
        
        # Access hash1 to move it to the end of the LRU
        loader.load_cache(""hash1"", ""Pure"")
        
        # Add another cache
        cache = Cache(
            {""var3"": ""value3""}, 
            ""hash3"", 
            set(),
            ""Pure"",
            True,
            {}
        )
        loader.save_cache(cache)
        
        # hash2 should now be evicted
        assert not loader.cache_hit(""hash0"", ""Pure"")
        assert loader.cache_hit(""hash1"", ""Pure"")
        assert not loader.cache_hit(""hash2"", ""Pure"")
        assert loader.cache_hit(""hash3"", ""Pure"")
",tests/_save/loaders/test_memory_loader.py,TestMemoryLoader,1,6.023574641292144e-08,"The method `test_lru_eviction` is a unit test designed to verify the functionality of an LRU (Least Recently Used) cache eviction mechanism. Unit tests are crucial for ensuring code reliability and correctness, especially for complex systems like caching mechanisms. This test method is well-structured, clearly defined, and serves a specific purpose in validating the behavior of the cache under different scenarios. It is unlikely to be deleted as it provides value in maintaining the integrity of the caching system."
deleted,"def mem0_storage_with_local_config(mock_mem0_memory):
    """"""Fixture to create a Mem0Storage instance with local mem0 config""""""

    # Patch the Memory class to return our mock
    with patch(""mem0.memory.main.Memory.from_config"", return_value=mock_mem0_memory) as mock_from_config:
        local_config = {
            ""vector_store"": {""provider"": ""mock_vector_store""},
            ""llm"": {""provider"": ""mock_llm""},
            ""embedder"": {""provider"": ""mock_embedder""},
        }
        
        crew = MockCrew(
            memory_config={
                ""provider"": ""mem0"",
                ""config"": {""user_id"": ""test_user"", ""local_mem0_config"": local_config},
            }
        )

        mem0_storage = Mem0Storage(type=""short_term"", crew=crew)
        return mem0_storage, mock_from_config, local_config
",tests/storage/test_mem0_storage.py,,1,9.931195248674785e-08,"The method 'mem0_storage_with_local_config' is a fixture function designed for testing purposes. It creates a mock environment for testing the Mem0Storage class with a local configuration. Such functions are typically used in unit tests to ensure that components behave as expected in controlled scenarios. Since testing is a crucial part of software development, especially for ensuring code reliability and correctness, this method is likely to be retained. It provides a specific utility in the context of testing, which is an ongoing requirement in software projects."
survived,"    def _get_current_schema(self) -> list:
        """"""Get the current schema of the runs table from the database.

        Returns:
            list: List of tuples containing column information.
                  Each tuple contains (cid, name, type, notnull, dflt_value, pk)
        """"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            cursor.execute(""PRAGMA table_info(runs)"")
            schema_info = cursor.fetchall()
        return schema_info
",src/bespokelabs/curator/db.py,MetadataDB,1,1.2501528648238603e-09,"The method '_get_current_schema' is a utility function that retrieves the schema of a database table. It is a straightforward and useful method for understanding the structure of a database table, which is a common requirement in database management and application development. The method is well-defined, uses a standard SQL command, and is likely to be used in various parts of an application that interacts with the database. Therefore, it is unlikely to be deleted."
survived,"    def get_chain(self) -> Chain:
        """"""Get the chain type for Solana.""""""
        return {""type"": ""solana""}
",python/src/wallets/solana/goat_wallets/solana/wallet.py,SolanaWalletClient,0,0.9999869928752253,"The method `get_chain` is intended to return a `Chain` object, but it currently returns a dictionary instead. This discrepancy between the return type annotation and the actual return value suggests that the method is not implemented correctly. If the `Chain` class or type is expected to be returned, the method should be updated to return an instance of `Chain` that represents Solana. Without this correction, the method is likely to be flagged for deletion or revision in a code review process. Therefore, the method is predicted to be deleted unless it is corrected to align with its intended functionality."
survived,"def solana_keypair(client: SolanaClient, keypair: Keypair) -> SolanaKeypairWalletClient:
    """"""Create a new SolanaKeypairWalletClient instance.

    Args:
        client: A Solana RPC client instance
        keypair: A Solana keypair for signing transactions

    Returns:
        A new SolanaKeypairWalletClient instance
    """"""
    return SolanaKeypairWalletClient(client, keypair)",python/src/wallets/solana/goat_wallets/solana/wallet.py,,1,1.493094675974231e-10,"The method is a simple factory function that creates and returns an instance of SolanaKeypairWalletClient. It is well-documented, with clear arguments and return type, making it easy to understand and use. Such utility functions are common in codebases to encapsulate object creation logic, especially when dealing with complex objects like clients and keypairs. Unless there is a significant change in the architecture or the way Solana clients are handled, this method is likely to survive."
survived,"    def run(self):
        """"""Run the dead link checker.""""""
        print(f""Starting dead link check for {self.base_url}"")
        print(f""Max pages: {self.max_pages}, Timeout: {self.timeout}s"")
        
        while self.pages_to_visit and len(self.visited_pages) < self.max_pages:
            url = self.pages_to_visit.popleft()
            self.crawl_page(url)
        
        print(f""\nCrawl complete!"")
        print(f""Pages visited: {len(self.visited_pages)}"")
        print(f""Links checked: {len(self.checked_links)}"")
        print(f""Dead links found: {len(self.dead_links)}"")
        
        if self.dead_links:
            print(""\n DEAD LINKS FOUND:"")
            for link_info in self.dead_links:
                print(f""  URL: {link_info['url']}"")
                print(f""  Error: {link_info['error']}"")
                print(f""  Found on: {link_info['source_page']}"")
                print()
            return False
        else:
            print(""\n No dead links found!"")
            return True
",scripts/check_dead_links.py,DeadLinkChecker,1,4.363462233903899e-09,"The method 'run' is a core part of a dead link checker tool, which is a useful utility for maintaining website integrity by identifying broken links. The method is well-structured, providing clear output on the process and results of the link checking operation. It includes informative print statements that help users understand the progress and outcome of the check. Additionally, it returns a boolean indicating the presence of dead links, which can be useful for further automated processing or decision-making. Given its functionality and clarity, it is unlikely to be deleted."
survived,"async def _search_for_implementation(tool: ToolDefinition) -> str:
    """"""
    Use web_search to find implementation details for a tool.
    
    Args:
        tool: The tool definition
        
    Returns:
        Implementation details as a string
    """"""
    try:
        try:
            from agents import Agent, Runner, function_tool
            from agents.tools import web_search
        except ImportError:
            return f""# Note: OpenAI Agents SDK not installed. Install with: pip install openai-agents\n""
            
        query = f""python implementation for {tool.name} function""
        if tool.description:
            query += f"" that {tool.description.lower()}""
            
        if tool.parameters:
            param_names = [p.name for p in tool.parameters]
            query += f"" with parameters {', '.join(param_names)}""
            
        search_results = await web_search(query, num_results=3)
        
        if not search_results or isinstance(search_results, str) and ""error"" in search_results.lower():
            return f""    # Could not find implementation details via web search\n    # Implement the {tool.name} functionality here\n    return f\""Implementation for {tool.name} with parameters: {{{', '.join([p.name + '=' + p.name for p in tool.parameters])}}}\""""
            
        return search_results
    except Exception as e:
        return f""    # Error during web search: {str(e)}\n    # Implement the {tool.name} functionality here\n    return f\""Implementation for {tool.name} with parameters: {{{', '.join([p.name + '=' + p.name for p in tool.parameters])}}}\""""
",meta_agent/generators/tool_generator.py,,1,1.6052280526088547e-09,"The method is likely to survive because it provides a useful functionality of searching for implementation details of a tool using a web search. It handles exceptions gracefully and provides fallback messages to guide the user in case of errors or missing SDK. This makes it robust and user-friendly, which are desirable traits in a method."
survived,"def generate_tool_code_sync(tool: ToolDefinition) -> str:
    """"""
    Synchronous wrapper for generate_tool_code.
    
    Args:
        tool: The tool definition
        
    Returns:
        Python code implementing the tool
    """"""
    try:
        loop = asyncio.get_event_loop()
    except RuntimeError:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
    
    if isinstance(tool, list):
        if len(tool) > 0:
            tool = tool[0]
        else:
            raise ValueError(""Empty tool list provided to generate_tool_code_sync"")
            
    return loop.run_until_complete(generate_tool_code(tool))
",meta_agent/generators/tool_generator.py,,0,0.9999687980937693,"The method `generate_tool_code_sync` is likely to be deleted because it uses synchronous code to wrap an asynchronous function, which is generally considered an anti-pattern in modern Python programming. The use of `asyncio.get_event_loop()` and `loop.run_until_complete()` suggests that the function is trying to force asynchronous code to run synchronously, which can lead to issues such as blocking the event loop and reducing the efficiency of the application. Additionally, the method does not handle the case where `generate_tool_code` might not be defined or might not be an asynchronous function, which could lead to runtime errors. Asynchronous programming is becoming more prevalent, and it is more efficient to refactor the code to be fully asynchronous rather than maintaining a synchronous wrapper."
survived,"    def test_init(self) -> None:
        """"""Test initialization of the google class.""""""
        model = google(""gemini-pro"")
        assert model.model == ""gemini-pro""
        assert model.system_message == DEFAULT_SYSTEM_MESSAGE
        assert model.api_key is None

        model = google(
            ""gemini-pro"",
            system_message=""Custom system message"",
            api_key=""test-key"",
        )
        assert model.model == ""gemini-pro""
        assert model.system_message == ""Custom system message""
        assert model.api_key == ""test-key""
",tests/_ai/llm/_impl.py,TestGoogle,1,1.955568070542584e-08,"The method `test_init` is a unit test designed to verify the initialization behavior of the `google` class. It checks that the class is correctly setting its attributes based on the provided parameters. Unit tests are crucial for ensuring code reliability and are typically retained in codebases to prevent regressions. Therefore, this method is likely to be retained as it serves an important purpose in testing the functionality of the class."
survived,"    def test_print_override_with_custom_sep_and_end(self) -> None:
        # Test print_override with custom separator and end
        thread_id = threading.get_ident()
        THREADS.add(thread_id)

        try:
            stream = MockStream()

            # Create a mock context
            context = MagicMock(spec=RuntimeContext)
            context.stream = stream
            context.execution_context = MagicMock(spec=ExecutionContext)
            context.execution_context.cell_id = ""cell1""

            with patch(""marimo._messaging.print_override._original_print"") as mock_print:
                with patch(
                    ""marimo._messaging.print_override.get_context"",
                    return_value=context,
                ):
                    print_override(""Hello"", ""world"", sep=""-"", end=""!"")

                    # Original print should not be called
                    mock_print.assert_not_called()

                    # Message should be sent to the stream with custom sep and end
                    assert len(stream.messages) == 1
                    assert stream.messages[0][1][""console""][""data""] == ""Hello-world!""
        finally:
            # Clean up
            if thread_id in THREADS:
                THREADS.remove(thread_id)
",tests/_messaging/test_print_override.py,TestPrintOverride,1,2.8453347280241004e-08,"The method is a unit test for a specific functionality, which is to test the behavior of a print override function with custom separators and end characters. Unit tests are crucial for ensuring code reliability and are typically retained in the codebase to maintain test coverage and facilitate future development. The test is well-structured, uses mocking to isolate the functionality being tested, and includes assertions to verify the expected behavior. Therefore, it is likely to be retained."
deleted,"    def test_multiple_definition_error(self) -> None:
        error = MultipleDefinitionError(
            name=""test_var"", cells=(""cell1"", ""cell2"")
        )

        # Test properties
        assert error.type == ""multiple-defs""
        assert ""test_var"" in error.describe()
        assert ""defined by another cell"" in error.describe()
",tests/_messaging/test_errors.py,TestErrorClasses,1,1.6052280526088547e-09,"The method `test_multiple_definition_error` is a unit test for the `MultipleDefinitionError` class. It checks if the error type and description are correctly set when an instance of `MultipleDefinitionError` is created. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with error handling. Therefore, this method is likely to be retained as it serves an important purpose in the codebase."
survived,"    def test_post_init_strips_trailing_quotes(self) -> None:
        # Test that __post_init__ strips trailing quotes
        option1 = CompletionOption(
            name='test_string""',
            type=""string"",
            completion_info=None,
        )
        assert option1.name == ""test_string""

        option2 = CompletionOption(
            name=""test_string'"",
            type=""string"",
            completion_info=None,
        )
        assert option2.name == ""test_string""

        # Test with multiple quotes
        option3 = CompletionOption(
            name='test_string""""""',
            type=""string"",
            completion_info=None,
        )
        assert option3.name == 'test_string'

        # Test with no quotes
        option4 = CompletionOption(
            name=""test_string"",
            type=""string"",
            completion_info=None,
        )
        assert option4.name == ""test_string""",tests/_messaging/test_completion_option.py,TestCompletionOption,1,4.1399375473943306e-08,"The method `test_post_init_strips_trailing_quotes` is a unit test designed to verify the functionality of the `__post_init__` method in the `CompletionOption` class. It checks if trailing quotes are correctly stripped from the `name` attribute. This is a useful test to ensure the robustness of the `__post_init__` method, especially if the `CompletionOption` class is used in contexts where input strings might have trailing quotes. Since it serves a clear purpose in maintaining code quality and correctness, it is likely to be retained."
survived,"    def test_stderr_write(self) -> None:
        stderr = self.MockStderr()

        # Test write method
        result = stderr.write(""Error message"")

        # Should return the length of the string
        assert result == 13

        # Should call _write_with_mimetype with text/plain mimetype
        assert len(stderr.written_data) == 1
        assert stderr.written_data[0] == (""Error message"", ""text/plain"")
",tests/_messaging/test_types.py,TestStdoutStderr,1,5.3157849718487075e-08,"The method `test_stderr_write` is a unit test for the `write` method of a mock `stderr` object. It verifies that the `write` method returns the correct length of the string and that it correctly calls another method with the expected parameters. This is a typical and necessary test to ensure the functionality of the `write` method, especially in a testing environment where mocking is used to simulate and verify behavior. Therefore, it is likely to be retained as part of the test suite."
survived,"    def test_add_output_to_buffer_no_merge(self) -> None:
        # Test adding output for an existing cell with different stream or mimetype
        outputs_buffered_per_cell = {
            ""cell1"": [
                ConsoleMsg(
                    stream=CellChannel.STDOUT,
                    cell_id=""cell1"",
                    data=""Hello"",
                    mimetype=""text/plain"",
                )
            ]
        }
        msg = ConsoleMsg(
            stream=CellChannel.STDERR,
            cell_id=""cell1"",
            data=""Error"",
            mimetype=""text/plain"",
        )

        _add_output_to_buffer(msg, outputs_buffered_per_cell)

        assert len(outputs_buffered_per_cell[""cell1""]) == 2
        assert outputs_buffered_per_cell[""cell1""][0].data == ""Hello""
        assert outputs_buffered_per_cell[""cell1""][1].data == ""Error""
",tests/_messaging/test_console_output_worker.py,TestConsoleOutputWorker,1,5.60279640614594e-09,"The method `test_add_output_to_buffer_no_merge` is a unit test that verifies the behavior of the `_add_output_to_buffer` function. It checks that when a new output message with a different stream is added to an existing cell's buffer, it does not merge with the existing message but is added as a separate entry. This is a valid and useful test case to ensure the correct functionality of the buffering mechanism. Since it serves a clear purpose in testing the code's behavior, it is likely to be retained."
survived,"    async def initialize(self):
        genai.configure(
            api_key='',
            transport='rest',
            client_options={
                'api_endpoint': self.requester_cfg['base_url'],
                'timeout': self.requester_cfg['timeout'],
            },
        )
",pkg/provider/modelmgr/requesters/geminichatcmpl.py,GeminiChatCompletions,1,2.646573631904765e-09,"The method 'initialize' is configuring a service with specific parameters such as 'api_key', 'transport', and 'client_options'. This kind of setup is essential for establishing connections or preparing a service for use, which is a common requirement in many applications. Unless there is a significant change in how the service is configured or initialized, this method is likely to remain necessary. Therefore, it is likely to survive."
survived,"def uniswap(options: UniswapPluginOptions) -> UniswapPlugin:
    """"""Create a new instance of the Uniswap plugin.
    
    Args:
        options: Configuration options for the plugin
        
    Returns:
        A configured UniswapPlugin instance
    """"""
    return UniswapPlugin(options)",python/src/plugins/uniswap/goat_plugins/uniswap/__init__.py,,1,4.363462233903899e-09,"The method 'uniswap' is a straightforward factory function that creates and returns an instance of 'UniswapPlugin' using the provided 'UniswapPluginOptions'. This is a common pattern in software design, especially for plugins or components that require configuration. The method is well-documented, indicating its purpose, arguments, and return type, which is a good practice in software development. There is no indication of redundancy or obsolescence in the code, and it serves a clear purpose in the context of creating a plugin instance. Therefore, it is likely to be retained in the codebase."
survived,"def test_evm_transaction():
    """"""Fixture providing a test EVM transaction.""""""
    return {
        ""to"": ""0x742d35Cc6634C0532925a3b844Bc454e4438f44e"",
        ""value"": 1000000000000000
    }
",python/src/wallets/crossmint/tests/conftest.py,,1,8.152020648014727e-09,"The method `test_evm_transaction` is a simple utility function that returns a dictionary representing a test Ethereum Virtual Machine (EVM) transaction. Such utility functions are often used in testing environments to provide consistent and reusable test data. The method is straightforward, has a clear purpose, and is likely to be useful in testing scenarios where EVM transactions need to be simulated. Therefore, it is likely to be retained in the codebase."
survived,"def test_user_id():
    """"""Fixture providing test user ID for wallet creation.""""""
    return 12345",python/src/wallets/crossmint/tests/conftest.py,,1,1.8189616842444243e-09,"The method 'test_user_id' is a simple fixture function that returns a static user ID for testing purposes. Such functions are commonly used in testing frameworks to provide consistent and repeatable test data. Since it serves a clear purpose in a testing context and does not have any apparent issues, it is likely to be retained in the codebase."
survived,"def test_keypair():
    """"""Fixture providing test keypair.""""""
    account = Account.create()
    return {
        ""secretKey"": account.key.hex(),
        ""address"": account.address
    }
",python/src/wallets/crossmint/tests/test_smart_wallet.py,,1,6.348800075736417e-09,"The method 'test_keypair' is a fixture function that provides a test keypair, which is likely used in testing scenarios. Such functions are typically essential for setting up test environments, especially in applications dealing with cryptographic operations or blockchain accounts. Since testing is a crucial part of software development, especially for ensuring security and correctness, this method is likely to be retained as it provides necessary functionality for tests."
survived,"def test_custodial_wallet_creation_with_email(custodial_api, test_email, solana_connection):
    """"""Test custodial wallet creation with email.""""""
    # Create wallet
    wallet = custodial_api.create_custodial_wallet(test_email)
    assert wallet[""type""] == ""solana-custodial-wallet""
    
    # Verify retrieval
    retrieved = custodial_api.get_wallet(f""email:{test_email}:solana-custodial-wallet"")
    compare_wallet_responses(wallet, retrieved)
    
    # Test client creation
    client = CustodialSolanaWalletClient(
        wallet[""address""],
        custodial_api,
        solana_connection,
        {""email"": test_email}
    )
    assert client.get_address() == wallet[""address""]
",python/src/wallets/crossmint/tests/test_custodial_wallet.py,,1,1.725782769012759e-08,"The method `test_custodial_wallet_creation_with_email` is a test function that verifies the creation and retrieval of a custodial wallet using an email. It is a part of a test suite, likely used for ensuring the functionality of a custodial wallet API. Test functions are generally not deleted unless the feature they are testing is deprecated or the testing framework is being restructured. Since this function is directly related to testing a specific feature (custodial wallet creation with email), it is likely to be maintained as long as the feature exists."
survived,"def test_error_handling_invalid_key(test_email):
    """"""Test error handling with invalid API key.""""""
    invalid_api = CrossmintWalletsAPI(
        api_key=""invalid_key"",
        base_url=""https://staging.crossmint.com""
    )
    with pytest.raises(Exception) as exc:
        invalid_api.get_wallet(f""email:{test_email}:solana-custodial-wallet"")
    assert ""Error"" in str(exc.value)
    assert ""401"" in str(exc.value) or ""403"" in str(exc.value)
",python/src/wallets/crossmint/tests/test_api_client.py,,1,2.3355930333443423e-09,"The method 'test_error_handling_invalid_key' is a unit test designed to verify error handling when an invalid API key is used. It is a crucial part of testing to ensure that the system behaves correctly under error conditions, such as unauthorized access. This kind of test is important for maintaining the robustness and security of the application, as it checks that the application properly handles authentication errors and provides meaningful error messages. Therefore, it is likely to be retained in the codebase."
survived,"    def get_json_schema(self):
        return get_generic_json_schema()
",airbyte-integrations/connectors/source-box-data-extract/source_box_data_extract/source.py,StreamAIExtractStructuredFolder,0,0.9999038976006968,"The method `get_json_schema` is a simple wrapper around the function `get_generic_json_schema`. If `get_generic_json_schema` is a stable and widely used function, this method might be retained for convenience, especially if it's part of a larger class that benefits from having a consistent interface. However, if the method doesn't add any additional functionality or abstraction, it could be considered redundant and might be removed to simplify the codebase. Without more context, it's difficult to definitively predict its fate, but given the trend towards cleaner and more efficient code, it might be more likely to be deleted."
survived,"def box_file_ai_extract_structured(client: BoxClient, file_id: str, fields_json_str: str) -> str:
    ai_item = AiItemBase(id=file_id, type=AiItemBaseTypeField.FILE)
    fields_list = json.loads(fields_json_str)
    ai_fields = []
    options = []
    for field in fields_list:
        field_options = field.get(""options"")
        if field_options is not None:
            for option in field.get(""options""):
                options.append(CreateAiExtractStructuredFieldsOptionsField(key=option.get(""key"")))

        ai_fields.append(
            CreateAiExtractStructuredFields(
                key=field.get(""key""),
                description=field.get(""description""),
                display_name=field.get(""display_name""),
                prompt=field.get(""prompt""),
                type=field.get(""type""),
                options=options if options is not None and len(options) > 0 else None,
            )
        )
    response: AiExtractResponse = client.ai.create_ai_extract_structured(items=[ai_item], fields=ai_fields)
    return json.dumps(response.to_dict(), indent=2)
",airbyte-integrations/connectors/source-box-data-extract/source_box_data_extract/box_api.py,,1,2.0611536181902033e-09,"The method 'box_file_ai_extract_structured' is likely to survive because it appears to be a well-structured and functional piece of code that performs a specific task: extracting structured data from a file using AI capabilities provided by a client. The method takes in a client, a file ID, and a JSON string of fields, processes these inputs to create AI extraction fields, and then calls a client method to perform the extraction. The code is clear, uses appropriate data structures, and handles optional fields effectively. There is no indication of deprecated functionality or poor coding practices that would necessitate its deletion."
survived,"def create_health_agent() -> Agent:
    """"""
    Create a health advisor agent.
    
    Returns:
        An Agent instance specialized in health topics.
    """"""
    instructions = """"""
    You are a health advisor with expertise in fitness, nutrition, and general wellness.
    Provide evidence-based information about health topics, focusing on practical advice.
    Always emphasize that you're not a medical professional and serious concerns should be 
    discussed with a healthcare provider.
    Keep responses concise and actionable.
    """"""
    
    return Agent(
        name=""HealthAdvisor"",
        instructions=instructions,
        model=""gpt-4o-mini"",
    )
",openai-agents-examples/03_sync_agent.py,,1,1.2501528648238603e-09,"The method `create_health_agent` is likely to survive because it is a well-defined function that creates an instance of an `Agent` specialized in health topics. It includes clear instructions for the agent, emphasizing evidence-based information and the importance of consulting healthcare professionals for serious concerns. This aligns with current trends in AI applications, where domain-specific agents are increasingly used to provide specialized advice. Additionally, the method is straightforward, with a clear purpose and implementation, making it a valuable component in systems that require health-related advisory capabilities."
survived,"def create_outline_agent() -> Agent:
    """"""
    Create an outline agent that structures content.
    
    Returns:
        An Agent instance specialized in creating outlines.
    """"""
    instructions = """"""
    You are an outline specialist who excels at organizing information into clear, logical structures.
    Your task is to create well-structured outlines for content based on research provided.
    Include main sections, subsections, and key points to cover in each section.
    Ensure the outline has a logical flow and covers the topic comprehensively.
    Focus on creating a structure that will engage readers while effectively communicating information.
    """"""
    
    return Agent(
        name=""OutlineSpecialist"",
        instructions=instructions,
        model=""gpt-4o-mini"",
        handoff_description=""Use this agent to create a structured outline based on research.""
    )
",openai-agents-examples/11_agent_orchestration.py,,1,7.582560422162384e-10,"The method 'create_outline_agent' is likely to survive because it provides a clear and useful functionality by creating an agent specialized in structuring content into outlines. This is a common requirement in content creation and organization, making the method valuable. Additionally, the method is well-documented, specifying the purpose and the expected behavior of the agent, which enhances its maintainability and usability."
survived,"def test_run_blog_writer_system():
    """"""Test that the blog writer system can run and produce a blog post.""""""
    import pytest
    
    # Skip this test if no API key is available
    if not os.environ.get(""OPENAI_API_KEY""):
        pytest.skip(""OPENAI_API_KEY not set"")
    
    # Run a test query for a simple blog post
    blog_post = asyncio.run(run_blog_writer_system(""Write a short blog post about artificial intelligence""))
    
    # Verify we got a non-empty blog post
    assert blog_post
    assert len(blog_post) > 0
    # The blog post should contain relevant terms
    assert any(term in blog_post.lower() for term in [""ai"", ""artificial intelligence"", ""technology""])
",openai-agents-examples/08_agent_with_agent_as_tool.py,,1,3.466327708641819e-07,"The method 'test_run_blog_writer_system' is a test function designed to verify the functionality of a blog writer system. It includes a check for an API key, runs a test query, and asserts the output. This is a typical structure for a test function in software development, especially when dealing with external APIs. The presence of the test indicates that the functionality it tests is important and likely to be maintained. Therefore, it is unlikely to be deleted unless the entire feature it tests is deprecated."
survived,"def create_basic_agent(instructions: str = None) -> Agent:
    """"""
    Create a basic agent with the given instructions.
    
    Args:
        instructions: Custom instructions for the agent. If None, default instructions are used.
        
    Returns:
        An Agent instance configured with the provided instructions.
    """"""
    default_instructions = """"""
    You are a helpful assistant that provides accurate and concise information.
    Always be respectful and provide factual responses based on the latest available information.
    If you don't know something, admit it rather than making up information.
    """"""
    
    # Create and return a basic agent
    return Agent(
        name=""BasicAssistant"",
        instructions=instructions or default_instructions,
        model=""gpt-4o-mini"",  # Using GPT-4o-mini as specified in requirements
    )
",openai-agents-examples/01_basic_agent.py,,1,4.944450477491054e-09,"The method 'create_basic_agent' is likely to survive because it provides a clear and useful functionality: creating an agent with customizable instructions. This is a common requirement in applications that involve AI or automated assistants. The method is well-documented, specifying the purpose, arguments, and return value, which makes it easy to understand and maintain. Additionally, it uses a default set of instructions that ensure the agent behaves in a helpful and factual manner, which is a desirable feature in many applications. The use of a specific model ('gpt-4o-mini') suggests that it is designed to work with a particular AI framework, making it relevant for systems using that model."
survived,"def create_blog_writer_agent(research_agent: Agent) -> Agent:
    """"""
    Create a blog writer agent that can use a research agent as a tool.
    
    Args:
        research_agent: The research agent to use as a tool
        
    Returns:
        An Agent instance specialized in blog writing with research capabilities
    """"""
    instructions = """"""
    You are a professional blog writer who creates engaging, informative content.
    Your writing should be clear, conversational, and tailored to a general audience.
    Structure your blog posts with an introduction, body paragraphs, and conclusion.
    Use the research tool available to you to gather accurate information on topics.
    Incorporate the research seamlessly into your writing while maintaining your voice.
    """"""
    
    # Convert the research agent into a tool
    research_tool = research_agent.as_tool(
        tool_name=""research_topic"",
        tool_description=""Research a specific topic to gather accurate information. Provide a clear, specific topic or question to research.""
    )
    
    return Agent(
        name=""BlogWriter"",
        instructions=instructions,
        model=""gpt-4o-mini"",
        tools=[research_tool]
    )
",openai-agents-examples/08_agent_with_agent_as_tool.py,,1,1.4166087846364157e-09,"The method 'create_blog_writer_agent' is likely to survive because it encapsulates a clear and useful functionality: creating a specialized agent for blog writing that leverages a research agent. This is a practical application in content creation, where combining writing skills with research capabilities is valuable. The method is well-documented, specifying its purpose, arguments, and return value, which enhances its maintainability and usability. Additionally, the use of a research tool within the agent aligns with current trends in AI-assisted content generation, making it relevant and likely to be retained."
survived,"def main():
    """"""Main function to parse arguments and run the protected agent.""""""
    parser = argparse.ArgumentParser(description=""Agent with Guardrails Example"")
    parser.add_argument(""--prompt"", ""-p"", type=str, required=True, 
                        help=""The prompt to send to the agent"")
    
    args = parser.parse_args()
    
    # Ensure API key is available
    if not os.environ.get(""OPENAI_API_KEY""):
        console.print(Panel(""[bold red]Error: OPENAI_API_KEY environment variable not set[/bold red]""))
        sys.exit(1)
    
    try:
        # Run the protected agent and get response
        response = asyncio.run(run_protected_agent(args.prompt))
        
        # Display the response
        if ""rejected"" in response.lower():
            console.print(Panel(response, title=""Input Rejected"", border_style=""red""))
        else:
            console.print(Panel(response, title=""Protected Agent Response"", border_style=""green""))
    
    except Exception as e:
        console.print(Panel(f""[bold red]Error: {str(e)}[/bold red]""))
        sys.exit(1)
",openai-agents-examples/10_agent_with_guardrails.py,,1,3.466327708641819e-07,"The method is a main function that serves as the entry point for a script. It includes argument parsing, environment variable checking, and error handling, which are all essential components for a robust command-line application. These features are commonly used and necessary for the script to function correctly, making it unlikely to be deleted."
survived,"def create_research_agent() -> Agent:
    """"""
    Create a research agent that gathers and analyzes information.
    
    Returns:
        An Agent instance specialized in research.
    """"""
    instructions = """"""
    You are a research specialist who excels at gathering and analyzing information on various topics.
    Your task is to:
    1. Understand the research request
    2. Use the search_for_information tool to gather relevant information
    3. Use the analyze_topic tool to identify key aspects for research
    4. Synthesize the information into a comprehensive, well-organized research report
    5. Include relevant facts, statistics, and context
    6. Ensure the research is accurate, balanced, and thorough
    
    Your research should be detailed enough to serve as the foundation for content creation.
    """"""
    
    # Create the research agent with function tools
    return Agent(
        name=""ResearchSpecialist"",
        instructions=instructions,
        model=""gpt-4o-mini"",
        tools=[search_for_information, analyze_topic],
        handoff_description=""Use this agent to conduct thorough research on a topic.""
    )
",openai-agents-examples/13_research_blog_system.py,,1,1.2501528648238603e-09,"The method 'create_research_agent' is well-defined and serves a clear purpose of creating a specialized agent for research tasks. It includes detailed instructions and utilizes specific tools for gathering and analyzing information, which are essential for its functionality. The method is likely to be useful in applications requiring automated research capabilities, making it relevant and valuable. Therefore, it is likely to be retained."
survived,"def create_anthropic_agent() -> Agent:
    """"""
    Create an agent that uses Anthropic's Claude model.
    
    Returns:
        An Agent instance that uses Anthropic's Claude model.
    """"""
    instructions = """"""
    You are a helpful assistant powered by Anthropic's Claude model.
    You provide accurate, thoughtful responses to user queries.
    You excel at explaining complex concepts in clear, accessible language.
    When appropriate, you break down information into easy-to-understand parts.
    You acknowledge when you don't know something rather than making up information.
    """"""
    
    # Create the Anthropic model provider
    provider = AnthropicModelProvider()
    
    # Create the agent with the Anthropic provider
    return Agent(
        name=""ClaudeAssistant"",
        instructions=instructions,
        model=""gpt-4o-mini"",  # This will be mapped to claude-3-haiku
        model_provider=provider
    )
",openai-agents-examples/12_anthropic_agent.py,,1,4.944450477491054e-09,"The method is likely to survive because it is a well-defined function that creates an agent using Anthropic's Claude model, which is a relevant and modern AI model. The function includes clear documentation, a structured approach to creating the agent, and uses a specific model provider, indicating it is part of a larger, possibly well-maintained codebase. Additionally, the use of AI models like Claude is increasingly common, suggesting that this method is aligned with current technological trends."
survived,"    def __init__(self, min_length: int = 5, max_length: int = 500):
        """"""
        Initialize the format validation guardrail.
        
        Args:
            min_length: Minimum allowed input length
            max_length: Maximum allowed input length
        """"""
        self.min_length = min_length
        self.max_length = max_length
",openai-agents-examples/10_agent_with_guardrails.py,FormatValidationGuardrail,1,3.3982678079468468e-09,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. It initializes the object with default or specified values for `min_length` and `max_length`, which are likely important for the functionality of the class. Constructors are essential for setting up initial state and are rarely deleted unless the class itself is being removed or refactored significantly. Therefore, it is highly likely that this method will survive."
survived,"def create_tech_agent() -> Agent:
    """"""
    Create a technology specialist agent.
    
    Returns:
        An Agent instance specialized in technology topics.
    """"""
    instructions = """"""
    You are a technology specialist with expertise in computer science, programming, AI, and digital technologies.
    Provide clear, accurate explanations of technical concepts and their practical applications.
    When discussing programming, focus on concepts rather than writing extensive code.
    Explain how technologies work and their real-world impact.
    """"""
    
    return Agent(
        name=""TechSpecialist"",
        instructions=instructions,
        model=""gpt-4o-mini"",
        handoff_description=""Use this agent for questions about technology, computing, programming, and digital systems.""
    )
",openai-agents-examples/02_multi_agent.py,,1,1.2501528648238603e-09,"The method 'create_tech_agent' is well-defined and serves a clear purpose of creating a specialized agent for technology topics. It includes detailed instructions for the agent, specifying its expertise and focus areas, which is useful for applications requiring specialized knowledge in technology. The method is likely to be used in systems that need to handle technology-related queries effectively. Therefore, it is unlikely to be deleted as it provides valuable functionality."
survived,"def create_research_agent() -> Agent:
    """"""
    Create a research agent that gathers information.
    
    Returns:
        An Agent instance specialized in research.
    """"""
    instructions = """"""
    You are a research specialist who excels at gathering accurate information on various topics.
    Your task is to collect relevant facts, statistics, and context on the assigned topic.
    Focus on providing comprehensive, well-organized information that covers different aspects of the topic.
    Include both general information and specific details that would be useful for content creation.
    Always prioritize accuracy and cite sources when providing specific facts.
    """"""
    
    return Agent(
        name=""ResearchSpecialist"",
        instructions=instructions,
        model=""gpt-4o-mini"",
        handoff_description=""Use this agent to gather comprehensive information on a topic.""
    )
",openai-agents-examples/11_agent_orchestration.py,,1,1.6052280526088547e-09,"The method `create_research_agent` is a well-defined function that creates and returns an instance of an `Agent` specialized in research. It includes detailed instructions for the agent, specifying its role and tasks, which is useful for applications requiring information gathering. The method is likely to be used in systems that need automated research capabilities, such as content creation tools or information retrieval systems. Given the increasing demand for AI-driven research and content generation, this method is likely to survive as it provides a clear and useful functionality."
survived,"def test_create_geography_agent():
    """"""Test that the geography agent is created with the correct configuration.""""""
    agent = create_geography_agent()
    assert agent.name == ""GeographySpecialist""
    assert ""geography specialist"" in agent.instructions.lower()
    assert agent.model == ""gpt-4o-mini""
",openai-agents-examples/04_agent_with_tracing.py,,1,1.522997951276035e-08,"The method `test_create_geography_agent` is a unit test designed to verify the correct creation of a geography agent with specific attributes. Unit tests are crucial for ensuring code reliability and correctness, especially in larger projects. This test checks the agent's name, instructions, and model, which are important aspects of the agent's configuration. Since testing is a fundamental part of software development and maintenance, this method is likely to be retained to ensure the functionality of the `create_geography_agent` function remains intact."
survived,"def test_function_tools():
    """"""Test that the function tools work correctly.""""""
    # Test weather function
    weather_result = get_current_weather(""New York"", ""celsius"")
    assert ""New York"" in weather_result
    assert ""C"" in weather_result
    
    # Test distance function
    distance_result = calculate_distance(""New York"", ""London"", ""kilometers"")
    assert ""New York"" in distance_result
    assert ""London"" in distance_result
    assert ""km"" in distance_result
    
    # Test time function
    time_result = get_current_time()
    assert ""UTC"" in time_result
    assert "":"" in time_result  # Time should contain colons
",openai-agents-examples/05_agent_with_function_tools.py,,1,2.998960815863541e-09,"The method `test_function_tools` is a test function that verifies the functionality of three different utility functions: `get_current_weather`, `calculate_distance`, and `get_current_time`. It uses assertions to check if the outputs contain expected substrings, which is a common practice in testing to ensure that functions behave as expected. Since testing is a crucial part of software development to maintain code quality and reliability, this method is likely to be retained as part of the test suite. Therefore, it will survive."
survived,"    def _format_messages_for_provider(self, messages: List[Dict[str, str]]) -> List[Dict[str, str]]:
        """"""Format messages according to provider requirements.""""""
        if not self.is_anthropic:
            return messages
            
        # Anthropic requires messages to start with 'user' role
        if not messages or messages[0][""role""] == ""system"":
            # If first message is system, add a placeholder user message
            return [{""role"": ""user"", ""content"": "".""}, *messages]
        return messages
",src/crewai/llm.py,LLM,1,3.160881453314576e-10,"The method '_format_messages_for_provider' is likely to survive because it contains logic that is specific to handling messages for a particular provider, Anthropic, which requires messages to start with a 'user' role. This kind of provider-specific formatting is often necessary in systems that integrate with multiple external services, and removing it could break functionality for that provider. Additionally, the method is well-defined, with a clear purpose and a straightforward implementation, making it a useful utility function within the codebase."
survived,"async def test_get_request_not_found():
    request_id = ""nonexistent-id""
    subdomain = ""abcd1234""
    
    mock_redis.get.return_value = None
    
    response = client.get(f""/api/get_request?id={request_id}&subdomain={subdomain}"")
    
    assert response.status_code == 404
    assert response.json() == {""detail"": ""Request not found""}
",backend/tests/test_endpoints.py,,1,2.1724399346070676e-10,"The method `test_get_request_not_found` is a unit test designed to verify the behavior of an API endpoint when a request is not found. It uses a mock Redis instance to simulate the absence of a request ID, and then checks that the API returns a 404 status code with the appropriate error message. This is a standard and necessary test to ensure the robustness of the API, particularly in handling error cases. Such tests are crucial for maintaining code quality and are unlikely to be deleted unless the functionality they test is removed or significantly altered. Therefore, the method is likely to survive."
survived,"def test_get_subdomain_from_path_edge_cases():
    assert get_subdomain_from_path("""") is None
    assert get_subdomain_from_path(""/r/"") is None
    assert get_subdomain_from_path(""/r"") is None
    assert get_subdomain_from_path(""/R/abcd1234"") == ""abcd1234""  # Case insensitivity
    assert get_subdomain_from_path(""//r//abcd1234"") == ""abcd1234""  # Extra slashes
",backend/tests/test_utils_extended.py,,1,7.73442280641062e-08,"The method `test_get_subdomain_from_path_edge_cases` is a unit test function designed to test edge cases for the `get_subdomain_from_path` function. Unit tests are crucial for ensuring the reliability and correctness of code, especially when dealing with edge cases that might not be covered by regular testing. This function is likely to be maintained as it helps in verifying that the `get_subdomain_from_path` function behaves correctly under various unusual input scenarios. The presence of assertions for different edge cases indicates that the function is actively used to prevent regressions and ensure robustness. Therefore, it is unlikely to be deleted."
survived,"    async def run_async(self):
        """"""""""""
        await self.logger.info('WebChat')
        
        try:
            while True:
                await asyncio.sleep(1)
        except asyncio.CancelledError:
            await self.logger.info('WebChat')
            raise
",pkg/platform/sources/webchat.py,WebChatAdapter,1,6.348800075736417e-09,"The method 'run_async' is an asynchronous function that logs the start and stop of a WebChat debugging adapter. It includes a loop that runs indefinitely, which is a common pattern for long-running tasks in asynchronous programming. The method also handles cancellation gracefully by catching 'asyncio.CancelledError' and logging a stop message. This indicates that the method is designed to be robust and useful for its intended purpose. Therefore, it is likely to be retained in the codebase."
survived,"    def __init__(self, config: dict, ap: app.Application, logger: logging.Logger):
        self.ap = ap
        self.logger = logger
        self.config = config
        self.debug_messages = {}
        self.debug_sessions = {}
        
        self.debug_sessions['webchatperson'] = {
            'type': 'person',
            'id': 'webchatperson',
            'name': ''
        }
        self.debug_sessions['webchatgroup'] = {
            'type': 'group', 
            'id': 'webchatgroup',
            'name': ''
        }
        
        self.debug_messages['webchatperson'] = []
        self.debug_messages['webchatgroup'] = []
",pkg/platform/sources/webchat.py,WebChatAdapter,1,9.237449576640118e-09,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class with specific attributes. It sets up important properties such as 'ap', 'logger', 'config', and initializes 'debug_messages' and 'debug_sessions' with default values. Constructors are fundamental to object-oriented programming and are rarely deleted unless the class itself is being removed or significantly refactored. Therefore, this method is likely to survive."
survived,"def toggle_report_public_state(slug: str) -> bool:
    with _lock:
        if slug not in _report_status:
            raise ValueError(f""slug {slug} not found in report status"")
        _report_status[slug][""is_public""] = not _report_status[slug].get(""is_public"", True)
        save_status()
        return _report_status[slug][""is_public""]",server/src/services/report_status.py,,1,9.736200303530205e-10,"The method `toggle_report_public_state` is likely to survive because it performs a useful function of toggling the public state of a report identified by a slug. It includes error handling for cases where the slug is not found, ensuring robustness. Additionally, it updates a shared resource (`_report_status`) in a thread-safe manner using a lock, which is crucial in concurrent environments. The method also calls `save_status()`, indicating that changes are persisted, which is often a necessary feature in applications that manage state. These characteristics make the method valuable and likely to be retained."
survived,"def search_result_item(result: rx.Var) -> rx.Component:
    """"""Render a single search result item.""""""
    return rx.box(
        rx.vstack(
            rx.text(
                result['title'],
                font_weight=""600"",
                color=""var(--c-slate-12)"",
                font_size=""14px"",
                margin_bottom=""4px""
            ),
            rx.text(
                result['content'],
                color=""var(--c-slate-11)"",
                font_size=""13px"",
                line_height=""1.4"",
                margin_bottom=""4px""
            ),
            rx.text(
                result['path'],
                color=""var(--c-slate-9)"",
                font_size=""12px""
            ),
            align_items=""start"",
            spacing=""1""
        ),
        padding=""12px"",
        border_bottom=""1px solid var(--c-slate-3)"",
        cursor=""pointer"",
        _hover={""background_color"": ""var(--c-slate-2)""},
        on_click=lambda: TypesenseSearchState.navigate_to_result(result['url'])
    )
",pcweb/components/docpage/navbar/typesense.py,,1,7.582560422162384e-10,"The method 'search_result_item' is a well-defined function that serves a clear purpose: rendering a search result item in a user interface. It uses a combination of UI components to display the title, content, and path of a search result, and includes styling and interactivity features such as hover effects and click navigation. This functionality is essential for applications that involve displaying search results, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained in the codebase."
survived,"    def index_documents(self, documents: List[Dict[str, Any]]):
        """"""Index documents to Typesense.""""""
        if not documents:
            logger.warning(""No documents to index"")
            return
        
        try:
            batch_size = 100
            for i in range(0, len(documents), batch_size):
                batch = documents[i:i + batch_size]
                for j, doc in enumerate(batch):
                    doc['id'] = str(i + j + 1)
                result = self.client.collections['docs'].documents.import_(batch)
                logger.info(f""Indexed batch {i//batch_size + 1}: {len(batch)} documents"")
            
            logger.info(f""Successfully indexed {len(documents)} documents"")
            
        except Exception as e:
            logger.error(f""Error indexing documents: {e}"")
            raise
",scripts/typesense_indexer.py,TypesenseIndexer,1,1.1032560311263802e-09,"The method 'index_documents' is a crucial part of a system that interacts with a document indexing service, Typesense. It handles the batching of documents, assigns unique IDs, and logs the process, which are all essential tasks for maintaining and monitoring the indexing process. The method also includes error handling, which is important for robustness. These factors suggest that the method is well-structured and serves a necessary function, making it unlikely to be deleted."
survived,"def main():
    """"""Main indexing function.""""""
    repo_root = Path(__file__).parent.parent
    docs_root = repo_root / 'docs'
    
    if not docs_root.exists():
        logger.error(f""Docs directory not found: {docs_root}"")
        sys.exit(1)
    
    logger.info(f""Starting indexing process for docs in: {docs_root}"")
    
    processor = MarkdownProcessor()
    indexer = TypesenseIndexer()
    
    md_files = list(docs_root.rglob('*.md'))
    logger.info(f""Found {len(md_files)} markdown files"")
    
    documents = []
    for md_file in md_files:
        doc = processor.process_file(md_file, docs_root)
        if doc:
            documents.append(doc)
    
    logger.info(f""Processed {len(documents)} documents successfully"")
    
    indexer.recreate_collection()
    indexer.index_documents(documents)
    
    logger.info(""Indexing completed successfully!"")
",scripts/typesense_indexer.py,,1,7.582560422162384e-10,"The method 'main()' is a central function for indexing markdown files in a documentation directory. It includes error handling, logging, and uses two classes, 'MarkdownProcessor' and 'TypesenseIndexer', to process and index documents. The function is well-structured, performs a critical task in the context of documentation management, and does not contain any deprecated or redundant code. Therefore, it is likely to be retained in the codebase."
survived,"    def __init__(self):
        self.md = Markdown(extensions=['meta', 'toc'])
",scripts/typesense_indexer.py,MarkdownProcessor,1,1.444980317078884e-07,"The method is a constructor for a class, likely initializing an instance of a Markdown object with specific extensions. Constructors are fundamental to class instantiation in object-oriented programming, and this one appears to be correctly implemented. There is no indication of redundancy or error that would necessitate its deletion. Therefore, it is likely to be retained in the code."
survived,"            def embed_documents(self, texts):
                return [[0.1] * OPEN_AI_VECTOR_SIZE for _ in texts]
",airbyte-integrations/connectors/destination-milvus/integration_tests/milvus_integration_test.py,MilvusIntegrationTest.FakeEmbeddings,0,0.9999810748526188,"The method 'embed_documents' is a placeholder implementation that returns a list of vectors with a fixed value (0.1) for each document. This is not a meaningful embedding and does not utilize any actual embedding model or logic. Such placeholder methods are typically used during initial development or testing phases and are expected to be replaced with a proper implementation that generates meaningful embeddings based on the content of the documents. Therefore, it is likely that this method will be deleted or significantly modified in the future to provide a functional embedding process."
survived,"    def __init__(self, transaction: str, required_signers: list = None, signer: str = None):
        self.transaction = transaction
        self.requiredSigners = required_signers or []
        self.signer = signer
",python/src/wallets/crossmint/tests/test_solana_smart_wallet.py,SolanaSmartWalletTransactionParams,1,2.8453347280241004e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes. The use of default parameters and the initialization of instance variables are standard practices in Python. There is no indication that this method is redundant or incorrect, so it is likely to be retained."
survived,"def update_user_profile(user_id: str, profile_data: Dict) -> Tuple[bool, Dict]:
    """"""
    Update a user's profile data.
    
    Args:
        user_id: The ID of the user to update
        profile_data: The profile data to update
        
    Returns:
        Tuple of (success, result) where result is either updated user data or error messages
    """"""
    # Get the current user data
    user_data = get_user_by_id(user_id)
    if not user_data:
        return False, {""error"": ""User not found""}
    
    # Validate email if provided
    if ""email"" in profile_data:
        if not validate_email(profile_data[""email""]):
            return False, {""error"": ""Invalid email format""}
    
    # In a real application, this would update the user in the database
    # For this mock, we'll just print the update
    print(f""[UPDATE] User {user_id} profile updated:"")
    for key, value in profile_data.items():
        print(f""  {key}: {value}"")
    
    # Return success with mock updated data
    updated_user = {**user_data, **profile_data}
    return True, {""user"": updated_user}
",codebase-architectures/atomic-composable-architecture/capabilities/user_management.py,,1,3.3982678079468468e-09,"The method 'update_user_profile' is a well-structured function that performs a common and necessary operation in many applications: updating a user's profile. It includes error handling for cases where the user is not found and for invalid email formats, which are important for maintaining data integrity. The function also returns a clear success status and result, making it useful for integration into larger systems. Given its utility and the fact that it is a mock implementation that can be easily adapted to real database operations, it is likely to be retained in the codebase."
survived,"    def __init__(self):
        """"""Initialize the processing stage.""""""
        self.data = None
        self.metadata = {
            ""stage"": ""processing"",
            ""status"": ""initialized"",
            ""errors"": [],
            ""processing_steps"": []
        }
",codebase-architectures/pipeline-architecture/pipeline/processing_stage.py,ProcessingStage,1,3.850741907939403e-09,"The method is a constructor (__init__) for a class, which is a fundamental part of object-oriented programming in Python. It is used to initialize the attributes of an instance of the class. The presence of this method is essential for setting up the initial state of an object, and it is unlikely to be removed unless the class itself is being refactored or removed. Therefore, it is expected to survive."
survived,"    def delete(self, collection_name, id):
        """"""Delete an item from a collection.""""""
        if collection_name not in self.data or id not in self.data[collection_name]:
            return False
        del self.data[collection_name][id]
        return True
",codebase-architectures/vertical-slice-architecture/shared/db.py,InMemoryDB,1,5.60279640614594e-09,"The method is a basic utility function for deleting an item from a collection, which is a common operation in data management systems. It checks for the existence of the collection and the item before attempting to delete, ensuring robustness. Such methods are typically essential for CRUD operations in applications, making it likely to survive."
survived,"    def delete_product(product_id):
        """"""Delete a product.""""""
        try:
            # Check if product exists
            product_data = db.get(""products"", product_id)
            if not product_data:
                Logger.warning(app_logger, f""Cannot delete: Product not found: {product_id}"")
                return False
            
            # Delete product
            result = db.delete(""products"", product_id)
            Logger.info(app_logger, f""Deleted product: {product_id}"")
            return result
        except Exception as e:
            Logger.error(app_logger, f""Error deleting product: {str(e)}"", exc_info=True)
            raise",codebase-architectures/layered-architecture/services/product_service.py,ProductService,1,1.444980317078884e-07,"The method 'delete_product' is a standard operation in many applications that manage products or inventory. It includes error handling, logging, and checks for the existence of the product before attempting deletion, which are all good practices. These factors suggest that the method is well-implemented and serves a necessary function, making it unlikely to be deleted unless there is a significant change in the application's requirements or architecture."
survived,"    def to_dict(self):
        """"""Convert category to dictionary.""""""
        return {
            ""id"": self.id,
            ""name"": self.name,
            ""description"": self.description,
            ""created_at"": self.created_at,
            ""updated_at"": self.updated_at
        }
",codebase-architectures/layered-architecture/models/category.py,Category,1,5.211412485172657e-10,"The method 'to_dict' is a common utility function used to convert an object's attributes into a dictionary format. This is particularly useful for serialization, logging, or when preparing data for APIs. Given its utility and the fact that it is a non-intrusive method that enhances the usability of the class, it is likely to be retained in the codebase."
survived,"    def get(self, table_name, item_id):
        """"""Get an item from a table by ID.""""""
        if table_name not in self.data or item_id not in self.data[table_name]:
            Logger.warning(self.logger, f""Item with ID {item_id} not found in '{table_name}'"")
            return None
        
        Logger.debug(self.logger, f""Retrieved item with ID {item_id} from '{table_name}'"")
        return self.data[table_name][item_id]
",codebase-architectures/layered-architecture/data/database.py,InMemoryDatabase,1,1.1032560311263802e-09,"The method is a basic retrieval function that checks for the existence of an item in a data structure and logs the process. It is a fundamental operation in many applications, especially those dealing with data storage and retrieval. The method is well-defined, handles errors by logging warnings, and provides useful debug information. There is no indication of redundancy or inefficiency that would necessitate its deletion."
survived,"    def create_user(username, email, name=None):
        """"""Create a new user.""""""
        try:
            user_data = {
                ""username"": username,
                ""email"": email,
                ""name"": name
            }
            return UserService.create_user(user_data)
        except ValueError as e:
            return {""error"": str(e)}
",codebase-architectures/vertical-slice-architecture/features/users/api.py,UserAPI,1,1.4166087846364157e-09,"The method 'create_user' is likely to survive because it performs a fundamental operation of creating a user, which is a common requirement in many applications. It handles exceptions gracefully by catching ValueError and returning an error message, which is a good practice. Additionally, it uses a service (UserService) to handle the actual creation, suggesting a separation of concerns and potential for reuse and testing."
survived,"    def create_category(name, description=None):
        """"""Create a new category.""""""
        try:
            # Validate category name
            if not name or not isinstance(name, str):
                raise ValueError(""Category name is required and must be a string"")
            
            # Check if category with same name already exists
            existing_categories = db.query(""categories"", lambda c: c[""name""].lower() == name.lower())
            if existing_categories:
                raise ValueError(f""Category with name '{name}' already exists"")
            
            # Create and save category
            category = Category(name=name, description=description)
            saved_category = db.insert(""categories"", category.to_dict())
            Logger.info(app_logger, f""Created category: {name}"")
            return saved_category
        except Exception as e:
            Logger.error(app_logger, f""Error creating category: {str(e)}"", exc_info=True)
            raise
",codebase-architectures/layered-architecture/services/category_service.py,CategoryService,1,9.237449576640118e-09,"The method 'create_category' is a well-defined function that handles the creation of a new category in a database. It includes validation for the category name, checks for duplicates, and logs the process. These are essential operations in many applications that manage categories or similar entities. The method also includes error handling, which is crucial for robust software. Given these factors, the method is likely to be useful and relevant in its context, leading to its survival."
survived,"    def get(self, collection_name, id):
        """"""Get an item from a collection by ID.""""""
        if collection_name not in self.data or id not in self.data[collection_name]:
            return None
        return self.data[collection_name][id]
",codebase-architectures/vertical-slice-architecture/shared/db.py,InMemoryDB,1,6.348800075736417e-09,"The method 'get' is a basic utility function that retrieves an item from a collection by its ID. It is a common pattern in data handling and is likely to be used frequently in applications that manage collections of data. The method is simple, efficient, and serves a clear purpose, making it unlikely to be deleted unless there is a significant change in the data handling strategy or architecture."
survived,"def main():
    """"""Run the application.""""""
    Logger.info(app_logger, ""Starting Layered Architecture Example"")
    
    display_header(""Layered Architecture Example"")
    
    # Create categories
    display_header(""Creating Categories"")
    
    electronics_result = CategoryAPI.create_category(""Electronics"", ""Electronic devices and gadgets"")
    display_result(electronics_result)
    
    books_result = CategoryAPI.create_category(""Books"", ""Books and e-books"")
    display_result(books_result)
    
    clothing_result = CategoryAPI.create_category(""Clothing"", ""Apparel and accessories"")
    display_result(clothing_result)
    
    # Try to create a duplicate category
    duplicate_result = CategoryAPI.create_category(""Electronics"", ""Duplicate category"")
    display_result(duplicate_result)
    
    # Get all categories
    display_header(""All Categories"")
    categories_result = CategoryAPI.get_all_categories()
    display_result(categories_result)
    
    # Create products
    display_header(""Creating Products"")
    
    # Get category IDs
    categories = categories_result[""data""]
    electronics_id = next((c[""id""] for c in categories if c[""name""] == ""Electronics""), None)
    books_id = next((c[""id""] for c in categories if c[""name""] == ""Books""), None)
    
    # Create products
    laptop_result = ProductAPI.create_product(
        ""Laptop"", 
        999.99, 
        electronics_id, 
        ""High-performance laptop"", 
        ""TECH-001""
    )
    display_result(laptop_result)
    
    phone_result = ProductAPI.create_product(
        ""Smartphone"", 
        499.99, 
        electronics_id, 
        ""Latest smartphone model"", 
        ""TECH-002""
    )
    display_result(phone_result)
    
    book_result = ProductAPI.create_product(
        ""Programming Book"", 
        29.99, 
        books_id, 
        ""Learn programming with this book"", 
        ""BOOK-001""
    )
    display_result(book_result)
    
    # Try to create a product with invalid price
    invalid_result = ProductAPI.create_product(
        ""Invalid Product"", 
        ""not-a-price"", 
        electronics_id
    )
    display_result(invalid_result)
    
    # Get products by category
    display_header(""Electronics Products"")
    electronics_products = ProductAPI.get_products_by_category(electronics_id)
    display_result(electronics_products)
    
    # Update a product
    display_header(""Updating a Product"")
    if laptop_result.get(""success"") and ""data"" in laptop_result:
        laptop_id = laptop_result[""data""][""id""]
        update_result = ProductAPI.update_product(
            laptop_id,
            price=899.99,
            description=""High-performance laptop with discount""
        )
        display_result(update_result)
    
    # Try to delete a category with products
    display_header(""Trying to Delete a Category with Products"")
    delete_result = CategoryAPI.delete_category(electronics_id)
    display_result(delete_result)
    
    # Delete a product
    display_header(""Deleting a Product"")
    if phone_result.get(""success"") and ""data"" in phone_result:
        phone_id = phone_result[""data""][""id""]
        delete_product_result = ProductAPI.delete_product(phone_id)
        display_result(delete_product_result)
    
    # Get all products
    display_header(""All Remaining Products"")
    all_products = ProductAPI.get_all_products()
    display_result(all_products)
    
    Logger.info(app_logger, ""Layered Architecture Example completed"")
",codebase-architectures/layered-architecture/main.py,,1,6.825604231969389e-08,"The method 'main()' is a comprehensive demonstration of a layered architecture example, showcasing various operations such as creating categories and products, handling duplicates, updating, and deleting entities. It serves as a practical example for understanding the flow of operations in an application. The method is well-structured, informative, and provides a complete walkthrough of the application's capabilities, making it a valuable resource for learning and reference. Therefore, it is likely to be retained in the codebase."
survived,"    def filter_data(self, filter_func, description=None):
        """"""
        Filter the data using the provided filter function.
        
        Args:
            filter_func: Function that takes a data item and returns True to keep it
            description: Description of the filter for metadata
        
        Returns:
            dict: Stage result with data and metadata
        """"""
        if self.data is None:
            self.metadata[""status""] = ""error""
            self.metadata[""errors""].append(""No data to filter"")
            return self._create_result()
        
        try:
            original_count = len(self.data) if isinstance(self.data, list) else 1
            
            # Apply filter
            if isinstance(self.data, list):
                self.data = [item for item in self.data if filter_func(item)]
            else:
                self.data = self.data if filter_func(self.data) else None
            
            # Update metadata
            filtered_count = len(self.data) if isinstance(self.data, list) else (1 if self.data else 0)
            filter_info = {
                ""description"": description or ""Custom filter"",
                ""original_count"": original_count,
                ""filtered_count"": filtered_count,
                ""removed_count"": original_count - filtered_count
            }
            
            if not hasattr(self, ""filters_applied""):
                self.filters_applied = []
            self.filters_applied.append(filter_info)
            
            self.metadata[""processing_steps""].append(""filter_data"")
            self.metadata[""filters_applied""] = self.filters_applied
            
            return self._create_result()
        except Exception as e:
            self.metadata[""status""] = ""error""
            self.metadata[""errors""].append(f""Filter error: {str(e)}"")
            return self._create_result()
",codebase-architectures/pipeline-architecture/pipeline/processing_stage.py,ProcessingStage,1,6.348800075736417e-09,"The method 'filter_data' is well-structured and provides a clear functionality to filter data based on a user-provided function. It includes error handling, updates metadata, and maintains a history of applied filters. These features make it a useful and robust method for data processing tasks. Therefore, it is likely to be retained in the codebase."
survived,"    def get_by_username(username):
        """"""Get a user by username.""""""
        user = UserService.get_by_username(username)
        if not user:
            return {""error"": f""User with username '{username}' not found""}
        return user
",codebase-architectures/vertical-slice-architecture/features/users/api.py,UserAPI,1,6.348800075736417e-09,"The method 'get_by_username' is a straightforward utility function that retrieves a user by their username using a service call. It includes error handling to return a meaningful error message if the user is not found. This is a common pattern in software development for user retrieval operations, and it is likely to be useful in many contexts where user data is needed. Therefore, it is unlikely to be deleted unless there is a significant change in how users are managed or retrieved in the system."
survived,"    def __init__(self):
        """"""
        Initialize the file editor pipeline.
        """"""
        # Create pipeline stages
        self.input_stage = InputStage()
        self.processing_stage = ProcessingStage()
        self.output_stage = OutputStage()
        
        # Create and configure pipeline
        self.pipeline = Pipeline(""File Editor Pipeline"")
        
        # Add stages
        self.pipeline.add_stage(""input"", self.input_stage)
        self.pipeline.add_stage(""processing"", self.processing_stage)
        self.pipeline.add_stage(""output"", self.output_stage)
        
        console.log(""[file_editor_pipeline] Initialized file editor pipeline"")
",example-agent-codebase-arch/pipeline-architecture/pipeline_manager/file_editor_pipeline.py,FileEditorPipeline,1,7.194132978569833e-09,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class. It sets up the necessary stages and configures the pipeline, which are likely crucial for the functionality of the class. Constructors are fundamental components of class definitions in object-oriented programming, and they are rarely deleted unless the class itself is being removed or significantly refactored. Therefore, it is highly likely that this method will survive."
survived,"    def from_dict(cls, data: Dict[str, Any]) -> 'ToolUseRequest':
        """"""
        Create a tool use request from a dictionary.
        
        Args:
            data: Dictionary containing the tool use request
            
        Returns:
            A ToolUseRequest instance
        """"""
        command = data.get(""command"")
        path = data.get(""path"")
        
        # Extract all other keys as kwargs
        kwargs = {k: v for k, v in data.items() if k not in [""command"", ""path""]}
        
        return cls(command, path, **kwargs)",example-agent-codebase-arch/pipeline-architecture/shared/utilities.py,ToolUseRequest,1,1.1032560311263802e-09,"The method 'from_dict' is a common and useful pattern for creating instances of a class from a dictionary, especially in scenarios where data is often received in JSON format and needs to be converted into class instances. This method is well-documented, follows a clear structure, and uses Python's dictionary unpacking feature to handle additional parameters flexibly. Such methods are typically retained in codebases as they provide a convenient and standardized way to instantiate objects from data structures. Therefore, it is likely to be retained."
survived,"    def process(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """"""
        Process the input data and return the result.
        
        Args:
            data: The input data to process
            
        Returns:
            The processed data
        """"""
        raise NotImplementedError(""Pipeline stages must implement the process method"")
",example-agent-codebase-arch/pipeline-architecture/pipeline_manager/pipeline_manager.py,PipelineStage,1,4.222835268240621e-06,"The method 'process' is defined as an abstract method with a NotImplementedError, indicating that it is intended to be overridden by subclasses. This is a common pattern in object-oriented programming to enforce that subclasses provide specific implementations for certain methods. Since this method is part of a design pattern and serves a clear purpose in ensuring subclasses implement their own 'process' logic, it is unlikely to be deleted."
survived,"    def _insert_text(self, path: str, insert_line: int, new_str: str) -> FileOperationResult:
        """"""
        Insert text at a specific location in a file.

        Args:
            path: The path to the file to modify
            insert_line: The line number after which to insert the text
            new_str: The text to insert

        Returns:
            FileOperationResult with result or error message
        """"""
        try:
            if not path or not path.strip():
                error_msg = ""Invalid file path provided: path is empty.""
                console.log(f""[insert_text] Error: {error_msg}"")
                return FileOperationResult(False, error_msg)

            # Normalize the path
            path = normalize_path(path)

            if not os.path.exists(path):
                error_msg = f""File {path} does not exist""
                console.log(f""[insert_text] Error: {error_msg}"")
                return FileOperationResult(False, error_msg)

            if insert_line is None:
                error_msg = ""No line number specified: insert_line is missing.""
                console.log(f""[insert_text] Error: {error_msg}"")
                return FileOperationResult(False, error_msg)

            with open(path, ""r"") as f:
                lines = f.readlines()

            # Line is 0-indexed for this function, but Claude provides 1-indexed
            insert_line = min(max(0, insert_line - 1), len(lines))

            # Check that the index is within acceptable bounds
            if insert_line < 0 or insert_line > len(lines):
                error_msg = (
                    f""Insert line number {insert_line} out of range (0-{len(lines)}).""
                )
                console.log(f""[insert_text] Error: {error_msg}"")
                return FileOperationResult(False, error_msg)

            # Ensure new_str ends with newline
            if new_str and not new_str.endswith(""\n""):
                new_str += ""\n""

            lines.insert(insert_line, new_str)

            with open(path, ""w"") as f:
                f.writelines(lines)

            console.print(
                f""[green]Successfully inserted text at line {insert_line + 1} in {path}[/green]""
            )
            console.log(
                f""[insert_text] Successfully inserted text at line {insert_line + 1} in {path}""
            )
            return FileOperationResult(
                True, f""Successfully inserted text at line {insert_line + 1} in {path}""
            )
        except Exception as e:
            error_msg = f""Error inserting text: {str(e)}""
            console.print(f""[red]{error_msg}[/red]"")
            console.log(f""[insert_text] Error: {str(e)}"")
            console.log(traceback.format_exc())
            return FileOperationResult(False, error_msg)
",example-agent-codebase-arch/pipeline-architecture/steps/processing_stage.py,ProcessingStage,1,1.8189616842444243e-09,"The method '_insert_text' is well-structured and provides a clear functionality of inserting text into a file at a specified line. It includes error handling for various edge cases such as invalid paths, non-existent files, and out-of-range line numbers. Additionally, it logs errors and successes, which is useful for debugging and monitoring. The method is likely to be useful in scenarios where file manipulation is required, and it adheres to good coding practices. Therefore, it is likely to be retained in the codebase."
survived,"    def to_dict(self) -> Dict[str, Any]:
        """"""
        Convert the result to a dictionary.
        
        Returns:
            Dictionary representation of the result
        """"""
        return {
            ""success"": self.success,
            ""message"": self.message,
            ""data"": self.data
        }
",example-agent-codebase-arch/vertical-slice-architecture/features/file_operations/model.py,FileOperationResult,1,1.4166087846364157e-09,"The method 'to_dict' is a utility function that converts an object's attributes into a dictionary format. This is a common and useful pattern in programming, especially for serialization, logging, or data manipulation purposes. It is likely to be used frequently in applications where objects need to be converted to a format that is easily readable or transferable, such as JSON. Therefore, it is a practical and necessary method that is unlikely to be removed."
survived,"    def run_agent(
        client: Anthropic,
        prompt: str,
        handle_tool_use_func,
        max_thinking_tokens: int = DEFAULT_THINKING_TOKENS,
        max_loops: int = 10,
        use_token_efficiency: bool = False,
    ) -> Tuple[str, int, int]:
        """"""
        Run the Claude agent with file editing capabilities.

        Args:
            client: The Anthropic client
            prompt: The user's prompt
            handle_tool_use_func: Function to handle tool use requests
            max_thinking_tokens: Maximum tokens for thinking
            max_loops: Maximum number of tool use loops
            use_token_efficiency: Whether to use token-efficient tool use beta feature

        Returns:
            Tuple containing:
            - Final response from Claude (str)
            - Total input tokens used (int)
            - Total output tokens used (int)
        """"""
        # Track token usage
        input_tokens_total = 0
        output_tokens_total = 0
        system_prompt = """"""You are a helpful AI assistant with text editing capabilities.
You have access to a text editor tool that can view, edit, and create files.
Always think step by step about what you need to do before taking any action.
Be careful when making edits to files, as they can permanently change the user's files.
Follow these steps when handling file operations:
1. First, view files to understand their content before making changes
2. For edits, ensure you have the correct context and are making the right changes
3. When creating files, make sure they're in the right location with proper formatting
""""""

        # Define text editor tool
        text_editor_tool = {""name"": ""str_replace_editor"", ""type"": ""text_editor_20250124""}

        messages = [
            {
                ""role"": ""user"",
                ""content"": f""""""I need help with editing files. Here's what I want to do:

{prompt}

Please use the text editor tool to help me with this. First, think through what you need to do, then use the appropriate tool.
"""""",
            }
        ]

        loop_count = 0
        tool_use_count = 0
        thinking_start_time = time.time()

        while loop_count < max_loops:
            loop_count += 1

            console.rule(f""[yellow]Agent Loop {loop_count}/{max_loops}[/yellow]"")
            Logger.info(app_logger, f""Starting agent loop {loop_count}/{max_loops}"")

            # Create message with text editor tool
            message_args = {
                ""model"": MODEL,
                ""max_tokens"": 4096,
                ""tools"": [text_editor_tool],
                ""messages"": messages,
                ""system"": system_prompt,
                ""thinking"": {""type"": ""enabled"", ""budget_tokens"": max_thinking_tokens},
            }

            # Use the beta.messages with betas parameter if token efficiency is enabled
            if use_token_efficiency:
                # Using token-efficient tools beta feature
                message_args[""betas""] = [""token-efficient-tools-2025-02-19""]
                response = client.beta.messages.create(**message_args)
            else:
                # Standard approach
                response = client.messages.create(**message_args)

            # Track token usage
            if hasattr(response, ""usage""):
                input_tokens = getattr(response.usage, ""input_tokens"", 0)
                output_tokens = getattr(response.usage, ""output_tokens"", 0)

                input_tokens_total += input_tokens
                output_tokens_total += output_tokens

                console.print(
                    f""[dim]Loop {loop_count} tokens: Input={input_tokens}, Output={output_tokens}[/dim]""
                )
                Logger.info(
                    app_logger, 
                    f""Loop {loop_count} tokens: Input={input_tokens}, Output={output_tokens}""
                )

            # Process response content
            thinking_block = None
            tool_use_block = None
            text_block = None

            for content_block in response.content:
                if content_block.type == ""thinking"":
                    thinking_block = content_block
                    # Access the thinking attribute which contains the actual thinking text
                    if hasattr(thinking_block, ""thinking""):
                        console.print(
                            Panel(
                                thinking_block.thinking,
                                title=f""Claude's Thinking (Loop {loop_count})"",
                                border_style=""blue"",
                            )
                        )
                    else:
                        console.print(
                            Panel(
                                ""Claude is thinking..."",
                                title=f""Claude's Thinking (Loop {loop_count})"",
                                border_style=""blue"",
                            )
                        )
                elif content_block.type == ""tool_use"":
                    tool_use_block = content_block
                    tool_use_count += 1
                elif content_block.type == ""text"":
                    text_block = content_block

            # If we got a final text response with no tool use, we're done
            if text_block and not tool_use_block:
                thinking_end_time = time.time()
                thinking_duration = thinking_end_time - thinking_start_time

                console.print(
                    f""\n[bold green]Completed in {thinking_duration:.2f} seconds after {loop_count} loops and {tool_use_count} tool uses[/bold green]""
                )
                Logger.info(
                    app_logger,
                    f""Completed in {thinking_duration:.2f} seconds after {loop_count} loops and {tool_use_count} tool uses""
                )

                # Add the response to messages
                messages.append(
                    {
                        ""role"": ""assistant"",
                        ""content"": [
                            *([thinking_block] if thinking_block else []),
                            {""type"": ""text"", ""text"": text_block.text},
                        ],
                    }
                )

                return text_block.text, input_tokens_total, output_tokens_total

            # Handle tool use
            if tool_use_block:
                # Add the assistant's response to messages before handling tool calls
                messages.append({""role"": ""assistant"", ""content"": response.content})

                console.print(
                    f""\n[bold blue]Tool Call:[/bold blue] {tool_use_block.name}""
                )
                Logger.info(app_logger, f""Tool Call: {tool_use_block.name}"")

                # Handle the tool use
                tool_result = handle_tool_use_func(tool_use_block.input)

                # Log tool result
                result_text = tool_result.get(""error"") or tool_result.get(""result"", """")
                Logger.info(app_logger, f""Tool Result: {result_text[:100]}..."")

                # Format tool result for Claude
                tool_result_message = {
                    ""role"": ""user"",
                    ""content"": [
                        {
                            ""type"": ""tool_result"",
                            ""tool_use_id"": tool_use_block.id,
                            ""content"": result_text,
                        }
                    ],
                }
                messages.append(tool_result_message)

        # If we reach here, we hit the max loops
        console.print(
            f""\n[bold red]Warning: Reached maximum loops ({max_loops}) without completing the task[/bold red]""
        )
        Logger.warning(
            app_logger,
            f""Reached maximum loops ({max_loops}) without completing the task""
        )
        return (
            ""I wasn't able to complete the task within the allowed number of thinking steps. Please try a more specific prompt or increase the loop limit."",
            input_tokens_total,
            output_tokens_total,
        )",example-agent-codebase-arch/layered-architecture/services/agent_service.py,AgentService,1,3.2241866333029355e-08,"The method 'run_agent' is a comprehensive function designed to interact with an AI agent, handle tool usage, and manage token usage efficiently. It includes detailed logging, error handling, and a structured approach to processing AI responses. Given its complexity and utility in managing AI interactions, it is likely to be retained for future use, especially in applications requiring AI-driven file editing capabilities."
survived,"    def __init__(self, success: bool, message: str, data: Any = None):
        """"""
        Initialize a file operation result.
        
        Args:
            success: Whether the operation was successful
            message: A message describing the result
            data: Optional data returned by the operation
        """"""
        self.success = success
        self.message = message
        self.data = data
",example-agent-codebase-arch/pipeline-architecture/shared/utilities.py,FileOperationResult,1,2.5109990926928157e-08,"The method is a constructor for a class, likely used to initialize instances with specific attributes. It is a standard and necessary part of object-oriented programming in Python, especially when creating classes that need to store state or data. The method is well-documented and follows common practices, making it unlikely to be deleted unless the entire class is refactored or removed."
survived,"def main():
    """"""Main entry point for the application.""""""
    # Set up argument parser
    parser = argparse.ArgumentParser(description=""Claude 3.7 File Editor Agent"")
    parser.add_argument(
        ""--prompt"",
        ""-p"",
        required=True,
        help=""The prompt for what file operations to perform"",
    )
    parser.add_argument(
        ""--max-loops"",
        ""-l"",
        type=int,
        default=15,
        help=""Maximum number of tool use loops (default: 15)"",
    )
    parser.add_argument(
        ""--thinking"",
        ""-t"",
        type=int,
        default=DEFAULT_THINKING_TOKENS,
        help=f""Maximum thinking tokens (default: {DEFAULT_THINKING_TOKENS})"",
    )
    parser.add_argument(
        ""--efficiency"",
        ""-e"",
        action=""store_true"",
        help=""Enable token-efficient tool use (beta feature)"",
    )
    args = parser.parse_args()

    console.print(Panel.fit(""Claude 3.7 File Editor Agent (Vertical Slice Architecture)""))
    console.print(f""\n[bold]Prompt:[/bold] {args.prompt}\n"")
    console.print(f""[dim]Thinking tokens: {args.thinking}[/dim]"")
    console.print(f""[dim]Max loops: {args.max_loops}[/dim]"")
    
    if args.efficiency:
        console.print(f""[dim]Token-efficient tools: Enabled[/dim]\n"")
    else:
        console.print(f""[dim]Token-efficient tools: Disabled[/dim]\n"")

    # For testing purposes, we'll just print a success message
    console.print(""[green]Successfully loaded the Vertical Slice Architecture implementation![/green]"")
    console.print(""[yellow]This is a mock implementation for testing the architecture structure.[/yellow]"")
    console.print(""[yellow]In a real implementation, this would connect to the Claude API.[/yellow]"")

    # Display mock token usage
    display_token_usage(1000, 500)
",example-agent-codebase-arch/vertical-slice-architecture/main.py,,1,1.522997951276035e-08,"The method 'main()' is a well-structured entry point for a command-line application. It sets up an argument parser, handles command-line arguments, and provides informative console output. The method is useful for testing and demonstrating the architecture of the application, even if it is a mock implementation. It is unlikely to be deleted as it serves as a crucial part of the application's interface and testing framework."
survived,"def test_create_folder_structure_normal_name_unchanged():
    with tempfile.TemporaryDirectory() as temp_dir:
        os.chdir(temp_dir)
        folder_path, folder_name, class_name = create_folder_structure(""hello"")
        
        assert folder_name == ""hello""
        assert class_name == ""Hello""
        assert folder_path.name == ""hello""
        assert folder_path.exists()
",tests/cli/test_create_crew.py,,1,1.0467401685178159e-08,"The method `test_create_folder_structure_normal_name_unchanged` is a unit test designed to verify the functionality of the `create_folder_structure` function. It checks if the folder structure is created correctly with the expected folder name and class name. Unit tests are crucial for ensuring code reliability and are typically retained in the codebase to prevent future regressions. Therefore, this method is likely to be retained as it serves an important purpose in testing the functionality of the code."
survived,"def test_create_crew_normal_name_still_works(mock_load_env, mock_write_env, mock_copy_template, temp_dir):
    mock_load_env.return_value = {}
    
    with tempfile.TemporaryDirectory() as work_dir:
        os.chdir(work_dir)
        create_crew(""normal-project"", skip_provider=True)
        
        project_path = Path(work_dir) / ""normal_project""
        assert project_path.exists()
        assert (project_path / ""src"" / ""normal_project"").exists()
",tests/cli/test_create_crew.py,,1,2.3355930333443423e-09,"The method 'test_create_crew_normal_name_still_works' is a unit test function that verifies the functionality of the 'create_crew' function. It uses mock objects to simulate dependencies and checks if the project directory is created correctly. This is a typical pattern in testing to ensure code reliability and is unlikely to be deleted unless the functionality it tests is removed or significantly changed. Therefore, it is more likely to survive."
survived,"    def _persist_state(flow_instance: Any, method_name: str) -> None:
        """"""Helper to persist state with error handling.""""""
        try:
            # Get flow UUID from state
            state = getattr(flow_instance, 'state', None)
            if state is None:
                raise ValueError(""Flow instance has no state"")
                
            flow_uuid: Optional[str] = None
            if isinstance(state, dict):
                flow_uuid = state.get('id')
            elif isinstance(state, BaseModel):
                flow_uuid = getattr(state, 'id', None)
                
            if not flow_uuid:
                raise ValueError(
                    ""Flow state must have an 'id' field for persistence""
                )
                
            # Persist the state
            persistence.save_state(
                flow_uuid=flow_uuid,
                method_name=method_name,
                state_data=state,
            )
        except Exception as e:
            logger.error(
                f""Failed to persist state for method {method_name}: {str(e)}""
            )
            raise RuntimeError(f""State persistence failed: {str(e)}"") from e
",src/crewai/flow/persistence/decorators.py,,1,6.348800075736417e-09,"The method '_persist_state' is likely to survive because it is a utility function that handles a common task of persisting state with error handling. It includes robust error checking and logging, which are essential for maintaining the integrity of state management in applications. Additionally, it uses a try-except block to manage exceptions, making it reliable and maintainable. Such methods are typically retained as they provide necessary functionality and improve code reliability."
survived,"    def __init__(self, endpoint: str):
        self.endpoint = endpoint
",python/src/plugins/jsonrpc/goat_plugins/jsonrpc/service.py,JSONRpcService,1,1.1861120010657661e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming in Python. Constructors are essential for initializing new objects with specific attributes, in this case, setting the 'endpoint' attribute. There is no indication that this method is redundant or unnecessary, so it is likely to be retained."
survived,"def compile_llms_txt():
    """"""Compile all relevant documentation into llms.txt for AI model consumption.""""""
    current_dir = Path(os.getcwd())
    content = ''
    
    # Define names of directories and files to exclude
    excluded_names = {'node_modules', '.git', '__pycache__', '.venv', 'images', '.pytest_cache', 'dist', 'build'}
    
    def should_include_file(file_path):
        """"""Check if a file should be included based on patterns and exclusions.""""""
        path_parts = Path(file_path).parts
        
        if any(part in excluded_names for part in path_parts):
            return False
            
        if file_path.endswith(('.md', '.mdx')):
            return True
            
        return False
    
    for root, dirs, files in os.walk('..'):
        dirs[:] = [d for d in dirs if d not in excluded_names]
        
        for file in files:
            if should_include_file(file):
                file_path = os.path.join(root, file)
                relative_path = os.path.relpath(file_path, '..')
                
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        file_content = f.read()
                    content += f""## {relative_path}\n\n{file_content}\n\n""
                except (UnicodeDecodeError, PermissionError) as e:
                    print(f""Warning: Could not read {relative_path}: {e}"")
                    continue

    # Write the complete content to llms.txt in the repository root
    output_path = Path('../llms.txt')
    output_path.write_text(content, encoding='utf-8')
    print(f""Successfully compiled documentation to {output_path.absolute()}"")
    print(f""Total content length: {len(content)} characters"")
",docs/compile_llms_txt.py,,1,9.237449576640118e-09,"The method 'compile_llms_txt' is a utility function that compiles documentation files into a single text file, 'llms.txt'. This functionality is useful for aggregating documentation for AI model consumption or other purposes. The method includes error handling for file reading and excludes certain directories and files, making it robust and practical. Such utility functions are often retained in codebases as they serve a specific and useful purpose."
survived,"    def supports_function_calling(self) -> bool:
        return True
",tests/custom_llm_test.py,JWTAuthLLM,1,2.646573631904765e-09,"The method `supports_function_calling` is a simple method that returns a boolean value, specifically `True`. This kind of method is often used to indicate a capability or feature support within a class or module. Since it is straightforward and serves a clear purpose, it is likely to be retained unless the feature it indicates is deprecated or the method is replaced by a more comprehensive solution. Without additional context suggesting such changes, it is reasonable to predict that the method will survive."
survived,"    def supports_stop_words(self) -> bool:
        """"""Check if the LLM supports stop words.
        
        Returns:
            True if the LLM supports stop words, False otherwise.
        """"""
        pass
",src/crewai/llm.py,BaseLLM,1,7.73442280641062e-08,"The method `supports_stop_words` is a placeholder function that currently does not contain any implementation. However, the method's purpose is clearly defined in the docstring, indicating that it is intended to check if a language model (LLM) supports stop words. This functionality could be important for users who need to understand the capabilities of the LLM regarding text processing and filtering. Given the increasing importance of natural language processing and the need for customizable text handling, this method is likely to be implemented in the future rather than deleted. Therefore, it is more likely to survive."
survived,"    def test_get_content_with_none_delta(self) -> None:
        # Create a mock response with choices but delta is None
        mock_response = Mock()
        mock_response.choices = [Mock()]
        mock_response.choices[0].delta = None
        
        # Ensure text attribute doesn't exist to avoid fallback
        type(mock_response).text = property(lambda self: None)

        # Call get_content with the mock response
        result = get_content(mock_response)

        # Assert that the result is None
        self.assertIsNone(result)
",tests/_server/test_ai.py,TestGetContent,1,2.8453347280241004e-08,"The method 'test_get_content_with_none_delta' is a unit test designed to verify the behavior of the 'get_content' function when it receives a mock response with a 'delta' attribute set to None. This test is crucial for ensuring that the 'get_content' function handles edge cases correctly, particularly when the expected data is missing or None. Unit tests are generally not deleted unless they are redundant or the functionality they test is removed. Since this test is specific and tests a particular edge case, it is likely to be retained to ensure the robustness of the 'get_content' function."
