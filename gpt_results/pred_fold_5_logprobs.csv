status,method,filepath,class_name,predict,prob_deleted,reason
survived,"    def __init__(self):
        self.functions: dict[str, ast.FunctionDef | ast.AsyncFunctionDef] = {}
        self.stack: list[ast.ClassDef] = []
",dev/check_function_signatures.py,FunctionSignatureExtractor,1,4.1399375473943306e-08,"The method is a constructor (__init__) for a class, which is a fundamental part of object-oriented programming in Python. It initializes the instance variables of the class, which are essential for the class's functionality. The use of type annotations for the dictionary and list also suggests that this code is modern and adheres to best practices. Therefore, it is unlikely that this method will be deleted as it is crucial for the class's operation."
survived,"def test_parameter_error_has_location_info():
    old_code = ""def func(a): pass""
    new_code = ""def func(b): pass""

    old_tree = ast.parse(old_code)
    new_tree = ast.parse(new_code)
    errors = check_signature_compatibility(old_tree.body[0], new_tree.body[0])

    assert len(errors) == 1
    assert errors[0].lineno == 1
    assert errors[0].col_offset > 0
",tests/dev/test_check_function_signatures.py,,1,1.8189616842444243e-09,"The method 'test_parameter_error_has_location_info' is a unit test function that checks if the 'check_signature_compatibility' function correctly identifies a change in function parameter names and provides location information for the error. This is a useful test for ensuring that the 'check_signature_compatibility' function works as expected, particularly in providing detailed error information. Since it serves a clear purpose in testing functionality, it is likely to be retained in the codebase."
survived,"    def visit_ClassDef(self, node: ast.ClassDef) -> None:
        self.stack.append(node)
        self.generic_visit(node)
        self.stack.pop()
",dev/check_function_signatures.py,FunctionSignatureExtractor,1,1.4166087846364157e-09,"The method visit_ClassDef is a part of a visitor pattern implementation, commonly used in abstract syntax tree (AST) processing. It is likely used to traverse and process class definitions within the AST. The method is simple and correctly manages a stack to keep track of the current node being visited, which is a standard practice in AST traversal. There is no indication that this method is redundant or incorrect, so it is likely to be retained."
survived,"def parse_args() -> Args:
    parser = argparse.ArgumentParser(
        description=""Check for breaking changes in Python function signatures""
    )
    parser.add_argument(""--base-branch"", default=os.environ.get(""GITHUB_BASE_REF"", ""master""))
    args = parser.parse_args()
    return Args(base_branch=args.base_branch)
",dev/check_function_signatures.py,,1,8.152020648014727e-09,"The method 'parse_args' is a utility function that uses the argparse library to parse command-line arguments. It is a common practice to encapsulate argument parsing in a function for better code organization and reusability. The function is straightforward, serves a clear purpose, and is likely part of a larger script or application that checks for breaking changes in Python function signatures. There is no indication that this function is redundant or unnecessary, and it is likely to be useful for the intended application. Therefore, it is likely to survive."
survived,"def get_visualization_data():
    """"""Return the visualization data and raw tensor data.""""""
    records, tensor_table, failures = collect_grid()
    visualization_data = {}
    raw_tensor_data = {}

    for grid_idx, program_records in records.items():
        viz_data, raw_data, kernel_src = prepare_visualization_data(
            program_records, tensor_table
        )
        visualization_data[str(grid_idx)] = viz_data
        raw_tensor_data.update(raw_data)

    # Get the kernel source code

    return {
        ""visualization_data"": visualization_data,
        ""raw_tensor_data"": raw_tensor_data,
        ""failures"": failures,
        ""kernel_src"": kernel_src,
    }
",triton_viz/visualizer/draw.py,,1,1.1032560311263802e-09,"The method `get_visualization_data` is likely to survive because it provides a structured way to collect and return important data for visualization purposes. It aggregates data from multiple sources, processes it, and returns it in a format that is useful for further analysis or visualization. This kind of functionality is often essential in data processing pipelines, especially in fields like machine learning or data science where visualization of data is crucial for understanding and interpreting results. Additionally, the method appears to be well-organized and clear in its purpose, which adds to its likelihood of being retained."
survived,"    def test_simple_matrix(self, func, expected_diag):
        """"""Test simple 2x2 matrix calculation.""""""
        data = np.array([[1, 2, 3, 4], [2, 4, 6, 8]], dtype=np.float64)
        result = func(data)

        # Check shape
        assert result.shape == (2, 2)

        # Check diagonal
        if expected_diag is not None:
            assert_allclose(np.diag(result), [expected_diag, expected_diag])
        else:
            # For covariance, just check diagonal is non-negative
            assert np.all(np.diag(result) >= 0)

        # Check symmetry
        assert_allclose(result, result.T)

        # For perfect linear relationship, correlation should be 1
        if func == nancorrmatrix:
            assert_allclose(result, [[1.0, 1.0], [1.0, 1.0]])
",numbagg/test/test_matrix_functions.py,TestMatrixFunctions,1,1.637377179507321e-07,"The method `test_simple_matrix` is a unit test function designed to verify the correctness of a matrix calculation function. It checks the shape, diagonal values, symmetry, and specific properties of the result matrix. Such test functions are crucial for ensuring code reliability and correctness, especially in mathematical computations. Therefore, it is unlikely to be deleted as it serves an important role in validating the functionality of the code it tests."
survived,"    def test_three_series_consistency(self):
        """"""Test consistency for a 3x3 matrix case.""""""
        np.random.seed(444)

        # Create three time series
        n_obs = 30
        a1 = np.random.randn(n_obs)
        a2 = np.random.randn(n_obs) * 1.5 + 0.5
        a3 = np.random.randn(n_obs) * 0.8 - 0.2

        alpha = 0.35

        # Test all pairwise combinations
        pairs = [(a1, a2, 0, 1), (a1, a3, 0, 2), (a2, a3, 1, 2)]

        # Compute matrix result once
        data_matrix = np.array([a1, a2, a3])
        cov_matrix_result = move_exp_nancovmatrix(data_matrix, alpha=alpha)
        corr_matrix_result = move_exp_nancorrmatrix(data_matrix, alpha=alpha)

        for series1, series2, i, j in pairs:
            # Compute pairwise results
            cov_nonmatrix = move_exp_nancov(series1, series2, alpha=alpha)
            corr_nonmatrix = move_exp_nancorr(series1, series2, alpha=alpha)

            # Extract from matrix results
            cov_from_matrix = cov_matrix_result[:, i, j]
            corr_from_matrix = corr_matrix_result[:, i, j]

            # They should match
            assert_allclose(
                cov_nonmatrix,
                cov_from_matrix,
                rtol=1e-10,
                err_msg=f""Covariance mismatch for series {i},{j}"",
            )
            assert_allclose(
                corr_nonmatrix,
                corr_from_matrix,
                rtol=1e-10,
                err_msg=f""Correlation mismatch for series {i},{j}"",
            )

            # Also check symmetry
            assert_allclose(
                cov_matrix_result[:, i, j], cov_matrix_result[:, j, i], rtol=1e-10
            )
            assert_allclose(
                corr_matrix_result[:, i, j], corr_matrix_result[:, j, i], rtol=1e-10
            )",numbagg/test/test_move_exp_matrix_consistency.py,TestMoveExpMatrixConsistency,1,4.6911638017642294e-08,"The method `test_three_series_consistency` is a well-structured unit test that verifies the consistency of covariance and correlation calculations for a 3x3 matrix of time series data. It uses assertions to ensure that pairwise calculations match those derived from matrix operations, and it checks for symmetry in the results. This kind of test is crucial for validating the correctness of statistical functions, especially in numerical computing libraries. Given its importance in ensuring the reliability of the codebase, it is unlikely to be deleted."
survived,"    def test_correlation_bounds(self):
        """"""Test that correlation values are properly bounded between -1 and 1.""""""
        # Create data with some negative correlation
        np.random.seed(42)
        data = np.random.randn(3, 100)
        data[1] = -data[0] + 0.1 * np.random.randn(100)  # Strong negative correlation

        result = move_exp_nancorrmatrix(data, alpha=0.5)

        # All correlation values should be between -1 and 1
        finite_mask = np.isfinite(result)
        assert np.all(result[finite_mask] >= -1.0)
        assert np.all(result[finite_mask] <= 1.0)
",numbagg/test/test_move_exp_matrix.py,TestMoveExpMatrixFunctions,1,3.3982678079468468e-09,"The method 'test_correlation_bounds' is a unit test designed to verify that the correlation values computed by the 'move_exp_nancorrmatrix' function are within the valid range of -1 to 1. This is a fundamental property of correlation coefficients, and ensuring this property is crucial for the correctness of the function. The test is well-structured, uses a controlled random dataset, and includes assertions to check the bounds. Such tests are essential for maintaining code quality and reliability, especially in numerical computations. Therefore, this method is likely to be retained as part of the test suite."
survived,"def content(
    pattern: str = typer.Argument(..., help=""Regex pattern to search for""),
    path: Optional[Path] = typer.Option(None, ""--path"", ""-p"", help=""Base path to search in""),
    type: Optional[List[str]] = typer.Option(None, ""--type"", ""-t"", help=""File types to search (e.g., .py)""),
    context: int = typer.Option(2, ""--context"", ""-c"", help=""Number of context lines""),
    ignore: Optional[List[str]] = typer.Option(None, ""--ignore"", ""-i"", help=""Patterns to ignore"")
):
    """"""Search for patterns in file contents""""""
    scanner = ModelScanner(
        base_path=path or Path.cwd(),
        ignore_patterns=ignore
    )
    
    results = scanner.search_content(pattern, file_types=type, context_lines=context)
    
    # Format output
    typer.echo(f""pattern: {results['pattern']}"")
    typer.echo(""matches:"")
    for match in results['matches']:
        typer.echo(f""  file: {match['file']}"")
        typer.echo(f""  line_number: {match['line_number']}"")
        typer.echo(f""  line: {match['line']}"")
        if match.get('context'):
            typer.echo(""  context:"")
            for line in match['context']:
                typer.echo(f""    - {line}"")
        typer.echo()
",src/haconiwa/scan/cli.py,,1,1.0467401685178159e-08,"The method 'content' is a well-defined function that uses the Typer library to create a command-line interface for searching patterns in file contents. It provides useful options for specifying the search pattern, file path, file types, context lines, and ignore patterns. This functionality is practical and relevant for users who need to perform text searches in files, making it a valuable tool. Additionally, the use of Typer for argument parsing and the clear output formatting enhance its usability. Therefore, it is likely to be retained."
survived,"def analyze(
    path: Optional[Path] = typer.Option(None, ""--path"", ""-p"", help=""Path to analyze""),
    category: Optional[str] = typer.Option(None, ""--category"", help=""Filter by category""),
    show_structure: bool = typer.Option(False, ""--show-structure"", help=""Show directory structure""),
    output_format: str = typer.Option(""text"", ""--format"", ""-f"", help=""Output format"")
):
    """"""Analyze AI model directory structure and categorization""""""
    analyzer = ModelAnalyzer(base_path=path or Path.cwd())
    
    results = analyzer.analyze_directory(
        show_structure=show_structure,
        category_filter=category
    )
    
    formatter = OutputFormatter()
    output = formatter.format_analysis_results(results, output_format)
    typer.echo(output)
",src/haconiwa/scan/cli.py,,1,1.6918979223288786e-10,"The method 'analyze' is likely to survive because it provides a useful functionality for analyzing AI model directory structures and categorization. It is well-structured, uses optional parameters for flexibility, and supports different output formats, making it versatile for various use cases. Additionally, it leverages external classes like 'ModelAnalyzer' and 'OutputFormatter', indicating a modular design that can be easily maintained or extended."
survived,"    def test_list_all_models(self, temp_model_dir):
        """"""Test listing all models""""""
        scanner = ModelScanner(temp_model_dir)
        
        models = scanner.list_all_models()
        assert len(models) >= 3  # We created 3 models
        
        # Check model info structure
        for model in models:
            assert 'name' in model
            assert 'provider' in model
            assert 'category' in model
            assert 'file_count' in model
            assert 'files' in model
",tests/test_scan/test_scanner.py,TestModelScanner,1,1.2501528648238603e-09,"The method 'test_list_all_models' is a unit test designed to verify the functionality of listing all models in a directory. It checks that at least three models are present and validates the structure of the model information. This is a typical and necessary test to ensure the integrity and correctness of the 'list_all_models' functionality. Since testing is a crucial part of software development to maintain code quality and prevent regressions, this method is likely to be retained."
survived,"    def _generate_development_guide(self, model_info: Dict[str, Any]) -> str:
        """"""Generate a development guide""""""
        lines = [
            f""# Development Guide: {model_info['name']}"",
            f""\nGenerated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"",
            ""\n## Overview"",
            f""\nThis guide provides development information for working with {model_info['name']}.""
        ]
        
        # Model information
        if model_info['config']:
            lines.extend([
                ""\n## Model Configuration"",
                ""\n```json"",
                json.dumps(model_info['config'], indent=2),
                ""```""
            ])
        
        # Categories
        if model_info['categories']:
            lines.extend([
                ""\n## Categories"",
                f""\nThis model is categorized as: {', '.join(model_info['categories'])}""
            ])
        
        # File structure
        lines.extend([
            ""\n## File Structure"",
            f""\nTotal files: {model_info['total_files']}"",
            ""\n### Key Files:""
        ])
        
        for file_info in model_info['files'][:10]:  # First 10 files
            lines.append(f""- `{file_info['path']}` ({file_info['type']})"")
        
        # Requirements
        if model_info['requirements']:
            lines.extend([
                ""\n## Requirements"",
                ""\n### Dependencies:""
            ])
            
            for req_file in model_info['requirements']:
                if req_file.get('content'):
                    lines.append(f""\nFrom `{req_file['name']}`:"")
                    lines.append(""```"")
                    lines.append(req_file['content'][:500])  # First 500 chars
                    if len(req_file['content']) > 500:
                        lines.append(""..."")
                    lines.append(""```"")
        
        # API Usage
        if model_info['api_info']:
            lines.extend([
                ""\n## API Integration"",
                f""\nAPI file found: `{model_info['api_info']['path']}`"",
                ""\nRefer to this file for API integration details.""
            ])
        
        # Examples
        if model_info['examples']:
            lines.extend([
                ""\n## Examples"",
                ""\n### Available Examples:""
            ])
            
            for example in model_info['examples'][:5]:
                lines.append(f""- `{example['path']}`"")
        
        # Getting Started
        lines.extend([
            ""\n## Getting Started"",
            ""\n### 1. Setup Environment"",
            ""```bash"",
            ""# Create virtual environment"",
            ""python -m venv venv"",
            ""source venv/bin/activate  # On Windows: venv\\Scripts\\activate"",
            """",
            ""# Install dependencies"",
            ""pip install -r requirements.txt"",
            ""```"",
            ""\n### 2. Load Model"",
            ""```python"",
            f""# Example code to load {model_info['name']}"",
            ""import json"",
            """",
            ""# Load configuration"",
            ""with open('config.json', 'r') as f:"",
            ""    config = json.load(f)"",
            """",
            ""# Initialize model (framework-specific)"",
            ""# Add your model initialization code here"",
            ""```""
        ])
        
        # Best Practices
        lines.extend([
            ""\n## Best Practices"",
            ""\n1. **Version Control**: Track model versions and configurations"",
            ""2. **Testing**: Implement comprehensive tests for model inference"",
            ""3. **Documentation**: Keep documentation up-to-date with model changes"",
            ""4. **Performance**: Monitor and optimize inference performance"",
            ""5. **Security**: Validate inputs and handle errors gracefully""
        ])
        
        # Additional Resources
        lines.extend([
            ""\n## Additional Resources"",
            ""\n- Model documentation: Check README files in the model directory"",
            ""- Examples: Review example files for usage patterns"",
            ""- Configuration: Refer to config files for model parameters""
        ])
        
        return ""\n"".join(lines)
",src/haconiwa/scan/guide_generator.py,GuideGenerator,1,4.944450477491054e-09,"The method `_generate_development_guide` is a comprehensive utility function designed to generate a detailed development guide for a given model. It covers various aspects such as model configuration, file structure, requirements, API usage, examples, and best practices. This method is highly useful for developers who need to understand and work with the model effectively. Its structured approach to documentation ensures that all necessary information is presented clearly, making it a valuable tool in a development environment. Therefore, it is likely to be retained in the codebase."
survived,"    def test_scan_list_command(self, runner, temp_model_dir):
        """"""Test the scan list command""""""
        result = runner.invoke(
            scan_app,
            [""list"", ""--path"", str(temp_model_dir), ""--format"", ""table""]
        )
        
        assert result.exit_code == 0
        assert ""Available AI Models"" in result.stdout
",tests/test_scan/test_cli.py,TestScanCLI,1,1.522997951276035e-08,"The method 'test_scan_list_command' is a unit test for a command-line interface (CLI) application. It uses a test runner to invoke a command and checks the output. This is a common practice in software development to ensure that the CLI behaves as expected. The method is well-defined, has a clear purpose, and is likely part of a test suite that ensures the reliability of the application. Therefore, it is unlikely to be deleted as it serves an important role in maintaining code quality."
survived,"    def _list_to_text(self, data: List[Any]) -> str:
        """"""Convert list to formatted text""""""
        lines = []
        for item in data:
            if isinstance(item, dict):
                lines.append(self._dict_to_text(item))
                lines.append("""")  # Empty line between items
            else:
                lines.append(f""- {item}"")
        
        return ""\n"".join(lines)
",src/haconiwa/scan/formatter.py,OutputFormatter,1,3.3982678079468468e-09,"The method '_list_to_text' is a utility function that converts a list into a formatted string. It handles both dictionary and non-dictionary items, making it versatile for different types of data. Such utility functions are commonly used in applications that require data formatting for display or logging purposes. The method is well-defined, with a clear purpose and implementation, and it is likely to be useful in various contexts where data needs to be converted to a readable text format. Therefore, it is likely to be retained in the codebase."
survived,"    def _get_timestamp(self) -> str:
        """"""Get current timestamp""""""
        from datetime import datetime
        return datetime.now().isoformat()",src/haconiwa/scan/comparator.py,ModelComparator,1,5.60279640614594e-09,"The method _get_timestamp is a simple utility function that returns the current timestamp in ISO format. Such utility functions are commonly used in various applications for logging, tracking, or timestamping events. The method is straightforward, does not have any apparent issues, and serves a useful purpose. Therefore, it is likely to be retained in the codebase."
survived,"    def test_scan_list_with_filters(self, runner, temp_model_dir):
        """"""Test list with provider and category filters""""""
        result = runner.invoke(
            scan_app,
            [""list"", ""--path"", str(temp_model_dir), ""--provider"", ""unknown"", ""--format"", ""json""]
        )
        
        assert result.exit_code == 0
        output = json.loads(result.stdout)
        assert isinstance(output, list)
",tests/test_scan/test_cli.py,TestScanCLI,1,4.6911638017642294e-08,"The method 'test_scan_list_with_filters' is a unit test function that is designed to test a specific functionality of a command-line application. It uses a test runner to invoke a command with specific arguments and checks the output. This is a common practice in software development to ensure that code behaves as expected. The method is well-structured, has a clear purpose, and is likely part of a test suite that ensures the reliability of the application. Therefore, it is unlikely to be deleted as it serves an important role in maintaining code quality."
survived,"    def _extract_model_name(self, path: Path) -> str:
        """"""Extract model name from path""""""
        # Try to extract from common patterns
        path_parts = path.parts
        
        for part in reversed(path_parts):
            if any(prefix in part.lower() for prefix in self.model_prefixes):
                return part
            if 'model' in part.lower() and len(part) > 5:
                return part
        
        return path.name
",src/haconiwa/scan/scanner.py,ModelScanner,1,1.2501528648238603e-09,"The method '_extract_model_name' is a utility function that extracts a model name from a given file path. It is likely to be useful in various contexts where file paths need to be parsed to identify model names, especially in machine learning or data processing applications. The method is straightforward, uses common patterns to identify model names, and provides a fallback to return the file name if no specific pattern is matched. This kind of functionality is often needed and reused, making it a candidate for survival."
survived,"    def test_scan_main_help(self, runner):
        """"""Test main scan help""""""
        result = runner.invoke(scan_app, [""--help""])
        
        assert result.exit_code == 0
        assert ""Universal AI model search"" in result.stdout
        
        # Test help command
        result = runner.invoke(scan_app, [""help""])
        
        assert result.exit_code == 0
        assert ""Haconiwa Scan Command"" in result.stdout
        assert ""generate-parallel-config"" in result.stdout",tests/test_scan/test_cli.py,TestScanCLI,1,3.3982678079468468e-09,"The method 'test_scan_main_help' is a unit test function that verifies the help command functionality of a CLI application. It checks if the help command returns the expected output and exit code, which is a common and necessary test to ensure the CLI behaves as expected. Such tests are crucial for maintaining the reliability of command-line tools, especially when they are part of a larger application or library. Therefore, this method is likely to be retained as it serves an important role in the testing suite."
survived,"    def _compare_capabilities(self, model_data: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
        """"""Compare model capabilities""""""
        capabilities = {}
        
        capability_keywords = {
            'text_generation': ['generate', 'completion', 'text', 'language'],
            'code_generation': ['code', 'programming', 'syntax'],
            'translation': ['translate', 'multilingual', 'language'],
            'summarization': ['summary', 'summarize', 'abstract'],
            'classification': ['classify', 'classification', 'categorize'],
            'embedding': ['embed', 'embedding', 'vector'],
            'chat': ['chat', 'conversation', 'dialogue'],
            'reasoning': ['reason', 'logic', 'analytical'],
            'multimodal': ['multimodal', 'image', 'vision', 'audio']
        }
        
        for model, data in model_data.items():
            model_capabilities = set()
            
            # Check config for capabilities
            if data.get('config'):
                config_str = json.dumps(data['config']).lower()
                for capability, keywords in capability_keywords.items():
                    if any(keyword in config_str for keyword in keywords):
                        model_capabilities.add(capability)
            
            # Check file names and paths
            for file_info in data.get('files', []):
                file_str = file_info['path'].lower()
                for capability, keywords in capability_keywords.items():
                    if any(keyword in file_str for keyword in keywords):
                        model_capabilities.add(capability)
            
            capabilities[model] = list(model_capabilities)
        
        return capabilities
",src/haconiwa/scan/comparator.py,ModelComparator,1,4.944450477491054e-09,"The method '_compare_capabilities' is a utility function that analyzes model data to determine the capabilities of different models based on their configuration and file paths. This is a useful function for systems that need to dynamically assess and categorize models based on their features. The method is well-structured, uses a clear dictionary of keywords to identify capabilities, and returns a dictionary mapping models to their identified capabilities. Such functionality is likely to be useful in various applications involving model management and capability assessment, making it a candidate for survival."
survived,"    def generate_for_pattern_fix(self,
                               pattern: str,
                               fix_description: str,
                               files: List[str]) -> Dict[str, Any]:
        """"""Generate YAML for fixing specific patterns across files""""""
        
        tasks = []
        
        for file_path in files:
            prompt = f""Find all occurrences of pattern '{pattern}' and {fix_description}. "" \
                    f""Ensure the changes maintain code functionality and follow best practices. "" \
                    f""Add comments explaining significant changes.""
            
            tasks.append({
                'file': file_path,
                'prompt': prompt
            })
        
        config = {
            'provider': 'claude',
            'metadata': {
                'generated_at': datetime.now().isoformat(),
                'source': 'haconiwa scan generate-parallel-config',
                'pattern': pattern,
                'fix': fix_description,
                'total_tasks': len(tasks)
            },
            'tasks': tasks,
            'options': {
                'max_concurrent': 5,
                'timeout': 90,
                'allowed_tools': ['Read', 'Write', 'Edit', 'MultiEdit'],
                'permission_mode': 'acceptEdits',  # Auto-accept for pattern fixes
                'output_dir': './pattern-fix-results'
            }
        }
        
        return config
",src/haconiwa/scan/generate_parallel.py,ParallelYAMLGenerator,1,4.599055376537186e-10,"The method 'generate_for_pattern_fix' is well-defined and serves a clear purpose of generating a configuration for fixing patterns in files. It is structured to create a list of tasks with specific prompts and metadata, which is useful for automation tools. The method is likely to be used in scenarios where automated code refactoring or pattern fixing is required, making it a valuable utility in a development environment. There are no apparent issues or redundancies that would necessitate its deletion."
survived,"    def test_category_determination(self, temp_model_dir):
        """"""Test category determination logic""""""
        scanner = ModelScanner(temp_model_dir)
        
        # Test various paths
        test_paths = [
            (Path(""models/llm/gpt4""), ""llm""),
            (Path(""models/vision/clip""), ""vision""),
            (Path(""models/audio/whisper""), ""audio""),
            (Path(""models/multimodal/flamingo""), ""multimodal""),
            (Path(""models/embedding/ada""), ""embedding""),
            (Path(""models/random/model""), ""general"")
        ]
        
        for path, expected_category in test_paths:
            category = scanner._determine_category(path)
            assert category == expected_category",tests/test_scan/test_scanner.py,TestModelScanner,1,5.60279640614594e-09,"The method 'test_category_determination' is a unit test designed to verify the functionality of the '_determine_category' method in the 'ModelScanner' class. Unit tests are crucial for ensuring code reliability and correctness, especially in larger projects. This test method is well-structured, covering various scenarios and expected outcomes, which is a good practice in software development. Therefore, it is likely to be retained as part of the codebase to maintain the integrity of the category determination logic."
survived,"    def test_correlation_covariance_relationship(self):
        """"""Test relationship between correlation and covariance.""""""
        np.random.seed(42)
        data = np.random.randn(4, 50)

        cov_matrix = nancovmatrix(data)
        corr_matrix = nancorrmatrix(data)

        # Correlation = Covariance / (std_i * std_j)
        stds = np.sqrt(np.diag(cov_matrix))
        expected_corr = cov_matrix / np.outer(stds, stds)

        assert_allclose(corr_matrix, expected_corr, rtol=1e-10)
",numbagg/test/test_matrix_functions.py,TestCorrelationCovarianceMatrices,1,9.931195248674785e-08,"The method `test_correlation_covariance_relationship` is a unit test that verifies the mathematical relationship between correlation and covariance matrices. It uses random data to compute both matrices and checks if the correlation matrix can be derived from the covariance matrix using the standard deviations. This is a fundamental statistical property, and the test ensures that the functions `nancovmatrix` and `nancorrmatrix` are implemented correctly. Such tests are crucial for validating the correctness of statistical computations in a codebase, especially when dealing with potentially missing data (as suggested by the 'nan' prefix). Therefore, this method is likely to be retained as it serves an important role in ensuring the reliability of the statistical functions."
survived,"    def test_no_axis_parameter_accepted(self):
        """"""Test that axis parameter is no longer accepted.""""""
        data = np.random.randn(3, 100)

        # These should all raise TypeError since axis parameter removed
        with pytest.raises(TypeError):
            nancorrmatrix(data, axis=0)

        with pytest.raises(TypeError):
            nancorrmatrix(data, axis=-1)

        with pytest.raises(TypeError):
            nancovmatrix(data, axis=1)
",numbagg/test/test_matrix_functions.py,TestCorrelationCovarianceMatrices,1,4.363462233903899e-09,"The method is testing for a specific behavior where the 'axis' parameter is no longer accepted by certain functions. This is a valid and necessary test to ensure that the functions behave as expected when deprecated or removed features are used. Such tests are crucial for maintaining code quality and ensuring that users are aware of changes in the API. Therefore, this method is likely to be retained as part of the test suite."
survived,"    async def test_unix_script_execution_with_chmod(
        self, mock_chmod, mock_tempfile, mock_platform
    ):
        """"""Test that chmod is called on Unix for script files.""""""
        mock_file = MagicMock()
        mock_file.name = ""/tmp/script.sh""
        mock_file.__enter__.return_value = mock_file
        mock_tempfile.return_value = mock_file
",tests/unit/test_windows_compatibility.py,TestWindowsCompatibility,1,1.955568070542584e-08,"The method is part of a test suite, specifically testing the behavior of a script execution on Unix systems. Test methods are generally not deleted unless they are redundant, testing deprecated features, or replaced by more comprehensive tests. This method seems to be testing a specific functionality (chmod usage on Unix), which is likely still relevant for ensuring correct behavior of the system."
survived,"    def test_windows_drive_letter_paths(self):
        """"""Test that Windows drive letter paths are allowed.""""""
        with patch(""platform.system"", return_value=""Windows""):
            validator = PathValidator()

            # Valid Windows paths
            valid_paths = [
                ""C:\\"",
                ""C:\\temp"",
                ""C:\\Users\\test\\file.txt"",
                ""D:\\project\\src"",
                ""C:/temp/file.txt"",  # Forward slashes also valid
            ]

            for path in valid_paths:
                is_valid, error, _ = validator.validate_path(path, check_exists=False)
                assert is_valid, f""Path '{path}' should be valid on Windows: {error}""
",tests/unit/test_windows_compatibility.py,TestWindowsPathValidation,1,1.0467401685178159e-08,"The method `test_windows_drive_letter_paths` is a unit test designed to verify that the `PathValidator` class correctly identifies valid Windows drive letter paths. This is a common requirement for software that needs to handle file paths on Windows systems. The test uses mocking to simulate a Windows environment and checks various valid path formats, including those with forward slashes, which are also acceptable on Windows. Since this functionality is essential for cross-platform compatibility and the test is well-structured, it is likely to be retained in the codebase."
survived,"    def test_build_uv_command_with_python_version(self):
        """"""Test building uv command with Python version.""""""
        cmd = _build_uv_command(""server.py"", python_version=""3.11"")
        expected = [
            ""uv"",
            ""run"",
            ""--python"",
            ""3.11"",
            ""--with"",
            ""fastmcp"",
            ""fastmcp"",
            ""run"",
            ""server.py"",
        ]
        assert cmd == expected
",tests/cli/test_cli.py,TestMainCLI,1,1.0467401685178159e-08,"The method 'test_build_uv_command_with_python_version' is a unit test designed to verify the functionality of the '_build_uv_command' function. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with command-line operations that can have significant impacts if incorrect. The test checks if the command is constructed correctly with a specific Python version, which is a common requirement in software development. Therefore, this method is likely to be maintained as part of the test suite to ensure ongoing code quality and functionality."
survived,"    def test_run_with_uv_project(self, mock_run):
        """"""Test run_with_uv with project directory.""""""
        mock_run.return_value = Mock(returncode=0)
        project_path = Path(""/my/project"")

        with pytest.raises(SystemExit) as exc_info:
            run_with_uv(""server.py"", project=project_path)

        assert exc_info.value.code == 0

        cmd = mock_run.call_args[0][0]
        expected = [
            ""uv"",
            ""run"",
            ""--project"",
            ""/my/project"",
            ""--with"",
            ""fastmcp"",
            ""fastmcp"",
            ""run"",
            ""server.py"",
        ]
        assert cmd == expected
",tests/cli/test_run_with_uv.py,TestRunWithUv,1,2.3355930333443423e-09,"The method `test_run_with_uv_project` is a unit test designed to verify the behavior of the `run_with_uv` function when a project directory is specified. It uses mocking to simulate the behavior of the `run_with_uv` function and checks that the correct command is constructed and executed. This is a typical and necessary part of testing in software development, ensuring that the function behaves as expected under certain conditions. Since testing is a crucial part of maintaining code quality and reliability, this method is likely to be retained in the codebase."
survived,"def visualise_from_checkpoint_manager(
    checkpoint_manager,
    meta_cluster_model,
    *,
    style: str = ""basic"",
    console: Optional[Console] = None
) -> None:
    """"""Visualize clusters using a CheckpointManager and meta cluster model.
    
    This function integrates with the v1 pipeline's CheckpointManager to automatically
    load and visualize clusters.
    
    Args:
        checkpoint_manager: CheckpointManager instance from v1 pipeline
        meta_cluster_model: Meta cluster model with checkpoint_filename
        style: Visualization style (""basic"", ""enhanced"", or ""rich"")
        console: Rich Console instance (for rich style)
        
    Raises:
        ValueError: If invalid style is provided
        FileNotFoundError: If checkpoint file doesn't exist
    """"""
    if not hasattr(meta_cluster_model, 'checkpoint_filename'):
        raise ValueError(""Meta cluster model must have checkpoint_filename attribute"")
    
    checkpoint_path = checkpoint_manager.get_checkpoint_path(meta_cluster_model.checkpoint_filename)
    
    if style == ""basic"":
        visualise_clusters(checkpoint_path=checkpoint_path)
    elif style == ""enhanced"":
        visualise_clusters_enhanced(checkpoint_path=checkpoint_path)
    elif style == ""rich"":
        visualise_clusters_rich(checkpoint_path=checkpoint_path, console=console)
    else:
        raise ValueError(f""Invalid style '{style}'. Must be one of: basic, enhanced, rich"")
",kura/v1/visualization.py,,1,8.592166611791576e-10,"The method 'visualise_from_checkpoint_manager' is well-defined and provides a clear utility for visualizing clusters using different styles. It includes error handling for invalid styles and missing attributes, making it robust. The method is likely to be useful in scenarios where visualization of clustering results is needed, especially in a pipeline that uses checkpoints. Given its clear purpose, error handling, and integration with existing components, it is likely to be retained."
survived,"def visualise_clusters(
    clusters: Optional[List[Cluster]] = None,
    *,
    checkpoint_path: Optional[Union[str, Path]] = None
) -> None:
    """"""Print a hierarchical visualization of clusters to the terminal.
    
    This function loads clusters either from the provided list or from a checkpoint file,
    builds a tree representation, and prints it to the console.
    The visualization shows the hierarchical relationship between clusters
    with indentation and tree structure symbols.
    
    Args:
        clusters: List of clusters to visualize. If None, loads from checkpoint_path
        checkpoint_path: Path to checkpoint file to load clusters from
        
    Raises:
        ValueError: If neither clusters nor checkpoint_path is provided
        FileNotFoundError: If checkpoint file doesn't exist
        
    Example output:
        ╠══ Compare and improve Flutter and React state management (45 conversations)
        ║   ╚══ Improve and compare Flutter and React state management (32 conversations)
        ║       ╠══ Improve React TypeScript application (15 conversations)
        ║       ╚══ Compare and select Flutter state management solutions (17 conversations)
        ╠══ Optimize blog posts for SEO and improved user engagement (28 conversations)
    """"""
    # Load clusters
    if clusters is None:
        if checkpoint_path is None:
            raise ValueError(""Either clusters or checkpoint_path must be provided"")
        clusters = _load_clusters_from_checkpoint(checkpoint_path)
    
    logger.info(f""Visualizing {len(clusters)} clusters"")
    
    # Build tree structure
    node_id_to_cluster = _build_cluster_tree(clusters)

    # Find root nodes and build the tree
    root_nodes = [
        node_id_to_cluster[cluster.id] for cluster in clusters if not cluster.parent_id
    ]

    total_conversations = sum(node.count for node in root_nodes)
    fake_root = ClusterTreeNode(
        id=""root"",
        name=""Clusters"",
        description=""All clusters"",
        count=total_conversations,
        children=[node.id for node in root_nodes],
    )

    tree_output = _build_tree_structure(fake_root, node_id_to_cluster, 0, False)
    print(tree_output)
",kura/v1/visualization.py,,1,2.3355930333443423e-09,"The method 'visualise_clusters' is well-documented, has a clear purpose, and provides useful functionality for visualizing hierarchical data. It includes error handling for missing inputs and uses logging to inform about the process. These factors suggest that the method is likely to be maintained and used in the future, as it provides a valuable feature for users who need to visualize cluster data."
survived,"    def decay(self, decay_rate: Optional[float] = None) -> None:
        """"""Decay all arms of the wrapped agent.

        Parameters
        ----------
        decay_rate : Optional[float], default=None
            Decay rate to use for decaying the arms.
        """"""
        self._agent.decay(decay_rate=decay_rate)
",bayesianbandits/pipelines/_agent.py,NonContextualAgentPipeline,1,2.998960815863541e-09,"The method 'decay' is a wrapper around another method call to 'self._agent.decay'. It provides a clear and concise interface for decaying the arms of the wrapped agent, with an optional parameter for specifying the decay rate. This method is likely part of a larger system where such functionality is necessary, and it is well-documented, making it useful for users of the class. There is no indication that this method is redundant or unnecessary, so it is likely to be retained."
survived,"    def test_pull_without_top_k(self):
        """"""Test pull method without top_k.""""""
        arms = make_arms(range(3))
        agent = ContextualAgent(arms, ThompsonSampling(), random_seed=42)
        steps = [(""identity"", FunctionTransformer())]

        pipeline = ContextualAgentPipeline(steps, agent)

        X = np.array([[1.0, 2.0], [3.0, 4.0]])
        actions = pipeline.pull(X)

        assert len(actions) == 2
        assert all(isinstance(action, int) for action in actions)
",tests/test_agent_pipeline.py,TestContextualAgentPipeline,1,1.275190675769241e-07,"The method `test_pull_without_top_k` is a unit test designed to verify the functionality of the `pull` method in a `ContextualAgentPipeline` without using the `top_k` parameter. It is a straightforward test that checks if the `pull` method returns the correct number of actions and that each action is an integer. This kind of test is essential for ensuring the reliability and correctness of the code, especially in a machine learning or decision-making context. Therefore, it is unlikely to be deleted as it serves a critical role in maintaining code quality."
survived,"    def test_pull_with_top_k(self):
        """"""Test pull method with top_k.""""""
        arms = make_arms(range(5))
        agent = Agent(arms, ThompsonSampling(), random_seed=42)
        steps = []

        pipeline = NonContextualAgentPipeline(steps, agent)

        action_lists = pipeline.pull(top_k=3)

        assert len(action_lists) == 1
        assert len(action_lists[0]) == 3
",tests/test_agent_pipeline.py,TestNonContextualAgentPipeline,1,6.825604231969389e-08,"The method 'test_pull_with_top_k' is a unit test designed to verify the functionality of the 'pull' method with a 'top_k' parameter. Unit tests are crucial for ensuring code reliability and correctness, especially in complex systems. This test checks that the 'pull' method returns the correct number of actions when 'top_k' is specified, which is an important aspect of the method's functionality. Therefore, it is unlikely to be deleted as it serves a valuable purpose in maintaining the integrity of the codebase."
survived,"    def test_factory_preserves_functionality(self):
        """"""Test factory-created pipelines work correctly.""""""
        # Test contextual
        arms = make_arms(range(3))
        contextual_agent = ContextualAgent(arms, ThompsonSampling(), random_seed=42)
        steps = [(""scale"", FunctionTransformer(lambda x: x / 10))]

        contextual_pipeline = AgentPipeline(steps, contextual_agent)

        X = np.array([[10.0, 20.0]])
        actions = contextual_pipeline.pull(X)
        assert len(actions) == 1

        # Test non-contextual
        arms = make_arms(range(3))
        agent = Agent(arms, ThompsonSampling(), random_seed=42)

        noncontextual_pipeline = AgentPipeline([], agent)

        actions = noncontextual_pipeline.pull()
        assert len(actions) == 1
",tests/test_agent_pipeline.py,TestAgentPipelineFactory,1,7.73442280641062e-08,"The method `test_factory_preserves_functionality` is a unit test designed to verify that factory-created pipelines maintain their intended functionality. It tests both contextual and non-contextual scenarios, ensuring that the pipelines can pull actions correctly. This is a crucial part of ensuring the reliability and correctness of the system, especially in a testing environment. Therefore, it is unlikely to be deleted as it serves an important purpose in maintaining code quality."
survived,"def _transform_data(X: Any, steps: List[Tuple[str, Any]]) -> Any:
    """"""Apply all transformers to input data.

    Transformers must be either stateless or pre-fitted.
    No fitting occurs during transformation.
    """"""
    result = X

    for name, transformer in steps:
        try:
            result = transformer.transform(result)
        except Exception as e:
            # Provide helpful error for common case
            if hasattr(e, ""args"") and ""not fitted"" in str(e).lower():
                raise RuntimeError(
                    f""Transformer '{name}' is not fitted. In online learning, ""
                    f""all transformers must be either stateless or pre-fitted ""
                    f""before use. Common stateless transformers include ""
                    f""FunctionTransformer, FeatureHasher, and HashingVectorizer. ""
                    f""Stateful transformers like StandardScaler must be fit on ""
                    f""historical data before creating the pipeline.""
                ) from e
            raise

    return result
",bayesianbandits/pipelines/_agent.py,,1,9.237449576640118e-09,"The method '_transform_data' is a utility function that applies a series of transformations to input data. It includes error handling to provide informative messages when a transformer is not fitted, which is a common issue in data processing pipelines. The function is well-documented, and its purpose is clear. It is likely to be useful in various data processing scenarios, especially in machine learning pipelines where transformations are applied sequentially. Therefore, it is likely to be retained in the codebase."
survived,"    def __len__(self) -> int:
        """"""Number of steps in the pipeline.""""""
        return len(self.steps)
",bayesianbandits/pipelines/_agent.py,ContextualAgentPipeline,1,5.60279640614594e-09,"The method `__len__` is a standard Python special method used to define the behavior of the `len()` function for instances of a class. In this case, it returns the number of steps in a pipeline, which is likely a core functionality of the class. Such methods are typically essential for the usability and integration of the class with Python's built-in functions. Therefore, it is unlikely to be deleted unless the class design changes significantly."
survived,"    def test_transformer_error_propagation(self):
        """"""Test that transformer errors are properly propagated.""""""

        def failing_transform(X):
            raise ValueError(""Custom transformation error"")

        arms = make_arms(range(3))
        agent = ContextualAgent(arms, ThompsonSampling())

        steps = [(""fail"", FunctionTransformer(failing_transform))]
        pipeline = ContextualAgentPipeline(steps, agent)

        X = np.array([[1.0]])

        with pytest.raises(ValueError, match=""Custom transformation error""):
            pipeline.pull(X)
",tests/test_agent_pipeline.py,TestErrorHandling,1,1.444980317078884e-07,"The method 'test_transformer_error_propagation' is a unit test designed to ensure that errors in a transformation step are correctly propagated through a pipeline. This is a common and important aspect of testing in software development, especially when dealing with pipelines or sequences of operations where an error in one step should be caught and handled appropriately. The test is well-defined, uses a mock transformation that raises a specific error, and checks that the error is raised as expected. Such tests are crucial for maintaining robust and reliable code, especially in systems that rely on complex data processing pipelines. Therefore, this method is likely to be retained as it serves a critical role in ensuring the correctness and reliability of the codebase."
survived,"        def add_interactions(X):
            """"""Add interaction terms.""""""
            # X shape: (n_samples, 2)
            interactions = X[:, 0:1] * X[:, 1:2]  # x1 * x2
            return np.c_[X, interactions]
",tests/test_agent_pipeline.py,TestIntegrationScenarios,1,3.3982678079468468e-09,"The method 'add_interactions' is a simple and useful utility function that adds interaction terms to a dataset. Interaction terms are often used in statistical models to capture the effect of two variables acting together, which can be crucial for improving model performance. The method is straightforward, performs a common task in data preprocessing, and is likely to be used in various machine learning and statistical modeling contexts. Therefore, it is likely to be retained in the codebase."
survived,"    def test_noncontextual_pipeline_policy_setter(self):
        """"""Test policy setter on non-contextual pipeline.""""""
        arms = make_arms(range(3))
        agent = Agent(arms, ThompsonSampling())
        pipeline = NonContextualAgentPipeline([], agent)

        new_policy = EpsilonGreedy(epsilon=0.2)
        pipeline.policy = new_policy
        assert pipeline.policy is new_policy
",tests/test_agent_pipeline.py,TestCoverage,1,9.237449576640118e-09,"The method 'test_noncontextual_pipeline_policy_setter' is a unit test designed to verify the functionality of setting a new policy in a 'NonContextualAgentPipeline'. It is a straightforward test that ensures the policy setter works as expected by assigning a new policy and asserting the change. Such tests are crucial for maintaining code reliability and ensuring that changes to the codebase do not break existing functionality. Therefore, it is likely to be retained as part of the test suite to ensure the robustness of the policy setting feature."
survived,"    def __init__(
        self, steps: List[Tuple[str, Any]], final_agent: Agent[TokenType]
    ) -> None:
        _validate_steps(
            steps
        ) if steps else None  # Allow empty steps for non-contextual
        self.steps = steps
        self._agent = final_agent
",bayesianbandits/pipelines/_agent.py,NonContextualAgentPipeline,1,3.466327708641819e-07,"The method is a constructor (__init__) for a class, which is a fundamental part of class instantiation in Python. Constructors are essential for initializing new objects and setting initial values for instance variables. Therefore, it is highly unlikely that this method would be deleted unless the entire class is being refactored or removed, which is not indicated here."
survived,"        def double_transform(X):
            return X * 2
",tests/test_learner_pipeline.py,TestLearnerPipelineTransformers,1,1.3440409770490404e-08,"The method 'double_transform' is a simple utility function that doubles the input value. Such functions are often useful in various contexts where a straightforward transformation is needed. It is likely to be retained because it provides a clear and reusable operation that can be applied to different datasets or values. Unless there is a specific reason to remove it, such as redundancy or a change in requirements, it is generally beneficial to keep such utility functions."
survived,"    def decay(self, X, *, decay_rate=None):
        self.decay_calls.append((X, decay_rate))
",tests/test_learner_pipeline.py,MockLearner,1,6.348800075736417e-09,"The method 'decay' is a simple function that appends a tuple of its arguments to a list 'decay_calls'. This method is likely part of a larger class that tracks or logs calls to 'decay' with the given parameters. The method is straightforward and serves a clear purpose of recording the calls, which can be useful for debugging, logging, or further processing. There is no indication that this method is redundant or unnecessary, so it is likely to be retained."
survived,"    def test_update(self):
        """"""Test update method.""""""
        arms = make_arms(range(3))
        agent = ContextualAgent(arms, ThompsonSampling(), random_seed=42)
        steps = [(""scale"", FunctionTransformer(lambda x: x / 10))]

        pipeline = ContextualAgentPipeline(steps, agent)

        X = np.array([[10.0, 20.0]])
        y = np.array([1.0])

        # Pull to set arm_to_update
        pipeline.pull(X)

        # Update should transform X before passing to agent
        pipeline.update(X, y)

        # Verify the learner was updated with transformed data
        arm_learner = pipeline.arm_to_update.learner
        assert hasattr(arm_learner, ""coef_"")
",tests/test_agent_pipeline.py,TestContextualAgentPipeline,1,6.825604231969389e-08,"The method `test_update` is a unit test designed to verify the functionality of the `update` method in a `ContextualAgentPipeline`. It checks if the data transformation step is correctly applied before updating the agent. This is a crucial part of ensuring the pipeline's integrity and functionality, especially in machine learning contexts where data preprocessing is essential. The presence of assertions to verify the expected behavior indicates that this test is valuable for maintaining code quality and preventing regressions. Therefore, it is likely to be retained."
survived,"    def policy(self, value):
        """"""Set the policy on the wrapped agent.""""""
        self._agent.policy = value
",bayesianbandits/pipelines/_agent.py,NonContextualAgentPipeline,1,1.8189616842444243e-09,"The method 'policy' is a simple setter method that assigns a value to the 'policy' attribute of the '_agent' object. Such methods are typically retained as they provide a clear and direct way to modify object attributes, which is a common practice in object-oriented programming. Unless there is a significant reason to remove it, like redundancy or a change in design pattern, it is likely to survive."
survived,"def test_export_from_pylock_not_empty(core, pdm):
    """"""Test that exporting from pylock.toml produces non-empty output (fixes issue #3573).""""""
    project = core.create_project(FIXTURES / ""projects/demo"")

    # Export from pylock.toml to requirements format
    with cd(project.root):
        result = pdm([""export"", ""-f"", ""requirements"", ""-L"", ""pylock.toml"", ""--no-hashes""], obj=project, strict=True)
        assert result.exit_code == 0

    # The output should not be empty (this was the original bug)
    output_lines = [
        line.strip() for line in result.stdout.strip().split(""\n"") if line.strip() and not line.strip().startswith(""#"")
    ]
    assert len(output_lines) > 0, ""Export from pylock.toml should not be empty""

    # Should contain expected packages
    output = result.stdout
    assert any(pkg in output for pkg in [""chardet"", ""idna""]), ""Expected at least some packages in output""",tests/test_formats.py,,1,4.1399375473943306e-08,"The method 'test_export_from_pylock_not_empty' is a test function that verifies a specific functionality related to exporting from a 'pylock.toml' file. It ensures that the export process produces a non-empty output and contains expected packages. This is a crucial test to prevent regressions related to issue #3573. Test functions like this are typically retained to ensure the software behaves as expected and to catch any future bugs that might arise from changes in the codebase. Therefore, it is unlikely to be deleted."
survived,"    def _identify_file_modifications(self, feature_request: str, analysis: Dict[str, Any]) -> List[str]:
        """"""Identify which files need modification.""""""
        return [""main.py"", ""utils.py""]
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,1,2.998960815863541e-09,"The method is straightforward and serves a clear purpose: identifying which files need modification based on a feature request and analysis. It returns a hardcoded list of files, which might be a placeholder for future logic. The method is likely part of a larger system where such functionality is necessary. Unless the system's requirements change drastically, this method is likely to survive as it provides a necessary utility."
survived,"    def _extract_code_patterns(self, project_path: str, file_patterns: List[str]) -> Dict[str, Any]:
        """"""Extract common code patterns from the project.""""""
        patterns = {""classes"": [], ""functions"": [], ""imports"": [], ""decorators"": []}
        # Implementation would analyze actual code files
        return patterns
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,1,4.363462233903899e-09,"The method '_extract_code_patterns' is a utility function designed to extract code patterns from a project. It is likely part of a larger code analysis or refactoring tool. The method is well-defined with a clear purpose, and its functionality is essential for understanding or transforming codebases. Such methods are typically retained as they provide valuable insights into the structure of the code, which can be crucial for various development tasks such as refactoring, documentation, or code quality analysis. Therefore, it is likely to survive."
survived,"    def _generate_failure_actions(self, criterion: str) -> List[str]:
        """"""Generate actions to take if criterion fails.""""""
        return [f""Review implementation for: {criterion}"", ""Fix issues"", ""Re-test""]
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,1,4.0586521248284276e-10,"The method '_generate_failure_actions' is a utility function that generates a list of actions to take when a certain criterion fails. It is a simple, clear, and useful method that encapsulates a specific functionality. Such methods are generally retained in codebases as they provide a reusable and maintainable way to handle specific tasks. There is no indication that this method is redundant or obsolete, so it is likely to survive."
survived,"    def enhance_prompt_with_context(self, base_prompt: str, context_data: Dict[str, Any]) -> str:
        """"""
        Enhance a basic prompt with comprehensive contextual information.
        
        Args:
            base_prompt (str): Original prompt to enhance
            context_data (Dict[str, Any]): Contextual data to inject
            
        Returns:
            str: Enhanced prompt with rich context
        """"""
        enhanced_prompt = f""""""# Enhanced Prompt with Context Engineering

## Original Request
{base_prompt}

## Contextual Information
{self._format_context_data(context_data)}

## Implementation Context
Based on the analysis, when implementing this request:

### Architecture Considerations
{self._extract_architecture_guidance(context_data)}

### Pattern Adherence
{self._extract_pattern_guidance(context_data)}

### Quality Requirements
{self._extract_quality_guidance(context_data)}

## Enhanced Request
{base_prompt}

**Additional Context**: Implement following the patterns and conventions identified above. 
Ensure the solution integrates seamlessly with the existing codebase architecture.
""""""
        
        return enhanced_prompt
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,1,2.4616969512093895e-10,"The method 'enhance_prompt_with_context' is well-documented and provides a clear utility by enhancing a base prompt with additional context. This is a valuable feature in many applications, especially those involving natural language processing or AI-driven content generation. The method is structured to incorporate various aspects of context, such as architecture, patterns, and quality requirements, which suggests it is designed to be flexible and comprehensive. Given the increasing importance of context-aware systems, this method is likely to be retained and used in future developments."
survived,"def test_backward_compatibility():
    """"""Test that existing PraisonAI functionality still works.""""""
    print(""\n🧪 Testing Backward Compatibility..."")
    
    try:
        # Test that we can still import and use existing agents
        from praisonaiagents import Agent, ImageAgent
        
        # Test basic Agent still works
        basic_agent = Agent(name=""Test Agent"")
        print(""✅ Basic Agent still works"")
        
        # Test ImageAgent still works
        image_agent = ImageAgent(name=""Test Image Agent"")
        print(""✅ ImageAgent still works"")
        
        # Test that we can import other PraisonAI components
        from praisonaiagents import Task, PraisonAIAgents
        print(""✅ Task and PraisonAIAgents can still be imported"")
        
        # Test that __all__ exports are working
        import praisonaiagents
        expected_exports = [
            'Agent', 'ImageAgent', 'ContextAgent', 'create_context_agent',
            'PraisonAIAgents', 'Task'
        ]
        
        for export in expected_exports:
            assert hasattr(praisonaiagents, export), f""Missing export: {export}""
        
        print(""✅ All expected exports are available"")
        
        return True
        
    except Exception as e:
        print(f""❌ Backward compatibility test failed: {e}"")
        return False
",test_context_agent.py,,1,3.2241866333029355e-08,"The method `test_backward_compatibility` is a utility function designed to ensure that existing functionality in the PraisonAI library remains operational after updates or changes. It is crucial for maintaining the integrity of the software and ensuring that updates do not break existing features. Such tests are typically retained in a codebase to prevent regressions and ensure reliability, especially in libraries or frameworks that are used by other developers. Therefore, it is unlikely to be deleted."
survived,"    def _generate_prp_success_criteria(self, feature_request: str, analysis: Dict[str, Any]) -> str:
        """"""Generate success criteria for PRP.""""""
        return f""Success criteria for: {feature_request}""
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,1,4.944450477491054e-09,"The method '_generate_prp_success_criteria' is a simple utility function that generates a string based on the input parameters. It is likely to be used internally within a class or module to create a standardized success criteria message for a given feature request. The method is straightforward, has a clear purpose, and does not have any apparent issues or redundancies that would necessitate its deletion. Therefore, it is likely to be retained in the codebase."
survived,"async def test_smart_decision_maker_tracks_llm_stats():
    """"""Test that SmartDecisionMakerBlock correctly tracks LLM usage stats.""""""
    from unittest.mock import MagicMock, patch

    import backend.blocks.llm as llm_module
    from backend.blocks.smart_decision_maker import SmartDecisionMakerBlock

    block = SmartDecisionMakerBlock()

    # Mock the llm.llm_call function to return controlled data
    mock_response = MagicMock()
    mock_response.response = ""I need to think about this.""
    mock_response.tool_calls = None  # No tool calls for simplicity
    mock_response.prompt_tokens = 50
    mock_response.completion_tokens = 25
    mock_response.reasoning = None
    mock_response.raw_response = {
        ""role"": ""assistant"",
        ""content"": ""I need to think about this."",
    }

    # Mock the _create_function_signature method to avoid database calls
    with patch(""backend.blocks.llm.llm_call"", return_value=mock_response), patch.object(
        SmartDecisionMakerBlock, ""_create_function_signature"", return_value=[]
    ):

        # Create test input
        input_data = SmartDecisionMakerBlock.Input(
            prompt=""Should I continue with this task?"",
            model=llm_module.LlmModel.GPT4O,
            credentials=llm_module.TEST_CREDENTIALS_INPUT,  # type: ignore
        )

        # Execute the block
        outputs = {}
        async for output_name, output_data in block.run(
            input_data,
            credentials=llm_module.TEST_CREDENTIALS,
            graph_id=""test-graph-id"",
            node_id=""test-node-id"",
            graph_exec_id=""test-exec-id"",
            node_exec_id=""test-node-exec-id"",
            user_id=""test-user-id"",
        ):
            outputs[output_name] = output_data

        # Verify stats tracking
        assert block.execution_stats is not None
        assert block.execution_stats.input_token_count == 50
        assert block.execution_stats.output_token_count == 25
        assert block.execution_stats.llm_call_count == 1

        # Verify outputs
        assert ""finished"" in outputs  # Should have finished since no tool calls
        assert outputs[""finished""] == ""I need to think about this.""",autogpt_platform/backend/backend/blocks/test/test_smart_decision_maker.py,,1,3.2241866333029355e-08,"The method is a well-structured test function that uses mocking to simulate the behavior of external dependencies, which is a common practice in unit testing. It verifies the functionality of the SmartDecisionMakerBlock by checking if it correctly tracks LLM usage stats and produces the expected outputs. This kind of test is crucial for ensuring the reliability and correctness of the code, especially when dealing with complex systems like LLMs. Therefore, it is likely to be retained as part of the test suite."
survived,"    def check(node: ast.Delete, resolver: Resolver) -> bool:
        """"""
        Returns True if the deletion is from os.environ[...].
        """"""
        if len(node.targets) == 1 and isinstance(node.targets[0], ast.Subscript):
            resolved = resolver.resolve(node.targets[0].value)
            return resolved == [""os"", ""environ""]
        return False",dev/clint/src/clint/rules/os_environ_delete_in_test.py,OsEnvironDeleteInTest,1,2.0611536181902033e-09,"The method 'check' is a utility function that checks if a given AST node represents a deletion from the 'os.environ' dictionary. This is a specific and useful functionality, especially in code analysis or transformation tools that need to track or modify environment variable manipulations. The method is concise, performs a clear task, and is likely to be used in contexts where environment variable management is critical. Therefore, it is likely to be retained in the codebase."
survived,"    def check(node: ast.FunctionDef | ast.AsyncFunctionDef, resolver: Resolver) -> bool:
        return InvalidAbstractMethod._is_abstract_method(
            node, resolver
        ) and InvalidAbstractMethod._has_invalid_body(node)",dev/clint/src/clint/rules/invalid_abstract_method.py,InvalidAbstractMethod,1,1.522997951276035e-08,"The method 'check' is a utility function that checks if a given function node is an invalid abstract method by using two helper methods: '_is_abstract_method' and '_has_invalid_body'. This kind of functionality is often necessary in static analysis tools or linters to ensure code quality and adherence to certain coding standards. Since it serves a specific purpose in validating abstract methods, it is likely to be retained in the codebase as long as the project requires such validation."
survived,"    def check(node: ast.AnnAssign) -> bool:
        """"""
        Returns True if the value to assign is `None` but the type annotation is
        not `Optional[...]` or `... | None`. For example: `a: int = None`.
        """"""
        return ImplicitOptional._is_none(node.value) and not (
            ImplicitOptional._is_optional(node.annotation)
            or ImplicitOptional._is_bitor_none(node.annotation)
        )
",dev/clint/src/clint/rules/implicit_optional.py,ImplicitOptional,1,3.3982678079468468e-09,"The method `check` is a utility function that checks if a given assignment in an abstract syntax tree (AST) is assigning `None` to a variable that is not annotated as `Optional` or with a union type that includes `None`. This kind of check is useful for static analysis tools or linters that enforce type safety and correctness in Python code. Given the increasing emphasis on type safety in Python, especially with the adoption of type hints and static type checkers like mypy, this method is likely to be useful and relevant. Therefore, it is likely to be retained in the codebase."
survived,"    def test_new_OpArg(self):
        mod = self.compile(
        """"""
        from operator import OpArg

        @blue
        def create_blue_oparg(x: i32) -> OpArg:
            return OpArg('blue', i32, x)

        @blue
        def create_red_oparg() -> OpArg:
            return OpArg('red', i32, None)
        """""")

        # Test blue OpArg creation
        w_blue_oparg = mod.create_blue_oparg(42, unwrap=False)
        assert isinstance(w_blue_oparg, W_OpArg)
        assert w_blue_oparg.color == 'blue'
        assert w_blue_oparg.w_static_type is B.w_i32
        assert w_blue_oparg._w_val is not None

        # Test red OpArg creation
        w_red_oparg = mod.create_red_oparg(unwrap=False)
        assert isinstance(w_red_oparg, W_OpArg)
        assert w_red_oparg.color == 'red'
        assert w_red_oparg.w_static_type is B.w_i32
        assert w_red_oparg._w_val is None
",spy/tests/compiler/test_opimpl.py,TestOpImpl,1,1.0467401685178159e-08,"The method `test_new_OpArg` is a unit test designed to verify the functionality of creating `OpArg` objects with different attributes. Unit tests are crucial for ensuring code reliability and correctness, especially in complex systems. The method is well-structured, testing both the creation of 'blue' and 'red' `OpArg` objects, and includes assertions to validate the expected behavior. Given the importance of testing in software development, this method is likely to be retained to ensure the continued correctness of the `OpArg` creation functionality."
survived,"    def definition(self, curie: CURIE, lang: Optional[LANGUAGE_TAG] = None) -> Optional[str]:
        """"""
        Fetch the definition for a CURIE from OLS.
        
        :param curie: The CURIE to fetch the definition for
        :param lang: Optional language tag (not currently supported by this implementation)
        :return: The definition for the CURIE, or None if not found
        """"""
        if curie in self.definition_cache:
            return self.definition_cache[curie]
        
        try:
            ontology = self.focus_ontology
            iri = self.curie_to_uri(curie)
            term = self.client.get_term(ontology=ontology, iri=iri)
            if term and ""description"" in term and term[""description""]:
                self.definition_cache[curie] = term[""description""]
                return term[""description""]
        except Exception:
            pass
        
        return None
",src/oaklib/implementations/ols/ols_implementation.py,BaseOlsImplementation,1,2.7894680920908113e-10,"The method 'definition' is likely to survive because it provides a useful functionality of fetching definitions for CURIEs from an ontology service. It includes caching to improve performance and handles exceptions gracefully. The method is well-documented, indicating that it is intended for use and maintenance. Additionally, the use of CURIEs and ontology services is common in semantic web and bioinformatics applications, suggesting that this method serves a relevant purpose."
survived,"    def test_label(self, mock_label):
        """"""Test the implementation of the label method""""""
        # Set up the mock to return the value we want
        mock_label.return_value = ""nucleus""
        
        # Test label retrieval
        label = self.oi.label(""GO:0005634"")
        self.assertEqual(label, ""nucleus"")
        
        # Verify the mock was called correctly
        mock_label.assert_called_with(""GO:0005634"")
",tests/test_implementations/test_ols.py,TestOlsImplementation,1,3.653482080241728e-08,"The method 'test_label' is a unit test designed to verify the behavior of a 'label' method using a mock object. Unit tests are crucial for ensuring code reliability and are typically retained in codebases to facilitate ongoing testing and validation of functionality. The presence of a mock object indicates that this test is isolating the 'label' method from external dependencies, which is a common and recommended practice in software development. Therefore, it is unlikely that this method will be deleted as it serves an important role in maintaining code quality."
survived,"    def test_constant_variable(self):
        # Test with constant (zero variance) variables
        data = np.array([[1, 1, 1, 1], [2, 2, 2, 2], [1, 2, 3, 4]], dtype=np.float64)
        result = nancovmatrix(data)

        # Diagonal elements for constant variables should be 0
        assert result[0, 0] == 0.0
        assert result[1, 1] == 0.0
        assert result[2, 2] > 0  # Non-constant variable

        # Covariance between constants should be 0
        assert result[0, 1] == 0.0
        assert result[1, 0] == 0.0
",numbagg/test/test_nancovmatrix.py,TestNanCovMatrix,1,1.3440409770490404e-08,"The method 'test_constant_variable' is a unit test designed to verify the behavior of the 'nancovmatrix' function when dealing with constant variables. It checks that the covariance matrix correctly identifies zero variance for constant variables and non-zero variance for non-constant variables. This is a fundamental test for validating the correctness of the covariance matrix computation, especially in handling edge cases like constant variables. Such tests are crucial for ensuring the reliability and accuracy of statistical functions, and therefore, it is likely to be retained in the codebase."
survived,"    def test_dtype_preservation(self):
        # Test float32
        data32 = np.random.randn(5, 20).astype(np.float32)
        result32 = nancovmatrix(data32)
        assert result32.dtype == np.float32

        # Test float64
        data64 = np.random.randn(5, 20).astype(np.float64)
        result64 = nancovmatrix(data64)
        assert result64.dtype == np.float64
",numbagg/test/test_nancovmatrix.py,TestNanCovMatrix,1,6.348800075736417e-09,"The method 'test_dtype_preservation' is a unit test designed to ensure that the 'nancovmatrix' function preserves the data type of the input array. This is a common and important test in numerical computing to ensure that precision is not lost during computations. The test is straightforward, checks a fundamental property, and is likely to be useful for maintaining the integrity of the 'nancovmatrix' function. Therefore, it is unlikely to be deleted."
survived,"def nancorrmatrix(a, out):
    """"""
    Compute correlation matrix treating NaN as missing values.

    For 2D input, correlates variables (rows) across observations (columns).
    Uses pairwise complete observations (like pandas.DataFrame.corr).
    """"""
    n_vars, n_obs = a.shape

    # Compute correlation matrix
    for i in range(n_vars):
        for j in range(i, n_vars):  # Only compute upper triangle
            if i == j:
                # Diagonal: correlation with itself is 1.0 if any valid values exist
                for k in range(n_obs):
                    if not np.isnan(a[i, k]):
                        out[i, j] = 1.0
                        break
                else:
                    # No valid values found
                    out[i, j] = np.nan
                continue

            # Find pairwise complete observations and compute sums in one pass
            sum_i = 0.0
            sum_j = 0.0
            count = 0

            for k in range(n_obs):
                val_i = a[i, k]
                val_j = a[j, k]
                if not np.isnan(val_i) and not np.isnan(val_j):
                    sum_i += val_i
                    sum_j += val_j
                    count += 1

            if count > 1:
                # Compute means using only pairwise complete observations
                mean_i = sum_i / count
                mean_j = sum_j / count

                # Compute correlation components in second pass
                cov_sum = 0.0
                var_i_sum = 0.0
                var_j_sum = 0.0

                for k in range(n_obs):
                    val_i = a[i, k]
                    val_j = a[j, k]
                    if not np.isnan(val_i) and not np.isnan(val_j):
                        diff_i = val_i - mean_i
                        diff_j = val_j - mean_j
                        cov_sum += diff_i * diff_j
                        var_i_sum += diff_i * diff_i
                        var_j_sum += diff_j * diff_j

                # Use count - 1 for sample correlation
                var_i = var_i_sum / (count - 1)
                var_j = var_j_sum / (count - 1)

                if var_i > 0 and var_j > 0:
                    corr = cov_sum / (count - 1) / np.sqrt(var_i * var_j)
                    out[i, j] = corr
                    out[j, i] = corr  # Symmetric
                else:
                    out[i, j] = np.nan
                    out[j, i] = np.nan
            else:
                out[i, j] = np.nan
                out[j, i] = np.nan
",numbagg/funcs.py,,1,4.1399375473943306e-08,"The method 'nancorrmatrix' is a specialized function for computing correlation matrices while handling NaN values, which is a common requirement in data analysis and statistics. It provides a useful utility for users dealing with datasets that have missing values, and it implements a pairwise complete observation approach similar to popular libraries like pandas. This functionality is valuable and not trivial to implement from scratch, making it likely to be retained in a codebase where handling NaN values in correlation calculations is necessary."
survived,"    async def test_get_prompt_on_parent_server(
        self,
        mcp_server: FastMCP,
        nested_mcp_server: FastMCP,
        recording_middleware: RecordingMiddleware,
        nested_middleware: RecordingMiddleware,
    ):
        mcp_server.mount(nested_mcp_server, prefix=""nested"")

        async with Client(mcp_server) as client:
            await client.get_prompt(""test_prompt"", {""x"": ""test""})

        assert recording_middleware.assert_called(times=3)
        assert recording_middleware.assert_called(method=""prompts/get"", times=3)
        assert recording_middleware.assert_called(hook=""on_message"", times=1)
        assert recording_middleware.assert_called(hook=""on_request"", times=1)
        assert recording_middleware.assert_called(hook=""on_get_prompt"", times=1)

        assert nested_middleware.assert_called(times=0)
",tests/server/middleware/test_middleware.py,TestNestedMiddlewareHooks,1,3.2241866333029355e-08,"The method is a test function that verifies the behavior of a system involving multiple components (servers and middleware). It checks if the middleware is called the expected number of times and with the correct parameters. Such test functions are crucial for ensuring the reliability and correctness of the system, especially in complex setups involving nested servers and middleware. Therefore, it is likely to be retained as part of the test suite to ensure ongoing system integrity."
survived,"    async def test_list_resource_templates_on_nested_server(
        self,
        mcp_server: FastMCP,
        nested_mcp_server: FastMCP,
        recording_middleware: RecordingMiddleware,
        nested_middleware: RecordingMiddleware,
    ):
        mcp_server.mount(nested_mcp_server, prefix=""nested"")

        async with Client(mcp_server) as client:
            await client.list_resource_templates()

        assert recording_middleware.assert_called(times=3)
        assert recording_middleware.assert_called(
            method=""resources/templates/list"", times=3
        )
        assert recording_middleware.assert_called(hook=""on_message"", times=1)
        assert recording_middleware.assert_called(hook=""on_request"", times=1)
        assert recording_middleware.assert_called(
            hook=""on_list_resource_templates"", times=1
        )

        assert nested_middleware.assert_called(times=3)
        assert nested_middleware.assert_called(
            method=""resources/templates/list"", times=3
        )
        assert nested_middleware.assert_called(hook=""on_message"", times=1)
        assert nested_middleware.assert_called(hook=""on_request"", times=1)
        assert nested_middleware.assert_called(
            hook=""on_list_resource_templates"", times=1
        )",tests/server/middleware/test_middleware.py,TestNestedMiddlewareHooks,1,6.023574641292144e-08,"The method is a test function that verifies the behavior of listing resource templates on a nested server setup. It uses assertions to ensure that the middleware is called the expected number of times and with the correct parameters. This kind of test is crucial for ensuring the correct functionality of the system, especially in complex setups involving nested servers. Therefore, it is likely to be maintained as part of the test suite to ensure ongoing reliability and correctness of the system."
survived,"        async def progress_tool(context: Context) -> None:
            await context.report_progress(progress=1, total=10, message=""test"")
",tests/server/middleware/test_middleware.py,TestNestedMiddlewareHooks,1,4.944450477491054e-09,"The method 'progress_tool' is an asynchronous function that reports progress using the 'context.report_progress' method. This kind of functionality is often useful in applications where progress tracking is necessary, such as in long-running tasks or operations that provide feedback to the user. Since it serves a specific purpose and is likely part of a larger system that requires progress reporting, it is more likely to be retained rather than deleted."
survived,"        async def _handler(
            context: MiddlewareContext[mcp.types.GetPromptRequestParams],
        ) -> GetPromptResult:
            return await self._get_prompt(
                name=context.message.name,
                arguments=context.message.arguments,
            )
",src/fastmcp/server/server.py,FastMCP,1,1.955568070542584e-08,"The method '_handler' is an asynchronous function that serves as a middleware handler. It takes a context parameter and returns a result from another asynchronous method '_get_prompt'. This structure is typical in modern asynchronous programming, especially in frameworks that handle requests or messages. The method is likely part of a larger system that processes requests and is designed to be efficient and non-blocking. Given the trend towards asynchronous programming for handling I/O-bound operations, this method is likely to be retained as it fits well with current best practices."
deleted,"    async def _list_prompts(self, apply_middleware: bool = True) -> list[Prompt]:
        """"""
        List all available prompts.
        """"""

        if (prompts := self._cache.get(""prompts"")) is self._cache.NOT_FOUND:
            prompts: list[Prompt] = []

            # iterate such that new mounts overwrite older ones
            for mounted_server in self._mounted_servers:
                try:
                    if apply_middleware:
                        server_prompts = (
                            await mounted_server.server._middleware_list_prompts()
                        )
                    else:
                        server_prompts = await mounted_server.server._list_prompts()
                    # Apply prefix to each prompt key if prefix exists
                    if mounted_server.prefix:
                        for prompt in server_prompts:
                            prompt = prompt.with_key(
                                f""{mounted_server.prefix}_{prompt.key}""
                            )
                            prompts.append(prompt)
                    else:
                        prompts.extend(server_prompts)
                except Exception as e:
                    logger.warning(
                        f""Failed to get prompts from mounted server '{mounted_server.prefix}': {e}""
                    )
                    continue
            prompts.extend(self._prompt_manager.get_prompts().values())
            self._cache.set(""prompts"", prompts)
        return prompts
",src/fastmcp/server/server.py,FastMCP,1,1.0467401685178159e-08,"The method '_list_prompts' is a crucial part of the system as it aggregates prompts from various mounted servers and applies middleware if necessary. It also handles caching to improve performance and includes error handling to ensure robustness. These features indicate that the method is well-designed and serves an important function in the system, making it unlikely to be deleted."
deleted,"    async def _middleware_list_resource_templates(self) -> list[ResourceTemplate]:
        """"""
        List all available resource templates, in the format expected by the low-level MCP
        server.

        """"""

        async def _handler(
            context: MiddlewareContext[dict[str, Any]],
        ) -> list[ResourceTemplate]:
            templates = await self._list_resource_templates()

            mcp_templates: list[ResourceTemplate] = []
            for template in templates:
                if self._should_enable_component(template):
                    mcp_templates.append(template)

            return mcp_templates

        with fastmcp.server.context.Context(fastmcp=self) as fastmcp_ctx:
            # Create the middleware context.
            mw_context = MiddlewareContext(
                message={},  # List resource templates doesn't have parameters
                source=""client"",
                type=""request"",
                method=""resources/templates/list"",
                fastmcp_context=fastmcp_ctx,
            )

            # Apply the middleware chain.
            return await self._apply_middleware(mw_context, _handler)
",src/fastmcp/server/server.py,FastMCP,1,7.194132978569833e-09,"The method '_middleware_list_resource_templates' is an asynchronous function that is designed to list all available resource templates in a specific format. It uses a handler function to filter and return templates based on certain conditions. The method is well-structured, uses context management, and applies middleware, which suggests it is part of a larger, well-designed system. There is no indication that this method is obsolete or redundant, and it seems to serve a specific purpose in the system. Therefore, it is likely to be retained."
survived,"    async def test_read_resource_on_parent_server(
        self,
        mcp_server: FastMCP,
        nested_mcp_server: FastMCP,
        recording_middleware: RecordingMiddleware,
        nested_middleware: RecordingMiddleware,
    ):
        mcp_server.mount(nested_mcp_server, prefix=""nested"")

        async with Client(mcp_server) as client:
            await client.read_resource(""resource://test"")

        assert recording_middleware.assert_called(times=3)
        assert recording_middleware.assert_called(method=""resources/read"", times=3)
        assert recording_middleware.assert_called(hook=""on_message"", times=1)
        assert recording_middleware.assert_called(hook=""on_request"", times=1)
        assert recording_middleware.assert_called(hook=""on_read_resource"", times=1)

        assert nested_middleware.assert_called(times=0)
",tests/server/middleware/test_middleware.py,TestNestedMiddlewareHooks,1,2.2159489282323004e-08,The method `test_read_resource_on_parent_server` is a test function that verifies the behavior of a server setup using assertions. It checks if certain middleware hooks are called the expected number of times when a resource is read. This kind of test is crucial for ensuring that the server and middleware interactions are functioning correctly. Test methods like this are typically retained as they are essential for maintaining code quality and reliability.
survived,"    async def test_call_tool(
        self, mcp_server: FastMCP, recording_middleware: RecordingMiddleware
    ):
        async with Client(mcp_server) as client:
            await client.call_tool(""add"", {""a"": 1, ""b"": 2})

        assert recording_middleware.assert_called(times=3)
        assert recording_middleware.assert_called(method=""tools/call"", times=3)
        assert recording_middleware.assert_called(hook=""on_message"", times=1)
        assert recording_middleware.assert_called(hook=""on_request"", times=1)
        assert recording_middleware.assert_called(hook=""on_call_tool"", times=1)
",tests/server/middleware/test_middleware.py,TestMiddlewareHooks,1,1.8189616842444243e-09,"The method 'test_call_tool' is a unit test designed to verify the behavior of a system involving a client-server interaction and middleware recording. It checks if the 'call_tool' method is invoked correctly and if the middleware records the expected number of calls and hooks. This kind of test is crucial for ensuring the reliability and correctness of the system's functionality, especially in asynchronous environments. Given its importance in maintaining code quality and preventing regressions, it is likely to be retained in the codebase."
survived,"def test_export_datasets_empty_database():
    """"""Test behavior with empty source database""""""
    with tempfile.TemporaryDirectory() as temp_dir:
        source_db_path = Path(temp_dir) / ""empty.db""
        target_db_path = Path(temp_dir) / ""target.db""
        export_path = Path(temp_dir) / ""exports""
        
        # Create empty database
        source_conn = connect(source_db_path)
        source_conn.close()
        
        # Run the export function
        result = export_datasets_and_create_metadata_db(
            source_db_path=source_db_path,
            target_db_path=target_db_path,
            export_path=export_path,
        )
        
        # Should return empty result
        assert result == {}
",tests/dataset/test_export_datasets_and_create_metadata_db.py,,1,5.3157849718487075e-08,"The method is a unit test designed to verify the behavior of the `export_datasets_and_create_metadata_db` function when the source database is empty. Unit tests are crucial for ensuring code reliability and are typically maintained as long as the functionality they test is relevant. Since this test checks for a specific edge case (an empty database), it is likely to be useful for validating the robustness of the export function. Therefore, it is unlikely to be deleted unless the functionality it tests is removed or significantly altered."
survived,"            def _make_check(
                p: re.Pattern[str], r: GuardrailRule
            ) -> Callable[[str], Awaitable[str]]:
                if r.action is GuardrailAction.REDACT:

                    async def _check(text: str) -> str:
                        return p.sub(""[REDACTED]"", text)

                else:  # DENY or FLAG -> raise error on match

                    async def _check(text: str) -> str:
                        if p.search(text):
                            raise ValueError(f""Policy violation: {r.name}"")
                        return text

                return _check
",src/meta_agent/policy.py,PolicyChecker,1,3.850741907939403e-09,"The method `_make_check` is a utility function that creates an asynchronous check function based on a pattern and a rule. It is designed to handle different actions (REDACT, DENY, FLAG) by either redacting matched text or raising an error. This kind of functionality is useful in applications that need to enforce content policies or data privacy rules. Given its utility in ensuring compliance and handling sensitive data, it is likely to be retained in the codebase."
survived,"    def add_from_config(self, config: GuardrailConfig) -> None:
        """"""Add checks from a :class:`GuardrailConfig`.""""""

        for rule in config.rules:
            pattern = re.compile(rule.pattern)

            def _make_check(
                p: re.Pattern[str], r: GuardrailRule
            ) -> Callable[[str], Awaitable[str]]:
                if r.action is GuardrailAction.REDACT:

                    async def _check(text: str) -> str:
                        return p.sub(""[REDACTED]"", text)

                else:  # DENY or FLAG -> raise error on match

                    async def _check(text: str) -> str:
                        if p.search(text):
                            raise ValueError(f""Policy violation: {r.name}"")
                        return text

                return _check

            self.checks.append(_make_check(pattern, rule))
",src/meta_agent/policy.py,PolicyChecker,1,2.7894680920908113e-10,"The method 'add_from_config' is likely to survive because it is a well-structured and useful function that adds checks from a configuration object to a list of checks. It uses regular expressions to define patterns and creates asynchronous functions to either redact or raise errors based on the rules provided. This functionality is essential for applications that need to enforce security or compliance rules dynamically based on configuration, making it a valuable part of the codebase."
survived,"def compute_hash(workbox: Path) -> str:
    data = workbox.read_bytes()
    digest = hashlib.sha384(data).digest()
    b64 = base64.b64encode(digest).decode()
    return f""sha384-{b64}""
",scripts/verify_workbox_hash.py,,1,2.646573631904765e-09,"The method 'compute_hash' is a utility function that computes a SHA-384 hash of the contents of a file and returns it in a base64-encoded format. This is a common and useful operation in many applications, such as verifying file integrity or creating unique identifiers for file contents. The method is well-defined, uses standard libraries, and performs a specific, useful task without any apparent issues. Therefore, it is likely to be retained in the codebase."
survived,"    def boom(*_: object) -> None:
        raise NotImplementedError
",test/windows/test_shutdown.py,,0,0.999999694097641,"The method 'boom' is defined to take any number of arguments but does nothing except raise a NotImplementedError. This suggests that the method is a placeholder for future implementation. However, without any additional context or usage, it doesn't provide any functionality or utility in its current state. Typically, such methods are either completed or removed if they are not needed. Given this, the method is more likely to be deleted unless there is a specific plan to implement it in the future."
survived,"def test_background_run_direct(tmp_path: Path, monkeypatch: pytest.MonkeyPatch) -> None:
    """"""Call the internal worker directly and verify progress and output.""""""

    monkeypatch.setenv(""SIM_RESULTS_DIR"", str(tmp_path))

    import importlib

    from src.interface import api_server as api

    api = importlib.reload(api)

    messages: list[dict[str, object]] = []

    class DummyWS:
        async def send_json(self, data: dict[str, object]) -> None:
            messages.append(data)

    ws = DummyWS()
    api._progress_ws.add(ws)

    sim_id = ""unit-test""
    cfg = api.SimRequest(horizon=1, pop_size=2, generations=1)
    asyncio.run(api._background_run(sim_id, cfg))

    api._progress_ws.discard(ws)

    assert (tmp_path / f""{sim_id}.json"").exists()
    assert messages and messages[0][""id""] == sim_id",tests/test_api_server.py,,1,2.2159489282323004e-08,"The method 'test_background_run_direct' is a test function that verifies the functionality of an internal worker by simulating a run and checking the output. It uses a temporary path and a monkeypatch to set up the environment, and it checks that the expected output file is created and that messages are sent correctly. This is a typical test case that is useful for ensuring the correctness of the code, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained."
survived,"    def test_main_happy_path(self, edge_parse, run_parse, apply_env, run):
        edge_parse.return_value = self._args()
        run_parse.return_value = argparse.Namespace()
        os.environ.pop(""PGHOST"", None)

        edge_runner.main()

        edge_parse.assert_called_once_with()
        run_parse.assert_called_once_with([
            ""--dev"",
            ""--port"",
            ""123"",
            ""--metrics-port"",
            ""456"",
            ""--a2a-port"",
            ""789"",
            ""--enabled"",
            ""A,B"",
            ""--cycle"",
            ""5"",
            ""--loglevel"",
            ""DEBUG"",
        ])
        apply_env.assert_called_once_with(run_parse.return_value)
        self.assertEqual(os.environ[""PGHOST""], ""sqlite"")
        run.assert_called_once_with()
",alpha_factory_v1/tests/test_edge_runner_main.py,EdgeRunnerMainInvokesRun,1,4.6911638017642294e-08,"The method `test_main_happy_path` is a unit test designed to verify the correct behavior of the `edge_runner.main` function. It uses mock objects to simulate and assert the expected interactions and state changes. The method is well-structured, follows common testing practices, and is likely part of a test suite that ensures the reliability of the codebase. Since testing is a crucial part of software development and maintenance, this method is likely to be retained to ensure the functionality it tests remains correct over time."
survived,"def _files_from_diff(diff: str) -> list[str]:
    files: set[str] = set()
    for line in diff.splitlines():
        if line.startswith(""+++"") or line.startswith(""---""):
            parts = line.split(maxsplit=1)
            if len(parts) != 2:
                continue
            path = parts[1]
            if path.startswith(""a/"") or path.startswith(""b/""):
                path = path[2:]
            files.add(path)
    return list(files)
",src/agents/self_improver_agent.py,,1,4.599055376537186e-10,"The method `_files_from_diff` is a utility function that extracts file paths from a diff string, which is a common requirement in version control systems like Git. The function is well-defined, concise, and performs a specific task effectively. It uses a set to ensure unique file paths and handles common diff line prefixes. Such utility functions are often reused in various contexts where diff parsing is needed, making it likely to survive."
survived,"    def __init__(self, settings: config.Settings) -> None:
        super().__init__(settings)
        self.published: list[tuple[str, messaging.Envelope]] = []
",tests/test_safety_agent.py,CaptureBus,1,2.998960815863541e-09,"The method is a constructor (__init__) for a class, which is essential for initializing class instances. It sets up the initial state of the object by calling the superclass constructor and initializing an instance variable. Constructors are fundamental to object-oriented programming and are rarely deleted unless the class itself is being removed or significantly refactored. Therefore, it is highly likely to survive."
survived,"def test_blocked_payload_not_stored(tmp_path) -> None:
    """"""ChaosAgent payloads should be blocked and skipped by the memory.""""""

    cfg = config.Settings(bus_port=0)
    bus = CaptureBus(cfg)
    ledger = logging.Ledger(str(tmp_path / ""ledger.db""), broadcast=False)

    mem = FilteringMemoryAgent(bus, ledger, str(tmp_path / ""mem.log""))
    guardian = safety_agent.SafetyGuardianAgent(bus, ledger)
    chaos = chaos_agent.ChaosAgent(bus, ledger, burst=1)

    async def run() -> None:
        async with bus, ledger:
            await chaos.run_cycle()
            await asyncio.sleep(0)

    asyncio.run(run())

    memory_events = [env for topic, env in bus.published if topic == ""memory""]
    assert memory_events
    assert memory_events[-1].payload[""status""] == ""blocked""
    assert mem.records == []",tests/test_safety_agent.py,,1,6.825604231969389e-08,"The method 'test_blocked_payload_not_stored' is a unit test designed to verify that a specific functionality (blocking and skipping of ChaosAgent payloads) is working as intended. Unit tests are crucial for ensuring code reliability and are typically retained in the codebase to prevent regressions. Therefore, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered."
survived,"    def __init__(
        self, 
        timeout: int = 60, 
        proxies: Optional[dict] = None
    ):
        """"""Initialize your PollinationsAI provider with custom settings

        Examples:
            >>> provider = PollinationsAI(timeout=30)
            >>> provider = PollinationsAI(proxies={""http"": ""http://proxy:8080""})

        Args:
            timeout (int): HTTP request timeout in seconds (default: 60)
            proxies (dict, optional): Proxy configuration for requests
        """"""
        self.image_gen_endpoint = ""https://image.pollinations.ai/prompt/{prompt}""
        self.headers = {
            ""Accept"": ""text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8"",
            ""Accept-Language"": ""en-US,en;q=0.5"",
            ""Accept-Encoding"": ""gzip, deflate"",
            ""User-Agent"": agent.random(),
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)
        if proxies:
            self.session.proxies.update(proxies)
            
        self.timeout = timeout
        self.prompt: str = ""AI-generated image - webscout""
        self.image_extension: str = ""jpeg""
",webscout/Provider/TTI/pollinations.py,PollinationsAI,1,1.8553915987649156e-07,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class with specific attributes and configurations. It sets up important parameters like timeout, proxies, headers, and session, which are likely crucial for the functionality of the class. Constructors are fundamental to object-oriented programming and are rarely deleted unless the entire class is being refactored or removed, which is not indicated here."
survived,"    def create_token(self, path: Path) -> Dict[str, Any]:
        """"""Create a new authentication token""""""
        # Step 1: Generate Authentication Token
        auth_payload = {""clientType"": ""CLIENT_TYPE_ANDROID""}
        proxies = self.session.proxies if self.session.proxies else None
        
        auth_response = self.session.post(self.auth_url, json=auth_payload, timeout=self.timeout, proxies=proxies)
        auth_data = auth_response.json()
        auth_token = auth_data.get(""idToken"")
        
        if not auth_token:

            raise Exception(""Failed to obtain authentication token."")
        
        with open(path, 'w') as f:
            json.dump(auth_data, f)
        
        return auth_data
",webscout/Provider/TTI/aiarta.py,AIArtaImager,1,2.0611536181902033e-09,"The method 'create_token' is likely to survive because it performs a crucial function of generating and storing an authentication token, which is a common requirement in applications that need to authenticate users or services. The method is well-structured, handles exceptions, and uses standard libraries for HTTP requests and JSON handling, making it a reliable and reusable piece of code."
survived,"    def generate(
        self,
        prompt: str,
        max_retries: int = 3,
        retry_delay: int = 5,
    ) -> List[bytes]:
        """"""Generate some fire images from your prompt! 🎨

        Args:
            prompt (str): Your image description
            max_retries (int): Max retry attempts if something fails (default: 3)
            retry_delay (int): Seconds to wait between retries (default: 5)

        Returns:
            List[bytes]: Your generated images as bytes

        Raises:
            ValueError: If the inputs ain't valid
            RequestException: If the API calls fail after retries
        """"""
        # Input validation
        if not prompt:
            raise ValueError(""Yo fam, the prompt can't be empty! 🤔"")

        self.prompt = prompt
        response = []
        
        # Get request ID
        data = {""prompt"": prompt}
        resp = self.session.post(self.request_id_endpoint, json=data, timeout=self.timeout)
        resp.raise_for_status()
        request_id = resp.json()[""requestId""]

        # Poll for results
        for attempt in range(max_retries):
            try:
                # Get image URLs
                resp = self.session.get(
                    f""{self.image_response_endpoint}?requestId={request_id}"",
                    timeout=self.timeout
                )
                resp.raise_for_status()
                image_data = resp.json()

                if ""results"" in image_data and len(image_data[""results""]) >= 2:
                    # Get provider names
                    provider_resp = self.session.post(
                        self.image_provider_endpoint,
                        json={""requestId"": request_id, ""preference"": 0},
                        timeout=self.timeout
                    )
                    provider_resp.raise_for_status()
                    provider_data = provider_resp.json()

                    # Download images
                    for i, url in enumerate(image_data[""results""][:2]):
                        img_resp = self.session.get(url, timeout=self.timeout)
                        img_resp.raise_for_status()
                        response.append(img_resp.content)
                    
                    break
                else:
                    if attempt == max_retries - 1:
                        raise RequestException(""Failed to get image results after max retries"")
                    time.sleep(retry_delay)

            except RequestException as e:
                if attempt == max_retries - 1:
                    raise
                time.sleep(retry_delay)

        return response
",webscout/Provider/TTI/imgsys.py,ImgSys,1,2.3355930333443423e-09,"The method is well-structured and provides a clear functionality of generating images based on a prompt. It includes error handling, retries, and input validation, which are essential for robust API interaction. The method is likely to be useful in applications that require image generation from text prompts, a common use case in AI and creative applications. Therefore, it is likely to be retained."
survived,"    def generate(
        self, 
        prompt: str,
        amount: int = 1,
        max_retries: int = 3,
        retry_delay: int = 5
    ) -> List[bytes]:
        """"""Generate some fire images from your prompt! 🎨""""""
        if not prompt:
            raise ValueError(""Yo fam, prompt can't be empty! 🚫"")
        if not isinstance(amount, int) or amount < 1:
            raise ValueError(""Amount needs to be a positive number! 📈"")

        self.prompt = prompt
        response = []

        for _ in range(amount):
            form_data = {
                ""prompt"": prompt,
                ""output_format"": ""bytes"",
                ""user_profile_id"": ""null"",
                ""anonymous_user_id"": str(uuid.uuid4()),
                ""request_timestamp"": time.time(),
                ""user_is_subscribed"": ""false"",
                ""client_id"": uuid.uuid4().hex,
            }

            for attempt in range(max_retries):
                try:
                    resp = self.session.post(
                        self.api_endpoint,
                        data=form_data,
                        timeout=self.timeout
                    )
                    resp.raise_for_status()
                    response.append(resp.content)
                    break
                except RequestException as e:
                    if attempt == max_retries - 1:
                        raise
                    time.sleep(retry_delay)

        return response
",webscout/Provider/TTI/magicstudio.py,MagicStudioImager,1,6.69158608681505e-10,"The method 'generate' is well-structured and provides a clear functionality of generating images based on a prompt. It includes error handling for invalid inputs and network request retries, which are essential for robustness. The method is likely part of a larger system that interacts with an API to generate images, a common use case in modern applications. Given its utility and the fact that it handles potential errors gracefully, it is likely to be retained in the codebase."
survived,"def numeric_grad(func, x, eps=1e-6):
    """"""Compute numeric gradient of scalar-valued function.""""""
    x = np.asarray(x, dtype=float)
    grad = np.zeros_like(x, dtype=float)
    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])
    while not it.finished:
        idx = it.multi_index
        orig = float(x[idx])
        x[idx] = orig + eps
        f_pos = func(x)
        x[idx] = orig - eps
        f_neg = func(x)
        grad[idx] = (f_pos - f_neg) / (2 * eps)
        x[idx] = orig
        it.iternext()
    return grad
",klongpy/autograd.py,,1,4.363462233903899e-09,"The method `numeric_grad` is a utility function that computes the numerical gradient of a scalar-valued function. This is a common requirement in optimization and machine learning tasks where analytical gradients are not available or difficult to compute. The method is implemented using finite differences, which is a standard approach for numerical differentiation. Given its utility and correctness, it is likely to be retained in the codebase."
survived,"    async def close(self) -> None:
        """"""Close the underlying HTTP session.""""""
        await self._session.close()
",src/meta_agent/services/telemetry_client.py,TelemetryAPIClient,1,1.3440409770490404e-08,"The method 'close' is a straightforward implementation that closes an HTTP session, which is a common requirement in managing resources in asynchronous programming. It is likely to be essential for ensuring that resources are properly released and to prevent potential memory leaks. Therefore, it is unlikely to be deleted as it serves a critical function in resource management."
survived,"        def __init__(self, *_, **__):
            pass
",src/meta_agent/services/telemetry_client.py,TCPConnector,0,0.9998415637531546,"The method is a constructor that takes arbitrary positional and keyword arguments but does nothing with them. This is often used as a placeholder or to satisfy an interface requirement without implementing any functionality. However, if the class is intended to be used in a meaningful way, this constructor would likely be replaced with one that initializes class attributes or performs some setup. If the class is meant to be a base class or a mixin where initialization is not needed, it might survive. Without additional context, it's more likely to be deleted or replaced in a practical codebase."
survived,"def test_form(monkeypatch):
    inputs = iter([""foo"", ""bar""])
    monkeypatch.setattr(""builtins.input"", lambda _: next(inputs))
    inter = Interactive()
    result = inter.form([""first"", ""second""])
    assert result == {""first"": ""foo"", ""second"": ""bar""}",tests/ux/test_interactive.py,,1,9.237449576640118e-09,"The method 'test_form' is a unit test that uses the 'monkeypatch' fixture to simulate user input for testing the 'form' method of an 'Interactive' class. This is a common and useful practice in testing to ensure that the 'form' method correctly processes input. The method is well-structured and serves a clear purpose in verifying the functionality of the 'form' method. Therefore, it is likely to be retained as part of the test suite."
survived,"def test_ask(monkeypatch):
    inter = Interactive()
    monkeypatch.setattr(""builtins.input"", lambda _: ""answer"")
    assert inter.ask(""Question?"") == ""answer""
",tests/ux/test_interactive.py,,1,2.0611536181902033e-09,"The method 'test_ask' is a unit test function that uses the 'monkeypatch' fixture to mock the 'input' function. This is a common practice in testing to simulate user input and verify that the 'ask' method of the 'Interactive' class returns the expected result. The code is well-structured for its purpose and does not contain any deprecated or problematic patterns. Therefore, it is likely to be retained in the codebase."
survived,"    def test_prom_metrics_stub(self):
        class Dummy:
            def __init__(self, *_, **__):
                self.label_arg = None
            def labels(self, name):
                self.label_arg = name
                return self
            def inc(self):
                pass
            def set(self, v):
                self.value = v
        orig_counter = base_mod.Counter
        orig_gauge = base_mod.Gauge
        base_mod.Counter = Dummy
        base_mod.Gauge = Dummy
        run, err, lat = base_mod._prom_metrics(""test"")
        self.assertIsInstance(run, Dummy)
        self.assertEqual(run.label_arg, ""test"")
        self.assertIsInstance(err, Dummy)
        self.assertIsInstance(lat, Dummy)
        base_mod.Counter = orig_counter
        base_mod.Gauge = orig_gauge
",tests/test_base_helpers.py,TestPromMetrics,1,1.3440409770490404e-08,"The method 'test_prom_metrics_stub' is a unit test designed to test the behavior of the '_prom_metrics' function in the 'base_mod' module. It uses a 'Dummy' class to mock the behavior of 'Counter' and 'Gauge' classes, allowing the test to verify that the '_prom_metrics' function correctly interacts with these classes. This is a common practice in testing to isolate the function being tested from its dependencies. Since this method is a test and serves a clear purpose in ensuring the correctness of the '_prom_metrics' function, it is likely to be retained in the codebase."
survived,"    def test_ping_capability_present(self):
        # diagnostics capability should map to the ping agent
        from alpha_factory_v1.backend.agents.ping_agent import PingAgent
        meta = AgentMetadata(
            name=PingAgent.NAME,
            cls=PingAgent,
            version=""0"",
            capabilities=PingAgent.CAPABILITIES,
            compliance_tags=[],
        )
        register_agent(meta)
        agents = capability_agents(""diagnostics"")
        self.assertIn(""ping"", agents)
",tests/test_agents_registry.py,TestAgentRegistryFunctions,1,2.5109990926928157e-08,"The method 'test_ping_capability_present' is a unit test that verifies the presence of a 'ping' capability within a system. It imports the 'PingAgent' class, creates an 'AgentMetadata' instance, registers the agent, and checks if 'ping' is included in the list of agents with 'diagnostics' capability. This test is crucial for ensuring that the 'ping' functionality is correctly mapped and available, which is likely an important feature in the system. Therefore, it is unlikely to be deleted as it serves a key role in maintaining the integrity and functionality of the system."
survived,"    def test_build_async_returns_ops(self):
        jobs = [[{""machine"": ""m1"", ""proc"": 2}, {""machine"": ""m2"", ""proc"": 3}]]
        req = {""jobs"": jobs, ""horizon"": 10}
        result = asyncio.run(self.agent._build_async(req))
        payload = json.loads(result)[""payload""]
        self.assertIn(""ops"", payload)
        self.assertIsInstance(payload[""ops""], list)
        self.assertGreaterEqual(payload[""horizon""], 5)
",tests/test_manufacturing_agent.py,TestManufacturingAgent,1,2.3355930333443423e-09,"The method `test_build_async_returns_ops` is a unit test designed to verify the behavior of the `_build_async` method in an asynchronous context. It checks that the result contains an 'ops' key in the payload and that 'ops' is a list, as well as ensuring the 'horizon' value is at least 5. This test is crucial for validating the functionality of the asynchronous method and ensuring it meets expected conditions. Given its role in maintaining code quality and correctness, it is likely to be retained."
survived,"    def test_run_cycle_negative_delta_g_posts_job(self) -> None:
        class LowFin(demo.AgentFin):
            def latent_work(self, bundle):
                return 0.0

        class CaptureOrch(demo.Orchestrator):
            def __init__(self) -> None:
                self.called = False

            def post_alpha_job(self, bundle_id: int, delta_g: float) -> None:
                self.called = True

        orch = CaptureOrch()
        demo.run_cycle(
            orch,
            LowFin(),
            demo.AgentRes(),
            demo.AgentEne(),
            demo.AgentGdl(),
            DummyModel(),
        )
        self.assertTrue(orch.called)
",tests/test_alpha_agi_business_3_v1.py,TestAlphaAgiBusiness3Demo,1,8.152020648014727e-09,"The method is a unit test designed to verify the behavior of a system when a specific condition is met (negative delta_g). It uses mock classes to simulate parts of the system and checks if a particular method is called. This is a common practice in testing to ensure that the system behaves as expected under certain conditions. Since testing is a crucial part of software development and maintenance, this method is likely to be retained to ensure the reliability of the system."
survived,"    def test_cli_execution(self) -> None:
        result = subprocess.run(
            [sys.executable, ""-m"", ""alpha_factory_v1.demos.alpha_agi_business_3_v1.alpha_agi_business_3_v1"", ""--cycles"", ""1"", ""--loglevel"", ""warning""],
            capture_output=True,
            text=True,
        )
        self.assertEqual(result.returncode, 0, result.stderr)
",tests/test_alpha_agi_business_3_v1.py,TestAlphaAgiBusiness3Demo,1,2.646573631904765e-09,"The method 'test_cli_execution' is a unit test that checks the execution of a command-line interface (CLI) command using the 'subprocess.run' method. It verifies that the command completes successfully by asserting that the return code is 0. This is a common practice in testing to ensure that scripts or commands run as expected without errors. Since this is a standard and useful test for validating CLI functionality, it is likely to be retained in the codebase."
survived,"            def latent_work(self, bundle):
                return 0.0
",tests/test_alpha_agi_business_3_v1.py,TestAlphaAgiBusiness3Demo.LowFin,0,0.9999995549151272,"The method 'latent_work' is a simple function that takes a parameter 'bundle' but does not use it in any computation or logic. It simply returns a constant value of 0.0. This suggests that the method might be a placeholder or stub for future implementation. However, as it currently stands, it does not perform any meaningful operation or contribute to the functionality of the class it belongs to. Unless there is a specific reason to keep this method as is (such as maintaining a consistent interface or for future development), it is likely to be considered redundant and could be deleted."
survived,"    def test_play_episode(self):
        frames, reward = play_episode(self.mu, render=False, max_steps=10)
        self.assertIsInstance(frames, list)
        self.assertIsInstance(reward, float)
        self.assertLessEqual(len(frames), 10)
",tests/test_muzero_planning.py,TestMiniMu,1,2.3355930333443423e-09,"The method `test_play_episode` is a unit test designed to verify the functionality of the `play_episode` function. It checks that the function returns a list of frames and a float reward, and that the number of frames does not exceed a specified maximum. This is a typical structure for a test method in a test suite, and such methods are generally retained to ensure code reliability and correctness. Therefore, it is likely to be Survived."
survived,"async def _call_next(_: Request) -> Response:
    return Response(""ok"")
",tests/test_rate_limiter_eviction.py,,1,3.2241866333029355e-08,"The method _call_next is a simple asynchronous function that takes a Request object as an argument and returns a Response object with the string ""ok"". The method is straightforward and functional, serving a clear purpose of responding to a request. There is no indication of it being deprecated or unnecessary, and it could be part of a larger system where such a response is needed. Therefore, it is likely to be retained in the codebase."
survived,"async def list_products(
    ctx: EnrichContext, category: str | None = None, page: int = 1, page_size: int = 20
) -> PageResult[ProductEnrichModel]:
    """"""List products with optional filtering by category.""""""
    session_factory = ctx.request_context.lifespan_context[""session_factory""]
    async with session_factory() as session:
        # Build query
        query = select(Product)
        if category:
            query = query.where(Product.category == category)

        # Get total count
        count_query = select(func.count()).select_from(query.subquery())
        total = await session.scalar(count_query)

        # Get paginated results
        query = query.offset((page - 1) * page_size).limit(page_size)
        result = await session.execute(query)
        products = result.scalars().all()

        items = [
            ProductEnrichModel(
                id=product.id,
                name=product.name,
                description=product.description,
                price=product.price,
                stock_quantity=product.stock_quantity,
                category=product.category,
                created_at=product.created_at,
            )
            for product in products
        ]

        return PageResult.create(
            items=items,
            page=page,
            page_size=page_size,
            total_items=total,
            has_next=page * page_size < total,
        )
",examples/sqlalchemy_shop/app.py,,1,1.1032560311263802e-09,"The method 'list_products' is a well-structured and useful function for listing products with optional filtering by category and pagination. It is likely to be retained because it provides essential functionality for applications that need to display product listings, which is a common requirement in e-commerce and inventory management systems. The use of asynchronous operations and pagination makes it efficient for handling large datasets, and the optional category filter adds flexibility. These features make it a valuable method in a modern web application context."
survived,"    def test_full_ecommerce_model(self):
        """"""Test a complete e-commerce model setup.""""""

        class Base(DeclarativeBase):
            pass

        class User(Base, EnrichSQLAlchemyMixin):
            """"""User account in the system.""""""

            __tablename__ = ""users""

            id: Mapped[int] = mapped_column(primary_key=True, info={""description"": ""User ID""})
            email: Mapped[str] = mapped_column(unique=True, info={""description"": ""Email address""})
            username: Mapped[str] = mapped_column(info={""description"": ""Display name""})
            password_hash: Mapped[str] = mapped_column(info={""exclude"": True})
            created_at: Mapped[datetime] = mapped_column(
                info={""description"": ""Account creation time""}
            )
            is_active: Mapped[bool] = mapped_column(
                default=True, info={""description"": ""Account status""}
            )

            orders: Mapped[list[""Order""]] = relationship(
                back_populates=""user"", info={""description"": ""Orders placed by this user""}
            )
            reviews: Mapped[list[""Review""]] = relationship(
                back_populates=""user"", info={""description"": ""Product reviews by this user""}
            )

        class Product(Base, EnrichSQLAlchemyMixin):
            """"""Product in the catalog.""""""

            __tablename__ = ""products""

            id: Mapped[int] = mapped_column(primary_key=True, info={""description"": ""Product ID""})
            name: Mapped[str] = mapped_column(info={""description"": ""Product name""})
            description: Mapped[str | None] = mapped_column(
                Text, nullable=True, info={""description"": ""Product description""}
            )
            price: Mapped[float] = mapped_column(info={""description"": ""Product price""})
            stock_quantity: Mapped[int] = mapped_column(info={""description"": ""Available stock""})

            reviews: Mapped[list[""Review""]] = relationship(
                back_populates=""product"", info={""description"": ""Customer reviews""}
            )

        class Order(Base, EnrichSQLAlchemyMixin):
            """"""Customer order.""""""

            __tablename__ = ""orders""

            id: Mapped[int] = mapped_column(primary_key=True, info={""description"": ""Order ID""})
            user_id: Mapped[int] = mapped_column(ForeignKey(""users.id""))
            total_amount: Mapped[float] = mapped_column(info={""description"": ""Order total""})
            status: Mapped[str] = mapped_column(info={""description"": ""Order status""})
            created_at: Mapped[datetime] = mapped_column(info={""description"": ""Order date""})

            user: Mapped[User] = relationship(
                back_populates=""orders"", info={""description"": ""Customer who placed the order""}
            )

        class Review(Base, EnrichSQLAlchemyMixin):
            """"""Product review.""""""

            __tablename__ = ""reviews""

            id: Mapped[int] = mapped_column(primary_key=True)
            user_id: Mapped[int] = mapped_column(ForeignKey(""users.id""))
            product_id: Mapped[int] = mapped_column(ForeignKey(""products.id""))
            rating: Mapped[int] = mapped_column(info={""description"": ""Rating 1-5""})
            comment: Mapped[str | None] = mapped_column(
                Text, nullable=True, info={""description"": ""Review text""}
            )

            user: Mapped[User] = relationship(back_populates=""reviews"")
            product: Mapped[Product] = relationship(back_populates=""reviews"")

        # Convert all models
        UserEnrichModel = User.__enrich_model__()
        ProductEnrichModel = Product.__enrich_model__()
        OrderEnrichModel = Order.__enrich_model__()
        ReviewEnrichModel = Review.__enrich_model__()

        # Verify User model
        user_fields = UserEnrichModel.model_fields
        assert ""id"" in user_fields
        assert ""email"" in user_fields
        assert ""username"" in user_fields
        assert ""password_hash"" not in user_fields  # Should be excluded
        assert ""created_at"" in user_fields
        assert ""is_active"" in user_fields
        assert ""orders"" in user_fields
        assert ""reviews"" in user_fields

        # Verify relationships are properly typed
        assert isinstance(user_fields[""orders""].default, Relationship)
        assert isinstance(user_fields[""reviews""].default, Relationship)

        # Verify Order model
        order_fields = OrderEnrichModel.model_fields
        assert ""user"" in order_fields
        assert isinstance(order_fields[""user""].default, Relationship)

        # Verify all models are proper EnrichModels
        for model in [UserEnrichModel, ProductEnrichModel, OrderEnrichModel, ReviewEnrichModel]:
            assert issubclass(model, EnrichModel)",tests/test_sqlalchemy_integration.py,TestComplexScenarios,1,1.275190675769241e-07,"The method `test_full_ecommerce_model` is a comprehensive test function for an e-commerce model setup using SQLAlchemy. It defines several classes representing different entities in an e-commerce system, such as User, Product, Order, and Review. The method then tests the conversion of these models to enriched models and verifies the presence and types of various fields and relationships. This is a typical and necessary test in a software development process to ensure that the model setup is correct and behaves as expected. Therefore, it is unlikely to be deleted as it serves a crucial role in maintaining the integrity of the e-commerce model."
survived,"    def forward(self, x): return torch.tanh(self.l(x))
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,Repr,1,8.592166611791576e-10,"The method 'forward' is a standard implementation in PyTorch models, where it defines the forward pass of the neural network. The use of 'torch.tanh' and 'self.l(x)' suggests that 'self.l' is likely a linear layer or some transformation applied to the input 'x'. This is a typical pattern in neural network implementations, and there is no indication that this method is deprecated or unnecessary. Therefore, it is likely to survive."
survived,"    def _parse(self, ep: str):
        if "":"" not in ep:
            raise ValueError(""Endpoint must be <backend>:<model>"")
        return ep.split("":"",1)
",alpha_factory_v1/demos/meta_agentic_agi/agents/agent_base.py,LMClient,1,1.0467401685178159e-08,"The method '_parse' is a utility function that checks if a string contains a colon and splits it into two parts. This is a common pattern for parsing configuration strings or identifiers in software systems. The method is simple, performs a specific task, and is likely used in a larger context where such parsing is necessary. Unless the entire system is being refactored or the method is replaced by a more comprehensive parsing utility, it is likely to survive."
survived,"    def _on(self, msg: dict):
        try:
            self.handle(msg)
        except Exception as exc:
            LOG.exception(""[%s] crash: %s"", self.name, exc)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,Agent,1,5.3157849718487075e-08,"The method '_on' is a private method (indicated by the underscore) that is designed to handle a message by calling another method 'handle'. It includes exception handling to log any exceptions that occur during the handling process. This is a common pattern in software development to ensure robustness and maintainability of the code. The method is likely to be part of a larger system where message handling is crucial, and the logging of exceptions is important for debugging and monitoring purposes. Therefore, it is unlikely to be deleted as it serves a functional purpose in the system."
survived,"async def send_cmd(cmd:Dict[str,str]):
    A2ABus.publish(""orch"",cmd); return {""ok"":True}
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,,1,6.348800075736417e-09,"The method 'send_cmd' is a simple asynchronous function that publishes a command to a bus and returns a success response. It is likely to be retained because it serves a clear purpose in a system that uses asynchronous communication. The function is concise, uses standard practices for async functions, and the use of a dictionary for commands is a common pattern. Unless there are changes in the system architecture or requirements that make this function obsolete, it is likely to survive."
survived,"    def log():
        if not path.exists():
            return ""(no events yet)""
        return flask.escape(path.read_text(""utf-8""))
",alpha_factory_v1/demos/meta_agentic_agi/agents/agent_base.py,,0,0.9999785550602307,"The method 'log' is a simple utility function that checks if a path exists and reads its content if it does. However, the function has a few issues that might lead to its deletion or significant modification:

1. **Undefined 'path'**: The variable 'path' is not defined within the function or passed as a parameter, which will lead to a NameError when the function is called.

2. **Lack of Parameters**: The function does not take any parameters, making it unclear what 'path' it is supposed to check. This limits its reusability and flexibility.

3. **Dependency on Flask**: The function uses 'flask.escape', which ties it to the Flask framework. If the function is intended to be a general utility, this dependency might be unnecessary or undesirable.

4. **Error Handling**: There is no error handling for cases where reading the file might fail (e.g., due to permission issues).

Due to these issues, especially the undefined 'path', the function is likely to be deleted or heavily refactored to address these problems."
survived,"    def acquire(self, cost: float = 1.0):
        while True:
            now = time.perf_counter()
            elapsed = now - self._last
            self._last = now
            self._allow = min(self._tps, self._allow + elapsed * self._tps)
            if self._allow >= cost:
                self._allow -= cost
                return
            sleep = (cost - self._allow) / self._tps + 1e-3
            time.sleep(sleep)
",alpha_factory_v1/demos/meta_agentic_agi_v2/agents/agent_base.py,RateLimiter,1,3.3982678079468468e-09,"The method 'acquire' is implementing a rate-limiting algorithm, which is a common and useful functionality in many applications to control the rate of operations, such as API requests. The method uses a token bucket-like approach to ensure that operations do not exceed a specified rate (transactions per second, tps). This is a well-established technique for managing load and preventing abuse of resources. Given its utility and the fact that it appears to be correctly implemented, it is likely to be retained in the codebase."
survived,"    def __init__(self, tps: float = 3.0):
        self._tps = float(tps)
        self._allow = self._tps
        self._last = time.perf_counter()
",alpha_factory_v1/demos/meta_agentic_agi/agents/agent_base.py,RateLimiter,1,1.8553915987649156e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with default or specified values. This particular constructor initializes three instance variables, which are likely crucial for the class's functionality. Therefore, it is unlikely to be deleted."
survived,"    def __init__(self, hidden: int, act_dim: int):
        super().__init__(); self.v = nn.Linear(hidden, 1); self.p = nn.Linear(hidden, act_dim)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,Pred,1,4.1399375473943306e-08,"The method is a constructor for a class, likely a neural network module, initializing two linear layers. This is a common and essential part of setting up a neural network model in PyTorch, which is widely used for defining the architecture of the model. Therefore, it is unlikely to be deleted as it is necessary for the functionality of the class."
survived,"    def handle(self, msg: dict):  # to be overridden
        raise NotImplementedError
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,Agent,1,7.889265051273362e-06,"The method `handle` is designed to be overridden in a subclass, as indicated by the comment and the use of `raise NotImplementedError`. This is a common pattern in object-oriented programming where a base class defines a method that must be implemented by any subclass. The presence of this method suggests that it is part of a framework or library where subclasses are expected to provide specific implementations for handling messages. Therefore, it is unlikely to be deleted as it serves a clear purpose in the design of the class hierarchy."
survived,"    def update(self, **kw):
        for k, v in kw.items():
            if hasattr(self, k):
                setattr(self, k, v)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,Config,1,1.8189616842444243e-09,"The method 'update' is a utility function that allows for dynamic updating of an object's attributes based on keyword arguments. This is a common and useful pattern in Python, especially for classes that need to be flexible and easily modifiable. The method checks if the object has the attribute before setting it, which prevents errors and ensures only existing attributes are updated. This kind of method is often used in data models or configurations, making it a valuable tool in many applications. Therefore, it is likely to be retained."
survived,"def test_csv_parser(tmp_path):
    csv_file = tmp_path / ""data.csv""
    csv_file.write_text(""a,b\n1,2\n3,4\n"", encoding=""utf-8"")
    parser = CsvParser(file_path=str(csv_file))
    result = parser.parse(file_path=str(csv_file))
    assert result[""title""] == ""csv""
    assert ""a"" in result[""content""]
    assert result[""lifecycle""][0][""life_metadata""][""source_file""] == str(csv_file)
",tests/test_csv_parser.py,,1,6.023574641292144e-08,"The method 'test_csv_parser' is a test function that is likely part of a test suite for a CSV parsing utility. It uses a temporary path to create a CSV file, then tests the parsing functionality of a 'CsvParser' class. The assertions check if the parsing result meets expected conditions. This method is crucial for ensuring the reliability and correctness of the CSV parsing functionality, which is a common requirement in many applications. Therefore, it is likely to be maintained as part of the test suite to ensure ongoing code quality and functionality verification."
survived,"def verify_commitment(
    activations_path: str, commitment: str, challenge: int = CHALLENGE
) -> bool:
    """"""Verify polynomial commitment against activations.""""""
    expected = commit_activations(activations_path, challenge)
    return expected == commitment.lower()
",src/zklora/polynomial_commit.py,,1,2.0611536181902033e-09,"The method 'verify_commitment' is a utility function that checks if a given commitment matches the expected commitment generated from a file path and a challenge number. This type of function is essential in cryptographic operations and data integrity checks, which are common in software dealing with security, blockchain, or data verification. Given its utility and the fact that it performs a specific, useful task, it is likely to be retained in the codebase."
survived,"def test_list_ids_with_tags(populated_db):
    command = ListIdsCommand(
        tags=[""programming""],
        limit=10,
        db_path=populated_db,
    )

    results = list_ids(command)

    assert len(results) == 4
    for expected in [""python-1"", ""sql-1"", ""testing-1"", ""regex-1""]:
        assert expected in results
",src/mcp_server_pocket_pick/tests/functionality/test_list_ids.py,,1,1.3440409770490404e-08,"The method 'test_list_ids_with_tags' is a unit test designed to verify the functionality of the 'list_ids' function when filtering by tags. It checks that the function returns the correct number of results and that the expected IDs are present in the results. This is a typical and necessary part of software development to ensure code reliability and correctness. Therefore, it is unlikely to be deleted as it serves an important purpose in maintaining the integrity of the codebase."
survived,"    def publish(self, topic: str, env: messaging.Envelope) -> None:
        self.published.append((topic, env))
",tests/test_codegen_safety.py,DummyBus,1,4.363462233903899e-09,"The method 'publish' is a simple utility function that appends a tuple of a topic and an envelope to a list called 'published'. This method is likely part of a larger system that deals with messaging or event handling. The method is straightforward, performs a clear function, and does not have any apparent issues or redundancies. It is likely to be useful in the context of tracking or logging published messages, which is a common requirement in messaging systems. Therefore, it is likely to be retained in the codebase."
survived,"        def recurrent(self, state, action):
            return None, 0.0, 0.0, None
",alpha_factory_v1/demos/muzero_planning/minimuzero.py,MiniMuNet,0,0.9999999530883621,"The method 'recurrent' is defined to take two parameters, 'state' and 'action', but it doesn't perform any operations or computations with these parameters. It simply returns a tuple with fixed values: None, 0.0, 0.0, and None. This suggests that the method is either a placeholder or not fully implemented. If this method is part of a larger class or system, it might be intended for future development or to be overridden by subclasses. However, in its current form, it doesn't provide any functionality or utility, which makes it a candidate for deletion unless there is a specific plan to implement it later. Therefore, the method is likely to be deleted."
survived,"    def value(self) -> float:
        return self.value_sum / self.visit_count if self.visit_count else 0.0
",alpha_factory_v1/demos/muzero_planning/minimuzero.py,Node,1,1.2501528648238603e-09,"The method 'value' is a simple utility function that calculates the average value by dividing 'value_sum' by 'visit_count'. It includes a safeguard to return 0.0 if 'visit_count' is zero, preventing division by zero errors. This method is likely to be useful in contexts where average calculations are needed, such as in statistical analysis or game AI. Its simplicity and utility suggest that it will be retained in the codebase."
survived,"def submit_job(path: str | Path, host: str = DEFAULT_HOST, port: int = DEFAULT_PORT) -> None:
    """"""Convenience wrapper to submit a job from a JSON file.""""""
    job = load_job(path)
    MarketplaceClient(host, port).queue_job(job)
",alpha_factory_v1/demos/alpha_agi_marketplace_v1/marketplace.py,,1,1.6052280526088547e-09,"The method 'submit_job' is a simple and clear utility function that wraps the process of loading a job from a JSON file and submitting it to a job queue. It uses type hints, default parameters, and a clear docstring, which are all good practices in modern Python code. The function is likely to be useful in various contexts where job submission is needed, and it abstracts away the details of interacting with the 'MarketplaceClient'. There is no indication of redundancy or obsolescence, so it is likely to be retained."
survived,"    def do_POST(self):
        length = int(self.headers.get(""Content-Length"", 0))
        type(self).received_body = self.rfile.read(length)
        type(self).received_path = self.path
        self.send_response(200)
        self.end_headers()
        self.wfile.write(b""ok"")
",alpha_factory_v1/tests/test_marketplace_client.py,_Handler,1,8.76424914819242e-08,"The method is a simple implementation of handling a POST request in a server. It reads the content length from the headers, reads the body of the request, and stores it in class variables. It then sends a 200 OK response back to the client. This is a basic and functional implementation for handling POST requests, which is a common requirement in web servers. Therefore, it is likely to be retained as it serves a fundamental purpose."
survived,"    def setUp(self):
        self.orc = DummyOrchestrator()
        # Force PingAgent to use the lightweight AgentBase implementation so we
        # can instantiate it without heavy dependencies.
        ping_agent.PingAgent.__bases__ = (NewAgentBase,)
        self.agent = ping_agent.PingAgent()
        self.agent.orchestrator = self.orc
",alpha_factory_v1/tests/test_ping_agent.py,PingAgentTest,1,6.348800075736417e-09,"The method `setUp` is a standard part of the unittest framework in Python, used to set up the test environment before each test method is run. It is unlikely to be deleted because it is essential for initializing the test conditions, such as creating instances of objects that will be used in the tests. The code within `setUp` is setting up a test environment by creating a `DummyOrchestrator` and modifying the base class of `PingAgent` to use a lightweight implementation, which suggests that this setup is necessary for the tests to run correctly. Therefore, the method is likely to survive."
survived,"    def test_ensure_dir(self):
        with tempfile.TemporaryDirectory() as tmp:
            path = Path(tmp) / 'd'
            preflight.ensure_dir(path)
            self.assertTrue(path.exists())
",alpha_factory_v1/tests/test_preflight.py,PreflightTest,1,2.998960815863541e-09,"The method 'test_ensure_dir' is a unit test designed to verify the functionality of the 'ensure_dir' method from the 'preflight' module. It uses a temporary directory to test if the 'ensure_dir' method correctly creates a directory at the specified path. The test is straightforward, uses standard testing practices, and is likely part of a test suite to ensure code reliability. There is no indication that this test is redundant or unnecessary, as it serves a clear purpose in verifying directory creation functionality. Therefore, it is likely to be retained."
survived,"    def test_build_env_removes_secrets(self):
        env = {
            'TOKEN': 'x',
            'my_secret': 'y',
            'PASSWORD': 'z',
            'KEY': 'k',
            'OTHER': 'ok',
        }
        with mock.patch.dict(os.environ, env, clear=True):
            cleaned = local_pytest._build_env()
            self.assertNotIn('TOKEN', cleaned)
            self.assertNotIn('my_secret', cleaned)
            self.assertNotIn('PASSWORD', cleaned)
            self.assertNotIn('KEY', cleaned)
            self.assertEqual(cleaned['OTHER'], 'ok')
",alpha_factory_v1/tests/test_local_pytest.py,LocalPytestUtilsTest,1,2.0611536181902033e-09,"The method 'test_build_env_removes_secrets' is a unit test designed to verify that the '_build_env' function correctly removes sensitive information from the environment variables. This is a crucial functionality for maintaining security and privacy, especially in environments where sensitive data like tokens, passwords, and keys are involved. Ensuring that these secrets are not inadvertently exposed is a common requirement in software development, particularly in testing and deployment processes. Therefore, this test method is likely to be retained to ensure the integrity and security of the environment handling code."
survived,"    def test_run_pytest_invokes_runner(self):
        fake = Path('.')
        with mock.patch('alpha_factory_v1.backend.tools.local_pytest.Path.exists', return_value=True):
            with mock.patch('alpha_factory_v1.backend.tools.local_pytest._run_pytest', return_value={'returncode':0,'passed':True,'duration_sec':0,'stdout':'','stderr':'','cmd':'py'}) as rp:
                out = local_pytest.run_pytest({}, path=str(fake))
        rp.assert_called_once()
        self.assertTrue(out['passed'])
        self.assertEqual(out['returncode'], 0)
",alpha_factory_v1/tests/test_local_pytest.py,LocalPytestUtilsTest,1,2.1724399346070676e-10,"The method `test_run_pytest_invokes_runner` is a unit test that verifies the behavior of the `run_pytest` function. It uses mocking to simulate the environment and checks if the function behaves as expected. This is a common practice in software testing to ensure code reliability and correctness. Since testing is a crucial part of software development, especially for maintaining code quality, this method is likely to be retained. Therefore, it will survive."
survived,"            def fake_distribution(name):
                self.assertEqual(name, ""requests"")
                return Dist()
",alpha_factory_v1/tests/test_requests_import.py,RequestsImportTest,1,6.348800075736417e-09,"The method `fake_distribution` is a simple utility function that seems to be used for testing purposes, as indicated by the use of `self.assertEqual`. It checks if the input `name` is equal to the string ""requests"" and returns an instance of `Dist`. Such methods are typically used in unit tests to mock or simulate certain behaviors. Since testing is a crucial part of software development, especially for ensuring code quality and reliability, this method is likely to be retained as part of the test suite. Therefore, it is predicted to survive."
survived,"    def setUp(self):
        for key in (""OPENAI_API_KEY"", ""ANTHROPIC_API_KEY"", ""LOCAL_LLM_BASE""):
            os.environ.pop(key, None)
",alpha_factory_v1/tests/test_memory_provider.py,ModelProviderStubTest,1,1.3440409770490404e-08,The method `setUp` is used to clear specific environment variables before running tests. This is a common practice in testing to ensure that tests run in a clean environment without any leftover state from previous tests. The method is likely to be retained because it serves a useful purpose in maintaining test isolation and reliability.
survived,"    def test_stub_backend(self):
        provider = ModelProvider()
        self.assertEqual(provider.backend[0], ""stub"")
        out = provider.complete(""hello"")
        self.assertIsInstance(out, str)
        self.assertTrue(out)
",alpha_factory_v1/tests/test_memory_provider.py,ModelProviderStubTest,1,8.76424914819242e-08,"The method 'test_stub_backend' is a unit test designed to verify the behavior of a 'ModelProvider' class. It checks if the backend is set to 'stub' and if the 'complete' method returns a non-empty string. This is a typical test case that ensures the functionality of the 'ModelProvider' class, especially in a development or testing environment where a 'stub' backend might be used for testing purposes. Such test methods are generally retained as they are crucial for maintaining code quality and ensuring that changes do not break existing functionality."
survived,"    def test_falls_back_to_unittest(self):
        with mock.patch('importlib.util.find_spec', return_value=None):
            with mock.patch('subprocess.call', return_value=0) as call:
                argv = sys.argv
                sys.argv = ['run_tests.py', 'tests']
                try:
                    with self.assertRaises(SystemExit):
                        run_tests.main()
                finally:
                    sys.argv = argv
                call.assert_called_once()
                cmd = call.call_args.args[0]
                self.assertIn('unittest', cmd)
                self.assertIn('tests', cmd[-1])
",alpha_factory_v1/tests/test_run_tests_script.py,RunTestsScriptTest,1,2.8453347280241004e-08,"The method 'test_falls_back_to_unittest' is a unit test that verifies the behavior of a function when a certain condition is met (in this case, when 'importlib.util.find_spec' returns None). It uses mocking to simulate this condition and checks that the 'subprocess.call' is made with the expected arguments. This is a typical pattern in unit testing to ensure that code falls back to a default behavior when a certain feature is unavailable. Such tests are crucial for maintaining code reliability and ensuring that fallback mechanisms work as intended. Therefore, this method is likely to be retained as part of the test suite."
survived,"def test_evaluate_flow(monkeypatch, tmp_path):
    fake_rc = MagicMock()
    collection = CollectionResult(exit_code=0, stdout='out', stderr='err', duration=1.0)
    fake_rc.execute_and_collect.return_value = collection
    fake_reporter = MagicMock()
    fake_reporter.generate_report.return_value = 'REPORT'

    harness = EvaluationHarness(fake_rc, fake_reporter)
    result = harness.evaluate(tmp_path, timeout=5, output_format='json')

    assert result == 'REPORT'
    fake_rc.execute_and_collect.assert_called_with(tmp_path, timeout=5)
    fake_reporter.generate_report.assert_called_with(collection, output_format='json')
",tests/unit/test_evaluation_harness.py,,1,1.1032560311263802e-09,"The method 'test_evaluate_flow' is a unit test function that uses mocking to test the 'evaluate' method of the 'EvaluationHarness' class. It verifies that the method returns the expected report and that the mocked methods are called with the correct arguments. This is a typical and useful test pattern in software development to ensure code reliability and correctness. There is no indication that this test is redundant or incorrect, so it is likely to be retained."
survived,"    def test_missing_version_fails(self) -> None:
        for name in (""openai_agents"", ""agents""):
            with self.subTest(module=name):
                self.assertFalse(self._run_check(name, None))
",tests/test_preflight_openai_agents_version.py,TestPreflightOpenAIAgentsVersion,1,4.944450477491054e-09,"The method 'test_missing_version_fails' is a unit test that checks if a certain condition fails when a version is missing. It uses a subTest to iterate over two module names and asserts that the '_run_check' method returns False when called with these names and a None version. This is a valid and useful test case to ensure that the system behaves correctly when a version is not provided. Therefore, it is likely to be retained in the codebase."
survived,"def test_run_macro_demo_help() -> None:
    """"""`run_macro_demo.sh --help` should exit successfully.""""""
    subprocess.run([str(RUN_SCRIPT), ""--help""], check=True, capture_output=True)",tests/test_macro_compose_config.py,,1,7.73442280641062e-08,"The method `test_run_macro_demo_help` is a simple test function that checks if a script can be run with the `--help` flag without errors. This is a common and useful test to ensure that the help command of a script is functioning correctly. It uses `subprocess.run` with `check=True` to ensure that an exception is raised if the command fails, which is a standard practice in testing. The method is straightforward, serves a clear purpose, and is likely part of a larger suite of tests. Therefore, it is unlikely to be deleted as it provides value in verifying the script's functionality."
survived,"    def test_stub_when_sdk_missing(self) -> None:
        os.environ.pop(""OPENAI_API_KEY"", None)
        sys.modules.pop(""agents"", None)
        sys.modules.pop(""alpha_factory_v1.backend.agent_factory"", None)
        importlib.invalidate_caches()

        orig_import_module = importlib.import_module

        def _fake_import(name: str, *args: object, **kwargs: object) -> object:
            if name == ""agents"":
                raise ModuleNotFoundError
            return orig_import_module(name, *args, **kwargs)

        with mock.patch(""importlib.import_module"", side_effect=_fake_import):
            af = orig_import_module(""alpha_factory_v1.backend.agent_factory"")
            af = importlib.reload(af)
            agent = af.build_core_agent(name=""t"", instructions=""demo"")

        self.assertTrue(hasattr(agent, ""run""))
        self.assertEqual(agent.run(""hi""), ""[t-stub] echo: hi"")
        self.assertFalse(any(isinstance(t, af.ComputerTool) for t in af.DEFAULT_TOOLS))
",tests/test_build_core_agent.py,TestBuildCoreAgent,1,1.4166087846364157e-09,"The method 'test_stub_when_sdk_missing' is a unit test designed to verify the behavior of a system when certain modules are missing. It uses mocking to simulate the absence of the 'agents' module and checks if the system can still function correctly by using a stub. This kind of test is crucial for ensuring robustness and handling of missing dependencies gracefully. Therefore, it is likely to be retained as it serves an important purpose in the testing suite."
survived,"def example5(b1, b2):
    if b1:
        None
    else:
        if b2:
            None
        else:
            None",tests/rosetta/transpiler/Python/conditional-structures-5.py,,0,0.9999999979388463,"The method 'example5' is likely to be deleted because it does not perform any meaningful operations or return any value. It only contains conditional statements that lead to 'None', which is effectively a no-operation. Such methods are typically removed during code cleanup as they do not contribute to the functionality of the program."
survived,"def newLife(w, h):
    a = newField(w, h)
    i = 0
    while i < (w * h // 2):
        setCell(a, randN(w), randN(h), True)
        i = i + 1
    return Life(a=a, b=newField(w, h), w=w, h=h)
",tests/rosetta/transpiler/Python/conways-game-of-life.py,,1,4.363462233903899e-09,"The method 'newLife' is a utility function that initializes a new game of Life, a popular cellular automaton. It creates a new field with given width and height, randomly sets half of the cells to be alive, and returns a Life object with the initialized fields. This method is likely to be useful in contexts where the Game of Life is being implemented or simulated, as it provides a straightforward way to set up the initial state of the game. Therefore, it is likely to be retained in the codebase."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/constrained-random-points-on-a-circle-1.py,,1,6.348800075736417e-09,"The method '_now' is a utility function that generates a pseudo-random number based on a global seed if '_now_seeded' is True, otherwise it returns the current time in nanoseconds. This method is likely to be used in scenarios where deterministic pseudo-random numbers are needed for testing or simulation purposes. The use of a global seed allows for repeatability, which is a common requirement in testing environments. The method is simple, serves a clear purpose, and does not have any apparent issues or redundancies that would necessitate its deletion. Therefore, it is likely to be retained in the codebase."
survived,"def newField(w, h):
    rows = []
    y = 0
    while y < h:
        row = []
        x = 0
        while x < w:
            row = row + [False]
            x = x + 1
        rows = rows + [row]
        y = y + 1
    return Field(s=rows, w=w, h=h)
",tests/rosetta/transpiler/Python/conways-game-of-life.py,,1,9.237449576640118e-09,"The method 'newField' is a utility function that creates a 2D list (a grid) of specified width 'w' and height 'h', filled with 'False' values. This is a common pattern used in initializing game boards, matrices, or any grid-like data structures. The method is straightforward, performs its task efficiently, and is likely to be useful in contexts where such a grid is needed. There are no apparent issues or inefficiencies that would necessitate its deletion. Therefore, it is likely to be retained in the codebase."
survived,"def gcd(a, b):
    x = a
    if x < 0:
        x = -x
    y = b
    if y < 0:
        y = -y
    while y != 0:
        t = x % y
        x = y
        y = t
    return x
",tests/rosetta/transpiler/Python/convert-decimal-number-to-rational.py,,1,2.998960815863541e-09,"The method implements the Euclidean algorithm to compute the greatest common divisor (GCD) of two numbers, which is a fundamental and widely used algorithm in mathematics and computer science. The code correctly handles negative inputs by taking their absolute values, ensuring the GCD is computed accurately. The logic is sound and the implementation is efficient, making it a useful utility function. Therefore, it is likely to be retained in the codebase."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/concurrent-computing-3.py,,1,6.023574641292144e-08,"The method _now() is a utility function that generates a pseudo-random number based on a seed if _now_seeded is True, otherwise it returns the current time in nanoseconds. This function is likely part of a larger system that requires either a deterministic sequence of numbers (when seeded) or a timestamp. Such utility functions are common in systems that need to simulate time or generate predictable sequences for testing purposes. Since it serves a specific purpose and is not inherently flawed, it is likely to be retained in the codebase."
survived,"def cfPi(nTerms):
    f = []
    n = 0
    while n < nTerms:
        g = 2 * n - 1
        f = f + [newTerm(6, g * g)]
        n = n + 1
    if nTerms > 0:
        f[0][""a""] = 3
    return f
",tests/rosetta/transpiler/Python/continued-fraction.py,,0,0.9999999907625504,"The method cfPi is likely to be deleted because it contains several issues that make it non-functional and inefficient. Firstly, the function newTerm is called but not defined anywhere in the code, which will result in a NameError when the function is executed. Secondly, the logic for calculating terms of Pi is not clear or correct, as it seems to be attempting to generate a continued fraction representation without a proper algorithm. Additionally, the use of lists and dictionary-like structures without clear purpose or explanation makes the code difficult to understand and maintain. These factors suggest that the method is not useful in its current form and is likely to be removed or significantly refactored."
survived,"def cfSqrt2(nTerms):
    f = []
    n = 0
    while n < nTerms:
        f = f + [newTerm(2, 1)]
        n = n + 1
    if nTerms > 0:
        f[0][""a""] = 1
    return f
",tests/rosetta/transpiler/Python/continued-fraction.py,,0,0.9999999530883621,"The method cfSqrt2 is likely to be deleted because it contains a reference to a function newTerm that is not defined within the code snippet or provided as an import. This makes the function incomplete and non-functional in its current state. Additionally, the method's purpose is unclear without further context or documentation, which reduces its utility and increases the likelihood of it being removed in favor of a more complete and functional implementation."
survived,"def newTerm(a, b):
    return {""a"": a, ""b"": b}
",tests/rosetta/transpiler/Python/continued-fraction.py,,1,1.0467401685178159e-08,"The method 'newTerm' is a simple utility function that creates and returns a dictionary with keys 'a' and 'b' mapped to the provided arguments. Such utility functions are often useful in various contexts where structured data is needed, and they are generally not removed unless they are redundant or replaced by a more efficient implementation. Since the function is straightforward and serves a clear purpose, it is likely to be retained in the codebase."
survived,"def example3(a, b):
    if a:
        None
    else:
        if b:
            None",tests/rosetta/transpiler/Python/conditional-structures-3.py,,0,0.9999999981810384,"The method 'example3' is likely to be deleted because it does not perform any meaningful operations. It contains conditional statements that lead to 'None', which means it has no functional output or side effects. Such methods are typically removed during code cleanup or refactoring as they do not contribute to the program's functionality."
survived,"    def __str__(self) -> str:
        lines = [f""# Data Model: {self.title}""]
        if self.description:
            lines.append(self.description)
        lines.append("""")
        if self.entities:
            lines.append(""## Entities"")
            for e in sorted(self.entities, key=lambda ent: ent.name):
                lines.append(f""- [{e.name}](#{e.name.lower()})"")
            lines.append("""")
            for e in sorted(self.entities, key=lambda ent: ent.name):
                lines.append(str(e))
        else:
            lines.append(""*No entities registered*"")
        return ""\n"".join(lines)
",src/enrichmcp/datamodel.py,ModelDescription,1,4.944450477491054e-09,"The method `__str__` is a common and useful method in Python classes, especially for classes that represent data models or entities. It provides a human-readable string representation of the object, which is helpful for debugging, logging, and displaying information to users. The implementation here is well-structured, providing a formatted output of the data model's title, description, and entities. This kind of method is typically retained in codebases because it enhances the usability and readability of the class instances."
survived,"def test_evonet_activation_applied_once() -> None:
    g = me.Genome(layers=(3,), activation=""sigmoid"")
    net = me.EvoNet(2, 1, g)
    x = torch.randn(1, 2)
    out = net(x)

    h = x
    for layer in net.model:
        h = me._ACT[g.activation](layer(h))

    assert torch.allclose(out, h)
",tests/test_evo_net_activation.py,,1,7.582560422162384e-10,"The method `test_evonet_activation_applied_once` is a unit test designed to verify that the activation function is applied correctly within the `EvoNet` model. Unit tests are crucial for ensuring code reliability and correctness, especially in complex systems like neural networks. This test checks if the output of the network matches the expected output when the activation function is applied manually. Such tests are typically retained to maintain code quality and prevent regressions. Therefore, it is likely to be Survived."
survived,"def check_network(host: str = ""pypi.org"", timeout: float = 2.0) -> bool:
    """"""Return True if *host* can be resolved within *timeout* seconds.""""""
    try:
        with suppress(Exception):
            prev = socket.getdefaulttimeout()
        socket.setdefaulttimeout(timeout)
        socket.gethostbyname(host)
    except Exception:
        banner(
            f""WARNING: Unable to resolve {host}. Use --wheelhouse for offline installs."",
            ""YELLOW"",
        )
        return False
    finally:
        with suppress(Exception):
            socket.setdefaulttimeout(prev)
    banner(f""{host} resolved"", ""GREEN"")
    return True
",alpha_factory_v1/scripts/preflight.py,,1,5.60279640614594e-09,"The method `check_network` is a utility function that checks if a network host can be resolved within a specified timeout. It is a useful function for network diagnostics and ensuring connectivity, especially in scenarios where network access is required, such as package installations. The function handles exceptions gracefully and provides user feedback through banners, which is beneficial for debugging and user experience. Given its utility and the fact that it doesn't have any apparent issues or redundancies, it is likely to be retained in the codebase."
survived,"def test_planning_agent_no_openai_sdk() -> None:
    """"""Agent should run even when openai.agents is missing.""""""
    from alpha_factory_v1.demos.alpha_agi_insight_v1.src.utils import config, messaging
    from alpha_factory_v1.demos.alpha_agi_insight_v1.src.agents import planning_agent

    class DummyLedger:
        def __init__(self, *_a, **_kw) -> None:
            pass

        def log(self, _env) -> None:  # type: ignore[override]
            pass

        def start_merkle_task(self, *_a, **_kw) -> None:
            pass

        async def stop_merkle_task(self) -> None:
            pass

        def close(self) -> None:
            pass

    settings = config.Settings(bus_port=0, openai_api_key=""k"")
    bus = messaging.A2ABus(settings)
    agent = planning_agent.PlanningAgent(bus, DummyLedger())

    assert agent.oai_ctx is None
    asyncio.run(agent.run_cycle())",tests/test_agents.py,,1,1.0467401685178159e-08,"The method `test_planning_agent_no_openai_sdk` is a test function designed to ensure that the `planning_agent` can operate without the `openai.agents` module. This is a useful test to verify the robustness and independence of the `planning_agent` from external dependencies. Test functions are generally retained as they are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, this method is likely to be retained."
survived,"    async def aspan(self, agent_name: str, phase: str, **payload: Any) -> Generator[None, None, None]:
        """"""Async variant of :meth:`span`.""""""
        start = _dt.datetime.utcnow()
        try:
            yield
        finally:
            duration = (_dt.datetime.utcnow() - start).total_seconds() * 1000
            payload[""duration_ms""] = round(duration, 3)
            await self.arecord(agent_name, phase, payload)
",alpha_factory_v1/backend/tracer.py,Tracer,1,1.493094675974231e-10,"The method 'aspan' is an asynchronous generator function that is a variant of a method called 'span'. It is designed to measure the duration of a code block and then record this duration using an asynchronous method 'arecord'. This kind of functionality is useful for performance monitoring and logging in asynchronous applications, which are common in modern software development. The method is well-structured, uses standard practices for asynchronous programming, and provides a clear utility. Therefore, it is likely to be retained in the codebase."
survived,"    def __init__(self, *a, **k):
        pass
",tests/test_selfheal_entrypoint_offline.py,DummyBlocks,0,0.9999724643101549,"The method is an initializer (__init__) that takes any number of positional and keyword arguments but does nothing with them. This is typically a placeholder or a default implementation that might be intended for future expansion or to satisfy an interface requirement. However, as it currently stands, it doesn't serve any functional purpose. If the class using this initializer doesn't require any specific initialization logic, this method might be considered redundant and could be deleted. However, if it's part of a larger framework or pattern where such a method is expected, it might survive as a placeholder. Without additional context, it's more likely to be deleted due to its lack of functionality."
survived,"    def __init__(self, *a, **k):
        pass
",tests/test_selfheal_entrypoint_offline.py,DummyMarkdown,0,0.9999945777825671,"The method is a constructor that takes any number of positional and keyword arguments but does nothing with them. This is often used as a placeholder or a base class constructor that is meant to be overridden by subclasses. If this is part of a larger framework or library where subclasses are expected to implement specific behavior, it might survive. However, if this is standalone or not serving any purpose, it might be deleted. Without additional context, it's more likely to be deleted as it currently serves no functional purpose."
survived,"    def launch(self, *a, **k):
        pass
",tests/test_selfheal_entrypoint_offline.py,DummyBlocks,0,0.9991959139981964,"The method 'launch' is defined but not implemented, as it only contains a 'pass' statement. This suggests that it is a placeholder for future code. If the method is part of a larger codebase where it is expected to be implemented later, it might survive. However, if it remains unimplemented and unused, it is likely to be deleted in future refactoring to clean up the codebase."
survived,"def test_build_vocab():
    corpus = [
        [""first"", ""document"", ""hello"", ""world""],
        [""second"", ""document"", ""world"", ""big"", ""bright""],
    ]

    vocab, index = run_hlda.build_vocab(corpus)
    expected_vocab = [""big"", ""bright"", ""document"", ""first"", ""hello"", ""second"", ""world""]
    expected_index = {w: i for i, w in enumerate(expected_vocab)}
    assert vocab == expected_vocab
    assert index == expected_index
",tests/test_run_hlda_utils.py,,1,1.522997951276035e-08,"The method `test_build_vocab` is a unit test designed to verify the functionality of the `build_vocab` method from the `run_hlda` module. Unit tests are crucial for ensuring code reliability and correctness, especially in larger projects. This test checks if the vocabulary and index generated by `build_vocab` match the expected results. Since testing is a fundamental part of software development and maintenance, this method is likely to be retained to ensure the `build_vocab` function works as intended."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/user_type_literal.py,Book,0,0.9999869928752253,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/user_type_literal.py,Person,0,0.9999756997690634,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical or expected behavior for `__contains__`, which is usually used for membership testing in collections like lists, sets, or dictionaries. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard use of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership testing."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/left_join.py,Order,0,0.9999952149051502,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not fulfill its intended purpose of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/inner_join.py,Customer,0,0.9999546021442518,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical or expected behavior for `__contains__`, which is usually used for membership testing in collections like lists, sets, or dictionaries. This misuse of the method could lead to confusion and incorrect behavior when the object is used in contexts expecting standard membership testing. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/group_by_conditional_sum.py,Item,0,0.9999910602998366,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/cross_join.py,Customer,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the implementation here uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/group_by_left_join.py,Auto1,0,0.9999930377415741,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/group_by_sort.py,Auto1,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of an item in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement the intended functionality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/group_by_multi_join.py,Auto1,1,1.892514738127224e-05,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually meant for checking membership in a collection like a list, set, or dictionary. However, if the class is designed to treat its attributes as keys in a collection-like manner, this implementation could be valid. Without additional context, it's difficult to determine if this is a misuse or a valid use case. Given the flexibility of Python and the potential for unconventional but valid use cases, this method is likely to survive unless there is a clear indication that it causes issues or is misused."
survived,"        def set_draw_color(self, *args, **kwargs):
            pass
",tests/conftest.py,DummyFPDF,0,0.9999997897565932,"The method `set_draw_color` is defined but not implemented, as it only contains a `pass` statement. This suggests that the method is either a placeholder for future implementation or is intentionally left empty because it is not needed. Without any additional context or usage, it is likely to be considered dead code. If it remains unused and unimplemented, it is likely to be deleted in future code clean-ups."
survived,"        def add_font(self, *args, **kwargs):
            pass
",tests/conftest.py,DummyFPDF,0,0.9999994956527948,"The method `add_font` is defined but not implemented, as it only contains a `pass` statement. This suggests that the method is either a placeholder for future implementation or it is not needed at all. If it remains unimplemented and unused, it is likely to be deleted in future code clean-ups to maintain code quality and remove dead code."
survived,"        def add_page(self):
            pass
",tests/conftest.py,DummyFPDF,0,0.9999991684720096,"The method `add_page` is currently a placeholder with no implementation (indicated by the `pass` statement). If this method is part of a larger class that is actively being developed, it might be intended for future implementation, suggesting it could survive. However, if there is no plan to implement this method or if it has been left unimplemented for a long time, it might be deleted in future refactoring to clean up the code. Without additional context, it's more likely to be deleted if it remains unimplemented."
survived,"    def Histogram(name: str, desc: str, labels=None):  # type: ignore[misc]
        return _get_metric(_Histogram, name, desc, labels)
",alpha_factory_v1/backend/agents/__init__.py,,1,1.6052280526088547e-09,"The method 'Histogram' is a simple wrapper around the '_get_metric' function, which suggests it is part of a larger system for handling metrics. The use of 'type: ignore[misc]' indicates that the developers are aware of potential type issues but have chosen to suppress them, likely because the function is working as intended within its context. This suggests that the method is functional and serves a purpose in the codebase. Unless there is a significant refactor or change in the system's architecture, such utility functions are typically retained. Therefore, it is likely to survive."
survived,"def test_governance_bridge_port_arg() -> None:
    """"""Verify the CLI accepts the --port option.""""""
    result = subprocess.run(
        [""governance-bridge"", ""--port"", ""1234"", ""--help""],
        capture_output=True,
        text=True,
        check=True,
    )
    assert result.returncode == 0",tests/test_governance_bridge_cli.py,,1,1.1032560311263802e-09,"The method 'test_governance_bridge_port_arg' is a test function that verifies if a command-line interface (CLI) accepts a specific option ('--port'). It uses subprocess to run the command and checks if it executes successfully by asserting the return code. This is a typical pattern for testing CLI tools, ensuring that the tool behaves as expected when given certain inputs. Such test functions are crucial for maintaining software quality and are unlikely to be deleted unless the functionality they test is removed or significantly changed. Therefore, the method is likely to survive."
survived,"    def visit_FunctionDef(self, node: ast.FunctionDef) -> None:
        if node.name == ""main"":
            for stmt in node.body:
                if isinstance(stmt, ast.Global):
                    continue
                self.visit(stmt)
            return
        if node.name.startswith(""test_""):
            name = node.name[5:]
            self.emit(f'test ""{name}"" {{')
            self.indent += 1
            for stmt in node.body:
                if isinstance(stmt, ast.Global):
                    continue
                self.visit(stmt)
            self.indent -= 1
            self.emit(""}"")
            return
        args = [
            f""{arg.arg}: {self.convert_type(arg.annotation)}"" for arg in node.args.args
        ]
        ret = self.convert_type(node.returns)
        self.emit(f""fun {node.name}({', '.join(args)}): {ret} {{"")
        call_info = self.parse_callable(node.returns)
        prev = self.current_callable
        if call_info:
            self.current_callable = call_info
        self.indent += 1
        for stmt in node.body:
            if isinstance(stmt, ast.Global):
                continue
            self.visit(stmt)
        self.indent -= 1
        self.emit(""}"")
        self.current_callable = prev
",tools/any2mochi/py/py2mochi.py,Converter,1,2.5109990926928157e-08,"The method 'visit_FunctionDef' is a core part of a visitor pattern implementation for traversing and processing AST nodes, specifically function definitions. It handles different types of functions, such as 'main', test functions, and others, by emitting code or processing statements accordingly. This functionality is essential for any tool or application that needs to analyze or transform Python code, such as a linter, code formatter, or transpiler. Therefore, it is unlikely to be deleted as it provides necessary functionality for these processes."
deleted,"def clear_tool_stats() -> None:
    with _lock:
        _tool_stats.clear()",src/serena/analytics.py,,1,1.4166087846364157e-09,"The method 'clear_tool_stats' is a simple utility function that clears a shared resource, '_tool_stats', while ensuring thread safety with a lock. Such utility functions are often necessary in multi-threaded applications to manage shared state. The method is straightforward, performs a clear and necessary function, and does not have any apparent issues or redundancies. Therefore, it is likely to be retained in the codebase."
survived,"def test_sqlalchemy_type_to_python_extra_types():
    assert _sqlalchemy_type_to_python(JSON()) is dict
    assert _sqlalchemy_type_to_python(LargeBinary()) is bytes
    assert _sqlalchemy_type_to_python(Time()) is time

    class MyInt(Integer):
        pass

    assert _sqlalchemy_type_to_python(MyInt()) is int

    class Custom(TypeEngine):
        pass

    assert _sqlalchemy_type_to_python(Custom()) is Any",tests/test_sqlalchemy_utils.py,,1,6.348800075736417e-09,"The method `test_sqlalchemy_type_to_python_extra_types` is a unit test function that verifies the behavior of the `_sqlalchemy_type_to_python` function. It checks if the function correctly maps SQLAlchemy types to their corresponding Python types. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with type conversions, which can be error-prone. Since this function serves a clear purpose in testing and validating the functionality of another function, it is likely to be retained in the codebase."
survived,"    def Button(self, *a, **k):
        return DummyButton()
",tests/test_agent_experience_entrypoint.py,DummyBlocks,1,4.006369513448866e-05,"The method 'Button' is a simple wrapper that returns an instance of 'DummyButton'. Without additional context, it's hard to determine its utility. However, if 'DummyButton' is a placeholder or mock object used for testing or as a temporary implementation, the method might be retained for testing purposes or until a more complete implementation is provided. If 'DummyButton' is not used elsewhere or the method is not called, it might be deleted. Given the lack of context, it's more likely to be retained for now."
survived,"        def __call__(self, *_a, **_k):
            return ""ok""
",tests/test_selfheal_env.py,FakeAgent,1,5.3157849718487075e-08,"The method is a simple implementation of the __call__ method, which allows an instance of the class to be called as a function. It returns a static string ""ok"" regardless of the input arguments. This method is functional and could be useful in scenarios where a consistent response is needed when an object is called. There is no indication of redundancy or lack of utility, so it is likely to be retained."
survived,"    def __init__(self, *a, **k):
        pass
",tests/test_selfheal_env.py,DummyButton,0,0.999915188952306,"The method is a constructor that takes any number of positional and keyword arguments but does nothing with them. This is often used as a placeholder or a base class constructor that is meant to be overridden by subclasses. However, if this is the final implementation and no subclass is overriding it, it serves no functional purpose. Without additional context, it's likely to be considered unnecessary and could be deleted unless it's part of a larger framework where such a pattern is common."
survived,"    def __enter__(self):
        return self
",tests/test_selfheal_env.py,DummyBlocks,1,6.023574641292144e-08,"The method is a part of the context management protocol in Python, specifically the implementation of the `__enter__` method. This method is essential for objects that are intended to be used with the `with` statement, allowing for resource management and ensuring that setup and teardown code is executed properly. Since this is a fundamental part of Python's context management, it is unlikely to be deleted."
survived,"    def test_ingest_and_step_concurrent(self) -> None:
        async def run_tasks() -> None:
            queue: asyncio.Queue[dict[str, Any]] = asyncio.Queue()

            async def ingest_loop() -> None:
                async for evt in demo.experience_stream():
                    await queue.put(evt)
                    break

            async def step_once() -> None:
                evt = await queue.get()
                self.assertIsInstance(evt, dict)

            await asyncio.gather(ingest_loop(), step_once())

        try:
            asyncio.run(run_tasks())
        except RuntimeError as exc:  # pragma: no cover - fail if raised
            self.fail(f""RuntimeError raised: {exc}"")
",tests/test_era_experience.py,TestEraOfExperience,1,1.0467401685178159e-08,"The method `test_ingest_and_step_concurrent` is a test function designed to verify the concurrent execution of two asynchronous tasks: `ingest_loop` and `step_once`. It uses `asyncio` to manage asynchronous operations and includes error handling to catch and report `RuntimeError`. The method is likely part of a test suite for an asynchronous system, and such test functions are crucial for ensuring the reliability and correctness of concurrent operations. Therefore, it is unlikely to be deleted as it serves an important role in testing the functionality of the system."
survived,"def _allow_local_code() -> bool:
    """"""Check both new and legacy opts for enabling local PythonTool.""""""
    return (
        os.getenv(ALLOW_LOCAL_CODE_ENV)
        or os.getenv(LEGACY_ALLOW_LOCAL_CODE_ENV)
    ) == ""1""
",alpha_factory_v1/backend/agent_factory.py,,1,5.3157849718487075e-08,"The method `_allow_local_code` is a utility function that checks environment variables to determine if local code execution is allowed. This is a common pattern in software development for enabling or disabling features based on environment settings. The method is simple, clear, and serves a specific purpose. It is unlikely to be deleted unless the feature it supports is deprecated or the environment variables are no longer used. Given that it checks both new and legacy options, it shows adaptability to changes, which further supports its survival."
survived,"def init_config(env_file: str = "".env"") -> None:
    """"""Load environment variables and refresh :data:`CFG`.""""""

    _load_dotenv(env_file)
    _prefetch_vault()
    global CFG
    CFG = Settings()
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/config.py,,1,4.363462233903899e-09,"The method 'init_config' is a utility function designed to load environment variables and refresh a global configuration object. This is a common and essential task in many applications, especially those that rely on environment-specific settings. The method is straightforward, performs a necessary function, and does not have any apparent issues or redundancies that would warrant its removal. Therefore, it is likely to be retained in the codebase."
survived,"    def my_op():
        call = call_context.get_current_call()
        call.summary[""foo""] = 1
        call.summary[""bar""] = 2
        return ""done""
",tests/trace/test_current_call.py,,1,3.3982678079468468e-09,"The method 'my_op' is a simple function that retrieves the current call context and updates its summary with two key-value pairs. It then returns a string 'done'. The method is straightforward and does not contain any deprecated or harmful operations. It appears to be a utility function that could be useful in various contexts where call summaries need to be updated. Without any indication of it being obsolete or replaced by a more efficient method, it is likely to survive."
survived,"    def __init__(self, num_levels, vocab, parent=None, level=0,
                 random_state=None):

        self.node_id = NCRPNode.last_node_id
        NCRPNode.last_node_id += 1

        self.customers = 0
        self.parent = parent
        self.children = []
        self.level = level
        self.total_words = 0
        self.num_levels = num_levels

        self.vocab = np.array(vocab)
        self.word_counts = np.zeros(len(vocab))

        if random_state is None:
            self.random_state = RandomState()
        else:
            self.random_state = random_state
",src/hlda/sampler.py,NCRPNode,1,7.194132978569833e-09,"The method is a constructor (__init__) for a class, which is a fundamental part of object-oriented programming in Python. Constructors are essential for initializing new objects with specific attributes and are unlikely to be removed unless the class itself is being deprecated or refactored significantly. Additionally, the method appears to be well-structured and serves a clear purpose in setting up the initial state of an object, which further supports its necessity and survival."
survived,"def load_documents(data_dir: str):
    """"""Load and preprocess all text files under *data_dir*.""""""
    corpus = []
    for filename in sorted(glob.glob(os.path.join(data_dir, ""*.txt""))):
        with open(filename, ""r"", encoding=""utf-8"", errors=""ignore"") as f:
            text = f.read().lower()
        tokens = [t for t in TOKEN_RE.findall(text) if t not in STOPWORDS]
        corpus.append(tokens)
    return corpus
",scripts/run_hlda.py,,1,8.592166611791576e-10,"The method 'load_documents' is a utility function that loads and preprocesses text files from a specified directory. It reads each file, converts the text to lowercase, tokenizes it, and removes stopwords. This is a common and useful operation in text processing and natural language processing tasks. The method is well-defined, performs a specific task, and is likely to be used in various applications that involve text data processing. Therefore, it is likely to be retained in the codebase."
survived,"def test_cross_industry_script_idempotent(tmp_path: Path) -> None:
    result = _run_script(tmp_path)
    first_services = result[""first""].get(""services"", {})
    second_services = result[""second""].get(""services"", {})
    assert first_services == second_services
    assert len(second_services) == len(set(second_services))",tests/test_cross_industry_patch.py,,1,2.5109990926928157e-08,"The method `test_cross_industry_script_idempotent` is a test function that checks the idempotency of a script by comparing the services obtained from two runs. It uses assertions to ensure that the services are the same in both runs and that there are no duplicate services in the second run. This is a typical pattern for testing idempotency, which is an important property in many systems to ensure consistent results. Test functions like this are crucial for maintaining software quality and are unlikely to be deleted unless the functionality they test is removed or significantly changed."
survived,"    def test_infer_fastmcp_server(self, fastmcp_server):
        """"""FastMCP server instances should infer to FastMCPTransport.""""""
        transport = infer_transport(fastmcp_server)
        assert isinstance(transport, FastMCPTransport)
",tests/client/test_client.py,TestInferTransport,1,4.944450477491054e-09,"The method `test_infer_fastmcp_server` is a unit test that verifies the functionality of the `infer_transport` function. It checks if the `infer_transport` function correctly infers a `FastMCPTransport` instance from a `fastmcp_server` input. Unit tests are crucial for ensuring code reliability and correctness, especially in larger codebases. Since this method serves a clear purpose in testing a specific functionality, it is likely to be maintained as part of the test suite."
survived,"    def run(
        self,
        input_data: Input,
        *,
        credentials: APIKeyCredentials,
        **kwargs,
    ) -> BlockOutput:
        seed = input_data.seed
        result = self.run_model(
            api_key=credentials.api_key,
            model_name=input_data.model.api_name,
            prompt=input_data.prompt,
            input_image=input_data.input_image,
            aspect_ratio=input_data.aspect_ratio.value,
            seed=seed,
        )
        yield ""image_url"", result
",autogpt_platform/backend/backend/blocks/flux_kontext.py,AIImageEditorBlock,1,9.736200303530205e-10,"The method 'run' is likely to survive because it appears to be a well-structured and functional piece of code. It takes in input data and credentials, processes them using a model, and yields a result. The method is clear in its purpose and seems to be part of a larger system that generates or processes images based on a model. There is no indication of deprecated practices or inefficiencies that would necessitate its deletion."
survived,"    def __init__(self):
        super().__init__(
            id=""3fd9c73d-4370-4925-a1ff-1b86b99fabfa"",
            description=(
                ""Edit images using BlackForest Labs' Flux Kontext models. Provide a prompt ""
                ""and optional reference image to generate a modified image.""
            ),
            categories={BlockCategory.AI, BlockCategory.MULTIMEDIA},
            input_schema=AIImageEditorBlock.Input,
            output_schema=AIImageEditorBlock.Output,
            test_input={
                ""prompt"": ""Add a hat to the cat"",
                ""input_image"": ""https://example.com/cat.png"",
                ""aspect_ratio"": AspectRatio.MATCH_INPUT_IMAGE,
                ""seed"": None,
                ""model"": FluxKontextModelName.PRO,
                ""credentials"": TEST_CREDENTIALS_INPUT,
            },
            test_output=[
                (""image_url"", ""https://replicate.com/output/edited-image.png""),
            ],
            test_mock={
                ""run_model"": lambda api_key, model_name, prompt, input_image, aspect_ratio, seed: ""https://replicate.com/output/edited-image.png"",
            },
            test_credentials=TEST_CREDENTIALS,
        )
",autogpt_platform/backend/backend/blocks/flux_kontext.py,AIImageEditorBlock,1,3.0590235908148916e-07,"The method is a constructor for initializing an object with specific attributes and configurations. It sets up the necessary parameters for an AI image editing block, including input and output schemas, test inputs, and mock functions. This kind of setup is essential for the functionality of the class it belongs to, especially in a context where AI models are used for image editing. Therefore, it is unlikely to be deleted as it is crucial for the initialization and proper functioning of the class."
survived,"            def add(self, instr: object) -> ""DummyTx"":
                self.instructions.append(instr)
                return self
",tests/test_merkle_broadcast.py,TestMerkleBroadcast.DummyTx,1,1.9171715133907573e-10,"The method 'add' is a simple utility function that appends an instruction to a list and returns the instance itself, allowing for method chaining. This is a common pattern in object-oriented programming and is likely to be useful for users of the 'DummyTx' class. There is no indication that this method is redundant or problematic, so it is likely to be retained."
survived,"            def __init__(self, program_id: object, data: bytes, keys: list[object]):
                self.data = data
",tests/test_merkle_broadcast.py,TestMerkleBroadcast.DummyInstr,1,4.1399375473943306e-08,"The method is a constructor (__init__) for a class, which is a fundamental part of object-oriented programming in Python. It initializes the instance variables of the class, which are essential for the class to function correctly. The presence of parameters like program_id, data, and keys suggests that these are important for the class's operation. Therefore, it is unlikely that this method will be deleted as it is crucial for setting up the initial state of the class instances."
survived,"            async def close(self) -> None:  # pragma: no cover - dummy
                pass
",tests/test_merkle_broadcast.py,TestMerkleBroadcast.DummyClient,1,3.653482080241728e-08,"The method 'close' is marked with a pragma directive 'no cover', indicating that it is intentionally left as a dummy or placeholder method. This suggests that the method is not currently implemented but may be intended for future use or to fulfill an interface requirement. Since it is common to have such placeholder methods in codebases to maintain structure or compatibility, it is likely to survive until it is either implemented or deemed unnecessary. Therefore, the method will likely survive."
survived,"    def _dummy_classes(self, raise_err=False):
        captured = {}

        class DummyClient:
            def __init__(self, url: str) -> None:
                captured[""url""] = url

            async def send_transaction(self, tx: object, *args: object) -> None:
                if raise_err:
                    raise RuntimeError(""fail"")
                captured[""root""] = tx.instructions[0].data.decode()

            async def close(self) -> None:  # pragma: no cover - dummy
                pass

        class DummyTx:
            def __init__(self) -> None:
                self.instructions = []

            def add(self, instr: object) -> ""DummyTx"":
                self.instructions.append(instr)
                return self

        class DummyInstr:
            def __init__(self, program_id: object, data: bytes, keys: list[object]):
                self.data = data

        class DummyPk:
            def __init__(self, val: str) -> None:  # pragma: no cover - dummy
                pass

        return captured, DummyClient, DummyTx, DummyInstr, DummyPk
",tests/test_merkle_broadcast.py,TestMerkleBroadcast,1,4.1399375473943306e-08,"The method `_dummy_classes` is a utility function that provides mock classes for testing purposes. It creates dummy classes like `DummyClient`, `DummyTx`, `DummyInstr`, and `DummyPk` which are likely used to simulate behavior in a controlled environment without relying on actual implementations. Such methods are often retained in codebases because they are useful for unit testing and ensuring that other parts of the code can be tested in isolation. The presence of `pragma: no cover` comments also suggests that these classes are intentionally excluded from test coverage metrics, reinforcing their role as testing utilities. Therefore, the method is likely to survive."
survived,"def test_impact_score() -> None:
    facts = CapsuleFacts(market_size=100, efficiency_gain=0.1, llm_score=0.6)
    scorer = ImpactScorer(llm_weight=0.5)
    score = scorer.score(facts, 0.2)
    assert score == 100 * 0.2 * (1 + 0.5 * 0.6)",tests/test_impact_scorer.py,,1,2.998960815863541e-09,"The method `test_impact_score` is a unit test designed to verify the functionality of the `ImpactScorer` class and its `score` method. Unit tests are crucial for ensuring code reliability and correctness, especially when changes are made to the codebase. This test checks if the scoring logic is correctly implemented by asserting the expected outcome. Given the importance of testing in software development, it is highly likely that this method will be retained to maintain code quality and prevent regressions."
survived,"        def _tool(*_a: object, **_k: object) -> Callable[[object], object]:
            def dec(f: object) -> object:
                return f

            return dec
",tests/test_alpha_opportunity_stub.py,TestAlphaOpportunityStub,1,9.931195248674785e-08,"The method _tool is a decorator factory that returns a decorator function 'dec'. The 'dec' function takes a function 'f' as an argument and returns it unchanged. This pattern is often used to create decorators that can be extended with additional functionality later. Since it is a utility function that can be useful for creating decorators, it is likely to be retained in the codebase for future use or extension."
survived,"            def __init__(self, *a: object, port: int = 5001, **_k: object) -> None:
                captured[""port""] = port
",tests/test_alpha_opportunity_stub.py,TestAlphaOpportunityStub.DummyRuntime,1,1.444980317078884e-07,"The method is a constructor (__init__) which is a fundamental part of a class in Python. It is used to initialize the instance of the class. The presence of this method is crucial for setting up initial state or configuration for objects created from the class. The method is not redundant or obsolete, and it serves a clear purpose in capturing the 'port' argument into a dictionary. Therefore, it is unlikely to be deleted."
survived,"def test_refinement_rejected_patch(tmp_path: Path) -> None:
    repo = _make_repo(tmp_path)
    logs = tmp_path / ""logs""
    logs.mkdir()
    (logs / ""log.json"").write_text(
        ""\n"".join([
            '{""hash"":""h0"",""ts"":0}',
            '{""hash"":""h1"",""ts"":1}',
            '{""hash"":""h2"",""ts"":5}'
        ]),
        encoding=""utf-8"",
    )

    reg = StakeRegistry()
    reg.set_stake(""meta"", 1.0)

    with patch.object(harness, ""vote_and_merge"", return_value=False):
        agent = MetaRefinementAgent(repo, logs, reg)
        merged = agent.refine()

    assert not merged
    assert (repo / ""metric.txt"").read_text().strip() == ""1""",tests/test_meta_refinement_agent.py,,1,3.466327708641819e-07,"The method 'test_refinement_rejected_patch' is a unit test designed to verify the behavior of a system when a patch is rejected. It uses mocking to simulate the behavior of the 'vote_and_merge' function, ensuring that it returns False, which means the patch is not merged. The test then asserts that the 'merged' variable is False and checks the content of a file to ensure the system behaves as expected when a patch is rejected. This is a typical and necessary test to ensure robustness in software development, especially in systems involving version control and patch management. Therefore, it is unlikely to be deleted as it serves a critical role in validating the system's functionality."
survived,"def test_compute_merkle_root_with_malformed_row(tmp_path: Path) -> None:
    ledger = Ledger(str(tmp_path / ""ledger.db""), broadcast=False)
    e1 = messaging.Envelope(sender=""a"", recipient=""b"", payload={""v"": 1}, ts=0.0)
    e2 = messaging.Envelope(sender=""b"", recipient=""c"", payload={""v"": 2}, ts=1.0)
    ledger.log(e1)
    ledger.log(e2)
    # insert invalid hash value
    ledger.conn.execute(
        ""INSERT INTO messages (ts, sender, recipient, payload, hash) VALUES (?, ?, ?, ?, ?)"",
        (2.0, ""x"", ""y"", ""{}"", ""zz""),
    )
    ledger.conn.commit()
    with pytest.raises(ValueError):
        ledger.compute_merkle_root()
",tests/test_ledger_corruption.py,,1,4.944450477491054e-09,"The method is likely to be Survived (1) because it is a test function designed to ensure that the `compute_merkle_root` method in the `Ledger` class correctly raises a `ValueError` when encountering a malformed row in the database. This is a valid and important test case to ensure the robustness and error handling of the `compute_merkle_root` method. The presence of such tests is crucial for maintaining code quality and reliability, especially in systems dealing with data integrity like ledgers."
survived,"def verify(wheel_path: Path) -> bool:
    """"""Return ``True`` if ``wheel_path`` verifies against its ``.sig`` file.""""""
    sig_path = wheel_path.with_suffix(wheel_path.suffix + "".sig"")
    if not sig_path.is_file():
        print(f""Signature file not found: {sig_path}"", file=sys.stderr)
        return False
    pub_b64 = agents_mod._WHEEL_PUBKEY
    with tempfile.NamedTemporaryFile(delete=False) as tmp:
        tmp.write(base64.b64decode(pub_b64))
        tmp.flush()
        pub_path = tmp.name
    try:
        digest = subprocess.run(
            [""openssl"", ""dgst"", ""-sha512"", ""-binary"", str(wheel_path)],
            check=True,
            capture_output=True,
        ).stdout
        res = subprocess.run(
            [
                ""openssl"",
                ""pkeyutl"",
                ""-verify"",
                ""-pubin"",
                ""-inkey"",
                pub_path,
                ""-sigfile"",
                str(sig_path),
            ],
            input=digest,
        )
        return res.returncode == 0
    finally:
        os.unlink(pub_path)
",alpha_factory_v1/scripts/verify_wheel_sig.py,,1,2.3355930333443423e-09,"The method 'verify' is a utility function that checks the integrity of a file by verifying it against a signature file. This is a common and important operation in software development, especially for ensuring the authenticity and integrity of distributed packages. The method is well-structured, uses standard libraries and tools (like OpenSSL), and handles temporary files and errors appropriately. Such functionality is crucial for security purposes, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q10.py,Nation,0,0.9999997617630155,"The method is likely to be deleted because it does not correctly implement the expected behavior of the `__contains__` method. In Python, `__contains__` is used to check if a container contains a certain item, typically using the `in` keyword. The current implementation uses `hasattr`, which checks for the presence of an attribute, not whether an item is in a collection. This could lead to incorrect behavior and confusion, prompting a refactor or deletion."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q13.py,Order,0,0.9999999530883621,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose suggests that it is likely to be deleted or refactored to align with the expected behavior of `__contains__`. Therefore, the method is predicted to be deleted."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q22.py,Customer,0,0.9999930377415741,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q2.py,Region,0,0.9999485577825553,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the typical or expected behavior for `__contains__`, which should check for membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate implementation that checks for membership in the intended collection."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q10.py,Auto1,0,0.999985261023967,"The method `__contains__` is intended to check if a key is present in a collection, typically using the `in` keyword. However, the implementation here uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement the intended functionality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q16.py,Supplier,0,0.9999938558278723,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which should be used for membership testing in collections like lists, sets, or dictionaries. This misuse of `__contains__` is likely to lead to confusion and incorrect behavior when the method is used, as it does not align with the standard Python protocol for membership testing. Therefore, it is likely to be deleted or refactored to correctly implement membership testing."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q3.py,Lineitem,0,0.9999687980937693,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q8.py,Region,0,0.9999930377415741,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q9.py,Auto9,0,0.9999485577825553,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which is usually used for membership testing in collections like lists, sets, or dictionaries. This misuse of `__contains__` could lead to confusion and unexpected behavior, as it does not align with the standard use case of checking membership in a collection. Therefore, it is likely that this method will be deleted or refactored to better align with its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q30.py,Auto4,0,0.9999952149051502,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the standard behavior expected from `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q15.py,Auto5,0,0.9999687980937693,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the typical or expected behavior for `__contains__`, which should check for membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate implementation that checks for membership in the intended collection."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q21.py,Auto4,1,1.3440409770490404e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. This implementation uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q16.py,Auto1,0,0.9999756997690634,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check membership rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to better fit its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q29.py,Auto11,0,0.9999952149051502,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the standard or expected behavior for `__contains__`, which should typically check for membership in a collection like a list, set, or dictionary. This misuse of `__contains__` is likely to lead to confusion and errors, as it does not align with the conventional use of the method. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q27.py,Auto5,0,0.9999980052698925,"The method is incorrectly implemented. The `__contains__` method is supposed to check for membership, typically in a collection or container, and return a boolean indicating whether the specified key or item is present. However, using `hasattr(self, key)` checks if the object has an attribute with the name `key`, which is not the intended use of `__contains__`. This method should be checking if `key` is in a collection attribute of the object, not if it's an attribute name itself. Therefore, this method is likely to be deleted or rewritten to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q7.py,Auto8,0,0.9999251538028718,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose is likely to lead to confusion and errors, suggesting that the method should be deleted or re-implemented correctly."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q22.py,Auto8,1,2.2159489282323004e-08,"The method is a simple implementation of the __getitem__ special method, which allows instances of the class to use the bracket notation (e.g., obj[key]) to access attributes. This is a common and useful pattern in Python, especially for classes that aim to mimic dictionary-like behavior. It provides a clear and concise way to access attributes dynamically, which can be very useful in various applications. Therefore, it is likely to be retained as it serves a practical purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q23.py,Auto5,0,0.999985261023967,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use of `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely to be deleted or refactored to better fit its intended purpose."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q24.py,Auto3,1,4.6911638017642294e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q23.py,Auto7,1,9.931195248674785e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. This implementation uses `getattr` to dynamically retrieve an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. It is likely to be retained because it provides a flexible and Pythonic way to access object attributes, enhancing the usability of the class."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q19.py,Auto4,0,0.9999994284997149,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys. However, this implementation uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of `__contains__` is likely to lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership testing. Therefore, it is likely to be deleted or replaced with a more appropriate implementation."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q21.py,Auto4,0,0.9999785550602307,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q30.py,Auto7,1,1.637377179507321e-07,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a common and useful pattern for dynamic attribute access, especially in cases where the object is used like a dictionary. It is unlikely to be deleted unless there is a significant change in the class design that makes this method redundant or unnecessary."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q29.py,Auto9,0,0.9999485577825553,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate logic that checks for membership in a collection."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q16.py,Auto3,1,1.3440409770490404e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/job/compiler/py/q13.py,,1,3.2241866333029355e-08,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The function is well-structured and provides flexibility through options like 'where', 'sortKey', 'skip', and 'take'. Such utility functions are often retained in codebases because they encapsulate common patterns of data manipulation, making them reusable and reducing code duplication. Therefore, it is likely to be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q7.py,Auto6,0,0.9999599363048656,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which is usually used for membership testing in collections like lists, sets, or dictionaries. This misuse of `__contains__` could lead to confusion and unexpected behavior, as it does not align with the standard use case of checking membership in a collection. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q15.py,Auto8,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical or expected behavior for `__contains__`, which is usually used for membership testing in collections like lists, sets, or dictionaries. This misuse of the method could lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership testing. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"def _min(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""min() expects list or group"")
    vals = [it for it in v if it is not None]
    if not vals:
        return 0
    return min(vals)
",tests/dataset/job/compiler/py/q25.py,,1,1.0677030767166749e-06,"The method '_min' is a custom implementation of the built-in 'min' function with additional handling for objects with an 'Items' attribute and filtering out 'None' values. However, it raises an exception if the input is not a list or does not have an 'Items' attribute, which might not be ideal for all use cases. Despite this, the method provides a specific utility that might be useful in certain contexts where such input handling is required. Therefore, it is likely to survive as it serves a distinct purpose that the built-in 'min' function does not cover."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q20.py,Auto6,0,0.999964643742472,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check membership rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to better fit its intended purpose."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q28.py,Auto12,1,3.653482080241728e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a common and useful pattern for dynamic attribute access, especially in cases where the object is used like a dictionary or needs to provide flexible access to its attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/job/compiler/py/q16.py,,1,1.1861120010657661e-08,"The method '_key' is a utility function that is likely used for sorting purposes, as indicated by the use of 'opts[""sortKey""]'. It converts the key to a string if it is a list, tuple, or dictionary, which is a common practice to ensure consistent sorting behavior. This method is simple, clear, and serves a specific purpose, making it unlikely to be deleted unless the entire sorting mechanism is refactored or removed. Therefore, it is more likely to survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q16.py,Auto9,1,6.023574641292144e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. This implementation uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. It is likely to be retained because it provides a flexible and Pythonic way to access object attributes, enhancing the usability of the class."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q22.py,Auto9,1,1.955568070542584e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for cases where the object is designed to behave like a dictionary or similar container, allowing attribute access via keys. Since this method provides a clear and functional purpose, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q19.py,Auto9,1,2.5109990926928157e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"def _min(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""min() expects list or group"")
    vals = [it for it in v if it is not None]
    if not vals:
        return 0
    return min(vals)
",tests/dataset/job/compiler/py/q29.py,,1,1.892514738127224e-05,"The method '_min' is a custom implementation of the built-in 'min' function with additional handling for objects with an 'Items' attribute and filtering out 'None' values. However, it raises an exception if the input is not a list or does not have an 'Items' attribute, which might not be ideal for all use cases. Despite this, the method provides a specific utility that might be useful in certain contexts where such input handling is required. Therefore, it is likely to be retained unless there is a shift towards using more robust or generalized solutions."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q26.py,Auto3,0,0.999985261023967,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method's intended purpose could lead to confusion and errors, as it does not align with the expected behavior of `__contains__`. Therefore, it is likely to be deleted or refactored to better fit its intended use."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q19.py,Auto10,1,4.1399375473943306e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q7.py,Auto2,0,0.999985261023967,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"def _min(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""min() expects list or group"")
    vals = [it for it in v if it is not None]
    if not vals:
        return 0
    return min(vals)
",tests/dataset/job/compiler/py/q27.py,,0,0.9999485577825553,"The method _min is a utility function that attempts to find the minimum value in a list or a similar iterable structure. However, it has several issues that make it a candidate for deletion or significant revision:

1. **Naming Convention**: The underscore prefix suggests it's intended for internal use, but it doesn't follow Python's standard naming conventions for private methods.

2. **Type Checking**: The method checks if the input has an 'Items' attribute and uses it if present, but this is not a common pattern and can lead to unexpected behavior if the input is not a list or doesn't have an 'Items' attribute.

3. **Error Handling**: Raising a generic Exception is not a good practice. It should raise a more specific exception like TypeError or ValueError.

4. **Default Return Value**: Returning 0 when the list is empty or contains only None values might not be appropriate for all use cases, as 0 could be a valid minimum value in some contexts.

5. **Redundancy**: Python's built-in min function already provides this functionality more robustly and efficiently.

Due to these reasons, the method is likely to be deleted or heavily refactored to align with best practices and to utilize existing Python functionalities more effectively."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q7.py,Auto3,0,0.9999952149051502,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not fulfill its intended purpose of checking membership in a collection. Therefore, it is likely to be deleted or replaced with a more appropriate implementation."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q24.py,Auto7,0,0.9999485577825553,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which is usually used for membership testing in collections like lists, sets, or dictionaries. This misuse of `__contains__` could lead to confusion and unexpected behavior, as it does not align with the standard use case of checking membership in a collection. Therefore, it is likely that this method will be deleted or refactored to better align with its intended purpose."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/job/compiler/py/q26.py,,1,2.2159489282323004e-08,"The method '_key' is a utility function that is likely used internally within a module or class to generate a key for sorting purposes. It takes an iterable 'it', applies a sorting key function from 'opts', and ensures the key is a string if it's a complex data type. This kind of function is common in data processing or sorting operations, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q26.py,Auto9,0,0.999983298584886,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking for membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q15.py,Auto2,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list, set, or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate method for checking membership."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q8.py,Auto5,0,0.9999991684720096,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the standard or expected behavior for `__contains__`, which should typically check for membership in a collection like a list, set, or dictionary. Therefore, this method is likely to be deleted or refactored to align with the expected behavior of `__contains__`."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q27.py,Auto8,1,0.06008665438181589,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. In this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not a typical use of `__contains__`, as it should generally check for membership in a collection rather than the presence of an attribute. However, if the class is designed to treat its attributes as a collection of keys, this implementation could be valid. Without additional context, it's difficult to determine if this is the intended use. If the class is indeed designed to treat its attributes as a collection, this method could survive. Otherwise, it might be considered incorrect and subject to deletion or modification."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q20.py,Auto4,0,0.999964643742472,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method could lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership checks. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q32.py,Auto6,1,1.725782769012759e-08,"The method is a simple implementation of the __getitem__ special method, which allows an object to use the bracket notation (obj[key]) to access its attributes. This is a common and useful pattern in Python, especially for classes that need to provide dictionary-like access to their attributes. It is a straightforward and efficient way to implement this functionality, and there is no indication that it is incorrect or unnecessary. Therefore, it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q16.py,Auto7,1,6.023574641292144e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be retained because it provides a flexible way to access object properties, which can be particularly useful in dynamic or reflective programming scenarios."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q17.py,Auto5,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking for membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement the intended functionality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q10.py,Auto9,0,0.9999339478346898,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys. However, this implementation uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which is usually used for membership testing in collections like lists, sets, or dictionaries. This misuse of `__contains__` could lead to confusion and unexpected behavior, as it does not align with the standard use case of checking for membership in a collection. Therefore, it is likely that this method will be deleted or refactored to better align with its intended purpose."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/job/compiler/py/q20.py,,1,8.152020648014727e-09,"The method '_key' is a utility function that is likely used internally within a module or class to generate a key for sorting purposes. It takes an iterable 'it', applies a sorting key function from 'opts', and ensures the key is a string if it's a complex data type. Such utility functions are common in codebases for handling sorting operations and are unlikely to be deleted unless the sorting mechanism is entirely refactored or replaced. Therefore, it is more likely to survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q19.py,Auto8,1,1.0467401685178159e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. It is a simple and effective way to provide dynamic access to object attributes, which can be particularly useful in data handling or configuration classes. Therefore, this method is likely to be retained as it serves a clear purpose and is implemented correctly."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q30.py,Auto1,0,0.9999938558278723,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q5.py,Auto4,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose suggests that it is likely to be deleted or refactored to align with its conventional use."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/job/compiler/py/q28.py,,1,2.5109990926928157e-08,"The method '_key' is a private utility function, indicated by the underscore prefix, which suggests it is intended for internal use within a module or class. It is a simple function that processes an iterable 'it' using a 'sortKey' function from the 'opts' dictionary. The function checks if the result is a list, tuple, or dictionary, and converts it to a string if so. This kind of utility function is common in codebases for handling sorting keys, and there is no indication of it being obsolete or redundant. Therefore, it is likely to be retained as it serves a specific purpose in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q19.py,Auto1,1,1.3440409770490404e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. Since it serves a clear purpose and is implemented correctly, it is likely to be retained in the code."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/job/compiler/py/q15.py,,1,2.5109990926928157e-08,"The method '_key' is a utility function that is likely used internally within a class or module to generate a key for sorting purposes. It is a simple and straightforward function that converts the result of a 'sortKey' function into a string if it is a list, tuple, or dictionary. This kind of utility function is common in codebases where sorting or ordering of complex data structures is required. Since it serves a specific purpose and is not overly complex or redundant, it is likely to be retained in the codebase."
survived,"def test_Q30_finds_violent_horror_thriller_movies_with_male_writer():
    assert result == [
        Auto1(
            movie_budget=""Horror"",
            movie_votes=2000,
            writer=""John Writer"",
            complete_violent_movie=""Violent Horror"",
        )
    ]
",tests/dataset/job/compiler/py/q30.py,,1,2.699578619062706e-07,"The method is a test function, which is typically used in software development to ensure that a specific piece of code works as expected. Test functions are crucial for maintaining code quality and reliability, especially in larger projects. The presence of a test function indicates that the codebase likely follows a test-driven development approach or at least values testing. Therefore, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered, which would necessitate a different test."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/job/compiler/py/q33.py,,1,4.363462233903899e-09,"The method '_key' is a utility function that is likely used internally within a module or class to generate a key for sorting purposes. It takes an iterable 'it', applies a 'sortKey' function from the 'opts' dictionary to it, and ensures the result is a string if it's a list, tuple, or dictionary. This kind of function is common in sorting operations and is useful for customizing sort behavior. Since it serves a specific purpose and is not overly complex or redundant, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q79.py,Auto2,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q25.py,_Group,1,2.998960815863541e-09,"The method `__len__` is a special method in Python that is used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q79.py,HouseholdDemographic,1,1.522997951276035e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a common and useful pattern for dynamic attribute access, especially in cases where the object is used like a dictionary or needs to provide flexible access to its attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q42.py,StoreSale,1,4.1399375473943306e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"def _sort_key(k):
    if hasattr(k, ""__dataclass_fields__""):
        return str(k)
    if isinstance(k, list):
        return tuple((_sort_key(x) for x in k))
    if isinstance(k, tuple):
        return tuple((_sort_key(x) for x in k))
    if isinstance(k, dict):
        return str(k)
    return k
",tests/dataset/tpc-ds/compiler/py/q36.py,,1,7.194132978569833e-09,"The method '_sort_key' is a utility function designed to generate a sorting key for various data types, including dataclasses, lists, tuples, and dictionaries. It is a versatile function that can be used in sorting operations where complex data structures are involved. The function is well-structured and handles multiple data types, making it useful in scenarios where sorting of heterogeneous collections is required. Given its utility and the fact that it doesn't have any apparent issues or redundancies, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q79.py,Auto3,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q21.py,Auto1,0,0.9999921107349486,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check membership rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely to be deleted or refactored to better fit its intended purpose."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q17.py,Auto1,1,2.5109990926928157e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q17.py,_Group,1,1.444980317078884e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes. The code snippet shows a typical pattern where an attribute is initialized and a list is created. This is a common and necessary practice in class design, so it is unlikely to be deleted."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q3.py,_Group,1,1.275190675769241e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes. The code snippet shows a typical pattern of initializing instance variables, which is a common and necessary practice in class definitions. Therefore, it is unlikely that this method will be deleted as it serves a crucial role in the class's functionality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q97.py,StoreSale,0,0.9999982396568657,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q24.py,Store,1,5.3157849718487075e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. It is likely to be retained because it provides a flexible and Pythonic way to access object attributes, enhancing the usability of the class."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q32.py,CatalogSale,1,4.1399375473943306e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"def test_TPCDS_Q90_ratio():
    assert result == 2.0
",tests/dataset/tpc-ds/compiler/py/q90.py,,0,0.9999546021442518,"The method `test_TPCDS_Q90_ratio` is a simple test function that contains a single assertion. It checks if the variable `result` is equal to 2.0. However, the function lacks context, such as the definition or calculation of `result`, and does not include any setup or teardown code that is typically found in a comprehensive test. Without additional context or functionality, this method is not very useful on its own. It is likely to be deleted unless it is part of a larger test suite where `result` is defined and this test serves a specific purpose."
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q7.py,,1,5.60279640614594e-09,"The method '_group_by' is a utility function that groups elements of a list based on a key function. It is a common pattern in data processing and transformation tasks. The function is generic, flexible, and can handle various input types, making it useful in many contexts. Unless there is a specific reason to remove it, such as redundancy or a better alternative, it is likely to be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q23.py,CatalogSale,0,0.9999952149051502,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which is usually used for membership testing in collections like lists, sets, or dictionaries. This misuse of `__contains__` could lead to confusion and unexpected behavior, as it does not align with the standard use case of checking membership in a collection. Therefore, it is likely to be deleted or refactored to better fit its intended purpose."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q48.py,DateDim,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. It is a simple and effective way to provide dynamic access to object attributes, which can be particularly useful in data handling or configuration classes. Therefore, this method is likely to be retained as it serves a clear purpose and follows Python's conventions for special methods."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q12.py,DateDim,0,0.999988521231025,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the typical or expected behavior for `__contains__`, which should be checking membership in a collection like a list, set, or dictionary. Therefore, this implementation is likely incorrect for its intended purpose and may be deleted or revised to properly check for key membership."
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q25.py,_Group,1,2.0611536181902033e-09,"The method is a standard implementation of the __iter__ method in Python, which is used to make an object iterable. It returns an iterator over the 'Items' attribute of the object. This is a common and necessary method for classes that need to support iteration, and there is no indication that it is redundant or incorrect. Therefore, it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q72.py,Warehouse,1,2.8453347280241004e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a flexible and Pythonic way to access object attributes, it is likely to be retained in the code."
survived,"def _q0():
    _groups = {}
    _order = []
    for j in joined:
        _k = Auto3(
            i_item_id=j.i_item_id,
            ca_country=j.ca_country,
            ca_state=j.ca_state,
            ca_county=j.ca_county,
        )
        _ks = str(_k)
        g = _groups.get(_ks)
        if not g:
            g = _Group(_k)
            _groups[_ks] = g
            _order.append(_ks)
        g.Items.append(j)
    _items1 = [_groups[k] for k in _order]
    return [
        Auto1(
            i_item_id=g.key[""i_item_id""],
            ca_country=g.key[""ca_country""],
            ca_state=g.key[""ca_state""],
            ca_county=g.key[""ca_county""],
            agg1=(
                sum([x.q for x in g]) / len([x.q for x in g]) if [x.q for x in g] else 0
            ),
            agg2=(
                sum([x.lp for x in g]) / len([x.lp for x in g])
                if [x.lp for x in g]
                else 0
            ),
            agg3=(
                sum([x.cp for x in g]) / len([x.cp for x in g])
                if [x.cp for x in g]
                else 0
            ),
            agg4=(
                sum([x.sp for x in g]) / len([x.sp for x in g])
                if [x.sp for x in g]
                else 0
            ),
            agg5=(
                sum([x.np for x in g]) / len([x.np for x in g])
                if [x.np for x in g]
                else 0
            ),
            agg6=(
                sum([x.by for x in g]) / len([x.by for x in g])
                if [x.by for x in g]
                else 0
            ),
            agg7=(
                sum([x.dep for x in g]) / len([x.dep for x in g])
                if [x.dep for x in g]
                else 0
            ),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q18.py,,1,5.3157849718487075e-08,"The method '_q0' is a utility function that processes a collection of items ('joined') and groups them based on certain attributes ('i_item_id', 'ca_country', 'ca_state', 'ca_county'). It then calculates several aggregate values for each group. This kind of functionality is common in data processing and transformation tasks, especially in data analysis and reporting contexts. The method is likely to be useful in scenarios where such grouped aggregation is needed, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained."
survived,"def _q2():
    _groups = {}
    _order = []
    for f in filtered:
        _k = f.i_class
        _ks = str(_k)
        g = _groups.get(_ks)
        if not g:
            g = _Group(_k)
            _groups[_ks] = g
            _order.append(_ks)
        g.Items.append(f)
    _items1 = [_groups[k] for k in _order]
    return [Auto4(_class=g.key, total=sum([x.itemrevenue for x in g])) for g in _items1]
",tests/dataset/tpc-ds/compiler/py/q20.py,,0,0.9999999981810384,"The method '_q2' is likely to be deleted (0) because it uses undefined variables and classes such as 'filtered', '_Group', and 'Auto4'. Without these definitions, the method cannot function correctly, indicating that it might be part of an incomplete or outdated codebase. Additionally, the method's purpose is unclear without further context, which suggests it might not be in active use or has been replaced by more complete implementations."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q59.py,SalesYear1,1,1.1253518384332553e-07,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name, which is a valid and useful pattern for objects that need to provide dictionary-like access to their attributes. This method is likely to be retained because it provides a flexible way to access object attributes and is consistent with Python's design philosophy of allowing objects to behave like built-in types when appropriate."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q72.py,,1,1.3440409770490404e-08,"The method '_key' is a utility function that is likely used for sorting purposes, as indicated by the use of 'sortKey' from the 'opts' dictionary. The function converts the key to a string if it is a list, tuple, or dictionary, which is a common practice to ensure consistent sorting behavior. This method is simple, serves a clear purpose, and does not have any apparent issues or redundancies that would necessitate its deletion. Therefore, it is likely to be retained in the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q92.py,WebSale,1,2.2159489282323004e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q96.py,TimeDim,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q18.py,_Group,1,6.69158608681505e-10,"The method is a standard implementation of the `__iter__` method, which is used to make an object iterable. It returns an iterator over the `Items` attribute of the object. This is a common and necessary method for classes that are meant to be iterable, and there is no indication that it is redundant or incorrect. Therefore, it is likely to be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q10.py,CustomerDemographic,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list, set, or dictionary. Therefore, the method is likely to be deleted or rewritten to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q39.py,DateDim,1,2.5109990926928157e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q14.py,Auto2,1,2.8453347280241004e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q14.py,CatalogSale,0,0.9999785550602307,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q98.py,DateDim,1,1.1861120010657661e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. Since it serves a clear purpose and is implemented correctly, it is likely to be retained in the code."
survived,"def test_TPCDS_Q93_active_sales():
    assert result == [
        Auto1(ss_customer_sk=1, sumsales=40.0),
        Auto1(ss_customer_sk=2, sumsales=60.0),
    ]
",tests/dataset/tpc-ds/compiler/py/q93.py,,1,2.3355930333443423e-09,"The method `test_TPCDS_Q93_active_sales` is a test function, likely part of a test suite for a larger codebase. Test functions are crucial for ensuring code correctness and reliability, especially in data processing or analytical applications. The function is asserting that the result matches an expected output, which is a common practice in unit testing. Given the importance of testing in software development, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered. Therefore, the method will likely survive."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q93.py,,1,3.2241866333029355e-08,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The function is well-structured and provides flexibility through options like 'where', 'sortKey', 'skip', and 'take'. Such utility functions are often retained in codebases because they encapsulate common patterns of data manipulation that can be reused across different parts of an application. Therefore, it is likely to be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q65.py,StoreSale,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the keys of a dictionary or similar structure. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical use case for `__contains__`, as it should be used to check membership in a collection, not the presence of an attribute. This misuse of the method suggests that it might be deleted or refactored to align with its intended purpose."
survived,"def test_TPCDS_Q12_revenue_ratio():
    assert result == [
        Auto1(
            i_item_id=""ITEM1"",
            i_item_desc=""Item One"",
            i_category=""A"",
            i_class=""C1"",
            i_current_price=10.0,
            itemrevenue=200.0,
            revenueratio=50.0,
        ),
        Auto1(
            i_item_id=""ITEM2"",
            i_item_desc=""Item Two"",
            i_category=""A"",
            i_class=""C1"",
            i_current_price=20.0,
            itemrevenue=200.0,
            revenueratio=50.0,
        ),
    ]
",tests/dataset/tpc-ds/compiler/py/q12.py,,1,3.850741907939403e-09,"The method `test_TPCDS_Q12_revenue_ratio` is a unit test function, which is essential for verifying the correctness of the code it is testing. Unit tests are a crucial part of software development as they help ensure that individual parts of the program work as expected. The presence of an assertion in the function indicates that it is checking the output against expected values, which is a standard practice in testing. Therefore, it is unlikely that this method will be deleted, as it serves an important role in maintaining code quality and reliability."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q9.py,StoreSale,0,0.9999756997690634,"The method is a custom implementation of the `__contains__` method, which is used to define behavior for the `in` keyword. However, the implementation uses `hasattr(self, key)`, which checks for the presence of an attribute rather than checking for membership in a collection. This is not the intended use of `__contains__`, which should check for the presence of an item in a collection. Therefore, the method is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q79.py,HouseholdDemographic,0,0.9999967112522585,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the typical or expected behavior for `__contains__`, which should check for membership in a collection like a list, set, or dictionary. This misuse of `__contains__` is likely to lead to confusion and errors, as it does not align with the standard behavior expected from this method. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q55.py,DateDim,1,4.6911638017642294e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python, especially in classes that aim to mimic dictionary behavior or provide dynamic attribute access. Therefore, this method is likely to be retained as it serves a clear purpose and is implemented correctly."
survived,"def _q3():
    _groups = {}
    _order = []
    for u in union:
        _k = u.get(""item"") if isinstance(u, dict) else getattr(u, ""item"")
        _ks = str(_k)
        g = _groups.get(_ks)
        if not g:
            g = _Group(_k)
            _groups[_ks] = g
            _order.append(_ks)
        g.Items.append(u)
    _items1 = [_groups[k] for k in _order]
    return [
        Auto1(
            i_item_id=g.key,
            total_sales=_sum(
                [
                    x.get(""total"") if isinstance(x, dict) else getattr(x, ""total"")
                    for x in g
                ]
            ),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q56.py,,1,7.194132978569833e-09,"The method '_q3' is a private method (indicated by the underscore prefix) that processes a collection of items, groups them, and calculates total sales for each group. It is likely part of a larger system that deals with sales data. The method is functional, and there is no indication of it being obsolete or redundant. It performs a specific task that is likely useful in its context, such as data aggregation or report generation. Therefore, it is more likely to be retained in the codebase."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q25.py,,1,4.944450477491054e-09,"The method '_key' is a utility function that is likely used for sorting purposes, as indicated by the use of 'sortKey' from the 'opts' dictionary. The function takes an iterable 'it', applies a sorting key function, and ensures the result is a string if it's a complex data type like list, tuple, or dict. This kind of utility function is common in codebases where custom sorting logic is needed, and it is unlikely to be deleted unless the entire sorting mechanism is refactored or removed. Therefore, it is more likely to survive."
survived,"def _q0():
    _src = store_sales
    _rows = _query(
        _src,
        [
            {
                ""items"": customer_demographics,
                ""on"": lambda ss, cd: ss.ss_cdemo_sk == cd.cd_demo_sk,
            },
            {
                ""items"": date_dim,
                ""on"": lambda ss, cd, d: ss.ss_sold_date_sk == d.d_date_sk,
            },
            {""items"": store, ""on"": lambda ss, cd, d, s: ss.ss_store_sk == s.s_store_sk},
            {""items"": item, ""on"": lambda ss, cd, d, s, i: ss.ss_item_sk == i.i_item_sk},
        ],
        {
            ""select"": lambda ss, cd, d, s, i: (ss, cd, d, s, i),
            ""where"": lambda ss, cd, d, s, i: (
                (
                    (cd.cd_gender == ""F"" and cd.cd_marital_status == ""M"")
                    and cd.cd_education_status == ""College""
                )
                and d.d_year == 2000
            )
            and s.s_state in [""CA""],
        },
    )
    _groups = _group_by(
        _rows, lambda ss, cd, d, s, i: Auto2(item_id=i.i_item_id, state=s.s_state)
    )
    _items1 = _groups
    _items1 = sorted(
        _items1, key=lambda g: _sort_key([g.key[""item_id""], g.key[""state""]])
    )
    return [
        Auto1(
            i_item_id=g.key[""item_id""],
            s_state=g.key[""state""],
            agg1=(
                sum([x[0].ss_quantity for x in g]) / len([x[0].ss_quantity for x in g])
                if [x[0].ss_quantity for x in g]
                else 0
            ),
            agg2=(
                sum([x[0].ss_list_price for x in g])
                / len([x[0].ss_list_price for x in g])
                if [x[0].ss_list_price for x in g]
                else 0
            ),
            agg3=(
                sum([x[0].ss_coupon_amt for x in g])
                / len([x[0].ss_coupon_amt for x in g])
                if [x[0].ss_coupon_amt for x in g]
                else 0
            ),
            agg4=(
                sum([x[0].ss_sales_price for x in g])
                / len([x[0].ss_sales_price for x in g])
                if [x[0].ss_sales_price for x in g]
                else 0
            ),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q27.py,,1,4.363462233903899e-09,"The method `_q0` is a complex query function that performs data joining, filtering, grouping, and aggregation on a set of sales data. It is likely part of a larger data processing or analytics system. The method is well-structured and performs specific tasks that are common in data analysis, such as filtering by demographic and date criteria, grouping by item and state, and calculating average values for various sales metrics. These operations are essential for generating insights from sales data, which is a common requirement in business intelligence applications. Therefore, the method is likely to be retained as it serves a useful purpose in data analysis."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q33.py,_Group,1,2.3355930333443423e-09,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q26.py,_Group,1,8.76424914819242e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes. The code snippet shows a typical pattern where an attribute is initialized and a list is created. This is a common and necessary practice in class design, so it is unlikely to be deleted."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q56.py,Auto1,1,1.1861120010657661e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be retained as it serves a clear purpose and follows Python's conventions for special methods."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q57.py,Item,1,1.955568070542584e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a simple and effective way to allow attribute access using keys, which can be particularly useful in classes that need to interface with code expecting dictionary-like objects. Therefore, this method is likely to be retained as it provides a clear and functional purpose."
survived,"def test_TPCDS_Q53_simplified():
    assert result == [
        Auto1(i_manufact_id=1, sum_sales=20.0),
        Auto1(i_manufact_id=2, sum_sales=53.0),
    ]
",tests/dataset/tpc-ds/compiler/py/q53.py,,1,1.8189616842444243e-09,"The method `test_TPCDS_Q53_simplified` is a test function, likely part of a test suite for a larger codebase. Test functions are generally not deleted unless they are redundant, incorrect, or replaced by more comprehensive tests. Since this function appears to be a straightforward assertion test, it is likely to be retained to ensure the correctness of the code it is testing. Therefore, the method will survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q44.py,Auto1,0,0.999983298584886,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method's intended purpose is likely to lead to confusion and errors, suggesting that the method should be deleted or rewritten to align with its intended use."
survived,"def test_TPCDS_Q79_simplified():
    assert result == [
        Auto1(
            c_last_name=""Smith"",
            c_first_name=""Alice"",
            s_city=""CityA"",
            ss_ticket_number=1,
            amt=5.0,
            profit=10.0,
        )
    ]
",tests/dataset/tpc-ds/compiler/py/q79.py,,1,4.1399375473943306e-08,"The method `test_TPCDS_Q79_simplified` is a test function, likely part of a test suite for a larger codebase. Test functions are crucial for ensuring code correctness and reliability, especially in complex systems. The function checks if the result matches an expected output, which is a common practice in unit testing. Given the importance of testing in software development, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q78.py,C,0,0.999983298584886,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of `__contains__` is likely to lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership testing. Therefore, it is likely to be deleted or refactored to align with its intended purpose."
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q23.py,,1,4.363462233903899e-09,"The method '_group_by' is a utility function that groups elements of a list based on a key function. It is a common pattern in data processing and transformation tasks. The function is generic, flexible, and can handle various types of input, making it useful in many contexts. Additionally, it uses a dictionary to maintain groups and a list to preserve the order of keys, which is a practical approach for many applications. There is no indication that this method is obsolete or redundant, and it provides a clear and useful functionality. Therefore, it is likely to be retained."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q46.py,_Group,1,3.2241866333029355e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes. The code snippet shows a typical pattern of initializing instance variables, which is a common and necessary practice in class definitions. Therefore, this method is likely to be retained as it serves a crucial role in object initialization."
survived,"def _sum(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""sum() expects list or group"")
    s = 0.0
    for it in v:
        if it is None:
            continue
        if isinstance(it, (int, float)):
            s += float(it)
        else:
            raise Exception(""sum() expects numbers"")
    return s
",tests/dataset/tpc-ds/compiler/py/q2.py,,1,1.1861120010657661e-08,"The method '_sum' is a utility function that calculates the sum of a list of numbers. It includes error handling for non-list inputs and non-numeric elements within the list. This functionality is fundamental and commonly needed in various applications, making it unlikely to be deleted. Additionally, the method handles edge cases like None values gracefully, which adds to its robustness and utility."
survived,"def test_TPCDS_Q11_growth():
    assert result == [
        Auto1(customer_id=""C1"", customer_first_name=""John"", customer_last_name=""Doe"")
    ]
",tests/dataset/tpc-ds/compiler/py/q11.py,,1,5.3157849718487075e-08,"The method `test_TPCDS_Q11_growth` is a test function, likely part of a test suite for a larger application. Test functions are generally not deleted unless they are redundant, incorrect, or the functionality they are testing is no longer relevant. Since this function is asserting a specific result, it indicates that it is testing a particular feature or behavior of the application. Unless the feature being tested is removed or significantly altered, the test function is likely to survive to ensure the application behaves as expected."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q73.py,_Group,1,2.699578619062706e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes. The code snippet shows a typical pattern of initializing instance variables, which is a common and necessary practice in class definitions. Therefore, it is unlikely that this method will be deleted as it serves a crucial role in the class's functionality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q67.py,StoreSale,0,0.9999898700118929,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement the intended functionality."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q10.py,CustomerAddres,1,4.6911638017642294e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is used as a dictionary-like structure, allowing for flexible and dynamic attribute access. Therefore, it is likely to be retained."
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q20.py,_Group,1,5.211412485172657e-10,"The method `__iter__` is a standard Python method used to make an object iterable. By returning an iterator over `self.Items`, it allows the object to be used in loops and other contexts where iteration is needed. This is a fundamental feature for many classes, especially those that represent collections or sequences. Unless there is a specific reason to remove iteration capability from the class, this method is likely to be retained."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q2.py,_Group,1,1.8553915987649156e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes. The code snippet shows a typical pattern of initializing instance variables, which is a common and necessary practice in class definitions. Therefore, it is unlikely that this method will be deleted."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q76.py,Item,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"def _q2():
    _groups = {}
    _order = []
    for ss in store_sales:
        _k = ss.ss_customer_sk
        _ks = str(_k)
        g = _groups.get(_ks)
        if not g:
            g = _Group(_k)
            _groups[_ks] = g
            _order.append(_ks)
        g.Items.append(ss)
    _items1 = [_groups[k] for k in _order]
    return [
        Auto2(cust=g.key, sales=sum([x.ss_quantity * x.ss_sales_price for x in g]))
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q23.py,,0,0.9999999956365377,"The method '_q2' is likely to be deleted (0) because it uses a non-descriptive name, which suggests it might be a temporary or internal function. Additionally, the method relies on external variables and classes like 'store_sales', '_Group', and 'Auto2', which are not defined within the code snippet. This lack of context and dependency on external elements makes it less likely to be a standalone, reusable function. Furthermore, the method's logic is straightforward and could be refactored or integrated into a larger, more descriptive function, leading to its potential removal."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q13.py,CustomerAddress,0,0.9999910602998366,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q33.py,Item,0,0.9999910602998366,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q91.py,CatalogReturn,0,0.999985261023967,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q56.py,_Group,1,1.8189616842444243e-09,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be useful and necessary for the class's functionality, leading to its survival."
survived,"def test_TPCDS_Q85_sample():
    assert result == 85.0
",tests/dataset/tpc-ds/compiler/py/q85.py,,1,4.1399375473943306e-08,"The method `test_TPCDS_Q85_sample` is a test function that appears to be part of a testing suite, likely for a larger application or system. The function contains an assertion that checks if the variable `result` is equal to 85.0. This kind of test is typically used to verify that a specific part of the code is functioning as expected.

Test functions are generally important for maintaining code quality and ensuring that changes do not introduce bugs. Unless there is a specific reason to remove this test, such as it being redundant, incorrect, or replaced by a more comprehensive test, it is likely to be retained.

Therefore, the method is predicted to survive because it serves a purpose in validating the correctness of the code."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q74.py,,1,3.3982678079468468e-09,"The method '_key' is a utility function that is likely used internally within a module or class to generate a key for sorting purposes. It takes an iterable 'it', applies a function 'sortKey' from the 'opts' dictionary to it, and ensures the result is a string if it's a list, tuple, or dictionary. This kind of function is common in sorting operations and is unlikely to be deleted unless the sorting mechanism is completely refactored or replaced. Therefore, it is more likely to survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q42.py,Auto2,1,7.73442280641062e-08,"The method is a simple implementation of the __getitem__ special method, which allows an object to use the bracket notation (obj[key]) to access its attributes. This is a common and useful pattern in Python, especially for classes that need to provide dictionary-like access to their attributes. It is likely to be retained as it provides a clear and concise way to access object attributes using keys, enhancing the flexibility and usability of the class."
survived,"def test_TPCDS_Q42_simplified():
    assert result == [
        Auto1(
            d_year=2020,
            i_category_id=200,
            i_category=""CatB"",
            sum_ss_ext_sales_price=20.0,
        ),
        Auto1(
            d_year=2020,
            i_category_id=100,
            i_category=""CatA"",
            sum_ss_ext_sales_price=10.0,
        ),
    ]
",tests/dataset/tpc-ds/compiler/py/q42.py,,1,2.3355930333443423e-09,"The method `test_TPCDS_Q42_simplified` is a test function, likely part of a test suite for a larger codebase. Test functions are crucial for ensuring code correctness and reliability, especially in complex systems. This particular test checks if the `result` matches a specific expected output, which is a common practice in unit testing. Given the importance of testing in software development, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered. Therefore, the method will likely survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q40.py,Auto2,1,7.73442280641062e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a flexible and Pythonic way to access object attributes, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q91.py,DateDim,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation, especially in cases where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, it is likely to be retained as it provides a clear and functional purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q33.py,WebSale,0,0.9999785550602307,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to better fit its intended purpose."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q95.py,,1,2.646573631904765e-09,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The function is not overly specific to a particular use case, making it versatile and reusable. Such utility functions are often retained in codebases because they encapsulate common patterns of data manipulation that can be reused across different parts of an application. Therefore, it is likely to survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q76.py,StoreSale,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q71.py,DateDim,0,0.9999869928752253,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q70.py,Store,0,0.999985261023967,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical or expected behavior for `__contains__`, which is usually used for membership testing in collections like lists, sets, or dictionaries. This misuse of the method could lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership testing. Therefore, it is likely to be deleted or refactored to align with its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q26.py,CustomerDemographic,0,0.9999687980937693,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose suggests that it is likely to be deleted or refactored to correctly implement membership checking."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q55.py,,1,2.2159489282323004e-08,"The method '_key' is a utility function that is likely used internally within a class or module to generate a key for sorting purposes. It takes an iterable 'it', applies a function 'sortKey' from a dictionary 'opts' to it, and then ensures the result is a string if it's a list, tuple, or dictionary. This kind of function is common in sorting operations where custom keys are needed. Since it serves a specific purpose and is not overly complex or redundant, it is likely to be retained in the codebase."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q18.py,,1,2.3355930333443423e-09,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The function is not overly specific to a particular use case, making it versatile and reusable. Such utility functions are often retained in codebases because they encapsulate common patterns of data manipulation that can be reused across different parts of a project. Therefore, it is likely to survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q27.py,StoreSale,0,0.9999952149051502,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the typical or expected behavior for `__contains__`, which should check for membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect for its intended purpose and may be deleted or replaced with a more appropriate implementation."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q13.py,_Group,1,8.76424914819242e-08,"The method is a constructor for a class, initializing the instance variables 'key', 'Items', and 'items'. It is a fundamental part of the class structure, necessary for creating instances of the class with the specified attributes. Therefore, it is unlikely to be deleted as it serves a crucial role in object instantiation."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q11.py,Customer,1,4.6911638017642294e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically retrieve an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q70.py,DateDim,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the codebase."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q70.py,_Group,1,6.023574641292144e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes. The code snippet shows a typical pattern where an attribute is initialized and a list is created. This is a common and necessary practice in class design, so it is unlikely to be deleted."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q74.py,Auto1,1,6.825604231969389e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a flexible and Pythonic way to access object attributes, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q29.py,Auto2,0,0.9999999827421723,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use of `__contains__`, which is expected to work with elements or keys in a collection, not attributes of an object. This misuse of the method's intended purpose makes it likely to be deleted or refactored to align with the expected behavior of `__contains__`. Therefore, the method is predicted to be deleted."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q16.py,,1,4.363462233903899e-09,"The method '_key' is a utility function that is likely used for sorting purposes, as indicated by the use of 'opts[""sortKey""]'. It converts the key to a string if it is a list, tuple, or dictionary, which is a common practice to ensure consistent sorting behavior. This method is simple, performs a specific task, and does not have any apparent issues or redundancies. Therefore, it is likely to be retained in the codebase."
survived,"def _sort_key(k):
    if hasattr(k, ""__dataclass_fields__""):
        return str(k)
    if isinstance(k, list):
        return tuple((_sort_key(x) for x in k))
    if isinstance(k, tuple):
        return tuple((_sort_key(x) for x in k))
    if isinstance(k, dict):
        return str(k)
    return k
",tests/dataset/tpc-ds/compiler/py/q6.py,,1,4.6911638017642294e-08,"The method '_sort_key' is a utility function designed to generate a sorting key for various data types, including dataclasses, lists, tuples, and dictionaries. It is a versatile function that can be useful in many contexts where sorting of complex data structures is required. The function handles different data types gracefully and provides a consistent way to convert them into a sortable format. This kind of utility function is often retained in codebases because it abstracts away the complexity of sorting heterogeneous data structures, making it easier for developers to sort collections without worrying about the underlying data types. Therefore, it is likely to be retained in the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q98.py,Auto2,1,4.1399375473943306e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q30.py,DateDim,1,2.5109990926928157e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a common and useful pattern for dynamic attribute access, especially in cases where the object is used like a dictionary or needs to provide flexible access to its attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q77.py,Auto4,1,4.6911638017642294e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q54.py,Customer,0,0.9999869928752253,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q18.py,Item,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically retrieve an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q19.py,Customer,1,4.944450477491054e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for classes that want to provide dictionary-like access to their attributes. It is a common pattern and does not have any apparent issues or redundancies that would necessitate its deletion. Therefore, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q26.py,Promotion,0,0.999985261023967,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q10.py,Auto1,0,0.999988521231025,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which is usually used for membership testing in collections like lists, sets, or dictionaries. This misuse of `__contains__` could lead to confusion and unexpected behavior, as it does not align with the standard use case of checking membership in a collection. Therefore, it is likely to be deleted or refactored to better fit its intended purpose."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q54.py,,1,1.3440409770490404e-08,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The function is not overly specific to a particular use case, making it versatile and reusable. Such utility functions are often retained in codebases because they encapsulate common patterns of data manipulation that can be reused across different parts of a project. Therefore, it is likely to survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q48.py,CustomerAddres,0,0.9999977396747258,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical use case for `__contains__`, which is expected to check membership rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q40.py,DateDim,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical use case for `__contains__`, which is expected to work with collections like lists, sets, or dictionaries. This misuse of `__contains__` could lead to confusion and unexpected behavior, as it does not align with the standard behavior of checking membership in a collection. Therefore, it is likely that this method will be deleted or refactored to better align with its intended purpose."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q19.py,Store,1,3.653482080241728e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method is implementing a standard Python protocol and is useful for enhancing the flexibility and usability of the object, it is likely to be retained in the code."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q94.py,,1,4.944450477491054e-09,"The method '_key' is a utility function that is likely used internally within a module or class to generate a key for sorting purposes. It takes an iterable 'it', applies a sorting key function from 'opts', and ensures the key is a string if it's a complex data type. This kind of function is common in data processing or sorting operations, and its utility suggests it is likely to be retained unless the overall design changes significantly. Therefore, it is more likely to survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q45.py,Item,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a flexible and Pythonic way to access object attributes, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q77.py,Auto5,1,3.653482080241728e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. It is likely to survive because it provides a flexible way to access object attributes, which can be particularly useful in dynamic or reflective programming scenarios."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q72.py,CatalogSale,0,0.9999974387182097,"The method is incorrectly implemented. The `__contains__` method is supposed to check for membership, typically in a collection or container, and return a boolean indicating whether the specified key or item is present. However, using `hasattr(self, key)` checks if the object has an attribute with the name `key`, which is not the intended use of `__contains__`. This method should be checking if `key` is in a collection attribute of the class, not if it's an attribute itself. Therefore, this method is likely to be deleted or rewritten to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q91.py,DateDim,1,0.05340333507274788,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually implemented to check for membership in a collection like a list, set, or dictionary. However, if the class is designed to treat its attributes as a collection of keys, this implementation could be valid. Without additional context, it's difficult to determine if this is the intended use. If the class is indeed designed to treat its attributes as keys, this method could survive. Otherwise, it might be considered incorrect and subject to deletion or modification."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q21.py,Auto3,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the typical or expected behavior for `__contains__`, which should check for membership in a collection like a list, set, or dictionary. Therefore, this implementation is likely incorrect for its intended purpose and may be deleted or replaced with a more appropriate implementation."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q25.py,DateDim,0,0.9999980052698925,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q40.py,Warehouse,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement the intended functionality."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q40.py,_Group,1,5.60279640614594e-09,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is correctly implemented to return the length of `self.Items`, which suggests that `self.Items` is likely a list or a similar collection. This is a standard and useful implementation for custom classes that manage collections, allowing them to integrate seamlessly with Python's built-in functions. Therefore, this method is likely to be retained as it provides essential functionality for the class."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q79.py,Auto1,0,0.9999967112522585,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q29.py,Store,0,0.9999898700118929,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q73.py,Auto2,0,0.9999785550602307,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute in an object, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking for membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q22.py,Auto1,0,0.999985261023967,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or replaced with a more appropriate implementation."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q4.py,WebSale,1,8.76424914819242e-08,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. In this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is a valid use case if the intention is to check for the presence of attributes rather than elements in a collection. Since this method aligns with a specific use case and is syntactically correct, it is likely to be useful in certain contexts where objects are treated as collections of attributes. Therefore, it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q75.py,DateDim,1,8.152020648014727e-09,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be retained as it serves a clear purpose and is implemented correctly."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q45.py,WebSale,1,4.6911638017642294e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a common and useful pattern for dynamic attribute access, especially in cases where the object is used like a dictionary or needs to provide flexible access to its attributes. Therefore, this method is likely to be retained as it provides a clear and useful functionality."
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q57.py,_Group,1,1.9171715133907573e-10,"The method `__iter__` is a standard Python method used to make an object iterable. It is implemented here to return an iterator over `self.Items`, which suggests that `self.Items` is a collection (like a list or a set). This is a common and useful pattern in Python, allowing objects to be used in loops and other iterable contexts. There is no indication that this method is redundant or unnecessary, so it is likely to be retained."
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q22.py,,1,1.1861120010657661e-08,"The method '_group_by' is a utility function that groups elements of a list based on a key function. It is a common pattern in data processing and transformation tasks. The function is generic, flexible, and can handle various input types, making it useful in many contexts. Unless there is a specific reason to remove it, such as redundancy or a better alternative, it is likely to be retained."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q15.py,,1,1.955568070542584e-08,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The function is well-structured and provides flexibility through the use of options (opts) for various operations like filtering, sorting, and selecting. Such utility functions are often retained in codebases because they encapsulate complex logic in a reusable manner, making them valuable for developers who need to perform similar operations across different parts of an application. Therefore, it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q45.py,Customer,1,1.3440409770490404e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be retained as it serves a clear purpose and follows Python's design principles."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q55.py,Item,1,2.2159489282323004e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the subscript notation (e.g., obj[key]). In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object needs to provide dictionary-like access to its attributes. Therefore, it is likely to be retained."
survived,"def _q0():
    _src = all_rows
    _rows = _query(_src, [], {""select"": lambda r: r})
    _groups = _group_by(
        _rows,
        lambda r: Auto3(
            channel=r.get(""channel"") if isinstance(r, dict) else getattr(r, ""channel""),
            col_name=(
                r.get(""col_name"") if isinstance(r, dict) else getattr(r, ""col_name"")
            ),
            d_year=r.get(""d_year"") if isinstance(r, dict) else getattr(r, ""d_year""),
            d_qoy=r.get(""d_qoy"") if isinstance(r, dict) else getattr(r, ""d_qoy""),
            i_category=(
                r.get(""i_category"") if isinstance(r, dict) else getattr(r, ""i_category"")
            ),
        ),
    )
    _items1 = _groups
    _items1 = sorted(_items1, key=lambda g: _sort_key(g.key[""channel""]))
    return [
        Auto1(
            channel=g.key[""channel""],
            col_name=g.key[""col_name""],
            d_year=g.key[""d_year""],
            d_qoy=g.key[""d_qoy""],
            i_category=g.key[""i_category""],
            sales_cnt=len(g),
            sales_amt=_sum(
                [
                    (
                        (x.get(""r"") if isinstance(x, dict) else getattr(x, ""r"")).get(
                            ""ext_sales_price""
                        )
                        if isinstance(
                            x.get(""r"") if isinstance(x, dict) else getattr(x, ""r""), dict
                        )
                        else getattr(
                            x.get(""r"") if isinstance(x, dict) else getattr(x, ""r""),
                            ""ext_sales_price"",
                        )
                    )
                    for x in g
                ]
            ),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q76.py,,1,9.237449576640118e-09,"The method _q0() appears to be a utility function that processes a collection of data rows, groups them by certain attributes, sorts the groups, and then aggregates some statistics for each group. This type of function is often used in data processing pipelines or reporting tools. Given its utility in transforming and summarizing data, it is likely to be a core part of a larger system. Unless there is a significant change in the system's requirements or architecture, such utility functions are generally retained. Therefore, it is likely to survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q37.py,Auto1,1,5.3157849718487075e-08,"The method is a simple implementation of the __getitem__ special method, which allows instances of the class to use the bracket notation (e.g., obj[key]) to access attributes. This is a common and useful pattern in Python, especially for classes that aim to mimic dictionary-like behavior. It provides a clear and concise way to access attributes dynamically, which can be very useful in various applications. Therefore, it is likely to be retained as it adds functionality and flexibility to the class."
survived,"def _q0():
    _src = store_sales
    _rows = _query(
        _src,
        [
            {
                ""items"": item,
                ""on"": lambda ss, i: ss.item == i.i_item_sk and i.i_manager_id == 1,
            },
            {
                ""items"": date_dim,
                ""on"": lambda ss, i, d: (
                    ss.sold_date == d.d_date_sk and d.d_year == 2001
                )
                and d.d_moy == 11,
            },
        ],
        {""select"": lambda ss, i, d: (ss, i, d)},
    )
    _groups = _group_by(
        _rows,
        lambda ss, i, d: Auto2(year=d.d_year, brand_id=i.i_brand_id, brand=i.i_brand),
    )
    _items1 = _groups
    return [
        Auto1(
            d_year=g.key[""year""],
            brand_id=g.key[""brand_id""],
            ext_price=sum([x[0].price for x in g]),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q52.py,,1,9.736200303530205e-10,"The method '_q0' appears to be a utility function that performs a query on a dataset, groups the results, and returns a list of objects. It is likely part of a larger codebase dealing with sales data analysis. The method is specific in its functionality, focusing on filtering and grouping sales data by year and brand. Such methods are typically retained as they encapsulate specific business logic and data processing tasks that are reusable and essential for the application's functionality. Unless there is a significant change in the application's requirements or architecture, this method is likely to survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q97.py,CatalogSale,1,6.825604231969389e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name, which can be useful for objects that need to provide dictionary-like access to their attributes. This is a valid and potentially useful implementation, especially in cases where the object is designed to act like a dictionary or needs to provide flexible attribute access. Therefore, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q64.py,StoreReturn,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q46.py,,1,4.363462233903899e-09,"The method '_key' is a utility function that is likely used internally within a class or module to generate a key for sorting purposes. It takes an iterable 'it', applies a function from 'opts' dictionary to generate a key, and ensures the key is a string if it's a complex data type. This kind of method is common in sorting operations and is unlikely to be deleted unless the sorting mechanism is completely refactored or replaced. Therefore, it is more likely to survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q77.py,Auto6,1,2.1024340680345882e-07,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is likely to be retained because it provides a flexible way to access object attributes, which can be particularly useful in dynamic or reflective programming scenarios."
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q81.py,_Group,1,7.194132978569833e-09,"The method is a standard implementation of the __iter__ method in Python, which allows an object to be iterable. This is a common and necessary feature for classes that need to support iteration, such as those representing collections or sequences. The method is simple, correct, and follows Python's iterator protocol, making it unlikely to be deleted unless the class design changes significantly."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q3.py,StoreSale,1,8.152020648014727e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern and does not have any apparent issues or redundancies that would warrant its deletion. Therefore, it is likely to be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q17.py,Store,0,0.9999977396747258,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the typical or expected behavior for `__contains__`, which should check for membership in a collection like a list or dictionary. Therefore, this method is likely to be deleted or refactored to align with the expected behavior of `__contains__`."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q12.py,,1,8.152020648014727e-09,"The method '_key' is a utility function that is likely used internally within a module or class to generate a key for sorting purposes. It takes an iterable 'it', applies a function 'sortKey' from a dictionary 'opts' to it, and ensures the result is a string if it's a list, tuple, or dictionary. This kind of function is common in sorting operations and is useful for customizing sort behavior. Since it serves a specific purpose and is not overly complex or redundant, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q57.py,Auto2,0,0.9999921107349486,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q16.py,CallCenter,0,0.9999977396747258,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the standard or expected behavior for `__contains__`, which should typically check for membership in a collection like a list, set, or dictionary. This misuse of `__contains__` is likely to lead to confusion and errors, as it does not align with the conventional use of the method. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q71.py,CatalogSale,1,5.60279640614594e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, this method is likely to be retained as it serves a clear purpose and is implemented correctly."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q98.py,Auto2,0,0.9999417087232136,"The method is implementing the `__contains__` magic method, which is used to define behavior for the `in` keyword. However, the implementation is incorrect because it uses `hasattr`, which checks for the presence of an attribute, not for membership in a collection. Typically, `__contains__` should check if an item is present in a collection, like a list or dictionary, not if an object has an attribute. This misunderstanding of the method's purpose suggests it might be deleted or rewritten to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q84.py,CustomerAddres,1,1.1253518384332553e-07,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be retained because it provides a flexible way to access object properties, which can be particularly useful in dynamic or reflective programming scenarios. It aligns with Python's dynamic nature and is a common pattern in Python code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q10.py,CustomerDemographics,0,0.999983298584886,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, this implementation uses `hasattr`, which checks if an object has an attribute with the given name. This is not the intended use of `__contains__`, as it should be checking membership rather than attribute existence. This misuse of the method's purpose is likely to lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership checks. Therefore, it is likely to be deleted or replaced with a more appropriate implementation."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q43.py,Auto3,0,0.9999898700118929,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical or expected behavior for `__contains__`, which should be used for membership testing in collections like lists, sets, or dictionaries. This misuse of the method could lead to confusion and incorrect behavior when the object is used in contexts expecting standard membership testing. Therefore, it is likely to be deleted or refactored to align with its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q85.py,WebReturn,0,0.999876605372333,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose suggests that it is likely to be deleted or refactored to align with its conventional use."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q19.py,Customer,0,0.9999485577825553,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical or expected behavior for `__contains__`, which is usually used for membership testing in collections like lists, sets, or dictionaries. This misuse of the method could lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership testing. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q29.py,StoreSale,1,7.194132978569833e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the indexing syntax (e.g., obj[key]). In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation, especially in cases where the object is designed to behave like a dictionary or to provide dynamic attribute access. There is no indication that this method is redundant or incorrect, so it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q35.py,DateDim,1,9.931195248674785e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is likely to be retained because it provides a flexible way to access object attributes, which can be particularly useful in dynamic or reflective programming scenarios."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q34.py,DateDim,1,7.194132978569833e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be retained as it serves a clear purpose and is implemented correctly."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q22.py,DateDim,0,0.999964643742472,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to work with collections like lists, sets, or dictionaries. This misuse of the method could lead to confusion and incorrect behavior when the object is used in contexts expecting standard collection behavior. Therefore, it is likely that this method will be deleted or refactored to align with expected behavior."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q53.py,Item,1,7.73442280641062e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a common and useful pattern for dynamic attribute access, especially in cases where the object is used like a dictionary or needs to provide flexible access to its attributes. Therefore, this method is likely to be retained as it provides a useful and standard functionality."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q1.py,StoreReturn,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically retrieve an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method is correctly implemented and serves a clear purpose, it is likely to be retained in the codebase."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q6.py,,1,3.850741907939403e-09,"The method '_key' is a utility function that is likely used internally within a class or module to generate a key for sorting purposes. It takes an iterable 'it', applies a sorting key function from 'opts', and ensures the key is a string if it's a complex data type. This kind of function is common in data processing and sorting operations, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q80.py,StoreSale,1,2.2159489282323004e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q43.py,StoreSale,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a common and useful pattern for dynamic attribute access, especially in cases where the object is used like a dictionary or needs to provide flexible access to its attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q76.py,StoreSale,1,3.3982678079468468e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. It is unlikely to be deleted unless the design of the class changes significantly, as it provides a flexible way to access object attributes. Therefore, the method will likely survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q52.py,StoreSale,1,1.1861120010657661e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method is straightforward, functional, and aligns with Python's design philosophy of allowing objects to behave like built-in types, it is likely to be retained in the code."
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q28.py,_Group,1,2.0611536181902033e-09,"The method is a standard implementation of the __iter__ method in Python, which is used to make an object iterable. It returns an iterator over the 'Items' attribute of the object. This is a common and necessary method for classes that need to support iteration, and there is no indication that it is redundant or incorrect. Therefore, it is likely to be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q63.py,Auto2,0,0.9999910602998366,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q20.py,Auto4,1,2.2159489282323004e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the indexing syntax (e.g., `obj[key]`). In this code, it is implemented to return the attribute of the object with the name specified by `key`. This is a valid and useful implementation, especially in cases where an object is designed to behave like a dictionary or to provide dynamic access to its attributes. Therefore, the method is likely to be retained as it serves a clear purpose and follows Python's conventions for special methods."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q12.py,Auto2,1,6.023574641292144e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a flexible and Pythonic way to access object attributes, it is likely to be retained in the code."
survived,"def _sort_key(k):
    if hasattr(k, ""__dataclass_fields__""):
        return str(k)
    if isinstance(k, list):
        return tuple((_sort_key(x) for x in k))
    if isinstance(k, tuple):
        return tuple((_sort_key(x) for x in k))
    if isinstance(k, dict):
        return str(k)
    return k
",tests/dataset/tpc-ds/compiler/py/q37.py,,1,6.348800075736417e-09,"The method '_sort_key' is a utility function designed to generate a sorting key for various data types, including dataclasses, lists, tuples, and dictionaries. This function is useful for sorting complex data structures, which is a common requirement in many applications. The method is generic and handles multiple data types, making it versatile and reusable. Such utility functions are often retained in codebases because they provide essential functionality that can be used across different parts of a program. Therefore, it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q90.py,HouseholdDemographic,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a flexible and Pythonic way to access object attributes, it is likely to be retained in the code."
survived,"def _sort_key(k):
    if hasattr(k, ""__dataclass_fields__""):
        return str(k)
    if isinstance(k, list):
        return tuple((_sort_key(x) for x in k))
    if isinstance(k, tuple):
        return tuple((_sort_key(x) for x in k))
    if isinstance(k, dict):
        return str(k)
    return k
",tests/dataset/tpc-ds/compiler/py/q52.py,,1,1.522997951276035e-08,"The method `_sort_key` is a utility function designed to generate a consistent sorting key for various data types, including dataclasses, lists, tuples, and dictionaries. This kind of function is useful in scenarios where complex data structures need to be sorted in a predictable manner. The function handles different data types and ensures that they are converted into a form that can be compared and sorted. Such utility functions are often retained in codebases because they provide essential functionality for data manipulation and sorting operations. Therefore, it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q37.py,Auto2,1,3.653482080241728e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for cases where the object is designed to behave like a dictionary or similar container, allowing attribute access via keys. Since this method provides a clear and functional purpose, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q50.py,StoreReturn,0,0.999983298584886,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q29.py,Auto1,1,8.152020648014727e-09,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically retrieve an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be retained as it serves a clear purpose and is implemented correctly."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q77.py,StoreSale,0,0.9999998555019682,"The method is likely to be deleted because it does not implement the expected behavior of the `__contains__` method. In Python, `__contains__` is used to check if a container contains a certain item, typically using the `in` keyword. The current implementation uses `hasattr`, which checks for the presence of an attribute, not an item in a collection. This could lead to confusion and incorrect behavior when the method is used, as it does not align with the standard use case of `__contains__`. Therefore, it is not fulfilling its intended purpose and is likely to be removed or rewritten."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q88.py,Store,0,0.9991959139981964,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in collections like lists or dictionaries. However, in this implementation, it uses `getattr` to access attributes of the object, which is unconventional for `__getitem__`. This could lead to confusion or errors if the object is expected to behave like a collection. Unless the class is specifically designed to map keys to attributes, this method might not be appropriate and could be removed or replaced with a more suitable implementation."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q99.py,Auto2,0,0.999988521231025,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys. However, this implementation uses `hasattr`, which checks if an object has an attribute with the given name. This is not the intended use of `__contains__`, as it should be checking membership in a collection, not attributes of an object. This misuse of the method is likely to lead to confusion and incorrect behavior, especially if the object is expected to behave like a collection. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q53.py,Auto1,0,0.9999785550602307,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q26.py,Item,0,0.9999869928752253,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the typical or expected behavior for `__contains__`, which should check for membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate implementation."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q54.py,Auto3,1,1.955568070542584e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a common and useful pattern for dynamic attribute access, especially in classes that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q40.py,Auto2,0,0.999915188952306,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"def _q0():
    _src = item
    _rows = _query(
        _src,
        [
            {
                ""items"": union_sales,
                ""on"": lambda i, s: (
                    s.get(""item_sk"") if isinstance(s, dict) else getattr(s, ""item_sk"")
                )
                == i.i_item_sk,
            },
            {
                ""items"": time_dim,
                ""on"": lambda i, s, t: t.t_time_sk
                == (s.get(""time_sk"") if isinstance(s, dict) else getattr(s, ""time_sk"")),
            },
        ],
        {
            ""select"": lambda i, s, t: (i, s, t),
            ""where"": lambda i, s, t: i.i_manager_id == 1
            and (t.t_meal_time == ""breakfast"" or t.t_meal_time == ""dinner""),
        },
    )
    _groups = _group_by(
        _rows,
        lambda i, s, t: Auto3(
            brand_id=i.i_brand_id, brand=i.i_brand, t_hour=t.t_hour, t_minute=t.t_minute
        ),
    )
    _items1 = _groups
    _items1 = sorted(
        _items1,
        key=lambda g: _sort_key(
            [
                -_sum(
                    [
                        (
                            x[1].get(""ext_price"")
                            if isinstance(x[1], dict)
                            else getattr(x[1], ""ext_price"")
                        )
                        for x in g
                    ]
                ),
                g.key[""brand_id""],
            ]
        ),
    )
    return [
        Auto1(
            i_brand_id=g.key[""brand_id""],
            i_brand=g.key[""brand""],
            t_hour=g.key[""t_hour""],
            t_minute=g.key[""t_minute""],
            ext_price=_sum(
                [
                    (
                        x[1].get(""ext_price"")
                        if isinstance(x[1], dict)
                        else getattr(x[1], ""ext_price"")
                    )
                    for x in g
                ]
            ),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q71.py,,1,5.60279640614594e-09,"The method '_q0' is a complex query function that seems to be part of a larger data processing or analytics system. It performs operations such as joining data from different sources, filtering based on specific conditions, grouping, and sorting. These operations are common in data analysis tasks, suggesting that the method is likely to be useful in its context. Unless there is a significant change in the requirements or the system architecture, such methods are typically retained for their utility in processing and analyzing data efficiently."
survived,"def test_TPCDS_Q33_simplified():
    assert result == [
        Auto1(i_manufact_id=1, total_sales=150.0),
        Auto1(i_manufact_id=2, total_sales=50.0),
    ]
",tests/dataset/tpc-ds/compiler/py/q33.py,,1,1.1861120010657661e-08,"The method `test_TPCDS_Q33_simplified` is a test function, likely part of a test suite for a larger codebase. Test functions are generally not deleted unless they are redundant, incorrect, or replaced by more comprehensive tests. This function appears to be a straightforward assertion test, checking if the result matches an expected output. Without additional context indicating that this test is obsolete or incorrect, it is reasonable to assume it will survive as it serves a purpose in validating code behavior."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q46.py,HouseholdDemographic,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose suggests that it is likely to be deleted or refactored to align with its conventional use."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q95.py,CustomerAddress,0,0.9999756997690634,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q39.py,Auto2,0,0.9999910602998366,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q95.py,Auto2,0,0.9999869928752253,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q72.py,Inventory,0,0.9999599363048656,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually implemented to check for membership in a collection like a list, set, or dictionary. This misuse of `__contains__` could lead to confusion and unexpected behavior, as it does not align with the standard behavior expected from this method. Therefore, it is likely to be deleted or refactored to better fit its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q78.py,Auto1,0,0.9999980052698925,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    async def async_step_user(self, user_input: dict | None = None) -> FlowResult:
        """"""Handle the initial step.""""""
        if user_input is not None:
            self._data.update(user_input)
            return self.async_create_entry(title=user_input.get(CONF_NAME) or ""Gree Climate"", data=self._data)

        data_schema = vol.Schema(
            {
                vol.Required(CONF_HOST): str,
                vol.Required(CONF_MAC): str,
                vol.Required(CONF_PORT, default=DEFAULT_PORT): int,
                vol.Optional(CONF_NAME): str,
                vol.Optional(CONF_TIMEOUT, default=DEFAULT_TIMEOUT): int,
                vol.Optional(CONF_ENCRYPTION_KEY): str,
                vol.Optional(CONF_UID): int,
                vol.Optional(CONF_ENCRYPTION_VERSION, default=1): int,
            }
        )
        return self.async_show_form(step_id=""user"", data_schema=data_schema)
",custom_components/gree/config_flow.py,ConfigFlow,1,3.850741907939403e-09,"The method 'async_step_user' is part of an asynchronous flow handling process, which is common in modern applications that require non-blocking operations, such as web servers or applications with user interfaces. The method is designed to handle user input, update internal data, and create entries based on that input. It also defines a schema for expected input, which is crucial for validating and processing user data. These functionalities are essential for maintaining a robust and user-friendly application, especially in environments like Home Assistant where user configuration is common. Therefore, the method is likely to be retained as it provides necessary functionality for user interaction and data handling."
survived,"def test_insight_bundle_sri() -> None:
    repo = Path(__file__).resolve().parents[1]
    insight_dir = repo / ""docs"" / ""alpha_agi_insight_v1""
    bundle = insight_dir / ""insight.bundle.js""
    html = insight_dir / ""index.html""

    digest = hashlib.sha384(bundle.read_bytes()).digest()
    expected = ""sha384-"" + base64.b64encode(digest).decode()

    text = html.read_text()
    match = re.search(r""<script[^>]*src=['\""]insight.bundle.js['\""][^>]*>"", text)
    assert match, ""script tag for insight.bundle.js missing""
    sri = re.search(r""integrity=['\""]([^'\""]+)['\""]"", match.group(0))
    assert sri, ""integrity attribute missing""
    assert sri.group(1) == expected",tests/test_insight_sri.py,,1,1.1861120010657661e-08,"The method `test_insight_bundle_sri` is a test function that verifies the Subresource Integrity (SRI) of a JavaScript bundle file. It checks if the integrity attribute in the HTML file matches the expected hash of the bundle file. This is a crucial security feature to ensure that the file has not been tampered with. Given the importance of security in web applications and the fact that this function is a test (indicated by the prefix 'test_'), it is likely to be maintained to ensure the integrity of the application. Therefore, the method is likely to survive."
survived,"    def dispatch_request(self, request: Request) -> Response:
        try:
            return self.run(request=request)
        except HTTPException as e:
            return Response(text=e.reason, status=e.status_code)
",src/graphql_server/webob/views.py,GraphQLView,1,4.944450477491054e-09,"The method 'dispatch_request' is a standard pattern for handling requests and exceptions in web frameworks. It tries to process a request and catches HTTP exceptions to return an appropriate response. This is a common and necessary functionality in web applications, making it unlikely to be deleted."
survived,"    async def _graphql_request(
        self,
        method: Literal[""get"", ""post""],
        query: Optional[str] = None,
        operation_name: Optional[str] = None,
        variables: Optional[dict[str, object]] = None,
        files: Optional[dict[str, BytesIO]] = None,
        headers: Optional[dict[str, str]] = None,
        extensions: Optional[dict[str, Any]] = None,
        **kwargs: Any,
    ) -> ClientResponse:
        body = self._build_body(
            query=query,
            operation_name=operation_name,
            variables=variables,
            files=files,
            method=method,
            extensions=extensions,
        )

        data: Union[dict[str, object], str, None] = None

        url = ""/graphql""

        if body and files:
            body.update({name: (file, name) for name, file in files.items()})

        if method == ""get"":
            body_encoded = urllib.parse.urlencode(body or {})
            url = f""{url}?{body_encoded}""
        else:
            if body:
                data = body if files else json.dumps(body)
            kwargs[""body""] = data

        headers = self._get_headers(method=method, headers=headers, files=files)

        return await self.request(url, method, headers=headers, **kwargs)
",src/tests/http/clients/webob.py,WebobHttpClient,1,3.3982678079468468e-09,"The method '_graphql_request' is a specialized function designed to handle GraphQL requests, supporting both 'get' and 'post' methods, and managing various parameters like query, variables, files, and headers. It is a utility function that abstracts the complexity of making GraphQL requests, which is a common requirement in applications that interact with GraphQL APIs. Given its utility and the increasing adoption of GraphQL, this method is likely to be retained in the codebase as it provides a necessary and efficient way to handle GraphQL requests."
survived,"def sha384(path: Path) -> str:
    digest = hashlib.sha384(path.read_bytes()).digest()
    return ""sha384-"" + base64.b64encode(digest).decode()
",tests/test_sw_integrity.py,,1,7.582560422162384e-10,"The method `sha384` is a utility function that computes the SHA-384 hash of a file's contents and returns it in a base64-encoded format prefixed with 'sha384-'. This is a useful function for verifying file integrity or for caching purposes. It is concise, uses standard libraries, and performs a common task efficiently. There is no indication that this method is redundant or obsolete, so it is likely to be retained."
survived,"    def test_run_with_data_dir(self) -> None:
        data_dir = Path(
            ""alpha_factory_v1/demos/macro_sentinel/offline_samples""
        ).as_posix()
        result = subprocess.run(
            [
                sys.executable,
                ""alpha_factory_v1/demos/era_of_experience/alpha_report.py"",
                ""--data-dir"",
                data_dir,
            ],
            capture_output=True,
            text=True,
        )
        self.assertEqual(result.returncode, 0, result.stderr)
        self.assertIn(""Alpha signals"", result.stdout)
",tests/test_alpha_report_cli.py,TestAlphaReportCLI,1,2.998960815863541e-09,"The method 'test_run_with_data_dir' is a unit test designed to verify the functionality of a script by running it with a specific data directory and checking the output. Unit tests are crucial for ensuring code reliability and are typically maintained as long as the functionality they test is relevant. Since this method is testing a specific feature (running a script with a data directory and checking for expected output), it is likely to be retained unless the feature itself is deprecated or the testing framework changes significantly. Therefore, the method is likely to survive."
survived,"def select_parent_weighted(population: Sequence[Any]) -> Any:
    """"""Return a parent weighted by fitness × children-with-edit-ability.""""""
    if not population:
        raise ValueError(""population is empty"")
    weights = []
    for ind in population:
        fitness = float(getattr(ind, ""fitness"", getattr(ind, ""score"", 0.0)))
        edits = float(getattr(ind, ""edit_children_count"", 0.0))
        weights.append(max(fitness * edits, 0.0))
    total = sum(weights)
    if total <= 0:
        index = int(np.random.choice(len(population)))
    else:
        probs = np.asarray(weights, dtype=float) / total
        index = int(np.random.choice(len(population), p=probs))
    metrics.dgm_parents_selected_total.inc()
    return population[index]
",src/archive/selector.py,,1,1.2501528648238603e-09,"The method 'select_parent_weighted' is a utility function that selects an individual from a population based on a weighted probability. It is a common pattern in genetic algorithms and evolutionary computation to select parents for the next generation based on their fitness and other attributes. The method is well-defined, handles edge cases (like an empty population or zero total weight), and uses numpy for efficient random choice operations. These factors make it a useful and likely retained function in any system that involves evolutionary algorithms or similar processes."
survived,"def _safe_extract(tf: tarfile.TarFile, target_dir: Path) -> None:
    """"""Safely extract tar members inside ``target_dir``.""""""
    base = target_dir.resolve()
    for member in tf.getmembers():
        dest = (base / member.name).resolve()
        if not str(dest).startswith(str(base)):
            raise HTTPException(status_code=400, detail=""Unsafe path in archive"")
    tf.extractall(base)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/evolution_worker.py,,1,5.60279640614594e-09,"The method '_safe_extract' is designed to safely extract files from a tar archive, ensuring that the files are extracted within a specified directory and preventing path traversal attacks. This is a crucial security feature when dealing with file extractions, especially from untrusted sources. The method checks if the resolved path of each file to be extracted starts with the base directory path, and raises an exception if it doesn't, thus preventing potential security vulnerabilities. Given the importance of security in file handling, this method is likely to be retained in the codebase."
survived,"def fix_file(path: str):
    with open(path, 'r', encoding='utf-8') as f:
        lines = f.readlines()

    in_code = False
    changed = False

    for i, line in enumerate(lines):
        stripped = line.strip()
        if stripped.startswith('```') or stripped.startswith('~~~'):
            in_code = not in_code
            continue
        if not in_code and line.startswith('# '):
            title = line[2:].rstrip('\n')
            new_title = title_case(title)
            if new_title != title:
                lines[i] = '# ' + new_title + '\n'
                changed = True
            break

    if changed:
        with open(path, 'w', encoding='utf-8') as f:
            f.writelines(lines)
        print(f'Updated {path}')
",scripts/fix_titlecase.py,,1,3.581747929000289e-10,"The method 'fix_file' is likely to survive because it performs a useful function of reading a file, checking for specific conditions, and updating the file if necessary. It handles text processing, which is a common requirement in many applications. The method is also well-structured, with clear logic for toggling code blocks and updating titles. Additionally, it provides feedback by printing a message when a file is updated, which is helpful for users. These factors make it a valuable utility function that is likely to be retained."
survived,"def makeAdder(n):
    def adder(x):
        return x + n
    return adder
",tests/human/python/closure.py,,1,9.237449576640118e-09,"The method 'makeAdder' is a higher-order function that returns a closure. It is a useful and common pattern in functional programming, allowing the creation of customized functions on the fly. This method is likely to be retained because it provides a flexible way to generate functions that add a specific number to their input, which can be very useful in various programming scenarios. The concept of closures is fundamental in many programming languages, and this implementation is a clear and concise example of it."
survived,"    def adder(x):
        return x + n
",tests/human/x/python/closure.py,,0,0.9999999950555496,"The method 'adder' is likely to be deleted because it references a variable 'n' that is not defined within the function or passed as a parameter. This will result in a NameError when the function is called, making it non-functional in its current state. Without additional context or modifications to include 'n' as a parameter or define it within the function, the method is not useful."
survived,"def test_taxonomy_mine_and_prune(tmp_path: Path) -> None:
    js_out = tmp_path / 'taxonomy.js'
    subprocess.run([
        'tsc', '--target', 'es2020', '--module', 'es2020', TAXONOMY_TS, '--outFile', js_out
    ], check=True)

    script = tmp_path / 'run.mjs'
    script.write_text(
        f""import {{ mineTaxonomy, pruneTaxonomy }} from '{js_out.resolve().as_posix()}';\n""
        ""const runs = [\n""
        ""  {params:{sector:'A'}},\n""
        ""  {params:{sector:'B'}},\n""
        ""  {params:{sector:'A'}}\n""
        ""];\n""
        ""let g = mineTaxonomy(runs);\n""
        ""g = pruneTaxonomy(g, new Set(['A']));\n""
        ""console.log(JSON.stringify(g));\n""
    )
    result = subprocess.run(['node', script], capture_output=True, text=True, check=True)
    data = json.loads(result.stdout)
    assert set(data['nodes'].keys()) == {'A'}",tests/test_taxonomy.py,,1,8.592166611791576e-10,"The method `test_taxonomy_mine_and_prune` is a test function that verifies the functionality of the `mineTaxonomy` and `pruneTaxonomy` methods. Test functions are generally crucial for ensuring code reliability and correctness, especially in a development environment where changes are frequent. This function is likely part of a test suite that ensures the taxonomy mining and pruning logic works as expected. Since testing is a fundamental part of software development and maintenance, it is unlikely that this method will be deleted unless the entire feature it tests is removed or significantly refactored. Therefore, the method will likely survive."
survived,"def test_pareto_entropy(tmp_path: Path) -> None:
    js_out = tmp_path / ""entropy.js""
    subprocess.run([
        ""tsc"",
        ""--target"",
        ""es2020"",
        ""--module"",
        ""es2020"",
        ENTROPY_TS,
        ""--outFile"",
        js_out,
    ], check=True)

    script = tmp_path / ""run.mjs""
    script.write_text(
        f""import {{ paretoEntropy }} from '{js_out.resolve().as_posix()}';\n""
        ""const pts = [{logic:0.1,feasible:0.1},{logic:0.9,feasible:0.9}];\n""
        ""console.log(paretoEntropy(pts,2).toFixed(2));\n"",
        encoding=""utf-8"",
    )
    res = subprocess.run([""node"", script], capture_output=True, text=True, check=True)
    assert res.stdout.strip() == ""1.00""",tests/test_entropy_ts.py,,1,5.905303995456778e-10,"The method `test_pareto_entropy` is a test function that verifies the functionality of a TypeScript module by compiling it to JavaScript and executing it with Node.js. This kind of test is crucial for ensuring that the TypeScript code behaves as expected when transpiled and run in a JavaScript environment. The method is likely to survive because it serves an important role in the development process by providing automated testing, which is a best practice in software development. Automated tests help catch errors early and ensure code reliability, making them valuable for maintaining code quality."
survived,"                def patched_curl_request(session_self, method, url, *a, **kw):
                    if self._proxies and 'proxies' not in kw:
                        kw['proxies'] = self._proxies
                    return self._original_curl_session_request(session_self, method, url, *a, **kw)
",webscout/Provider/TTI/base.py,_GlobalProxyManager,0,0.9999999895325983,"The method 'patched_curl_request' is likely to be deleted (0) because it contains a reference to 'self', which is not defined within the method's scope. This indicates a potential error or oversight in the code, as 'self' is typically used within class methods to refer to instance attributes. Without proper context or definition of 'self', the method cannot function correctly, leading to its potential removal or refactoring."
survived,"        def get_proxied_curl_session(impersonate=""chrome120"", **kw):
            if CurlSession:
                return CurlSession(proxies=proxies, impersonate=impersonate, **kw)
            raise ImportError(""curl_cffi is not installed"")
",webscout/Provider/TTI/base.py,ProxyAutoMeta,1,1.4166087846364157e-09,"The method 'get_proxied_curl_session' is likely to survive because it provides a useful functionality by creating a curl session with proxy and impersonation capabilities. This is a common requirement in web scraping and automation tasks where bypassing restrictions and simulating different browsers is necessary. The method also includes error handling for missing dependencies, which is a good practice."
survived,"def is_linux():
    return platform.system() == 'Linux'
",build.py,,1,6.348800075736417e-09,The method is simple and serves a clear purpose: to check if the operating system is Linux. This is a common utility function that can be useful in cross-platform applications where behavior might need to change based on the operating system. It is unlikely to be deleted unless it is replaced by a more comprehensive solution or becomes redundant due to changes in the codebase or project requirements.
survived,"    def tearDown(self) -> None:
        AGENT_REGISTRY.clear()
        AGENT_REGISTRY.update(self._backup)
",tests/test_demo_registration.py,TestRegisterDemoAgents,1,3.927863699585036e-07,"The method `tearDown` is a common method used in unit testing frameworks like `unittest` in Python. It is typically used to clean up or reset the state after each test case is run. The presence of `tearDown` suggests that this code is part of a test suite, and the operations it performs (clearing and updating a registry) are consistent with resetting state for tests. Such methods are generally essential for maintaining test isolation and ensuring that tests do not interfere with each other. Therefore, it is unlikely to be deleted as it serves a crucial role in the testing process."
survived,"    def test_future_regressor_alignment(self):
        forecast_length = 5
        df = load_daily(long=False).iloc[:50]
        df = df.drop(df.index[5])
        reg_df = df[[df.columns[0]]].copy()
        reg_train, _ = create_lagged_regressor(
            reg_df,
            forecast_length=forecast_length,
            frequency='infer',
            scale=False,
            summarize=None,
            backfill='bfill',
            fill_na='pchip',
        )
        reg_train = reg_train.iloc[forecast_length:]
        df_train = df.iloc[forecast_length:]
        model = AutoTS(
            forecast_length=forecast_length,
            max_generations=1,
            num_validations=1,
            validation_method='backwards',
            model_list=['LastValueNaive'],
            transformer_list=[],
            verbose=0,
        )
        model = model.fit(df_train, future_regressor=reg_train)
        self.assertEqual(
            model.future_regressor_train.shape[0],
            model.df_wide_numeric.shape[0],
        )",tests/test_regressor.py,FutureRegressorAlignmentTest,1,8.152020648014727e-09,"The method `test_future_regressor_alignment` is a unit test that checks the alignment of the future regressor with the training data in a time series forecasting model. Unit tests are crucial for ensuring code correctness and reliability, especially in data science and machine learning projects where data alignment is critical. The method is likely to be maintained as it serves an important role in verifying the functionality of the `AutoTS` model's handling of future regressors. Additionally, the method is concise and directly tests a specific functionality, which is a good practice in software development."
survived,"    def run_tests(self, path: Path, timeout: int = 60) -> ExecutionResult:
        """"""Execute tests located at ``path`` inside the sandbox.""""""
        exit_code, stdout, stderr = self.sandbox_manager.run_code_in_sandbox(
            code_directory=path,
            command=[""pytest"", ""-vv""],
            timeout=timeout,
        )
        return ExecutionResult(exit_code=exit_code, stdout=stdout, stderr=stderr)",src/meta_agent/evaluation/execution.py,ExecutionModule,1,4.599055376537186e-10,"The method 'run_tests' is a utility function that executes tests in a sandbox environment using pytest. It is a straightforward and useful method for running tests with a specified timeout, capturing the exit code, stdout, and stderr. Such functionality is essential in automated testing environments, especially when dealing with code that needs to be isolated for security or stability reasons. The method is well-defined, serves a clear purpose, and is likely to be used frequently in testing scenarios. Therefore, it is unlikely to be deleted."
survived,"def test_skip_backup_when_local_has_no_space(tmp_path):
    db_path = tmp_path / ""db.sqlite""
    config[""storage""][""database""] = str(db_path)

    conn = sqlite3.connect(db_path)
    conn.execute(""CREATE TABLE t(id INTEGER)"")
    conn.commit()
    conn.close()

    output = tmp_path / ""backup.sqlite""

    with (
        patch(
            ""pioreactor.actions.leader.backup_database.long_running_managed_lifecycle"",
            dummy_lifecycle,
        ),
        patch(
            ""pioreactor.actions.leader.backup_database.create_logger"",
            return_value=MagicMock(),
        ),
        patch(
            ""pioreactor.actions.leader.backup_database._local_available_space"",
            return_value=0,
        ),
        patch(
            ""sqlite3.connect"",
        ) as mock_connect,
    ):
        backup_database(str(output), force=True, backup_to_workers=0)
        mock_connect.assert_not_called()",pioreactor/tests/test_backup_database.py,,1,1.275190675769241e-07,"The method is a test function that checks if the backup process is skipped when there is no local space available. It uses mocking to simulate the environment and conditions for the test. Such test functions are crucial for ensuring the robustness of the code, especially in handling edge cases. Therefore, it is likely to be retained as part of the test suite to ensure the software behaves correctly under these conditions."
survived,"def test_unsubscribe_stops_delivery():
    asyncio.run(_run_unsubscribe())",tests/test_trace_hub.py,,1,8.76424914819242e-08,"The method `test_unsubscribe_stops_delivery` is a test function, likely part of a test suite for a larger application. Test functions are generally not deleted unless they are redundant, incorrect, or the functionality they test is no longer relevant. Since the function name suggests it tests the unsubscribe functionality, which is a common feature in applications, it is likely still relevant and necessary for ensuring the application behaves correctly. Therefore, it is more likely to be maintained rather than deleted."
survived,"async def _async_fn(x):
    await asyncio.sleep(0)
    return x * 2
",tests/test_agent_runner_utils.py,,1,1.275190675769241e-07,"The method is a simple asynchronous function that uses asyncio to sleep for a negligible amount of time (0 seconds) and then returns the input value multiplied by 2. This function is syntactically correct and demonstrates a basic use of async/await in Python, which is a common pattern for handling asynchronous operations. There is no indication of any issues or reasons for this method to be deleted, as it serves a valid purpose in demonstrating asynchronous behavior."
survived,"    async def _run_output_guardrails(
        cls,
        guardrails: list[OutputGuardrail[TContext]],
        agent: Agent[TContext],
        agent_output: Any,
        context: RunContextWrapper[TContext],
    ) -> list[OutputGuardrailResult]:
        if not guardrails:
            return []

        guardrail_tasks = [
            asyncio.create_task(
                RunImpl.run_single_output_guardrail(guardrail, agent, agent_output, context)
            )
            for guardrail in guardrails
        ]

        guardrail_results = []

        for done in asyncio.as_completed(guardrail_tasks):
            result = await done
            if result.output.tripwire_triggered:
                # Cancel all guardrail tasks if a tripwire is triggered.
                for t in guardrail_tasks:
                    t.cancel()
                _error_tracing.attach_error_to_current_span(
                    SpanError(
                        message=""Guardrail tripwire triggered"",
                        data={""guardrail"": result.guardrail.get_name()},
                    )
                )
                raise OutputGuardrailTripwireTriggered(result)
            else:
                guardrail_results.append(result)

        return guardrail_results
",src/agents/run.py,DefaultAgentRunner,1,2.646573631904765e-09,"The method '_run_output_guardrails' is a well-structured asynchronous function that handles a list of guardrails, processes them concurrently, and manages errors effectively. It uses asyncio to run tasks concurrently, which is a modern and efficient approach in Python for I/O-bound operations. The method also includes error handling by checking for a 'tripwire' condition and cancelling tasks if necessary, which is a robust way to handle potential issues during execution. These characteristics make the method useful and relevant for scenarios where output needs to be validated or checked against certain conditions. Therefore, it is likely to be retained in the codebase."
survived,"    async def policy(self, obs, ctx):  # type: ignore[override]
        if isinstance(obs, dict):
            action = obs.get(""action"")
            if action == ""discover"":
                return await self.tools.discover(obs.get(""num"", 1))
            if action == ""recent"":
                return await self.tools.recent_log(obs.get(""limit"", 5))
        return await self.tools.list_samples()
",alpha_factory_v1/demos/cross_industry_alpha_factory/openai_agents_bridge.py,CrossIndustryAgent,1,3.2241866333029355e-08,"The method 'policy' is an asynchronous function that handles different actions based on the input observation. It checks if the observation is a dictionary and then performs actions like 'discover' or 'recent' using the 'tools' object. This method is likely to survive because it is well-structured, handles different cases, and uses asynchronous programming, which is beneficial for performance in I/O-bound operations. Additionally, it provides default values for 'num' and 'limit', making it robust against missing data."
survived,"def main() -> None:
    try:
        check_env.main([""--auto-install""])
    except Exception as exc:  # pragma: no cover - optional network failure
        print(f""⚠️  Environment check failed: {exc}"")

    env = os.environ.copy()
    port = env.get(""PORT"", ""8000"")
    cmd = [sys.executable, ""run_business_v1_local.py"", ""--bridge""]
    proc = subprocess.Popen(cmd, cwd=SCRIPT_DIR, env=env)

    url = f""http://localhost:{port}/docs""
    for _ in range(20):
        if proc.poll() is not None:
            break
        try:
            import requests

            if requests.get(f""http://localhost:{port}/healthz"", timeout=1).status_code == 200:
                break
        except Exception:
            time.sleep(0.5)
    try:
        webbrowser.open(url, new=1)
    except Exception:
        print(f""Open {url} to access the dashboard"")
    try:
        proc.wait()
    except KeyboardInterrupt:
        proc.terminate()
        proc.wait()
",alpha_factory_v1/demos/alpha_agi_business_v1/start_alpha_business.py,,1,1.8189616842444243e-09,"The method 'main' is a complete and functional script that sets up an environment, runs a subprocess, checks for a service's health, and attempts to open a web browser to a specific URL. It includes error handling for network failures and user interruptions, making it robust and useful for its intended purpose. There is no indication that this method is deprecated or redundant, and it appears to be a critical part of a larger application. Therefore, it is likely to be retained in the codebase."
survived,"def test_agent_macro_entrypoint_custom_base_url(monkeypatch: pytest.MonkeyPatch) -> None:
    stub = ModuleType(""openai_agents"")
    captured = {}

    class DummyOpenAI:
        def __init__(self, *a, **kw) -> None:
            captured[""base_url""] = kw.get(""base_url"")

    stub.Agent = object
    stub.OpenAIAgent = DummyOpenAI
    stub.Tool = lambda *_a, **_k: (lambda f: f)
    monkeypatch.setitem(sys.modules, ""openai_agents"", stub)
    monkeypatch.setenv(""OPENAI_API_KEY"", """")
    monkeypatch.setenv(""OLLAMA_BASE_URL"", ""http://example.com/v1"")

    mod_path = ""alpha_factory_v1.demos.macro_sentinel.agent_macro_entrypoint""
    sys.modules.pop(mod_path, None)

    with patch(f""{mod_path}._check_ollama""):
        importlib.import_module(mod_path)

    assert captured[""base_url""] == ""http://example.com/v1""",tests/test_macro_agent_base_url.py,,1,4.6911638017642294e-08,"The method is a test function that uses monkeypatching to test the behavior of a module when a custom base URL is set. It is a specific test case that ensures the correct base URL is captured and used, which is important for testing the integration with external services. Such test functions are typically retained as they are crucial for maintaining the reliability and correctness of the codebase."
survived,"def test_relative_links_converted(tmp_path, monkeypatch):
    repo = tmp_path
    demo = repo / ""alpha_factory_v1"" / ""demos"" / ""demo_b""
    demo.mkdir(parents=True)
    (demo / ""colab_demo.ipynb"").write_text(""data"", encoding=""utf-8"")
    (demo / ""assets"").mkdir()
    (demo / ""assets"" / ""graph.png"").write_text(""img"", encoding=""utf-8"")

    readme = (
        ""# Demo B\n""
        ""See [Guide](../../../docs/OFFLINE_SETUP.md).\n""
        ""Open [Notebook](colab_demo.ipynb).\n""
        ""![shot](assets/graph.png)\n""
    )
    (demo / ""README.md"").write_text(readme, encoding=""utf-8"")

    assets = repo / ""docs"" / ""demo_b"" / ""assets""
    assets.mkdir(parents=True)
    (assets / ""preview.png"").write_text(""data"", encoding=""utf-8"")
    docs_demos = repo / ""docs"" / ""demos""

    monkeypatch.setattr(gdd, ""REPO_ROOT"", repo)
    monkeypatch.setattr(gdd, ""DEMOS_DIR"", repo / ""alpha_factory_v1"" / ""demos"")
    monkeypatch.setattr(gdd, ""DOCS_DIR"", docs_demos)

    gdd.generate_docs()

    page = docs_demos / ""demo_b.md""
    text = page.read_text(encoding=""utf-8"")
    base = ""https://github.com/MontrealAI/AGI-Alpha-Agent-v0/blob/main/""
    assert f""[Notebook]({base}alpha_factory_v1/demos/demo_b/colab_demo.ipynb)"" in text
    assert f""![shot]({base}alpha_factory_v1/demos/demo_b/assets/graph.png)"" in text",tests/test_generate_demo_docs.py,,1,2.2159489282323004e-08,"The method `test_relative_links_converted` is a test function that verifies the conversion of relative links in a documentation generation process. It uses `monkeypatch` to modify the environment and checks if the generated documentation contains the correct absolute links. This is a typical use case in testing environments to ensure that documentation links are correctly formatted, which is crucial for maintaining the integrity of documentation in projects. Since it serves a clear purpose in testing the functionality of link conversion, it is likely to be retained."
survived,"        def start_merkle_task(self, *_a, **_kw) -> None:
            pass
",tests/test_orchestrator.py,DummyLedger,0,0.9999984465026855,"The method `start_merkle_task` is defined but not implemented, as it only contains a `pass` statement. This suggests that it might be a placeholder for future functionality. However, without any implementation or usage context, it is difficult to justify its retention. If it remains unused and unimplemented, it is likely to be deleted in future code clean-ups to maintain codebase quality."
survived,"        def vstack(self, arrays):
            out: list[list[float]] = []
            for arr in arrays:
                out.extend(arr)
            return out
",alpha_factory_v1/backend/memory_vector.py,_SimpleNP,1,2.8453347280241004e-08,"The method 'vstack' is a simple utility function that takes a list of lists (arrays) and flattens them into a single list. This is a common operation in data processing and manipulation, especially in numerical computing contexts. The method is straightforward, performs a useful task, and does not have any apparent issues or inefficiencies that would warrant its deletion. Therefore, it is likely to be retained."
survived,"async def test_pending_safety_check_acknowledged() -> None:
    """"""Safety checks should be acknowledged via the callback.""""""

    computer = LoggingComputer(screenshot_return=""img"")
    called: list[ComputerToolSafetyCheckData] = []

    def on_sc(data: ComputerToolSafetyCheckData) -> bool:
        called.append(data)
        return True

    tool = ComputerTool(computer=computer, on_safety_check=on_sc)
    safety = PendingSafetyCheck(id=""sc"", code=""c"", message=""m"")
    tool_call = ResponseComputerToolCall(
        id=""t1"",
        type=""computer_call"",
        action=ActionClick(type=""click"", x=1, y=1, button=""left""),
        call_id=""t1"",
        pending_safety_checks=[safety],
        status=""completed"",
    )
    run_action = ToolRunComputerAction(tool_call=tool_call, computer_tool=tool)
    agent = Agent(name=""a"", tools=[tool])
    ctx = RunContextWrapper(context=None)

    results = await RunImpl.execute_computer_actions(
        agent=agent,
        actions=[run_action],
        hooks=RunHooks[Any](),
        context_wrapper=ctx,
        config=RunConfig(),
    )

    assert len(results) == 1
    raw = results[0].raw_item
    assert isinstance(raw, dict)
    assert raw.get(""acknowledged_safety_checks"") == [{""id"": ""sc"", ""code"": ""c"", ""message"": ""m""}]
    assert len(called) == 1
    assert called[0].safety_check.id == ""sc""",tests/test_computer_action.py,,1,3.466327708641819e-07,"The method is a test function that verifies the functionality of acknowledging safety checks via a callback. Test functions are generally not deleted unless they are redundant or the functionality they test is removed. Since this test is specific to a feature (safety checks acknowledgment) that is likely important for the system's integrity and safety, it is unlikely to be removed unless the feature itself is deprecated."
survived,"async def api_frame_assets_rename(
    id: int,
    src: str = Form(...),
    dst: str = Form(...),
    db: Session = Depends(get_db),
    redis: Redis = Depends(get_redis),
):
    frame = db.get(Frame, id) or _not_found()

    s_rel = src.lstrip(""/"")
    d_rel = dst.lstrip(""/"")
    if any(x in s_rel for x in ["".."", ""*""]) or os.path.isabs(s_rel):
        _bad_request(""Invalid source path"")
    if any(x in d_rel for x in ["".."", ""*""]) or os.path.isabs(d_rel):
        _bad_request(""Invalid destination path"")

    assets_path = frame.assets_path or ""/srv/assets""
    src_full = os.path.normpath(os.path.join(assets_path, s_rel))
    dst_full = os.path.normpath(os.path.join(assets_path, d_rel))
    if not src_full.startswith(
        os.path.normpath(assets_path)
    ) or not dst_full.startswith(os.path.normpath(assets_path)):
        _bad_request(""Invalid asset path"")

    await rename_path(db, redis, frame, src_full, dst_full)
    return {""message"": ""Renamed""}
",backend/app/api/frames.py,,1,9.736200303530205e-10,"The method 'api_frame_assets_rename' is likely to survive because it performs a critical function of renaming assets within a specified path, ensuring security by validating paths to prevent directory traversal attacks. It uses dependency injection for database and Redis connections, which is a modern and efficient approach. The method is asynchronous, aligning with current best practices for handling I/O operations in web applications. These factors suggest it is a well-structured and necessary part of the application."
survived,"    def render() -> None:
        data = [(r.agent.name,) for r in orch.runners.values()]
        _rich_table([""agent""], data)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/cli.py,,1,1.955568070542584e-08,"The method 'render' is a simple utility function that creates a table with agent names using a helper function '_rich_table'. It is likely part of a larger system for displaying or logging information. The method is straightforward, performs a specific task, and does not have any apparent issues or redundancies. Therefore, it is likely to be retained as it serves a clear purpose in the codebase."
survived,"def test_simulate_export_csv() -> None:
    runner = CliRunner()
    with patch.object(cli, ""asyncio""):
        with patch.object(cli.orchestrator, ""Orchestrator""):
            res = runner.invoke(
                cli.main,
                [
                    ""simulate"",
                    ""--horizon"",
                    ""1"",
                    ""--offline"",
                    ""--pop-size"",
                    ""1"",
                    ""--generations"",
                    ""1"",
                    ""--export"",
                    ""csv"",
                ],
            )
    assert res.exit_code == 0
    assert ""year,capability,affected"" in res.output",tests/test_cli.py,,1,1.2501528648238603e-09,"The method 'test_simulate_export_csv' is a unit test designed to verify the functionality of a command-line interface (CLI) command. It uses the 'CliRunner' to simulate running the CLI command and checks if the output is as expected. The test is well-structured, uses mocking to isolate the test from external dependencies, and includes assertions to validate the output. These are all good practices in software testing, making it likely that this method will be retained in the codebase to ensure the CLI command works correctly."
survived,"def test_slash_on_forged_ledger(tmp_path, monkeypatch) -> None:
    settings = config.Settings(bus_port=0, ledger_path=str(tmp_path / ""ledger.db""))
    monkeypatch.setattr(orchestrator.Orchestrator, ""_init_agents"", lambda self: [])
    orch = orchestrator.Orchestrator(settings)
    orch.registry.set_stake(""A"", 100)
    original_root = orch.ledger.compute_merkle_root()
    env = messaging.Envelope(""A"", ""b"", {""v"": 1}, 0.0)
    orch.ledger.log(env)
    orch.verify_merkle_root(original_root, ""A"")
    assert orch.registry.stakes[""A""] == 90",tests/test_slash_e2e.py,,1,8.76424914819242e-08,"The method 'test_slash_on_forged_ledger' is a unit test function, which is typically used to verify the behavior of a specific piece of code. Unit tests are crucial for ensuring code reliability and are generally not deleted unless they are redundant or replaced by more comprehensive tests. This test seems to be checking the functionality of slashing a stake when a forged ledger is detected, which is an important aspect of the system's security. Therefore, it is likely to be retained."
survived,"def _changed_files(diff: str) -> list[str]:
    files: set[str] = set()
    for line in diff.splitlines():
        if line.startswith(""+++"") or line.startswith(""---""):
            parts = line.split(maxsplit=1)
            if len(parts) != 2:
                continue
            path = parts[1]
            if path.startswith(""a/"") or path.startswith(""b/""):
                path = path[2:]
            files.add(path)
    return list(files)
",src/utils/patch_guard.py,,1,3.581747929000289e-10,"The method '_changed_files' is a utility function that processes a diff string to extract a list of changed files. This is a common requirement in version control systems and code review tools, where understanding which files have been modified is crucial. The method is well-defined, using clear logic to parse the diff and handle edge cases like paths starting with 'a/' or 'b/'. It returns a list of unique file paths, which is a useful output for further processing. Given its utility and clear implementation, it is likely to be retained in the codebase."
survived,"def test_rejects_empty_diff() -> None:
    assert not is_patch_valid("""")
",tests/test_patch_guard.py,,1,3.160881453314576e-10,"The method 'test_rejects_empty_diff' is a unit test that checks if the function 'is_patch_valid' correctly identifies an empty string as an invalid patch. This is a common and useful test case to ensure that the function handles edge cases properly. Unit tests are generally retained in codebases to ensure functionality remains correct as the code evolves. Therefore, this method is likely to be Survived."
survived,"    def _ensure(self) -> None:
        with sqlite3.connect(self.path) as cx:
            cx.execute(
                ""CREATE TABLE IF NOT EXISTS agents(""
                ""id INTEGER PRIMARY KEY AUTOINCREMENT,""
                ""meta TEXT,""
                ""score REAL""
                "")""
            )
",src/archive/__init__.py,Archive,1,1.0467401685178159e-08,"The method `_ensure` is responsible for ensuring that a specific table exists in a SQLite database. It uses a common pattern of connecting to the database and executing a SQL command to create the table if it does not already exist. This is a fundamental operation in database management, ensuring that the necessary schema is in place before performing further operations. Such methods are typically retained because they encapsulate essential setup logic that is reused across different parts of an application. Therefore, it is likely to survive."
survived,"    def sample(self, k: int, *, lam: float = 10.0, alpha0: float = 0.5) -> List[Agent]:
        agents = self.all()
        if not agents:
            return []
        weights = [1.0 / (1.0 + math.exp(-lam * (a.score - alpha0))) for a in agents]
        chosen = random.choices(agents, weights=weights, k=min(k, len(agents)))
        return chosen
",src/archive/__init__.py,Archive,1,4.0586521248284276e-10,"The method 'sample' is a well-defined function that performs a specific task of selecting a subset of agents based on a weighted random choice. It uses parameters to adjust the behavior of the selection process, which makes it flexible and potentially useful in various contexts. The method is likely to be part of a larger system where agent selection is necessary, such as simulations or decision-making processes. Its use of mathematical functions to calculate weights based on agent scores suggests it is designed for nuanced selection, which is a common requirement in many applications. Therefore, it is likely to be retained."
survived,"    def fake_run(*args, **kwargs):
        raise subprocess.TimeoutExpired(cmd=args[0], timeout=120)
",tests/test_secure_run.py,,1,1.275190675769241e-07,"The method `fake_run` is designed to simulate a timeout exception by raising `subprocess.TimeoutExpired`. This can be useful for testing purposes, especially when you want to ensure that your code correctly handles timeout scenarios without actually waiting for a real timeout to occur. Such utility functions are often kept in codebases for testing and debugging purposes, as they provide a controlled way to simulate and test error handling. Therefore, it is likely to be retained in the codebase."
survived,"def _load_entries(db_path: Path) -> List[ArchiveEntry]:
    """"""Return all archive entries.""""""
    with sqlite3.connect(db_path) as cx:
        rows = list(
            cx.execute(
                ""SELECT hash, parent, score, novelty, is_live, ts FROM archive""
            )
        )
    return [
        ArchiveEntry(
            hash=r[0],
            parent=r[1],
            score=float(r[2]),
            novelty=float(r[3]),
            is_live=bool(r[4]),
            ts=float(r[5]),
        )
        for r in rows
    ]
",src/tools/analyse_backtrack.py,,1,1.8189616842444243e-09,"The method '_load_entries' is a utility function that loads data from a database and returns it as a list of 'ArchiveEntry' objects. It is a straightforward and efficient way to retrieve and transform data from a database table into a usable format in the application. Such methods are typically essential for data handling and are unlikely to be removed unless there is a significant change in how data is managed or accessed in the application. Therefore, it is more likely to survive."
survived,"def test_invalid_resources(monkeypatch, tmp_path):
    fake_client = MagicMock()
    fake_client.ping.return_value = None
    monkeypatch.setattr(sm.docker, ""from_env"", lambda: fake_client)
    manager = SandboxManager()
    code_dir = tmp_path / ""code""
    code_dir.mkdir()
    with pytest.raises(ValueError):
        manager.run_code_in_sandbox(code_dir, [""python""], cpu_shares=-1)
",tests/unit/test_sandbox_manager.py,,1,5.905303995456778e-10,"The method 'test_invalid_resources' is a unit test designed to verify that the 'run_code_in_sandbox' function raises a ValueError when provided with invalid CPU shares. This is a valid and useful test case to ensure the robustness of the 'run_code_in_sandbox' function against invalid input. Unit tests are generally not deleted unless they are redundant or incorrect, and this test appears to be neither. Therefore, it is likely to survive."
survived,"    def __init__(
        self,
        name: str = ""LitLogger"",
        level: LogLevel = LogLevel.INFO,
        handlers: Optional[List[Handler]] = None,
        fmt: str = DEFAULT,
        async_mode: bool = False,
    ):
        self.name = name
        self.level = level
        self.format = fmt
        self.async_mode = async_mode
        self.handlers = handlers or [ConsoleHandler()]
",webscout/litlogger/logger.py,Logger,1,1.6052280526088547e-09,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class with specific attributes. It sets default values for parameters and allows customization when creating an object. Constructors are fundamental to object-oriented programming and are rarely deleted unless the class itself is being removed or significantly refactored. Therefore, this method is likely to survive."
survived,"    def _rotate(self):
        if self.backups <= 0:
            self._file.close()
            self.path.unlink(missing_ok=True)
            self._open()
            return
        self._file.close()
        for i in range(self.backups, 0, -1):
            src = self.path.with_suffix(f"".{i}"") if i == 1 else self.path.with_suffix(f"".{i-1}"")
            dst = self.path.with_suffix(f"".{i}"")
            if src.exists():
                if dst.exists():
                    dst.unlink()
                src.rename(dst)
        self._open()
",webscout/litlogger/handlers.py,FileHandler,1,1.725782769012759e-08,"The method '_rotate' is a utility function that handles file rotation, which is a common requirement in logging systems to manage file sizes and backups. It checks the number of backups, closes the current file, and renames existing backup files to maintain a sequence. This functionality is essential for managing log files efficiently, preventing them from growing indefinitely and consuming excessive disk space. Given its utility and the fact that it is a private method (indicated by the underscore), it is likely to be retained as part of the internal workings of a logging or file management system."
survived,"    def emit(self, message: str, level: LogLevel):
        color = LEVEL_COLORS.get(level, """")
        self.stream.write(f""{color}{message}{RESET}\n"")
        self.stream.flush()
",webscout/litlogger/handlers.py,ConsoleHandler,1,4.0586521248284276e-10,"The method 'emit' is a straightforward logging function that writes a message to a stream with a specific color based on the log level. This is a common and useful functionality in logging systems, allowing for easy identification of log levels through color coding. The method is simple, effective, and does not have any apparent issues or redundancies that would warrant its removal. Therefore, it is likely to be retained in the codebase."
survived,"        async def __call__(self, _text: str) -> str:  # pragma: no cover - stub
            return ""ok""
",alpha_factory_v1/demos/aiga_meta_evolution/openai_agents_bridge.py,OpenAIAgent,1,3.466327708641819e-07,"The method is a simple asynchronous callable that returns a fixed string ""ok"". It is marked with a pragma to exclude it from coverage analysis, indicating it might be a placeholder or stub for future implementation. However, the method itself is functional and could be useful in contexts where an asynchronous callable is required. Without further context on its usage or the surrounding code, it's reasonable to assume it will survive as it provides a basic, yet valid, functionality."
survived,"def _pkg_installed(pkg: str) -> bool:
    """"""Return ``True`` when ``pkg`` is installed.

    The check uses ``python -m pip show`` for reliability when namespace
    packages are involved.
    """"""

    result = subprocess.run(
        [sys.executable, ""-m"", ""pip"", ""show"", pkg],
        stdout=subprocess.DEVNULL,
        stderr=subprocess.DEVNULL,
    )
    return result.returncode == 0
",scripts/check_python_deps.py,,1,7.582560422162384e-10,"The method `_pkg_installed` is a utility function that checks if a Python package is installed using `pip show`. This is a common requirement in many Python applications to ensure dependencies are available before proceeding with certain operations. The method is straightforward, uses standard library modules (`subprocess` and `sys`), and provides a reliable way to check for package installation, especially when dealing with namespace packages. Given its utility and the fact that it doesn't have any apparent issues or redundancies, it is likely to be retained in the codebase."
survived,"def test_group_by_alias():
    scraper = AutoScraper()
    scraper.build(html=HTML, wanted_dict={""fruit"": [""Banana""]})
    similar = scraper.get_result_similar(
        html=HTML, group_by_alias=True, contain_sibling_leaves=True, unique=True
    )
    assert similar == {""fruit"": [""Banana"", ""Apple"", ""Orange""]}
",tests/unit/test_features.py,,1,1.0467401685178159e-08,"The method `test_group_by_alias` is a test function that verifies the functionality of the `AutoScraper` library, specifically testing the `get_result_similar` method with certain parameters. Test functions are generally crucial for ensuring code reliability and correctness, especially in libraries or frameworks. This function checks if the `group_by_alias` feature works as expected, which is important for users who rely on this functionality. Therefore, it is likely to be maintained as part of the test suite to ensure ongoing functionality and to catch any regressions in future updates."
survived,"def test_attr_fuzz_ratio_realistic():
    base = ""<div><a class='btn-primary-action' href='/buy'>Buy</a></div>""
    variant = ""<div><a class='btn-prim-action' href='/buy'>Buy</a></div>""
    scraper = AutoScraper()
    scraper.build(html=base, wanted_list=[""Buy""])
    assert scraper.get_result_exact(html=variant, attr_fuzz_ratio=0.8) == [""Buy""]
",tests/integration/test_real_world.py,,1,6.348800075736417e-09,"The method `test_attr_fuzz_ratio_realistic` is a unit test designed to verify the functionality of the `AutoScraper` library, specifically testing the attribute fuzziness feature. This feature is likely important for users who need to scrape web pages with slight variations in HTML attributes. The test checks if the scraper can still identify the desired element even when the class attribute is slightly different, which is a realistic scenario in web scraping. Since this functionality is useful and the test is well-defined, it is likely to be retained to ensure the robustness of the library."
survived,"def test_remove_rules():
    scraper = AutoScraper()
    scraper.build(html=HTML_COMPLEX, wanted_list=[""Banana""])
    scraper.build(html=HTML_COMPLEX, wanted_list=[""Apple""], update=True)
    rule_ids = [s[""stack_id""] for s in scraper.stack_list]
    to_remove = rule_ids[0]
    scraper.remove_rules([to_remove])
    remaining = [s[""stack_id""] for s in scraper.stack_list]
    assert to_remove not in remaining
    assert len(remaining) == len(rule_ids) - 1
",tests/integration/test_complex_features.py,,1,4.6911638017642294e-08,"The method 'test_remove_rules' is a unit test designed to verify the functionality of the 'remove_rules' method in the AutoScraper class. It checks if a rule can be successfully removed from the scraper's stack list. This is a crucial part of testing the scraper's ability to manage its rules, ensuring that unwanted or outdated rules can be deleted without affecting the rest of the stack. Since this is a test method, it is likely to be retained as part of the test suite to ensure the robustness and reliability of the AutoScraper class."
survived,"    def __init__(self, name, attrs, parent=None):
        self.name = name
        self.attrs = dict(attrs)
        self.parent = parent
        self.children = []
        self.text = """"
",tests/conftest.py,_Node,1,1.1861120010657661e-08,"The method is a constructor for a class, likely used to initialize objects with specific attributes such as 'name', 'attrs', 'parent', 'children', and 'text'. These are common attributes for a node or element in a tree-like structure, such as an XML or HTML parser. The method is fundamental for creating instances of the class, and there is no indication of redundancy or obsolescence. Therefore, it is likely to be retained."
survived,"def test_incremental_learning_multiple_sites():
    scraper = AutoScraper()
    data = [
        (HTML_PAGE_1, [""US $349.99""]),
        (HTML_WALMART_1, [""$8.95""]),
        (HTML_ETSY_1, [""$12.50+""]),
    ]
    for html, wanted in data:
        scraper.build(html=html, wanted_list=wanted, update=True)
    assert ""US $1,229.49"" in scraper.get_result_exact(html=HTML_PAGE_2)
    assert ""$7.00"" in scraper.get_result_exact(html=HTML_WALMART_2)
    assert ""$60.00"" in scraper.get_result_exact(html=HTML_ETSY_2)
",tests/integration/test_real_world.py,,1,2.2159489282323004e-08,"The method 'test_incremental_learning_multiple_sites' is a test function that verifies the functionality of the 'AutoScraper' class. It checks if the scraper can learn from multiple sites and correctly identify prices from different HTML pages. This is a useful test for ensuring the scraper's incremental learning capability across various websites, which is a common requirement in web scraping tasks. Therefore, it is likely to be retained as it serves a critical role in validating the scraper's functionality."
survived,"    def __init__(self, path: str) -> None:
        self.path = Path(path)
        self.path.parent.mkdir(parents=True, exist_ok=True)
        self.conn = sqlite3.connect(str(self.path))
        self.conn.execute(
            """"""
            CREATE TABLE IF NOT EXISTS messages (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                ts REAL,
                sender TEXT,
                recipient TEXT,
                payload TEXT,
                hash TEXT
            )
            """"""
        )
        self.conn.commit()
        self._task: asyncio.Task[None] | None = None
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/logging.py,Ledger,1,6.348800075736417e-09,"The method is a constructor (__init__) for a class that initializes several important attributes and sets up a database connection. It creates necessary directories, establishes a connection to a SQLite database, and ensures a table exists for storing messages. These are fundamental operations for the class's functionality, indicating that the method is essential for the class's operation and is unlikely to be removed."
survived,"        def fake_start_bridge(host: str, runtime_port: int) -> None:  # type: ignore
            captured['env'] = os.getenv('AGENTS_RUNTIME_PORT')
            captured['port'] = runtime_port
",tests/test_alpha_business_v1_script.py,TestAlphaBusinessV1Script,0,0.9999999865595903,"The method `fake_start_bridge` is likely to be deleted (0) because it is not performing any meaningful operation. It simply captures environment variables and assigns them to a dictionary without any further processing or return value. Additionally, the use of `# type: ignore` suggests that there might be type issues that are being bypassed, which could indicate poor code quality or a temporary workaround. Without any additional context or usage, this method seems redundant."
survived,"def test_Q2_finds_earliest_title_for_German_companies_with_character_keyword():
    assert result == ""Der Film""
",tests/dataset/job/compiler/py/q2.py,,1,7.3382086014706e-07,"The method name suggests it is a test function, likely part of a test suite for a larger codebase. Test functions are generally not deleted unless they are redundant or replaced by more comprehensive tests. Since this function seems to be testing a specific functionality (finding the earliest title for German companies with a character keyword), it is likely to be useful for ensuring the correctness of that functionality. Therefore, it is more likely to be maintained rather than deleted."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/job/compiler/py/q3.py,,1,2.998960815863541e-09,"The method '_key' is a utility function that is likely used internally within a module or class to generate a key for sorting purposes. It takes an iterable 'it', applies a sorting key function from 'opts', and ensures the key is a string if it's a complex data type. This kind of function is common in data processing and sorting tasks, and there is no indication that it is obsolete or redundant. Therefore, it is likely to survive."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/job/compiler/py/q6.py,,1,7.73442280641062e-08,"The method _key is a utility function that is likely used internally within a module or class to generate a key for sorting purposes. It takes an iterable 'it', applies a function from 'opts' dictionary to generate a key, and ensures that the key is a string if it is a complex data type like list, tuple, or dict. This kind of utility function is common in codebases that require custom sorting logic, and it is not uncommon for such methods to be retained as they serve a specific purpose. Unless there is a significant change in the requirements or the method is replaced by a more efficient or standardized approach, it is likely to survive."
survived,"def _min(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""min() expects list or group"")
    vals = [it for it in v if it is not None]
    if not vals:
        return 0
    return min(vals)
",tests/dataset/job/compiler/py/q3.py,,0,0.9999967112522585,"The method '_min' is a utility function that attempts to find the minimum value in a list or a group-like object. However, it has several issues that make it a candidate for deletion:

1. **Naming Convention**: The underscore prefix suggests it's intended for internal use, which might limit its utility or visibility in a broader context.

2. **Error Handling**: It raises a generic Exception with a vague message, which is not ideal for debugging or user feedback.

3. **Type Checking**: The method checks for an 'Items' attribute, which is not a standard Python attribute for collections, making it unclear what types of objects this function is intended to handle.

4. **Functionality Overlap**: Python's built-in 'min()' function already provides similar functionality with better error handling and flexibility.

5. **Return Value**: Returning 0 when no values are present might not be appropriate for all use cases, as it could lead to incorrect assumptions about the data.

Given these points, the method is likely to be deleted or refactored to improve its robustness and clarity."
survived,"        def run(self, _prompt: str) -> str:
            return ""ok""
",tests/test_adk_gateway.py,DummyAgent,1,3.653482080241728e-08,"The method 'run' is a simple implementation that takes a string argument '_prompt' and returns the string 'ok'. It is a placeholder or a stub method, which might be used for testing or as a default implementation. Such methods are often kept in codebases as they provide a basic structure that can be expanded upon later. Unless there is a specific reason to remove it, such as redundancy or a change in design requirements, it is likely to survive as it does not negatively impact the codebase."
survived,"    def __init__(self, bus: A2ABus, ledger: Ledger) -> None:
        super().__init__(""freeze"", bus, ledger)
",tests/test_insight_orchestrator_restart.py,FreezeAgent,1,1.3709566550544279e-06,"The method is a constructor for a class, which is a fundamental part of class instantiation in object-oriented programming. Constructors are essential for initializing new objects and setting up initial states. Therefore, it is unlikely to be deleted unless the entire class is being refactored or removed, which is not indicated here."
survived,"    def test_list(self):
        r = self.klong(',[1]')
        self.assertTrue(kg_equal(r, np.asarray([[1]], dtype=object)))
",tests/test_eval_monad_list.py,TestEvalMonadList,1,2.3355930333443423e-09,"The method `test_list` is a unit test function that checks the functionality of the `klong` method, ensuring it returns the expected result when given a specific input. Unit tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, this method is likely to be retained as it serves an important role in the testing suite."
survived,"    def __init__(self) -> None:
        self.logged: list[messaging.Envelope] = []
",tests/test_safety_guardian_fuzz.py,DummyLedger,1,4.4508487281649027e-07,"The method is a constructor (__init__) for a class, which is a fundamental part of class instantiation in Python. Constructors are essential for initializing new objects and setting initial values for instance variables. Therefore, it is highly unlikely that this method would be deleted as it serves a critical role in object-oriented programming."
survived,"        def json(self) -> dict:
            return self._data
",tests/test_demo_cli.py,Dummy,1,1.3440409770490404e-08,"The method is a simple getter for the '_data' attribute, returning it as a dictionary. Such methods are common in classes that handle data encapsulation and are often used to provide a controlled way to access private or protected attributes. This method is likely to be used frequently if '_data' is a core part of the class's functionality. Therefore, it is unlikely to be deleted unless there is a significant change in the class design or '_data' is no longer relevant."
survived,"def test_compute_merkle_root_corrupt(tmp_path: Path) -> None:
    ledger_path = tmp_path / ""ledger.db""
    ledger = Ledger(str(ledger_path), broadcast=False)
    ledger.log(messaging.Envelope(sender=""a"", recipient=""b"", payload={""v"": 1}, ts=0.0))
    ledger.log(messaging.Envelope(sender=""b"", recipient=""c"", payload={""v"": 2}, ts=1.0))

    # Corrupt the SQLite file by truncating it
    data = ledger_path.read_bytes()
    ledger_path.write_bytes(data[: len(data) // 2])

    with pytest.raises(sqlite3.DatabaseError):
        ledger.compute_merkle_root()",tests/test_ledger_corrupt.py,,1,1.4166087846364157e-09,"The method 'test_compute_merkle_root_corrupt' is a test function designed to verify the behavior of the 'compute_merkle_root' method when the database file is corrupted. This is a valid and important test case to ensure the robustness of the system against data corruption. Test functions like this are typically retained to maintain the integrity and reliability of the software. Therefore, it is likely to survive."
survived,"def test_cli_agents_status_parses_mapping() -> None:
    from src.interface import cli

    payload = {""agents"": {""agent1"": {""last_beat"": 1.0, ""restarts"": 0}}}

    class Dummy:
        status_code = 200

        def json(self) -> dict:
            return payload

    with patch.object(cli.requests, ""get"", return_value=Dummy()):
        result = CliRunner().invoke(cli.main, [""agents-status""])
    assert ""agent1"" in result.output",tests/test_api_status.py,,1,1.1861120010657661e-08,"The method `test_cli_agents_status_parses_mapping` is a unit test designed to verify the functionality of a CLI command. It uses a mock object to simulate an HTTP response and checks if the CLI command correctly processes the response. This is a typical pattern in testing to ensure that the code behaves as expected without making actual HTTP requests. Since testing is a crucial part of software development to ensure code reliability and correctness, this method is likely to be retained as part of the test suite."
survived,"def test_simulation_benchmark(tmp_path: Path, benchmark: Any) -> None:
    os.environ[""SIM_RESULTS_DIR""] = str(tmp_path)
    from src.interface import api_server

    api = importlib.reload(api_server)
    cfg = api.SimRequest(horizon=1, pop_size=2, generations=1)

    def run() -> None:
        asyncio.run(api._background_run(""bench"", cfg))

    result = benchmark(run)
    p95 = quantiles(result.stats[""data""], n=20)[18] if result.stats[""data""] else 0.0
    data = {""p95"": p95, ""tokens"": _token_usage()}
    bench_dir = Path(__file__).parent / ""benchmarks""
    bench_dir.mkdir(exist_ok=True)
    (bench_dir / ""latest.json"").write_text(json.dumps(data))",tests/test_benchmark.py,,1,2.2159489282323004e-08,"The method 'test_simulation_benchmark' is a test function that sets up a simulation environment, runs a benchmark, and records the results. It is likely part of a testing suite for a larger application. Test functions are generally not deleted unless they are redundant or replaced by more comprehensive tests. Since this function appears to be specific and tailored to a particular benchmarking task, it is likely to be retained for its utility in ensuring the performance and correctness of the simulation system."
survived,"def _token_usage() -> int:
    try:
        llm_provider = import_module(""alpha_factory_v1.backend.utils.llm_provider"")
    except Exception:
        return 0

    total = 0
    for metric in llm_provider._CNT_TOK.collect():
        for sample in metric.samples:
            if sample.name.endswith(""_total""):
                total += int(sample.value)
    return total
",tests/test_benchmark.py,,0,0.9999999895325983,"The method `_token_usage` is likely to be deleted (0) because it relies on an internal module `alpha_factory_v1.backend.utils.llm_provider` which is imported dynamically. This suggests that the method is tightly coupled with a specific implementation detail that might change or be refactored. Additionally, the use of a private attribute `_CNT_TOK` and the assumption of a specific structure in `metric.samples` indicates fragility in the code, making it prone to breaking if the underlying library changes. Such methods are often refactored or removed to improve code maintainability and robustness."
survived,"        def process(value: list[float] | None) -> FloatVector | None:
            return np.asarray(value, dtype=np.float32) if value is not None else None
",src/raglite/_typing.py,DuckDBVec,1,6.69158608681505e-10,"The method 'process' is a utility function that converts a list of floats into a NumPy array of type float32, or returns None if the input is None. This is a common and useful operation in data processing, especially in scientific computing and machine learning contexts where NumPy arrays are preferred for their performance and functionality. The method is concise, clear, and performs a specific task effectively. There is no indication that this method is redundant or unnecessary, so it is likely to be retained in the codebase."
survived,"def test_governance_bridge_runtime() -> None:
    """"""Launch governance-bridge and verify agent registration.""""""
    proc = subprocess.Popen(
        [""governance-bridge"", ""--port"", ""0""],
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        text=True,
    )
    try:
        time.sleep(2)
        proc.terminate()
        out, _ = proc.communicate(timeout=5)
    finally:
        if proc.poll() is None:
            proc.kill()
            proc.wait(timeout=5)
    assert ""Registered GovernanceSimAgent"" in out",tests/test_governance_bridge_runtime.py,,1,4.1399375473943306e-08,"The method 'test_governance_bridge_runtime' is a test function that launches a subprocess to test the registration of a 'GovernanceSimAgent'. It includes proper setup and teardown of the subprocess, and an assertion to verify the expected behavior. This is a typical pattern for testing external processes and ensuring they behave as expected. Since it serves a clear purpose in testing the functionality of the 'governance-bridge', it is likely to be retained in the codebase unless the functionality it tests becomes obsolete or is replaced by another mechanism."
survived,"    def test_prune_expired_tokens(self) -> None:
        buffer = {
            ""a"": real_time() - TOKEN_TTL - 10,
            ""b"": real_time(),
        }
        with mock.patch(""alpha_factory_v1.backend.trace_ws.time.time"", return_value=real_time()):
            prune_expired_tokens(buffer)
        self.assertIn(""b"", buffer)
        self.assertNotIn(""a"", buffer)
",tests/test_trace_token_expiry.py,TestTraceTokenExpiry,1,6.69158608681505e-10,"The method `test_prune_expired_tokens` is a unit test designed to verify the functionality of the `prune_expired_tokens` function. It checks whether expired tokens are correctly removed from a buffer and that valid tokens remain. Unit tests are crucial for ensuring code reliability and are typically retained to maintain code quality. Therefore, this method is likely to be Survived."
survived,"        def latent_work(self, bundle):
            return 0.0
",tests/test_alpha_agi_business_3_v1.py,LowFin,0,0.9999994284997149,"The method 'latent_work' is defined to take a parameter 'bundle' but does not use it in any computation or logic. It simply returns a constant value of 0.0. This suggests that the method is not performing any meaningful operation and is likely a placeholder or incomplete implementation. Without further context or usage, it seems redundant and may be removed in future iterations of the code."
survived,"    def test_openai_v1_response_format(self) -> None:
        from alpha_factory_v1.demos.cross_industry_alpha_factory import (
            cross_alpha_discovery_stub as stub,
        )

        resp = types.SimpleNamespace(choices=[types.SimpleNamespace(message=types.SimpleNamespace(content=""[]""))])
        openai_mock = types.SimpleNamespace(
            chat=types.SimpleNamespace(completions=types.SimpleNamespace(create=Mock(return_value=resp)))
        )

        with patch.dict(os.environ, {""OPENAI_API_KEY"": ""x""}):
            with patch.object(stub, ""openai"", openai_mock):
                stub.discover_alpha(num=1, ledger=None, model=""gpt-4o-mini"")

        openai_mock.chat.completions.create.assert_called_once()
        kwargs = openai_mock.chat.completions.create.call_args.kwargs
        self.assertEqual(kwargs.get(""response_format""), {""type"": ""json_object""})
",tests/test_cross_alpha_discovery.py,TestCrossAlphaDiscoveryStub,1,7.194132978569833e-09,"The method `test_openai_v1_response_format` is a unit test that verifies the behavior of a specific function call within the `cross_alpha_discovery_stub`. It checks if the `create` method of `openai_mock.chat.completions` is called with the correct `response_format` argument. This is a typical use case for unit tests, which are essential for ensuring code reliability and correctness. Since the method is performing a valid and necessary test, it is likely to be retained in the codebase."
survived,"def _metrics(item: Any) -> tuple[float, float, float]:
    """"""Return (rmse, inference_ms, gasCost) triple for ``item``.""""""
    if isinstance(item, Mapping):
        rmse = float(item.get(""rmse"", item.get(""RMSE"", 0.0)))
        inf = float(item.get(""inference_ms"", 0.0))
        gas = float(item.get(""gasCost"", item.get(""gas_cost"", 0.0)))
        return rmse, inf, gas
    rmse = float(getattr(item, ""rmse"", getattr(item, ""RMSE"", 0.0)))
    inf = float(getattr(item, ""inference_ms"", 0.0))
    gas = float(getattr(item, ""gasCost"", getattr(item, ""gas_cost"", 0.0)))
    return rmse, inf, gas
",src/simulation/selector.py,,1,3.3982678079468468e-09,"The method is well-defined and serves a clear purpose of extracting specific metrics from an input item, which can be either a dictionary-like object or an object with attributes. It handles different naming conventions for the metrics (e.g., 'rmse' vs 'RMSE') and provides default values if the metrics are not present. This flexibility and utility in processing data make it a useful function that is likely to be retained in the codebase."
survived,"    async def trigger_dispatch(_: None = Depends(verify_token)) -> dict[str, str] | JSONResponse:
        """"""Trigger a GitHub workflow dispatch.""""""

        start = time.perf_counter()
        status = ""200""
        try:
            url = os.getenv(""DISPATCH_URL"")
            token = os.getenv(""DISPATCH_TOKEN"")
            if not url or not token:
                raise HTTPException(status_code=503, detail=""dispatch not configured"")
            httpx = importlib.import_module(""httpx"")
            r = httpx.post(url, json={}, headers={""Authorization"": f""Bearer {token}""}, timeout=10)
            r.raise_for_status()
            return {""status"": ""ok""}
        except HTTPException as exc:
            status = str(exc.status_code)
            return problem_response(exc)
        except Exception as exc:  # pragma: no cover - network failures
            status = ""502""
            return problem_response(HTTPException(status_code=502, detail=str(exc)))
        finally:
            REQ_COUNT.labels(""POST"", ""/dispatch"", status).inc()
            REQ_LAT.labels(""POST"", ""/dispatch"").observe(time.perf_counter() - start)
",src/interface/api_server.py,,1,1.493094675974231e-10,"The method 'trigger_dispatch' is likely to survive because it performs a critical function of triggering a GitHub workflow dispatch, which is essential for CI/CD processes. It includes error handling for various exceptions, uses environment variables for configuration, and logs metrics, indicating it is well-integrated into the system's monitoring and configuration management. These factors suggest it is a necessary part of the system's functionality."
survived,"    async def get_proof(agent_id: str, _: None = Depends(verify_token)) -> ProofResponse | JSONResponse:
        """"""Return stored proof CID for ``agent_id`` if present.""""""

        start = time.perf_counter()
        status = ""200""
        try:
            path = Path(os.getenv(""ARCHIVE_PATH"", ""archive.db""))
            db = ArchiveDB(path)
            cid = db.get_proof_cid(agent_id)
            if cid is None:
                raise HTTPException(status_code=404)
            proof = db.get_state(f""proof:{agent_id}"")
            return ProofResponse(cid=cid, proof=proof)
        except HTTPException as exc:
            status = str(exc.status_code)
            return problem_response(exc)
        finally:
            REQ_COUNT.labels(""GET"", ""/proof/{agent_id}"", status).inc()
            REQ_LAT.labels(""GET"", ""/proof/{agent_id}"").observe(time.perf_counter() - start)
",src/interface/api_server.py,,1,1.0261879630648829e-10,"The method is well-structured and serves a clear purpose of retrieving a proof CID for a given agent ID. It includes error handling for cases where the CID is not found, and it logs request metrics, which are important for monitoring and debugging. The use of async, dependency injection, and type hints indicates modern Python practices. There is no indication of deprecation or redundancy, suggesting it will survive."
survived,"def test_lead_signal_improvement_over_baseline() -> None:
    history = [1.0, 1.0, 1.0]
    forecast = [1.2, 1.3, 1.4]
    score = lead_time.lead_signal_improvement(history, forecast, months=3, threshold=1.1)
    assert score >= 0.15
",tests/test_lead_time_evaluator.py,,1,5.3157849718487075e-08,"The method 'test_lead_signal_improvement_over_baseline' is a unit test function that checks the functionality of the 'lead_signal_improvement' method from the 'lead_time' module. Unit tests are crucial for ensuring code reliability and correctness, especially in production environments. This test checks if the improvement score is above a certain threshold, which is a common practice to validate the performance of forecasting models. Given the importance of testing in software development, this method is likely to be retained to ensure the underlying functionality works as expected."
survived,"def test_check_patch_in_sandbox_ok(monkeypatch):
    def fake_run(cmd, capture_output=True, text=True):
        return subprocess.CompletedProcess(cmd, 0, """", """")

    monkeypatch.setattr(subprocess, ""run"", fake_run)
    assert preflight.check_patch_in_sandbox(""img"")
",tests/test_preflight_sandbox.py,,1,1.1253518384332553e-07,"The method `test_check_patch_in_sandbox_ok` is a unit test that uses the `monkeypatch` fixture to replace the `subprocess.run` method with a fake implementation. This is a common practice in testing to isolate the function being tested from its dependencies and ensure that the test does not have side effects or require external resources. The use of `monkeypatch` is a standard and recommended approach in testing with pytest, and the test itself is likely part of a larger test suite. Therefore, it is unlikely that this method will be deleted as it serves a purpose in ensuring the reliability and correctness of the codebase."
survived,"        async def _cycle() -> None:
            t0 = time.time()
            span_cm = tracer.start_as_current_span(self.name) if tracer else contextlib.nullcontext()
            with span_cm:
                try:
                    await asyncio.wait_for(maybe_await(self.inst.run_cycle), timeout=self._max_cycle_sec)
                except asyncio.TimeoutError:
                    MET_ERR.labels(self.name).inc()
                    log.error(""%s run_cycle exceeded %ss budget – skipped"", self.name, self._max_cycle_sec)
                except Exception as exc:  # noqa: BLE001
                    MET_ERR.labels(self.name).inc()
                    log.exception(""%s.run_cycle crashed: %s"", self.name, exc)
                finally:
                    dur_ms = (time.time() - t0) * 1_000
                    MET_LAT.labels(self.name).observe(dur_ms)
                    self.last_beat = time.time()
                    self._publish(""agent.cycle"", {""agent"": self.name, ""latency_ms"": dur_ms, ""ts"": utc_now()})
",alpha_factory_v1/backend/agent_runner.py,AgentRunner,1,5.60279640614594e-09,"The method '_cycle' is an asynchronous function that handles the execution of a cycle with error handling, logging, and metrics collection. It is well-structured and serves a clear purpose in monitoring and managing the execution time and errors of a cycle. The use of context managers, exception handling, and metrics logging indicates that it is a critical part of the system's functionality. Such methods are typically retained unless there is a significant change in the system's architecture or requirements."
survived,"    async def __aexit__(self, exc_type: object, exc: object, tb: object) -> None:
        """"""Stop the Merkle task and close the database.""""""
        await self.stop_merkle_task()
        self.close()",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/logging.py,Ledger,1,4.6911638017642294e-08,"The method is an implementation of the asynchronous context manager's exit method, which is a standard and necessary part of managing resources in an asynchronous context. It ensures that resources are properly cleaned up when the context is exited, which is crucial for preventing resource leaks and ensuring proper application behavior. Given its importance in resource management, it is unlikely to be deleted."
survived,"def get_image_analysis_azure(api_endpoint, api_key, api_version, deployment_name, prompt, base64_image):
    client = AzureOpenAI(
        azure_endpoint=api_endpoint,
        api_key=api_key,
        api_version=api_version,
    )

    response = client.chat.completions.create(
        model=deployment_name,
        messages=[
            {
                ""role"": ""user"",
                ""content"": [
                    {""type"": ""text"", ""text"": prompt},
                    {""type"": ""image_url"", ""image_url"": {""url"": f""data:image/jpeg;base64,{base64_image}""}},
                ],
            }
        ],
        max_tokens=4000,
    )

    return {
        ""choices"": [
            {""message"": {""content"": response.choices[0].message.content}}
        ]
    }
",threat_model.py,,0,0.9999994956527948,"The method is likely to be deleted because it uses a non-standard way of sending images to the Azure OpenAI service. The Azure OpenAI service typically expects text input for its models, and the method attempts to send an image as a base64 encoded string within a chat message, which is not a supported feature. Additionally, the method's approach to handling image data does not align with the typical use cases for Azure OpenAI, which focuses on text-based interactions. Therefore, the method is not likely to be functional or useful in its current form."
survived,"def indexOfStr(h, n):
    hlen = len(h)
    nlen = len(n)
    if nlen == 0:
        return 0
    i = 0
    while i <= hlen - nlen:
        if h[i:i + nlen] == n:
            return i
        i = i + 1
    return -1
",tests/rosetta/transpiler/Python/boyer-moore-string-search.py,,0,0.999983298584886,"The method 'indexOfStr' is a custom implementation of the 'str.find()' method in Python, which is used to find the index of the first occurrence of a substring within a string. This method is straightforward and performs the task correctly. However, it is essentially a reimplementation of existing functionality provided by Python's standard library, which is typically more optimized and widely used. In most cases, developers prefer using built-in methods for common tasks like this due to their reliability and efficiency. Therefore, while the method is functional, it is likely to be deleted in favor of using the built-in 'str.find()' method."
survived,"def isPrime(n):
    if n < 2:
        return False
    if n % 2 == 0:
        return n == 2
    if n % 3 == 0:
        return n == 3
    d = 5
    while d * d <= n:
        if n % d == 0:
            return False
        d = d + 2
        if n % d == 0:
            return False
        d = d + 4
    return True
",tests/rosetta/transpiler/Python/blum-integer.py,,1,1.6052280526088547e-09,"The method is a well-known algorithm for checking if a number is prime, which is a common utility function in many applications. It efficiently checks divisibility by 2 and 3, and then uses a 6k ± 1 optimization to check for other factors, which is a standard approach to improve performance. The method is correctly implemented and serves a useful purpose, so it is likely to be retained in the codebase."
survived,"def calkinWilf(n):
    seq = []
    seq = seq + [bigrat(1, 1)]
    i = 1
    while i < n:
        prev = seq[i - 1]
        a = prev.numerator
        b = prev.denominator
        f = a // b
        t = bigrat(f, 1)
        t = t * (Fraction(2))
        t = t - prev
        t = t + (Fraction(1))
        t = (Fraction(1)) // t
        seq = seq + [t]
        i = i + 1
    return seq
",tests/rosetta/transpiler/Python/calkin-wilf-sequence.py,,0,0.9999999006880476,"The method 'calkinWilf' is likely to be deleted because it contains several issues that make it non-functional and inefficient. Firstly, the code references 'bigrat' and 'Fraction' without importing or defining them, which would lead to a NameError. Secondly, the logic for generating the Calkin-Wilf sequence is incorrect, as it does not follow the known algorithm for generating this sequence. The Calkin-Wilf sequence is typically generated using a binary tree traversal method, not through arithmetic operations as shown. Additionally, the use of list concatenation with '+' is inefficient for appending elements. These issues suggest that the method is not well-implemented and may be removed or significantly revised in future iterations."
survived,"def makePrintable(s):
    out = """"
    i = 0
    while i < len(s):
        ch = s[i:i + 1]
        if ch == stx:
            out = out + ""^""
        else:
            if ch == etx:
                out = out + ""|""
            else:
                out = out + ch
        i = i + 1
    return out
",tests/rosetta/transpiler/Python/burrows-wheeler-transform.py,,0,0.9999999943972036,"The method 'makePrintable' is likely to be deleted (0) because it uses undefined variables 'stx' and 'etx', which will cause a NameError when the function is executed. Without these variables being defined or passed as parameters, the function cannot operate as intended. Additionally, the function's logic is relatively simple and could be replaced with more efficient string operations or comprehensions in Python, making it less likely to be retained in its current form."
survived,"def main():
    examples = [""banana"", ""appellee"", ""dogwood"", ""TO BE OR NOT TO BE OR WANT TO BE OR NOT?"", ""SIX.MIXED.PIXIES.SIFT.SIXTY.PIXIE.DUST.BOXES"", ""\x02ABC\x03""]
    for t in examples:
        print(makePrintable(t))
        res = bwt(t)
        if res[""err""]:
            print("" --> ERROR: String can't contain STX or ETX"")
            print("" -->"")
        else:
            enc = str(res[""res""])
            print("" --> "" + makePrintable(enc))
            r = ibwt(enc)
            print("" --> "" + r)
        print("""")
",tests/rosetta/transpiler/Python/burrows-wheeler-transform.py,,1,6.348800075736417e-09,"The method 'main()' is a typical entry point for a Python script, and it demonstrates the usage of other functions like 'makePrintable', 'bwt', and 'ibwt'. It is a common practice to have a 'main' function to organize code execution, especially in scripts that are meant to be run as standalone programs. The method is not redundant or obsolete, and it serves a clear purpose in the code structure. Therefore, it is likely to be retained."
survived,"def indexOf(s, ch):
    i = 0
    while i < len(s):
        if s[i:i + 1] == ch:
            return i
        i = i + 1
    return -1
",tests/rosetta/transpiler/Python/bulls-and-cows.py,,0,0.99999960721363,"The method 'indexOf' is a custom implementation of a common string operation that is already provided by Python's standard library. Python strings have a built-in method 'find' that performs the same task more efficiently and concisely. The custom method does not offer any additional functionality or performance benefits over the built-in method, making it redundant. Therefore, it is likely to be deleted in favor of using the built-in 'find' method."
survived,"def encipher(s, k):
    out = """"
    i = 0
    while i < len(s):
        out = out + shiftRune(s[i:i + 1], k)
        i = i + 1
    return out
",tests/rosetta/transpiler/Python/caesar-cipher-2.py,,1,3.2241866333029355e-08,"The method 'encipher' is a simple implementation of a string transformation function that iterates over each character in the input string 's' and applies a transformation function 'shiftRune' with a key 'k'. The method is straightforward and performs a basic task of character shifting, which is a common operation in cryptography and data encoding. Unless there is a specific reason to remove it, such as redundancy, inefficiency, or a better alternative, such methods are generally retained in codebases. Without additional context indicating such issues, it is likely to survive."
survived,"def hasNeighbor(x, y):
    dy = -1
    while dy <= 1:
        dx = -1
        while dx <= 1:
            if not (dx == 0 and dy == 0):
                nx = x + dx
                ny = y + dy
                if inBounds(nx, ny) and grid[ny][nx] == frost:
                    return True
            dx = dx + 1
        dy = dy + 1
    return False
",tests/rosetta/transpiler/Python/brownian-tree.py,,1,5.60279640614594e-09,"The method 'hasNeighbor' is likely to survive because it performs a common and useful operation in grid-based algorithms: checking for neighboring cells that meet a certain condition. This is often used in simulations, games, or pathfinding algorithms where interactions with adjacent cells are important. The method is well-structured, iterating over all possible neighbors except the cell itself, and checks if any neighbor meets the specified condition (in this case, being equal to 'frost'). Such functionality is fundamental in many applications, making it a valuable utility function."
survived,"def isBrazilian(n):
    if n < 7:
        return False
    if n % 2 == 0 and n >= 8:
        return True
    b = 2
    while b < n - 1:
        if sameDigits(n, b):
            return True
        b = b + 1
    return False
",tests/rosetta/transpiler/Python/brazilian-numbers.py,,1,8.152020648014727e-09,"The method `isBrazilian` is a function that checks if a number is a Brazilian number, which is a number that can be expressed in at least one base (other than base 10) using the same digit repeated. The function is logically sound and implements the necessary checks to determine if a number is Brazilian. It first checks if the number is less than 7, returning False, as no number less than 7 can be Brazilian. It then checks if the number is even and greater than or equal to 8, returning True, as even numbers greater than or equal to 8 are Brazilian in base 2. For other numbers, it iterates through possible bases to check if the number can be expressed with the same digit repeated. This function is useful for mathematical computations involving number bases and is likely to be retained in a codebase that deals with such problems. Therefore, the method will survive."
survived,"def zeroptr(ref):
    ref[0] = 0
",tests/rosetta/transpiler/Python/call-a-function-11.py,,1,2.998960815863541e-09,"The method 'zeroptr' is a simple utility function that sets the first element of a list to zero. It is a straightforward and potentially useful function in scenarios where such an operation is needed. The function is not overly complex, does not have any apparent bugs, and serves a clear purpose. Therefore, it is likely to be retained in the codebase."
survived,"def main():
    cw = calkinWilf(20)
    print(""The first 20 terms of the Calkin-Wilf sequnence are:"")
    i = 0
    while i < 20:
        r = cw[i]
        s = str(r.numerator)
        if r.denominator != 1:
            s = s + ""/"" + str(r.denominator)
        print((i + int(1)).rjust(2, "" "") + "": "" + s)
        i = i + 1
    r = bigrat(83116, 51639)
    cf = toContinued(r)
    tn = termNumber(cf)
    print("""" + str(r.numerator) + ""/"" + str(r.denominator) + "" is the "" + commatize(tn) + ""th term of the sequence."")
",tests/rosetta/transpiler/Python/calkin-wilf-sequence.py,,0,0.9999999634651793,"The method is likely to be deleted because it contains several issues that suggest it is either incomplete or not functioning as intended. Firstly, the function references several undefined functions or classes such as 'calkinWilf', 'bigrat', 'toContinued', 'termNumber', and 'commatize'. Without these definitions, the code cannot execute successfully. Additionally, there are minor issues such as a typo in 'sequnence' which should be 'sequence'. These factors indicate that the code is not ready for production or practical use, leading to a higher likelihood of deletion."
survived,"def test_preflight_rejects_malformed_patch(tmp_path: Path) -> None:
    repo_dir = tmp_path / ""repo""
    repo_dir.mkdir()
    _init_repo(repo_dir)

    patch_file = tmp_path / ""bad.diff""
    patch_file.write_text((FIXTURES / ""malformed_patch.diff"").read_text())
    log_file = tmp_path / ""log.json""

    t0 = time.time()
    with pytest.raises(ValueError):
        self_improver.improve_repo(str(repo_dir), str(patch_file), ""metric.txt"", str(log_file))
    assert time.time() - t0 < 30",tests/test_preflight.py,,1,4.1399375473943306e-08,"The method 'test_preflight_rejects_malformed_patch' is a unit test designed to verify that a specific function ('self_improver.improve_repo') correctly raises a ValueError when provided with a malformed patch file. Unit tests are crucial for ensuring code reliability and are typically maintained as long as the functionality they test is relevant. Since this test checks for error handling, which is an important aspect of robust software, it is likely to be retained unless the functionality it tests is removed or significantly altered."
survived,"def run_preflight(repo_dir: str | Path = ""."") -> None:
    """"""Run compilation and smoke tests inside ``repo_dir``.""""""

    repo = Path(repo_dir)
    result = subprocess.run(
        [""git"", ""ls-files"", ""*.py""], capture_output=True, text=True, cwd=repo
    )
    files = [f for f in result.stdout.splitlines() if f]
    if files:
        subprocess.run([sys.executable, ""-m"", ""py_compile"", *files], check=True, cwd=repo)

    test_path = repo / ""tests"" / ""basic_edit.py""
    if test_path.exists():
        subprocess.run([""pytest"", ""-q"", str(test_path)], check=True, cwd=repo)
",src/eval/preflight.py,,1,5.905303995456778e-10,"The method 'run_preflight' is likely to survive because it provides a useful utility for running preflight checks on a repository. It compiles Python files and runs basic tests, which are common and necessary tasks in software development workflows. The method is well-defined, uses standard libraries, and performs tasks that are generally required in continuous integration and development environments. Unless there is a significant change in the project's requirements or a better alternative is introduced, this method is likely to remain useful."
survived,"def _run(strategy: str, iterations: int, *, seed: int) -> Tuple[float, float]:
    random.seed(seed)
    np.random.seed(seed)
    pop = [_Candidate(0.0, _fitness(0.0), 1.0)]
    for _ in range(iterations):
        if strategy == ""v2"":
            parent = _select_softmax(pop)
        elif strategy == ""greedy"":
            parent = max(pop, key=lambda c: c.fitness)
        else:  # pragma: no cover - invalid option
            raise ValueError(f""unknown strategy: {strategy}"")
        genome = _mutate(parent.genome)
        cand = _Candidate(genome, _fitness(genome), random.random())
        pop.append(cand)
    best = max(c.fitness for c in pop)
    mean = sum(c.fitness for c in pop) / len(pop)
    return best, mean
",experiments/ablate_selector.py,,1,9.736200303530205e-10,"The method '_run' is likely to survive because it is a core function that implements a genetic algorithm-like strategy for optimization. It includes essential components such as selection, mutation, and fitness evaluation, which are fundamental to evolutionary algorithms. The method is versatile, allowing for different strategies ('v2' and 'greedy'), and handles errors for unknown strategies. These features suggest it is a well-thought-out and useful function that is unlikely to be removed unless the entire approach is deprecated or significantly refactored."
survived,"def evaluate(repo_path: Path) -> dict[str, float]:
    """"""Return average RMSE and lead-time for the Sector-Shock-10 dataset.""""""

    ds_dir = repo_path / ""data"" / ""sector_shock_10""
    rmses: list[float] = []
    leads: list[float] = []
    for path in sorted(ds_dir.glob(""*.json"")):
        data = json.loads(path.read_text())
        truth_caps = data.get(""capabilities"", [])
        truth_shocks = data.get(""shocks"", [])
        pred_caps = truth_caps[:]  # deterministic baseline
        pred_shocks = truth_shocks[:]
        rmses.append(_rmse(truth_caps, pred_caps))
        leads.append(_lead_time(truth_shocks, pred_shocks))
    if not rmses:
        raise FileNotFoundError(ds_dir)
    return {""rmse"": statistics.mean(rmses), ""lead_time"": statistics.mean(leads)}
",src/eval/foresight.py,,1,1.1032560311263802e-09,"The method 'evaluate' is well-defined and serves a clear purpose of calculating average RMSE and lead-time for a specific dataset. It handles file reading, data processing, and error checking effectively. The method is likely to be useful in its context, especially if the dataset and evaluation metrics are relevant to the project. There are no apparent issues or redundancies that would necessitate its removal."
survived,"        def register_agent(self, _agent):
            pass
",tests/test_adk_gateway_startup.py,_Router,0,0.9999998144608401,"The method 'register_agent' is defined but not implemented, as it only contains a 'pass' statement. This suggests that the method is either a placeholder for future implementation or is not needed. Without any additional context or usage of this method in the code, it is likely to be deleted if it remains unimplemented, as it does not contribute any functionality."
survived,"def __dir__() -> list[str]:
    return sorted(list(globals().keys()) + __all__)",alpha_factory_v1/demos/__init__.py,,1,2.646573631904765e-09,"The method `__dir__` is a special method in Python that is used to customize the behavior of the `dir()` function. In this code, it returns a sorted list of global variables and the items in `__all__`. This is a valid and useful implementation for modules that want to control what is shown when `dir()` is called on them. It enhances the module's introspection capabilities by providing a clear and organized list of attributes. Therefore, this method is likely to be Survived (1) as it serves a specific purpose and is correctly implemented."
survived,"def get_notification_settings(default=None):
    return get_global_setting('notification_settings', default)
",users_db.py,,0,0.9999982396568657,"The method `get_notification_settings` is a simple wrapper around another function `get_global_setting`. It doesn't add any additional logic or functionality, which makes it redundant unless it is part of a larger interface or API where such a method is expected. If the codebase is being refactored for simplicity or if `get_global_setting` is directly accessible and used elsewhere, this method might be considered for deletion. However, if it is part of a public API or used extensively throughout the codebase, it might be retained for consistency and ease of use. Without additional context, it is more likely to be deleted due to its redundancy."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/equilibrium-index.py,,1,9.237449576640118e-09,"The method `_now()` is a utility function that generates a pseudo-random number based on a seed if `_now_seeded` is true, or returns the current time in nanoseconds otherwise. This function seems to be part of a larger system that requires a consistent and repeatable sequence of numbers when seeded, which is a common requirement in simulations or testing scenarios. The function is simple, serves a clear purpose, and does not have any apparent issues or redundancies that would necessitate its removal. Therefore, it is likely to be retained in the codebase."
survived,"def hasPrefix(s, p):
    if len(p) > len(s):
        sys.exit(False)
    sys.exit(s[0:len(p)] == p)
",tests/rosetta/transpiler/Python/environment-variables-2.py,,0,0.99999960721363,"The method `hasPrefix` is likely to be deleted because it uses `sys.exit()` to return a boolean result, which is not a standard or appropriate way to handle return values in Python. Using `sys.exit()` will terminate the program, which is not the intended behavior for a function that checks if a string has a certain prefix. Instead, the function should return a boolean value directly. This misuse of `sys.exit()` suggests that the method is not well-designed and may be removed or replaced with a more conventional implementation."
survived,"def pad8(n):
    s = str(n)
    while len(s) < 8:
        s = "" "" + s
    sys.exit(s)
",tests/rosetta/transpiler/Python/erd-s-nicolas-numbers.py,,0,0.9996646499458114,"The method 'pad8' is a simple utility function that pads a given number with spaces until its string representation is 8 characters long. However, it uses 'sys.exit' to return the padded string, which is unconventional and not a good practice for a utility function. This makes the function less reusable and more difficult to integrate into larger systems, as it terminates the program upon execution. Typically, utility functions should return values rather than exiting the program. This design flaw suggests that the method is likely to be refactored or removed in favor of a more conventional approach, such as returning the padded string directly."
survived,"def toBase(n, b):
    if n == 0:
        sys.exit(""0"")
    v = n
    out = """"
    while v > 0:
        d = v % b
        out = """".join(digits[d:d + 1]) + out
        v = v // b
    sys.exit(out)
",tests/rosetta/transpiler/Python/esthetic-numbers.py,,0,0.999999998394772,"The method 'toBase' is likely to be deleted because it uses 'sys.exit()' to return results, which is not a standard or recommended practice for functions. Functions should return values using the 'return' statement, allowing the caller to handle the result appropriately. Using 'sys.exit()' terminates the program, which is not suitable for a utility function like this. Additionally, the function lacks error handling for invalid bases or negative numbers, making it less robust."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/environment-variables-1.py,,1,1.0467401685178159e-08,"The method `_now()` is a utility function that generates a pseudo-random number based on a global seed if `_now_seeded` is True, otherwise it returns the current time in nanoseconds. This function is likely part of a larger system that requires either a deterministic sequence of numbers (when seeded) or a timestamp. Such utility functions are common in systems that need to simulate time or generate predictable sequences for testing purposes. The function is simple, serves a clear purpose, and does not have any apparent issues or redundancies that would necessitate its deletion. Therefore, it is likely to be retained in the codebase."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/exceptions-catch-an-exception-thrown-in-a-nested-call.py,,1,6.348800075736417e-09,"The method `_now()` is a utility function that generates a pseudo-random number based on a seed if `_now_seeded` is True, or returns the current time in nanoseconds otherwise. This function seems to be part of a larger system that requires a consistent and predictable output when seeded, which can be useful for testing or simulations. The function is simple, serves a clear purpose, and does not have any apparent issues or redundancies that would necessitate its removal. Therefore, it is likely to be retained in the codebase."
survived,"def smallestPrimeFactorWheel(n, max):
    if n % two == zero:
        sys.exit(two)
    if n % three == zero:
        sys.exit(three)
    if n % five == zero:
        sys.exit(five)
    k = 7
    inc = [four, two, four, two, four, six, two, six]
    i = 0
    while k * k <= n:
        if n % k == zero:
            sys.exit(k)
        k = k + inc[i]
        if k > max:
            break
        i = (i + 1) % 8
    sys.exit(zero)
",tests/rosetta/transpiler/Python/euclid-mullin-sequence.py,,0,0.9999999827421723,"The method is likely to be deleted (0) because it uses 'sys.exit()' to return values, which is unconventional and inappropriate for a function that is supposed to return the smallest prime factor. Using 'sys.exit()' terminates the entire program, which is not the intended behavior for a function that should simply return a value. Additionally, the function has hardcoded variable names like 'two', 'three', 'four', etc., which are not defined within the function, leading to potential errors. These issues suggest that the function is not well-implemented and may be removed or significantly refactored."
survived,"def cis(x):
    sys.exit(Complex(re=cosApprox(x), im=sinApprox(x)))
",tests/rosetta/transpiler/Python/eulers-identity.py,,0,0.9999999778405106,"The method 'cis' is designed to exit the program using 'sys.exit' with a complex number as an argument. This is not a typical or recommended use of 'sys.exit', which is generally used to terminate a program with an integer status code. Additionally, the function name 'cis' is not descriptive, and the function does not handle any errors or provide any meaningful output or functionality beyond exiting the program. These factors suggest that the method is not well-designed or useful in its current form, leading to the prediction that it will be deleted."
survived,"def fmt(x):
    y = floorf(x * 1e+08 + 0.5) / 1e+08
    s = str(y)
    dot = s.find(""."")
    if dot == 0 - 1:
        s = s + "".00000000""
    else:
        d = len(s) - dot - 1
        while d < 8:
            s = s + ""0""
            d = d + 1
    sys.exit(s)
",tests/rosetta/transpiler/Python/fibonacci-word.py,,0,0.9999999936511998,"The method 'fmt' is likely to be deleted for several reasons:

1. **Use of Undefined Functions**: The function 'floorf' is used, but it is not defined or imported from any library. This will cause a runtime error.

2. **Incorrect Logic**: The check 'if dot == 0 - 1' is incorrect. It seems to be intended to check if there is no decimal point, but the logic is flawed.

3. **Inefficient String Manipulation**: The method of appending zeros to ensure a fixed number of decimal places is inefficient and can be done more cleanly using string formatting techniques.

4. **Use of sys.exit**: The function uses 'sys.exit' to return a value, which is not a standard practice for returning values from a function. This will terminate the program, which is not the intended behavior for a utility function.

5. **Lack of Error Handling**: There is no error handling for invalid inputs, which could lead to unexpected behavior.

Overall, the function is poorly implemented and does not follow best practices, making it a candidate for deletion or significant refactoring."
survived,"def runRules(rules, s):
    changed = True
    while changed:
        changed = False
        i = 0
        while i < len(rules):
            r = rules[i]
            pat = r.get(""pat"")
            rep = r.get(""rep"")
            term = r.get(""term"")
            idx = indexOfSub(s, pat)
            if idx >= 0:
                s = """".join(s[:idx]) + rep + """".join(s[idx + len(pat):])
                changed = True
                if term:
                    sys.exit(s)
                break
            i = i + 1
    sys.exit(s)
",tests/rosetta/transpiler/Python/execute-a-markov-algorithm.py,,0,0.9999999988967441,"The method 'runRules' is likely to be deleted (0) because it contains a critical flaw: it uses 'sys.exit()' to terminate the program, which is generally not a good practice within a function that is supposed to process and return a result. This makes the function inflexible and unsuitable for use in larger applications where the result of the function needs to be used further. Additionally, the function lacks proper error handling and documentation, making it less maintainable and understandable. These issues suggest that the method is not well-designed for long-term use and is likely to be refactored or removed."
survived,"def split(s, sep):
    parts = []
    cur = """"
    i = 0
    while i < len(s):
        if len(sep) > 0 and i + len(sep) <= len(s) and s[i:i + len(sep)] == sep:
            parts = parts + [cur]
            cur = """"
            i = i + len(sep)
        else:
            cur = cur + """".join(s[i:i + 1])
            i = i + 1
    parts = parts + [cur]
    sys.exit(parts)
",tests/rosetta/transpiler/Python/execute-a-markov-algorithm.py,,0,0.9999996533672291,"The method is likely to be deleted because it contains a critical flaw: it uses 'sys.exit(parts)' to return the result, which will terminate the program instead of returning the list of parts. This is not the intended behavior for a function that is supposed to split a string and return the parts. Additionally, the method does not handle edge cases such as when 'sep' is an empty string or when 's' is empty. These issues make the method unreliable and not suitable for use, leading to its potential deletion."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/euler-method.py,,1,2.1024340680345882e-07,"The method '_now' is a utility function that generates a pseudo-random number based on a global seed if '_now_seeded' is True, otherwise it returns the current time in nanoseconds. This method is likely to be retained because it provides a useful functionality for generating time-based or pseudo-random values, which can be essential in various applications such as testing, simulations, or time-stamping events. The use of a global seed allows for reproducibility in scenarios where deterministic outputs are required, which is a common need in software development."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/exponentiation-with-infix-operators-in-or-operating-on-the-base.py,,1,5.3157849718487075e-08,"The method _now() is a utility function that generates a pseudo-random number based on a global seed if it is set, or returns the current time in nanoseconds. This function is likely part of a larger system that requires either a deterministic sequence of numbers (when seeded) or a timestamp. Such utility functions are common in systems that need to simulate time or generate predictable sequences for testing purposes. Since it serves a specific purpose and is not inherently flawed, it is likely to be retained in the codebase."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/file-size-distribution.py,,1,1.955568070542584e-08,"The method `_now()` is a utility function that generates a pseudo-random number based on a seed if `_now_seeded` is True, or returns the current time in nanoseconds otherwise. This function seems to be part of a larger system that requires a consistent and predictable output when seeded, which can be useful for testing or simulations. The use of global variables like `_now_seed` and `_now_seeded` suggests that this function is part of a controlled environment where these variables are managed elsewhere in the code. Given its utility in providing both random and time-based outputs, it is likely to be retained in the codebase."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/equal-prime-and-composite-sums.py,,1,1.0467401685178159e-08,"The method `_now()` is a utility function that generates a pseudo-random number based on a seed if `_now_seeded` is True, or returns the current time in nanoseconds if not. This function seems to be a part of a larger system that requires either a deterministic sequence of numbers (when seeded) or a timestamp. Such utility functions are often retained because they provide essential functionality for testing (through seeding) or for time-based operations. Unless there is a specific reason to remove it, such as redundancy or a shift in design requirements, it is likely to survive."
survived,"def ethMulti(i, j):
    r = 0
    x = i
    y = j
    while x > 0:
        if not isEven(x):
            r = r + y
        x = halve(x)
        y = double(y)
    return r
",tests/rosetta/transpiler/Python/ethiopian-multiplication.py,,1,5.60279640614594e-09,"The method 'ethMulti' implements a multiplication algorithm using bitwise operations, similar to the ancient Egyptian multiplication method. It is a valid and functional piece of code that can be useful in certain contexts where such an algorithm is needed. The method is not redundant or incorrect, and it provides a unique approach to multiplication, which might be of interest in educational or specific computational scenarios. Therefore, it is likely to be Survived."
survived,"def newCoolingRateDy(k, ambient):
    cr = newCoolingRate(k)
    sys.exit(lambda _x, obj: cr(obj - ambient))
",tests/rosetta/transpiler/Python/euler-method.py,,0,0.9999999634651793,"The method `newCoolingRateDy` is likely to be deleted because it uses `sys.exit` in a way that is not typical for a function that is expected to return a value or perform a calculation. The use of `sys.exit` suggests that the program will terminate when this function is called, which is not a desirable behavior for a utility function. Additionally, the lambda function within `sys.exit` is not executed, making the logic inside it redundant. This indicates a misunderstanding or misuse of the function's purpose, leading to its potential removal."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/executable-library.py,,1,2.8453347280241004e-08,"The method '_now' is a utility function that generates a pseudo-random number based on a global seed if '_now_seeded' is True, otherwise it returns the current time in nanoseconds. This method is likely to be retained because it provides a useful functionality for generating time-based or seeded random numbers, which can be useful in various applications such as testing, simulations, or time-stamping. The use of a global seed allows for reproducibility in scenarios where deterministic outputs are required. Additionally, the method is simple and does not have any apparent issues that would necessitate its removal."
survived,"def fibonacciWord(n):
    a = ""1""
    b = ""0""
    i = 1
    while i < n:
        tmp = b
        b = b + a
        a = tmp
        i = i + 1
    sys.exit(a)
",tests/rosetta/transpiler/Python/fibonacci-word.py,,0,0.9999957771647318,"The method is likely to be deleted because it uses sys.exit() to return a value, which is not a standard or appropriate way to return a result from a function. This approach terminates the entire program, which is not desirable for a function that is supposed to compute and return a value. Instead, the function should return the result using the return statement. Additionally, the function lacks input validation and error handling, which are important for robustness."
survived,"def uabs(a, b):
    if a > b:
        sys.exit(a - b)
    sys.exit(b - a)
",tests/rosetta/transpiler/Python/esthetic-numbers.py,,0,0.999985261023967,"The method 'uabs' is a simple utility function that calculates the absolute difference between two numbers 'a' and 'b'. However, instead of returning the result, it uses 'sys.exit()' to terminate the program with the difference as the exit code. This is not a typical or useful behavior for a function that calculates a difference, as it doesn't allow the caller to use the result in further computations. Additionally, using 'sys.exit()' in this way is unconventional and can lead to confusion or errors in larger programs. Therefore, it is likely that this method will be deleted or significantly refactored to return the difference instead of exiting the program."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/exponentiation-order.py,,1,4.1399375473943306e-08,"The method `_now()` is a utility function that generates a pseudo-random number based on a seed if `_now_seeded` is True, or returns the current time in nanoseconds otherwise. This function seems to be part of a larger system that requires either a deterministic sequence of numbers (when seeded) or a timestamp. Such utility functions are often useful in testing or in systems where time-based operations are needed. Unless there is a specific reason to remove it, such as redundancy or a shift in design requirements, it is likely to be retained."
survived,"async def test_relationship_resolver_validation():
    app, lifespan = create_app()
    async with lifespan(app) as ctx:
        session_factory = ctx[""session_factory""]
        mock_ctx = Mock(spec=EnrichContext)
        mock_ctx.request_context = Mock()
        mock_ctx.request_context.lifespan_context = {""session_factory"": session_factory}

        get_orders = app.resources[""get_userenrichmodel_orders""]

        with pytest.raises(ValueError):
            await get_orders(user_id=1, page=0, page_size=1, ctx=mock_ctx)

        empty = await get_orders(page=1, page_size=1, ctx=mock_ctx)
        assert empty.items == []
        assert not empty.has_next
",tests/test_sqlalchemy_autogen_extra.py,,1,9.237449576640118e-09,"The method 'test_relationship_resolver_validation' is a test function that is likely part of a test suite for an application. Test functions are generally not deleted unless they are redundant or replaced by more comprehensive tests. This function appears to be testing the behavior of the 'get_orders' resource under certain conditions, which is valuable for ensuring the application's reliability and correctness. Therefore, it is likely to be retained as part of the test suite."
survived,"def test_devicon_py_file():
    file = MockFile('example.py')
    assert devicons.devicon(file) == ''
",tests/test_devicons.py,,1,6.348800075736417e-09,"The method `test_devicon_py_file` is a unit test function that checks if the `devicons.devicon` function correctly identifies a Python file and returns the appropriate icon. Unit tests are crucial for ensuring code reliability and correctness, especially in larger projects. They help in catching bugs early and verifying that the code behaves as expected. Therefore, this method is likely to be retained as part of the test suite to maintain code quality."
survived,"    def __init__(self, path, is_directory=False):
        self.relative_path = path
        self.is_directory = is_directory
        self.extension = os.path.splitext(path)[1][1:]
",tests/test_devicons.py,MockFile,1,2.0611536181902033e-09,"The method is a constructor for a class, likely intended to initialize an object with a file path and a flag indicating if it's a directory. It also extracts the file extension from the path. This is a common and useful pattern in object-oriented programming, especially for classes dealing with file management or manipulation. The method is straightforward, performs a clear function, and is likely to be used frequently in the context of the class it belongs to. Therefore, it is unlikely to be deleted."
survived,"    def publish(self, topic: str, env: messaging.Envelope) -> None:
        self.published.append((topic, env))
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_codegen_safety.py,DummyBus,1,6.348800075736417e-09,"The method 'publish' is a simple implementation that appends a tuple of 'topic' and 'env' to a list 'self.published'. This method is likely part of a larger system where messages or events are published to a topic. The method is straightforward, performs a clear function, and does not have any apparent issues or redundancies. Therefore, it is likely to be retained as it serves a specific purpose in the context of message handling or event publishing."
survived,"    def get_context(self) -> EnrichContext:
        """"""Return the current :class:`EnrichContext` for this app.""""""

        base_ctx = self.mcp.get_context()
        return EnrichContext(
            request_context=getattr(base_ctx, ""_request_context"", None),
            fastmcp=getattr(base_ctx, ""_fastmcp"", None),
        )
",src/enrichmcp/app.py,EnrichMCP,1,4.944450477491054e-09,"The method `get_context` is a straightforward utility function that retrieves and returns an `EnrichContext` object. It is likely a part of a larger system where context management is crucial, such as in web applications or services that require context propagation. The method is simple, clear, and serves a specific purpose of encapsulating context retrieval logic, which is a common pattern in software design. There is no indication of redundancy or obsolescence in the code provided, suggesting that it is still relevant and useful for its intended purpose."
survived,"def test_search_capabilities(tmp_path):
    reg = TemplateRegistry(base_dir=tmp_path)
    reg.register(_meta(""basic"", TemplateCategory.CONVERSATION), ""c1"")
    m2 = _meta(""web"", TemplateCategory.CONVERSATION)
    m2.requires_web_search = True
    reg.register(m2, ""c2"")

    engine = TemplateSearchEngine(reg)
    none = engine.search(""c"", capabilities=[])
    assert [r.slug for r in none] == [""basic""]

    cap = engine.search(""c"", capabilities=[""web_search""])
    slugs = {r.slug for r in cap}
    assert slugs == {""basic"", ""web""}",tests/test_template_search.py,,1,1.6052280526088547e-09,"The method `test_search_capabilities` is a test function that verifies the functionality of a template search engine. It checks if the search engine can correctly filter templates based on their capabilities, such as requiring web search. This is a crucial part of ensuring the search engine behaves as expected, especially in systems where templates have different requirements. Test functions like this are essential for maintaining code quality and are unlikely to be deleted unless the functionality they test is removed or significantly changed. Therefore, the method is likely to survive."
survived,"def _groups_equal(a: RolloutGroup, b: RolloutGroup) -> bool:
    """"""Deep equality helper via dataclasses.asdict with float tolerance.""""""

    da, db = asdict(a), asdict(b)
    # Allow tiny float differences in ""created""
    if abs(da[""created""] - db[""created""]) > 1e-9:
        return False
    da[""created""] = db[""created""] = 0  # normalise
    return da == db
",tests/rl/test_parquet_store.py,,1,5.60279640614594e-09,"The method _groups_equal is a utility function that checks for deep equality between two RolloutGroup objects, allowing for minor differences in floating-point values. This is a common requirement in software that deals with data comparison, especially when timestamps or floating-point calculations are involved. The method is well-defined, uses a standard approach with dataclasses, and addresses a specific need for tolerance in float comparisons. Such utility functions are often retained as they provide essential functionality for ensuring data consistency and correctness in applications."
survived,"    def build(self, inference: InferenceEndpoint, rollout_sink: RolloutSink) -> AbstractMarinEnv:
        """"""Instantiate the environment.

        The *rollout_sink* should be called with :class:`~marin.rl.types.RolloutGroup` batches.
        """"""
",marin/rl/config.py,AbstractEnvConfig,1,7.73442280641062e-08,"The method 'build' is a part of a class that seems to be related to setting up an environment for some form of machine learning or simulation task. The method is documented and appears to be a crucial part of the class's functionality, as it is responsible for instantiating the environment using the provided 'inference' and 'rollout_sink' parameters. This suggests that it is a core method necessary for the operation of the class, and therefore, it is unlikely to be deleted unless there is a significant refactor or change in the design of the system."
survived,"def test_chat_echo_env(openai_mock):  # type: ignore[valid-type]
    # Prepare mock response
    openai_mock.chat.completions.create.response = {
        ""choices"": [
            {
                ""index"": 0,
                ""finish_reason"": ""stop"",
                ""message"": {""content"": ""Hello! How can I help?"", ""role"": ""assistant""},
            }
        ]
    }

    # Collect rollouts emitted by the env
    collected: deque[RolloutGroup] = deque()

    def sink(groups: list[RolloutGroup]):
        collected.extend(groups)

    env = ChatEchoEnv(
        inference=InferenceEndpoint(""https://api.openai.com/v1""),
        rollout_sink=sink,  # type: ignore[arg-type]
        prompt=""Hello!"",
        max_iters=1,  # run exactly once then stop
        api_key=""sk-fake"",
    )

    asyncio.run(env.run())

    # Ensure sink received one rollout group with expected content
    assert len(collected) == 1
    rg = collected.pop()
    assert rg.rollouts[0].turns[0].message == ""Hello! How can I help?""
    # Mock should have been hit exactly once
    assert openai_mock.chat.completions.create.route.call_count == 1",tests/rl/test_openai_env.py,,1,1.1253518384332553e-07,"The method `test_chat_echo_env` is a unit test designed to verify the behavior of a `ChatEchoEnv` environment when interacting with a mocked OpenAI API. Unit tests are crucial for ensuring code reliability and are typically maintained as long as the functionality they test remains relevant. Since this test checks the integration with an API and ensures the environment behaves as expected, it is likely to be retained to prevent regressions in future code changes."
survived,"def write_rollout_groups(
    groups: list[RolloutGroup],
    root_path: str,
    *,
    compression: str = ""zstd"",
) -> None:
    """"""Append *groups* to a Parquet dataset located at *root_path*.

    Each call writes a new part file named ``part-<uuid>.parquet`` so that
    concurrent writers (e.g. many Ray env actors) can operate without locking.
    """"""

    # Resolve path to a pyarrow filesystem (handles ""gs://"", ""s3://"", etc.).
    fs, dataset_root = pafs.FileSystem.from_uri(root_path)

    # Ensure directory exists (noop if already present).  Some remote FS may
    # raise EEXIST—ignore it.
    try:
        fs.create_dir(dataset_root, recursive=True)
    except FileExistsError:
        pass

    table = _groups_to_table(groups)

    filename = f""{dataset_root.rstrip('/')}/part-{uuid.uuid4().hex}.parquet""
    pq.write_table(table, filename, compression=compression, filesystem=fs)
",marin/rl/parquet_store.py,,1,2.3355930333443423e-09,"The method 'write_rollout_groups' is a utility function that appends data to a Parquet dataset, handling concurrent writes and supporting various filesystems. It is a useful function for data processing tasks, especially in distributed environments. The method is well-documented, handles exceptions, and uses efficient data storage formats. These characteristics make it a valuable part of a codebase dealing with data storage and processing, suggesting it is likely to be retained."
survived,"    def sink(groups: list[RolloutGroup]):
        collected.extend(groups)
",tests/rl/test_openai_env.py,,1,6.348800075736417e-09,"The method 'sink' is a simple function that takes a list of 'RolloutGroup' objects and extends a global or external list 'collected' with these objects. The function itself is straightforward and performs a basic operation of list extension, which is a common and useful operation in many programming scenarios. There is no indication of redundancy, inefficiency, or obsolescence in the code provided. Therefore, it is likely to be retained as it serves a clear purpose in managing or aggregating data."
survived,"async def convert_alpha_tool(alpha: str) -> dict:
    return convert_alpha(alpha)
",alpha_factory_v1/demos/aiga_meta_evolution/workflow_demo.py,,1,2.3823698451773172e-07,"The method 'convert_alpha_tool' is a simple wrapper around the 'convert_alpha' function, adding asynchronous behavior. If 'convert_alpha' is a synchronous function, this wrapper might not be necessary unless there is a specific need to call it asynchronously. However, if the codebase is moving towards more asynchronous operations, this method could be useful. Without more context on the usage of 'convert_alpha' and the overall architecture, it's difficult to definitively say it will be deleted. However, given the trend towards asynchronous programming, it's likely to survive."
survived,"def reward(state: Any, action: Any, result: Any) -> float:
    """"""Compute a scalar reward in ``[0, 1]``.

    Parameters
    ----------
    state : Any
        Snapshot of the environment or agent state.
    action : Any
        Action executed by the agent.
    result : Any
        Observation or outcome returned by the environment.

    Returns
    -------
    float
        Normalised reward signal.
    """"""
    # TODO: replace this example logic with your custom calculation
    return 0.5",alpha_factory_v1/demos/era_of_experience/reward_backends/template.py,,0,0.9999869928752253,"The method is a placeholder function with a TODO comment indicating that the current logic is not the intended final implementation. It returns a constant value of 0.5, which is likely not useful for any real application. The presence of the TODO comment suggests that the method is expected to be replaced or significantly modified in the future. Therefore, the method in its current form is likely to be deleted or replaced once the actual reward calculation logic is implemented."
survived,"    def test_detect_supply_chain_alpha(self) -> None:
        msg = alpha_detection.detect_supply_chain_alpha()
        self.assertIsInstance(msg, str)
        self.assertTrue(""USD"" in msg or ""offline data missing"" in msg)
",tests/test_alpha_detection.py,TestAlphaDetection,1,2.3355930333443423e-09,"The method `test_detect_supply_chain_alpha` is a unit test designed to verify the behavior of the `detect_supply_chain_alpha` function from the `alpha_detection` module. It checks that the returned message is a string and contains either 'USD' or 'offline data missing'. This is a typical structure for a unit test, which is essential for maintaining code quality and ensuring that changes do not break existing functionality. Given the importance of testing in software development, this method is likely to be retained as part of the test suite."
survived,"    def launch_dashboard() -> None:  # type: ignore[return-type]
        """"""Placeholder when optional dependencies are absent.""""""
        raise RuntimeError(
            ""gradio and other optional packages are required for the MuZero demo""
        )
",alpha_factory_v1/demos/muzero_planning/__init__.py,,1,1.522997951276035e-08,"The method 'launch_dashboard' is a placeholder function that raises a RuntimeError when called, indicating that certain optional dependencies are missing. This is a common pattern used in code to handle situations where optional features are not available due to missing dependencies. The method is not intended to perform any actual functionality unless the required packages are installed. Since it serves a specific purpose in the codebase to handle missing dependencies gracefully, it is likely to be retained as part of the error handling strategy. Therefore, the method will likely survive."
survived,"    async def step(self) -> None:
        await self.publish(""alpha.compliance"", {""status"": ""ok""})
",alpha_factory_v1/demos/alpha_agi_business_v1/alpha_agi_business_v1.py,AlphaComplianceAgent,1,5.60279640614594e-09,"The method 'step' is an asynchronous function that performs a single task: publishing a message with a status to a specific channel. This is a common pattern in asynchronous programming, especially in systems that rely on message passing or event-driven architectures. The method is simple, clear, and serves a specific purpose, which makes it unlikely to be deleted unless the entire messaging system or the specific channel ('alpha.compliance') is deprecated or refactored. Therefore, the method is likely to survive."
survived,"async def trigger_compliance() -> str:
    resp = requests.post(f""{HOST}/agent/alpha_compliance/trigger"", timeout=5)
    resp.raise_for_status()
    return ""alpha_compliance queued""
",alpha_factory_v1/demos/alpha_agi_business_v1/openai_agents_bridge.py,,0,0.9999993524053853,"The method 'trigger_compliance' is likely to be deleted because it uses 'requests.post' in an asynchronous function without using an asynchronous HTTP library like 'aiohttp'. This can lead to blocking behavior, which is not ideal in an async context. Additionally, the method does not handle exceptions other than HTTP errors, which could lead to unhandled exceptions in production. These issues suggest that the method may be refactored or removed in favor of a more robust solution."
survived,"def _parse_args(argv: list[str] | None = None) -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description=""Call BusinessAgent via OpenAI Agents runtime""
    )
    parser.add_argument(
        ""--host"",
        default=os.getenv(""AGENTS_HOST"", ""http://localhost:5001""),
        help=""Base URL for the Agents runtime (default: http://localhost:5001)"",
    )
    parser.add_argument(
        ""--action"",
        default=""recent_alpha"",
        help=""Action to invoke (default: recent_alpha)"",
    )
    parser.add_argument(
        ""--job"",
        help=""Optional JSON file with a custom job payload"",
    )
    return parser.parse_args(argv)
",alpha_factory_v1/demos/alpha_agi_business_v1/examples/openai_agent_client.py,,1,2.3355930333443423e-09,"The method '_parse_args' is a utility function for parsing command-line arguments using the argparse library. It is a common practice in Python scripts to handle input parameters in a structured way. The method is well-defined, uses standard libraries, and provides default values and help descriptions for each argument, making it user-friendly and robust. There is no indication that this method is obsolete or redundant, and it serves a clear purpose in the context of the script. Therefore, it is likely to be retained in the codebase."
survived,"        def parse_dataset_iter(it: ast.expr) -> tuple[str, str | None, str | None, str | None]:
            sort = None
            skip = None
            take = None
            cur = it

            # handle take
            if isinstance(cur, ast.Subscript) and isinstance(cur.slice, ast.Slice):
                sl = cur.slice
                if (
                    sl.lower is None
                    and sl.step is None
                    and isinstance(sl.upper, ast.Call)
                    and getattr(sl.upper.func, ""id"", None) == ""max""
                    and len(sl.upper.args) == 2
                    and isinstance(sl.upper.args[1], ast.Constant)
                    and sl.upper.args[1].value == 0
                ):
                    take = self.convert_expr(sl.upper.args[0])
                    cur = cur.value

            # handle skip
            if isinstance(cur, ast.Subscript) and isinstance(cur.slice, ast.Slice):
                sl = cur.slice
                if (
                    sl.upper is None
                    and sl.step is None
                    and isinstance(sl.lower, ast.Call)
                    and getattr(sl.lower.func, ""id"", None) == ""max""
                    and len(sl.lower.args) == 2
                    and isinstance(sl.lower.args[1], ast.Constant)
                    and sl.lower.args[1].value == 0
                ):
                    skip = self.convert_expr(sl.lower.args[0])
                    cur = cur.value

            # handle sort
            if isinstance(cur, ast.Call) and isinstance(cur.func, ast.Name) and cur.func.id == ""sorted"":
                if cur.keywords:
                    for kw in cur.keywords:
                        if kw.arg == ""key"" and isinstance(kw.value, ast.Lambda):
                            body = kw.value.body
                            if (
                                isinstance(body, ast.Call)
                                and isinstance(body.func, ast.Name)
                                and body.func.id == ""_sort_key""
                                and body.args
                            ):
                                sort = self.convert_expr(body.args[0])
                            else:
                                sort = self.convert_expr(body)
                if cur.args:
                    cur = cur.args[0]

            # remove trivial list comp wrappers
            if (
                isinstance(cur, ast.ListComp)
                and len(cur.generators) == 1
                and isinstance(cur.generators[0].target, ast.Name)
                and isinstance(cur.elt, ast.Name)
                and cur.elt.id == cur.generators[0].target.id
                and not cur.generators[0].ifs
            ):
                cur = cur.generators[0].iter

            return self.convert_expr(cur), sort, skip, take
",tools/py2mochi/py2mochi.py,Converter,1,1.522997951276035e-08,"The method `parse_dataset_iter` is a utility function that parses an abstract syntax tree (AST) expression to extract specific components related to data manipulation: sorting, skipping, and taking elements. It is a specialized function that likely serves a specific purpose in a larger codebase, such as a data processing or query optimization system. The method is well-structured, handles different cases of AST nodes, and returns a tuple of parsed components, which suggests it is useful for its intended purpose. Unless the entire system is being refactored or replaced, this method is likely to survive as it provides a clear and necessary functionality."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/binary-digits.py,,1,1.275190675769241e-07,"The method _now() is a utility function that generates a pseudo-random number based on a seed if _now_seeded is True, otherwise it returns the current time in nanoseconds. This function seems to be a part of a larger system that requires either a deterministic sequence of numbers (when seeded) or the current time. Such utility functions are often useful in testing or in systems where time-based or pseudo-random number generation is needed. Unless there is a specific reason to remove it, such as redundancy or a shift in design requirements, it is likely to be retained."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/boolean-values.py,,1,1.0467401685178159e-08,"The method '_now' is a utility function that generates a pseudo-random number based on a seed if '_now_seeded' is True, otherwise it returns the current time in nanoseconds. This method is likely to survive because it provides a useful functionality for generating time-based or seeded pseudo-random numbers, which can be useful in various applications such as testing, simulations, or time-stamping events. Additionally, the method is simple, does not have any apparent bugs, and does not rely on deprecated or obsolete features."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/convert-decimal-number-to-rational.py,,1,2.5109990926928157e-08,"The method '_now' is a utility function that generates a pseudo-random number based on a seed if '_now_seeded' is True, otherwise it returns the current time in nanoseconds. This method is likely to survive because it provides a useful functionality for generating time-based or seeded pseudo-random numbers, which can be useful in various applications such as testing, simulations, or time-stamping events. Additionally, the method is simple, does not have any apparent bugs, and does not rely on deprecated or obsolete features."
survived,"async def test_explore_data_model_returns_summary() -> None:
    app = EnrichMCP(""My API"", description=""Demo server"")

    @app.entity(description=""Test entity"")
    class Item(EnrichModel):
        id: int = Field(description=""Identifier"")

    tool_name = ""explore_my_api_data_model""
    assert tool_name in app.resources

    summary = await app.resources[tool_name]()
    assert isinstance(summary, DataModelSummary)
    assert summary.title == ""My API""
    assert summary.entity_count == 1
    assert summary.entities == [""Item""]
    summary_text = str(summary)
    assert ""# My API"" in summary_text
    assert ""**Entity count:** 1"" in summary_text
    assert ""- Item"" in summary_text

    tools = await app.mcp.list_tools()
    tool = next(t for t in tools if t.name == tool_name)
    assert ""Call this tool FIRST"" in tool.description
    assert ""Demo server"" in tool.description",tests/test_explore_data_model.py,,1,5.60279640614594e-09,"The method `test_explore_data_model_returns_summary` is a test function that verifies the functionality of an API data model exploration tool. It checks if the tool is correctly registered, if it returns a summary with the expected properties, and if the tool's description contains specific text. This kind of test is crucial for ensuring the reliability and correctness of the API's functionality, especially in a development or testing environment. Therefore, it is likely to be maintained as part of the test suite to ensure ongoing quality assurance."
survived,"def test_bus_logs_start_stop(caplog: pytest.LogCaptureFixture) -> None:
    caplog.set_level(logging.INFO)
    cfg = config.Settings(bus_port=1234, broker_url=""kafka:9092"")
    bus = messaging.A2ABus(cfg)
    with mock.patch.object(messaging, ""AIOKafkaProducer"", None), \
         mock.patch.object(messaging, ""grpc"", None):
        asyncio.run(bus.start())
        asyncio.run(bus.stop())
    messages = [r.message for r in caplog.records]
    assert any(""Starting A2ABus"" in m and ""1234"" in m and ""kafka:9092"" in m for m in messages)
    assert any(""Stopping A2ABus"" in m for m in messages)",tests/test_bus_logging.py,,1,1.1032560311263802e-09,"The method `test_bus_logs_start_stop` is a unit test function that verifies the logging behavior of the `A2ABus` class when it starts and stops. It uses the `caplog` fixture to capture log messages and asserts that specific messages are present, indicating that the bus started and stopped correctly. This is a typical and necessary test to ensure that the logging functionality works as expected, which is crucial for debugging and monitoring purposes. Therefore, the method is likely to be retained as it serves an important role in the testing suite."
survived,"    async def step(self) -> None:
        # Pretend to fetch and summarise data
        await self.publish(""alpha.research"", {""summary"": ""market stable""})
",alpha_factory_v1/demos/alpha_agi_business_2_v1/alpha_agi_business_2_v1.py,ResearchAgent,1,5.3157849718487075e-08,"The method 'step' is an asynchronous function that simulates fetching and summarizing data, then publishes a message with a summary. This kind of functionality is common in applications that deal with real-time data processing or event-driven architectures. The method is simple, but it serves a clear purpose in the context of a system that needs to communicate updates or results asynchronously. Therefore, it is likely to be retained as it provides a useful operation within such a system."
survived,"def main() -> None:
    try:
        orchestrator.Orchestrator().run_forever()
    except KeyboardInterrupt:
        pass
",alpha_factory_v1/demos/alpha_agi_business_2_v1/alpha_agi_business_2_v1.py,,1,1.725782769012759e-08,"The method is a simple main function that initializes an orchestrator and runs it indefinitely, handling a KeyboardInterrupt gracefully. This is a common pattern in applications that need to run continuously until manually stopped, such as servers or services. The method is functional, concise, and handles a common use case effectively, so it is likely to be retained in the codebase."
survived,"def inc(x):
    return x + k
",tests/transpiler/x/py/pure_global_fold.py,,0,0.9999999895325983,"The method 'inc' is likely to be deleted because it references a variable 'k' that is not defined within the function or passed as a parameter. This will lead to a NameError when the function is called, making it non-functional in its current state. Without additional context or corrections, such as defining 'k' or passing it as an argument, the function is not usable."
survived,"    def get_router(cls) -> APIRouter:
        router = APIRouter()
        OutputModel = cls.OutputSchema

        @router.post(""/execute"", response_model=OutputModel)
        def execute_endpoint(payload: Dict[str, Any]) -> Any:
            input_obj = cls.InputSchema(**payload)
            instance = cls()
            result = instance.execute(input_obj.dict())
            return OutputModel(**result)

        return router
",servers/server_clear_thought/core/base_tool.py,BaseTool,1,3.160881453314576e-10,"The method 'get_router' is likely to survive because it is a well-structured and useful utility function for setting up an API router with a specific endpoint. It uses FastAPI's APIRouter to define a POST endpoint, which is a common pattern in web application development. The method is generic and can be reused across different classes that follow the same schema pattern, making it a valuable part of the codebase."
survived,"    async def meme_usage(_: None = Depends(verify_token)) -> dict[str, int]:
        """"""Return meme usage counts.""""""
        return _meme_usage
",src/interface/api_server.py,,1,2.1724399346070676e-10,"The method 'meme_usage' is a simple asynchronous function that returns a dictionary of meme usage counts. It uses a dependency injection pattern with 'Depends(verify_token)' to ensure that the token is verified before executing the function. This is a common pattern in web frameworks like FastAPI to handle authentication or authorization. The function itself is straightforward and serves a clear purpose, which is to provide usage statistics. There is no indication that this method is redundant or unnecessary, and it likely serves a useful role in the application. Therefore, it is likely to be retained."
survived,"def test_meme_reuse() -> None:
    rng = random.Random(0)
    op = SelfRewriteOperator(steps=3, rng=rng, templates=[""meme""], reuse_rate=1.0)
    result = op(""improve quick test"")
    assert result == ""meme""
    assert op.reuse_count >= 1
",tests/test_meme_reuse.py,,1,2.2159489282323004e-08,"The method 'test_meme_reuse' is a unit test designed to verify the functionality of the 'SelfRewriteOperator' class, specifically its ability to reuse a template. Unit tests are crucial for ensuring code reliability and are typically retained in the codebase to facilitate ongoing testing and development. The test checks that the operator returns the expected result and that the reuse count is incremented, which are important aspects of the class's functionality. Therefore, it is unlikely that this method will be deleted."
survived,"def test_meme_mining(tmp_path: Path) -> None:
    js_out = tmp_path / 'memeplex.js'
    subprocess.run(
        ['tsc', '--target', 'es2020', '--module', 'es2020', MEMEPLEX_TS, '--outFile', js_out],
        check=True,
    )
    script = tmp_path / 'run.mjs'
    script.write_text(
        f""import {{ mineMemes }} from '{js_out.resolve().as_posix()}';\n""
        ""const runs = [\n""
        ""  {edges:[{from:'A',to:'B'},{from:'B',to:'C'}]},\n""
        ""  {edges:[{from:'A',to:'B'}]},\n""
        ""  {edges:[{from:'A',to:'B'}]}\n""
        ""];\n""
        ""const memes = mineMemes(runs,2);\n""
        ""console.log(JSON.stringify(memes));\n"",
        encoding='utf-8',
    )
    res = subprocess.run(['node', script], capture_output=True, text=True, check=True)
    data = json.loads(res.stdout)
    assert len(data) == 1
    assert data[0]['count'] == 3",tests/test_memeplex_ts.py,,1,1.275190675769241e-07,"The method 'test_meme_mining' is a test function that appears to be part of a testing suite for a JavaScript/TypeScript project. It compiles TypeScript code to JavaScript, runs a script using Node.js, and checks the output against expected results. Such test functions are crucial for ensuring code correctness and are typically maintained as part of the development process. Therefore, it is unlikely to be deleted unless the functionality it tests is removed or significantly altered."
survived,"def test_generate_docs(tmp_path, monkeypatch):
    repo = tmp_path
    demos = repo / ""alpha_factory_v1"" / ""demos"" / ""demo_a""
    demos.mkdir(parents=True)
    (demos / ""README.md"").write_text(""# Demo A\nHello"", encoding=""utf-8"")
    assets = repo / ""docs"" / ""demo_a"" / ""assets""
    assets.mkdir(parents=True)
    (assets / ""preview.png"").write_text(""data"", encoding=""utf-8"")
    docs_demos = repo / ""docs"" / ""demos""

    monkeypatch.setattr(gdd, ""REPO_ROOT"", repo)
    monkeypatch.setattr(gdd, ""DEMOS_DIR"", repo / ""alpha_factory_v1"" / ""demos"")
    monkeypatch.setattr(gdd, ""DOCS_DIR"", docs_demos)

    gdd.generate_docs()

    page = docs_demos / ""demo_a.md""
    text = page.read_text(encoding=""utf-8"")
    assert ""# Demo A"" in text
    assert ""![preview](../demo_a/assets/preview.png){.demo-preview}"" in text
    assert ""[View README](../../alpha_factory_v1/demos/demo_a/README.md)"" in text",tests/test_generate_demo_docs.py,,1,9.237449576640118e-09,"The method `test_generate_docs` is a unit test function that verifies the functionality of the `generate_docs` method from the `gdd` module. It uses `monkeypatch` to modify the environment and file paths to ensure the test is isolated and does not depend on external factors. The test checks if the documentation is generated correctly by asserting the presence of specific content in the generated markdown file. This is a typical and necessary test to ensure the documentation generation feature works as expected. Since it is a well-structured test that serves a clear purpose, it is likely to be retained in the codebase."
survived,"    def __repr__(self) -> str:  # pragma: no cover - trivial
        data = self.model_dump()
        for k in tuple(data):
            if any(s in k.lower() for s in (""token"", ""key"", ""password"")) and data[k]:
                data[k] = ""***""
        return f""Settings({data})""
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/config.py,Settings,1,1.725782769012759e-08,"The method is a customized __repr__ method for a class, which is a common practice in Python to provide a string representation of an object. This method is particularly useful for debugging and logging purposes. It includes a security feature that masks sensitive information such as tokens, keys, and passwords, which is a good practice for protecting sensitive data. The use of 'pragma: no cover' suggests that this method is considered trivial and not necessary to cover in tests, indicating that it is stable and unlikely to change. Therefore, it is likely to be retained in the codebase."
survived,"    def test_concurrent_writes_with_filelock(self) -> None:
        try:
            import filelock
        except Exception:  # pragma: no cover - optional dependency
            self.skipTest(""filelock not installed"")

        from alpha_factory_v1.demos.cross_industry_alpha_factory import (
            cross_alpha_discovery_stub as stub,
        )

        with tempfile.TemporaryDirectory() as tmp:
            ledger = Path(tmp) / ""thread_lock_log.json""

            def worker(seed: int) -> None:
                stub.discover_alpha(num=1, seed=seed, ledger=ledger, model=""gpt-4o-mini"")

            threads = [threading.Thread(target=worker, args=(i,)) for i in range(5)]
            with patch.object(stub, ""FileLock"", filelock.FileLock):
                for t in threads:
                    t.start()
                for t in threads:
                    t.join()

            data = json.loads(ledger.read_text())
            self.assertIsInstance(data, list)
            self.assertEqual(len(data), 5)
            self.assertEqual(len(data), len({json.dumps(i, sort_keys=True) for i in data}))
",tests/test_cross_alpha_discovery.py,TestCrossAlphaDiscoveryStub,1,2.2159489282323004e-08,"The method 'test_concurrent_writes_with_filelock' is a test function that verifies the functionality of concurrent writes using file locks. It is a useful test to ensure that the system behaves correctly under concurrent conditions, which is a common scenario in many applications. The test is well-structured, using threads to simulate concurrent access and checking the integrity of the written data. Additionally, it handles the optional dependency on 'filelock' gracefully by skipping the test if the module is not installed. These factors make it a valuable test case that is likely to be retained in the codebase."
survived,"            async def __aenter__(self_inner):
                return Response()
",src/aiohttp/__init__.py,ClientSession._RespCtx,1,3.3982678079468468e-09,"The method `__aenter__` is part of the asynchronous context manager protocol in Python, which is used to define asynchronous context managers. The presence of this method suggests that the class is intended to be used with an `async with` statement, which is a common and useful pattern in asynchronous programming. The method returns a `Response` object, which implies it is likely part of a larger framework or library that deals with asynchronous operations, such as handling HTTP requests or similar tasks. Given the increasing use of asynchronous programming in Python, this method is likely to be useful and relevant, thus it will survive."
survived,"def test_usage_accumulation():
    t = TelemetryCollector(cost_cap=1.0)
    t.add_usage(500, 500, model=""o3"")
    assert t.token_count == 1000
    assert pytest.approx(t.cost, 0.0001) == 0.01
",tests/unit/test_telemetry_collector.py,,1,1.1861120010657661e-08,"The method 'test_usage_accumulation' is a unit test designed to verify the functionality of the 'TelemetryCollector' class, specifically the 'add_usage' method. Unit tests are crucial for ensuring code reliability and correctness, especially in production environments. The test checks if the token count and cost calculations are accurate, which are essential aspects of the 'TelemetryCollector' class. Therefore, this method is likely to be retained as it serves an important role in maintaining code quality."
survived,"    def stop_timer(self) -> None:
        """"""Stop the latency timer and accumulate duration.""""""
        if self._start is not None:
            self.latency += time.perf_counter() - self._start
            self._start = None
",src/meta_agent/telemetry.py,TelemetryCollector,1,2.0611536181902033e-09,"The method `stop_timer` is likely to survive because it performs a crucial function of stopping a timer and accumulating the duration, which is a common requirement in performance monitoring and latency tracking. The method is simple, well-defined, and serves a clear purpose in managing timing operations, which are essential in many applications for performance analysis and optimization."
survived,"    def _init_db(self) -> None:
        cur = self.conn.cursor()
        cur.execute(
            """"""
            CREATE TABLE IF NOT EXISTS telemetry (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT NOT NULL,
                tokens INTEGER,
                cost REAL,
                latency REAL,
                guardrail_hits INTEGER
            )
            """"""
        )
        self.conn.commit()
",src/meta_agent/telemetry_db.py,TelemetryDB,1,8.152020648014727e-09,"The method `_init_db` is responsible for initializing a database table if it does not already exist. This is a fundamental operation in many applications that require persistent data storage. The method uses standard SQL commands to create a table with specific columns, which suggests it is part of setting up the necessary infrastructure for the application to function correctly. Such methods are typically essential for the application's operation and are unlikely to be removed unless there is a significant change in how data is managed or stored. Therefore, it is likely to survive."
survived,"    def __init__(self, *args, **kwargs):
        self.request_info = kwargs.get(""request_info"")
        self.history = kwargs.get(""history"")
        self.status = kwargs.get(""status"")
        self.message = kwargs.get(""message"")
        self.headers = kwargs.get(""headers"")
        super().__init__(self.message)
",src/aiohttp/__init__.py,ClientResponseError,1,7.73442280641062e-08,"The method is a constructor for a class, likely inheriting from another class, as indicated by the call to `super().__init__(self.message)`. It initializes several instance variables using keyword arguments, which is a common and flexible pattern in Python. This allows the class to be easily extended or modified without changing the constructor signature. The method is well-structured and follows a common pattern for handling optional parameters, making it likely to be useful in various contexts. Therefore, it is unlikely to be deleted."
survived,"async def trigger_best_alpha() -> str:
    """"""Read the bundled alpha opportunities and enqueue the best one.""""""
    try:
        path = Path(__file__).with_name(""examples"") / ""alpha_opportunities.json""
        data = json.loads(path.read_text(encoding=""utf-8""))
        best = max(data, key=lambda x: x.get(""score"", 0))
    except Exception as exc:  # pragma: no cover - file may be missing
        raise RuntimeError(f""failed to load alpha opportunities: {exc}"") from exc
    resp = requests.post(
        f""{HOST}/agent/alpha_execution/trigger"",
        json=best,
        timeout=5,
    )
    resp.raise_for_status()
    return ""best alpha queued""
",alpha_factory_v1/demos/alpha_agi_business_v1/openai_agents_bridge.py,,1,1.0467401685178159e-08,"The method 'trigger_best_alpha' is likely to survive because it performs a critical function of reading and processing data from a JSON file and then making an HTTP POST request to trigger an action based on the best data point. This kind of functionality is often essential in systems that rely on data-driven decision-making and automation. Additionally, the method includes error handling, which is a good practice for robustness. The use of asynchronous programming also suggests that it is designed to be efficient and non-blocking, which is beneficial in modern applications."
survived,"    async def broadcast_merkle_root(self) -> None:
        try:
            root = self.compute_merkle_root()
        except Exception as exc:  # pragma: no cover - corruption
            _log.warning(""Failed to compute Merkle root: %s"", exc)
            return
        if AsyncClient is None or not self.broadcast:
            _log.info(""Merkle root %s"", root)
            return
        try:
            client = AsyncClient(self.rpc_url or ""https://api.testnet.solana.com"")
            memo_prog = PublicKey(""MemoSq4gqABAXKb96qnH8TysNcWxMyWCqXgDLGmfcHr"")
            tx = Transaction().add(TransactionInstruction(program_id=memo_prog, data=root.encode(), keys=[]))
            signer = None
            if self.wallet:
                try:  # pragma: no cover - optional dependency
                    from solana.keypair import Keypair

                    signer = Keypair.from_secret_key(bytes.fromhex(self.wallet))
                except Exception as exc:  # noqa: BLE001 - invalid key
                    _log.warning(""Invalid wallet key: %s"", exc)
            if signer:
                await client.send_transaction(tx, signer)
            else:
                await client.send_transaction(tx)
            _log.info(""Broadcasted Merkle root %s"", root)
        except Exception as exc:  # pragma: no cover - network errors
            _log.warning(""Failed to broadcast Merkle root: %s"", exc)
        finally:
            try:
                await client.close()
            except Exception:  # pragma: no cover - ignore close errors
                pass
",alpha_factory_v1/common/utils/logging.py,Ledger,1,2.0611536181902033e-09,"The method 'broadcast_merkle_root' is likely to survive because it performs a critical function of broadcasting a Merkle root, which is essential in blockchain operations for ensuring data integrity. The method is well-structured with error handling for various potential issues such as computation errors, invalid keys, and network errors. It also includes logging for monitoring purposes, which is crucial for debugging and operational transparency. The use of async operations and handling of optional dependencies further indicates that this method is designed to be robust and adaptable, making it a valuable part of the codebase."
survived,"    def format(self, record: logging.LogRecord) -> str:  # noqa: D401 - short
        data = {
            ""ts"": datetime.fromtimestamp(record.created).isoformat(timespec=""seconds""),
            ""lvl"": record.levelname,
            ""name"": record.name,
            ""msg"": record.getMessage(),
        }
        return json.dumps(data)
",alpha_factory_v1/common/utils/logging.py,_JsonFormatter,1,1.0467401685178159e-08,"The method 'format' is a custom implementation for formatting log records into a JSON string. This is a common requirement in logging systems where logs need to be structured and easily parsable, especially in environments that use log aggregation tools. The method is concise, uses standard libraries, and provides a clear and useful output format. There is no indication that this method is redundant or unnecessary, and it serves a specific purpose that is likely to be useful in many applications. Therefore, it is likely to be retained."
survived,"    def __enter__(self) -> ""Ledger"":
        """"""Return ``self`` for context manager support.""""""
        return self
",alpha_factory_v1/common/utils/logging.py,Ledger,1,5.3157849718487075e-08,"The method is an implementation of the __enter__ method, which is part of the context management protocol in Python. This method is essential for objects that are intended to be used with the 'with' statement, allowing for resource management and ensuring that resources are properly acquired and released. Since context managers are a fundamental part of Python's resource management, this method is likely to be retained."
survived,"def _env_int(name: str, default: int) -> int:
    try:
        return int(os.getenv(name, default))
    except (TypeError, ValueError):
        return default
",alpha_factory_v1/common/utils/config.py,,1,1.725782769012759e-08,"The method '_env_int' is a utility function that attempts to retrieve an environment variable and convert it to an integer, returning a default value if the conversion fails. This is a common pattern in software development for handling environment variables, and it provides a robust way to ensure that a valid integer is returned even if the environment variable is not set or is not a valid integer. Such utility functions are often useful and reused across different parts of a codebase, making it likely to be retained."
survived,"    def __init__(self, settings: Settings) -> None:
        self.settings = settings
        self._subs: Dict[str, List[Callable[[EnvelopeLike], Awaitable[None] | None]]] = {}
        self._server: ""grpc.aio.Server | None"" = None
        self._producer: Optional[AIOKafkaProducer] = None
        self._handshake_peers: set[str] = set()
        self._handshake_failures: TTLCache[str, int] = TTLCache(maxsize=1024, ttl=self.HANDSHAKE_TTL)
        self._handshake_nonces: TTLCache[str, None] = TTLCache(maxsize=1024, ttl=self.HANDSHAKE_TTL)
",alpha_factory_v1/common/utils/messaging.py,A2ABus,1,7.73442280641062e-08,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class with specific attributes. It sets up important components like settings, subscriptions, server, producer, and handshake-related caches. These are likely crucial for the functionality of the class, especially in a context involving asynchronous operations and network communication. Therefore, it is unlikely to be removed unless the entire class is refactored or removed."
survived,"    async def stop_merkle_task(self) -> None:
        if self._task:
            self._task.cancel()
            try:
                await self._task
            except asyncio.CancelledError:  # pragma: no cover - expected
                pass
            self._task = None
",alpha_factory_v1/common/utils/logging.py,Ledger,1,3.160881453314576e-10,"The method 'stop_merkle_task' is likely to survive because it performs a crucial task of stopping an asynchronous task safely. It checks if a task is running, cancels it, and handles the potential 'CancelledError' exception, ensuring that the task is properly cleaned up. This is a common pattern in asynchronous programming to manage resources effectively and prevent potential issues with dangling tasks."
survived,"    async def start(self) -> None:
        self._rest_task, self._grpc_server = await start_servers(
            self._runners,
            self._model_max_bytes,
            self._mem,
            self._rest_port,
            self._grpc_port,
            self._loglevel,
            self._ssl_disable,
        )
",alpha_factory_v1/backend/services/api_server_service.py,APIServer,1,1.522997951276035e-08,"The method 'start' is an asynchronous method that initializes two server components, '_rest_task' and '_grpc_server', by calling 'start_servers' with several configuration parameters. This method is likely a crucial part of setting up the server infrastructure for an application, which suggests it is an integral part of the system's functionality. Therefore, it is unlikely to be deleted unless there is a significant architectural change or refactoring that replaces its functionality."
survived,"async def test_api_server_start_stop(monkeypatch):
    events = []

    async def fake_start_servers(*a, **k):
        events.append(""start"")

        async def sleeper():
            await asyncio.sleep(0)
        task = asyncio.create_task(sleeper())
        server = SimpleNamespace(stop=lambda code=0: events.append(""stop""))
        return task, server

    monkeypatch.setattr(
        ""alpha_factory_v1.backend.services.api_server_service.start_servers"",
        fake_start_servers,
    )

    srv = APIServer({}, 1, object(), 0, 0, ""INFO"", True)
    await srv.start()
    assert events == [""start""]
    await srv.stop()
    assert events[-1] == ""stop""",tests/test_api_server_service.py,,1,2.2159489282323004e-08,"The method `test_api_server_start_stop` is a unit test function that uses the `monkeypatch` fixture to replace the `start_servers` function with a fake implementation for testing purposes. This is a common practice in testing to isolate the function being tested from its dependencies. The method is well-structured, uses asynchronous programming correctly, and serves a clear purpose in verifying the start and stop behavior of the `APIServer`. There is no indication that this method is obsolete or redundant, and it is likely to be useful for ensuring the reliability of the server start/stop functionality. Therefore, it is likely to be retained in the codebase."
survived,"    async def stop(self) -> None:
        if self._rest_task:
            self._rest_task.cancel()
            with contextlib.suppress(asyncio.CancelledError):
                await self._rest_task
        if self._grpc_server:
            self._grpc_server.stop(0)",alpha_factory_v1/backend/services/api_server_service.py,APIServer,1,2.3355930333443423e-09,"The method 'stop' is likely to survive because it performs essential cleanup operations for asynchronous tasks and server instances. It checks if there are active tasks or servers and attempts to stop them gracefully, which is a common requirement in managing resources in asynchronous programming. The use of contextlib.suppress to handle exceptions also indicates a well-thought-out design to prevent unhandled exceptions during task cancellation."
survived,"def main() -> None:
    if update():
        print(""Workflow updated."")
    else:
        print(""Workflow already up to date."")
",tools/update_actions.py,,1,1.8189616842444243e-09,"The method 'main' is a simple function that checks if an update is needed and prints a message accordingly. It is a straightforward and useful utility function that can be part of a larger system to ensure workflows are current. There is no indication that this function is redundant or unnecessary, as it serves a clear purpose in maintaining workflow updates. Therefore, it is likely to be retained in the codebase."
survived,"def fetch_latest(owner_repo: str) -> tuple[str, str] | None:
    """"""Return the newest tag name and commit sha for a GitHub action.""""""
    url = f""https://api.github.com/repos/{owner_repo}/tags""
    try:
        resp = requests.get(url, timeout=60)
        resp.raise_for_status()
    except requests.RequestException as exc:
        sys.stderr.write(f""Failed to fetch {url}: {exc}\n"")
        return None
    tags = resp.json()
    if not tags:
        return None
    tag = tags[0]
    return tag[""name""], tag[""commit""][""sha""]
",tools/update_actions.py,,1,7.991959892315218e-11,"The method `fetch_latest` is likely to survive because it performs a useful function of fetching the latest tag and commit SHA from a GitHub repository. It handles exceptions gracefully, returns meaningful data, and uses a clear and concise implementation. The use of type hints and a docstring also suggests good coding practices, making it a valuable part of the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-h/compiler/py/q8.py,Auto1,1,4.1399375473943306e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a flexible and Pythonic way to access object attributes, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-h/compiler/py/q20.py,Auto3,1,4.1399375473943306e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-h/compiler/py/q4.py,_Group,1,1.1861120010657661e-08,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation here is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-h/compiler/py/q16.py,Auto1,1,1.725782769012759e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation, especially in cases where the object is designed to behave like a dictionary or needs dynamic attribute access. There is no indication that this method is redundant or incorrect, so it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-h/compiler/py/q14.py,Auto1,1,1.1861120010657661e-08,"The method is a simple implementation of the __getitem__ special method, which allows instances of the class to use the bracket notation (e.g., obj[key]) to access attributes. This is a common and useful pattern in Python, especially for classes that aim to mimic dictionary-like behavior. It provides a clear and concise way to access attributes dynamically, which can be very useful in various applications. Therefore, it is likely to be retained as it serves a practical purpose."
survived,"        def seed(self, seed: int) -> None:
            self._rand = random.Random(seed)
",src/meta_agent/embedding_models.py,_RandomNormal,1,1.6052280526088547e-09,"The method 'seed' is a simple utility function that initializes a random number generator with a given seed. This is a common practice in programming to ensure reproducibility of random operations. The method is straightforward, performs a useful function, and does not have any apparent issues or redundancies. Therefore, it is likely to be retained in the codebase."
survived,"        def normal(self, mu: float, sigma: float, size: int):
            return [self._rand.gauss(mu, sigma) for _ in range(size)]
",src/meta_agent/embedding_models.py,_RandomNormal,1,1.1032560311263802e-09,"The method 'normal' is a simple utility function that generates a list of random numbers following a Gaussian distribution, using the 'gauss' method from a random number generator object 'self._rand'. This is a common and useful functionality in many applications that require random sampling from a normal distribution. The method is straightforward, does not have any apparent issues, and serves a clear purpose. Therefore, it is likely to be retained in the codebase."
survived,"    def test_accumulate_entries(self) -> None:
        with tempfile.TemporaryDirectory() as tmp:
            ledger = Path(tmp) / 'log.json'
            for seed in ('1', '2'):
                result = subprocess.run(
                    [
                        sys.executable,
                        STUB,
                        '-n',
                        '1',
                        '--seed',
                        seed,
                        '--ledger',
                        str(ledger),
                        '--model',
                        'gpt-4o-mini',
                    ],
                    capture_output=True,
                    text=True,
                )
                self.assertEqual(result.returncode, 0, result.stderr)

            logged = json.loads(ledger.read_text())
            self.assertIsInstance(logged, list)
            self.assertEqual(len(logged), 2)
",tests/test_cross_alpha_discovery.py,TestCrossAlphaDiscoveryStub,1,1.4166087846364157e-09,"The method `test_accumulate_entries` is a unit test designed to verify the functionality of a script that logs entries to a JSON file. It uses a temporary directory to ensure no side effects on the file system, checks the return code of the subprocess to ensure it runs successfully, and validates the structure and content of the JSON log. This is a typical and useful test case for ensuring the reliability of the logging functionality, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained."
survived,"    def test_env_overrides_default_ledger(self) -> None:
        default = Path(STUB).with_name(""cross_alpha_log.json"")
        if default.exists():
            default.unlink()
        with tempfile.TemporaryDirectory() as tmp:
            ledger = Path(tmp) / ""env_log.json""
            env = os.environ.copy()
            env[""CROSS_ALPHA_LEDGER""] = str(ledger)
            result = subprocess.run(
                [
                    sys.executable,
                    STUB,
                    ""-n"",
                    ""1"",
                    ""--seed"",
                    ""3"",
                    ""--model"",
                    ""gpt-4o-mini"",
                ],
                capture_output=True,
                text=True,
                env=env,
            )
            self.assertEqual(result.returncode, 0, result.stderr)
            self.assertFalse(default.exists(), ""default ledger should not be used"")
            self.assertTrue(ledger.exists())
            data = json.loads(ledger.read_text())
            self.assertIsInstance(data, list)
            self.assertEqual(len(data), 1)
",tests/test_cross_alpha_discovery.py,TestCrossAlphaDiscoveryStub,1,2.5109990926928157e-08,"The method 'test_env_overrides_default_ledger' is a unit test designed to verify that an environment variable correctly overrides a default file path. It uses temporary directories and subprocesses to ensure the test environment is isolated and does not affect or depend on external state. This is a common and necessary practice in software testing to ensure code behaves as expected in different environments. The method is well-structured, uses assertions to validate behavior, and is likely part of a test suite that ensures the reliability of the software. Therefore, it is unlikely to be deleted as it serves an important role in maintaining code quality."
survived,"    def test_alpha_factory_import(self) -> None:
        mod = importlib.import_module(""alpha_factory_v1"")
        self.assertTrue(hasattr(mod, ""__version__""))
",tests/test_imports.py,TestImports,1,4.363462233903899e-09,"The method `test_alpha_factory_import` is a unit test that checks if the module `alpha_factory_v1` can be imported and if it has an attribute `__version__`. This is a basic and useful test to ensure that the module is correctly installed and versioned, which is important for maintaining compatibility and tracking changes. Such tests are generally considered good practice in software development, especially in environments where modules are frequently updated or changed. Therefore, it is likely to be retained."
survived,"    def setUp(self):
        self._registry_backup = AGENT_REGISTRY.copy()
        AGENT_REGISTRY.clear()
",tests/test_agents_registry.py,TestHealthQuarantine,1,5.043472052266442e-07,"The method `setUp` is a common method used in unit testing frameworks like `unittest` in Python. It is typically used to set up the test environment before each test method is run. The code provided shows that it backs up the current state of `AGENT_REGISTRY` and then clears it, which is a typical setup step to ensure tests run in a clean environment. This method is likely to be essential for the test suite to function correctly, as it ensures that each test starts with a known state. Therefore, it is unlikely to be deleted."
survived,"            async def step(self):
                return None
",tests/test_agents_registry.py,TestAgentRegistryFunctions.DAgent,0,0.9999999895325983,"The method 'step' is an asynchronous function that currently does nothing but return None. If this method is part of a larger codebase, it might be a placeholder for future implementation. However, if it remains unchanged and unused, it is likely to be deleted in future code clean-ups to maintain code quality and remove unnecessary parts. Without additional context indicating its planned use, the method is more likely to be deleted."
survived,"    def test_exception_metrics(self) -> None:
        agent = DummyAgent()
        agent._metrics_run = _Counter()
        agent._metrics_err = _Counter()
        agent._metrics_lat = _Gauge()
        asyncio.run(agent._safe_step({""agent"": agent.NAME}))
        self.assertEqual(agent.calls, 1)
        self.assertEqual(agent._metrics_run.count, 1)
        self.assertEqual(agent._metrics_err.count, 1)
        self.assertIsNotNone(agent._metrics_lat.value)
",tests/test_agent_base.py,TestSafeStep,1,4.1399375473943306e-08,"The method 'test_exception_metrics' is a unit test method, which is typically used to verify the functionality of code. Unit tests are crucial for ensuring code reliability and are generally not deleted unless they are redundant or replaced by more comprehensive tests. The method tests specific metrics related to an agent's operation, which suggests it is part of a testing suite to ensure the agent's behavior is correctly monitored and reported. Therefore, it is likely to be maintained as part of the codebase to ensure ongoing code quality and reliability."
survived,"    def test_battery_optim_no_pulp(self):
        with patch.object(energy_agent, ""pulp"", None):
            res = energy_agent._battery_optim([1, 2], [3, 4])
        self.assertEqual(res, {""schedule"": []})
",tests/test_energy_utils.py,TestEnergyUtils,1,2.3355930333443423e-09,"The method 'test_battery_optim_no_pulp' is a unit test that checks the behavior of the '_battery_optim' method when the 'pulp' attribute of 'energy_agent' is set to None. This is a valid test case to ensure that the method handles the absence of 'pulp' correctly and returns an expected result. Unit tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, this method is likely to be retained as part of the test suite."
survived,"def test_agent_runner_loop_publishes_heartbeat() -> None:
    agent = DummyAgent()
    runner = orchestrator.AgentRunner(agent)

    events: list[tuple[str, str]] = []

    class Bus:
        def publish(self, topic: str, env: messaging.Envelope) -> None:
            events.append((""pub"", env.sender))

    class Ledger:
        def log(self, env: messaging.Envelope) -> None:
            events.append((""log"", env.sender))

    bus = Bus()
    led = Ledger()

    async def run_once() -> None:
        async def _sleep(_: float) -> None:
            raise asyncio.CancelledError()

        with patch.object(asyncio, ""sleep"", _sleep):
            with contextlib.suppress(asyncio.CancelledError):
                await runner.loop(bus, led)

    asyncio.run(run_once())

    assert agent.calls == 1
    assert (""pub"", ""dummy"") in events
    assert (""log"", ""dummy"") in events",tests/test_agent_runner.py,,1,1.444980317078884e-07,"The method is a test function that verifies the behavior of an agent runner loop, ensuring it publishes a heartbeat and logs it. It uses mock objects and assertions to validate the expected behavior. Test functions like this are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is unlikely to be deleted as it serves an important role in the testing suite."
survived,"        async def _sleep(_: float) -> None:
            raise asyncio.CancelledError()
",tests/test_agent_runner.py,,0,0.9999989322969233,"The method `_sleep` is designed to immediately raise an `asyncio.CancelledError` whenever it is called. This behavior is unusual for a method named `_sleep`, which typically implies a delay or pause in execution. Raising an exception immediately without performing any other operations makes the method effectively non-functional for its implied purpose. Additionally, the underscore prefix suggests it is intended for internal use, but even for internal methods, this behavior is not practical unless it is specifically used to test cancellation handling. Without further context indicating a specific use case for this behavior, it is likely that the method will be deleted or refactored to serve a more meaningful purpose."
survived,"async def test_loop_until_condition():
    counter = {""i"": 0}

    async def step(prompt, **kwargs):
        counter[""i""] += 1
        return counter[""i""]

    wf = Workflow(
        name=""wf"",
        steps=[
            WorkflowStep(
                runner=step,
                mode=StepMode.LOOP,
                condition=lambda r: r >= 2,
                max_iterations=5,
            )
        ],
    )

    result = await wf.run(0)
    assert result >= 2
    assert counter[""i""] <= 2",tests/test_workflow.py,,1,3.3982678079468468e-09,"The method 'test_loop_until_condition' is a test function that uses an asynchronous workflow to loop until a condition is met. It is well-structured and serves a clear purpose in testing the loop functionality of a workflow. The use of assertions ensures that the function behaves as expected, making it a valuable part of a test suite. Therefore, it is likely to be retained in the codebase."
survived,"def _no_missing(monkeypatch: pytest.MonkeyPatch) -> None:
    monkeypatch.setattr(check_env, ""REQUIRED"", [])
    monkeypatch.setattr(check_env, ""OPTIONAL"", [])
    monkeypatch.setattr(check_env, ""warn_missing_core"", lambda: [])
",tests/test_check_env_network.py,,1,3.3982678079468468e-09,"The method '_no_missing' is a utility function used in testing, specifically with the pytest framework. It uses the 'monkeypatch' fixture to modify the behavior of the 'check_env' module by setting its 'REQUIRED' and 'OPTIONAL' attributes to empty lists and changing the 'warn_missing_core' function to return an empty list. This is likely used to simulate an environment where no required or optional configurations are missing, which can be useful for testing purposes.

Such utility functions are common in test suites to ensure that tests can run in controlled environments. Since it serves a specific purpose in testing and does not have any apparent issues or redundancies, it is likely to be retained in the codebase as long as the tests that depend on it are relevant.

Therefore, the method is predicted to survive."
survived,"def test_scatter_set():
    B, V = Axis(""batch"", 2), Axis(""vocab"", 6)
    x = hax.zeros((B, V))
    idx = hax.named(jnp.array([1, 4]), B)
    val = hax.ones(B) * 9
    y = x.at[{V: idx}].set(val)
    ref = jnp.zeros((2, 6)).at[jnp.arange(2), idx.array].set(9)
    assert jnp.array_equal(y.array, ref)",tests/test_scatter_gather.py,,1,4.1399375473943306e-08,"The method 'test_scatter_set' is a unit test function that verifies the functionality of a scatter set operation using a hypothetical library 'hax'. It creates a zero-initialized array, sets specific indices to a value, and checks if the result matches the expected output. This is a typical pattern for unit tests, which are crucial for ensuring code correctness and stability. Since the method is a test function, it is likely to be retained as part of the test suite to ensure the functionality it covers remains correct over time."
survived,"    def __init__(self, max_seqs: int, max_len: int, eos: int):
        self.max_seqs = max_seqs
        self.max_len = max_len
        self.eos = eos
",src/levanter/inference/scheduler.py,JittedScheduler,1,1.725782769012759e-08,"The method is a constructor for a class, which is essential for initializing object instances with specific attributes. Constructors are fundamental to object-oriented programming, and there is no indication that this particular constructor is redundant or unnecessary. It sets up the initial state of an object with parameters that are likely important for the class's functionality."
survived,"    def __init__(self, eos: int):
        self.eos = eos
        self.waiting: Deque[Sequence] = deque()
        self.running: Deque[Sequence] = deque()
",src/levanter/inference/scheduler.py,Scheduler,1,9.931195248674785e-08,"The method is a constructor (__init__) for a class, which is essential for initializing object instances. Constructors are fundamental to object-oriented programming as they set up the initial state of an object. Therefore, it is unlikely to be deleted unless the entire class is being refactored or removed, which is not indicated here."
survived,"    def last_token(self) -> int:
        return self.token_ids[-1]
",src/levanter/inference/sequence.py,Sequence,1,1.8189616842444243e-09,"The method 'last_token' is a simple utility function that returns the last element of the 'token_ids' list. Such methods are often useful in various contexts where the last element of a list is needed frequently. It is a straightforward and efficient way to access the last token, assuming 'token_ids' is a list. Unless there is a significant change in the design or requirements that makes this method redundant or incorrect, it is likely to be retained. Therefore, the method will likely survive."
survived,"def slide_neighbours(n):
    movelist = []
    for gap in range(n*n):
        x, y = gap % n, gap // n
        moves = []
        if x > 0: moves.append(-1)    # Move the gap left.
        if x < n-1: moves.append(+1)  # Move the gap right.
        if y > 0: moves.append(-n)    # Move the gap up.
        if y < n-1: moves.append(+n)  # Move the gap down.
        movelist.append(moves)

    def neighbours(p):
        gap = p.index(0)
        l = list(p)

        for m in movelist[gap]:
            l[gap] = l[gap + m]
            l[gap + m] = 0
            yield (1, tuple(l), (l[gap], m))
            l[gap + m] = l[gap]
            l[gap] = 0

    return neighbours
",tests/rosetta/x/Python/15-puzzle-solver/15-puzzle-solver-1.py,,1,1.3440409770490404e-08,"The method 'slide_neighbours' is a utility function that generates possible moves for a sliding puzzle game, such as the 8-puzzle or 15-puzzle. It is a well-defined function that calculates possible moves based on the current position of the gap (zero) in the puzzle. This type of function is useful in puzzle-solving algorithms, such as A* or BFS, where generating possible states is crucial. The function is complete, logically structured, and serves a specific purpose in puzzle-solving contexts, making it unlikely to be deleted."
survived,"def listconflicts(goal_list):
    """"""
    list all possible start lists that will have at least
    one linear conflict.

    Possible goal tile configurations

    g g g g
    g g g x
    g g x g
    g x g g
    x g g g
    g g x x
    g x g x
    g x x g
    x g g x
    x g x g
    x x g g

    """"""

    all_tiles = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]

    non_goal_tiles = []

    for t in all_tiles:
        if t not in goal_list:
            non_goal_tiles.append(t)

    combinations = lcmap()

    # g g g g

    for i in goal_list:
        tile_list2 = goal_list[:]
        tile_list2.remove(i)
        for j in tile_list2:
            tile_list3 = tile_list2[:]
            tile_list3.remove(j)
            for k in tile_list3:
                tile_list4 = tile_list3[:]
                tile_list4.remove(k)
                for l in tile_list4:
                    start_list = (i, j, k, l)
                    conflictadd = linear_conflicts(start_list,goal_list)
                    if conflictadd > 0:
                        combinations[start_list]=conflictadd

    # g g g x

    for i in goal_list:
        tile_list2 = goal_list[:]
        tile_list2.remove(i)
        for j in tile_list2:
            tile_list3 = tile_list2[:]
            tile_list3.remove(j)
            for k in tile_list3:
                for l in non_goal_tiles:
                    start_list = (i, j, k, l)
                    conflictadd = linear_conflicts(start_list,goal_list)
                    if conflictadd > 0:
                        combinations[start_list]=conflictadd

    # g g x g

    for i in goal_list:
        tile_list2 = goal_list[:]
        tile_list2.remove(i)
        for j in tile_list2:
            tile_list3 = tile_list2[:]
            tile_list3.remove(j)
            for k in non_goal_tiles:
                for l in tile_list3:
                    start_list = (i, j, k, l)
                    conflictadd = linear_conflicts(start_list,goal_list)
                    if conflictadd > 0:
                        combinations[start_list]=conflictadd
    # g x g g

    for i in goal_list:
        tile_list2 = goal_list[:]
        tile_list2.remove(i)
        for j in non_goal_tiles:
            for k in tile_list2:
                tile_list3 = tile_list2[:]
                tile_list3.remove(k)
                for l in tile_list3:
                    start_list = (i, j, k, l)
                    conflictadd = linear_conflicts(start_list,goal_list)
                    if conflictadd > 0:
                        combinations[start_list]=conflictadd

    # x g g g

    for i in non_goal_tiles:
        for j in goal_list:
            tile_list2 = goal_list[:]
            tile_list2.remove(j)
            for k in tile_list2:
                tile_list3 = tile_list2[:]
                tile_list3.remove(k)
                for l in tile_list3:
                    start_list = (i, j, k, l)
                    conflictadd = linear_conflicts(start_list,goal_list)
                    if conflictadd > 0:
                        combinations[start_list]=conflictadd

    # g g x x

    for i in goal_list:
        tile_list2 = goal_list[:]
        tile_list2.remove(i)
        for j in tile_list2:
            tile_list3 = tile_list2[:]
            tile_list3.remove(j)
            for k in non_goal_tiles:
                tile_list4 = non_goal_tiles[:]
                tile_list4.remove(k)
                for l in tile_list4:
                    start_list = (i, j, k, l)
                    conflictadd = linear_conflicts(start_list,goal_list)
                    if conflictadd > 0:
                        combinations[start_list]=conflictadd

    # g x g x

    for i in goal_list:
        tile_list2 = goal_list[:]
        tile_list2.remove(i)
        for j in non_goal_tiles:
            tile_list3 = non_goal_tiles[:]
            tile_list3.remove(j)
            for k in tile_list2:
                for l in tile_list3:
                    start_list = (i, j, k, l)
                    conflictadd = linear_conflicts(start_list,goal_list)
                    if conflictadd > 0:
                        combinations[start_list]=conflictadd

    # g x x g

    for i in goal_list:
        tile_list2 = goal_list[:]
        tile_list2.remove(i)
        for j in non_goal_tiles:
            tile_list3 = non_goal_tiles[:]
            tile_list3.remove(j)
            for k in tile_list2:
                for l in tile_list3:
                    start_list = (i, j, k, l)
                    conflictadd = linear_conflicts(start_list,goal_list)
                    if conflictadd > 0:
                        combinations[start_list]=conflictadd

    # x g g x

    for i in non_goal_tiles:
        tile_list2 = non_goal_tiles[:]
        tile_list2.remove(i)
        for j in goal_list:
            tile_list3 = goal_list[:]
            tile_list3.remove(j)
            for k in tile_list3:
                for l in tile_list2:
                    start_list = (i, j, k, l)
                    conflictadd = linear_conflicts(start_list,goal_list)
                    if conflictadd > 0:
                        combinations[start_list]=conflictadd

    # x g x g

    for i in non_goal_tiles:
        tile_list2 = non_goal_tiles[:]
        tile_list2.remove(i)
        for j in goal_list:
            tile_list3 = goal_list[:]
            tile_list3.remove(j)
            for k in tile_list3:
                for l in tile_list2:
                    start_list = (i, j, k, l)
                    conflictadd = linear_conflicts(start_list,goal_list)
                    if conflictadd > 0:
                        combinations[start_list]=conflictadd

    # x x g g

    for i in non_goal_tiles:
        tile_list2 = non_goal_tiles[:]
        tile_list2.remove(i)
        for j in tile_list2:
            for k in goal_list:
                tile_list3 = goal_list[:]
                tile_list3.remove(k)
                for l in tile_list3:
                    start_list = (i, j, k, l)
                    conflictadd = linear_conflicts(start_list,goal_list)
                    if conflictadd > 0:
                        combinations[start_list]=conflictadd

    return combinations
",tests/rosetta/x/Python/15-puzzle-solver/15-puzzle-solver-2.py,,1,7.3382086014706e-07,"The method `listconflicts` is a complex function that generates all possible start lists that will have at least one linear conflict with a given goal list. It does this by iterating over various combinations of goal and non-goal tiles and checking for conflicts using a function `linear_conflicts`. The method is quite comprehensive in its approach, covering all possible configurations of tiles.

The function is unlikely to be deleted because it serves a specific purpose in calculating linear conflicts, which is a common problem in puzzle-solving algorithms, such as the 15-puzzle. The function is well-documented, and its logic is clear, making it a valuable utility for anyone working on similar problems. Additionally, the function's complexity and the fact that it is not trivial to rewrite from scratch suggest that it is a useful piece of code that would be retained in a codebase."
survived,"    def __repr__(self):
        # printable version of self
        strrep = """"
        for e in self.qheap:
          fscore, tiles = e
          strrep += str(fscore)+"":""+str(tiles)+""\n""

        return strrep
",tests/rosetta/x/Python/15-puzzle-solver/15-puzzle-solver-2.py,PriorityQueue,1,5.3157849718487075e-08,"The method is a standard implementation of the __repr__ method, which is used to provide a string representation of an object. This is a common and useful method in Python, especially for debugging and logging purposes. It is not redundant or harmful, and it enhances the usability of the class by allowing easy inspection of its instances. Therefore, it is unlikely to be deleted."
survived,"    def test_list_option(self) -> None:
        result = subprocess.run([sys.executable, STUB, '--list'], capture_output=True, text=True)
        self.assertEqual(result.returncode, 0)
        data = json.loads(result.stdout)
        self.assertIsInstance(data, list)
        self.assertGreaterEqual(len(data), 5)
",tests/test_alpha_discovery_stub.py,TestAlphaDiscoveryStub,1,3.160881453314576e-10,"The method `test_list_option` is a unit test that verifies the functionality of a command-line option. It checks that the command returns a successful exit code, that the output is a JSON list, and that the list contains at least 5 elements. This is a typical and useful test to ensure the command-line tool behaves as expected. There is no indication that this test is redundant or obsolete, and it serves a clear purpose in validating the software's behavior. Therefore, it is likely to be retained."
survived,"    async def policy(self, obs, ctx):  # type: ignore[override]
        gens = int(obs.get(""gens"", 1)) if isinstance(obs, dict) else 1
        await evolve(gens)
        return await best_alpha()
",alpha_factory_v1/demos/aiga_meta_evolution/openai_agents_bridge.py,EvolverAgent,1,2.3355930333443423e-09,"The method 'policy' is an asynchronous function that takes two parameters, 'obs' and 'ctx'. It checks if 'obs' is a dictionary and retrieves the 'gens' value, defaulting to 1 if not present. It then calls an asynchronous 'evolve' function with 'gens' as an argument and returns the result of another asynchronous function 'best_alpha'. The method seems to be well-structured and serves a clear purpose in the context of an asynchronous operation, likely related to some form of evolutionary computation or optimization process. Without any apparent issues or redundancy, it is likely to be useful and thus survive."
survived,"def _rest_pnl() -> Any:
    """"""Return P&L via the REST fallback.""""""
    return requests.get(f""{BASE}/api/finance/pnl"", timeout=3).json()
",alpha_factory_v1/demos/finance_alpha/agent_control.py,,1,9.736200303530205e-10,"The method `_rest_pnl` is a simple function that makes a REST API call to retrieve P&L (Profit and Loss) data. It is a straightforward utility function that serves a specific purpose and is likely part of a larger system that requires this data. The function is well-defined, with a clear docstring explaining its purpose. Unless there are changes in the system architecture or the method is replaced by a more efficient or secure alternative, there is no immediate reason to delete it. Therefore, it is likely to survive."
survived,"        def run(self) -> None:
            pass
",alpha_factory_v1/demos/muzero_planning/agent_muzero_entrypoint.py,AgentRuntime,1,3.1201906230699086e-05,"The method 'run' is defined but not implemented, as it only contains a 'pass' statement. This suggests that it is a placeholder for future code or is meant to be overridden in a subclass. If this method is part of a base class intended for inheritance, it is likely to survive. However, if it is not used or overridden anywhere, it might be considered for deletion. Without additional context, it is more likely to survive as a placeholder or abstract method."
survived,"        def __init__(self, *_, **__):
            pass
",alpha_factory_v1/demos/muzero_planning/agent_muzero_entrypoint.py,AgentRuntime,0,0.9999930377415741,"The method is a constructor that takes arbitrary positional and keyword arguments but does nothing with them. This is often used as a placeholder or a way to prevent errors when subclassing, but it doesn't serve any functional purpose in its current form. Without any additional context or usage, it's likely to be removed or replaced with a more meaningful implementation."
survived,"async def reset_endpoint(background_tasks: BackgroundTasks):
    background_tasks.add_task(service.reset)
    return {""msg"": ""reset scheduled""}
",alpha_factory_v1/demos/aiga_meta_evolution/agent_aiga_entrypoint.py,,1,1.1628233028868813e-10,"The method 'reset_endpoint' is a simple and effective way to schedule a background task using the 'BackgroundTasks' utility. It is a common pattern in asynchronous web frameworks like FastAPI to offload tasks that do not need to be completed immediately. The method is concise, follows best practices for asynchronous programming, and provides a clear response to the client. There is no indication of redundancy or inefficiency that would warrant its deletion. Therefore, it is likely to be retained."
survived,"def test_experience_launcher_api_key(tmp_path: Path, monkeypatch: pytest.MonkeyPatch) -> None:
    script = Path(""alpha_factory_v1/demos/era_of_experience/run_experience_demo.sh"")
    config = script.parent / ""config.env""
    docker_log = tmp_path / ""docker.log""
    curl_log = tmp_path / ""curl.log""
    bin_dir = tmp_path / ""bin""
    bin_dir.mkdir()

    docker_stub = bin_dir / ""docker""
    docker_stub.write_text(
        ""#!/usr/bin/env bash\n""
        'echo ""$@"" >> ""$DOCKER_LOG""\n'
        'if [ ""$1"" = ""info"" ]; then echo ""{}""; fi\n'
        'if [ ""$1"" = ""version"" ]; then echo ""24.0.0""; fi\n'
        ""exit 0\n""
    )
    docker_stub.chmod(0o755)

    curl_stub = bin_dir / ""curl""
    curl_stub.write_text(
        ""#!/usr/bin/env bash\n""
        'echo ""$@"" >> ""$CURL_LOG""\n'
        'out=""""\n'
        ""for ((i=1;i<=$#;i++)); do\n""
        '  if [ ""${!i}"" = ""-o"" ]; then\n'
        ""    j=$((i+1))\n""
        ""    out=${!j}\n""
        ""  fi\n""
        ""done\n""
        'if [ -n ""$out"" ]; then echo sample > ""$out""; fi\n'
        'echo ""OK""\n'
    )
    curl_stub.chmod(0o755)

    env = os.environ.copy()
    env.update(
        {
            ""PATH"": f""{bin_dir}:{env['PATH']}"",
            ""SKIP_ENV_CHECK"": ""1"",
            ""SAMPLE_DATA_DIR"": str(tmp_path / ""samples""),
            ""DOCKER_LOG"": str(docker_log),
            ""CURL_LOG"": str(curl_log),
            ""OPENAI_API_KEY"": ""dummy"",
        }
    )

    if config.exists():
        config.unlink()
    try:
        result = subprocess.run([f""./{script.name}""], cwd=script.parent, env=env, capture_output=True, text=True)
        created = config.exists()
    finally:
        if config.exists():
            config.unlink()

    assert result.returncode == 0, result.stderr
    assert docker_log.exists()
    log = docker_log.read_text()
    assert ""--profile offline"" not in log
    assert created
",tests/test_experience_launcher.py,,1,1.0467401685178159e-08,"The method is a well-structured test function using pytest and monkeypatch to simulate and verify the behavior of a script. It includes setup, execution, and assertions to ensure the script runs correctly and logs are created as expected. This kind of test is essential for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is likely to be retained in the codebase."
survived,"    def __eq__(self, other):
        return (
            self.name == other.name
            and self.age == other.age
            and self.status == other.status
        )
",tests/machine/x/python/update_stmt.py,Person,1,2.998960815863541e-09,"The method is a standard implementation of the equality operator for a class, comparing the 'name', 'age', and 'status' attributes of two objects. This is a common and useful method for object comparison, especially in data classes or models where equality is determined by specific attributes. It is likely to be retained as it provides essential functionality for comparing instances of the class."
survived,"def test_grpc_bus_tls_message_exchange(tmp_path: Path) -> None:
    from alpha_factory_v1.demos.alpha_agi_insight_v1.src.utils import config, messaging

    port = _free_port()
    cert, key, ca = _make_cert(tmp_path)
    cfg = config.Settings(bus_port=port, bus_cert=cert, bus_key=key, bus_token=""tok"")
    bus = messaging.A2ABus(cfg)
    received: list[messaging.Envelope] = []

    async def run() -> None:
        bus.subscribe(""b"", lambda e: received.append(e))
        await bus.start()
        try:
            creds = grpc.ssl_channel_credentials(root_certificates=ca)
            async with grpc.aio.secure_channel(f""localhost:{port}"", creds) as ch:
                stub = ch.unary_unary(""/bus.Bus/Send"")
                payload = {
                    ""sender"": ""a"",
                    ""recipient"": ""b"",
                    ""payload"": {""v"": 1},
                    ""ts"": 0.0,
                    ""token"": ""tok"",
                }
                await stub(json.dumps(payload).encode())
            await asyncio.sleep(0.05)
        finally:
            await bus.stop()

    asyncio.run(run())
    assert received and received[0].payload[""v""] == 1
",tests/test_agents.py,,1,6.348800075736417e-09,"The method `test_grpc_bus_tls_message_exchange` is a test function that verifies the functionality of a gRPC message exchange over a secure channel. It is a part of a test suite, likely used to ensure that the messaging system works correctly with TLS encryption. Test functions are generally not deleted unless they are redundant, replaced by more comprehensive tests, or the functionality they test is removed. Since this test appears to be specific and useful for validating secure message exchange, it is likely to be retained."
survived,"    def _setup_opencl(self) -> None:
        """"""Initialize OpenCL context and compile kernel.""""""
        self._ctx = cl.create_some_context()
        self._queue = cl.CommandQueue(self._ctx)
        kernel = r""""""
        __kernel void sw_diag(
            __global const char* seq1,
            __global const char* seq2,
            __global int* H,
            const int len1,
            const int len2,
            const int diag,
            const int start_i,
            const int match,
            const int mismatch,
            const int gap)
        {
            int gid = get_global_id(0);
            int i = start_i + gid;
            int j = diag - i + 1;
            if(i<=len1 && j>=1 && j<=len2) {
                int diag_idx = (i-1)*(len2+1) + (j-1);
                int up_idx   = (i-1)*(len2+1) + j;
                int left_idx = i*(len2+1) + (j-1);
                int idx      = i*(len2+1) + j;
                int match_val = seq1[i-1]==seq2[j-1] ? match : mismatch;
                int diag_val  = H[diag_idx] + match_val;
                int up_val    = H[up_idx] + gap;
                int left_val  = H[left_idx] + gap;
                int val = diag_val;
                if(up_val > val) val = up_val;
                if(left_val > val) val = left_val;
                if(val < 0) val = 0;
                H[idx] = val;
            }
        }
        """"""
        self._prog = cl.Program(self._ctx, kernel).build()
",src/python/gpu_smith_waterman.py,SmithWatermanGPU,1,5.60279640614594e-09,"The method `_setup_opencl` is responsible for setting up an OpenCL context and compiling a kernel, which is a crucial step in utilizing GPU resources for parallel computation. This functionality is essential for applications that require high-performance computing, such as those involving large-scale data processing or complex simulations. Given the increasing reliance on GPU acceleration in various fields, this method is likely to be retained as it provides foundational support for leveraging OpenCL capabilities. Additionally, the method is well-defined and encapsulates a specific task, making it a candidate for survival."
survived,"def sync(
    neo4j_session: neo4j.Session,
    boto3_session: boto3.session.Session,
    regions: List[str],
    current_aws_account_id: str,
    update_tag: int,
    common_job_parameters: Dict,
) -> None:
    for region in regions:
        logger.info(
            f""Syncing ACM certificates for region {region} in account {current_aws_account_id}.""
        )
        certs = get_acm_certificates(boto3_session, region)
        transformed = transform_acm_certificates(certs, region)
        load_acm_certificates(
            neo4j_session,
            transformed,
            region,
            current_aws_account_id,
            update_tag,
        )

    cleanup_acm_certificates(neo4j_session, common_job_parameters)

    merge_module_sync_metadata(
        neo4j_session,
        group_type=""AWSAccount"",
        group_id=current_aws_account_id,
        synced_type=""ACMCertificate"",
        update_tag=update_tag,
        stat_handler=stat_handler,
    )",cartography/intel/aws/acm.py,,1,3.850741907939403e-09,"The method 'sync' is a crucial part of a data pipeline that synchronizes ACM certificates from AWS to a Neo4j database. It involves fetching data, transforming it, loading it into a database, and performing cleanup and metadata merging operations. These operations are essential for maintaining up-to-date and accurate data in the database, which is critical for applications relying on this data. The method is well-structured, follows a clear sequence of operations, and uses logging for monitoring, making it a robust and necessary component of the system. Therefore, it is unlikely to be deleted."
survived,"def test_queue_max_size() -> None:
    bus = EventBus(None, True, max_queue_size=2)
    bus.publish(""x"", {""v"": 1})
    bus.publish(""x"", {""v"": 2})
    bus.publish(""x"", {""v"": 3})
    events = bus.read_and_clear(""x"")
    assert events == {""x"": [{""v"": 2}, {""v"": 3}]}",tests/test_eventbus.py,,1,1.6052280526088547e-09,"The method `test_queue_max_size` is a unit test designed to verify the behavior of an `EventBus` class when the maximum queue size is set. It ensures that the queue correctly maintains only the most recent events up to the specified limit. This is a common and useful test to ensure that the `EventBus` class handles queue overflow as expected. Since it serves a clear purpose in testing the functionality of the `EventBus`, it is likely to be retained in the codebase."
survived,"    def _slice_batch_info(self, updated_seqs, old_seq_lens, new_table, new_token_counts, tokens):
        mask = updated_seqs >= 0
        safe_updated = hax.where(mask, updated_seqs, 0)

        gathered_page_indices = new_table.page_indices[""seq"", safe_updated]
        page_indices = hax.where(mask, gathered_page_indices, -1)

        seq_lens = new_table.seq_lens[""seq"", safe_updated]
        seq_lens = hax.where(mask, seq_lens, -1)

        num_seqs = hax.sum(mask).scalar()

        token_dests = hax.full(tokens.shape, -1, dtype=jnp.int32)
        seq_cursors = jnp.where(old_seq_lens.array < 0, 0, old_seq_lens.array)

        def token_body(i, carry):
            token_dests, seq_cursors = carry
            seq_id = tokens[""position"", i].scalar()

            def assign(carry):
                token_dests, seq_cursors = carry
                page_idx = seq_cursors[seq_id] // self.page_size
                page_offset = seq_cursors[seq_id] % self.page_size
                page = new_table.page_indices[""seq"", seq_id, ""page"", page_idx]
                dest = hax.where(page < 0, -1, page * self.page_size + page_offset)
                token_dests = token_dests.at[""position"", i].set(dest)
                seq_cursors = seq_cursors.at[seq_id].add(1)
                return token_dests, seq_cursors

            token_dests, seq_cursors = jax.lax.cond(seq_id >= 0, assign, lambda c: c, (token_dests, seq_cursors))
            return token_dests, seq_cursors

        token_dests, _ = jax.lax.fori_loop(0, tokens.axis_size(""position""), token_body, (token_dests, seq_cursors))

        cu_q_lens = hax.concatenate(
            ""seq"",
            [
                hax.zeros({""seq"": 1}, dtype=jnp.int32),
                hax.cumsum(new_token_counts, ""seq"", dtype=jnp.int32),
            ],
        )
        batch_info = PageBatchInfo(
            page_indices=page_indices,
            seq_lens=seq_lens,
            cu_q_lens=cu_q_lens,
            num_seqs=num_seqs,
            new_token_dests=token_dests,
            page_size=self.page_size,
        )
        return batch_info
",src/levanter/layers/page_table.py,PageTable,1,4.944450477491054e-09,"The method '_slice_batch_info' is a complex function that appears to be part of a larger system, likely dealing with batch processing or sequence handling in a machine learning or data processing context. It involves operations like masking, gathering indices, and handling sequences, which are common in such systems. The method is not trivial and seems to be well-integrated into the system, suggesting it serves a specific and necessary purpose. Without any indication of it being deprecated or replaced, it is likely to survive."
survived,"            def assign(carry):
                token_dests, seq_cursors = carry
                page_idx = seq_cursors[seq_id] // self.page_size
                page_offset = seq_cursors[seq_id] % self.page_size
                page = new_table.page_indices[""seq"", seq_id, ""page"", page_idx]
                dest = hax.where(page < 0, -1, page * self.page_size + page_offset)
                token_dests = token_dests.at[""position"", i].set(dest)
                seq_cursors = seq_cursors.at[seq_id].add(1)
                return token_dests, seq_cursors
",src/levanter/layers/page_table.py,PageTable,1,1.0467401685178159e-08,"The method 'assign' appears to be a utility function that is part of a larger data processing or transformation task. It manipulates indices and offsets within a data structure, likely for the purpose of organizing or accessing data efficiently. The method is not overly complex, and its functionality seems specific and necessary for the task it is designed for. There is no indication that it is redundant or obsolete, and it seems to be a part of a larger system that relies on this functionality. Therefore, it is likely to be retained in the codebase."
survived,"    def free_pages(self, seq_id: int) -> ""PageTable"":
        new_page_owners = hax.where(self.page_owners == seq_id, -1, self.page_owners)
        new_page_indices = self.page_indices.at[""seq"", seq_id].set(-1)
        new_seq_lens = self.seq_lens.at[""seq"", seq_id].set(-1)

        return dataclasses.replace(
            self,
            page_owners=new_page_owners,
            page_indices=new_page_indices,
            seq_lens=new_seq_lens,
        )
",src/levanter/layers/page_table.py,PageTable,1,2.1724399346070676e-10,"The method 'free_pages' is likely to survive because it performs a specific and useful operation within the context of managing page tables. It updates the page ownership, indices, and sequence lengths for a given sequence ID, which is a common requirement in memory management or similar systems. The method is well-defined, uses clear logic, and returns a modified instance of the class, indicating it is part of a larger system that relies on these updates. Unless there is a significant change in the system's requirements or architecture, this method is likely to remain relevant and necessary."
survived,"    async def invoke(
        self, prompt: str, context: Optional[Dict[str, Any]] | None = None
    ) -> str:
        """"""Generate a response for the given prompt.""""""
        ...
",src/meta_agent/services/guardrail_router.py,ModelAdapter,1,2.0611536181902033e-09,"The method 'invoke' is an asynchronous function designed to generate a response based on a given prompt and an optional context. This type of functionality is highly relevant in modern applications, especially those involving AI, chatbots, or any system requiring dynamic content generation. The use of async indicates that it is designed to handle potentially long-running operations without blocking, which is a best practice in contemporary software development. Given these factors, the method is likely to be retained as it provides essential functionality in a scalable and efficient manner."
survived,"def square(x):
    return x * x
",tests/kgtests/autograd/helpers.py,,1,2.3355930333443423e-09,"The method 'square' is a simple and commonly used utility function that calculates the square of a given number. Such functions are often retained in codebases because they provide a basic mathematical operation that can be reused in various contexts. Additionally, the function is correctly implemented and does not contain any errors or inefficiencies that would necessitate its removal. Therefore, it is likely to be retained in the codebase."
survived,"        def policy(_o: np.ndarray) -> int:
            """"""Random baseline policy used for Monte Carlo evaluation.""""""
            return random.randint(0, 3)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,POETGenerator,1,2.998960815863541e-09,"The method 'policy' is a simple implementation of a random baseline policy, which is often used in Monte Carlo evaluations as a control or comparison point. Such methods are typically retained in codebases for testing, benchmarking, or as a starting point for more complex policy development. The method is straightforward, has a clear purpose, and is likely to be useful in its current context, suggesting it will survive."
survived,"def test_openai_agents_installed_from_wheelhouse(tmp_path: Path, monkeypatch: pytest.MonkeyPatch) -> None:
    wheelhouse = tmp_path / ""wheels""
    wheelhouse.mkdir()
    _make_wheel(wheelhouse, ""openai-agents"", ""0.0.15"")

    monkeypatch.setattr(check_env, ""CORE"", [])
    monkeypatch.setattr(check_env, ""REQUIRED"", [])
    monkeypatch.setattr(check_env, ""OPTIONAL"", [""openai_agents""])
    monkeypatch.setattr(check_env, ""warn_missing_core"", lambda: [])
    monkeypatch.setattr(check_env, ""has_network"", lambda: False)
    monkeypatch.delitem(sys.modules, ""openai_agents"", raising=False)

    rc = check_env.main([""--auto-install"", ""--wheelhouse"", str(wheelhouse)])
    assert rc == 0
    mod = importlib.import_module(""openai_agents"")
    assert getattr(mod, ""__version__"", """") == ""0.0.15""",tests/test_aiga_offline_setup.py,,1,8.152020648014727e-09,"The method is a test function that verifies the installation of a specific version of a package from a local wheelhouse. It uses pytest's monkeypatching to simulate the environment and ensure the package is installed correctly. Such test functions are crucial for maintaining software quality and ensuring that dependencies are correctly managed. Therefore, it is likely to be retained as part of the test suite."
survived,"async def _make_client() -> tuple[AsyncClient, Any]:
    app = FastAPI()
    app.middleware(""http"")(mod._count_requests)

    @app.get(""/"")
    async def root():
        return {""ok"": True}

    transport = ASGITransport(app=app)
    client = AsyncClient(base_url=""http://test"", transport=transport)
    return client, app
",tests/test_rate_lock.py,,1,1.0467401685178159e-08,"The method '_make_client' is a utility function that sets up an asynchronous HTTP client for testing purposes using FastAPI and ASGITransport. It is a common pattern in testing environments to create such clients to simulate requests to the application without needing a live server. This method is likely to survive because it is useful for testing FastAPI applications, and there is no indication of it being deprecated or replaced by a better alternative."
survived,"def test_session_id_deterministic() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri()

    with sync_playwright() as p:
        browser = p.chromium.launch()
        page = browser.new_page()
        page.goto(url)
        page.evaluate(
            ""window.OTEL_ENDPOINT='https://example.com';""
            ""window.confirm=() => true;""
            ""navigator.sendBeacon=(...a)=>{window.beacon=a;return true;}""
        )
        page.reload()
        page.wait_for_selector(""#controls"")
        page.click(""text=Share"")
        page.evaluate(""window.dispatchEvent(new Event('beforeunload'))"")
        first = page.evaluate(""window.beacon[1]"")
        page.reload()
        page.evaluate(
            ""navigator.sendBeacon=(...a)=>{window.beacon=a;return true;}""
        )
        page.wait_for_selector(""#controls"")
        page.click(""text=Share"")
        page.evaluate(""window.dispatchEvent(new Event('beforeunload'))"")
        second = page.evaluate(""window.beacon[1]"")
        import json

        assert json.loads(first)[""session""] == json.loads(second)[""session""]
        browser.close()
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_telemetry.py,,1,7.194132978569833e-09,"The method `test_session_id_deterministic` is a test function that verifies the determinism of session IDs in a web application. It uses Playwright to automate a browser, navigate to a specific page, and simulate user interactions. The test checks that the session ID remains consistent across page reloads, which is a critical aspect of session management in web applications. This kind of test is essential for ensuring the reliability and correctness of session handling, which is a fundamental feature in many web applications. Therefore, the method is likely to be retained as it serves an important purpose in the testing suite."
survived,"    def test_csv_gz_load(dest_uri):
        """"""When the source URI is a gzipped CSV file, the data should be ingested.""""""
        with (
            patch(target_fs) as target_fs_mock,
            patch(""ingestr.src.filesystem.glob_files"", wraps=glob_files_override),
        ):
            target_fs_mock.return_value = test_fs
            schema_rand_prefix = f""testschema_fs_{get_random_string(5)}""
            dest_table = f""{schema_rand_prefix}.fs_{get_random_string(5)}""
            result = invoke_ingest_command(
                f""{protocol}://bucket?{auth}"",
                ""/data.csv.gz"",
                dest_uri,
                dest_table,
            )
            assert result.exit_code == 0
            assert_rows(dest_uri, dest_table, 5)
",ingestr/main_test.py,,1,6.348800075736417e-09,"The method 'test_csv_gz_load' is a test function that verifies the functionality of loading a gzipped CSV file into a destination URI. It uses mocking to simulate the file system and checks if the ingestion command executes successfully and the expected number of rows are present. Test functions are generally crucial for ensuring code reliability and correctness, especially in data processing pipelines. Therefore, it is unlikely to be deleted as it serves an important role in maintaining the integrity of the codebase."
survived,"    def test_parquet_gz_load(dest_uri):
        """"""When the source URI is a gzipped Parquet file, the data should be ingested.""""""
        with (
            patch(target_fs) as target_fs_mock,
            patch(""ingestr.src.filesystem.glob_files"", wraps=glob_files_override),
        ):
            target_fs_mock.return_value = test_fs
            schema_rand_prefix = f""testschema_fs_{get_random_string(5)}""
            dest_table = f""{schema_rand_prefix}.fs_{get_random_string(5)}""
            result = invoke_ingest_command(
                f""{protocol}://bucket?{auth}"",
                ""/data.parquet.gz"",
                dest_uri,
                dest_table,
            )
            assert result.exit_code == 0
            assert_rows(dest_uri, dest_table, 5)
",ingestr/main_test.py,,1,7.194132978569833e-09,"The method 'test_parquet_gz_load' is a test function that verifies the functionality of loading gzipped Parquet files. Test functions are crucial for ensuring code reliability and correctness, especially when dealing with data ingestion processes. The function uses mocking to simulate file system interactions and checks the success of the ingestion command. Given its role in maintaining code quality and preventing regressions, it is likely to be retained."
survived,"        def __exit__(self, *exc: object) -> None:
            pass
",tests/test_check_env_network.py,_Sock,0,0.9999546021442518,"The method `__exit__` is a special method in Python used in context managers to handle cleanup actions. However, in this code, the method is defined but not implemented (it only contains a `pass` statement). This suggests that the method is not performing any meaningful action, which could lead to its deletion if it is not needed for any specific functionality or if the context manager does not require any cleanup. However, if this is a placeholder for future implementation or if it is part of a larger framework where the method is expected to be overridden, it might survive. Without additional context, it is more likely to be deleted due to its current lack of functionality."
survived,"def test_capability_growth_params() -> None:
    """"""Capability growth should forward ``k`` and ``x0``.""""""
    val_default = forecast.capability_growth(0.5, curve=""logistic"")
    val_custom = forecast.capability_growth(0.5, curve=""logistic"", k=5.0, x0=0.0)
    assert val_custom == pytest.approx(forecast.logistic_curve(0.5, k=5.0))
    assert val_custom != val_default
",tests/test_forecast.py,,1,2.998960815863541e-09,"The method `test_capability_growth_params` is a unit test that verifies the behavior of the `capability_growth` function with different parameters. It checks that the function correctly forwards the parameters `k` and `x0` to the `logistic_curve` function and that the output changes when these parameters are modified. This is a useful test to ensure the function behaves as expected when different parameters are used, which is important for maintaining the correctness of the code. Therefore, the method is likely to be retained as it serves a valuable purpose in testing the functionality of the code."
survived,"    def fold_via(self, fn: Callable[..., CarryT]):
        """"""Return a function that folds over the sequence using ``fn``.

        ``fn`` should take a block and a carry and return a new carry. The
        returned function mirrors :func:`haliax.fold` over the block axis.
        """"""

        def do_fold(init: CarryT) -> CarryT:
            carry = init
            for block in self.blocks:
                carry = fn(block, carry)
                carry = tree_checkpoint_name(carry, self._carry_ckpt_name)
            return carry

        return do_fold
",src/haliax/nn/scan.py,BlockSeq,1,9.736200303530205e-10,"The method `fold_via` is a utility function that provides a way to fold over a sequence using a provided function `fn`. This is a common pattern in functional programming and is useful for aggregating or transforming data in a sequence. The method is well-documented, indicating its purpose and usage, which suggests it is intended for use by other parts of the code or by users of the library. Additionally, the method is generic and can be applied to various use cases, making it a valuable part of the codebase. Therefore, it is likely to be retained."
survived,"    def _tool(*_a: object, **_k: object) -> object:
        def _decorator(func: object) -> object:
            return func

        return _decorator
",tests/test_aiga_agents_import.py,,1,2.3823698451773172e-07,"The method _tool is a decorator factory that returns a decorator function (_decorator) which, in turn, returns the original function without any modifications. This pattern is often used to create decorators that can be extended or modified later. Since it is a utility function that can be useful for creating decorators, it is likely to be retained in the codebase for future use or extension."
survived,"        async def runner() -> None:
            self.assertIsInstance(self.agent.forecast_demand(), str)
            self.assertIsInstance(self.agent.optimise_dispatch(), str)
            self.assertIsInstance(self.agent.hedge_strategy(), str)
",tests/test_energy_agent.py,TestEnergyAgentSyncRun,1,2.646573631904765e-09,"The method 'runner' is an asynchronous function that is used to assert that the methods 'forecast_demand', 'optimise_dispatch', and 'hedge_strategy' of the 'agent' object return strings. This is a typical pattern in testing to ensure that methods return the expected data types. Since this is a utility function for testing purposes, it is likely to be retained as part of the test suite to ensure code reliability and correctness. Therefore, it is predicted to survive."
survived,"def test_dgm_import(tmp_path: Path) -> None:
    log_dir = Path(""tests/fixtures/dgm_logs"")
    db_path = tmp_path / ""archive.db""
    count = dgm_import.import_logs(log_dir, db_path=db_path)
    assert count == 80

    db = ArchiveDB(db_path)
    history = list(db.history(""h79""))
    assert len(history) == 80",tests/test_dgm_import.py,,1,9.237449576640118e-09,"The method 'test_dgm_import' is a test function, likely part of a test suite for a software project. Test functions are generally not deleted unless they are redundant, testing deprecated features, or replaced by more comprehensive tests. This function appears to be testing the import functionality of a logging system, which is a critical aspect of many applications. As long as the feature it tests remains relevant, the test is likely to be maintained to ensure the integrity of the import process."
survived,"    def update(self, metrics: Mapping[str, Mapping[str, float]]) -> None:
        """"""Update rolling stats and switch datasets when thresholds pass.""""""

        rate = metrics.get(self._dataset, {}).get(""pass_rate"")
        if rate is not None:
            self.history.append(rate)
        if not self.history:
            return
        avg = sum(self.history) / len(self.history)

        if self._dataset == self.MINI and avg >= 0.40:
            self._dataset = self.FULL
            self.history.clear()
            self.db.set_state(""dataset"", self._dataset)
            self._log.info(""switched dataset to %s"", self._dataset)
        elif self._dataset == self.FULL and avg >= 0.60:
            self._dataset = self.POLYGLOT
            self.history.clear()
            self.db.set_state(""dataset"", self._dataset)
            self._log.info(""switched dataset to %s"", self._dataset)",src/eval/fitness.py,CurriculumSwitcher,1,3.850741907939403e-09,"The method 'update' is likely to survive because it implements a clear and logical functionality for updating rolling statistics and switching datasets based on certain thresholds. This kind of functionality is essential in systems that adapt based on performance metrics, and the code is structured to handle these updates efficiently. Additionally, the use of logging and state management indicates that this method is part of a larger, well-maintained system, which further supports its continued relevance and utility."
survived,"    def dataset(self) -> str:
        """"""Return the active dataset name.""""""

        return self._dataset
",src/eval/fitness.py,CurriculumSwitcher,1,9.736200303530205e-10,"The method 'dataset' is a simple getter method that returns the name of the active dataset. Getter methods are commonly used in object-oriented programming to provide controlled access to private attributes. Since this method is straightforward, serves a clear purpose, and does not have any apparent issues, it is likely to be retained in the codebase."
survived,"    def test_task_waits_for_self_mod(self) -> None:
        archive = InMemoryArchive()
        events: list[Phase] = []
        current: Phase | None = None

        def hook(p: Phase) -> None:
            nonlocal current
            current = p

        def op(g):
            return g + 1

        async def evaluate(_g):
            events.append(current)
            return 0.0, 0.01

        asyncio.run(
            evolve(op, evaluate, archive, max_cost=0.02, phase_hook=hook)
        )

        assert Phase.SELF_MOD in events
        assert Phase.TASK_SOLVE in events
        first_task = events.index(Phase.TASK_SOLVE)
        assert all(e == Phase.SELF_MOD for e in events[:first_task])
",tests/test_phase_order.py,TestPhaseOrder,1,5.3157849718487075e-08,"The method `test_task_waits_for_self_mod` is a unit test function that verifies the behavior of a system involving phases and tasks. It uses an in-memory archive, a list to track events, and a hook function to update the current phase. The test checks that certain phases occur in a specific order during the execution of an asynchronous operation. This kind of test is crucial for ensuring the correct functionality of the system, especially in complex asynchronous workflows. Therefore, it is likely to be retained as part of the test suite to ensure ongoing reliability and correctness of the code."
survived,"def test_a2a_port_zero(monkeypatch):
    """"""`_A2A` should remain ``None`` when ``A2A_PORT=0``.""""""
    dummy = types.ModuleType(""a2a"")

    class DummySocket:
        def __init__(self, *args, **kwargs) -> None:  # pragma: no cover - dummy
            raise AssertionError(""should not be instantiated"")

    dummy.A2ASocket = DummySocket
    monkeypatch.setitem(sys.modules, ""a2a"", dummy)
    monkeypatch.setenv(""A2A_PORT"", ""0"")
    if MODULE in sys.modules:
        del sys.modules[MODULE]
    mod = importlib.import_module(MODULE)
    assert mod._A2A is None
",tests/test_alpha_agi_business_3_v1.py,,1,1.3440409770490404e-08,"The method `test_a2a_port_zero` is a unit test designed to verify that the `_A2A` attribute remains `None` when the environment variable `A2A_PORT` is set to `0`. This is a specific test case that ensures the correct behavior of the module under a particular configuration. Unit tests are crucial for maintaining code quality and ensuring that changes do not introduce regressions. Therefore, this method is likely to be retained as part of the test suite to ensure the robustness of the code."
survived,"def main() -> None:
    ap = argparse.ArgumentParser(description=""Export tree visualization data"")
    ap.add_argument(""logs"", type=Path, nargs=""+"", help=""JSONL log files"")
    ap.add_argument(
        ""-o"",
        ""--output"",
        type=Path,
        default=Path(""tree.json""),
        help=""Destination JSON path"",
    )
    args = ap.parse_args()

    recs = _read_logs(args.logs)
    tree = _build_tree(recs)
    args.output.write_text(json.dumps(tree, indent=2))
    print(f""Tree exported → {args.output}"")
",alpha_factory_v1/demos/alpha_agi_insight_v1/tools/export_tree.py,,1,2.3355930333443423e-09,"The method 'main' is a well-structured and functional piece of code that serves a clear purpose: it parses command-line arguments to read log files, processes them to build a tree structure, and exports this structure to a JSON file. This functionality is useful for users who need to visualize or further process log data. The code uses standard libraries and practices, making it robust and maintainable. There is no indication that this method is obsolete or redundant, and it aligns with common use cases in data processing and visualization. Therefore, it is likely to be retained in the codebase."
survived,"            def latest_log(self) -> str:
                return ""log""
",tests/test_openai_bridge_runtime.py,TestAIGABridgeRuntime.DummyEvolver,0,0.9996200154435826,"The method 'latest_log' is a simple method that returns a static string ""log"". It doesn't perform any dynamic operations or computations, nor does it interact with any class attributes or external resources. Such methods are often placeholders or stubs for future development. If the method is intended to be a placeholder for future functionality, it might survive. However, if it remains unchanged and unused, it is likely to be deleted as it doesn't add any value in its current form."
survived,"    def test_index_row_wildcard(self):
        """"""Select entire first row using wildcard""""""
        self.assert_eval_cmp('[[1 2 3] [4 5 6]]:@[0 []]', '[1 2 3]')
",tests/test_numpy_slice.py,TestNumpySliceBehavior,1,1.0467401685178159e-08,"The method 'test_index_row_wildcard' is a test case that appears to be part of a larger test suite. It is designed to verify the functionality of selecting an entire row from a matrix using a wildcard. Test methods are generally not deleted unless they are redundant, incorrect, or the functionality they test is no longer relevant. Since this method is specific in its purpose and there is no indication that it is redundant or incorrect, it is likely to be retained to ensure the tested functionality works as expected."
survived,"def test_python_available() -> None:
    browser_dir = Path(__file__).resolve().parents[1]
    repo_root = browser_dir.parents[3]
    py_snippet = """"""import ast, json, pathlib
txt = pathlib.Path('scripts/fetch_assets.py').read_text()
tree = ast.parse(txt)
assets = {}
for node in tree.body:
    if isinstance(node, ast.Assign):
        for t in node.targets:
            if getattr(t, 'id', None) == 'ASSETS':
                assets = ast.literal_eval(node.value)
print(json.dumps(list(assets.keys())))""""""
    node_code = f""""""
import {{ spawnSync }} from 'child_process';
const out = spawnSync('python', ['-'], {{
  input: `{py_snippet}`,
  cwd: {json.dumps(str(repo_root))},
  encoding: 'utf8',
}});
if (out.error) {{ throw out.error; }}
process.exit(out.status);
""""""
    res = subprocess.run([
        ""node"",
        ""-e"",
        node_code,
    ], cwd=browser_dir, capture_output=True, text=True)
    assert res.returncode == 0, res.stderr",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_build_python.py,,1,1.955568070542584e-08,"The method 'test_python_available' is a utility function that checks if Python is available and can execute a specific script. It is a test function that ensures the environment is correctly set up for Python execution, which is a common requirement in many development and testing environments. Such utility functions are often retained because they provide a necessary check for the proper functioning of the system, especially in environments where multiple languages and tools are used together. Therefore, it is likely to be retained."
survived,"    def latest_log(self):
        champ = self.best_genome or max(self.population, key=lambda g: sum(g.layers))
        msg = f""Champion {champ.sha}: {champ.to_json()}""
        if self.llm:
            msg += ""\n"" + self.llm(f""Critique genome {champ.to_json()} in ≤30 words."")
        return msg
",alpha_factory_v1/demos/aiga_meta_evolution/meta_evolver.py,MetaEvolver,1,6.69158608681505e-10,"The method 'latest_log' is likely to be Survived (1) because it provides a useful functionality of logging the best genome from a population, which is a common requirement in genetic algorithms or evolutionary computation. It also integrates with a language model (llm) to provide additional critique, enhancing its utility."
survived,"        def _worker(js: str):
            g = Genome.from_json(js)
            module = import_module(__name__)
            return module.MetaEvolver._simulate(module.MetaEvolver, g)
",alpha_factory_v1/demos/aiga_meta_evolution/meta_evolver.py,MetaEvolver,1,1.8189616842444243e-09,"The method '_worker' is a private helper function, indicated by the underscore prefix, which is commonly used in Python to denote non-public methods. It is designed to process a JSON string to create a Genome object and then simulate it using the MetaEvolver class. This method is likely part of a larger system for evolutionary computation or genetic algorithms. Given its specific utility and the fact that it is a private method, it is unlikely to be deleted unless the entire system is refactored or deprecated. Therefore, it is more likely to survive."
survived,"    def mutate(self) -> ""Genome"":
        g = copy.deepcopy(self)
        if random.random() < 0.4:
            idx = random.randrange(len(g.layers))
            delta = random.randint(-8, 8)
            new_size = max(4, min(128, g.layers[idx] + delta))
            layers = list(g.layers)
            layers[idx] = new_size
            if random.random() < 0.2 and len(layers) < 4:
                layers.insert(idx, random.choice([16, 32, 64]))
            g.layers = tuple(layers)
        if random.random() < 0.2:
            g.activation = random.choice(list(_ACT))
        if random.random() < 0.1:
            g.hebbian = not g.hebbian
        if random.random() < 0.15:
            g.novelty_weight = round(min(1.0, max(0.0, g.novelty_weight + random.uniform(-0.15, 0.15))), 2)
        return g
",alpha_factory_v1/demos/aiga_meta_evolution/meta_evolver.py,Genome,1,1.725782769012759e-08,"The method 'mutate' is a crucial part of evolutionary algorithms, which are commonly used in machine learning and artificial intelligence for optimizing neural network architectures. The method introduces randomness and variation into the 'Genome' object, which is essential for exploring the solution space and finding optimal configurations. The use of random mutations in layers, activation functions, and other parameters is a standard practice in genetic algorithms to ensure diversity and adaptability. Given its importance in evolutionary computation, it is unlikely that this method will be deleted."
survived,"    def _evaluate_population(self) -> List[float]:
        if self.parallel and _HAS_RAY:
            return self._ray_eval()
        return self._mp_eval() if self.parallel else self._thread_eval()
",alpha_factory_v1/demos/aiga_meta_evolution/meta_evolver.py,MetaEvolver,1,1.6052280526088547e-09,"The method '_evaluate_population' is a private method (indicated by the underscore prefix) and is likely part of a larger class that deals with evaluating a population, possibly in a genetic algorithm or similar context. The method provides flexibility in execution by supporting parallel processing with different backends (Ray, multiprocessing, or threading). This flexibility is valuable for performance optimization, especially in computationally intensive tasks. The method's design suggests it is well-integrated into a system that can benefit from parallel execution, making it unlikely to be removed unless the entire system undergoes a significant redesign. Therefore, the method is likely to survive."
survived,"def _wrap_mcp(agent: str, payload: Any) -> Dict[str, Any]:
    return {
        ""mcp_version"": ""0.1"",
        ""agent"": agent,
        ""ts"": _now_iso(),
        ""digest"": _sha256(json.dumps(payload, separators=("","", "":""))),
        ""payload"": payload,
    }
",alpha_factory_v1/backend/agents/drug_design_agent.py,,1,8.152020648014727e-09,"The method '_wrap_mcp' is a utility function that wraps a given payload with additional metadata such as the agent, timestamp, and a digest of the payload. This kind of functionality is often useful in systems where data integrity and tracking are important, such as logging, auditing, or communication between services. The method is generic and can be reused in various contexts where such a wrapping is needed. Therefore, it is likely to be retained in the codebase."
survived,"def _passes_filters(smi: str) -> bool:
    return PAINS_REGEX.search(smi) is None
",alpha_factory_v1/backend/agents/drug_design_agent.py,,1,4.944450477491054e-09,"The method `_passes_filters` is a utility function that checks if a given string `smi` passes certain filters defined by a regular expression `PAINS_REGEX`. This type of function is common in data processing and validation tasks, especially in fields like cheminformatics where filtering based on patterns is necessary. The function is simple, clear, and serves a specific purpose, making it likely to be retained unless the filtering logic itself becomes obsolete or is replaced by a more comprehensive solution. Therefore, it is likely to survive."
survived,"def test_safari_pyodide_fallback() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri()

    try:
        with sync_playwright() as p:
            browser = p.webkit.launch()
            context = browser.new_context(
                user_agent=(
                    ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) ""
                    ""AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.6 Safari/605.1.15""
                )
            )
            page = context.new_page()
            page.goto(url)
            page.wait_for_selector(""#controls"")
            page.wait_for_selector(""#toast.show"")
            assert ""Pyodide unavailable; using JS only"" in page.inner_text(""#toast"")
            assert page.evaluate(""typeof d3 !== 'undefined'"")
            browser.close()
    except PlaywrightError as exc:
        pytest.skip(f""Playwright browser not installed: {exc}"")",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_safari_pyodide.py,,1,7.73442280641062e-08,"The method 'test_safari_pyodide_fallback' is a test function that uses Playwright to automate a browser for testing purposes. It checks if a web page correctly falls back to JavaScript when Pyodide is unavailable. This is a specific test case that ensures the functionality of a web application under certain conditions. Such test functions are generally useful for maintaining the quality and reliability of software, especially in environments where different browser behaviors need to be accounted for. Therefore, it is likely to be retained as part of the test suite."
survived,"def _verify(dest: Path) -> None:
    expected = CHECKSUMS.get(dest.name)
    if expected:
        digest = hashlib.sha256(dest.read_bytes()).hexdigest()
        if digest != expected:
            raise RuntimeError(f""Checksum mismatch for {dest.name}"")
",scripts/download_hf_gpt2.py,,1,7.194132978569833e-09,"The method '_verify' is a utility function that checks the integrity of a file by comparing its checksum with an expected value. This is a common and useful operation in software development, especially for ensuring data integrity during file transfers or downloads. The method is well-defined, uses standard libraries, and serves a clear purpose. There is no indication that this method is obsolete or redundant, and it is likely to be useful in various contexts where file integrity needs to be verified. Therefore, it is likely to be retained in the codebase."
survived,"def test_rgb(h, f):
    """"""test for the SGI image library.""""""
    if h.startswith(b'\001\332'):
        return 'rgb'
",metaflow/_vendor/imghdr/__init__.py,,1,1.6052280526088547e-09,"The method 'test_rgb' is a simple utility function that checks if a given header 'h' starts with a specific byte sequence, indicating an SGI image format. This kind of function is often useful in image processing libraries to quickly identify file types. It is a straightforward and efficient way to perform this check, and such utility functions are commonly retained in codebases for their utility. Therefore, it is likely to survive."
survived,"def lidarr_export(cfg: configparser.ConfigParser) -> None:
    baseurl = cfg[""lidarr""][""baseurl""]
    api_key = cfg[""lidarr""][""api_key""]
    headers = {""Content-type"": ""application/json"", ""X-Api-Key"": api_key}
    url = f""{baseurl}/api/v1/artist""
    rsp = requests.get(url, headers=headers)
    rsp.raise_for_status()
    data = rsp.json()
    with open(""lidarr_backup.csv"", ""w"", newline="""", encoding=""utf-8"") as f:
        writer = csv.writer(f)
        writer.writerow([""artist"", ""foreignArtistId""])
        for d in data:
            writer.writerow([d.get(""artistName""), d.get(""foreignArtistId"")])
",arr_gui.py,,1,5.60279640614594e-09,"The method `lidarr_export` is likely to survive because it performs a useful function of exporting artist data from a Lidarr instance to a CSV file. It uses standard libraries like `configparser`, `requests`, and `csv`, which are commonly used for configuration management, HTTP requests, and CSV file handling, respectively. The method is straightforward, well-structured, and fulfills a specific purpose, making it a valuable utility function in applications that need to backup or export data from Lidarr."
survived,"    def gen_span_id(self) -> str:
        """"""Generate a new span ID.""""""
        return f""span_{uuid.uuid4().hex[:24]}""
",src/agents/tracing/setup.py,TraceProvider,1,7.194132978569833e-09,"The method 'gen_span_id' is a utility function that generates a unique span ID using the UUID library. This is a common requirement in many applications for tracking or logging purposes. The method is simple, efficient, and serves a clear purpose, making it unlikely to be removed unless the application's requirements change significantly or a different ID generation strategy is adopted."
survived,"    def __call__(self, text: str) -> str:
        words = text.split()
        if not words:
            return text
        idx = self.rng.randrange(len(words))
        w = words[idx].lower()
        words[idx] = self.synonyms.get(w, words[idx])
        return "" "".join(words)
",src/simulation/mats_ops.py,PromptRewrite,1,8.152020648014727e-09,"The method is a useful utility for replacing a random word in a given text with its synonym, if available. This can be beneficial for tasks like text variation, data augmentation, or simply enhancing text diversity. The method is straightforward, leverages randomness for variability, and uses a dictionary for synonym lookup, which is a common and effective approach. There are no apparent issues or inefficiencies in the code that would warrant its deletion."
survived,"        def raise_for_status(self) -> None:
            pass
",tests/test_llm_client_offline.py,DummyResp,0,0.9924227578181974,"The method `raise_for_status` is defined but not implemented (it uses `pass`), which suggests it might be a placeholder for future functionality. However, without any implementation, it currently does nothing. If this method is part of a larger class or module that is actively being developed, it might be retained for future use. On the other hand, if the codebase is being cleaned up or if this method has been in this state for a long time without any updates, it might be considered for deletion. Without additional context, it's difficult to definitively predict its fate, but generally, methods that do nothing are candidates for deletion unless they serve a clear purpose in the code structure."
survived,"def iter_demos() -> list[Path]:
    return sorted(p for p in DOCS_DIR.iterdir() if p.is_dir() and (p / ""index.html"").exists())
",scripts/verify_demo_pages.py,,1,3.850741907939403e-09,"The method 'iter_demos' is a concise and efficient way to list directories within 'DOCS_DIR' that contain an 'index.html' file. It uses modern Python features such as type hinting with 'list[Path]' and generator expressions, which are considered best practices. The method is clear, readable, and performs a common task that is likely useful in many contexts, such as generating a list of documentation directories. Therefore, it is likely to be retained in the codebase."
survived,"def test_publish_grpc() -> None:
    port = _free_port()
    cfg = config.Settings(bus_port=port, allow_insecure=True)
    bus = messaging.A2ABus(cfg)
    received: list[messaging.Envelope] = []

    def handler(env: messaging.Envelope) -> None:
        received.append(env)

    bus.subscribe(""x"", handler)

    async def run() -> None:
        async with bus:
            async with grpc.aio.insecure_channel(f""localhost:{port}"") as ch:
                stub = ch.unary_unary(""/bus.Bus/Send"")
                payload = {
                    ""sender"": ""a"",
                    ""recipient"": ""x"",
                    ""payload"": {""v"": 1},
                    ""ts"": 0.0,
                }
                await stub(json.dumps(payload).encode())
                await asyncio.sleep(0)

    asyncio.run(run())

    assert len(received) == 1
    assert received[0].payload[""v""] == 1
",tests/test_message_bus.py,,1,1.1861120010657661e-08,"The method 'test_publish_grpc' is a test function that verifies the functionality of a gRPC-based messaging system. It sets up a test environment, sends a message, and checks if the message is received correctly. Test functions are crucial for ensuring code reliability and are typically retained unless the functionality they test is deprecated or removed. Since this function is actively testing a feature, it is likely to be maintained as long as the feature it tests is relevant."
survived,"        def __call__(self, *args, **kwargs):  # noqa: D401
            raise ModuleNotFoundError(
                ""The OpenAI Agents SDK is required for this operation. ""
                ""Please install it with:  pip install openai-agents""
            )
",alpha_factory_v1/backend/__init__.py,_MissingSDK,1,4.006369513448866e-05,"The method is designed to raise an exception if called, indicating that a required SDK is not installed. This is a common pattern used to inform users about missing dependencies. The method itself is not performing any functional operation other than raising an error, which suggests it might be a placeholder or a temporary solution until the dependency is installed. However, this pattern is often used to ensure that users are aware of the missing requirement, and it serves a clear purpose in the codebase. Therefore, it is likely to be retained as long as the dependency is optional or not bundled with the main package."
survived,"  async def get_co2(self) -> CytomatIncupationResponse:
    return await self.get_incubation_query(""ic"")
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend,1,2.5109990926928157e-08,"The method `get_co2` is an asynchronous function that calls another method `get_incubation_query` with a specific parameter ""ic"". This suggests that it is part of a larger system dealing with incubation data, likely in a scientific or laboratory context. The method is specific and seems to be a necessary part of the system's functionality, especially if CO2 levels are a critical parameter being monitored. Without any indication of redundancy or obsolescence, it is likely to be retained."
survived,"  async def get_sensor_register(self) -> SensorStates:
    hex_value = await self.send_command(""ch"", ""ts"", """")
    binary_values = hex_to_base_twelve(hex_value)
    return SensorStates(
      **{member.name: bool(int(binary_values[member.value])) for member in SensorRegister}
    )
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend,1,8.592166611791576e-10,"The method 'get_sensor_register' is likely to survive because it is a well-structured asynchronous function that performs a specific task: sending a command to retrieve sensor data, converting the data, and returning it in a structured format. This functionality is essential for applications that require real-time sensor data processing, making it a valuable part of the codebase."
survived,"  async def send_action(
    self, command_type: str, command: str, params: str, timeout: Optional[int] = 60
  ) -> OverviewRegisterState:
    """"""Calls send_command, but has a timeout handler and returns the overview register state.
    Args:
      timeout: The maximum time to wait for the command to complete. If None, the command will not
        wait for completion.
    """"""
    await self.send_command(command_type, command, params)
    if timeout is not None:
      overview_register = await self.wait_for_task_completion(timeout=timeout)
    return overview_register
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend,1,5.905303995456778e-10,"The method 'send_action' is likely to survive because it provides a useful abstraction over the 'send_command' method by adding a timeout feature. This is a common requirement in asynchronous programming to prevent indefinite waiting for a task to complete. Additionally, the method is well-documented, specifying its purpose and parameters, which indicates good software engineering practices. The use of 'Optional[int]' for the timeout parameter also suggests that the method is designed with flexibility in mind, allowing for both specified and indefinite wait times. These factors contribute to the method's utility and maintainability, making it a candidate for survival."
survived,"  async def action_storage_to_transfer(  # used by retrieve_plate
    self, site: PlateHolder
  ) -> OverviewRegisterState:
    """"""Retrieve from storage, open door, move to transfer, close door""""""
    return await self.send_action(""mv"", ""st"", self._site_to_firmware_string(site))
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend,1,6.348800075736417e-09,"The method 'action_storage_to_transfer' is a specific utility function that is part of a larger system, likely dealing with robotic or automated systems for handling plates. It is used by another method 'retrieve_plate', indicating it is part of a workflow. The method is asynchronous, suggesting it is designed to handle operations that may take time, such as moving physical objects. The method is concise and directly calls another function 'send_action', which implies it is a wrapper or a higher-level abstraction for a specific action. Given its specific purpose and integration into a larger system, it is unlikely to be deleted unless the entire system or the specific functionality it supports is deprecated or refactored. Therefore, it is more likely to survive."
survived,"def cytomat_rack_10mm_47(name: str):
  return _cytomat_rack(name=name, site_height=10, num_sites=47, model=""cytomat_rack_10mm_47"")
",pylabrobot/storage/cytomat/racks.py,,1,4.6911638017642294e-08,"The method `cytomat_rack_10mm_47` is a simple wrapper function that calls another function `_cytomat_rack` with specific parameters. This kind of function is often used to simplify the API for users by providing a more descriptive or specific function name that sets certain parameters by default. Unless `_cytomat_rack` is deprecated or the specific configuration is no longer needed, there is no strong reason to delete this method. It provides a clear and specific utility."
survived,"  async def initialize(self):
    await self._send_command(""ST 1900"")
    await self._send_command(""ST 1801"")
    await self._wait_ready()
",pylabrobot/storage/cytomat/heraeus_cytomat_backend.py,HeraeusCytomatBackend,1,7.194132978569833e-09,"The method 'initialize' is an asynchronous function that sends two commands and waits for a ready state. This pattern is common in initializing or setting up connections or devices, which is a fundamental part of many systems. The method is likely to be essential for the proper functioning of the system it is part of, as it ensures that the necessary commands are sent and the system is ready before proceeding. Therefore, it is unlikely to be deleted unless the entire system or its initialization process is being refactored or removed."
survived,"  def deserialize(cls, data: dict):
    return cls(num_slots=data[""num_slots""], pitch=data[""pitch""])
",pylabrobot/storage/cytomat/constants.py,CytomatRack,1,1.0261879630648829e-10,"The method 'deserialize' is a common utility function used to convert a dictionary into an instance of a class. This is a typical pattern in object-oriented programming, especially when dealing with data serialization and deserialization. The method is straightforward and serves a clear purpose, making it unlikely to be removed unless the class itself is being deprecated or the method is replaced by a more comprehensive solution. Therefore, it is likely to survive."
survived,"  async def setup(self, **backend_kwargs):
    await super().setup()
    await self.backend.set_racks(self._racks)
",pylabrobot/storage/incubator.py,Incubator,1,7.582560422162384e-10,"The method 'setup' is an asynchronous method that overrides a parent class's 'setup' method and adds additional functionality by setting racks in the backend. This indicates that it is part of a larger system where asynchronous operations are necessary, likely due to I/O operations or network requests. The method is concise, clear, and serves a specific purpose, which suggests it is well-designed and necessary for the system's operation. Therefore, it is likely to be retained in the codebase."
survived,"  def _site_to_firmware_string(self, site: PlateHolder) -> str:
    rack = cast(PlateCarrier, site.parent)
    rack_idx = [rack.name for rack in self._racks].index(
      rack.name
    )  # autoreload resistant, should work
    site_idx = next(idx for idx, s in rack.sites.items() if s == site)

    if self.model in [CytomatType.C2C_425]:
      return f""{str(rack_idx).zfill(2)} {str(site_idx).zfill(2)}""

    # TODO: configure all cytomats to use `rack site` format
    if self.model in [
      CytomatType.C6000,
      CytomatType.C6002,
      CytomatType.C2C_450_SHAKE,
      CytomatType.C5C,
    ]:
      slots_to_skip = sum(r.capacity for r in self._racks[:rack_idx])
      absolute_slot = slots_to_skip + site_idx + 1  # 1-indexed

      return f""{absolute_slot:03}""

    raise ValueError(f""Unsupported Cytomat model: {self.model}"")
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend,1,1.1253518384332553e-07,"The method '_site_to_firmware_string' is highly specific to the context of handling different Cytomat models and converting site information into a firmware string format. It includes logic for different models and raises an error for unsupported models, indicating its importance in ensuring correct operation with different hardware configurations. The presence of a TODO comment suggests that there is an intention to expand or modify its functionality in the future, rather than remove it. Therefore, it is likely to be maintained and possibly updated rather than deleted."
survived,"  async def initialize(self) -> None:
    await self.send_action(""ll"", ""in"", """", timeout=300)  # this command sometimes times out
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend,1,1.522997951276035e-08,"The method 'initialize' is an asynchronous function that calls another asynchronous method 'send_action'. The comment indicates that the command sometimes times out, which suggests that there might be a need for error handling or retry logic. However, the method itself is functional and serves a purpose in the codebase. Without additional context indicating that this method is obsolete or replaced, it is likely to survive as it performs an initialization task that is presumably necessary for the application."
survived,"  async def start_shaking(self, frequency: float):
    print(f""Starting shaking at {frequency} Hz"")
",pylabrobot/storage/chatterbox.py,IncubatorChatterboxBackend,1,1.522997951276035e-08,"The method 'start_shaking' is a simple asynchronous function that prints a message indicating the start of a shaking process at a given frequency. It is a straightforward utility function that could be part of a larger system, such as a simulation or a hardware control interface. The method is likely to be useful in contexts where asynchronous operations are needed, such as in robotics or real-time simulations. Since it serves a clear purpose and is non-trivial in its application, it is likely to be retained in the codebase."
survived,"  async def open_door(self):
    return await self.send_action(""ll"", ""gp"", ""002"")
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend,1,2.0611536181902033e-09,"The method 'open_door' is a simple asynchronous function that sends an action using 'send_action'. It is likely part of a larger system where such actions are necessary, such as a smart home or automated system. The method is straightforward, performs a clear task, and uses asynchronous programming, which is beneficial for non-blocking operations. There is no indication of redundancy or obsolescence in the method itself, suggesting it will likely be retained."
survived,"  async def get_temperature(self) -> float:
    """"""Get the temperature of the incubator in degrees Celsius.""""""
",pylabrobot/storage/backend.py,IncubatorBackend,1,4.944450477491054e-09,"The method `get_temperature` is a simple, clear, and useful function that retrieves the temperature of an incubator. It is likely part of a larger system that monitors or controls an incubator, which is a common requirement in various scientific and industrial applications. The method is asynchronous, suggesting it may be part of a non-blocking I/O operation, which is a modern and efficient approach to handling such tasks. Given its utility and the context, it is unlikely to be deleted."
survived,"  async def set_temperature(self, temperature: float):
    """"""Set the temperature of the incubator in degrees Celsius.""""""
",pylabrobot/storage/backend.py,IncubatorBackend,1,1.8189616842444243e-09,"The method 'set_temperature' is a straightforward and essential function for controlling the temperature of an incubator, which is a critical feature in many applications such as biological research, industrial processes, or any environment where temperature control is necessary. The method is asynchronous, suggesting it is designed to handle potentially time-consuming operations without blocking the main thread, which is a modern and efficient approach in programming. There is no indication that this method is redundant or obsolete, and it serves a clear purpose in its context. Therefore, it is likely to be retained."
survived,"    def __init__(self, registry: Optional[TemplateRegistry] = None) -> None:
        self.registry = registry or TemplateRegistry()
        self.env = Environment(loader=_RegistryLoader(self.registry))
",src/meta_agent/template_mixer.py,TemplateMixer,1,1.3440409770490404e-08,"The method is a constructor (__init__) for a class, which is a fundamental part of class instantiation in Python. Constructors are essential for initializing new objects and setting up initial state, making them crucial for the functionality of the class. Therefore, it is highly unlikely that this method would be deleted unless the entire class is being removed or refactored significantly."
survived,"    def get_source(
        self, environment: Environment, template: str
    ) -> Tuple[str, str, Any]:
        slug, version = _split_name(template)
        source = self.registry.load_template(slug, version)
        if source is None:
            raise TemplateNotFound(template)
        return source, template, lambda: True
",src/meta_agent/template_mixer.py,_RegistryLoader,1,1.4166087846364157e-09,"The method 'get_source' is likely to be Survived (1) because it appears to be a functional and necessary part of a system that retrieves a template source from a registry. It handles the case where the template is not found by raising an exception, which is a good practice for error handling. The method's structure and logic seem sound and purposeful, indicating it serves a specific role in the codebase."
survived,"    def _save_ratings(self, data: Dict[str, List[int]]) -> None:
        with open(self.ratings_path, ""w"", encoding=""utf-8"") as f:
            json.dump(data, f, indent=2)
",src/meta_agent/template_sharing.py,TemplateSharingManager,1,6.69158608681505e-10,"The method _save_ratings is a utility function that saves a dictionary of ratings to a file in JSON format. This is a common and useful operation in many applications that need to persist data. The method is straightforward, uses standard library functions, and is likely to be used in various contexts where data needs to be saved. There is no indication that this method is redundant or obsolete, so it is likely to be retained."
survived,"    def on_end(run: RunTree) -> None:
        nonlocal collected_run
        collected_run = run
",python/tests/unit_tests/test_run_helpers.py,,1,2.646573631904765e-09,"The method 'on_end' is a simple function that assigns a value to a nonlocal variable 'collected_run'. It is likely part of a larger system where 'on_end' is a callback or event handler that gets triggered at the end of a process, represented by 'RunTree'. The method itself is straightforward and serves a clear purpose of updating the state of 'collected_run'. Without additional context suggesting it's obsolete or replaced, there's no reason to delete it. Therefore, it is likely to survive."
survived,"def unique_counts(
    array: NamedArray,
    Unique: Axis,
    *,
    axis: AxisSelector | None = None,
    fill_value: ArrayLike | None = None,
) -> tuple[NamedArray, NamedArray]:
    """"""Shortcut for :func:`unique` that also returns counts.""""""

    values, counts = typing.cast(
        tuple[NamedArray, NamedArray],
        unique(
            array,
            Unique,
            return_counts=True,
            axis=axis,
            fill_value=fill_value,
        ),
    )
    return values, counts
",src/haliax/ops.py,,1,1.4166087846364157e-09,"The method `unique_counts` is a utility function that provides a convenient way to obtain unique elements and their counts from a given array. It is a wrapper around the `unique` function, adding the functionality of returning counts alongside the unique values. This kind of functionality is commonly needed in data processing and analysis tasks, making it a useful addition to a codebase. The method is well-defined, with clear parameters and a straightforward implementation. There is no indication that it is deprecated or redundant, and it serves a practical purpose. Therefore, it is likely to be retained in the codebase."
survived,"def test_page_cache_extend_simple():
    Seq = Axis(""seq"", 2)
    Page = Axis(""page"", 2)
    MaxPage = Axis(""max_page"", 2)
    Slot = Axis(""slot"", 2)
    KVH = Axis(""kv_head"", 1)
    HD = Axis(""head_dim"", 1)

    cache = PageCache.init(Seq, Page, Slot, KVH, HD, MaxPage, dtype=jnp.float32)

    Tok = Axis(""tok"", 2)
    new_k = hax.arange(Tok).broadcast_axis((KVH, HD)).rearrange((Tok, KVH, HD)) + 1
    new_v = hax.arange(Tok).broadcast_axis((KVH, HD)).rearrange((Tok, KVH, HD)) + 101

    cu = jnp.array([0, 1, 2], dtype=jnp.int32)
    pages = jnp.array([0, 1], dtype=jnp.int32)

    jit_extend = eqx.filter_jit(PageCache.extend)
    cache = jit_extend(cache, new_k, new_v, cu, pages, 2)

    assert jnp.all(cache.kv_lens.array == jnp.array([1, 1], dtype=jnp.int32))
    assert jnp.all(cache.page_indices.array == jnp.array([[0, -1], [1, -1]], dtype=jnp.int32))
    assert cache.kv_pages.array[0, 0, 0, 0] == 1
    assert cache.kv_pages.array[0, 0, 1, 0] == 101
    assert cache.kv_pages.array[1, 0, 0, 0] == 2
    assert cache.kv_pages.array[1, 0, 1, 0] == 102
",tests/test_page_cache.py,,1,9.42244663976186e-07,"The method `test_page_cache_extend_simple` is a unit test function designed to test the functionality of the `PageCache.extend` method. Unit tests are crucial for ensuring code reliability and correctness, especially in complex systems. This function is likely part of a test suite that verifies the behavior of the `PageCache` class, particularly its ability to extend cache pages with new key-value pairs. Since testing is an essential part of software development and maintenance, this method is likely to be retained to ensure the continued correctness of the `PageCache` functionality."
survived,"def test_init_sets_default_stake(tmp_path: Path) -> None:
    repo = _make_repo(tmp_path)
    logs = tmp_path / ""logs""
    logs.mkdir()
    reg = StakeRegistry()
    assert ""meta"" not in reg.stakes
    MetaRefinementAgent(repo, logs, reg)
    assert reg.stakes[""meta""] == 1.0",tests/test_meta_refinement_agent.py,,1,8.152020648014727e-09,"The method 'test_init_sets_default_stake' is a unit test that verifies the initialization behavior of a 'MetaRefinementAgent' object. It checks if the 'meta' stake is set to 1.0 by default in the 'StakeRegistry'. This is a typical test case to ensure that the default values are correctly set during initialization, which is a common requirement in software development. Since this test is essential for verifying the correct behavior of the initialization process, it is likely to be retained in the codebase."
survived,"def test_generate_basic_tests():
    spec = ToolSpecification(
        name=""greet"",
        purpose=""Greets a user"",
        input_parameters=[ToolParameter(name=""name"", type_=""string"")],
        output_format=""string"",
    )
    test_code = generate_basic_tests(spec)
    assert ""import importlib"" in test_code
    assert ""greet"" in test_code
    # ensure code is syntactically valid
    ast.parse(test_code)",tests/generators/test_test_generator.py,,1,1.6052280526088547e-09,"The method `test_generate_basic_tests` is a unit test function that checks the functionality of `generate_basic_tests`. It verifies that the generated test code includes specific elements such as the import statement and the function name, and it also checks for syntactical validity using `ast.parse`. These are standard practices in test-driven development to ensure code correctness and robustness. Since the method is performing a useful validation task, it is likely to be retained in the codebase."
survived,"    def model_post_init(self, __context: Any) -> None:
        """"""Remove relationship defaults after initialization.""""""
        super().model_post_init(__context)

        for field in self.__class__.relationship_fields():
            if field in self.__dict__:
                del self.__dict__[field]
",src/enrichmcp/entity.py,EnrichModel,1,7.194132978569833e-09,"The method `model_post_init` is likely to be Survived (1) because it serves a specific purpose in the class by removing relationship defaults after initialization. This is a common pattern in object-relational mapping (ORM) frameworks where relationships might need to be reset or cleared after an object is initialized to ensure that they are correctly set up later. The method is also calling a superclass method, indicating that it is part of a larger framework or system where this behavior is necessary. Without more context suggesting that this functionality is no longer needed, it is reasonable to assume that this method will continue to be useful."
survived,"            async def get_one() -> dict[str, float | str]:
                it = mod.stream_macro_events(live=False)
                return await anext(it)
",tests/test_offline_data_feeds.py,,1,4.363462233903899e-09,"The method 'get_one' is an asynchronous function that returns a dictionary with string keys and values that are either floats or strings. It uses 'anext' to asynchronously retrieve the next item from an asynchronous iterator 'it', which is obtained from 'mod.stream_macro_events'. This method is likely to be useful in scenarios where asynchronous data streaming is required, such as in real-time data processing or event-driven applications. The use of type hints and asynchronous programming patterns suggests that the method is well-structured and modern, aligning with current Python best practices. Therefore, it is likely to be retained in the codebase."
survived,"    def test_live_feed_requires_aiohttp(self) -> None:
        async def run_live() -> None:
            os.environ[""LIVE_FEED""] = ""1""
            orig = data_feeds.aiohttp  # type: ignore[attr-defined]
            data_feeds.aiohttp = None  # type: ignore[attr-defined]
            try:
                it = data_feeds.stream_macro_events(live=True)
                await anext(it)
            finally:
                data_feeds.aiohttp = orig  # type: ignore[attr-defined]
                os.environ.pop(""LIVE_FEED"", None)

        with self.assertRaises(RuntimeError):
            asyncio.run(run_live())
",tests/test_macro_sentinel.py,TestMacroSentinel,1,1.4166087846364157e-09,The method 'test_live_feed_requires_aiohttp' is a unit test designed to ensure that the 'stream_macro_events' function raises a RuntimeError when 'aiohttp' is not available. This is a valid and useful test case to verify the behavior of the code under specific conditions. It is likely to be retained as it helps maintain the robustness of the code by ensuring that the absence of a required dependency is properly handled.
survived,"def validate_identifier(value: str, field_name: str) -> None:
    """"""Ensure simple alphanumeric names to avoid path traversal.""""""
    if not _SAFE_NAME_RE.match(value):
        raise HTTPException(status_code=400, detail=f""Invalid {field_name} provided."")
",no-ocr-api/np_ocr/api.py,,1,2.0611536181902033e-09,"The method 'validate_identifier' is a utility function that checks if a given string matches a safe pattern, presumably defined by '_SAFE_NAME_RE'. This is a common practice to prevent security vulnerabilities such as path traversal attacks. The method raises an HTTPException with a 400 status code if the validation fails, which is a standard way to handle invalid input in web applications. Given its role in ensuring security and input validation, it is likely to be retained in the codebase."
survived,"def _lambda1():
    draw.get(1)()
    draw.get(6)()
",tests/rosetta/transpiler/Python/cistercian-numerals.py,,1,7.73442280641062e-08,"The method _lambda1() is a private method (indicated by the underscore) and seems to be part of a larger codebase where 'draw' is likely a dictionary or similar structure with callable objects. The method calls two functions stored in 'draw' at keys 1 and 6. Without additional context, it's difficult to determine its utility, but the method itself is functional and could be part of a necessary operation in the codebase. Therefore, unless the functionality it provides is no longer needed or has been replaced, it is likely to survive."
survived,"def printBoard(b):
    print(repeat(""__"", cols) + ""\n\n"")
    r = 0
    while r < rows:
        line = """"
        c = 0
        while c < cols:
            cell = b[r][c]
            if cell == "" "":
                line = line + ""  ""
            else:
                line = line + "" "" + cell
            c = c + 1
        print(line + ""\n"")
        r = r + 1
",tests/rosetta/transpiler/Python/forest-fire.py,,1,5.60279640614594e-09,"The method 'printBoard' is a utility function that prints a board represented by a 2D list 'b'. It uses nested loops to iterate over the rows and columns of the board, constructing a string representation of each row and printing it. The method is straightforward and serves a clear purpose in displaying the board's current state, which is a common requirement in many board games or grid-based applications. Since it performs a useful function and there are no apparent issues with its implementation, it is likely to be retained in the codebase."
survived,"def parseInt(str):
    i = 0
    neg = False
    if len(str) > 0 and str[0:1] == ""-"":
        neg = True
        i = 1
    n = 0
    digits = {""0"": 0, ""1"": 1, ""2"": 2, ""3"": 3, ""4"": 4, ""5"": 5, ""6"": 6, ""7"": 7, ""8"": 8, ""9"": 9}
    while i < len(str):
        n = n * 10 + digits[str[i:i + 1]]
        i = i + 1
    if neg:
        n = -n
    return n
",tests/rosetta/transpiler/Python/gui-component-interaction.py,,0,0.9999999317439577,"The method 'parseInt' is a basic implementation of converting a string to an integer, handling negative numbers. While it is functional, it is not optimal or necessary in modern Python programming due to the built-in 'int()' function, which performs the same task more efficiently and with better error handling. Therefore, this method is likely to be deleted in favor of using the built-in functionality."
survived,"def formatFloat(f, prec):
    scale = pow10(prec)
    scaled = (f * scale) + 0.5
    n = (int(scaled))
    digits = str(n)
    while len(digits) <= prec:
        digits = ""0"" + digits
    intPart = digits[0:len(digits) - prec]
    fracPart = digits[len(digits) - prec:len(digits)]
    return intPart + ""."" + fracPart
",tests/rosetta/transpiler/Python/functional-coverage-tree.py,,1,6.825604231969389e-08,"The method 'formatFloat' is a utility function that formats a floating-point number to a specified precision. It is a common requirement in many applications to control the number of decimal places for display or further processing. The method uses basic arithmetic and string manipulation to achieve this, which is a straightforward and efficient approach. There is no indication that this method is redundant or replaced by a more efficient built-in function, so it is likely to be retained for its utility."
survived,"def pad(n, width):
    s = str(n)
    while len(s) < width:
        s = "" "" + s
    return s
",tests/rosetta/transpiler/Python/four-is-the-number-of-letters-in-the-....py,,1,2.5109990926928157e-08,"The method 'pad' is a simple utility function that pads a number with spaces to ensure it reaches a specified width. This type of function is quite common and useful in formatting tasks, especially when dealing with text-based outputs that require alignment. The function is straightforward, does not have any apparent bugs, and serves a clear purpose. Therefore, it is likely to be retained in the codebase."
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    nums = [0, 4, 6, 11, 13, 75, 100, 337, -164, 9223372036854775807]
    for n in nums:
        print(fourIsMagic(n))
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/four-is-magic.py,,1,1.8553915987649156e-07,"The method 'main' is a typical entry point for a Python script, and it includes functionality to benchmark memory usage and execution time, which can be useful for performance analysis. The method also demonstrates the use of a function 'fourIsMagic' on a list of numbers, which suggests it is part of a larger program. Without additional context indicating that this method is obsolete or redundant, it is likely to be retained for its utility in performance monitoring and as a script entry point."
survived,"def differentiate(a):
    return newFps(lambda n: (float((n + 1))) * extract(a, n + 1))
",tests/rosetta/transpiler/Python/formal-power-series.py,,1,6.023574641292144e-08,"The method 'differentiate' seems to be a part of a larger codebase dealing with mathematical operations, possibly related to calculus or polynomial differentiation. The function uses 'newFps' and 'extract', which are likely defined elsewhere in the code. Without the context of these functions, it's hard to determine the exact functionality or correctness of 'differentiate'. However, the method appears to be a utility function that could be useful in a mathematical library. Unless there are significant issues with the implementation or redundancy, such utility functions are generally retained in codebases. Therefore, it is likely to survive."
survived,"def repLeap(year):
    a = int(((year + 1) % 4))
    b = int(((year + 1) % 100))
    c = int(((year + 1) % 400))
    return a == 0 and (b != 0 or c == 0)
",tests/rosetta/transpiler/Python/french-republican-calendar.py,,0,0.9999251538028718,"The method 'repLeap' is a function that determines if a given year is a leap year. However, it incorrectly checks the year by adding 1 to the input year before performing the leap year calculation. This is not the standard way to check for leap years, which should directly use the input year without modification. The correct logic should be applied directly to the input year, not 'year + 1'. This incorrect implementation is likely to lead to confusion and errors, making it a candidate for deletion or significant modification."
survived,"def render(g):
    out = """"
    y = 0
    while y < height:
        line = """"
        x = 0
        while x < width:
            line = line + g[y][x]
            x = x + 1
        out = out + line
        if y < height - 1:
            out = out + ""\n""
        y = y + 1
    return out
",tests/rosetta/transpiler/Python/fractal-tree.py,,1,1.0467401685178159e-08,"The method 'render' is a basic implementation of rendering a 2D grid into a string format. It iterates over each row and column of the grid, appending each element to a string, and adds a newline character after each row except the last one. This is a common utility function in many applications that deal with grid or matrix representations, such as games, simulations, or graphical applications. The method is straightforward, performs a clear task, and does not have any apparent issues or inefficiencies that would necessitate its deletion. Therefore, it is likely to be retained in the codebase."
survived,"def test_percent_dict_fmt_extra_aggressive(state: State):
    s_in = """"""a = '%(?)ld world' % {'?': var}""""""
    s_expected = """"""a = f'{var} world'""""""
    state.aggressive = 2
    assert code_editor.fstringify_code_by_line(s_in, state)[0] == s_expected
",test/test_edits.py,,1,2.3355930333443423e-09,"The method `test_percent_dict_fmt_extra_aggressive` is a test function that checks the functionality of converting a percent-formatted string to an f-string using a specific level of aggressiveness. This kind of test is crucial for ensuring that the code transformation logic works correctly, especially when dealing with different levels of transformation aggressiveness. Test functions are generally not deleted unless they are redundant or the feature they are testing is removed. Since this test is specific to a feature (aggressive f-string conversion) that is likely to remain relevant, the method is expected to survive."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/values_builtin.py,,1,1.1861120010657661e-08,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted consistently for output or logging. Its simplicity and general applicability make it likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/for_list_collection.py,,1,3.3982678079468468e-09,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in many programming contexts where data needs to be formatted for display or logging. Its simplicity and general applicability suggest that it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/var_assignment.py,,1,2.3355930333443423e-09,"The method _fmt is a utility function that formats different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted for display or logging. Since it provides a flexible and reusable solution for formatting, it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/nested_function.py,,1,6.348800075736417e-09,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in many programming scenarios where data needs to be consistently formatted for output or logging. Its simplicity and general applicability make it likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/string_prefix_slice.py,,1,7.194132978569833e-09,"The method _fmt is a utility function that formats different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted for display or logging. Its simplicity and general applicability suggest that it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/fun_call.py,,1,1.1861120010657661e-08,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted consistently for output or logging. Its simplicity and general applicability make it likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/list_index.py,,1,2.998960815863541e-09,"The method _fmt is a utility function that formats different types of input values into strings. It handles lists by recursively formatting each element, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted consistently for output or logging. Its simplicity and general applicability suggest that it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/map_literal_dynamic.py,,1,5.60279640614594e-09,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in many programming scenarios where data needs to be consistently formatted for output or logging. Its simplicity and general applicability make it likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/go_auto.py,,1,7.582560422162384e-10,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is quite useful in data processing and formatting tasks, making it likely to be retained in codebases where such operations are needed. Its simplicity and general applicability suggest it will survive."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/string_concat.py,,1,5.60279640614594e-09,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in many programming scenarios where data needs to be consistently formatted for output or logging. Its simplicity and general applicability make it likely to be retained in the codebase."
survived,"        def list_entries(self) -> list[tuple[int, str, str, int]]:
            return [(1, ""foo.tar"", ""deadbeef"", 1)]
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_demo_cli.py,DummyArchive,0,0.9999967112522585,"The method 'list_entries' is a simple function that returns a hardcoded list with a single tuple. It doesn't perform any dynamic operations or computations, and its utility seems limited to returning a static value. Unless this method is part of a larger system where this specific return value is necessary for testing or demonstration purposes, it is likely to be deleted due to its limited functionality and lack of adaptability."
survived,"def twoSum(nums, target):
    n = len(nums)
    for i in range(n):
        for j in range(i + 1, n):
            if nums[i] + nums[j] == target:
                return [i, j]
    return [-1, -1]
",tests/human/x/python/two-sum.py,,1,1.3440409770490404e-08,"The method implements a basic solution to the Two Sum problem, which is a common interview question. Although the solution is not the most efficient (O(n^2) time complexity), it is correct and straightforward. Such methods are often retained for educational purposes or as a simple baseline solution. Therefore, it is likely to survive."
survived,"    def count_nodes(node: Mapping[str, Any]) -> int:
        return 1 + sum(count_nodes(c) for c in node.get(""children"", []))
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_tree_visualization.py,,1,3.3982678079468468e-09,"The method `count_nodes` is a recursive function that counts the number of nodes in a tree-like structure represented by a dictionary. It is a simple and efficient implementation for counting nodes, which is a common operation in tree data structures. The method is likely to be useful in various contexts where tree structures are used, such as parsing JSON data, representing organizational hierarchies, or managing file systems. Given its utility and correctness, it is likely to be retained in the codebase."
survived,"def _env_int(name: str, default: int) -> int:
    """"""Return ``int`` environment value or ``default`` if conversion fails.""""""

    try:
        return int(os.getenv(name, default))
    except (TypeError, ValueError):
        return default
",alpha_factory_v1/edge_runner.py,,1,1.1032560311263802e-09,"The method _env_int is a utility function that attempts to retrieve an environment variable and convert it to an integer, returning a default value if the conversion fails. This is a common and useful pattern in software development for handling environment variables, especially in configurations where environment variables are used to control application behavior. The function is robust, handling both TypeError and ValueError exceptions, which makes it reliable. Such utility functions are often retained in codebases because they encapsulate error handling and provide a clear, reusable way to access environment variables. Therefore, it is likely to survive."
survived,"    async def stop_merkle_task(self) -> None:  # pragma: no cover - interface
        pass
",tests/test_adk_agent.py,DummyLedger,1,3.0590235908148916e-07,"The method `stop_merkle_task` is defined as an asynchronous function with no implementation (it only contains a `pass` statement). The presence of the `# pragma: no cover - interface` comment suggests that this method is part of an interface or abstract class, indicating that it is intended to be overridden by subclasses. This is a common pattern in Python to define methods that are expected to be implemented by subclasses, especially in frameworks or libraries that use asynchronous operations. Therefore, the method is likely to survive as it serves a purpose in defining an interface or contract for subclasses."
survived,"    def subscribe(self, _t: str, _h):
        pass
",tests/test_adk_agent.py,DummyBus,0,0.9999997897565932,"The method 'subscribe' is defined but not implemented, as it only contains a 'pass' statement. This suggests that the method is either a placeholder for future implementation or is not needed at all. Without any additional context or usage of this method in the code, it is likely to be deleted in the future if it remains unimplemented, as it does not contribute any functionality."
survived,"    async def handle(self, env: messaging.Envelope) -> None:
        """"""Store research payload for later summarisation.""""""
        with span(""summariser.handle""):
            val = env.payload.get(""research"")
            if val is not None:
                self._records.append(str(val))",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/adk_summariser_agent.py,ADKSummariserAgent,1,8.152020648014727e-09,"The method 'handle' is an asynchronous function that processes a messaging envelope to store research payloads for later summarization. It uses a span for tracing and checks if the payload contains a 'research' key, appending its value to a list if present. This functionality is specific and useful for applications dealing with message processing and data collection, which are common in modern software systems. The method is well-defined, serves a clear purpose, and is likely part of a larger system that relies on this functionality. Therefore, it is unlikely to be deleted."
survived,"    async def run_cycle(self) -> None:
        raise RuntimeError(""boom"")
",tests/test_orchestrator_backoff.py,FailingAgent,0,0.9999999397642536,"The method 'run_cycle' is designed to raise a RuntimeError every time it is called, which makes it non-functional for any practical use unless the intention is to test error handling. If this method is part of a larger codebase, it is likely to be deleted or refactored to serve a meaningful purpose. Without additional context indicating that this behavior is intentional and necessary, the method is more likely to be deleted."
survived,"    async def handle(self, _env: orchestrator.messaging.Envelope) -> None:
        pass
",tests/test_orchestrator_backoff.py,FailingAgent,0,0.7549149868676283,"The method 'handle' is defined as an asynchronous function but contains only a 'pass' statement, meaning it currently does nothing. In its current state, it is not serving any functional purpose. However, it is possible that this method is a placeholder for future implementation, especially given its naming and the context of handling a messaging envelope, which suggests it might be part of a larger messaging or orchestration system. If the surrounding codebase or future plans indicate that this method will be implemented with actual logic, it might survive. However, if it remains unimplemented and unused, it is likely to be deleted to clean up the codebase."
survived,"    def test_skill_test_endpoint(self) -> None:
        app = orchestrator._build_rest({""simple"": Runner(SimpleAgent())})
        self.assertIsNotNone(app)
        client = TestClient(app)
        headers = {""Authorization"": ""Bearer test-token""}
        resp = client.post(""/agent/simple/skill_test"", json={""t"": 1}, headers=headers)
        self.assertEqual(resp.status_code, 200)
        self.assertEqual(resp.json(), {""ok"": True})
",tests/test_skill_test_route.py,TestSkillTestRoute,1,1.3440409770490404e-08,"The method 'test_skill_test_endpoint' is a unit test designed to verify the functionality of a specific endpoint in a REST API. It uses a test client to simulate a POST request to the '/agent/simple/skill_test' endpoint and checks if the response status code is 200 and the response JSON is as expected. This is a typical and necessary part of testing in software development to ensure that the API behaves as intended. Therefore, it is unlikely to be deleted as it serves an important role in maintaining code quality and reliability."
survived,"def test_branching_and_cid(tmp_path: Path) -> None:
    js_out = tmp_path / ""replay.js""
    subprocess.run([
        ""tsc"",
        ""--target"",
        ""es2020"",
        ""--module"",
        ""es2020"",
        REPLAY_TS,
        ""--outFile"",
        js_out,
    ], check=True)

    script = tmp_path / ""run.mjs""
    script.write_text(
        f""import {{ ReplayDB }} from '{js_out.resolve().as_posix()}';\n""
        ""const db = new ReplayDB('jest');\n""
        ""await db.open();\n""
        ""const root = await db.addFrame(null,{msg:'root'});\n""
        ""const a = await db.addFrame(root,{msg:'a'});\n""
        ""const b = await db.addFrame(root,{msg:'b'});\n""
        ""const cid1 = await db.computeCid(b);\n""
        ""const thread = await db.exportThread(b);\n""
        ""const cid2 = await ReplayDB.cidForFrames(thread);\n""
        ""console.log(thread.length,cid1===cid2);\n"",
        encoding=""utf-8"",
    )
    res = subprocess.run([""node"", script], capture_output=True, text=True, check=True)
    parts = res.stdout.strip().split()
    assert int(parts[0]) == 2
    assert parts[1] == ""true""",tests/test_replay_ts.py,,1,2.2159489282323004e-08,"The method 'test_branching_and_cid' is a test function that verifies the functionality of a JavaScript/TypeScript module. It compiles TypeScript code, writes a script to test the module, and checks the output for correctness. Test functions are generally crucial for ensuring code reliability and are not typically deleted unless they are redundant or replaced by more comprehensive tests. Given that this function seems to be a specific test for a particular feature (branching and CID computation), it is likely to be retained to ensure that this functionality works as expected."
survived,"def make_cfg():
    return OmegaConf.create({
        'seed': {'train': 7},
        'es_manager': {
            'train': {
                'env_groups': 1,
                'group_size': 1,
                'env_configs': {'tags': ['Bandit'], 'n_groups': [1]},
            }
        },
        'custom_envs': {
            'Bandit': {
                'env_type': 'bandit',
                'max_actions_per_traj': 1,
                'env_config': None
            }
        }
    })
",tests/es_manager/test_seed_iteration.py,,1,1.1032560311263802e-09,"The method 'make_cfg' is likely to survive because it is a utility function that creates and returns a configuration object using the OmegaConf library. This type of function is useful for setting up configurations in a structured and reusable way, which is a common practice in software development, especially in projects involving machine learning or simulations. The function is concise, clear, and serves a specific purpose, making it a valuable part of the codebase."
survived,"def _gen_crc16_table(poly: int) -> list[int]:
    table = []
    for i in range(256):
        crc = i << 8
        for _ in range(8):
            if crc & 0x8000:
                crc = ((crc << 1) ^ poly) & 0xFFFF
            else:
                crc = (crc << 1) & 0xFFFF
        table.append(crc)
    return table
",opendbc/can/packer.py,,1,1.725782769012759e-08,"The method _gen_crc16_table is a utility function that generates a CRC16 table based on a given polynomial. This is a common requirement in computing for error-checking purposes, especially in data transmission and storage. The method is well-defined, performs a specific task, and is likely to be useful in contexts where CRC16 checksums are needed. Therefore, it is unlikely to be deleted unless the entire system or library it belongs to is deprecated or replaced by a different error-checking mechanism."
survived,"def tesla_checksum(address: int, sig: Signal, d: bytearray) -> int:
    checksum = (address & 0xFF) + ((address >> 8) & 0xFF)
    checksum_byte = sig.start_bit // 8
    for i in range(len(d)):
        if i != checksum_byte:
            checksum += d[i]
    return checksum & 0xFF
",opendbc/can/packer.py,,1,9.736200303530205e-10,"The method 'tesla_checksum' is a utility function that calculates a checksum for a given address and data. It is a simple and efficient implementation that is likely used in a larger system for data integrity verification. Such functions are generally useful and necessary in systems dealing with data transmission or storage, where checksums are used to detect errors. Unless there is a significant change in the system's requirements or a better checksum algorithm is adopted, this method is likely to survive."
survived,"    def __init__(self, x: int, y: int):
        self.x = x
        self.y = y
",runtime/ffi/python/testmod.py,Point,1,3.3982678079468468e-09,"The method is a constructor for a class, initializing two instance variables, x and y. This is a fundamental part of object-oriented programming, allowing objects to be created with specific initial states. Such methods are essential for the functionality of classes and are unlikely to be removed unless the class design changes significantly. Therefore, it is likely to survive."
survived,"    def visit_While(self, node):
        self.emit(f""while {self.expr(node.test)} {{"")
        self.indent += 1
        for s in node.body:
            self.visit(s)
        self.indent -= 1
        self.emit(""}"")
",tools/any2mochi/py_simple.py,Conv,1,2.646573631904765e-09,"The method `visit_While` is a part of a code generation or transpilation process, likely converting an abstract syntax tree (AST) representation of a programming language into another language, such as converting Python code into C-like syntax. This method handles the translation of 'while' loop constructs. Such methods are typically essential in compilers or transpilers, and unless there is a significant change in the language or the way loops are handled, this method is likely to survive. It performs a specific and necessary function in the context of code generation."
survived,"    async def _metrics() -> PlainTextResponse:  # noqa: D401
        if ""generate_latest"" not in globals():
            raise HTTPException(503, ""prometheus_client not installed"")
        from .telemetry import generate_latest, CONTENT_TYPE_LATEST

        return PlainTextResponse(generate_latest(), media_type=CONTENT_TYPE_LATEST)
",alpha_factory_v1/backend/api_server.py,,1,7.194132978569833e-09,"The method is a private asynchronous function that checks for the presence of 'generate_latest' in the global namespace and raises an HTTPException if it's not found. It then imports 'generate_latest' and 'CONTENT_TYPE_LATEST' from a local module and returns a PlainTextResponse. This method is likely part of a telemetry or monitoring feature, which is a common requirement in many applications for performance tracking and alerting. Since it serves a specific purpose and is not overly complex or redundant, it is likely to be retained in the codebase."
survived,"    def __init__(self, name: str, cycle_seconds: int, max_cycle_sec: int, publish: callable):
        self.name = name
        self.inst = get_agent(name)
        self.period = getattr(self.inst, ""CYCLE_SECONDS"", cycle_seconds)
        self.spec = getattr(self.inst, ""SCHED_SPEC"", None)
        self.next_ts = 0.0
        self.last_beat = time.time()
        self.task: Optional[asyncio.Task] = None
        self._max_cycle_sec = max_cycle_sec
        self._publish = publish
        self._calc_next()

        with contextlib.suppress(ModuleNotFoundError):
            from openai.agents import AgentContext  # type: ignore[attr-defined]

            if isinstance(self.inst, AgentContext):
                from .telemetry import tracer  # avoid circular import
                from openai.agents import AgentRuntime  # type: ignore[attr-defined]

                runtime = AgentRuntime()
                runtime.register(self.inst)
                atexit.register(runtime.close)
",alpha_factory_v1/backend/agent_manager.py,AgentRunner,1,8.76424914819242e-08,"The method is a constructor (__init__) for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting up their initial state. This particular constructor is setting up various attributes and handling some conditional imports and registrations, which suggests it is part of a larger system. Such methods are rarely deleted unless the entire class is refactored or removed, which is less likely given the specific functionality it provides."
survived,"def init_metrics(port: int) -> None:
    """"""Start the Prometheus exporter if possible.""""""

    if port and ""start_http_server"" in globals():
        start_http_server(port)
        log.info(""Prometheus metrics exposed at :%d/metrics"", port)",alpha_factory_v1/backend/telemetry.py,,1,7.194132978569833e-09,"The method 'init_metrics' is a utility function that initializes a Prometheus metrics exporter if the necessary conditions are met. It checks if a valid port is provided and if the 'start_http_server' function is available in the global scope. This is a common pattern for setting up monitoring in applications, and it is likely to be useful in various contexts where Prometheus is used for metrics collection. Therefore, the method is likely to be retained as it serves a specific and useful purpose in the context of application monitoring."
survived,"def _noop_metric(*_a: Any, **_kw: Any) -> Any:
    class _Metric:  # pylint: disable=too-few-public-methods
        def labels(self, *_a: Any, **_kw: Any) -> ""_Metric"":
            return self

        def observe(self, *_a: Any) -> None:
            ...

        def inc(self, *_a: Any) -> None:
            ...

        def set(self, *_a: Any) -> None:
            ...

    return _Metric()
",alpha_factory_v1/backend/telemetry.py,,1,1.522997951276035e-08,"The method '_noop_metric' is a utility function that returns an instance of a class '_Metric' with several no-operation methods. This pattern is often used as a placeholder or a default implementation that does nothing, which can be useful in scenarios where metrics are optional or when testing. Since it provides a clear purpose and can be useful in certain contexts, it is likely to be retained in the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/cross_join.py,Customer,1,9.931195248674785e-08,"The method is a simple implementation of the __getitem__ special method, which allows an object to use the bracket notation (obj[key]) to access its attributes. This is a common and useful pattern in Python, especially for classes that need to provide dictionary-like access to their attributes. It is likely to be retained as it provides a clear and concise way to access object attributes using keys, enhancing the flexibility and usability of the class."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/left_join_multi.py,Customer,1,5.3157849718487075e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the codebase."
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/group_by_multi_join_sort.py,Customer,1,5.60279640614594e-09,"The __repr__ method is a special method used to define a string representation of an object. In this case, it returns the string representation of the object's __dict__, which is a dictionary containing all the attributes of the object. This is a common and useful implementation of __repr__ as it provides a clear and detailed view of the object's state, which is helpful for debugging and logging purposes. Therefore, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/group_by_having.py,Person,1,2.9023122007764653e-06,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in collections like lists or dictionaries. In this code, it is implemented to return an attribute of the object using `getattr`. This is a non-standard use of `__getitem__`, as it is expected to work with indices or keys, not attribute names. However, it can be useful in certain contexts where an object is designed to behave like a dictionary of its attributes. Without additional context, it's hard to determine if this is the best design choice, but it is a valid implementation. Therefore, it is likely to survive unless there is a specific reason in the broader codebase to remove it."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/group_by.py,Person,1,8.152020648014727e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. Since it provides a clear and functional purpose, it is likely to be retained in the code."
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/outer_join.py,Order,1,6.348800075736417e-09,"The __repr__ method is a special method used to define a string representation of an object. In this case, it returns the string representation of the object's __dict__, which is a dictionary containing all the attributes of the object. This is a common and useful implementation for debugging purposes, as it provides a clear and detailed view of the object's state. Therefore, this method is likely to be retained as it serves a practical purpose in understanding and debugging the code."
survived,"async def test_rest_and_quarantine(dev_orchestrator: orch_mod.Orchestrator) -> None:
    app = build_rest(dev_orchestrator.manager.runners, 1024 * 1024, _mem_stub())
    assert app is not None
    client = TestClient(app)
    headers = {""Authorization"": ""Bearer test-token""}

    resp = client.get(""/agents"", headers=headers)
    assert resp.status_code == 200
    assert set(resp.json()) == {""dummy"", ""fail""}

    runner = dev_orchestrator.manager.runners[""fail""]
    await runner.maybe_step()
    if runner.task:
        with contextlib.suppress(Exception):
            await runner.task
    await asyncio.sleep(0.05)
    time.sleep(0.05)  # allow health thread to process

    assert AGENT_REGISTRY[""fail""].cls is StubAgent",tests/test_backend_orchestrator_dev.py,,1,3.466327708641819e-07,"The method `test_rest_and_quarantine` is a test function that appears to be part of a testing suite for a REST API. It uses an asynchronous approach to test the functionality of an orchestrator and its interaction with agents. The method includes assertions to verify the expected behavior of the system, such as checking the response status code and the contents of the response JSON. It also tests the behavior of a runner within the orchestrator. Test functions like this are crucial for ensuring the reliability and correctness of software systems, especially in complex environments involving asynchronous operations and external dependencies. Therefore, it is likely to be retained as part of the test suite to ensure ongoing quality assurance."
survived,"    async def step(self) -> None:  # pragma: no cover - simple agent
        return None
",tests/test_backend_orchestrator_dev.py,DummyAgent,1,1.4738976032926566e-05,"The method 'step' is marked with a pragma directive 'no cover', indicating that it is intentionally excluded from test coverage. This suggests that the method is either trivial or not critical to the core functionality, which might imply it is a placeholder or a stub for future development. However, the method is defined as 'async', which means it is intended to be used in an asynchronous context, possibly as part of a larger framework or system that requires such a method signature. Given that it is a simple method returning 'None', it might be kept for structural or interface consistency within an asynchronous framework, even if it currently does nothing. Therefore, it is likely to survive as a placeholder or for future implementation."
survived,"def test_shutdown_stops_loop(non_network: None) -> None:
    """"""The orchestrator loop thread should terminate on app shutdown.""""""
    os.environ[""NO_LLM""] = ""1""
    os.environ.setdefault(""ALPHA_ASI_MAX_STEPS"", ""100000"")

    mod = importlib.import_module(""alpha_factory_v1.demos.alpha_asi_world_model.alpha_asi_world_model_demo"")

    with TestClient(cast(Any, mod.app)) as client:
        client.get(""/agents"")
        loop = mod.loop_thread
        assert loop is not None and loop.is_alive()
    assert loop is not None and not loop.is_alive()",tests/test_world_model_demo.py,,1,9.237449576640118e-09,"The method 'test_shutdown_stops_loop' is a test function that checks if a loop thread in an application stops when the application is shut down. It uses environment variables and a test client to simulate the application behavior. Test functions are generally important for ensuring the reliability and correctness of code, especially in production environments. Since this function is part of a test suite, it is likely to be retained to ensure the application behaves as expected during shutdown. Therefore, it is predicted to survive."
survived,"    async def _run() -> None:
        for env in envs:
            await agent.handle(env)
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_memory_agent_file_persistence.py,,1,1.3440409770490404e-08,"The method '_run' is an asynchronous function that iterates over a collection 'envs' and calls an asynchronous 'handle' method on each 'env' using an 'agent' object. This pattern is common in asynchronous programming, especially when dealing with I/O-bound operations or concurrent tasks. The method is likely to be useful in scenarios where multiple environments need to be processed concurrently, which is a common requirement in modern applications. Therefore, the method is likely to be retained as it serves a practical purpose in handling asynchronous operations efficiently."
survived,"def test_sandbox_env_limits(monkeypatch) -> None:
    recorded: list[tuple[int, tuple[int, int]]] = []

    def fake_setrlimit(res: int, limits: tuple[int, int]) -> None:
        recorded.append((res, limits))

    def fake_run(*args, **kwargs):
        if kwargs.get(""preexec_fn""):
            kwargs[""preexec_fn""]()

        class P:
            stdout = ""{}""
            stderr = """"

        return P()

    monkeypatch.setenv(""SANDBOX_CPU_SEC"", ""1"")
    monkeypatch.setenv(""SANDBOX_MEM_MB"", ""64"")
    monkeypatch.setattr(codegen_agent.subprocess, ""run"", fake_run)
    fake_resource = type(
        ""R"",
        (),
        {""RLIMIT_CPU"": 0, ""RLIMIT_AS"": 1, ""setrlimit"": fake_setrlimit},
    )
    monkeypatch.setitem(sys.modules, ""resource"", fake_resource)

    agent = _make_agent()
    agent.execute_in_sandbox(""print('hi')"")
    assert (0, (1, 1)) in recorded
    assert (1, (64 * 1024 * 1024, 64 * 1024 * 1024)) in recorded",tests/test_codegen_agent.py,,1,1.1861120010657661e-08,"The method 'test_sandbox_env_limits' is a unit test designed to verify the behavior of a sandbox environment by mocking certain functions and checking if resource limits are set correctly. It uses the 'monkeypatch' fixture to modify environment variables and mock functions, which is a common practice in testing to isolate the test environment from the actual system environment. The test checks if the resource limits for CPU and memory are set as expected, which is a crucial aspect of ensuring the sandbox operates within defined constraints. Since this is a test function, it is unlikely to be deleted unless the functionality it tests is removed or significantly altered. Therefore, the method will likely survive."
survived,"def test_simulate_export_formats(export_fmt: str) -> None:
    """"""Ensure simulate exports JSON and CSV correctly.""""""
    runner = CliRunner()
    with patch.object(cli, ""asyncio""):
        with patch.object(cli.orchestrator, ""Orchestrator""):
            res = runner.invoke(
                cli.main,
                [
                    ""simulate"",
                    ""--horizon"",
                    ""1"",
                    ""--offline"",
                    ""--sectors"",
                    ""1"",
                    ""--pop-size"",
                    ""1"",
                    ""--generations"",
                    ""1"",
                    ""--export"",
                    export_fmt,
                ],
            )

    assert res.exit_code == 0
    if export_fmt == ""json"":
        assert res.output.startswith(""["")
    else:
        lines = res.output.splitlines()
        assert lines[0] == ""year,capability,affected""
        assert "","" in lines[1]
",tests/test_demo_cli.py,,1,2.3355930333443423e-09,"The method `test_simulate_export_formats` is a unit test designed to verify the functionality of exporting simulation results in different formats (JSON and CSV). It uses a test runner and mocks to simulate the command-line interface behavior. Such tests are crucial for ensuring that the software behaves as expected when exporting data, which is a common requirement in many applications. Therefore, this method is likely to be maintained as part of the test suite to ensure ongoing reliability of the export functionality."
survived,"def test_run_forever_shutdown() -> None:
    settings = config.Settings(bus_port=0)
    with mock.patch.object(orchestrator.Orchestrator, ""_init_agents"", lambda self: []):
        orch = orchestrator.Orchestrator(settings)

    async def run() -> None:
        with mock.patch.object(orch.bus, ""stop"", mock.AsyncMock()) as bus_stop, \
             mock.patch.object(orch.ledger, ""stop_merkle_task"", mock.AsyncMock()) as merkle_stop:
            task = asyncio.create_task(orch.run_forever())
            await asyncio.sleep(0.05)
            task.cancel()
            with contextlib.suppress(asyncio.CancelledError):
                await task
            bus_stop.assert_awaited_once()
            merkle_stop.assert_awaited_once()

    asyncio.run(run())",tests/test_orchestrator.py,,1,6.348800075736417e-09,"The method `test_run_forever_shutdown` is a unit test designed to test the shutdown behavior of an orchestrator's `run_forever` method. It uses mocking to simulate and verify that certain methods (`bus.stop` and `ledger.stop_merkle_task`) are called when the task is cancelled. This is a typical pattern in testing asynchronous code to ensure proper cleanup and resource management. Since it is a test function, it is unlikely to be deleted unless the functionality it tests is removed or significantly changed. Therefore, it is more likely to survive."
survived,"    def binary_path(self, target_dir: str) -> str:
        dep = self.single_for_current_platform()
        if not dep.binary_name:
            return target_dir
        return os.path.join(target_dir, dep.binary_name)
",src/solidlsp/language_servers/common.py,RuntimeDependencyCollection,1,7.194132978569833e-09,The method `binary_path` is a simple utility function that constructs a file path by joining a target directory with a binary name. It checks if the `binary_name` is present and returns the target directory if not. This kind of utility function is common and useful in many applications where file paths need to be dynamically constructed based on certain conditions. It is unlikely to be deleted as it provides a clear and specific functionality that is often needed in software dealing with file systems or deployment processes.
survived,"    def __init__(self, dependencies: Sequence[RuntimeDependency]):
        self._dependencies = list(dependencies)
",src/solidlsp/language_servers/common.py,RuntimeDependencyCollection,1,2.2159489282323004e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. It initializes the object with a list of dependencies, which is a common pattern for managing dependencies in a class. There is no indication that this method is redundant or unnecessary, and it serves a clear purpose in setting up the initial state of an object. Therefore, it is likely to be retained."
survived,"def test_skip_net_check(monkeypatch: pytest.MonkeyPatch) -> None:
    """"""Ensure --skip-net-check avoids connectivity checks.""""""
    _no_missing(monkeypatch)

    def _fail_net() -> bool:
        raise AssertionError(""has_network called"")

    monkeypatch.setattr(check_env, ""has_network"", _fail_net)
    rc = check_env.main([""--auto-install"", ""--skip-net-check""])
    assert rc == 0",tests/test_check_env_network.py,,1,2.5109990926928157e-08,"The method 'test_skip_net_check' is a unit test function that uses the 'monkeypatch' fixture from pytest to modify the behavior of the 'check_env.has_network' function. The purpose of this test is to ensure that when the '--skip-net-check' flag is used, the 'has_network' function is not called, as indicated by the AssertionError that would be raised if it were called. The test is well-structured, uses a common testing pattern, and is likely part of a larger test suite. There is no indication that this method is obsolete or redundant, and it serves a clear purpose in testing the functionality of a specific feature. Therefore, it is likely to be retained."
survived,"def collect_entries() -> list[tuple[str, str, str]]:
    entries: list[tuple[str, str, str]] = []
    for page in sorted(DEMOS_DIR.glob(""*.md"")):
        entries.append(parse_page(page))
    return entries
",scripts/generate_gallery_html.py,,1,4.363462233903899e-09,"The method 'collect_entries' is a simple utility function that collects and returns a list of tuples by parsing markdown files in a specified directory. It is straightforward, performs a clear task, and is likely to be useful in contexts where markdown files need to be processed. There are no apparent issues with the code, such as inefficiencies or errors, that would necessitate its deletion. Therefore, it is likely to survive."
survived,"def test_resolve_pins_versions():
    manager = DependencyManager()
    reqs, licenses, _ = manager.resolve([""pydantic"", ""click""])
    assert any(r.startswith(""pydantic=="") for r in reqs)
    assert any(r.startswith(""click=="") for r in reqs)
    assert licenses.get(""pydantic"") == ""MIT""
    assert ""click"" in licenses
",tests/test_dependency_manager.py,,1,9.237449576640118e-09,"The method 'test_resolve_pins_versions' is a unit test designed to verify the functionality of the 'resolve' method in the 'DependencyManager' class. It checks if the resolved dependencies include specific versions of 'pydantic' and 'click', and also verifies the licenses associated with these packages. Unit tests are crucial for ensuring code reliability and correctness, especially in dependency management, which is a critical aspect of software development. Therefore, this method is likely to be retained as it serves an important role in maintaining the integrity of the codebase."
survived,"def test_bundle_generator_custom_metadata(tmp_path: Path) -> None:
    gen = BundleGenerator(tmp_path)
    gen.generate(
        agent_code=""print('agent')"",
        metadata_fields={""meta_agent_version"": ""1.2.3"", ""extra"": ""field""},
        custom_metadata={""tag"": ""example""},
    )

    with open(tmp_path / ""bundle.json"", encoding=""utf-8"") as f:
        data = json.load(f)

    assert data[""meta_agent_version""] == ""1.2.3""
    assert data[""extra""] == ""field""
    assert data[""custom""][""tag""] == ""example""",tests/test_bundle_generator.py,,1,1.0467401685178159e-08,"The method `test_bundle_generator_custom_metadata` is a unit test function that verifies the functionality of the `BundleGenerator` class, specifically its ability to generate a bundle with custom metadata. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with data generation and file operations. The test checks if the generated JSON file contains the expected metadata fields and custom metadata, which is a common requirement in software development to ensure that the code behaves as expected. Therefore, this method is likely to be retained as it serves an important role in maintaining code quality."
survived,"    def git_available() -> bool:
        """"""Return True if the ``git`` executable can be found.""""""
        return shutil.which(""git"") is not None
",src/meta_agent/git_utils.py,GitManager,1,4.0586521248284276e-10,"The method `git_available` is a simple utility function that checks for the presence of the `git` executable in the system's PATH. This is a common requirement in many software projects that rely on version control, especially those that automate tasks involving repositories. The function is straightforward, efficient, and provides a useful check that can be reused across different parts of a codebase. Given its utility and simplicity, it is likely to be retained in the codebase."
survived,"    def __init__(self, *args: object, **kwargs: object) -> None:
        super().__init__(*args)
",tests/conftest.py,APIConnectionError,1,3.466327708641819e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming in Python. It initializes the class instance and is necessary for creating objects. The use of *args and **kwargs allows for flexible argument passing, making the constructor versatile. Therefore, it is unlikely to be deleted."
survived,"    def fCounter(f):
        global s
        s = s + ""|""
        return f
",tests/rosetta/transpiler/Python/church-numerals-2.py,,1,7.194132978569833e-09,"The method 'fCounter' is a simple function that takes another function 'f' as an argument, modifies a global variable 's' by appending a '|' character to it, and then returns the function 'f'. This method is likely to be used as a decorator or for some form of function tracking or modification. The method itself is functional and does not contain any errors or deprecated practices. It is a utility function that can be useful in certain contexts, such as logging or modifying behavior of functions. Therefore, it is likely to be Survived."
survived,"def choleskyLower(a):
    n = a[""order""]
    ae = a[""ele""]
    le = []
    idx = 0
    while idx < len(ae):
        le = le + [0.0]
        idx = idx + 1
    row = 1
    col = 1
    dr = 0
    dc = 0
    i = 0
    while i < len(ae):
        e = ae[i]
        if i < dr:
            d = (e - le[i]) // le[dc]
            le[i] = d
            ci = col
            cx = dc
            j = i + 1
            while j <= dr:
                cx = cx + ci
                ci = ci + 1
                le[j] = le[j] + d * le[cx]
                j = j + 1
            col = col + 1
            dc = dc + col
        else:
            le[i] = sqrtApprox(e - le[i])
            row = row + 1
            dr = dr + row
            col = 1
            dc = 0
        i = i + 1
    return {""order"": n, ""ele"": le}
",tests/rosetta/transpiler/Python/cholesky-decomposition-1.py,,1,3.466327708641819e-07,"The method 'choleskyLower' is a custom implementation of the Cholesky decomposition algorithm, which is a fundamental numerical method used in various scientific and engineering applications. Despite its unconventional implementation and potential inefficiencies, it serves a specific purpose in linear algebra computations. Such methods are typically retained unless they are replaced by more efficient or accurate implementations. Given that this method is functional and serves a specific purpose, it is likely to survive unless there is a significant reason to replace it with a more optimized version."
survived,"def pad10(s):
    str = s
    while len(str) < 10:
        str = "" "" + str
    return str
",tests/rosetta/transpiler/Python/composite-numbers-k-with-no-single-digit-factors-whose-factors-are-all-substrings-of-k.py,,1,3.850741907939403e-09,"The method 'pad10' is a simple utility function that pads a given string with spaces until its length is 10. This type of function is quite common and useful in formatting tasks, especially when dealing with fixed-width text outputs. The function is straightforward, performs its task efficiently, and does not have any apparent issues or bugs. Therefore, it is likely to be retained in the codebase as it serves a clear purpose and is implemented correctly."
survived,"def main():
    print(""zero = "" + str(toInt(zero())))
    onev = one()
    print(""one = "" + str(toInt(onev)))
    two = succ(succ(zero()))
    print(""two = "" + str(toInt(two)))
    three = plus(onev, two)
    print(""three = "" + str(toInt(three)))
    four = mult(two, two)
    print(""four = "" + str(toInt(four)))
    eight = exp(two, three)
    print(""eight = "" + str(toInt(eight)))
    print(""toStr(four) = "" + toStr(four))",tests/rosetta/transpiler/Python/church-numerals-2.py,,1,1.522997951276035e-08,"The method 'main()' is a typical entry point for a Python script, and it contains a series of function calls that demonstrate the use of various mathematical operations. The functions 'zero()', 'one()', 'succ()', 'plus()', 'mult()', 'exp()', 'toInt()', and 'toStr()' are likely defined elsewhere in the code, and 'main()' is used to showcase their functionality. Since 'main()' is a standard way to execute a script and test functions, it is unlikely to be deleted unless the entire script is being refactored or removed. Therefore, the method will likely survive."
survived,"def exp(m, n):
    return n(m)
",tests/rosetta/transpiler/Python/church-numerals-2.py,,1,4.6911638017642294e-08,"The method 'exp' is a higher-order function that takes two arguments: 'm' and 'n'. It applies the function 'n' to the argument 'm'. This is a valid and potentially useful function in functional programming contexts where functions are passed as arguments. The method is simple, clear, and can be used in various scenarios where function application is needed. Therefore, it is likely to be retained as it serves a purpose in functional programming paradigms."
survived,"def test_throttle_alert(monkeypatch: pytest.MonkeyPatch) -> None:
    monkeypatch.setenv(""API_RATE_LIMIT"", ""1"")
    from src.interface import api_server as mod
    api = importlib.reload(mod)

    sent: list[str] = []
    monkeypatch.setattr(api.alerts, ""send_alert"", lambda msg, url=None: sent.append(msg))

    client = TestClient(cast(Any, api.app))
    headers = {""Authorization"": ""Bearer test-token""}

    client.get(""/runs"", headers=headers)
    client.get(""/runs"", headers=headers)

    stack = api.app.middleware_stack
    metrics = stack.app.app
    limiter = metrics.app
    metrics.window_start = time.time() - 61
    limiter.counters[""testclient""] = (0, time.time())

    client.get(""/runs"", headers=headers)

    assert sent, ""alert not triggered""

    monkeypatch.setenv(""API_RATE_LIMIT"", ""1000"")
    importlib.reload(api)",tests/test_api_server_static.py,,1,1.522997951276035e-08,"The method `test_throttle_alert` is a test function that verifies the behavior of an API rate limiting feature. It uses the `monkeypatch` fixture to simulate different environment settings and checks if an alert is triggered when the rate limit is exceeded. This is a common and necessary test in systems where rate limiting is implemented to ensure that the feature works as expected. Since rate limiting is a critical part of API management to prevent abuse and ensure fair usage, this test is likely to be important for maintaining the integrity of the system. Therefore, the method is likely to be retained."
survived,"def test_error_handler_logs_and_outputs(caplog, capsys):
    handler = ErrorHandler(cli_output=CLIOutput())
    err = CLIOutputError(""boom"", context={""foo"": ""bar""})
    with caplog.at_level(logging.ERROR):
        handler.handle(err)
    out, err_stream = capsys.readouterr()
    assert ""boom"" in err_stream
    assert ""boom"" in caplog.text
    assert ""foo"" in caplog.text
",tests/ux/test_error_handler.py,,1,1.1032560311263802e-09,"The method 'test_error_handler_logs_and_outputs' is a unit test designed to verify the functionality of an error handler. It checks if the error message and context are correctly logged and outputted. This is a crucial part of ensuring the robustness and reliability of error handling in software applications. Unit tests are generally not deleted unless they are redundant or replaced by more comprehensive tests. Since this test seems to be well-structured and serves a clear purpose, it is likely to be retained."
survived,"    def raise_interrupt(_):
        raise EOFError
",tests/ux/test_interactive.py,,0,0.5926665999540698,"The method `raise_interrupt` is a simple function that raises an `EOFError` when called. This function might be used in a context where an interrupt needs to be simulated or handled, such as in testing scenarios or specific application logic where an EOFError is expected to trigger certain behavior. However, the function itself is very specific and not broadly applicable, which might limit its use cases. If the surrounding codebase or application frequently requires such an interrupt, the method might survive. Otherwise, it could be considered redundant or too specific, leading to its deletion."
survived,"def test_menu_empty_options():
    inter = Interactive()
    with pytest.raises(InteractiveError):
        inter.menu(""Pick"", [])
",tests/ux/test_interactive.py,,1,1.0467401685178159e-08,"The method 'test_menu_empty_options' is a unit test designed to verify that the 'menu' method of the 'Interactive' class raises an 'InteractiveError' when provided with an empty list of options. This is a valid and useful test case to ensure that the 'menu' method handles edge cases correctly. Unit tests are crucial for maintaining code quality and ensuring that methods behave as expected under various conditions. Therefore, this method is likely to be retained as part of the test suite."
survived,"    def __init__(self, cli_output: CLIOutput | None = None) -> None:
        self.cli_output = cli_output or CLIOutput()
",src/meta_agent/ux/user_feedback.py,UserFeedback,1,1.1253518384332553e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting initial values for instance variables. The use of type hinting with 'CLIOutput | None' indicates modern Python practices, suggesting the code is up-to-date and likely part of a maintained codebase. Therefore, it is unlikely to be deleted."
survived,"def test_mcp_invoke_tool_missing():
    async def _run() -> None:
        adapter = MCPAdapter()
        with pytest.raises(KeyError):
            await adapter.invoke_tool(""missing_tool"", {})

    asyncio.run(_run())
",tests/test_adapters.py,,1,6.348800075736417e-09,"The method `test_mcp_invoke_tool_missing` is a test function that checks if the `invoke_tool` method of the `MCPAdapter` class raises a `KeyError` when a non-existent tool is invoked. This is a valid and useful test case to ensure that the system behaves correctly when an invalid tool is requested. Test functions like this are essential for maintaining code quality and ensuring that edge cases are handled properly. Therefore, it is likely to be retained in the codebase."
survived,"        async def stop_merkle_task(self) -> None:  # pragma: no cover - interface
            pass
",tests/test_adapters.py,DummyLedger,1,2.3823698451773172e-07,"The method `stop_merkle_task` is an asynchronous method that currently does nothing (it only contains a `pass` statement). However, it is marked with a comment `# pragma: no cover - interface`, which suggests that this method is part of an interface or a contract that needs to be implemented by subclasses or in the future. This indicates that the method is intentionally left as a placeholder for future implementation, rather than being redundant or unnecessary. Therefore, it is likely to survive as it serves a purpose in the design of the code, even if it is not currently functional."
survived,"        def start_merkle_task(self, *_a, **_kw):
            pass
",tests/test_adapters.py,DummyLedger,0,0.999999922655772,"The method `start_merkle_task` is defined but not implemented, as it only contains a `pass` statement. This suggests that it might be a placeholder for future functionality. However, without any additional context or usage within the codebase, it is likely to be considered dead code. If it remains unused and unimplemented, it is likely to be deleted in future iterations to clean up the codebase."
survived,"        def __init__(self) -> None:
            self.logged: list[messaging.Envelope] = []
",tests/test_adapters.py,DummyLedger,1,2.8453347280241004e-08,"The method is a constructor (__init__) for a class, which is a fundamental part of class instantiation in Python. Constructors are essential for initializing new objects and setting initial values for instance variables. Therefore, it is highly unlikely that this method would be deleted as it is crucial for the proper functioning of the class."
survived,"    def fake_generate(self, prompt: str) -> str:
        calls[""prompt""] = prompt
        return ""resp""
",tests/test_adapters.py,,0,0.9999999778405106,"The method 'fake_generate' is a simple function that takes a string input 'prompt', assigns it to a dictionary 'calls' with the key 'prompt', and returns a static string 'resp'. This method is likely a placeholder or a mock function used for testing purposes. Such methods are often temporary and used during development to simulate behavior without implementing full functionality. Therefore, it is likely to be deleted once the actual implementation is completed or when the testing phase is over."
survived,"def _reset_islands() -> None:
    mats.ISLANDS.clear()
    mats.ISLAND_SEEDS.clear()
",tests/test_mats.py,,1,1.0467401685178159e-08,"The method `_reset_islands` is a utility function that clears two collections, `ISLANDS` and `ISLAND_SEEDS`, presumably to reset some state in the application. Such utility functions are often necessary for maintaining or resetting the state of an application, especially in testing or when reinitializing components. Since it performs a clear and specific task without any apparent issues, it is likely to be retained in the codebase."
survived,"def main(argv: List[str] | None = None) -> None:
    """"""Run the α‑AGI Insight demo with environment validation.""""""
    args = [""--verify-env""]
    if argv:
        args.extend(argv)
    __main__.main(args)
",alpha_factory_v1/demos/alpha_agi_insight_v0/official_demo.py,,1,4.944450477491054e-09,"The method 'main' is a standard entry point for Python scripts and is used to execute the main functionality of a program. It is a common practice to define a 'main' function to encapsulate the script's logic, making it easier to manage and test. The use of 'argv' as an argument allows for flexibility in passing command-line arguments, which is a typical requirement for many scripts. Additionally, the function includes a docstring, indicating that it is well-documented and likely part of a larger, maintained codebase. There is no indication that this method is obsolete or redundant, so it is likely to be retained."
survived,"def create_app():
    engine = create_async_engine(""sqlite+aiosqlite:///:memory:"")
    lifespan = sqlalchemy_lifespan(Base, engine, seed=seed)
    app = EnrichMCP(""Test"", ""Desc"", lifespan=lifespan)
    include_sqlalchemy_models(app, Base)
    return app, lifespan
",tests/test_sqlalchemy_autogen.py,,1,1.955568070542584e-08,"The method 'create_app' is a typical setup function for initializing an application with a database connection and models. It uses an asynchronous engine for SQLite, which is suitable for modern web applications that require non-blocking operations. The method is well-structured, using a lifespan for managing the database connection and including models into the app. This kind of setup is common in web frameworks and is unlikely to be deleted unless there is a significant change in the application's architecture or technology stack."
survived,"def include_sqlalchemy_models(
    app: EnrichMCP,
    base: type[DeclarativeBase],
    *,
    session_key: str = ""session_factory"",
) -> dict[str, type]:
    """"""Register SQLAlchemy models with automatic resources and resolvers.""""""

    models: dict[str, type] = {}
    for mapper in base.registry.mappers:
        sa_model = mapper.class_
        if not issubclass(sa_model, EnrichSQLAlchemyMixin):
            continue
        enrich_cls = sa_model.__enrich_model__()
        model = type(
            enrich_cls.__name__,
            (enrich_cls,),
            {""__doc__"": enrich_cls.__doc__},
        )
        app.entity(model)
        models[sa_model.__name__] = model
        models[model.__name__] = model

    for mapper in base.registry.mappers:
        sa_model = mapper.class_
        if sa_model.__name__ not in models:
            continue
        enrich_model = models[sa_model.__name__]
        _register_default_resources(app, sa_model, enrich_model, session_key)
        _register_relationship_resolvers(app, sa_model, enrich_model, models, session_key)
        enrich_model.model_rebuild(_types_namespace=models)

    return models",src/enrichmcp/sqlalchemy/auto.py,,1,1.522997951276035e-08,"The method `include_sqlalchemy_models` is a utility function that registers SQLAlchemy models with an application, providing automatic resources and resolvers. This is a common requirement in applications that use SQLAlchemy for ORM (Object-Relational Mapping) and need to integrate these models with a larger application framework. The method is well-structured, uses type hints, and follows a clear logic to register models and their relationships. Such functionality is essential for applications that rely on dynamic model registration and resource management, making it unlikely to be deleted unless the entire architecture or framework changes significantly."
survived,"def test_ragged_paged_attention_incremental_single_seq():
    rng = jr.PRNGKey(2)
    seq_lens = [47]
    k_lens = [5]
    q, kv_pages, kv_lens, page_indices, cu_q_lens, num_seqs = _build_incremental_case(rng, seq_lens, k_lens)

    ragged = default_ragged_paged_attention(q, kv_pages, kv_lens, page_indices, cu_q_lens, num_seqs, sm_scale=SM_SCALE)
    ref = _reference_attention(q, kv_pages, kv_lens, page_indices, cu_q_lens, k_lens)

    assert ragged.axes == ref.axes
    assert_trees_all_close(ragged.array, ref.array, atol=1e-3, rtol=1e-3)
",tests/test_paged_attention.py,,1,1.1253518384332553e-07,"The method `test_ragged_paged_attention_incremental_single_seq` is a unit test function, which is crucial for ensuring the correctness of the `ragged_paged_attention` functionality. Unit tests are generally not deleted unless the functionality they are testing is removed or significantly changed. Since this test is likely part of a test suite ensuring the reliability of a specific feature, it is more likely to be maintained or updated rather than deleted."
survived,"    def agents(self) -> list[str]:
        """"""Return the list of registered agents.""""""
        url = f""{self.base_url}/agents""
        resp = requests.get(url)
        resp.raise_for_status()
        return resp.json()
",alpha_factory_v1/demos/alpha_agi_marketplace_v1/marketplace.py,MarketplaceClient,1,5.905303995456778e-10,"The method 'agents' is a straightforward implementation that fetches a list of registered agents from a specified URL. It uses the requests library to perform an HTTP GET request and handles potential errors with 'raise_for_status'. The method is simple, clear, and serves a specific purpose, which makes it unlikely to be deleted unless the functionality it provides is no longer needed or the implementation is moved elsewhere. Therefore, it is more likely to survive."
survived,"    def exec_module(self, module: ModuleType) -> None:
        file_path = module.__spec__.origin  # type: ignore
        base_path = os.path.dirname(file_path)
        target = os.path.splitext(os.path.basename(file_path))[0]
        ret = JacMachineInterface.jac_import(
            target=target,
            base_path=base_path,
            override_name=module.__name__,
        )
        if ret:
            loaded_module = ret[0]
            module.__dict__.update(loaded_module.__dict__)
        else:
            raise ImportError(f""Unable to import {module.__name__}"")
",jac/jaclang/runtimelib/meta_importer.py,JacMetaImporter,1,1.6052280526088547e-09,"The method 'exec_module' is likely to survive because it performs a specific and necessary function of executing a module by importing it using a custom interface. It handles both the successful import and the error case, which is a common requirement in module management. Additionally, the method is well-structured and uses standard Python practices for module handling, making it a useful and reusable piece of code."
survived,"    def create_module(self, spec):
        return None  # use default machinery
",jac/jaclang/runtimelib/meta_importer.py,JacMetaImporter,0,0.9999898700118929,"The method 'create_module' is a placeholder that returns None, indicating that it relies on the default machinery for module creation. This suggests that the method is not currently implementing any custom logic or functionality. In many cases, such placeholder methods are either removed or replaced with actual implementations. However, if the method is part of a larger framework or API where extensibility is expected, it might be retained for future customization. Without additional context, it's more likely to be deleted if it serves no current purpose."
survived,"def test_build_llm_missing_api_key(monkeypatch):
    if importlib.util.find_spec(""openai_agents""):
        import openai_agents as oa
    else:  # pragma: no cover - legacy package name
        import agents as oa

    captured = {}

    class DummyAgent:
        def __init__(self, *a, base_url=None, **kw):
            captured['base_url'] = base_url

    monkeypatch.setattr(oa, ""OpenAIAgent"", DummyAgent)
    monkeypatch.setenv(""OPENAI_API_KEY"", """")
    monkeypatch.setenv(""OLLAMA_BASE_URL"", ""http://testserver"")

    import importlib as _imp
    mod = _imp.reload(_imp.import_module(""alpha_factory_v1.demos.aiga_meta_evolution.utils""))
    llm = mod.build_llm()
    assert isinstance(llm, DummyAgent)
    assert captured.get('base_url') == ""http://testserver""
",tests/test_external_integrations.py,,1,9.931195248674785e-08,"The method is a test function that uses the 'monkeypatch' fixture to modify the environment and test the behavior of the 'build_llm' function when the API key is missing. This is a common practice in testing to ensure that the function behaves correctly under different conditions. The method is useful for ensuring robustness and reliability of the code, especially in handling missing configurations. Therefore, it is likely to be retained as part of the test suite."
survived,"def _verify_wheel(path: Path) -> bool:
    """"""Return ``True`` if the wheel's signature is valid.""""""
    sig_path = path.with_suffix(path.suffix + "".sig"")
    if not sig_path.is_file():
        logger.error(""Missing .sig file for %s"", path.name)
        return False
    if ed25519 is None:
        logger.error(""cryptography library required for signature checks"")
        return False
    try:
        sig_b64 = sig_path.read_text().strip()
        expected = _WHEEL_SIGS.get(path.name)
        if expected and expected != sig_b64:
            logger.error(""Signature mismatch for %s"", path.name)
            return False
        pub_bytes = base64.b64decode(_WHEEL_PUBKEY)
        signature = base64.b64decode(sig_b64)
        ed25519.Ed25519PublicKey.from_public_bytes(pub_bytes).verify(signature, path.read_bytes())
        return True
    except InvalidSignature:
        logger.error(""Invalid signature for %s"", path.name)
    except Exception:
        logger.exception(""Signature verification failed for %s"", path.name)
    return False
",alpha_factory_v1/backend/agents/__init__.py,,1,6.348800075736417e-09,"The method '_verify_wheel' is a utility function that checks the validity of a wheel file's signature. This is a crucial security feature, especially in package management systems, to ensure that the files being used are not tampered with. The method handles various error cases, such as missing signature files, mismatched signatures, and exceptions during verification, which are all important for robust error handling. Given the importance of security in software distribution and the comprehensive error handling in this method, it is likely to be retained in the codebase."
survived,"    def __exit__(self, exc_type, exc, tb) -> bool:
        try:
            self.close()
        except Exception as err:  # pragma: no cover - defensive
            logger.warning(""MemoryFabric: close failed → %s"", err)
            return exc_type is None
        return False
",alpha_factory_v1/backend/memory_fabric.py,MemoryFabric,1,3.2241866333029355e-08,"The method is a custom implementation of the __exit__ method, which is part of the context management protocol in Python. This method is crucial for ensuring that resources are properly released when an object is used in a 'with' statement. The method includes error handling to log any exceptions that occur during the close operation, which is a good practice for robustness. The use of 'pragma: no cover' suggests that the exception handling is defensive and not expected to be covered by tests, indicating careful consideration of edge cases. Therefore, this method is likely to be retained as it provides essential functionality and error handling."
survived,"    def __enter__(self) -> ""MemoryFabric"":
        return self
",alpha_factory_v1/backend/memory_fabric.py,MemoryFabric,1,2.998960815863541e-09,"The method `__enter__` is part of the context management protocol in Python, which is used to define what should happen when a context is entered using the `with` statement. This method is essential for classes that are intended to be used as context managers. Since context managers are a common and useful pattern in Python for resource management, it is unlikely that this method will be deleted unless the class itself is being deprecated or significantly refactored. Therefore, the method will likely survive."
deleted,"  def supports_active_cooling(self) -> bool:
    return False",pylabrobot/heating_shaking/backend.py,HeaterShakerBackend,1,3.3982678079468468e-09,"The method `supports_active_cooling` is a simple boolean method that returns `False`. It is likely a placeholder or a default implementation indicating that the current object does not support active cooling. Such methods are often part of an interface or a base class where different subclasses might override this method to return `True` if they do support active cooling. Therefore, it is likely to be retained as part of a larger design pattern or framework, allowing for polymorphic behavior. Hence, it is more likely to survive."
survived,"  async def test_passive_cooling_with_support(self):
    backend = _FakeBackend(temperature=30.0)
    tc = TemperatureController(
      name=""tc"",
      size_x=1,
      size_y=1,
      size_z=1,
      backend=backend,
      child_location=Coordinate.zero(),
    )

    await tc.set_temperature(20, passive=True)
    self.assertFalse(backend.set_called)",pylabrobot/temperature_controlling/temperature_controller_tests.py,PassiveCoolingWithSupportTests,1,3.3982678079468468e-09,"The method `test_passive_cooling_with_support` is a unit test designed to verify the behavior of a `TemperatureController` when passive cooling is requested. It checks that the backend's `set_called` attribute remains `False`, indicating that no active temperature setting was invoked. This is a valid and useful test case for ensuring the correct functionality of the passive cooling feature. Therefore, it is likely to be retained in the codebase."
survived,"  async def stop(self):
    pass
",pylabrobot/temperature_controlling/temperature_controller_tests.py,_FakeBackend,1,6.475946147757848e-07,"The method 'stop' is defined as an asynchronous function but contains only a 'pass' statement, meaning it currently does nothing. However, the method name 'stop' suggests it might be intended for future use to stop or terminate an ongoing process or task. In many cases, such placeholder methods are kept in the codebase to be implemented later when the functionality is needed. Therefore, it is likely to survive as it might be part of a planned feature or functionality."
survived,"  async def test_cannot_cool_without_support(self):
    backend = TemperatureControllerChatterboxBackend(dummy_temperature=20.0)
    tc = TemperatureController(
      name=""tc"",
      size_x=1,
      size_y=1,
      size_z=1,
      backend=backend,
      child_location=Coordinate.zero(),
    )

    with self.assertRaises(ValueError):
      await tc.set_temperature(10)
",pylabrobot/temperature_controlling/temperature_controller_tests.py,PassiveCoolingTests,1,4.1399375473943306e-08,"The method `test_cannot_cool_without_support` is a unit test designed to verify that the `TemperatureController` raises a `ValueError` when attempting to set a temperature lower than the current temperature without support. This is a valid and useful test case to ensure the robustness of the `TemperatureController` class, especially in scenarios where cooling might not be supported or could lead to errors. Therefore, the method is likely to be retained as it serves a clear purpose in testing the functionality and error handling of the system."
survived,"  async def deactivate(self):
    pass
",pylabrobot/temperature_controlling/temperature_controller_tests.py,_FakeBackend,0,0.9999756997690634,"The method `deactivate` is defined as an asynchronous function but contains only a `pass` statement, meaning it currently has no implementation. This suggests that it might be a placeholder for future functionality. However, without any implementation or documentation indicating its purpose, it is not serving any current function. If the method remains unimplemented for an extended period, it is likely to be deleted unless there is a clear plan to implement it in the future."
survived,"def test_pdfs_to_hf_dataset(monkeypatch, tmp_path, fake_dataset_class):
    from importlib import reload

    data = fake_dataset_class
    reload(data)

    def fake_convert_from_path(*args, **kwargs):
        return [Image.new(""RGB"", (10, 10)), Image.new(""RGB"", (10, 10))]

    class FakePage:
        def __init__(self, text):
            self.text = text

        def extract_text(self):
            return self.text

    class FakeReader:
        def __init__(self, _):
            self.pages = [FakePage(""a""), FakePage(""b"")]

    monkeypatch.setattr(data, ""convert_from_path"", fake_convert_from_path)
    monkeypatch.setattr(data, ""PdfReader"", FakeReader)

    (tmp_path / ""doc1.pdf"").write_bytes(b""%PDF-1.4"")
    (tmp_path / ""doc2.pdf"").write_bytes(b""%PDF-1.4"")

    dataset = data.pdfs_to_hf_dataset(tmp_path)
    assert len(dataset) == 4
    assert dataset[0][""pdf_name""] == ""doc1.pdf""
    assert dataset[0][""pdf_page""] == 1
",no-ocr-api/tests/test_ingest_search.py,,1,3.2241866333029355e-08,"The method 'test_pdfs_to_hf_dataset' is a unit test function that uses the 'monkeypatch' fixture to mock certain behaviors and test the 'pdfs_to_hf_dataset' function from the 'fake_dataset_class'. This is a common practice in testing to isolate the function being tested from its dependencies. The method is well-structured, uses mock objects effectively, and includes assertions to verify the expected behavior of the function under test. Since testing is a crucial part of software development to ensure code quality and reliability, this method is likely to be retained in the codebase."
survived,"def test_ai_search_dataset_missing(client, monkeypatch):
    from np_ocr import api as api_module

    monkeypatch.setattr(api_module, ""search_client"", types.SimpleNamespace(search_images_by_text=lambda *a, **k: []))

    response = client.post(
        ""/search"",
        data={""user_query"": ""foo"", ""user_id"": ""user"", ""case_name"": ""case""},
    )
    assert response.status_code == 404
",no-ocr-api/tests/test_ingest_search.py,,1,8.76424914819242e-08,"The method 'test_ai_search_dataset_missing' is a unit test designed to verify the behavior of an API endpoint when a search operation returns no results. It uses the 'monkeypatch' fixture to mock the 'search_client' method, ensuring it returns an empty list, simulating a scenario where no data is found. The test then asserts that the response status code is 404, indicating a 'Not Found' error, which is a valid and necessary test case to ensure the API handles missing data correctly. Therefore, this method is likely to be retained as it serves a critical role in testing the robustness of the API."
survived,"async def test_ask_llm_requires_request_context():
    ctx = EnrichContext()
    with pytest.raises(ValueError, match=""outside of a request""):
        await ctx.ask_llm(""ping"")",tests/test_llm.py,,1,2.2159489282323004e-08,"The method `test_ask_llm_requires_request_context` is a test function that checks if a `ValueError` is raised when `ask_llm` is called outside of a request context. This is a valid and useful test to ensure that the `ask_llm` function behaves correctly under certain conditions. Test functions like this are crucial for maintaining code quality and ensuring that the application behaves as expected. Therefore, it is likely to be retained in the codebase."
survived,"        async def stop(self) -> None:
            return None
",tests/test_bus_large_payloads_property.py,Prod,0,0.9999999979388463,"The method 'stop' is defined as an asynchronous function but does not perform any asynchronous operations or have any meaningful implementation, as it simply returns None. This makes the method redundant and likely to be removed in future code refactoring to clean up the codebase. Therefore, it is predicted to be deleted."
survived,"def copy_assets(manifest: dict, repo_root: Path, dist_dir: Path) -> None:
    for rel in manifest[""files""]:
        src_path = ROOT / rel
        if src_path.exists():
            target = dist_dir / rel
            target.parent.mkdir(parents=True, exist_ok=True)
            target.write_bytes(src_path.read_bytes())

    quickstart_pdf = repo_root / manifest[""quickstart_pdf""]
    if quickstart_pdf.exists():
        (dist_dir / quickstart_pdf.name).write_bytes(quickstart_pdf.read_bytes())

    translations = ROOT / manifest[""dirs""][""translations""]
    if translations.exists():
        for f in translations.iterdir():
            if f.is_file():
                target = dist_dir / manifest[""dirs""][""translations""] / f.name
                target.parent.mkdir(parents=True, exist_ok=True)
                target.write_bytes(f.read_bytes())

    critics_src = repo_root / manifest[""dirs""][""critics""]
    critics_dst = dist_dir / manifest[""dirs""][""critics""]
    if critics_src.exists():
        critics_dst.mkdir(parents=True, exist_ok=True)
        for f in critics_src.iterdir():
            (critics_dst / f.name).write_bytes(f.read_bytes())

    for key in (""wasm"", ""wasm_llm""):
        d = ROOT / manifest[""dirs""][key]
        if d.exists():
            target_dir = dist_dir / manifest[""dirs""][key]
            target_dir.mkdir(exist_ok=True)
            for f in d.iterdir():
                (target_dir / f.name).write_bytes(f.read_bytes())
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/manual_build.py,,1,9.736200303530205e-10,"The method 'copy_assets' is likely to survive because it performs a crucial function of copying various assets from a source directory to a distribution directory based on a manifest. This is a common requirement in software projects for preparing files for deployment or distribution. The method is well-structured, handles different types of assets, and ensures directories are created as needed, which indicates it is a useful utility function."
survived,"def scenario_1994_web() -> replay.Scenario:
    return replay.load_scenario(""1994_web"")
",tests/conftest.py,,1,5.3157849718487075e-08,"The method `scenario_1994_web` is a simple wrapper around the `replay.load_scenario` function, which loads a scenario named ""1994_web"". This method is likely part of a larger framework or library that deals with scenarios, possibly for testing or simulation purposes. The method is straightforward, has a clear purpose, and is likely used in multiple places within the codebase. Unless the ""1994_web"" scenario is deprecated or the entire framework is being refactored, there is no strong reason to delete this method. It is more likely to be retained for its utility in loading a specific scenario."
survived,"def post(
    url: str,
    *,
    params: dict | None = None,
    json: dict | None = None,
    data: dict | bytes | None = None,
    headers: dict | None = None,
    timeout: float | None = None,
) -> Response:
    """"""Perform a minimal HTTP POST request.""""""
    return _call(
        ""POST"",
        url,
        params=params,
        json=json,
        data=data,
        headers=headers,
        timeout=timeout,
    )
",alpha_factory_v1/af_requests.py,,1,2.0611536181902033e-09,"The method 'post' is a utility function for making HTTP POST requests, which is a common requirement in many applications that interact with web services. It provides a clean and simple interface for specifying various request parameters such as URL, headers, and data. The method is likely to be useful in a wide range of scenarios, from testing APIs to integrating with web services, making it a valuable part of a codebase. Therefore, it is unlikely to be deleted unless there is a significant change in the way HTTP requests are handled in the application."
survived,"    def build_index(self) -> None:
        """"""Build an in-memory index of template metadata and content.""""""
        self._index.clear()
        for entry in self.registry.list_templates():
            slug = entry[""slug""]
            version = entry.get(""current_version"")
            if not version:
                continue
            content = self.registry.load_template(slug, version) or """"
            metadata_path = (
                self.registry.templates_dir
                / slug.replace("" "", ""_"").lower()
                / f""v{version.replace('.', '_')}""
                / METADATA_FILE_NAME
            )
            try:
                with open(metadata_path, ""r"", encoding=""utf-8"") as f:
                    metadata = json.load(f)
            except (OSError, json.JSONDecodeError):
                metadata = {}
            self._index.append(
                {
                    ""slug"": slug,
                    ""version"": version,
                    ""metadata"": metadata,
                    ""content"": content,
                }
            )
",src/meta_agent/template_search.py,TemplateSearchEngine,1,8.592166611791576e-10,"The method 'build_index' is likely to survive because it performs a crucial function of building an in-memory index of template metadata and content, which is essential for applications that need to manage and access template data efficiently. The method is well-structured, handles exceptions, and uses clear logic to iterate over templates, making it a valuable part of the codebase."
survived,"    def _register(self, runner: AgentRunner) -> None:
        env = messaging.Envelope(
            ""orch"",
            ""system"",
            {""event"": ""register"", ""agent"": runner.agent.name, ""capabilities"": runner.capabilities},
            time.time(),
        )
        self.ledger.log(env)
        self.bus.publish(""system"", env)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/orchestrator.py,Orchestrator,1,3.850741907939403e-09,"The method '_register' is likely to be Survived (1) because it performs a crucial function of registering an agent runner by creating an envelope with necessary details and logging it to a ledger. It also publishes this information to a system bus, indicating its role in communication and event handling within the system. These operations suggest that the method is integral to the system's functionality, particularly in managing agent runners and their interactions."
survived,"    def test_rpc_auth(self) -> None:
        self.settings.bus_token = ""s3cr3t""
        bus = messaging.A2ABus(self.settings)

        class Ctx:
            def abort(self, *_a, **_kw):
                raise RuntimeError(""denied"")

        payload = {
            ""sender"": ""a"",
            ""recipient"": ""b"",
            ""payload"": {},
            ""ts"": 0.0,
            ""token"": ""s3cr3t"",
        }
        asyncio.run(bus._handle_rpc(json.dumps(payload).encode(), Ctx()))
",tests/test_insight_orchestrator_features.py,TestMessaging,1,4.6911638017642294e-08,"The method `test_rpc_auth` is a test function that appears to be testing the authentication mechanism of an RPC (Remote Procedure Call) system. It sets up a token, creates a bus object, and defines a context class with an abort method to simulate an error condition. The function then constructs a payload and runs an asynchronous method to handle the RPC. This kind of test function is crucial for ensuring that the authentication logic works correctly and is likely part of a test suite. Test functions are generally not deleted unless they are redundant or replaced by more comprehensive tests. Therefore, this method is likely to be retained as part of the testing framework."
survived,"    def fn(genome: list[float]) -> tuple[float, float]:
        x, y = genome
        return x**2, y**2
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/simulation/forecast.py,,1,5.905303995456778e-10,"The method 'fn' is a simple function that takes a list of two floats and returns a tuple of their squares. This is a basic mathematical operation that is unlikely to be removed unless the requirements change significantly. The function is clear, concise, and performs a straightforward task, which makes it useful in contexts where such operations are needed. Therefore, it is likely to survive."
survived,"    def test_ledger_default_home(self) -> None:
        env = {""CROSS_ALPHA_LEDGER"": """"}
        with patch.dict(os.environ, env, clear=False):
            path = stub._ledger_path(None)
        expected = stub.DEFAULT_LEDGER.resolve()
        self.assertEqual(path, expected)
        self.assertTrue(path.parent.exists())
",alpha_factory_v1/tests/test_cross_industry_alpha.py,TestCrossIndustryAlpha,1,2.2159489282323004e-08,"The method `test_ledger_default_home` is a unit test that verifies the behavior of a function related to ledger paths. It uses mocking to simulate an environment variable and checks if the ledger path resolves to the expected default path. This is a typical and necessary test to ensure the correct functionality of the code, especially when dealing with environment-dependent behavior. Such tests are crucial for maintaining code reliability and are unlikely to be deleted unless the functionality they test is removed or significantly altered."
survived,"def restrict_wizard():
    if current_user.is_authenticated:
        return
    if not session.get(""wizard_access""):
        return redirect(""/"")
",app/blueprints/wizard/routes.py,,1,1.522997951276035e-08,"The method 'restrict_wizard' is a simple utility function that checks if a user is authenticated or has a session variable 'wizard_access'. If neither condition is met, it redirects the user to the home page. This is a common pattern in web applications to restrict access to certain parts of the application based on user authentication or session variables. The method is likely to be useful in maintaining security and access control, which are critical aspects of web development. Therefore, it is likely to be retained in the codebase."
survived,"    def foo(x: f32[""batch embed""]):  # type: ignore  # noqa: F722
        pass
",tests/test_dtype_typing.py,,0,0.9999993524053853,"The method is likely to be deleted because it contains a type hint that is not valid in Python. The type hint 'f32[""batch embed""]' is not a recognized type in Python, and the use of 'type: ignore' and 'noqa: F722' suggests that the developer is aware of this issue but is suppressing the warnings. This indicates that the code may not be functional or is a placeholder, leading to its potential deletion."
survived,"def test_other_dtype_annotation():
    def bar(x: i32[""batch""]):  # type: ignore  # noqa: F722
        pass

    spec = typing.get_args(typing.get_type_hints(bar, include_extras=True)[""x""])[1]
    assert spec.dtype == jnp.int32
    assert spec.before == (""batch"",)
",tests/test_dtype_typing.py,,0,0.999999694097641,"The method `test_other_dtype_annotation` is likely to be deleted because it uses a non-standard type annotation `i32[""batch""]` which is not a recognized or valid Python type hint. The use of `type: ignore` and `noqa: F722` suggests that the code is intentionally bypassing type checking and linting errors, which is generally not a good practice for maintainable code. Additionally, the test seems to rely on specific behavior of `typing.get_type_hints` that may not be supported or intended, making the test fragile and potentially unreliable."
survived,"    def test_trigger_discovery(self):
        agent = bridge.BusinessAgent()
        with patch.object(bridge, ""requests"") as req:
            req.post.return_value = DummyResponse()
            result = asyncio.run(bridge.trigger_discovery())
        req.post.assert_called_once_with(
            f""{bridge.HOST}/agent/alpha_discovery/trigger"", timeout=5
        )
        self.assertEqual(result, ""alpha_discovery queued"")
",tests/test_openai_bridge_integration.py,TestBusinessAgentIntegration,1,6.825604231969389e-08,"The method `test_trigger_discovery` is a unit test for the `trigger_discovery` function in the `bridge` module. It uses mocking to simulate the behavior of the `requests` library and checks if the `post` method is called with the correct parameters. The test also verifies that the result of the `trigger_discovery` function is as expected. This is a typical and necessary test to ensure the functionality of the `trigger_discovery` method, especially in a network-related context where actual HTTP requests should be avoided during testing. Therefore, this method is likely to be retained as it serves a crucial role in maintaining code quality and reliability."
survived,"    def test_submit_job(self):
        agent = bridge.BusinessAgent()
        job = {""agent"": ""alpha_discovery"", ""foo"": 1}
        with patch.object(bridge, ""requests"") as req:
            req.post.return_value = DummyResponse()
            result = asyncio.run(bridge.submit_job(job))
        req.post.assert_called_once_with(
            f""{bridge.HOST}/agent/alpha_discovery/trigger"", json=job, timeout=5
        )
        self.assertEqual(result, ""job for alpha_discovery queued"")
",tests/test_openai_bridge_integration.py,TestBusinessAgentIntegration,1,6.023574641292144e-08,"The method `test_submit_job` is a unit test for the `submit_job` function, which is a crucial part of ensuring that the job submission process works correctly. It uses mocking to simulate the behavior of the `requests` library, which is a common practice in testing to isolate the function being tested from external dependencies. This method is likely to be retained because it verifies the functionality of a key feature in the system, ensuring that jobs are submitted correctly and the expected response is returned. Such tests are essential for maintaining code quality and reliability."
survived,"def _ensure_assets() -> None:
    placeholders = []
    for p in (bundle_path, workbox_path):
        if p.exists():
            data = p.read_text(errors=""ignore"")
            if ""placeholder"" in data.lower():
                placeholders.append(p)
        else:
            placeholders.append(p)
    if placeholders:
        print(""Fetching missing browser assets..."")
        subprocess.run(
            [sys.executable, str(repo_root / ""scripts/fetch_assets.py"")],
            check=True,
        )
        for p in placeholders:
            if not p.exists() or ""placeholder"" in p.read_text(errors=""ignore"").lower():
                sys.exit(f""Failed to download {p.relative_to(ROOT)}"")
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/manual_build.py,,1,1.0467401685178159e-08,"The method '_ensure_assets' is responsible for ensuring that certain assets are present and valid. It checks for the existence of files and whether they contain placeholders, and if any issues are found, it attempts to fetch the necessary assets. This functionality is crucial for maintaining the integrity and functionality of the application, especially if these assets are required for the application to run correctly. Therefore, it is unlikely that this method will be deleted as it serves an important role in asset management."
survived,"def test_mutate_cleanup_nested(server: str) -> None:
    """"""Creating nested files should be cleaned up.""""""
    import io
    import tarfile

    before = set(evolution_worker.STORAGE_PATH.iterdir()) if evolution_worker.STORAGE_PATH.exists() else set()

    buf = io.BytesIO()
    with tarfile.open(fileobj=buf, mode=""w"") as tf:
        info = tarfile.TarInfo(name=""dir1/dir2/file.txt"")
        data = b""nested""
        info.size = len(data)
        tf.addfile(info, io.BytesIO(data))
    buf.seek(0)

    with httpx.Client(base_url=server) as client:
        files = {""tar"": (""nested.tar"", buf.read())}
        r = client.post(""/mutate"", files=files)
        assert r.status_code == 200

    after = set(evolution_worker.STORAGE_PATH.iterdir()) if evolution_worker.STORAGE_PATH.exists() else set()
    assert before == after",tests/test_evolution_worker.py,,1,1.522997951276035e-08,"The method 'test_mutate_cleanup_nested' is a test function that verifies the cleanup of nested files after a mutation operation. Test functions are generally not deleted unless they are redundant or replaced by more comprehensive tests. This function appears to be specific in its purpose, testing the cleanup of nested files, which is a valid and potentially important test case. Therefore, it is likely to be retained."
survived,"def test_bbc_demo_deterministic():
    args = argparse.Namespace(
        data_dir=BBC_DIR,
        iterations=2,
        display_topics=2,
        n_words=3,
        num_levels=3,
        alpha=10.0,
        gamma=1.0,
        eta=0.1,
        seed=0,
    )
    hlda = bbc_demo.run_demo(args)
    assert hlda.root_node.total_nodes == 15
    assert hlda.root_node.customers == 401
    assert hlda.num_documents == 401
",tests/test_bbc_demo.py,,1,1.0467401685178159e-08,"The method `test_bbc_demo_deterministic` is a test function that appears to be part of a testing suite for a hierarchical latent Dirichlet allocation (hLDA) model. It sets up a specific configuration using `argparse.Namespace` and then runs a demo function `bbc_demo.run_demo` with these arguments. The function includes assertions to verify that the model's output matches expected values, which is a common practice in testing to ensure code correctness. Since testing functions are crucial for maintaining code quality and ensuring that changes do not break existing functionality, it is likely that this method will be retained in the codebase."
survived,"    def test_openai_response_format(self) -> None:
        from alpha_factory_v1.demos.cross_industry_alpha_factory import (
            cross_alpha_discovery_stub as stub,
        )

        resp = types.SimpleNamespace(choices=[types.SimpleNamespace(message=types.SimpleNamespace(content=""[]""))])
        openai_mock = types.SimpleNamespace(ChatCompletion=types.SimpleNamespace(create=Mock(return_value=resp)))

        with patch.dict(os.environ, {""OPENAI_API_KEY"": ""x""}):
            with patch.object(stub, ""openai"", openai_mock):
                stub.discover_alpha(num=1, ledger=None, model=""gpt-4o-mini"")

        openai_mock.ChatCompletion.create.assert_called_once()
        kwargs = openai_mock.ChatCompletion.create.call_args.kwargs
        self.assertEqual(kwargs.get(""response_format""), {""type"": ""json_object""})
",tests/test_cross_alpha_discovery.py,TestCrossAlphaDiscoveryStub,1,2.3355930333443423e-09,"The method `test_openai_response_format` is a unit test designed to verify the behavior of a specific function in the codebase. It uses mocking to simulate the behavior of an external API (OpenAI's API in this case) and checks if the function under test calls the API with the expected parameters. Unit tests are crucial for ensuring code reliability and are typically retained in the codebase to prevent regressions. Therefore, this method is likely to be retained as it serves an important purpose in maintaining the integrity of the code."
survived,"def test_aiga_bridge_no_agents(monkeypatch: pytest.MonkeyPatch) -> None:
    """"""Import bridge without agents packages and expect helpful error.""""""
    monkeypatch.delitem(sys.modules, ""openai_agents"", raising=False)
    monkeypatch.delitem(sys.modules, ""agents"", raising=False)

    # Reload backend so the missing SDK shim is installed
    importlib.reload(importlib.import_module(""alpha_factory_v1.backend""))

    # Provide minimal curriculum_env to avoid gymnasium dependency
    env_stub = types.ModuleType(""curriculum_env"")

    class DummyEnv:
        pass

    env_stub.CurriculumEnv = DummyEnv  # type: ignore[attr-defined]
    monkeypatch.setitem(
        sys.modules,
        ""alpha_factory_v1.demos.aiga_meta_evolution.curriculum_env"",
        env_stub,
    )

    with pytest.raises(ModuleNotFoundError, match=""OpenAI Agents SDK is required""):
        importlib.import_module(""alpha_factory_v1.demos.aiga_meta_evolution.openai_agents_bridge"")",tests/test_aiga_bridge_no_agents.py,,1,6.023574641292144e-08,"The method is a test function that uses monkeypatching to simulate the absence of certain modules and checks if the appropriate error is raised. This is a common practice in testing to ensure that the code behaves correctly when dependencies are missing. The function is useful for maintaining the robustness of the codebase by ensuring that missing dependencies are handled gracefully. Therefore, it is likely to be retained as part of the test suite."
survived,"def test_base_url_env(monkeypatch: pytest.MonkeyPatch) -> None:
    custom = ""https://example.com/gpt2""
    monkeypatch.setenv(""HF_GPT2_BASE_URL"", custom)
    assert dg._base_url() == custom
",tests/test_download_hf_gpt2.py,,1,1.8189616842444243e-09,"The method 'test_base_url_env' is a test function that uses the 'monkeypatch' fixture from pytest to temporarily set an environment variable and then asserts that a function returns the expected value. This is a common pattern in testing to ensure that environment-dependent code behaves correctly. Test functions like this are generally not deleted unless they are redundant or replaced by a more comprehensive test. Therefore, it is likely to survive."
survived,"        def set_tracer_provider(self, _provider: Any) -> None:
            pass
",tests/test_metrics.py,DummyTrace,0,0.9999999936511998,"The method `set_tracer_provider` is defined but does not perform any operations as it only contains a `pass` statement. This suggests that it might be a placeholder for future implementation or a method that is intentionally left empty for subclassing purposes. However, without any additional context or usage, it is likely to be considered dead code and could be removed in future iterations unless it is part of an interface or abstract class where subclasses are expected to override it. Therefore, the method is more likely to be deleted."
survived,"    def fake_apply(diff_text, repo_path):
        applied.append(diff_text)
        diff_utils.apply_diff(diff_text, repo_dir=repo_path)
",tests/test_self_healer_pipeline.py,,0,0.9999999943972036,"The method 'fake_apply' is likely to be deleted because it seems to be a mock or test function, indicated by the prefix 'fake'. Such functions are often used temporarily during development or testing to simulate behavior without performing actual operations. Once the real implementation is complete or the testing phase is over, these mock functions are typically removed to clean up the codebase."
survived,"def build_regex_guardrails(
    config: GuardrailConfig,
) -> List[Callable[[str], Awaitable[None]]]:
    """"""Build async guardrail callables from a configuration.""""""

    guards: List[Callable[[str], Awaitable[None]]] = []
    for rule in config.rules:
        pattern = re.compile(rule.pattern)

        async def guard(value: str, *, _p=pattern, _r=rule) -> None:
            if _p.search(value):
                raise ValueError(f""Guardrail '{_r.name}' triggered"")

        guards.append(guard)
    return guards
",src/meta_agent/generators/guardrail_generator.py,,1,3.581747929000289e-10,"The method 'build_regex_guardrails' is likely to survive because it is a utility function that generates a list of asynchronous guardrail functions based on a given configuration. This kind of functionality is useful in many applications where input validation or filtering is required. The method is well-structured, uses asynchronous programming which is increasingly common, and provides a clear purpose by raising exceptions when certain patterns are matched. These characteristics make it a valuable and reusable piece of code."
survived,"async def test_output_guardrail_exception_propagates():
    adapter = MockAdapter()
    router = GuardrailModelRouter({""a"": adapter}, default_model=""a"")

    async def bad_guard(_output: str):
        raise RuntimeError(""bad"")

    router.add_output_guardrail(bad_guard)

    with pytest.raises(RuntimeError):
        await router.invoke(""x"")",tests/test_guardrail_router.py,,1,2.0611536181902033e-09,"The method `test_output_guardrail_exception_propagates` is a test function designed to ensure that exceptions raised by an output guardrail are properly propagated. This is a valid and useful test case for verifying the robustness and error handling of the `GuardrailModelRouter` class. It is important to maintain such tests to ensure that the system behaves correctly under error conditions. Therefore, the method is likely to be retained in the codebase."
survived,"    def __init__(self):
        self.allowed_tags = [
            ""p"",""br"",""strong"",""em"",""h1"",""h2"",""h3"",""h4"",""h5"",""h6"",
            ""ul"",""ol"",""li"",""blockquote"",""code"",""pre"",
            ""a"",""img"",""hr"",""table"",""thead"",""tbody"",""tr"",""th"",""td""
        ]
        self.allowed_attributes = {
            ""a"": [""href"", ""title""],
            ""img"": [""src"", ""alt"", ""title"", ""width"", ""height""],
        }
        self.allowed_protocols = [""http"", ""https"", ""mailto""]
        self.md = Markdown(extras=[""fenced-code-blocks""])
",app/utils/markdown_renderer.py,SafeMarkdownRenderer,1,7.73442280641062e-08,"The method is a constructor (__init__) for a class, which initializes important attributes such as allowed_tags, allowed_attributes, and allowed_protocols. These attributes are likely essential for the functionality of the class, especially if it deals with parsing or rendering markdown or HTML content. The presence of these attributes suggests that they are used to define what tags, attributes, and protocols are permissible, which is a common requirement in web development to ensure security and proper rendering. Therefore, it is unlikely that this method will be deleted as it sets up the foundational configuration for the class."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/machine/x/python/q1.py,_Group,1,1.1253518384332553e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes. The code snippet shows a typical pattern where an attribute is initialized and a list is created. This is a common and necessary practice in class design, so it is unlikely to be deleted."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/machine/x/python/q3.py,_Group,1,9.931195248674785e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes. The code snippet shows a typical pattern where an attribute is initialized and a list is created. This is a common and necessary practice in class design, so it is unlikely to be deleted."
survived,"def _sum(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""sum() expects list or group"")
    s = 0.0
    for it in v:
        if it is None:
            continue
        if isinstance(it, (int, float)):
            s += float(it)
        else:
            raise Exception(""sum() expects numbers"")
    return s
",tests/machine/x/python/q3.py,,1,5.60279640614594e-09,"The method '_sum' is a utility function that calculates the sum of a list of numbers. It includes error handling for non-list inputs and non-numeric elements within the list. This function is likely to survive because it provides a basic yet essential functionality that can be reused in various contexts. Additionally, it handles edge cases such as None values and non-numeric types, making it robust and reliable for summing operations."
survived,"def test_service_worker_checksum() -> None:
    browser_dir = Path(__file__).resolve().parents[1]
    text = (browser_dir / ""manual_build.py"").read_text()
    assert 'sha384(dist_dir / ""service-worker.js"")' in text",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_manual_build_size_limit.py,,1,7.194132978569833e-09,"The method `test_service_worker_checksum` is a test function that checks if a specific string is present in the text of a file. This is a typical use case in testing to ensure that certain code or configuration is present, which is crucial for maintaining code integrity and functionality. Test functions are generally not deleted unless they are redundant or replaced by more comprehensive tests. Since this function serves a clear purpose in verifying the presence of a checksum operation, it is likely to be retained."
survived,"        def act(self, _obs):
            return 0
",tests/test_world_model_demo.py,DummyLearner,0,0.999998790133938,"The method 'act' is very simplistic and returns a constant value of 0 regardless of the input '_obs'. This lack of functionality suggests that it might not be useful in a real-world application or in a more complex system where dynamic behavior is expected. Therefore, it is likely to be deleted or replaced with a more sophisticated implementation."
survived,"        def __init__(self, reward: float) -> None:
            self.reward = reward
",tests/test_world_model_demo.py,DummyEnv,1,1.0467401685178159e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming in Python. Constructors are essential for initializing new objects with specific attributes, in this case, setting the 'reward' attribute. There is no indication that this constructor is redundant or unnecessary, so it is likely to be retained."
survived,"    def __init__(self, steps: int = 2, rng: random.Random | None = None) -> None:
        self.steps = steps
        self.rng = rng or random.Random()
        self._op = PromptRewrite(rng=self.rng)
",src/simulation/mats_ops.py,SelfRewriteOperator,1,4.6911638017642294e-08,"The method is a constructor (__init__) for a class, which is a fundamental part of class instantiation in Python. Constructors are essential for initializing object attributes and setting up the initial state of an object. Therefore, it is highly unlikely that this method would be deleted as it is crucial for the functionality of the class."
survived,"def run() -> None:
    n = 5
    total = sum(range(n))
    expected = n*(n-1)//2
    assert total == expected",benchmarks/swe_mini/task_005.py,,1,2.1024340680345882e-07,"The method 'run' is a simple function that calculates the sum of the first 'n' natural numbers and checks if it matches the expected formula result. This is a basic demonstration of using assertions to verify the correctness of a calculation. The function is straightforward, has no side effects, and serves as a useful example or test case for educational purposes. Therefore, it is likely to be retained in the codebase for its simplicity and utility in demonstrating basic concepts."
survived,"def run() -> None:
    parts = [""poly"", ""task"", ""15""]
    joined = ""-"".join(parts)
    assert joined.split(""-"")[2] == str(15)",benchmarks/poly_mini/task_015.py,,1,3.653482080241728e-08,"The method 'run' is a simple function that joins a list of strings with a hyphen and then splits the resulting string to assert that the third element is '15'. This is a basic operation that demonstrates string manipulation and is likely used for educational or illustrative purposes. It doesn't have any apparent issues or redundancies that would necessitate its deletion. Therefore, it is likely to be retained in the codebase."
survived,"def run() -> None:
    parts = [""poly"", ""task"", ""4""]
    joined = ""-"".join(parts)
    assert joined.split(""-"")[2] == str(4)",benchmarks/poly_mini/task_004.py,,1,1.2501528648238603e-09,"The method 'run' is a simple function that joins a list of strings with a hyphen and then splits the resulting string to assert that the third element is '4'. This is a basic operation that demonstrates string manipulation and is likely used for educational or illustrative purposes. It doesn't have any apparent issues or redundancies that would necessitate its deletion. Additionally, it could be part of a larger codebase where such operations are relevant. Therefore, it is more likely to survive."
survived,"    async def lineage(_: None = Depends(verify_token)) -> list[LineageNode]:
        """"""Return archive lineage information.""""""
        path = Path(os.getenv(""ARCHIVE_PATH"", ""archive.db""))
        arch = Archive(path)
        nodes: list[LineageNode] = []
        for a in arch.all():
            nodes.append(
                LineageNode(
                    id=a.id,
                    parent=a.meta.get(""parent""),
                    diff=a.meta.get(""diff"") or a.meta.get(""patch""),
                    pass_rate=a.score,
                )
            )
        return nodes
",src/interface/api_server.py,,1,9.736200303530205e-10,"The method 'lineage' is likely to survive because it is a well-defined asynchronous function that retrieves and processes data from an archive. It uses dependency injection to verify a token, which is a common practice for securing endpoints. The function constructs a list of 'LineageNode' objects from the archive data, which suggests it is part of a larger system that deals with lineage or versioning information. The use of environment variables for configuration and the structured return type further indicate that this method is part of a robust and maintainable codebase."
survived,"def test_rewrite_blocks_malicious() -> None:
    op = SelfRewriteOperator(steps=1)
    code = ""import os\nos.system('rm -rf /')""
    assert op(code) == code
",tests/test_safety_filter.py,,1,8.31527990378713e-07,"The method 'test_rewrite_blocks_malicious' is testing a function 'SelfRewriteOperator' with a code snippet that is potentially harmful ('os.system('rm -rf /')'). This test seems to be checking if the operator does not alter the malicious code, which is a valid test case for ensuring that the operator does not inadvertently modify code. However, the presence of such a dangerous command in a test, even if not executed, might raise concerns about safety and best practices. Despite this, the method itself is a valid test and serves a purpose in verifying the behavior of 'SelfRewriteOperator'. Therefore, it is likely to be Survived."
survived,"    def api_key(self, value: Optional[str]) -> None:
        object.__setattr__(self, ""_api_key"", value)
        object.__setattr__(self, ""_headers"", self._compute_headers())
",python/langsmith/client.py,Client,1,4.363462233903899e-09,"The method 'api_key' is a setter method for setting the API key and updating headers accordingly. It uses 'object.__setattr__' to set private attributes, which is a common pattern in Python to ensure immutability or controlled access to attributes. This method is likely part of a class that interacts with an API, and managing API keys and headers is a crucial part of such functionality. Therefore, it is unlikely to be deleted as it serves an essential role in the class's operation."
survived,"def test_run_muzero_demo_invokes_docker(tmp_path: Path) -> None:
    repo_root = Path(__file__).resolve().parents[1]
    src = repo_root / ""alpha_factory_v1""
    dst = tmp_path / ""alpha_factory_v1""
    shutil.copytree(src, dst)

    script = dst / ""demos"" / ""muzero_planning"" / ""run_muzero_demo.sh""
    log_file = tmp_path / ""docker.log""
    bin_dir = tmp_path / ""bin""
    bin_dir.mkdir()
    docker_stub = bin_dir / ""docker""
    docker_stub.write_text(
        f""#!/usr/bin/env bash\necho \""$@\"" >> '{log_file}'\nexit 0\n""
    )
    docker_stub.chmod(0o755)

    with socket.socket() as s:
        s.bind((""localhost"", 0))
        port = s.getsockname()[1]

    env = os.environ.copy()
    env.update({""PATH"": f""{bin_dir}:{env.get('PATH', '')}"", ""HOST_PORT"": str(port)})

    subprocess.run([""bash"", str(script)], check=True, env=env)

    assert log_file.read_text(), ""Docker stub was not invoked""
    assert ""compose"" in log_file.read_text()",tests/test_run_muzero_demo.py,,1,7.194132978569833e-09,"The method is a test function that verifies the invocation of a Docker command through a stub. It sets up a temporary environment, copies necessary files, creates a mock Docker executable, and checks if the Docker command is logged. This is a typical pattern for testing external command invocations in a controlled environment. The method is likely to survive because it is a useful test for ensuring that the Docker command is correctly invoked in the context of the application."
survived,"def test_improve_repo_applies_patch(tmp_path: Path) -> None:
    repo_dir = tmp_path / ""repo""
    repo_dir.mkdir()
    _init_repo(repo_dir)

    patch = """"""--- a/metric.txt\n+++ b/metric.txt\n@@\n-1\n+2\n""""""
    patch_file = tmp_path / ""patch.diff""
    patch_file.write_text(patch)
    log_file = tmp_path / ""log.json""

    delta, clone = self_improver.improve_repo(
        str(repo_dir), str(patch_file), ""metric.txt"", str(log_file), cleanup=False
    )

    assert (clone / ""metric.txt"").read_text().strip() == ""2""
    data = json.loads(log_file.read_text())
    assert isinstance(data[0][""delta""], (int, float))
    assert delta == data[0][""delta""]
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_self_improver.py,,1,3.653482080241728e-08,"The method 'test_improve_repo_applies_patch' is a unit test designed to verify the functionality of the 'improve_repo' method from the 'self_improver' module. It sets up a temporary repository, applies a patch, and checks if the patch was applied correctly by asserting the contents of a file and the log data. This is a typical structure for a test function, and such tests are crucial for ensuring code reliability and correctness. Therefore, it is unlikely to be deleted as it serves an important role in the development process."
survived,"def _init_repo(path: Path) -> git.Repo:
    repo = git.Repo.init(path)
    (path / ""metric.txt"").write_text(""1\n"")
    repo.git.add(""metric.txt"")
    repo.index.commit(""init"")
    return repo
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_self_improver.py,,1,1.0467401685178159e-08,"The method '_init_repo' is a utility function that initializes a Git repository at a given path, creates a file named 'metric.txt', adds it to the repository, and commits it. This is a common operation in software development, especially in scripts that automate repository setup. The method is straightforward, performs a useful task, and is likely to be used in various contexts where automated repository initialization is needed. Therefore, it is unlikely to be deleted unless the project undergoes a significant change in its requirements or structure."
survived,"    def test_main_uses_env_key(self) -> None:
        stub = types.ModuleType(""openai_agents"")

        runtime = MagicMock()

        def _tool(*_a, **_k):
            def _decorator(func):
                return func

            return _decorator

        stub.Agent = object
        stub.AgentRuntime = MagicMock(return_value=runtime)
        stub.Tool = _tool

        with (
            patch.dict(sys.modules, {""openai_agents"": stub}),
            patch.dict(os.environ, {""OPENAI_API_KEY"": ""key""}, clear=False),
            patch(""alpha_factory_v1.backend.adk_bridge.auto_register"") as auto_reg,
            patch(""alpha_factory_v1.backend.adk_bridge.maybe_launch"") as maybe_launch,
        ):
            sys.modules.pop(
                ""alpha_factory_v1.demos.cross_industry_alpha_factory.openai_agents_bridge"",
                None,
            )
            mod = importlib.import_module(""alpha_factory_v1.demos.cross_industry_alpha_factory.openai_agents_bridge"")
            mod.main()

            stub.AgentRuntime.assert_called_once_with(api_key=""key"")
            runtime.register.assert_called_once()
            auto_reg.assert_called_once()
            maybe_launch.assert_called_once()
",tests/test_cross_industry_bridge_runtime.py,TestCrossIndustryBridgeRuntime,1,5.60279640614594e-09,"The method 'test_main_uses_env_key' is a unit test that verifies the behavior of a module when the 'OPENAI_API_KEY' environment variable is set. It uses mocking to simulate the environment and dependencies, ensuring that the 'AgentRuntime' is called with the correct API key and that certain functions are called once. This is a typical pattern for testing code that relies on external dependencies and environment variables. Since testing is a crucial part of software development to ensure code reliability and correctness, this method is likely to be retained in the codebase."
survived,"def rsi(prices: Sequence[float], period: int = 14) -> float:
    """"""Compute the relative strength index (0‒100).""""""

    if period <= 0:
        raise ValueError(""period must be positive"")
    if len(prices) <= period:
        return 0.0

    if np is not None:
        deltas = np.diff(np.asarray(prices, dtype=float))
        gains = np.clip(deltas, 0, None)
        losses = np.clip(-deltas, 0, None)

        avg_gain = float(np.mean(gains[:period]))
        avg_loss = float(np.mean(losses[:period]))

        for g, l in zip(gains[period:], losses[period:]):
            avg_gain = (avg_gain * (period - 1) + float(g)) / period
            avg_loss = (avg_loss * (period - 1) + float(l)) / period
    else:
        deltas = [prices[i + 1] - prices[i] for i in range(len(prices) - 1)]
        gains = [max(d, 0.0) for d in deltas]
        losses = [max(-d, 0.0) for d in deltas]

        avg_gain = sum(gains[:period]) / period
        avg_loss = sum(losses[:period]) / period

        for g, l in zip(gains[period:], losses[period:]):
            avg_gain = (avg_gain * (period - 1) + g) / period
            avg_loss = (avg_loss * (period - 1) + l) / period

    if avg_loss == 0:
        return 100.0
    rs = avg_gain / avg_loss
    return 100.0 - (100.0 / (1 + rs))
",alpha_factory_v1/backend/alpha_model.py,,1,7.194132978569833e-09,"The method implements a well-known financial indicator, the Relative Strength Index (RSI), which is widely used in technical analysis to evaluate the strength or weakness of a stock or market. The code is functional, correctly handles edge cases (like zero losses), and provides a fallback for when numpy is not available. Given its utility and correctness, it is likely to be retained."
survived,"    def legal_actions(self) -> List[str]:
        """"""Available trade actions.""""""
        return [""HOLD"", ""BUY"", ""SELL""]
",alpha_factory_v1/backend/environments/market_sim.py,MarketEnv,1,5.211412485172657e-10,"The method 'legal_actions' is a simple and clear implementation that returns a list of available trade actions. It is well-defined, serves a specific purpose, and is likely to be used in contexts where trade actions need to be enumerated. There is no indication of redundancy or obsolescence, and it is a fundamental part of any trading system. Therefore, it is unlikely to be deleted."
survived,"    def sample_next_price(self, price: float) -> float:
        """"""Return the next price using a Gaussian random walk.""""""
        return price + random.gauss(0.0, self.volatility)
",alpha_factory_v1/backend/environments/market_sim.py,MarketEnv,1,1.6052280526088547e-09,"The method 'sample_next_price' is a simple and clear implementation of a Gaussian random walk to predict the next price based on a given volatility. This is a common technique used in financial simulations and modeling. The method is straightforward, uses standard library functions, and is likely to be useful in contexts where price simulation is needed. Therefore, it is likely to be retained in the codebase."
survived,"    async def __aexit__(self, *_exc):  # pragma: no cover - interface default
        return None
",alpha_factory_v1/backend/market_data.py,BaseMarketData,1,3.653482080241728e-08,"The method is an implementation of the asynchronous context manager's exit method, which is a standard part of Python's asynchronous programming interface. The use of 'pragma: no cover' suggests that this method is intentionally left as a default implementation, possibly to be overridden by subclasses. Since it serves a specific purpose in the context of asynchronous context managers, it is unlikely to be deleted unless the entire context management functionality is being refactored or removed, which is uncommon. Therefore, it is more likely to survive."
survived,"    def complete(self, prompt: str) -> str:  # noqa: D401
        return self.resp
",alpha_factory_v1/tests/test_planner_agent.py,DummyModel,0,0.9999974387182097,"The method 'complete' is a simple function that returns a predefined response 'self.resp' regardless of the input 'prompt'. This method lacks functionality and flexibility, as it does not process or utilize the input in any meaningful way. Such methods are often considered redundant or placeholders in code, and unless 'self.resp' is dynamically updated elsewhere in the class, this method is likely to be deleted or refactored to provide more utility."
survived,"    def history(self) -> Iterable[Fill]:
        """"""Iterate over all persisted fills (newest-last).""""""
        if not self._db_path.exists():
            return []
        with self._db_path.open() as fh:
            for line in fh:
                try:
                    yield Fill(**json.loads(line))
                except Exception:
                    continue
",alpha_factory_v1/backend/portfolio.py,Portfolio,1,9.736200303530205e-10,"The method 'history' is likely to survive because it provides a useful functionality of iterating over persisted data, which is a common requirement in applications dealing with data storage and retrieval. The method is designed to handle exceptions gracefully, ensuring that it continues to function even if some lines in the file are not properly formatted. This robustness makes it a valuable part of the codebase."
survived,"    def forward(self, h): return self.v(h), torch.log_softmax(self.p(h), -1)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,Pred,1,4.1399375473943306e-08,"The method 'forward' is a typical implementation in neural network models, especially in PyTorch, where 'forward' defines the forward pass of the model. The method is concise and uses common operations like 'torch.log_softmax', which are standard in defining neural network layers. There is no indication that this method is redundant or incorrect, and it is likely part of a larger model class. Therefore, it is likely to be retained as it serves a specific purpose in the model's functionality."
survived,"    def __init__(self, hidden: int, act_dim: int):
        super().__init__(); self.v = nn.Linear(hidden, 1); self.p = nn.Linear(hidden, act_dim)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,Pred,1,3.3982678079468468e-09,"The method is a constructor for a class, likely a neural network module, initializing two linear layers. This is a common pattern in machine learning models, where layers are defined in the constructor. Such methods are essential for the setup of the class and are unlikely to be deleted unless the entire class is being refactored or removed. Therefore, it is expected to survive."
survived,"    def initial(self, obs):
        h = self.repr(obs)
        v, p = self.pred(h)
        return h, v, p
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,MuZeroTiny,1,5.211412485172657e-10,"The method 'initial' is a simple function that takes an observation, processes it through two other methods 'repr' and 'pred', and returns the results. There is no indication that this method is redundant or unnecessary based on the provided code snippet. It seems to serve a clear purpose in the context of the code, likely related to some form of prediction or representation task. Without additional context suggesting that this method is obsolete or replaced by another, it is reasonable to predict that it will survive."
survived,"        def handle(self, _msg):
            LOG.debug(""[Fallback%d] ← %s"", idx, _msg)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,Fallback,1,3.653482080241728e-08,"The method 'handle' is a simple logging function that logs a message with a specific format. It uses a debug log level, which is common for development and debugging purposes. The method itself is not complex and does not perform any critical operations that would necessitate its removal. Logging is an essential part of software development for tracking and diagnosing issues, and this method serves that purpose. Therefore, it is likely to be retained in the codebase."
survived,"    def _clip(self,v): return max(0, min(self.size-1, v))
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,MiniWorld,1,5.3157849718487075e-08,"The method _clip is a utility function that ensures a value v is within the bounds of 0 and size-1. This is a common operation in programming, especially in contexts like array indexing or graphical operations where values need to be clamped to a certain range. Such utility functions are often useful and reused in various parts of a codebase, making them likely to survive unless the entire codebase is refactored or the method is replaced by a more efficient or standardized library function."
survived,"    def subscribe(cls, topic: str, cb: Callable[[dict], None]):
        with cls._lock:
            cls._subs.setdefault(topic, []).append(cb)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,A2ABus,1,5.211412485172657e-10,"The method 'subscribe' is likely to survive because it provides a fundamental functionality for a publish-subscribe pattern, which is a common design pattern in software development. This method allows for the registration of callback functions to specific topics, enabling event-driven programming. Such methods are essential for systems that rely on asynchronous communication and event handling, making them valuable and unlikely to be removed unless the entire design pattern is being deprecated or replaced."
survived,"    def __init__(self, cash: float = 1_000_000.0) -> None:
        self.cash = cash
        self.positions: Dict[str, float] = {}
",alpha_factory_v1/backend/broker/broker_sim.py,SimulatedBroker,1,1.1861120010657661e-08,"The method is a constructor for a class, initializing the 'cash' attribute with a default value and setting up an empty dictionary for 'positions'. This is a standard and necessary part of class design in Python, especially for financial or trading applications where initial cash and positions need to be tracked. Therefore, it is unlikely to be deleted as it serves a fundamental purpose in the class."
survived,"def parse_args() -> argparse.Namespace:
    ap = argparse.ArgumentParser(description=""Alpha-Factory Edge Runner"")
    ap.add_argument(
        ""--agents"",
        help=""Comma separated list of agents to enable"",
    )
    ap.add_argument(
        ""--port"",
        type=int,
        default=8000,
        help=""REST API port (default: 8000)"",
    )
    ap.add_argument(
        ""--metrics-port"",
        type=int,
        help=""Prometheus metrics port"",
    )
    ap.add_argument(
        ""--a2a-port"",
        type=int,
        help=""gRPC A2A port"",
    )
    return ap.parse_args()
",alpha_factory_v1/edge_runner.py,,1,1.6052280526088547e-09,"The method `parse_args` is a standard way to handle command-line arguments in Python using the `argparse` module. It is well-structured, providing clear options for users to specify different ports and agents. This method is essential for configuring the application from the command line, which is a common requirement for many applications. There is no indication that this method is obsolete or redundant, and it follows best practices for argument parsing. Therefore, it is likely to be retained in the codebase."
survived,"def main() -> None:
    args = parse_args()

    cli = [""--dev"", f""--port"", str(args.port)]
    if args.metrics_port:
        cli += [""--metrics-port"", str(args.metrics_port)]
    if args.a2a_port:
        cli += [""--a2a-port"", str(args.a2a_port)]
    if args.agents:
        cli += [""--enabled"", args.agents]

    ns = af_run.parse_args(cli)
    af_run.apply_env(ns)

    os.environ.setdefault(""PGHOST"", ""sqlite"")

    af_run.run()
",alpha_factory_v1/edge_runner.py,,1,7.582560422162384e-10,"The method 'main' is likely to survive because it contains a structured and purposeful sequence of operations that are typical in command-line interface (CLI) applications. It parses arguments, constructs a CLI command, sets environment variables, and executes a run command. These operations suggest that the method is functional and integral to the application's operation, making it unlikely to be removed unless there is a significant refactor or change in the application's architecture."
survived,"    def test_version_flag(self):
        args = self._parse([""--version""])
        self.assertTrue(args.version)
",alpha_factory_v1/tests/test_edge_runner.py,EdgeRunnerParseTest,1,7.582560422162384e-10,"The method `test_version_flag` is a unit test that checks if the `--version` flag is correctly parsed and set in the arguments. This is a common and necessary test to ensure that command-line interfaces behave as expected when users request version information. Such tests are crucial for maintaining software reliability and are unlikely to be removed unless the feature itself is deprecated, which is not indicated here."
survived,"def _positive_int(name: str) -> callable:
    """"""Return a parser for positive integers.""""""

    def parser(value: str) -> int:
        try:
            iv = int(value)
        except ValueError as exc:  # pragma: no cover - argparse handles message
            raise argparse.ArgumentTypeError(f""{name} must be an integer"") from exc
        if iv <= 0:
            raise argparse.ArgumentTypeError(f""{name} must be > 0"")
        return iv

    return parser
",alpha_factory_v1/edge_runner.py,,1,5.905303995456778e-10,"The method _positive_int is a utility function designed to create a parser for positive integers, which is a common requirement in many applications, especially those involving command-line argument parsing. The function is well-structured, handles exceptions, and provides clear error messages, making it robust and user-friendly. Such utility functions are often reused across different projects or modules, indicating their usefulness and likelihood of being retained in the codebase."
survived,"def _attempt() -> bool:
    logs: list[str] = []
    try:
        with sync_playwright() as p:
            browser = p.chromium.launch()
            context = browser.new_context()
            page = context.new_page()
            page.on(""console"", lambda msg: logs.append(f""[{msg.type}] {msg.text}""))
            page.goto(URL)
            page.wait_for_function(""navigator.serviceWorker.ready"", timeout=TIMEOUT_MS)
            page.wait_for_selector(""body"", timeout=TIMEOUT_MS)
            context.set_offline(True)
            page.reload()
            page.wait_for_selector(""body"", timeout=TIMEOUT_MS)
            page.wait_for_selector(""#tree-container .node"", timeout=TIMEOUT_MS)
            browser.close()
        return True
    except PlaywrightError as exc:
        print(f""Playwright error: {exc}"", file=sys.stderr)
    except Exception as exc:  # noqa: BLE001
        print(f""Offline check failed: {exc}"", file=sys.stderr)

    _print_console(logs)
    return False
",scripts/verify_insight_offline.py,,1,8.152020648014727e-09,"The method '_attempt' is likely to survive because it is a well-structured function that performs a specific task of checking offline capabilities using Playwright. It handles exceptions gracefully, logs console messages, and returns a boolean indicating success or failure. This functionality is useful for testing web applications' offline capabilities, which is a common requirement in modern web development."
survived,"def join_domain(domain, admin_user, ou):
    cmd = [""realm"", ""join"", ""-v"", f""--user={admin_user}""]
    if ou:
        cmd.append(f""--computer-ou={ou}"")
    cmd.append(domain)
    return run_cmd("" "".join(cmd))
",adconnection_gui.py,,1,2.0611536181902033e-09,"The method 'join_domain' is a utility function that constructs a command to join a domain using the 'realm' command-line tool. It takes a domain, an admin user, and an optional organizational unit (OU) as parameters. The method is straightforward, performs a specific task, and is likely useful in contexts where domain joining is required. There is no indication that this method is obsolete or redundant, and it serves a clear purpose in system administration tasks. Therefore, it is likely to be retained."
survived,"def main():
    parser = argparse.ArgumentParser(description=""Join Linux host to Active Directory"")
    parser.add_argument(""domain"", nargs=""?"", help=""Domain to join"")
    parser.add_argument(""-u"", ""--user"", required=False, help=""Admin user for the join"")
    parser.add_argument(""-o"", ""--ou"", help=""OU for computer object"")
    parser.add_argument(""--discover"", action=""store_true"", help=""Only discover domain"")
    args = parser.parse_args()

    if args.discover:
        domain = discover_domain()
        if domain:
            print(domain)
        else:
            print(""No domain discovered"")
        return

    domain = args.domain or discover_domain()
    if not domain:
        print(""Domain could not be discovered. Please specify the domain as argument."")
        sys.exit(1)

    admin_user = args.user or input(""Admin user: "")
    join_domain(domain, admin_user, args.ou)
    print(f""Successfully joined {domain}"")
",adconnection_app.py,,1,4.944450477491054e-09,"The method 'main()' is a typical command-line interface (CLI) entry point for a script that joins a Linux host to an Active Directory domain. It uses argparse to handle command-line arguments, which is a common and effective way to manage user inputs in Python scripts. The method includes functionality for discovering a domain, handling user input for an admin user, and joining the domain, which are all essential tasks for the script's purpose. There is no indication that this method is obsolete or redundant, and it appears to be well-structured for its intended use. Therefore, it is likely to be retained in the codebase."
survived,"def run_cmd(cmd):
    """"""Run a shell command and return output and exit code.""""""
    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
    return result.stdout.strip(), result.returncode
",adconnection_gui.py,,1,1.725782769012759e-08,"The method 'run_cmd' is a utility function that executes a shell command and returns its output and exit code. This is a common requirement in many applications that need to interact with the system shell, automate tasks, or execute external programs. The function is well-defined, using the subprocess module, which is the recommended way to spawn new processes and connect to their input/output/error pipes. It captures both the standard output and the exit code, which are often needed to handle the results of the command execution effectively. Given its utility and correct implementation, it is likely to be retained in the codebase."
survived,"    def test_summary_api_connection_error(self) -> None:
        import openai

        with patch.dict(os.environ, {""OPENAI_API_KEY"": ""sk-test""}):
            with patch(""openai.OpenAI"") as mock_client:
                mock_client.return_value.chat.completions.create.side_effect = openai.APIConnectionError(""fail"")
                text = summarise_with_agent(
                    0.5,
                    agents=2,
                    rounds=10,
                    delta=0.9,
                    stake=1.0,
                )
        self.assertIn(""offline summary"", text)
        self.assertIn(""connection"", text)
",tests/test_governance_sim.py,TestGovernanceSim,1,1.6052280526088547e-09,"The method `test_summary_api_connection_error` is a unit test designed to verify the behavior of a function when an API connection error occurs. It uses mocking to simulate the error and checks if the appropriate error handling is in place. Such tests are crucial for ensuring robustness and reliability of the code, especially when dealing with external APIs. Therefore, it is likely to be retained as part of the test suite to maintain code quality and handle potential real-world issues effectively."
survived,"def _free_port() -> int:
    """"""Return an unused localhost port.""""""
    with socket.socket() as s:
        s.bind((""127.0.0.1"", 0))
        return int(s.getsockname()[1])
",tests/test_aiga_service_mixtral.py,,1,8.152020648014727e-09,"The method _free_port is a utility function that provides a useful feature: finding an unused port on localhost. This is a common requirement in network programming, especially for testing purposes where a free port is needed to avoid conflicts. The implementation is straightforward and leverages the operating system's ability to allocate a free port when binding to port 0. This method is likely to be retained because it serves a practical purpose and is implemented efficiently."
survived,"    def register(self, *_a, **_kw):
        pass
",tests/test_openai_bridge_integration.py,_AgentRuntime,1,0.002182715952956951,"The method 'register' is defined but does not perform any operations, as it only contains a 'pass' statement. This suggests that it is a placeholder or a stub for future implementation. If the method is part of a larger class or module that is actively being developed, it might be retained for future use. However, if there is no plan to implement functionality in this method, it could be considered for deletion to clean up the codebase. Without additional context, it's difficult to determine the exact intention, but generally, such methods are often placeholders and may survive if they are part of a planned feature."
survived,"    async def _stop() -> None:
        task = getattr(app_f.state, ""task"", None)
        if task:
            task.cancel()
            with contextlib.suppress(asyncio.CancelledError):
                await task
            app_f.state.task = None
        app_f.state.orchestrator = None
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/api_server.py,,1,1.6052280526088547e-09,"The method `_stop` is an asynchronous function designed to cancel a task if it exists and handle the cancellation gracefully. This is a common pattern in asynchronous programming to ensure that resources are cleaned up properly. The method is likely part of a larger system where tasks need to be managed and stopped when no longer needed. Since it performs a crucial role in managing the lifecycle of tasks, it is unlikely to be deleted unless the entire task management approach is refactored or replaced. Therefore, the method will likely survive."
survived,"    async def healthz() -> str:
        """"""Simple liveness probe.""""""

        return ""ok""
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/api_server.py,,1,2.3355930333443423e-09,"The method 'healthz' is a simple liveness probe that returns a string 'ok'. Such methods are commonly used in web services to check if the service is running and healthy. They are lightweight and serve a crucial role in monitoring and maintaining the health of applications. Given its utility and simplicity, it is unlikely to be deleted unless the entire service architecture changes or a more comprehensive health check mechanism is implemented. Therefore, the method will likely survive."
survived,"def run_jax_simulation(model, importer, ts, atol, rtol):
    p = jnp.array([importer.sbml.getParameter(pid).getValue() for pid in model.parameter_ids])
    ts_jnp = jnp.asarray(ts, dtype=float)
    zeros = jnp.zeros_like(ts_jnp)
    solver = diffrax.Kvaerno5()
    controller = diffrax.PIDController(rtol=rtol / 1e4, atol=atol / 1e4)
    x, stats = model.simulate_condition(
        p,
        ts_jnp,
        jnp.array([]),
        zeros,
        jnp.zeros_like(ts_jnp, dtype=int),
        jnp.zeros_like(ts_jnp, dtype=int),
        jnp.zeros((ts_jnp.shape[0], 0)),
        jnp.zeros((ts_jnp.shape[0], 0)),
        solver,
        controller,
        diffrax.DirectAdjoint(),
        diffrax.steady_state_event(),
        2 ** 8,
        ret=amici.jax.ReturnValue.x,
    )
    tcl = model._tcl(x[0], p)
    y = jax.vmap(lambda t, xs: model._y(t, xs, p, tcl, jnp.zeros(len(model.observable_ids))))(
        ts_jnp, stats[""x""]
    )
    w = jax.vmap(lambda t, xs: model._w(t, xs, p, tcl))(ts_jnp, stats[""x""])

    class RData(dict):
        __getattr__ = dict.__getitem__

    return RData(
        ts=np.asarray(ts_jnp).copy(),
        y=np.asarray(y).copy(),
        w=np.asarray(w).copy(),
        status=amici.AMICI_SUCCESS,
    )
",tests/testSBMLSuiteJax.py,,1,2.998960815863541e-09,"The method 'run_jax_simulation' is a specialized function that integrates JAX with the AMICI library to perform simulations using differential equation solvers. It is likely to be used in scientific computing or research contexts where such simulations are necessary. The method is well-structured, uses modern libraries, and provides a clear output format, making it useful for its intended purpose. There is no indication that it is obsolete or redundant, so it is likely to be retained."
survived,"def test_oai_and_adk(monkeypatch: pytest.MonkeyPatch, tmp_path: Path) -> None:
    settings = config.Settings(openai_api_key=""k"")
    settings.ledger_path = str(tmp_path / ""ledger.db"")
    bus = messaging.A2ABus(settings)
    ledger = insight_logging.Ledger(settings.ledger_path)

    import openai.agents as oa_agents  # type: ignore
    import google_adk

    called: dict[str, str] = {}

    async def fake_run(self, prompt: str) -> str:  # pragma: no cover - async stub
        called[""run""] = prompt
        return ""ok""

    monkeypatch.patch.object(oa_agents.AgentContext, ""run"", fake_run)

    class DummyClient:
        def generate(self, prompt: str) -> str:
            called[""adk""] = prompt
            return ""ok""

    monkeypatch.setattr(google_adk, ""Client"", DummyClient)

    strat = StrategyAgent(bus, ledger)
    summariser = ADKSummariserAgent(bus, ledger)

    summariser._records.append(""hello"")
    env = messaging.Envelope(""a"", ""b"", {""research"": ""foo""}, 0.0)

    async def _run() -> None:
        await strat.handle(env)
        await summariser.run_cycle()

    asyncio.run(_run())

    assert called.get(""run"") == ""foo""
    assert called.get(""adk"") == ""hello""",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_openai_adk_integration.py,,1,2.699578619062706e-07,"The method is a test function that uses the pytest framework to test the integration of OpenAI and Google ADK components. It uses monkeypatching to replace certain methods with dummy implementations for testing purposes. This is a common practice in testing to isolate the unit under test and ensure that the test is not dependent on external systems. The function is well-structured and serves a clear purpose in the testing suite, making it unlikely to be deleted unless the functionality it tests is removed or significantly altered."
survived,"        def generate(self, prompt: str) -> str:
            called[""adk""] = prompt
            return ""ok""
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_openai_adk_integration.py,DummyClient,1,1.0467401685178159e-08,"The method 'generate' is a simple function that takes a string input 'prompt', assigns it to a dictionary key 'adk', and returns the string 'ok'. This method is straightforward and functional, serving a clear purpose of logging the prompt and providing a consistent return value. There is no indication of redundancy, inefficiency, or lack of utility that would necessitate its deletion. Therefore, it is likely to be retained in the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/q1.py,Auto3,1,4.6911638017642294e-08,"The method is a simple implementation of the __getitem__ special method, which allows an object to use the bracket notation (obj[key]) to access its attributes. This is a common and useful pattern in Python, especially for classes that need to provide dictionary-like access to their attributes. It is likely to be retained as it provides a clear and concise way to access object attributes using keys, enhancing the usability of the class."
survived,"        def fake_find_spec(name: str):
            if name in {""pytest"", ""prometheus_client""}:
                return object()
            return None
",tests/test_preflight_optional_missing.py,TestPreflightOptionalMissing,1,3.850741907939403e-09,"The method `fake_find_spec` is a simple utility function that checks if a given module name is either 'pytest' or 'prometheus_client'. If it is, the function returns a generic object; otherwise, it returns None. This kind of function can be useful in testing scenarios where you want to mock or simulate the behavior of module loading without actually loading the modules. Since it serves a specific purpose in testing or mocking environments, it is likely to be retained as long as there is a need for such functionality. Therefore, the method will likely survive."
survived,"def generate_corpus(n_topics, vocab_size, doc_len, n_docs, alpha=0.5, seed=0):
    rng = np.random.default_rng(seed)
    width = vocab_size // n_topics

    word_dists = np.zeros((n_topics, vocab_size))
    for k in range(n_topics):
        start = k * width
        word_dists[k, start:start + width] = 1.0 / width

    vocab = [f""w{i}"" for i in range(vocab_size)]
    corpus = []
    for _ in range(n_docs):
        theta = rng.dirichlet([alpha] * n_topics)
        doc = []
        for _ in range(doc_len):
            k = rng.choice(n_topics, p=theta)
            w = rng.choice(vocab_size, p=word_dists[k])
            doc.append(w)
        corpus.append(doc)
    return corpus, vocab
",tests/test_synthetic_hlda.py,,1,9.237449576640118e-09,"The method 'generate_corpus' is a utility function that generates a synthetic corpus of documents based on specified parameters. It is useful for testing and simulating scenarios in natural language processing and machine learning tasks. The method is well-defined, uses standard libraries, and has a clear purpose. There is no indication that it is obsolete or redundant, and it serves a practical purpose in generating data for experiments. Therefore, it is likely to be retained."
survived,"    def test_mats_bridge_compiles(self):
        """"""Ensure the MATS demo bridge compiles.""""""
        path = Path('alpha_factory_v1/demos/meta_agentic_tree_search_v0/openai_agents_bridge.py')
        py_compile.compile(path, doraise=True)
",tests/test_openai_bridge.py,TestOpenAIBridge,1,2.646573631904765e-09,"The method 'test_mats_bridge_compiles' is a unit test designed to ensure that a specific Python script compiles without errors. This is a basic but important test to verify that the code is syntactically correct and can be executed. Such tests are typically part of a larger suite of tests to ensure code quality and reliability. Since it serves a clear purpose in the testing process, it is likely to be retained in the codebase."
survived,"    def test_bridge_run_search_helper(self) -> None:
        import asyncio
        from alpha_factory_v1.demos.meta_agentic_tree_search_v0 import openai_agents_bridge as bridge

        if bridge.has_oai:  # pragma: no cover - only run offline path
            self.skipTest(""openai-agents installed"")

        result = asyncio.run(bridge.run_search(episodes=1, target=2))
        self.assertIn(""completed"", result)
",tests/test_meta_agentic_tree_search_demo.py,TestMetaAgenticTreeSearchDemo,1,5.3157849718487075e-08,"The method `test_bridge_run_search_helper` is a unit test designed to test the functionality of the `run_search` method from the `openai_agents_bridge` module. It uses asyncio to run the search and checks if the result contains the word 'completed'. The test is skipped if the `openai-agents` package is installed, indicating that it is meant to test an offline path. This method is likely to survive because it is a test case that ensures the functionality of a specific part of the codebase, which is crucial for maintaining code quality and reliability."
survived,"def test_request_patch_no_api_key(monkeypatch: pytest.MonkeyPatch) -> None:
    diff = ""--- a/y\n+++ b/y\n@@\n-old\n+new\n""
    monkeypatch.setenv(""USE_LOCAL_LLM"", ""false"")
    monkeypatch.setenv(""OPENAI_API_KEY"", """")
    client = _reload_client(monkeypatch, diff)
    out = client.request_patch([{""role"": ""user"", ""content"": ""fix""}])
    assert out == diff",tests/test_llm_client_offline.py,,1,1.3440409770490404e-08,"The method 'test_request_patch_no_api_key' is a test function that uses the 'monkeypatch' fixture from pytest to modify the environment variables temporarily for the test. It checks the behavior of the 'request_patch' method when no API key is provided. This is a valid and useful test case to ensure that the system behaves correctly under these conditions. Test functions like this are crucial for maintaining code quality and ensuring that edge cases are handled properly. Therefore, it is unlikely to be deleted as it serves an important purpose in the test suite."
survived,"def _asset_paths() -> list[str]:
    fetch = repo_root / 'scripts' / 'fetch_assets.py'
    tree = ast.parse(fetch.read_text())
    assets = {}
    for node in tree.body:
        if isinstance(node, ast.Assign):
            for t in node.targets:
                if getattr(t, 'id', None) == 'ASSETS':
                    assets = ast.literal_eval(node.value)
                    break
    return list(assets)
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/manual_build.py,,1,3.3982678079468468e-09,"The method `_asset_paths` is a utility function that parses a Python script to extract a list of asset paths. It uses the `ast` module to parse the script and extract the value of a variable named `ASSETS`. This method is likely to be useful in scenarios where dynamic asset management is required, such as in build systems or deployment scripts. The method is specific and serves a clear purpose, which suggests it is not redundant or obsolete. Therefore, it is likely to be retained in the codebase."
survived,"def main() -> None:
    print_disclaimer()
    banner(""Alpha-Factory Setup Wizard"", ""YELLOW"")
    ok = True
    ok &= check_python()
    ok &= check_cmd(""git"")
    ok &= check_cmd(""docker"")
    ok &= check_node()

    if not ok:
        banner(""Some dependencies are missing"", ""RED"")
    else:
        banner(""Environment looks good"", ""GREEN"")

    repo_root = Path(__file__).resolve().parents[1]
    while True:
        print()
        print(""Select an option:"")
        print(""1) Run check_env.py --auto-install"")
        print(""2) Run ./codex/setup.sh"")
        print(""3) Start Insight demo with ./quickstart.sh"")
        print(""4) Start Insight demo in Docker (docker compose up)"")
        print(""5) Exit"")
        choice = input(""Enter choice: "").strip()
        if choice == ""1"":
            run([sys.executable, str(repo_root / ""check_env.py""), ""--auto-install""])
        elif choice == ""2"":
            run([str(repo_root / ""codex"" / ""setup.sh"")])
        elif choice == ""3"":
            run([str(repo_root / ""quickstart.sh"")])
        elif choice == ""4"":
            run([""docker"", ""compose"", ""up""])
        elif choice == ""5"":
            break
        else:
            print(""Invalid choice"")
",scripts/setup_wizard.py,,1,3.2241866333029355e-08,"The method 'main' is a comprehensive setup wizard for an application, providing essential checks and options for the user to configure their environment. It includes checks for necessary dependencies and offers multiple setup options, which are crucial for user experience and ensuring the application runs smoothly. Such utility functions are typically retained as they are integral to the initial setup process of software."
survived,"def test_simulator_init_fast(tmp_path: Path) -> None:
    js_out = tmp_path / ""sim.js""
    subprocess.run([
        ""tsc"",
        ""--target"",
        ""es2020"",
        ""--module"",
        ""es2020"",
        SIM_TS,
        ""--outFile"",
        js_out,
    ], check=True)

    script = tmp_path / ""run.mjs""
    script.write_text(
        f""import {{ Simulator }} from '{js_out.resolve().as_posix()}';\n""
        ""const start = performance.now();\n""
        ""const it = Simulator.run({popSize:1,generations:1});\n""
        ""await it.next();\n""
        ""console.log(performance.now()-start);\n"",
        encoding=""utf-8"",
    )
    res = subprocess.run([""node"", script], capture_output=True, text=True, check=True)
    elapsed = float(res.stdout.strip())
    assert elapsed < 70",tests/test_simulator_init.py,,1,1.1861120010657661e-08,"The method 'test_simulator_init_fast' is a test function that checks the performance of a simulator initialization. It compiles TypeScript code to JavaScript, runs a script using Node.js, and asserts that the execution time is below a certain threshold. This type of test is useful for ensuring performance benchmarks are met, which is a common requirement in software development. Therefore, it is likely to be maintained as part of the test suite to ensure the simulator's performance remains optimal."
survived,"        def __init__(self, *_a: object, **_k: object) -> None:
            pass
",tests/test_agent_manager_consumer.py,DummyBus,1,0.0011695103433855766,"The method is a constructor that takes any number of positional and keyword arguments but does nothing with them. This is typically used as a placeholder or a base class constructor that is meant to be overridden by subclasses. Since it doesn't perform any operations, it might be considered unnecessary in its current form. However, if it's part of a larger framework or library where subclasses are expected to override it, it might be retained for structural purposes. Without additional context, it's difficult to determine its exact purpose, but generally, such methods are often retained for future extensibility."
survived,"    def test_innovation_gain_positive(self) -> None:
        gain = forecast._innovation_gain(pop_size=2, generations=1)
        self.assertGreater(gain, 0.0)
        self.assertLess(gain, 0.1)",tests/test_forecast_functions.py,TestForecastFunctions,1,4.0586521248284276e-10,"The method `test_innovation_gain_positive` is a unit test that checks the behavior of the `_innovation_gain` function from the `forecast` module. It verifies that the gain is positive and less than 0.1 when called with specific parameters. This kind of test is crucial for ensuring the correctness and reliability of the function it tests. Since testing is a fundamental part of software development to maintain code quality, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly changed. Therefore, the method will likely survive."
survived,"            def __init__(self) -> None:
                self.gen = 2
                self.best_fitness = 0.5
",tests/test_aiga_evolver_agent_logic.py,TestEvolverAgentLogic.Dummy,1,6.825604231969389e-08,"The method is a constructor for a class, initializing two attributes: 'gen' and 'best_fitness'. Constructors are essential for setting up initial states of objects in object-oriented programming. Without this method, instances of the class would not have these attributes initialized, which could lead to errors when the attributes are accessed. Therefore, it is unlikely to be deleted."
survived,"def agents_status() -> None:
    """"""List registered agents.""""""
    orch = orchestrator.Orchestrator()
    for agent in orch.agents:
        click.echo(agent.__class__.__name__)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/cli.py,,1,1.6052280526088547e-09,"The method `agents_status` is a simple utility function that lists registered agents by iterating over them and printing their class names. It is a straightforward and useful function for debugging or monitoring purposes, especially in systems where understanding the current state of agents is important. Since it provides a clear and direct functionality without any apparent issues or redundancies, it is likely to be retained in the codebase."
survived,"def main() -> None:
    parser = argparse.ArgumentParser(description=""Remove outdated LMDB records"")
    parser.add_argument(""path"", type=Path, help=""Path to LMDB directory"")
    parser.add_argument(
        ""keep"",
        help=""Retention period, e.g. 14d or 24h. Use 'all' to delete every record"",
    )
    args = parser.parse_args()

    rotate_lmdb(args.path, args.keep)
",scripts/rotate_lmdb.py,,1,4.599055376537186e-10,"The method 'main' is a typical entry point for a script that uses command-line arguments to perform a specific task, in this case, removing outdated LMDB records. It uses the argparse library to handle command-line arguments, which is a common and recommended practice in Python for scripts that require user input. The method is well-structured and serves a clear purpose, making it unlikely to be deleted unless the entire script is deprecated or replaced by a different approach. Therefore, it is likely to survive."
survived,"    def fake_import(name, globals=None, locals=None, fromlist=(), level=0):
        if name == ""gradio"":
            raise ModuleNotFoundError(name)
        return orig_import(name, globals, locals, fromlist, level)
",tests/test_agent_muzero_entrypoint.py,,0,0.9999999677581336,"The method 'fake_import' is a custom implementation of the import mechanism, specifically designed to raise a ModuleNotFoundError when attempting to import the 'gradio' module. This kind of function is typically used for testing purposes, to simulate the absence of a module. Such functions are often temporary and used in specific testing scenarios. Once the testing is complete or if the function is no longer needed, it is likely to be deleted. Therefore, the method is predicted to be deleted."
survived,"def test_agents_status_lists_names() -> None:
    with patch.object(cli.orchestrator, ""Orchestrator"") as orch_cls:
        orch = orch_cls.return_value
        orch.agents = [type(""A"", (), {})()]
        orch.agents[0].__class__.__name__ = ""AgentX""
        result = CliRunner().invoke(cli.main, [""agents-status""])
        assert ""AgentX"" in result.output
",tests/test_cli.py,,1,5.60279640614594e-09,"The method `test_agents_status_lists_names` is a unit test that checks if the CLI command `agents-status` correctly lists the names of agents. It uses mocking to simulate the behavior of the `Orchestrator` class and its `agents` attribute. The test verifies that the output of the command includes the name of the agent, ""AgentX"". This is a typical and necessary test to ensure that the CLI command functions as expected, especially in a system where agent management is crucial. Therefore, it is likely to be retained as part of the test suite."
survived,"def make_function(code: str) -> str:
    try:
        import_stmts = []
        all_other_stmts = []
        astree = ast.parse(code)
        for stmt in astree.body:
            if isinstance(stmt, (ast.Import, ast.ImportFrom)):
                import_stmts.append(stmt)
            else:
                all_other_stmts.append(stmt)

        function_ast = ast.FunctionDef(
            name=""wrapped_function"",
            args=ast.arguments(
                posonlyargs=[], args=[], kwonlyargs=[], kw_defaults=[], defaults=[]
            ),
            body=all_other_stmts,
            decorator_list=[],
            lineno=-1,
        )
        main_code = (
            import_string
            + ""\n""
            + ast.unparse(import_stmts)  # type: ignore
            + ""\n""
            + ast.unparse(function_ast)  # type: ignore
        )
        return main_code
    except Exception as e:
        return code
",scripts/utils/lcb_runner.py,,0,0.9999998555019682,"The method is likely to be deleted because it contains several issues that make it unreliable and potentially unusable. Firstly, the 'import_string' variable is used without being defined, which will cause a NameError. Secondly, the 'ast' module is used without being imported, which will also lead to an error. Additionally, the method attempts to use 'ast.unparse', which is not available in all Python versions, making the code less portable. These issues suggest that the method is not well-implemented and may be removed or significantly revised in the future."
survived,"def compile_code(code: str, timeout: int):
    signal.alarm(timeout)
    try:
        tmp_sol = ModuleType(""tmp_sol"", """")
        exec(code, tmp_sol.__dict__)
        if ""class Solution"" in code:
            # leetcode wraps solutions in `Solution`
            # this is a hack to check if it is leetcode solution or not
            # currently livecodebench only supports LeetCode but
            # else condition allows future extensibility to other platforms
            compiled_sol = tmp_sol.Solution()
        else:
            # do nothing in the other case since function is accesible
            compiled_sol = tmp_sol

        assert compiled_sol is not None
    finally:
        signal.alarm(0)

    return compiled_sol
",scripts/utils/lcb_runner.py,,1,1.522997951276035e-08,"The method 'compile_code' is a utility function that compiles a given code string into a Python module and checks if it contains a class named 'Solution'. This is useful for platforms like LeetCode where solutions are often wrapped in a 'Solution' class. The method also handles a timeout using the 'signal' module to prevent long-running executions. This functionality is quite specific and useful for competitive programming platforms or environments where code execution needs to be controlled and verified. Given its utility and specificity, it is likely to be retained in the codebase."
survived,"def clean_if_name(code: str) -> str:
    try:
        astree = ast.parse(code)
        last_block = astree.body[-1]
        if isinstance(last_block, ast.If):
            condition = last_block.test
            if ast.unparse(condition).strip() == ""__name__ == '__main__'"":
                code = (
                    ast.unparse(astree.body[:-1]) + ""\n"" + ast.unparse(last_block.body)  # type: ignore
                )
    except:
        pass

    return code
",scripts/utils/lcb_runner.py,,0,0.9999930377407442,"The method 'clean_if_name' is likely to be deleted because it contains several issues that make it unreliable and potentially problematic. Firstly, it uses 'ast.unparse', which is only available in Python 3.9 and later, limiting its compatibility. Secondly, the method does not handle exceptions properly; it catches all exceptions without any logging or error handling, which is a bad practice. Thirdly, the method modifies the code by removing the '__name__ == ""__main__""' block without any clear indication of why this is necessary, which could lead to unexpected behavior. Lastly, the method does not return anything if an exception occurs, which could lead to a 'NoneType' being returned instead of a string, causing further issues in the code that relies on this function. These factors suggest that the method is not robust or reliable enough to be maintained."
survived,"def test_run_benchmarks(tmp_path: Path) -> None:
    result = subprocess.run(
        [sys.executable, str(Path('benchmarks') / 'run_benchmarks.py')],
        capture_output=True,
        text=True,
        check=True,
    )
    data = json.loads(result.stdout)
    assert any(d['task_id'].startswith('swebench_verified_mini') for d in data)
    assert any(d['task_id'].startswith('polyglot_lite') for d in data)
    for entry in data:
        assert 'time_ms' in entry and isinstance(entry['time_ms'], int)
        assert 'pass' in entry",tests/test_benchmarks.py,,1,6.825604231969389e-08,"The method `test_run_benchmarks` is a test function that verifies the output of a benchmark script. It checks for specific task IDs and ensures that certain keys are present in the output data. This type of function is crucial for maintaining the integrity of the benchmarking process, ensuring that the benchmarks are running correctly and producing expected results. Test functions like this are typically retained as they are essential for continuous integration and testing processes."
survived,"    def __init__(self) -> None:
        super().__init__(name=""file_tools"")
",src/self_edit/tools.py,FileToolsADK,1,5.043472052266442e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting up initial states. The use of 'super().__init__()' suggests that this class is part of an inheritance hierarchy, and the constructor is correctly calling the parent class's constructor. This is a standard and necessary practice in Python to ensure proper initialization of the class. Therefore, the method is likely to be retained."
survived,"def test_evolve_stops_on_cost_cap():
    arch = InMemoryArchive()
    asyncio.run(arch.accept(Candidate(0.0, fitness=0.0, novelty=1.0)))

    async def run():
        await evolve(_op, _eval, arch, max_cost=0.1)

    asyncio.run(run())
    # seed + at least two children added
    assert len(arch.all()) >= 3",tests/test_evolve.py,,1,1.725782769012759e-08,"The method 'test_evolve_stops_on_cost_cap' is a unit test designed to verify the behavior of an 'evolve' function when a cost cap is applied. It uses an in-memory archive to simulate the evolution process and checks that at least three candidates (the seed and two children) are present after the evolution process. This test is crucial for ensuring that the 'evolve' function respects the cost cap constraint, which is likely an important feature of the system being tested. Since it serves a clear purpose in validating the functionality of the code, it is likely to be retained in the codebase."
survived,"async def evolve(
    operator: Callable[[Any], Any],
    evaluate: Callable[[Any], tuple[float, float]],
    archive: InMemoryArchive,
    *,
    max_cost: float | None = None,
    wallclock: float | None = None,
) -> None:
    """"""Run an asynchronous evolution loop until the budget is exhausted.""""""

    if not archive.all():
        # seed with a random candidate
        await archive.accept(Candidate(genome=0.0, fitness=0.0, novelty=1.0, cost=0.0))

    spent = 0.0
    start = time.time()

    while True:
        if max_cost is not None and spent >= max_cost:
            break
        if wallclock is not None and time.time() - start >= wallclock:
            break

        parent = select_parent(archive.all(), temp=1.0)
        genome = operator(parent.genome)
        fitness, cost = await evaluate(genome)
        child = Candidate(genome=genome, fitness=fitness, novelty=random.random(), cost=cost)
        await archive.accept(child)
        spent += cost
",src/evolve.py,,1,3.3982678079468468e-09,"The method 'evolve' is a well-defined asynchronous function that implements an evolution loop with clear stopping conditions based on cost and time. It uses an archive to store candidates and employs an operator and evaluation function to generate and assess new candidates. The method is likely to be useful in scenarios involving evolutionary algorithms or optimization tasks. Given its clear purpose, structured implementation, and potential utility in various applications, it is likely to be retained in the codebase."
survived,"    def test_invalid_signature_fails(self) -> None:
        agents._WHEEL_SIGS = {WHEEL_PATH.name: ""invalid""}
        self.assertFalse(agents._verify_wheel(WHEEL_PATH))",tests/test_verify_wheel.py,VerifyWheelTests,1,1.2501528648238603e-09,"The method 'test_invalid_signature_fails' is a unit test designed to verify that the '_verify_wheel' function correctly identifies an invalid signature. Unit tests are crucial for ensuring code reliability and are typically retained in the codebase to maintain test coverage and facilitate future development. Therefore, this method is likely to be retained."
survived,"def bool_expr(prev_token_index, next_token_index, tok, change_end_line, change_end_char):
    if (not (prev_token_index is None or next_token_index is None)) and (tok[0] > change_end_line or (tok[0] == change_end_line and tok[1] > change_end_char)):
        return True
    return False",jac/jaclang/tests/fixtures/py_bool_expr.py,,1,7.194132978569833e-09,"The method 'bool_expr' is a simple utility function that checks certain conditions on token indices and a token's position relative to a change's end position. It is a straightforward and efficient way to encapsulate this logic, making the code more readable and maintainable. Such utility functions are often retained in codebases because they help avoid code duplication and improve clarity. Therefore, it is likely to survive."
survived,"def extract_level(desc):
    match = re.search(r""(\d+)(?:st|nd|rd|th) level"", desc, re.IGNORECASE)
    if match:
        try:
            return int(match.group(1))
        except ValueError:
            return None
    return None
",convert_missing.py,,1,1.4166087846364157e-09,"The method 'extract_level' is a utility function that extracts a numerical level from a string description. It uses regular expressions to find patterns like '1st level', '2nd level', etc., and returns the integer value of the level. This is a common task in text processing, especially in applications like parsing game descriptions or educational content. The method is well-defined, handles exceptions, and serves a clear purpose, making it likely to be useful in various contexts. Therefore, it is likely to be retained."
survived,"def _get_requests():
    """"""Import ``requests`` or attempt to install it on demand.""""""
    global _REQUESTS
    if _REQUESTS is not None:
        return _REQUESTS
    try:  # pragma: no cover - handled at runtime
        import requests as _req
    except ImportError:
        sys.stderr.write(""Installing 'requests'...\n"")
        try:
            subprocess.check_call([sys.executable, ""-m"", ""pip"", ""install"", ""requests""])
            import requests as _req
        except Exception:
            sys.stderr.write(
                ""Failed to install 'requests'. Please run 'pip install -r requirements-dev.txt'.\n""
            )
            raise
    _REQUESTS = _req
    return _req
",tools/update_actions.py,,1,2.5109990926928157e-08,"The method _get_requests() is designed to dynamically import the 'requests' library or install it if it's not available. This is a useful feature for ensuring that the necessary dependencies are available at runtime without requiring manual installation by the user. Such functionality is particularly valuable in environments where dependencies might not be pre-installed or in scripts that need to be portable across different systems. Given the utility and robustness of this approach, it is likely to be retained in the codebase."
survived,"def test_call_vllm_parses_response(env_setup, monkeypatch):
    from importlib import reload

    import np_ocr.search as search
    reload(search)

    class FakeCompletions:
        @staticmethod
        def parse(*args, **kwargs):
            class Msg:
                parsed = search.ImageAnswer(answer=""ok"")
            class Choice:
                message = Msg()
            class Completion:
                choices = [Choice()]
            return Completion()

    class FakeOpenAI:
        def __init__(self, base_url=None, api_key=None):
            pass
        class Beta:
            class Chat:
                completions = FakeCompletions()
            chat = Chat()
        beta = Beta()

    monkeypatch.setattr(search, ""OpenAI"", FakeOpenAI)
    img = Image.new(""RGB"", (10, 10))
    result = search.call_vllm(img, ""hi"", base_url=""http://x"", api_key=""y"", model=""m"")
    assert result.answer == ""ok""
",no-ocr-api/tests/test_utils.py,,1,1.1253518384332553e-07,"The method is a unit test designed to test the functionality of the `call_vllm` function in the `np_ocr.search` module. It uses monkeypatching to replace the `OpenAI` class with a fake implementation that returns a predefined response. This is a common practice in testing to isolate the function being tested from external dependencies. The test checks if the `call_vllm` function correctly parses the response from the fake OpenAI API. Since this is a test method, it is unlikely to be deleted unless the functionality it tests is removed or significantly changed. Therefore, it is more likely to survive."
survived,"def _get(obj, name):
    if obj is None:
        return None
    if isinstance(obj, dict):
        if name in obj:
            return obj[name]
    if hasattr(obj, name):
        return getattr(obj, name)
    if name == ""items"" and hasattr(obj, ""Items""):
        return getattr(obj, ""Items"")
    if isinstance(obj, (list, tuple)):
        for it in obj:
            try:
                return _get(it, name)
            except Exception:
                pass
    raise Exception(""field not found: "" + name)
",tests/machine/x/python/python_math.py,,1,2.0611536181902033e-09,"The method '_get' is a utility function designed to retrieve a value from an object based on a given name. It handles various types of objects, including dictionaries, objects with attributes, and lists or tuples. This flexibility makes it a useful function for accessing nested data structures, which is a common requirement in many applications. The method also includes error handling to manage cases where the desired field is not found, which is a good practice. Given its utility and robustness, it is likely to be retained in the codebase."
survived,"    def test_falls_back_to_unittest(self):
        with tempfile.TemporaryDirectory() as tmpdir:
            target = Path(tmpdir)
            with mock.patch('importlib.util.find_spec', return_value=None):
                with mock.patch('subprocess.call', return_value=0) as call:
                    with mock.patch.object(sys, 'argv', ['run_tests.py', str(target)]):
                        with self.assertRaises(SystemExit):
                            run_tests.main()
                    call.assert_called_once()
                    self.assertIn('unittest', call.call_args[0][0])
",alpha_factory_v1/tests/test_scripts_run_tests.py,RunTestsScriptTest,1,1.522997951276035e-08,"The method `test_falls_back_to_unittest` is a unit test that verifies the behavior of a function when a certain condition is met (in this case, when `importlib.util.find_spec` returns `None`). It ensures that the `run_tests.main()` function falls back to using `unittest` when the specified module cannot be found. This is a valid and useful test case for ensuring the robustness of the `run_tests` functionality. As such, it is likely to be retained in the codebase to maintain test coverage and ensure the correct behavior of the application."
survived,"def on_exception(
    wait_gen: Callable[..., Any],
    exceptions: Tuple[Type[BaseException], ...],
    max_tries: int = 1,
):
    def decorator(func: Callable[..., Any]):
        async def wrapper(*args: Any, **kwargs: Any):
            tries = 0
            while True:
                try:
                    return await func(*args, **kwargs)
                except exceptions:
                    tries += 1
                    if tries >= max_tries:
                        raise

        return wrapper

    return decorator",src/backoff/__init__.py,,1,2.3355930333443423e-09,"The method 'on_exception' is a decorator designed to handle exceptions in asynchronous functions. It allows for retrying a function call a specified number of times before ultimately raising the exception. This is a common and useful pattern in programming, especially for handling transient errors in network calls or other I/O operations. The method is well-structured, uses type hints, and provides flexibility with customizable wait generators and exception types. Given its utility and the fact that it follows a standard pattern for exception handling, it is likely to be retained in the codebase."
survived,"    def __init__(self, searchpath: str) -> None:
        self.searchpath = searchpath
",src/jinja2/__init__.py,FileSystemLoader,1,3.653482080241728e-08,"The method is a constructor for a class, initializing an instance variable 'searchpath'. Constructors are essential for setting up new instances of a class, and this one is straightforward and correctly implemented. There is no indication of redundancy or poor design that would necessitate its removal."
survived,"        def map_type(t: str) -> str:
            return t
",src/jinja2/__init__.py,,0,0.9999339478346898,"The method 'map_type' is a simple identity function that returns the input string as is. While it may seem trivial, such functions can be useful in certain contexts where a consistent interface is required, or when the function is expected to evolve in the future to include more complex logic. However, without additional context or usage, it appears redundant. If the function is not part of a larger framework or does not have anticipated future use, it is likely to be deleted as it does not add any value in its current form."
survived,"def safe_load(stream: Any) -> Any:
    try:
        if hasattr(stream, ""read""):
            data = stream.read()
        else:
            data = str(stream)
        return json.loads(data)
    except Exception as e:
        raise YAMLError(str(e))
",src/yaml/__init__.py,,1,9.237449576640118e-09,"The method 'safe_load' is a utility function that attempts to read data from a stream and parse it as JSON. It includes error handling to raise a custom 'YAMLError' if parsing fails. This method is likely to survive because it provides a useful functionality for safely loading JSON data from various input types, handling both file-like objects and strings. Additionally, it includes error handling, which is a good practice in robust code design."
survived,"def dump(data: Any, stream: Any = None) -> str:
    text = json.dumps(data, indent=2)
    if stream is not None:
        stream.write(text)
        return """"
    return text",src/yaml/__init__.py,,1,1.1032560311263802e-09,"The method 'dump' is a utility function that serializes a Python object into a JSON formatted string. It also provides the option to write this JSON string to a stream if provided. This functionality is quite useful for logging, debugging, or saving data in a structured format. The method is simple, effective, and provides flexibility by allowing both string output and direct writing to a stream. Such utility functions are commonly used and are unlikely to be removed unless there is a significant change in the requirements or a better alternative is introduced. Therefore, the method is likely to survive."
survived,"    def decorator(func: Callable[..., Any]):
        async def wrapper(*args: Any, **kwargs: Any):
            tries = 0
            while True:
                try:
                    return await func(*args, **kwargs)
                except exceptions:
                    tries += 1
                    if tries >= max_tries:
                        raise

        return wrapper
",src/backoff/__init__.py,,1,8.31527990378713e-07,"The method is a decorator function that wraps an asynchronous function with retry logic. It is a useful utility for handling transient errors in asynchronous operations, which are common in network or I/O bound tasks. The method is generic and can be applied to any async function, making it versatile and reusable. Such utility functions are often retained in codebases for their practicality and ability to improve the robustness of async operations."
survived,"def test_dataframe_helpers() -> None:
    traj = _simulate(2, ""linear"", 2, 1)
    df_time = _timeline_df(traj)
    assert set(df_time.columns) == {""year"", ""sector"", ""energy"", ""disrupted""}
    assert len(df_time) == 4

    df_dis = _disruption_df(traj)
    assert set(df_dis.columns) == {""sector"", ""year""}
    assert len(df_dis) <= 2",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_web_app.py,,1,2.998960815863541e-09,"The method `test_dataframe_helpers` is a test function that verifies the correctness of two helper functions, `_timeline_df` and `_disruption_df`. It checks the structure and length of the dataframes returned by these functions. Test functions are generally crucial for ensuring code reliability and are not typically deleted unless they are redundant or replaced by more comprehensive tests. Since this function seems to be a straightforward and useful test, it is likely to be retained."
survived,"def test_cli_export_csv(runner, tmp_path):
    db_path = tmp_path / ""tele.db""
    db = TelemetryDB(db_path)
    db.record(5, 0.1, 0.2, 1)
    db.close()
    out = tmp_path / ""export.csv""
    result = runner.invoke(
        cli,
        [
            ""export"",
            ""--db-path"",
            str(db_path),
            ""--output"",
            str(out),
            ""--format"",
            ""csv"",
            ""--metric"",
            ""tokens"",
        ],
    )
    assert result.exit_code == 0
    assert out.exists()",tests/test_cli.py,,1,1.725782769012759e-08,"The method `test_cli_export_csv` is a test function that verifies the functionality of a command-line interface (CLI) export feature. It uses a test runner to invoke the CLI command and checks if the export operation completes successfully by asserting the exit code and the existence of the output file. Test functions like this are crucial for ensuring the reliability and correctness of software features, especially in a CLI context where user interaction is involved. Therefore, it is likely to be retained as part of the test suite to maintain software quality."
survived,"def test_export_json_and_csv(tmp_path):
    db_path = tmp_path / ""tele.db""
    db = TelemetryDB(db_path)
    # Create two records with known timestamps
    now = datetime.utcnow()
    db.record(5, 0.02, 0.3, 1)
    db.conn.execute(
        ""UPDATE telemetry SET timestamp=? WHERE id=1"",
        ((now - timedelta(days=1)).isoformat(),),
    )
    db.record(10, 0.05, 0.6, 2)

    json_path = tmp_path / ""export.json""
    csv_path = tmp_path / ""export.csv""

    db.export_json(json_path, start=now.isoformat())
    with open(json_path, ""r"", encoding=""utf-8"") as f:
        data = json.load(f)
    assert len(data) == 1
    assert data[0][""tokens""] == 10

    db.export_csv(csv_path, metrics=[""tokens""], start=now.isoformat())
    with open(csv_path, newline="""", encoding=""utf-8"") as f:
        reader = csv.reader(f)
        rows = list(reader)
    assert rows[0] == [""timestamp"", ""tokens""]
    assert len(rows) == 2
    db.close()
",tests/unit/test_telemetry_db.py,,1,1.1861120010657661e-08,"The method 'test_export_json_and_csv' is a unit test designed to verify the functionality of exporting data to JSON and CSV formats from a database. It is a crucial part of ensuring the reliability and correctness of the export functions in the TelemetryDB class. Unit tests are generally not deleted unless they are redundant or replaced by more comprehensive tests. Since this test checks specific functionality and uses temporary paths to avoid side effects, it is likely to be retained to maintain code quality and prevent regressions."
survived,"    def export(
        self,
        path: str | Path,
        *,
        fmt: str = ""json"",
        start: datetime | str | None = None,
        end: datetime | str | None = None,
        metrics: Iterable[str] | None = None,
        compress: bool | None = None,
    ) -> str:
        """"""Export telemetry data in ``fmt`` ('json' or 'csv').""""""
        fmt = fmt.lower()
        if fmt == ""json"":
            return self.export_json(
                path,
                start=start,
                end=end,
                metrics=metrics,
                compress=compress,
            )
        if fmt == ""csv"":
            return self.export_csv(
                path,
                start=start,
                end=end,
                metrics=metrics,
                compress=compress,
            )
        if fmt == ""pdf"":
            raise NotImplementedError(""PDF export not implemented"")
        raise ValueError(f""Unknown format: {fmt}"")
",src/meta_agent/telemetry_db.py,TelemetryDB,1,2.646573631904765e-09,"The method is well-structured and provides a clear interface for exporting telemetry data in different formats. It currently supports 'json' and 'csv', with a placeholder for 'pdf', indicating potential future expansion. The use of type hints and default parameters enhances its usability and maintainability. The method is likely to survive as it is functional, extensible, and aligns with common practices for data export functions."
survived,"    def test_top_tags_page(self):
        for i in range(1, 12):
            tag = Tag.objects.create(tag=f""tag{i}"")
            for j in range(i):
                entry = EntryFactory(title=f""Entry{i}-{j}"")
                entry.tags.add(tag)
        response = self.client.get(""/top-tags/"")
        assert response.status_code == 200
        tags_info = response.context[""tags_info""]
        self.assertEqual(len(tags_info), 10)
        self.assertEqual(tags_info[0][""tag""].tag, ""tag11"")
        self.assertFalse(any(info[""tag""].tag == ""tag1"" for info in tags_info))
        latest = Tag.objects.get(tag=""tag11"").entry_set.order_by(""-created"")[0].title
        self.assertContains(response, latest)",blog/tests.py,BlogTests,1,5.3157849718487075e-08,"The method 'test_top_tags_page' is a unit test designed to verify the functionality of a web page that displays the top tags. It checks if the page returns a 200 status code, if the correct number of tags are displayed, and if the tags are ordered correctly. It also verifies that the latest entry for the top tag is present in the response. This test is crucial for ensuring the integrity of the 'top-tags' feature, making it unlikely to be deleted unless the feature itself is removed or significantly altered."
survived,"def download_openai_gpt2(model: str = ""117M"", dest: Path | str = ""models"", attempts: int = 3) -> None:
    dest_dir = Path(dest) / model
    urls = model_urls(model)
    last_exc: Exception | None = None
    for url in urls:
        target = dest_dir / Path(url).name
        if target.exists():
            print(f""{target} already exists, skipping"")
            continue
        for i in range(1, attempts + 1):
            try:
                print(f""Downloading {url} to {target} (attempt {i})"")
                _download(url, target)
                break
            except Exception as exc:  # noqa: PERF203
                last_exc = exc
                if i < attempts:
                    print(f""Attempt {i} failed: {exc}, retrying..."")
                else:
                    print(f""ERROR: could not download {url}: {exc}"")
                    if target.exists():
                        try:
                            target.unlink()
                        except Exception:
                            pass
    if last_exc:
        raise last_exc
",scripts/download_openai_gpt2.py,,1,1.0467401685178159e-08,"The method `download_openai_gpt2` is a utility function designed to download a specified model from a list of URLs, with retry logic and error handling. It is a useful function for managing model downloads, especially in environments where network reliability is a concern. The function is well-structured, with clear error handling and retry mechanisms, making it robust and reliable for its intended purpose. Such utility functions are often retained in codebases as they provide essential functionality for model management, especially in machine learning and AI projects. Therefore, it is likely to be retained."
survived,"def test_cycle_detection():
    agent_a = Agent(name=""A"")
    agent_b = Agent(name=""B"")
    agent_a.handoffs.append(agent_b)
    agent_b.handoffs.append(agent_a)

    nodes = get_all_nodes(agent_a)
    edges = get_all_edges(agent_a)

    assert nodes.count('""A"" [label=""A""') == 1
    assert nodes.count('""B"" [label=""B""') == 1
    assert '""A"" -> ""B""' in edges
    assert '""B"" -> ""A""' in edges",tests/test_visualization.py,,1,1.1861120010657661e-08,"The method 'test_cycle_detection' is a unit test designed to verify the functionality of cycle detection in a graph-like structure involving agents. It creates two agents, establishes a bidirectional relationship between them, and then checks if the nodes and edges are correctly identified. This is a fundamental test for ensuring that the cycle detection logic works as expected. Such tests are crucial for maintaining the integrity of the codebase, especially when dealing with graph structures where cycles can lead to infinite loops or other logical errors. Therefore, this method is likely to be retained as it serves an important purpose in validating the code's correctness."
survived,"def install_wheel(path: Path) -> Optional[ModuleType]:
    """"""Load a wheel from *path* and return the module.""""""
    if not verify_wheel(path):
        logger.error(""Refusing to load unsigned wheel: %s"", path.name)
        return None
    spec = importlib.util.spec_from_file_location(path.stem, path)
    if spec and spec.loader:
        mod = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(mod)  # type: ignore[arg-type]
        return mod
    return None",alpha_factory_v1/backend/agents/plugins.py,,1,2.7894680920908113e-10,"The method 'install_wheel' is a utility function that loads a Python wheel file from a given path and returns the module. It includes a verification step to ensure the wheel is signed, which is a good security practice. The function is useful for dynamically loading modules and is implemented using standard library functions like 'importlib.util'. Given its utility, security feature, and reliance on standard practices, it is likely to be retained in the codebase."
survived,"def test_show_memory_missing(tmp_path) -> None:
    with patch.object(cli.config.CFG, ""memory_path"", str(tmp_path / ""mem.log"")):
        res = CliRunner().invoke(cli.main, [""show-memory""])
        assert ""No memory"" in res.output
",tests/test_cli.py,,1,3.3982678079468468e-09,"The method 'test_show_memory_missing' is a test function that uses a temporary path to simulate a missing memory log file and checks if the output contains 'No memory'. This is a typical test case for ensuring that the application handles missing files gracefully. Test functions like this are generally useful for maintaining code quality and are unlikely to be deleted unless the feature they test is removed or significantly changed. Therefore, the method is likely to survive."
survived,"    async def insight(req: InsightRequest, _: None = Depends(verify_token)) -> InsightResponse:
        """"""Return aggregated forecast data across runs.""""""

        ids = req.ids or list(_simulations.keys())
        forecasts = [
            _simulations[i].forecast
            for i in ids
            if i in _simulations
        ]
        if not forecasts:
            raise HTTPException(status_code=404)

        year_map: dict[int, list[float]] = {}
        for fc in forecasts:
            for point in fc:
                year_map.setdefault(point.year, []).append(point.capability)
        agg = [
            InsightPoint(year=year, capability=sum(vals) / len(vals))
            for year, vals in sorted(year_map.items())
        ]
        return InsightResponse(forecast=agg)
",src/interface/api_server.py,,1,9.736200303530205e-10,"The method 'insight' is likely to survive because it provides a valuable functionality by aggregating forecast data across multiple simulations. This kind of data processing is often crucial in applications that require analysis of trends over time. The method is well-structured, uses asynchronous programming which is beneficial for performance, and includes error handling for cases where no forecasts are found. These factors suggest that the method is useful and well-implemented, making it unlikely to be deleted."
survived,"def test_manifest_parsing_when_registration_tags_given_as_selector(
    image_field_name: str,
    image_selector: str,
    predictions: Optional[str],
) -> None:
    raw_manifest = {
        ""type"": ""roboflow_core/roboflow_dataset_upload@v2"",
        ""name"": ""some"",
        image_field_name: image_selector,
        ""predictions"": predictions,
        ""target_project"": ""some1"",
        ""usage_quota_name"": ""my_quota"",
        ""data_percentage"": ""$inputs.data_percentage"",
        ""persist_predictions"": ""$inputs.persist_predictions"",
        ""minutely_usage_limit"": 10,
        ""hourly_usage_limit"": 100,
        ""daily_usage_limit"": 1000,
        ""max_image_size"": (100, 200),
        ""compression_level"": 100,
        ""registration_tags"": ""$inputs.tags"",
        ""disable_sink"": ""$inputs.disable_sink"",
        ""fire_and_forget"": ""$inputs.fire_and_forget"",
        ""labeling_batch_prefix"": ""$inputs.labeling_batch_prefix"",
        ""labeling_batches_recreation_frequency"": ""never"",
    }

    result = BlockManifest.model_validate(raw_manifest)

    assert result == BlockManifest(
        type=""roboflow_core/roboflow_dataset_upload@v2"",
        name=""some"",
        images=image_selector,
        predictions=predictions,
        target_project=""some1"",
        usage_quota_name=""my_quota"",
        data_percentage=""$inputs.data_percentage"",
        persist_predictions=""$inputs.persist_predictions"",
        minutely_usage_limit=10,
        hourly_usage_limit=100,
        daily_usage_limit=1000,
        max_image_size=(100, 200),
        compression_level=100,
        registration_tags=""$inputs.tags"",
        disable_sink=""$inputs.disable_sink"",
        fire_and_forget=""$inputs.fire_and_forget"",
        labeling_batch_prefix=""$inputs.labeling_batch_prefix"",
        labeling_batches_recreation_frequency=""never"",
    )
",tests/workflows/unit_tests/core_steps/sinks/roboflow/roboflow_dataset_upload/test_v2.py,,1,2.5109990926928157e-08,"The method is a test function that validates the parsing of a manifest with specific parameters. It is likely part of a test suite to ensure that the manifest is correctly constructed and validated. Such test functions are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is unlikely to be deleted as it serves an important role in testing and validation."
survived,"        def _mp_fn(index: int, cfg: TextLogitsConfig, tmp_dir: str):
            dataset = read_dataset(cfg.input_path)
            dataset = dataset.shard(xmp.xrt_world_size(), index)

            tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)
            model = AutoModelForCausalLM.from_pretrained(cfg.model_name)
            device = xm.xla_device()
            model.to(device)
            model.eval()

            def _forward(batch):
                tokens = tokenizer(
                    batch[""text""],
                    truncation=True,
                    padding=True,
                    max_length=cfg.max_length,
                    return_tensors=""pt"",
                )
                tokens = {k: v.to(device) for k, v in tokens.items()}
                with torch.no_grad():
                    outputs = model(**tokens)
                xm.mark_step()
                batch[""logits""] = outputs.logits.cpu().tolist()
                return batch

            dataset = dataset.map(
                _forward, batched=True, batch_size=cfg.batch_size
            )

            shard_path = os.path.join(tmp_dir, f""logits_{index}.jsonl.gz"")
            write_dataset(dataset, shard_path)
",marin/generation/logits.py,,1,5.043472052266442e-07,"The method '_mp_fn' is a specialized function designed to process a dataset using a machine learning model. It includes reading a dataset, tokenizing text, running a model inference, and saving the results. The function is well-structured, uses modern libraries like Hugging Face Transformers and PyTorch, and is likely part of a larger system for distributed processing or model evaluation. Given its utility in processing and saving model outputs, it is unlikely to be deleted unless the entire system is deprecated or replaced by a more efficient method."
survived,"    def run(cfg: TextLogitsConfig):
        import torch_xla.core.xla_model as xm
        import torch_xla.distributed.xla_multiprocessing as xmp

        def _mp_fn(index: int, cfg: TextLogitsConfig, tmp_dir: str):
            dataset = read_dataset(cfg.input_path)
            dataset = dataset.shard(xmp.xrt_world_size(), index)

            tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)
            model = AutoModelForCausalLM.from_pretrained(cfg.model_name)
            device = xm.xla_device()
            model.to(device)
            model.eval()

            def _forward(batch):
                tokens = tokenizer(
                    batch[""text""],
                    truncation=True,
                    padding=True,
                    max_length=cfg.max_length,
                    return_tensors=""pt"",
                )
                tokens = {k: v.to(device) for k, v in tokens.items()}
                with torch.no_grad():
                    outputs = model(**tokens)
                xm.mark_step()
                batch[""logits""] = outputs.logits.cpu().tolist()
                return batch

            dataset = dataset.map(
                _forward, batched=True, batch_size=cfg.batch_size
            )

            shard_path = os.path.join(tmp_dir, f""logits_{index}.jsonl.gz"")
            write_dataset(dataset, shard_path)

        with tempfile.TemporaryDirectory() as tmp_dir:
            xmp.spawn(_mp_fn, args=(cfg, tmp_dir))
            import glob
            import datasets

            shard_files = sorted(glob.glob(os.path.join(tmp_dir, ""logits_*.jsonl.gz"")))
            shards = [read_dataset(p) for p in shard_files]
            combined = datasets.concatenate_datasets(shards)
            write_dataset(combined, cfg.output_path)
",marin/generation/logits.py,,1,1.444980317078884e-07,"The method is a well-structured implementation for distributed processing using PyTorch XLA, which is essential for running models on TPUs. It includes data sharding, tokenization, model inference, and result aggregation, all of which are necessary for efficient large-scale model evaluation. The use of temporary directories and multiprocessing is appropriate for the task, and the method follows best practices for handling large datasets and model outputs. Given the increasing importance of distributed computing and TPU usage, this method is likely to be retained for its utility in these contexts."
survived,"def makeAdder(n):
    return lambda x: x + n
",tests/transpiler/x/py/closure.py,,1,3.160881453314576e-10,"The method 'makeAdder' is a higher-order function that returns a lambda function. This lambda function takes an argument 'x' and adds it to 'n', which is a parameter of 'makeAdder'. This is a useful and common pattern in functional programming, allowing for the creation of customized functions on the fly. Such utility functions are often retained in codebases due to their flexibility and reusability. Therefore, it is likely to be Survived."
survived,"def test_bridge_online_mode(monkeypatch) -> None:
    pytest.importorskip(""openai_agents"")
    monkeypatch.setenv(""OPENAI_API_KEY"", ""dummy"")
    result = subprocess.run(
        [
            sys.executable,
            ""-m"",
            ""alpha_factory_v1.demos.meta_agentic_tree_search_v0.openai_agents_bridge"",
            ""--episodes"",
            ""1"",
            ""--rewriter"",
            ""openai"",
        ],
        capture_output=True,
        text=True,
    )
    assert result.returncode == 0, result.stderr
    assert ""Best agents"" in result.stdout
",tests/test_meta_agentic_tree_search_demo.py,,1,9.237449576640118e-09,"The method 'test_bridge_online_mode' is a test function that uses the 'monkeypatch' fixture to set an environment variable and then runs a subprocess to test a specific module. It includes assertions to verify the expected behavior of the subprocess. This is a typical pattern for testing in Python, especially when dealing with external dependencies or subprocesses. The method is likely to survive because it is a functional test that ensures the integration of different components works as expected, which is valuable for maintaining code quality and reliability."
survived,"def self_improver_cmd(repo_url: str, patch_file: str, metric_file: str, log_file: str) -> None:
    """"""Clone repo, apply patch, evaluate score delta and log it.""""""

    delta, _ = self_improver.improve_repo(repo_url, patch_file, metric_file, log_file)
    click.echo(f""score delta: {delta}"")
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/cli.py,,1,3.850741907939403e-09,"The method `self_improver_cmd` is a utility function that performs a series of operations: cloning a repository, applying a patch, evaluating the score delta, and logging the result. This type of function is typically useful in automation scripts or command-line tools where such operations are common. The function is concise, has a clear purpose, and uses external dependencies (like `self_improver` and `click`) which suggests it is part of a larger system. Unless the functionality it provides is no longer needed or has been replaced by a more efficient method, it is likely to be retained. Therefore, it is predicted to survive."
survived,"    def fake_chat(prompt: str, cfg: object | None = None) -> str:
        called[""prompt""] = prompt
        return ""local""
",tests/test_alpha_agi_business_3_v1.py,,1,8.76424914819242e-08,"The method 'fake_chat' is a simple function that takes a prompt and an optional configuration object, stores the prompt in a dictionary, and returns a static string ""local"". This method is likely a placeholder or a mock function used for testing purposes. Such methods are often retained in codebases for testing or development purposes, especially if they are part of a larger testing framework or if they are used to simulate interactions in a controlled environment. Therefore, it is more likely to survive unless there is a significant refactor or change in the testing strategy."
survived,"    def __getitem__(cls, item: NamedArrayAxesSpec) -> typing.Annotated[""NamedArray"", NamedArrayAxes]:
        axes = _parse_namedarray_axes(item)
        return typing.Annotated[NamedArray, axes]
",src/haliax/core.py,NamedArrayMeta,1,1.637377179507321e-07,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the indexing syntax (e.g., obj[key]). In this code, it is implemented to handle a specific type of input (`NamedArrayAxesSpec`) and return a type-annotated object. This suggests that the method is part of a class that deals with named arrays, likely providing a way to access or manipulate these arrays based on their axes specifications. The use of type annotations and the specific parsing function `_parse_namedarray_axes` indicates that this method is part of a well-structured and possibly widely used library or framework. Therefore, it is unlikely to be deleted as it serves a clear purpose in the context of the class it belongs to."
survived,"def build_llm() -> OpenAIAgent:
    """"""Create the default ``OpenAIAgent`` instance.""""""
    api_key = os.getenv(""OPENAI_API_KEY"")
    return OpenAIAgent(
        model=os.getenv(""MODEL_NAME"", ""gpt-4o-mini""),
        api_key=api_key,
        base_url=None if api_key else os.getenv(""OLLAMA_BASE_URL"", ""http://localhost:11434/v1""),
    )",alpha_factory_v1/demos/aiga_meta_evolution/utils.py,,1,1.4166087846364157e-09,"The method `build_llm` is likely to survive because it provides a clear and necessary functionality for creating an instance of `OpenAIAgent` with configurable parameters. It uses environment variables to set the API key and model name, which is a common practice for managing configuration in a flexible and secure manner. Additionally, it includes a fallback mechanism for the base URL, enhancing its robustness. These features make it a useful utility function in a codebase that interacts with OpenAI's API."
survived,"        def __init__(self):
            self.image_size_cache = {}
            self.class_embeddings_cache = {}
            self.image_embed_cache = {}
            self.cpu_image_embed_cache = {}
            self.before_unload_image_none = False
            self.after_unload = False
",tests/inference/models_predictions_tests/test_owlv2.py,DummyOwl,1,2.699578619062706e-07,"The method is a constructor (__init__) for a class, which is a fundamental part of object-oriented programming in Python. Constructors are essential for initializing new objects and setting up initial state, such as initializing caches and flags in this case. Therefore, it is highly unlikely that this method would be deleted as it is crucial for the proper functioning of the class."
survived,"def classify_with_llm(text: str) -> bool:
    """"""Placeholder LLM classifier for ambiguous snippets.""""""
    lower = text.lower()
    return ""paywalled"" in lower or ""proprietary"" in lower
",scripts/dp_scrubber.py,,1,4.6911638017642294e-08,"The method `classify_with_llm` is a simple placeholder function that checks if certain keywords ('paywalled' or 'proprietary') are present in the input text. This kind of utility function is often useful in larger systems where text needs to be classified based on specific criteria. The function is straightforward, performs a clear task, and could be part of a larger text processing or classification system. Given its utility and simplicity, it is likely to be retained in the codebase unless there is a significant change in requirements or a more sophisticated solution is implemented."
survived,"        async def _spawn():  # pragma: no cover - Rocketry callback
            await self._spawn_jobs()
",src/scheduler/__init__.py,SelfImprovementScheduler,1,8.152020648014727e-09,"The method _spawn is an asynchronous function that is likely used as a callback in the Rocketry scheduling framework. The pragma: no cover comment suggests that this method is intentionally excluded from test coverage, which often indicates that it is a critical part of the system's functionality that is either difficult to test or is tested indirectly through other means. Additionally, the method calls another function, _spawn_jobs, which implies that it is part of a larger job scheduling or execution process. Given its role in the system and the fact that it is marked as a callback, it is unlikely to be deleted unless there is a significant refactor or change in the underlying framework or architecture. Therefore, the method is likely to survive."
survived,"    async def _spawn_jobs(self) -> None:
        """"""Spawn new worker tasks until quotas or limits are hit.""""""
        if self.time_quota and time.time() - self.start_time >= self.time_quota:
            self.app.session.finish()
            return
        if self.tokens_quota is not None and self.tokens_used >= self.tokens_quota:
            self.app.session.finish()
            return
        # schedule initial evaluation or bandit-selected jobs
        while len(self.running) < self.max_workers:
            if not self._first_round_done:
                if self.queue.empty():
                    break
                job = await self.queue.get()
            else:
                if not self._active_jobs:
                    self.app.session.finish()
                    break
                job = self._select_job()
            task = asyncio.create_task(self._run_job(job))
            self.running.add(task)
            task.add_done_callback(self.running.discard)
",src/scheduler/__init__.py,SelfImprovementScheduler,1,7.194132978569833e-09,"The method '_spawn_jobs' is a crucial part of an asynchronous task management system, responsible for spawning new worker tasks while respecting quotas and limits. It includes logic to handle time and token quotas, manage a queue of jobs, and ensure that the number of running tasks does not exceed the maximum allowed. This functionality is essential for maintaining the efficiency and stability of the system, especially in environments where resources are limited or need to be carefully managed. Therefore, it is unlikely to be deleted as it serves a fundamental role in the application's operation."
survived,"def _fetch_spot_price(region: str = ""us-east-1"") -> float:
    """"""Return the current A10 spot price per hour in ``region``.""""""
    if boto3 is None:  # pragma: no cover - missing deps
        raise RuntimeError(""boto3 not available"")
    ec2 = boto3.client(""ec2"", region_name=region)
    history = ec2.describe_spot_price_history(
        InstanceTypes=[""g5.2xlarge""],
        ProductDescriptions=[""Linux/UNIX""],
        MaxResults=1,
    )
    price = float(history[""SpotPriceHistory""][0][""SpotPrice""])
    return price
",src/scheduler/spot_gpu.py,,1,2.3355930333443423e-09,"The method `_fetch_spot_price` is a utility function that fetches the current spot price for a specific instance type in a given AWS region. This functionality is useful for applications that need to dynamically adjust their behavior based on current cloud pricing, such as cost optimization tools or dynamic scaling solutions. The method is straightforward, relies on a well-known library (boto3), and provides a clear and specific purpose. There is no indication of redundancy or obsolescence in the code, and it addresses a common need in cloud-based applications. Therefore, it is likely to be retained in the codebase."
survived,"    async def _run_job(self, job: Job) -> None:
        start = time.perf_counter()
        try:
            delta, _ = await asyncio.to_thread(
                self_improver.improve_repo,
                job.repo,
                job.patch,
                job.metric,
                job.log,
            )
            self.tokens_used += job.tokens
            gpu_hours = (time.perf_counter() - start) / 3600
            metrics.dgm_gpu_hours_total.inc(gpu_hours)
            if delta > 0:
                metrics.dgm_fitness_gain_total.inc(delta)
            if metrics.dgm_fitness_gain_total._value.get() > 0:
                ratio = (
                    metrics.dgm_gpu_hours_total._value.get()
                    / metrics.dgm_fitness_gain_total._value.get()
                )
                metrics.dgm_gpu_hours_per_gain.set(ratio)
            if not self._first_round_done:
                self._results[job] = delta
            else:
                suc, fail = self._stats.get(job, (0, 0))
                if delta > 0:
                    suc += 1
                else:
                    fail += 1
                self._stats[job] = (suc, fail)
        except Exception:  # noqa: BLE001
            await self.queue.put(job)
        if not self._first_round_done and len(self._results) == len(self._initial_jobs):
            self._finalize_first_round()
",src/scheduler/__init__.py,SelfImprovementScheduler,1,1.955568070542584e-08,"The method '_run_job' is an asynchronous function that handles the execution of a job, including measuring performance, updating metrics, and handling exceptions. It is well-structured and serves a clear purpose in the context of job processing and metric tracking. The use of asyncio for asynchronous execution and the handling of exceptions by re-queuing jobs suggest that it is a robust and necessary part of the system. Therefore, it is unlikely to be deleted unless there is a significant change in the system's architecture or requirements."
survived,"    def start_merkle_task(self, interval: int = 86_400) -> None:
        if self._task is None:
            try:
                loop = asyncio.get_running_loop()
            except RuntimeError:  # pragma: no cover - no loop in sync context
                _log.warning(""Merkle task requires a running event loop"")
                return
            self._task = loop.create_task(self._loop(interval))
",src/archive/service.py,ArchiveService,1,3.160881453314576e-10,"The method 'start_merkle_task' is likely to survive because it contains a clear and useful functionality for starting a task in an asynchronous event loop. It checks if a task is already running and attempts to get the current event loop to create a new task if none exists. The method also handles the case where no event loop is running, logging a warning instead of failing silently. This kind of functionality is essential in asynchronous programming, especially in applications that require periodic tasks, making it a valuable part of the codebase."
survived,"    def __init__(
        self,
        path: str | Path = _DEFAULT_DB,
        *,
        rpc_url: str | None = None,
        wallet: str | None = None,
        broadcast: bool = True,
    ) -> None:
        self.path = Path(path)
        self.path.parent.mkdir(parents=True, exist_ok=True)
        self.conn = sqlite3.connect(str(self.path))
        self.conn.execute(
            """"""
            CREATE TABLE IF NOT EXISTS entries(
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                parent TEXT,
                spec TEXT,
                scores TEXT,
                hash TEXT,
                ts REAL
            )
            """"""
        )
        self.conn.commit()
        self.rpc_url = rpc_url
        self.wallet = wallet
        self.broadcast = broadcast
        self._task: asyncio.Task[None] | None = None
",src/archive/service.py,ArchiveService,1,1.522997951276035e-08,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class. It sets up important attributes and database connections, making it a critical part of the class's functionality. Constructors are rarely deleted unless the entire class is being removed or refactored, which is not indicated here."
survived,"    def _report() -> None:  # pragma: no cover - scheduler callback
        weekly_report(csv_path)
",src/analysis/meta_foresight.py,,1,1.3440409770490404e-08,"The method _report is marked with a pragma directive 'no cover', indicating that it is intentionally excluded from test coverage. This suggests that the method is likely a utility or callback function that is not directly tested but is still necessary for the application's functionality. Additionally, the method calls another function, weekly_report, which implies it serves a specific purpose in generating or handling reports. Given these factors, it is unlikely that this method will be deleted as it seems to play a role in the application's reporting mechanism."
survived,"    def raise_for_status(self) -> None:
        """"""Raise :class:`RuntimeError` if the status code signals an error.""""""
        if self.status_code >= 400:
            raise RuntimeError(f""HTTP {self.status_code}"")
",alpha_factory_v1/requests.py,Response,1,2.0611536181902033e-09,"The method `raise_for_status` is a common utility in HTTP client libraries to check if a response indicates an error based on its status code. It is a useful method for error handling, allowing developers to easily identify and respond to HTTP errors. This functionality is essential for robust network communication, and similar methods are found in popular libraries like `requests`. Given its utility and common usage pattern, it is likely to be retained in the codebase."
survived,"        def skipif(self, *_, **__):
            def wrapper(func):
                return func
            return wrapper
",alpha_factory_v1/tests/test_smoke.py,_DummyMark,0,0.9999997897565932,"The method 'skipif' is a decorator that does not perform any operation other than returning the function it decorates. It takes any number of positional and keyword arguments but does not use them, which suggests it might be a placeholder or a stub for future functionality. However, as it stands, it doesn't provide any utility or functionality, making it redundant. Unless there is a specific use case or future plan to implement logic within this decorator, it is likely to be deleted as it serves no purpose in its current form."
survived,"    def test_register_condition_callable(self):
        @register(condition=lambda: True)
        class BazAgent(AgentBase):
            NAME = ""baz""
        self.assertIn(""baz"", AGENT_REGISTRY)
",alpha_factory_v1/tests/test_register_decorator.py,RegisterDecoratorTest,1,2.3355930333443423e-09,"The method `test_register_condition_callable` is a unit test that verifies the functionality of the `register` decorator with a condition. It checks if a class `BazAgent` is correctly registered in `AGENT_REGISTRY` when the condition is a callable that returns `True`. This is a valid and useful test to ensure that the registration mechanism works as expected when conditions are used. Therefore, it is likely to be retained in the codebase."
survived,"        def start(self) -> None:  # pragma: no cover - unused
            pass
",tests/test_alpha_agi_business_3_v1.py,DummySock,0,0.9999999397642536,"The method 'start' is currently not implemented and is marked with a pragma comment indicating it is unused. This suggests that the method is not currently needed or utilized in the codebase. Without any implementation or indication of future use, it is likely to be removed to clean up the code."
survived,"            async def close(self) -> None:
                pass
",tests/test_insight_orchestrator_features.py,TestLedger.DummyClient,1,5.715002851580502e-07,"The method 'close' is defined as an asynchronous function but currently does nothing (it contains only a 'pass' statement). However, it is likely a placeholder for future implementation, especially in the context of asynchronous programming where resource management (like closing connections or files) is crucial. Therefore, it is more probable that this method will be implemented in the future rather than deleted, as it serves a potential purpose in managing resources asynchronously."
survived,"async def main() -> None:
    example_path = Path(__file__).parent / ""app.py""

    config = {
        ""mcpServers"": {
            ""hello"": {
                ""command"": sys.executable,
                ""args"": [str(example_path)],
            }
        }
    }

    client = MCPClient(config=config)
    session = await client.create_session(""hello"")
    result = await session.connector.call_tool(""hello_world"", {})
    print(result.content[0].text)

    await client.close_all_sessions()
",examples/hello_world/client.py,,1,9.237449576640118e-09,"The method is an asynchronous main function that sets up a configuration for an MCPClient, creates a session, calls a tool, and prints the result. It is well-structured, uses modern Python features like async/await, and seems to be part of a larger system that interacts with external tools or services. Such methods are typically essential for the operation of the system they are part of, especially if they handle important tasks like session management and tool invocation. Therefore, it is likely to be retained in the codebase."
survived,"def _start_server_with_retry(
    port: int, env: dict[str, str] | None = None, *, attempts: int = 3
) -> subprocess.Popen[bytes]:
    url = f""http://127.0.0.1:{port}""
    last_err: AssertionError | None = None
    for _ in range(attempts):
        proc = _start_server(port, env)
        try:
            _wait_ready(proc, url)
            return proc
        except AssertionError as err:
            last_err = err
            proc.terminate()
            proc.wait(timeout=5)
    assert last_err is not None
    raise last_err
",tests/test_metrics.py,,1,2.7894680920908113e-10,"The method '_start_server_with_retry' is likely to survive because it implements a robust mechanism to start a server with retry logic. This is a common pattern in software development to handle transient errors or issues that may occur during server startup. The method is well-structured, uses type hints, and includes error handling, making it a valuable utility function in a codebase that requires reliable server startup processes."
survived,"    async def emit(self, recipient: str, payload: Any) -> None:
        env = messaging.Envelope(
            sender=self.name,
            recipient=recipient,
            payload=struct_pb2.Struct(),
            ts=time.time(),
        )
        if isinstance(payload, dict):
            env.payload.update(payload)
        self.ledger.log(env)
        self.bus.publish(recipient, env)
",alpha_factory_v1/core/agents/base_agent.py,BaseAgent,1,4.599055376537186e-10,"The method 'emit' is likely to survive because it performs a clear and useful function within the code. It constructs a messaging envelope with a sender, recipient, and payload, logs it, and then publishes it to a bus. This is a common pattern in event-driven or message-passing systems, indicating that it serves a necessary role in the application's architecture. Additionally, the use of asynchronous programming suggests it is designed to handle potentially high-latency operations efficiently, which is a modern and relevant approach."
survived,"def lead_signal_improvement(
    history: Sequence[float],
    forecast: Sequence[float],
    *,
    months: int = 6,
    threshold: float | None = None,
) -> float:
    """"""Return relative lead-time improvement over the baseline.""""""
    base = _arima_baseline(history, months)
    thr = threshold if threshold is not None else (history[-1] if history else 0.0)

    def first_cross(seq: Sequence[float]) -> int:
        for i, v in enumerate(seq, 1):
            if v >= thr:
                return i
        return months + 1

    base_idx = first_cross(base)
    cand_idx = first_cross(forecast[:months])
    if base_idx <= cand_idx:
        return 0.0
    return (base_idx - cand_idx) / base_idx
",alpha_factory_v1/core/evaluators/lead_time.py,,1,1.4166087846364157e-09,"The method 'lead_signal_improvement' is a well-defined function that calculates the relative lead-time improvement over a baseline using a forecast and historical data. It includes a default parameter for months and an optional threshold, making it flexible for different use cases. The logic for determining the first crossing point in the sequences is clear and the function returns a meaningful metric. There are no apparent issues with the code that would necessitate its deletion, and it seems to serve a useful purpose in forecasting analysis."
survived,"    async def evolve(
        self,
        scenario_hash: str,
        fn: Callable[[list[float]], tuple[float, ...]],
        genome_length: int,
        sector: str = ""generic"",
        approach: str = ""ga"",
        experiment_id: str = ""default"",
        **kwargs: object,
    ) -> mats.Population:
        """"""Run evolution for ``scenario_hash`` keyed by ``experiment_id``.""""""

        pops = self.experiment_pops.setdefault(experiment_id, {})
        if len(self.experiment_pops) > 10:
            raise RuntimeError(""max concurrent experiments exceeded"")

        pop = await asyncio.to_thread(
            mats.run_evolution,
            fn,
            genome_length,
            scenario_hash=scenario_hash,
            populations=pops,
            **cast(Any, kwargs),
        )
        pops[scenario_hash] = pop
        for ind in pop:
            self.solution_archive.add(
                sector,
                approach,
                ind.score,
                {""genome"": ind.genome},
            )
            self.archive.insert_entry(
                {""experiment_id"": experiment_id, ""genome"": ind.genome},
                {""score"": ind.score},
            )
        return pop
",alpha_factory_v1/core/orchestrator.py,Orchestrator,1,2.998960815863541e-09,"The method 'evolve' is likely to survive because it appears to be a well-structured and useful function within its context. It is designed to run an evolutionary algorithm asynchronously, which is a common and valuable operation in computational tasks that involve optimization or machine learning. The method also includes error handling for too many concurrent experiments, which indicates thoughtful design. Additionally, it interacts with other components like 'solution_archive' and 'archive', suggesting it is part of a larger, integrated system. These factors contribute to its likelihood of being retained in the codebase."
survived,"    def _generate_basic_tool_code(name: str) -> str:
        """"""Return a very small tool implementation used as a fallback.""""""
        return f""""""
import logging

logger_tool = logging.getLogger(__name__)

class {name}Tool:
    def __init__(self, salutation: str = 'Hello'):
        self.salutation = salutation
        logger_tool.info(f'{name}Tool initialized with {{self.salutation}}')

    def run(self, name: str) -> str:
        logger_tool.info(f'{name}Tool.run called with {{name}}')
        return f'{{self.salutation}}, {{name}} from {name}Tool!'

def get_tool_instance():
    logger_tool.info('get_tool_instance called')
    return {name}Tool()
""""""
",src/meta_agent/sub_agent_manager.py,SubAgentManager,1,6.023574641292144e-08,"The method `_generate_basic_tool_code` is a utility function that dynamically generates a basic tool class with logging capabilities. This kind of functionality is useful for creating simple, consistent tool implementations with minimal code duplication. The method is likely to be retained because it provides a flexible way to create tool classes with logging, which can be useful in various scenarios where dynamic class generation is needed. Additionally, the use of logging suggests that the method is intended for use in a production environment where monitoring and debugging are important."
survived,"def test_merge_usage_entries_with_new_keys():
    """"""Ensure merging usage entries preserves unseen keys.""""""
    tracker = UsageTracker()

    tracker.add_usage(""model-x"", {""prompt_tokens"": 5})
    tracker.add_usage(""model-x"", {""completion_tokens"": 2})

    total_usage = tracker.get_total_tokens()

    assert total_usage[""model-x""][""prompt_tokens""] == 5
    assert total_usage[""model-x""][""completion_tokens""] == 2",tests/utils/test_usage_tracker.py,,1,1.1253518384332553e-07,"The method 'test_merge_usage_entries_with_new_keys' is a test function that verifies the functionality of merging usage entries in a 'UsageTracker' class. Test functions are generally essential for ensuring code reliability and correctness, especially in a development environment. This function checks that the 'UsageTracker' correctly accumulates token usage for different keys, which is a critical feature for any application tracking usage metrics. Therefore, it is unlikely to be deleted as it serves an important role in validating the functionality of the 'UsageTracker'."
survived,"def test_missing_value_returns_zero() -> None:
    value = er.reward(None, None, {""latency_ms"": 400})
    assert value == 0.0
",tests/test_efficiency_reward.py,,1,2.8453347280241004e-08,"The method `test_missing_value_returns_zero` is a unit test that checks if the `reward` function from the `er` module returns 0.0 when called with `None` values for its first two parameters and a dictionary with a `latency_ms` key. This test is likely to be useful for ensuring that the `reward` function handles missing or `None` inputs correctly, which is a common edge case that needs to be tested. Therefore, the method is likely to be retained as it serves a purpose in verifying the robustness of the `reward` function."
survived,"    def __init__(self) -> None:
        self.history = deque()
",tests/test_education_reward.py,DummyState,1,8.152020648014727e-09,"The method is a constructor for a class, initializing an instance variable 'history' as a deque. This is a common pattern in Python for setting up initial state in an object. Since constructors are essential for creating instances of classes, this method is unlikely to be deleted unless the entire class is being refactored or removed. Therefore, it is more likely to survive."
survived,"def test_first_solution_yields_one() -> None:
    _reset()
    value = ns.reward(None, None, ""solve x"")
    assert isinstance(value, float)
    assert value == 1.0
",tests/test_novel_solution_reward.py,,1,1.444980317078884e-07,"The method `test_first_solution_yields_one` is a test function that checks if the `reward` method from the `ns` module returns a float value of 1.0 when called with specific arguments. This is a straightforward test case that verifies the expected behavior of the `reward` method. Test functions like this are crucial for ensuring code reliability and correctness, especially in larger projects. Therefore, it is unlikely to be deleted as it serves an important role in maintaining the integrity of the codebase."
survived,"def _reset_ledger() -> None:
    eb._ledger.clear()
",tests/test_energy_balance_reward.py,,1,7.194132978569833e-09,"The method _reset_ledger is a private method (indicated by the underscore prefix) that clears a ledger, which is likely a data structure such as a list or dictionary. This method is straightforward and serves a clear purpose in resetting or clearing the state of the ledger. Such utility methods are often necessary for maintaining or resetting the state of an application, especially in testing or when reinitializing components. Therefore, it is likely to be retained as it provides essential functionality."
survived,"def test_typical_day_score_in_range() -> None:
    _reset_ledger()
    res = {""date"": ""2025-04-22"", ""calories_in"": 2400, ""calories_out"": 600, ""bmr"": 1650}
    value = eb.reward(None, None, res)
    assert isinstance(value, float)
    assert 0.0 <= value <= 1.0
",tests/test_energy_balance_reward.py,,1,1.0467401685178159e-08,"The method `test_typical_day_score_in_range` is a unit test designed to verify that the `reward` function from the `eb` module returns a float value within the range of 0.0 to 1.0. This is a typical test case to ensure that the function behaves as expected under normal conditions. Unit tests are crucial for maintaining code quality and ensuring that changes do not introduce bugs. Therefore, this method is likely to be retained as it serves an important role in the software development process by validating the functionality of the `reward` function."
survived,"def test_add():
    assert calc.add(1, 1) == 2",alpha_factory_v1/demos/self_healing_repo/sample_broken_calc/test_calc.py,,1,7.73442280641062e-08,"The method `test_add` is a unit test for a function `add` in a module or class `calc`. Unit tests are essential for verifying that individual parts of the code work as expected. This test checks if the `add` function correctly adds two numbers, which is a fundamental operation. Such tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is unlikely that this method will be deleted unless the `add` function itself is removed or significantly changed, which would require a different test."
survived,"def _simulate(horizon: int, curve: str, pop_size: int, generations: int) -> list[Any]:
    """"""Run the disruption forecast and return the trajectory.""""""
    secs = [sector.Sector(f""s{i:02d}"") for i in range(pop_size)]
    return cast(
        list[Any],
        forecast.forecast_disruptions(
            secs,
            horizon,
            curve,
            pop_size=pop_size,
            generations=generations,
        ),
    )
",src/interface/minimal_ui.py,,1,4.944450477491054e-09,"The method '_simulate' is a private method (indicated by the underscore prefix) that is designed to simulate a disruption forecast. It is well-defined with clear parameters and a docstring explaining its purpose. The method uses list comprehension and type casting, which are common practices in Python. Additionally, it leverages other components like 'sector.Sector' and 'forecast.forecast_disruptions', suggesting it is part of a larger, possibly modular system. Unless there is a significant change in the system's requirements or architecture, there is no apparent reason for this method to be deleted. It seems to serve a specific purpose within its context."
survived,"def test_single_file_format():
    source_files = {""Contract"": {""content"": ""contract C {}""}}
    assert not is_standard_json_contract(source_files)
",tests/test_utils.py,,1,7.194132978569833e-09,"The method `test_single_file_format` is a unit test function that checks the behavior of the `is_standard_json_contract` function. Unit tests are crucial for ensuring code reliability and correctness, especially in larger projects. This test seems to be checking that a single file format does not meet the criteria for a standard JSON contract, which is a valid and useful test case. Therefore, it is likely to be retained as part of the test suite."
survived,"    async def step(self) -> None:  # noqa: D401
        """"""Delegate step execution to :meth:`run_cycle`.""""""
        await self.run_cycle()
",alpha_factory_v1/backend/agents/cyber_threat_agent.py,CyberThreatAgent,1,1.4166087846364157e-09,"The method 'step' is a simple asynchronous function that delegates its execution to another method 'run_cycle'. It is likely part of a larger asynchronous system where such delegation is common. The method is straightforward, follows Python's async conventions, and is documented. There is no indication of redundancy or obsolescence, suggesting it will be retained."
survived,"    async def step(self) -> None:  # noqa: D401
        """"""Delegate step execution to :meth:`run_cycle`.""""""
        await self.run_cycle()
",alpha_factory_v1/backend/agents/climate_risk_agent.py,ClimateRiskAgent,1,1.1861120010657661e-08,"The method 'step' is a simple asynchronous function that delegates its execution to another method 'run_cycle'. It is likely part of a larger class or module where 'run_cycle' is defined. The method is straightforward and serves a clear purpose of abstraction and delegation, which is a common pattern in asynchronous programming to maintain clean and organized code. Unless there is a significant change in the design or requirements of the system that makes this delegation unnecessary, the method is likely to survive."
survived,"def _build_parser() -> argparse.ArgumentParser:
    p = argparse.ArgumentParser(description=""Run α‑AGI Insight simulation"")
    p.add_argument(""--horizon"", type=int, default=5)
    return p
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/cli.py,,1,3.3982678079468468e-09,"The method `_build_parser` is a private helper function that constructs and returns an `argparse.ArgumentParser` object. It is a simple and straightforward function that is likely used internally within a module to handle command-line arguments for a simulation. The function is well-defined, serves a clear purpose, and does not contain any obvious issues or redundancies. Therefore, it is likely to be retained in the codebase as it provides necessary functionality for argument parsing."
survived,"    async def handle(self, env):
        pass",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/planning_agent.py,PlanningAgent,0,0.9999999123575085,"The method 'handle' is defined as an asynchronous function but contains only a 'pass' statement, meaning it currently does nothing. Without any implementation, it serves no functional purpose in its current state. Unless it is intended to be overridden in a subclass or is a placeholder for future development, it is likely to be deleted as it does not contribute to the codebase."
survived,"    async def run_cycle(self) -> None:
        pass
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/research_agent.py,ResearchAgent,0,0.9999999468421502,"The method 'run_cycle' is defined as an asynchronous function but contains no implementation (just a 'pass' statement). This suggests that it is either a placeholder for future code or it is not needed. If it remains unimplemented for a long time, it is likely to be deleted as it serves no purpose in its current state. However, if there is a plan to implement it soon, it might survive. Without additional context, the lack of implementation leans towards deletion."
survived,"    def fn(g):
        return (g[0] ** 2, g[1] ** 2)
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_mats.py,,1,6.825604231969389e-08,"The method 'fn' is a simple function that takes a tuple 'g' as input and returns a new tuple with the squares of the first two elements of 'g'. This function is straightforward and performs a basic mathematical operation, which is a common requirement in many programming tasks. There is no indication that this function is redundant or unnecessary, as squaring elements of a tuple can be a useful operation in various contexts. Therefore, it is likely to be retained in the codebase."
survived,"    async def handle(self, env):
        pass",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/memory_agent.py,MemoryAgent,0,0.99999960721363,"The method 'handle' is defined as an asynchronous function but contains only a 'pass' statement, meaning it currently does nothing. Without any implementation, it serves no functional purpose. Unless it is intended as a placeholder for future development, it is likely to be deleted to clean up the codebase."
survived,"    def __init__(self, bus, ledger) -> None:
        super().__init__(""memory"", bus, ledger)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/memory_agent.py,MemoryAgent,1,1.444980317078884e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting up initial states. Therefore, it is unlikely to be deleted as it serves a critical role in the class's functionality."
survived,"    async def stop(self) -> None:
        if self._server:
            await self._server.stop(0)
            self._server = None",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/messaging.py,A2ABus,1,1.8189616842444243e-09,"The method 'stop' is likely to survive because it performs a crucial function of stopping a server, which is a common requirement in server management. The method is also implemented asynchronously, which is suitable for non-blocking operations in modern applications. Additionally, the method checks if the server is running before attempting to stop it, which is a good practice to prevent errors. These factors suggest that the method is well-designed and serves an important purpose, making it unlikely to be deleted."
survived,"        def simplify_link_target(text_content: str) -> str:
            match_colon_num = re.match(r""([^:]+:\d+)"", text_content)
            if match_colon_num:
                return match_colon_num.group(1)
            return text_content
",app/services/client.py,GeminiClientWrapper,1,1.3440409770490404e-08,"The method 'simplify_link_target' is a utility function that attempts to match a specific pattern in a string and return a part of it if the pattern is found. This kind of function is often useful in processing text data, especially when dealing with URLs or other structured strings. The function is simple, has a clear purpose, and does not have any apparent issues or redundancies. Therefore, it is likely to be retained in the codebase as it serves a specific and useful purpose."
survived,"    async def init(self, **kwargs):
        # Inject default configuration values
        kwargs.setdefault(""timeout"", g_config.gemini.timeout)
        kwargs.setdefault(""auto_refresh"", g_config.gemini.auto_refresh)
        kwargs.setdefault(""verbose"", g_config.gemini.verbose)
        kwargs.setdefault(""refresh_interval"", g_config.gemini.refresh_interval)

        await super().init(**kwargs)
",app/services/client.py,GeminiClientWrapper,1,2.5109990926928157e-08,"The method 'init' is an asynchronous initializer that sets default configuration values using the 'setdefault' method on the 'kwargs' dictionary. This is a common pattern for initializing objects with default settings while allowing for overrides. The method then calls the superclass's 'init' method, passing the updated 'kwargs'. This pattern is useful for ensuring that objects are initialized with consistent settings and is likely to be a necessary part of the class's functionality. Therefore, it is unlikely to be deleted unless the entire class is refactored or the initialization process is significantly changed."
survived,"    async def process_conversation(messages: list[Message], tempdir: Path | None = None):
        """"""
        Process the entire conversation and return a formatted string and list of
        files. The last message is assumed to be the assistant's response.
        """"""
        conversation: list[str] = []
        files: list[Path | str] = []

        for msg in messages:
            input_part, files_part = await GeminiClientWrapper.process_message(msg, tempdir)
            conversation.append(input_part)
            files.extend(files_part)

        # Left with the last message as the assistant's response
        conversation.append(add_tag(""assistant"", """", unclose=True))

        return ""\n"".join(conversation), files
",app/services/client.py,GeminiClientWrapper,1,1.1032560311263802e-09,"The method 'process_conversation' is likely to survive because it is a well-structured asynchronous function that processes a list of messages, which is a common requirement in applications dealing with chat or conversation data. It uses modern Python features such as type hints and asynchronous programming, making it suitable for contemporary software development practices. Additionally, it interacts with an external client ('GeminiClientWrapper'), suggesting it is part of a larger system, which increases its likelihood of being maintained and used."
survived,"    def test_invalid_env_logs_warning(self) -> None:
        logging.disable(logging.NOTSET)
        with patch.dict(os.environ, {""FOO"": ""bar""}, clear=True):
            with self.assertLogs(""alpha_factory_v1.edge_runner"", level=""WARNING"") as cm:
                self.assertEqual(edge_runner._env_int(""FOO"", 5), 5)
        self.assertTrue(any(""Invalid FOO"" in msg for msg in cm.output))",tests/test_edge_runner.py,TestEnvIntWarning,1,2.0611536181902033e-09,"The method 'test_invalid_env_logs_warning' is a unit test designed to verify that a warning is logged when an invalid environment variable is encountered. This is a common and useful test case to ensure that the system behaves correctly in the presence of unexpected or incorrect environment variables. The test uses mocking to simulate the environment and checks the logging output, which is a standard practice in testing logging behavior. Therefore, this method is likely to be retained as it serves a clear purpose in maintaining code quality and reliability."
survived,"def get_window_region(window_title):
    window_list = Quartz.CGWindowListCopyWindowInfo(
        Quartz.kCGWindowListOptionOnScreenOnly | Quartz.kCGWindowListExcludeDesktopElements,
        Quartz.kCGNullWindowID
    )
    # Get all exist windows
    all_titles = []
    for window in window_list:
        title = window.get(Quartz.kCGWindowName, '')
        owner = window.get(Quartz.kCGWindowOwnerName, '')
        if title:
            all_titles.append(f""{title} (Owner: {owner})"")
    logger.debug(f""all_titles: {all_titles}"")
    for window in window_list:
        if window.get(Quartz.kCGWindowName, '') == window_title:
            bounds = window.get(Quartz.kCGWindowBounds, {})
            return {
                ""left"": int(bounds.get('X', 0)),
                ""top"": int(bounds.get('Y', 0)),
                ""width"": int(bounds.get('Width', 0)),
                ""height"": int(bounds.get('Height', 0))
            }
    return None
",src/input/GameWindowCapturorForMac.py,,1,2.3355930333443423e-09,"The method `get_window_region` is likely to survive because it performs a useful function of retrieving the position and size of a window given its title. This functionality is relevant for applications that need to interact with or manage window positions on a screen, such as screen recording software, window management tools, or automated testing frameworks. The method uses the Quartz API, which is a standard way to interact with windowing systems on macOS, indicating that it is using appropriate and supported libraries for its task. Additionally, the method includes logging for debugging purposes, which is a good practice for maintaining and troubleshooting code."
survived,"def parse_and_validate_attributes(attr_str):
    raw_values = attr_str.split(',')
    if len(raw_values) != 4:
        raise argparse.ArgumentTypeError(""You must provide exactly 4 attributes: STR,DEX,INT,LUK"")

    parsed = []
    total_known = 0
    unknown_count = 0

    for v in raw_values:
        if v.strip() == '?':
            parsed.append(None)
            unknown_count += 1
        else:
            try:
                val = int(v)
            except ValueError:
                raise argparse.ArgumentTypeError(f""Invalid attribute value: {v}"")
            if not (4 <= val <= 13):
                raise argparse.ArgumentTypeError(""Each attribute must be between 4 and 13."")
            parsed.append(val)
            total_known += val

    if unknown_count > 0 and (total_known > 25 or total_known + 4 * unknown_count > 25):
        raise argparse.ArgumentTypeError(""Impossible to satisfy sum of 25 with current values."")

    return parsed
",tools/AutoDiceRoller.py,,1,5.905303995456778e-10,"The method 'parse_and_validate_attributes' is well-defined and serves a specific purpose of parsing and validating a string of attributes. It includes error handling for incorrect input formats and logical checks to ensure the sum of attributes is within a specified range. These features make it robust and useful in scenarios where attribute validation is necessary, such as in games or simulations. There is no indication that this method is obsolete or redundant, so it is likely to be retained."
survived,"    def solve_rune(self):
        '''
        Solve the rune puzzle by detecting the arrow directions and pressing corresponding keys.
        '''
        while self.is_in_rune_game():
            for arrow_idx in [0,1,2,3]:
                # Get lastest game screen frame buffer
                self.frame = self.capture.get_frame()
                # Resize game screen to 1296x759
                self.img_frame = cv2.resize(self.frame, (1296, 759),
                                            interpolation=cv2.INTER_NEAREST)

                # Crop arrow detection box
                x = self.cfg.arrow_box_start_point[0] + self.cfg.arrow_box_interval*arrow_idx
                y = self.cfg.arrow_box_start_point[1]
                size = self.cfg.arrow_box_size
                img_roi = self.img_frame[y:y+size, x:x+size]

                # Loop through all possible arrows template and choose the most possible one
                best_score = float('inf')
                best_direction = """"
                for direction, arrow_list in self.img_arrows.items():
                    for img_arrow in arrow_list:
                        _, score, _ = find_pattern_sqdiff(
                                        img_roi, img_arrow,
                                        mask=get_mask(img_arrow, (0, 255, 0)))
                        if score < best_score:
                            best_score = score
                            best_direction = direction
                logger.info(f""[solve_rune] Arrow({arrow_idx}) is {best_direction} with score({best_score})"")

                # Update img_frame_debug
                self.img_frame_debug = self.img_frame.copy()
                draw_rectangle(
                    self.img_frame_debug, (x, y), (size, size),
                    (0, 0, 255), str(round(best_score, 2))
                )
                # Update debug window
                self.update_img_frame_debug()
                cv2.waitKey(1)

                # For logging
                screenshot(self.img_frame_debug, ""solve_rune"")

                # Press the key for 0.5 second
                if not self.args.disable_control:
                    self.kb.press_key(best_direction, 0.5)
                time.sleep(1)


        logger.info(f""[solve_rune] Solved all arrows"")
",src/legacy/mapleStoryAutoLevelUp_legacy.py,MapleStoryBot,1,2.2603252742033343e-06,"The method 'solve_rune' is a specific implementation for solving a rune puzzle in a game by detecting arrow directions and pressing corresponding keys. It involves image processing, pattern matching, and interaction with a game interface. Such methods are typically highly specialized and not generic, making them less likely to be reused in different contexts. However, the method is well-documented, uses logging, and has a clear purpose, which are positive indicators for its survival. Additionally, it seems to be part of a larger system (as indicated by the use of 'self'), suggesting it is integrated into a class or module that relies on it. Therefore, it is more likely to be maintained as long as the system it belongs to is in use."
survived,"    def get_monsters_in_range(self, top_left, bottom_right):
        '''
        get_monsters_in_range
        '''
        x0, y0 = top_left
        x1, y1 = bottom_right

        img_roi = self.img_frame[y0:y1, x0:x1]

        monster_info = []
        for monster_name, monster_imgs in self.monsters.items():
            for img_monster, mask_monster in monster_imgs:
                if self.args.patrol:
                    pass # Don't detect monster using template in patrol mode
                elif self.cfg.monster_detect_mode == ""template_free"":
                    # Generate mask where pixel is exactly (0,0,0)
                    black_mask = np.all(img_roi == [0, 0, 0], axis=2).astype(np.uint8) * 255
                    cv2.imshow(""Black Pixel Mask"", black_mask)

                    # Shift player's location into ROI coordinate system
                    px, py = self.loc_player
                    px_in_roi = px - x0
                    py_in_roi = py - y0

                    # Define rectangle range around player (in ROI coordinate)
                    char_x_min = max(0, px_in_roi - self.cfg.character_width // 2)
                    char_x_max = min(img_roi.shape[1], px_in_roi + self.cfg.character_width // 2)
                    char_y_min = max(0, py_in_roi - self.cfg.character_height // 2)
                    char_y_max = min(img_roi.shape[0], py_in_roi + self.cfg.character_height // 2)

                    # Zero out mask inside this region (ignore player's own character)
                    black_mask[char_y_min:char_y_max, char_x_min:char_x_max] = 0

                    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (20, 20))
                    closed_mask = cv2.morphologyEx(black_mask, cv2.MORPH_CLOSE, kernel)
                    # cv2.imshow(""Black Mask"", closed_mask)

                    # draw player character bounding box

                    draw_rectangle(
                        self.img_frame_debug, (char_x_min+x0, char_y_min+y0),
                        (self.cfg.character_height, self.cfg.character_width),
                        (255, 0, 0), ""Character Box""
                    )

                    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(closed_mask, connectivity=8)

                    monster_info = []
                    min_area = 1000
                    for i in range(1, num_labels):
                        x, y, w, h, area = stats[i]
                        if area > min_area:
                            monster_info.append({
                                ""name"": """",
                                ""position"": (x0+x, y0+y),
                                ""size"": (h, w),
                                ""score"": 1.0,
                            })
                elif self.cfg.monster_detect_mode == ""contour_only"":
                    # Use only black lines contour to detect monsters
                    # Create masks (already grayscale)
                    mask_pattern = np.all(img_monster == [0, 0, 0], axis=2).astype(np.uint8) * 255
                    mask_roi = np.all(img_roi == [0, 0, 0], axis=2).astype(np.uint8) * 255

                    # Apply Gaussian blur (soften the masks)
                    img_monster_blur = cv2.GaussianBlur(mask_pattern, (self.cfg.blur_range, self.cfg.blur_range), 0)
                    img_roi_blur = cv2.GaussianBlur(mask_roi, (self.cfg.blur_range, self.cfg.blur_range), 0)

                    # Check template vs ROI size before matching
                    h_roi, w_roi = img_roi_blur.shape[:2]
                    h_temp, w_temp = img_monster_blur.shape[:2]

                    if h_temp > h_roi or w_temp > w_roi:
                        return []  # template bigger than roi, skip this matching

                    # Perform template matching
                    res = cv2.matchTemplate(img_roi_blur, img_monster_blur, cv2.TM_SQDIFF_NORMED)

                    # Apply soft threshold
                    match_locations = np.where(res <= self.cfg.monster_diff_thres)

                    h, w = img_monster.shape[:2]
                    for pt in zip(*match_locations[::-1]):
                        monster_info.append({
                            ""name"": monster_name,
                            ""position"": (pt[0] + x0, pt[1] + y0),
                            ""size"": (h, w),
                            ""score"": res[pt[1], pt[0]],
                        })
                elif self.cfg.monster_detect_mode == ""grayscale"":
                    img_monster_gray = cv2.cvtColor(img_monster, cv2.COLOR_BGR2GRAY)
                    img_roi_gray = cv2.cvtColor(img_roi, cv2.COLOR_BGR2GRAY)
                    res = cv2.matchTemplate(
                            img_roi_gray,
                            img_monster_gray,
                            cv2.TM_SQDIFF_NORMED,
                            mask=mask_monster)
                    match_locations = np.where(res <= self.cfg.monster_diff_thres)
                    h, w = img_monster.shape[:2]
                    for pt in zip(*match_locations[::-1]):
                        monster_info.append({
                            ""name"": monster_name,
                            ""position"": (pt[0] + x0, pt[1] + y0),
                            ""size"": (h, w),
                            ""score"": res[pt[1], pt[0]],
                    })
                elif self.cfg.monster_detect_mode == ""color"":
                    res = cv2.matchTemplate(
                            img_roi,
                            img_monster,
                            cv2.TM_SQDIFF_NORMED,
                            mask=mask_monster)
                    match_locations = np.where(res <= self.cfg.monster_diff_thres)
                    h, w = img_monster.shape[:2]
                    for pt in zip(*match_locations[::-1]):
                        monster_info.append({
                            ""name"": monster_name,
                            ""position"": (pt[0] + x0, pt[1] + y0),
                            ""size"": (h, w),
                            ""score"": res[pt[1], pt[0]],
                    })
                else:
                    logger.error(f""Unexpected camera localization mode: {self.cfg.monster_detect_mode}"")
                    return []

        # Apply Non-Maximum Suppression to monster detection
        monster_info = nms(monster_info, iou_threshold=0.4)

        # Detect monster via health bar
        if self.cfg.monster_detect_with_health_bar:
            # Create color mask for Monsters' HP bar
            mask = cv2.inRange(img_roi,
                               np.array(self.cfg.monster_health_bar_color),
                               np.array(self.cfg.monster_health_bar_color))

            # Find connected components (each cluster of green pixels)
            num_labels, labels, stats, centroids = \
                cv2.connectedComponentsWithStats(mask, connectivity=8)

            for i in range(1, num_labels):  # skip background (label 0)
                x, y, w, h, area = stats[i]
                if area < 3:  # small noise filter
                    continue

                # Guess a monster bounding box
                y += 10
                x = max(0, x)
                y = max(0, y)
                w = 70
                h = 70

                monster_info.append({
                    ""name"": ""Health Bar"",
                    ""position"": (x0 + x, y0 + y),
                    ""size"": (h, w),
                    ""score"": 1.0,
                })

        # Debug
        # Draw attack detection range
        draw_rectangle(
            self.img_frame_debug, (x0, y0), (y1-y0, x1-x0),
            (255, 0, 0), ""Monster Detection Box""
        )

        # Draw monsters bounding box
        for monster in monster_info:
            if monster[""name""] == ""Health Bar"":
                color = (0, 255, 255)
            else:
                color = (0, 255, 0)

            draw_rectangle(
                self.img_frame_debug, monster[""position""], monster[""size""],
                color, str(round(monster['score'], 2))
            )

        return monster_info
",src/legacy/mapleStoryAutoLevelUp_legacy.py,MapleStoryBot,1,1.275190675769241e-07,"The method `get_monsters_in_range` is a comprehensive function that detects monsters within a specified region of interest (ROI) in an image frame. It supports multiple detection modes (template-free, contour-only, grayscale, color) and includes additional features like non-maximum suppression and health bar detection. The method is well-structured, with clear logic for each detection mode, and includes debugging visualizations. These features make it a valuable part of a larger system, likely for a game or image processing application. Given its complexity and utility, it is unlikely to be deleted unless the entire system undergoes a significant redesign."
survived,"    def get_minimap_location(self):
        '''
        get_minimap_location
        '''
        loc_minimap, score, is_cached = find_pattern_sqdiff(
                                            self.img_frame, self.img_map)

        return loc_minimap
",src/legacy/mapleStoryAutoLevelUp_legacy.py,MapleStoryBot,1,2.998960815863541e-09,"The method `get_minimap_location` is a straightforward utility function that retrieves the location of a minimap within an image frame using a pattern matching technique. It is likely to be a useful part of a larger system, especially in applications involving image processing or game development where minimap detection is necessary. The method is simple, well-defined, and serves a clear purpose, which suggests it is likely to be retained in the codebase."
survived,"def test_new_async_manager_includes_tags() -> None:
    config = {""callbacks"": None}
    manager = get_async_callback_manager_for_config(config, tags=[""x"", ""y""])
    assert isinstance(manager, AsyncCallbackManager)
    assert manager.inheritable_tags == [""x"", ""y""]
",libs/langgraph/tests/test_config_async.py,,1,7.73442280641062e-08,"The method `test_new_async_manager_includes_tags` is a test function that verifies the behavior of the `get_async_callback_manager_for_config` function. It checks if the manager created includes the specified tags. Test functions are generally important for ensuring code reliability and correctness, especially in a development environment where changes are frequent. Therefore, it is likely to be retained to ensure that the functionality it tests remains correct."
survived,"        def run(self) -> None:
            pass
",tests/test_aiga_openai_bridge_offline.py,AgentRuntime,1,0.00013982203410499962,"The method 'run' is defined but not implemented, as it only contains a 'pass' statement. This suggests that the method is either a placeholder for future implementation or is intentionally left empty because it is meant to be overridden in a subclass. If the class is part of a framework or library where 'run' is expected to be overridden, it will likely survive. However, if this is standalone code and 'run' is never implemented or used, it might be deleted. Without additional context, it's more likely to survive as a placeholder or abstract method."
survived,"def test_patcher_cli_offline(tmp_path, monkeypatch):
    repo = tmp_path / ""repo""
    repo.mkdir()
    (repo / ""test_ok.py"").write_text(""def test_ok():\n    assert True\n"", encoding=""utf-8"")

    # stub openai to satisfy import in llm_client
    monkeypatch.setitem(sys.modules, ""openai"", types.ModuleType(""openai""))

    orig_import = builtins.__import__

    def fake_import(name, globals=None, locals=None, fromlist=(), level=0):
        if name == ""openai_agents"":
            raise ModuleNotFoundError(name)
        return orig_import(name, globals, locals, fromlist, level)

    monkeypatch.setattr(builtins, ""__import__"", fake_import)
    monkeypatch.setattr(sys, ""argv"", [""patcher_core.py"", ""--repo"", str(repo)])

    runpy.run_module(
        ""alpha_factory_v1.demos.self_healing_repo.patcher_core"", run_name=""__main__""
    )",tests/test_patcher_core_cli_offline.py,,1,1.2501528648238603e-09,"The method 'test_patcher_cli_offline' is a test function that sets up a temporary environment to test a specific functionality. It uses 'monkeypatch' to modify the behavior of imports and command-line arguments, which is a common practice in testing to isolate the test environment from external dependencies. This method is likely part of a test suite and is useful for ensuring the robustness of the code it tests. Test functions are generally not deleted unless they are redundant or replaced by more comprehensive tests. Therefore, it is likely to survive."
survived,"    def fake_import(name, globals=None, locals=None, fromlist=(), level=0):
        if name == ""openai_agents"":
            raise ModuleNotFoundError(name)
        return orig_import(name, globals, locals, fromlist, level)
",tests/test_patcher_core_cli_offline.py,,1,4.222835268240621e-06,"The method 'fake_import' is a custom implementation of the import mechanism, specifically designed to raise a ModuleNotFoundError when attempting to import a module named 'openai_agents'. This kind of function is typically used for testing purposes, to simulate the absence of certain modules or to control the import behavior in a specific environment. Such methods are often temporary and used in specific contexts, which suggests that it might not be a permanent part of the codebase. However, the method itself is functional and serves a clear purpose, which could justify its retention if the need for this specific import behavior persists. Therefore, without additional context on the long-term requirements of the project, it's reasonable to predict that the method will survive for now."
survived,"    def test_agents_must_be_positive(self) -> None:
        with self.assertRaises(ValueError):
            run_sim(agents=0, rounds=10, delta=0.5, stake=1.0)
        with self.assertRaises(ValueError):
            run_sim(agents=-1, rounds=10, delta=0.5, stake=1.0)
",tests/test_governance_sim.py,TestGovernanceSim,1,9.237449576640118e-09,"The method 'test_agents_must_be_positive' is a unit test designed to ensure that the 'run_sim' function raises a ValueError when the 'agents' parameter is zero or negative. This is a valid and important test case to ensure the robustness of the 'run_sim' function by checking its input validation. Such tests are crucial for maintaining code quality and preventing errors in production. Therefore, it is unlikely that this method will be deleted as it serves a clear purpose in the testing suite."
survived,"def test_pyodide_fallback() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri()

    with sync_playwright() as p:
        browser = p.chromium.launch()
        page = browser.new_page()
        page.route(""**/pyodide.js"", lambda route: route.abort())
        page.goto(url)
        page.wait_for_selector(""#controls"")
        page.wait_for_selector(""#toast.show"")
        assert ""Pyodide"" in page.inner_text(""#toast"")
        browser.close()
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_pyodide_fallback.py,,1,3.3982678079468468e-09,"The method `test_pyodide_fallback` is a test function that uses Playwright to automate a browser for testing purposes. It is designed to verify the behavior of a web application when the `pyodide.js` script is unavailable. This kind of test is crucial for ensuring that the application can handle script loading failures gracefully, which is an important aspect of robust web application development. Given the increasing importance of automated testing in software development, especially for web applications, it is likely that this method will be retained to ensure the reliability and resilience of the application."
survived,"    def test_old_version_fails(self) -> None:
        fake_mod = types.SimpleNamespace(__version__=""0.0.13"")
        orig_import_module = importlib.import_module
        orig_find_spec = importlib.util.find_spec

        def _fake_import(name: str, *args: Any, **kwargs: Any) -> object:
            if name == ""openai_agents"":
                return fake_mod
            return orig_import_module(name, *args, **kwargs)

        def _fake_find_spec(name: str, *args: Any, **kwargs: Any) -> object:
            if name == ""openai_agents"":
                return object()
            return orig_find_spec(name, *args, **kwargs)

        with (
            mock.patch(""importlib.import_module"", side_effect=_fake_import),
            mock.patch(""importlib.util.find_spec"", side_effect=_fake_find_spec),
        ):
            self.assertFalse(preflight.check_openai_agents_version())
",tests/test_preflight_openai_agents_version.py,TestPreflightOpenAIAgentsVersion,1,5.3157849718487075e-08,"The method 'test_old_version_fails' is a unit test designed to verify that the 'preflight.check_openai_agents_version()' function correctly identifies an outdated version of a module ('openai_agents'). This is a common practice in software development to ensure that version checks are functioning as expected. Since testing for version compatibility is a crucial aspect of maintaining software that relies on external libraries, this method is likely to be retained to ensure the robustness of the version checking mechanism."
survived,"def _insert_after_tool(ctx: RunContextWrapper | dict, path: str, anchor: str, code: str) -> str:
    insert_after(path, anchor, code)
    return ""ok""
",src/self_edit/tools.py,,0,0.999999694097641,"The method `_insert_after_tool` is a simple wrapper around the `insert_after` function, adding no additional logic or functionality. It takes a context, path, anchor, and code as parameters, calls `insert_after`, and returns a static string ""ok"". This method is likely to be deleted because it doesn't add any value beyond calling `insert_after` directly. If the `insert_after` function is accessible and can be called directly, this wrapper is redundant and unnecessary, leading to its potential removal."
survived,"def test_undo_idempotent(temp_path: Path) -> None:
    temp_path.write_text(""a\nb\nc\n"")
    insert_after(temp_path, ""b"", ""x"")
    assert ""x"" in temp_path.read_text()
    assert undo_last_edit() is True
    assert temp_path.read_text() == ""a\nb\nc\n""
    assert undo_last_edit() is False
    assert temp_path.read_text() == ""a\nb\nc\n""
",tests/test_tools_undo.py,,1,3.653482080241728e-08,"The method 'test_undo_idempotent' is a test function that verifies the idempotency of an undo operation. It checks that after inserting a line and undoing the operation, the file content returns to its original state, and further undo attempts do not alter the content. This is a useful test to ensure the reliability and correctness of the undo functionality, which is a common requirement in many applications. Therefore, the method is likely to be retained as it serves a critical role in validating the behavior of the undo feature."
survived,"def _undo_tool(ctx: RunContextWrapper | dict) -> bool:
    return undo_last_edit()
",src/self_edit/tools.py,,1,2.998960815863541e-09,"The method _undo_tool is a private method (indicated by the underscore prefix) and is likely part of a larger codebase. It has a clear and specific purpose: to undo the last edit, which is a common functionality in many applications. The method is simple and directly calls another function, undo_last_edit, suggesting it acts as a wrapper or an interface for this functionality. Unless there is a significant change in the application's requirements or architecture that makes this method redundant or obsolete, it is likely to be retained. Therefore, it is predicted to survive."
survived,"def _ensure_db(path: Path) -> None:
    with sqlite3.connect(path) as cx:
        cx.execute(
            ""CREATE TABLE IF NOT EXISTS tarballs(id INTEGER PRIMARY KEY AUTOINCREMENT,path TEXT,cid TEXT,pinned INTEGER,ts REAL)""
        )
        cx.execute(
            ""CREATE TABLE IF NOT EXISTS merkle(date TEXT PRIMARY KEY,root TEXT)""
        )
",src/archive/hash_archive.py,,1,5.60279640614594e-09,"The method _ensure_db is responsible for ensuring that the necessary database tables exist. It uses the 'CREATE TABLE IF NOT EXISTS' SQL command, which is a common and efficient way to initialize or verify the existence of tables in a database. This method is likely to be a crucial part of the application's setup or initialization process, ensuring that the database schema is correct before any operations are performed. Such methods are typically essential for the stability and functionality of applications that rely on databases, and therefore, it is likely to be retained in the codebase."
survived,"def _dump_yaml(obj: Any, indent: int = 0) -> List[str]:
    lines: List[str] = []
    prefix = "" "" * indent
    if isinstance(obj, dict):
        for k, v in obj.items():
            if isinstance(v, (dict, list)):
                lines.append(f""{prefix}{k}:"")
                lines.extend(_dump_yaml(v, indent + 2))
            else:
                lines.append(f""{prefix}{k}: {v}"")
    elif isinstance(obj, list):
        for item in obj:
            if isinstance(item, (dict, list)):
                lines.append(f""{prefix}-"")
                lines.extend(_dump_yaml(item, indent + 2))
            else:
                lines.append(f""{prefix}- {item}"")
    else:
        lines.append(f""{prefix}{obj}"")
    return lines
",src/yaml/__init__.py,,1,2.0611536181902033e-09,"The method `_dump_yaml` is a utility function that converts a Python object into a YAML-formatted string. This function is useful for serializing data structures into a human-readable format, which is a common requirement in many applications, especially those dealing with configuration files or data interchange. The function handles nested dictionaries and lists, which are common in YAML files, and provides indentation for readability. Given its utility and the fact that YAML is a widely used format, it is likely that this function will be retained in the codebase."
survived,"def _gen_crc16_table(poly: int) -> list[int]:
  table = []
  for i in range(256):
    crc = i << 8
    for _ in range(8):
      if crc & 0x8000:
        crc = ((crc << 1) ^ poly) & 0xFFFF
      else:
        crc = (crc << 1) & 0xFFFF
    table.append(crc)
  return table
",opendbc/car/crc.py,,1,6.023574641292144e-08,"The method _gen_crc16_table is a utility function that generates a CRC-16 table based on a given polynomial. This type of function is often used in data integrity checks and error-detection algorithms, which are fundamental in many applications. The function is well-defined, performs a specific task, and is likely to be useful in contexts where CRC calculations are needed. Therefore, it is unlikely to be deleted unless the entire CRC functionality is removed or replaced by a different implementation."
survived,"def fca_giorgio_checksum(address: int, sig, d: bytearray) -> int:
  crc = 0
  for i in range(len(d) - 1):
    crc ^= d[i]
    crc = CRC8J1850[crc]
  if address == 0xDE:
    return crc ^ 0x10
  elif address == 0x106:
    return crc ^ 0xF6
  elif address == 0x122:
    return crc ^ 0xF1
  else:
    return crc ^ 0x0A",opendbc/car/chrysler/chryslercan.py,,1,1.8189616842444243e-09,"The method 'fca_giorgio_checksum' is a utility function that calculates a checksum based on a given address and data. It uses a CRC8 table (CRC8J1850) to compute the checksum, which is a common operation in data integrity checks, especially in automotive and communication protocols. The function includes specific logic for different addresses, which suggests it is tailored for a specific application or protocol. Such functions are typically essential for ensuring data integrity and are unlikely to be removed unless the entire protocol or application is deprecated. Therefore, the method is likely to survive."
survived,"def list_destinations() -> list[Destination]:
    """"""Return the full list of available destinations.""""""

    return DESTINATIONS
",examples/server_side_llm_travel_planner/app.py,,1,3.653482080241728e-08,"The method `list_destinations` is a simple utility function that returns a list of available destinations. It is straightforward, has a clear purpose, and is likely used in other parts of the codebase to access the list of destinations. Unless there is a significant change in how destinations are managed or accessed, such as moving to a database or a different data structure, there is no reason to delete this method. It provides a clean and encapsulated way to access the `DESTINATIONS` list, which is a common pattern in software design."
survived,"    async def sampling(
        self,
        messages: str | list[str | SamplingMessage],
        **kwargs,
    ) -> CreateMessageResult:
        """"""Alias for :meth:`ask_llm`.""""""

        return await self.ask_llm(messages, **kwargs)
",src/enrichmcp/context.py,EnrichContext,1,4.363462233903899e-09,"The method 'sampling' is an alias for another method 'ask_llm'. This is a common practice in programming to provide a more intuitive or context-specific name for a function. Since it serves a purpose by potentially improving code readability and usability, it is likely to be retained. Additionally, the use of type hints and async functionality suggests it is part of a modern codebase, further supporting its survival."
survived,"    def count_links_in_html(html_path: Path) -> int:
        content = html_path.read_text(encoding=""utf-8"", errors=""ignore"")
        return content.count(""See docs/DISCLAIMER_SNIPPET.md"")
",scripts/verify_disclaimer_snippet.py,,0,0.9999999397642536,"The method is likely to be deleted because it is not accurately counting links in an HTML file. Instead, it counts occurrences of a specific string, which may not represent actual HTML links. The method's name suggests it should count all links, but its implementation does not fulfill this purpose, making it misleading and potentially unused or replaced by a more accurate implementation."
survived,"def test_self_improve_prompt_snapshot(monkeypatch):
    log = (FIXTURES / ""self_improve.txt"").read_text()

    def fake_llm(prompt: str, system: str | None) -> str:
        return f""patch-{random.random()}""

    monkeypatch.setattr(prompting, ""_get_llm"", lambda: fake_llm)
    out = prompting.self_improve(""Fix bug:\n{logs}"", log, seed=7)
    assert out == ""patch-0.32383276483316237""",tests/test_self_improve_prompting.py,,1,2.5109990926928157e-08,"The method 'test_self_improve_prompt_snapshot' is a unit test designed to verify the behavior of the 'self_improve' function from the 'prompting' module. It uses 'monkeypatch' to replace the '_get_llm' method with a fake implementation that returns a predictable output. The test then asserts that the output of 'self_improve' matches the expected result. This is a typical pattern for testing functions that rely on external dependencies or random outputs. Since the test is well-structured and serves a clear purpose in ensuring the reliability of the 'self_improve' function, it is likely to be retained in the codebase."
survived,"def test_startup_requires_token(monkeypatch: pytest.MonkeyPatch) -> None:
    monkeypatch.delenv(""API_TOKEN"", raising=False)
    with pytest.raises(RuntimeError):
        _run_client()

    monkeypatch.setenv(""API_TOKEN"", ""changeme"")
    with pytest.raises(RuntimeError):
        _run_client()",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_api_token_required.py,,1,1.522997951276035e-08,"The method `test_startup_requires_token` is a test function that uses the `monkeypatch` fixture from `pytest` to manipulate environment variables and test the behavior of the `_run_client` function. It checks that a `RuntimeError` is raised when the `API_TOKEN` environment variable is not set or is set to a placeholder value. This is a valid and useful test to ensure that the application behaves correctly when required environment variables are missing or incorrect. Therefore, it is likely to be retained as part of the test suite."
survived,"    def __class_getitem__(cls, item: NamedArrayAxesSpec) -> typing.Any:
        axes = _parse_namedarray_axes(item)
        return typing.Annotated[NamedArray, axes]
",src/haliax/core.py,Named,1,3.2241866333029355e-08,"The method `__class_getitem__` is a special method in Python that allows a class to define behavior for when it is accessed with the subscript notation (e.g., `ClassName[...]`). This is particularly useful for creating classes that behave like generic types or for implementing custom behavior when accessing class-level items. The method is part of the Python data model and is used in modern Python code, especially with the introduction of PEP 560 which improved support for generic types. Given its utility and relevance in type hinting and generic programming, it is likely to be retained in the codebase."
survived,"    def is_git_ignored(p: Path) -> bool:
        try:
            result = subprocess.run(
                [""git"", ""check-ignore"", ""-q"", str(p.relative_to(repo_root))],
                cwd=repo_root,
            )
            return result.returncode == 0
        except Exception:
            return False
",scripts/verify_disclaimer_snippet.py,,1,1.6052280526088547e-09,"The method `is_git_ignored` is a utility function that checks if a given file path is ignored by Git. This is a useful function for developers working with Git repositories, as it allows them to programmatically determine if a file is being ignored by Git's ignore rules. The function uses the `git check-ignore` command, which is a standard way to check ignore status in Git, and handles exceptions gracefully by returning `False` if an error occurs. This functionality is likely to be useful in various scenarios, such as in build scripts, deployment processes, or development tools that need to interact with Git repositories. Therefore, the method is likely to be retained in the codebase."
survived,"    def test_cli_invalid_port_error(self) -> None:
        with patch.dict(os.environ, {}, clear=True):
            with self.assertRaises(SystemExit):
                edge_runner.parse_args([""--port"", ""0""])
",tests/test_edge_runner_cli.py,TestParseArgs,1,2.0611536181902033e-09,"The method 'test_cli_invalid_port_error' is a unit test designed to verify that the 'edge_runner.parse_args' function raises a 'SystemExit' exception when an invalid port number (in this case, '0') is provided. This is a valid and useful test case to ensure that the command-line interface handles invalid input correctly. Therefore, it is likely to be retained in the codebase."
survived,"def test_execute_and_collect_propagates_error(monkeypatch, tmp_path):
    fake_exec = MagicMock()
    fake_exec.run_tests.side_effect = rc_mod.SandboxExecutionError(""boom"")
    module = ResultCollectionModule(fake_exec)
    with pytest.raises(rc_mod.SandboxExecutionError):
        module.execute_and_collect(tmp_path)",tests/unit/test_result_collection_module.py,,1,3.850741907939403e-09,"The method 'test_execute_and_collect_propagates_error' is a unit test designed to verify that the 'execute_and_collect' method correctly propagates an error when 'run_tests' raises a 'SandboxExecutionError'. This is a typical pattern in testing to ensure that exceptions are handled as expected. Such tests are crucial for maintaining code reliability and ensuring that error handling is properly implemented. Therefore, this method is likely to be retained as it serves an important role in the test suite."
survived,"    def __init__(self, execution_module: Optional[ExecutionModule] = None) -> None:
        self.execution_module = execution_module or ExecutionModule()
",src/meta_agent/evaluation/result_collection.py,ResultCollectionModule,1,1.522997951276035e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. It initializes an instance of the class with a default or provided execution module. This is a common and necessary pattern in Python to ensure that objects are properly set up with their required components. Therefore, it is unlikely to be deleted as it serves a crucial role in the class's functionality."
survived,"def _adk_available() -> bool:
    for name in (""google_adk"", ""google.adk""):
        try:
            spec = importlib.util.find_spec(name)
        except ValueError:
            spec = None
        if spec is None:
            continue
        mod = importlib.import_module(name)
        if hasattr(mod, ""Router""):
            return True
    return False
",tests/test_external_integrations.py,,1,8.152020648014727e-09,"The method `_adk_available` is a utility function that checks for the availability of a specific module (either 'google_adk' or 'google.adk') and whether it contains a 'Router' attribute. This kind of function is useful for conditional imports and feature toggling based on the presence of certain modules. Such utility functions are common in codebases that need to maintain compatibility with optional dependencies or different versions of libraries. Therefore, it is likely to be retained as it serves a practical purpose in ensuring the code can adapt to different environments."
survived,"def _oai_available() -> bool:
    for name in (""openai_agents"", ""agents""):
        try:
            spec = importlib.util.find_spec(name)
        except ValueError:
            spec = None
        if spec is None:
            continue
        mod = importlib.import_module(name)
        if Version(getattr(mod, ""__version__"", ""0"")) >= Version(""0.0.17""):
            return True
    return False
",tests/test_external_integrations.py,,1,1.8189616842444243e-09,"The method `_oai_available` is a utility function that checks for the availability of certain modules and their versions. It is useful for ensuring compatibility and functionality of a larger system that depends on these modules. Such utility functions are often retained because they encapsulate a specific check that might be reused or needed for maintaining the system's integrity. Unless there is a significant change in the system's architecture or the modules it depends on, this method is likely to survive."
survived,"def zero():
    return Pt(x=0.0, y=0.0, inf=True)
",tests/rosetta/transpiler/Python/elliptic-curve-arithmetic.py,,1,1.3440409770490404e-08,"The method 'zero' is a simple utility function that returns a new instance of a class 'Pt' with specific default values. Such utility functions are often useful in codebases for creating standardized objects with default properties. Unless the 'Pt' class or the specific use case for this method is removed or refactored, this method is likely to survive as it provides a clear and concise way to create a 'Pt' object with default values."
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    s = """"
    s2 = """"
    s = """"
    print((1 if s == """" else 0))
    print((1 if len(s) == 0 else 0))
    print((1 if s != """" else 0))
    print((1 if len(s) != 0 else 0))
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/empty-string-1.py,,0,0.9999999468421502,"The method is likely to be deleted because it doesn't perform any meaningful operations. It initializes some variables, performs redundant checks on an empty string, and prints the results. The memory and time benchmarking is also not useful in this context as the operations are trivial. Overall, the function doesn't provide any valuable functionality or insights, making it a candidate for deletion."
survived,"def log2(x):
    k = 0.0
    v = x
    while v >= 2.0:
        v = v / 2.0
        k = k + 1.0
    while v < 1.0:
        v = v * 2.0
        k = k - 1.0
    z = (v - 1.0) / (v + 1.0)
    zpow = z
    sum = z
    i = 3
    while i <= 9:
        zpow = zpow * z * z
        sum = sum + zpow / (float(i))
        i = i + 2
    ln2 = 0.6931471805599453
    return k + 2.0 * sum / ln2
",tests/rosetta/transpiler/Python/entropy-2.py,,0,0.9999982396568657,"The method implements a custom algorithm to calculate the base-2 logarithm of a number. While it is a valid implementation, it is not as efficient or accurate as using built-in functions like math.log2 in Python, which are optimized and tested for performance and precision. Given the availability of such built-in functions, this custom implementation is likely to be considered redundant and unnecessary in most practical applications, leading to its deletion."
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    print(str(H(""1223334444"")))
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/entropy-1.py,,1,8.152020648014727e-09,"The method 'main' is a complete and functional piece of code that performs a specific task: it benchmarks the execution time and memory usage of a function 'H' with a given input. It uses standard libraries like 'resource' and 'json', and the code is structured to provide useful output in a JSON format. There is no indication that this method is redundant or obsolete, and it serves a clear purpose in performance measurement. Therefore, it is likely to be retained in the codebase."
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    cells = 20
    generations = 9
    print(""Single 1, rule 90:"")
    state = singleInit(cells)
    elem(90, cells, generations, state)
    print(""Random intial state, rule 30:"")
    state = randInit(cells, 3)
    elem(30, cells, generations, state)
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/elementary-cellular-automaton.py,,1,9.931195248674785e-08,"The method is a main function that serves as an entry point for a script. It initializes some variables, prints some information, and calls other functions to perform tasks. The method also benchmarks the execution time and memory usage, which can be useful for performance analysis. These characteristics suggest that the method is functional and serves a purpose in the context of the script. Therefore, it is likely to be retained."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/enumerations-2.py,,1,1.275190675769241e-07,"The method _now() is a utility function that generates a pseudo-random number based on a global seed if it is set, or returns the current time in nanoseconds if not. This kind of function can be useful in scenarios where deterministic behavior is needed for testing or simulation purposes. The use of a global seed allows for repeatable results, which is a common requirement in testing environments. Since this function provides a specific utility that can be useful in various contexts, it is likely to be retained in the codebase."
survived,"def fromY(y):
    return Pt(x=cbrtApprox(y * y - bCoeff), y=y, inf=False)
",tests/rosetta/transpiler/Python/elliptic-curve-arithmetic.py,,1,5.905303995456778e-10,"The method 'fromY' appears to be a utility function that constructs an object of type 'Pt' using a given 'y' value. It calculates the 'x' value using a cube root approximation function 'cbrtApprox' and a coefficient 'bCoeff'. The method is straightforward and likely serves a specific purpose in the context of the codebase, such as creating points or objects with specific properties. Without additional context indicating that this method is redundant or replaced, it is reasonable to assume it will survive."
survived,"def add(a, b):
    return a + b
",tests/rosetta/transpiler/Python/element-wise-operations.py,,1,8.152020648014727e-09,"The method 'add' is a simple and fundamental utility function that performs addition of two numbers. Such basic arithmetic functions are commonly used in various programming tasks and are unlikely to be deleted unless they are redundant or replaced by a more comprehensive library. However, given its simplicity and utility, it is more likely to be retained for its straightforward functionality."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/ekg-sequence-convergence.py,,1,3.2241866333029355e-08,"The method `_now()` is a utility function that generates a pseudo-random number based on a seed if `_now_seeded` is True, or returns the current time in nanoseconds otherwise. This kind of function can be useful in scenarios where deterministic behavior is needed for testing or simulation purposes, and non-deterministic behavior is needed in other cases. The function is simple, serves a clear purpose, and does not have any obvious issues or redundancies. Therefore, it is likely to be retained in the codebase."
survived,"def randInit(cells, seed):
    s = """"
    val = seed
    i = 0
    while i < cells:
        val = (val * 1664525 + 1013904223) % 2147483647
        if val % 2 == 0:
            s = s + ""0""
        else:
            s = s + ""1""
        i = i + 1
    return s
",tests/rosetta/transpiler/Python/elementary-cellular-automaton.py,,1,7.194132978569833e-09,"The method 'randInit' is a simple random binary string generator based on a linear congruential generator (LCG) algorithm. It takes two parameters: 'cells', which determines the length of the output string, and 'seed', which initializes the random number generation. The method is straightforward, performs its intended function, and does not have any apparent issues or inefficiencies. Such utility functions are often useful in various applications, such as simulations or testing, where random binary data is needed. Therefore, it is likely to be retained in the codebase."
survived,"            def passwords_per_seconds(self, seconds):
                return 0
",btcrecover/test/test_passwords.py,TestOuterIterations.DummyWallet,0,0.9999999530883621,"The method 'passwords_per_seconds' is currently implemented to always return 0, which suggests it is not performing any meaningful computation or providing useful functionality. Without additional context or future plans to implement a proper calculation, this method is likely to be considered redundant or unnecessary. Therefore, it is likely to be deleted unless there is a specific reason to keep it as a placeholder for future development."
survived,"def test_load_gitignore_as_context_rules_spaces_and_comments(tmp_path: Path):
    """"""Ensure gitignore lines are converted with spaces preserved and comments ignored.""""""
    gi_file = tmp_path / "".gitignore""
    gi_file.write_text(
        ""\n"".join(
            [
                ""# a comment"",
                ""foo.py"",
                ""!bar.py"",
                "" baz.txt"",
                ""trail.txt   "",
                ""\\#literal"",
                """",
            ]
        ),
        encoding=""utf-8"",
    )

    rules = load_gitignore_as_context_rules(gi_file)

    assert rules == [
        ""!foo.py"",
        ""bar.py"",
        ""! baz.txt"",
        ""!trail.txt   "",
        ""!\\#literal"",
    ]
",tests/test_config_system.py,,1,1.522997951276035e-08,"The method is a test function that verifies the behavior of a function `load_gitignore_as_context_rules`. It checks if the function correctly processes a `.gitignore` file by preserving spaces and ignoring comments. This is a useful test to ensure the function behaves as expected, especially in handling edge cases like spaces and comments. Such tests are crucial for maintaining code quality and reliability, so it is likely to be retained."
survived,"    def test_generate_plan(self) -> None:
        with tempfile.TemporaryDirectory() as tmp:
            ledger = Path(tmp) / 'plan.json'
            result = subprocess.run(
                [sys.executable, STUB, '--alpha', 'test opportunity', '--ledger', str(ledger)],
                capture_output=True,
                text=True,
            )
            self.assertEqual(result.returncode, 0, result.stderr)
            self.assertTrue(ledger.exists())
            data = json.loads(ledger.read_text())
            self.assertIsInstance(data, dict)
            self.assertIn('steps', data)
",tests/test_alpha_conversion_stub.py,TestAlphaConversionStub,1,1.3440409770490404e-08,"The method `test_generate_plan` is a unit test designed to verify the functionality of a script that generates a plan and writes it to a JSON file. It uses a temporary directory to ensure no side effects on the file system, checks the return code of the subprocess to ensure it executed successfully, and validates the structure of the output JSON. These are all good practices for testing, and there is no indication of redundancy or obsolescence in the code. Therefore, it is likely to be maintained as part of the test suite."
survived,"    def test_stub_compiles(self):
        py_compile.compile(STUB, doraise=True)
",tests/test_alpha_opportunity_stub.py,TestAlphaOpportunityStub,1,2.2159489282323004e-08,"The method `test_stub_compiles` is a simple test function that checks if a given Python code (referred to as `STUB`) can be compiled without syntax errors. This is a basic yet useful test to ensure that the code is syntactically correct. Such tests are often used in development to catch syntax errors early in the development process. The method is straightforward, does not have any apparent issues, and serves a clear purpose in the context of testing. Therefore, it is likely to be retained in the codebase."
survived,"def test_cli_overrides_env(monkeypatch: pytest.MonkeyPatch) -> None:
    """"""CLI options should override preset environment variables.""""""
    if MODULE in sys.modules:
        del sys.modules[MODULE]
    mod = importlib.import_module(MODULE)

    monkeypatch.setattr(mod, ""check_env"", types.SimpleNamespace(main=lambda *_a, **_k: None), raising=False)

    monkeypatch.setenv(""OPENAI_API_KEY"", ""env-key"")
    monkeypatch.setenv(""ADK_HOST"", ""http://env-adk:8"")
    monkeypatch.setenv(""A2A_PORT"", ""1234"")
    monkeypatch.setenv(""A2A_HOST"", ""env-host"")
    monkeypatch.setenv(""LOCAL_LLM_URL"", ""http://env-llm"")
    monkeypatch.setenv(""LLAMA_MODEL_PATH"", ""/env/model.gguf"")
    monkeypatch.setenv(""LLAMA_N_CTX"", ""99"")

    captured: dict[str, Any] = {}

    async def _llm(_: float) -> str:
        captured[""api_key""] = os.getenv(""OPENAI_API_KEY"")
        captured[""local_llm_url""] = os.getenv(""LOCAL_LLM_URL"")
        captured[""llama_model_path""] = os.getenv(""LLAMA_MODEL_PATH"")
        captured[""llama_n_ctx""] = os.getenv(""LLAMA_N_CTX"")
        return ""ok""

    class DummyADK:
        def __init__(self, host: str) -> None:  # pragma: no cover - init only
            captured[""adk_host""] = host

    class DummySock:
        def __init__(self, host: str, port: int, app_id: str) -> None:
            captured[""a2a""] = f""{host}:{port}""  # pragma: no cover - record args

        def start(self) -> None:  # pragma: no cover - unused
            pass

        def stop(self) -> None:  # pragma: no cover - unused
            pass

        def sendjson(self, *_a: object, **_kw: object) -> None:  # pragma: no cover - unused
            pass

    monkeypatch.setattr(mod, ""_llm_comment"", _llm)
    monkeypatch.setattr(mod, ""ADKClient"", DummyADK)
    monkeypatch.setattr(mod, ""A2ASocket"", DummySock)

    asyncio.run(
        mod.main(
            [
                ""--cycles"",
                ""1"",
                ""--interval"",
                ""0"",
                ""--openai-api-key"",
                ""cli-key"",
                ""--adk-host"",
                ""http://cli-adk:9"",
                ""--a2a-port"",
                ""7777"",
                ""--a2a-host"",
                ""cli-host"",
                ""--local-llm-url"",
                ""http://cli-llm"",
                ""--llama-model-path"",
                ""/cli/model.gguf"",
                ""--llama-n-ctx"",
                ""120"",
            ]
        )
    )

    assert captured[""api_key""] == ""cli-key""
    assert captured[""adk_host""] == ""http://cli-adk:9""
    assert captured[""a2a""] == ""cli-host:7777""
    assert captured[""local_llm_url""] == ""http://cli-llm""
    assert captured[""llama_model_path""] == ""/cli/model.gguf""
    assert captured[""llama_n_ctx""] == ""120""
",tests/test_alpha_agi_business_3_v1.py,,1,6.023574641292144e-08,"The method `test_cli_overrides_env` is a test function that verifies the behavior of a command-line interface (CLI) in overriding environment variables. This is a common and important test case in software development to ensure that user-specified CLI options take precedence over default or environment-configured settings. The function uses `monkeypatch` to simulate different environments and checks if the CLI arguments correctly override these settings. This kind of test is crucial for maintaining the reliability and predictability of software that relies on both environment variables and CLI inputs. Therefore, it is unlikely to be deleted as it serves a critical role in ensuring the software behaves as expected in different configurations."
survived,"            def __init__(self) -> None:
                self.instructions: list[Any] = []
",tests/test_ledger_broadcast.py,DummyTx,1,1.1861120010657661e-08,"The method is a constructor for a class, indicated by the name `__init__`. Constructors are essential for initializing new objects in object-oriented programming. The method initializes an instance variable `instructions` as an empty list, which is a common practice to set up the initial state of an object. Therefore, this method is crucial for the class's functionality and is unlikely to be deleted."
survived,"def test_broadcast_merkle_root_logs_on_error() -> None:
    with tempfile.TemporaryDirectory() as tmp:
        ledger = Ledger(os.path.join(tmp, ""l.db""), rpc_url=""http://rpc.test"", broadcast=True)
        env = messaging.Envelope(sender=""a"", recipient=""b"", payload={""v"": 1}, ts=0.0)
        ledger.log(env)
        root = ledger.compute_merkle_root()

        captured: dict[str, Any] = {}

        class DummyClient:
            def __init__(self, url: str) -> None:
                captured[""url""] = url

            async def send_transaction(self, tx: Any, *args: Any) -> None:
                captured[""root""] = tx.instructions[0].data.decode()
                raise RuntimeError(""fail"")

            async def close(self) -> None:
                pass

        class DummyTx:
            def __init__(self) -> None:
                self.instructions: list[Any] = []

            def add(self, instr: Any) -> ""DummyTx"":
                self.instructions.append(instr)
                return self

        class DummyInstr:
            def __init__(self, program_id: Any, data: bytes, keys: list[Any]):
                self.data = data

        class DummyPk:
            def __init__(self, val: str) -> None:
                pass

        with (
            mock.patch.dict(
                sys.modules,
                {
                    ""solana"": ModuleType(""solana""),
                    ""solana.rpc"": ModuleType(""solana.rpc""),
                    ""solana.rpc.async_api"": ModuleType(""solana.rpc.async_api""),
                },
            ),
            mock.patch(""solana.rpc.async_api.AsyncClient"", DummyClient, create=True),
            mock.patch.object(insight_logging, ""AsyncClient"", DummyClient, create=True),
            mock.patch.object(insight_logging, ""Transaction"", DummyTx, create=True),
            mock.patch.object(insight_logging, ""TransactionInstruction"", DummyInstr, create=True),
            mock.patch.object(insight_logging, ""PublicKey"", DummyPk, create=True),
            mock.patch.object(insight_logging, ""_log"") as log,
        ):
            asyncio.run(ledger.broadcast_merkle_root())

        assert captured[""root""] == root
        log.warning.assert_called()",tests/test_ledger_broadcast.py,,1,6.023574641292144e-08,"The method `test_broadcast_merkle_root_logs_on_error` is a unit test designed to verify the behavior of the `broadcast_merkle_root` function when an error occurs. It uses mock objects to simulate the environment and checks if the appropriate logging occurs when a RuntimeError is raised. This is a typical pattern in testing to ensure robustness and error handling in code. Since it is a test method, it is unlikely to be deleted unless the functionality it tests is removed or significantly altered. Therefore, it is more likely to survive."
survived,"            def __init__(self, program_id: Any, data: bytes, keys: list[Any]):
                self.data = data
",tests/test_ledger_broadcast.py,DummyInstr,1,1.1253518384332553e-07,"The method is a constructor (__init__) which is essential for initializing objects in Python. It sets up the initial state of an object by assigning values to instance variables. In this case, it initializes 'data' and potentially other attributes (though not shown in the snippet). Constructors are fundamental to object-oriented programming in Python, and there is no indication that this specific constructor is redundant or unnecessary. Therefore, it is unlikely to be deleted."
survived,"def test_broadcast_merkle_root_sends_transaction() -> None:
    with tempfile.TemporaryDirectory() as tmp:
        ledger = Ledger(os.path.join(tmp, ""l.db""), rpc_url=""http://rpc.test"", broadcast=True)
        env = messaging.Envelope(sender=""a"", recipient=""b"", payload={""v"": 1}, ts=0.0)
        ledger.log(env)
        root = ledger.compute_merkle_root()

        calls: list[tuple[str, Any]] = []

        class DummyClient:
            def __init__(self, url: str) -> None:
                calls.append((""url"", url))

            async def send_transaction(self, tx: Any, *args: Any) -> None:
                calls.append((""sent"", tx.instructions[0].data.decode()))

            async def close(self) -> None:
                pass

        class DummyTx:
            def __init__(self) -> None:
                self.instructions: list[Any] = []

            def add(self, instr: Any) -> ""DummyTx"":
                self.instructions.append(instr)
                return self

        class DummyInstr:
            def __init__(self, program_id: Any, data: bytes, keys: list[Any]):
                self.data = data

        class DummyPk:
            def __init__(self, val: str) -> None:
                pass

        with (
            mock.patch.dict(
                sys.modules,
                {
                    ""solana"": ModuleType(""solana""),
                    ""solana.rpc"": ModuleType(""solana.rpc""),
                    ""solana.rpc.async_api"": ModuleType(""solana.rpc.async_api""),
                },
            ),
            mock.patch(""solana.rpc.async_api.AsyncClient"", DummyClient, create=True),
            mock.patch.object(insight_logging, ""AsyncClient"", DummyClient, create=True),
            mock.patch.object(insight_logging, ""Transaction"", DummyTx, create=True),
            mock.patch.object(insight_logging, ""TransactionInstruction"", DummyInstr, create=True),
            mock.patch.object(insight_logging, ""PublicKey"", DummyPk, create=True),
        ):
            asyncio.run(ledger.broadcast_merkle_root())

        assert (""url"", ""http://rpc.test"") in calls
        assert (""sent"", root) in calls
",tests/test_ledger_broadcast.py,,1,3.653482080241728e-08,"The method is a test function that verifies the functionality of broadcasting a Merkle root by simulating a transaction send. It uses mock objects to replace actual network calls, ensuring the test is isolated and does not depend on external systems. This is a common practice in unit testing to ensure code reliability and correctness. The method is likely to survive because it is essential for maintaining the integrity of the codebase by ensuring that the broadcast functionality works as expected."
survived,"            def __init__(self, url: str) -> None:
                calls.append((""url"", url))
",tests/test_ledger_client_close.py,DummyClient,1,4.4508487281649027e-07,"The method is a constructor for a class, indicated by the name `__init__`. Constructors are essential for initializing new objects in object-oriented programming. The presence of the `url` parameter suggests that this constructor is designed to initialize an object with a specific URL, which is likely important for the functionality of the class. Additionally, the line `calls.append((""url"", url))` suggests that this constructor is tracking or logging the initialization calls, which could be useful for debugging or analytics purposes. Therefore, it is unlikely that this method will be deleted as it serves a fundamental role in object creation and possibly in logging or tracking."
survived,"            def add(self, instr: Any) -> ""DummyTx"":
                self.instructions.append(instr)
                return self
",tests/test_ledger_client_close.py,DummyTx,1,5.905303995456778e-10,"The method 'add' is a simple utility function that appends an instruction to a list and returns the instance itself, allowing for method chaining. This is a common pattern in Python for building up a sequence of operations in a fluent interface style. The method is straightforward, performs a useful operation, and is likely to be used in contexts where instructions need to be dynamically added to a transaction or similar object. There is no indication that this method is redundant or unnecessary, so it is likely to be retained in the codebase."
survived,"def load_ipython_extension(ip):
    ip.register_magics(MochiMagics)",tools/notebook/mochi_magic.py,,1,3.3982678079468468e-09,"The method `load_ipython_extension` is a standard way to extend IPython with custom magic commands. It is a well-established pattern used in IPython extensions to register new magics, and there is no indication that this pattern is deprecated or discouraged. Therefore, it is likely to survive as it is a necessary part of extending IPython's functionality."
survived,"    def convert(self, node):
        self.visit(node)
        if self.lines and self.lines[-1] != """":
            self.lines.append("""")
        return ""\n"".join(self.lines)
",tools/any2mochi/py_simple.py,Conv,1,2.3355930333443423e-09,"The method 'convert' is a utility function that processes a 'node' by visiting it and then formats the result into a string. It checks if there are any lines collected and ensures the last line is not empty before appending a newline. This kind of method is common in code that deals with parsing or transforming data structures into a string format, such as in compilers or interpreters. The method is concise, performs a clear function, and does not have any obvious issues or redundancies. Therefore, it is likely to be useful and retained in the codebase."
survived,"def test_from_client_deprecation_warning():
    """"""Test that FastMCP.from_client raises a deprecation warning.""""""
    server = FastMCP(""TestServer"")
    with pytest.warns(DeprecationWarning, match=""from_client""):
        FastMCP.from_client(Client(server))",tests/test_deprecated.py,,0,0.9999998724809324,"The method is specifically designed to test for a deprecation warning, indicating that the 'from_client' method is likely deprecated or will be deprecated soon. This suggests that the method is being phased out and will eventually be removed, leading to its deletion."
survived,"    async def delete_item(item_id: int) -> bool:
        """"""Delete item.""""""
        return True
",tests/test_mutability.py,,0,0.999998790133938,"The method 'delete_item' is a simple asynchronous function that takes an item ID as an argument and returns True, indicating that the item has been deleted. However, the method lacks any actual implementation for deleting an item, such as interacting with a database or an API. Without any real functionality, the method is not useful in its current state. Therefore, it is likely to be deleted unless further developed to include the necessary logic for item deletion."
survived,"async def delete_customer(customer_id: int) -> bool:
    """"""Delete a customer.""""""
    return CUSTOMERS.pop(customer_id, None) is not None
",examples/mutable_crud/app.py,,1,1.1861120010657661e-08,"The method 'delete_customer' is a straightforward utility function that attempts to remove a customer from a dictionary named CUSTOMERS using the provided customer_id. It returns a boolean indicating whether the deletion was successful. This is a common operation in applications that manage collections of data, and the method is simple, clear, and performs a necessary function. There is no indication of redundancy or inefficiency that would warrant its deletion. Therefore, it is likely to be retained."
survived,"    async def update_item(item_id: int, patch: Item.PatchModel) -> Item:
        """"""Update item.""""""
        return Item(id=item_id, name=patch.name or ""n"")
",tests/test_mutability.py,,1,3.850741907939403e-09,"The method 'update_item' is a simple asynchronous function that updates an item based on a given patch model. It is likely to survive because it performs a basic and necessary operation in many applications: updating an item. The method is straightforward, uses modern async syntax, and follows a common pattern in CRUD operations, making it a useful and reusable piece of code."
survived,"        def _is_mutable(f: Any) -> bool:
            extra = getattr(f, ""json_schema_extra"", None)
            if extra is None:
                info = getattr(f, ""field_info"", None)
                extra = getattr(info, ""extra"", {}) if info is not None else {}
            return extra.get(""mutable"") is True
",src/enrichmcp/entity.py,EnrichModel,1,5.60279640614594e-09,"The method `_is_mutable` is a utility function that checks if a given object `f` has a mutable attribute set to True. It does this by looking for a `json_schema_extra` attribute or a `field_info` attribute with an `extra` dictionary. This kind of utility function is often useful in scenarios where objects need to be checked for certain properties or configurations, especially in frameworks or libraries dealing with data validation or schema management. Since it provides a specific and potentially reusable functionality, it is likely to be retained in the codebase unless the overall design or requirements change significantly."
survived,"    def update_note(self, note_id: str, patch: dict[str, object]) -> MemoryNote:
        note = self.get_note(note_id)
        if note is None:
            raise KeyError(note_id)
        updated = note.model_copy(update=patch)
        self.store.save(self.name, updated)
        return updated
",examples/basic_memory/memory.py,MemoryProject,1,1.493094675974231e-10,"The method 'update_note' is likely to survive because it performs a common and necessary operation in many applications: updating an existing note with new data. It includes error handling for cases where the note does not exist, uses a method to apply updates, and saves the updated note, which are all standard practices in maintaining data integrity and functionality. Additionally, the method is concise and clear in its purpose, making it a valuable part of the codebase."
survived,"    def delete(self, project: str, note_id: str) -> bool:
        """"""Remove the note if present and return ``True`` on success.""""""
",examples/basic_memory/memory.py,MemoryStore,1,4.944450477491054e-09,"The method 'delete' is a common and essential operation in many applications, especially those dealing with data management, such as note-taking apps. The method's purpose is to remove a note identified by 'note_id' from a project, which is a fundamental feature for maintaining and organizing data. The method is likely to be retained because it provides necessary functionality for users to manage their notes effectively. Without such a method, users would be unable to delete unwanted or outdated notes, leading to clutter and inefficiency."
survived,"def auroc(truth: list[bool], scores: list[float]) -> float:
    """"""Compute AUROC using the rank method.""""""
    order = sorted(range(len(scores)), key=lambda i: scores[i])
    rank_sum = 0.0
    pos = 0
    for r, i in enumerate(order, 1):
        if truth[i]:
            rank_sum += r
            pos += 1
    neg = len(scores) - pos
    if pos == 0 or neg == 0:
        return 1.0
    return (rank_sum - pos * (pos + 1) / 2) / (pos * neg)
",src/simulation/replay.py,,1,1.2501528648238603e-09,"The method 'auroc' is a well-defined function that calculates the Area Under the Receiver Operating Characteristic curve using the rank method. This is a standard statistical measure used in machine learning and data analysis to evaluate the performance of binary classification models. The code is clear, efficient, and implements a common algorithm correctly. There is no indication of redundancy or obsolescence, and it serves a useful purpose in its context. Therefore, it is likely to be retained."
survived,"def _append_metrics(path: Path, name: str, f1: float, auc: float, lead: float) -> None:
    import csv

    exists = path.exists()
    with path.open(""a"", newline="""", encoding=""utf-8"") as fh:
        writer = csv.writer(fh)
        if not exists:
            writer.writerow(_def_fields)
        writer.writerow([name, f1, auc, lead])
",src/simulation/replay.py,,1,2.1724399346070676e-10,"The method '_append_metrics' is a utility function designed to append metrics to a CSV file. It checks if the file exists, and if not, it writes a header before appending the data. This is a common and useful functionality in data processing and logging, especially in machine learning and data analysis workflows where tracking metrics is crucial. The method is well-defined, uses standard libraries, and serves a clear purpose. There is no indication that this method is redundant or obsolete, so it is likely to be retained."
survived,"    def run_find_neighbors(self):
        """"""Search neighbors using the hashed grid.""""""
        n = self.sorted_position.shape[0]
        max_n = self.config.get(""max_neighbor_count"", 50)
        neighbors = torch.full((n, max_n), -1, dtype=torch.long, device=self.device)
        cell_id = self.particle_index[:, 0]
        pos = self.sorted_position[:, :3]
        gsx = self.config[""grid_cells_x""]
        gsy = self.config[""grid_cells_y""]
        gsz = self.config[""grid_cells_z""]
        for p in range(n):
            cid = cell_id[p].item()
            gz = cid // (gsx * gsy)
            rem = cid % (gsx * gsy)
            gy = rem // gsx
            gx = rem % gsx
            idx = 0
            for dz in (-1, 0, 1):
                nz = gz + dz
                if nz < 0 or nz >= gsz:
                    continue
                for dy in (-1, 0, 1):
                    ny = gy + dy
                    if ny < 0 or ny >= gsy:
                        continue
                    for dx in (-1, 0, 1):
                        nx = gx + dx
                        if nx < 0 or nx >= gsx:
                            continue
                        cell = nx + ny * gsx + nz * gsx * gsy
                        start = self.grid_cell_index_fixed[cell]
                        end = self.grid_cell_index_fixed[cell + 1]
                        if start < 0 or end <= start:
                            continue
                        ids = self.particle_index[start:end, 1]
                        for j in ids:
                            j = j.item()
                            if j == self.particle_index[p, 1].item():
                                continue
                            if torch.norm(pos[p] - pos[j]) < self.config[""h""]:
                                if idx < max_n:
                                    neighbors[p, idx] = j
                                    idx += 1
        self.neighbor_map = neighbors
",pytorch_solver.py,PytorchSolver,1,9.237449576640118e-09,"The method 'run_find_neighbors' is a core part of a particle simulation system, likely used for finding neighboring particles within a certain distance. This is a fundamental operation in many physics simulations, such as fluid dynamics or particle systems, where interactions between particles are calculated based on proximity. The method is well-structured, uses efficient indexing, and leverages torch for tensor operations, indicating it is optimized for performance. Given its importance in simulations and the lack of any deprecated or redundant code, it is unlikely to be deleted."
survived,"    def run_compute_pressure(self):
        """"""Compute pressure from density error.""""""
        self.pressure = self.config[""delta""] * (self.rho - self.config[""rho0""])
",pytorch_solver.py,PytorchSolver,1,2.0611536181902033e-09,"The method 'run_compute_pressure' is a simple and straightforward calculation method that computes pressure based on a given formula. It is likely to be a core part of a larger system where pressure calculations are necessary, especially if the system deals with physical simulations or models. The method is concise, has a clear purpose, and does not have any apparent issues or redundancies that would warrant its removal. Therefore, it is likely to be retained in the codebase."
survived,"    def __init__(self, position, velocity, config):
        self.device = torch.device(config.get(""device"", ""cpu""))
        self.config = config
        self.position = torch.as_tensor(
            position, dtype=torch.float32, device=self.device
        )
        self.velocity = torch.as_tensor(
            velocity, dtype=torch.float32, device=self.device
        )
        self.acceleration = torch.zeros_like(self.position)
        self.pressure = torch.zeros(self.position.shape[0], device=self.device)
        self.rho = torch.zeros(self.position.shape[0], device=self.device)

        self.particle_index = None
        self.sorted_position = None
        self.sorted_velocity = None
        self.particle_index_back = None
        self.grid_cell_index = None
        self.grid_cell_index_fixed = None
        self.neighbor_map = None
",pytorch_solver.py,PytorchSolver,1,1.8553915987649156e-07,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class with specific attributes. It sets up the initial state of an object, including device configuration, position, velocity, and other attributes. Such methods are fundamental to object-oriented programming and are unlikely to be removed unless the class itself is deprecated or significantly refactored."
survived,"def convert_species_add(species_path, item_fields, pk_prefix, parent=None):
    data = load_json(species_path)
    data.append({
        ""model"": ""api_v2.species"",
        ""pk"": f""{pk_prefix}_{slugify(item_fields['name'])}"",
        ""fields"": {
            ""name"": item_fields[""name""],
            ""desc"": item_fields[""desc""],
            ""document"": pk_prefix,
            ""subspecies_of"": parent,
        },
    })
    save_json(data, species_path)
",convert_missing.py,,1,2.998960815863541e-09,"The method 'convert_species_add' is likely to survive because it performs a specific and useful function: it loads a JSON file, appends a new species entry to it, and then saves the updated data back to the file. This functionality is essential for applications that manage species data, especially in a database or content management system context. The method is well-structured, uses clear parameter names, and follows a logical sequence of operations. Additionally, it uses helper functions like 'load_json', 'save_json', and 'slugify', which suggests modularity and reusability, making it a valuable part of a larger codebase."
survived,"def test_research_agent_emits_strategy(monkeypatch) -> None:
    cfg = config.Settings(bus_port=0, openai_api_key=""k"")
    bus = DummyBus(cfg)
    led = DummyLedger()
    agent = research_agent.ResearchAgent(bus, led)
    monkeypatch.setattr(random, ""random"", lambda: 0.5)
    env = messaging.Envelope(""planning"", ""research"", {""plan"": ""y""}, 0.0)
    asyncio.run(agent.handle(env))
    assert bus.published[-1][0] == ""strategy""
",tests/test_agent_handle_methods.py,,1,4.1399375473943306e-08,"The method `test_research_agent_emits_strategy` is a unit test designed to verify that the `ResearchAgent` correctly publishes a 'strategy' message when handling a specific envelope. This is a typical use case for unit tests, which are crucial for ensuring code reliability and correctness. The use of `monkeypatch` to control randomness and the assertion at the end to check the expected behavior are standard practices in testing. Given the importance of testing in software development, especially for complex systems involving messaging and asynchronous operations, it is unlikely that this method will be deleted. Instead, it is more likely to be maintained or updated as the codebase evolves."
survived,"    def __init__(self, settings: config.Settings) -> None:
        self.settings = settings
        self.published: list[tuple[str, messaging.Envelope]] = []
",tests/test_agent_handle_methods.py,DummyBus,1,1.637377179507321e-07,"The method is a constructor (__init__) for a class, which is essential for initializing class instances. It sets up the initial state of the object by assigning the 'settings' parameter to an instance variable and initializing an empty list 'published'. Constructors are fundamental to object-oriented programming and are unlikely to be deleted unless the class itself is being removed or significantly refactored."
survived,"def test_bundle_generator_creates_files(tmp_path: Path) -> None:
    gen = BundleGenerator(tmp_path)
    metadata = gen.generate(
        agent_code=""print('agent')"",
        tests={""test_sample.py"": ""def test_sample():\n    assert True""},
        requirements=[""foo==1.0""],
        readme=""# Hello"",
        guardrails_manifest=""{}"",
    )

    assert (tmp_path / ""agent.py"").exists()
    assert (tmp_path / ""tests"" / ""test_sample.py"").exists()
    assert (tmp_path / ""requirements.txt"").exists()
    assert (tmp_path / ""README.md"").exists()
    assert (tmp_path / ""guardrails"" / ""manifest.json"").exists()
    assert (tmp_path / ""traces"").is_dir()
    assert (tmp_path / ""bundle.json"").exists()

    with open(tmp_path / ""bundle.json"", encoding=""utf-8"") as f:
        data = json.load(f)
    assert data[""schema_version""] == BUNDLE_SCHEMA_VERSION
    checksums = data[""custom""][""checksums""]

    with open(tmp_path / ""agent.py"", encoding=""utf-8"") as f:
        expected = hashlib.sha256(f.read().encode(""utf-8"")).hexdigest()
    assert checksums[""agent.py""] == expected
",tests/test_bundle_generator.py,,1,9.931195248674785e-08,"The method is a well-structured test function that verifies the functionality of a BundleGenerator class. It checks if the generator creates the expected files and directories, and validates the contents of a JSON file. This is a typical unit test that ensures the correct behavior of the code, which is crucial for maintaining code quality and reliability. Such test functions are generally retained in the codebase to ensure ongoing functionality and to catch regressions, especially in a development environment where changes are frequent."
survived,"    def _write_file(self, relative: str | Path, content: str) -> str:
        path = self.bundle_dir / relative
        path.parent.mkdir(parents=True, exist_ok=True)
        with open(path, ""w"", encoding=""utf-8"") as f:
            f.write(content)
        return hashlib.sha256(content.encode(""utf-8"")).hexdigest()
",src/meta_agent/bundle_generator.py,BundleGenerator,1,3.850741907939403e-09,"The method '_write_file' is a utility function that writes content to a file and returns the SHA-256 hash of the content. This is a common and useful operation in many applications, especially those dealing with file management, data integrity, or caching. The method is well-structured, using pathlib for path operations and ensuring directories exist before writing. It also handles encoding explicitly, which is good practice. Given its utility and the fact that it doesn't have any apparent issues or redundancies, it is likely to be retained in the codebase."
survived,"    def force_garbage_collection(self):
        """"""
        强制垃圾回收并返回清理的对象数量
        """"""
        try:
            collected = gc.collect()
            logger.info(f""强制垃圾回收完成，清理了 {collected} 个对象"")
            return collected
        except Exception as e:
            logger.error(f""强制垃圾回收失败: {e}"")
            return 0
",app/helper/memory.py,MemoryHelper,1,1.0467401685178159e-08,"The method 'force_garbage_collection' is a utility function that forces garbage collection and logs the number of objects collected. This can be useful in scenarios where memory management is critical, and developers need to ensure that unused objects are cleaned up to free memory. The method also includes error handling, which makes it robust against potential exceptions during garbage collection. Given its utility in managing resources and ensuring application stability, it is likely to be retained in the codebase."
survived,"    def _write_python_objects_info(self, snapshot_file):
        """"""
        写入Python对象类型统计信息
        """"""
        # 获取当前tracemalloc统计
        current, peak = tracemalloc.get_traced_memory()
        
        # 获取所有对象
        all_objects = muppy.get_objects()
        sum1 = summary.summarize(all_objects)
        
        # 计算Python对象总内存
        python_total_mb = 0
        for line in summary.format_(sum1):
            if '|' in line and line.strip() and not line.startswith('=') and not line.startswith('-'):
                parts = line.split('|')
                if len(parts) >= 3:
                    try:
                        size_str = parts[2].strip()
                        if 'MB' in size_str:
                            size_mb = float(size_str.replace('MB', '').strip())
                            python_total_mb += size_mb
                    except:
                        pass

        with open(snapshot_file, 'a', encoding='utf-8') as f:
            f.write(""\n"" + ""="" * 80 + ""\n"")
            f.write(""Python内存使用情况:\n"")
            f.write(""-"" * 80 + ""\n"")
            f.write(f""tracemalloc当前内存: {current / 1024 / 1024:.2f} MB\n"")
            f.write(f""tracemalloc峰值内存: {peak / 1024 / 1024:.2f} MB\n"")
            f.write(f""Python对象总内存: {python_total_mb:.2f} MB\n"")
            f.write(f""未统计内存(可能为C扩展): {self._get_unaccounted_memory():.2f} MB\n"")
            
            f.write(""\n对象类型统计:\n"")
            f.write(""-"" * 80 + ""\n"")
            # 写入对象统计信息
            for line in summary.format_(sum1):
                f.write(line + ""\n"")
            
            f.flush()
",app/helper/memory.py,MemoryHelper,1,1.725782769012759e-08,"The method '_write_python_objects_info' is a utility function that writes memory usage statistics to a file. It uses the 'tracemalloc' and 'muppy' libraries to gather memory usage data and formats it for logging. This type of method is useful for debugging and monitoring memory usage in Python applications, especially in environments where memory management is critical. Therefore, it is likely to be retained for its utility in performance monitoring and debugging."
deleted,"    def correctness_reward(prompt, response, answer, state):
        """"""Check if the response contains correct information.""""""
        response_lower = response.lower()
        answer_lower = answer.lower()
        
        # Check for exact match (normalized)
        if answer_lower in response_lower:
            return 1.0
        
        # Check for key terms match
        answer_terms = set(answer_lower.split())
        response_terms = set(response_lower.split())
        
        # Remove common words
        common_words = {""the"", ""a"", ""an"", ""is"", ""are"", ""was"", ""were"", ""of"", ""in"", ""to"", ""for""}
        answer_terms = answer_terms - common_words
        response_terms = response_terms - common_words
        
        if answer_terms:
            overlap = len(answer_terms & response_terms) / len(answer_terms)
            return min(overlap * 1.5, 1.0)  # Boost overlap score, cap at 1.0
        
        return 0.0
",environments/truthful_qa/truthful_qa.py,,1,3.850741907939403e-09,"The method 'correctness_reward' is a utility function that evaluates the correctness of a response by checking for exact matches and key term overlaps with the expected answer. This type of functionality is often useful in applications involving natural language processing, such as chatbots or automated grading systems. The method is well-defined, with a clear purpose and logic that can be easily understood and potentially reused in various contexts. It is unlikely to be deleted as it provides a valuable mechanism for assessing response accuracy, which is a common requirement in many software systems."
survived,"def main():
    """"""Main function to run the example.""""""
    print(""Starting OpenAI o3 Responses API Example"")
    print(""="" * 60)
    
    try:
        results = run_example()
        
        print(f""\n{'='*60}"")
        print(""Example Summary"")
        print(f""{'='*60}"")
        
        for i, result in enumerate(results, 1):
            print(f""Scenario {i}: {result['action']}"")
        
        # End the trace
        agentops.end_trace(tracer, end_state=""Success"")
        
        # Validate the trace
        print(f""\n{'='*60}"")
        print(""Validating AgentOps Trace"")
        print(f""{'='*60}"")
        
        try:
            validation_result = agentops.validate_trace_spans(trace_context=tracer)
            agentops.print_validation_summary(validation_result)
            print(""✅ Example completed successfully!"")
        except agentops.ValidationError as e:
            print(f""❌ Error validating spans: {e}"")
            raise
            
    except Exception as e:
        print(f""❌ Example failed: {e}"")
        agentops.end_trace(tracer, end_state=""Error"")
        raise
",examples/openai/o3_responses_example.py,,1,3.653482080241728e-08,"The method 'main()' is a well-structured function that includes error handling, logging, and validation processes. It is likely part of a larger application or script that demonstrates the use of an API, possibly for educational or demonstration purposes. The function is complete, functional, and follows good coding practices, making it unlikely to be deleted unless the entire application is deprecated or significantly refactored."
survived,"    def test_package_exists_dependency_change(self, mock_config, mock_logger):
        """"""Test scenario 3: Package existed in database and changed its dependencies""""""

        # Setup existing package and dependencies
        existing_pkg_id = uuid4()
        dep1_id = uuid4()
        dep2_id = uuid4()
        dep3_id = uuid4()

        existing_package = Package(
            id=existing_pkg_id,
            derived_id=""pkgx/dep-pkg"",
            name=""dep-pkg"",
            package_manager_id=mock_config.pm_config.pm_id,
            import_id=""dep-pkg"",
            readme="""",
        )

        # Create dependency packages
        dep1_pkg = Package(
            id=dep1_id, derived_id=""pkgx/dep1"", name=""dep1"", import_id=""dep1""
        )
        dep2_pkg = Package(
            id=dep2_id, derived_id=""pkgx/dep2"", name=""dep2"", import_id=""dep2""
        )
        dep3_pkg = Package(
            id=dep3_id, derived_id=""pkgx/dep3"", name=""dep3"", import_id=""dep3""
        )

        # Create existing dependencies (dep1 as runtime, dep2 as build)
        existing_dep1 = LegacyDependency(
            package_id=existing_pkg_id,
            dependency_id=dep1_id,
            dependency_type_id=mock_config.dependency_types.runtime,
        )
        existing_dep2 = LegacyDependency(
            package_id=existing_pkg_id,
            dependency_id=dep2_id,
            dependency_type_id=mock_config.dependency_types.build,
        )

        # Create cache
        cache = Cache(
            package_map={
                ""dep-pkg"": existing_package,
                ""dep1"": dep1_pkg,
                ""dep2"": dep2_pkg,
                ""dep3"": dep3_pkg,
            },
            url_map={},
            package_urls={},
            dependencies={existing_pkg_id: {existing_dep1, existing_dep2}},
        )

        # Create new package data with changed dependencies
        # Remove dep2, keep dep1, add dep3 as runtime
        new_pkg_data = create_pkgx_package(
            dependencies=[""dep1"", ""dep3""],  # runtime deps
            build_deps=[],  # no build deps (removes dep2)
        )

        # Test the diff
        diff = PkgxDiff(mock_config, cache, mock_logger)
        new_deps, removed_deps = diff.diff_deps(""dep-pkg"", new_pkg_data)

        # Assertions
        assert len(new_deps) == 1  # dep3 should be added
        assert new_deps[0].dependency_id == dep3_id
        assert new_deps[0].dependency_type_id == mock_config.dependency_types.runtime

        assert len(removed_deps) == 1  # dep2 should be removed
        assert removed_deps[0].dependency_id == dep2_id
        assert removed_deps[0].dependency_type_id == mock_config.dependency_types.build
",tests/package_managers/pkgx/test_pkgx_diff.py,TestPkgxDifferentialLoading,1,2.2159489282323004e-08,"The method `test_package_exists_dependency_change` is a well-structured unit test that verifies the behavior of a package dependency management system when dependencies change. It sets up a scenario, performs operations, and asserts expected outcomes, which is a common and necessary practice in software development to ensure code reliability. The method is likely to be maintained as it provides valuable testing for changes in package dependencies, which is a critical aspect of package management systems."
survived,"def guess(db_client: DB, package_managers: list[UUID], url: str) -> list[str]:
    names = possible_names(url)
    urls = db_client.search_names(names, package_managers)
    return urls
",package_managers/pkgx/url.py,,1,2.0611536181902033e-09,"The method 'guess' is a simple utility function that takes a database client, a list of package manager UUIDs, and a URL to return a list of URLs. It uses a helper function 'possible_names' to generate potential names from the URL and then searches these names in the database using 'db_client.search_names'. This method is likely to be useful in contexts where URL-based name resolution is needed, such as in package management or web scraping applications. Its functionality is clear, and it doesn't seem to have any major issues or redundancies that would warrant its deletion. Therefore, it is likely to survive."
survived,"    async def test_create_api_key_after_deleting_last_key(
        self,
        organization_storage: MongoOrganizationStorage,
        org_col: AsyncCollection,
    ) -> None:
        """"""Test that reproduces the MongoDB index issue when deleting the last API key.

        With the old index ({""api_keys"": {""$exists"": True}}), creating a new API key after
        deleting the last one would fail with a duplicate key error because the index would
        still match the document even with an empty api_keys array.

        This test uses multiple tenants to demonstrate the issue more clearly.
        """"""
        tenant1 = TENANT
        tenant2 = ""tenant2""

        # Create organizations for both tenants
        await org_col.insert_one(dump_model(OrganizationDocument(tenant=tenant1, uid=1, slug=""1"")))
        await org_col.insert_one(dump_model(OrganizationDocument(tenant=tenant2, uid=2, slug=""2"")))

        tenant1_storage = MongoOrganizationStorage(
            tenant=(tenant1, 1),
            collection=org_col,
            encryption=organization_storage.encryption,
        )
        tenant2_storage = MongoOrganizationStorage(
            tenant=(tenant2, 2),
            collection=org_col,
            encryption=organization_storage.encryption,
        )

        # Create API key for tenant 1 and tenant 2
        tenant1_key = await tenant1_storage.create_api_key_for_organization(
            name=""tenant1 key"",
            hashed_key=""hashed123"",
            partial_key=""sk-123****"",
            created_by=UserIdentifier(user_id=""user1"", user_email=""test@example.com""),
        )

        tenant2_key = await tenant2_storage.create_api_key_for_organization(
            name=""tenant2 key"",
            hashed_key=""hashed456"",
            partial_key=""sk-456****"",
            created_by=UserIdentifier(user_id=""user2"", user_email=""test2@example.com""),
        )

        # Delete the API key for tenant 1
        result = await tenant1_storage.delete_api_key_for_organization(key_id=str(tenant1_key.id))
        assert result is True

        # Delete the API key for tenant 2
        result = await tenant2_storage.delete_api_key_for_organization(key_id=str(tenant2_key.id))
        assert result is True

        # Verify no keys remain for either tenant
        tenant1_keys = await tenant1_storage.get_api_keys_for_organization()
        tenant2_keys = await tenant2_storage.get_api_keys_for_organization()
        assert len(tenant1_keys) == 0
        assert len(tenant2_keys) == 0
",api/core/storage/mongo/partials/mongo_organizations_test.py,TestDeleteAPIKeyForOrganization,1,4.1399375473943306e-08,"The method is a well-structured test case that verifies a specific bug related to MongoDB indexing when deleting and recreating API keys. It is useful for ensuring the integrity and correctness of the system, especially in a multi-tenant environment. Such test cases are crucial for maintaining software quality and are unlikely to be deleted unless the underlying functionality is removed or significantly changed."
survived,"    def test_status_utils_with_invalid_resources(self):
        """"""Test status utility functions handle invalid resources gracefully.""""""
        # Create a mock cluster record with problematic resources
        mock_record = {
            'status': None,
            'num_nodes': 1,
            'resources': None,  # Problematic: None resources
            'total_cost': 0.0
        }
        
        # These should not crash even with None resources
        try:
            status_utils._get_resources_for_cost_report(mock_record, truncate=True)
            status_utils._get_price_for_cost_report(mock_record, truncate=True)
            status_utils._get_estimated_cost_for_cost_report(mock_record, truncate=True)
        except (AttributeError, TypeError):
            # Expected - the functions might fail gracefully, but shouldn't crash the whole system
            pass
",tests/unit_tests/test_sky_cost_report.py,TestHistoricalClusterRobustness,1,1.1861120010657661e-08,"The method `test_status_utils_with_invalid_resources` is a test case designed to ensure that certain utility functions handle invalid input gracefully. It is important for robust software to handle edge cases and invalid inputs without crashing. This test case is valuable for maintaining the stability and reliability of the software, especially when dealing with external or unpredictable data sources. Therefore, it is likely to be retained to ensure the software's resilience."
survived,"    def test_cost_report_mixed_valid_invalid_clusters(self):
        """"""Test cost report works when some clusters are valid and others have issues.""""""
        valid_cluster = {
            'name': 'valid-cluster',
            'status': status_lib.ClusterStatus.UP,
            'num_nodes': 1,
            'resources': mock.Mock(),
            'total_cost': 5.50,
            'launched_at': 1640995200,
            'duration': 3600,
            'cluster_hash': 'valid123',
            'usage_intervals': [(1640995200, 1640998800)],
            'user_hash': 'user_valid',
            'user_name': 'validuser',
            'workspace': 'default',
        }
        valid_cluster['resources'].instance_type = 'standard-instance'
        valid_cluster['resources'].cloud = mock.Mock()
        valid_cluster['resources'].cloud.__str__ = lambda: 'aws'
        
        invalid_cluster = {
            'name': 'invalid-cluster',
            'status': None,
            'num_nodes': 1,
            'resources': mock.Mock(),
            'total_cost': 0.0,
            'launched_at': 1640995200,
            'duration': 1800,
            'cluster_hash': 'invalid456',
            'usage_intervals': [(1640995200, 1640997000)],
            'user_hash': 'user_invalid',
            'user_name': 'invaliduser',
            'workspace': 'default',
        }
        invalid_cluster['resources'].instance_type = 'discontinued-instance-type'
        invalid_cluster['resources'].cloud = mock.Mock()
        invalid_cluster['resources'].cloud.__str__ = lambda: 'nonexistent-cloud'
        
        with mock.patch('sky.global_user_state.get_clusters_from_history', 
                      return_value=[valid_cluster, invalid_cluster]):
            
                         # Should return both clusters, even if one has issues
             result = core.cost_report(days=30)
             self.assertEqual(len(result), 2)
             
             cluster_names = [r['name'] for r in result]
             self.assertIn('valid-cluster', cluster_names)
             self.assertIn('invalid-cluster', cluster_names)
",tests/unit_tests/test_sky_cost_report.py,TestHistoricalClusterRobustness,1,8.152020648014727e-09,"The method is a unit test that verifies the functionality of a cost report feature, ensuring it handles both valid and invalid clusters. It is important for maintaining the robustness of the cost reporting system, especially in environments where cluster validity can vary. The test checks that the system correctly includes both valid and invalid clusters in the report, which is a critical aspect of the feature's functionality. Therefore, it is likely to be retained to ensure ongoing reliability and correctness of the cost reporting feature."
survived,"def main():
    data_dir = ""data/debian/latest""

    # Check if data files exist
    sources_file = os.path.join(data_dir, ""sources"")
    packages_file = os.path.join(data_dir, ""packages"")

    if not os.path.exists(sources_file):
        logger.log(f""ERROR: Sources file not found at {sources_file}"")
        logger.log(""Use --fetch to download the latest data"")
        return 1

    if not os.path.exists(packages_file):
        logger.log(f""ERROR: Packages file not found at {packages_file}"")
        logger.log(""Use --fetch to download the latest data"")
        return 1

    logger.log(f""Using sources file: {sources_file}"")
    logger.log(f""Using packages file: {packages_file}"")

    investigate_mapping(sources_file, packages_file)

    return 0
",package_managers/debian/scripts/investigate_sources.py,,1,2.646573631904765e-09,"The method is a main function that checks for the existence of specific data files and logs appropriate messages if they are missing. It also calls another function, 'investigate_mapping', if the files are present. This is a typical pattern for a script that processes data files, and it includes error handling and logging, which are good practices. There is no indication that this method is obsolete or redundant, and it seems to serve a clear purpose in the context of the script. Therefore, it is likely to be retained."
survived,"    def get_project_by_id(project_id: int, user_id: str) -> Optional[Dict]:
        """"""Get a specific project by ID for a user""""""
        try:
            result = supabase.table('projects').select('*').eq('id', project_id).eq('user_id', user_id).execute()
            return result.data[0] if result.data else None
        except Exception as e:
            logger.error(f""Error fetching project {project_id}: {e}"")
            raise
",server/database.py,DatabaseOperations,1,2.0611536181902033e-09,"The method 'get_project_by_id' is a utility function that retrieves a project from a database based on a project ID and user ID. It is a common operation in applications that manage user-specific data. The method is well-structured, uses error handling, and logs errors, which are good practices. It is unlikely to be deleted unless there is a significant change in the application's architecture or database access strategy."
survived,"def get_task_details(task_id):
    """"""Get detailed information about a specific task""""""
    try:
        user_id = request.headers.get('X-User-ID')
        if not user_id:
            return jsonify({'error': 'User ID required'}), 400
        
        task = DatabaseOperations.get_task_by_id(task_id, user_id)
        if not task:
            return jsonify({'error': 'Task not found'}), 404
        
        return jsonify({
            'status': 'success',
            'task': task
        })
        
    except Exception as e:
        logger.error(f""Error fetching task details: {str(e)}"")
        return jsonify({'error': str(e)}), 500
",server/tasks.py,,1,5.211412485172657e-10,"The method 'get_task_details' is a well-structured function that handles a common use case in web applications: fetching details of a specific task for a user. It includes error handling for missing user ID, task not found, and general exceptions, which are essential for robust API endpoints. The function also logs errors, which is crucial for debugging and monitoring. These characteristics make it a valuable part of an application, suggesting it is likely to be retained."
survived,"    def test_flow_output_model(self):
        """"""Test FlowOutput model validation.""""""
        # Success output
        output = FlowOutput(
            result=""test result"",
            execution_time=1.5
        )
        assert output.result == ""test result""
        assert output.execution_time == 1.5
        assert output.error is None

        # Error output
        error_output = FlowOutput(
            result=None,
            error=""Test error occurred""
        )
        assert error_output.result is None
        assert error_output.error == ""Test error occurred""
",src/backend/tests/unit/test_mcp_server.py,TestFlowModels,1,2.998960815863541e-09,"The method 'test_flow_output_model' is a unit test for the 'FlowOutput' model, which is likely part of a test suite to ensure the model behaves as expected. Unit tests are crucial for maintaining code quality and ensuring that changes do not introduce bugs. Since this method is testing the validation of a model, it is important for the integrity of the application and is unlikely to be deleted unless the 'FlowOutput' model itself is removed or significantly refactored."
survived,"def run_mcp_server(
    mcp_server: FastMCP,
    transport: str = ""stdio"",
    host: str = ""127.0.0.1"", 
    port: int = 8000,
) -> None:
    """"""Run the MCP server with the specified transport.
    
    Args:
        mcp_server: The FastMCP server instance
        transport: Transport type (""stdio"", ""sse"", ""websocket"")
        host: Host to bind to (for network transports)
        port: Port to bind to (for network transports)
    """"""
    if transport == ""stdio"":
        # For stdio transport, run with default settings
        mcp_server.run()
    elif transport == ""sse"":
        # For SSE transport, run with HTTP server
        mcp_server.run(transport=""sse"", host=host, port=port)
    elif transport == ""websocket"":
        # For WebSocket transport
        mcp_server.run(transport=""websocket"", host=host, port=port)
    else:
        raise ValueError(f""Unsupported transport: {transport}. Use 'stdio', 'sse', or 'websocket'"")",src/backend/base/langflow/cli/mcp_server.py,,1,2.998960815863541e-09,"The method `run_mcp_server` is a utility function that provides a flexible way to run a server with different transport protocols. It is well-documented, handles different cases for transport types, and raises an error for unsupported types, which makes it robust and useful. Such utility functions are often retained in codebases as they encapsulate common patterns and provide flexibility for future extensions or modifications. Therefore, it is likely to be retained in the codebase."
deleted,"    def integration_graphs_and_metas(self, mock_graph_with_execution):
        """"""Create graphs and metas for integration testing.""""""
        graphs = {
            ""echo_flow"": mock_graph_with_execution,
            ""processing_flow"": mock_graph_with_execution
        }
        
        # Create more realistic metas
        echo_meta = MagicMock()
        echo_meta.title = ""Echo Flow""
        echo_meta.description = ""Echoes the input back""
        
        processing_meta = MagicMock()
        processing_meta.title = ""Processing Flow""
        processing_meta.description = ""Processes input data""
        
        metas = {
            ""echo_flow"": echo_meta,
            ""processing_flow"": processing_meta
        }
        
        return graphs, metas
",src/backend/tests/unit/test_mcp_server.py,TestMCPServerIntegration,1,2.4616969512093895e-10,"The method 'integration_graphs_and_metas' is likely to survive because it serves a clear purpose in setting up mock data for integration testing. It creates and returns a dictionary of graphs and metas, which are essential for testing the integration of different components. The use of mock objects suggests that this method is part of a testing framework, which is crucial for ensuring code quality and reliability. Additionally, the method is well-documented and structured, making it a valuable part of the codebase."
survived,"    def sample_graphs_and_metas(self, mock_graph, mock_meta):
        """"""Create sample graphs and metas for testing.""""""
        graphs = {
            ""flow1"": mock_graph,
            ""flow2"": mock_graph
        }
        metas = {
            ""flow1"": mock_meta,
            ""flow2"": mock_meta
        }
        return graphs, metas
",src/backend/tests/unit/test_mcp_server.py,TestMCPServerCreation,1,4.944450477491054e-09,"The method 'sample_graphs_and_metas' is a utility function designed to create sample data for testing purposes. Such methods are often useful in testing environments to ensure that the code behaves as expected with predefined inputs. The method is straightforward, has a clear purpose, and is likely to be used in test cases or during development to simulate different scenarios. Therefore, it is unlikely to be deleted unless the testing strategy changes significantly or the method is replaced by a more comprehensive testing framework."
deleted,"    def get_flow_schema(flow_id: str) -> str:
        """"""Get the schema (inputs/outputs) for a specific flow.""""""
        if flow_id not in graphs:
            return json.dumps({""error"": f""Flow '{flow_id}' not found""})
        
        graph = graphs[flow_id]
        
        # This could be expanded to provide detailed schema information
        # by analyzing the graph structure
        schema_info = {
            ""flow_id"": flow_id,
            ""inputs"": {
                ""input_value"": {
                    ""type"": ""string"",
                    ""description"": ""Main input value for the flow""
                },
                ""tweaks"": {
                    ""type"": ""object"",
                    ""description"": ""Optional parameter tweaks"",
                    ""optional"": True
                }
            },
            ""outputs"": {
                ""result"": {
                    ""type"": ""any"",
                    ""description"": ""Flow execution result""
                },
                ""execution_time"": {
                    ""type"": ""number"",
                    ""description"": ""Execution time in seconds"",
                    ""optional"": True
                },
                ""error"": {
                    ""type"": ""string"",
                    ""description"": ""Error message if execution failed"",
                    ""optional"": True
                }
            }
        }
        
        return json.dumps(schema_info, indent=2)
",src/backend/base/langflow/cli/mcp_server.py,,1,1.4166087846364157e-09,"The method `get_flow_schema` is likely to survive because it provides a useful functionality of retrieving the schema for a specific flow, which is essential for understanding the inputs and outputs of a flow in a system. The method is well-documented, handles errors gracefully by returning a JSON error message if the flow is not found, and provides a structured JSON response with detailed schema information. This makes it a valuable part of any system that deals with flow management or execution."
survived,"    def test_run_mcp_server_stdio(self, mock_fastmcp):
        """"""Test running MCP server with stdio transport.""""""
        mock_mcp_instance = MagicMock()
        mock_mcp_instance.run = MagicMock()

        run_mcp_server(
            mcp_server=mock_mcp_instance,
            transport=""stdio""
        )

        # Should call run() with no arguments for stdio
        mock_mcp_instance.run.assert_called_once_with()
",src/backend/tests/unit/test_mcp_server.py,TestMCPServerRuntime,1,1.1861120010657661e-08,"The method `test_run_mcp_server_stdio` is a unit test that verifies the behavior of the `run_mcp_server` function when using the 'stdio' transport. It uses mock objects to simulate the behavior of the MCP server and checks that the `run` method is called correctly. This is a typical and necessary test to ensure that the function behaves as expected, especially in a codebase that relies on external services or complex interactions. Unit tests are crucial for maintaining code quality and reliability, so this method is likely to be retained in the codebase."
deleted,"    def test_moonshot_completion_mock(self, respx_mock):
        """"""
        Mock test for Moonshot completion using the model format from docs.
        This test mocks the actual HTTP request to test the integration properly.
        """"""

        litellm.disable_aiohttp_transport = (
            True  # since this uses respx, we need to set use_aiohttp_transport to False
        )

        # Set up environment variables for the test
        api_key = ""fake-moonshot-key""
        api_base = ""https://api.moonshot.ai/v1""
        model = ""moonshot/moonshot-v1-8k""
        model_name = ""moonshot-v1-8k""  # The actual model name without provider prefix

        # Mock the HTTP request to the moonshot API
        respx_mock.post(f""{api_base}/chat/completions"").respond(
            json={
                ""id"": ""chatcmpl-123"",
                ""object"": ""chat.completion"",
                ""created"": 1677652288,
                ""model"": model_name,
                ""choices"": [
                    {
                        ""index"": 0,
                        ""message"": {
                            ""role"": ""assistant"",
                            ""content"": '```python\nprint(""Hey from LiteLLM!"")\n```\n\nThis simple Python code prints a greeting message from LiteLLM.',
                        },
                        ""finish_reason"": ""stop"",
                    }
                ],
                ""usage"": {
                    ""prompt_tokens"": 9,
                    ""completion_tokens"": 12,
                    ""total_tokens"": 21,
                },
            },
            status_code=200,
        )

        # Make the actual API call through LiteLLM
        response = completion(
            model=model,
            messages=[
                {""role"": ""user"", ""content"": ""write code for saying hey from LiteLLM""}
            ],
            api_key=api_key,
            api_base=api_base,
        )

        # Verify response structure
        assert response is not None
        assert hasattr(response, ""choices"")
        assert len(response.choices) > 0
        assert hasattr(response.choices[0], ""message"")
        assert hasattr(response.choices[0].message, ""content"")
        assert response.choices[0].message.content is not None

        # Check for specific content in the response
        assert ""```python"" in response.choices[0].message.content
        assert ""Hey from LiteLLM"" in response.choices[0].message.content",tests/test_litellm/llms/moonshot/test_moonshot_chat_transformation.py,TestMoonshotConfig,1,6.023574641292144e-08,"The method is a well-structured unit test for a specific functionality, which is mocking an API call to test the integration with the Moonshot API. It uses a mock library to simulate the API response, ensuring that the integration can be tested without making actual network requests. This is a common practice in software testing to ensure reliability and efficiency. The method is likely to be maintained as it provides value in testing the integration layer of the application."
survived,"    async def test_transfer_traces_fails_with_non_existent_trace_id(
        self,
        gql_client: AsyncGraphQLClient,
        trace_transfer_fixture: dict[str, int],
        db: DbSessionFactory,
    ) -> None:
        source_project_id = trace_transfer_fixture[""source_project_id""]
        dest_project_id = trace_transfer_fixture[""dest_project_id""]
        trace1_id = trace_transfer_fixture[""trace1_id""]

        async with db() as session:
            trace = await session.get(models.Trace, trace1_id)
            assert trace is not None
            assert trace.project_rowid == source_project_id

        result = await gql_client.execute(
            self.TRANSFER_TRACES_MUTATION,
            variables={
                ""traceIds"": [
                    str(GlobalID(""Trace"", str(trace1_id))),
                    str(GlobalID(""Trace"", ""99999"")),
                ],
                ""projectId"": str(GlobalID(""Project"", str(dest_project_id))),
            },
        )
        assert result.errors

        async with db() as session:
            trace = await session.get(models.Trace, trace1_id)
            assert trace is not None
            assert trace.project_rowid == source_project_id
",tests/unit/server/api/mutations/test_trace_transfer_mutations.py,TestTraceTransferMutationMixin,1,1.637377179507321e-07,"The method is a test function that checks the behavior of a system when attempting to transfer traces with a non-existent trace ID. It is a part of a test suite, likely for a larger application, and is important for ensuring the robustness and correctness of the trace transfer functionality. Test functions are generally not deleted unless they are redundant or replaced by more comprehensive tests. This test specifically checks for error handling, which is crucial for maintaining software quality."
survived,"    def test_csharp_edge_cases(self):
        patch = """"""
@@ -152,10 +152,6 @@ public unsafe void* GetPointer()

@@ -152,10 +152,6 @@ public extern static void ExternalMethod();

@@ -152,10 +152,6 @@ [Obsolete(""Use NewMethod instead"")]
public void OldMethod()

@@ -152,10 +152,6 @@ public partial void PartialMethod();

@@ -152,10 +152,6 @@ public virtual async Task<IEnumerable<T>> ComplexMethod<T>()

""""""

        assert CSharpParser.extract_functions_from_patch(patch) == {
            ""GetPointer"",
            ""ExternalMethod"",
            ""OldMethod"",
            ""PartialMethod"",
            ""ComplexMethod"",
        }",tests/sentry/integrations/source_code_management/test_language_parsers.py,CSharpParserTestCase,1,9.736200303530205e-10,"The method `test_csharp_edge_cases` is a unit test designed to verify the functionality of the `CSharpParser.extract_functions_from_patch` method. It checks if the parser correctly identifies and extracts function names from a given patch. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with edge cases. Therefore, this method is likely to be retained as it serves an important role in maintaining the quality of the codebase."
survived,"def get_patch_parsers_for_organization(organization=None):
    """"""
    Returns the appropriate patch parsers based on feature flags.
    Falls back to the standard parsers if no organization is provided.
    """"""
    if organization and features.has(""organizations:csharp-open-pr-comments"", organization):
        # Merge stable and beta parsers when feature flag is enabled
        return {**PATCH_PARSERS, **BETA_PATCH_PARSERS}
    else:
        # Return only stable parsers when feature flag is disabled or no organization context
        return {k: v for k, v in PATCH_PARSERS.items() if k not in BETA_PATCH_PARSERS}",src/sentry/integrations/source_code_management/language_parsers.py,,1,3.160881453314576e-10,"The method `get_patch_parsers_for_organization` is likely to survive because it provides a flexible way to return different sets of parsers based on feature flags and organization context. This kind of functionality is often necessary in systems that need to support feature toggles or gradual rollouts of new features. The method is also well-documented and has a clear purpose, making it a valuable part of the codebase."
survived,"    def test_env_group_rubric_initialization(self, mock_openai_client):
        """"""Test EnvGroupRubric initialization with multiple environments.""""""
        # Create test environments with different rubrics
        def func1(completion, **kwargs):
            return 1.0
        
        def func2(completion, **kwargs):
            return 0.5
        
        def func3(completion, **kwargs):
            return 0.8
        
        env1 = SingleTurnEnv(
            client=mock_openai_client,
            model=""test-model"",
            eval_dataset=Dataset.from_dict({""question"": [""q1""], ""answer"": [""a1""]}),
            rubric=Rubric(funcs=[func1, func2], weights=[1.0, 0.5])
        )
        
        env2 = SingleTurnEnv(
            client=mock_openai_client,
            model=""test-model"",
            eval_dataset=Dataset.from_dict({""question"": [""q2""], ""answer"": [""a2""]}),
            rubric=Rubric(funcs=[func2, func3], weights=[0.7, 1.0])
        )
        
        env_map = {""task1"": env1, ""task2"": env2}
        rubric = EnvGroupRubric(env_map)
        
        assert rubric.env_map == env_map
        # Should have all unique reward function names
        assert set(rubric.all_reward_names) == {""func1"", ""func2"", ""func3""}
",tests/test_env_group.py,TestEnvGroupRubric,1,8.152020648014727e-09,"The method `test_env_group_rubric_initialization` is a unit test designed to verify the correct initialization of the `EnvGroupRubric` class with multiple environments. It checks that the environment map is correctly set and that all unique reward function names are captured. This is a fundamental test to ensure the functionality of the `EnvGroupRubric` class, which is likely a core component of the system being tested. Unit tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, this method is likely to be retained as part of the test suite."
survived,"    def test_parse_chat_completion_logprobs(self, mock_openai_client, sample_dataset):
        """"""Test parsing logprobs from a vLLM chat completion.""""""
        env = SimpleEnvironment(
            client=mock_openai_client,
            model=""test-model"",
            dataset=sample_dataset,
            parser=Parser(),
            rubric=Rubric()
        )
        
        # Create mock chat completion with logprobs
        mock_completion = Mock()
        mock_completion.choices = [Mock()]
        mock_completion.choices[0].logprobs = Mock()
        mock_completion.choices[0].logprobs.content = [
            Mock(logprob=-0.5),
            Mock(logprob=-1.2),
            Mock(logprob=-0.3)
        ]
        
        logprobs = env.parse_chat_completion_logprobs(mock_completion)
        assert logprobs == [-0.5, -1.2, -0.3]
",tests/test_environment.py,TestEnvironmentBase,1,7.194132978569833e-09,"The method 'test_parse_chat_completion_logprobs' is a unit test designed to verify the functionality of parsing log probabilities from a chat completion object. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with external dependencies like mock clients. This test method is well-structured, uses mock objects to simulate the behavior of the OpenAI client, and includes an assertion to validate the expected outcome. Given its role in maintaining code quality and the absence of any indication that it is obsolete or redundant, it is likely to be retained."
survived,"    def test_process_env_results_chat(self, mock_openai_client, sample_dataset):
        """"""Test processing environment results for chat format.""""""
        env = SimpleEnvironment(
            client=mock_openai_client,
            model=""test-model"",
            dataset=sample_dataset,
            parser=Parser(),
            rubric=Rubric()
        )
        
        # Create a mock tokenizer
        mock_tokenizer = Mock()
        
        # Track the conversation state
        def mock_apply_chat_template(conversation, tokenize=False, add_generation_prompt=True):
            # Convert messages to a string representation
            text = """"
            for msg in conversation:
                text += f""{msg['role']}: {msg['content']} ""
            return text.strip()
        
        def mock_encode(text, **kwargs):
            # Return tokens based on the text content
            if ""assistant: Hi there!"" in text:
                # Prompt + completion: return extended tokens
                return [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
            elif ""user: Hello"" in text:
                # Just prompt: return base tokens
                return [1, 2, 3, 4, 5]
            else:
                # Default case
                return [1, 2, 3]
        
        mock_tokenizer.apply_chat_template = Mock(side_effect=mock_apply_chat_template)
        mock_tokenizer.encode = Mock(side_effect=mock_encode)
        
        prompts = [[{""role"": ""user"", ""content"": ""Hello""}]]
        completions = [[{""role"": ""assistant"", ""content"": ""Hi there!""}]]
        states = [{}]
        rewards = [1.0]
        
        results = env.process_env_results(
            prompts, completions, states, rewards, mock_tokenizer
        )
        
        assert ""prompt_ids"" in results
        assert ""prompt_mask"" in results
        assert ""completion_ids"" in results
        assert ""completion_mask"" in results
        assert ""completion_logprobs"" in results
        assert ""rewards"" in results
        assert len(results[""rewards""]) == 1
        assert results[""rewards""][0] == 1.0
",tests/test_environment.py,TestEnvironmentBase,1,6.023574641292144e-08,"The method `test_process_env_results_chat` is a unit test for the `process_env_results` function in a chat environment. It uses mock objects to simulate the behavior of external dependencies, such as the tokenizer and the OpenAI client. The test checks if the `process_env_results` function correctly processes prompts, completions, states, and rewards, and verifies the structure and content of the results. Unit tests are crucial for ensuring code reliability and are typically maintained as long as the functionality they test is relevant. Therefore, this method is likely to be retained as long as the `process_env_results` function is part of the codebase."
survived,"    async def test_env_group_rollout_routing(self, mock_openai_client):
        """"""Test that rollout is properly routed to the correct sub-environment.""""""
        # Create environments with different behaviors
        env1 = SingleTurnEnv(
            client=mock_openai_client,
            model=""test-model"",
            dataset=Dataset.from_dict({""question"": [""q1""], ""answer"": [""a1""]}),
            rubric=Rubric()
        )
        
        env2 = SingleTurnEnv(
            client=mock_openai_client,
            model=""test-model"",
            dataset=Dataset.from_dict({""question"": [""q2""], ""answer"": [""a2""]}),
            rubric=Rubric()
        )
        
        # Mock the rollout methods to return different values
        env1.rollout = AsyncMock(return_value=(""response1"", {""env"": ""env1""}))
        env2.rollout = AsyncMock(return_value=(""response2"", {""env"": ""env2""}))
        
        env_group = EnvGroup(envs=[env1, env2], env_names=[""math"", ""code""])
        
        # Test routing to math environment
        result1, state1 = await env_group.rollout(
            client=mock_openai_client,
            model=""test-model"",
            prompt=""Test prompt"",
            task=""math""
        )
        
        assert result1 == ""response1""
        assert state1[""env""] == ""env1""
        env1.rollout.assert_called_once()
        env2.rollout.assert_not_called()
        
        # Reset mocks
        env1.rollout.reset_mock()
        env2.rollout.reset_mock()
        
        # Test routing to code environment
        result2, state2 = await env_group.rollout(
            client=mock_openai_client,
            model=""test-model"",
            prompt=""Test prompt"",
            task=""code""
        )
        
        assert result2 == ""response2""
        assert state2[""env""] == ""env2""
        env1.rollout.assert_not_called()
        env2.rollout.assert_called_once()
",tests/test_env_group.py,TestEnvGroup,1,1.1253518384332553e-07,"The method 'test_env_group_rollout_routing' is a unit test designed to verify the correct routing of rollouts to different sub-environments based on the task. It uses mock objects to simulate the behavior of the environments and checks that the correct environment is called based on the task. This is a typical and necessary part of testing in software development, especially when dealing with complex systems that involve multiple components. Therefore, it is unlikely to be deleted as it serves an important purpose in ensuring the reliability and correctness of the code."
survived,"    async def test_singleturn_stops_after_one_response(self, mock_openai_client, sample_dataset):
        """"""Test that SingleTurnEnv truly stops after one response.""""""
        # We'll verify this by checking the is_completed logic
        env = SingleTurnEnv(
            client=mock_openai_client,
            model=""test-model"",
            dataset=sample_dataset
        )
        
        # Before any responses
        state = {""responses"": []}
        assert not env.is_completed([], state)
        
        # After one response
        state = {""responses"": [MagicMock()]}
        assert env.is_completed([], state)
        
        # Even with multiple responses (shouldn't happen), it's still completed
        state = {""responses"": [MagicMock(), MagicMock()]}
        assert env.is_completed([], state)",tests/test_singleturn_env.py,TestSingleTurnEnv,1,3.653482080241728e-08,"The method is a unit test for a specific functionality of the SingleTurnEnv class, ensuring that it behaves as expected by stopping after one response. Unit tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, this method is likely to be retained as it serves an important role in the development and maintenance process."
survived,"        def func3(completion, **kwargs):
            return 0.8
",tests/test_env_group.py,TestEnvGroupRubric,0,0.9999980052698925,"The method 'func3' is very simplistic and does not utilize its parameters effectively. It takes a 'completion' argument and arbitrary keyword arguments (**kwargs), but it only returns a constant value of 0.8, regardless of the input. This suggests that the method is not performing any meaningful computation or logic based on its inputs, which is typically not useful in a real-world application. Therefore, it is likely to be deleted unless it is part of a larger framework where this behavior is specifically required."
survived,"async def main():
    """"""Main entry point""""""
    try:
        await run_sequence_demo()
    except KeyboardInterrupt:
        print(""\n\nDemo interrupted by user"")
        sys.exit(0)
    except Exception as e:
        print(f""\nError: {e}"")
        sys.exit(1)
",examples/python_mcp_chunk_stream.py,,1,5.60279640614594e-09,"The method 'main' is a standard asynchronous entry point for a Python script, handling exceptions and user interruptions gracefully. It is a common pattern in Python programming, especially for scripts that involve asynchronous operations. The use of try-except blocks to manage exceptions and the inclusion of a KeyboardInterrupt handler to allow for clean exits are best practices. There is no indication that this method is obsolete or redundant, and it serves a clear purpose in managing the flow of an asynchronous program."
survived,"async def run_sequence_demo():
    """"""Run a demo sequence showing chunk-like streaming""""""
    
    # Define our automation sequence
    sequence = [
        {
            ""tool_name"": ""get_applications"",
            ""arguments"": {}
        },
        {
            ""tool_name"": ""delay"",
            ""arguments"": {""delay_ms"": 1000}
        },
        {
            ""tool_name"": ""capture_screen"",
            ""arguments"": {}
        },
        {
            ""tool_name"": ""get_clipboard"",
            ""arguments"": {}
        },
        {
            ""tool_name"": ""open_application"",
            ""arguments"": {""app_name"": ""notepad""}
        },
        {
            ""tool_name"": ""delay"", 
            ""arguments"": {""delay_ms"": 2000}
        },
        {
            ""tool_name"": ""type_into_element"",
            ""arguments"": {
                ""selector"": ""role:document"",
                ""text_to_type"": ""Hello from chunk streaming demo!""
            }
        }
    ]
    
    # Convert sequence to the format expected by execute_sequence
    items = []
    for tool in sequence:
        items.append({
            ""tool_name"": tool[""tool_name""],
            ""arguments"": tool.get(""arguments"", {}),
            ""continue_on_error"": tool.get(""continue_on_error"", False),
            ""delay_ms"": tool.get(""delay_ms"", 0)
        })
    
    # Connect to MCP server
    server_params = StdioServerParameters(
        command=""terminator-mcp-agent"",
        args=[],
        env=None
    )
    
    async with stdio_client(server_params) as (read, write):
        async with ClientSession(read, write) as session:
            await session.initialize()
            
            print(""Connected to terminator-mcp-agent"")
            print(""\n"" + ""=""*60)
            print(""ENHANCED SEQUENCE EXECUTION WITH DETAILED TRACKING"")
            print(""=""*60)
            
            # Execute the sequence
            print(""\nExecuting sequence..."")
            result = await session.call_tool(
                ""execute_sequence"",
                arguments={
                    ""items"": items,
                    ""stop_on_error"": True,
                    ""include_detailed_results"": True
                }
            )
            
            # Parse the result
            if result.content and len(result.content) > 0:
                data = json.loads(result.content[0].text)
                
                # Display execution plan
                print(""\n📋 EXECUTION PLAN:"")
                print(""-"" * 50)
                plan = data.get(""execution_plan"", {})
                print(f""Total steps to execute: {plan.get('total_steps', 0)}"")
                for step in plan.get(""steps"", []):
                    print(f""  Step {step['step']}: {step['tool_name']} - {step['description']}"")
                
                # Display step results as they would appear in a stream
                print(""\n🚀 EXECUTING STEPS:"")
                print(""-"" * 50)
                
                step_results = data.get(""step_results"", [])
                for step_result in step_results:
                    print_step_info(step_result)
                    
                    # Show a sample of the result content if available
                    if ""result"" in step_result and ""result"" in step_result[""result""]:
                        result_data = step_result[""result""][""result""]
                        if isinstance(result_data, dict) and ""content"" in result_data:
                            content = result_data[""content""]
                            if isinstance(content, list) and len(content) > 0:
                                # Show truncated content for readability
                                content_str = str(content[0])
                                if len(content_str) > 100:
                                    content_str = content_str[:100] + ""...""
                                print(f""  Result: {content_str}"")
                
                # Display execution summary
                print(""\n📊 EXECUTION SUMMARY:"")
                print(""-"" * 50)
                summary = data.get(""execution_summary"", {})
                print(f""Total steps planned:    {summary.get('total_steps', 0)}"")
                print(f""Steps executed:         {summary.get('executed_steps', 0)}"")
                print(f""Successful steps:       {summary.get('successful_steps', 0)}"")
                print(f""Failed steps:           {summary.get('failed_steps', 0)}"")
                print(f""Total duration:         {summary.get('total_duration_ms', 0)}ms"")
                print(f""Started at:             {format_timestamp(summary.get('started_at', ''))}"")
                print(f""Completed at:           {format_timestamp(summary.get('completed_at', ''))}"")
                
                # Final status
                print(f""\n🏁 FINAL STATUS: {data.get('status', 'unknown').upper()}"")
                
            else:
                print(""No result received from execute_sequence"")
",examples/python_mcp_chunk_stream.py,,1,5.60279640614594e-09,"The method `run_sequence_demo` is a well-structured asynchronous function that demonstrates a sequence of operations using a client-server model. It includes detailed logging and error handling, making it useful for debugging and monitoring purposes. The method is likely part of a larger system that requires such functionality, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained in the codebase."
deleted,"    def _log_verbose_output(self, messages: List[Dict[str, str]], output: LLMResult) -> None:
        """"""Log verbose output for debugging.""""""
        # Truncate messages to 500 chars
        messages_str = str(messages)
        truncated_messages = (
            messages_str[:500] + ""...""
            if len(messages_str) > 500
            else messages_str
        )

        # Log with nice formatting
        self.runner.console.print(
            Panel(
                Group(
                    Text(""Input:"", style=""bold cyan""),
                    Text(truncated_messages),
                    Text(""\nOutput:"", style=""bold cyan""),
                    Text(str(output)),
                ),
                title=""[bold green]LLM Call Details[/bold green]"",
                border_style=""green"",
            )
        )",docetl/operations/utils/api.py,APIWrapper,1,4.363462233903899e-09,"The method '_log_verbose_output' is designed to log detailed information for debugging purposes, which is a common requirement in software development. It includes functionality to truncate long messages and format them nicely for console output. Such methods are typically retained as they are useful for developers to diagnose issues and understand the flow of data. Therefore, it is likely to survive."
survived,"    async def test_score_rollout_single(self):
        """"""Test scoring a single rollout.""""""
        def func1(completion, answer, **kwargs):
            return 1.0 if completion == answer else 0.0
        
        def func2(completion, **kwargs):
            return len(completion) * 0.1
        
        rubric = Rubric(funcs=[func1, func2], weights=[1.0, 0.5])
        
        result = await rubric.score_rollout(
            prompt=""test prompt"",
            completion=""test"",
            answer=""test"",
            state={},
            task=""test_task"",
            info={}
        )
        
        assert ""func1"" in result
        assert ""func2"" in result
        assert ""reward"" in result
        assert result[""func1""] == 1.0  # completion == answer
        assert result[""func2""] == 0.4  # len(""test"") * 0.1
        assert result[""reward""] == 1.0 * 1.0 + 0.4 * 0.5  # Weighted sum
",tests/test_rubric.py,TestRubric,1,2.1024340680345882e-07,"The method `test_score_rollout_single` is a unit test for a specific functionality, which is essential for ensuring the correctness of the `score_rollout` method in the `Rubric` class. Unit tests are crucial for maintaining code quality and reliability, especially in asynchronous environments where bugs can be harder to trace. The test checks the integration of multiple scoring functions and their weighted contributions to the final reward, which is a common pattern in testing scoring systems. Therefore, it is likely to be retained as part of the test suite."
survived,"    def test_parse_empty_fields(self, xml_parser):
        """"""Test parsing XML with empty fields.""""""
        xml_text = ""<reasoning></reasoning><answer></answer>""
        result = xml_parser.parse(xml_text)
        assert result.reasoning == """"
        assert result.answer == """"
",tests/test_xml_parser.py,TestXMLParser,1,3.3982678079468468e-09,"The method 'test_parse_empty_fields' is a unit test designed to verify that the 'xml_parser' can correctly handle XML elements with empty fields. This is a common edge case that parsers need to handle, and having a test for it is important to ensure robustness. The method is straightforward, does not contain any deprecated practices, and serves a clear purpose in testing the functionality of the parser. Therefore, it is likely to be retained in the codebase."
survived,"            def env_response(self, messages, state, **kwargs):
                # This should never be called due to immediate completion
                return {""role"": ""user"", ""content"": ""Should not appear""}, state
",tests/test_multiturn_env.py,TestMultiTurnEnv.ImmediateCompletionEnv,1,5.715002851580502e-07,"The method `env_response` is designed to handle a situation that should never occur, as indicated by the comment. This suggests that the method is a safeguard or placeholder for unexpected behavior. Such methods are often kept in codebases to ensure robustness and to handle edge cases gracefully, even if they are not expected to be called under normal circumstances. Therefore, it is likely to be retained in the codebase as a defensive programming measure."
survived,"    def test_rubric_group_initialization(self):
        """"""Test RubricGroup initialization with multiple rubrics.""""""
        def func1(completion, **kwargs):
            return 1.0
        
        def func2(completion, **kwargs):
            return 0.5
        
        rubric1 = Rubric(funcs=[func1], weights=[1.0])
        rubric2 = Rubric(funcs=[func2], weights=[0.8])
        
        rubrics = [rubric1, rubric2]
        group = RubricGroup(rubrics=rubrics)
        
        assert group.rubrics == rubrics
        assert len(group.rubrics) == 2
",tests/test_rubric_group.py,TestRubricGroup,1,1.4166087846364157e-09,"The method 'test_rubric_group_initialization' is a unit test that verifies the initialization of a 'RubricGroup' with multiple 'Rubric' objects. It checks that the 'RubricGroup' correctly stores the list of rubrics and that the length of the rubrics list is as expected. This is a fundamental test to ensure that the 'RubricGroup' class is functioning as intended when initialized. Such tests are crucial for maintaining code quality and are typically retained in the codebase to prevent regressions. Therefore, it is likely to survive."
survived,"    def test_format_reward_function_bad_format(self, think_parser):
        """"""Test format reward function with poorly formatted content.""""""
        reward_func = think_parser.get_format_reward_func()
        
        # Missing think tags
        bad_completion1 = [
            {""role"": ""assistant"", ""content"": ""Just an answer without thinking""}
        ]
        reward1 = reward_func(bad_completion1)
        assert reward1 == 0.0
        
        # Multiple think tags
        bad_completion2 = [
            {""role"": ""assistant"", ""content"": ""<think>First</think><think>Second</think>Answer""}
        ]
        reward2 = reward_func(bad_completion2)
        assert reward2 == 0.0
        
        # No content after think
        bad_completion3 = [
            {""role"": ""assistant"", ""content"": ""<think>Only thinking</think>""}
        ]
        reward3 = reward_func(bad_completion3)
        assert reward3 == 0.0
",tests/test_think_parser.py,TestThinkParser,1,3.850741907939403e-09,"The method 'test_format_reward_function_bad_format' is a unit test designed to verify the behavior of a reward function when it encounters poorly formatted input. It checks for specific cases such as missing tags, multiple tags, and lack of content after a tag. These are important test cases to ensure the robustness of the reward function. Since testing for edge cases and ensuring the function handles them correctly is a crucial part of software development, this method is likely to be retained as it contributes to the reliability and correctness of the code."
survived,"    def test_rubric_initialization_empty(self):
        """"""Test Rubric initialization with no parameters.""""""
        rubric = Rubric()
        
        assert rubric.reward_funcs == []
        assert rubric.reward_weights == []
        assert isinstance(rubric.parser, Parser)
",tests/test_rubric.py,TestRubric,1,1.1861120010657661e-08,"The method `test_rubric_initialization_empty` is a unit test designed to verify the correct initialization of a `Rubric` object with default parameters. Unit tests are crucial for ensuring code reliability and are typically retained in the codebase to maintain software quality. This test checks that the `Rubric` object initializes its attributes correctly, which is a fundamental aspect of its functionality. Therefore, it is unlikely to be deleted as it serves an important role in validating the behavior of the `Rubric` class."
survived,"    def test_rubric_initialization_with_functions(self):
        """"""Test Rubric initialization with reward functions.""""""
        def reward_func1(completion, answer, **kwargs):
            return 1.0 if completion == answer else 0.0
        
        def reward_func2(completion, **kwargs):
            return len(completion) * 0.1
        
        funcs = [reward_func1, reward_func2]
        weights = [1.0, 0.5]
        
        rubric = Rubric(funcs=funcs, weights=weights)
        
        assert rubric.reward_funcs == funcs
        assert rubric.reward_weights == weights
        assert len(rubric.get_reward_func_names()) == 2
        assert rubric.get_reward_func_names() == [""reward_func1"", ""reward_func2""]
",tests/test_rubric.py,TestRubric,1,2.0611536181902033e-09,"The method is a unit test that verifies the initialization of a Rubric object with specific reward functions and weights. It checks that the functions and weights are correctly assigned and that the function names are retrieved as expected. This is a typical and necessary test to ensure that the Rubric class behaves as intended when initialized with these parameters. There is no indication of redundancy or obsolescence, and it serves a clear purpose in validating the functionality of the Rubric class."
survived,"        def func2(completion, **kwargs):
            return len(completion) * 0.1
",tests/test_rubric.py,TestRubric,1,5.60279640614594e-09,"The method 'func2' is a simple utility function that calculates 10% of the length of the input string 'completion'. It is a straightforward and potentially useful function for scenarios where such a calculation is needed. The function is generic and does not have any apparent issues or redundancies that would necessitate its deletion. Therefore, it is likely to be retained in the codebase."
survived,"    def _handle_text_completion(self, prompt, **kwargs):
        """"""Handle text completion requests.""""""
        if prompt in self.text_completions:
            response_data = self.text_completions[prompt]
        else:
            response_data = {
                ""text"": self.default_text_response,
                ""finish_reason"": ""stop""
            }
        
        # Create mock response
        mock_response = MagicMock()
        mock_response.choices = [MagicMock()]
        mock_response.choices[0].text = response_data[""text""]
        mock_response.choices[0].finish_reason = response_data[""finish_reason""]
        return mock_response
",tests/conftest.py,MockAsyncOpenAI,1,5.60279640614594e-09,"The method '_handle_text_completion' is a utility function that handles text completion requests by checking if a prompt exists in a predefined dictionary and returning a mock response. This method is likely part of a larger system that deals with text generation or completion tasks, possibly for testing purposes. Since it serves a specific purpose and is not redundant or obsolete, it is likely to be retained in the codebase."
survived,"def sample_chat_dataset():
    """"""Return a sample dataset with chat format.""""""
    return Dataset.from_dict({
        ""prompt"": [
            [{""role"": ""user"", ""content"": ""What is 2+2?""}],
            [{""role"": ""user"", ""content"": ""What is the capital of France?""}]
        ],
        ""answer"": [""4"", ""Paris""]
    })
",tests/conftest.py,,1,4.944450477491054e-09,"The method 'sample_chat_dataset' is a utility function that provides a sample dataset in a chat format, which can be useful for testing or demonstration purposes. Such utility functions are often retained in codebases because they provide a quick way to generate example data without needing to manually create it each time. Additionally, the function is simple, self-contained, and does not have any dependencies that would make it obsolete or redundant. Therefore, it is likely to be retained in the codebase."
survived,"    async def test_a_generate_basic(self, mock_singleturn_env):
        """"""Test async generation with basic inputs.""""""
        inputs = {
            ""prompt"": [
                [{""role"": ""user"", ""content"": ""What is 2+2?""}],
                [{""role"": ""user"", ""content"": ""What is 3+3?""}]
            ],
            ""answer"": [""4"", ""6""]
        }
        
        # Mock the rubric.score_rollouts method
        mock_singleturn_env.rubric.score_rollouts = AsyncMock(return_value={
            ""rewards"": [1.0, 1.0],
            ""scores"": [{""correctness"": 1.0}, {""correctness"": 1.0}]
        })
        
        results = await mock_singleturn_env.a_generate(inputs)
        
        assert ""completion"" in results
        assert ""state"" in results
        assert ""rewards"" in results
        assert len(results[""completion""]) == 2
        assert len(results[""state""]) == 2
",tests/test_singleturn_env.py,TestSingleTurnEnv,1,2.5109990926928157e-08,"The method `test_a_generate_basic` is a unit test for an asynchronous function, which is a common practice in modern software development. It uses mocking to simulate the behavior of external dependencies, allowing for isolated testing of the function's logic. The test checks for the presence of expected keys in the results and verifies the length of the output, which are standard assertions in test cases. Given the importance of testing in ensuring code reliability and the increasing use of asynchronous programming, it is likely that this method will be maintained to ensure the correctness of the `a_generate` function."
survived,"    def test_xml_parser_initialization(self, xml_parser):
        """"""Test that XMLParser initializes correctly.""""""
        assert isinstance(xml_parser, XMLParser)
        assert xml_parser.answer_field == ""answer""
",tests/test_xml_parser.py,TestXMLParser,1,6.348800075736417e-09,"The method 'test_xml_parser_initialization' is a unit test designed to verify the correct initialization of an XMLParser object. Unit tests are crucial for ensuring code reliability and are typically retained in codebases to maintain software quality. The method is straightforward, checks essential properties of the XMLParser, and does not contain any deprecated or redundant logic. Therefore, it is likely to be retained."
survived,"    def test_completion_mode_with_system_prompt_raises_error(self, mock_openai_client, sample_dataset):
        """"""Test that completion mode with system prompt raises error.""""""
        with pytest.raises(ValueError, match=""not supported for completion tasks""):
            TestEnvironment(
                client=mock_openai_client,
                model=""test-model"",
                dataset=sample_dataset,
                message_type=""completion"",
                system_prompt=""test prompt"",
                parser=Parser(),
                rubric=Rubric()
            )
",tests/test_environment.py,TestEnvironmentBase,1,4.944450477491054e-09,"The method is a unit test designed to ensure that a specific error is raised when an unsupported configuration is used. Such tests are crucial for maintaining code quality and ensuring that the system behaves as expected in edge cases. Deleting this test could lead to undetected issues in the future if the system prompt is mistakenly used in completion mode. Therefore, it is likely to be retained."
survived,"def xml_parser_with_alternatives():
    """"""Return an XMLParser instance with alternative field names.""""""
    return XMLParser(
        fields=[""reasoning"", (""code"", ""answer"")],
        answer_field=""answer""
    )
",tests/conftest.py,,0,0.9999999907625504,"The method 'xml_parser_with_alternatives' is likely to be deleted (0) because it references an 'XMLParser' class or function that is not defined within the provided code snippet. Without the definition or import of 'XMLParser', this method cannot function as intended, leading to potential errors or confusion. Additionally, the method's purpose is not clear without further context on how 'XMLParser' is supposed to work with the given fields and answer_field parameters."
survived,"    def setup(self, mock_config):
        """"""Set up transformer for each test.""""""
        self.transformer = PkgxTransformer(mock_config, None)
",tests/package_managers/crates/test_special_case.py,TestSpecialCase,1,4.1399375473943306e-08,"The method 'setup' is a common pattern in testing frameworks to initialize or configure objects before each test case runs. This method is likely part of a test suite, and such setup methods are essential for preparing the test environment. Therefore, it is unlikely to be deleted as it serves a crucial role in ensuring tests are run in a controlled and repeatable manner."
survived,"def package_ids():
    """"""Fixture providing consistent package IDs for testing.""""""
    return {
        ""foo"": uuid4(),
        ""bar"": uuid4(),
        ""baz"": uuid4(),
        ""qux"": uuid4(),
    }
",tests/package_managers/homebrew/test_diff_dep.py,,1,2.646573631904765e-09,"The method 'package_ids' is a simple utility function that generates a dictionary of unique identifiers using the 'uuid4' function. This is a common pattern in testing to ensure that each test run uses unique identifiers, which helps in avoiding conflicts and ensuring test isolation. Such utility functions are generally useful and are likely to be retained in the codebase as they provide a consistent way to generate test data. Therefore, the method is likely to survive."
survived,"def mock_sources():
    """"""
    Mock sources with consistent UUIDs for testing.

    Returns a dict mapping source names to mock Source objects.
    """"""
    return {
        ""github"": Mock(
            spec=Source, id=uuid.UUID(""00000000-0000-0000-0000-000000000020"")
        ),
        ""crates"": Mock(
            spec=Source, id=uuid.UUID(""00000000-0000-0000-0000-000000000021"")
        ),
        ""homebrew"": Mock(
            spec=Source, id=uuid.UUID(""00000000-0000-0000-0000-000000000022"")
        ),
        ""debian"": Mock(
            spec=Source, id=uuid.UUID(""00000000-0000-0000-0000-000000000023"")
        ),
        ""pkgx"": Mock(spec=Source, id=uuid.UUID(""00000000-0000-0000-0000-000000000024"")),
    }
",tests/conftest.py,,1,9.237449576640118e-09,"The method `mock_sources` is a utility function designed to create mock objects for testing purposes. It provides a consistent set of mock Source objects with predefined UUIDs, which is useful for ensuring that tests are repeatable and reliable. Such utility functions are commonly used in software development to facilitate testing, especially in environments where dependency injection or mocking is necessary. Given its utility in testing, it is likely to be retained in the codebase as long as the testing framework or the need for mocking these specific sources remains relevant."
survived,"    def test_load_urls(self, mock_config, test_scenarios):
        """"""Test URL loading for different scenarios.""""""
        for scenario_name, scenario in test_scenarios.items():
            # Set up cache for this scenario
            cache = Cache(
                package=Package(
                    id=scenario[""package_id""], import_id=scenario[""import_id""]
                ),
                urls=[
                    URL(
                        url=url,
                        url_type_id=mock_config.db.select_url_types_by_name(
                            url_type
                        ).id,
                    )
                    for url, url_types in scenario[""transformer_urls""]
                    for url_type in url_types
                ],
                dependencies=Dependencies(),
            )

            # Create cache map as expected by loader
            cache_map = {scenario[""import_id""]: cache}

            # Create loader with our test data
            loader = PkgxLoader(mock_config, cache_map)

            # Mock DB state for this scenario
            current_urls_mock = MagicMock()
            current_urls_mock.url_map = scenario[""db_state""][""urls""]
            current_urls_mock.package_urls = scenario[""db_state""][""package_urls""]

            # Mock the get_current_urls method
            mock_config.db.get_current_urls = MagicMock()
            mock_config.db.get_current_urls.return_value = current_urls_mock

            # Mock the session for loader operations
            mock_config.db.session = MagicMock()
            mock_session = MagicMock()
            mock_config.db.session.return_value.__enter__.return_value = mock_session

            # Track calls to verify behavior
            urls_added = []
            package_urls_added = []
            urls_updated = []

            def track_add(obj):
                if hasattr(obj, ""url""):  # It's a URL object
                    urls_added.append(obj)
                else:  # It's a PackageURL object
                    package_urls_added.append(obj)

            def track_bulk_update(mapper, mappings):
                urls_updated.extend(mappings)

            mock_session.add.side_effect = track_add
            mock_session.bulk_update_mappings.side_effect = track_bulk_update

            # Run the loader
            loader.load_urls()

            # Verify expected behavior
            expected = scenario[""expected_behavior""]
            assert (
                len(urls_added) == expected[""new_urls_created""]
            ), f""Scenario {scenario_name}: Expected {expected['new_urls_created']} new URLs, got {len(urls_added)}""  # noqa: E501
            assert (
                len(package_urls_added) == expected[""new_package_urls_created""]
            ), f""Scenario {scenario_name}: Expected {expected['new_package_urls_created']} new PackageURLs, got {len(package_urls_added)}""  # noqa: E501

            # URLs updated is tracked through bulk_update_mappings calls
            if expected[""urls_updated""] > 0:
                assert mock_session.bulk_update_mappings.called, f""Scenario {scenario_name}: Expected bulk_update_mappings to be called""  # noqa: E501
                # Check that the right number of URLs were updated
                total_updated = sum(
                    len(call[0][1])
                    for call in mock_session.bulk_update_mappings.call_args_list
                )
                assert (
                    total_updated == expected[""urls_updated""]
                ), f""Scenario {scenario_name}: Expected {expected['urls_updated']} URLs updated, got {total_updated}""  # noqa: E501",tests/package_managers/pkgx/test_pkgx_load_urls.py,TestPkgxLoader,1,4.1399375473943306e-08,"The method `test_load_urls` is a unit test designed to verify the behavior of the `load_urls` function in different scenarios. It uses mock objects to simulate database interactions and checks if the expected number of URLs and PackageURLs are created or updated. This method is crucial for ensuring the correctness of the `load_urls` function, especially in a complex system where URL management is important. Unit tests are generally not deleted unless the functionality they test is removed or significantly changed. Therefore, this method is likely to be retained as long as the `load_urls` function exists."
survived,"def capture_ingest_calls(mock_db):
    """"""Helper function to capture arguments passed to db.ingest.""""""
    ingest_calls = []

    def capture_ingest(new_canons, new_canon_packages, updated_canon_packages):
        ingest_calls.append((new_canons, new_canon_packages, updated_canon_packages))

    mock_db.ingest.side_effect = capture_ingest
    return ingest_calls
",tests/ranker/test_dedupe.py,,1,8.592166611791576e-10,"The method 'capture_ingest_calls' is a utility function designed to capture and store the arguments passed to a mock database's 'ingest' method. This is a common pattern in testing, where capturing calls to a mock object is necessary to verify that the code under test interacts with the mock as expected. Such utility functions are often retained in codebases because they facilitate testing and improve test reliability. Therefore, it is likely that this method will survive."
survived,"def map_sample_data_with_extra_keys():
    return [
        {
            ""text"": ""This is a positive sentence."",
            ""original_sentiment"": ""positive"",
            ""to_be_dropped"": ""extra"",
        },
        {
            ""text"": ""This is a negative sentence."",
            ""original_sentiment"": ""negative"",
            ""to_be_dropped"": ""extra"",
        },
        {
            ""text"": ""This is a neutral sentence."",
            ""original_sentiment"": ""neutral"",
            ""to_be_dropped"": ""extra"",
        },
    ]
",tests/basic/test_basic_map.py,,0,0.999999057755336,"The method `map_sample_data_with_extra_keys` is likely to be deleted because it includes a key `to_be_dropped` in each dictionary, which suggests that this key is not needed or relevant for the intended use of the data. The presence of this key indicates that the method may be a temporary or transitional solution, and the data structure might be refined to remove unnecessary elements. Additionally, the method does not perform any operations beyond returning a static list, which might not be useful in a dynamic or production environment."
survived,"def map_config_with_drop_keys_no_prompt():
    return {
        ""name"": ""drop_keys_only"",
        ""type"": ""map"",
        ""drop_keys"": [""to_be_dropped""],
        ""model"": ""gpt-4o-mini"",
    }
",tests/basic/test_basic_map.py,,1,1.8189616842444243e-09,"The method `map_config_with_drop_keys_no_prompt` is a simple configuration function that returns a dictionary with specific settings. It is likely part of a larger system where configurations are dynamically generated or modified. The method is straightforward, does not have any apparent issues, and serves a clear purpose by defining a configuration with a specific model and drop keys. Unless there is a significant change in the system requirements or architecture that makes this configuration obsolete, there is no reason to delete it. Therefore, it is likely to survive."
survived,"    def test_go_real_world_example(self):
        # Based on a typical Go service with various function types
        patch = """"""
@@ -73,9 +73,7 @@ func NewService(db *sql.DB) *Service

@@ -87,7 +87,8 @@ func (s *Service) GetUser(ctx context.Context, id int) (*User, error)

@@ -95,6 +95,7 @@ func (s *Service) CreateUser(user *User) error

@@ -103,4 +107,23 @@ func validateEmail(email string) bool

@@ -115,6 +118,13 @@ var logger = func(msg string) {

@@ -125,7 +125,7 @@ func (s *Service) updateCache(key string, value interface{})

@@ -135,8 +135,8 @@ handleError := func(err error) {

@@ -145,10 +145,10 @@ func init()

@@ -168,15 +168,15 @@ func main()

""""""

        assert GoParser.extract_functions_from_patch(patch) == {
            ""NewService"",
            ""GetUser"",
            ""CreateUser"",
            ""validateEmail"",
            ""logger"",
            ""updateCache"",
            ""handleError"",
            ""init"",
            ""main"",
        }
",tests/sentry/integrations/source_code_management/test_language_parsers.py,GoParserTestCase,1,9.237449576640118e-09,"The method `test_go_real_world_example` is a test function that verifies the functionality of `GoParser.extract_functions_from_patch`. It checks if the function correctly extracts function names from a given patch. Test functions are crucial for ensuring code reliability and correctness, especially in a development environment. Since this method is a test case, it is likely to be maintained to ensure the associated functionality works as expected. Therefore, it is more likely to survive."
survived,"    def smtp_provider(self, context_manager, smtp_config):
        """"""Create an SMTP provider instance.""""""
        return SmtpProvider(
            context_manager=context_manager,
            provider_id=""test_smtp_provider"",
            config=smtp_config,
        )
",tests/test_smtp_provider.py,TestSmtpProvider,1,5.211412485172657e-10,"The method 'smtp_provider' is a utility function that creates and returns an instance of 'SmtpProvider'. It is likely to be used in various parts of the codebase where an SMTP provider instance is needed. The method is straightforward, has a clear purpose, and is likely to be reused, which makes it a candidate for survival. Unless there is a significant change in the architecture or the 'SmtpProvider' class is deprecated, this method will likely survive."
survived,"def test_numpy_arrays():
    import numpy as np

    serializer = EventSerializer()

    # Test 1D array
    arr_1d = np.array([1, 2, 3])
    assert json.loads(serializer.encode(arr_1d)) == [1, 2, 3]

    # Test 2D array
    arr_2d = np.array([[1, 2], [3, 4]])
    assert json.loads(serializer.encode(arr_2d)) == [[1, 2], [3, 4]]

    # Test float array
    arr_float = np.array([1.1, 2.2, 3.3])
    assert json.loads(serializer.encode(arr_float)) == [1.1, 2.2, 3.3]

    # Test empty array
    arr_empty = np.array([])
    assert json.loads(serializer.encode(arr_empty)) == []

    # Test mixed types that numpy can handle
    arr_mixed = np.array([1, 2.5, 3])
    assert json.loads(serializer.encode(arr_mixed)) == [1.0, 2.5, 3.0]",tests/test_serializer.py,,1,1.725782769012759e-08,"The method `test_numpy_arrays` is a unit test function that tests the functionality of an `EventSerializer` class to correctly encode numpy arrays into JSON format. This is a common requirement in data processing and serialization tasks, especially when dealing with numerical data in Python. The method covers various cases such as 1D arrays, 2D arrays, float arrays, empty arrays, and mixed-type arrays, which are typical scenarios that need to be handled in data serialization. Given its comprehensive nature and relevance to data handling tasks, it is likely to be useful for ensuring the correctness of the serialization process. Therefore, it is likely to be retained in the codebase."
survived,"def workflow_share_delete(
        share_id: int,
        _: schemas.TokenPayload = Depends(get_current_active_user)) -> Any:
    """"""
    删除分享
    """"""
    state, errmsg = WorkflowHelper().share_delete(share_id=share_id)
    return schemas.Response(success=state, message=errmsg)
",app/api/endpoints/workflow.py,,1,1.8189616842444243e-09,"The method `workflow_share_delete` is likely to survive because it performs a specific and necessary function within an application: deleting a shared item. This is a common operation in many systems that manage user-generated content or collaborative resources. The method is also well-structured, using dependency injection to ensure that only authenticated users can perform the delete operation, which is a good practice for security. Additionally, it returns a response with a success state and message, which is useful for client-side handling of the operation's result."
survived,"def workflow_shares(
        name: Optional[str] = None,
        page: Optional[int] = 1,
        count: Optional[int] = 30,
        _: schemas.TokenPayload = Depends(get_current_active_user)) -> Any:
    """"""
    查询分享的工作流
    """"""
    return WorkflowHelper().get_shares(name=name, page=page, count=count)
",app/api/endpoints/workflow.py,,1,1.8189616842444243e-09,"The method 'workflow_shares' is likely to survive because it appears to be a well-defined function that serves a specific purpose in the application. It is designed to query shared workflows, which is a common feature in applications that manage workflows or tasks. The use of parameters like 'name', 'page', and 'count' suggests that it supports pagination and filtering, which are essential for handling large datasets efficiently. Additionally, the use of dependency injection with 'Depends(get_current_active_user)' indicates that it incorporates user authentication, enhancing security. These factors contribute to its utility and relevance in the application."
survived,"    def __init__(self):
        self.base_url = ""https://api.dexscreener.com/latest/dex""
",python/src/plugins/dexscreener/goat_plugins/dexscreener/service.py,DexscreenerService,1,4.1399375473943306e-08,"The method is a constructor for a class, initializing an instance variable 'base_url'. Constructors are fundamental to class definitions in object-oriented programming, and this one sets up a base URL for what appears to be an API interaction. There is no indication that this method is redundant or unnecessary, as it serves a clear purpose in setting up the initial state of an object. Therefore, it is likely to be retained."
survived,"    async def get_token_pairs_by_token_address(self, parameters: dict):
        addresses = "","".join(parameters[""tokenAddresses""])
        url = f""{self.base_url}/tokens/{addresses}""
        return await self._fetch(url, ""get token pairs"")",python/src/plugins/dexscreener/goat_plugins/dexscreener/service.py,DexscreenerService,1,3.581747929000289e-10,"The method 'get_token_pairs_by_token_address' is likely to survive because it performs a specific and useful function: it constructs a URL using token addresses and fetches data asynchronously. This is a common pattern in modern web applications, especially those dealing with APIs and asynchronous operations. The method is concise, uses async/await for non-blocking operations, and leverages string manipulation to handle multiple addresses, which are all good practices in Python programming."
survived,"    async def get_cast(self, parameters: dict):
        url = f""{self.base_url}/cast?identifier={parameters['identifier']}&type={parameters['type']}""
        return await self._make_request(""GET"", url)
",python/src/plugins/farcaster/goat_plugins/farcaster/service.py,FarcasterService,1,7.582560422162384e-10,"The method 'get_cast' is likely to survive because it is a straightforward asynchronous function that constructs a URL using parameters and makes a GET request. It follows a common pattern for API calls, which is essential for fetching data in many applications. The method is also flexible, as it takes a dictionary of parameters, making it adaptable to different use cases. Unless there is a significant change in the application's requirements or architecture, such as a shift away from using this API or a change in how requests are handled, this method is likely to remain useful."
deleted,"def plot_stock_comparison(tickers: list[str], days: int = 30) -> str:
    end_date = datetime.today()
    start_date = end_date - timedelta(days=days)
    
    plt.figure(figsize=(12, 6))
    for ticker in tickers:
        data = yf.download(ticker, start=start_date, end=end_date)
        normalized_price = data['Close'] / data['Close'].iloc[0] * 100
        plt.plot(data.index, normalized_price, label=ticker)
    
    plt.title('Stock Price Performance Comparison')
    plt.xlabel('Date')
    plt.ylabel('Normalized Price (%)')
    plt.legend()
    plt.grid(True)
    
    filename = 'stock_comparison.png'
    plt.savefig(filename)
    plt.close()
    return filename
",financial_analysis/functions.py,,1,2.0611536181902033e-09,"The method `plot_stock_comparison` is a useful utility for visualizing stock performance over a specified period. It uses popular libraries like `matplotlib` for plotting and `yfinance` for fetching stock data, which are commonly used in financial data analysis. The method is well-structured, with clear input parameters and a return value that provides the filename of the saved plot. This functionality is valuable for users interested in financial analysis, making it likely to be retained in the codebase."
deleted,"def analyze_market_data(ticker: str, days: int = 30) -> dict:
    data = yf.download(ticker, start=datetime.today()-timedelta(days=days), end=datetime.today())
    return {
        'avg_volume': data['Volume'].mean(),
        'volatility': data['Close'].pct_change().std() * 100,
        'high': data['High'].max(),
        'low': data['Low'].min(),
        'trading_days': len(data)
    }",financial_analysis/functions.py,,1,2.7894680920908113e-10,"The method 'analyze_market_data' is a useful utility function for analyzing stock market data. It provides key insights such as average volume, volatility, highest and lowest prices, and the number of trading days over a specified period. These are common metrics used in financial analysis, making the function valuable for users interested in market trends. Additionally, the function is well-structured, uses clear parameter names, and leverages the popular 'yfinance' library for data retrieval, which is widely used in financial data analysis. Therefore, it is likely to be retained in the codebase."
deleted,"    def category(self) -> CheckCategory:
        return CheckCategory.METADATA
",airbyte-ci/connectors/connectors_qa/src/connectors_qa/checks/version.py,VersionCheck,1,1.725782769012759e-08,"The method 'category' is a simple getter method that returns a constant value, 'CheckCategory.METADATA'. Such methods are often used to provide a clear and consistent way to access certain properties or constants related to a class. Unless there is a significant change in the design or requirements that makes this method redundant or unnecessary, it is likely to be retained. Getter methods like this are common in object-oriented programming to encapsulate and manage access to class properties."
survived,"def run_final_polars_code(reasoning: str, csv_path: str, polars_python_code: str, output_file: Optional[str] = None) -> str:
    """"""Executes the final Polars code and returns results to user.

    This is the last tool call the agent should make after validating the code.
    The code should be fully tested and ready for production use.
    Results will be displayed to the user and optionally saved to a file.

    Args:
        reasoning: Final explanation of how this code satisfies user request
        csv_path: Path to the CSV file
        polars_python_code: The validated Polars Python code to run. Should use pl.scan_csv() for lazy evaluation.
        output_file: Optional path to save results to. Use .csv or .json extension.

    Returns:
        Code execution results as a string

    Example:
        result = run_final_polars_code(
            ""Calculating average user age"",
            ""data.csv"",
            '''
            # Calculate average age using lazy evaluation
            result = df.select(pl.col(""age"").mean().alias(""avg_age"")).collect()
            print(""Average age:"", float(result[0, ""avg_age""]))
            ''',
            ""results.csv""
        )
    """"""
    try:
        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
            # Ensure code is properly indented
            indented_code = ""\n"".join(""    "" + line if line.strip() else line 
                                    for line in polars_python_code.splitlines())
            
            script = '''import polars as pl
import sys

try:
    # Read the CSV file using lazy evaluation
    df = pl.scan_csv(""{csv_path}"")
    
    # Execute the user's code
{code}
    
    # If no result was explicitly printed, try to collect and display
    if 'result' not in locals():
        if any(var for var in locals().values() if isinstance(var, (pl.LazyFrame, pl.DataFrame))):
            result = next(var for var in reversed(list(locals().values())) 
                      if isinstance(var, (pl.LazyFrame, pl.DataFrame)))
            if isinstance(result, pl.LazyFrame):
                result = result.collect()
        else:
            result = df.collect()
    
    # Handle output file if specified
    output_file = {output_file}
    if output_file:
        if isinstance(result, pl.DataFrame):
            if output_file.endswith('.csv'):
                result.write_csv(output_file)
            elif output_file.endswith('.json'):
                result.write_json(output_file)
            else:
                result.write_csv(output_file + '.csv')  # Default to CSV
        else:
            # For non-DataFrame results, create a single column DataFrame
            pl.DataFrame({{""result"": [str(result)]}}).write_csv(output_file)
        print(""Results written to "" + str(output_file))
    
    # Convert result to string for display
    if isinstance(result, pl.DataFrame):
        print(result.select(pl.all()).write_csv(None))
    else:
        print(str(result))
except Exception as e:
    print(""Error: "" + str(e), file=sys.stderr)
    sys.exit(1)
'''
            script_content = script.format(
                csv_path=csv_path,
                code=indented_code,
                output_file=repr(output_file) if output_file else 'None'
            )
            f.write(script_content)
            temp_file = f.name
            temp_file = f.name

        result = subprocess.run(['uv', 'run', '--with', 'polars', temp_file],
                              capture_output=True, text=True)
        os.unlink(temp_file)

        if result.returncode != 0:
            return f""Error: {result.stderr}""

        console.log(
            Panel(
                f""[green]Final Code Tool[/green]\nReasoning: {reasoning}\nCode:\n{polars_python_code}""
            )
        )
        return result.stdout
    except Exception as e:
        console.log(f""[red]Error running final code: {str(e)}[/red]"")
        return str(e)
",sfa_polars_csv_agent_openai_v2.py,,1,1.1861120010657661e-08,"The method is well-documented, has a clear purpose, and includes error handling. It uses Polars for data processing, which is efficient for handling large datasets. The method also provides flexibility with optional output file saving and handles different file formats. These features make it a useful utility for data processing tasks, suggesting it will likely be retained."
deleted,"def test_scrape_url_with_parse_pdf_false():
    if TEST_API_KEY:
        app = FirecrawlApp(api_url=API_URL, api_key=TEST_API_KEY)
        response = app.scrape_url('https://arxiv.org/pdf/astro-ph/9301001.pdf', parse_pdf=False)
        assert response is not None
        assert 'markdown' in response
        assert 'h7uKu14adDL6yGfnGf2qycY5uq8kC3OKCWkPxm' in response['markdown']
",apps/python-sdk/firecrawl/__tests__/v1/e2e_withAuth/test.py,,1,5.60279640614594e-09,"The method `test_scrape_url_with_parse_pdf_false` is a test function that checks the functionality of the `scrape_url` method from the `FirecrawlApp` class. It verifies that when a PDF URL is scraped with `parse_pdf` set to `False`, the response contains a 'markdown' key and a specific string within the markdown content. This test is crucial for ensuring that the `scrape_url` method behaves correctly under specific conditions. Since testing is an essential part of software development to maintain code quality and reliability, this method is likely to be retained in the codebase."
survived,"def recognize_from_video():
    env_id = args.env_id
    net = ailia.Net(MODEL_PATH_6DRepNet360, WEIGHT_PATH_6DRepNet360, env_id=env_id)
    face_detect = ailia.Net(MODEL_PATH_FACE, WEIGHT_PATH_FACE, env_id=env_id)
    detector = RetinaFaceOnnx(face_detect)

    capture = webcamera_utils.get_capture(args.video)

    if args.savepath != SAVE_IMAGE_PATH:
        logger.warning(
            'currently, video results cannot be output correctly...'
        )
        f_h = int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT))
        f_w = int(capture.get(cv2.CAP_PROP_FRAME_WIDTH))
        save_h, save_w = f_h, f_w
        writer = webcamera_utils.get_writer(args.savepath, save_h, save_w)
    else:
        writer = None

    frame_shown = False
    while (True):
        ret, frame = capture.read()
        if (cv2.waitKey(1) & 0xFF == ord('q')) or not ret:
            break
        if frame_shown and cv2.getWindowProperty('frame', cv2.WND_PROP_VISIBLE) == 0:
            break

        frame = cv2.resize(frame, dsize=(640, 480))
        faces = detector(frame)
        for box, landmarks, score in faces:
            if score < .95:
                continue
            x_min = int(box[0])
            y_min = int(box[1])
            x_max = int(box[2])
            y_max = int(box[3])
            bbox_width = abs(x_max - x_min)
            bbox_height = abs(y_max - y_min)

            x_min = max(0, x_min - int(0.2 * bbox_height))
            y_min = max(0, y_min - int(0.2 * bbox_width))
            x_max = x_max + int(0.2 * bbox_height)
            y_max = y_max + int(0.2 * bbox_width)

            img = frame[y_min:y_max, x_min:x_max]
            img = cv2.resize(img, dsize=(HEIGHT, WIDTH))
            img = utils.transform(img, MEAN, STD)

            img = np.expand_dims(img, 0)
            img = np.array(img, dtype='float32')

            c = cv2.waitKey(1)
            if c == 27:
                break

            start = time.time()

            R_pred = net.run(img)[0]
            end = time.time()
            print('Head pose estimation: %2f ms' % ((end - start) * 1000.))

            euler = utils.compute_euler_angles_from_rotation_matrices(R_pred) * 180 / np.pi
            p_pred_deg = euler[:, 0]
            y_pred_deg = euler[:, 1]
            r_pred_deg = euler[:, 2]

            utils.plot_pose_cube(frame, y_pred_deg, p_pred_deg, r_pred_deg, x_min + int(.5 * (
                    x_max - x_min)), y_min + int(.5 * (y_max - y_min)), size=bbox_width)

        cv2.imshow(""Demo"", frame)
        cv2.waitKey(5)

        if writer is not None:
            writer.write(frame)

    capture.release()
    cv2.destroyAllWindows()
    if writer is not None:
        writer.release()
    logger.info('Script finished successfully.')
",face_recognition/6d_repnet_360/6d_repnet_360.py,,1,1.725782769012759e-08,"The method 'recognize_from_video' is a functional piece of code that performs a specific task: recognizing and estimating head poses from a video input. It utilizes machine learning models for face detection and head pose estimation, processes video frames, and displays the results. The method is well-structured, handles video input and output, and includes user interaction through keyboard inputs. Given its clear utility in video processing and head pose estimation, it is likely to be retained in the codebase unless there are significant changes in requirements or technology."
survived,"def get_pose_params_from_mat(mat_path):
    mat = sio.loadmat(mat_path)
    pre_pose_params = mat['Pose_Para'][0]
    pose_params = pre_pose_params[:5]
    return pose_params
",face_recognition/6d_repnet_360/utils_6d_repnet_360/utils.py,,1,2.0611536181902033e-09,"The method 'get_pose_params_from_mat' is a simple utility function that extracts pose parameters from a MATLAB file. It is likely to be used in a context where pose estimation or analysis is required, such as in computer vision or robotics applications. The function is straightforward, performs a specific task, and does not have any apparent issues or redundancies that would necessitate its deletion. Therefore, it is likely to be retained in the codebase."
survived,"def compute_rotation_matrix_from_ortho6d(poses, use_gpu=False):
    x_raw = poses[:, 0:3]
    y_raw = poses[:, 3:6]

    x = normalize_vector(x_raw, use_gpu)
    z = cross_product(x, y_raw)
    z = normalize_vector(z, use_gpu)
    y = cross_product(z, x)

    x = x.view(-1, 3, 1)
    y = y.view(-1, 3, 1)
    z = z.view(-1, 3, 1)
    matrix = torch.cat((x, y, z), 2)
    return matrix
",face_recognition/6d_repnet_360/utils_6d_repnet_360/utils.py,,1,2.0611536181902033e-09,"The method 'compute_rotation_matrix_from_ortho6d' is a utility function that computes a rotation matrix from a 6D orthogonal representation. This is a common task in computer graphics and robotics, where converting between different representations of rotations is necessary. The function is well-defined, uses standard operations like normalization and cross products, and is likely to be useful in various applications that require rotation matrices. Therefore, it is unlikely to be deleted as it serves a specific and useful purpose."
survived,"def download_model():
    import urllib.request
    model_url = ""https://cloud.ovgu.de/s/TewGC9TDLGgKkmS/download/6DRepNet360_Full-Rotation_300W_LP+Panoptic.pth""
    model_path = ""6DRepNet360_Full-Rotation_300W_LP+Panoptic.pth""
    
    if not os.path.exists(model_path):
        print(f""Downloading model from {model_url}"")
        urllib.request.urlretrieve(model_url, model_path)
        print(f""Model downloaded to {model_path}"")
    else:
        print(f""Model already exists at {model_path}"")
    
    return model_path
",face_recognition/6d_repnet_360/convert_to_onnx.py,,1,5.211412485172657e-10,"The method 'download_model' is a utility function that checks if a specific model file exists locally and downloads it if it doesn't. This is a common pattern in machine learning and data science workflows where models need to be loaded for inference or training. The function is straightforward, performs a necessary task, and includes informative print statements for user feedback. There are no apparent issues or inefficiencies in the code that would warrant its deletion. Therefore, it is likely to be retained in the codebase."
survived,"    async def run_async_tests():
        await async_no_stream()
        await async_stream()
",tests/core_manual_tests/providers/mistral_canary.py,,1,2.0611536181902033e-09,"The method 'run_async_tests' is a simple asynchronous function that calls two other asynchronous functions, 'async_no_stream' and 'async_stream'. There is no indication that this method is obsolete, redundant, or incorrect. It appears to be a utility function for testing purposes, likely used to ensure that both 'async_no_stream' and 'async_stream' functions work as expected. Without any context suggesting that this function is no longer needed or has been replaced, it is reasonable to predict that it will survive."
survived,"    async def async_no_stream():
        await async_chat_client.create(
            model=""jamba-instruct"",
            system=""You are a helpful AI assistant"",
            messages=async_messages,
            maxTokens=10
        )
",tests/core_manual_tests/providers/ai21_canary.py,,1,1.955568070542584e-08,"The method `async_no_stream` is an asynchronous function that calls `async_chat_client.create` with specific parameters. The method seems to be part of a larger asynchronous system, likely for handling chat or AI interactions. The method itself is simple and does not contain any deprecated or problematic code patterns. It is likely to be used in contexts where non-streaming responses are needed from the chat client. Given the increasing use of asynchronous programming in modern applications, especially for I/O-bound operations like network requests, this method is likely to be useful and relevant. Therefore, it is predicted to survive."
deleted,"            async def handle_coroutine():
                result = await response
                # Create a new LLM event for async response
                async_event = LLMEvent(init_timestamp=init_timestamp, params=kwargs)
                if session is not None:
                    async_event.session_id = session.session_id
                    async_event.agent_id = check_call_stack_for_agent_id()
                    async_event.model = kwargs.get(""model"", ""command-r-plus"")
                    async_event.prompt = kwargs.get(""message"", """")
                    async_event.returns = result
                    logger.info(f""Created new async LLM event with session_id: {session.session_id}"")
                if hasattr(result, ""text""):
                    async_event.completion = {
                        ""role"": ""assistant"",
                        ""content"": result.text
                    }
                    logger.info(f""Set completion for async LLM event: {result.text}"")
                elif hasattr(result, ""chat_history""):
                    async_event.prompt = []
                    role_map = {""USER"": ""user"", ""CHATBOT"": ""assistant"", ""SYSTEM"": ""system""}
                    for i in range(len(result.chat_history) - 1):
                        message = result.chat_history[i]
                        async_event.prompt.append({
                            ""role"": role_map.get(message.role, message.role),
                            ""content"": message.message,
                        })
                    last_message = result.chat_history[-1]
                    async_event.completion = {
                        ""role"": role_map.get(last_message.role, last_message.role),
                        ""content"": last_message.message,
                    }
                    async_event.prompt_tokens = int(result.meta.tokens.input_tokens)
                    async_event.completion_tokens = int(result.meta.tokens.output_tokens)
                    logger.info(f""Set chat history for async LLM event"")
                self._safe_record(session, async_event)
                return result
",agentops/llms/providers/cohere.py,CohereProvider,1,1.4166087846364157e-09,"The method 'handle_coroutine' is designed to handle asynchronous operations, which are increasingly common in modern programming due to their efficiency in handling I/O-bound tasks. The method is well-structured to handle different types of responses, such as text and chat history, and logs important information for debugging and tracking purposes. It also integrates with a session management system, which is crucial for maintaining state in asynchronous operations. Given these factors, the method is likely to be useful and relevant in its context, suggesting it will survive."
survived,"    def sync_stream():
        stream_response = anthropic_client.messages.create(
            max_tokens=1024,
            model=""claude-3-5-sonnet-20240620"",
            messages=[
                {
                    ""role"": ""user"",
                    ""content"": ""Hello from sync streaming"",
                }
            ],
            stream=True,
            session=session
        )
        for _ in stream_response:
            pass
",tests/core_manual_tests/providers/anthropic_canary.py,,0,0.9999999715466527,"The method `sync_stream` is likely to be deleted (0) because it doesn't perform any meaningful operations with the `stream_response`. The loop iterates over `stream_response` but does nothing with the data, which suggests that the method is incomplete or not useful in its current form. Without any processing or output, the method doesn't serve a clear purpose, making it a candidate for deletion unless further development is planned."
survived,"    def sync_no_stream():
        chat_client.create(
            model=""jamba-instruct"",
            system=""You are a helpful AI assistant"",
            messages=sync_messages,
            maxTokens=10
        )
",tests/core_manual_tests/providers/ai21_canary.py,,0,0.9999999677581336,"The method `sync_no_stream` is a simple wrapper around a call to `chat_client.create`. It doesn't have any complex logic or unique functionality that would make it indispensable. If the `chat_client.create` method is updated or if the parameters change, this method might become obsolete. Additionally, the method name `sync_no_stream` suggests it might be part of a larger set of methods, and if the streaming functionality is not needed or is integrated differently, this method could be removed. Therefore, it is likely to be deleted."
survived,"    async def async_no_stream():
        await async_groq_client.chat.completions.create(
            model=""llama3-70b-8192"",
            messages=[
                {""role"": ""user"", ""content"": ""Hello from async no stream""},
            ],
            session=session
        )
",tests/core_manual_tests/providers/groq_canary.py,,1,1.955568070542584e-08,"The method 'async_no_stream' is using an asynchronous call to 'async_groq_client.chat.completions.create', which suggests it is designed to handle non-blocking operations efficiently. Asynchronous programming is a modern and widely adopted approach in software development, especially for I/O-bound tasks. The method appears to be correctly implemented for its intended purpose, and there is no indication of deprecated practices or errors. Therefore, it is likely to be retained in the codebase."
survived,"def setup_dataset_root(temp_dir):
  """"""Set up the dataset root directory structure.""""""
  root_dir = os.path.join(temp_dir, ""dataset_root"")
  raw_dir = os.path.join(root_dir, ""Raw"")
  parsed_dir = os.path.join(root_dir, ""Parsed"")

  os.makedirs(raw_dir, exist_ok=True)
  os.makedirs(parsed_dir, exist_ok=True)

  return root_dir, raw_dir, parsed_dir
",tests/dataset_creation_test.py,,1,2.646573631904765e-09,"The method 'setup_dataset_root' is a utility function that sets up a directory structure for datasets, which is a common requirement in data processing and machine learning workflows. It creates directories if they do not exist, ensuring that the necessary folder structure is in place for subsequent data operations. This functionality is essential for organizing data and is likely to be reused in various projects. Therefore, it is a useful and necessary function that is unlikely to be deleted."
survived,"def main(_):
  """"""Main function to run the tests.""""""
  print(""Running single-threaded test..."")
  single_thread_data = test_dataset_creation(threads=1)

  print(""\nRunning parallel test..."")
  parallel_data = test_parallel_dataset_creation()

  assert len(single_thread_data) == len(parallel_data), (
    f""Single-threaded ({len(single_thread_data)} entries) and ""
    f""parallel ({len(parallel_data)} entries) results differ""
  )

  print(""\nAll tests passed!"")
  return 0
",tests/dataset_creation_test.py,,1,2.0611536181902033e-09,"The method 'main' is a standard entry point for running tests in a script. It includes print statements for user feedback, runs tests in both single-threaded and parallel modes, and checks for consistency between the two methods. The use of assertions to verify the results is a common practice in testing to ensure correctness. There is no indication that this method is obsolete or redundant, and it serves a clear purpose in the context of testing. Therefore, it is likely to be retained."
survived,"def main():
    # Set up argument parser
    parser = argparse.ArgumentParser(description=""Codebase Context Agent using Claude 3.7"")
    parser.add_argument(""-p"", ""--prompt"", required=True, help=""The user's request"")
    parser.add_argument(""-d"", ""--directory"", default=os.getcwd(), help=""Directory to search in (defaults to current working directory)"")
    parser.add_argument(""-g"", ""--globs"", nargs=""*"", default=[], help=""List of glob patterns to filter files (optional)"")
    parser.add_argument(""-e"", ""--extensions"", nargs=""*"", default=[], help=""List of file extensions to filter files (optional)"")
    parser.add_argument(""-q"", ""--quiet"", action=""store_true"", help=""Quiet mode (don't show logging)"")
    parser.add_argument(""-l"", ""--limit"", type=int, default=100, help=""Maximum number of files to return"")
    parser.add_argument(""-f"", ""--file-line-limit"", type=int, default=500, help=""Maximum number of lines per file"")
    parser.add_argument(""-c"", ""--compute"", type=int, default=10, help=""Maximum number of agent loops (default: 10)"")
    args = parser.parse_args()

    # Configure the API key
    ANTHROPIC_API_KEY = os.getenv(""ANTHROPIC_API_KEY"")
    if not ANTHROPIC_API_KEY:
        console.print(
            ""[red]Error: ANTHROPIC_API_KEY environment variable is not set[/red]""
        )
        console.print(
            ""Please get your API key from https://console.anthropic.com/settings/keys""
        )
        console.print(""Then set it with: export ANTHROPIC_API_KEY='your-api-key-here'"")
        sys.exit(1)

    client = Anthropic(api_key=ANTHROPIC_API_KEY)

    # Set global USER_PROMPT
    global USER_PROMPT
    USER_PROMPT = args.prompt

    # Configure quiet mode
    if args.quiet:
        console.quiet = True

    # Create a single combined prompt based on the full template
    completed_prompt = (
        AGENT_PROMPT.replace(""{{user_request}}"", args.prompt)
        .replace(""{{directory}}"", args.directory)
        .replace(""{{globs}}"", str(args.globs))
        .replace(""{{extensions}}"", str(args.extensions))
        .replace(""{{file_line_limit}}"", str(args.file_line_limit))
        .replace(""{{limit}}"", str(args.limit))
    )
    
    # Initialize messages with proper typing for Anthropic chat
    messages = [{""role"": ""user"", ""content"": completed_prompt}]

    compute_iterations = 0
    break_loop = False
    # Main agent loop
    while True:
        if break_loop or compute_iterations >= args.compute or len(RELEVANT_FILES) >= args.limit:
            break

        console.rule(
            f""[yellow]Agent Loop {compute_iterations+1}/{args.compute}[/yellow]""
        )
        compute_iterations += 1

        try:
            # Generate content with tool support
            response = client.messages.create(
                model=""claude-3-7-sonnet-20250219"",
                system=""You are a codebase context builder. Use the available tools to search, filter and determine which files in the codebase are relevant to the prompt (user query)."",
                messages=messages,
                tools=TOOLS,
                max_tokens=4000,
                thinking={
                    ""type"": ""enabled"",
                    ""budget_tokens"": 2000
                },
            )

            # Extract thinking block and other content
            thinking_block = None
            tool_use_block = None
            text_block = None
            
            if response.content:
                # Get the message content
                for content_block in response.content:
                    if content_block.type == ""thinking"":
                        thinking_block = content_block
                        previous_thinking = thinking_block
                    elif content_block.type == ""tool_use"":
                        tool_use_block = content_block
                        # Access the proper attributes directly
                        tool_name = content_block.name
                        tool_input = content_block.input
                        tool_id = content_block.id
                    elif content_block.type == ""text"":
                        text_block = content_block
                        console.print(f""[cyan]Model response:[/cyan] {content_block.text}"")
                
                # Handle text responses if there was no tool use
                if not tool_use_block and text_block:
                    messages.append({
                        ""role"": ""assistant"", 
                        ""content"": [
                            *([thinking_block] if thinking_block else []), 
                            {""type"": ""text"", ""text"": text_block.text}
                        ]
                    })
                    break_loop = True
                    continue
                
                # We need a tool use block to proceed
                if tool_use_block:
                    console.print(
                        f""[blue]Tool Call:[/blue] {tool_name}({json.dumps(tool_input, indent=2)})""
                    )

                    try:
                        # Execute the appropriate tool based on name
                        if tool_name == ""git_list_files"":
                            directory = tool_input.get(""directory"", args.directory)
                            globs = tool_input.get(""globs"", args.globs)
                            extensions = tool_input.get(""extensions"", args.extensions)
                            result = git_list_files(
                                reasoning=tool_input[""reasoning""],
                                directory=directory,
                                globs=globs,
                                extensions=extensions,
                            )
                        elif tool_name == ""check_file_paths_line_length"":
                            result = check_file_paths_line_length(
                                reasoning=tool_input[""reasoning""],
                                file_paths=tool_input[""file_paths""],
                                file_line_limit=args.file_line_limit,
                            )
                        elif tool_name == ""determine_if_files_are_relevant"":
                            result = determine_if_files_are_relevant(
                                reasoning=tool_input[""reasoning""],
                                file_paths=tool_input[""file_paths""],
                            )
                        elif tool_name == ""add_relevant_files"":
                            result = add_relevant_files(
                                reasoning=tool_input[""reasoning""],
                                file_paths=tool_input[""file_paths""],
                            )
                            # Check if we've reached the limit
                            if len(RELEVANT_FILES) >= args.limit:
                                console.print(f""[green]Reached file limit of {args.limit}. Stopping.[/green]"")
                                break_loop = True
                        else:
                            raise Exception(f""Unknown tool call: {tool_name}"")

                        console.print(
                            f""[blue]Tool Call Result:[/blue] {tool_name}(...)""
                        )

                        # Append the tool result to messages
                        messages.append(
                            {
                                ""role"": ""assistant"",
                                ""content"": [
                                    *([thinking_block] if thinking_block else []),
                                    {
                                        ""type"": ""tool_use"",
                                        ""id"": tool_id,
                                        ""name"": tool_name,
                                        ""input"": tool_input
                                    }
                                ]
                            }
                        )

                        messages.append(
                            {
                                ""role"": ""user"",
                                ""content"": [
                                    {
                                        ""type"": ""tool_result"",
                                        ""tool_use_id"": tool_id,
                                        ""content"": json.dumps(result)
                                    }
                                ]
                            }
                        )

                    except Exception as e:
                        error_msg = f""Error executing {tool_name}: {e}""
                        console.print(f""[red]{error_msg}[/red]"")

                        # Append the error to messages
                        messages.append(
                            {
                                ""role"": ""assistant"",
                                ""content"": [
                                    *([thinking_block] if thinking_block else []),
                                    {
                                        ""type"": ""tool_use"",
                                        ""id"": tool_id,
                                        ""name"": tool_name,
                                        ""input"": tool_input
                                    }
                                ]
                            }
                        )

                        messages.append(
                            {
                                ""role"": ""user"",
                                ""content"": [
                                    {
                                        ""type"": ""tool_result"",
                                        ""tool_use_id"": tool_id,
                                        ""content"": str(error_msg)
                                    }
                                ]
                            }
                        )

        except Exception as e:
            console.print(f""[red]Error in agent loop: {str(e)}[/red]"")
            raise e

    # Print the final list of relevant files
    console.rule(""[green]Relevant Files[/green]"")
    for i, file_path in enumerate(RELEVANT_FILES, 1):
        console.print(f""{i}. {file_path}"")
",sfa_codebase_context_agent_v3.py,,1,1.0677030767166749e-06,"The method is a comprehensive implementation of a command-line tool that uses an AI model to analyze codebases. It includes argument parsing, API key configuration, and a main loop for processing user requests. The method is well-structured, with error handling and detailed logging, making it a robust solution for its intended purpose. Given its complexity and utility, it is unlikely to be deleted unless the entire project is deprecated or significantly refactored."
survived,"        def patched_function(*args, **kwargs):
            init_timestamp = get_ISO_time()
            session = kwargs.pop(""session"", None) if ""session"" in kwargs else None
            
            # Handle positional content argument
            if args:
                kwargs[""contents""] = args[0]
                args = args[1:]  # Remove content from args
            
            # Ensure we have the original method
            if self.original_generate is None:
                logger.error(""Original generate_content method not found. Cannot proceed with override."")
                return None
            
            # Call original method and track event
            result = self.original_generate(*args, **kwargs)
            return self.handle_response(result, kwargs, init_timestamp, session=session)
",agentops/llms/providers/gemini.py,GeminiProvider,1,1.522997951276035e-08,"The method 'patched_function' is a wrapper around an original method, adding functionality such as timestamping, session handling, and logging. It checks for the existence of the original method before proceeding, ensuring robustness. This kind of method is often used to extend or modify existing functionality without altering the original code, which is a common and useful practice in software development. Therefore, it is likely to be retained as it provides additional features and error handling."
survived,"    def supports_chain(self, chain) -> bool:
        return chain['type'] == 'solana'
",python/src/plugins/jupiter/goat_plugins/jupiter/__init__.py,JupiterPlugin,1,1.0467401685178159e-08,"The method `supports_chain` is a simple utility function that checks if a given chain is of type 'solana'. This kind of method is often useful in applications that need to handle multiple blockchain types and need to perform operations conditionally based on the type of chain. Since blockchain applications are prevalent and the need to support multiple chains is common, this method is likely to be useful in its context. Therefore, it is likely to be retained."
survived,"def spl_token(options: SplTokenPluginOptions) -> SplTokenPlugin:
    return SplTokenPlugin(options)",python/src/plugins/spl_token/goat_plugins/spl_token/__init__.py,,1,8.592166611791576e-10,"The method 'spl_token' is a simple factory function that takes an instance of 'SplTokenPluginOptions' and returns an instance of 'SplTokenPlugin'. This pattern is common and useful for encapsulating the creation logic of objects, making the code more modular and easier to maintain. There is no indication that this method is redundant or unnecessary, as it provides a clear and concise way to create 'SplTokenPlugin' objects. Therefore, it is likely to survive."
survived,"    async def _cleanup(self) -> StepResult:
        if self.backup_schema_path:
            shutil.rmtree(self.backup_schema_path)
        return StepResult(
            step=self,
            status=StepStatus.SUCCESS,
        )
",airbyte-ci/connectors/pipelines/pipelines/airbyte_ci/connectors/migrate_to_inline_schemas/pipeline.py,RestoreInlineState,1,2.2159489282323004e-08,"The method '_cleanup' is performing a specific task of cleaning up resources by removing a directory if 'backup_schema_path' is set. This is a common utility function in many applications to ensure that temporary or backup files do not persist longer than necessary, which can help in managing disk space and maintaining a clean state. The method is also asynchronous, which is beneficial for non-blocking operations in an asynchronous environment. Given its utility and the fact that it is a private method (indicated by the underscore prefix), it is likely to be retained as part of the codebase to support resource management tasks."
survived,"    async def _run(self) -> StepResult:
        connector = self.context.connector
        connector_path = connector.code_directory
        manifest_path = connector.manifest_path
        python_path = connector.python_source_dir_path
        logger = self.logger

        json_streams = _parse_json_streams(python_path)
        if len(json_streams) == 0:
            return StepResult(step=self, status=StepStatus.SKIPPED, stderr=""No JSON streams found."")

        data = read_yaml(manifest_path)
        if ""streams"" not in data:
            return StepResult(
                step=self,
                status=StepStatus.SKIPPED,
                stderr=""No manifest streams found."",
            )

        # find the explit ones and remove or udpate
        json_loaders = _find_json_loaders(data, [])
        for loader in json_loaders:
            logger.info(f""     JSON loader ref: {loader.ref} -> {loader.file_path}"")

        _update_json_loaders(connector_path, data, json_streams, json_loaders)

        # go through the declared streams and update the inline schemas
        for stream in data[""streams""]:
            if isinstance(stream, str):
                # see if reference
                if stream.startswith(""#""):
                    yaml_stream = _load_reference(data, stream)
                    if not yaml_stream:
                        logger.info(f""    Stream reference not found: {stream}"")
                        continue
                    if not _get_stream_name(yaml_stream):
                        logger.info(f""    Stream reference name not found: {stream}"")
                        continue
                else:
                    logger.info(f""    Stream reference unknown: {stream}"")
                    continue
            else:
                yaml_stream = stream

            if not yaml_stream:
                logger.info(f""    !! Yaml stream not found: {stream}"")
                continue

            stream_name = _get_stream_name(yaml_stream)
            if not stream_name:
                logger.info(f""    !! Stream name not found: {stream}"")
                continue
            if yaml_stream.get(""schema_loader"") and yaml_stream[""schema_loader""].get(""type"") == ""InlineSchemaLoader"":
                continue

            yaml_stream[""schema_loader""] = {}
            schema_loader = yaml_stream[""schema_loader""]
            _update_inline_schema(schema_loader, json_streams, stream_name)

        write_yaml(data, manifest_path)
        # await format_prettier([manifest_path], logger=logger)

        for json_stream in json_streams.values():
            logger.info(f""     !! JSON schema not found: {json_stream.name}"")

        return StepResult(step=self, status=StepStatus.SUCCESS)
",airbyte-ci/connectors/pipelines/pipelines/airbyte_ci/connectors/migrate_to_inline_schemas/pipeline.py,InlineSchemas,1,1.3440409770490404e-08,"The method '_run' is performing a series of operations that are essential for processing and updating JSON and YAML data related to streams. It includes parsing JSON streams, reading YAML data, updating JSON loaders, and handling inline schemas. These operations are crucial for the functionality of the system it is part of, as they ensure that the data is correctly processed and updated. The method also includes logging for debugging and error handling, which are important for maintaining the system. Given its comprehensive functionality and importance in data processing, it is unlikely to be deleted."
survived,"    def get_all_env_vars(cls) -> List[Tuple[str, Any]]:
        """"""Get all environment variables from the environment class.
        
        Returns:
            A list of tuples containing the environment variable name and its EnvVar instance.
        """"""
        env_vars = []
        for name, attr in inspect.getmembers(EnvironmentVariables):
            if name.startswith('_') or not hasattr(attr, 'name'):
                continue
            env_vars.append((name, attr))
        return env_vars
",pcweb/pages/docs/env_vars.py,EnvVarDocs,1,7.582560422162384e-10,"The method 'get_all_env_vars' is a utility function that retrieves all environment variables from a class, filtering out private attributes and those without a 'name' attribute. This functionality is useful for debugging, logging, or dynamically accessing environment variables, which are common tasks in software development. The method is well-defined, has a clear purpose, and is likely to be used in various contexts where environment variables need to be managed or inspected. Therefore, it is likely to be retained in the codebase."
survived,"def env_vars_page():
    """"""Generate the environment variables documentation page.
    
    Returns:
        A Reflex component containing the documentation.
    """"""
    return rx.box(
        h1_comp(text=""Environment Variables""),
        rx.code(""reflex.config.EnvironmentVariables"", class_name=""code-style text-[18px]""),
        rx.divider(),
        markdown(
            """"""
            Reflex provides a number of environment variables that can be used to configure the behavior of your application.
            These environment variables can be set in your shell environment or in a `.env` file.
            
            This page documents all available environment variables in Reflex.
            """"""
        ),
        h2_comp(text=""Environment Variables""),
        EnvVarDocs.generate_env_var_table(include_internal=False),
    )
",pcweb/pages/docs/env_vars.py,,1,1.8189616842444243e-09,"The method 'env_vars_page' is a utility function that generates a documentation page for environment variables. It is likely part of a larger documentation or configuration system within a software project. Such functions are generally useful for maintaining and updating documentation, especially in projects where environment variables play a crucial role in configuration. Since it serves a specific purpose and contributes to the usability and maintainability of the project, it is unlikely to be deleted unless the entire documentation approach is overhauled or the project is deprecated."
survived,"    def get_env_var_docstring(cls, name: str) -> Optional[str]:
        """"""Get the docstring for an environment variable.
        
        Args:
            name: The name of the environment variable.
            
        Returns:
            The docstring for the environment variable, or None if not found.
        """"""
        source_code = inspect.getsource(EnvironmentVariables)
        lines = source_code.splitlines()
        
        for i, line in enumerate(lines):
            if f""{name}:"" in line and ""EnvVar"" in line:
                j = i - 1
                comments = []
                while j >= 0 and lines[j].strip().startswith('#'):
                    comments.insert(0, lines[j].strip()[1:].strip())
                    j -= 1
                if comments:
                    return ""\n"".join(comments)
        return None
",pcweb/pages/docs/env_vars.py,EnvVarDocs,1,9.736200303530205e-10,"The method `get_env_var_docstring` is a utility function that retrieves the docstring for a specified environment variable from a class `EnvironmentVariables`. This functionality is useful for documentation purposes, especially in large codebases where environment variables are used extensively. The method is well-documented, specifying its purpose, arguments, and return value. It uses Python's `inspect` module to access the source code, which is a common practice for introspection tasks. Given its utility in improving code documentation and understanding, it is likely to be retained in the codebase."
survived,"    def pause_live_updates(self) -> None:
        """"""Pause Live session updates to allow for human input without interference.""""""
        if not self._live_paused:
            if self._live:
                self._live.stop()
                self._live = None
            self._live_paused = True
",src/crewai/utilities/events/utils/console_formatter.py,ConsoleFormatter,1,1.955568070542584e-08,"The method 'pause_live_updates' is a utility function that pauses live session updates, which can be crucial in scenarios where human input is needed without interference from live updates. This functionality is often necessary in applications that require user interaction or manual intervention. The method is straightforward, checks if updates are already paused, and stops the live session if it is active. Such utility functions are typically retained as they provide essential control over the application's behavior during live sessions."
survived,"    def resume_live_updates(self) -> None:
        """"""Resume Live session updates after human input is complete.""""""
        if self._live_paused:
            self._live_paused = False
",src/crewai/utilities/events/utils/console_formatter.py,ConsoleFormatter,1,5.905303995456778e-10,"The method 'resume_live_updates' is a simple utility function that resumes live updates by setting a flag '_live_paused' to False. This method is likely part of a larger system that manages live sessions, and its functionality is straightforward and necessary for resuming operations after a pause. Such utility methods are common in systems that require pausing and resuming operations, and they are typically retained unless the entire feature they support is deprecated. Therefore, it is likely to survive."
survived,"    def test_training_mode_human_input(self):
        """"""Test human input in training mode.""""""
        from crewai.agents.agent_builder.base_agent_executor_mixin import CrewAgentExecutorMixin
        
        executor = CrewAgentExecutorMixin()
        executor.crew = MagicMock()
        executor.crew._train = True
        executor._printer = MagicMock()
        
        formatter = event_listener.formatter
        
        original_paused_state = formatter._live_paused
        
        try:
            with patch.object(formatter, 'pause_live_updates') as mock_pause, \
                 patch.object(formatter, 'resume_live_updates') as mock_resume, \
                 patch('builtins.input', return_value='training feedback'):
                
                result = executor._ask_human_input(""Test result"")
                
                mock_pause.assert_called_once()
                mock_resume.assert_called_once()
                assert result == 'training feedback'
                
                executor._printer.print.assert_called()
                call_args = [call[1]['content'] for call in executor._printer.print.call_args_list]
                training_prompt_found = any('TRAINING MODE' in content for content in call_args)
                assert training_prompt_found
        finally:
            formatter._live_paused = original_paused_state",tests/test_flow_human_input_integration.py,TestFlowHumanInputIntegration,1,1.3440409770490404e-08,"The method `test_training_mode_human_input` is a unit test designed to verify the behavior of a system when human input is required in a training mode. It uses mocking to simulate dependencies and checks that the system behaves as expected, such as pausing and resuming live updates and correctly handling user input. This kind of test is crucial for ensuring the reliability of interactive features in software, especially in training or development environments. Therefore, it is likely to be retained as part of the test suite to ensure ongoing functionality and to catch regressions."
survived,"            def track_resume():
                resume_calls.append(True)
",tests/test_flow_human_input_integration.py,TestFlowHumanInputIntegration,0,0.999983298584886,"The method 'track_resume' is very simple and only appends a boolean value to a list 'resume_calls'. Without additional context, it seems to serve a very specific and limited purpose. If 'resume_calls' is not used elsewhere in a meaningful way, or if this method is part of a larger refactoring effort to clean up unused or redundant code, it might be deleted. However, if 'resume_calls' is crucial for tracking purposes in the application, it might survive. Without more context, it's more likely to be deleted due to its simplicity and potential redundancy."
survived,"def existing_file() -> Generator[str, None, None]:
    """"""Create a temporary file that already exists.""""""
    with tempfile.NamedTemporaryFile(delete=False, suffix="".txt"") as f:
        f.write(b""existing content"")
        path = f.name
    
    try:
        yield path
    finally:
        if os.path.exists(path):
            os.unlink(path)
",tests/_cli/test_file_overwrite.py,,1,3.3982678079468468e-09,"The method 'existing_file' is a utility function that creates a temporary file with predefined content and ensures its cleanup after use. This is a common pattern in testing and temporary file management, making it a useful and reusable piece of code. It handles file creation and deletion safely, which is a necessary functionality in many applications. Therefore, it is likely to be retained in the codebase."
survived,"def test_export_overwrite_with_yes_flag() -> None:
    """"""Test export command with -y flag to automatically overwrite files.""""""
    # Create a temporary directory and file
    with tempfile.TemporaryDirectory() as tmp_dir:
        # Create a simple marimo file
        marimo_file = Path(tmp_dir) / ""test.py""
        marimo_file.write_text(""""""
import marimo
app = marimo.App()

@app.cell
def __():
    print(""Hello, World!"")
    return

if __name__ == ""__main__"":
    app.run()
"""""")
        
        # Create an existing output file
        output_file = Path(tmp_dir) / ""output.html""
        output_file.write_text(""initial content"")
        
        # Use the -y flag to verify that the file can be overwritten without prompting
        result = subprocess.run(
            [
                ""marimo"",
                ""-y"",
                ""export"",
                ""html"",
                str(marimo_file),
                ""--output"",
                str(output_file),
            ],
            capture_output=True,
            text=True,
        )
        
        # Check that the command completed successfully
        assert result.returncode == 0
        
        # Verify the file was overwritten with -y flag
        assert output_file.read_text() != ""initial content""
        
        # Verify there was no prompt in the output
        assert ""Warning: The file"" not in result.stdout
        assert ""Overwrite?"" not in result.stdout
",tests/_cli/test_file_overwrite.py,,1,2.8453347280241004e-08,"The method `test_export_overwrite_with_yes_flag` is a well-structured test function that verifies the functionality of a command-line tool. It uses a temporary directory to avoid side effects, checks the command's success, and ensures the file is overwritten without prompts when the `-y` flag is used. This is a common and useful test pattern for command-line utilities, especially those involving file operations. There is no indication that this method is obsolete or redundant, and it serves a clear purpose in testing the overwrite functionality of the export command."
survived,"    def fingerprint(self) -> Fingerprint:
        """"""
        Get the crew's fingerprint.

        Returns:
            Fingerprint: The crew's fingerprint
        """"""
        return self.security_config.fingerprint
",src/crewai/crew.py,Crew,1,1.1032560311263802e-09,"The method 'fingerprint' is a simple getter method that retrieves the fingerprint from the 'security_config' attribute. Such methods are typically retained as they provide a clear and encapsulated way to access specific data within an object. This method is likely to be used in various parts of the codebase where the fingerprint is needed, making it a useful and necessary part of the class interface."
survived,"    def validate_fingerprint(cls, values):
        """"""Ensure fingerprint is properly initialized.""""""
        if isinstance(values, dict):
            # Handle case where fingerprint is not provided or is None
            if 'fingerprint' not in values or values['fingerprint'] is None:
                values['fingerprint'] = Fingerprint()
            # Handle case where fingerprint is a string (seed)
            elif isinstance(values['fingerprint'], str):
                if not values['fingerprint'].strip():
                    raise ValueError(""Fingerprint seed cannot be empty"")
                values['fingerprint'] = Fingerprint.generate(seed=values['fingerprint'])
        return values
",src/crewai/security/security_config.py,SecurityConfig,1,2.998960815863541e-09,"The method 'validate_fingerprint' is a utility function that ensures the 'fingerprint' field in a dictionary is properly initialized. It handles cases where the fingerprint is missing, None, or a string seed, and raises an error if the seed is empty. This kind of validation is crucial for maintaining data integrity and preventing errors in systems that rely on fingerprinting for identification or security purposes. Given its importance in ensuring correct data initialization and preventing potential runtime errors, it is likely to be retained in the codebase."
survived,"def create_source_connection(config: Mapping[str, Any]) -> PipelineDataSource:
    pipeline_id = config.get(""pipeline_id"")
    pipeline_access_token = config.get(""pipeline_access_token"")

    return PipelineDataSource(pipeline_id=pipeline_id, pipeline_access_token=pipeline_access_token)
",airbyte-integrations/connectors/destination-glassflow/destination_glassflow/destination.py,,1,4.599055376537186e-10,"The method 'create_source_connection' is a straightforward utility function that creates and returns an instance of 'PipelineDataSource' using configuration data. It is likely to be a useful part of a larger system where connections to data sources are needed. The method is simple, clear, and performs a necessary task without any apparent issues or redundancies. Therefore, it is likely to be retained in the codebase."
survived,"def _state() -> AirbyteMessage:
    return AirbyteMessage(type=Type.STATE, state=AirbyteStateMessage(data={}))
",airbyte-integrations/connectors/destination-glassflow/unit_tests/unit_test.py,,1,2.646573631904765e-09,"The method '_state' is a private helper function, indicated by the underscore prefix, which is a common convention in Python to denote non-public methods. It returns an 'AirbyteMessage' object with a specific type and state. This function is likely part of a larger codebase related to data integration or ETL processes, where maintaining state is crucial. Since it serves a specific purpose and follows a naming convention that suggests it's intended for internal use, it is unlikely to be deleted unless the entire functionality it supports is refactored or removed. Therefore, it is more likely to survive."
survived,"def _configured_catalog() -> ConfiguredAirbyteCatalog:
    stream_schema = {""type"": ""object"", ""properties"": {}}
    append_stream = ConfiguredAirbyteStream(
        stream=AirbyteStream(name=""test"", json_schema=stream_schema, supported_sync_modes=[SyncMode.full_refresh]),
        sync_mode=SyncMode.full_refresh,
        destination_sync_mode=DestinationSyncMode.append,
    )
    return ConfiguredAirbyteCatalog(streams=[append_stream])
",airbyte-integrations/connectors/destination-glassflow/unit_tests/unit_test.py,,1,8.76424914819242e-08,"The method '_configured_catalog' is a utility function that creates and returns a 'ConfiguredAirbyteCatalog' object with a predefined stream configuration. This type of method is typically used to set up or initialize configurations for data synchronization tasks. It is likely to be used in the context of data integration or ETL processes, where such configurations are necessary. Since it serves a specific purpose and is likely to be used in the setup or testing of data pipelines, it is unlikely to be deleted unless the entire configuration approach changes or the method becomes obsolete due to a major refactor."
survived,"def run():
    destination = DestinationGlassflow()
    destination.run(sys.argv[1:])",airbyte-integrations/connectors/destination-glassflow/destination_glassflow/run.py,,1,1.522997951276035e-08,"The method 'run' is a simple wrapper that creates an instance of 'DestinationGlassflow' and calls its 'run' method with command-line arguments. This pattern is common in scripts that serve as entry points for applications. Since it is likely part of a larger system where 'DestinationGlassflow' is a key component, the method is essential for executing the program. Therefore, it is unlikely to be deleted unless the entire application is refactored or replaced."
survived,"def test_write():
    f = open(
        ""secrets/config.json"",
    )
    config = json.load(f)
    messages = [_record(), _state()]
    destination = DestinationGlassflow()
    for m in destination.write(config=config, configured_catalog=_configured_catalog(), input_messages=messages):
        assert m.type == Type.STATE
    consume(config)",airbyte-integrations/connectors/destination-glassflow/integration_tests/integration_test.py,,0,0.999999694097641,"The method 'test_write' is likely to be deleted because it contains several issues that suggest it is not a well-structured or complete test function. Firstly, the function opens a file but does not close it, which can lead to resource leaks. Secondly, it uses undefined functions and variables such as '_record()', '_state()', 'DestinationGlassflow', '_configured_catalog()', and 'consume', which indicates that the code is either incomplete or not self-contained. Additionally, the function lacks proper exception handling and does not follow best practices for writing test cases, such as using a testing framework like unittest or pytest. These issues suggest that the method is not ready for production use and may be removed or significantly refactored."
survived,"def test_check_succeeds():
    f = open(
        ""secrets/config.json"",
    )
    config = json.load(f)
    destination = DestinationGlassflow()
    status = destination.check(logger=Mock(), config=config)
    assert status.status == Status.SUCCEEDED
",airbyte-integrations/connectors/destination-glassflow/integration_tests/integration_test.py,,1,1.522997951276035e-08,"The method 'test_check_succeeds' is a unit test function that checks if a certain operation succeeds. It is a part of a test suite, which is essential for ensuring code reliability and correctness. Test functions are generally not deleted unless they are redundant or replaced by more comprehensive tests. Since this function is straightforward and serves a clear purpose in verifying the success of a configuration check, it is likely to be retained."
survived,"        def _run(self, input_text: str) -> str:
            return f""Processed {input_text}""
",tests/tools/test_tool_usage_limit.py,LimitedTool,1,8.592166611791576e-10,"The method '_run' is a simple utility function that takes an input string and returns a formatted string. It is likely to be a part of a larger class or module where such processing is needed. The method is straightforward, has a clear purpose, and does not contain any obvious issues or redundancies. Therefore, it is likely to be retained in the codebase."
survived,"    def test_cache_hit_miss(self) -> None:
        """"""Test cache hit and miss.""""""
        loader = JsonLoader(""test"", self.save_path)
        
        # No file exists yet
        assert not loader.cache_hit(""hash1"", ""Pure"")
        
        # Create a cache file
        cache_path = loader.build_path(""hash1"", ""Pure"")
        
        # Create a valid JSON cache
        cache_dict = {
            ""defs"": {""var1"": ""value1""},
            ""hash"": ""hash1"",
            ""stateful_refs"": [],
            ""cache_type"": ""Pure"",
            ""hit"": True,
            ""meta"": {}
        }
        
        with open(cache_path, ""w"") as f:
            json.dump(cache_dict, f)
        
        # Now it should hit
        assert loader.cache_hit(""hash1"", ""Pure"")
        
        # Different hash should miss
        assert not loader.cache_hit(""hash2"", ""Pure"")
        
        # Different cache type should miss
        assert not loader.cache_hit(""hash1"", ""Deferred"")
        
        # Empty file should miss
        empty_path = loader.build_path(""empty"", ""Pure"")
        with open(empty_path, ""w"") as f:
            pass
        assert not loader.cache_hit(""empty"", ""Pure"")
",tests/_save/loaders/test_json_loader.py,TestJsonLoader,1,6.825604231969389e-08,"The method 'test_cache_hit_miss' is a unit test designed to verify the functionality of the 'cache_hit' method in the 'JsonLoader' class. Unit tests are crucial for ensuring code reliability and are typically retained in the codebase to facilitate ongoing testing and validation of code changes. This method is well-structured, covers multiple scenarios (cache hit, cache miss due to different hash, cache miss due to different type, and cache miss due to empty file), and is likely part of a test suite that ensures the correctness of the caching mechanism. Therefore, it is unlikely to be deleted."
survived,"    def test_init_default(self) -> None:
        """"""Test default initialization.""""""
        loader = MemoryLoader(""test"")
        assert loader.name == ""test""
        assert loader.max_size == 128
        assert loader.is_lru is True
        assert isinstance(loader._cache, OrderedDict)
        assert loader._cache_lock is not None
",tests/_save/loaders/test_memory_loader.py,TestMemoryLoader,1,6.348800075736417e-09,"The method `test_init_default` is a unit test that verifies the default initialization of a `MemoryLoader` object. It checks if the attributes are set correctly upon instantiation. Such tests are crucial for ensuring that the class behaves as expected when initialized with default parameters. Since this is a fundamental test for the class's constructor, it is unlikely to be deleted unless the class itself is removed or significantly refactored, which would require a corresponding update to the test."
survived,"    def setup_method(self) -> None:
        """"""Set up a temporary directory for each test.""""""
        self.temp_dir = Path(""/tmp/marimo_test_loader"")
        self.temp_dir.mkdir(exist_ok=True)
        self.save_path = str(self.temp_dir)
",tests/_save/loaders/test_loader.py,TestBasePersistenceLoader,1,3.2241866333029355e-08,"The method `setup_method` is a common pattern in testing frameworks like pytest, where it is used to set up a specific environment or state before each test method is run. This method creates a temporary directory, which is a typical setup task to ensure tests have a clean and isolated environment to work with. Such methods are generally retained as they are crucial for ensuring tests do not interfere with each other and have consistent starting conditions. Therefore, it is unlikely to be deleted."
survived,"    def test_max_size_property(self) -> None:
        """"""Test the max_size property.""""""
        loader = MemoryLoader(""test"", max_size=3)
        assert loader.max_size == 3
        
        # Change max_size
        loader.max_size = 1
        assert loader.max_size == 1
        assert loader.is_lru is True
        
        # Disable LRU
        loader.max_size = 0
        assert loader.max_size == 0
        assert loader.is_lru is False",tests/_save/loaders/test_memory_loader.py,TestMemoryLoader,1,2.3355930333443423e-09,"The method 'test_max_size_property' is a unit test designed to verify the behavior of the 'max_size' property in the 'MemoryLoader' class. It checks if the property correctly updates and affects the 'is_lru' attribute. Unit tests are crucial for ensuring code reliability and are typically retained to maintain code quality. Therefore, this method is likely to be retained."
survived,"def find_and_print_langsmith_run_url(client: Client, project_name: Optional[str] = None) -> Optional[str]:
    """"""Find the most recent LangSmith run and print its URL.

    Args:
        client: The LangSmith client
        project_name: Optional name of the project

    Returns:
        The URL for the run in LangSmith if found, None otherwise
    """"""
    separator = ""="" * 60
    
    try:
        # Get the most recent runs with proper filter parameters
        # We need to provide at least one filter parameter as required by the API
        recent_runs = list(
            client.list_runs(
                # Use the project name from environment variable
                project_name=project_name,
                # Limit to just the most recent run
                limit=1,
            )
        )

        if recent_runs and len(recent_runs) > 0:
            # Make sure we have a valid run object with an id attribute
            if hasattr(recent_runs[0], ""id""):
                # Convert the ID to string to ensure it's in the right format
                run_id = str(recent_runs[0].id)

                # Get the run URL using the run_id parameter
                run_url = get_langsmith_url(client, run_id=run_id, project_name=project_name)

                print(f""\n{separator}\n🔍 LangSmith Run URL: {run_url}\n{separator}"")
                return run_url
            else:
                print(f""\n{separator}\nRun object has no 'id' attribute: {recent_runs[0]}\n{separator}"")
                return None
        else:
            # If no runs found with project name, try a more general approach
            # Use a timestamp filter to get recent runs (last 10 minutes)
            ten_minutes_ago = datetime.datetime.now() - datetime.timedelta(minutes=10)

            recent_runs = list(client.list_runs(start_time=ten_minutes_ago.isoformat(), limit=1))

            if recent_runs and len(recent_runs) > 0 and hasattr(recent_runs[0], ""id""):
                # Convert the ID to string to ensure it's in the right format
                run_id = str(recent_runs[0].id)

                # Get the run URL using the run_id parameter
                run_url = get_langsmith_url(client, run_id=run_id, project_name=project_name)

                print(f""\n{separator}\n🔍 LangSmith Run URL: {run_url}\n{separator}"")
                return run_url
            else:
                print(f""\n{separator}\nNo valid runs found\n{separator}"")
                return None
    except Exception as e:
        print(f""\n{separator}\nCould not retrieve LangSmith URL: {e}"")
        import traceback

        print(traceback.format_exc())
        print(separator)
        return None",src/codegen/extensions/langchain/utils/get_langsmith_url.py,,1,8.152020648014727e-09,"The method `find_and_print_langsmith_run_url` is well-structured and serves a clear purpose: to find and print the URL of the most recent LangSmith run. It includes error handling, checks for valid data, and provides fallback logic if the initial search criteria do not yield results. The method is likely to be useful in contexts where users need to quickly access the latest run information from LangSmith, making it a valuable utility function. Therefore, it is likely to be retained in the codebase."
survived,"def create_init_file(goat_plugins_dir: Path, plugin_name: str, is_evm: bool) -> None:
    """"""Create the __init__.py file with plugin class.""""""
    class_name = f""{plugin_name.title()}Service""
    plugin_class = f""{plugin_name.title()}Plugin""
    options_class = f""{plugin_name.title()}PluginOptions""
    
    init_content = '''from dataclasses import dataclass
from goat.classes.plugin_base import PluginBase
from .service import {class_name}


@dataclass
class {options_class}:
    """"""Options for the {plugin_class}.""""""
    api_key: str  # API key for external service integration


class {plugin_class}(PluginBase):
    def __init__(self, options: {options_class}):
        super().__init__(""{plugin_name}"", [{class_name}(options.api_key)])

    def supports_chain(self, chain) -> bool:
        return {supports_chain}


def {plugin_name}(options: {options_class}) -> {plugin_class}:
    return {plugin_class}(options)
'''.format(
        class_name=class_name,
        plugin_class=plugin_class,
        options_class=options_class,
        plugin_name=plugin_name,
        supports_chain=""chain['type'] == 'evm'"" if is_evm else ""True""
    )

    with open(goat_plugins_dir / ""__init__.py"", ""w"") as f:
        f.write(init_content)
",python/create_plugin.py,,1,7.194132978569833e-09,"The method `create_init_file` is a utility function designed to generate an `__init__.py` file for a plugin system. It dynamically creates content based on the provided plugin name and whether the plugin supports EVM chains. This kind of functionality is essential for automating the setup of plugin modules, especially in environments where plugins are frequently added or modified. The method is well-structured, uses string formatting to customize the file content, and handles file writing efficiently. Such utility functions are common in software projects to reduce manual setup work and ensure consistency. Therefore, it is likely to be retained in the codebase."
survived,"def create_parameters_file(goat_plugins_dir: Path, plugin_name: str) -> None:
    """"""Create the parameters.py file with example parameters in the goat_plugins directory.""""""
    parameters_content = '''from pydantic import BaseModel, Field
from typing import Optional


class ExampleQueryParameters(BaseModel):
    query: str = Field(
        description=""An example query parameter (e.g., 'search term', 'identifier')""
    )
    limit: Optional[int] = Field(
        None,
        description=""Maximum number of results to return. Defaults to no limit."",
    )
    include_metadata: bool = Field(
        default=False,
        description=""Include additional metadata in the response""
    )


class ExampleActionParameters(BaseModel):
    target_id: str = Field(
        description=""The ID of the target to perform action on""
    )
    action_type: str = Field(
        description=""The type of action to perform (e.g., 'create', 'update', 'delete')""
    )
    parameters: Optional[dict] = Field(
        None,
        description=""Optional parameters for the action""
    )
'''
    
    with open(goat_plugins_dir / ""parameters.py"", ""w"") as f:
        f.write(parameters_content)
",python/create_plugin.py,,1,6.69158608681505e-10,"The method `create_parameters_file` is likely to survive because it serves a clear and useful purpose: it generates a `parameters.py` file with predefined content in a specified directory. This is a common task in software development, especially when setting up plugin systems or modular architectures. The method is straightforward, uses standard libraries, and does not have any apparent issues or redundancies that would necessitate its removal."
survived,"    def balance_of(self, address: str) -> Balance:
        """"""Get the SOL balance of an address.""""""
        pass
",python/src/wallets/solana/goat_wallets/solana/wallet.py,SolanaWalletClient,0,0.999998629043345,"The method `balance_of` is a placeholder function that is intended to retrieve the SOL balance of a given address. However, it currently lacks an implementation, as indicated by the `pass` statement. This suggests that the method is either incomplete or not yet implemented. Without any functionality, it does not serve any purpose in its current state. Therefore, unless it is implemented in the future, it is likely to be deleted as it does not contribute to the codebase."
survived,"def test_scrape_with_return_html_true(_mocked_chrome_driver):
    html_content = ""<html><body><div>HTML content</div></body></html>""
    mock_driver = mock_driver_with_html(html_content)
    tool = initialize_tool_with(mock_driver)

    result = tool._run(website_url=""https://example.com"", return_html=True)

    assert html_content in result
    mock_driver.get.assert_called_once_with(""https://example.com"")
    mock_driver.find_element.assert_called_with(""tag name"", ""body"")
    mock_driver.close.assert_called_once()
",tests/tools/selenium_scraping_tool_test.py,,1,3.653482080241728e-08,"The method `test_scrape_with_return_html_true` is a unit test designed to verify the functionality of a web scraping tool. It checks if the tool correctly returns HTML content when the `return_html` parameter is set to `True`. The test uses a mocked web driver to simulate the behavior of a real browser, ensuring that the tool interacts with the web driver as expected. This kind of test is crucial for maintaining the reliability and correctness of the web scraping tool, especially when changes are made to the codebase. Therefore, it is unlikely to be deleted as it serves an important role in the testing suite."
survived,"def test_telemetry_otel_sdk_disabled_after_creation():
    """"""Test that OTEL_SDK_DISABLED also works when set after singleton creation.""""""
    Telemetry._instance = None
    
    with patch.dict(os.environ, {}, clear=True):
        with patch(""crewai.telemetry.telemetry.TracerProvider""):
            telemetry = Telemetry()
            assert telemetry.ready is True
            
            mock_operation = MagicMock()
            telemetry._safe_telemetry_operation(mock_operation)
            mock_operation.assert_called_once()
            
            mock_operation.reset_mock()
            
            os.environ['OTEL_SDK_DISABLED'] = 'true'
            
            telemetry._safe_telemetry_operation(mock_operation)
            mock_operation.assert_not_called()",tests/telemetry/test_telemetry_disable.py,,1,2.0611536181902033e-09,"The method is a unit test for a specific functionality related to telemetry in a software system. It checks if the telemetry system respects the 'OTEL_SDK_DISABLED' environment variable even after the telemetry singleton has been created. This is a valid and useful test to ensure that the system behaves correctly under different configurations. Such tests are crucial for maintaining software reliability and are unlikely to be deleted unless the functionality they test is removed or significantly altered. Therefore, the method is likely to survive."
deleted,"        def check_port():
            try:
                sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                result = sock.connect_ex((""127.0.0.1"", self.backend_port))
                sock.close()
            except Exception:
                return False
            else:
                return result == 0
",reflex/testing.py,AppHarness,1,9.237449576640118e-09,"The method 'check_port' is a utility function that checks if a specific port on the localhost is open. This is a common requirement in network programming to ensure that a service is running and accessible. The method is simple, effective, and uses standard library functions to achieve its goal. It handles exceptions gracefully and provides a clear boolean result indicating the port's status. Such utility functions are often reused in various network-related applications, making them valuable. Therefore, it is likely to be retained in the codebase."
survived,"    def normalize_url(self, url):
        """"""Normalize URL for comparison.""""""
        parsed = urlparse(url)
        normalized = f""{parsed.scheme}://{parsed.netloc}{parsed.path}""
        if parsed.query:
            normalized += f""?{parsed.query}""
        return normalized
",scripts/check_dead_links.py,DeadLinkChecker,1,5.211412485172657e-10,"The method 'normalize_url' is a utility function that takes a URL and normalizes it for comparison purposes. This is a common requirement in many applications where URLs need to be compared or stored in a consistent format. The method is straightforward, uses standard library functions, and addresses a common problem in web development. Therefore, it is likely to be useful and retained in the codebase."
survived,"    def test_require_api_key_env(self) -> None:
        """"""Test _require_api_key with environment variable.""""""
        model = groq(""llama3-70b-8192"")
        assert model._require_api_key == ""env-key""
",tests/_ai/llm/_impl.py,TestGroq,1,7.73442280641062e-08,"The method `test_require_api_key_env` is a test function that checks if the `_require_api_key` attribute of a `model` object is set to ""env-key"". This is a straightforward test that verifies the behavior of the `model` object when initialized with a specific configuration. Test methods are generally essential for ensuring code reliability and correctness, especially in environments where API keys and configurations are critical. Therefore, this method is likely to be retained as part of the test suite to ensure that the environment variable setup for API keys is functioning as expected."
survived,"    def test_init(self) -> None:
        """"""Test initialization of the openai class.""""""
        model = openai(""gpt-4"")
        assert model.model == ""gpt-4""
        assert model.system_message == DEFAULT_SYSTEM_MESSAGE
        assert model.api_key is None
        assert model.base_url is None

        model = openai(
            ""gpt-4"",
            system_message=""Custom system message"",
            api_key=""test-key"",
            base_url=""https://example.com"",
        )
        assert model.model == ""gpt-4""
        assert model.system_message == ""Custom system message""
        assert model.api_key == ""test-key""
        assert model.base_url == ""https://example.com""
",tests/_ai/llm/_impl.py,TestOpenAI,1,2.0611536181902033e-09,"The method `test_init` is a unit test function that verifies the initialization of an `openai` class instance. It checks if the class is correctly initialized with default and custom parameters. Such test functions are crucial for ensuring that the class behaves as expected when instantiated. Since testing is a fundamental part of software development to maintain code quality and reliability, this method is likely to be retained in the codebase."
survived,"    def test_call(
        self,
        mock_generative_model: MagicMock,
        mock_configure: MagicMock,
        mock_require_api_key: MagicMock,
    ) -> None:
        """"""Test calling the google class.""""""
        mock_require_api_key.return_value = ""test-key""
        mock_client = MagicMock()
        mock_generative_model.return_value = mock_client
        mock_response = MagicMock()
        mock_response.text = ""Test response""
        mock_client.generate_content.return_value = mock_response

        model = google(""gemini-pro"")
        # Patch the _require_api_key property to return the test key directly
        with patch.object(model, ""_require_api_key"", ""test-key""):
            messages = [ChatMessage(role=""user"", content=""Test prompt"")]
            config = ChatModelConfig(
                max_tokens=100,
                temperature=0.7,
                top_p=0.9,
                top_k=10,
                frequency_penalty=0.5,
                presence_penalty=0.5,
            )

            result = model(messages, config)
            assert result == ""Test response""

            mock_configure.assert_called_once_with(api_key=""test-key"")
        mock_generative_model.assert_called_once()
        call_args = mock_generative_model.call_args[1]
        assert call_args[""model_name""] == ""gemini-pro""
        generation_config = call_args[""generation_config""]
        assert generation_config.max_output_tokens == 100
        assert generation_config.temperature == 0.7
        assert generation_config.top_p == 0.9
        assert generation_config.top_k == 10
        assert generation_config.frequency_penalty == 0.5
        assert generation_config.presence_penalty == 0.5

        mock_client.generate_content.assert_called_once()
",tests/_ai/llm/_impl.py,TestGoogle,1,3.927863699585036e-07,"The method `test_call` is a unit test function that verifies the behavior of a class method by using mock objects. It checks if the method correctly configures and calls the generative model with the expected parameters. Unit tests are crucial for ensuring code reliability and are typically maintained as part of the codebase to prevent regressions. Therefore, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly changed."
deleted,"    def test_http_request_context_manager_with_request(self) -> None:
        # Test that http_request_context sets and unsets the HTTP request
        request = HTTPRequest(
            url={""path"": ""/test"", ""port"": None, ""scheme"": ""http"", ""netloc"": ""localhost"", ""query"": """", ""hostname"": ""localhost""},
            base_url={""path"": """", ""port"": None, ""scheme"": ""http"", ""netloc"": ""localhost"", ""query"": """", ""hostname"": ""localhost""},
            headers={},
            query_params={},
            path_params={},
            cookies={},
            meta={},
            user=None,
        )

        with http_request_context(request):
            # Request should be set within the context
            ctx_request = HTTP_REQUEST_CTX.get()
            assert ctx_request is not None
            assert ctx_request is request
            assert ctx_request.url[""path""] == ""/test""

        # Request should be unset outside the context
        with pytest.raises(LookupError):
            HTTP_REQUEST_CTX.get()
",tests/_messaging/test_context.py,TestHTTPRequestContext,1,1.0467401685178159e-08,"The method is a unit test for a context manager that handles HTTP requests. It verifies that the request is correctly set and unset within the context, which is a crucial part of ensuring the context manager works as expected. Such tests are essential for maintaining code reliability and are unlikely to be deleted unless the functionality they test is removed or significantly changed."
deleted,"    def test_run_id_context_generates_unique_ids(self) -> None:
        # Test that run_id_context generates unique IDs
        with run_id_context() as ctx1:
            run_id1 = RUN_ID_CTX.get()

            with run_id_context() as ctx2:
                run_id2 = RUN_ID_CTX.get()

                # IDs should be different
                assert run_id1 != run_id2

            # Should restore the outer context
            assert RUN_ID_CTX.get() == run_id1

        # Run ID should be unset outside the context
        with pytest.raises(LookupError):
            RUN_ID_CTX.get()
",tests/_messaging/test_context.py,TestRunIDContext,1,3.2241866333029355e-08,"The method is a test function that verifies the functionality of a context manager, ensuring it generates unique IDs and restores context correctly. It is well-structured, uses assertions to validate behavior, and includes exception handling to check for expected errors. These are all good practices in test code, making it likely to be retained."
deleted,"    def test_nested_http_request_contexts(self) -> None:
        # Test nested http_request_contexts
        request1 = HTTPRequest(
            url={""path"": ""/test1"", ""port"": None, ""scheme"": ""http"", ""netloc"": ""localhost"", ""query"": """", ""hostname"": ""localhost""},
            base_url={""path"": """", ""port"": None, ""scheme"": ""http"", ""netloc"": ""localhost"", ""query"": """", ""hostname"": ""localhost""},
            headers={},
            query_params={},
            path_params={},
            cookies={},
            meta={},
            user=None,
        )

        request2 = HTTPRequest(
            url={""path"": ""/test2"", ""port"": None, ""scheme"": ""http"", ""netloc"": ""localhost"", ""query"": """", ""hostname"": ""localhost""},
            base_url={""path"": """", ""port"": None, ""scheme"": ""http"", ""netloc"": ""localhost"", ""query"": """", ""hostname"": ""localhost""},
            headers={},
            query_params={},
            path_params={},
            cookies={},
            meta={},
            user=None,
        )

        with http_request_context(request1):
            # Outer context should have request1
            assert HTTP_REQUEST_CTX.get() is request1

            with http_request_context(request2):
                # Inner context should have request2
                assert HTTP_REQUEST_CTX.get() is request2

            # Should restore the outer context
            assert HTTP_REQUEST_CTX.get() is request1

        # Request should be unset outside the context
        with pytest.raises(LookupError):
            HTTP_REQUEST_CTX.get()",tests/_messaging/test_context.py,TestHTTPRequestContext,1,1.522997951276035e-08,"The method `test_nested_http_request_contexts` is a unit test designed to verify the behavior of nested HTTP request contexts. It uses assertions to ensure that the context manager correctly switches between different HTTP request contexts and restores the previous context after exiting a nested context. This is a common pattern in testing context managers and is crucial for ensuring the correct functionality of context management in applications. Since it serves a clear purpose in testing the functionality of context management, it is likely to be retained in the codebase."
survived,"    def test_stdin_stop(self) -> None:
        stdin = Stdin()
        # Should not raise any exceptions
        stdin.stop()
",tests/_messaging/test_types.py,TestStdin,1,8.592166611791576e-10,"The method `test_stdin_stop` is a test method that checks if the `stop` method of a `Stdin` object can be called without raising exceptions. This is a valid and useful test case to ensure that the `stop` method behaves correctly under normal conditions. Test methods like this are typically retained to ensure code reliability and stability, especially if `Stdin` is a part of a larger system where stopping the input stream is a critical operation. Therefore, the method is likely to be Survived."
survived,"    def test_stdin_name(self) -> None:
        stdin = Stdin()
        assert stdin.name == ""stdin""
",tests/_messaging/test_types.py,TestStdin,1,9.237449576640118e-09,"The method `test_stdin_name` is a simple unit test that checks if the `name` attribute of a `Stdin` object is equal to the string ""stdin"". This is a straightforward and valid test case that ensures the `Stdin` class is correctly implemented with the expected attribute. Such tests are essential for verifying the correctness of code and are unlikely to be deleted unless the `Stdin` class itself is removed or significantly refactored. Therefore, the method is likely to survive."
survived,"    def test_is_code_highlighting(self) -> None:
        # Test is_code_highlighting function

        # Should return True for strings containing the codehilite class
        assert is_code_highlighting(""<span class=\""codehilite\"">code</span>"") is True
        assert is_code_highlighting(""before <span class=\""codehilite\"">code</span> after"") is True

        # Should return False for strings not containing the codehilite class
        assert is_code_highlighting(""<span>code</span>"") is False
        assert is_code_highlighting("""") is False
        assert is_code_highlighting(""class=\""not-codehilite\"""") is False",tests/_messaging/test_tracebacks.py,TestTracebacks,1,2.998960815863541e-09,"The method `test_is_code_highlighting` is a unit test for the function `is_code_highlighting`. It is well-structured, with clear assertions that test both positive and negative cases for the presence of the 'codehilite' class in a string. This kind of test is essential for ensuring the correctness of the `is_code_highlighting` function, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained in the codebase."
survived,"    def test_mime_bundle(self) -> None:
        # Test that MimeBundle can be used as a type annotation
        def accepts_mime_bundle(bundle: MimeBundle) -> MimeBundle:
            return bundle

        # Create a valid mime bundle
        bundle: MimeBundle = {
            ""text/plain"": ""Hello, world!"",
            ""text/html"": ""<h1>Hello, world!</h1>"",
        }

        assert accepts_mime_bundle(bundle) == bundle

        # Test with empty bundle
        empty_bundle: MimeBundle = {}
        assert accepts_mime_bundle(empty_bundle) == empty_bundle
",tests/_messaging/test_mimetypes.py,TestMimeTypes,1,2.0611536181902033e-09,"The method `test_mime_bundle` is a unit test function that verifies the functionality of using `MimeBundle` as a type annotation. It checks if a function can accept and return a `MimeBundle` correctly, both with a populated and an empty bundle. This is a typical use case in testing to ensure that the type annotations and the function logic work as expected. Since it serves a clear purpose in validating the behavior of code related to `MimeBundle`, it is likely to be retained in the codebase for ongoing testing and validation purposes."
survived,"    def test_print_override_with_thread_and_context(self) -> None:
        # Test print_override when in a marimo thread with context
        thread_id = threading.get_ident()
        THREADS.add(thread_id)

        try:
            stream = MockStream()

            # Create a mock context
            context = MagicMock(spec=RuntimeContext)
            context.stream = stream
            context.execution_context = MagicMock(spec=ExecutionContext)
            context.execution_context.cell_id = ""cell1""

            with patch(""marimo._messaging.print_override._original_print"") as mock_print:
                with patch(
                    ""marimo._messaging.print_override.get_context"",
                    return_value=context,
                ):
                    print_override(""Hello, world!"")

                    # Original print should not be called
                    mock_print.assert_not_called()

                    # Message should be sent to the stream
                    assert len(stream.messages) == 1
                    assert stream.messages[0][0] == ""cell-op""  # op
                    assert stream.messages[0][1][""cell_id""] == ""cell1""
                    assert stream.messages[0][1][""console""][""channel""] == ""stdout""
                    assert stream.messages[0][1][""console""][""mimetype""] == ""text/plain""
                    assert stream.messages[0][1][""console""][""data""] == ""Hello, world!\n""
        finally:
            # Clean up
            if thread_id in THREADS:
                THREADS.remove(thread_id)
",tests/_messaging/test_print_override.py,TestPrintOverride,1,3.0590235908148916e-07,"The method is a unit test for a specific functionality, which is to test the behavior of the `print_override` function in a threaded context. Unit tests are generally not deleted unless they are testing deprecated or removed functionality. Since this test is verifying the correct behavior of a function in a specific scenario, it is likely to be maintained as long as the functionality it tests is relevant."
survived,"    def test_write_traceback_to_regular_stderr(self) -> None:
        # Test writing traceback to regular stderr (not Stderr)
        mock_stderr = MagicMock()
        mock_stderr.write = MagicMock()

        with patch(""sys.stderr"", mock_stderr):
            traceback = ""Traceback (most recent call last):\n  File \""<stdin>\"", line 1, in <module>\nValueError: invalid value""
            write_traceback(traceback)

            # Should call write with the original traceback
            mock_stderr.write.assert_called_once_with(traceback)
",tests/_messaging/test_tracebacks.py,TestTracebacks,1,2.998960815863541e-09,"The method 'test_write_traceback_to_regular_stderr' is a unit test designed to verify that the 'write_traceback' function correctly writes a given traceback to the standard error stream. It uses mocking to replace 'sys.stderr' with a mock object and checks if the 'write' method is called with the expected traceback. This is a typical pattern in unit testing to ensure that functions interact with system resources as expected. Since this is a well-structured test that serves a clear purpose in verifying functionality, it is likely to be retained in the codebase."
survived,"    def test_stderr_name(self) -> None:
        stderr = self.MockStderr()
        assert stderr.name == ""stderr""
",tests/_messaging/test_types.py,TestStdoutStderr,1,7.194132978569833e-09,"The method `test_stderr_name` is a simple unit test that checks if the `name` attribute of a `MockStderr` object is equal to the string ""stderr"". This is a straightforward test that verifies a basic property of the `MockStderr` class. Such tests are typically useful for ensuring that the class behaves as expected, especially if `MockStderr` is used in multiple places in the codebase. Since it is a simple and clear test that ensures the integrity of a class attribute, it is likely to be retained in the codebase."
survived,"def test_plugin_instantiation():
    """"""Test that the plugin can be instantiated without errors.""""""
    api_key = os.environ.get(""UNISWAP_API_KEY"")
    assert api_key is not None, ""UNISWAP_API_KEY environment variable is required""
    
    options = UniswapPluginOptions(api_key=api_key)
    plugin = uniswap(options)
    
    assert plugin is not None
    assert plugin.name == ""uniswap""
    
    # Test chain support
    ethereum_chain: EvmChain = {""type"": ""evm"", ""id"": 1}  # Ethereum mainnet
    polygon_chain: EvmChain = {""type"": ""evm"", ""id"": 137}  # Polygon
    solana_chain: SolanaChain = {""type"": ""solana""}  # Solana chain
    unknown_chain: EvmChain = {""type"": ""evm"", ""id"": 999}  # Unknown EVM chain
    
    assert plugin.supports_chain(ethereum_chain)
    assert plugin.supports_chain(polygon_chain)
    assert not plugin.supports_chain(solana_chain)
    assert not plugin.supports_chain(unknown_chain)",python/src/plugins/uniswap/tests/test_uniswap_plugin.py,,1,2.2159489282323004e-08,"The method 'test_plugin_instantiation' is a unit test designed to verify the instantiation and basic functionality of a plugin. It checks for the presence of an API key, creates an instance of the plugin, and verifies its name and chain support. This is a typical and necessary test to ensure that the plugin is set up correctly and can handle different blockchain types. Such tests are crucial for maintaining code quality and reliability, especially in environments where plugins interact with external services. Therefore, it is unlikely to be deleted as it serves an important purpose in the codebase."
survived,"def test_custodial_wallet_invalid_options(custodial_api, invalid_options, solana_connection):
    """"""Test error handling with invalid options.""""""
    with pytest.raises(Exception) as exc:
        custodial_api.create_custodial_wallet(list(invalid_options.values())[0])
    assert ""error"" in str(exc.value).lower() or ""invalid"" in str(exc.value).lower()
",python/src/wallets/crossmint/tests/test_custodial_wallet.py,,1,3.3982678079468468e-09,"The method `test_custodial_wallet_invalid_options` is a unit test designed to verify the error handling of the `create_custodial_wallet` function when provided with invalid options. Unit tests are crucial for ensuring code reliability and robustness, especially in handling edge cases and errors. This test checks that the function raises an exception with an appropriate error message when invalid input is provided. Such tests are typically retained to maintain code quality and prevent regressions, making it unlikely for this method to be deleted."
survived,"def test_smart_wallet_ens_resolution(smart_api, test_wallet_options, test_keypair):
    """"""Test ENS name resolution.""""""
    # Create wallet and client
    wallet = smart_api.create_smart_wallet()
    client = SmartWalletClient(
        wallet[""address""],
        smart_api,
        test_wallet_options[""chain""],
        test_keypair,
        test_wallet_options[""provider""],
        test_wallet_options[""options""][""ensProvider""]
    )
    
    # Test with a known ENS name
    try:
        address = client.resolve_address(""vitalik.eth"")
        assert address.startswith(""0x"")
        assert Web3.is_address(address)
    except ValueError as e:
        # ENS provider might be unavailable, that's ok
        assert ""provider is not configured"" in str(e).lower() or ""could not resolve"" in str(e).lower()
",python/src/wallets/crossmint/tests/test_smart_wallet.py,,1,9.931195248674785e-08,"The method `test_smart_wallet_ens_resolution` is a test function designed to verify the functionality of ENS (Ethereum Name Service) resolution within a smart wallet context. It is a specific test case that checks if a known ENS name can be resolved to an Ethereum address using the provided client and API. Test functions like this are typically retained in codebases to ensure that critical functionalities work as expected, especially in blockchain applications where address resolution is crucial. Therefore, it is unlikely to be deleted unless the feature it tests is deprecated or the testing framework is significantly changed."
survived,"def test_smart_wallet_read_contract(smart_api, test_wallet_options, test_keypair):
    """"""Test reading from a smart contract.""""""
    # Create wallet and client
    wallet = smart_api.create_smart_wallet()
    client = SmartWalletClient(
        wallet[""address""],
        smart_api,
        test_wallet_options[""chain""],
        test_keypair,
        test_wallet_options[""provider""],
        test_wallet_options[""options""][""ensProvider""]
    )
    
    # Example ERC20 balanceOf ABI
    abi = [{
        ""constant"": True,
        ""inputs"": [{""name"": ""_owner"", ""type"": ""address""}],
        ""name"": ""balanceOf"",
        ""outputs"": [{""name"": ""balance"", ""type"": ""uint256""}],
        ""type"": ""function""
    }]
    
    # Read contract
    try:
        result = client.read({
            ""address"": ""0x742d35Cc6634C0532925a3b844Bc454e4438f44e"",
            ""abi"": abi,
            ""functionName"": ""balanceOf"",
            ""args"": [wallet[""address""]]
        })
        assert ""value"" in result
    except Exception as e:
        # Contract might not exist on testnet, that's ok
        assert ""revert"" in str(e).lower() or ""not found"" in str(e).lower()
",python/src/wallets/crossmint/tests/test_smart_wallet.py,,1,7.73442280641062e-08,"The method `test_smart_wallet_read_contract` is a test function designed to verify the functionality of reading from a smart contract using a smart wallet. It is a part of a test suite, likely for a blockchain or cryptocurrency application, and is essential for ensuring that the smart wallet can interact with smart contracts correctly. Test functions are crucial for maintaining code quality and reliability, especially in blockchain applications where financial transactions are involved. Therefore, this method is likely to be retained as it serves an important role in testing the application's functionality."
survived,"def get_box_ccg_client(config: Mapping[str, Any]) -> BoxClient:
    client_id = config[""client_id""]
    client_secret = config[""client_secret""]
    box_subject_type = config[""box_subject_type""]
    box_subject_id = config[""box_subject_id""]

    if box_subject_type == ""enterprise"":
        enterprise_id = box_subject_id
        user_id = None
    else:
        enterprise_id = None
        user_id = box_subject_id
    ccg_config = CCGConfig(client_id=client_id, client_secret=client_secret, enterprise_id=enterprise_id, user_id=user_id)
    ccg_auth = BoxCCGAuth(ccg_config)
    return add_extra_header_to_box_client(BoxClient(ccg_auth))
",airbyte-integrations/connectors/source-box-data-extract/source_box_data_extract/box_api.py,,1,3.160881453314576e-10,"The method 'get_box_ccg_client' is likely to survive because it encapsulates a specific functionality of creating a BoxClient with CCG (Client Credentials Grant) authentication. This is a common pattern for setting up API clients with specific authentication mechanisms, and the method is well-structured to handle different configurations based on the 'box_subject_type'. It is also modular, making it reusable and easy to maintain. Unless there is a significant change in the way BoxClient or CCG authentication is handled, this method will remain useful."
survived,"def box_file_ai_ask(client: BoxClient, file_id: str, prompt: str) -> str:
    mode = CreateAiAskMode.SINGLE_ITEM_QA
    ai_item = AiItemBase(id=file_id, type=AiItemBaseTypeField.FILE)
    response = client.ai.create_ai_ask(mode=mode, prompt=prompt, items=[ai_item])
    return response.answer
",airbyte-integrations/connectors/source-box-data-extract/source_box_data_extract/box_api.py,,1,6.69158608681505e-10,"The method 'box_file_ai_ask' is likely to survive because it encapsulates a specific functionality that interacts with an AI service to perform a question-answering task on a file. This kind of functionality is valuable in applications that require AI-driven insights or data extraction from files. Additionally, the method is well-defined with clear parameters and a return type, making it reusable and easy to integrate into larger systems. Unless there are changes in the API or the service it relies on, this method is likely to remain useful."
survived,"    def get_json_schema(self):
        return get_generic_json_schema()
",airbyte-integrations/connectors/source-box-data-extract/source_box_data_extract/source.py,StreamAIAskFolder,0,0.9997965729390125,"The method `get_json_schema` is a simple wrapper around another function `get_generic_json_schema`. If `get_generic_json_schema` is a stable and widely used function, this method might be retained for convenience, especially if it is part of a larger class where such a method is expected. However, if the method does not add any additional functionality or customization, it could be considered redundant and might be removed to simplify the codebase. Without additional context on how this method is used or the importance of `get_generic_json_schema`, it's challenging to definitively predict its fate. However, given the trend towards code simplification and removal of unnecessary layers, it is more likely to be deleted unless it serves a specific purpose in the class or module."
survived,"def test_streams(mocker):
    source = SourceBoxDataExtract()
    config_mock = MagicMock()
    streams = source.streams(config_mock)
    expected_streams_number = 4
    assert len(streams) == expected_streams_number",airbyte-integrations/connectors/source-box-data-extract/unit_tests/test_source.py,,1,1.1861120010657661e-08,"The method 'test_streams' is a unit test function that uses a mock object to test the 'streams' method of the 'SourceBoxDataExtract' class. It checks if the number of streams returned matches the expected number. This is a typical and useful test case to ensure the functionality of the 'streams' method, especially in a test-driven development environment. Therefore, it is likely to be retained as it serves a clear purpose in verifying the code's correctness."
survived,"    def get_rejection_message(self, input_str: str) -> str:
        """"""
        Get a message explaining why the input was rejected.
        
        Args:
            input_str: The rejected input string
            
        Returns:
            A message explaining the rejection
        """"""
        return ""Your input contains terms that may be related to harmful or inappropriate content. Please rephrase your request.""
",openai-agents-examples/10_agent_with_guardrails.py,ContentModerationGuardrail,1,2.0611536181902033e-09,"The method 'get_rejection_message' is a utility function that provides a standardized response for rejected inputs. Such methods are often useful in applications that require consistent messaging for user feedback, especially in systems that need to handle inappropriate or harmful content. Given the increasing importance of content moderation and user communication in software applications, this method is likely to be retained for its utility in providing clear and consistent rejection messages."
survived,"def get_current_weather(location: str, unit: str) -> str:
    """"""
    Get the current weather in a given location.
    
    Args:
        location: The city and state, e.g. San Francisco, CA or country e.g., London, UK
        unit: The temperature unit to use. Either ""celsius"" or ""fahrenheit"".
        
    Returns:
        A string containing the weather information.
    """"""
    # This is a mock implementation - in a real application, you would call a weather API
    weather_data = {
        ""New York"": {""temperature"": 22, ""condition"": ""Sunny""},
        ""London"": {""temperature"": 15, ""condition"": ""Cloudy""},
        ""Tokyo"": {""temperature"": 28, ""condition"": ""Rainy""},
        ""Sydney"": {""temperature"": 31, ""condition"": ""Hot and sunny""},
    }
    
    # Default weather if location not found
    default_weather = {""temperature"": 20, ""condition"": ""Clear""}
    
    # Get weather for the location (case insensitive)
    location_key = next((k for k in weather_data.keys() if k.lower() == location.lower()), None)
    weather = weather_data.get(location_key, default_weather)
    
    # Convert temperature if needed
    temp = weather[""temperature""]
    if unit.lower() == ""fahrenheit"":
        temp = (temp * 9/5) + 32
    
    return f""The current weather in {location} is {weather['condition']} with a temperature of {temp}°{'F' if unit.lower() == 'fahrenheit' else 'C'}.""
",openai-agents-examples/05_agent_with_function_tools.py,,1,5.043472052266442e-07,"The method `get_current_weather` is a mock implementation that provides a basic functionality to return weather information based on a hardcoded dataset. While it does not connect to a real weather API, it serves as a useful placeholder or example for educational purposes or initial development stages. Such methods are often retained in codebases for testing, demonstration, or as a template for future development. Therefore, it is likely to survive unless there is a specific requirement to replace it with a real API call."
survived,"def create_travel_assistant() -> Agent:
    """"""
    Create a travel assistant agent with function tools.
    
    Returns:
        An Agent instance with function tools for travel assistance.
    """"""
    instructions = """"""
    You are a helpful travel assistant that can provide information about weather, 
    distances between locations, and current time.
    Use the tools available to you to provide accurate information when asked.
    If you don't have a tool for the specific request, acknowledge the limitations
    and provide the best information you can.
    """"""
    
    # Create the agent with function tools
    return Agent(
        name=""TravelAssistant"",
        instructions=instructions,
        model=""gpt-4o-mini"",
        tools=[get_current_weather, calculate_distance, get_current_time]
    )
",openai-agents-examples/05_agent_with_function_tools.py,,1,9.736200303530205e-10,"The method 'create_travel_assistant' is likely to survive because it encapsulates the creation of a travel assistant agent with specific functionalities. It is well-documented, clearly defines its purpose, and uses a structured approach to instantiate an 'Agent' with predefined tools. This kind of utility function is useful in applications that require modular and reusable components, especially in contexts where travel assistance is needed. Additionally, the use of a model and tools suggests it is part of a larger system, making it integral to the application's functionality."
survived,"async def run_customer_support_system(prompt: str) -> str:
    """"""
    Run the customer support system with the given prompt.
    
    Args:
        prompt: The customer's inquiry
        
    Returns:
        The final response from the appropriate specialist agent
    """"""
    # Create specialist agents
    billing_agent = create_billing_agent()
    technical_agent = create_technical_agent()
    account_agent = create_account_agent()
    
    # Create triage agent with specialists
    triage_agent = create_triage_agent([billing_agent, technical_agent, account_agent])
    
    # Run the triage agent with the prompt
    result = await Runner.run(triage_agent, prompt)
    
    # Return the final response
    return result.final_output
",openai-agents-examples/07_agent_with_handoffs.py,,1,8.592166611791576e-10,"The method is likely to survive because it is a well-structured asynchronous function that handles customer support inquiries by utilizing a triage system with specialist agents. This approach is efficient for handling different types of customer queries, such as billing, technical, and account issues. The use of asynchronous programming is also beneficial for improving the responsiveness and scalability of the system. Additionally, the method is clearly documented, making it easier to maintain and understand."
survived,"async def run_conversation_with_context(prompt: str, context: Optional[Context] = None) -> tuple[str, Context]:
    """"""
    Run a conversation agent with context management.
    
    Args:
        prompt: The user's query or prompt
        context: Optional existing context from previous interactions
        
    Returns:
        A tuple containing the agent's response and the updated context
    """"""
    # Create the conversation agent
    agent = create_conversation_agent()
    
    # Create a new context if none is provided
    if context is None:
        context = Context()
    
    # Run the agent with the prompt and context
    result = await Runner.run(agent, prompt, context=context)
    
    # Return the response and updated context
    return result.final_output, result.context
",openai-agents-examples/09_agent_with_context_management.py,,1,4.0586521248284276e-10,"The method 'run_conversation_with_context' is well-defined and serves a clear purpose in managing conversations with context. It is asynchronous, which is suitable for handling potentially long-running operations like conversation processing. The method also provides flexibility by allowing an optional context parameter, which is useful for maintaining state across multiple interactions. Given the increasing importance of context-aware systems in AI and conversational agents, this method is likely to be retained and used in applications that require such functionality."
survived,"def test_create_triage_agent():
    """"""Test that the triage agent is created with the correct configuration.""""""
    billing_agent = create_billing_agent()
    technical_agent = create_technical_agent()
    account_agent = create_account_agent()
    
    triage_agent = create_triage_agent([billing_agent, technical_agent, account_agent])
    
    assert triage_agent.name == ""TriageAgent""
    assert ""triage agent"" in triage_agent.instructions.lower()
    assert len(triage_agent.handoffs) == 3
",openai-agents-examples/07_agent_with_handoffs.py,,1,6.348800075736417e-09,"The method 'test_create_triage_agent' is a unit test designed to verify the correct creation and configuration of a 'triage agent'. Unit tests are crucial for ensuring code reliability and correctness, especially in complex systems where multiple components interact. This test checks that the 'triage agent' is created with the expected name, instructions, and number of handoffs, which are essential aspects of its functionality. Given the importance of testing in software development, this method is likely to be retained to maintain code quality and prevent regressions."
survived,"def test_create_health_agent():
    """"""Test that the health agent is created with the correct configuration.""""""
    agent = create_health_agent()
    assert agent.name == ""HealthAdvisor""
    assert ""health advisor"" in agent.instructions.lower()
    assert agent.model == ""gpt-4o-mini""
",openai-agents-examples/03_sync_agent.py,,1,7.73442280641062e-08,"The method 'test_create_health_agent' is a unit test function that checks the creation of a health agent with specific attributes. Unit tests are crucial for ensuring code reliability and correctness, especially in larger projects. They help in identifying bugs early and ensure that changes do not break existing functionality. Given the importance of testing in software development, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered."
survived,"def format_blog_as_markdown(title: str, content: str) -> str:
    """"""
    Format a blog post as markdown.
    
    Args:
        title: The blog post title
        content: The blog post content
        
    Returns:
        A string containing the formatted markdown
    """"""
    # Ensure the content has proper markdown formatting
    if not content.startswith('#'):
        content = f""# {title}\n\n{content}""
    
    # Add metadata
    markdown = f""""""---
title: ""{title}""
date: ""{datetime.now().strftime('%Y-%m-%d')}""
author: ""AI Research & Blog System""
tags: [""ai"", ""research"", ""blog""]
---

{content}
""""""
    
    return markdown
",openai-agents-examples/13_research_blog_system.py,,1,5.905303995456778e-10,"The method 'format_blog_as_markdown' is a utility function that formats a blog post into markdown, which is a common requirement for content management systems and static site generators. It includes metadata such as title, date, author, and tags, which are essential for organizing and displaying blog content. The function is well-documented, with clear arguments and return types, making it easy to understand and use. Given the widespread use of markdown in web development and content creation, this method is likely to be useful and relevant, leading to its survival."
survived,"    def filter(self, input_str: str) -> Optional[str]:
        """"""
        Filter the input string based on format requirements.
        
        Args:
            input_str: The input string to filter
            
        Returns:
            The input string if it passes, or None if it should be rejected
        """"""
        # Check length constraints
        if len(input_str) < self.min_length:
            return None  # Too short
        
        if len(input_str) > self.max_length:
            return None  # Too long
        
        return input_str  # Accept the input
",openai-agents-examples/10_agent_with_guardrails.py,FormatValidationGuardrail,1,6.69158608681505e-10,"The method 'filter' is a utility function that checks if a given string meets certain length constraints. It is a straightforward implementation that is likely to be useful in various contexts where input validation is required. The method is well-documented, specifying its purpose, arguments, and return value clearly. Such utility methods are common in codebases to ensure data integrity and are unlikely to be removed unless the entire validation approach is refactored or replaced. Therefore, it is likely to survive."
survived,"def test_create_specialist_agents():
    """"""Test that specialist agents are created with the correct configuration.""""""
    research_agent = create_research_agent()
    outline_agent = create_outline_agent()
    content_agent = create_content_agent()
    editor_agent = create_editor_agent()
    
    assert research_agent.name == ""ResearchSpecialist""
    assert outline_agent.name == ""OutlineSpecialist""
    assert content_agent.name == ""ContentSpecialist""
    assert editor_agent.name == ""EditingSpecialist""
    
    assert ""research specialist"" in research_agent.instructions.lower()
    assert ""outline specialist"" in outline_agent.instructions.lower()
    assert ""content writing specialist"" in content_agent.instructions.lower()
    assert ""editing specialist"" in editor_agent.instructions.lower()
",openai-agents-examples/11_agent_orchestration.py,,1,1.8189616842444243e-09,"The method `test_create_specialist_agents` is a unit test designed to verify that different types of specialist agents are created with the correct configurations. It checks both the names and the instructions of these agents to ensure they match expected values. This is a typical and necessary test in software development to ensure that the code behaves as expected. Since it serves a clear purpose in maintaining code quality and correctness, it is unlikely to be deleted."
survived,"def test_create_anthropic_agent():
    """"""Test that the Anthropic agent is created with the correct configuration.""""""
    import pytest
    
    # Skip this test if no API key is available
    if not os.environ.get(""ANTHROPIC_API_KEY""):
        pytest.skip(""ANTHROPIC_API_KEY not set"")
    
    agent = create_anthropic_agent()
    assert agent.name == ""ClaudeAssistant""
    assert ""claude"" in agent.instructions.lower()
    assert isinstance(agent.model_provider, AnthropicModelProvider)
",openai-agents-examples/12_anthropic_agent.py,,1,9.237449576640118e-09,"The method `test_create_anthropic_agent` is a unit test designed to verify the creation of an Anthropic agent with the correct configuration. It includes a conditional skip if the necessary API key is not set, which is a common practice in testing to avoid failures due to missing environment variables. The test checks for specific attributes and types, which are essential for ensuring the agent is correctly instantiated. There is no indication of deprecated functionality or issues that would necessitate its deletion. Therefore, it is likely to be maintained as part of the test suite."
survived,"def main():
    """"""Main function to parse arguments and run the conversation agent.""""""
    parser = argparse.ArgumentParser(description=""Agent with Context Management Example"")
    parser.add_argument(""--prompt"", ""-p"", type=str, required=True, 
                        help=""The prompt to send to the agent"")
    parser.add_argument(""--follow-up"", ""-f"", type=str, nargs=""*"", default=[],
                        help=""Optional follow-up prompts to simulate a conversation"")
    
    args = parser.parse_args()
    
    # Ensure API key is available
    if not os.environ.get(""OPENAI_API_KEY""):
        console.print(Panel(""[bold red]Error: OPENAI_API_KEY environment variable not set[/bold red]""))
        sys.exit(1)
    
    try:
        # Simulate a conversation with the provided prompts
        responses = simulate_conversation(args.prompt, args.follow_up)
        
        # Display the initial response
        console.print(Panel(responses[0], title=f""Response to: {args.prompt}"", border_style=""green""))
        
        # Display follow-up responses if any
        for i, response in enumerate(responses[1:]):
            console.print(Panel(response, title=f""Response to: {args.follow_up[i]}"", border_style=""blue""))
    
    except Exception as e:
        console.print(Panel(f""[bold red]Error: {str(e)}[/bold red]""))
        sys.exit(1)
",openai-agents-examples/09_agent_with_context_management.py,,1,3.3982678079468468e-09,"The method 'main()' is a typical entry point for a Python script that uses command-line arguments to perform its tasks. It includes argument parsing, environment variable checking, and error handling, which are all standard practices for robust script design. The method is well-structured and serves a clear purpose in the context of running a conversation agent. There is no indication that this method is obsolete or redundant, and it is likely to be useful for users who need to interact with the conversation agent via the command line. Therefore, it is likely to be retained in the codebase."
survived,"def test_create_research_blog():
    """"""Test that the research blog system can run and produce a blog post.""""""
    import pytest
    
    # Skip this test if no API key is available
    if not os.environ.get(""OPENAI_API_KEY""):
        pytest.skip(""OPENAI_API_KEY not set"")
    
    # Run a test with a simple topic
    # Use a shorter timeout for testing
    blog_post = asyncio.run(create_research_blog(""AI Ethics""))
    
    # Verify we got a non-empty blog post
    assert blog_post
    assert len(blog_post) > 0
    # The blog post should contain relevant terms
    assert any(term in blog_post.lower() for term in [""ai"", ""ethics"", ""principles""])
",openai-agents-examples/13_research_blog_system.py,,1,4.944450477491054e-09,"The method 'test_create_research_blog' is a test function designed to verify the functionality of a system that creates research blog posts. It includes a check for an API key, uses asynchronous execution, and contains assertions to validate the output. These are all standard practices in test functions, indicating that the method is well-structured and serves a clear purpose in ensuring the reliability of the blog creation system. Therefore, it is likely to be maintained as part of the test suite."
survived,"    async def reply_message(
        self,
        message_source: platform_message.MessageChain,
        message: platform_message.MessageChain,
    ) -> dict:
        """"""回复消息""""""
        source_components = [comp for comp in message_source if isinstance(comp, platform_message.Source)]
        if source_components:
            source = source_components[0]
            session_key = getattr(source, 'session_id', 'webchatperson')
        else:
            session_key = 'webchatperson'
            
        return await self.send_message('person', session_key, message)
",pkg/platform/sources/webchat.py,WebChatAdapter,1,2.1724399346070676e-10,"The method 'reply_message' is likely to survive because it performs a specific and useful function: replying to a message by extracting a session key and sending a message using an asynchronous call. The method is well-structured, uses asynchronous programming which is common in modern applications, and handles potential cases where the source component might not have a session ID. These characteristics suggest it is a functional and necessary part of the codebase."
survived,"    async def initialize(self) -> None:
        @self.route('/send', methods=['POST'])
        async def send_message() -> str:
            """"""发送调试消息到流水线""""""
            try:
                data = await quart.request.get_json()
                session_type = data.get('session_type', 'person')
                content = data.get('content', '')
                
                if not content:
                    return self.http_status(400, -1, 'content is required')
                
                if session_type not in ['person', 'group']:
                    return self.http_status(400, -1, 'session_type must be person or group')
                
                webchat_adapter = None
                for bot in self.ap.platform_mgr.bots:
                    if hasattr(bot.adapter, '__class__') and bot.adapter.__class__.__name__ == 'WebChatAdapter':
                        webchat_adapter = bot.adapter
                        break
                
                if not webchat_adapter:
                    return self.http_status(404, -1, 'WebChat adapter not found')
                
                result = await webchat_adapter.send_debug_message(session_type, content)
                
                return self.success(data=result)
                
            except Exception as e:
                return self.http_status(500, -1, f'Internal server error: {str(e)}')

        @self.route('/messages/<session_type>', methods=['GET'])
        async def get_messages(session_type: str) -> str:
            """"""获取调试消息历史""""""
            try:
                if session_type not in ['person', 'group']:
                    return self.http_status(400, -1, 'session_type must be person or group')
                
                webchat_adapter = None
                for bot in self.ap.platform_mgr.bots:
                    if hasattr(bot.adapter, '__class__') and bot.adapter.__class__.__name__ == 'WebChatAdapter':
                        webchat_adapter = bot.adapter
                        break
                
                if not webchat_adapter:
                    return self.http_status(404, -1, 'WebChat adapter not found')
                
                messages = webchat_adapter.get_debug_messages(session_type)
                
                return self.success(data={'messages': messages})
                
            except Exception as e:
                return self.http_status(500, -1, f'Internal server error: {str(e)}')

        @self.route('/reset/<session_type>', methods=['POST'])
        async def reset_session(session_type: str) -> str:
            """"""重置调试会话""""""
            try:
                if session_type not in ['person', 'group']:
                    return self.http_status(400, -1, 'session_type must be person or group')
                
                webchat_adapter = None
                for bot in self.ap.platform_mgr.bots:
                    if hasattr(bot.adapter, '__class__') and bot.adapter.__class__.__name__ == 'WebChatAdapter':
                        webchat_adapter = bot.adapter
                        break
                
                if not webchat_adapter:
                    return self.http_status(404, -1, 'WebChat adapter not found')
                
                webchat_adapter.reset_debug_session(session_type)
                
                return self.success(data={'message': 'Session reset successfully'})
                
            except Exception as e:
                return self.http_status(500, -1, f'Internal server error: {str(e)}')

        @self.route('/pipelines', methods=['GET'])
        async def get_pipelines() -> str:
            """"""获取可用的流水线列表""""""
            try:
                pipelines = await self.ap.pipeline_mgr.get_pipelines()
                
                pipeline_list = []
                for pipeline in pipelines:
                    pipeline_list.append({
                        'id': pipeline.uuid,
                        'name': pipeline.name,
                        'description': pipeline.description,
                        'is_default': pipeline.is_default
                    })
                
                return self.success(data={'pipelines': pipeline_list})
                
            except Exception as e:
                return self.http_status(500, -1, f'Internal server error: {str(e)}')",pkg/api/http/controller/groups/debug/webchat.py,WebChatDebugRouterGroup,1,1.0467401685178159e-08,"The method is a comprehensive implementation of an asynchronous API with multiple endpoints for handling messages, sessions, and pipelines. It includes error handling, input validation, and interaction with a WebChat adapter. The functionality provided is essential for the operation of a messaging platform, and there are no apparent issues or redundancies that would necessitate its removal. Therefore, it is likely to be retained."
survived,"def test_milvus_lite_connection():
    """"""Test basic Milvus Lite connection and operations.""""""
    temp_dir = tempfile.mkdtemp(prefix=""milvus_lite_test_"")
    db_path = os.path.join(temp_dir, ""test.db"")
    
    try:
        # Connect to Milvus Lite
        logger.info(f""Connecting to Milvus Lite at {db_path}"")
        connections.connect(
            alias=""default"",
            uri=db_path,
            use_lite=True,
            timeout=30
        )
        logger.info(""Successfully connected to Milvus Lite"")
        
        # List connections
        conns = connections.list_connections()
        logger.info(f""Active connections: {conns}"")
        
        # Check if connection is working
        assert connections.has_connection(""default""), ""Connection not established""
        
        # For Milvus Lite, we'll test basic collection operations instead of version check
        test_collection = ""test_collection""
        
        # Create a test collection
        from pymilvus import Collection, CollectionSchema, DataType, FieldSchema
        
        if utility.has_collection(test_collection):
            utility.drop_collection(test_collection)
            
        fields = [
            FieldSchema(name=""id"", dtype=DataType.INT64, is_primary=True, auto_id=True),
            FieldSchema(name=""vector"", dtype=DataType.FLOAT_VECTOR, dim=8)
        ]
        schema = CollectionSchema(fields=fields, enable_dynamic_field=True)
        collection = Collection(name=test_collection, schema=schema)
        
        # Create FLAT index (only supported type in Milvus Lite)
        collection.create_index(
            field_name=""vector"",
            index_params={""metric_type"": ""L2"", ""index_type"": ""FLAT""}
        )
        
        logger.info(""Successfully created test collection and index"")
        utility.drop_collection(test_collection)
        
        return True
        
    except Exception as e:
        logger.error(f""Connection test failed: {str(e)}"")
        return False
        
    finally:
        # Clean up
        try:
            if connections.has_connection(""default""):
                connections.disconnect(""default"")
            shutil.rmtree(temp_dir, ignore_errors=True)
        except Exception as e:
            logger.warning(f""Cleanup error: {str(e)}"")
",airbyte-integrations/connectors/destination-milvus/integration_tests/test_connection.py,,1,5.3157849718487075e-08,"The method `test_milvus_lite_connection` is a utility function designed to test the connection and basic operations with Milvus Lite, a lightweight version of the Milvus vector database. It includes connection setup, collection creation, index creation, and cleanup processes. Such utility functions are crucial for ensuring that the database setup and operations are functioning correctly, especially in testing environments. Given its importance in verifying the functionality of Milvus Lite connections and operations, it is likely to be retained in the codebase for testing purposes."
survived,"def test_solana_smart_wallet_with_phone(smart_api, test_phone, test_solana_wallet_options):
    """"""Test Solana smart wallet creation with phone.""""""
    wallet = smart_api.create_wallet(
        wallet_type=WalletType.SOLANA_SMART_WALLET,
        linked_user=f""phoneNumber:{test_phone}""
    )
    assert wallet[""type""] == ""solana-smart-wallet""
    assert ""linkedUser"" in wallet
",python/src/wallets/crossmint/tests/test_solana_smart_wallet.py,,1,2.646573631904765e-09,"The method 'test_solana_smart_wallet_with_phone' is a test function that verifies the creation of a Solana smart wallet using a phone number. It uses assertions to ensure the wallet is created with the correct type and linked user. Test functions like this are crucial for maintaining code quality and ensuring that new features or changes do not break existing functionality. Given the importance of testing in software development, especially in blockchain and financial applications where accuracy and reliability are critical, this method is likely to be retained to ensure the system behaves as expected."
survived,"def change_password(user_id: str, current_password: str, new_password: str) -> Tuple[bool, Dict]:
    """"""
    Change a user's password.
    
    Args:
        user_id: The ID of the user
        current_password: The current password
        new_password: The new password
        
    Returns:
        Tuple of (success, result) where result contains a success message or error message
    """"""
    # Validate required fields
    missing_fields = validate_required_fields(
        {""current_password"": current_password, ""new_password"": new_password},
        [""current_password"", ""new_password""]
    )
    
    if missing_fields:
        return False, {""error"": f""Missing required fields: {', '.join(missing_fields)}""}
    
    # Validate new password strength
    password_validation = validate_password_strength(new_password)
    if not password_validation[""is_valid""]:
        errors = []
        if not password_validation[""length""]:
            errors.append(""Password must be at least 8 characters"")
        if not password_validation[""uppercase""]:
            errors.append(""Password must contain at least one uppercase letter"")
        if not password_validation[""lowercase""]:
            errors.append(""Password must contain at least one lowercase letter"")
        if not password_validation[""digit""]:
            errors.append(""Password must contain at least one digit"")
        if not password_validation[""special_char""]:
            errors.append(""Password must contain at least one special character"")
        
        return False, {""error"": errors}
    
    # In a real application, this would verify the current password and update it
    # For this mock, we'll just print the change
    print(f""[PASSWORD] User {user_id} password changed"")
    
    return True, {""message"": ""Password changed successfully""}",codebase-architectures/atomic-composable-architecture/capabilities/user_management.py,,1,1.0467401685178159e-08,"The method 'change_password' is a fundamental part of user account management, which is a critical feature in any application that requires user authentication. It includes necessary validations for password strength and checks for missing fields, which are essential for security and user experience. These features are unlikely to be removed as they are standard practices in software development for handling user credentials securely."
survived,"    def get_all_categories():
        """"""Get all categories.""""""
        try:
            categories = CategoryService.get_all_categories()
            return {
                ""success"": True,
                ""data"": categories
            }
        except Exception as e:
            Logger.error(app_logger, f""Error in get_all_categories: {str(e)}"", exc_info=True)
            return {
                ""success"": False,
                ""message"": ""An error occurred while retrieving categories""
            }
",codebase-architectures/layered-architecture/api/category_api.py,CategoryAPI,1,4.944450477491054e-09,"The method `get_all_categories` is a utility function that retrieves all categories using a service class `CategoryService`. It includes error handling and logging, which are good practices for robust code. The method is likely to be useful in various parts of an application where category data is needed. Since it provides a clear and structured response, it is unlikely to be deleted unless there is a significant change in how categories are managed or retrieved in the application."
survived,"    def _execute_stage(self, stage_instance, previous_result):
        """"""Execute a stage with the result from the previous stage.""""""
        # This method should be overridden in subclasses to provide
        # specific implementation for subsequent stages
        raise NotImplementedError(""Subclasses must implement _execute_stage"")
",codebase-architectures/pipeline-architecture/pipeline/pipeline_manager.py,PipelineManager,1,3.927863699585036e-07,"The method _execute_stage is designed to be overridden by subclasses, as indicated by the NotImplementedError. This is a common pattern in object-oriented programming to define a template method in a base class that requires subclasses to provide specific implementations. Since this method is part of a framework or a base class that expects subclasses to implement specific behavior, it is unlikely to be deleted. Instead, it serves as a contract for subclasses, ensuring they provide the necessary functionality."
survived,"def create_sample_data():
    """"""Create sample sales data for the pipeline example.""""""
    # Create output directory if it doesn't exist
    os.makedirs(""./data"", exist_ok=True)
    
    # Sample sales data
    sales_data = [
        {
            ""id"": ""S001"",
            ""product"": ""Laptop"",
            ""category"": ""Electronics"",
            ""price"": 1299.99,
            ""quantity"": 5,
            ""date"": ""2025-01-15"",
            ""customer"": ""ABC Corp"",
            ""discount"": 0.1
        },
        {
            ""id"": ""S002"",
            ""product"": ""Smartphone"",
            ""category"": ""Electronics"",
            ""price"": 899.99,
            ""quantity"": 10,
            ""date"": ""2025-01-20"",
            ""customer"": ""XYZ Ltd"",
            ""discount"": 0.05
        },
        {
            ""id"": ""S003"",
            ""product"": ""Office Chair"",
            ""category"": ""Furniture"",
            ""price"": 249.99,
            ""quantity"": 8,
            ""date"": ""2025-01-22"",
            ""customer"": ""123 Industries"",
            ""discount"": 0.0
        },
        {
            ""id"": ""S004"",
            ""product"": ""Desk"",
            ""category"": ""Furniture"",
            ""price"": 349.99,
            ""quantity"": 4,
            ""date"": ""2025-01-25"",
            ""customer"": ""ABC Corp"",
            ""discount"": 0.15
        },
        {
            ""id"": ""S005"",
            ""product"": ""Monitor"",
            ""category"": ""Electronics"",
            ""price"": 499.99,
            ""quantity"": 12,
            ""date"": ""2025-01-30"",
            ""customer"": ""XYZ Ltd"",
            ""discount"": 0.1
        },
        {
            ""id"": ""S006"",
            ""product"": ""Printer"",
            ""category"": ""Electronics"",
            ""price"": 299.99,
            ""quantity"": 3,
            ""date"": ""2025-02-05"",
            ""customer"": ""123 Industries"",
            ""discount"": 0.0
        },
        {
            ""id"": ""S007"",
            ""product"": ""Bookshelf"",
            ""category"": ""Furniture"",
            ""price"": 199.99,
            ""quantity"": 6,
            ""date"": ""2025-02-10"",
            ""customer"": ""ABC Corp"",
            ""discount"": 0.05
        }
    ]
    
    # Save to file
    with open(""./data/sales_data.json"", ""w"") as file:
        json.dump(sales_data, file, indent=2)
    
    print(f""Created sample data file: ./data/sales_data.json"")
    return ""./data/sales_data.json""
",codebase-architectures/pipeline-architecture/main.py,,1,4.944450477491054e-09,"The method `create_sample_data` is a utility function that generates sample sales data and saves it to a JSON file. It is useful for testing and demonstration purposes, especially in data processing pipelines or applications that require sample data for development. The method is self-contained, does not rely on external dependencies beyond standard libraries, and provides a clear output (a JSON file with sample data). Such utility functions are often retained in codebases for testing, development, and educational purposes. Therefore, it is likely to be retained."
survived,"def display_header(text):
    """"""Display a header with the given text.""""""
    print(""\n"" + ""="" * 50)
    print(f"" {text}"")
    print(""="" * 50)
",codebase-architectures/layered-architecture/main.py,,1,9.736200303530205e-10,"The method 'display_header' is a simple utility function that formats and prints a header with a given text. Such utility functions are often useful in various applications for consistent formatting of output, especially in command-line interfaces or logging. The method is straightforward, has a clear purpose, and is likely to be reused in different parts of a codebase where formatted headers are needed. Therefore, it is likely to survive as it provides a basic yet useful functionality."
survived,"def mark_all_alerts_as_read(user_id: str) -> int:
    """"""
    Mark all alerts for a user as read.
    
    Args:
        user_id: The ID of the user
        
    Returns:
        Number of alerts marked as read
    """"""
    return mark_all_notifications_as_read(user_id)
",codebase-architectures/atomic-composable-architecture/capabilities/alerting.py,,0,0.9999998555019682,"The method 'mark_all_alerts_as_read' is a simple wrapper around another function 'mark_all_notifications_as_read'. It doesn't add any additional logic or functionality, making it somewhat redundant. If the underlying function 'mark_all_notifications_as_read' is sufficient and well-named, this wrapper might be considered unnecessary and could be deleted to simplify the codebase."
survived,"    def info(logger, message):
        """"""Log an info message.""""""
        logger.info(message)
",codebase-architectures/layered-architecture/utils/logger.py,Logger,1,3.2241866333029355e-08,"The method 'info' is a simple utility function that wraps the logger's 'info' method to log messages. This kind of function is often used to standardize logging across a codebase, making it easier to change logging behavior in one place if needed. It is a common practice to have such utility functions for logging, and unless there is a specific reason to remove it (like redundancy or a change in logging strategy), it is likely to be retained."
survived,"def send_email_notification(email: str, subject: str, message: str) -> bool:
    """"""
    Send an email notification (mock implementation).
    
    Args:
        email: The recipient's email address
        subject: The email subject
        message: The email message
        
    Returns:
        True if the email was sent successfully (always True in this mock)
    """"""
    # In a real application, this would send an actual email
    print(f""[EMAIL] To: {email}, Subject: {subject}"")
    print(f""[EMAIL] Message: {message}"")
    return True
",codebase-architectures/atomic-composable-architecture/modules/notifications.py,,1,1.444980317078884e-07,"The method `send_email_notification` is a mock implementation that simulates sending an email by printing the email details to the console. It is a simple and useful utility function for testing purposes, especially in environments where sending real emails is not feasible or necessary. Such mock functions are often retained in codebases for testing and development purposes, as they allow developers to verify email-related logic without the overhead of actual email delivery. Therefore, it is likely to be retained in the codebase."
survived,"    def send_alert(token: str, message: str, level: str = ""info"", 
                  email: Optional[str] = None, phone: Optional[str] = None,
                  additional_data: Optional[Dict] = None) -> Dict:
        """"""
        Send an alert to a user.
        
        Args:
            token: Authentication token
            message: The alert message
            level: Alert level (info, warning, error)
            email: Optional email address to send the alert to
            phone: Optional phone number to send the alert to
            additional_data: Additional data for the alert
            
        Returns:
            Response with success status and alert details or error message
        """"""
        # Validate token
        success, user_data = validate_user_token(token)
        if not success:
            return {
                ""status"": ""error"",
                ""message"": ""Invalid or expired token"",
                ""data"": None
            }
        
        # Send alert
        success, result = send_user_alert(
            user_id=user_data[""id""],
            message=message,
            level=level,
            email=email,
            phone=phone,
            additional_data=additional_data
        )
        
        if success:
            return {
                ""status"": ""success"",
                ""message"": ""Alert sent successfully"",
                ""data"": result
            }
        else:
            return {
                ""status"": ""error"",
                ""message"": result.get(""error"", ""Failed to send alert""),
                ""data"": None
            }
",codebase-architectures/atomic-composable-architecture/endpoints/alerts_api.py,AlertsAPI,1,9.736200303530205e-10,"The method 'send_alert' is well-defined and serves a clear purpose of sending alerts to users with various options for customization. It includes token validation, which is crucial for security, and handles different alert levels and optional contact methods. The method also provides detailed responses for success and error cases, making it robust and user-friendly. Given these factors, the method is likely to be useful in many applications that require alert notifications, and there is no indication that it is obsolete or redundant. Therefore, it is likely to survive."
survived,"    def delete_product(product_id):
        """"""Delete a product.""""""
        try:
            result = ProductService.delete_product(product_id)
            if not result:
                return {
                    ""success"": False,
                    ""message"": f""Product with ID {product_id} not found""
                }
            return {
                ""success"": True,
                ""message"": ""Product deleted successfully""
            }
        except Exception as e:
            Logger.error(app_logger, f""Error in delete_product: {str(e)}"", exc_info=True)
            return {
                ""success"": False,
                ""message"": ""An error occurred while deleting the product""
            }",codebase-architectures/layered-architecture/api/product_api.py,ProductAPI,1,4.599055376537186e-10,"The method is well-structured and handles both successful and unsuccessful deletion attempts. It uses a try-except block to catch exceptions, logs errors, and provides clear messages for both success and failure cases. This makes it robust and user-friendly, which are desirable qualities in production code. Therefore, it is likely to be retained."
survived,"    def get_by_username(username):
        """"""Get a user by username.""""""
        all_users = db.get_all(""users"")
        for user in all_users:
            if user[""username""] == username:
                return user
        return None
",codebase-architectures/vertical-slice-architecture/features/users/service.py,UserService,1,4.363462233903899e-09,"The method 'get_by_username' is a straightforward utility function that retrieves a user from a database by their username. This is a common requirement in many applications where user management is involved. The method is simple, clear, and performs a necessary task efficiently. Unless there is a significant change in how users are managed or retrieved, such as a shift to a different database structure or a more complex querying system, this method is likely to remain useful and relevant."
survived,"    def validate_data(self, schema=None, required_fields=None):
        """"""
        Validate the loaded data against a schema or required fields.
        
        Args:
            schema: Schema definition for validation
            required_fields: List of required field names
        
        Returns:
            dict: Stage result with data and metadata
        """"""
        if self.data is None:
            self.metadata[""status""] = ""error""
            self.metadata[""errors""].append(""No data loaded to validate"")
            return self._create_result()
        
        try:
            validation_errors = []
            
            # Validate required fields if specified
            if required_fields:
                if isinstance(self.data, list):
                    for i, item in enumerate(self.data):
                        try:
                            validate_required_fields(item, required_fields)
                        except ValueError as e:
                            validation_errors.append(f""Record {i}: {str(e)}"")
                else:
                    try:
                        validate_required_fields(self.data, required_fields)
                    except ValueError as e:
                        validation_errors.append(str(e))
            
            # Update metadata based on validation results
            if validation_errors:
                self.metadata[""status""] = ""validation_failed""
                self.metadata[""errors""].extend(validation_errors)
            else:
                self.metadata[""status""] = ""validated""
            
            return self._create_result()
        except Exception as e:
            self.metadata[""status""] = ""error""
            self.metadata[""errors""].append(f""Validation error: {str(e)}"")
            return self._create_result()
",codebase-architectures/pipeline-architecture/pipeline/input_stage.py,InputStage,1,1.1032560311263802e-09,"The method 'validate_data' is a crucial part of data processing pipelines, ensuring that the data conforms to expected formats and contains necessary fields. It handles both schema-based and field-based validation, which are common requirements in data validation tasks. The method also includes error handling and updates metadata accordingly, making it robust and informative. These characteristics make it a valuable utility in data processing, suggesting it will likely be retained in the codebase."
survived,"    def _create_pipeline_result(self):
        """"""Create a result dictionary for the entire pipeline.""""""
        # Get the final result
        final_result = self.get_final_result()
        
        # Create pipeline result
        pipeline_result = {
            ""metadata"": self.metadata,
            ""stages"": [{
                ""name"": stage[""name""],
                ""status"": stage[""status""]
            } for stage in self.stages]
        }
        
        # Add data from final stage if available
        if final_result and ""data"" in final_result:
            pipeline_result[""data""] = final_result[""data""]
        
        # Add analysis from final stage if available
        if final_result and ""analysis"" in final_result:
            pipeline_result[""analysis""] = final_result[""analysis""]
        
        return pipeline_result
",codebase-architectures/pipeline-architecture/pipeline/pipeline_manager.py,PipelineManager,1,5.905303995456778e-10,"The method '_create_pipeline_result' is well-structured and serves a clear purpose in the context of a pipeline processing system. It aggregates metadata, stages, and results into a cohesive dictionary, which is likely essential for reporting or further processing. The method is also flexible, checking for the presence of 'data' and 'analysis' in the final result before adding them, which suggests it is designed to handle varying outputs gracefully. These characteristics make it a valuable part of the codebase, and there is no indication that it is obsolete or redundant."
survived,"def mark_alert_as_read(user_id: str, notification_id: str) -> bool:
    """"""
    Mark an alert as read.
    
    Args:
        user_id: The ID of the user
        notification_id: The ID of the notification
        
    Returns:
        True if the alert was marked as read, False otherwise
    """"""
    return mark_notification_as_read(user_id, notification_id)
",codebase-architectures/atomic-composable-architecture/capabilities/alerting.py,,1,1.0467401685178159e-08,"The method 'mark_alert_as_read' is a straightforward utility function that serves a clear purpose: marking a notification as read for a specific user. It is likely to be a part of a larger notification system, and such functionality is commonly required in applications that handle user notifications. The method is simple, with a clear input and output, and it delegates the actual marking process to another function, 'mark_notification_as_read', which suggests good separation of concerns. Therefore, it is likely to be retained as it provides necessary functionality in a clean and understandable manner."
survived,"def send_sms_notification(phone_number: str, message: str) -> bool:
    """"""
    Send an SMS notification (mock implementation).
    
    Args:
        phone_number: The recipient's phone number
        message: The SMS message
        
    Returns:
        True if the SMS was sent successfully (always True in this mock)
    """"""
    # In a real application, this would send an actual SMS
    print(f""[SMS] To: {phone_number}"")
    print(f""[SMS] Message: {message}"")
    return True
",codebase-architectures/atomic-composable-architecture/modules/notifications.py,,1,2.2159489282323004e-08,"The method is a mock implementation of sending an SMS notification, which is a common requirement in many applications for alerting users. Despite being a mock, it provides a clear interface and can be easily replaced with a real implementation when needed. The method is simple, well-documented, and serves a useful purpose in testing or development environments where actual SMS sending is not required. Therefore, it is likely to be retained for its utility in simulating SMS functionality."
survived,"def validate_numeric_range(value: Union[int, float], min_value: Optional[Union[int, float]] = None, 
                          max_value: Optional[Union[int, float]] = None) -> bool:
    """"""
    Validate that a numeric value is within the specified range.
    
    Args:
        value: The numeric value to validate
        min_value: Minimum allowed value, or None for no minimum
        max_value: Maximum allowed value, or None for no maximum
        
    Returns:
        True if the value is within range, False otherwise
    """"""
    if not isinstance(value, (int, float)):
        return False
    
    if min_value is not None and value < min_value:
        return False
    
    if max_value is not None and value > max_value:
        return False
    
    return True
",codebase-architectures/atomic-composable-architecture/modules/validation.py,,1,4.0586521248284276e-10,"The method `validate_numeric_range` is a utility function that checks if a given numeric value falls within a specified range. This is a common requirement in many applications, such as data validation, input checking, and configuration management. The function is well-documented, handles optional parameters for minimum and maximum values, and includes type checking for the input value. These features make it versatile and robust for various use cases. Given its utility and the fact that it is implemented correctly, it is likely to be retained in the codebase."
survived,"    def delete_task(task_id):
        """"""Delete a task.""""""
        success = TaskService.delete_task(task_id)
        if not success:
            return {""error"": f""Task with ID {task_id} not found""}
        return {""message"": f""Task with ID {task_id} deleted successfully""}",codebase-architectures/vertical-slice-architecture/features/tasks/api.py,TaskAPI,1,9.736200303530205e-10,"The method 'delete_task' is a straightforward utility function that interacts with a service to delete a task by its ID. It provides clear feedback on the success or failure of the operation, which is a common requirement in task management systems. The method is likely to be useful in various contexts where task deletion is needed, and it handles errors gracefully by returning an error message if the task is not found. Therefore, it is likely to be retained in the codebase."
survived,"    def create_user(user_data):
        """"""Create a new user.""""""
        validate_required_fields(user_data, [""username"", ""email""])
        
        # Check if username already exists
        all_users = db.get_all(""users"")
        if any(user[""username""] == user_data[""username""] for user in all_users):
            raise ValueError(f""Username '{user_data['username']}' already exists"")
        
        user = User(**user_data)
        db.insert(""users"", user.id, user.to_dict())
        return user.to_dict()
",codebase-architectures/vertical-slice-architecture/features/users/service.py,UserService,1,3.3982678079468468e-09,"The method 'create_user' is a fundamental part of user management in many applications. It includes essential functionality such as validating required fields, checking for duplicate usernames, and inserting new user data into the database. These operations are critical for maintaining data integrity and ensuring a smooth user registration process. Unless there is a significant change in the application's requirements or architecture, such as a shift to a different user management system, this method is likely to be retained."
survived,"def delete_user_alert(user_id: str, notification_id: str) -> bool:
    """"""
    Delete an alert.
    
    Args:
        user_id: The ID of the user
        notification_id: The ID of the notification
        
    Returns:
        True if the alert was deleted, False otherwise
    """"""
    return delete_notification(user_id, notification_id)
",codebase-architectures/atomic-composable-architecture/capabilities/alerting.py,,0,0.9999417087232136,"The method `delete_user_alert` is a simple wrapper around the `delete_notification` function, which suggests that it might be redundant if `delete_notification` is already accessible and provides the same functionality. However, if `delete_user_alert` is part of a larger interface or API that requires a specific method for deleting user alerts, it might be retained for consistency and clarity. Without additional context on how this method fits into the larger codebase, it's difficult to definitively predict its fate. However, given its simplicity and potential redundancy, it is more likely to be deleted unless it serves a specific purpose in the codebase."
survived,"    def _view_file(self, path: str, view_range=None) -> FileOperationResult:
        """"""
        View the contents of a file.

        Args:
            path: The path to the file to view
            view_range: Optional start and end lines to view [start, end]

        Returns:
            FileOperationResult with content or error message
        """"""
        try:
            # Normalize the path
            path = normalize_path(path)

            if not os.path.exists(path):
                error_msg = f""File {path} does not exist""
                console.log(f""[view_file] Error: {error_msg}"")
                return FileOperationResult(False, error_msg)

            with open(path, ""r"") as f:
                lines = f.readlines()

            if view_range:
                start, end = view_range
                # Convert to 0-indexed for Python
                start = max(0, start - 1)
                if end == -1:
                    end = len(lines)
                else:
                    end = min(len(lines), end)
                lines = lines[start:end]

            content = """".join(lines)

            # Display the file content (only for console, not returned to Claude)
            display_file_content(path, content)

            return FileOperationResult(True, f""Successfully viewed file {path}"", content)
        except Exception as e:
            error_msg = f""Error viewing file: {str(e)}""
            console.print(f""[red]{error_msg}[/red]"")
            console.log(f""[view_file] Error: {str(e)}"")
            console.log(traceback.format_exc())
            return FileOperationResult(False, error_msg)
",example-agent-codebase-arch/pipeline-architecture/steps/processing_stage.py,ProcessingStage,1,4.363462233903899e-09,"The method '_view_file' is a utility function that provides a useful feature for viewing the contents of a file, with optional line range selection. It handles errors gracefully, logs messages for debugging, and returns a structured result. Such methods are typically retained in codebases because they encapsulate a common operation (file viewing) with added functionality (range selection) and error handling, making them reusable and valuable."
survived,"def display_token_usage(input_tokens: int, output_tokens: int) -> None:
    """"""
    Display token usage in a table.

    Args:
        input_tokens: Number of input tokens used
        output_tokens: Number of output tokens used
    """"""
    table = Table(title=""Token Usage"")
    table.add_column(""Type"", style=""cyan"")
    table.add_column(""Count"", style=""green"")
    
    table.add_row(""Input Tokens"", str(input_tokens))
    table.add_row(""Output Tokens"", str(output_tokens))
    table.add_row(""Total Tokens"", str(input_tokens + output_tokens))
    
    console.print(table)
",example-agent-codebase-arch/atomic-composable-architecture/main.py,,1,1.8189616842444243e-09,"The method 'display_token_usage' is likely to survive because it provides a clear and useful functionality: displaying token usage in a formatted table. This is a common requirement in applications that deal with token-based systems, such as APIs or language models, where tracking and displaying token usage is important for monitoring and optimization purposes. The method is well-documented, with clear arguments and a straightforward implementation using a table format, which enhances readability and usability."
survived,"    def str_replace(path: str, old_str: str, new_str: str) -> FileOperationResult:
        """"""
        Replace a specific string in a file.

        Args:
            path: The path to the file to modify
            old_str: The text to replace
            new_str: The new text to insert

        Returns:
            FileOperationResult with result or error message
        """"""
        try:
            # Normalize the path
            path = normalize_path(path)

            if not os.path.exists(path):
                error_msg = f""File {path} does not exist""
                console.log(f""[str_replace] Error: {error_msg}"")
                return FileOperationResult(False, error_msg)

            with open(path, ""r"") as f:
                content = f.read()

            if old_str not in content:
                error_msg = f""The specified string was not found in the file {path}""
                console.log(f""[str_replace] Error: {error_msg}"")
                return FileOperationResult(False, error_msg)

            new_content = content.replace(old_str, new_str, 1)

            with open(path, ""w"") as f:
                f.write(new_content)

            console.print(f""[green]Successfully replaced text in {path}[/green]"")
            console.log(f""[str_replace] Successfully replaced text in {path}"")
            return FileOperationResult(True, f""Successfully replaced text in {path}"")
        except Exception as e:
            error_msg = f""Error replacing text: {str(e)}""
            console.print(f""[red]{error_msg}[/red]"")
            console.log(f""[str_replace] Error: {str(e)}"")
            console.log(traceback.format_exc())
            return FileOperationResult(False, error_msg)
",example-agent-codebase-arch/vertical-slice-architecture/features/file_operations/service.py,FileOperationService,1,3.850741907939403e-09,"The method 'str_replace' is a utility function that performs a common task of replacing a string in a file. It includes error handling, logging, and returns a structured result, which makes it robust and useful in various applications. Such utility functions are often retained because they encapsulate a specific functionality that can be reused across different parts of a codebase. Additionally, the method is well-documented and follows good coding practices, which further supports its survival."
survived,"    def __init__(self, command: str, path: str = None, **kwargs):
        """"""
        Initialize a tool use request.
        
        Args:
            command: The command to execute
            path: The path to operate on
            **kwargs: Additional arguments for the command
        """"""
        self.command = command
        self.path = path
        self.kwargs = kwargs
",example-agent-codebase-arch/layered-architecture/models/tool_models.py,ToolUseRequest,1,9.931195248674785e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes, and this method is well-documented and follows standard practices. It is unlikely to be deleted unless the entire class is refactored or removed, which is not indicated here."
survived,"    def view_file(path: str, view_range=None) -> FileOperationResult:
        """"""
        View the contents of a file.

        Args:
            path: The path to the file to view
            view_range: Optional start and end lines to view [start, end]

        Returns:
            FileOperationResult with content or error message
        """"""
        try:
            # Normalize the path
            path = normalize_path(path)

            if not os.path.exists(path):
                error_msg = f""File {path} does not exist""
                Logger.error(app_logger, f""[view_file] {error_msg}"")
                return FileOperationResult(False, error_msg)

            with open(path, ""r"") as f:
                lines = f.readlines()

            if view_range:
                start, end = view_range
                # Convert to 0-indexed for Python
                start = max(0, start - 1)
                if end == -1:
                    end = len(lines)
                else:
                    end = min(len(lines), end)
                lines = lines[start:end]

            content = """".join(lines)

            # Display the file content (only for console, not returned to Claude)
            display_file_content(path, content)

            return FileOperationResult(True, f""Successfully viewed file {path}"", content)
        except Exception as e:
            error_msg = f""Error viewing file: {str(e)}""
            Logger.error(app_logger, f""[view_file] {error_msg}"", exc_info=True)
            return FileOperationResult(False, error_msg)
",example-agent-codebase-arch/layered-architecture/services/file_service.py,FileService,1,8.592166611791576e-10,"The method 'view_file' is well-structured and serves a clear purpose of reading and optionally slicing the content of a file. It includes error handling for file existence and general exceptions, making it robust. The method also logs errors and returns a structured result, which is useful for debugging and consistent API responses. These factors suggest that the method is useful and reliable, increasing its chances of being retained in the codebase."
deleted,"def ensure_directory_exists(path: str) -> None:
    """"""
    Ensure that the directory for a file path exists.
    Creates the directory if it doesn't exist.

    Args:
        path: The path to check
    """"""
    directory = os.path.dirname(path)
    if directory and not os.path.exists(directory):
        os.makedirs(directory)
",example-agent-codebase-arch/atomic-composable-architecture/atom/path_utils.py,,1,9.237449576640118e-09,"The method 'ensure_directory_exists' is a utility function that checks if a directory exists and creates it if it doesn't. This is a common and useful operation in many applications that deal with file I/O, ensuring that the necessary directory structure is in place before attempting to write files. Such utility functions are often reused across different projects and are unlikely to be deleted unless they are replaced by a more efficient or standardized library function. However, the functionality it provides is fundamental and widely needed, making it more likely to survive."
deleted,"def get_file_extension(path: str) -> str:
    """"""
    Get the file extension from a path.

    Args:
        path: The path to get the extension from

    Returns:
        The file extension without the dot
    """"""
    return os.path.splitext(path)[1][1:]
",example-agent-codebase-arch/atomic-composable-architecture/atom/path_utils.py,,1,3.2241866333029355e-08,"The method 'get_file_extension' is a simple utility function that extracts the file extension from a given file path. This is a common requirement in many programming tasks, such as file handling, data processing, and user interface development. The function is straightforward, efficient, and serves a clear purpose. It is unlikely to be deleted as it provides a useful functionality that is often needed in various applications."
survived,"    def __init__(self, command: str, path: str = None, **kwargs):
        """"""
        Initialize a tool use request.
        
        Args:
            command: The command to execute
            path: The path to operate on
            **kwargs: Additional arguments for the command
        """"""
        self.command = command
        self.path = path
        self.kwargs = kwargs
",example-agent-codebase-arch/pipeline-architecture/shared/utilities.py,ToolUseRequest,1,7.73442280641062e-08,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class with specific attributes. It is a fundamental part of object-oriented programming in Python and is unlikely to be deleted unless the entire class is being refactored or removed. The method is well-documented and follows standard practices, making it a necessary component of the class."
survived,"def main():
    """"""Main entry point for the application.""""""
    # Set up argument parser
    parser = argparse.ArgumentParser(description=""Claude 3.7 File Editor Agent"")
    parser.add_argument(
        ""--prompt"",
        ""-p"",
        required=True,
        help=""The prompt for what file operations to perform"",
    )
    parser.add_argument(
        ""--max-loops"",
        ""-l"",
        type=int,
        default=15,
        help=""Maximum number of tool use loops (default: 15)"",
    )
    parser.add_argument(
        ""--thinking"",
        ""-t"",
        type=int,
        default=DEFAULT_THINKING_TOKENS,
        help=f""Maximum thinking tokens (default: {DEFAULT_THINKING_TOKENS})"",
    )
    parser.add_argument(
        ""--efficiency"",
        ""-e"",
        action=""store_true"",
        help=""Enable token-efficient tool use (beta feature)"",
    )
    args = parser.parse_args()

    console.print(Panel.fit(""Claude 3.7 File Editor Agent (Layered Architecture)""))
    console.print(f""\n[bold]Prompt:[/bold] {args.prompt}\n"")
    console.print(f""[dim]Thinking tokens: {args.thinking}[/dim]"")
    console.print(f""[dim]Max loops: {args.max_loops}[/dim]"")
    
    if args.efficiency:
        console.print(f""[dim]Token-efficient tools: Enabled[/dim]\n"")
    else:
        console.print(f""[dim]Token-efficient tools: Disabled[/dim]\n"")

    # For testing purposes, we'll just print a success message
    console.print(""[green]Successfully loaded the Layered Architecture implementation![/green]"")
    console.print(""[yellow]This is a mock implementation for testing the architecture structure.[/yellow]"")
    console.print(""[yellow]In a real implementation, this would connect to the Claude API.[/yellow]"")

    # Display mock token usage
    display_token_usage(1000, 500)
",example-agent-codebase-arch/layered-architecture/main.py,,1,1.3440409770490404e-08,"The method 'main()' is a well-structured entry point for a command-line application. It sets up an argument parser, handles command-line arguments, and provides informative console output. The method is essential for the application's functionality, as it initializes the program's execution flow and user interaction. There is no indication that this method is redundant or unnecessary, and it appears to be a core part of the application's architecture. Therefore, it is likely to be retained in the codebase."
survived,"def normalize_path(path: str) -> str:
    """"""
    Normalize file paths to handle various formats (absolute, relative, Windows paths, etc.)

    Args:
        path: The path to normalize

    Returns:
        The normalized path
    """"""
    if not path:
        return path

    # Handle Windows backslash paths if provided
    path = path.replace(""\\"", os.sep)

    is_windows_path = False
    if os.name == ""nt"" and len(path) > 1 and path[1] == "":"":
        is_windows_path = True

    # Handle /repo/ paths from Claude (tool use convention)
    if path.startswith(""/repo/""):
        path = os.path.join(os.getcwd(), path[6:])
        return path

    if path.startswith(""/""):
        # Handle case when Claude provides paths with leading slash
        if path == ""/"" or path == ""/."":
            # Special case for root directory
            path = os.getcwd()
        else:
            # Replace leading slash with current working directory
            path = os.path.join(os.getcwd(), path[1:])
    elif path.startswith(""./""):
        # Handle relative paths starting with ./
        path = os.path.join(os.getcwd(), path[2:])
    elif not os.path.isabs(path) and not is_windows_path:
        # For non-absolute paths that aren't Windows paths either
        path = os.path.join(os.getcwd(), path)

    return path
",example-agent-codebase-arch/atomic-composable-architecture/atom/path_utils.py,,1,1.4166087846364157e-09,"The method 'normalize_path' is a utility function that provides a useful feature for normalizing file paths across different operating systems and formats. It handles various cases such as Windows paths, relative paths, and special cases like '/repo/' paths. This kind of functionality is often needed in applications that deal with file systems, making it a valuable method to retain. Additionally, the method is well-documented and straightforward, which increases its likelihood of being maintained in the codebase."
survived,"    def to_dict(self) -> Dict[str, Any]:
        """"""
        Convert the result to a dictionary.
        
        Returns:
            Dictionary representation of the result
        """"""
        return {
            ""success"": self.success,
            ""message"": self.message,
            ""data"": self.data
        }
",example-agent-codebase-arch/layered-architecture/models/tool_models.py,FileOperationResult,1,1.1032560311263802e-09,"The method 'to_dict' is a utility function that converts an object's attributes into a dictionary format. This is a common and useful pattern in programming, especially for serialization, logging, or data manipulation purposes. It is likely to be used frequently in applications where objects need to be converted to a format that is easily readable or transferable, such as JSON. Therefore, the method is likely to be retained in the codebase."
survived,"def test_create_folder_structure_handles_spaces_and_dashes_with_slash():
    with tempfile.TemporaryDirectory() as temp_dir:
        os.chdir(temp_dir)
        folder_path, folder_name, class_name = create_folder_structure(""My Cool-Project/"")
        
        assert folder_name == ""my_cool_project""
        assert class_name == ""MyCoolProject""
        assert folder_path.name == ""my_cool_project""
        assert folder_path.exists()
",tests/cli/test_create_crew.py,,1,9.931195248674785e-08,"The method is a test function that verifies the behavior of the `create_folder_structure` function, specifically how it handles folder names with spaces and dashes. Test functions are crucial for ensuring code reliability and correctness, especially when dealing with string manipulations and file system operations. This test checks if the folder name is correctly transformed and if the folder is actually created, which are important aspects of the function's intended behavior. Therefore, it is likely to be retained as part of the test suite to ensure ongoing code quality."
survived,"        def step_1(self):
            self.state.counter = 1
            self.state.message = ""Step 1""
",tests/test_flow_persistence.py,MultiStepFlow,1,1.1861120010657661e-08,"The method 'step_1' is a simple setter method that initializes or resets the state of an object by setting a counter and a message. Such methods are typically useful in managing the state of an object, especially in state machines or processes that involve multiple steps. Since it is likely part of a larger sequence of operations, it is unlikely to be deleted unless the entire process is refactored or removed. Therefore, it is predicted to survive."
survived,"def test_structured_state_persistence(tmp_path):
    """"""Test persistence with Pydantic model state.""""""
    db_path = os.path.join(tmp_path, ""test_flows.db"")
    persistence = SQLiteFlowPersistence(db_path)
    
    class StructuredFlow(Flow[TestState]):
        initial_state = TestState
        
        @start()
        @persist(persistence)
        def count_up(self):
            self.state.counter += 1
            self.state.message = f""Count is {self.state.counter}""
    
    # Run flow and verify state changes are saved
    flow = StructuredFlow(persistence=persistence)
    flow.kickoff()
    
    # Load and verify state
    saved_state = persistence.load_state(flow.state.id)
    assert saved_state is not None
    assert saved_state[""counter""] == 1
    assert saved_state[""message""] == ""Count is 1""
",tests/test_flow_persistence.py,,1,3.466327708641819e-07,"The method 'test_structured_state_persistence' is a test function that verifies the persistence of state in a flow using a Pydantic model and SQLite database. Test functions are crucial for ensuring the reliability and correctness of code, especially when dealing with state management and persistence. This function is likely part of a test suite that ensures the system behaves as expected, which is essential for maintaining software quality. Therefore, it is unlikely to be deleted as it serves an important role in the development and maintenance process."
survived,"    def decorator(method: Callable[..., T]) -> Callable[..., T]:
        """"""Decorator that handles both sync and async methods.""""""
        if asyncio.iscoroutinefunction(method):
            @functools.wraps(method)
            async def async_wrapper(flow_instance: Any, *args: Any, **kwargs: Any) -> T:
                # Execute the original async method
                result = await method(flow_instance, *args, **kwargs)
                # Persist state after method completion
                _persist_state(flow_instance, method.__name__)
                return result
            return cast(Callable[..., T], async_wrapper)
        else:
            @functools.wraps(method)
            def sync_wrapper(flow_instance: Any, *args: Any, **kwargs: Any) -> T:
                # Execute the original sync method
                result = method(flow_instance, *args, **kwargs)
                # Persist state after method completion
                _persist_state(flow_instance, method.__name__)
                return result
            return cast(Callable[..., T], sync_wrapper)
",src/crewai/flow/persistence/decorators.py,,1,1.8189616842444243e-09,"The method is a decorator that provides functionality to handle both synchronous and asynchronous methods, which is a common requirement in modern Python applications. It ensures that the state is persisted after the method execution, which is a useful feature for maintaining consistency and reliability in applications. The use of decorators to abstract such functionality is a well-accepted practice in Python programming. Therefore, the method is likely to be useful and relevant, leading to its survival."
survived,"def test_xai_create_with_completion():
    """"""Test that create_with_completion works with XAI provider""""""
    client = instructor.from_provider(""xai/grok-3-mini"", mode=instructor.Mode.XAI_JSON)
    
    user, raw_response = client.chat.completions.create_with_completion(
        response_model=User,
        messages=[
            {
                ""role"": ""system"",
                ""content"": ""You are a helpful assistant that extracts information."",
            },
            {
                ""role"": ""user"",
                ""content"": ""Extract: Jason is 25 years old."",
            },
        ],
    )
    
    assert isinstance(user, User)
    assert user.name.lower() == ""jason""
    assert user.age == 25
    assert hasattr(user, ""_raw_response""), (
        ""The raw response should be available from XAI""
    )
    assert raw_response is not None
    assert user._raw_response == raw_response
",tests/llm/test_xai/test_raw_response.py,,1,9.237449576640118e-09,"The method 'test_xai_create_with_completion' is a unit test designed to verify the functionality of a specific feature, which is the 'create_with_completion' method of an XAI provider client. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with external APIs or complex logic. This test checks if the method correctly extracts information and returns the expected user object. Since testing is an integral part of software development and maintenance, this method is likely to be retained to ensure the continued functionality of the codebase."
survived,"def mock_knowledge_source():
    """"""Create a mock knowledge source with test content.""""""
    content = """"""
    Important context about AI:
    1. AI systems use machine learning algorithms
    2. Neural networks are a key component
    3. Training data is essential for good performance
    """"""
    return StringKnowledgeSource(content=content)
",tests/utilities/test_knowledge_planning.py,,1,2.2159489282323004e-08,"The method `mock_knowledge_source` is a utility function designed to create a mock object for testing purposes. Such methods are often retained in codebases because they are useful for unit testing and ensuring that other parts of the code can be tested without relying on external dependencies. This method provides a controlled environment to test how the system interacts with a knowledge source, which is a common practice in software development to ensure reliability and correctness. Therefore, it is likely to be retained."
survived,"    def call(
        self,
        messages: Union[str, List[Dict[str, str]]],
        tools: Optional[List[dict]] = None,
        callbacks: Optional[List[Any]] = None,
        available_functions: Optional[Dict[str, Any]] = None,
    ) -> Union[str, Any]:
        self.calls.append({
            ""messages"": messages, 
            ""tools"": tools,
            ""callbacks"": callbacks,
            ""available_functions"": available_functions
        })
        # In a real implementation, this would use the JWT token to authenticate
        # with an external service
        return ""Response from JWT-authenticated LLM""
",tests/custom_llm_test.py,JWTAuthLLM,1,4.944450477491054e-09,"The method 'call' is likely to survive because it appears to be a core part of a class that interacts with an external service using JWT authentication. The method is designed to handle various inputs such as messages, tools, callbacks, and available functions, which suggests it is flexible and can be used in multiple scenarios. Additionally, the method appends the call details to a list, which could be useful for logging or debugging purposes. These characteristics indicate that the method is functional and serves a purpose in the system, making it unlikely to be deleted."
survived,"    def get_context_window_size(self) -> int:
        """"""Return a default context window size.""""""
        return 8192
",tests/custom_llm_test.py,CustomLLM,1,2.5109990926928157e-08,"The method `get_context_window_size` is a simple utility function that returns a constant value, which is the default context window size. Such methods are often used in codebases to centralize configuration values or constants, making it easier to manage and update them in the future. This method is likely to survive because it provides a clear and centralized way to access a specific configuration value, which can be useful for maintaining consistency across the codebase. Unless there is a significant change in how context window sizes are managed or if this value becomes obsolete, the method is likely to remain useful."
