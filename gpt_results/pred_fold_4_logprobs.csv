status,method,filepath,class_name,predict,prob_deleted,reason
survived,"def test_multiple_keyword_only_removed():
    old_code = ""def func(*, a, b, c): pass""
    new_code = ""def func(*, b): pass""

    old_tree = ast.parse(old_code)
    new_tree = ast.parse(new_code)
    errors = check_signature_compatibility(old_tree.body[0], new_tree.body[0])

    assert len(errors) == 2
    error_messages = {e.message for e in errors}
    assert ""Keyword-only param 'a' was removed."" in error_messages
    assert ""Keyword-only param 'c' was removed."" in error_messages
",tests/dev/test_check_function_signatures.py,,1,3.850741907939403e-09,"The method `test_multiple_keyword_only_removed` is a unit test designed to verify that the function `check_signature_compatibility` correctly identifies when keyword-only parameters are removed from a function signature. This is a valid and useful test case for ensuring backward compatibility checks in code refactoring or API changes. Since it serves a clear purpose in testing the functionality of another method, it is likely to be retained in the codebase."
survived,"def test_optional_positional_became_required():
    old_code = ""def func(a, b=1): pass""
    new_code = ""def func(a, b): pass""

    old_tree = ast.parse(old_code)
    new_tree = ast.parse(new_code)
    errors = check_signature_compatibility(old_tree.body[0], new_tree.body[0])

    assert len(errors) == 1
    assert errors[0].message == ""Optional positional param 'b' became required.""
    assert errors[0].param_name == ""b""
",tests/dev/test_check_function_signatures.py,,1,1.0261879630648829e-10,"The method is a test function that checks for a specific change in function signatures, which is a common requirement in software development to ensure backward compatibility. It is likely to be useful for maintaining code quality and preventing breaking changes, thus it will survive."
survived,"def get_value():
    global raw_tensor_data, precomputed_c_values, current_fullscreen_op
    print(current_fullscreen_op)
    data = request.json
    uuid = data.get(""uuid"")
    matrix_name = data.get(""matrixName"")
    row = data.get(""row"")
    col = data.get(""col"")

    if uuid not in raw_tensor_data:
        return jsonify({""error"": ""Operation not found""}), 404

    op_data = raw_tensor_data[uuid]

    if matrix_name == ""A"":
        value = (
            op_data[""input_data""][row, col].item() if ""input_data"" in op_data else None
        )
        return jsonify({""value"": value})
    elif matrix_name == ""B"":
        value = (
            op_data[""other_data""][row, col].item() if ""other_data"" in op_data else None
        )
        return jsonify({""value"": value})
    elif matrix_name == ""C"":
        current_step = data.get(""currentStep"", 0)

        if uuid not in precomputed_c_values:
            return jsonify({""error"": ""Precomputed values not found""}), 404

        precomputed = precomputed_c_values[uuid]
        current_value = precomputed[(row, col)][current_step]

        return jsonify(
            {
                ""value"": current_value,
            }
        )
    else:
        return jsonify({""error"": ""Invalid matrix name""}), 400
",triton_viz/visualizer/interface.py,,1,1.2501528648238603e-09,"The method 'get_value' is a utility function that retrieves specific values from a data structure based on input parameters. It handles different cases for matrix names ('A', 'B', 'C') and provides error handling for missing data or invalid inputs. This functionality is essential for applications that require dynamic data retrieval and error management, making it a useful and likely necessary part of the codebase. Therefore, it is unlikely to be deleted."
survived,"def update_data():
    update_global_data()
    return jsonify({""status"": ""Data updated successfully""})
",triton_viz/visualizer/interface.py,,1,6.348800075736417e-09,"The method 'update_data' is a simple function that calls another function 'update_global_data' and then returns a JSON response indicating success. The function is straightforward and likely serves a specific purpose in the application, such as updating some global data and confirming the update to the client. There is no indication of redundancy, inefficiency, or lack of use from the provided code snippet. Therefore, it is likely to be retained in the codebase."
survived,"    def test_comparison_with_numpy(self, func):
        """"""Compare with numpy's implementation for data without NaNs.""""""
        np.random.seed(42)
        data = np.random.randn(5, 100)

        result = func(data)
        if func == nancorrmatrix:
            expected = np.corrcoef(data)
        else:
            expected = np.cov(data)

        assert_allclose(result, expected, rtol=1e-10)
",numbagg/test/test_matrix_functions.py,TestMatrixFunctions,1,1.8189616842444243e-09,"The method 'test_comparison_with_numpy' is a unit test function that compares the output of a given function 'func' with the expected output from numpy's implementation. It is a useful test to ensure that the custom function behaves as expected when compared to a well-established library like numpy. Such tests are crucial for maintaining code reliability and correctness, especially when dealing with mathematical computations. Therefore, it is likely to be retained in the codebase."
survived,"    def test_exponential_decay_property(self):
        """"""Test that older observations have less influence (exponential decay).""""""
        # Create a dataset where values change over time
        np.random.seed(42)  # For reproducibility
        early_data = np.random.randn(2, 20)
        late_data = np.random.randn(2, 20) + 10  # Different mean
        data = np.concatenate([early_data, late_data], axis=1)

        # With high alpha, recent values should dominate more than low alpha
        result_high = move_exp_nancovmatrix(data, alpha=0.9)
        result_low = move_exp_nancovmatrix(data, alpha=0.1)

        # The final covariance matrices should be different
        # (high alpha should weight recent data more)
        final_cov_high = result_high[-1]
        final_cov_low = result_low[-1]

        # Results should be different due to different weighting
        assert not np.allclose(final_cov_high, final_cov_low, rtol=1e-3)
",numbagg/test/test_move_exp_matrix.py,TestMoveExpMatrixFunctions,1,3.2241866333029355e-08,"The method is a unit test for a specific property of an exponential decay function, which is a common requirement in data analysis and signal processing. It is well-structured, uses reproducible random data, and checks for expected behavior of the function under test. Such tests are crucial for ensuring the correctness of the implementation, especially when dealing with statistical computations. Therefore, it is likely to be retained as part of the test suite."
survived,"    def _determine_category(self, path: Path) -> str:
        """"""Determine model category""""""
        path_str = str(path).lower()
        
        categories = {
            'llm': ['llm', 'language', 'text', 'chat'],
            'vision': ['vision', 'image', 'visual', 'cv'],
            'audio': ['audio', 'speech', 'voice', 'sound'],
            'multimodal': ['multimodal', 'multi-modal'],
            'embedding': ['embedding', 'embed', 'vector']
        }
        
        for category, keywords in categories.items():
            if any(keyword in path_str for keyword in keywords):
                return category
        
        return 'general'
",src/haconiwa/scan/analyzer.py,ModelAnalyzer,1,1.8189616842444243e-09,"The method '_determine_category' is a utility function that categorizes a given path based on predefined keywords. This is a common requirement in many applications where categorization is needed for processing or organizing data. The method is well-structured, uses a dictionary for easy extension of categories, and provides a default return value ('general') if no keywords match. These characteristics make it a useful and reusable piece of code, suggesting it is likely to be retained in the codebase."
survived,"    def _compare_performance(self, model_data: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
        """"""Compare model performance metrics""""""
        performance = {}
        
        for model, data in model_data.items():
            model_perf = {
                'inference_speed': 'Unknown',
                'memory_usage': 'Unknown',
                'accuracy': 'Unknown',
                'benchmark_scores': {}
            }
            
            # Try to find performance data in config or metadata
            if data.get('config'):
                config = data['config']
                
                # Look for benchmark scores
                benchmark_keys = ['benchmark', 'evaluation', 'scores', 'metrics']
                for key in benchmark_keys:
                    if key in config:
                        model_perf['benchmark_scores'] = config[key]
                        break
            
            # Estimate based on model size
            if data.get('size', 0) > 0:
                size_gb = data['size'] / (1024 ** 3)
                if size_gb < 1:
                    model_perf['inference_speed'] = 'Fast'
                elif size_gb < 10:
                    model_perf['inference_speed'] = 'Medium'
                else:
                    model_perf['inference_speed'] = 'Slow'
            
            performance[model] = model_perf
        
        return performance
",src/haconiwa/scan/comparator.py,ModelComparator,1,2.0611536181902033e-09,"The method '_compare_performance' is a utility function that processes a dictionary of model data to extract and estimate performance metrics such as inference speed, memory usage, and benchmark scores. It is a useful function for comparing different models based on their configurations and sizes. The method is well-structured, with clear logic for estimating inference speed based on model size and extracting benchmark scores from configuration data. Such functionality is often needed in machine learning and data science applications to evaluate and compare model performance. Therefore, it is likely to be retained in the codebase."
survived,"    def test_search_by_model_name(self, temp_model_dir):
        """"""Test searching for models by name""""""
        scanner = ModelScanner(temp_model_dir)
        
        # Test with exact name
        results = scanner.search_by_model_name(""gpt-4"")
        assert results['model_name'] == ""gpt-4""
        assert results['total_files'] > 0
        assert len(results['categories']) > 0
        
        # Test with prefix stripping
        results = scanner.search_by_model_name(""claude-3-opus"")
        assert results['normalized_name'] == ""3-opus""  # ""claude-"" prefix stripped
        assert results['total_files'] > 0
",tests/test_scan/test_scanner.py,TestModelScanner,1,1.522997951276035e-08,"The method 'test_search_by_model_name' is a unit test designed to verify the functionality of the 'search_by_model_name' method in the 'ModelScanner' class. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with search functionalities that may have complex logic, such as handling prefixes or exact matches. The presence of assertions checking for expected outcomes indicates that this test is actively used to validate the behavior of the code. Therefore, it is likely to be maintained as part of the test suite to ensure ongoing code quality."
survived,"    def _compare_use_cases(self, model_data: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
        """"""Compare model use cases""""""
        use_cases = {}
        
        use_case_patterns = {
            'chatbot': ['chat', 'conversation', 'dialogue'],
            'content_generation': ['generate', 'create', 'write'],
            'code_assistance': ['code', 'programming', 'development'],
            'translation': ['translate', 'multilingual'],
            'analysis': ['analyze', 'analysis', 'insight'],
            'summarization': ['summary', 'summarize'],
            'question_answering': ['qa', 'question', 'answer'],
            'research': ['research', 'academic', 'scientific']
        }
        
        for model, data in model_data.items():
            model_use_cases = set()
            
            # Check all text content for use case patterns
            all_text = []
            if data.get('config'):
                all_text.append(json.dumps(data['config']))
            
            for file_info in data.get('files', []):
                all_text.append(file_info['path'])
            
            combined_text = ' '.join(all_text).lower()
            
            for use_case, patterns in use_case_patterns.items():
                if any(pattern in combined_text for pattern in patterns):
                    model_use_cases.add(use_case)
            
            use_cases[model] = list(model_use_cases)
        
        return use_cases
",src/haconiwa/scan/comparator.py,ModelComparator,1,1.6918979223288786e-10,"The method '_compare_use_cases' is a utility function that analyzes model data to determine applicable use cases based on predefined patterns. It is a useful function for categorizing models, which can be beneficial in various applications such as model management, recommendation systems, or analytics. The method is well-structured, uses clear logic to match patterns, and returns a dictionary that maps models to their identified use cases. Given its utility and the fact that it doesn't have any apparent issues or redundancies, it is likely to be retained in the codebase."
survived,"    def __init__(self, base_path: Path):
        self.base_path = Path(base_path)
        
        # Guide templates
        self.templates = {
            'development': self._generate_development_guide,
            'usage': self._generate_usage_guide,
            'integration': self._generate_integration_guide,
            'quickstart': self._generate_quickstart_guide
        }
",src/haconiwa/scan/guide_generator.py,GuideGenerator,1,2.8453347280241004e-08,"The method is a constructor (__init__) for a class, which is essential for initializing class instances. It sets up the base_path attribute and initializes a dictionary of templates, which are likely used for generating different types of guides. This setup is crucial for the functionality of the class, as it prepares the object with necessary attributes and methods for further operations. Therefore, it is unlikely to be deleted."
survived,"    def __init__(self, base_path: Path):
        self.base_path = Path(base_path)
        
        # Common model configuration files
        self.config_files = [
            'config.json', 'model_config.json', 'configuration.json',
            'config.yaml', 'config.yml', 'metadata.json',
            'model_card.md', 'README.md'
        ]
        
        # Model file extensions
        self.model_extensions = {
            '.pt': 'PyTorch',
            '.pth': 'PyTorch',
            '.onnx': 'ONNX',
            '.pb': 'TensorFlow',
            '.h5': 'Keras/TensorFlow',
            '.tflite': 'TensorFlow Lite',
            '.mlmodel': 'Core ML',
            '.bin': 'Binary',
            '.safetensors': 'SafeTensors',
            '.gguf': 'GGUF (llama.cpp)',
            '.ggml': 'GGML'
        }
",src/haconiwa/scan/analyzer.py,ModelAnalyzer,1,6.023574641292144e-08,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class with specific attributes. It sets up the base path and defines lists and dictionaries for configuration files and model file extensions, which are likely used throughout the class. This setup is crucial for the functionality of the class, especially if it deals with model management or configuration handling. Therefore, it is unlikely to be deleted as it provides necessary initialization for the class."
survived,"    def test_generate_from_scan_results_with_matches(self):
        """"""Test generation from scan results with matches""""""
        scan_results = {
            'model_name': 'gpt-4',
            'matches': {
                'model': [
                    {'path': 'models/gpt4/model.py', 'type': 'python'},
                    {'path': 'models/gpt4/config.py', 'type': 'python'}
                ],
                'api': [
                    {'path': 'api/gpt4_api.py', 'type': 'python'}
                ]
            }
        }
        
        config = self.generator.generate_from_scan_results(
            scan_results,
            action='add_tests',
            max_files=2
        )
        
        assert config['provider'] == 'claude'
        assert len(config['tasks']) == 2
        assert config['metadata']['action'] == 'add_tests'
        assert config['options']['max_concurrent'] == 1  # min(5, max(1, 2//2))
        
        # Check that appropriate prompts were generated
        for task in config['tasks']:
            assert 'file' in task
            assert 'prompt' in task
            assert len(task['prompt']) > 0
",tests/test_scan/test_generate_parallel.py,TestParallelYAMLGenerator,1,6.348800075736417e-09,"The method `test_generate_from_scan_results_with_matches` is a unit test that verifies the functionality of generating a configuration from scan results with matches. It checks various aspects of the generated configuration, such as the provider, the number of tasks, metadata, and options. This is a typical test case that ensures the correctness of the `generate_from_scan_results` method in the `generator` object. Since it is a test method, it is crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is likely to be retained in the codebase."
survived,"    def save_yaml(self, config: Dict[str, Any], output_path: Path) -> Path:
        """"""Save configuration to YAML file""""""
        
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            yaml.dump(config, f, default_flow_style=False, sort_keys=False, allow_unicode=True)
        
        return output_path
",src/haconiwa/scan/generate_parallel.py,ParallelYAMLGenerator,1,2.7894680920908113e-10,"The method 'save_yaml' is a utility function that saves a given configuration dictionary to a YAML file at a specified path. This is a common and useful operation in many applications, especially those involving configuration management or data serialization. The method is well-implemented, handling directory creation and file writing with appropriate options for YAML formatting. There are no apparent issues or redundancies in the code, and it serves a clear purpose. Therefore, it is likely to be retained in the codebase."
survived,"    def _get_context(self, lines: List[str], index: int, context_lines: int) -> List[str]:
        """"""Get context lines around a match""""""
        start = max(0, index - context_lines)
        end = min(len(lines), index + context_lines + 1)
        return lines[start:end]
",src/haconiwa/scan/scanner.py,ModelScanner,1,5.905303995456778e-10,"The method '_get_context' is a utility function that extracts a specified number of lines around a given index from a list of strings. This functionality is generally useful in various applications such as text processing, debugging, or displaying context around search results. The method is well-defined, concise, and serves a clear purpose, making it likely to be retained in the codebase."
survived,"def list_models(
    path: Optional[Path] = typer.Option(None, ""--path"", ""-p"", help=""Base path to search in""),
    category: Optional[str] = typer.Option(None, ""--category"", help=""Filter by category""),
    provider: Optional[str] = typer.Option(None, ""--provider"", help=""Filter by provider""),
    output_format: str = typer.Option(""table"", ""--format"", ""-f"", help=""Output format"")
):
    """"""List all available AI models""""""
    scanner = ModelScanner(base_path=path or Path.cwd())
    
    models = scanner.list_all_models(
        category=category,
        provider=provider
    )
    
    formatter = OutputFormatter()
    output = formatter.format_model_list(models, output_format)
    typer.echo(output)
",src/haconiwa/scan/cli.py,,1,1.6918979223288786e-10,"The method 'list_models' is likely to survive because it provides a useful functionality for listing AI models with various filtering options. It uses a command-line interface (CLI) tool, Typer, which is popular for building user-friendly command-line applications. The method is well-structured, offering flexibility in specifying the path, category, provider, and output format, which enhances its usability. Additionally, it leverages a 'ModelScanner' and 'OutputFormatter', suggesting a modular design that can be easily maintained or extended. These factors contribute to its potential longevity in the codebase."
survived,"    def test_scan_analyze_with_category(self, runner, temp_model_dir):
        """"""Test analyze with specific category""""""
        result = runner.invoke(
            scan_app,
            [""analyze"", ""--path"", str(temp_model_dir), ""--category"", ""general"", ""--format"", ""json""]
        )
        
        assert result.exit_code == 0
        output = json.loads(result.stdout)
        assert output['category'] == 'general'
",tests/test_scan/test_cli.py,TestScanCLI,1,2.5109990926928157e-08,"The method 'test_scan_analyze_with_category' is a unit test that verifies the functionality of a command-line application. It checks if the application correctly analyzes a given path with a specified category and outputs the result in JSON format. This is a typical and necessary test to ensure the application behaves as expected, especially when dealing with command-line interfaces and specific options. Such tests are crucial for maintaining software quality and are unlikely to be deleted unless the functionality they test is removed or significantly altered."
survived,"    def test_scan_analyze_command(self, runner, temp_model_dir):
        """"""Test the scan analyze command""""""
        result = runner.invoke(
            scan_app,
            [""analyze"", ""--path"", str(temp_model_dir), ""--format"", ""summary""]
        )
        
        assert result.exit_code == 0
        assert ""Model Analysis Summary"" in result.stdout
",tests/test_scan/test_cli.py,TestScanCLI,1,1.2501528648238603e-09,"The method 'test_scan_analyze_command' is a unit test for a command-line interface function. Unit tests are crucial for ensuring code reliability and are typically maintained as part of the codebase to ensure ongoing functionality. The method is well-defined, with clear assertions checking the exit code and output, indicating it is a useful test case. Therefore, it is likely to be retained."
survived,"    def _categorize_size(self, size_gb: float) -> str:
        """"""Categorize model size""""""
        if size_gb < 0.1:
            return 'Tiny'
        elif size_gb < 1:
            return 'Small'
        elif size_gb < 10:
            return 'Medium'
        elif size_gb < 50:
            return 'Large'
        else:
            return 'Very Large'
",src/haconiwa/scan/comparator.py,ModelComparator,1,1.4166087846364157e-09,"The method '_categorize_size' is a utility function that categorizes a given size in gigabytes into predefined categories. This is a common requirement in many applications where size categorization is needed for decision-making or display purposes. The method is simple, clear, and serves a specific purpose, making it likely to be useful in various contexts. Therefore, it is likely to be retained in the codebase."
survived,"    def _extract_provider(self, path: Path) -> str:
        """"""Extract provider from path or config""""""
        providers = {
            'openai': ['openai', 'gpt'],
            'anthropic': ['anthropic', 'claude'],
            'meta': ['meta', 'llama'],
            'google': ['google', 'gemini', 'palm'],
            'mistral': ['mistral'],
            'huggingface': ['huggingface', 'hf']
        }
        
        path_str = str(path).lower()
        
        for provider, keywords in providers.items():
            if any(keyword in path_str for keyword in keywords):
                return provider
        
        return 'unknown'
",src/haconiwa/scan/analyzer.py,ModelAnalyzer,1,1.3176514268359263e-10,"The method `_extract_provider` is likely to survive because it serves a clear and useful purpose: extracting a provider name from a given path based on predefined keywords. This functionality is essential for categorizing or routing tasks based on the provider, which is a common requirement in systems dealing with multiple service providers. The method is straightforward, efficient, and does not have any apparent issues that would necessitate its removal."
survived,"    def test_scan_generate_parallel_config_example(self, runner):
        """"""Test generate-parallel-config with example option""""""
        with tempfile.TemporaryDirectory() as tmpdir:
            output_path = Path(tmpdir) / ""test-parallel.yaml""
            
            result = runner.invoke(
                scan_app,
                [""generate-parallel-config"", ""--example"", ""--output"", str(output_path)]
            )
            
            assert result.exit_code == 0
            assert ""Generated example parallel-dev.yaml"" in result.stdout
            assert output_path.exists()
            
            # Check generated YAML content
            import yaml
            with open(output_path, 'r') as f:
                config = yaml.safe_load(f)
            
            assert config['provider'] == 'claude'
            assert len(config['tasks']) == 5
            assert config['options']['max_concurrent'] == 3
",tests/test_scan/test_cli.py,TestScanCLI,1,1.522997951276035e-08,"The method is a test case for a specific functionality of a command-line application, which is a common practice in software development to ensure code reliability and correctness. It is well-structured, uses temporary directories to avoid side effects, and checks the output thoroughly. Such test methods are crucial for maintaining code quality and are unlikely to be deleted unless the functionality they test is removed or significantly changed."
survived,"    def test_broadcasting_higher_dims(self, func):
        """"""Test that gufunc broadcasting works correctly for higher dimensional arrays.""""""
        np.random.seed(42)

        # 3D array: (2, 4, 10) -> broadcast dims (2,) + core dims (4, 10)
        data_3d = np.random.randn(2, 4, 10)
        result_3d = func(data_3d)
        assert result_3d.shape == (2, 4, 4)

        # 4D array: (2, 3, 4, 10) -> broadcast dims (2, 3) + core dims (4, 10)
        data_4d = np.random.randn(2, 3, 4, 10)
        result_4d = func(data_4d)
        assert result_4d.shape == (2, 3, 4, 4)

        # Check each broadcast element is valid
        for i in range(2):
            for j in range(3):
                matrix = result_4d[i, j]
                # Check symmetry
                assert_allclose(matrix, matrix.T, rtol=1e-10)

                if func == nancorrmatrix:
                    # Check diagonal is 1
                    assert_allclose(np.diag(matrix), np.ones(4), rtol=1e-10)
                    # Check bounds
                    assert np.all((matrix >= -1) & (matrix <= 1))
                else:
                    # Check diagonal (variance) is non-negative
                    assert np.all(np.diag(matrix) >= 0)

        # Verify correctness - each slice should match individual computation
        for i in range(2):
            single_result = func(data_3d[i])
            assert_allclose(result_3d[i], single_result, rtol=1e-10)
",numbagg/test/test_matrix_functions.py,TestCorrelationCovarianceMatrices,1,3.0590235908148916e-07,"The method is a well-structured test function that verifies the behavior of a function (likely a generalized ufunc) when applied to higher-dimensional arrays. It includes checks for expected output shapes, symmetry, and specific properties depending on the function being tested. Such test functions are crucial for ensuring the correctness of numerical computations, especially in scientific computing libraries like NumPy. Given its importance in validating functionality, it is unlikely to be deleted."
survived,"    def test_command_sanitizer_windows_patterns(self):
        """"""Test Windows dangerous command detection.""""""
        with patch(""platform.system"", return_value=""Windows""):
            sanitizer = CommandSanitizer()

            # Test Windows-specific dangerous commands
            dangerous_commands = [
                ""format C:"",
                ""del /S C:\\Windows"",
                ""rd /S C:\\Users"",
                ""reg delete HKLM\\Software"",
                ""taskkill /F /T"",
                ""Remove-Item -Recurse C:\\Windows"",
                ""Stop-Computer -Force"",
            ]

            for cmd in dangerous_commands:
                is_safe, _, reason = sanitizer.sanitize_command(cmd)
                assert not is_safe, f""Command '{cmd}' should be blocked on Windows""
                assert reason, f""Should provide reason for blocking '{cmd}'""
",tests/unit/test_windows_compatibility.py,TestWindowsCompatibility,1,6.348800075736417e-09,"The method 'test_command_sanitizer_windows_patterns' is a unit test designed to verify the functionality of a command sanitizer for Windows-specific dangerous commands. It is crucial for ensuring that the sanitizer correctly identifies and blocks potentially harmful commands that could compromise system integrity. Given the importance of security in software applications, especially when dealing with command execution, this test method is likely to be retained to maintain the robustness and reliability of the command sanitizer."
survived,"def mcp_json_command(
    server_spec: str,
    *,
    server_name: Annotated[
        str | None,
        cyclopts.Parameter(
            name=[""--name"", ""-n""],
            help=""Custom name for the server in MCP config"",
        ),
    ] = None,
    with_editable: Annotated[
        Path | None,
        cyclopts.Parameter(
            name=[""--with-editable"", ""-e""],
            help=""Directory with pyproject.toml to install in editable mode"",
        ),
    ] = None,
    with_packages: Annotated[
        list[str],
        cyclopts.Parameter(
            ""--with"",
            help=""Additional packages to install"",
            negative=False,
        ),
    ] = [],
    env_vars: Annotated[
        list[str],
        cyclopts.Parameter(
            ""--env"",
            help=""Environment variables in KEY=VALUE format"",
            negative=False,
        ),
    ] = [],
    env_file: Annotated[
        Path | None,
        cyclopts.Parameter(
            ""--env-file"",
            help=""Load environment variables from .env file"",
        ),
    ] = None,
    copy: Annotated[
        bool,
        cyclopts.Parameter(
            ""--copy"",
            help=""Copy configuration to clipboard instead of printing to stdout"",
            negative=False,
        ),
    ] = False,
) -> None:
    """"""Generate MCP configuration JSON for manual installation.

    Args:
        server_spec: Python file to install, optionally with :object suffix
    """"""
    file, server_object, name, packages, env_dict = process_common_args(
        server_spec, server_name, with_packages, env_vars, env_file
    )

    success = install_mcp_json(
        file=file,
        server_object=server_object,
        name=name,
        with_editable=with_editable,
        with_packages=packages,
        env_vars=env_dict,
        copy=copy,
    )

    if not success:
        sys.exit(1)",src/fastmcp/cli/install/mcp_json.py,,1,4.363462233903899e-09,"The method 'mcp_json_command' is a utility function designed to generate a configuration JSON for manual installation of a server. It is well-structured, uses type annotations, and provides a clear interface for command-line options using the 'cyclopts.Parameter'. The function is likely part of a larger system for managing server configurations, and its functionality is relevant and useful for users needing to automate or script server setups. There is no indication that this method is obsolete or redundant, and it appears to be a well-implemented feature that aligns with modern Python practices."
survived,"def run_with_uv(
    server_spec: str,
    python_version: str | None = None,
    with_packages: list[str] | None = None,
    with_requirements: Path | None = None,
    project: Path | None = None,
    transport: TransportType | None = None,
    host: str | None = None,
    port: int | None = None,
    path: str | None = None,
    log_level: LogLevelType | None = None,
    show_banner: bool = True,
) -> None:
    """"""Run a MCP server using uv run subprocess.

    Args:
        server_spec: Python file, object specification (file:obj), or URL
        python_version: Python version to use (e.g. ""3.10"")
        with_packages: Additional packages to install
        with_requirements: Requirements file to use
        project: Run the command within the given project directory
        transport: Transport protocol to use
        host: Host to bind to when using http transport
        port: Port to bind to when using http transport
        path: Path to bind to when using http transport
        log_level: Log level
        show_banner: Whether to show the server banner
    """"""
    cmd = [""uv"", ""run""]

    # Add Python version if specified
    if python_version:
        cmd.extend([""--python"", python_version])

    # Add project if specified
    if project:
        cmd.extend([""--project"", str(project)])

    # Add fastmcp package
    cmd.extend([""--with"", ""fastmcp""])

    # Add additional packages
    if with_packages:
        for pkg in with_packages:
            if pkg:
                cmd.extend([""--with"", pkg])

    # Add requirements file
    if with_requirements:
        cmd.extend([""--with-requirements"", str(with_requirements)])

    # Add fastmcp run command
    cmd.extend([""fastmcp"", ""run"", server_spec])

    # Add transport options
    if transport:
        cmd.extend([""--transport"", transport])
    if host:
        cmd.extend([""--host"", host])
    if port:
        cmd.extend([""--port"", str(port)])
    if path:
        cmd.extend([""--path"", path])
    if log_level:
        cmd.extend([""--log-level"", log_level])
    if not show_banner:
        cmd.append(""--no-banner"")

    # Run the command
    logger.debug(f""Running command: {' '.join(cmd)}"")
    try:
        process = subprocess.run(cmd, check=True)
        sys.exit(process.returncode)
    except subprocess.CalledProcessError as e:
        logger.error(f""Failed to run server: {e}"")
        sys.exit(e.returncode)
",src/fastmcp/cli/run.py,,1,9.237449576640118e-09,"The method 'run_with_uv' is a utility function designed to run a server using a subprocess call with various customizable options. It is well-documented, flexible, and uses standard practices for subprocess management in Python. The method is likely to be useful in scenarios where a server needs to be started with specific configurations, making it a valuable part of a codebase that deals with server management. There is no indication of it being deprecated or replaced by another method, and it appears to be functioning as intended without any major issues. Therefore, it is likely to survive."
survived,"    def test_run_with_uv_basic(self, mock_run):
        """"""Test basic run_with_uv execution.""""""
        mock_run.return_value = Mock(returncode=0)

        with pytest.raises(SystemExit) as exc_info:
            run_with_uv(""server.py"")

        assert exc_info.value.code == 0

        # Check the command that was called
        mock_run.assert_called_once()
        cmd = mock_run.call_args[0][0]

        expected = [""uv"", ""run"", ""--with"", ""fastmcp"", ""fastmcp"", ""run"", ""server.py""]
        assert cmd == expected
",tests/cli/test_run_with_uv.py,TestRunWithUv,1,5.211412485172657e-10,"The method `test_run_with_uv_basic` is a unit test designed to verify the behavior of the `run_with_uv` function. It uses mocking to simulate the function's execution and checks if the correct command is called. This is a typical and necessary part of software testing to ensure code reliability and correctness. There is no indication that this test is obsolete or unnecessary, so it is likely to be retained."
survived,"    def test_run_with_uv_logging(self, mock_run, mock_logger):
        """"""Test that run_with_uv logs the command.""""""
        mock_run.return_value = Mock(returncode=0)

        with pytest.raises(SystemExit):
            run_with_uv(""server.py"", python_version=""3.11"")

        # Check that debug logging was called with the command
        mock_logger.debug.assert_called()
        call_args = mock_logger.debug.call_args[0][0]
        assert ""Running command:"" in call_args
        assert ""uv run --python 3.11"" in call_args",tests/cli/test_run_with_uv.py,TestRunWithUv,1,1.725782769012759e-08,"The method is a unit test for a function `run_with_uv`, which is likely part of a test suite. Unit tests are generally not deleted unless they are redundant, testing deprecated functionality, or replaced by more comprehensive tests. This test checks that a specific logging behavior occurs, which is a valid and useful test case to ensure that logging is functioning as expected. Therefore, it is likely to be retained."
survived,"    def add_node_to_tree(rich_tree, cluster_node, level=0):
        """"""Recursively add nodes to Rich tree with formatting.""""""
        # Color scheme based on level
        colors = [""bright_green"", ""bright_yellow"", ""bright_magenta"", ""bright_blue"", ""bright_red""]
        color = colors[level % len(colors)]
        
        # Calculate percentage
        percentage = (cluster_node.count / total_conversations * 100) if total_conversations > 0 else 0
        
        # Create progress bar representation
        bar_width = 15
        filled_width = int((cluster_node.count / total_conversations) * bar_width) if total_conversations > 0 else 0
        progress_bar = ""█"" * filled_width + ""░"" * (bar_width - filled_width)
        
        # Create node label with rich formatting
        label = f""[bold {color}]{cluster_node.name}[/] [dim]({cluster_node.count:,} conversations, {percentage:.1f}%)[/]""
        if hasattr(cluster_node, 'description') and cluster_node.description:
            short_desc = cluster_node.description[:80] + ""..."" if len(cluster_node.description) > 80 else cluster_node.description
            label += f""\n[italic dim]{short_desc}[/]""
        label += f""\n[dim]Progress: [{progress_bar}][/]""
        
        node = rich_tree.add(label)
        
        # Add children
        for child_id in cluster_node.children:
            child = node_id_to_cluster[child_id]
            add_node_to_tree(node, child, level + 1)
",kura/v1/visualization.py,,1,4.363462233903899e-09,"The method 'add_node_to_tree' is a recursive function that adds nodes to a tree structure with rich formatting. It includes features like color coding based on level, percentage calculation, and progress bar representation. These features are useful for visualizing hierarchical data structures in a user-friendly manner. The method is well-structured, with clear logic and formatting, making it a valuable utility for applications that require tree visualization. Therefore, it is likely to be retained."
survived,"async def generate_base_clusters_from_conversation_summaries(
    summaries: List[ConversationSummary],
    *,
    model: BaseClusterModel,
    checkpoint_manager: Optional[CheckpointManager] = None
) -> List[Cluster]:
    """"""Generate base clusters from conversation summaries.
    
    This function groups similar summaries into initial clusters using
    the provided clustering model. Supports different clustering algorithms
    through the model interface.
    
    Args:
        summaries: List of conversation summaries to cluster
        model: Model to use for clustering (HDBSCAN, KMeans, etc.)
        checkpoint_manager: Optional checkpoint manager for caching
        
    Returns:
        List of base clusters
        
    Example:
        >>> cluster_model = ClusterModel(algorithm=""hdbscan"")
        >>> clusters = await generate_base_clusters(
        ...     summaries=conversation_summaries,
        ...     model=cluster_model,
        ...     checkpoint_manager=checkpoint_mgr
        ... )
    """"""
    logger.info(f""Starting clustering of {len(summaries)} summaries using {type(model).__name__}"")
    
    # Try to load from checkpoint
    if checkpoint_manager:
        cached = checkpoint_manager.load_checkpoint(
            model.checkpoint_filename,
            Cluster
        )
        if cached:
            logger.info(f""Loaded {len(cached)} clusters from checkpoint"")
            return cached
    
    # Generate clusters
    logger.info(""Generating new clusters..."")
    clusters = await model.cluster_summaries(summaries)
    logger.info(f""Generated {len(clusters)} clusters"")
    
    # Save to checkpoint
    if checkpoint_manager:
        checkpoint_manager.save_checkpoint(model.checkpoint_filename, clusters)
    
    return clusters
",kura/v1/kura.py,,1,2.3355930333443423e-09,"The method is well-documented, uses asynchronous programming which is modern and efficient, and includes functionality for checkpointing which is useful for large-scale data processing. It is likely to be useful in various applications involving clustering of conversation summaries, making it a valuable method to retain."
survived,"    def test_decay_method(self):
        """"""Test decay method delegates correctly.""""""
        X = np.array([[1, 2]])

        # Train the pipeline first
        self.pipeline.partial_fit(X, np.array([1]))

        # Now decay
        self.pipeline.decay(X, decay_rate=0.9)

        assert len(self.mock_learner.decay_calls) == 1
        received_X, decay_rate = self.mock_learner.decay_calls[0]
        assert decay_rate == 0.9
        assert received_X.shape == X.shape
",tests/test_learner_pipeline.py,TestLearnerPipelineInterface,1,1.3440409770490404e-08,"The method 'test_decay_method' is a unit test designed to verify the correct delegation of the decay method within a machine learning pipeline. It checks that the decay method is called with the correct parameters and that the mock learner's decay method is invoked exactly once. This is a typical and necessary test to ensure the robustness and correctness of the pipeline's functionality. Since testing is a crucial part of software development, especially in machine learning, this method is likely to be retained to maintain code quality and reliability."
survived,"    def predict(self, X: X_contra) -> NDArray[np.float64]:
        """"""Predict expected values.

        Parameters
        ----------
        X : X_contra
            Input data (enriched features from ArmFeaturizer)

        Returns
        -------
        predictions : NDArray[np.float64]
            Expected values
        """"""
        X_transformed = self._apply_transformers(X)
        return self._learner.predict(X_transformed)
",bayesianbandits/pipelines/_learner.py,LearnerPipeline,1,5.905303995456778e-10,"The method 'predict' is a standard implementation of a prediction function in a machine learning model. It takes input data, applies necessary transformations, and uses a learner to make predictions. This is a fundamental part of any predictive model and is essential for the model's functionality. There is no indication that this method is redundant or unnecessary, and it follows a clear and logical structure. Therefore, it is likely to be retained."
survived,"    def test_contextual_pipeline_policy_setter(self):
        """"""Test policy setter on contextual pipeline.""""""
        arms = make_arms(range(3))
        agent = ContextualAgent(arms, ThompsonSampling())
        pipeline = ContextualAgentPipeline([(""identity"", FunctionTransformer())], agent)

        new_policy = EpsilonGreedy(epsilon=0.2)
        pipeline.policy = new_policy
        assert pipeline.policy is new_policy
        assert agent.policy is new_policy
",tests/test_agent_pipeline.py,TestCoverage,1,2.998960815863541e-09,"The method `test_contextual_pipeline_policy_setter` is a unit test designed to verify the functionality of setting a new policy in a `ContextualAgentPipeline`. It checks that the policy is correctly updated in both the pipeline and the agent. This is a typical and necessary test to ensure that the system behaves as expected when changing policies, which is a common operation in machine learning pipelines. Therefore, it is likely to be retained as it serves a clear purpose in maintaining code quality and reliability."
survived,"            def partial_fit(self, X, y):
                pass
",tests/test_learner_pipeline.py,TestLearnerPipelineInit.BadLearner,0,0.9998415637531546,"The method 'partial_fit' is defined but not implemented, as it only contains a 'pass' statement. In many cases, methods that are not implemented are either placeholders for future development or are meant to be overridden in subclasses. However, if this method is part of a larger class that requires 'partial_fit' to function correctly, it might be implemented later. Without additional context, it's difficult to determine its necessity, but generally, unimplemented methods are more likely to be deleted if they are not used or planned for future use."
survived,"        def multiply_two(X):
            return X * 2
",tests/test_learner_pipeline.py,TestLearnerPipelineTransformers,1,1.6052280526088547e-09,"The method 'multiply_two' is a simple and useful utility function that takes an input and returns its double. Such functions are often used in various programming tasks where multiplication by a constant is required. It is straightforward, has a clear purpose, and can be reused in different contexts, making it likely to be retained in the codebase."
survived,"    def test_pull_without_top_k(self):
        """"""Test pull method without top_k.""""""
        arms = make_arms(range(3))
        agent = Agent(arms, ThompsonSampling(), random_seed=42)
        steps = []

        pipeline = NonContextualAgentPipeline(steps, agent)

        actions = pipeline.pull()

        assert len(actions) == 1
        assert isinstance(actions[0], int)
",tests/test_agent_pipeline.py,TestNonContextualAgentPipeline,1,8.152020648014727e-09,"The method 'test_pull_without_top_k' is a unit test for the 'pull' method of a 'NonContextualAgentPipeline' object. It verifies that the 'pull' method returns a list with a single integer, which is a valid test case to ensure the method's functionality. There is no indication that this test is redundant or incorrect, and it serves a purpose in validating the behavior of the 'pull' method. Therefore, it is likely to be retained."
survived,"    def test_getitem_method(self):
        """"""Test __getitem__ method.""""""
        scaler = StandardScaler()
        learner = MockLearner()
        pipeline = LearnerPipeline(steps=[(""scale"", scaler)], learner=learner)

        # Access by index
        assert pipeline[0] == (""scale"", scaler)

        # Access by name (only transformer steps)
        assert pipeline[""scale""] is scaler
",tests/test_learner_pipeline.py,TestLearnerPipelineProperties,1,1.955568070542584e-08,"The method `test_getitem_method` is a unit test for the `__getitem__` method of a `LearnerPipeline` class. It verifies that the pipeline can be accessed both by index and by name, which are common functionalities in pipeline structures. This test ensures that the pipeline behaves as expected when retrieving components, which is crucial for debugging and validating the pipeline's setup. Since testing is an essential part of software development to ensure code reliability and correctness, this method is likely to be retained."
survived,"    def test_no_transformers(self):
        """"""Test pipeline with no transformer steps (only learner).""""""
        mock_learner = MockLearner()
        pipeline = LearnerPipeline(steps=[], learner=mock_learner)

        X = np.array([[1, 2], [3, 4]])
        y = np.array([1, 2])

        # Should pass data through unchanged when no transformers
        pipeline.partial_fit(X, y)

        # Check that data was passed through unchanged
        received_X, received_y, _ = mock_learner.partial_fit_calls[0]
        np.testing.assert_array_equal(received_X, X)
        np.testing.assert_array_equal(received_y, y)

        # Test other methods also pass data through unchanged
        pipeline.sample(X, size=2)
        sample_X, size = mock_learner.sample_calls[0]
        np.testing.assert_array_equal(sample_X, X)
        assert size == 2

        pipeline.predict(X)
        predict_X = mock_learner.predict_calls[0]
        np.testing.assert_array_equal(predict_X, X)

        pipeline.decay(X, decay_rate=0.9)
        decay_X, decay_rate = mock_learner.decay_calls[0]
        np.testing.assert_array_equal(decay_X, X)
        assert decay_rate == 0.9
",tests/test_learner_pipeline.py,TestLearnerPipelineTransformers,1,1.955568070542584e-08,"The method is a unit test for a specific functionality of a pipeline with no transformers, ensuring that data is passed through unchanged. It is well-structured, uses mock objects to verify behavior, and covers multiple methods of the pipeline. Such tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is likely to be retained."
survived,"    def partial_fit(self, X, y, sample_weight=None):
        self.partial_fit_calls.append((X, y, sample_weight))
        return self
",tests/test_learner_pipeline.py,MockLearner,1,1.955568070542584e-08,"The method 'partial_fit' is likely to survive because it is a common method used in machine learning models for incremental learning. It allows the model to be updated with new data without retraining from scratch, which is useful for handling large datasets or streaming data. The method's implementation here is simple and functional, appending the call details to a list, which suggests it is part of a larger system that tracks or logs these calls for further processing or analysis."
survived,"        def add_one(X):
            return X + 1
",tests/test_learner_pipeline.py,TestLearnerPipelineTransformers,1,1.522997951276035e-08,"The method 'add_one' is a simple utility function that increments a given number by one. Such functions are often useful in various programming scenarios, especially in educational contexts, testing, or as part of larger algorithms. Its simplicity and clear purpose make it a candidate for survival, as it can be reused in different parts of a codebase where incrementing a value is needed."
survived,"    def test_invalid_agent_type(self):
        """"""Test error handling for invalid agent types.""""""
        # This would be caught by type checker, but test runtime behavior
        steps = [(""identity"", FunctionTransformer())]

        # Mock object that doesn't have the expected interface
        class MockAgent:
            pass

        mock_agent = MockAgent()

        # The factory function should handle invalid agent types
        # In practice, this would be a type error at development time
        # Since isinstance check won't match, it will try to create ContextualAgentPipeline
        # which will fail on first attribute access
        pipeline = AgentPipeline(steps, mock_agent)  # type: ignore
        # The error will happen when trying to use the agent
        with pytest.raises(AttributeError):
            _ = pipeline.arms
",tests/test_agent_pipeline.py,TestErrorHandling,1,8.76424914819242e-08,The method is a test case designed to ensure that the system correctly handles invalid agent types by raising an AttributeError. This is a valid and useful test to ensure robustness and error handling in the code. It is unlikely to be deleted as it serves a purpose in verifying the behavior of the system under incorrect usage scenarios.
survived,"    def test_uncovered_functionality(self):
        """"""Test functionality to improve code coverage.""""""
        arms = make_arms(range(3))

        # Test NonContextualAgentPipeline with non-empty steps (edge case)
        agent = Agent(arms, ThompsonSampling(), random_seed=42)
        steps = [(""identity"", FunctionTransformer())]
        pipeline = NonContextualAgentPipeline(steps, agent)

        # Test all delegation methods on NonContextualAgentPipeline
        assert len(pipeline.arms) == 3
        assert pipeline.arm(0) is not None
        pipeline.select_for_update(1)
        assert pipeline.arm_to_update is not None

        # Test add/remove arm
        new_arm = Arm(99, learner=NormalRegressor(alpha=1.0, beta=1.0))
        pipeline.add_arm(new_arm)
        pipeline.remove_arm(99)

        # Test indexing on NonContextualAgentPipeline
        assert pipeline[""identity""] is not None
        assert pipeline[0] == (""identity"", steps[0][1])

        # Test with invalid string key
        with pytest.raises(KeyError):
            _ = pipeline[""nonexistent""]

        # Test with invalid index
        with pytest.raises(IndexError):
            _ = pipeline[10]",tests/test_agent_pipeline.py,TestCoverage,1,1.1253518384332553e-07,"The method 'test_uncovered_functionality' is a test function that aims to improve code coverage by testing various functionalities of the 'NonContextualAgentPipeline' class. It includes tests for edge cases, delegation methods, arm addition/removal, and indexing. These tests are crucial for ensuring the robustness and reliability of the code. Since the method is focused on testing and improving code coverage, it is likely to be retained to maintain the quality of the codebase."
survived,"    def random_state(self, value: Union[np.random.Generator, int, None]) -> None:
        """"""Propagate random state to learner.""""""
        if hasattr(self._learner, ""random_state""):
            self._learner.random_state = value
",bayesianbandits/pipelines/_learner.py,LearnerPipeline,1,3.850741907939403e-09,"The method 'random_state' is a utility function that sets the random state for a learner object if it has the 'random_state' attribute. This is a common practice in machine learning to ensure reproducibility of results. The method is simple, clear, and serves a specific purpose, which is likely to be useful in various contexts where a learner's random state needs to be controlled. Therefore, it is likely to be retained in the codebase."
survived,"    def test_empty_steps_error(self):
        """"""Test empty steps raise error.""""""
        arms = make_arms(range(3))
        agent = ContextualAgent(arms, ThompsonSampling())

        with pytest.raises(ValueError, match=""Pipeline steps cannot be empty""):
            ContextualAgentPipeline([], agent)
",tests/test_agent_pipeline.py,TestContextualAgentPipeline,1,8.152020648014727e-09,"The method `test_empty_steps_error` is a unit test designed to ensure that an error is raised when an empty list of steps is passed to `ContextualAgentPipeline`. This is a valid and useful test case to ensure the robustness of the `ContextualAgentPipeline` class. It checks for proper error handling, which is a critical aspect of software development. Therefore, this method is likely to be retained as it contributes to the overall quality and reliability of the codebase."
survived,"    def test_transformer_not_fitted_error(self):
        """"""Test helpful error message when transformer is not fitted.""""""
        from sklearn.preprocessing import StandardScaler
        
        mock_learner = MockLearner()
        # Create pipeline with unfitted transformer
        pipeline = LearnerPipeline(steps=[(""unfitted_scaler"", StandardScaler())], learner=mock_learner)

        X = np.array([[1, 2], [3, 4]])
        y = np.array([1, 2])

        # Should provide helpful error message
        with pytest.raises(RuntimeError) as exc_info:
            pipeline.partial_fit(X, y)

        error_msg = str(exc_info.value)
        assert ""unfitted_scaler"" in error_msg
        assert ""not fitted"" in error_msg
        assert ""stateless or pre-fitted"" in error_msg
        assert ""FunctionTransformer"" in error_msg
",tests/test_learner_pipeline.py,TestLearnerPipelineTransformers,1,1.1861120010657661e-08,The method is a unit test designed to ensure that a specific error message is raised when a transformer in a pipeline is not fitted. This is a common and important test in machine learning pipelines to ensure robustness and clarity of error messages. Such tests are crucial for maintaining code quality and are unlikely to be deleted unless the functionality they test is removed or significantly altered.
survived,"    def test_valid_initialization(self):
        """"""Test valid initialization.""""""
        mock_learner = MockLearner()
        pipeline = LearnerPipeline(
            steps=[(""scale"", StandardScaler())],
            learner=mock_learner
        )

        assert len(pipeline.steps) == 1
        assert pipeline.learner is mock_learner
",tests/test_learner_pipeline.py,TestLearnerPipelineInit,1,2.2159489282323004e-08,"The method `test_valid_initialization` is a unit test that checks the correct initialization of a `LearnerPipeline` object. It ensures that the pipeline is set up with the correct steps and learner. This is a fundamental test to verify that the pipeline is constructed as expected, which is crucial for any further testing or usage of the pipeline. Such tests are essential for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is likely to be retained in the codebase."
survived,"    def analyze_codebase_patterns(self, project_path: str, file_patterns: List[str] = None) -> Dict[str, Any]:
        """"""
        Analyze codebase to extract patterns, conventions, and architectural insights.
        
        Args:
            project_path (str): Path to the project directory to analyze
            file_patterns (List[str]): Optional list of file patterns to focus on (e.g., ['*.py', '*.js'])
            
        Returns:
            Dict[str, Any]: Comprehensive analysis of codebase patterns
        """"""
        if not os.path.exists(project_path):
            return {""error"": f""Project path does not exist: {project_path}""}
        
        if file_patterns is None:
            file_patterns = ['*.py', '*.js', '*.ts', '*.java', '*.cpp', '*.c', '*.rb', '*.go']
        
        analysis = {
            ""project_structure"": self._analyze_project_structure(project_path),
            ""code_patterns"": self._extract_code_patterns(project_path, file_patterns),
            ""naming_conventions"": self._analyze_naming_conventions(project_path, file_patterns),
            ""import_patterns"": self._analyze_import_patterns(project_path, file_patterns),
            ""architecture_insights"": self._analyze_architecture(project_path),
            ""documentation_style"": self._analyze_documentation_style(project_path)
        }
        
        return analysis
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,1,2.646573631904765e-09,"The method 'analyze_codebase_patterns' is a comprehensive utility function designed to analyze a codebase for various patterns and insights. It is well-documented, handles optional parameters, and provides a structured output. Such methods are valuable for developers and teams looking to maintain or improve code quality, making it likely to be retained in the codebase."
survived,"def test_imports():
    """"""Test that ContextAgent can be imported correctly.""""""
    print(""🧪 Testing ContextAgent Imports..."")
    
    try:
        # Test importing from main package
        from praisonaiagents import ContextAgent, create_context_agent
        print(""✅ Successfully imported ContextAgent and create_context_agent from main package"")
        
        # Test importing from agent submodule
        from praisonaiagents.agent import ContextAgent as AgentContextAgent
        print(""✅ Successfully imported ContextAgent from agent submodule"")
        
        # Test importing from specific module
        from praisonaiagents.agent.context_agent import ContextAgent as DirectContextAgent
        print(""✅ Successfully imported ContextAgent from direct module"")
        
        return True
        
    except ImportError as e:
        print(f""❌ Import failed: {e}"")
        return False
",test_context_agent.py,,1,4.944450477491054e-09,"The method `test_imports` is a utility function designed to verify the correct importation of modules and classes from a package. Such functions are often useful for debugging and ensuring that the package structure is correctly set up, especially in development environments. Since it provides a clear and straightforward way to check for import errors, it is likely to be retained in the codebase for ongoing maintenance and testing purposes. Therefore, the method is predicted to survive."
survived,"    def _format_prp_codebase_analysis(self, analysis: Dict[str, Any]) -> str:
        """"""Format codebase analysis for PRP.""""""
        return json.dumps(analysis, indent=2)
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,1,5.905303995456778e-10,"The method '_format_prp_codebase_analysis' is a utility function that formats a dictionary into a JSON string with indentation. This is a common and useful operation in many codebases, especially when dealing with data serialization and logging. The method is simple, clear, and serves a specific purpose without any apparent issues or redundancies. Therefore, it is likely to be retained in the codebase."
survived,"    def _analyze_test_structure(self, project_path: str) -> Dict[str, Any]:
        """"""Analyze test directory structure.""""""
        return {""pattern"": ""mirror"", ""location"": ""tests/""}
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,1,2.5109990926928157e-08,"The method '_analyze_test_structure' is a private method (indicated by the underscore prefix) that is designed to analyze the test directory structure of a project. It returns a dictionary with a fixed pattern and location, which suggests it might be a placeholder or a simplified version of a more complex analysis. However, the method is functional and provides a clear output, which could be useful for other parts of the code that need to understand the test structure. Unless there is a significant change in the requirements or the method is deemed unnecessary due to redundancy or a change in project structure, it is likely to survive."
survived,"    def _format_context_data(self, context_data: Dict[str, Any]) -> str:
        """"""Format context data for prompt enhancement.""""""
        return json.dumps(context_data, indent=2)
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,1,8.592166611791576e-10,"The method '_format_context_data' is a utility function that formats a dictionary into a JSON string with indentation. This is a common and useful operation, especially in contexts where data needs to be logged, displayed, or sent over a network in a readable format. The method is simple, clear, and serves a specific purpose, which makes it likely to be retained in the codebase. There are no apparent issues or redundancies that would necessitate its removal."
survived,"    def _extract_quality_guidance(self, context_data: Dict[str, Any]) -> str:
        """"""Extract quality guidance from context data.""""""
        return ""Maintain code quality standards identified in the codebase.""
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,1,1.637377179507321e-07,"The method '_extract_quality_guidance' is a simple utility function that extracts a predefined string as quality guidance. It is likely to survive because it encapsulates a specific piece of functionality that might be reused in different parts of the codebase. Even though the method currently returns a static string, it provides a clear interface for future enhancements where the guidance might be dynamically generated based on the 'context_data'."
survived,"    def _format_code_conventions(self, code_patterns: Dict[str, Any], naming: Dict[str, Any]) -> str:
        """"""Format code conventions for context document.""""""
        return f""Naming Style: {naming.get('style', 'Unknown')}""
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,1,1.725782769012759e-08,"The method '_format_code_conventions' is a private method (indicated by the underscore prefix) that formats code conventions into a string. It is a simple utility function that returns a formatted string based on the input dictionaries. Such methods are typically useful for internal processing and documentation purposes. Unless there is a significant change in the codebase or the method is deemed unnecessary due to redundancy or lack of use, it is likely to survive. The method is straightforward and serves a clear purpose, which suggests it will be retained."
survived,"    def _generate_quality_gates(self, criteria: List[str]) -> List[Dict[str, str]]:
        """"""Generate quality gate specifications.""""""
        return [{""gate"": ""all_tests_pass"", ""description"": ""All validation criteria must pass""}]
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,1,5.905303995456778e-10,"The method `_generate_quality_gates` is a simple utility function that generates a list of dictionaries representing quality gate specifications. It is likely to be useful in contexts where quality gates are needed, such as in testing or validation processes. The method is straightforward, has a clear purpose, and does not contain any obvious issues or redundancies that would warrant its removal. Therefore, it is likely to be retained in the codebase."
survived,"def create_context_agent(llm: Optional[Union[str, Any]] = None, **kwargs) -> ContextAgent:
    """"""
    Factory function to create a ContextAgent with sensible defaults.
    
    Args:
        llm: Language model to use (e.g., ""gpt-4o-mini"", ""claude-3-haiku"")
        **kwargs: Additional arguments to pass to ContextAgent constructor
        
    Returns:
        ContextAgent: Configured ContextAgent instance
    """"""
    if llm is None:
        llm = ""gpt-4o-mini""  # Default to a capable model for context generation
    
    return ContextAgent(llm=llm, **kwargs)",src/praisonai-agents/praisonaiagents/agent/context_agent.py,,1,3.850741907939403e-09,"The method 'create_context_agent' is a factory function designed to create instances of 'ContextAgent' with sensible defaults. It provides flexibility by allowing the user to specify a language model or use a default one, and it accepts additional arguments for further customization. This kind of utility function is often useful in codebases where object creation needs to be standardized or simplified, especially when dealing with complex objects like agents that require specific configurations. Therefore, it is likely to be retained as it adds value by simplifying the creation process and ensuring consistency."
survived,"    def estimate_tokens_for_request(self, request: FenicCompletionsRequest):
        """"""Estimate the number of tokens for a request.

        Args:
            request: The request to estimate tokens for

        Returns:
            TokenEstimate: The estimated token usage
        """"""

        # Count input tokens
        input_tokens = self.count_tokens(request.messages)
        input_tokens += self._count_auxiliary_input_tokens(request)
        
        # Estimate output tokens
        output_tokens = self._get_max_output_tokens(request)
        
        return TokenEstimate(
            input_tokens=input_tokens,
            output_tokens=output_tokens
        )
",src/fenic/_inference/google/gemini_native_chat_completions_client.py,GeminiNativeChatCompletionsClient,1,2.1724399346070676e-10,"The method 'estimate_tokens_for_request' is likely to survive because it provides a clear and necessary functionality within the context of handling requests. It estimates the number of tokens required for a request, which is crucial for managing resources and ensuring efficient processing. The method is well-documented, indicating its importance and clarity in its purpose. Additionally, it uses helper methods to modularize the logic, suggesting a well-structured approach that is less likely to be removed unless the entire token estimation process is refactored or deprecated."
survived,"    async def test_merge_llm_stats(self):
        """"""Test the merge_llm_stats method correctly merges stats from another block.""""""
        import backend.blocks.llm as llm

        block1 = llm.AITextGeneratorBlock()
        block2 = llm.AIStructuredResponseGeneratorBlock()

        # Set stats on block2
        block2.execution_stats = NodeExecutionStats(
            input_token_count=100,
            output_token_count=50,
            llm_call_count=2,
            llm_retry_count=1,
        )
        block2.prompt = [{""role"": ""user"", ""content"": ""Test""}]

        # Merge stats from block2 into block1
        block1.merge_llm_stats(block2)

        # Check that stats were merged
        assert block1.execution_stats.input_token_count == 100
        assert block1.execution_stats.output_token_count == 50
        assert block1.execution_stats.llm_call_count == 2
        assert block1.execution_stats.llm_retry_count == 1
        assert block1.prompt == [{""role"": ""user"", ""content"": ""Test""}]
",autogpt_platform/backend/backend/blocks/test/test_llm.py,TestLLMStatsTracking,1,6.825604231969389e-08,"The method is a unit test for the `merge_llm_stats` function, which is likely a crucial part of the system's functionality for handling and merging statistics from different blocks. Unit tests are essential for ensuring code reliability and correctness, especially in complex systems. This test verifies that the merging of statistics between two blocks works as expected, which is important for maintaining the integrity of data processing in the application. Therefore, it is unlikely to be deleted as it serves a critical role in validating the functionality of the code."
survived,"        async def mock_create(*args, **kwargs):
            nonlocal call_count
            call_count += 1

            mock_response = MagicMock()
            # Return different responses for chunk summary vs final summary
            if call_count == 1:
                mock_response.choices = [
                    MagicMock(
                        message=MagicMock(
                            content='{""summary"": ""Test chunk summary""}', tool_calls=None
                        )
                    )
                ]
            else:
                mock_response.choices = [
                    MagicMock(
                        message=MagicMock(
                            content='{""final_summary"": ""Test final summary""}',
                            tool_calls=None,
                        )
                    )
                ]
            mock_response.usage = MagicMock(prompt_tokens=50, completion_tokens=30)
            return mock_response
",autogpt_platform/backend/backend/blocks/test/test_llm.py,TestLLMStatsTracking,1,3.850741907939403e-09,"The method 'mock_create' is a mock function used for testing purposes, simulating the behavior of an asynchronous function that returns different mock responses based on the call count. Such mock functions are commonly used in unit tests to verify the behavior of code without making actual API calls. Since it is a utility function for testing, it is likely to be retained as long as the tests it supports are relevant. Therefore, the method will likely survive."
survived,"    async def test_ai_conversation_block_tracks_stats(self):
        """"""Test that AIConversationBlock correctly tracks stats.""""""
        import backend.blocks.llm as llm

        block = llm.AIConversationBlock()

        # Mock the llm_call method
        async def mock_llm_call(input_data, credentials):
            block.execution_stats = NodeExecutionStats(
                input_token_count=100,
                output_token_count=50,
                llm_call_count=1,
            )
            return {""response"": ""AI response to conversation""}

        block.llm_call = mock_llm_call  # type: ignore

        # Run the block
        input_data = llm.AIConversationBlock.Input(
            messages=[
                {""role"": ""user"", ""content"": ""Hello""},
                {""role"": ""assistant"", ""content"": ""Hi there!""},
                {""role"": ""user"", ""content"": ""How are you?""},
            ],
            model=llm.LlmModel.GPT4O,
            credentials=llm.TEST_CREDENTIALS_INPUT,  # type: ignore
        )

        outputs = {}
        async for output_name, output_data in block.run(
            input_data, credentials=llm.TEST_CREDENTIALS
        ):
            outputs[output_name] = output_data

        # Check stats
        assert block.execution_stats.input_token_count == 100
        assert block.execution_stats.output_token_count == 50
        assert block.execution_stats.llm_call_count == 1

        # Check output
        assert outputs[""response""] == {""response"": ""AI response to conversation""}
",autogpt_platform/backend/backend/blocks/test/test_llm.py,TestLLMStatsTracking,1,1.3440409770490404e-08,"The method is a well-structured test function that verifies the functionality of the AIConversationBlock class, specifically its ability to track execution statistics and produce the expected output. It uses mocking to simulate the behavior of the llm_call method, ensuring that the test is isolated and does not depend on external factors. This is a common and necessary practice in software testing to ensure code reliability and correctness. Therefore, the method is likely to be retained as it serves a crucial role in maintaining code quality."
survived,"    def _message(self) -> str:
        return ""Empty notebook cell. Remove it or add some content.""",dev/clint/src/clint/rules/empty_notebook_cell.py,EmptyNotebookCell,1,1.1861120010657661e-08,"The method _message is a simple utility function that returns a static string. It is likely used internally within a class to provide a consistent message when a certain condition is met, such as when a notebook cell is empty. This kind of method is often useful for maintaining code readability and consistency, especially if the message is used in multiple places. Since it serves a clear purpose and is likely part of a larger system, it is more likely to be retained rather than deleted."
survived,"    def __init__(self, type_hint: str) -> None:
        self.type_hint = type_hint
",dev/clint/src/clint/rules/unparameterized_generic_type.py,UnparameterizedGenericType,1,1.0467401685178159e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming in Python. Constructors are essential for initializing new objects with specific attributes, and this method is doing just that by setting the 'type_hint' attribute. There is no indication that this method is redundant or unnecessary, so it is likely to be retained."
survived,"    def _message(self) -> str:
        return ""Do not use RST style. Use Google style instead.""",dev/clint/src/clint/rules/no_rst.py,NoRst,1,6.348800075736417e-09,"The method _message is a private method, indicated by the underscore prefix, and it returns a simple string message. The method is straightforward and serves a specific purpose of providing a message, likely for internal use within a class or module. There is no indication that this method is redundant or unnecessary, as it might be used for logging, documentation, or guiding developers on style preferences. Therefore, it is likely to survive."
survived,"    def _is_none(value: ast.AnnAssign) -> bool:
        """"""
        Returns True if `value` represents `None`.
        """"""
        return isinstance(value, ast.Constant) and value.value is None",dev/clint/src/clint/rules/implicit_optional.py,ImplicitOptional,1,4.0586521248284276e-10,"The method `_is_none` is a utility function that checks if a given AST node represents a `None` value. This is a common requirement when analyzing or transforming Python code using the Abstract Syntax Tree (AST). The function is simple, clear, and serves a specific purpose, which is likely to be useful in various contexts where AST manipulation is involved. Therefore, it is likely to be retained in the codebase."
survived,"    def check(node: ast.Assign, resolver: Resolver) -> bool:
        """"""
        Returns True if the assignment is to os.environ[...].
        """"""
        if len(node.targets) == 1 and isinstance(node.targets[0], ast.Subscript):
            resolved = resolver.resolve(node.targets[0].value)
            return resolved == [""os"", ""environ""]
        return False",dev/clint/src/clint/rules/os_environ_set_in_test.py,OsEnvironSetInTest,1,3.850741907939403e-09,"The method 'check' is a utility function that checks if a given assignment in an abstract syntax tree (AST) is targeting the 'os.environ' dictionary. This is a specific and useful function for code analysis or transformation tasks, especially when dealing with environment variables in Python code. Such functionality is often needed in static analysis tools, linters, or code refactoring tools. Given its utility in these contexts, it is likely to be retained in the codebase."
survived,"    def _message(self) -> str:
        return (
            f""Importing module `{self.module}` at the top level is not allowed ""
            ""in this file. Use lazy import instead.""
        )",dev/clint/src/clint/rules/forbidden_top_level_import.py,ForbiddenTopLevelImport,1,1.522997951276035e-08,"The method _message is a private method (indicated by the underscore) that returns a formatted string. It is likely used internally within a class to provide a specific error or warning message related to module imports. Since it serves a clear purpose and is encapsulated within a class, it is unlikely to be deleted unless the functionality it supports is no longer needed or is refactored. Therefore, it is more likely to survive."
survived,"    def _message(self) -> str:
        return (
            ""`threading.Thread()` must be called with a `name` argument to improve debugging ""
            ""and traceability of thread-related issues.""
        )
",dev/clint/src/clint/rules/unnamed_thread.py,UnnamedThread,1,1.955568070542584e-08,"The method _message is a private method (indicated by the underscore prefix) that returns a static string message. It is likely used internally within a class to provide a consistent error or log message. Since it serves a specific purpose of improving code readability and maintainability by providing a clear message about the importance of naming threads, it is unlikely to be deleted unless the entire class or its functionality is refactored or removed. Therefore, it is more likely to survive."
survived,"    def __init__(self, function_name: str) -> None:
        self.function_name = function_name
",dev/clint/src/clint/rules/unknown_mlflow_function.py,UnknownMlflowFunction,1,1.637377179507321e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming in Python. It initializes an instance of the class with a given function name, which is likely essential for the class's functionality. Constructors are rarely deleted unless the class itself is being removed or significantly refactored, which is not indicated here."
survived,"    def test_webhook(
        self, webhook_id: str, event: Optional[WebhookEvent] = None
    ) -> WebhookTestResult:
        """"""
        Test a webhook by sending a test payload.

        Args:
            webhook_id: The ID of the webhook to test.
            event: Optional event type to test. If not specified, uses the first event from webhook.

        Returns:
            A :py:class:`mlflow.entities.webhook.WebhookTestResult` indicating success/failure and
            response details.
        """"""
        return self.store.test_webhook(webhook_id, event)",mlflow/tracking/_model_registry/client.py,ModelRegistryClient,1,3.160881453314576e-10,"The method 'test_webhook' is likely to survive because it provides a useful functionality for testing webhooks by sending a test payload. This is a common requirement in systems that use webhooks to ensure that they are set up correctly and are functioning as expected. The method is well-documented, specifying the arguments and return type, which indicates that it is a well-thought-out part of the codebase. Additionally, it leverages an existing store method to perform the actual test, suggesting that it is part of a larger, cohesive system."
survived,"    def example(cls) -> ""RegisteredModelCreatedPayload"":
        return cls(
            name=""example_model"",
            tags={""example_key"": ""example_value""},
            description=""An example registered model"",
        )
",mlflow/webhooks/types.py,RegisteredModelCreatedPayload,1,1.8189616842444243e-09,"The method 'example' is a class method that returns an instance of 'RegisteredModelCreatedPayload' with predefined attributes. This method is useful for creating a standardized example or template instance of the class, which can be helpful for testing, documentation, or demonstration purposes. Such methods are often retained in codebases to facilitate easier understanding and usage of the class. Therefore, it is likely to be Survived."
survived,"    def w_GET_blueval(vm: 'SPyVM', wop_x: 'W_OpArg',
                      wop_attr: 'W_OpArg') -> 'W_OpImpl':
        from spy.vm.builtin import builtin_func
        from spy.vm.primitive import W_Dynamic

        @builtin_func(W_OpArg._w.fqn, 'get_blueval')
        def w_get_blueval(vm: 'SPyVM', w_oparg: W_OpArg) -> W_Dynamic:
            if w_oparg.color != 'blue':
                raise SPyRuntimeError('oparg is not blue')
            return w_oparg.w_blueval

        return W_OpImpl(w_get_blueval, [wop_x])
",spy/vm/opimpl.py,W_OpArg,1,2.0611536181902033e-09,"The method `w_GET_blueval` is a specialized function that checks if an operation argument (`w_oparg`) has a specific attribute ('blue') and returns a value associated with it. This kind of functionality is often necessary in systems that deal with dynamic or polymorphic data types, where certain operations are only valid for specific types or states of objects. The method is also well-structured, using decorators and error handling, which suggests it is part of a larger, well-maintained codebase. Unless the entire system or the specific functionality it supports is deprecated, this method is likely to survive."
survived,"    def test_opimpl_null(self):
        mod = self.compile(
        """"""
        from operator import OpImpl

        @blue
        def get_null() -> OpImpl:
            return OpImpl.NULL
        """""")
        w_null = mod.get_null(unwrap=False)
        assert w_null is W_OpImpl.NULL",spy/tests/compiler/test_opimpl.py,TestOpImpl,1,9.931195248674785e-08,"The method 'test_opimpl_null' is a test function that checks the behavior of a compiled module using the 'OpImpl' class. It verifies that the 'get_null' function returns the 'NULL' attribute of 'OpImpl'. This is a straightforward test case that ensures the correct functionality of the 'get_null' method. Test methods are generally retained unless they are redundant or the functionality they test is deprecated. Since this test is simple and directly verifies a specific behavior, it is likely to be retained."
survived,"def test_api_key_parameter_with_async_client():
    """"""Test that api_key parameter works with async clients.""""""
    from unittest.mock import patch, MagicMock

    # Mock the openai module
    with patch(""openai.AsyncOpenAI"") as mock_async_openai_class:
        mock_client = MagicMock()
        mock_async_openai_class.return_value = mock_client

        # Mock the from_openai import
        with patch(""instructor.from_openai"") as mock_from_openai:
            mock_instructor = MagicMock()
            mock_from_openai.return_value = mock_instructor

            # Test with async client
            from_provider(""openai/gpt-4"", async_client=True, api_key=""test-async-key"")

            # Verify AsyncOpenAI was called with the api_key
            mock_async_openai_class.assert_called_once()
            _, kwargs = mock_async_openai_class.call_args
            assert kwargs[""api_key""] == ""test-async-key""
",tests/test_auto_client.py,,1,2.998960815863541e-09,"The method is a unit test designed to verify that the 'api_key' parameter is correctly passed to an asynchronous client. It uses mocking to simulate the behavior of external dependencies, which is a common practice in testing. The method is well-structured and serves a clear purpose in ensuring the functionality of the API key parameter with async clients. There is no indication that this functionality is obsolete or unnecessary, so it is likely to be retained."
survived,"def test_api_key_parameter_extraction():
    """"""Test that api_key parameter is correctly extracted from kwargs.""""""
    from unittest.mock import patch, MagicMock

    # Mock the openai module to avoid actual API calls
    with patch(""openai.OpenAI"") as mock_openai_class:
        mock_client = MagicMock()
        mock_openai_class.return_value = mock_client

        # Mock the from_openai import
        with patch(""instructor.from_openai"") as mock_from_openai:
            mock_instructor = MagicMock()
            mock_from_openai.return_value = mock_instructor

            # Test that api_key is passed to client constructor
            from_provider(""openai/gpt-4"", api_key=""test-key-123"")

            # Verify OpenAI was called with the api_key
            mock_openai_class.assert_called_once()
            _, kwargs = mock_openai_class.call_args
            assert kwargs[""api_key""] == ""test-key-123""
",tests/test_auto_client.py,,1,4.6911638017642294e-08,"The method is a unit test designed to verify that the 'api_key' parameter is correctly extracted and passed to the OpenAI client constructor. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with API integrations. This test uses mocking to simulate the behavior of external dependencies, which is a common practice in testing. Given its purpose and implementation, it is unlikely to be deleted as it serves an important role in maintaining the integrity of the codebase."
survived,"    def test_comparison_with_numpy(self):
        # Compare with numpy's cov for data without NaNs
        np.random.seed(42)
        data = np.random.randn(5, 100)

        result = nancovmatrix(data)
        expected = np.cov(data)

        assert_allclose(result, expected, rtol=1e-10)
",numbagg/test/test_nancovmatrix.py,TestNanCovMatrix,1,2.5109990926928157e-08,"The method 'test_comparison_with_numpy' is a unit test that verifies the functionality of the 'nancovmatrix' function by comparing its output to numpy's 'cov' function. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with mathematical computations. This test is well-structured, uses a fixed random seed for reproducibility, and checks the result with a high precision tolerance. Therefore, it is likely to be retained as part of the test suite to ensure the 'nancovmatrix' function works as expected."
survived,"    def test_relationship_to_correlation(self):
        # Test relationship between covariance and correlation
        from numbagg import nancorrmatrix

        np.random.seed(42)
        data = np.random.randn(4, 50)

        cov_matrix = nancovmatrix(data)
        corr_matrix = nancorrmatrix(data)

        # Correlation = Covariance / (std_i * std_j)
        stds = np.sqrt(np.diag(cov_matrix))
        expected_corr = cov_matrix / np.outer(stds, stds)

        assert_allclose(corr_matrix, expected_corr, rtol=1e-10)
",numbagg/test/test_nancovmatrix.py,TestNanCovMatrix,1,3.2241866333029355e-08,"The method is a test function that verifies the relationship between covariance and correlation using the `nancorrmatrix` and `nancovmatrix` functions. It uses a random dataset to compute both matrices and checks if the correlation matrix is correctly derived from the covariance matrix. This is a fundamental test for validating the correctness of statistical computations, which is crucial in many scientific and data analysis applications. Therefore, it is likely to be retained as it ensures the reliability of the correlation computation functionality."
survived,"    def test_large_matrix(self):
        # Test performance with larger matrix
        np.random.seed(42)
        data = np.random.randn(50, 1000)

        # Add some NaNs
        mask = np.random.rand(50, 1000) < 0.1
        data[mask] = np.nan

        result = nancovmatrix(data)

        # Check basic properties
        assert result.shape == (50, 50)
        assert_allclose(result, result.T, rtol=1e-10)
        # All diagonal elements should be non-negative (variances)
        assert np.all(np.diag(result) >= 0 | np.isnan(np.diag(result)))",numbagg/test/test_nancovmatrix.py,TestNanCovMatrix,1,1.0467401685178159e-08,"The method `test_large_matrix` is a unit test designed to test the performance and correctness of the `nancovmatrix` function with a large matrix input. It includes setting up a random matrix, introducing NaN values, and checking the properties of the resulting covariance matrix. This is a typical and necessary test to ensure the function handles large datasets and missing values correctly. Such tests are crucial for validating the functionality and robustness of the code, especially in data processing and statistical analysis contexts. Therefore, it is likely to be retained as part of the test suite."
survived,"    def _field_has_secrets(self, field_name: str) -> bool:
        """"""Check if a field contains secrets based on the schema's secret_fields.""""""
        secret_fields = self.model_json_schema().get(""secret_fields"", [])

        # Check if field_name matches any secret field pattern
        for secret_field in secret_fields:
            if secret_field == field_name:
                return True
            elif secret_field.startswith(f""{field_name}.""):
                # This field contains nested secrets
                return True
            elif secret_field.endswith("".*""):
                # Handle wildcard patterns like ""field.*""
                prefix = secret_field[:-2]  # Remove .*
                if field_name == prefix:
                    return True

        return False
",src/prefect/blocks/core.py,Block,1,5.905303995456778e-10,"The method '_field_has_secrets' is a utility function that checks if a given field name is considered a secret based on a schema's 'secret_fields'. This functionality is crucial for maintaining data security and privacy, especially in applications dealing with sensitive information. The method is well-defined, handles different patterns of secret fields, and is likely to be used in various parts of the codebase where such checks are necessary. Therefore, it is unlikely to be deleted as it serves an important purpose."
survived,"    async def _list_resource_templates(
        self, apply_middleware: bool = True
    ) -> list[ResourceTemplate]:
        """"""
        List all available resource templates.
        """"""

        if (
            templates := self._cache.get(""resource_templates"")
        ) is self._cache.NOT_FOUND:
            templates: list[ResourceTemplate] = []

            # iterate such that new mounts overwrite older ones
            for mounted_server in self._mounted_servers:
                try:
                    if apply_middleware:
                        server_templates = await mounted_server.server._middleware_list_resource_templates()
                    else:
                        server_templates = (
                            await mounted_server.server._list_resource_templates()
                        )
                    # Apply prefix to each template key if prefix exists
                    if mounted_server.prefix:
                        for template in server_templates:
                            template = template.with_key(
                                add_resource_prefix(
                                    template.key,
                                    mounted_server.prefix,
                                    self.resource_prefix_format,
                                )
                            )
                            templates.append(template)
                    else:
                        templates.extend(server_templates)
                except Exception as e:
                    logger.warning(
                        ""Failed to get resource templates from mounted server ""
                        f""'{mounted_server.prefix}': {e}""
                    )
                    continue
            templates.extend(self._resource_manager.get_templates().values())
            self._cache.set(""resource_templates"", templates)
        return templates
",src/fastmcp/server/server.py,FastMCP,1,1.9171715133907573e-10,"The method '_list_resource_templates' is likely to survive because it performs a crucial function of listing resource templates, which is essential for managing and accessing resources in a system. It includes caching to improve performance, error handling to ensure robustness, and flexibility with middleware application. These features indicate that the method is well-designed and serves an important role in the system's functionality."
survived,"    def __init__(self, name: str | None = None):
        super().__init__()
        self.calls: list[Recording] = []
        self.name = name
",tests/server/middleware/test_middleware.py,RecordingMiddleware,1,9.237449576640118e-09,"The method is a constructor (__init__) for a class, which is essential for initializing class instances. It sets up initial values for instance variables, such as 'calls' and 'name'. Constructors are fundamental to object-oriented programming, and there is no indication that this constructor is redundant or unnecessary. Therefore, it is unlikely to be deleted."
survived,"    async def test_get_prompt(
        self, mcp_server: FastMCP, recording_middleware: RecordingMiddleware
    ):
        async with Client(mcp_server) as client:
            await client.get_prompt(""test_prompt"", {""x"": ""test""})

        assert recording_middleware.assert_called(times=3)
        assert recording_middleware.assert_called(method=""prompts/get"", times=3)
        assert recording_middleware.assert_called(hook=""on_message"", times=1)
        assert recording_middleware.assert_called(hook=""on_request"", times=1)
        assert recording_middleware.assert_called(hook=""on_get_prompt"", times=1)
",tests/server/middleware/test_middleware.py,TestMiddlewareHooks,1,1.725782769012759e-08,"The method `test_get_prompt` is a test function that verifies the behavior of a system using assertions. Test functions are generally not deleted unless they are redundant or the functionality they test is removed. Since this function is testing specific interactions with a middleware and a client, it is likely important for ensuring the system's reliability and correctness. Therefore, it is more likely to be maintained or updated rather than deleted."
survived,"        async def sample_tool(context: Context) -> None:
            await context.sample(""hello"")
",tests/server/middleware/test_middleware.py,TestNestedMiddlewareHooks,1,2.646573631904765e-09,"The method 'sample_tool' is an asynchronous function that takes a 'Context' object as a parameter and calls an asynchronous 'sample' method on it with the argument 'hello'. This method is simple, clear, and follows common asynchronous programming patterns. There is no indication of deprecated practices or inefficiencies that would warrant its deletion. Therefore, it is likely to survive."
survived,"def test_native_library_loading():
    """"""Test that native library loading doesn't crash""""""
    from wvlet.compiler import _load_native_library
    # This should not raise an exception, even if library is not found
    lib = _load_native_library()
    # lib can be None if platform is not supported or library not found
    assert lib is None or hasattr(lib, 'wvlet_compile_query')
",sdks/python/tests/test_compiler.py,,1,1.0467401685178159e-08,"The method `test_native_library_loading` is a test function designed to ensure that the loading of a native library does not cause a crash, even if the library is not found. This is a useful test to verify the robustness of the library loading mechanism, especially in environments where the native library might not be available. The function includes an assertion to check that the library, if loaded, has a specific attribute, which is a reasonable check for the expected functionality. Since this test is valuable for maintaining the stability and reliability of the system, it is likely to be retained."
survived,"def test_inferred_parameters_transitively_collected():
    """"""
    Test that parameters inferred from dependencies are properly collected
    when enqueuing results.
    """"""
    
    with tempfile.TemporaryDirectory() as temp_dir:
        db_path = Path(temp_dir) / ""test.db""
        initialise_or_create_database_at(db_path)
        
        # Create experiment  
        exp = new_experiment(""test_exp"", sample_name=""test_sample"")
        
        # Create mock instruments
        dac = DummyInstrument(""dac"", gates=[""ch1"", ""ch2""])
        
        # Create delegate parameter that should be inferred from dac.ch1
        del_param = DelegateParameter(""del_param_1"", label=""del param 1"", source=dac.ch1)
        
        # Create a measurement parameter that depends on the delegate parameter
        measurement_param = Parameter(""measurement"", get_cmd=lambda: 42.0)
        
        # Create measurement
        meas = Measurement(name=""test_measurement"", exp=exp)
        
        # Register parameters to create the dependency chain:
        # measurement depends on del_param_1, del_param_1 is inferred from dac_ch1
        meas.register_parameter(dac.ch1)  # standalone
        meas.register_parameter(del_param, basis=(dac.ch1,))  # inferred from dac_ch1
        meas.register_parameter(measurement_param, setpoints=(del_param,))  # depends on del_param_1
        
        # Verify the interdependencies are set up correctly
        interdeps = meas._interdeps
        
        # Check that we have the expected structure
        assert len(interdeps.dependencies) == 1  # measurement depends on del_param_1
        assert len(interdeps.inferences) == 1    # del_param_1 inferred from dac_ch1
        assert len(interdeps.standalones) == 1   # dac_ch1 is standalone
        
        # Get the parameter specs
        measurement_spec = interdeps._id_to_paramspec[""measurement""]
        del_param_spec = interdeps._id_to_paramspec[""del_param_1""] 
        dac_spec = interdeps._id_to_paramspec[""dac_ch1""]
        
        # Test the _collect_all_related_parameters method directly
        from qcodes.dataset.data_set import DataSet
        
        # Create a dummy dataset to access the method
        with meas.run() as datasaver:
            dataset = datasaver.dataset
            
            # Simulate a result_dict that would be passed to _enqueue_results
            result_dict = {
                measurement_spec: [1.0],
                del_param_spec: [0.5],
                dac_spec: [0.1]
            }
            
            # Test the helper method
            initial_params = {measurement_spec, del_param_spec}
            collected = dataset._collect_all_related_parameters(interdeps, initial_params, result_dict)
            
            # Verify that all three parameters are collected
            collected_names = {p.name for p in collected}
            expected_names = {""measurement"", ""del_param_1"", ""dac_ch1""}
            assert collected_names == expected_names, f""Expected {expected_names}, got {collected_names}""
",tests/dataset/measurement/test_inferred_parameters_fix.py,,1,1.725782769012759e-08,"The method is a test function that verifies the correct behavior of a specific feature in a codebase. Test functions are generally crucial for ensuring code reliability and are not typically deleted unless they are redundant or replaced by more comprehensive tests. This function appears to be well-structured and serves a clear purpose in testing parameter dependencies, making it likely to be retained."
deleted,"    def _collect_all_related_parameters(
        self, 
        interdeps: ""InterDependencies_"", 
        initial_params: set[ParamSpecBase], 
        result_dict: Mapping[ParamSpecBase, npt.NDArray]
    ) -> set[ParamSpecBase]:
        """"""
        Transitively collect all parameters that are related to the initial set of parameters.
        This includes parameters that any parameter in the set is inferred from, and parameters
        that depend on or are inferred from those parameters, etc.
        
        Only includes parameters that are present in result_dict.
        """"""
        collected = set(initial_params)
        to_process = set(initial_params)
        
        while to_process:
            current = to_process.pop()
            
            # Add parameters that current parameter is inferred from
            inferred_from = set(interdeps.inferences.get(current, ()))
            new_inferred = inferred_from - collected
            # Only add if they're in result_dict
            new_inferred = new_inferred.intersection(result_dict.keys())
            collected.update(new_inferred)
            to_process.update(new_inferred)
            
            # Add parameters that depend on current parameter
            dependents = set(interdeps._dependencies_inv.get(current, ()))
            new_dependents = dependents - collected
            # Only add if they're in result_dict
            new_dependents = new_dependents.intersection(result_dict.keys())
            collected.update(new_dependents)
            to_process.update(new_dependents)
            
            # Add parameters that are inferred from current parameter
            infers = set(interdeps._inferences_inv.get(current, ()))
            new_infers = infers - collected
            # Only add if they're in result_dict
            new_infers = new_infers.intersection(result_dict.keys())
            collected.update(new_infers)
            to_process.update(new_infers)
        
        return collected
",src/qcodes/dataset/data_set_in_memory.py,DataSetInMem,1,3.581747929000289e-10,"The method '_collect_all_related_parameters' is a utility function that performs a specific task of collecting related parameters based on dependencies and inferences. It is well-defined, has a clear purpose, and is likely used in a larger context where parameter relationships are important. Such methods are typically retained as they encapsulate a specific logic that is reusable and necessary for the functionality of the system. Additionally, the method is not overly complex or redundant, which further supports its survival."
survived,"def test_inferred_parameters_in_actual_measurement():
    """"""
    Test the full measurement flow to ensure inferred parameters are saved correctly.
    """"""
    
    with tempfile.TemporaryDirectory() as temp_dir:
        db_path = Path(temp_dir) / ""test.db""
        initialise_or_create_database_at(db_path)
        
        # Create experiment  
        exp = new_experiment(""test_exp"", sample_name=""test_sample"")
        
        # Create mock instruments
        dac = DummyInstrument(""dac"", gates=[""ch1""])
        
        # Create delegate parameter
        del_param = DelegateParameter(""del_param_1"", label=""del param 1"", source=dac.ch1)
        
        # Create measurement
        meas = Measurement(name=""test_measurement"", exp=exp)
        
        # Register parameters  
        meas.register_parameter(dac.ch1)
        meas.register_parameter(del_param, basis=(dac.ch1,))
        
        # Run measurement
        with meas.run() as datasaver:
            # Set values and add results
            dac.ch1.set(0.5)
            del_param.set(0.5) 
            
            datasaver.add_result(
                (dac.ch1, dac.ch1()),
                (del_param, del_param()),
            )
            
        # Retrieve the dataset
        dataset = datasaver.dataset
        
        # Get parameter data - both parameters should be present
        param_data = dataset.get_parameter_data()
        
        # Both parameters should be in the dataset
        assert ""dac_ch1"" in param_data, ""dac_ch1 should be in parameter data""
        assert ""del_param_1"" in param_data, ""del_param_1 should be in parameter data""
        
        # Check that the data is correct
        assert len(param_data[""dac_ch1""][""dac_ch1""]) == 1
        assert len(param_data[""del_param_1""][""del_param_1""]) == 1",tests/dataset/measurement/test_inferred_parameters_fix.py,,1,6.023574641292144e-08,"The method is a test function that verifies the functionality of a measurement flow in a database context. It is well-structured, uses temporary resources, and includes assertions to ensure correctness. Such test functions are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is likely to be retained in the codebase."
survived,"    def __init__(self, config: Optional[GuardrailConfig] = None) -> None:
        self.checks: List[Callable[[str], Awaitable[str]]] = []
        if config is not None:
            self.add_from_config(config)
",src/meta_agent/policy.py,PolicyChecker,1,4.944450477491054e-09,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting up initial states. This particular constructor also includes logic to handle optional configuration, which adds flexibility and utility to the class. Such methods are rarely deleted unless the entire class is being refactored or removed, which is not indicated here. Therefore, it is likely to survive."
survived,"        def __init__(self, url, token):
            self.secrets = types.SimpleNamespace(kv=FakeKV())
",tests/test_root_config.py,FakeClient,1,3.0590235908148916e-07,"The method is a constructor (__init__) for a class, which is a fundamental part of class instantiation in Python. Constructors are essential for initializing object attributes and setting up the initial state of an object. Therefore, it is unlikely that this method will be deleted as it serves a critical role in object-oriented programming."
survived,"def test_replay_since_and_count(tmp_path: Path) -> None:
    path = tmp_path / ""audit.db""
    with logging.Ledger(str(path), broadcast=False) as led:
        led.log(messaging.Envelope(""a"", ""b"", {""x"": 1}, 0.0))
        led.log(messaging.Envelope(""b"", ""c"", {""y"": 2}, 1.0))

    with patch.object(cli.config.CFG, ""ledger_path"", str(path)):
        with patch.object(cli.time, ""sleep"", return_value=None):
            res = CliRunner().invoke(cli.main, [""replay"", ""--since"", ""0.5"", ""--count"", ""1""])

    lines = [ln.strip() for ln in res.output.splitlines() if ln.strip()]
    assert len(lines) == 1
    assert ""b -> c"" in lines[0]
",tests/test_demo_cli.py,,1,9.237449576640118e-09,"The method 'test_replay_since_and_count' is a unit test function that verifies the functionality of a command-line interface (CLI) tool. It uses temporary paths, mocks, and assertions to ensure that the 'replay' command works as expected. Unit tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, this method is likely to be retained as it serves an important role in the software development process."
survived,"def parse_expected_hash(service_worker: Path) -> str:
    text = service_worker.read_text()
    match = re.search(r""WORKBOX_SW_HASH\s*=\s*['\""]([^'\""]+)['\""]"", text)
    if not match:
        raise ValueError(""WORKBOX_SW_HASH not found"")
    return match.group(1)
",scripts/verify_workbox_hash.py,,1,1.1032560311263802e-09,"The method 'parse_expected_hash' is a utility function that reads a file and extracts a specific pattern using regular expressions. This type of function is commonly used in software development for configuration or validation purposes. It is well-defined, performs a specific task, and raises an appropriate exception if the expected pattern is not found. These characteristics make it a useful and reusable piece of code, suggesting that it is likely to be retained in the codebase."
survived,"    async def run_manager(manager: DummyManager, *args: object, **kwargs: object) -> None:
        await manager.run()
",test/windows/test_shutdown.py,,1,6.69158608681505e-10,"The method 'run_manager' is a simple asynchronous function that calls the 'run' method on a 'DummyManager' instance. It is likely to be a utility function used to execute the manager's run method asynchronously. Since it serves a clear purpose and is straightforward, it is likely to be retained in the codebase unless the 'DummyManager' class or its 'run' method is removed or significantly refactored. Therefore, the method is predicted to survive."
survived,"async def test_self_improver_agent_rollback(monkeypatch, tmp_path: Path) -> None:
    repo_dir = tmp_path / ""repo""
    repo_dir.mkdir()
    _init_repo(repo_dir)
    patch = """"""--- a/metric.txt\n+++ b/metric.txt\n@@\n-1\n+2\n""""""
    patch_file = tmp_path / ""p.diff""
    patch_file.write_text(patch)
    bus = messaging.A2ABus(config.Settings(bus_port=0))
    agent = SelfImproverAgent(bus, DummyLedger(), str(repo_dir), str(patch_file), allowed=[""metric.txt""])
    orig_commit = git.Repo(repo_dir).head.commit.hexsha
    def fail_commit(self, *a, **k):
        raise RuntimeError(""boom"")
    monkeypatch.setattr(git.index.base.IndexFile, ""commit"", fail_commit)
    with pytest.raises(RuntimeError):
        await agent.run_cycle()
    assert git.Repo(repo_dir).head.commit.hexsha == orig_commit
    assert (repo_dir / ""metric.txt"").read_text().strip() == ""1""
    REGISTRY._names_to_collectors.clear()
    REGISTRY._collector_to_names.clear()",tests/test_self_improver.py,,1,1.725782769012759e-08,"The method is a test function for a self-improving agent's rollback mechanism. It uses a monkeypatch to simulate a failure during a commit and checks if the rollback is successful. This is a crucial part of testing the robustness of the agent, ensuring that it can handle errors gracefully. Such tests are essential for maintaining software reliability, especially in systems that involve automated changes. Therefore, it is likely to be retained as part of the test suite."
survived,"        def _cookie_key(k):
            return b""plain.http.cookies"" + force_bytes(k)
",plain/plain/http/response.py,ResponseBase,1,1.6052280526088547e-09,"The method '_cookie_key' is a utility function that is likely used internally to generate a specific key format for cookies. It is a simple and efficient way to ensure consistency in how cookie keys are handled within the application. Since it is a private method (indicated by the underscore prefix) and serves a clear purpose, it is unlikely to be deleted unless the entire mechanism for handling cookies is refactored or removed. Therefore, it is more likely to survive."
survived,"    def __init__(
        self,
        api_token: str = None,
        timeout: int = 60,
        proxies: dict = {},
        logging: bool = True
    ):
        """"""Initialize your HuggingFace provider with custom settings! ⚙️

        Args:
            api_token (str, optional): HuggingFace API token. Uses env var ""HUGGINGFACE_API_TOKEN"" if None
            timeout (int): Request timeout in seconds (default: 60)
            proxies (dict): Proxy settings for requests (default: {})
            logging (bool): Enable fire logging (default: True)
        """"""
        self.base_url = ""https://api-inference.huggingface.co/models/""
        self.api_token = api_token or os.environ[""HUGGINGFACE_API_TOKEN""]
        self.headers = {
            ""Authorization"": f""Bearer {self.api_token}"",
            ""User-Agent"": agent.random(),
            ""Accept"": ""application/json""
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)
        self.session.proxies.update(proxies)
        self.timeout = timeout
        self.prompt: str = ""AI-generated image - webscout""
        self.image_extension: str = ""jpg""
        self.logging = logging
        if self.logging:
            logger.info(""HuggingFace provider initialized! 🚀"")
",webscout/Provider/TTI/huggingface.py,HFimager,1,8.76424914819242e-08,"The method is a constructor (__init__) for initializing an object with specific settings, which is a fundamental part of object-oriented programming. It sets up necessary configurations such as API tokens, headers, and session settings, which are crucial for the functionality of the class. Such methods are typically not deleted unless the entire class is being refactored or removed, which is not indicated here."
survived,"def count_tokens(text_or_messages: Any) -> int:
    """"""
    Count tokens in a string or a list of messages using tiktoken if available, else fallback to webstoken's WordTokenizer.

    Args:
        text_or_messages: A string or a list of messages (string or any type).
        model: Optional model name for tiktoken encoding.

    Returns:
        int: Number of tokens.
    """"""
    try:
        import tiktoken
        # Use tiktoken if available
        if isinstance(text_or_messages, str):
            enc = tiktoken.encoding_for_model(""gpt-4o"")
            return len(enc.encode(text_or_messages))
        elif isinstance(text_or_messages, list):
            enc = tiktoken.encoding_for_model(""gpt-4o"")
            total = 0
            for m in text_or_messages:
                # Remove .get('content', '') and treat m as string or convert to string
                if isinstance(m, str):
                    total += len(enc.encode(m))
                else:
                    total += len(enc.encode(str(m)))
            return total
        else:
            return 0
    except ImportError:
        # Fallback to webstoken's WordTokenizer
        try:
            from webstoken import WordTokenizer
        except ImportError:
            return 0
        tokenizer = WordTokenizer()
        if isinstance(text_or_messages, str):
            return len(tokenizer.tokenize(text_or_messages))
        elif isinstance(text_or_messages, list):
            total = 0
            for m in text_or_messages:
                if isinstance(m, str):
                    total += len(tokenizer.tokenize(m))
                else:
                    total += len(tokenizer.tokenize(str(m)))
            return total
        else:
            return 0",webscout/Provider/TTI/utils.py,,1,1.0467401685178159e-08,"The method is likely to survive because it provides a useful functionality of counting tokens in a string or list of messages, which is a common requirement in text processing tasks. It also includes a fallback mechanism to ensure functionality even if the primary library is unavailable, increasing its robustness and adaptability."
survived,"    def save(
        self,
        response: List[bytes],
        name: Optional[str] = None,
        dir: Optional[Union[str, Path]] = None,
        filenames_prefix: str = """",
    ) -> List[str]:
        """"""Save your fire generated images! 💾

        Examples:
            >>> provider = AIArtaImager()
            >>> images = provider.generate(""Cool art"")
            >>> # Save with default settings
            >>> paths = provider.save(images)
            >>> # Save with custom name and directory
            >>> paths = provider.save(
            ...     images,
            ...     name=""my_art"",
            ...     dir=""my_images"",
            ...     filenames_prefix=""test_""
            ... )

        Args:
            response (List[bytes]): Your generated images
            name (Optional[str]): Custom name for your images
            dir (Optional[Union[str, Path]]): Where to save the images (default: current directory)
            filenames_prefix (str): Prefix for your image files

        Returns:
            List[str]: Paths to your saved images
        """"""
        save_dir = dir if dir else os.getcwd()
        if not os.path.exists(save_dir):
            os.makedirs(save_dir)

        name = self.prompt if name is None else name
            
        # Clean up name for filename use
        safe_name = """".join(c if c.isalnum() or c in ""_-"" else ""_"" for c in name)
        safe_name = safe_name[:50]  # Truncate if too long
            
        filenames = []
        count = 0

        for image in response:
            def complete_path():
                count_value = """" if count == 0 else f""_{count}""
                return os.path.join(save_dir, filenames_prefix + safe_name + count_value + ""."" + self.image_extension)

            while os.path.isfile(complete_path()):
                count += 1

            filepath = complete_path()
            filenames.append(os.path.basename(filepath))

            with open(filepath, ""wb"") as fh:
                fh.write(image)
        return filenames
",webscout/Provider/TTI/aiarta.py,AIArtaImager,1,2.0611536181902033e-09,"The method is well-documented, provides a clear and useful functionality, and includes examples for usage. It handles optional parameters, ensures directory existence, and manages file naming conflicts. These factors suggest it is a valuable and robust method that is likely to be retained."
survived,"    def generate(
        self, 
        prompt: str, 
        amount: int = 1, 
        additives: bool = True,
        model: str = ""flux-3d"", 
        width: int = 768, 
        height: int = 768, 
        seed: Optional[int] = None,
        max_retries: int = 3, 
        retry_delay: int = 5
    ) -> List[bytes]:
        """"""Generate some fire images from your prompt! 🎨

        Examples:
            >>> provider = AiForceimager()
            >>> # Basic usage
            >>> images = provider.generate(""Cool art"")
            >>> # Advanced usage
            >>> images = provider.generate(
            ...     prompt=""Epic dragon"",
            ...     amount=3,
            ...     model=""Flux-1.1-Pro""
            ... )

        Args:
            prompt (str): Your image description
            amount (int): How many images you want (default: 1)
            additives (bool): Make each prompt unique (default: True)
            model (str): Model to use - check AVAILABLE_MODELS (default: ""Flux-1.1-Pro"")
            width (int): Image width (default: 768)
            height (int): Image height (default: 768)
            seed (int, optional): Seed for reproducible results
            max_retries (int): Max retry attempts if something fails (default: 3)
            retry_delay (int): Seconds to wait between retries (default: 5)

        Returns:
            List[bytes]: Your generated images

        Raises:
            ValueError: If the inputs ain't valid
            RequestException: If the API calls fail after retries
        """"""
        assert bool(prompt), ""Prompt cannot be null""
        assert isinstance(amount, int), f""Amount should be an integer only not {type(amount)}""
        assert amount > 0, ""Amount should be greater than 0""
        assert model in self.AVAILABLE_MODELS, f""Model should be one of {self.AVAILABLE_MODELS}""

        ads = lambda: (
            """"
            if not additives
            else choice(punctuation)
            + choice(punctuation)
            + choice(punctuation)
            + choice(punctuation)
            + choice(punctuation)
        )

        self.prompt = prompt
        response = []
        for _ in range(amount):
            url = f""{self.api_endpoint}?model={model}&prompt={prompt}&size={width}:{height}""
            if seed:
                url += f""&seed={seed}""
            
            for attempt in range(max_retries):
                try:
                    resp = self.session.get(url, timeout=self.timeout)
                    resp.raise_for_status()
                    response.append(resp.content)
                    break
                except RequestException as e:
                    if attempt == max_retries - 1:
                        raise
                    else:
                        time.sleep(retry_delay)

        return response
",webscout/Provider/TTI/aiforce.py,AiForceimager,1,4.944450477491054e-09,"The method 'generate' is a well-defined function that provides a clear and useful functionality for generating images based on a prompt. It includes error handling, retries for network requests, and allows for customization through various parameters. The method is likely to be used frequently in applications that require image generation, making it a valuable part of the codebase. Therefore, it is unlikely to be deleted."
survived,"    def _create_payload(self, prompt: str) -> Dict[str, Any]:
        """"""Create the API request payload 📦

        Args:
            prompt (str): The image generation prompt

        Returns:
            Dict[str, Any]: API request payload
        """"""
        return {
            ""type"": ""image"",
            ""messagesHistory"": [
                {
                    ""id"": str(uuid.uuid4()),
                    ""from"": ""you"",
                    ""content"": prompt
                }
            ],
            ""settings"": {
                ""model"": ""gpt-4o-mini""  # Or another suitable model if available
            }
        }
",webscout/Provider/TTI/talkai.py,TalkaiImager,1,4.0586521248284276e-10,"The method '_create_payload' is well-defined and serves a clear purpose: constructing a payload for an API request. It includes necessary components such as a unique message ID, the prompt content, and model settings. The method is likely to be useful in contexts where API requests for image generation are needed, and it follows good practices by documenting its purpose and parameters. There is no indication of redundancy or obsolescence, suggesting it will survive."
survived,"    def save(
        self,
        response: List[bytes],
        name: Optional[str] = None,
        dir: Optional[Union[str, Path]] = None,
        filenames_prefix: str = """",
    ) -> List[str]:
        """"""Save your fire generated images! 💾

        Examples:
            >>> provider = PiclumenImager()
            >>> images = provider.generate(""Cool art"")
            >>> # Save with default settings
            >>> paths = provider.save(images)
            >>> # Save with custom name and directory
            >>> paths = provider.save(
            ...     images,
            ...     name=""my_art"",
            ...     dir=""my_images"",
            ...     filenames_prefix=""test_""
            ... )

        Args:
            response (List[bytes]): Your generated images
            name (Optional[str]): Custom name for your images
            dir (Optional[Union[str, Path]]): Where to save the images (default: current directory)
            filenames_prefix (str): Prefix for your image files

        Returns:
            List[str]: Paths to your saved images
        """"""
        save_dir = dir if dir else os.getcwd()
        if not os.path.exists(save_dir):
            os.makedirs(save_dir)

        saved_paths = []
        timestamp = int(time.time())
        
        # Clean up name for filename use
        safe_name = """"
        if name:
            safe_name = """".join(c if c.isalnum() or c in ""_-"" else ""_"" for c in name)
            
        # Use prompt-based name if no name is provided
        if not safe_name and self.prompt:
            # Clean and truncate prompt for filename
            prompt_words = self.prompt.split()[:5]  # First 5 words
            safe_name = ""_"".join("""".join(c if c.isalnum() else ""_"" for c in word) for word in prompt_words).lower()
        
        for i, image_bytes in enumerate(response):
            if safe_name:
                filename = f""{filenames_prefix}{safe_name}_{i}.{self.image_extension}""
            else:
                filename = f""{filenames_prefix}piclumen_{timestamp}_{i}.{self.image_extension}""
            
            filepath = os.path.join(save_dir, filename)
            
            with open(filepath, ""wb"") as f:
                f.write(image_bytes)
            
            saved_paths.append(filepath)

        return saved_paths
",webscout/Provider/TTI/piclumen.py,PiclumenImager,1,5.60279640614594e-09,"The method 'save' is well-documented, has a clear purpose, and provides flexibility in saving images with custom names and directories. It handles default values, checks for directory existence, and ensures filenames are safe for the filesystem. These features make it a useful utility function for saving images, which is a common requirement in image processing applications. Therefore, it is likely to be retained."
survived,"            def complete_path():
                count_value = """" if count == 0 else f""_{count}""
                return os.path.join(dir, name + count_value + ""."" + self.image_extension)
",webscout/Provider/TTI/huggingface.py,HFimager,0,0.9999999985833912,"The method 'complete_path' is likely to be deleted (0) because it references variables 'count', 'dir', 'name', and 'self.image_extension' that are not defined within the method or passed as parameters. This suggests that the method relies on external state, which can lead to errors or unexpected behavior if those variables are not properly managed. Additionally, the method lacks documentation or context, making it unclear how it fits into the larger codebase. Without further information or refactoring to make it self-contained, it is prone to being removed or replaced."
survived,"    def save(
        self,
        response: List[bytes],
        name: Optional[str] = None,
        dir: Optional[Union[str, Path]] = None,
        filenames_prefix: str = """",
    ) -> List[str]:
        """"""Save your fire generated images! 💾

        Examples:
            >>> provider = NexraImager()
            >>> images = provider.generate(""Cool art"")
            >>> # Save with default settings
            >>> paths = provider.save(images)
            >>> # Save with custom name and directory
            >>> paths = provider.save(
            ...     images,
            ...     name=""my_art"",
            ...     dir=""my_images"",
            ...     filenames_prefix=""test_""
            ... )

        Args:
            response (List[bytes]): Your generated images
            name (Optional[str]): Custom name for your images
            dir (Optional[Union[str, Path]]): Where to save the images (default: current directory)
            filenames_prefix (str): Prefix for your image files

        Returns:
            List[str]: Paths to your saved images
        """"""
        save_dir = dir if dir else os.getcwd()
        if not os.path.exists(save_dir):
            os.makedirs(save_dir)
            if self.logging:
                logger.info(f""Created directory: {save_dir} 📁"")

        name = self.prompt if name is None else name
        filenames = []

        if self.logging:
            logger.info(f""Saving {len(response)} images... 💾"")
        for i, image in enumerate(response):
            filename = f""{filenames_prefix}{name}_{i}.{self.image_extension}""
            filepath = os.path.join(save_dir, filename)

            with open(filepath, ""wb"") as fh:
                fh.write(image)
            filenames.append(filename)
            if self.logging:
                logger.success(f""Saved image to: {filepath} 💾"")

        if self.logging:
            logger.success(f""Images saved successfully! Check {dir} 🎉"")
        return filenames
",webscout/Provider/TTI/nexra.py,NexraImager,1,1.725782769012759e-08,"The method is well-documented, provides a clear and useful functionality for saving images, and includes logging for better traceability. It is likely to be retained as it serves a practical purpose in the context of image generation and storage."
survived,"    def to_string(value) -> str:
        if isinstance(value, str):
            return value
        elif isinstance(value, dict):
            if ""text"" in value:
                return value.get(""text"", """")
            return """"
        elif isinstance(value, list):
            return """".join([to_string(v) for v in value])
        return str(value)
",webscout/Provider/TTI/utils.py,,1,7.582560422162384e-10,"The method 'to_string' is a utility function that converts various data types into a string representation. It handles strings, dictionaries, lists, and other types, making it versatile and useful in many scenarios where data needs to be converted to a string format. Such utility functions are common in codebases to ensure consistent data handling and are unlikely to be deleted unless they are replaced by a more efficient or comprehensive solution. Therefore, the method is likely to survive."
survived,"    def _create_payload(self, prompt: str, model: str, style: str, aspect_ratio: str) -> dict:
        """"""Create the API request payload 📦

        Args:
            prompt (str): The image generation prompt
            model (str): Model to use
            style (str): Style to apply
            aspect_ratio (str): Aspect ratio

        Returns:
            dict: API request payload
        """"""
        return {
            ""prompt"": prompt,
            ""model"": model,
            ""style"": style,
            ""aspect_ratio"": aspect_ratio
        }
",webscout/Provider/TTI/pixelmuse.py,PixelMuseImager,1,7.194132978569833e-09,"The method '_create_payload' is a utility function that constructs a dictionary to be used as a payload for an API request. It is well-documented, clearly defines its purpose, and is likely a necessary part of a larger system that interacts with an API. Such methods are common in codebases that deal with external services, and there is no indication that it is redundant or obsolete. Therefore, it is likely to be retained in the codebase."
survived,"def grad_of_fn(klong, fn, x):
    """"""Return gradient of Klong or Python function ``fn`` at ``x``.""""""
    def call_fn(v):
        if isinstance(fn, (KGSym, KGLambda)):
            return klong.call(KGCall(fn, [v], 1))
        elif isinstance(fn, KGCall):
            return klong.call(KGCall(fn.a, [v], fn.arity))
        elif isinstance(fn, KGFn):
            return klong.call(KGCall(fn.a, [v], fn.arity))
        else:
            return fn(v)
    return numeric_grad(call_fn, x)",klongpy/autograd.py,,1,7.194132978569833e-09,"The method 'grad_of_fn' is a utility function that calculates the gradient of a given function 'fn' at a point 'x'. It is a specialized function that handles different types of function objects (KGSym, KGLambda, KGCall, KGFn) and uses a helper function 'numeric_grad' to compute the gradient. This method is likely to be useful in contexts where automatic differentiation or gradient computation is needed, such as in optimization or machine learning tasks. Since it provides a specific and useful functionality, it is likely to be retained in the codebase."
survived,"def eval_monad_track(a):
    """"""

        ˙a                                                    [Track]

        Identity operator used when marking values for gradient tracking.

    """"""
    return a
",klongpy/monads.py,,0,0.9999546021442518,"The method 'eval_monad_track' is a simple identity function that returns its input without any modification. Such functions are often used in contexts where a consistent interface is required, or for marking or tracking purposes, as suggested by the comment. However, the function itself does not perform any meaningful computation or transformation, which might lead to its deletion if it is deemed unnecessary or if there are no use cases that justify its existence. Without additional context or usage, it is likely to be considered redundant."
survived,"def test_with_retry_sync(monkeypatch: pytest.MonkeyPatch) -> None:
    monkeypatch.setattr(retry, ""backoff"", None)
    calls = {""n"": 0}

    def func() -> str:
        calls[""n""] += 1
        if calls[""n""] < 3:
            raise ValueError(""boom"")
        return ""ok""

    wrapped = retry.with_retry(func, max_tries=3)
    assert wrapped() == ""ok""
    assert calls[""n""] == 3
",tests/test_retry_wrapper.py,,1,9.056076988852742e-11,"The method 'test_with_retry_sync' is a unit test function that tests the retry functionality of a function wrapped with a retry mechanism. It uses the 'monkeypatch' fixture from pytest to modify the behavior of the 'retry' module for testing purposes. The test ensures that the function 'func' is retried the correct number of times before succeeding. This is a typical use case in testing to ensure robustness and correctness of retry logic, which is a common pattern in software development. Therefore, the method is likely to be useful for maintaining the reliability of the retry feature and will survive."
survived,"    async def close(self) -> None:
        pass",src/aiohttp/__init__.py,ClientSession,1,0.006692851410316465,"The method 'close' is defined as an asynchronous function but contains only a 'pass' statement, meaning it currently does nothing. If this method is part of a larger class or module where a 'close' operation is expected to perform some cleanup or resource deallocation, it is likely that this method will be implemented in the future. However, if there is no such requirement or if the method is not used anywhere, it might be deleted. Without additional context, it's difficult to determine its necessity, but generally, placeholder methods like this are often kept for future implementation, especially in asynchronous contexts where resource management is crucial."
survived,"            def __init__(self, *_, **__):
                pass
",src/meta_agent/services/llm_service.py,AiohttpPlaceholder.ClientSession,0,0.9999952149051502,"The method is a constructor (__init__) that takes arbitrary positional and keyword arguments but does nothing with them. This is typically not useful unless it's a placeholder or part of a larger framework where the arguments are handled elsewhere. Without additional context or functionality, this method is likely to be considered unnecessary and could be removed to clean up the code."
survived,"    def set_verbosity(self, verbosity: int) -> None:
        """"""Set the current verbosity level.""""""
        self.verbosity = verbosity
",src/meta_agent/ux/cli_output.py,CLIOutput,1,3.3982678079468468e-09,"The method `set_verbosity` is a simple setter method that allows the user to set the verbosity level of an object. Such methods are common in object-oriented programming as they provide a way to encapsulate the internal state of an object and allow controlled access to it. This method is likely to be useful in scenarios where the verbosity level needs to be adjusted dynamically, such as in logging or debugging contexts. Therefore, it is unlikely to be deleted as it serves a clear purpose in managing the object's state."
survived,"    def form(self, fields: Sequence[str]) -> dict[str, str]:
        """"""Prompt for multiple fields and return a mapping of answers.""""""
        responses: dict[str, str] = {}
        for field in fields:
            responses[field] = self.ask(f""{field}:"")
        return responses",src/meta_agent/ux/interactive.py,Interactive,1,2.0611536181902033e-09,"The method 'form' is a utility function that prompts for multiple fields and returns a dictionary mapping each field to its response. This is a common pattern in applications that require user input, such as command-line interfaces or form handling in web applications. The method is straightforward, useful, and does not contain any deprecated or harmful practices. Therefore, it is likely to be retained in the codebase."
survived,"    def test_cvar(self):
        returns = [-0.1, 0.2, -0.05, 0.03]
        expected = 0.1
        self.assertAlmostEqual(finance_agent._cvar(returns), expected)
",tests/test_finance_utils.py,TestFinanceUtils,1,1.0467401685178159e-08,"The method `test_cvar` is a unit test for the `_cvar` function, which likely calculates the Conditional Value at Risk (CVaR) of a set of returns. Unit tests are crucial for ensuring the correctness of code, especially in financial calculations where accuracy is important. The test checks if the CVaR calculation is close to an expected value, which is a common practice in test-driven development. Therefore, this method is likely to be retained as it serves an important role in validating the functionality of the `_cvar` method."
survived,"    def test_run_cycle_publishes(self, mock_refresh, mock_publish):
        asyncio.run(self.agent.run_cycle())
        mock_refresh.assert_awaited()
        mock_publish.assert_called()
",tests/test_energy_agent_behavior.py,TestEnergyAgentBehavior,1,5.905303995456778e-10,"The method `test_run_cycle_publishes` is a unit test method that verifies the behavior of the `run_cycle` method of an `agent` object. It uses mock objects to ensure that `refresh` and `publish` methods are called as expected. This is a typical pattern in unit testing to ensure that certain methods are invoked during the execution of a function. Since testing is a crucial part of software development to ensure code reliability and correctness, this method is likely to be retained. Therefore, it will survive."
survived,"            async def step(self):
                return None
",tests/test_agents_registry.py,TestVersionOverride.AgentOld,0,0.9999993524053853,"The method 'step' is an asynchronous function that currently does nothing but return None. If this method is part of a larger codebase, it might be a placeholder for future implementation. However, if it remains unchanged and unused, it is likely to be deleted in the future as it serves no functional purpose. Without additional context on its intended use or future plans, the method is more likely to be removed to clean up the code."
survived,"    def test_demo_init_files(self) -> None:
        """"""Every demo directory is importable as a package.""""""
        base = Path(validate_demos.DEFAULT_DIR)
        for path in base.iterdir():
            if (
                path.is_dir()
                and not path.name.startswith(""."")
                and not path.name.startswith(""__"")
            ):
                self.assertTrue(
                    (path / ""__init__.py"").exists(),
                    f""Missing __init__.py in {path.name}"",
                )",tests/test_demos.py,TestDemos,1,1.3440409770490404e-08,"The method `test_demo_init_files` is a unit test that checks if every demo directory is importable as a package by verifying the presence of an `__init__.py` file. This is a useful test to ensure that the directory structure is correctly set up for Python package imports. The method is straightforward, performs a necessary check, and is likely part of a larger suite of tests ensuring the integrity of the demo directories. Therefore, it is likely to be retained as it serves a clear purpose in maintaining code quality."
survived,"    def test_policy_distribution(self):
        obs = self.mu.reset()
        policy = self.mu.policy(obs)
        self.assertEqual(len(policy), self.mu.action_dim)
        self.assertAlmostEqual(sum(policy), 1.0, places=2)
",tests/test_muzero_planning.py,TestMiniMu,1,1.0467401685178159e-08,"The method 'test_policy_distribution' is a unit test that checks the distribution of a policy generated by a model. It verifies that the policy has the correct length and that the probabilities sum to 1, which are essential checks for validating the correctness of a policy distribution in reinforcement learning or similar contexts. Such tests are crucial for ensuring the reliability and correctness of the model's behavior, especially in environments where actions are probabilistically determined. Therefore, this method is likely to be retained as it serves an important role in validating the functionality of the model."
survived,"async def seed_database(session: AsyncSession) -> None:
    """"""Populate the database with example data.""""""

    users = [
        User(
            username=""john_doe"",
            email=""john@example.com"",
            full_name=""John Doe"",
            created_at=datetime.now(),
        ),
        User(
            username=""jane_smith"",
            email=""jane@example.com"",
            full_name=""Jane Smith"",
            created_at=datetime.now(),
        ),
    ]
    session.add_all(users)

    products = [
        Product(
            name=""Laptop"",
            description=""High-performance laptop"",
            price=999.99,
            stock_quantity=50,
            category=""Electronics"",
            created_at=datetime.now(),
        ),
        Product(
            name=""Wireless Mouse"",
            description=""Ergonomic wireless mouse"",
            price=29.99,
            stock_quantity=200,
            category=""Electronics"",
            created_at=datetime.now(),
        ),
        Product(
            name=""USB-C Cable"",
            description=""Fast charging USB-C cable"",
            price=19.99,
            stock_quantity=500,
            category=""Accessories"",
            created_at=datetime.now(),
        ),
        Product(
            name=""Coffee Maker"",
            description=""Programmable coffee maker"",
            price=79.99,
            stock_quantity=30,
            category=""Appliances"",
            created_at=datetime.now(),
        ),
    ]
    session.add_all(products)
    await session.flush()

    order1 = Order(
        order_number=""ORD-001"",
        user_id=users[0].id,
        status=""delivered"",
        total_amount=1029.98,
        created_at=datetime.now(),
        updated_at=datetime.now(),
        shipping_address=""123 Main St, City, State 12345"",
    )
    order2 = Order(
        order_number=""ORD-002"",
        user_id=users[1].id,
        status=""processing"",
        total_amount=99.98,
        created_at=datetime.now(),
        updated_at=datetime.now(),
        shipping_address=""456 Oak Ave, Town, State 67890"",
    )
    session.add_all([order1, order2])
    await session.flush()

    items = [
        OrderItem(
            order_id=order1.id,
            product_id=products[0].id,
            quantity=1,
            unit_price=999.99,
            total_price=999.99,
        ),
        OrderItem(
            order_id=order1.id,
            product_id=products[1].id,
            quantity=1,
            unit_price=29.99,
            total_price=29.99,
        ),
        OrderItem(
            order_id=order2.id,
            product_id=products[3].id,
            quantity=1,
            unit_price=79.99,
            total_price=79.99,
        ),
        OrderItem(
            order_id=order2.id,
            product_id=products[2].id,
            quantity=1,
            unit_price=19.99,
            total_price=19.99,
        ),
    ]
    session.add_all(items)
",examples/sqlalchemy_shop/app.py,,1,3.2241866333029355e-08,"The method `seed_database` is a utility function designed to populate a database with initial or example data. Such methods are commonly used in development and testing environments to ensure that the database has the necessary data for testing application features. This method is well-structured, uses asynchronous operations which are suitable for modern Python applications, and provides a comprehensive set of example data across multiple entities (users, products, orders, and order items). Given its utility in setting up a test environment and its clean implementation, it is likely to be retained in the codebase."
survived,"def _utcnow_ms() -> str:
    return time.strftime(""%Y-%m-%dT%H:%M:%S"", time.gmtime()) + f"".{int((time.time()%1)*1000):03d}Z""
",alpha_factory_v1/demos/meta_agentic_agi_v2/agents/agent_base.py,,1,4.944450477491054e-09,"The method _utcnow_ms() is a utility function that returns the current UTC time in a specific string format with millisecond precision. This is a useful function for logging, timestamping, or any application that requires precise time tracking. The function is simple, efficient, and serves a clear purpose, making it likely to be retained in the codebase."
survived,"    def _risk_assess(self, prompt:str, response:str) -> float:
        # toy heuristic: long responses & code carry more risk
        return min(1.0, 0.1 + 0.9*(len(response)/4000))
",alpha_factory_v1/demos/meta_agentic_agi/agents/agent_base.py,Agent,1,4.1399375473943306e-08,"The method '_risk_assess' is a simple heuristic function that calculates a risk score based on the length of a response. It is a straightforward implementation that does not rely on complex logic or external dependencies, making it easy to understand and maintain. Such utility functions are often useful in various contexts where a quick risk assessment is needed based on response length. Therefore, it is likely to be retained in the codebase."
survived,"    def _risk_assess(self, prompt:str, response:str) -> float:
        # toy heuristic: long responses & code carry more risk
        return min(1.0, 0.1 + 0.9*(len(response)/4000))
",alpha_factory_v1/demos/meta_agentic_agi_v2/agents/agent_base.py,Agent,1,8.152020648014727e-09,"The method '_risk_assess' is a simple heuristic function that calculates a risk score based on the length of a response. It is a straightforward implementation that doesn't rely on complex logic or external dependencies, making it easy to maintain and understand. Such utility functions are often retained in codebases as they provide a quick and efficient way to perform specific calculations. Additionally, the method is encapsulated and doesn't affect other parts of the system, reducing the likelihood of it being removed unless the entire risk assessment approach is overhauled. Therefore, it is likely to survive."
survived,"    def idx():
        return VIEW_HTML
",alpha_factory_v1/demos/meta_agentic_agi/agents/agent_base.py,,0,0.9999982396568657,"The method `idx` is very minimal and lacks any parameters or functionality beyond returning a constant `VIEW_HTML`. Without context, it's unclear what `VIEW_HTML` represents or how this method fits into a larger codebase. If `VIEW_HTML` is a constant that is used frequently, this method might be useful for abstraction or future expansion. However, if `VIEW_HTML` is a simple constant that doesn't change, the method might be considered redundant and could be replaced by directly using the constant. Without additional context, it's more likely that this method will be deleted as it doesn't add significant value."
survived,"    def __init__(self): super().__init__(""safety"")
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,BasicSafetyAgent,1,5.60279640614594e-09,"The method is a constructor for a class, and it calls the constructor of its superclass with a specific argument ('safety'). This is a common pattern in object-oriented programming to ensure proper initialization of the class hierarchy. There is no indication that this method is redundant or incorrect, so it is likely to be retained in the codebase."
survived,"    def acquire(self, cost: float = 1.0):
        while True:
            now = time.perf_counter()
            elapsed = now - self._last
            self._last = now
            self._allow = min(self._tps, self._allow + elapsed * self._tps)
            if self._allow >= cost:
                self._allow -= cost
                return
            sleep = (cost - self._allow) / self._tps + 1e-3
            time.sleep(sleep)
",alpha_factory_v1/demos/meta_agentic_agi_v3/agents/agent_base.py,RateLimiter,1,3.3982678079468468e-09,"The method 'acquire' is implementing a rate-limiting algorithm, which is a common and useful functionality in many applications to control the rate of operations. The method uses a token bucket-like approach to ensure that operations do not exceed a specified rate (transactions per second, _tps). This is a well-established pattern for managing resource usage and preventing abuse or overloading of systems. Given its utility and the fact that it is correctly implemented, it is unlikely to be deleted unless the entire rate-limiting feature is removed or replaced with a different approach."
survived,"def _boot(path: str):
    module_path, cls_name = (MODROOT + path).rsplit(""."", 1)
    try:
        cls = getattr(importlib.import_module(module_path), cls_name)
        inst: Agent = cls()  # type: ignore
        LOG.info(""[BOOT] loaded real agent %s"", inst.name)
    except Exception as exc:
        class Stub(Agent):
            def handle(self, _msg):  # noqa
                LOG.debug(""[Stub:%s] ← %s"", cls_name, _msg)
        inst = Stub(cls_name)
        LOG.warning(""[BOOT] stubbed %s (%s)"", cls_name, exc)
    AGENTS[inst.name] = inst
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,,1,3.3982678079468468e-09,"The method '_boot' is likely to survive because it contains essential functionality for dynamically loading and instantiating classes based on a given path. This is a common pattern in systems that require modularity and flexibility, such as plugin systems or dynamic agent loading. The method also includes error handling to ensure that if the desired class cannot be loaded, a stub is created instead, which is a robust approach to maintain system stability. Additionally, the use of logging for both successful and failed operations indicates that the method is well-integrated into the system's monitoring and debugging processes."
survived,"    def __init__(self, env: MiniWorld):
        self.net = MuZeroTiny(env.size**2, 4).to(CFG.device)
        self.opt = optim.Adam(self.net.parameters(), CFG.lr)
        self.buffer : List[Tuple[np.ndarray,float]]=[]
        self.step_count=0
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,Learner,1,3.927863699585036e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes and states. This particular constructor initializes important components such as a neural network, an optimizer, and a buffer, which are likely crucial for the functionality of the class. Therefore, it is unlikely to be deleted."
survived,"    def __init__(self,
                 endpoint: str = ""openai:gpt-4o"",
                 temperature: float = 0.2,
                 max_tokens: int = 2048,
                 context_len: int = 8192,
                 stream: bool = False,
                 timeout: int = 120,
                 **extra):
        self.endpoint = endpoint
        self.temperature = temperature
        self.max_tokens = max_tokens
        self.context_len = context_len
        self.stream = stream
        self.timeout = timeout
        self.extra = extra
        self._backend, self._model = self._parse(endpoint)
        self._client = self._init_backend()
",alpha_factory_v1/demos/meta_agentic_agi_v2/agents/agent_base.py,LMClient,1,9.237449576640118e-09,"The method is a constructor (__init__) for a class, which is essential for initializing object instances with specific attributes. It sets up important parameters like endpoint, temperature, max_tokens, context_len, stream, and timeout, which are likely crucial for the functionality of the class. Additionally, it calls other methods (_parse and _init_backend) to further set up the object. Such methods are fundamental to the class's operation and are unlikely to be removed unless the entire class is refactored or deprecated."
survived,"    def forward(self, input_ids, labels=None):
        out = types.SimpleNamespace(loss=torch.tensor(0.0))
        return out
",tests/test_multi_contributor.py,DummyModel,0,0.999985261023967,"The method 'forward' is a placeholder or a stub, as it only returns a SimpleNamespace object with a loss attribute set to a tensor of 0.0. It doesn't perform any meaningful computation or processing of the input data. In a real-world scenario, especially in machine learning models, the 'forward' method is expected to perform significant operations like passing data through layers of a neural network. Since this method does not fulfill its intended purpose, it is likely to be deleted or replaced with a proper implementation."
survived,"def test_revive_rate() -> None:
    rng = random.Random(12345)
    agents = {""A"": True, ""B"": False}
    result = loop.run_loop(
        cost_budget=100.0,
        cost_per_cycle=1.0,
        revive_rate=10,
        agents=agents,
        rng=rng,
    )
    assert result.revives >= 1",tests/test_revive_rate.py,,1,3.927863699585036e-07,"The method `test_revive_rate` is a unit test function that checks if the `revive_rate` parameter in the `run_loop` function works as expected. It uses a fixed random seed to ensure reproducibility and asserts that the number of revives is at least 1. This is a typical test case to ensure that the functionality of reviving agents is working correctly. Since it is a test function, it is likely to be retained as part of the test suite to ensure the reliability of the codebase."
survived,"def _make_agent() -> safety_agent.SafetyGuardianAgent:
    cfg = config.Settings(bus_port=0)
    bus = DummyBus(cfg)
    led = DummyLedger()
    return safety_agent.SafetyGuardianAgent(bus, led)
",tests/test_codegen_safety.py,,1,2.998960815863541e-09,"The method _make_agent is a private helper function that creates and returns an instance of SafetyGuardianAgent. It is likely used internally within a module or class to encapsulate the creation logic of the agent. Since it is a utility function that simplifies the creation of a complex object, it is likely to be useful and thus will be Survived."
survived,"        def __init__(self, *a, **kw) -> None:
            self.action_dim = kw.get(""action_dim"", 2)
",alpha_factory_v1/demos/muzero_planning/minimuzero.py,MiniMuNet,1,3.2241866333029355e-08,"The method is a constructor for a class, indicated by the name `__init__`. Constructors are essential for initializing new objects in object-oriented programming. The method sets a default value for `action_dim` if it is not provided, which is a common and useful practice. Therefore, it is unlikely to be deleted as it serves a fundamental role in object initialization."
survived,"def parse_args(argv: list[str] | None = None) -> argparse.Namespace:
    ap = argparse.ArgumentParser(description=""Queue a job on the α‑AGI Marketplace"")
    ap.add_argument(""job_file"", nargs=""?"", default=str(Path(__file__).resolve().parent / ""examples"" / ""sample_job.json""))
    ap.add_argument(""--host"", default=DEFAULT_HOST, help=""Orchestrator host"")
    ap.add_argument(""--port"", type=int, default=DEFAULT_PORT, help=""Orchestrator port"")
    return ap.parse_args(argv)
",alpha_factory_v1/demos/alpha_agi_marketplace_v1/marketplace.py,,1,1.2501528648238603e-09,"The method 'parse_args' is a utility function that uses the argparse library to parse command-line arguments. This is a common and essential functionality in many command-line applications, allowing users to specify options and parameters when running a script. The method is well-defined, with default values and descriptions for each argument, making it user-friendly and robust. There is no indication that this method is obsolete or redundant, and it serves a clear purpose in the context of the application. Therefore, it is likely to be retained in the codebase."
survived,"    def test_load_job(self):
        path = Path(""alpha_factory_v1/demos/alpha_agi_marketplace_v1/examples/sample_job.json"")
        job = load_job(path)
        self.assertEqual(job[""agent""], ""finance"")
",alpha_factory_v1/tests/test_marketplace_client.py,MarketplaceClientTest,1,2.5109990926928157e-08,"The method `test_load_job` is a unit test that checks if the `load_job` function correctly loads a job from a JSON file and verifies that the 'agent' field is 'finance'. This is a typical test case that ensures the functionality of the `load_job` function, which is crucial for maintaining code quality and reliability. Unit tests are generally not deleted unless they are redundant or the functionality they test is removed. Since this test seems to be directly related to a specific functionality, it is likely to be retained."
survived,"def main(argv: list[str] | None = None) -> None:
    args = parse_args(argv)
    submit_job(args.job_file, args.host, args.port)
    print(f""Queued job {args.job_file} → {args.host}:{args.port}"")
",alpha_factory_v1/demos/alpha_agi_marketplace_v1/marketplace.py,,1,2.7894680920908113e-10,"The method 'main' is a typical entry point for a Python script, which is used to parse command-line arguments and execute a primary function of the script. It is a common pattern in Python programming to have a 'main' function that orchestrates the execution of the script. The method is functional, concise, and follows a standard practice, making it unlikely to be deleted unless the entire script is being refactored or removed. Therefore, it is more likely to survive."
survived,"    def test_missing_agent(self):
        client = MarketplaceClient()
        with self.assertRaises(ValueError):
            client.queue_job({})
",alpha_factory_v1/tests/test_marketplace_client.py,MarketplaceClientTest,1,7.194132978569833e-09,"The method 'test_missing_agent' is a unit test designed to verify that the 'queue_job' method of the 'MarketplaceClient' class raises a 'ValueError' when called with an empty dictionary. This is a valid and useful test case to ensure that the 'queue_job' method handles invalid input correctly. Unit tests are crucial for maintaining code quality and ensuring that methods behave as expected under various conditions. Therefore, this method is likely to be retained as part of the test suite."
survived,"    def test_run_headless(self):
        if not dependencies_available:
            self.skipTest(""demo dependencies missing"")
        orch = run_headless(steps=10)
        time.sleep(0.5)
        orch.stop = True
        self.assertGreaterEqual(len(orch.learners), 1)
        self.assertGreater(len(orch.learners[0].buffer), 0)
",alpha_factory_v1/tests/test_alpha_asi_world_model.py,TestAlphaASIWorldModel,1,1.0467401685178159e-08,"The method 'test_run_headless' is a unit test designed to verify the functionality of running a process in a headless mode. It checks for the availability of dependencies, runs the process, and then asserts certain conditions to ensure the process behaves as expected. Unit tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is unlikely that this method will be deleted as it serves an important role in the testing suite."
survived,"    def test_banner_colours(self):
        with mock.patch('builtins.print') as p:
            preflight.banner('msg', 'RED')
            p.assert_called_once()
            args, _ = p.call_args
            self.assertIn('msg', args[0])
            self.assertIn(preflight.COLORS['RED'], args[0])
            self.assertIn(preflight.COLORS['RESET'], args[0])
",alpha_factory_v1/tests/test_preflight.py,PreflightTest,1,2.998960815863541e-09,"The method 'test_banner_colours' is a unit test designed to verify the functionality of the 'banner' method in the 'preflight' module. It uses mocking to intercept print calls and checks if the correct color codes and message are included in the output. This is a standard practice in testing to ensure that the method behaves as expected. Since it is a well-structured test that serves a clear purpose in verifying code functionality, it is likely to be retained."
survived,"    def test_basic_routes(self):
        runners = {""foo"": DummyRunner()}
        app = _build_rest(runners)
        self.assertIsNotNone(app)
        client = TestClient(app)
        resp = client.get(""/agents"")
        self.assertEqual(resp.status_code, 200)
        self.assertEqual(resp.json(), [""foo""])

        resp = client.post(""/agent/foo/trigger"")
        self.assertEqual(resp.status_code, 200)
        self.assertTrue(resp.json().get(""queued""))",alpha_factory_v1/tests/test_orchestrator_rest.py,BuildRestTest,1,1.0261879630648829e-10,"The method 'test_basic_routes' is a unit test for a REST API application. It verifies that the application is correctly set up and that the basic routes are functioning as expected. The test checks if the application can be built, if the '/agents' endpoint returns the expected data, and if the '/agent/foo/trigger' endpoint responds correctly. These are fundamental tests for ensuring the reliability and correctness of the API, making it unlikely that this method would be deleted unless the entire API or its structure is significantly changed. Therefore, the method is likely to survive."
survived,"    def test_hash_embedder(self):
        emb = memf._load_embedder()
        vec = emb(""test"")
        self.assertEqual(len(vec), memf.CFG.VECTOR_DIM)
        self.assertTrue(all(isinstance(x, (float, int)) for x in vec))
",alpha_factory_v1/tests/test_memory_provider.py,EmbedderFallbackTest,1,9.237449576640118e-09,"The method `test_hash_embedder` is a unit test function that checks the functionality of the `memf._load_embedder()` method. It verifies that the embedder returns a vector of the correct length and that all elements in the vector are either floats or integers. This is a standard practice in software development to ensure that code behaves as expected. Unit tests are crucial for maintaining code quality and catching bugs early in the development process. Therefore, this method is likely to be retained as it serves an important role in testing the functionality of the embedder."
survived,"    def setUp(self):
        self.fabric = memf.MemoryFabric()
        # Avoid metrics context when Prometheus is absent
        memf._MET_V_SRCH = None
",alpha_factory_v1/tests/test_memory_provider.py,MemoryFabricFallbackTest,1,7.73442280641062e-08,"The method `setUp` is typically used in testing frameworks like `unittest` to set up the test environment before each test case is run. The code snippet shows that it initializes a `MemoryFabric` object and modifies a module-level variable `_MET_V_SRCH`. This setup is likely necessary for the tests that follow, ensuring that the environment is correctly configured and that certain conditions (like the absence of Prometheus) are accounted for. Since this is a standard practice in test setups and there is no indication that this setup is redundant or incorrect, it is likely to be retained."
survived,"def test_agents_status_names() -> None:
    with patch.object(cli.orchestrator, ""Orchestrator"") as orch_cls:
        orch = orch_cls.return_value
        runner_obj = type(""Runner"", (), {""agent"": type(""Agent"", (), {""name"": ""AgentZ""})()})()
        orch.runners = {""AgentZ"": runner_obj}
        result = CliRunner().invoke(cli.main, [""agents-status""])
    assert ""AgentZ"" in result.output
",tests/test_cli_runner_ext.py,,1,5.60279640614594e-09,"The method `test_agents_status_names` is a unit test that verifies the functionality of a command-line interface (CLI) command. It uses mocking to simulate the behavior of the `Orchestrator` class and checks if the output of the `agents-status` command includes the name of an agent. This is a typical pattern in testing CLI applications to ensure that the command produces the expected output. Since testing is a crucial part of software development to ensure code reliability and correctness, this method is likely to be retained."
survived,"def step(l):
    y = 0
    while y < l.h:
        x = 0
        while x < l.w:
            setCell(l.b, x, y, nextState(l.a, x, y))
            x = x + 1
        y = y + 1
    tmp = l.a
    l = dataclasses.replace(l, a=l.b)
    l = dataclasses.replace(l, b=tmp)
",tests/rosetta/transpiler/Python/conways-game-of-life.py,,0,0.9999991684720096,"The method 'step' is likely to be deleted because it contains a critical issue: it attempts to modify the 'l' object by reassigning it with 'dataclasses.replace', but this does not actually modify the original object outside the function. This is a common mistake when dealing with dataclasses in Python, as 'dataclasses.replace' returns a new instance rather than modifying the existing one. Additionally, the method lacks proper error handling and documentation, which are important for maintainability and understanding of the code. These factors suggest that the method may be removed or significantly refactored to address these issues."
survived,"def nextState(f, x, y):
    count = 0
    dy = -1
    while dy <= 1:
        dx = -1
        while dx <= 1:
            if not (dx == 0 and dy == 0) and state(f, x + dx, y + dy):
                count = count + 1
            dx = dx + 1
        dy = dy + 1
    return count == 3 or (count == 2 and state(f, x, y))
",tests/rosetta/transpiler/Python/conways-game-of-life.py,,1,1.522997951276035e-08,"The method `nextState` is a part of a common algorithm used in cellular automata, specifically Conway's Game of Life. This method calculates the next state of a cell based on its neighbors, which is a fundamental operation in this type of simulation. Given the popularity and educational value of Conway's Game of Life, methods like `nextState` are often retained in codebases for simulations, educational purposes, or as utility functions in larger projects. Therefore, it is likely to be retained."
survived,"def peelFirstEat(p):
    print(""mm, that "" + p.value + "" was good!"")
",tests/rosetta/transpiler/Python/constrained-genericity-4.py,,1,0.0002034270609875745,"The method 'peelFirstEat' is a simple function that prints a message using the 'value' attribute of the parameter 'p'. Without additional context, such as the class or type of 'p', it's difficult to determine its utility. However, the method seems to be a straightforward utility function that could be part of a larger codebase dealing with objects that have a 'value' attribute, possibly representing food items. If this function is part of a larger, actively maintained codebase where such functionality is needed, it is likely to survive. However, if it is standalone or part of a deprecated or unused module, it might be deleted. Given the lack of context, I'll assume it is part of a useful module."
survived,"def shuffle(xs):
    arr = xs
    i = len(arr) - 1
    while i > 0:
        j = _now() % (i + 1)
        tmp = arr[i]
        arr[i] = arr[j]
        arr[j] = tmp
        i = i - 1
    return arr
",tests/rosetta/transpiler/Python/concurrent-computing-1.py,,0,0.999999922655772,"The method is likely to be deleted because it uses a non-standard and potentially insecure way to shuffle a list. The use of '_now()' to generate random indices is not a reliable method for shuffling, as it depends on the current time, which can lead to predictable patterns. A more standard and secure approach would be to use Python's built-in 'random.shuffle()' function, which is specifically designed for this purpose and uses a robust random number generator."
survived,"    def __str__(self) -> str:
        type_repr = self.type
        if self.mutable and ""mutable"" not in type_repr:
            type_repr = f""{type_repr}, mutable""
        return f""- **{self.name}** ({type_repr}): {self.description}""
",src/enrichmcp/datamodel.py,FieldDescription,1,8.152020648014727e-09,"The method `__str__` is a standard Python method used to provide a string representation of an object. This implementation is customized to include specific attributes of the object, such as `name`, `type`, and `description`, and it also conditionally appends 'mutable' to the type representation if applicable. This kind of method is useful for debugging and logging purposes, making it likely to be retained in the codebase."
survived,"    def delete_stale_entries(self, stale_after: timedelta) -> None:
        """"""Remove stale entries from the in-memory cache.""""""
        now = datetime.now()
        with self.lock:
            keys_to_delete = [
                k for k, v in self.cache.items() if now - v.time > stale_after
            ]
            for key in keys_to_delete:
                del self.cache[key]",src/cachier/cores/memory.py,_MemoryCore,1,3.653482080241728e-08,"The method 'delete_stale_entries' is a utility function that helps in maintaining the efficiency of an in-memory cache by removing outdated entries. This is a common requirement in cache management to ensure that the cache does not grow indefinitely and only contains relevant data. The method is well-defined, uses a lock to ensure thread safety, and is likely to be useful in any application that uses caching. Therefore, it is unlikely to be deleted."
survived,"def list_envs() -> List[str]:
    """"""Return available environment names.""""""
    return sorted(_ENV_REG.keys())
",alpha_factory_v1/backend/world_model.py,,1,4.0586521248284276e-10,"The method 'list_envs' is a simple utility function that returns a sorted list of environment names from a dictionary '_ENV_REG'. Such utility functions are often useful in larger systems for retrieving and displaying available options to users or for internal processing. Since it provides a clear and straightforward functionality without any apparent issues, it is likely to be retained in the codebase."
survived,"    async def __aexit__(self, exc_type, exc, tb) -> None:
        ...
",alpha_factory_v1/backend/types.py,TradeBrokerProtocol,1,1.4166087846364157e-09,"The method `__aexit__` is a special method used in asynchronous context managers in Python. It is part of the asynchronous context management protocol, which is essential for managing resources in asynchronous programming. Given the increasing use of asynchronous programming in Python, especially with the popularity of frameworks like asyncio, this method is likely to be retained as it is fundamental to the language's asynchronous capabilities."
survived,"    async def submit_order(
        self,
        symbol: str,
        qty: float,
        side: str,
        type: str = ""market"",
    ) -> str:
        """"""Place an order and return the broker-specific order identifier.""""""
",alpha_factory_v1/backend/types.py,TradeBrokerProtocol,1,1.725782769012759e-08,"The method 'submit_order' is a fundamental part of trading applications, as it allows users to place orders in the market. The method is asynchronous, which is suitable for handling network operations like submitting orders to a broker's API. It includes parameters for the symbol, quantity, side (buy/sell), and type of order, which are all essential for executing trades. The method's purpose is clear and it returns a broker-specific order identifier, which is crucial for tracking and managing orders. Given its importance in trading systems, it is unlikely to be deleted."
survived,"    async def get_position(self, symbol: str) -> float:
        """"""Return the signed position for ``symbol`` in shares.""""""
",alpha_factory_v1/backend/types.py,TradeBrokerProtocol,1,3.3982678079468468e-09,"The method `get_position` is an asynchronous function that returns the signed position for a given symbol in shares. This type of method is essential in financial applications where tracking the position of a stock or asset is crucial for decision-making processes. The method is likely part of a larger system that deals with trading or portfolio management, where knowing the position is fundamental. Therefore, it is unlikely to be deleted as it serves a core functionality in such systems."
survived,"        def __call__(self, prompt: str) -> str:
            return llm_client.call_local_model([{""role"": ""user"", ""content"": prompt}])
",alpha_factory_v1/demos/self_healing_repo/agent_selfheal_entrypoint.py,OpenAIAgent,1,1.955568070542584e-08,"The method is likely to be Survived (1) because it provides a clear and direct interface for calling a local language model using a prompt. The method is simple, with a single responsibility, and it leverages an existing client (`llm_client`) to perform its task. This makes it a useful and reusable component in a system that interacts with language models."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/outer_join.py,Auto1,0,0.9996646499458114,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, making it a candidate for deletion or refactoring."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/group_by_sort.py,Item,0,0.999860177965895,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose could lead to confusion and incorrect behavior when the method is used. Therefore, it is likely that this method will be deleted or refactored to align with its intended use."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/save_jsonl_stdout.py,Person,0,0.9999910602998366,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/group_by_left_join.py,Order,0,0.999915188952306,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose suggests that it might be deleted or refactored to align with its conventional use."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/in_operator_extended.py,Auto1,0,0.9999921107349486,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/left_join.py,Customer,1,0.00037998455641741793,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually implemented to check for membership in a collection like a list, set, or dictionary. However, if the class is designed to treat its attributes as keys in a collection, this implementation could be valid. Without additional context, it's difficult to determine if this is the intended use. If the class is indeed using its attributes as a collection, this method could be useful. Otherwise, it might be misleading or incorrect. Given the ambiguity, the method might survive if the class context supports this usage."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/join_multi.py,Item,0,0.999860177965895,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually used to check for membership in a collection like a list, set, or dictionary. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior expected from `__contains__`. Therefore, it is likely that this method will be deleted or refactored to better fit its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/group_by_multi_join_sort.py,Nation,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/group_by_multi_join_sort.py,Auto2,0,0.999999057755336,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys. However, this implementation uses `hasattr`, which checks if an object has an attribute with the given name. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This could lead to confusion and incorrect usage, as it does not align with the typical use case of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"        def multi_cell(self, *args, **kwargs):
            pass
",tests/conftest.py,DummyFPDF,0,0.9999999990263799,"The method 'multi_cell' is defined but not implemented, as it only contains a 'pass' statement. This suggests that it is a placeholder for future functionality or is meant to be overridden in a subclass. Without any implementation or documentation indicating its purpose, it is likely to be removed if it remains unused or unimplemented. Therefore, the method is predicted to be deleted."
survived,"def test_remove_question_and_ampersand():
    assert remove_chars('Where & When?') == 'Where and When'
    assert remove_chars('Q? & A?') == 'Q and A'
    assert remove_chars('This & That & Those') == 'This and That and Those'
    assert remove_chars('??What?') == 'What'
    assert remove_chars(' weird??? &?? ') == 'weird and'
",tests/test_remove_chars.py,,1,1.955568070542584e-08,"The method 'test_remove_question_and_ampersand' is a test function that checks the functionality of a method 'remove_chars'. It is a useful test case to ensure that the 'remove_chars' function correctly replaces ampersands with 'and' and removes question marks. Test functions are generally not deleted unless they are redundant or incorrect. Since this test function appears to be well-structured and serves a clear purpose, it is likely to be retained."
survived,"    def Gauge(name: str, desc: str, labels=None):  # type: ignore[misc]
        return _get_metric(_Gauge, name, desc, labels)
",alpha_factory_v1/backend/agents/__init__.py,,1,1.4166087846364157e-09,"The method 'Gauge' is a simple wrapper function that calls another function '_get_metric' with specific parameters. It is likely part of a larger codebase dealing with metrics or monitoring, possibly in a system that uses Prometheus or a similar tool. The function is straightforward and serves a clear purpose, which is to create or retrieve a metric of type '_Gauge'. Unless there is a significant change in the requirements or the underlying system, such utility functions are generally retained as they encapsulate specific functionality and improve code readability. Therefore, it is likely to survive."
survived,"    def _get_metric(cls, name: str, desc: str, labels=None):
        if name in getattr(_REG, ""_names_to_collectors"", {}):
            return _REG._names_to_collectors[name]
        return cls(name, desc, labels) if labels else cls(name, desc)
",alpha_factory_v1/backend/agents/__init__.py,,1,1.0467401685178159e-08,"The method '_get_metric' is a utility function that checks if a metric with a given name already exists in a registry and returns it if it does. If not, it creates a new metric using the provided class. This is a common pattern in metric collection libraries to avoid duplicate metrics and ensure efficient metric management. The method is likely to be useful in its context and does not have any apparent issues that would warrant its deletion."
survived,"def convert(path: str) -> str:
    with open(path, ""r"", encoding=""utf-8"") as f:
        src = f.read()
    tree = ast.parse(src)
    conv = Converter(src)
    try:
        conv.visit(tree)
    except ConversionError as e:
        lines = src.splitlines()
        start = max(e.lineno - 2, 0)
        end = min(e.lineno + 1, len(lines))
        context = ""\n"".join(f""{i + 1}: {lines[i]}"" for i in range(start, end))
        raise ConversionError(
            f""{e} at line {e.lineno}: {e.line}\n{context}"", e.lineno, e.line
        )
    return ""\n"".join(conv.lines) + (""\n"" if conv.lines else """")
",tools/any2mochi/py/py2mochi.py,,1,9.237449576640118e-09,"The method 'convert' is a utility function that reads a file, parses its content into an abstract syntax tree (AST), and then processes it using a 'Converter' class. This type of functionality is common in code transformation or analysis tools, which are widely used in software development for tasks like code refactoring, linting, or transpiling. The method handles errors gracefully by providing context around the error location, which is a good practice in error handling. Given its utility and the fact that it is well-structured, it is likely to be retained in the codebase."
survived,"async def test_sqlalchemy_lifespan_creates_session_and_seeds():
    engine = create_async_engine(""sqlite+aiosqlite:///:memory:"")

    class Base(DeclarativeBase):
        pass

    class User(Base, EnrichSQLAlchemyMixin):
        __tablename__ = ""users""
        id: Mapped[int] = mapped_column(primary_key=True)

    seed_called = False

    async def seed(session: AsyncSession) -> None:
        nonlocal seed_called
        session.add(User(id=1))
        seed_called = True

    lifespan = sqlalchemy_lifespan(Base, engine, seed=seed, session_kwargs={""autoflush"": False})
    app = EnrichMCP(""Test"", ""Desc"")
    async with lifespan(app) as ctx:
        assert seed_called is True
        session_factory = ctx[""session_factory""]
        assert session_factory.kw[""autoflush""] is False
        async with session_factory() as session:
            result = await session.execute(select(User.id))
            assert result.scalar_one() == 1",tests/test_lifespan.py,,1,1.8553915987649156e-07,"The method is a test function for a specific feature in a codebase, which is to ensure that the SQLAlchemy lifespan creates a session and seeds data correctly. Test functions are generally not deleted unless they are testing deprecated or removed features. Since this function is testing a specific functionality related to session creation and seeding, it is likely to be retained as long as the feature it tests is relevant and in use."
survived,"    def DummyOpenAIAgent(*_a, **kw):
        recorded[""base_url""] = kw.get(""base_url"")
        return object()
",tests/test_agent_experience_entrypoint.py,,1,2.3823698451773172e-07,"The method `DummyOpenAIAgent` is a simple function that records a 'base_url' from its keyword arguments into a dictionary called `recorded`. It then returns a generic object. This function seems to be a placeholder or a mock function, likely used for testing purposes. Such functions are often retained in codebases for testing or development purposes, especially if they are used to simulate or stub out complex interactions with external systems like APIs. Therefore, it is likely to survive as it serves a specific purpose in testing or development environments."
survived,"    def click(self, *a, **k):
        pass
",tests/test_agent_experience_entrypoint.py,DummyButton,1,5.8291276786344415e-05,"The method 'click' is defined but not implemented, as it only contains a 'pass' statement. This suggests that it is a placeholder for future functionality or is meant to be overridden in a subclass. If the method is part of a base class or interface that is intended to be extended, it is likely to survive. However, if it is not used or overridden anywhere in the codebase, it might be considered for deletion during code cleanup. Without additional context, it's more likely to survive as a placeholder or interface method."
survived,"            async def step_once() -> None:
                evt = await queue.get()
                self.assertIsInstance(evt, dict)
",tests/test_era_experience.py,TestEraOfExperience,1,6.69158608681505e-10,"The method 'step_once' is an asynchronous function that retrieves an event from a queue and checks if it is a dictionary. This is a common pattern in asynchronous programming, especially in event-driven systems. The use of 'async' and 'await' indicates modern Python practices, and the method is likely part of a larger system that processes events. There is no indication of redundancy or obsolescence in the code snippet provided, suggesting that the method is still relevant and useful."
survived,"def init_config(env_file: str = "".env"") -> None:
    """"""Load environment variables and refresh :data:`CFG`.""""""

    _load_dotenv(env_file)
    _prefetch_vault()
    global CFG
    CFG = Settings()
",src/utils/config.py,,1,6.348800075736417e-09,"The method 'init_config' is a utility function designed to load environment variables and refresh a global configuration object. This is a common pattern in software development, especially in applications that rely on environment-specific settings. The function is simple, clear, and serves a specific purpose, which is essential for maintaining configuration consistency across different environments. There is no indication that this method is redundant or unnecessary, and it likely plays a crucial role in the application's configuration management. Therefore, it is likely to be retained."
deleted,"  async def test_dispense_custom_flow_rate(self):
    op = SingleChannelDispense(
      resource=self.plate.get_item(""A1""),
      offset=Coordinate.zero(),
      tip=self.tr.get_tip(""A1""),
      volume=100,
      flow_rate=200,
      liquid_height=10,
      blow_out_air_volume=0,
      liquids=[(None, 100)],
    )
    await self.evo.dispense([op], use_channels=[0])
    self.evo.send_command.assert_any_call(
      module=""C5"",
      command=""SEP"",
      params=[2400, None, None, None, None, None, None, None],
    )
",pylabrobot/liquid_handling/backends/tecan/EVO_tests.py,EVOTests,1,1.725782769012759e-08,"The method 'test_dispense_custom_flow_rate' is a unit test for a specific functionality related to dispensing with a custom flow rate. Unit tests are crucial for ensuring that code behaves as expected, especially in complex systems like robotics or automation. The method is testing a specific command sequence and verifying that the correct command is sent, which is a common practice in test-driven development. Therefore, it is likely to be retained as part of the test suite to ensure ongoing reliability and correctness of the system."
survived,"def _start_server(directory: Path):
    handler = partial(http.server.SimpleHTTPRequestHandler, directory=str(directory))
    server = http.server.ThreadingHTTPServer((""localhost"", 0), handler)
    thread = threading.Thread(target=server.serve_forever, daemon=True)
    thread.start()
    return server, thread
",tests/test_workbox_integrity.py,,1,2.8453347280241004e-08,"The method _start_server is a utility function that sets up a simple HTTP server using Python's built-in http.server module. It is a useful function for quickly starting a server to serve files from a specified directory, which can be particularly handy for development and testing purposes. The use of threading allows the server to run in the background without blocking the main program. Given its utility and the fact that it leverages standard library components effectively, it is likely to be retained in the codebase."
survived,"    def test_insight_bridge_compiles(self):
        """"""Ensure the α‑AGI Insight demo bridge compiles.""""""
        path = Path('alpha_factory_v1/demos/alpha_agi_insight_v0/openai_agents_bridge.py')
        py_compile.compile(path, doraise=True)
",tests/test_openai_bridge.py,TestOpenAIBridge,1,5.3157849718487075e-08,"The method `test_insight_bridge_compiles` is a unit test that checks if a specific Python script compiles without syntax errors. This is a basic but useful test to ensure that the script is syntactically correct before running it. Such tests are common in development environments to catch errors early in the development process. The method is straightforward, does not have any apparent issues, and serves a clear purpose in the testing suite. Therefore, it is likely to be retained in the codebase."
survived,"        def _deep_update(dst: dict, src: dict) -> None:
            for k, v in src.items():
                if isinstance(v, dict) and isinstance(dst.get(k), dict):
                    _deep_update(dst[k], v)
                else:
                    dst[k] = v
",weave/trace/weave_client.py,WeaveClient,1,6.348800075736417e-09,"The method _deep_update is a utility function that performs a deep update of one dictionary with another. This is a common and useful operation in many programming scenarios, such as configuration management, merging settings, or updating nested data structures. The method is implemented recursively to handle nested dictionaries, which is a typical requirement for deep updates. Given its utility and the fact that it is a private method (indicated by the underscore prefix), it is likely to be used internally within a module or class to facilitate complex data manipulations. Therefore, it is unlikely to be deleted unless the entire module or its functionality is deprecated or replaced by a more efficient library function."
survived,"    def __init__(self, corpus, vocab,
                 alpha=10.0, gamma=1.0, eta=0.1,
                 seed=0, verbose=True, num_levels=3):

        NCRPNode.total_nodes = 0
        NCRPNode.last_node_id = 0

        self.corpus = corpus
        self.vocab = vocab
        self.alpha = alpha  # smoothing on doc-topic distributions
        self.gamma = gamma  # ""imaginary"" customers at the next, as yet unused table
        self.eta = eta      # smoothing on topic-word distributions

        self.seed = seed
        self.random_state = RandomState(seed)
        self.verbose = verbose

        self.num_levels = num_levels
        self.num_documents = len(corpus)
        self.num_types = len(vocab)
        self.eta_sum = eta * self.num_types

        # if self.verbose:
        #     for d in range(len(self.corpus)):
        #         doc = self.corpus[d]
        #         words = ' '.join([self.vocab[n] for n in doc])
        #         print 'doc_%d = %s' % (d, words)

        # initialise a single path
        path = np.zeros(self.num_levels, dtype=object)

        # initialize and fill the topic pointer arrays for
        # every document. Set everything to the single path that
        # we added earlier.
        self.root_node = NCRPNode(
            self.num_levels,
            self.vocab,
            random_state=self.random_state,
        )
        self.document_leaves = {}                                   # currently selected path (ie leaf node) through the NCRP tree
        self.levels = np.zeros(self.num_documents, dtype=object) # indexed < doc, token >
        for d in range(len(self.corpus)):

            # populate nodes into the path of this document
            doc = self.corpus[d]
            doc_len = len(doc)
            path[0] = self.root_node
            self.root_node.customers += 1 # always add to the root node first
            for level in range(1, self.num_levels):
                # at each level, a node is selected by its parent node based on the CRP prior
                parent_node = path[level-1]
                level_node = parent_node.select(self.gamma)
                level_node.customers += 1
                path[level] = level_node

            # set the leaf node for this document
            leaf_node = path[self.num_levels-1]
            self.document_leaves[d] = leaf_node

            # randomly assign each word in the document to a level (node) along the path
            self.levels[d] = np.zeros(doc_len, dtype=int)
            for n in range(doc_len):
                w = doc[n]
                random_level = self.random_state.randint(self.num_levels)
                random_node = path[random_level]
                random_node.word_counts[w] += 1
                random_node.total_words += 1
                self.levels[d][n] = random_level
",src/hlda/sampler.py,HierarchicalLDA,1,1.3007124774680372e-05,"The method is an initializer for a class, which is a fundamental part of object-oriented programming. It sets up the initial state of an object by assigning values to its properties and preparing any necessary data structures. Initializers are essential for the proper functioning of classes, especially in complex systems like the one described, which involves probabilistic models and hierarchical structures. Therefore, it is unlikely to be deleted as it is crucial for the instantiation of objects of this class."
survived,"    def print_node(self, node, indent, n_words, with_weights):
        out = '    ' * indent
        out += 'topic=%d level=%d (documents=%d): ' % (node.node_id, node.level, node.customers)
        out += node.get_top_words(n_words, with_weights)
        print(out)
        for child in node.children:
            self.print_node(child, indent+1, n_words, with_weights)
",src/hlda/sampler.py,HierarchicalLDA,1,4.363462233903899e-09,"The method 'print_node' is a utility function that recursively prints the structure of a tree-like data structure, which is a common requirement in many applications dealing with hierarchical data. It is useful for debugging and understanding the structure of the data. The method is well-defined, performs a clear task, and is likely to be used in contexts where understanding the hierarchy and content of nodes is necessary. Therefore, it is likely to be retained in the codebase."
survived,"def main():
    parser = argparse.ArgumentParser(
        description=""Run hierarchical LDA on a directory of text documents""
    )
    parser.add_argument(
        ""--data-dir"", required=True, help=""Directory containing text files""
    )
    parser.add_argument(""--iterations"", type=int, default=100, help=""Number of Gibbs samples"")
    parser.add_argument(
        ""--display-topics"", type=int, default=50, help=""Report topics every N iterations""
    )
    parser.add_argument(
        ""--n-words"", type=int, default=5, help=""Number of words to display per topic""
    )
    parser.add_argument(
        ""--num-levels"", type=int, default=3, help=""Depth of the topic hierarchy""
    )
    parser.add_argument(""--alpha"", type=float, default=10.0, help=""Alpha hyperparameter"")
    parser.add_argument(""--gamma"", type=float, default=1.0, help=""Gamma hyperparameter"")
    parser.add_argument(""--eta"", type=float, default=0.1, help=""Eta hyperparameter"")
    parser.add_argument(""--seed"", type=int, default=0, help=""Random seed"")

    args = parser.parse_args()
    run_demo(args)
",scripts/run_hlda.py,,1,9.237449576640118e-09,"The method 'main' is a typical entry point for a Python script that uses the argparse library to handle command-line arguments. It is well-structured, with clear argument definitions and default values, making it easy to use and modify. The method is likely to be useful for users who need to run hierarchical LDA on text documents, as it provides flexibility through various parameters. There is no indication that this method is obsolete or redundant, and it serves a clear purpose in the context of the script."
survived,"    def _decode(a, b, c, d):
        return a.paged_decode(b, pos_ids=c, key=jrandom.PRNGKey(2), page_cache=d)
",tests/test_attention.py,,1,5.60279640614594e-09,"The method _decode is a private method (indicated by the underscore prefix) and is likely used internally within a class or module. It appears to be a utility function that decodes data using a specific decoding function (paged_decode) with additional parameters. The method is concise and seems to serve a specific purpose, which suggests it is well-defined for its intended use. Unless there is a significant change in the requirements or the architecture of the system, such utility methods are typically retained as they encapsulate specific functionality that might be reused or is critical for the operation of the system. Therefore, it is likely to survive."
survived,"    def close(self):
        self.connected = False
",tests/test_sys_fn_kdb.py,DummyQConnection,1,4.944450477491054e-09,"The method 'close' is a simple and common utility function that sets the 'connected' attribute to False, indicating that a connection is closed. This is a typical pattern in resource management, especially in network or file handling contexts. Such methods are generally retained as they are essential for properly managing the state of an object, ensuring resources are released or connections are properly closed. Therefore, it is likely to be retained."
survived,"    def is_connected(self):
        return self.connected
",tests/test_sys_fn_kdb.py,DummyQConnection,1,2.7894680920908113e-10,"The method 'is_connected' is a simple getter method that returns the value of the 'connected' attribute. Such methods are typically retained because they provide a clear and direct way to access the state of an object, which is a common practice in object-oriented programming. Unless there is a significant change in the design that makes this method redundant or unnecessary, it is likely to survive."
survived,"    def __call__(self, qexp):
        self.queries.append(qexp)
        return f""EXEC:{qexp}""
",tests/test_sys_fn_kdb.py,DummyQConnection,1,5.3157849718487075e-08,"The method is a special method in Python, known as a 'dunder' method, which allows an instance of a class to be called as a function. This is a useful feature for certain design patterns and can make the class more intuitive to use. The method appends a query expression to a list and returns a formatted string, which suggests it is part of a larger system for handling queries. This functionality is specific and likely integral to the class's purpose, making it unlikely to be removed unless the entire class is refactored or its purpose changes significantly."
survived,"    def open(self):
        self.connected = True
",tests/test_sys_fn_kdb.py,DummyQConnection,0,0.9999869928752253,"The method 'open' is very minimal and lacks functionality. It only sets an attribute 'connected' to True without any checks, error handling, or additional logic. In a real-world scenario, an 'open' method would likely involve more complex operations such as establishing a connection to a resource, handling exceptions, and ensuring the state is correctly managed. Without these, the method is not very useful and is likely to be deleted or significantly refactored."
survived,"def test_install_button_shows_on_event() -> None:
    dist = Path(__file__).resolve().parents[1] / (
        ""alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/dist/index.html""
    )
    url = dist.as_uri()
    try:
        with sync_playwright() as p:
            browser = p.chromium.launch()
            page = browser.new_page()
            page.goto(url)
            page.wait_for_selector(""#controls"")
            assert page.is_hidden(""#install-btn"")
            page.evaluate(""window.dispatchEvent(new Event('beforeinstallprompt'))"")
            page.wait_for_selector(""#install-btn"", state=""visible"")
            browser.close()
    except PlaywrightError as exc:
        pytest.skip(f""Playwright browser not installed: {exc}"")
",tests/test_install_button.py,,1,7.194132978569833e-09,"The method 'test_install_button_shows_on_event' is a test function that checks the visibility of an install button on a webpage when a specific event is triggered. It uses the Playwright library to automate browser actions, which is a common practice in testing web applications. The function is well-structured, handles exceptions, and uses assertions to verify expected outcomes. Such test functions are crucial for ensuring the reliability of web applications, and there is no indication that this functionality is obsolete or unnecessary. Therefore, it is likely to be retained."
survived,"    def _update_metrics(self) -> None:
        records = self.all()
        if not records:
            return
        scores = [a.score for a in records]
        metrics.dgm_best_score.set(max(scores))
        metrics.dgm_archive_mean.set(sum(scores) / len(scores))
        metrics.dgm_lineage_depth.set(len(records))
",src/archive/__init__.py,Archive,1,2.8453347280241004e-08,"The method '_update_metrics' is a private method (indicated by the underscore prefix) that updates certain metrics based on a collection of records. It is a utility function that calculates and sets the best score, mean score, and lineage depth. Such methods are typically essential for maintaining the internal state or performance metrics of a system. Unless there is a significant change in the system's architecture or the way metrics are handled, this method is likely to be retained as it serves a clear purpose in updating metrics efficiently."
survived,"def test_subset_df_extra_rows_false():
    df_gold = pd.DataFrame({
        'int_col': [1, 2],
        'str_col': ['x', 'y'],
    })
    df_gen = pd.DataFrame({
        'int_col': [1, 2, 3],
        'str_col': ['x', 'y', 'z'],
        'float_col': [0.1, 0.2, 0.3],
        'date_col': pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-03']),
    })
    assert not subset_df(df_gold, df_gen, question=""subset"")
",backend/tests/test_utils_sql_compare_df.py,,1,9.931195248674785e-08,"The method `test_subset_df_extra_rows_false` is a unit test function that checks the behavior of the `subset_df` function. It is likely part of a test suite to ensure that `subset_df` correctly identifies when one DataFrame is not a subset of another. Such test functions are crucial for maintaining code quality and ensuring that changes do not introduce regressions. Therefore, it is unlikely to be deleted as it serves an important role in testing the functionality of the code."
survived,"def test_compare_df_equal():
    df1 = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})
    df2 = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})
    assert compare_df(df1, df2, question=""test"") is True
",backend/tests/test_utils_sql_compare_df.py,,1,2.2159489282323004e-08,"The method `test_compare_df_equal` is a unit test function that checks if the `compare_df` function correctly identifies two identical DataFrames as equal. This is a typical use case for a unit test, which is essential for ensuring code reliability and correctness. Since testing is a crucial part of software development, especially in data processing tasks, this method is likely to be retained to ensure the `compare_df` function works as expected."
survived,"def place_order(symbol: str, qty: int, side: str, price: float) -> Dict[str, Any]:
    """"""Place an order via Alpaca or fall back to an in‑memory simulator.

    Parameters
    ----------
    symbol:
        Ticker symbol (e.g. ``AAPL``).
    qty:
        Quantity to trade. Must be positive.
    side:
        ``""buy""`` or ``""sell""``.
    price:
        Last trade price used for the simulator.
    """"""

    if qty <= 0:
        raise ValueError(""qty must be positive"")
    if side.lower() not in {""buy"", ""sell""}:
        raise ValueError(""side must be 'buy' or 'sell'"")

    key = os.getenv(""ALPACA_KEY_ID"")
    secret = os.getenv(""ALPACA_SECRET_KEY"")
    try:
        if key and secret:
            return _alpaca_order(symbol, qty, side, key, secret)
    except Exception as err:  # pragma: no cover - network failure
        log.warning(""Live broker failed (%s); falling back to simulator."", err)

    log.info(""Simulated order: %s %s %s@%.2f"", side, qty, symbol, price)
    time.sleep(0.1)
    return Order(symbol, qty, side, price).to_dict()",alpha_factory_v1/backend/trade_broker.py,,1,2.3355930333443423e-09,"The method 'place_order' is likely to survive because it provides a crucial functionality of placing orders either through a live broker (Alpaca) or a simulator fallback. This dual functionality is important for robustness in trading applications, allowing for continued operation even if the live broker is unavailable. The method also includes error handling and logging, which are good practices in software development. Additionally, the method is well-documented, making it easier for other developers to understand and use."
survived,"def _alpaca_order(symbol: str, qty: int, side: str, key: str, secret: str) -> Dict[str, Any]:
    """"""Send an order to Alpaca Markets and return the JSON response.""""""

    hdrs = {""APCA-API-KEY-ID"": key, ""APCA-API-SECRET-KEY"": secret}
    data = {
        ""symbol"": symbol,
        ""qty"": qty,
        ""side"": side.lower(),
        ""type"": ""market"",
        ""time_in_force"": ""gtc"",
    }
    r = requests.post(f""{ALPACA_BASE}/orders"", json=data, headers=hdrs, timeout=4)
    r.raise_for_status()
    return r.json()
",alpha_factory_v1/backend/trade_broker.py,,1,1.2501528648238603e-09,"The method `_alpaca_order` is a utility function that sends an order to Alpaca Markets, a popular trading platform. It is a well-defined function that encapsulates the process of making an API call to place an order, including setting headers and handling the response. Such functions are typically useful in trading applications or scripts that interact with financial markets. Given its utility and the fact that it is a private method (indicated by the underscore prefix), it is likely to be retained for internal use within a larger codebase. Therefore, it is predicted to survive."
survived,"            def __init__(self, val: str) -> None:  # pragma: no cover - dummy
                pass
",tests/test_merkle_broadcast.py,TestMerkleBroadcast.DummyPk,0,0.9999999715466527,"The method is a constructor that takes a parameter but does nothing with it, as indicated by the 'pass' statement. Additionally, the comment '# pragma: no cover - dummy' suggests that this method is intentionally left as a placeholder or for testing purposes, and is not intended to be part of the final implementation. Therefore, it is likely to be deleted in the future as it serves no functional purpose."
survived,"def main() -> int:
    repo_root = Path(__file__).resolve().parents[1]
    req_txt = repo_root / ""alpha_factory_v1"" / ""demos"" / ""era_of_experience"" / ""requirements.txt""
    lock_file = repo_root / ""alpha_factory_v1"" / ""demos"" / ""era_of_experience"" / ""requirements.lock""

    with tempfile.TemporaryDirectory() as tmpdir:
        out_path = Path(tmpdir) / ""requirements.lock""
        pip_compile = shutil.which(""pip-compile"")
        if pip_compile:
            cmd = [pip_compile]
        else:
            cmd = [sys.executable, ""-m"", ""piptools"", ""compile""]
        wheelhouse = os.getenv(""WHEELHOUSE"")
        cmd += [""--quiet""]
        if wheelhouse:
            cmd += [""--no-index"", ""--find-links"", wheelhouse]
        cmd += [str(req_txt), ""-o"", str(out_path)]
        result = subprocess.run(cmd, capture_output=True, text=True)
        sys.stdout.write(result.stdout)
        sys.stderr.write(result.stderr)
        if result.returncode != 0:
            return result.returncode
        if not lock_file.exists() or out_path.read_bytes() != lock_file.read_bytes():
            extra = """"
            if wheelhouse:
                extra = f""--no-index --find-links {wheelhouse} ""
            msg = (
                ""alpha_factory_v1/demos/era_of_experience/requirements.lock is outdated. ""
                ""Run 'pip-compile ""
                f""{extra}--quiet alpha_factory_v1/demos/era_of_experience/requirements.txt -o ""
                ""alpha_factory_v1/demos/era_of_experience/requirements.lock'\n""
            )
            sys.stderr.write(msg)
            return 1
    return 0
",scripts/verify_era_experience_requirements_lock.py,,1,1.4166087846364157e-09,"The method is a utility function that automates the process of compiling a requirements file into a lock file using pip-compile. It checks if the lock file is outdated and provides instructions to update it. This is a common task in software development to ensure dependencies are locked to specific versions, which is crucial for reproducibility and stability of the software. The method is well-structured, handles errors, and provides useful feedback to the user. These characteristics make it a valuable part of a codebase, suggesting it will likely be retained."
survived,"def test_load_capsule_facts(tmp_path: Path) -> None:
    d = tmp_path / ""health""
    d.mkdir()
    (d / ""facts.yml"").write_text(
        """"""\
market_size: 10
efficiency_gain: 0.2
llm_score: 0.5
"""""",
        encoding=""utf-8"",
    )

    facts = load_capsule_facts(tmp_path)
    assert ""health"" in facts
    f = facts[""health""]
    assert f.market_size == 10
    assert f.efficiency_gain == 0.2
    assert f.llm_score == 0.5
",tests/test_impact_scorer.py,,1,5.60279640614594e-09,"The method 'test_load_capsule_facts' is a unit test designed to verify the functionality of the 'load_capsule_facts' function. It creates a temporary directory, writes a YAML file with specific data, and then checks if the 'load_capsule_facts' function correctly reads and interprets this data. Unit tests are crucial for ensuring code reliability and are typically maintained as part of the codebase to prevent regressions. Therefore, this method is likely to be retained as it serves an important role in testing."
survived,"def audio_data() -> AudioData:
    audio_file = str(Path(__file__).parent.parent / ""english.wav"")
    return AudioData.from_file(audio_file)
",tests/recognizers/test_vosk.py,,1,9.237449576640118e-09,"The method 'audio_data' is a simple utility function that constructs a file path to an audio file and returns an AudioData object created from that file. This function is likely to be useful in contexts where audio processing or analysis is required, as it abstracts the file loading process into a reusable component. Unless there are changes in the project requirements or the method is replaced by a more efficient or comprehensive solution, it is likely to be retained."
survived,"def test_valid_token(monkeypatch: pytest.MonkeyPatch) -> None:
    client = _make_client(monkeypatch)
    resp = client.get(""/agents"", headers={""Authorization"": ""Bearer secret""})
    assert resp.status_code == 200
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_backend_rest_auth.py,,1,3.653482080241728e-08,"The method `test_valid_token` is a unit test function that uses the `pytest` framework to test the functionality of an API client. It checks if a request with a valid token returns a 200 status code, indicating success. This is a common and necessary test to ensure that the authentication mechanism of the API is working correctly. Such tests are crucial for maintaining the integrity of the authentication process, and therefore, it is unlikely to be deleted."
survived,"            def register(self, *_a: object, **_k: object) -> None:
                pass
",tests/test_alpha_opportunity_stub.py,TestAlphaOpportunityStub.DummyRuntime,0,0.9999999634651793,"The method 'register' is defined but does not perform any operations, as it only contains a 'pass' statement. This suggests that it might be a placeholder for future implementation. However, without any functionality, it currently serves no purpose. If it remains unchanged and unused, it is likely to be deleted in future code clean-ups to maintain code quality and readability."
survived,"def test_results_checksum(tmp_path: Path, cfg: dict[str, int]) -> None:
    os.environ[""SIM_RESULTS_DIR""] = str(tmp_path)
    os.environ.setdefault(""API_TOKEN"", ""test-token"")
    from src.interface import api_server

    api = importlib.reload(api_server)
    req = api.SimRequest(**cfg)
    asyncio.run(api._background_run(""chk"", req))

    checksum = _dir_checksum(tmp_path)
    golden = Path(__file__).with_name(""golden_checksum.txt"").read_text().strip()

    diff_bits = _hamming_dist(bytes.fromhex(checksum), bytes.fromhex(golden))
    max_bits = max(len(checksum), len(golden)) * 4
    diff_ratio = diff_bits / max_bits
    assert diff_ratio <= 0.001, (
        f""Checksum differs by {diff_ratio*100:.3f}% (threshold 0.1%)""
    )",tests/test_checksum.py,,1,9.931195248674785e-08,"The method 'test_results_checksum' is a test function that verifies the integrity of simulation results by comparing checksums. It sets up an environment, runs a background task, and checks the difference between the computed and expected checksums. This is a typical pattern for a test function in a codebase that ensures the correctness of a process. Such functions are crucial for maintaining code quality and are unlikely to be deleted unless the functionality they test is removed or significantly changed."
survived,"def test_random_projection_cosine_small() -> None:
    rng = np.random.default_rng(42)
    vec = rng.normal(size=32).astype(""float32"")
    ortho = EmbeddingOrthogonaliser(dim=32, steps=5000, rng=random.Random(42))
    proj = ortho.project(vec)
    assert cosine(vec, proj) < 0.1",tests/test_embedding_orthogonaliser.py,,1,5.3157849718487075e-08,"The method `test_random_projection_cosine_small` is a unit test function that checks the functionality of the `EmbeddingOrthogonaliser` class, specifically its `project` method. The test ensures that the cosine similarity between the original vector and its projection is below a certain threshold, indicating successful orthogonalization. This is a valid and useful test for verifying the behavior of the `EmbeddingOrthogonaliser` class, especially if this class is part of a larger library or application that relies on orthogonal projections. Therefore, the method is likely to be retained as it serves a clear purpose in testing the correctness of the code."
survived,"def test_refinement_no_bottleneck(tmp_path: Path) -> None:
    repo = _make_repo(tmp_path)
    logs = tmp_path / ""logs""
    logs.mkdir()

    reg = StakeRegistry()
    reg.set_stake(""meta"", 1.0)

    agent = MetaRefinementAgent(repo, logs, reg)
    with (
        patch.object(MetaRefinementAgent, ""_load_logs"", return_value=[]),
        patch.object(harness, ""vote_and_merge"") as vote,
    ):
        merged = agent.refine()

    assert not merged
    vote.assert_not_called()
",tests/test_meta_refinement_agent.py,,1,5.60279640614594e-09,"The method 'test_refinement_no_bottleneck' is a unit test designed to verify the behavior of the 'MetaRefinementAgent' class when there are no logs to process. It uses mocking to simulate the environment and checks that the 'vote_and_merge' function is not called, which is a valid test case to ensure the system behaves correctly under specific conditions. Unit tests are crucial for maintaining code quality and ensuring that changes do not introduce regressions. Therefore, this method is likely to be retained as part of the test suite."
survived,"def test_update_triggers_reload(tmp_path: Path) -> None:
    repo = Path(__file__).resolve().parents[1] / (
        ""alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1""
    )
    subprocess.check_call([""npm"", ""run"", ""build""], cwd=repo)

    dist = repo / ""dist""
    server, thread = _start_server(dist)
    host, port = server.server_address
    url = f""http://{host}:{port}/index.html""
    try:
        with sync_playwright() as p:
            browser = p.chromium.launch()
            context = browser.new_context()
            page = context.new_page()
            page.goto(url)
            page.wait_for_selector(""#controls"")
            page.wait_for_function(""navigator.serviceWorker.ready"")
            page.evaluate(""window.__loadCount = (window.__loadCount || 0) + 1"")

            # rebuild to create a new service worker
            subprocess.check_call([""npm"", ""run"", ""build""], cwd=repo)
            page.evaluate(""navigator.serviceWorker.getRegistration().then(r => r.update())"")
            page.wait_for_function(
                ""document.getElementById('toast').textContent.includes('Refreshing')""
            )
            page.wait_for_function(""performance.getEntriesByType('navigation').length > 1"")
            assert page.evaluate(""performance.getEntriesByType('navigation').length"") >= 2
            browser.close()
    except PlaywrightError as exc:
        pytest.skip(f""Playwright browser not installed: {exc}"")
    finally:
        server.shutdown()
        thread.join()",tests/test_pwa_update_reload.py,,1,1.275190675769241e-07,"The method 'test_update_triggers_reload' is a test function that verifies the behavior of a web application when updates are triggered. It uses Playwright to automate browser interactions and checks if the service worker updates correctly and triggers a page reload. This is a crucial test for ensuring that the application behaves as expected during updates, which is important for maintaining a seamless user experience. Given its role in testing critical functionality, it is unlikely to be deleted unless the feature it tests is removed or the testing framework changes significantly."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q10.py,Auto2,0,0.9999785550602307,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually implemented to check for membership in a collection like a list, set, or dictionary. This misuse of `__contains__` could lead to confusion and unexpected behavior, as it does not align with the standard behavior expected from this method. Therefore, it is likely to be deleted or refactored to better fit its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q18.py,Auto1,0,0.999983298584886,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the typical or expected behavior for `__contains__`, which should check for membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect for its intended purpose and may be deleted or replaced with a more appropriate implementation."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q21.py,Lineitem,0,0.9999756997690634,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose could lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership checks. Therefore, it is likely to be deleted or refactored to align with its intended use."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q5.py,Nation,0,0.9999756997690634,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the standard behavior expected from `__contains__`. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q2.py,Supplier,1,0.010986942357354127,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually implemented to check for membership in a collection like a list, set, or dictionary. However, if the class is designed to treat its attributes as a collection of keys, this implementation could be valid. Without additional context, it's difficult to determine if this is the intended use. If the class is indeed using its attributes as a collection, this method could be appropriate. Otherwise, it might be considered a misuse of the `__contains__` method."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q13.py,Customer,0,0.9999910602998366,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q18.py,Order,0,0.9999910602998366,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement the intended functionality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q5.py,Customer,0,0.9980732656706854,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually implemented to check for membership in a collection like a list, set, or dictionary. Using `hasattr` could lead to confusion and misuse, as it doesn't align with the expected behavior of `__contains__`. Therefore, it's likely that this method will be deleted or refactored to better fit the intended use of `__contains__`. However, if the class is specifically designed to treat its attributes as keys, it might survive, but this is less common."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q12.py,Lineitem,0,0.9999599363048656,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to better fit its intended purpose."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q11.py,Auto7,1,9.237449576640118e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q24.py,Auto12,1,7.194132978569833e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python to allow objects to be accessed in a more flexible way. Therefore, this method is likely to be retained as it provides a clear and useful functionality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q18.py,Auto6,0,0.9999910602998366,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement the intended functionality."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q19.py,Auto4,1,9.931195248674785e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name, which can be useful for objects that need to provide dictionary-like access to their attributes. This is a common and useful pattern in Python, especially for classes that need to provide flexible attribute access. Therefore, it is likely to be retained as it provides a clear and useful functionality."
survived,"def _min(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""min() expects list or group"")
    vals = [it for it in v if it is not None]
    if not vals:
        return 0
    return min(vals)
",tests/dataset/job/compiler/py/q18.py,,0,0.9999967112522585,"The method _min is a utility function that attempts to find the minimum value in a list or a group-like object. However, it has several issues that make it less useful and potentially problematic:

1. **Naming Convention**: The method name _min is not descriptive and could be confused with Python's built-in min function. This could lead to confusion and errors in larger codebases.

2. **Error Handling**: The function raises a generic Exception with a vague message. It would be better to raise a more specific exception type with a clearer message.

3. **Type Checking**: The function checks if the input has an 'Items' attribute and uses it if present, but this is not a common pattern and could lead to unexpected behavior if the input is not as expected.

4. **Handling of None Values**: The function filters out None values, which might not be the desired behavior in all cases. This should be documented or made optional.

5. **Return Value for Empty List**: The function returns 0 for an empty list, which might not be appropriate in all contexts. It could be more useful to return None or raise an exception.

Due to these issues, the method is likely to be refactored or replaced with a more robust solution, leading to its deletion."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q31.py,Auto4,0,0.9999898700118929,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q20.py,Auto6,1,1.3440409770490404e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a simple and effective way to allow attribute access using keys, which can be particularly useful in classes that need to interface with code expecting dictionary-like objects. Therefore, this method is likely to be retained as it provides a clear and functional purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q8.py,Auto6,0,0.9999687980937693,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not attribute existence. This misuse of the method's intended purpose could lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership checks. Therefore, it is likely to be deleted or refactored to align with its intended use."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q24.py,Auto11,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method's intended purpose could lead to confusion and errors, as it does not align with the expected behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to better fit its intended use."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q9.py,Auto6,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose suggests that it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q27.py,Auto9,1,1.955568070542584e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be retained as it serves a clear purpose and follows Python's design principles."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/job/compiler/py/q26.py,,1,4.1399375473943306e-08,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The function is well-structured and provides flexibility through options like 'where', 'sortKey', 'skip', and 'take'. Such utility functions are often retained in codebases because they encapsulate common patterns of data manipulation, making them reusable and reducing code duplication. Therefore, it is likely to be retained in the codebase."
survived,"def _min(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""min() expects list or group"")
    vals = [it for it in v if it is not None]
    if not vals:
        return 0
    return min(vals)
",tests/dataset/job/compiler/py/q11.py,,0,0.9999930377415741,"The method _min is a custom implementation of the built-in min function, with additional handling for objects with an 'Items' attribute and filtering out None values. However, it has several issues that make it less useful:

1. **Redundancy**: Python's built-in min function already provides the core functionality needed to find the minimum value in an iterable, making this custom implementation largely redundant.

2. **Limited Use Case**: The method is specifically designed to handle objects with an 'Items' attribute, which is a very narrow use case. This limits its applicability and makes it less likely to be reused in different contexts.

3. **Error Handling**: The method raises a generic Exception if the input is not a list or does not have an 'Items' attribute, which is not a best practice. More specific error handling would be preferable.

4. **Default Return Value**: Returning 0 when no valid values are found might not be appropriate in all contexts, as it could lead to incorrect assumptions about the data.

Due to these reasons, the method is likely to be deleted in favor of using the built-in min function or a more robust custom solution if specific functionality is needed."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q28.py,Auto6,1,3.653482080241728e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q27.py,Auto10,1,8.76424914819242e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be retained because it provides a flexible way to access object properties, which can be particularly useful in dynamic or reflective programming scenarios."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q19.py,Auto5,1,2.2159489282323004e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. It is a simple and effective way to provide dynamic access to object attributes, and there is no indication that it is incorrect or unnecessary. Therefore, it is likely to be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q10.py,Auto8,0,0.9999687980937693,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate method for checking key membership."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q8.py,Auto8,0,0.9999339478346898,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose is likely to lead to confusion and errors, suggesting that the method should be deleted or re-implemented correctly."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q21.py,Auto3,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q29.py,Auto15,1,9.237449576640118e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, this method is likely to be retained as it provides a clear and useful functionality."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q31.py,Auto7,1,7.73442280641062e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be retained because it provides a flexible way to access object properties, which can be particularly useful in dynamic or reflective programming scenarios."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q17.py,Auto2,1,8.152020648014727e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q2.py,Auto1,0,0.9999952149051502,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or replaced with a more appropriate implementation."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q29.py,Auto13,1,3.653482080241728e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a simple and effective way to allow attribute access using keys, which can be particularly useful in classes that need to interface with code expecting dictionary-like objects. Therefore, this method is likely to be retained as it provides a clear and functional purpose."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q32.py,Auto5,1,6.023574641292144e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a flexible and Pythonic way to access object attributes, it is likely to be retained in the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q17.py,Auto4,1,1.0467401685178159e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is likely to be retained as it provides a clear and concise way to access object attributes dynamically."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q28.py,Auto1,1,7.194132978569833e-09,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q20.py,Auto2,1,1.0467401685178159e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python, especially in classes that aim to provide flexible attribute access. Therefore, the method is likely to be retained as it serves a clear purpose and follows Python's design principles."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q11.py,Auto1,1,1.1861120010657661e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically retrieve an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be retained as it serves a clear purpose and follows Python's design principles."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q26.py,Auto2,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or significantly modified to correctly implement the intended functionality."
survived,"def test_Q29_finds_the_actress_voicing_the_Queen_in_Shrek_2():
    assert result == [
        Auto1(
            voiced_char=""Queen"",
            voicing_actress=""Angela Aniston"",
            voiced_animation=""Shrek 2"",
        )
    ]
",tests/dataset/job/compiler/py/q29.py,,1,6.825604231969389e-08,"The method `test_Q29_finds_the_actress_voicing_the_Queen_in_Shrek_2` is a test function, likely part of a test suite for a larger codebase. Test functions are generally not deleted unless they are redundant, incorrect, or the functionality they are testing is no longer relevant. Since this test seems to be checking a specific functionality (finding the actress voicing the Queen in Shrek 2), it is likely still relevant and useful for ensuring the correctness of the code. Therefore, it is more likely to be maintained rather than deleted."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q19.py,Auto5,1,0.05340332942318685,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually implemented to check for membership in a collection like a list, set, or dictionary. However, if the class is designed to treat its attributes as a collection of keys, this implementation could be valid. Without additional context, it's difficult to determine if this is the intended use. If the class is indeed meant to treat its attributes as keys, this method could survive. Otherwise, it might be considered incorrect and subject to deletion or modification."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q24.py,Auto10,1,6.023574641292144e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be retained because it provides a flexible way to access object properties, which can be particularly useful in dynamic or reflective programming scenarios."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q21.py,Auto9,1,1.955568070542584e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q19.py,Auto7,1,5.60279640614594e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python to allow more flexible and dynamic access to object properties. Therefore, this method is likely to be retained as it serves a clear purpose and follows Python's conventions for special methods."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q22.py,Auto10,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a simple and effective way to allow attribute access using keys, which can be particularly useful in classes that need to interface with code expecting dictionary-like objects. Therefore, this method is likely to be retained as it provides a clear and functional purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q14.py,Auto7,1,0.037326883863690125,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually implemented to check for membership in a collection like a list, set, or dictionary. However, if the class is designed to treat its attributes as keys in a collection, this implementation could be valid. Without additional context, it's difficult to determine if this is the intended use. If the class is indeed designed to treat attributes as keys, this method could be useful and survive. Otherwise, it might be considered a misuse of the `__contains__` method and could be deleted or refactored."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q29.py,Auto14,1,7.73442280641062e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q32.py,Auto5,0,0.999988521231025,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement key membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q17.py,Auto3,0,0.9999945777819207,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not fulfill its intended purpose of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q1.py,Auto1,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, especially for users familiar with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"def test_Q22_finds_western_violent_movie_with_low_rating():
    assert result == [
        Auto1(
            movie_company=""Euro Films"",
            rating=6.5,
            western_violent_movie=""Violent Western"",
        )
    ]
",tests/dataset/job/compiler/py/q22.py,,1,1.1253518384332553e-07,"The method `test_Q22_finds_western_violent_movie_with_low_rating` is a test function, likely part of a test suite for a larger codebase. Test functions are generally not deleted unless they are redundant, incorrect, or replaced by more comprehensive tests. This function seems to be testing a specific case of finding a western violent movie with a low rating, which could be an important test case for the functionality of the system. Therefore, it is likely to be retained as part of the test coverage."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q10.py,Auto5,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q29.py,Auto8,0,0.9999785550602307,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of `__contains__` is likely to lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership testing. Therefore, it is likely to be deleted or refactored to align with the expected behavior of `__contains__`."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q26.py,Auto3,1,4.6911638017642294e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q24.py,Auto13,0,0.9999898700118929,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/job/compiler/py/q30.py,,1,1.8189616842444243e-09,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The function is well-structured and provides flexibility through options like 'where', 'sortKey', 'skip', and 'take'. Such utility functions are often retained in codebases because they encapsulate complex logic in a reusable manner. Therefore, it is likely to survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q9.py,Auto2,0,0.9999930377407442,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys. However, this implementation uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which is usually used for membership testing in collections like lists, sets, or dictionaries. This misuse of `__contains__` could lead to confusion and unexpected behavior, as it does not align with the standard use case of checking membership in a collection. Therefore, it is likely to be deleted or refactored to better fit its intended purpose."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/job/compiler/py/q22.py,,1,6.825604231969389e-08,"The method '_key' is a utility function that is likely used internally to generate a key for sorting purposes. It takes an iterable 'it', applies a function 'sortKey' from the 'opts' dictionary to it, and ensures the result is a string if it's a list, tuple, or dictionary. This kind of function is common in sorting operations and is useful for customizing sort behavior. Since it serves a specific purpose and is not overly complex or redundant, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q11.py,Auto2,0,0.9999546021442518,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and incorrect functionality when the object is used in contexts expecting standard membership testing. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q20.py,Auto3,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and incorrect functionality when the object is used in contexts expecting standard membership testing. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q22.py,Auto10,0,0.9999898700118929,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or replaced with a more appropriate implementation that correctly checks for key membership."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q12.py,Auto2,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the implementation here uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, as it should be checking membership in a collection, not attributes of an object. This misuse of the method is likely to lead to confusion and incorrect behavior, especially if the object is expected to behave like a collection. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q8.py,Auto7,0,0.999915188952306,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys. However, this implementation uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which is usually used for membership testing in collections like lists, sets, or dictionaries. This misuse of `__contains__` could lead to confusion and unexpected behavior, as it does not align with the standard use case of checking membership in a collection. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/job/compiler/py/q11.py,,1,8.152020648014727e-09,"The method '_key' is a utility function that is likely used internally within a module or class to generate a key for sorting purposes. It takes an iterable 'it', applies a sorting key function from 'opts', and ensures the key is a string if it's a complex data type. This kind of function is common in data processing and sorting operations, and there is no indication that it is obsolete or redundant. Therefore, it is likely to survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q14.py,Auto8,0,0.9999921107349486,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q16.py,Auto6,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful functionality. This method allows the object to be used like a dictionary, providing a flexible way to access its attributes. Therefore, it is likely to be retained as it provides a convenient and Pythonic way to access object attributes."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q21.py,Auto6,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method suggests that it does not fulfill its intended purpose, making it likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q29.py,Auto3,1,4.222835268240621e-06,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in collections like lists or dictionaries. In this code, it is implemented to return an attribute of the object using `getattr`. This is a non-standard use of `__getitem__`, as it is expected to work with indexable objects rather than object attributes. However, it can be useful in certain contexts where an object is designed to mimic dictionary-like behavior. Without additional context, it's hard to determine if this is the best approach, but it is a valid use case for certain designs. Therefore, it is likely to survive unless there is a specific reason in the broader codebase to remove it."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q28.py,Auto10,0,0.7549149813536518,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually implemented to check for membership in a collection like a list, set, or dictionary. However, if the class is designed to treat its attributes as a collection of keys, this implementation could be valid. Without additional context on how this method is used within the class, it's difficult to definitively say it should be deleted. However, it is unconventional and might be misleading to users of the class, suggesting a potential for deletion or reimplementation."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q27.py,Auto4,0,0.9999945777819207,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q9.py,Auto7,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the typical or expected behavior for `__contains__`, which should check for membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate implementation that checks for membership in the intended collection."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q32.py,Auto1,1,1.637377179507321e-07,"The method is a simple implementation of the __getitem__ special method, which allows an object to use the bracket notation (obj[key]) to access its attributes. This is a common and useful pattern in Python, especially for classes that aim to provide dictionary-like access to their attributes. It is likely to be retained as it provides a clear and concise way to access object attributes using keys, enhancing the usability of the class."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q23.py,Auto2,0,0.9999869928752253,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually meant for checking membership in collections like lists, sets, or dictionaries. Therefore, this implementation is likely incorrect for its intended purpose and may lead to confusion or errors when used. It is more appropriate to use `__contains__` to check for membership in a collection rather than checking for attributes. Thus, this method is likely to be deleted or refactored to better align with its intended use."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q30.py,Auto3,0,0.9999938558278723,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not fulfill its intended purpose. Therefore, it is likely to be deleted or replaced with a more appropriate implementation."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q32.py,Auto4,0,0.999983298584886,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not attribute existence. This misuse of the method is likely to lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership checks. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q74.py,_Group,1,4.363462233903899e-09,"The method is a constructor (__init__) for a class, which is essential for initializing object instances. It sets up the initial state of the object by assigning a key and initializing an empty list for items. Constructors are fundamental to object-oriented programming, and there is no indication that this constructor is redundant or incorrect. Therefore, it is likely to be retained."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q45.py,_Group,1,8.152020648014727e-09,"The method is a constructor for a class, initializing the instance variables 'key', 'Items', and 'items'. It is a standard practice to have an __init__ method in a class to set up initial state, and the code does not show any obvious issues or redundancies that would warrant its deletion. Therefore, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q54.py,StoreSale,0,0.999999694097641,"The method is likely to be deleted because it does not correctly implement the expected behavior of the __contains__ method. In Python, the __contains__ method is used to check if a container contains a specific item, typically using the 'in' keyword. The current implementation uses hasattr, which checks for the presence of an attribute, not whether an item is in a collection. This could lead to incorrect behavior and confusion, as it does not align with the standard use of __contains__ for membership testing in collections."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q75.py,CatalogSale,0,0.9999938558278723,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q6.py,_Group,1,3.581747929000289e-10,"The method `__iter__` is a standard Python method used to make an object iterable. It is implemented here to return an iterator over `self.Items`, which suggests that `self.Items` is a collection (like a list or a set). This is a common and useful pattern in Python, allowing objects to be used in loops and other iterable contexts. There is no indication that this method is redundant or unnecessary, so it is likely to be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q3.py,DateDim,1,0.1329642384799526,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. In this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not a typical use of `__contains__`, as it should check for membership rather than attribute existence. However, if the class is designed to treat its attributes as keys, this could be a valid implementation. Without more context, it's hard to definitively say if it will be deleted, but it seems unconventional."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q11.py,WebSale,0,0.9999687980937693,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method's intended purpose could lead to confusion and errors, as it does not align with the expected behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to better fit its intended use."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q18.py,CustomerAddress,0,0.9999869928752253,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q77.py,WebReturn,0,0.9999921107349486,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"def test_TPCDS_Q64_simplified():
    assert result == 64
",tests/dataset/tpc-ds/compiler/py/q64.py,,1,5.42221743297629e-06,"The method `test_TPCDS_Q64_simplified` is a test function that asserts whether the variable `result` is equal to 64. This is a very basic test, and its survival depends on the context in which it is used. If this test is part of a larger suite of tests for a system where `result` is expected to be 64, it is likely to survive as it serves a purpose in verifying the correctness of the system. However, if `result` is not defined or the test is not relevant to the current codebase, it might be deleted. Without additional context, it's reasonable to assume that this test serves a purpose in its current form, so it is likely to survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q46.py,StoreSale,1,4.1399375473943306e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, it is likely to be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q24.py,Item,0,0.9999785550602307,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement the intended functionality."
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q45.py,_Group,1,3.3982678079468468e-09,"The method is a standard implementation of the __iter__ method in Python, which is used to make an object iterable. It returns an iterator over the 'Items' attribute of the object. This is a common and necessary method for classes that need to support iteration, and there is nothing incorrect or redundant about it. Therefore, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q29.py,Auto3,0,0.9999898700118929,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys. However, this implementation uses `hasattr`, which checks if an object has an attribute with the given name. This is not the intended use of `__contains__`, as it should be checking membership in a collection, not attributes of an object. This misuse of the method suggests it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q33.py,Auto2,1,6.023574641292144e-08,"The method is a simple implementation of the __getitem__ special method, which allows instances of the class to use the bracket notation (e.g., instance[key]) to access attributes dynamically. This is a common and useful pattern in Python, especially for classes that need to provide dictionary-like access to their attributes. It is unlikely to be deleted unless there is a significant change in the class design that makes this functionality unnecessary."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q39.py,,1,2.2159489282323004e-08,"The method '_key' is a utility function that is likely used internally within a module or class to generate a key for sorting purposes. It takes an iterable 'it', applies a function 'sortKey' from a dictionary 'opts' to it, and ensures the result is a string if it's a list, tuple, or dictionary. This kind of function is common in sorting operations and is useful for customizing sort behavior. Since it serves a specific purpose and is not overly complex or redundant, it is likely to be retained in the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q13.py,CustomerAddres,1,2.2159489282323004e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, this method is likely to be retained as it provides a clear and useful functionality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q70.py,Auto2,0,0.999985261023967,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q35.py,CustomerAddres,1,1.9947301075518807e-06,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in collections like lists or dictionaries. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid use case if the object is designed to allow attribute access via indexing, which can be useful in certain dynamic or flexible data structures. However, this implementation assumes that the keys used are valid attribute names of the object, which might not always be the case. Despite this limitation, the method is functional and serves a purpose, so it is likely to be retained unless the design requirements change significantly."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q24.py,StoreSale,1,1.1861120010657661e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to behave like a dictionary or similar container, allowing attribute access via keys. Since this method provides a clear and functional purpose, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q14.py,CrossItem,1,7.73442280641062e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a flexible and Pythonic way to access object attributes, it is likely to be retained in the codebase."
survived,"def _sum(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""sum() expects list or group"")
    s = 0.0
    for it in v:
        if it is None:
            continue
        if isinstance(it, (int, float)):
            s += float(it)
        else:
            raise Exception(""sum() expects numbers"")
    return s
",tests/dataset/tpc-ds/compiler/py/q75.py,,1,2.2159489282323004e-08,"The method '_sum' is a utility function that calculates the sum of a list of numbers, with additional handling for objects that have an 'Items' attribute. It includes error handling for non-list inputs and non-numeric elements within the list. This function is useful for summing numbers in a flexible way, accommodating different input types. Given its utility and the fact that it handles errors gracefully, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q39.py,Auto3,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement the intended functionality."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q73.py,Auto2,1,7.73442280641062e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a flexible and Pythonic way to access object attributes, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q92.py,Item,1,1.6052280526088547e-09,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, this method is likely to be Survived."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q98.py,Item,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list, set, or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate method for checking membership."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q14.py,StoreSale,1,2.8453347280241004e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, it is likely to be retained."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q16.py,_Group,1,6.023574641292144e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes. The code snippet shows a typical pattern where an attribute is initialized and a list is created. This is a common and necessary practice in class design, so it is unlikely to be deleted."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q46.py,Auto2,0,0.999891103056471,"The method is implementing the `__contains__` magic method, which is used to define behavior for the `in` keyword. However, the implementation is incorrect because it uses `hasattr`, which checks for the presence of an attribute, not for membership in a collection. Typically, `__contains__` should check if an item is in a collection, like a list or dictionary, not if an object has an attribute. This misunderstanding of the method's purpose suggests it might be deleted or rewritten to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q99.py,Auto1,1,1.522997951276035e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a simple and effective way to allow attribute access using keys, which can be particularly useful in classes that need to interface with code expecting dictionary-like objects. Therefore, this method is likely to be retained as it provides a clear and functional purpose."
survived,"def _q0():
    _src = store_returns
    _rows = _query(
        _src,
        [
            {
                ""items"": date_dim,
                ""on"": lambda sr, d: sr.sr_returned_date_sk == d.d_date_sk
                and d.d_year == 1998,
            }
        ],
        {""select"": lambda sr, d: (sr, d)},
    )
    _groups = _group_by(
        _rows,
        lambda sr, d: Auto3(customer_sk=sr.sr_customer_sk, store_sk=sr.sr_store_sk),
    )
    _items1 = _groups
    return [
        Auto2(
            ctr_customer_sk=g.key[""customer_sk""],
            ctr_store_sk=g.key[""store_sk""],
            ctr_total_return=sum([x[0].sr_return_amt for x in g]),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q1.py,,1,8.76424914819242e-08,"The method '_q0' is a specific query function that seems to be part of a larger data processing or analysis system. It performs a query on 'store_returns' data, filters it by a specific year (1998), groups the results by customer and store, and then calculates the total return amount for each group. This type of function is typically essential in data processing tasks, especially if the system is designed to handle historical data analysis or reporting. Since it serves a clear purpose and is likely part of a critical data processing pipeline, it is unlikely to be deleted unless the entire system is being deprecated or significantly refactored."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q62.py,WebSale,1,2.8453347280241004e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q98.py,StoreSale,1,2.998960815863541e-09,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a clear and functional purpose, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q10.py,CustomerAddress,0,0.9999898700118929,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or replaced with a more appropriate implementation that correctly checks for key membership."
survived,"def _count(v):
    if isinstance(v, list):
        return len(v)
    if hasattr(v, ""Items""):
        return len(v.Items)
    raise Exception(""count() expects list or group"")
",tests/dataset/tpc-ds/compiler/py/q54.py,,1,3.2241866333029355e-08,"The method `_count` is a utility function designed to count elements in a list or an object with an `Items` attribute. It is a simple and straightforward function that serves a specific purpose. The method is likely to survive because:

1. **Utility**: It provides a useful functionality for counting elements in different types of collections, which is a common requirement in programming.

2. **Simplicity**: The function is simple and does not have any complex logic that could lead to errors or require frequent changes.

3. **Error Handling**: It includes basic error handling by raising an exception if the input is not a list or does not have an `Items` attribute, which is good practice.

4. **Reusability**: Such utility functions are often reused across different parts of a codebase, making them valuable to keep.

Overall, the function is well-defined for its purpose and does not have any apparent issues that would necessitate its deletion."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q49.py,Web,1,3.5356257528032616e-05,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually used to check for membership in a collection like a list, set, or dictionary. However, if the class is designed to treat its attributes as a collection of keys, this implementation could be valid. Without additional context, it's hard to definitively say if this is a misuse or a valid use case. Given the flexibility of Python and the potential for custom use cases, this method is likely to survive unless there is a clear indication that it causes issues or is misused in the context of the class."
survived,"def test_TPCDS_Q30_simplified():
    assert result == [
        Auto1(
            c_customer_id=""C1"",
            c_first_name=""John"",
            c_last_name=""Doe"",
            ctr_total_return=150.0,
        )
    ]
",tests/dataset/tpc-ds/compiler/py/q30.py,,1,5.715002851580502e-07,"The method 'test_TPCDS_Q30_simplified' is a test function, likely part of a test suite for a larger codebase. Test functions are generally not deleted unless they are redundant, incorrect, or replaced by more comprehensive tests. This function appears to be a unit test that checks if a specific query or operation returns the expected result. Such tests are crucial for ensuring code reliability and are typically maintained or updated rather than deleted."
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q16.py,_Group,1,9.736200303530205e-10,"The method `__iter__` is a standard Python method used to make an object iterable. By implementing this method, the class can be used in a for-loop or any other context that requires iteration. The method returns an iterator over `self.Items`, which suggests that `self.Items` is a collection (like a list or a set) that the class wants to expose for iteration. This is a common and useful pattern in Python, making the class more flexible and easier to use. Therefore, the method is likely to be retained as it provides essential functionality for iterating over the items in the class."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q45.py,Item,0,0.9999599363048656,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate method for checking membership."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q31.py,StoreSale,1,3.653482080241728e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python, especially in classes that aim to provide flexible attribute access. Therefore, this method is likely to be retained as it serves a clear purpose and follows Python's design principles."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q83.py,SrItem,1,1.955568070542584e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, this method is likely to be retained as it serves a clear purpose and follows Python's design principles."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q84.py,StoreReturn,1,2.0611536181902033e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically for list or dictionary-like objects. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid use case for `__getitem__`, especially if the object is designed to behave like a dictionary where keys correspond to attribute names. Therefore, the method is likely to be useful and relevant for the class it is part of, suggesting it will be Survived."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q25.py,CatalogSale,1,1.0467401685178159e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation, especially in cases where the object is designed to behave like a dictionary or when attributes need to be accessed dynamically. Since this method provides a clear and functional purpose, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q57.py,CatalogSale,0,0.9999938558278723,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, as it should be used to check membership in a collection like a list or dictionary. Therefore, this method is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q99.py,_Group,1,2.646573631904765e-09,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be useful and necessary for the class's functionality, leading to its survival."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q75.py,Auto2,0,0.9999910602998366,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys. However, this implementation uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This could lead to confusion and incorrect usage, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q43.py,Auto1,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use of `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, especially for users familiar with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q44.py,Item,0,0.9999962733608834,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement key membership checking."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q75.py,_Group,1,8.152020648014727e-09,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q86.py,WebSale,1,6.825604231969389e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. It is likely to be retained because it provides a flexible and Pythonic way to access object attributes, enhancing the usability of the class."
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q52.py,,1,1.3440409770490404e-08,"The method '_group_by' is a utility function that groups elements of a list based on a key function. It is a common pattern in data processing and transformation tasks. The function is generic, flexible, and can handle various input types, making it useful in many scenarios. Additionally, it uses a dictionary to maintain groups and a list to preserve the order of keys, which is a thoughtful design choice. These characteristics suggest that the method is well-designed and likely to be retained for its utility in organizing and processing data collections."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q27.py,Store,1,1.3440409770490404e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q16.py,CatalogSale,1,4.1399375473943306e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q59.py,Auto1,0,0.9999898700118929,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, this implementation uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This could lead to confusion and incorrect usage, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q73.py,StoreSale,0,0.9999910602998366,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q46.py,Store,0,0.999985261023967,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the implementation here uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list, set, or dictionary. This misuse of `__contains__` is likely to lead to confusion and incorrect behavior, as it does not align with the expected functionality of checking for membership in a collection. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q72.py,Auto1,1,1.3440409770490404e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation, especially in cases where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, the method is likely to be retained as it provides a clear and functional purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q29.py,Item,0,0.9999485577825553,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate method for checking membership."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q4.py,Auto1,1,1.0467401685178159e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q76.py,Auto3,1,1.725782769012759e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation, especially in cases where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Since it provides a clear and functional purpose, it is likely to be retained in the code."
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q55.py,_Group,1,2.4616969512093895e-10,"The method `__iter__` is a standard Python method used to make an object iterable. By returning an iterator over `self.Items`, it allows the object to be used in loops and other contexts where iteration is needed. This is a fundamental feature for many Python classes, especially those that represent collections or sequences. Unless there is a specific reason to remove iteration capability from the class, this method is likely to be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q21.py,Auto2,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list or dictionary. Therefore, the method is likely to be deleted or rewritten to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q91.py,CustomerDemographic,0,0.9999991684720096,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q34.py,,1,4.6911638017642294e-08,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The function is well-structured and provides flexibility through the use of options (opts) for various operations. Such utility functions are often retained in codebases because they encapsulate complex logic that would otherwise need to be repeated or rewritten in multiple places. Therefore, it is likely to be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q12.py,Item,0,0.9999756997690634,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical or expected behavior for `__contains__`, which is usually used for membership testing in collections like lists, sets, or dictionaries. This misuse of the method could lead to confusion and incorrect behavior when the object is used in contexts expecting standard membership testing. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q75.py,Item,0,0.9999930377415741,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"def test_TPCDS_Q31_simplified():
    assert result == [
        Auto1(
            ca_county=""A"",
            d_year=2000,
            web_q1_q2_increase=1.5,
            store_q1_q2_increase=1.2,
            web_q2_q3_increase=1.6666666666666667,
            store_q2_q3_increase=1.3333333333333333,
        )
    ]
",tests/dataset/tpc-ds/compiler/py/q31.py,,1,2.3355930333443423e-09,"The method `test_TPCDS_Q31_simplified` is a test function, which is typically used to verify the correctness of code. Test functions are generally important for maintaining code quality and ensuring that changes do not introduce bugs. The presence of an assertion indicates that this function is checking specific expected outcomes, which is a common practice in software development to ensure reliability. Therefore, it is likely that this method will be retained as part of the test suite to ensure the functionality it is testing remains correct."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q90.py,,1,2.8453347280241004e-08,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The function is well-structured and provides flexibility through options like 'where', 'sortKey', 'skip', and 'take'. Such utility functions are often retained in codebases because they encapsulate common patterns of data manipulation, making them reusable and reducing code duplication. Therefore, it is likely to be retained in the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q25.py,StoreReturn,1,2.2159489282323004e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. It is likely to survive because it provides a flexible way to access object attributes, which can be particularly useful in dynamic or reflective programming scenarios."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q15.py,DateDim,1,2.8453347280241004e-08,"The method is a simple implementation of the __getitem__ special method, which allows instances of the class to use the bracket notation (e.g., obj[key]) to access attributes. This is a common and useful pattern in Python, especially for classes that need to behave like dictionaries or provide dynamic attribute access. There is no indication that this method is redundant or harmful, so it is likely to be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q29.py,StoreSale,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"def _q0():
    _src = catalog_sales
    _rows = _query(
        _src,
        [
            {""items"": item, ""on"": lambda cs, i: cs.item == i.i_item_sk},
            {""items"": date_dim, ""on"": lambda cs, i, d: cs.date == d.d_date_sk},
            {
                ""items"": call_center,
                ""on"": lambda cs, i, d, cc: cs.call == cc.cc_call_center_sk,
            },
        ],
        {""select"": lambda cs, i, d, cc: (cs, i, d, cc)},
    )
    _groups = _group_by(
        _rows,
        lambda cs, i, d, cc: Auto2(cat=i.i_category, call=cc.cc_name, year=d.d_year),
    )
    _items1 = _groups
    return [
        Auto1(
            cat=g.key[""cat""],
            call=g.key[""call""],
            year=g.key[""year""],
            sum_sales=sum([x[0].price for x in g]),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q57.py,,1,2.646573631904765e-09,"The method _q0() appears to be a part of a data processing pipeline, likely used for querying and aggregating data from a sales catalog. It performs operations such as joining tables, grouping data, and calculating sums, which are common tasks in data analysis and reporting. These operations are essential for generating insights from data, and unless there is a significant change in the data processing requirements or the method is replaced by a more efficient or updated version, it is likely to be retained. Therefore, the method is predicted to survive."
survived,"def test_TPCDS_Q81_sample():
    assert result == 81.0
",tests/dataset/tpc-ds/compiler/py/q81.py,,1,5.3157849718487075e-08,"The method `test_TPCDS_Q81_sample` is a test function, likely part of a test suite for a larger codebase. Test functions are generally not deleted unless they are redundant, incorrect, or the functionality they test is no longer relevant. Since this function is asserting a specific result, it seems to be a valid test case. Without additional context indicating that this test is obsolete or incorrect, it is reasonable to assume it will be retained to ensure the correctness of the code it tests."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q35.py,Auto2,0,0.9999898700118929,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q40.py,,1,7.73442280641062e-08,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially in scenarios where data needs to be manipulated in a flexible and dynamic way. The function is well-structured and covers various cases for joining and filtering data, which suggests it is a mature piece of code that serves a specific purpose. Unless there is a significant change in the requirements or a better alternative is developed, such utility functions are likely to be retained in the codebase due to their usefulness."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q18.py,Customer,1,3.653482080241728e-08,"The method is a simple implementation of the __getitem__ special method, which allows instances of the class to use the bracket notation (e.g., obj[key]) to access attributes. This is a common and useful pattern in Python, especially for classes that aim to mimic dictionary-like behavior. It provides a clear and concise way to access attributes dynamically, which can be very useful in various applications. There is no indication that this method is redundant or harmful, so it is likely to be retained."
survived,"def _q0():
    _src = store_sales
    _rows = _query(
        _src,
        [
            {""items"": item, ""on"": lambda ss, i: ss.item == i.i_item_sk},
            {""items"": date_dim, ""on"": lambda ss, i, d: ss.date == d.d_date_sk},
        ],
        {""select"": lambda ss, i, d: (ss, i, d)},
    )
    _groups = _group_by(_rows, lambda ss, i, d: i.i_manufact_id)
    _items1 = _groups
    return [
        Auto2(
            manu=g.key,
            sum_sales=sum([x[0].price for x in g]),
            avg_sales=(
                sum([x[0].price for x in g]) / len([x[0].price for x in g])
                if [x[0].price for x in g]
                else 0
            ),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q53.py,,1,1.955568070542584e-08,"The method '_q0' is a private function (indicated by the underscore prefix) that performs a specific query operation on sales data. It joins sales data with item and date dimensions, groups the results by manufacturer ID, and calculates the sum and average sales for each manufacturer. This type of function is typically used in data processing or reporting tasks, which are common in business applications. Since it performs a useful operation and there is no indication of it being obsolete or replaced, it is likely to be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q46.py,Auto1,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement the intended functionality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q77.py,Auto7,0,0.999964643742472,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate membership check."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q40.py,CatalogSale,0,0.999876605372333,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose suggests that it might be deleted or refactored to align with conventional usage."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q72.py,HouseholdDemographic,0,0.999983298584886,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q49.py,Auto1,1,4.6911638017642294e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q6.py,Item,1,1.6052280526088547e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a common and useful pattern for dynamic attribute access, especially in cases where the object is used like a dictionary or needs to provide flexible access to its attributes. Therefore, this method is likely to be useful and relevant in many contexts, suggesting it will survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q98.py,DateDim,0,0.9999921107349486,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"def test_TPCDS_Q15_zip():
    assert filtered == [Auto1(ca_zip=""85669"", sum_sales=600.0)]
",tests/dataset/tpc-ds/compiler/py/q15.py,,1,9.237449576640118e-09,"The method `test_TPCDS_Q15_zip` is a test function, likely part of a test suite for a larger codebase. Test functions are generally not deleted unless they are redundant, incorrect, or replaced by more comprehensive tests. This function appears to be a simple assertion test, which is common in test-driven development to ensure specific functionality or data integrity. Without additional context indicating that this test is obsolete or incorrect, it is reasonable to assume it will survive."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q37.py,_Group,1,5.905303995456778e-10,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be useful and necessary for the class's functionality, leading to its survival."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q97.py,,1,1.1253518384332553e-07,"The method '_key' is a utility function that is likely used internally within a module or class to generate a key for sorting purposes. It is a private method (indicated by the underscore prefix) and seems to be a helper function that converts the result of 'opts[""sortKey""](*it)' into a string if it is a list, tuple, or dictionary. This kind of functionality is common in sorting operations where keys need to be comparable. Since it serves a specific purpose and is not overly complex or redundant, it is likely to be retained in the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q84.py,Customer,1,2.646573631904765e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python to allow more flexible and dynamic access to object properties. Therefore, this method is likely to be Survived."
survived,"def _avg(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""avg() expects list or group"")
    if not v:
        return 0
    s = 0.0
    for it in v:
        if isinstance(it, (int, float)):
            s += float(it)
        else:
            raise Exception(""avg() expects numbers"")
    return s / len(v)
",tests/dataset/tpc-ds/compiler/py/q28.py,,1,9.237449576640118e-09,"The method '_avg' is a utility function that calculates the average of a list of numbers. It includes error handling for non-list inputs and non-numeric elements within the list. Such utility functions are commonly used in various applications to perform basic operations on data structures. The method is well-defined, handles edge cases (like empty lists), and raises exceptions for invalid inputs, which makes it robust. Therefore, it is likely to be retained in the codebase as it provides a useful and reusable functionality."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q67.py,Reason,1,7.194132978569833e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, this method is likely to be retained as it provides a clear and useful functionality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q20.py,Auto3,0,0.999964643742472,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list or dictionary. Therefore, the method is likely to be deleted or rewritten to correctly implement membership checking."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q54.py,,1,1.522997951276035e-08,"The method '_key' is a utility function that is likely used internally within a module or class to generate a key for sorting purposes. It takes an iterable 'it', applies a function 'sortKey' from a dictionary 'opts' to it, and ensures the result is a string if it's a list, tuple, or dictionary. This kind of function is common in sorting operations where custom keys are needed. Since it serves a specific purpose and is not overly complex or redundant, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q1.py,Auto1,0,0.9999038976006968,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use of `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, especially for users who expect `in` to check for membership in a collection. Therefore, it is likely that this method will be deleted or refactored to align with the expected behavior of `__contains__`."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q93.py,_Group,1,1.8189616842444243e-09,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation here is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be useful and necessary for the class's functionality, leading to its survival."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q82.py,Item,1,1.8553915987649156e-07,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful functionality for objects that need to provide dynamic attribute access. This method is likely to be retained as it provides a flexible way to access object attributes, which can be particularly useful in dynamic or reflective programming scenarios."
survived,"def _q0():
    _src = store_sales
    _rows = _query(
        _src,
        [
            {""items"": date_dim, ""on"": lambda ss, d: d.d_date_sk == ss.ss_sold_date_sk},
            {""items"": store, ""on"": lambda ss, d, s: s.s_store_sk == ss.ss_store_sk},
        ],
        {
            ""select"": lambda ss, d, s: (ss, d, s),
            ""where"": lambda ss, d, s: d.d_month_seq >= dms
            and d.d_month_seq <= dms + 11,
        },
    )
    _groups = _group_by(
        _rows, lambda ss, d, s: Auto2(state=s.s_state, county=s.s_county)
    )
    _items1 = _groups
    _items1 = sorted(
        _items1, key=lambda g: _sort_key([g.key[""state""], g.key[""county""]])
    )
    return [
        Auto1(
            s_state=g.key[""state""],
            s_county=g.key[""county""],
            total_sum=_sum([x[0].ss_net_profit for x in g]),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q70.py,,1,1.8189616842444243e-09,"The method '_q0' appears to be a utility function that performs a specific query operation on a dataset, likely within a larger codebase. It involves querying, grouping, and sorting data, which are common operations in data processing tasks. The method is not overly complex, and its functionality seems clear and purposeful. Unless there is a significant change in the requirements or the structure of the codebase, such utility functions are typically retained as they serve a specific need. Therefore, it is likely to survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q29.py,Auto3,1,2.998960815863541e-09,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be Survived."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q26.py,,1,1.1861120010657661e-08,"The method '_key' is a utility function that is likely used internally within a larger codebase to generate a key for sorting purposes. It takes an iterable 'it', applies a sorting key function from 'opts', and ensures the key is a string if it's a complex data type. This kind of function is common in data processing and sorting operations, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained in the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q40.py,Item,1,2.5109990926928157e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to survive because it provides a flexible way to access object properties, which can be particularly useful in dynamic or reflective programming scenarios."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q81.py,CatalogReturn,0,0.9999687980937693,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use of `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to better fit its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q72.py,DateDim,0,0.9999967112522585,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q4.py,,1,2.998960815863541e-09,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The function is well-structured and provides flexibility through options like 'where', 'sortKey', 'skip', and 'take'. Such utility functions are often retained in codebases because they encapsulate complex logic in a reusable manner, making them valuable for various data manipulation tasks. Therefore, it is likely to survive."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q19.py,,1,9.237449576640118e-09,"The method '_key' is a utility function that is likely used internally within a class or module to generate a key for sorting purposes. It takes an iterable 'it', applies a sorting key function from 'opts', and ensures the key is a string if it's a complex data type. This kind of method is common in data processing or sorting operations, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q17.py,Store,1,1.955568070542584e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically retrieve an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q4.py,Auto2,1,3.653482080241728e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name, which can be useful for objects that need to provide dictionary-like access to their attributes. This is a valid and potentially useful implementation, especially in cases where the object is designed to mimic a dictionary or provide flexible attribute access. Therefore, it is likely to be retained in the code."
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q6.py,,1,3.850741907939403e-09,"The method '_group_by' is a utility function that groups elements of a list based on a key function. It is a common pattern in data processing and transformation tasks. The function is generic, flexible, and can handle various types of input, making it useful in many contexts. There is no indication that it is obsolete or redundant, and it provides a clear and useful functionality. Therefore, it is likely to be retained."
survived,"def _sum(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""sum() expects list or group"")
    s = 0.0
    for it in v:
        if it is None:
            continue
        if isinstance(it, (int, float)):
            s += float(it)
        else:
            raise Exception(""sum() expects numbers"")
    return s
",tests/dataset/tpc-ds/compiler/py/q29.py,,1,1.637377179507321e-07,"The method '_sum' is a utility function that calculates the sum of a list of numbers. It includes error handling for non-list inputs and non-numeric elements within the list. This kind of utility function is often useful in various applications where data might be in different formats or types, and a robust sum function is needed. The method is well-defined, handles edge cases, and provides clear error messages, making it a candidate for survival. However, the name '_sum' is a bit generic and could potentially conflict with built-in functions or other utility functions, but this is a minor issue that can be easily resolved by renaming. Overall, the method is likely to survive as it provides a necessary and well-implemented functionality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q25.py,StoreReturn,0,0.9999599363048656,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate method for checking membership."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q73.py,Customer,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q6.py,CustomerAddres,1,1.6052280526088547e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in collections like lists or dictionaries. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid use case for `__getitem__`, especially if the object is designed to behave like a dictionary or if it needs to provide dynamic access to its attributes. Therefore, the method is likely to be useful and relevant in its context, suggesting it will be Survived."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q17.py,Auto1,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which is usually used for membership testing in collections like lists, sets, or dictionaries. This misuse of `__contains__` could lead to confusion and unexpected behavior, as it does not align with the standard use case of checking membership in a collection. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q33.py,Auto2,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q26.py,,1,1.444980317078884e-07,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be used in various data processing scenarios, making it versatile and potentially useful in many contexts. The function is not overly specific to a single use case, which increases its chances of being retained for future use. Additionally, the function is well-structured and covers various edge cases, such as handling missing data and applying conditions. These factors contribute to its likelihood of survival."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q72.py,Auto2,1,8.152020648014727e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to behave like a dictionary or similar container, allowing attribute access via keys. Since this method provides a clear and functional purpose, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q14.py,WebSale,0,0.9999980052698925,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the typical or expected behavior for `__contains__`, which should check for membership in a collection like a list, set, or dictionary. Therefore, this method is likely to be deleted or refactored to align with the expected behavior of `__contains__`."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q16.py,,1,1.0467401685178159e-08,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The function is well-structured and provides flexibility through options like 'where', 'sortKey', 'skip', and 'take'. Such utility functions are often retained in codebases because they encapsulate common patterns of data manipulation, making them reusable and reducing code duplication. Therefore, it is likely to be retained."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q12.py,_Group,1,2.1024340680345882e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes. The code snippet shows a typical pattern of initializing instance variables, which is a common and necessary practice in class definitions. Therefore, it is unlikely that this method will be deleted."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q73.py,HouseholdDemographic,1,2.2159489282323004e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a common and useful pattern for dynamic attribute access, especially in classes that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q39.py,Inventory,1,6.348800075736417e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be retained as it serves a clear purpose and follows Python's conventions for special methods."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q39.py,_Group,1,5.60279640614594e-09,"The method is a constructor for a class, initializing instance variables. It sets up the 'key' and two lists, 'Items' and 'items', which are references to the same list. This is a common pattern in Python to initialize object state, and there is no indication of redundancy or error. Therefore, it is likely to be retained in the code."
survived,"def test_TPCDS_Q61_simplified():
    assert result == 61
",tests/dataset/tpc-ds/compiler/py/q61.py,,1,1.2098660619383578e-06,"The method `test_TPCDS_Q61_simplified` is a test function that asserts whether the variable `result` is equal to 61. This is a typical pattern in unit testing where a specific outcome is expected. The method is likely part of a test suite for a larger application or system, possibly related to a database or query system given the name `TPCDS` (which stands for TPC-DS, a decision support benchmark). Test functions are generally not deleted unless they are redundant or replaced by more comprehensive tests. Since this function serves a clear purpose in verifying a specific condition, it is more likely to be maintained or modified rather than deleted."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q18.py,Auto1,0,0.9998204719779977,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical or expected behavior for `__contains__`, which is usually used for membership testing in collections like lists, sets, or dictionaries. This misuse of the method could lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership testing. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q52.py,,1,4.6911638017642294e-08,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The function is well-structured and provides flexibility through the use of options (opts) for various operations. Such utility functions are often retained in codebases because they encapsulate complex logic that would otherwise need to be repeated or rewritten in multiple places. Therefore, it is likely to be retained for its utility and flexibility."
survived,"def average(xs):
    if len(xs) == 0:
        return 0.0
    sum = 0.0
    for x in xs:
        sum = sum + x
    return sum / float(len(xs))
",tests/dataset/tpc-ds/compiler/py/q65.py,,1,2.3355930333443423e-09,"The method 'average' is a basic utility function that calculates the average of a list of numbers. It handles the edge case of an empty list by returning 0.0, which is a reasonable default behavior. The logic is straightforward and correct, making it a useful function in many contexts. Therefore, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q99.py,Auto1,0,0.9999485577825553,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually implemented to check for membership in a collection like a list, set, or dictionary. This misuse of `__contains__` could lead to confusion and unexpected behavior, as it does not align with the standard behavior expected from this method. Therefore, it is likely that this method will be deleted or refactored to better fit its intended purpose."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q87.py,StoreSale,1,6.825604231969389e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q59.py,,1,1.275190675769241e-07,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It appears to be a utility function that could be part of a larger data processing or querying system. Such functions are often essential in applications that require dynamic data manipulation, especially in systems that mimic SQL-like operations in a non-SQL environment. Given its utility and the fact that it encapsulates a significant amount of logic for data processing, it is likely to be retained in the codebase unless there is a major refactor or a shift to a different data processing paradigm."
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q99.py,,1,9.237449576640118e-09,"The method '_group_by' is a utility function that groups elements of a list based on a key function. It is a common pattern in data processing and transformation tasks. The function is generic, flexible, and can handle various input types, making it useful in many contexts. Unless there is a specific reason to remove it, such as redundancy or a better alternative, it is likely to be retained."
survived,"def _q0():
    _src = inventory
    _rows = _query(
        _src,
        [{""items"": date_dim, ""on"": lambda inv, d: inv.inv_date_sk == d.d_date_sk}],
        {
            ""select"": lambda inv, d: (inv, d),
            ""where"": lambda inv, d: d.d_date < ""2000-03-15"",
        },
    )
    _groups = _group_by(
        _rows, lambda inv, d: Auto3(w=inv.inv_warehouse_sk, i=inv.inv_item_sk)
    )
    _items1 = _groups
    return [
        Auto2(
            w=g.key[""w""], i=g.key[""i""], qty=sum([x[0].inv_quantity_on_hand for x in g])
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q21.py,,1,9.237449576640118e-09,"The method _q0() is a private function (indicated by the underscore prefix) that performs a specific query operation on an inventory dataset. It filters data based on a date condition, groups the results, and then processes these groups to return a list of Auto2 objects. The method seems to be part of a larger codebase that deals with inventory management or data processing. Since it performs a specific and potentially useful operation, it is likely to be retained unless the entire functionality it supports is deprecated or refactored. Without additional context indicating that this functionality is obsolete or replaced, it is reasonable to predict that the method will survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q70.py,DateDim,0,0.9999756997690634,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute in an object, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q21.py,DateDim,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation, especially in cases where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, it is likely to be retained as it provides a clear and functional purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q11.py,StoreSale,0,0.9999546021442518,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate method for checking membership in the intended context."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q57.py,Auto4,1,1.1253518384332553e-07,"The method is a simple implementation of the __getitem__ special method, which allows an object to use the bracket notation (obj[key]) to access its attributes. This is a common and useful pattern in Python, especially for classes that need to provide dictionary-like access to their attributes. It is likely to be retained as it provides a clear and concise way to access object attributes using keys, enhancing the flexibility and usability of the class."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q35.py,Customer,1,2.0611536181902033e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a common and useful pattern for dynamic attribute access, especially in cases where the object is used like a dictionary or needs to provide flexible access to its attributes. Therefore, this method is likely to be useful and relevant in many contexts, suggesting it will survive."
survived,"def test_TPCDS_Q16_shipping():
    assert filtered == [
        Auto1(order_count=1, total_shipping_cost=5.0, total_net_profit=20.0)
    ]
",tests/dataset/tpc-ds/compiler/py/q16.py,,1,3.581747929000289e-10,"The method `test_TPCDS_Q16_shipping` is a test function, likely part of a test suite for a larger codebase. Test functions are generally not deleted unless they are redundant, incorrect, or replaced by more comprehensive tests. This function appears to be a straightforward assertion test, which is common in test-driven development to ensure specific functionality works as expected. Without additional context indicating that this test is obsolete or incorrect, it is reasonable to predict that it will survive."
survived,"def abs(x):
    if x >= 0.0:
        return x
    else:
        return -x
",tests/dataset/tpc-ds/compiler/py/q47.py,,0,0.9999810748526188,"The method is a custom implementation of the absolute value function, which is already provided by Python's standard library as `abs()`. Redefining built-in functions is generally discouraged as it can lead to confusion and unexpected behavior in the code. Therefore, it is likely that this method will be deleted in favor of using the built-in `abs()` function, which is more efficient and widely understood."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q77.py,DateDim,0,0.999985261023967,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q23.py,DateDim,1,6.348800075736417e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern and does not have any apparent issues or redundancies that would necessitate its deletion. Therefore, it is likely to be retained in the code."
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q77.py,,1,9.237449576640118e-09,"The method '_group_by' is likely to survive because it provides a useful utility function for grouping elements of a list based on a key function. This is a common requirement in data processing and analysis tasks. The method is flexible, allowing for different types of input (lists, tuples, or single elements) and handles complex keys by converting them to a string representation. Additionally, it maintains the order of first occurrence of each group, which can be important for certain applications. These features make it a valuable tool in a programmer's toolkit."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q82.py,StoreSale,0,0.999983298584886,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys. However, this implementation uses `hasattr`, which checks if an object has an attribute with the given name. This is not the intended use of `__contains__`, as it should be used for membership testing in collections, not for checking attributes. This misuse of the method is likely to lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership testing. Therefore, it is likely to be deleted or refactored to correctly implement membership testing."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q2.py,,1,3.2241866333029355e-08,"The method '_key' is a utility function that is likely used internally within a class or module to generate a key for sorting purposes. It is a simple and straightforward function that converts the result of a 'sortKey' function into a string if it is a list, tuple, or dictionary. This kind of utility function is common in codebases where sorting or ordering of complex data structures is required. Since it serves a specific purpose and is not overly complex or redundant, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q50.py,Auto2,0,0.9999869928752253,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the typical or expected behavior for `__contains__`, which should check for membership in a collection like a list or dictionary. Therefore, this method is likely to be deleted or refactored to correctly implement membership checking."
survived,"def _q0():
    _src = store_sales
    _rows = _query(
        _src,
        [
            {""items"": date_dim, ""on"": lambda ss, d: ss.ss_sold_date_sk == d.d_date_sk},
            {""items"": item, ""on"": lambda ss, d, i: ss.ss_item_sk == i.i_item_sk},
            {""items"": store, ""on"": lambda ss, d, i, s: ss.ss_store_sk == s.s_store_sk},
        ],
        {
            ""select"": lambda ss, d, i, s: (ss, d, i, s),
            ""where"": lambda ss, d, i, s: d.d_year == 2000
            and (s.s_state == ""A"" or s.s_state == ""B""),
        },
    )
    _groups = _group_by(
        _rows, lambda ss, d, i, s: Auto2(category=i.i_category, _class=i.i_class)
    )
    _items1 = _groups
    _items1 = sorted(
        _items1, key=lambda g: _sort_key([g.key[""category""], g.key[""_class""]])
    )
    return [
        Auto1(
            i_category=g.key[""category""],
            i_class=g.key[""_class""],
            gross_margin=sum([x[0].ss_net_profit for x in g])
            / sum([x[0].ss_ext_sales_price for x in g]),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q36.py,,1,1.4166087846364157e-09,"The method '_q0' appears to be a utility function that performs a specific query on a dataset, processes the results, and returns a list of objects with calculated gross margins. It is likely part of a larger codebase dealing with sales data analysis. The method is well-structured, uses meaningful variable names, and performs a clear task of filtering, grouping, and sorting data. Such methods are typically retained as they encapsulate a specific functionality that might be reused or adapted in different contexts. Unless there is a significant change in the requirements or the data model, this method is likely to survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q36.py,DateDim,1,2.4300230936537083e-05,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically for list or dictionary-like objects. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid use case if the object is designed to allow attribute access via indexing. However, this implementation can be considered unconventional because `__getitem__` is usually expected to work with integer indices or keys in a dictionary-like structure, not attribute names. Despite this unconventional use, the method is functional and could be useful in specific scenarios where attribute access via indexing is desired. Therefore, it is likely to survive unless there is a strong reason to enforce more conventional use of `__getitem__`."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q54.py,Store,0,0.9999756997690634,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose is likely to lead to confusion and incorrect behavior when the method is used. Therefore, it is likely that this method will be deleted or refactored to align with its intended use."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q3.py,Auto1,1,7.73442280641062e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q90.py,WebSale,0,0.9999417087232136,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose is likely to lead to confusion and incorrect behavior when the method is used. Therefore, it is likely that this method will be deleted or refactored to align with its intended use."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q21.py,Auto1,1,2.8453347280241004e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method is functional, concise, and leverages Python's dynamic attribute access capabilities, it is likely to be retained in the codebase."
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q56.py,_Group,1,6.69158608681505e-10,"The method `__iter__` is a standard Python method used to make an object iterable. It is implemented correctly here by returning an iterator over `self.Items`. This is a common and necessary method for classes that need to support iteration, such as those representing collections or sequences. There is no indication that this method is redundant or incorrect, so it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q33.py,CatalogSale,1,2.2159489282323004e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for cases where an object needs to behave like a dictionary or list, allowing attribute access via keys. Since this method provides a flexible and Pythonic way to access object attributes, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q10.py,Auto2,0,0.999983298584886,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q39.py,Item,0,0.9999687980937693,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q46.py,Auto1,1,5.3157849718487075e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python to allow dynamic access to object attributes, especially in cases where the object is used to represent a collection of data. Therefore, this method is likely to be retained as it provides a flexible and Pythonic way to access object attributes."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q75.py,StoreSale,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a simple and effective way to allow attribute access using keys, which can be particularly useful in cases where the object is designed to mimic a dictionary or when the attributes are dynamically determined. Therefore, this method is likely to be retained as it provides a clear and functional purpose."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q61.py,Sale,1,5.3157849718487075e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q54.py,_Group,1,2.2159489282323004e-08,"The method is a constructor for a class, initializing an instance variable 'key' and two lists 'Items' and 'items'. The 'items' list is just a reference to 'Items', which might be redundant but not harmful. Constructors are essential for object instantiation, and this one does not contain any errors or deprecated practices that would warrant deletion. Therefore, it is likely to survive."
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q27.py,,1,1.3440409770490404e-08,"The method '_group_by' is a utility function that groups elements of a list based on a key function. It is a common pattern in data processing and transformation tasks. The function is generic, flexible, and can handle various input types, making it useful in many contexts. Unless there is a specific reason to remove it, such as redundancy or a better alternative, it is likely to be retained."
survived,"def _sum(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""sum() expects list or group"")
    s = 0.0
    for it in v:
        if it is None:
            continue
        if isinstance(it, (int, float)):
            s += float(it)
        else:
            raise Exception(""sum() expects numbers"")
    return s
",tests/dataset/tpc-ds/compiler/py/q79.py,,1,2.5109990926928157e-08,"The method '_sum' is a utility function that calculates the sum of a list of numbers, with additional handling for objects that have an 'Items' attribute. It includes error handling for non-list inputs and non-numeric elements within the list. This function is likely to survive because it provides a specific utility that might be used in various contexts where such a summation is needed, especially when dealing with objects that encapsulate their data in an 'Items' attribute. The function is well-defined, handles exceptions, and performs a common operation, making it useful and reusable."
survived,"def test_TPCDS_Q2_result():
    assert result == [Auto1(d_week_seq1=1, sun_ratio=0.5, mon_ratio=0.5)]
",tests/dataset/tpc-ds/compiler/py/q2.py,,1,6.348800075736417e-09,"The method `test_TPCDS_Q2_result` is a unit test function that checks if the variable `result` matches a specific expected output. Unit tests are crucial for ensuring code correctness and reliability, especially in larger projects. They help in identifying bugs early and ensure that changes in the code do not break existing functionality. Given the importance of testing in software development, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q65.py,_Group,1,1.4166087846364157e-09,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is correctly implemented to return the length of `self.Items`, which suggests that `self.Items` is likely a list or a similar collection. This is a standard and expected implementation for making a custom object compatible with the `len()` function, enhancing the usability of the class. Therefore, this method is likely to be retained as it provides essential functionality."
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q37.py,_Group,1,5.60279640614594e-09,"The method is a standard implementation of the `__iter__` method in Python, which is used to make an object iterable. It returns an iterator over the `Items` attribute of the object. This is a common and useful pattern in Python, especially for classes that are meant to represent collections or sequences. There is no indication that this method is redundant or incorrect, so it is likely to be retained."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q12.py,,1,1.1253518384332553e-07,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The function is well-structured and provides flexibility through options like 'where', 'sortKey', 'skip', 'take', and 'select'. Such a function is likely to be retained in a codebase because it encapsulates a lot of functionality that would otherwise need to be implemented repeatedly in different parts of the code. Therefore, it is more likely to be maintained and possibly refactored for optimization rather than deleted."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q7.py,Auto2,1,2.8453347280241004e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, this method is likely to be retained as it provides a clear and useful functionality."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q8.py,StoreSale,1,4.944450477491054e-09,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be retained as it serves a clear purpose and follows Python's design principles."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q30.py,Auto2,1,1.1861120010657661e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern and does not have any apparent issues that would necessitate its removal. Therefore, it is likely to be retained in the code."
survived,"def _sum(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""sum() expects list or group"")
    s = 0.0
    for it in v:
        if it is None:
            continue
        if isinstance(it, (int, float)):
            s += float(it)
        else:
            raise Exception(""sum() expects numbers"")
    return s
",tests/dataset/tpc-ds/compiler/py/q13.py,,1,6.348800075736417e-09,"The method '_sum' is a utility function that calculates the sum of a list of numbers. It includes error handling for non-list inputs and non-numeric elements within the list. This functionality is fundamental and commonly needed in various applications, making it unlikely to be deleted. The method is well-defined, checks for valid input types, and handles exceptions appropriately, which are good practices in programming. Therefore, it is more likely to be retained in the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q94.py,WebSale,1,1.275190675769241e-07,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be retained because it provides a flexible way to access object properties, which can be particularly useful in dynamic or reflective programming scenarios. It aligns with Python's dynamic nature and is a common pattern in Python code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q22.py,Auto2,0,0.9999251538028718,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list or dictionary. This misuse of the method suggests it may be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q51.py,Auto3,1,1.275190675769241e-07,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a common and useful pattern for dynamic attribute access, especially in classes that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q93.py,_Group,1,2.4616969512093895e-10,"The method `__iter__` is a standard Python method used to make an object iterable. By returning an iterator over `self.Items`, it allows the object to be used in loops and other contexts where iteration is needed. This is a fundamental feature for many Python classes, especially those that represent collections or sequences. Unless there is a specific reason to remove iteration capability from the class, this method is likely to be retained."
survived,"def test_TPCDS_Q87_sample():
    assert result == 87.0
",tests/dataset/tpc-ds/compiler/py/q87.py,,1,7.3382086014706e-07,"The method `test_TPCDS_Q87_sample` is a test function that contains a single assertion checking if `result` equals 87.0. Without additional context, such as the presence of a testing framework or the definition of `result`, it's difficult to determine its utility. However, test functions are generally important for ensuring code correctness. If this test is part of a larger suite and `result` is defined elsewhere, it is likely to be retained to verify the correctness of the code. If `result` is undefined or the test is not part of a structured testing framework, it might be considered for deletion. Given the lack of context, I'll assume it's part of a testing suite and predict it will survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q88.py,StoreSale,1,6.023574641292144e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. It is a simple and effective way to provide dynamic access to object attributes, which can be particularly useful in data handling or configuration classes. Therefore, this method is likely to be retained as it serves a clear purpose and is implemented correctly."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q24.py,_Group,1,3.3982678079468468e-09,"The method `__len__` is a special method in Python that is used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q74.py,DateDim,0,0.9997965729390125,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method could lead to confusion and unexpected behavior, especially if the object is expected to behave like a collection. Therefore, it is likely that this method will be deleted or refactored to align with the expected behavior of `__contains__`."
survived,"def _q12():
    _src = per_channel
    _rows = _query(_src, [], {""select"": lambda p: p})
    _groups = _group_by(
        _rows,
        lambda p: Auto8(
            channel=p.get(""channel"") if isinstance(p, dict) else getattr(p, ""channel""),
            id=p.get(""id"") if isinstance(p, dict) else getattr(p, ""id""),
        ),
    )
    _items13 = _groups
    _items13 = sorted(_items13, key=lambda g: _sort_key(g.key[""channel""]))
    return [
        Auto1(
            channel=g.key[""channel""],
            id=g.key[""id""],
            sales=_sum(
                [
                    (
                        (x.get(""p"") if isinstance(x, dict) else getattr(x, ""p"")).get(
                            ""sales""
                        )
                        if isinstance(
                            x.get(""p"") if isinstance(x, dict) else getattr(x, ""p""), dict
                        )
                        else getattr(
                            x.get(""p"") if isinstance(x, dict) else getattr(x, ""p""),
                            ""sales"",
                        )
                    )
                    for x in g
                ]
            ),
            returns=_sum(
                [
                    (
                        (x.get(""p"") if isinstance(x, dict) else getattr(x, ""p"")).get(
                            ""returns""
                        )
                        if isinstance(
                            x.get(""p"") if isinstance(x, dict) else getattr(x, ""p""), dict
                        )
                        else getattr(
                            x.get(""p"") if isinstance(x, dict) else getattr(x, ""p""),
                            ""returns"",
                        )
                    )
                    for x in g
                ]
            ),
            profit=_sum(
                [
                    (
                        (x.get(""p"") if isinstance(x, dict) else getattr(x, ""p"")).get(
                            ""profit""
                        )
                        if isinstance(
                            x.get(""p"") if isinstance(x, dict) else getattr(x, ""p""), dict
                        )
                        else getattr(
                            x.get(""p"") if isinstance(x, dict) else getattr(x, ""p""),
                            ""profit"",
                        )
                    )
                    for x in g
                ]
            ),
        )
        for g in _items13
    ]
",tests/dataset/tpc-ds/compiler/py/q77.py,,1,1.0467401685178159e-08,"The method _q12 appears to be a utility function that processes data from a source, groups it by certain attributes, and then calculates aggregated values like sales, returns, and profit for each group. This type of function is typically useful in data processing and analysis tasks, especially in business intelligence or reporting contexts. The function is well-structured and performs a clear task, which suggests it is likely to be useful in its current context. Therefore, it is more likely to be retained rather than deleted."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q6.py,_Group,1,1.955568070542584e-08,"The method is a constructor for a class, initializing the instance variables 'key', 'Items', and 'items'. It is a fundamental part of the class structure, allowing for the creation of objects with specific attributes. Constructors are essential for object-oriented programming, and there is no indication that this constructor is redundant or incorrect. Therefore, it is likely to be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q13.py,CustomerDemographics,0,0.9999869928752253,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement the intended functionality."
survived,"def _q0():
    _groups = {}
    _order = []
    for s in sales:
        _k = Auto2(mgr=s.mgr)
        _ks = str(_k)
        g = _groups.get(_ks)
        if not g:
            g = _Group(_k)
            _groups[_ks] = g
            _order.append(_ks)
        g.Items.append(s)
    _items1 = [_groups[k] for k in _order]
    return [
        Auto1(mgr=g.key[""mgr""], sum_sales=sum([x.amount for x in g])) for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q63.py,,0,0.9999999317439577,"The method _q0() is likely to be deleted (0) because it contains several issues that suggest it is not well-maintained or optimized. Firstly, the method uses a custom class Auto2 to create keys for grouping, but the implementation details of Auto2 are not provided, making it difficult to understand its purpose or effectiveness. Secondly, the method uses a dictionary and a list to manage groups and their order, which could be simplified or optimized using more modern data structures or libraries. Thirdly, the method's logic for summing sales and creating Auto1 objects is somewhat convoluted and could be refactored for clarity and efficiency. These factors suggest that the method may be considered for deletion or significant refactoring."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q91.py,HouseholdDemographic,1,5.3157849718487075e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. It is likely to survive because it provides a flexible way to access object attributes, which can be particularly useful in dynamic or reflective programming scenarios."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q75.py,,1,1.3440409770490404e-08,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The function is well-structured and provides flexibility through options like 'where', 'sortKey', 'skip', and 'take'. Such utility functions are often retained in codebases because they encapsulate common patterns of data manipulation, making them reusable and reducing code duplication. Therefore, it is likely to be retained in the codebase."
survived,"    async def get_population(sim_id: str, _: None = Depends(verify_token)) -> PopulationResponse:
        """"""Return the final population for ``sim_id`` if available.""""""
        result = _simulations.get(sim_id)
        if result is None:
            raise HTTPException(status_code=404)
        return PopulationResponse(id=sim_id, population=result.population)
",src/interface/api_server.py,,1,7.582560422162384e-10,"The method 'get_population' is likely to survive because it performs a specific and useful function within an application. It retrieves the population data for a given simulation ID, which is a common requirement in applications dealing with simulations or data retrieval. The use of async and dependency injection with 'Depends' indicates that it is designed to work efficiently within an asynchronous framework, such as FastAPI. Additionally, it handles errors gracefully by raising an HTTPException if the simulation ID is not found, which is good practice for robust API design."
survived,"async def async_setup(hass: HomeAssistant, config: ConfigType) -> bool:
    """"""Set up the Gree component from yaml.""""""
    return True
",custom_components/gree/__init__.py,,1,3.3982678079468468e-09,"The method `async_setup` is a standard part of the Home Assistant integration setup process, particularly for setting up components from YAML configuration. It is an asynchronous function, which aligns with modern practices in Home Assistant for non-blocking operations. The method is simple and returns `True`, indicating successful setup, which is a common pattern. There is no indication that this method is deprecated or unnecessary, so it is likely to survive."
survived,"    async def async_get_options_flow(self, config_entry: config_entries.ConfigEntry) -> config_entries.OptionsFlow:
        return OptionsFlowHandler(config_entry)
",custom_components/gree/config_flow.py,ConfigFlow,1,2.8453347280241004e-08,"The method `async_get_options_flow` is an asynchronous method that returns an instance of `OptionsFlowHandler` based on a `config_entry`. This method is likely part of a larger framework or system that deals with configuration entries and options flows, possibly in a home automation or similar system. Given the context, this method is likely essential for handling configuration options asynchronously, which is a common requirement in modern software systems to improve performance and responsiveness. Therefore, it is unlikely to be deleted as it serves a specific purpose in the system's architecture."
survived,"    def validate(self) -> ValidationResult:
        errors: List[str] = []
        try:
            metadata = self._load_metadata()
        except Exception as exc:  # pragma: no cover - invalid json path rare
            errors.append(f""invalid bundle metadata: {exc}"")
            return ValidationResult(success=False, errors=errors, coverage=0.0)

        self._validate_checksums(metadata, errors)
        self._validate_requirements(errors)
        self._validate_agent(errors)

        if not errors:
            self._run_tests(errors)

        success = not errors
        return ValidationResult(success=success, errors=errors, coverage=0.0)",src/meta_agent/bundle_validator.py,BundleValidator,1,5.905303995456778e-10,"The method 'validate' is a comprehensive validation function that handles exceptions, performs multiple validation checks, and returns a structured result. It is well-structured and serves a clear purpose in ensuring data integrity and correctness. The use of a ValidationResult object to encapsulate the success status and errors is a good practice, making the method's output easy to understand and use. Additionally, the method includes a mechanism to handle rare exceptions, which indicates robustness. These factors suggest that the method is useful and likely to be retained in the codebase."
survived,"def test_bundle_validator_test_failure(tmp_path: Path) -> None:
    bundle_dir = create_sample_bundle(tmp_path)
    failing_test = bundle_dir / ""tests"" / ""test_main.py""
    failing_test.write_text(""def test_fail():\n    assert False"")
    # update checksum so validation reaches test execution
    import hashlib
    import json

    bundle_file = bundle_dir / ""bundle.json""
    data = json.loads(bundle_file.read_text())
    digest = hashlib.sha256(failing_test.read_bytes()).hexdigest()
    data[""custom""][""checksums""][""tests/test_main.py""] = digest
    bundle_file.write_text(json.dumps(data))
    validator = BundleValidator(bundle_dir)
    result = validator.validate()
    assert result.success is False
    assert any(""tests failed"" in e for e in result.errors)",tests/test_bundle_validator.py,,1,2.8453347280241004e-08,"The method 'test_bundle_validator_test_failure' is a unit test designed to ensure that the BundleValidator correctly identifies a failing test within a bundle. It creates a sample bundle, introduces a failing test, updates the checksum, and then validates the bundle. The test asserts that the validation fails and that the error message indicates a test failure. This is a typical and necessary test to ensure the robustness of the validation process, especially in handling test failures. Therefore, it is unlikely to be deleted as it serves a critical role in maintaining code quality."
survived,"    def __init__(self, bundle_dir: str | Path) -> None:
        self.bundle_dir = Path(bundle_dir)
",src/meta_agent/bundle_validator.py,BundleValidator,1,1.1253518384332553e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming in Python. Constructors are essential for initializing new objects with specific attributes, and this particular constructor is setting up a path attribute for the object. There is no indication that this method is redundant or unnecessary, and it follows a common pattern for initializing path-related attributes. Therefore, it is unlikely to be deleted."
survived,"    def _validate_checksums(self, metadata: BundleMetadata, errors: List[str]) -> None:
        checksums = metadata.custom.get(""checksums"", {})
        for rel, expected in checksums.items():
            path = self.bundle_dir / rel
            if not path.exists():
                errors.append(f""missing file {rel}"")
                continue
            digest = hashlib.sha256(path.read_bytes()).hexdigest()
            if digest != expected:
                errors.append(f""checksum mismatch for {rel}"")
",src/meta_agent/bundle_validator.py,BundleValidator,1,1.4166087846364157e-09,"The method '_validate_checksums' is a utility function that checks the integrity of files by comparing their checksums against expected values. This is a common and essential operation in software systems that deal with file storage and transfer, ensuring data integrity and detecting corruption. The method is well-defined, performs a specific task, and is likely to be useful in contexts where data integrity is critical. Therefore, it is unlikely to be deleted."
survived,"def test_is_yaml_detects_yaml_extensions() -> None:
    """"""Test detection of YAML file extensions.""""""
    assert yaml_utils.is_yaml(""config.yaml"")
    assert yaml_utils.is_yaml(""config.yml"")
",tests/unit/utils/test_yaml_utils.py,,1,2.0611536181902033e-09,"The method `test_is_yaml_detects_yaml_extensions` is a unit test function that checks if the `is_yaml` function correctly identifies files with YAML extensions. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with file format detection, which can be error-prone. This test is simple, clear, and directly tests the functionality of the `is_yaml` method, making it a valuable part of the test suite. Therefore, it is likely to be retained."
survived,"def test_chat_formatter_r1_style():
    training_data = ModelTrainingData(
        input=""test input"",
        system_message=""system message"",
        final_output=""test output"",
        thinking=""thinking output"",
        thinking_instructions=None,
        thinking_final_answer_prompt=None,
        thinking_r1_style=True,
    )
    expected = generate_chat_message_response(training_data)[""messages""]
    combined = expected[-1][""content""]

    formatter = get_chat_formatter(
        strategy=ChatStrategy.final_and_intermediate_r1_compatible,
        system_message=""system message"",
        user_input=""test input"",
    )

    first = formatter.next_turn()
    assert [m.__dict__ for m in first] == expected[:2]

    assert formatter.next_turn(combined) is None
    assert formatter.message_dicts() == expected",libs/core/kiln_ai/adapters/chat/test_chat_formatter.py,,1,4.6911638017642294e-08,"The method `test_chat_formatter_r1_style` is a unit test designed to verify the functionality of a chat formatter. It checks if the formatter correctly processes input and produces the expected output. Unit tests are crucial for ensuring code reliability and are typically retained unless the functionality they test is deprecated or the testing framework changes significantly. Since the method is actively testing a feature, it is likely to be maintained as long as the feature it tests is relevant."
deleted,"    def next_turn(
        self, previous_output: str | None = None
    ) -> Optional[List[ChatMessage]]:
        if self._state == ""start"":
            msgs = [
                ChatMessage(""system"", self.system_message),
                ChatMessage(""user"", self.user_input),
            ]
            self._state = ""awaiting_final""
            self._messages.extend(msgs)
            return msgs

        if self._state == ""awaiting_final"":
            if previous_output is None:
                raise ValueError(""previous_output required for final step"")
            self._messages.append(ChatMessage(""assistant"", previous_output))
            self._state = ""done""
            return None

        return None
",libs/core/kiln_ai/adapters/chat/chat_formatter.py,FinalOnlyFormatter,1,5.211412485172657e-10,"The method 'next_turn' is well-structured and serves a clear purpose in managing the state of a chat interaction. It handles different states ('start', 'awaiting_final', and 'done') and processes messages accordingly. The use of state management and message handling is common in chat systems, making this method likely to be useful and relevant. Additionally, the method includes error handling for missing 'previous_output', which is a good practice. Therefore, it is likely to be retained in the codebase."
deleted,"    def next_turn(
        self, previous_output: str | None = None
    ) -> Optional[List[ChatMessage]]:
        if self._state == ""start"":
            msgs = [
                ChatMessage(""system"", self.system_message),
                ChatMessage(""user"", self.user_input),
            ]
            self._state = ""awaiting_final""
            self._messages.extend(msgs)
            return msgs

        if self._state == ""awaiting_final"":
            if previous_output is None:
                raise ValueError(""previous_output required for final step"")
            self._messages.append(ChatMessage(""assistant"", previous_output))
            self._state = ""done""
            return None

        return None
",libs/core/kiln_ai/adapters/chat/chat_formatter.py,R1Formatter,1,2.3355930333443423e-09,"The method 'next_turn' is well-structured and serves a clear purpose in managing the state of a chat interaction. It handles different states ('start', 'awaiting_final', and 'done') and processes messages accordingly. The use of state management and message handling is common in chat systems, making this method likely to be useful and relevant. Additionally, the method includes error handling for missing 'previous_output', which is a good practice. Therefore, it is likely to be retained in the codebase."
survived,"    async def post(
        self,
        url: str,
        data: Optional[bytes] = None,
        json: Optional[JSON] = None,
        headers: Optional[dict[str, str]] = None,
    ) -> ClientResponse:
        body = json if json is not None else data
        return await self.request(url, ""post"", headers=headers, body=body)",src/tests/http/clients/webob.py,WebobHttpClient,1,1.4166087846364157e-09,"The method is a standard implementation of an HTTP POST request in an asynchronous context. It is well-structured, using type hints for better readability and maintainability. The method provides flexibility by allowing either JSON or byte data to be sent in the request body, which is a common requirement in web applications. Additionally, it leverages an existing 'request' method, suggesting that it is part of a larger, reusable HTTP client class. These factors indicate that the method is useful, follows good coding practices, and is likely to be retained in the codebase."
survived,"    def post_data(self) -> Mapping[str, Union[str, bytes]]:
        return self.request.POST
",src/graphql_server/webob/views.py,WebobHTTPRequestAdapter,1,3.850741907939403e-09,"The method 'post_data' is a simple utility function that returns the POST data from a request object. This is a common pattern in web development, especially in frameworks like Django, where handling POST data is a frequent task. The method is straightforward, does not have any apparent issues, and serves a clear purpose. Therefore, it is likely to be retained as it provides a useful abstraction for accessing POST data."
survived,"    def get_context(self, request: Request, response: Response) -> Context:
        return {""request"": request, ""response"": response}  # type: ignore
",src/graphql_server/webob/views.py,GraphQLView,1,7.194132978569833e-09,"The method 'get_context' is a simple utility function that returns a dictionary containing the request and response objects. This kind of method is often useful in web frameworks or applications where context needs to be passed around or logged. The use of 'type: ignore' suggests that there might be some type checking issues, but it doesn't necessarily indicate a problem with the functionality. Given its utility in handling web requests and responses, it's likely to be a useful part of a larger system, and thus, it is more likely to be retained rather than deleted."
survived,"    def _do_request(
        self,
        url: str,
        method: Literal[""get"", ""post"", ""patch"", ""put"", ""delete""],
        headers: Optional[dict[str, str]] = None,
        **kwargs: Any,
    ) -> ClientResponse:
        body = kwargs.get(""body"", None)
        req = Request.blank(
            url, method=method.upper(), headers=headers or {}, body=body
        )
        resp = self.view.dispatch_request(req)
        return ClientResponse(
            status_code=resp.status_code, data=resp.body, headers=resp.headers
        )
",src/tests/http/clients/webob.py,WebobHttpClient,1,6.348800075736417e-09,"The method '_do_request' is a utility function that abstracts the process of making HTTP requests. It supports multiple HTTP methods (GET, POST, PATCH, PUT, DELETE) and allows for custom headers and additional parameters through kwargs. This kind of method is generally useful in applications that need to interact with web services or APIs, as it centralizes and simplifies the request-making process. Given its utility and flexibility, it is likely to be retained in the codebase."
survived,"    def get_root_value(self, request: Request) -> Query:
        super().get_root_value(request)  # for coverage
        return Query()
",src/tests/http/clients/webob.py,GraphQLView,0,0.9999994956527948,"The method `get_root_value` is likely to be deleted because it doesn't perform any meaningful operation. It calls a superclass method for coverage, which suggests it's only there for testing purposes, and then returns a new instance of `Query` without using the `request` parameter. This indicates that the method might be a placeholder or a stub, and if not used elsewhere in a meaningful way, it could be considered redundant and removed."
survived,"    def get_context(self, request: Request, response: Response) -> dict[str, object]:
        context = super().get_context(request, response)
        return get_context(context)
",src/tests/http/clients/webob.py,GraphQLView,0,0.9999999847700205,"The method `get_context` is likely to be deleted because it seems to be incorrectly implemented. It calls `super().get_context(request, response)` to get a context dictionary, but then it immediately calls `get_context(context)` which suggests a recursive call or a call to a function with the same name, leading to potential infinite recursion or a NameError if `get_context` is not defined elsewhere. This indicates a misunderstanding or error in the code logic, making it a candidate for deletion or significant refactoring."
survived,"def process_module(path):
    path = Path(path)
    if path in processed:
        return
    code = path.read_text()
    for dep in find_deps(code):
        dep_path = (path.parent / dep).resolve()
        if not dep_path.exists():
            dep_path = (ROOT / dep.lstrip('./')).resolve()
        if dep_path.exists():
            process_module(dep_path)
    # strip import lines
    code = re.sub(r'^\s*import[^\n]*\n', '', code, flags=re.MULTILINE)
    # strip export keywords
    code = re.sub(r'^\s*export\s+', '', code, flags=re.MULTILINE)
    processed[path] = code
    order.append(path)
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/manual_build.py,,1,2.646573631904765e-09,"The method 'process_module' is likely to survive because it performs a critical function in processing and resolving module dependencies, which is a common requirement in software projects. It reads the content of a file, identifies dependencies, and processes them recursively, ensuring that all necessary modules are handled. Additionally, it modifies the code by stripping import and export statements, which might be necessary for the specific use case. These functionalities suggest that the method is integral to the system's operation, making it unlikely to be deleted."
survived,"    def _log_retry(details: dict[str, Any]) -> None:
        _log.warning(
            ""Retry %d/%d for %s due to %s"",
            details[""tries""],
            max_tries,
            getattr(details.get(""target""), ""__name__"", ""call""),
            details.get(""exception""),
        )
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/retry.py,,1,6.69158608681505e-10,"The method '_log_retry' is a private utility function used for logging retry attempts. It is well-defined, uses standard logging practices, and is likely part of a larger system that handles retries. Such utility functions are generally useful for debugging and monitoring purposes, especially in systems where retries are common. There is no indication that this method is obsolete or redundant, so it is likely to be retained."
survived,"    async def run(self, stop_event: asyncio.Event) -> None:
        """"""Run agent cycles until ``stop_event`` is set.""""""
        await self.start()
        await self.manager.run(stop_event)
        await self.stop()
",alpha_factory_v1/backend/agent_scheduler.py,AgentScheduler,1,2.998960815863541e-09,"The method 'run' is an asynchronous function that is designed to execute a sequence of operations until a stop event is triggered. It is structured to start a process, run a manager, and then stop the process, which is a common pattern in asynchronous programming. This method is likely part of a larger system where it plays a crucial role in managing the lifecycle of an agent or task. Given its clear purpose and structured design, it is unlikely to be deleted unless the entire system undergoes a significant redesign or the functionality is no longer needed."
survived,"def init_metrics(port: int) -> None:
    """"""Initialise metric exporter.""""""
    _init_metrics(port)",alpha_factory_v1/backend/metrics.py,,0,0.9999999804443193,"The method `init_metrics` is a simple wrapper around another function `_init_metrics`. It doesn't add any additional functionality or abstraction, which makes it redundant. If `_init_metrics` is accessible and can be called directly, there's no need for this wrapper function. Therefore, it's likely to be deleted to simplify the codebase."
survived,"def _import_detectors():
    try:
        from alpha_factory_v1.demos.era_of_experience.alpha_detection import (
            detect_yield_curve_alpha,
            detect_supply_chain_alpha,
        )
    except ModuleNotFoundError:  # pragma: no cover - running as stand-alone script
        import pathlib
        import sys

        sys.path.append(str(pathlib.Path(__file__).resolve().parents[3]))
        from alpha_factory_v1.demos.era_of_experience.alpha_detection import (
            detect_yield_curve_alpha,
            detect_supply_chain_alpha,
        )
    return detect_yield_curve_alpha, detect_supply_chain_alpha
",alpha_factory_v1/demos/era_of_experience/alpha_report.py,,1,2.998960815863541e-09,"The method _import_detectors() is designed to import specific functions from a module, handling the case where the module might not be found by adjusting the system path. This is a common pattern used to ensure that the code can run both in a development environment and as a standalone script. The method is functional, handles exceptions, and provides a fallback mechanism, which are all good practices in Python programming. There is no indication that this method is obsolete or redundant, and it serves a clear purpose in the codebase. Therefore, it is likely to be retained."
survived,"def reload_devicons(lang):
    os.environ['DEVICONS_LANG'] = lang
    from ranger_devicons import devicons
    importlib.reload(devicons)
    return devicons
",tests/test_devicons.py,,1,4.363462233903899e-09,"The method 'reload_devicons' is likely to survive because it performs a specific and useful function: reloading a module with a new environment variable setting. This can be particularly useful in development or dynamic environments where the icons need to be updated based on different languages. The use of environment variables and module reloading is a common pattern in Python for managing dynamic configurations, suggesting that this method serves a practical purpose."
survived,"def _ledger(tmp: Path) -> insight_logging.Ledger:
    led = insight_logging.Ledger(str(tmp / ""led.db""), broadcast=False)
    env = messaging.Envelope(sender=""a"", recipient=""b"", payload={""v"": 1}, ts=0.0)
    led.log(env)
    return led
",tests/test_mutator.py,,1,1.1861120010657661e-08,"The method '_ledger' is a private helper function, indicated by the underscore prefix, which is commonly used in Python to denote that a function is intended for internal use within a module or class. The function itself is straightforward, creating a Ledger object, logging an envelope, and returning the ledger. This functionality seems useful for setting up or testing logging mechanisms, especially in a context where logging and messaging are important. There is no indication that this function is obsolete or redundant, and it appears to serve a clear purpose in the context of logging and message handling. Therefore, it is likely to be retained."
survived,"    def generate_diff(self, repo_path: str, spec: str, *, lines: int = 5) -> str:
        """"""Return a unified diff implementing ``spec`` inside ``repo_path``.""""""
        rel, goal = _parse_spec(spec)
        file_path = str(Path(repo_path) / rel)

        patch = """"
        if not _offline():
            prompt = (
                f""Repository: {repo_path}\n""
                f""Change: {spec}\n""
                f""Recent logs:\n{self._log_slice(lines)}\n""
                ""Produce a unified diff.""
            )
            try:
                patch = _sync_chat(prompt)
            except Exception:
                patch = """"

        if not patch:
            patch = _fallback_diff(file_path, goal)

        if self._rng.random() < 0.3:
            patch += self._random_patch(file_path)

        if not patch.endswith(""\n""):
            patch += ""\n""
        return patch",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/mutators/llm_mutator.py,LLMMutator,1,3.160881453314576e-10,"The method 'generate_diff' is likely to survive because it provides a useful functionality of generating a unified diff based on a specification and repository path. It includes error handling, a fallback mechanism, and randomness to enhance its output, making it robust and versatile. These characteristics suggest it is a well-thought-out and valuable method in its context."
survived,"def apply_patch(repo: str | Path, diff: str) -> Tuple[bool, Path]:
    """"""Apply ``diff`` to ``repo`` inside a sandbox and run tests.""""""
    src = Path(repo).resolve()
    tmp = Path(tempfile.mkdtemp(prefix=""self-evo-""))
    shutil.copytree(src, tmp, dirs_exist_ok=True)
    patcher_core.apply_patch(diff, repo_path=str(tmp))
    run_preflight(tmp)
    rc = _run_tests(tmp)
    return rc == 0, tmp
",src/self_evolution/harness.py,,1,1.2501528648238603e-09,"The method 'apply_patch' is likely to survive because it performs a specific and useful function: applying a patch to a repository in a sandbox environment and running tests. This is a common requirement in software development workflows, especially in continuous integration and deployment pipelines. The method is well-structured, using temporary directories to avoid affecting the original repository, and it integrates with other functions like 'run_preflight' and '_run_tests', indicating it is part of a larger system. Unless there are changes in the requirements or the method is replaced by a more efficient or secure alternative, it is likely to remain useful."
survived,"def self_test(patch: str) -> None:
    """"""Apply PATCH and run sandboxed tests.""""""
    registry = StakeRegistry()
    registry.set_stake(""orch"", 1.0)
    diff = Path(patch).read_text(encoding=""utf-8"")
    accepted = harness.vote_and_merge(Path.cwd(), diff, registry)
    click.echo(""accepted"" if accepted else ""rejected"")
",src/interface/cli.py,,1,9.237449576640118e-09,"The method 'self_test' is a utility function that applies a patch and runs tests in a sandboxed environment. It uses a 'StakeRegistry' to set a stake and then reads the patch file to apply it. The function then uses a 'harness' to vote and merge the patch, and outputs whether the patch was accepted or rejected. This functionality is useful for testing and validating patches in a controlled manner, which is a common requirement in software development workflows. Therefore, the method is likely to be retained as it provides essential functionality for testing patches."
survived,"def test_evolution_panel_persists_after_reload() -> None:
    dist = Path(__file__).resolve().parents[1] / (
        ""alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/dist/index.html""
    )
    url = dist.as_uri() + ""#s=1&p=3&g=3""
    try:
        with sync_playwright() as p:
            browser = p.chromium.launch()
            page = browser.new_page()
            page.goto(url)
            page.wait_for_selector(""#controls"")
            page.wait_for_function(""window.gen >= 3"")
            page.reload()
            page.wait_for_selector(""#controls"")
            page.wait_for_function(""document.querySelectorAll('#evolution-panel table tr').length > 1"")
            browser.close()
    except PlaywrightError as exc:
        pytest.skip(f""Playwright browser not installed: {exc}"")",tests/test_evolution_panel_reload.py,,1,2.2159489282323004e-08,"The method is a test function that checks the persistence of a UI element after a page reload. It uses Playwright, a popular tool for browser automation, which is commonly used in testing environments. The function is well-structured, handles exceptions, and skips the test if Playwright is not installed, making it robust and useful for ensuring UI consistency. Such test functions are crucial for maintaining software quality, especially in web applications, and are unlikely to be deleted unless the feature being tested is removed or the testing framework changes."
survived,"    def finalize(self, parts: List[doc.DocType], group: bool = True) -> doc.DocType:
        """"""Concat parts and remove trailing whitespace before grouping.""""""
        result = self._strip_trailing_ws(self.concat(parts))
        return self.group(result) if group else result
",jac/jaclang/compiler/passes/tool/doc_ir_gen_pass.py,DocIRGenPass,1,8.592166611791576e-10,"The method 'finalize' is a utility function that processes a list of document parts by concatenating them, removing trailing whitespace, and optionally grouping them. This type of method is often useful in document processing or formatting tasks, which are common in many applications. The method is concise, performs a clear function, and is likely to be used in contexts where document manipulation is required. Therefore, it is likely to be retained in the codebase."
survived,"def test_debate_arena() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri()

    with sync_playwright() as p:
        browser = p.chromium.launch()
        page = browser.new_page()
        page.goto(url)
        page.wait_for_selector(""#arena-panel"")
        page.wait_for_selector(""#arena-panel button"")
        page.click(""#arena-panel button"")
        page.wait_for_selector(""#debate-panel li"")
        page.wait_for_selector(""#ranking li"")
        browser.close()",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_debate_arena.py,,1,9.736200303530205e-10,"The method `test_debate_arena` is a test function that uses Playwright to automate browser actions for testing a web page. It is likely to survive because it is a functional test that ensures the web page's elements are loaded and interactable, which is crucial for maintaining the quality and functionality of the web application. Automated tests are essential in modern software development for continuous integration and deployment processes."
survived,"            def patched_curl_async_init(session_self, *args, **kwargs):
                if self._proxies and 'proxies' not in kwargs:
                    kwargs['proxies'] = self._proxies
                self._original_curl_async_session_init(session_self, *args, **kwargs)
",webscout/Provider/TTI/base.py,_GlobalProxyManager,0,0.9999995549151272,"The method 'patched_curl_async_init' is likely to be deleted because it contains a reference to 'self._proxies' and 'self._original_curl_async_session_init', which are not defined within the method or passed as parameters. This suggests that the method relies on external state or context that is not provided, making it potentially non-functional or error-prone. Additionally, the method seems to be a patch or a workaround, which might be replaced by a more robust solution in the future."
survived,"    def test_update_model_symlink(self):
        client, _runner = self._make_client()
        import io
        import zipfile
        import stat

        buf = io.BytesIO()
        with zipfile.ZipFile(buf, ""w"") as zf:
            zi = zipfile.ZipInfo(""link"")
            zi.create_system = 3
            zi.external_attr = (stat.S_IFLNK | 0o777) << 16
            zf.writestr(zi, ""target"")
        data = buf.getvalue()
        res = client.post(""/agent/foo/update_model"", files={""file"": (""f.zip"", data)})
        self.assertEqual(res.status_code, 400)",alpha_factory_v1/tests/test_orchestrator_rest.py,UpdateModelTest,1,1.6052280526088547e-09,"The method `test_update_model_symlink` is a unit test designed to verify that the system correctly handles an attempt to upload a symlink within a zip file. The test checks that the server responds with a 400 status code, indicating a bad request, which is a valid and important test case for security and robustness. Since handling symlinks improperly can lead to security vulnerabilities, this test is crucial for ensuring the system's integrity. Therefore, it is likely to be retained as part of the test suite."
survived,"    async def _get_new_response(
        cls,
        agent: Agent[TContext],
        system_prompt: str | None,
        input: list[TResponseInputItem],
        output_schema: AgentOutputSchemaBase | None,
        all_tools: list[Tool],
        handoffs: list[Handoff],
        context_wrapper: RunContextWrapper[TContext],
        run_config: RunConfig,
        tool_use_tracker: AgentToolUseTracker,
        previous_response_id: str | None,
    ) -> ModelResponse:
        model = cls._get_model(agent, run_config)
        model_settings = agent.model_settings.resolve(run_config.model_settings)
        model_settings = RunImpl.maybe_reset_tool_choice(agent, tool_use_tracker, model_settings)

        new_response = await model.get_response(
            system_instructions=system_prompt,
            input=input,
            model_settings=model_settings,
            tools=all_tools,
            output_schema=output_schema,
            handoffs=handoffs,
            tracing=get_model_tracing_impl(
                run_config.tracing_disabled, run_config.trace_include_sensitive_data
            ),
            previous_response_id=previous_response_id,
        )

        context_wrapper.usage.add(new_response.usage)

        return new_response
",src/agents/run.py,DefaultAgentRunner,1,4.363462233903899e-09,"The method '_get_new_response' is an asynchronous function that appears to be a core part of a system designed to interact with a model, likely for generating responses based on input data and configurations. It is well-structured, uses type hints, and integrates various components such as model settings, tools, and tracing. The method is likely crucial for the functionality of the system, as it handles the interaction with the model and processes the response. Given its importance and the fact that it is well-implemented, it is unlikely to be deleted."
survived,"    async def _run_single_turn_streamed(
        cls,
        streamed_result: RunResultStreaming,
        agent: Agent[TContext],
        hooks: RunHooks[TContext],
        context_wrapper: RunContextWrapper[TContext],
        run_config: RunConfig,
        should_run_agent_start_hooks: bool,
        tool_use_tracker: AgentToolUseTracker,
        all_tools: list[Tool],
        previous_response_id: str | None,
    ) -> SingleStepResult:
        if should_run_agent_start_hooks:
            await asyncio.gather(
                hooks.on_agent_start(context_wrapper, agent),
                (
                    agent.hooks.on_start(context_wrapper, agent)
                    if agent.hooks
                    else _coro.noop_coroutine()
                ),
            )

        output_schema = cls._get_output_schema(agent)

        streamed_result.current_agent = agent
        streamed_result._current_agent_output_schema = output_schema

        system_prompt = await agent.get_system_prompt(context_wrapper)

        handoffs = cls._get_handoffs(agent)
        model = cls._get_model(agent, run_config)
        model_settings = agent.model_settings.resolve(run_config.model_settings)
        model_settings = RunImpl.maybe_reset_tool_choice(agent, tool_use_tracker, model_settings)

        final_response: ModelResponse | None = None

        input = ItemHelpers.input_to_new_input_list(streamed_result.input)
        input.extend([item.to_input_item() for item in streamed_result.new_items])

        # 1. Stream the output events
        async for event in model.stream_response(
            system_prompt,
            input,
            model_settings,
            all_tools,
            output_schema,
            handoffs,
            get_model_tracing_impl(
                run_config.tracing_disabled, run_config.trace_include_sensitive_data
            ),
            previous_response_id=previous_response_id,
        ):
            if isinstance(event, ResponseCompletedEvent):
                usage = (
                    Usage(
                        requests=1,
                        input_tokens=event.response.usage.input_tokens,
                        output_tokens=event.response.usage.output_tokens,
                        total_tokens=event.response.usage.total_tokens,
                        input_tokens_details=event.response.usage.input_tokens_details,
                        output_tokens_details=event.response.usage.output_tokens_details,
                    )
                    if event.response.usage
                    else Usage()
                )
                final_response = ModelResponse(
                    output=event.response.output,
                    usage=usage,
                    response_id=event.response.id,
                )
                context_wrapper.usage.add(usage)

            streamed_result._event_queue.put_nowait(RawResponsesStreamEvent(data=event))

        # 2. At this point, the streaming is complete for this turn of the agent loop.
        if not final_response:
            raise ModelBehaviorError(""Model did not produce a final response!"")

        # 3. Now, we can process the turn as we do in the non-streaming case
        single_step_result = await cls._get_single_step_result_from_response(
            agent=agent,
            original_input=streamed_result.input,
            pre_step_items=streamed_result.new_items,
            new_response=final_response,
            output_schema=output_schema,
            all_tools=all_tools,
            handoffs=handoffs,
            hooks=hooks,
            context_wrapper=context_wrapper,
            run_config=run_config,
            tool_use_tracker=tool_use_tracker,
        )

        RunImpl.stream_step_result_to_queue(single_step_result, streamed_result._event_queue)
        return single_step_result
",src/agents/run.py,DefaultAgentRunner,1,8.76424914819242e-08,"The method '_run_single_turn_streamed' is a complex and integral part of a system that handles asynchronous streaming of responses in an agent-based architecture. It involves multiple components such as hooks, context management, model interaction, and event streaming, which are crucial for the system's functionality. The method is likely to be essential for the operation of the system, especially in scenarios where real-time or streamed processing is required. Therefore, it is unlikely to be deleted unless there is a significant redesign of the system that renders this functionality obsolete."
survived,"    async def step(self) -> None:
        await self.publish(""alpha.opportunity"", {""alpha"": ""supply-chain bottleneck detected""})
",alpha_factory_v1/demos/alpha_agi_business_v1/alpha_agi_business_v1.py,AlphaOpportunityAgent,1,1.2501528648238603e-09,"The method 'step' is an asynchronous function that publishes a message to a topic 'alpha.opportunity'. This kind of functionality is common in event-driven architectures and microservices, where services communicate through message passing. The method is simple, clear, and serves a specific purpose of notifying or logging an event. There is no indication of redundancy or obsolescence in the code provided, and it aligns with modern programming practices. Therefore, it is likely to be retained."
survived,"def _start_bridge() -> None:
    """"""Start the OpenAI Agents bridge in a background thread.""""""
    try:
        from alpha_factory_v1.demos.alpha_agi_business_v1 import openai_agents_bridge
    except Exception as exc:  # pragma: no cover - optional dep
        print(f""⚠️  OpenAI bridge not available: {exc}"")
        return
    thread = threading.Thread(target=openai_agents_bridge.main, daemon=True)
    thread.start()
",alpha_factory_v1/demos/alpha_agi_business_v1/run_business_v1_local.py,,1,1.1253518384332553e-07,"The method '_start_bridge' is designed to start a background thread for the OpenAI Agents bridge, which is a specific functionality that might be crucial for certain operations within the application. The method includes error handling to manage the absence of the required module gracefully, indicating that it is intended to be robust and optional. This suggests that the method is likely to be retained as it provides a specific utility that can be conditionally used based on the availability of the 'openai_agents_bridge'."
survived,"async def recent_log(limit: int = 5) -> List[Dict[str, str]]:
    return _read_log(limit)
",alpha_factory_v1/demos/cross_industry_alpha_factory/openai_agents_bridge.py,,1,2.1724399346070676e-10,"The method `recent_log` is a simple asynchronous function that calls another function `_read_log` with a limit parameter. It is likely part of a logging or monitoring system where retrieving recent logs is a common requirement. The method is straightforward, performs a useful task, and does not have any apparent issues or redundancies. Therefore, it is likely to be retained in the codebase."
survived,"def test_group_tag_data_by_resource_type():
    grouped = rgta._group_tag_data_by_resource_type(
        copy.deepcopy(test_data.GET_RESOURCES_RESPONSE),
        rgta.TAG_RESOURCE_TYPE_MAPPINGS,
    )
    assert len(grouped[""ec2:instance""]) == 1
    assert len(grouped[""s3""]) == 1
",tests/unit/cartography/intel/aws/test_resourcegroupstaggingapi.py,,1,6.825604231969389e-08,"The method `test_group_tag_data_by_resource_type` is a test function, which is typically used to verify the functionality of a specific piece of code. Test functions are generally not deleted unless they are redundant, testing obsolete code, or have been replaced by more comprehensive tests. In this case, the function is testing the grouping of tag data by resource type, which seems like a fundamental aspect of the functionality being tested. Therefore, it is likely to be retained to ensure the correctness of the code it is testing."
survived,"    def __init__(self, base_url: str):
        self._client = DummyClient(base_url)
",tests/integrations/openai/test_openai_sdk.py,DummyCompletion,1,2.8453347280241004e-08,"The method is a constructor for initializing an instance of a class with a base URL, which is a common and necessary practice in object-oriented programming. It sets up a client object, which is likely essential for the class's functionality. Therefore, it is unlikely to be deleted."
survived,"async def test_stream_options_not_injected_for_non_openai_base_url_async() -> None:
    captured = {}

    async def dummy_fn(completion, **kwargs):
        captured.update(kwargs)
        return ""ok""

    wrapped = create_wrapper_async(OpSettings())(dummy_fn)

    await wrapped(DummyCompletion(""https://api.mistral.ai""), stream=True)

    assert ""stream_options"" not in captured",tests/integrations/openai/test_openai_sdk.py,,1,1.0677030767166749e-06,The method is a test function that checks if 'stream_options' is not injected into the captured dictionary when the base URL is not from OpenAI. This is a specific test case that ensures the function behaves correctly under certain conditions. Test functions are generally not deleted as they are crucial for maintaining code quality and ensuring that changes do not break existing functionality.
survived,"        def __init__(self, *a, **kw) -> None:
            captured[""base_url""] = kw.get(""base_url"")
",tests/test_macro_agent_base_url.py,DummyOpenAI,1,8.76424914819242e-08,"The method is a constructor for a class, indicated by the name `__init__`. Constructors are essential for initializing new objects in object-oriented programming. The code captures a keyword argument `base_url` and stores it in a dictionary `captured`, which suggests it is part of a larger system where this information is necessary for the object's functionality. Since constructors are fundamental to class instantiation and this one appears to be performing a specific task, it is unlikely to be deleted unless the entire class is refactored or removed."
survived,"    def __init__(self, bus: orchestrator.messaging.A2ABus, ledger: orchestrator.Ledger) -> None:
        super().__init__(""fail"", bus, ledger)
",tests/test_orchestrator.py,FailingAgent,1,2.646573631904765e-09,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting up initial states. The use of '__init__' is standard in Python for this purpose, and it is unlikely to be removed unless the entire class is being refactored or removed. Therefore, the method will survive."
survived,"        def log(self, env) -> None:  # type: ignore[override]
            if env.payload.get(""event""):
                events.append(env.payload[""event""])
",tests/test_orchestrator.py,DummyLedger,1,9.237449576640118e-09,"The method 'log' is a simple function that appends an event from the 'env' object to a list called 'events'. It is a straightforward utility function that is likely used for logging or tracking events. Such methods are generally useful in applications for debugging or monitoring purposes. There is no indication that this method is redundant or harmful, and it seems to serve a clear purpose. Therefore, it is likely to be retained in the codebase."
survived,"    def _generate_ip_pool(self, count: int = 20) -> List[str]:
        """"""Generate a pool of random IP addresses.""""""
        return [self.random_crypto_ip() for _ in range(count)]
",webscout/litagent/agent.py,LitAgent,1,4.599055376537186e-10,"The method `_generate_ip_pool` is a utility function that generates a list of random IP addresses. It is a simple, self-contained function that serves a clear purpose, which is to create a pool of IP addresses. Such utility functions are often useful in various contexts, such as testing, simulations, or network-related operations. Unless there is a significant change in the requirements or the method is replaced by a more efficient or comprehensive solution, it is likely to survive."
survived,"            def norm(mat, axis=1, keepdims=True):
                if axis == 1:
                    norms = [sqrt(sum(x * x for x in row)) for row in mat]
                    return [[n] for n in norms] if keepdims else norms
                raise NotImplementedError
",alpha_factory_v1/backend/memory_vector.py,_SimpleNP.linalg,1,1.0467401685178159e-08,"The method 'norm' is a simple utility function that calculates the norm of each row in a matrix. It is straightforward and performs a common mathematical operation, which is likely to be useful in various contexts. The function is implemented correctly for the specified axis and includes an option to keep dimensions, which adds to its flexibility. The use of a NotImplementedError for unsupported axes is a good practice, indicating that the function is designed with potential future extensions in mind. These factors suggest that the method is well-implemented and useful, making it likely to survive."
survived,"def test_cli_emit_helpers() -> None:
    """"""Ensure emit flags generate expected files.""""""
    with tempfile.TemporaryDirectory() as tmpdir:
        tmp = Path(tmpdir)
        for flag in [""--emit-docker"", ""--emit-helm"", ""--emit-notebook""]:
            result = subprocess.run(
                [
                    sys.executable,
                    ""-m"",
                    ""alpha_factory_v1.demos.alpha_asi_world_model.alpha_asi_world_model_demo"",
                    flag,
                ],
                cwd=tmp,
                capture_output=True,
                text=True,
            )
            assert result.returncode == 0, result.stderr

        assert (tmp / ""Dockerfile"").exists()
        assert (tmp / ""helm_chart"" / ""values.yaml"").exists()
        assert (tmp / ""alpha_asi_world_model_demo.ipynb"").exists()

    assert not Path(tmpdir).exists()",tests/test_world_model_cli.py,,1,1.1861120010657661e-08,"The method `test_cli_emit_helpers` is a test function that ensures certain command-line interface (CLI) flags generate the expected files. It uses a temporary directory to run the tests and checks for the existence of specific files after executing commands. The method is well-structured, uses assertions to validate outcomes, and cleans up the temporary directory after execution. These characteristics make it a useful and necessary part of a test suite, especially for verifying CLI functionality. Therefore, it is likely to be retained in the codebase."
survived,"def test_duckdb_merkle_root(tmp_path) -> None:
    ledger = Ledger(tmp_path / ""log.duckdb"", db=""duckdb"", broadcast=False)
    env = messaging.Envelope(sender=""a"", recipient=""b"", payload={""v"": 1}, ts=0.0)
    ledger.log(env)
    assert ledger.compute_merkle_root() == _expected_root([env])
",tests/test_ledger_backends.py,,1,1.3440409770490404e-08,"The method `test_duckdb_merkle_root` is a test function, which is typically used to verify the functionality of a specific feature or component in the codebase. Test functions are generally not deleted unless they are redundant, testing deprecated features, or replaced by more comprehensive tests. In this case, the function is testing the computation of a Merkle root in a ledger system using DuckDB, which seems to be a relevant and specific test. Therefore, it is likely to be retained to ensure the correctness of the Merkle root computation."
survived,"    def _get(self: struct_pb2.Struct, key: str, default=None):
        try:
            return self[key]
        except Exception:
            return default
",tests/test_chaos_agent.py,,1,1.3440409770490404e-08,"The method '_get' is a utility function designed to safely retrieve a value from a 'struct_pb2.Struct' object using a key. If the key does not exist, it returns a default value. This is a common pattern in Python to handle potential exceptions gracefully and provide a fallback value. Such methods are generally useful and enhance code robustness, making them likely to be retained unless there is a significant change in the surrounding codebase or a better alternative is introduced."
survived,"    def fake_chat(prompt: str, cfg) -> str:
        calls[""prompt""] = prompt
        calls[""cfg""] = cfg
        return ""patch-local""
",tests/test_self_edit_prompting.py,,1,1.725782769012759e-08,"The method 'fake_chat' is a simple function that takes a prompt and a configuration, stores them in a dictionary called 'calls', and returns a string 'patch-local'. The method is straightforward and does not contain any complex logic or dependencies that would make it obsolete or unnecessary. It seems to serve a specific purpose, possibly for testing or mocking purposes, by storing the inputs and returning a fixed string. Unless the requirements change significantly or the method is replaced by a more sophisticated implementation, it is likely to survive."
survived,"def is_patch_valid(diff: str) -> bool:
    """"""Return ``True`` if ``diff`` does not appear dangerous.""""""

    if not diff.strip():
        return False

    lowered = diff.lower()
    for pat in _BAD_PATTERNS:
        if re.search(pat, lowered):
            return False

    files = _changed_files(diff)
    if files and all(f.startswith(""tests/"") or ""/tests/"" in f or f.split(""/"")[-1].startswith(""test_"") for f in files):
        return False

    return True",src/utils/patch_guard.py,,1,9.736200303530205e-10,"The method 'is_patch_valid' is a utility function that checks if a given patch (diff) is potentially dangerous by looking for bad patterns and ensuring that changes are not only in test files. This kind of validation is crucial in software development to prevent harmful changes from being applied. The method is well-defined, serves a clear purpose, and is likely to be useful in various contexts where code changes need to be validated. Therefore, it is unlikely to be deleted."
survived,"    def _migrate_legacy(self) -> None:
        json_path = self.path.with_name(""archive.json"")
        if not json_path.exists():
            return
        try:
            records = json.loads(json_path.read_text())
        except Exception:
            return
        with Session(self.engine) as session:
            for rec in records:
                row = _ArchiveRow(
                    hash=rec[""hash""],
                    parent=rec.get(""parent""),
                    score=rec.get(""score"", 0.0),
                    novelty=rec.get(""novelty"", 0.0),
                    is_live=rec.get(""is_live"", True),
                    ts=rec.get(""ts"", time.time()),
                )
                session.merge(row)
            session.commit()
",src/archive/db.py,ArchiveDB,1,2.0611536181902033e-09,"The method '_migrate_legacy' is responsible for migrating legacy data from a JSON file into a database. This is a common task in software systems that evolve over time, where data formats or storage mechanisms change. The method is well-structured, handling file existence checks, JSON parsing, and database operations with error handling. Such methods are typically retained as long as there is a need to support legacy data migration, which can be a long-term requirement in many systems. Therefore, it is likely to survive."
survived,"def test_secure_run_timeout(monkeypatch) -> None:
    monkeypatch.setattr(shutil, ""which"", lambda n: None)

    def fake_run(*args, **kwargs):
        raise subprocess.TimeoutExpired(cmd=args[0], timeout=120)

    monkeypatch.setattr(subprocess, ""run"", fake_run)

    with pytest.raises(SandboxTimeout):
        secure_run([""sleep"", ""130""])",tests/test_secure_run.py,,1,1.725782769012759e-08,"The method `test_secure_run_timeout` is a unit test designed to verify the behavior of the `secure_run` function when a timeout occurs. It uses `monkeypatch` to mock the behavior of `shutil.which` and `subprocess.run` to simulate a timeout scenario. This is a common practice in testing to ensure that the function handles timeouts correctly. Since testing for timeouts is a critical aspect of ensuring robust and reliable code, especially in environments where operations may hang or take longer than expected, this method is likely to be retained. It serves an important role in validating the functionality and reliability of the `secure_run` function under specific conditions."
survived,"    def _validate_inputs(
        self,
        code_directory: Path,
        command: list[str],
        mem_limit: str,
        cpu_shares: int,
    ) -> None:
        """"""Validate inputs and resource limits for sandbox execution.""""""



        if not code_directory.is_dir():
            raise FileNotFoundError(f""Code directory not found: {code_directory}"")

        if not command or any(
            not isinstance(c, str) or any(x in c for x in ["";"", ""&"", ""|"", ""`"", ""\n""])
            for c in command
        ):
            raise ValueError(""Invalid command passed to sandbox"")

        if cpu_shares <= 0 or cpu_shares > MAX_CPU_SHARES:
            raise ValueError(""cpu_shares out of allowed range"")

        if mem_limit[-1].lower() not in {""m"", ""g""} or not mem_limit[:-1].isdigit():
            raise ValueError(""mem_limit must be like '256m' or '1g'"")
",src/meta_agent/sandbox/sandbox_manager.py,SandboxManager,1,1.8189616842444243e-09,"The method '_validate_inputs' is crucial for ensuring that the inputs and resource limits for sandbox execution are valid and safe. It checks for the existence of the code directory, validates the command to prevent injection attacks, and ensures that the CPU and memory limits are within acceptable ranges. These validations are essential for maintaining the integrity and security of the sandbox environment, making it unlikely that this method will be deleted."
survived,"def test_invalid_command(monkeypatch, tmp_path):
    fake_client = MagicMock()
    fake_client.ping.return_value = None
    monkeypatch.setattr(sm.docker, ""from_env"", lambda: fake_client)
    manager = SandboxManager()
    code_dir = tmp_path / ""code""
    code_dir.mkdir()
    with pytest.raises(ValueError):
        manager.run_code_in_sandbox(code_dir, [""python; rm -rf /""])
",tests/unit/test_sandbox_manager.py,,1,8.592166611791576e-10,"The method 'test_invalid_command' is a unit test designed to ensure that the 'run_code_in_sandbox' method of the 'SandboxManager' class correctly raises a ValueError when an invalid command is passed. This is a valid and important test case to ensure the security and robustness of the system, especially when dealing with potentially dangerous commands like 'rm -rf /'. Therefore, it is likely to be retained in the codebase to prevent regressions and ensure the system handles such cases appropriately."
survived,"    def __init__(self, host: str, port: int, level: LogLevel = LogLevel.DEBUG):
        super().__init__(level)
        self.host = host
        self.port = port
",webscout/litlogger/handlers.py,TCPHandler,1,3.2241866333029355e-08,"The method is a constructor for a class, initializing important attributes such as 'host', 'port', and 'level'. Constructors are essential for setting up the initial state of an object, and this one appears to be well-structured and necessary for the class's functionality. Therefore, it is unlikely to be deleted."
survived,"    def __init__(self, level: LogLevel = LogLevel.DEBUG):
        self.level = level
",webscout/litlogger/handlers.py,Handler,1,1.444980317078884e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes or default values. In this case, it sets a default logging level, which is a common practice in logging frameworks to control the verbosity of log messages. Removing this method would make it impossible to initialize objects of the class with a specific logging level, thus reducing the functionality and flexibility of the class. Therefore, it is unlikely to be deleted."
survived,"    def _open(self):
        self.path.parent.mkdir(parents=True, exist_ok=True)
        self._file = open(self.path, ""a"", encoding=""utf-8"")
",webscout/litlogger/handlers.py,FileHandler,1,1.0467401685178159e-08,"The method '_open' is a private method (indicated by the underscore) that is responsible for ensuring the directory structure exists and then opening a file for appending. This is a common utility function in file handling classes, especially when dealing with file operations that require directory creation. The method is likely to be used internally by other methods in the class to manage file operations safely and efficiently. Since it performs a necessary and specific task, it is unlikely to be deleted unless the entire file handling mechanism is refactored or removed."
survived,"def test_get_result_exact_order():
    scraper = AutoScraper()
    scraper.build(html=HTML_COMPLEX_ORDER, wanted_list=[""Banana"", ""$2""])
    assert scraper.get_result_exact(html=HTML_COMPLEX_ORDER) == [""Banana"", ""$2""]
",tests/unit/test_features.py,,1,8.152020648014727e-09,"The method test_get_result_exact_order is a unit test for the AutoScraper library, which is used to verify that the get_result_exact method returns the expected results when given a specific HTML input. Unit tests are crucial for ensuring code reliability and correctness, especially in libraries that are used for data extraction like AutoScraper. Therefore, this method is likely to be retained as it serves an important role in maintaining the integrity of the codebase."
survived,"    def _attr_match(self, child, attrs):
        from autoscraper.utils import FuzzyText

        for key, val in (attrs or {}).items():
            actual = child.attrs.get(key, """")
            if isinstance(actual, list):
                actual = "" "".join(actual)

            if isinstance(val, FuzzyText):
                if not val.search(actual):
                    return False
            elif actual != val:
                return False
        return True
",tests/conftest.py,_Node,1,1.1032560311263802e-09,"The method '_attr_match' is a utility function that checks if a given set of attributes matches those of a child element. It uses a fuzzy text matching utility, which suggests it is part of a web scraping or data extraction library. Such utility functions are often essential for the functionality of the library, as they provide the core logic for matching elements based on attributes. Unless there is a significant change in the library's approach or a better alternative is introduced, this method is likely to be retained."
survived,"def test_similar_keep_order():
    scraper = AutoScraper()
    scraper.build(html=HTML, wanted_list=[""Banana""])
    result = scraper.get_result_similar(html=HTML, contain_sibling_leaves=True, keep_order=True)
    assert result == [""Banana"", ""Apple"", ""Orange""]",tests/unit/test_additional_features.py,,1,9.736200303530205e-10,"The method `test_similar_keep_order` is a test function that checks the functionality of the `AutoScraper` library, specifically the `get_result_similar` method with the `keep_order` parameter set to `True`. This test ensures that the scraper maintains the order of elements as they appear in the HTML. Such test functions are crucial for verifying the correctness of the library's features and are typically retained in the codebase to ensure ongoing reliability and correctness of the software. Therefore, it is likely to survive."
survived,"    def tail(self, count: int = 10) -> List[dict[str, object]]:
        """"""Return the last ``count`` ledger entries.""""""

        cur = self.conn.execute(
            ""SELECT ts, sender, recipient, payload FROM messages ORDER BY id DESC LIMIT ?"",
            (count,),
        )
        rows = cur.fetchall()
        result: List[dict[str, object]] = []
        for ts, sender, recipient, payload in reversed(rows):
            try:
                data = json.loads(payload)
            except Exception:
                data = payload
            result.append({""ts"": ts, ""sender"": sender, ""recipient"": recipient, ""payload"": data})
        return result
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/logging.py,Ledger,1,2.7894680920908113e-10,"The method 'tail' is a useful utility function that retrieves the last 'count' number of ledger entries from a database. It is well-implemented, handling potential JSON parsing errors gracefully and returning a structured list of dictionaries. This functionality is common in applications that need to display recent activity or logs, making it a valuable part of the codebase. There are no apparent issues or redundancies that would necessitate its removal."
survived,"def _min(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""min() expects list or group"")
    vals = [it for it in v if it is not None]
    if not vals:
        return 0
    return min(vals)
",tests/dataset/job/compiler/py/q1.py,,0,0.9999992661791398,"The method _min is a custom implementation of the built-in min function, with additional handling for objects with an 'Items' attribute and filtering out None values. However, it has several issues that make it less useful and potentially problematic:

1. **Redundancy**: Python's built-in min function already provides the core functionality needed to find the minimum value in an iterable, making this custom implementation largely redundant.

2. **Error Handling**: The method raises a generic Exception with a non-descriptive message, which is not a best practice. It could be improved by raising a more specific exception type with a clearer message.

3. **Limited Use Case**: The method is designed to handle a very specific case (objects with an 'Items' attribute), which limits its general applicability.

4. **Performance**: The method creates a new list to filter out None values, which could be inefficient for large datasets.

5. **Naming Convention**: The underscore prefix suggests that this is a private method, which might not be intended for widespread use.

Given these points, the method is likely to be deleted in favor of using the built-in min function with additional pre-processing if needed."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/job/compiler/py/q10.py,,1,1.444980317078884e-07,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The function is generic and flexible, allowing for various operations based on the options provided. Such utility functions are often retained in codebases because they encapsulate complex logic in a reusable manner. Therefore, it is likely to be retained unless there is a significant change in the requirements or a better alternative is developed."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/job/compiler/py/q7.py,,1,2.8453347280241004e-08,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be useful in various data processing scenarios. The function is not overly specific to a particular use case, making it versatile and potentially reusable in different contexts. Additionally, the function is well-structured and implements common data manipulation operations, which are often needed in software development. Therefore, it is likely to be retained for its utility and flexibility."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/job/compiler/py/q1.py,,1,4.6911638017642294e-08,"The method _key is a utility function that is likely used internally within a class or module to generate a key for sorting purposes. It takes an iterable, applies a sorting key function from a dictionary of options, and ensures the key is a string if it's a complex data type. This kind of function is common in data processing or sorting operations, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained."
survived,"                def __init__(self) -> None:
                    super().__init__(name)
                    threading.Thread(target=self._loop, daemon=True).start()
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,StepAdapter,1,6.023574641292144e-08,"The method is a constructor for a class, indicated by the name `__init__`. Constructors are essential for initializing new objects in object-oriented programming. The presence of `super().__init__(name)` suggests that it is calling the constructor of a superclass, which is a common practice to ensure proper initialization of inherited attributes. Additionally, the method starts a new thread, which might be crucial for the functionality of the class, especially if it involves concurrent operations. Therefore, it is unlikely that this method will be deleted as it serves a fundamental role in the class's operation."
survived,"        def __call__(self, query: str, *args: Any, **kwargs: Any) -> str:
            return ""Hosted tool unavailable in this environment.""
",src/meta_agent/sub_agent_manager.py,WebSearchTool,1,6.825604231969389e-08,"The method is a simple implementation of the __call__ method, which returns a fixed string message indicating that a hosted tool is unavailable. This method is likely part of a larger class that deals with tool availability or execution. The method itself is straightforward and does not contain any complex logic or dependencies that would necessitate its removal. It serves a clear purpose by providing a consistent response when the object is called with a query. Therefore, it is likely to be retained as it fulfills its intended function without any apparent issues."
survived,"def test_docs_invalid_token(adk_server: Tuple[str, str]) -> None:
    """"""Invalid token should return 401.""""""

    url, _token = adk_server
    with httpx.Client(base_url=url) as client:
        r = client.get(""/docs"", headers={""x-alpha-factory-token"": ""bad""})
        assert r.status_code == 401",tests/test_adk_gateway.py,,1,8.152020648014727e-09,"The method 'test_docs_invalid_token' is a unit test designed to verify that an invalid token results in a 401 Unauthorized status code. This is a standard and necessary test to ensure the security and proper functioning of an API endpoint. Such tests are crucial for maintaining the integrity of authentication mechanisms. Therefore, it is unlikely to be deleted as it serves an important purpose in the codebase."
survived,"    def Histogram(name: str, desc: str, labels=None):  # type: ignore[misc]
        return _get_metric(_Histogram, name, desc, labels)
",alpha_factory_v1/backend/agents/registry.py,,1,2.998960815863541e-09,"The method 'Histogram' is a simple wrapper around the '_get_metric' function, which likely serves a specific purpose in the codebase related to metrics collection or monitoring. The use of 'type: ignore[misc]' suggests that the developers are aware of potential type issues but have chosen to suppress them, indicating that the function is still in use and necessary. Without any indication of deprecation or replacement, it is likely that this method will survive."
survived,"        async def _wrapped(*a, **kw):  # type: ignore[no-untyped-def]
            t0 = time.perf_counter()
            ok = True
            try:
                return await orig(*a, **kw)  # type: ignore[misc]
            except Exception:  # noqa: BLE001
                ok = False
                raise
            finally:
                _HEALTH_Q.put((meta.name, (time.perf_counter() - t0) * 1000, ok))
",alpha_factory_v1/backend/agents/registry.py,,1,4.944450477491054e-09,"The method '_wrapped' is an asynchronous function that wraps another function 'orig'. It measures the execution time of 'orig', handles exceptions, and logs the result to a queue '_HEALTH_Q'. This kind of functionality is useful for monitoring and logging purposes, especially in asynchronous environments where performance metrics are crucial. The method is likely to be retained as it provides valuable insights into the performance and reliability of the wrapped function."
survived,"def capability_agents(capability: str):
    """"""Return list of agent names exposing *capability*.""""""
    with _REGISTRY_LOCK:
        return CAPABILITY_GRAPH.get(capability, []).copy()
",alpha_factory_v1/backend/agents/registry.py,,1,1.522997951276035e-08,"The method `capability_agents` is a simple utility function that retrieves a list of agent names associated with a given capability from a global `CAPABILITY_GRAPH`. It uses a lock (`_REGISTRY_LOCK`) to ensure thread safety when accessing the shared resource. This function is likely to be useful in contexts where capabilities are dynamically registered and queried, such as in plugin systems or modular architectures. The use of a lock suggests that the function is designed to be thread-safe, which is a good practice in concurrent programming. Therefore, the method is likely to be retained as it serves a clear purpose and is implemented with consideration for thread safety."
survived,"    def test_string(self):
        r = self.klong(',""xyz""')
        self.assertTrue(kg_equal(r, np.asarray(['xyz'], dtype=object)))
",tests/test_eval_monad_list.py,TestEvalMonadList,1,2.646573631904765e-09,"The method `test_string` is a unit test that checks if the function `klong` correctly processes a string input and returns the expected numpy array. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with data processing functions. Since this test is part of a test suite, it is likely to be maintained to ensure the functionality of the `klong` method remains consistent. Therefore, the method is likely to be retained."
survived,"def handle_heartbeat(runners: Dict[str, AgentRunner], env: object) -> None:
    """"""Update the heartbeat timestamp for ``env.sender`` if it exists.""""""
    payload = getattr(env, ""payload"", None)
    if payload and getattr(payload, ""get"", lambda *_: None)(""heartbeat""):
        sender = getattr(env, ""sender"", None)
        if sender in runners:
            r = runners[sender]
            r.last_beat = getattr(env, ""ts"", time.time())
            r.restart_streak = 0",alpha_factory_v1/backend/agent_supervisor.py,,1,1.4166087846364157e-09,"The method 'handle_heartbeat' is likely to survive because it performs a necessary function of updating the heartbeat timestamp for a given sender if it exists in the runners dictionary. This is a common pattern in systems that need to track the activity or status of agents or services, ensuring they are alive and functioning. The method is straightforward, checks for necessary conditions, and updates relevant attributes, which are typical requirements in such systems."
survived,"        def __init__(self, data: dict) -> None:
            self._data = data
",tests/test_cli_runner_ext.py,Dummy,1,7.73442280641062e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming in Python. Constructors are essential for initializing new objects with specific attributes, in this case, storing a dictionary in the instance variable '_data'. There is no indication that this method is redundant or unnecessary, as it serves a clear purpose in setting up the object's initial state. Therefore, it is unlikely to be deleted."
survived,"    def test_matrix_grad_numpy(self):
        self._check_matrix_grad(""numpy"")
",tests/test_autograd.py,TestAutograd,1,2.2159489282323004e-08,"The method `test_matrix_grad_numpy` is a test method, likely part of a test suite for verifying the functionality of matrix gradient calculations using the 'numpy' library. Test methods are generally retained as they are crucial for ensuring code correctness and stability. Unless there is a significant change in the testing framework or the library being tested, such methods are typically not deleted."
survived,"def test_llm_gpu_backend(tmp_path: Path) -> None:
    script = tmp_path / ""run.mjs""
    script.write_text(
        f""globalThis.navigator = {{ gpu: {{}} }};\n""
        f""globalThis.localStorage = {{ getItem: () => null }};\n""
        f""const m = await import('{LLM.resolve().as_posix()}');\n""
        ""console.log(m.gpuBackend());\n""
    )
    res = subprocess.run([""node"", script], capture_output=True, text=True)
    assert res.returncode == 0, res.stderr
    assert res.stdout.strip() == ""webgpu""
",tests/test_gpu_detection.py,,1,7.582560422162384e-10,"The method 'test_llm_gpu_backend' is a test function that verifies the GPU backend functionality of a module. It is likely part of a test suite to ensure that the module behaves as expected when executed in a specific environment. Test functions are generally retained as they are crucial for maintaining code quality and reliability. Unless there is a significant change in the module's functionality or testing strategy, this method is likely to survive."
survived,"def test_with_retry_sync_property(monkeypatch: pytest.MonkeyPatch, failures: int, max_tries: int) -> None:
    assume(max_tries > 0)
    monkeypatch.setattr(retry, ""backoff"", None)
    monkeypatch.setattr(retry.time, ""sleep"", lambda *_: None)
    calls = {""n"": 0}

    def func() -> str:
        calls[""n""] += 1
        if calls[""n""] <= failures:
            raise ValueError(""boom"")
        return ""ok""

    wrapped = retry.with_retry(func, max_tries=max_tries)
    if failures >= max_tries:
        with pytest.raises(ValueError):
            wrapped()
        assert calls[""n""] == max_tries
    else:
        assert wrapped() == ""ok""
        assert calls[""n""] == failures + 1
",tests/test_retry_property.py,,1,4.6911638017642294e-08,"The method 'test_with_retry_sync_property' is a test function that uses the 'pytest' framework to test the behavior of a retry mechanism. It is a well-structured test that checks both successful and failure scenarios of a retry function. Such test functions are crucial for ensuring the reliability and correctness of code, especially when dealing with retry logic which is common in handling transient errors. Therefore, it is unlikely to be deleted as it serves an important purpose in the codebase."
survived,"def test_json_formatter_output() -> None:
    record = logging.LogRecord(
        name=""test"",
        level=logging.INFO,
        pathname=__file__,
        lineno=10,
        msg=""hello"",
        args=(),
        exc_info=None,
    )
    out = _JsonFormatter().format(record)
    data = json.loads(out)
    assert data[""msg""] == ""hello""
    assert data[""lvl""] == ""INFO""
    assert data[""name""] == ""test""
    # timestamp is ISO formatted
    datetime.fromisoformat(data[""ts""])",tests/test_json_formatter.py,,1,6.348800075736417e-09,"The method `test_json_formatter_output` is a unit test for a JSON formatter, which is a common requirement in logging systems to ensure that log records are correctly formatted as JSON. This is a useful and necessary function for validating the behavior of the logging system, especially in applications where logs need to be structured and machine-readable. The test checks that the JSON output contains the expected fields and values, which is crucial for debugging and monitoring purposes. Therefore, it is likely to be retained in the codebase."
survived,"    def run() -> None:
        asyncio.run(api._background_run(""bench"", cfg))
",tests/test_benchmark.py,,1,6.348800075736417e-09,"The method 'run' is a simple wrapper around 'asyncio.run' to execute an asynchronous function 'api._background_run'. This method is likely to be retained because it encapsulates a specific functionality that might be reused in different parts of the codebase. It provides a clear entry point for running the asynchronous task with a specific configuration ('bench', cfg), which suggests it has a defined purpose and utility. Unless there is a significant change in the architecture or the way asynchronous tasks are handled, this method is likely to survive."
survived,"def test_self_healer_succeeds_with_local_llm(tmp_path: Path, monkeypatch: pytest.MonkeyPatch) -> None:
    repo_src = Path(__file__).parent / ""fixtures"" / ""self_heal_repo""
    repo_path = tmp_path / ""repo""
    shutil.copytree(repo_src, repo_path)
    subprocess.run([""git"", ""init""], cwd=repo_path, check=True)
    subprocess.run([""git"", ""add"", "".""], cwd=repo_path, check=True)
    subprocess.run([""git"", ""commit"", ""-m"", ""init""], cwd=repo_path, check=True)
    commit = subprocess.check_output([""git"", ""rev-parse"", ""HEAD""], cwd=repo_path, text=True).strip()

    monkeypatch.setenv(""USE_LOCAL_LLM"", ""true"")
    monkeypatch.delenv(""OPENAI_API_KEY"", raising=False)
    importlib.reload(llm_client)

    patch = """"""--- a/calc.py
+++ b/calc.py
@@
-    return a - b
+    return a + b
""""""

    monkeypatch.setattr(llm_client, ""request_patch"", lambda *_: patch)
    monkeypatch.setattr(self_healer.SelfHealer, ""commit_and_push_fix"", lambda self: ""branch"")
    monkeypatch.setattr(self_healer.SelfHealer, ""create_pull_request"", lambda self, branch: 1)

    def fake_run(
        cmd: list[str],
        repo_dir: str,
        *,
        image: str | None = None,
        mounts: dict[str, str] | None = None,
    ) -> tuple[int, str]:
        if ""pytest"" in cmd:
            res = subprocess.run(
                [""pytest"", ""-q"", ""--color=no""],
                cwd=repo_dir,
                capture_output=True,
                text=True,
            )
            return res.returncode, res.stdout + res.stderr
        if ""patch"" in cmd:
            ok, out = diff_utils.apply_diff(patch, repo_dir=repo_dir)
            return (0 if ok else 1), out
        return 0, """"

    monkeypatch.setattr(sandbox, ""run_in_docker"", fake_run)

    workdir = tmp_path / ""work""
    healer = self_healer.SelfHealer(repo_url=str(repo_path), commit_sha=commit)
    healer.working_dir = str(workdir)

    pr = healer.run()

    with open(workdir / ""calc.py"") as fh:
        content = fh.read()
    assert ""a + b"" in content
    assert ""1 passed"" in healer.test_results
    assert pr == 1
    assert llm_client.USE_LOCAL_LLM
",tests/test_self_healer_sandbox.py,,1,7.194132978569833e-09,"The method is a well-structured test function that uses pytest and monkeypatching to simulate a scenario where a local LLM (Language Model) is used to generate and apply a code patch. It verifies the functionality of a self-healing system by checking if the patch is applied correctly and if the tests pass. The method is likely to survive because it is a comprehensive test that ensures the robustness of the self-healing feature, which is valuable for maintaining code quality and reliability."
deleted,"    def cosine_distance(self, other: FloatVector) -> Operators:
        """"""Compute the cosine distance.""""""
        if self._is_postgres():
            return self.op(""<=>"", return_type=Float)(other)
        if self._is_duckdb():
            return func.array_cosine_distance(self.expr, other)
        return self.op(""<=>"", return_type=Float)(other)
",src/raglite/_typing.py,EmbeddingComparator,1,1.9171715133907573e-10,"The method `cosine_distance` is likely to survive because it provides a useful functionality for computing the cosine distance between vectors, which is a common operation in many data processing and machine learning tasks. The method also includes specific implementations for different database systems (Postgres and DuckDB), indicating that it is designed to be versatile and adaptable to different environments. This adaptability increases its utility and likelihood of being retained in the codebase."
survived,"    def start(self, bus: object, ledger: object) -> None:
        self.task = asyncio.create_task(self.loop(bus, ledger))
",alpha_factory_v1/backend/agent_supervisor.py,AgentRunner,1,5.905303995456778e-10,"The method 'start' is a simple wrapper that initiates an asynchronous task using asyncio. This is a common pattern in asynchronous programming, especially when dealing with event-driven architectures or systems that require non-blocking operations. The method is likely to be useful in contexts where the 'loop' method needs to be executed asynchronously, and thus, it is unlikely to be deleted unless the entire asynchronous approach is refactored or the method is replaced with a more efficient or updated pattern. Therefore, the method will likely survive."
survived,"def load_translations(lang=None):
    """"""Load directory name translations for the given language.""""""
    if lang is None:
        lang = os.getenv('DEVICONS_LANG')
        if not lang:
            loc = locale.getdefaultlocale()[0]
            if loc:
                lang = loc.split('_')[0]
    if not lang:
        return {}
    try:
        module = importlib.import_module(f'ranger_devicons.locales.{lang}')
        return getattr(module, 'translations', {})
    except ModuleNotFoundError:
        return {}
",devicons.py,,1,8.592166611791576e-10,"The method 'load_translations' is likely to survive because it provides a useful functionality of loading language-specific translations for directory names. It handles different scenarios such as when no language is specified, when the environment variable is not set, and when the module for the specified language does not exist. This makes it robust and adaptable to different environments, which is a desirable trait in software development."
survived,"    def __init__(self) -> None:
        async def _run() -> None:
            while True:
                await asyncio.sleep(0.1)
        self.task = asyncio.create_task(_run())
",tests/test_governance.py,DummyRunner,1,2.2159489282323004e-08,"The method is likely to be Survived (1) because it is a constructor method (__init__) that initializes an instance of a class. It sets up an asynchronous task that runs indefinitely, which might be crucial for the functionality of the class, especially if it is designed to perform continuous background operations. The use of asyncio and the creation of a task suggest that this method is part of a larger asynchronous system, which is a common pattern in modern Python applications."
survived,"def select_parent(pop: Sequence[Any], *, epsilon: float = 0.1, rng: random.Random | None = None) -> Any:
    """"""Return a parent from ``pop`` via Pareto rank with epsilon-greedy randomness.""""""
    if not pop:
        raise ValueError(""population is empty"")
    rng = rng or random.Random()
    if rng.random() < epsilon:
        return rng.choice(list(pop))
    ranks = _pareto_ranks(pop)
    best = min(ranks)
    candidates = [ind for ind, r in zip(pop, ranks) if r == best]
    return rng.choice(candidates)",src/simulation/selector.py,,1,4.0586521248284276e-10,"The method `select_parent` is a well-defined function that implements a selection mechanism using Pareto ranking with an epsilon-greedy strategy. This is a common approach in evolutionary algorithms and optimization problems to introduce randomness and ensure diversity in selection. The function is complete, handles edge cases (like an empty population), and uses standard library functions effectively. There is no indication of redundancy or inefficiency that would warrant deletion. Therefore, it is likely to be retained in the codebase."
survived,"    def __init__(self, threshold: float) -> None:
        self.threshold = threshold
        self.cost = 0.0
        self.gain = 0.0
        self.success = 1
        self.fail = 1
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/simulation/loop.py,BanditEarlyStopper,1,3.653482080241728e-08,"The method is a constructor for a class, initializing several instance variables: 'threshold', 'cost', 'gain', 'success', and 'fail'. These variables are likely used in other methods of the class to perform calculations or track state. Constructors are essential for setting up the initial state of an object, and there is no indication that this constructor is redundant or unnecessary. Therefore, it is unlikely to be deleted."
survived,"def _hash_scores(scores: Sequence[float]) -> str:
    data = "","".join(f""{s:.8f}"" for s in scores).encode()
    return sha256(data).hexdigest()
",src/snark/proof.py,,1,4.944450477491054e-09,"The method _hash_scores is likely to survive because it performs a useful and specific function: it takes a sequence of float scores, formats them to a consistent precision, encodes them, and then hashes the result using SHA-256. This is a common requirement in many applications where data integrity and consistency are important, such as in caching, data verification, or creating unique identifiers for sets of scores. The method is also well-implemented, using standard libraries and practices."
survived,"def test_check_patch_in_sandbox_missing(monkeypatch):
    def fake_run(*_a, **_k):
        return subprocess.CompletedProcess([], 1, """", """")

    monkeypatch.setattr(subprocess, ""run"", fake_run)
    assert not preflight.check_patch_in_sandbox(""img"")
",tests/test_preflight_sandbox.py,,1,8.76424914819242e-08,"The method `test_check_patch_in_sandbox_missing` is a unit test that uses the `monkeypatch` fixture to replace the `subprocess.run` method with a fake implementation. This is a common practice in testing to isolate the function being tested from its dependencies. The test checks that the `preflight.check_patch_in_sandbox` function returns `False` when the subprocess returns a non-zero exit code, indicating a failure. This is a valid and useful test case for ensuring the robustness of the `check_patch_in_sandbox` function. Therefore, the method is likely to be retained as it serves a clear purpose in the test suite."
survived,"    def __init__(self, broker: str | None, dev_mode: bool) -> None:
        self._queues: Dict[str, asyncio.Queue] | None = None
        self._producer: KafkaProducer | None = None  # type: ignore
        if broker and ""KafkaProducer"" in globals():
            self._producer = KafkaProducer(
                bootstrap_servers=broker.split("",""),
                value_serializer=lambda v: json.dumps(v).encode(),
                linger_ms=50,
            )
            atexit.register(self._close)
        else:
            if broker and not dev_mode:
                log.warning(""Kafka unavailable → falling back to in-proc bus"")
            self._queues = {}
",alpha_factory_v1/backend/agent_runner.py,EventBus,1,2.2159489282323004e-08,"The method is an initializer for a class, which is a fundamental part of setting up the class's state. It handles the initialization of important components like KafkaProducer and in-process queues, depending on the environment and availability of Kafka. Such initializers are crucial for the proper functioning of the class and are unlikely to be removed unless the entire class is refactored or removed. Therefore, it is more likely to survive."
survived,"    def _close(self) -> None:
        if not self._producer:
            return
        try:
            self._producer.flush()
            self._producer.close()
        except Exception:  # noqa: BLE001
            log.exception(""Kafka producer close failed"")
",alpha_factory_v1/backend/agent_runner.py,EventBus,1,1.522997951276035e-08,"The method '_close' is a private method (indicated by the underscore prefix) that is responsible for safely closing a Kafka producer. It checks if the producer exists, attempts to flush and close it, and logs an exception if the operation fails. This is a common pattern for resource management in programming, ensuring that resources are properly released and errors are logged for debugging purposes. The method is likely to be essential for the stability and reliability of the application, especially in production environments where resource leaks can lead to significant issues. Therefore, it is unlikely to be deleted."
survived,"async def regression_guard(runners: Dict[str, AgentRunner], on_alert: Callable[[str], None] | None = None) -> None:
    history: deque[float] = deque(maxlen=3)
    while True:
        await asyncio.sleep(1)
        try:
            sample = metrics.dgm_best_score.collect()[0].samples[0]
            score = float(sample.value)
        except Exception:  # pragma: no cover - metrics optional
            continue
        history.append(score)
        if len(history) == 3 and history[1] <= history[0] * 0.8 and history[2] <= history[1] * 0.8:
            runner = runners.get(""aiga_evolver"")
            if runner and runner.task:
                runner.task.cancel()
                with contextlib.suppress(asyncio.CancelledError):
                    await runner.task
            if on_alert:
                on_alert(""Evolution paused due to metric regression"")
            history.clear()",alpha_factory_v1/backend/agent_runner.py,,1,8.592166611791576e-10,"The method 'regression_guard' is likely to survive because it implements a useful functionality for monitoring and responding to metric regressions in an asynchronous environment. It uses a deque to maintain a history of scores and checks for significant drops in performance, which can trigger an alert and cancel a task. This kind of functionality is valuable in systems that require real-time monitoring and adaptive responses to changes in performance metrics. Additionally, the use of async/await and exception handling makes it robust and suitable for modern Python applications."
survived,"async def get_orders_for_user(user_id: int, ctx: EnrichContext) -> list[Order]:
    return await list_orders(user_id=user_id, ctx=ctx)
",examples/shop_api_gateway/app.py,,0,0.9998415637531546,"The method `get_orders_for_user` is a simple asynchronous wrapper around the `list_orders` function, which suggests it might be redundant if `list_orders` is already accessible and provides the necessary functionality. However, if `get_orders_for_user` is part of a larger interface or is used to enforce a specific pattern or abstraction, it might be retained. Without additional context, such as whether `list_orders` is a private method or if `get_orders_for_user` is part of a public API, it's difficult to definitively predict its fate. However, given the trend towards simplifying code and removing unnecessary abstractions, it is more likely to be deleted unless it serves a specific purpose in the codebase."
survived,"async def list_users(ctx: EnrichContext) -> list[User]:
    client = await _client(ctx)
    resp = await client.get(""/users"")
    resp.raise_for_status()
    return [User(**u) for u in resp.json()]
",examples/shop_api_gateway/app.py,,1,5.905303995456778e-10,"The method 'list_users' is an asynchronous function that retrieves a list of users from an API endpoint. It uses modern Python features such as type hinting with 'list[User]' and async/await syntax, which are considered best practices for writing clean and efficient asynchronous code. The method also includes error handling with 'raise_for_status()', ensuring that HTTP errors are not silently ignored. These factors suggest that the method is well-implemented and follows current programming standards, making it likely to be retained in the codebase."
survived,"def main() -> int:
    env_vars = parse_env_sample(ENV_SAMPLE)
    md_vars = parse_agents_table(AGENTS_MD)

    missing_in_md = sorted(env_vars - md_vars)
    missing_in_env = sorted(md_vars - env_vars)

    if missing_in_md or missing_in_env:
        if missing_in_md:
            print(""Missing from AGENTS.md:"", "", "".join(missing_in_md))
        if missing_in_env:
            print(""Missing from .env.sample:"", "", "".join(missing_in_env))
        return 1

    print(""Environment variable table is up-to-date."")
    return 0
",tools/check_env_table.py,,1,2.4616969512093895e-10,"The method is likely to survive because it performs a useful function of comparing environment variables between two sources (ENV_SAMPLE and AGENTS_MD) and reports discrepancies. This is a common requirement in software development to ensure consistency between configuration files and documentation. The method is straightforward, has a clear purpose, and provides informative output, making it valuable for maintaining system integrity."
survived,"def test_simulate_offline(tmp_path: Path) -> None:
    led_path = tmp_path / ""audit.db""
    runner = CliRunner()
    from unittest.mock import patch

    with patch.object(cli.config.CFG, ""ledger_path"", str(led_path)):
        result = runner.invoke(cli.main, [""simulate"", ""--horizon"", ""2"", ""--offline""])
    assert result.exit_code == 0
    assert ""year"" in result.output
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_demo_cli.py,,1,1.725782769012759e-08,"The method 'test_simulate_offline' is a unit test function that uses the 'unittest.mock.patch' to temporarily modify the 'ledger_path' configuration for testing purposes. It then uses 'CliRunner' to invoke a CLI command and checks the result. This is a typical pattern for testing CLI applications and is useful for ensuring that the 'simulate' command works correctly in offline mode. Since it is a test function, it is unlikely to be deleted unless the functionality it tests is removed or significantly changed. Therefore, it is more likely to survive."
survived,"def get_image_analysis_anthropic(api_key, model_name, prompt, base64_image):
    client = Anthropic(api_key=api_key)
    response = client.messages.create(
        model=model_name,
        max_tokens=4000,
        messages=[
            {
                ""role"": ""user"",
                ""content"": [
                    {
                        ""type"": ""image"",
                        ""source"": {
                            ""type"": ""base64"",
                            ""media_type"": ""image/jpeg"",
                            ""data"": base64_image,
                        },
                    },
                    {""type"": ""text"", ""text"": prompt},
                ],
            }
        ],
    )

    text = """".join(block.text for block in response.content if getattr(block, ""text"", None))
    return {""choices"": [{""message"": {""content"": text}}]}
",threat_model.py,,0,0.999985261023967,"The method is likely to be deleted because it relies on a specific API from Anthropic, which may not be widely used or supported. Additionally, the method's functionality is highly dependent on the availability and stability of the external service, which can change over time. If the API changes or is deprecated, this method would become obsolete. Furthermore, the method's utility is limited to users who have access to the Anthropic API, which may not be the case for all users."
survived,"def firstPrimeFactor(n):
    if n == 1:
        return 1
    if n % 3 == 0:
        return 3
    if n % 5 == 0:
        return 5
    inc = [4, 2, 4, 2, 4, 6, 2, 6]
    k = 7
    i = 0
    while k * k <= n:
        if n % k == 0:
            return k
        k = k + inc[i]
        i = (i + 1) % len(inc)
    return n
",tests/rosetta/transpiler/Python/blum-integer.py,,1,1.6052280526088547e-09,"The method 'firstPrimeFactor' is a function that calculates the smallest prime factor of a given number 'n'. It handles edge cases like when 'n' is 1, and it efficiently checks divisibility by 3 and 5 before using a wheel factorization approach to check other potential factors. This method is useful for number theory applications and is implemented in a way that optimizes for common small factors and reduces the number of checks needed for larger numbers. Given its utility and efficiency, it is likely to be retained in a codebase."
survived,"def main():
    print(""Cows and Bulls"")
    print(""Guess four digit number of unique digits in the range 1 to 9."")
    print(""A correct digit but not in the correct place is a cow."")
    print(""A correct digit in the correct place is a bull."")
    digits = [""1"", ""2"", ""3"", ""4"", ""5"", ""6"", ""7"", ""8"", ""9""]
    digits = shuffle(digits)
    pat = digits[0] + digits[1] + digits[2] + digits[3]
    valid = ""123456789""
    while True:
        print(""Guess: "")
        guess = input()
        if len(guess) != 4:
            print(""Please guess a four digit number."")
            continue
        cows = 0
        bulls = 0
        seen = """"
        i = 0
        malformed = False
        while i < 4:
            cg = guess[i:i + 1]
            if indexOf(seen, cg) != (-1):
                print(""Repeated digit: "" + cg)
                malformed = True
                break
            seen = seen + cg
            pos = indexOf(pat, cg)
            if pos == (-1):
                if indexOf(valid, cg) == (-1):
                    print(""Invalid digit: "" + cg)
                    malformed = True
                    break
            else:
                if pos == i:
                    bulls = bulls + 1
                else:
                    cows = cows + 1
            i = i + 1
        if malformed:
            continue
        print(""Cows: "" + str(cows) + "", bulls: "" + str(bulls))
        if bulls == 4:
            print(""You got it."")
            break
",tests/rosetta/transpiler/Python/bulls-and-cows.py,,0,0.9947798749303169,"The method is a complete implementation of a simple game called 'Cows and Bulls'. It includes input validation, game logic, and output to the user. However, there are some issues in the code that might lead to its deletion or require significant modification. For instance, the 'shuffle' and 'indexOf' functions are not defined, which would cause the code to fail. Additionally, the use of 'input()' without any exception handling could lead to runtime errors if the input is not as expected. These issues suggest that the method might be deleted or heavily revised to ensure it functions correctly."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/bulls-and-cows.py,,1,8.76424914819242e-08,"The method `_now()` is a utility function that generates a pseudo-random number based on a global seed if `_now_seeded` is True, otherwise it returns the current time in nanoseconds. This function is likely part of a larger system that requires a consistent and repeatable random number generation when seeded, which can be useful for testing or simulations. The use of global variables and the specific random number generation formula suggest it is tailored for a specific purpose. Such utility functions are often retained unless they are replaced by a more efficient or standardized library function. However, without context on its usage or any deprecation notice, it's reasonable to assume it will survive."
survived,"def strdup(s):
    return s + """"
",tests/rosetta/transpiler/Python/call-a-foreign-language-function.py,,1,4.6911638017642294e-08,"The method `strdup` is a simple function that takes a string `s` and returns a new string that is a duplicate of `s`. This is a basic utility function that can be useful in various contexts where string duplication is needed. The implementation is straightforward and does not have any apparent issues or inefficiencies. Therefore, it is likely to be retained as it serves a clear purpose and is correctly implemented."
survived,"def commatize(n):
    s = str(n)
    out = """"
    i = 0
    cnt = 0
    neg = False
    if s[0:1] == ""-"":
        neg = True
        s = s[1:]
    i = len(s) - 1
    while i >= 0:
        out = """".join(s[i:i + 1]) + out
        cnt = cnt + 1
        if cnt == 3 and i != 0:
            out = "","" + out
            cnt = 0
        i = i - 1
    if neg:
        out = ""-"" + out
    return out
",tests/rosetta/transpiler/Python/calkin-wilf-sequence.py,,1,1.3440409770490404e-08,"The method 'commatize' is a utility function that formats a number by adding commas as thousand separators. This is a common requirement in many applications for better readability of large numbers. The function handles both positive and negative numbers, making it versatile. Such utility functions are often retained in codebases because they provide a useful feature that is not always available in standard libraries, especially in older versions of programming languages. Therefore, it is likely to be retained."
survived,"def sameDigits(n, b):
    f = n % b
    n = int((n // b))
    while n > 0:
        if n % b != f:
            return False
        n = int((n // b))
    return True
",tests/rosetta/transpiler/Python/brazilian-numbers.py,,1,2.0611536181902033e-09,"The method 'sameDigits' checks if all digits of a number 'n' in base 'b' are the same. This is a useful utility function for number theory and base conversion problems. It is simple, efficient, and has a clear purpose, making it likely to be retained in a codebase."
survived,"def link(graphdb_filename, osmdb_filename, gtfsdb_filename):
    """"""Link OSM vertices to GTFS vertices.""""""
    gtfsdb = GTFSDatabase(gtfsdb_filename)
    osmdb = OSMDB(osmdb_filename)
    gdb = GraphDatabase(graphdb_filename)

    n_stops = gtfsdb.count_stops()
    c = gdb.get_cursor()
    for i, (stop_id, _name, stop_lat, stop_lon) in enumerate(gtfsdb.stops()):
        click.echo(f""{i}/{n_stops}"")

        nd_id, nd_lat, nd_lon, nd_dist = osmdb.nearest_node(stop_lat, stop_lon)
        station_vertex_id = f""sta-{stop_id}""
        osm_vertex_id = f""osm-{nd_id}""

        click.echo(f""{station_vertex_id} {osm_vertex_id}"")

        gdb.add_edge(station_vertex_id, osm_vertex_id, Link(), c)
        gdb.add_edge(osm_vertex_id, station_vertex_id, Link(), c)

    gdb.commit()
",pygs/graphserver/cli.py,,1,1.725782769012759e-08,"The method 'link' is a crucial part of a system that integrates data from different sources (GTFS, OSM, and a graph database) to create a linked network of transportation data. This functionality is essential for applications that require mapping and routing capabilities, such as transportation planning and navigation systems. The method is well-defined, performs a specific task, and is likely part of a larger system that relies on this linking process. Therefore, it is unlikely to be deleted as it serves a fundamental purpose in the data integration process."
survived,"def gtfs(gtfs_filename, gtfsdb_filename, tables, verbose):
    """"""Compile a GTFS zip file into a GTFS database.""""""
    if not tables:
        tables = None
    gtfsdb = GTFSDatabase(gtfsdb_filename, overwrite=True)
    gtfsdb.load_gtfs(gtfs_filename, tables, reporter=sys.stdout, verbose=verbose)
",pygs/graphserver/cli.py,,1,2.5109990926928157e-08,"The method 'gtfs' is a utility function that compiles a GTFS (General Transit Feed Specification) zip file into a GTFS database. This is a specific and useful functionality for applications dealing with public transit data. The method is straightforward, with clear parameters and a specific purpose, making it likely to be retained in the codebase. Additionally, it uses a class 'GTFSDatabase' which suggests that it is part of a larger system or library, further indicating its utility and relevance."
survived,"def _tool_roundtrip() -> bool:
    """"""Return ``True`` if edit/undo leaves no changes.""""""
    path = REPO_ROOT / ""_roundtrip.txt""
    path.write_text(""a\nb\n"", encoding=""utf-8"")
    baseline = path.read_text(encoding=""utf-8"")
    edit(path, 1, 2, ""x"")
    undo_last_edit()
    ok = path.read_text(encoding=""utf-8"") == baseline
    path.unlink(missing_ok=True)  # type: ignore[call-arg]
    return ok
",src/archive/manager.py,,1,1.522997951276035e-08,"The method _tool_roundtrip is a utility function that tests if an edit followed by an undo operation results in no changes to a file. This is a useful test for ensuring the correctness of edit and undo functionalities, which are common in many applications. The method is self-contained, does not rely on external dependencies, and performs a clear and specific task. Such utility functions are often retained in codebases for testing purposes, especially if they help verify the integrity of critical operations like editing and undoing changes. Therefore, it is likely to be retained."
survived,"def _mutate(g: float) -> float:
    return g + random.uniform(-3.0, 3.0)
",experiments/ablate_selector.py,,1,3.3982678079468468e-09,"The method _mutate is a simple utility function that takes a float as input and returns a mutated version of it by adding a random float between -3.0 and 3.0. This kind of function is often used in genetic algorithms or simulations where slight variations are needed. The function is straightforward, performs a clear task, and does not have any apparent issues or redundancies. Therefore, it is likely to be useful in contexts where such mutations are needed, and there is no indication that it should be deleted."
survived,"def thread_and_agent():
    mock_client = Mock()
    mock_user = User()
    test_agent = Agent(name=""TestAgent"", description="""", instructions="""")
    thread = Thread(mock_user, test_agent)
    thread.client = mock_client
    thread.id = ""test_thread_id""
    thread._thread = Mock()
    thread._run = Mock()
    thread._run.id = ""test_run_id""
    thread._create_run = Mock()
    return thread, test_agent
",tests/test_thread_retry.py,,1,1.522997951276035e-08,"The method 'thread_and_agent' is a utility function that sets up a mock environment for testing purposes. It creates mock objects for a client, user, and thread, and associates them with a test agent. Such utility functions are commonly used in test suites to simplify the setup of test cases. Since it is likely part of a test suite, it is not expected to be deleted unless the testing framework or the way tests are conducted changes significantly. Therefore, it is likely to survive."
survived,"        def __init__(self, target, *a, **k):
            self.target = target
",tests/test_adk_gateway_startup.py,DummyThread,1,1.725782769012759e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes, in this case, setting the 'target' attribute. There is no indication that this constructor is redundant or unnecessary, so it is likely to be retained."
survived,"def test_problem_json_subprocess() -> None:
    port = _free_port()
    proc = _start_server(port)
    url = f""http://127.0.0.1:{port}""
    headers = {""Authorization"": ""Bearer test-token""}
    try:
        _wait_running(url, headers)
        r = httpx.get(f""{url}/results/missing"", headers=headers)
        assert r.status_code == 404
        data = r.json()
        assert data.get(""type"") == ""about:blank""
        assert data.get(""status"") == 404
        assert ""title"" in data
    finally:
        proc.terminate()
        proc.wait(timeout=5)",tests/test_api_server_subprocess.py,,1,2.1724399346070676e-10,"The method `test_problem_json_subprocess` is a test function that checks the behavior of a server when a specific endpoint is accessed. It ensures that the server returns a 404 status code and the expected JSON structure when a non-existent resource is requested. This is a common and necessary test to verify the correct handling of missing resources in web applications. The function is well-structured, uses a try-finally block to ensure the server process is terminated, and checks for specific response attributes. These characteristics make it a valuable part of a test suite, so it is likely to be retained."
survived,"def test_governance_sim_cli() -> None:
    """"""Verify the console script prints a result.""""""
    result = subprocess.run(
        [""governance-sim"", ""-N"", ""10"", ""-r"", ""20""],
        check=True,
        capture_output=True,
        text=True,
    )
    assert ""mean cooperation"" in result.stdout.lower()",tests/test_governance_sim_cli.py,,1,4.599055376537186e-10,"The method `test_governance_sim_cli` is a test function that verifies the output of a command-line interface tool. It uses `subprocess.run` to execute the command and checks if the expected output is present in the command's stdout. This is a common pattern for testing CLI tools, ensuring that the tool behaves as expected when run with specific arguments. Since testing CLI tools is a necessary part of software development to ensure reliability and correctness, this method is likely to be retained in the codebase."
survived,"def randN(n):
    global seed
    seed = (seed * 1664525 + 1013904223) % 2147483647
    sys.exit(seed % n)
",tests/rosetta/transpiler/Python/equilibrium-index.py,,0,0.9999994956527948,"The method 'randN' is a simple random number generator that uses a global variable 'seed' to generate a pseudo-random number. However, it has a critical flaw: it calls 'sys.exit' with the generated number, which will terminate the program every time this function is called. This makes the function unusable in any practical scenario where the program needs to continue running after generating a random number. Additionally, the function does not return a value, which is not typical for a random number generator function. These issues make the method impractical and likely to be deleted or significantly refactored."
survived,"    def g(x, y):
        x2 = x * x
        x2 = x2 + c
        return x2 % y
",tests/rosetta/transpiler/Python/euclid-mullin-sequence.py,,0,0.999985261023967,"The method 'g' is a simple mathematical function that takes two inputs, 'x' and 'y', and performs a series of operations: it squares 'x', adds a constant 'c', and then returns the result modulo 'y'. However, the variable 'c' is not defined within the function or passed as a parameter, which will lead to a NameError when the function is executed. This oversight suggests that the function is incomplete or incorrect as it stands. Without further context or correction, the function is likely to be deleted or significantly modified to address this issue."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/eulers-sum-of-powers-conjecture.py,,1,1.955568070542584e-08,"The method `_now()` is a utility function that generates a pseudo-random number based on a seed if `_now_seeded` is True, or returns the current time in nanoseconds otherwise. This function seems to be part of a larger system that requires a consistent and repeatable random number generation when seeded, and a fallback to the current time when not. Such utility functions are often retained in codebases for their utility in testing and time-based operations. Unless there is a specific reason to remove it, such as redundancy or a shift to a different random number generation strategy, it is likely to survive."
survived,"def showInt(n):
    line = ""Testing integer "" + pad(n, 3) + "":  ""
    if n % 2 == 0:
        line = line + ""even ""
    else:
        line = line + "" odd ""
    if n % 2 == 0:
        line = line + ""even""
    else:
        line = line + "" odd""
    print(line)
",tests/rosetta/transpiler/Python/even-or-odd.py,,0,0.9999997617630155,"The method 'showInt' is likely to be deleted because it contains redundant code and lacks efficiency. The method checks if a number is even or odd twice, which is unnecessary. Additionally, the 'pad' function is used but not defined within the code, which could lead to errors if 'pad' is not defined elsewhere. These issues suggest that the method is not well-optimized or complete, making it a candidate for deletion or significant revision."
survived,"def floorf(x):
    y = int(x)
    sys.exit(float(y))
",tests/rosetta/transpiler/Python/euler-method.py,,0,0.999999057755336,"The method 'floorf' is a simple implementation of flooring a floating-point number to the nearest lower integer. However, it uses 'sys.exit' to return the result, which is unconventional and not practical for a function that is supposed to return a value. This makes the function unusable in most contexts where a return value is expected, as it will terminate the program instead. This poor design choice is likely to lead to the method being deleted or significantly refactored."
survived,"def bottles(n):
    if n == 0:
        sys.exit(""No more bottles"")
    if n == 1:
        sys.exit(""1 bottle"")
    sys.exit(str(n) + "" bottles"")
",tests/rosetta/transpiler/Python/execute-hq9+.py,,0,0.9999999123575085,"The method 'bottles' is likely to be deleted because it uses 'sys.exit' to terminate the program, which is not a typical or recommended way to handle such logic in a function. Functions should return values or raise exceptions rather than exiting the program, as this limits the function's reusability and flexibility. Additionally, the function does not handle cases where 'n' is negative or non-integer, which could lead to unexpected behavior."
survived,"def fitness(s):
    h = 0
    i = 0
    while i < len(target):
        if s[i:i + 1] != target[i:i + 1]:
            h = h + 1
        i = i + 1
    sys.exit(h)
",tests/rosetta/transpiler/Python/evolutionary-algorithm.py,,0,0.9999999907625504,"The method 'fitness' is likely to be deleted because it contains a critical flaw: it calls 'sys.exit(h)', which will terminate the entire program execution when this function is called. This is not a typical or desirable behavior for a function that is supposed to calculate a fitness score, as it prevents further execution of the program and does not return a value that can be used by other parts of the program. Additionally, the function uses a global variable 'target' without defining it within the function or passing it as a parameter, which makes the function less modular and harder to test or reuse. These issues suggest that the function is not well-designed for its intended purpose and is likely to be removed or significantly refactored."
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    b = 2
    while b <= 16:
        start = 4 * b
        stop = 6 * b
        print(""Base "" + str(b) + "": "" + str(start) + ""th to "" + str(stop) + ""th esthetic numbers:"")
        n = 1
        c = 0
        line = """"
        while c < stop:
            if isEsthetic(n, b):
                c = c + 1
                if c >= start:
                    if len(line) > 0:
                        line = line + "" ""
                    line = line + toBase(n, b)
            n = n + 1
        print(line)
        print("""")
        b = b + 1
    listEsths(1000, 1010, 9999, 9898, 16, True)
    listEsths(100000000, 101010101, 130000000, 123456789, 9, True)
    listEsths(100000000000, 101010101010, 130000000000, 123456789898, 7, False)
    listEsths(100000000000000, 101010101010101, 130000000000000, 123456789898989, 5, False)
    listEsths(100000000000000000, 101010101010101010, 130000000000000000, 123456789898989898, 4, False)
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/esthetic-numbers.py,,1,3.850741907939403e-09,"The method 'main' is a complete function that performs a specific task of calculating and printing esthetic numbers in different bases. It also benchmarks the execution time and memory usage. The function is well-structured and serves a clear purpose, which makes it likely to be retained in the codebase. Additionally, it uses helper functions like 'isEsthetic' and 'toBase', indicating modular design, which is a good practice in programming. Therefore, it is likely to survive."
survived,"def if2(cond1, cond2, f):
    if cond1 and cond2:
        f()
    return If2(cond1=cond1, cond2=cond2)
",tests/rosetta/transpiler/Python/extend-your-language.py,,0,0.9993736658585413,"The method 'if2' is a utility function that checks two conditions and executes a function if both are true. However, it returns an instance of 'If2', which is not defined in the provided code. This suggests that the code is incomplete or the 'If2' class is defined elsewhere. Without the definition of 'If2', the method is not fully functional, which could lead to its deletion unless the missing parts are provided or the method is revised to be self-contained."
survived,"def libMain():
    seq = hailstone(27)
    print("""")
    print(""Hailstone sequence for the number 27:"")
    print(""  has "" + str(len(seq)) + "" elements"")
    print(""  starts with "" + listString(seq[0:4]))
    print(""  ends with "" + listString(seq[len(seq) - 4:len(seq)]))
    longest = 0
    length = 0
    i = 1
    while i < 100000:
        l = len(hailstone(i))
        if l > length:
            longest = i
            length = l
        i = i + 1
    print("""")
    print(str(longest) + "" has the longest Hailstone sequence, its length being "" + str(length) + ""."")
",tests/rosetta/transpiler/Python/executable-library.py,,1,9.931195248674785e-08,"The method 'libMain' is a standalone function that calculates and prints the Hailstone sequence for the number 27, and also finds the number with the longest Hailstone sequence up to 100,000. It is a complete and functional piece of code that serves a specific purpose. There is no indication that it is deprecated, redundant, or incorrect. Therefore, it is likely to be retained in the codebase."
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    wf = fibonacciWord(23)
    print(str(len(wf)))
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/fibonacci-word-fractal.py,,0,0.999999922655772,"The method 'main' is likely to be deleted (0) because it appears to be a benchmarking or testing function rather than a core part of an application. It measures the time and memory usage of generating a Fibonacci word of a specific length, which is typically useful for development and testing purposes but not necessary in a production environment. Such functions are often removed or commented out once the performance testing is complete."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/evolutionary-algorithm.py,,1,3.653482080241728e-08,"The method `_now()` is a utility function that generates a pseudo-random number based on a seed if `_now_seeded` is True, or returns the current time in nanoseconds otherwise. This function is likely part of a larger system that requires a consistent and repeatable sequence of numbers when seeded, which can be useful for testing or simulations. The function is simple, serves a clear purpose, and does not have any obvious issues or redundancies. Therefore, it is likely to be retained in the codebase."
survived,"def floorf(x):
    y = int(x)
    sys.exit(float(y))
",tests/rosetta/transpiler/Python/feigenbaum-constant-calculation.py,,0,0.999999057755336,"The method 'floorf' is a custom implementation that attempts to mimic the behavior of the standard library function 'math.floor'. However, it has a critical issue: it uses 'sys.exit' to return the result, which is not a standard or appropriate way to return values from a function. This will terminate the program instead of returning a value to the caller, making it impractical for use in any meaningful context. Additionally, the function name 'floorf' is unconventional and does not follow Python's naming conventions. Given these issues, it is likely that this method will be deleted or significantly refactored to be useful."
survived,"def cat(p, primes):
    if p in prevCats:
        return prevCats.get(p)
    pf = primeFactors(p + 1, primes)
    all23 = True
    for f in pf:
        if f != 2 and f != 3:
            all23 = False
            break
    if all23:
        prevCats[p] = 1
        return 1
    if p > 2:
        unique = []
        last = -1
        for f in pf:
            if f != last:
                unique = unique + [f]
                last = f
        pf = unique
    c = 2
    while c <= 11:
        ok = True
        for f in pf:
            if cat(f, primes) >= c:
                ok = False
                break
        if ok:
            prevCats[p] = c
            return c
        c = c + 1
    prevCats[p] = 12
    return 12
",tests/rosetta/transpiler/Python/erd-s-selfridge-categorization-of-primes.py,,1,1.8189616842444243e-09,"The method 'cat' is a recursive function that calculates a value based on the prime factors of a number. It uses memoization to store previously computed results in 'prevCats'. The function checks if all prime factors of 'p+1' are either 2 or 3, and if so, returns 1. Otherwise, it iterates through possible values from 2 to 11, checking conditions recursively. If none of these conditions are met, it returns 12. The function seems to be part of a larger algorithm, possibly related to number theory or combinatorial game theory, and appears to be well-structured and functional. Therefore, it is likely to be useful and survive."
survived,"def sing99():
    i = 99
    while i > 0:
        print(bottles(i) + "" of beer on the wall"")
        print(bottles(i) + "" of beer"")
        print(""Take one down, pass it around"")
        print(bottles(i - 1) + "" of beer on the wall"")
        i = i - 1
",tests/rosetta/transpiler/Python/execute-hq9+.py,,1,7.73442280641062e-08,"The method 'sing99' is a simple implementation of the '99 Bottles of Beer' song, which is a common programming exercise. It is a complete and functional method that correctly implements the logic of the song. The method is likely to survive because it serves as a good example of a loop and string manipulation in programming, and it doesn't have any apparent issues or bugs that would necessitate its deletion."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/environment-variables-2.py,,1,9.237449576640118e-09,"The method _now() is a utility function that generates a pseudo-random number based on a seed if _now_seeded is True, or returns the current time in nanoseconds if not. This function is likely part of a larger system that requires either a deterministic sequence of numbers (when seeded) or a timestamp. Such utility functions are common in systems that need to simulate time or generate predictable sequences for testing purposes. The function is simple, serves a clear purpose, and does not have any apparent issues or redundancies that would necessitate its removal. Therefore, it is likely to be retained in the codebase."
survived,"def expf(x):
    if x < 0.0:
        sys.exit(1.0 / expf(-x))
    term = 1.0
    sum = 1.0
    i = 1
    while i < 20:
        term = term * x / (float(i))
        sum = sum + term
        i = i + 1
    sys.exit(sum)
",tests/rosetta/transpiler/Python/euler-method.py,,0,0.9999999979388463,"The method `expf` is a custom implementation of the exponential function, but it has several issues that make it likely to be deleted. Firstly, it uses `sys.exit()` to return values, which is not a standard or appropriate way to return results from a function. This will terminate the program, which is not the intended behavior for a mathematical function. Secondly, the function does not handle edge cases or provide any error handling for invalid inputs. Lastly, Python's standard library already provides a robust and efficient implementation of the exponential function through `math.exp`, making this custom implementation redundant and unnecessary. Therefore, it is likely that this method will be deleted."
survived,"def entropy(s):
    counts = {}
    i = 0
    while i < len(s):
        ch = s[i:i + 1]
        if ch in counts:
            counts[ch] = counts[ch] + 1
        else:
            counts[ch] = 1
        i = i + 1
    hm = 0.0
    for k in list(counts.keys()):
        c = float(counts[k])
        hm = hm + c * (math.log(c) / math.log(2.0))
    l = float(len(s))
    sys.exit((math.log(l) / math.log(2.0)) - hm // l)
",tests/rosetta/transpiler/Python/fibonacci-word.py,,0,0.999999694097641,"The method is likely to be deleted because it contains several issues that make it unreliable and potentially unusable. Firstly, the use of `sys.exit()` to return a value is unconventional and inappropriate for a function that is supposed to calculate entropy. This will terminate the program instead of returning a result. Secondly, the calculation of entropy is incorrect; the formula used does not correctly implement the entropy calculation, which should involve summing the probabilities of each character times the log of the probability. Additionally, the use of integer division (`//`) in the entropy calculation is incorrect and will lead to incorrect results. These issues suggest that the method is not functioning as intended and would likely be removed or significantly revised in a codebase."
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    showInt(-2)
    showInt(-1)
    showInt(0)
    showInt(1)
    showInt(2)
    showBig(""-222222222222222222222222222222222222"")
    showBig(""-1"")
    showBig(""0"")
    showBig(""1"")
    showBig(""222222222222222222222222222222222222"")
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/even-or-odd.py,,1,4.944450477491054e-09,"The method 'main' is a complete function that performs specific tasks: it benchmarks memory usage and execution time, and it calls two functions, 'showInt' and 'showBig', with various inputs. The function is well-structured and outputs its results in a JSON format, which is useful for logging or further processing. There is no indication that this function is redundant or unnecessary, as it serves a clear purpose in performance measurement. Therefore, it is likely to be retained in the codebase."
survived,"def test_create_streamable_http_app_sets_state():
    server = FastMCP(name=""StateTest"")
    app = create_streamable_http_app(server, ""/mcp"")
    assert app.state.fastmcp_server is server
",tests/server/test_app_state.py,,1,1.1032560311263802e-09,"The method `test_create_streamable_http_app_sets_state` is a unit test that checks if the `create_streamable_http_app` function correctly sets the state of the app with the `fastmcp_server`. This is a straightforward and useful test to ensure that the function behaves as expected, especially in a development or testing environment. Unit tests are generally considered good practice for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, this method is likely to be Survived (1) as it serves a clear purpose in verifying the behavior of the code."
survived,"    def verify_ledger(self, expected: str, agent_id: str) -> None:
        """"""Slash ``agent_id`` when the current ledger root mismatches ``expected``.""""""
        actual = self.ledger.compute_merkle_root()
        if actual != expected:
            log.warning(""Merkle mismatch for %s"", agent_id)
            self.slash(agent_id)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/orchestrator.py,Orchestrator,1,1.1861120010657661e-08,"The method 'verify_ledger' is a utility function that checks if the current ledger's Merkle root matches an expected value. If there is a mismatch, it logs a warning and calls another method 'slash' on the agent_id. This method is likely part of a larger system that requires integrity checks on data, such as a blockchain or distributed ledger system. The functionality it provides is essential for maintaining data integrity and security, which are critical in such systems. Therefore, it is unlikely to be deleted as it serves an important purpose."
survived,"    def __init__(self, settings: config.Settings) -> None:
        self.settings = settings
        self.published = []
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_codegen_safety.py,DummyBus,1,2.998960815863541e-09,"The method is a constructor (__init__) for a class, which is a fundamental part of class instantiation in Python. It initializes the instance with the provided settings and an empty list for published items. Such methods are essential for setting up initial state and are unlikely to be removed unless the class itself is being refactored or removed. Therefore, it is expected to survive."
survived,"def sample_distribution(pop, beta, gamma, runs=20000):
    np.random.seed(123)
    counts = {id(ind): 0 for ind in pop}
    for _ in range(runs):
        ind = select_parent(pop, beta=beta, gamma=gamma)
        counts[id(ind)] += 1
    return np.asarray([counts[id(ind)] / runs for ind in pop])
",tests/test_selector_v2.py,,1,5.905303995456778e-10,"The method 'sample_distribution' is a utility function that simulates a distribution of selections from a population based on certain parameters (beta and gamma). It uses a random seed for reproducibility, which is a good practice in simulations. The function is straightforward, performs a specific task, and is likely useful in contexts where such simulations are needed. There are no apparent issues with the logic or implementation that would warrant its deletion. Therefore, it is likely to be retained."
survived,"def test_select_parent_weighting() -> None:
    pop = [
        Candidate(1.0, 0),
        Candidate(0.5, 1),
        Candidate(2.0, 2),
    ]
    beta, gamma = 0.5, 1.0
    expected = softmax(np.asarray([beta * p.score + gamma * p.edit_children_count for p in pop]))
    observed = sample_distribution(pop, beta, gamma)
    assert np.allclose(observed, expected, atol=0.02)",tests/test_selector.py,,1,2.998960815863541e-09,"The method `test_select_parent_weighting` is a unit test function that verifies the behavior of a function `sample_distribution`. It checks if the observed distribution of candidates matches the expected distribution calculated using the softmax function. This is a typical pattern in testing to ensure that the function under test behaves as expected. Since testing is a crucial part of software development to maintain code quality and prevent regressions, this method is likely to be retained. It serves a clear purpose in validating the logic of the `sample_distribution` function."
survived,"def test_get_context_returns_enrich_context():
    """"""app.get_context should return an EnrichContext""""""

    app = EnrichMCP(""Test API"", description=""Test API description"")
    ctx = app.get_context()

    assert isinstance(ctx, EnrichContext)
    assert ctx.fastmcp is app.mcp

    with pytest.raises(ValueError):
        _ = ctx.request_context
",tests/test_core.py,,1,3.927863699585036e-07,The method 'test_get_context_returns_enrich_context' is a test function that verifies the behavior of the 'get_context' method in the 'EnrichMCP' class. Test functions are generally not deleted as they are crucial for ensuring the correctness of the code. This test checks if the 'get_context' method returns an instance of 'EnrichContext' and if it raises a 'ValueError' when accessing 'request_context'. These are important checks for maintaining code quality and functionality.
survived,"def test_template_metadata_compat_flags() -> None:
    meta = TemplateMetadata(
        slug=""compat"",
        title=""Compat"",
        description=""desc"",
        intended_use=""demo"",
        io_contract={""input"": ""text"", ""output"": ""text""},
        tools=[],
        guardrails=[],
        model_pref=""gpt3"",
        category=TemplateCategory.CONVERSATION,
        complexity=TemplateComplexity.BASIC,
        created_by=""tester"",
        semver=""0.1.0"",
        last_test_passed=""2024-01-01T00:00:00Z"",
        requires_structured_outputs=True,
    )
    assert meta.requires_structured_outputs is True
    assert meta.requires_web_search is False",tests/test_template_schema.py,,1,8.152020648014727e-09,"The method `test_template_metadata_compat_flags` is a unit test function that checks the properties of a `TemplateMetadata` object. It verifies that the `requires_structured_outputs` attribute is set to `True` and `requires_web_search` is `False`. This kind of test is useful for ensuring that the metadata object is correctly initialized and behaves as expected. Since testing is a crucial part of software development to maintain code quality and prevent regressions, this method is likely to be retained. It serves a clear purpose in validating the behavior of the `TemplateMetadata` class."
survived,"    def record_event(
        self,
        category: ""TelemetryCollector.Category"",
        message: str,
        severity: ""TelemetryCollector.Severity"" = Severity.ERROR,
    ) -> None:
        """"""Record an informational or error event.""""""
        self.events.append(
            TelemetryCollector.Event(
                category=category,
                severity=severity,
                message=message,
            )
        )
        log = self.logger.info
        if severity in (self.Severity.ERROR, self.Severity.CRITICAL):
            log = self.logger.error
        elif severity is self.Severity.WARNING:
            log = self.logger.warning
        log(message)
",src/meta_agent/telemetry.py,TelemetryCollector,1,1.6918979223288786e-10,"The method 'record_event' is likely to survive because it serves a clear and useful purpose in the codebase. It records events with different severity levels and logs them appropriately, which is a common requirement in software systems for monitoring and debugging. The method is well-structured, using default parameters and handling different severity levels effectively. There is no indication of redundancy or obsolescence in its functionality."
survived,"def _turn_to_pyobj(turn: Turn) -> dict:
    """"""Convert a :class:`Turn` into a Python mapping understood by Arrow.""""""

    return {
        ""message"": turn.message,
        ""role"": turn.role,
        ""logprobs"": list(turn.logprobs) if turn.logprobs is not None else None,
        ""reward"": turn.reward,
        ""inference_metadata_json"": json.dumps(turn.inference_metadata, separators=("","", "":"")),
    }
",marin/rl/parquet_store.py,,1,1.1032560311263802e-09,"The method `_turn_to_pyobj` is a utility function that converts an instance of the `Turn` class into a dictionary format. This is a common pattern in Python for serializing objects, especially when preparing data for storage or transmission. The method is straightforward, performs a clear and useful task, and does not have any apparent issues or redundancies. It is likely to be used in various parts of a codebase where `Turn` objects need to be converted to a format compatible with other systems or libraries, such as Arrow. Therefore, it is unlikely to be deleted."
survived,"    async def run(self) -> None:
        """"""Execute :py:meth:`do_rollout` in a loop and dispatch results.""""""

        while not await self._should_stop():
            groups = await asyncio.to_thread(self.do_rollout)
            if groups:
                self._rollout_sink(groups)
            await asyncio.sleep(0)  # yield to Ray scheduler",marin/rl/env.py,SimpleEnv,1,2.8453347280241004e-08,"The method 'run' is an asynchronous function that continuously executes 'do_rollout' in a loop until a stopping condition is met. It uses asyncio to manage asynchronous execution and threading to offload 'do_rollout' to a separate thread. The method also includes a mechanism to yield control to the Ray scheduler, which is useful in distributed computing environments. This design pattern is common in modern asynchronous and distributed systems, making it likely to be retained for its utility in handling concurrent tasks efficiently."
survived,"def _rollout_to_pyobj(rollout: Rollout) -> dict:
    """"""Convert a :class:`Rollout` into a flat Python mapping suitable for Arrow.""""""

    return {
        ""turns"": [_turn_to_pyobj(t) for t in rollout.turns],
        ""rollout_metadata_json"": json.dumps(rollout.metadata, separators=("","", "":"")),
    }
",marin/rl/parquet_store.py,,1,2.3355930333443423e-09,"The method `_rollout_to_pyobj` is a utility function that converts a `Rollout` object into a dictionary format suitable for further processing, such as serialization with Arrow. This kind of conversion function is often necessary in data processing pipelines, especially when dealing with complex objects that need to be flattened or serialized. The method is straightforward, performs a clear and useful task, and is likely to be used in contexts where data needs to be prepared for storage or transmission. Therefore, it is likely to be retained in the codebase."
survived,"    async def _should_stop(self) -> bool:
        return self._stop_event.is_set()
",marin/rl/env.py,AbstractMarinEnv,1,2.646573631904765e-09,"The method `_should_stop` is a simple utility function that checks if a stop event has been set, which is a common pattern in asynchronous programming to gracefully handle stopping of tasks. This method is likely to be useful in managing the lifecycle of asynchronous operations, ensuring that tasks can be stopped cleanly when needed. Therefore, it is likely to be retained in the codebase."
survived,"    def build(self, inference: InferenceEndpoint, rollout_sink: RolloutSink, seed: int) -> ray.actor.ActorHandle:
        ActorCls = ray.remote(num_cpus=1)(HelloWorldEnv)
        actor = ActorCls.remote(inference, rollout_sink)
        actor.run.remote()  # kick off event loop
        return actor",marin/rl/envs/hello.py,HelloEnvConfig,1,2.646573631904765e-09,"The method 'build' is likely to survive because it is a functional piece of code that creates and returns a remote actor using Ray, a popular library for distributed computing. The method is straightforward, uses standard practices for creating remote actors, and does not contain any deprecated or problematic code patterns. Additionally, it is likely part of a larger system that relies on distributed processing, making it a necessary component."
survived,"    async def handle_request(self, payload: Dict[str, Any]) -> Dict[str, Any]:  # type: ignore[override]
        return {""echo"": payload}",alpha_factory_v1/demos/era_of_experience/stub_agents.py,FederatedExperienceAgent,1,3.3982678079468468e-09,"The method 'handle_request' is a simple asynchronous function that takes a dictionary as input and returns a dictionary with the same content under the key 'echo'. This method is straightforward and functional, providing a basic echo service which can be useful in various scenarios such as testing or as a placeholder for more complex logic. There is no indication of redundancy or obsolescence in the method's functionality, and it adheres to modern Python practices by using async and type hints. Therefore, it is likely to be retained."
survived,"async def trigger_memory() -> str:
    resp = requests.post(f""{HOST}/agent/memory/trigger"", timeout=5)
    resp.raise_for_status()
    return ""memory queued""
",alpha_factory_v1/demos/alpha_agi_business_v1/openai_agents_bridge.py,,0,0.999999057755336,"The method 'trigger_memory' is likely to be deleted because it uses the 'requests' library in an asynchronous function without using an asynchronous HTTP client like 'aiohttp'. This can lead to blocking behavior, which is contrary to the purpose of using async functions. To properly handle asynchronous HTTP requests, the code should be refactored to use an async-compatible library."
survived,"async def trigger_safety() -> str:
    resp = requests.post(f""{HOST}/agent/safety/trigger"", timeout=5)
    resp.raise_for_status()
    return ""safety queued""
",alpha_factory_v1/demos/alpha_agi_business_v1/openai_agents_bridge.py,,0,0.9999998144608401,"The method 'trigger_safety' is likely to be deleted because it uses 'requests.post' in an asynchronous function without using an asynchronous HTTP library like 'aiohttp'. This can lead to blocking behavior, which is not ideal in an asynchronous context. To properly handle asynchronous HTTP requests, the method should be refactored to use an appropriate library that supports async/await syntax."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/copy-a-string-2.py,,1,3.466327708641819e-07,"The method _now() is a utility function that generates a pseudo-random number based on a seed if _now_seeded is True, or returns the current time in nanoseconds if not. This function is likely used for testing or generating unique identifiers. The use of global variables and the specific seeding mechanism suggest it is tailored for a specific use case, possibly within a larger system. However, the function is not inherently flawed or redundant, and it serves a clear purpose. Therefore, it is more likely to be retained unless the system's requirements change significantly."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/constrained-genericity-4.py,,1,4.1399375473943306e-08,"The method _now() is a utility function that generates a pseudo-random number based on a global seed if it is set, or returns the current time in nanoseconds if not. This kind of function can be useful in scenarios where deterministic behavior is needed for testing or simulation purposes, as well as when a fallback to real-time is acceptable. The use of global variables is generally discouraged, but in this context, it serves a specific purpose. The function is simple, serves a clear purpose, and does not have any obvious flaws or redundancies that would necessitate its deletion. Therefore, it is likely to be retained."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/conditional-structures-8.py,,1,3.653482080241728e-08,"The method '_now' is a utility function that generates a pseudo-random number based on a seed if '_now_seeded' is True, otherwise it returns the current time in nanoseconds. This method is likely to be retained because it provides a useful functionality for generating time-based or seeded pseudo-random numbers, which can be useful in various applications such as testing, simulations, or time-stamping events. The method is simple, efficient, and does not have any apparent issues that would necessitate its removal."
survived,"    def is_available(cls) -> bool:
        try:
            import importlib

            importlib.import_module(""adk"")
            return True
        except Exception:
            return False
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/adk_adapter.py,ADKAdapter,1,3.581747929000289e-10,"The method `is_available` is a utility function that checks for the availability of a module named 'adk'. This is a common pattern used to conditionally enable features based on the presence of optional dependencies. Such methods are generally useful in making the codebase more flexible and adaptable to different environments. Since it provides a clear and straightforward way to check for module availability, it is likely to be retained in the codebase."
survived,"    def is_available(cls) -> bool:
        try:
            import importlib

            importlib.import_module(""mcp"")
            return True
        except Exception:
            return False
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/mcp_adapter.py,MCPAdapter,1,1.4166087846364157e-09,"The method `is_available` is a utility function that checks for the availability of a module named 'mcp'. It uses a try-except block to attempt importing the module and returns True if successful, otherwise False. This is a common pattern for checking module availability and is useful in scenarios where optional dependencies are involved. The method is simple, effective, and serves a clear purpose, making it likely to be retained in the codebase."
survived,"    def __init__(self) -> None:
        import importlib

        adk = importlib.import_module(""adk"")
        self._client = adk.Client()
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/adk_adapter.py,ADKAdapter,1,3.653482080241728e-08,"The method is a constructor for a class, initializing an instance variable `_client` using a module `adk`. This is a typical pattern for setting up a client or service in a class, and there is no indication that it is redundant or incorrect. Therefore, it is likely to be retained in the code."
survived,"    def execute(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        steps = [
            f""Practice {payload['skill']} at level {lvl}""
            for lvl in range(payload[""current_level""], payload[""target_level""] + 1)
        ]
        measures = [""Take breaks"", ""Monitor progress""]
        return {
            ""scaffold_steps"": steps,
            ""safety_measures"": measures,
            ""review_intervals"": ""weekly"",
        }",servers/server_clear_thought/tools/safe_struggle_designer.py,SafeStruggleDesigner,1,9.736200303530205e-10,"The method 'execute' is well-structured and provides a clear functionality: it generates a list of steps to practice a skill from a current level to a target level, includes safety measures, and sets review intervals. This kind of functionality is useful in applications related to skill development, learning management systems, or personal development tools. The method is generic and can be easily adapted or extended for various use cases. Therefore, it is likely to be retained in the codebase."
survived,"def test_assumption_xray():
    client = get_client()
    resp = client.post(
        ""/assumption-xray/execute"",
        json={""claim"": ""A"", ""context"": ""B""},
    )
    assert resp.status_code == 200
    data = resp.json()
    assert set(data.keys()) == {""assumptions"", ""confidence"", ""tests""}
",servers/server_clear_thought/tests/test_new_tools.py,,1,3.3982678079468468e-09,"The method `test_assumption_xray` is a unit test function that checks the functionality of an API endpoint. It uses a client to send a POST request to the `/assumption-xray/execute` endpoint with a JSON payload. The test then asserts that the response status code is 200 and that the response JSON contains specific keys. This is a typical structure for a test function in a codebase that uses automated testing to ensure the reliability of API endpoints. Such test functions are crucial for maintaining code quality and are unlikely to be deleted unless the endpoint itself is deprecated or the testing framework is changed. Therefore, the method is likely to survive."
survived,"        def _apply_limits() -> None:  # pragma: no cover - platform dependent
            try:
                import resource

                resource.setrlimit(resource.RLIMIT_CPU, (2, 2))
                mem = 128 * 1024 * 1024
                resource.setrlimit(resource.RLIMIT_AS, (mem, mem))
            except Exception:
                pass
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/codegen_agent.py,CodeGenAgent,1,1.522997951276035e-08,"The method '_apply_limits' is designed to set resource limits on CPU time and memory usage, which can be crucial for preventing excessive resource consumption in certain applications. Although it is marked with 'pragma: no cover', indicating it is not covered by tests due to platform dependency, this does not necessarily mean it is unused or unimportant. Such methods are often retained for their utility in specific environments where resource management is critical. Therefore, it is likely to survive as it serves a practical purpose in resource-constrained scenarios."
survived,"def _prefetch_vault() -> None:
    """"""Populate environment secrets from HashiCorp Vault if configured.""""""
    if ""VAULT_ADDR"" in os.environ:
        try:  # pragma: no cover - optional dependency
            import importlib

            hvac = importlib.import_module(""hvac"")

            addr = os.environ[""VAULT_ADDR""]
            token = os.getenv(""VAULT_TOKEN"")
            secret_path = os.getenv(""OPENAI_API_KEY_PATH"", ""OPENAI_API_KEY"")
            client = hvac.Client(url=addr, token=token)
            data = client.secrets.kv.read_secret_version(path=secret_path)
            value = data[""data""][""data""].get(""OPENAI_API_KEY"")
            if value:
                os.environ[""OPENAI_API_KEY""] = value
        except Exception as exc:  # noqa: BLE001
            _log.warning(""Vault lookup failed: %s"", exc)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/config.py,,1,4.599055376537186e-10,"The method `_prefetch_vault` is designed to fetch secrets from HashiCorp Vault if the environment is configured with a `VAULT_ADDR`. This functionality is crucial for applications that rely on secure secret management, especially in environments where security and dynamic configuration are priorities. The method includes error handling and logging, which are good practices for maintaining robustness. Additionally, the use of environment variables for configuration makes it flexible and adaptable to different deployment scenarios. Given the increasing importance of security and secret management in software development, this method is likely to be retained."
survived,"    def archive(self, path: Optional[str] = None) -> str:
        """"""Export all telemetry records to a gzipped JSON file.""""""
        data = self.fetch_all()
        if path is None:
            name = datetime.utcnow().isoformat().replace("":"", """").replace(""."", """")
            path = f""telemetry_{name}.json.gz""
        with gzip.open(path, ""wt"", encoding=""utf-8"") as f:
            json.dump(data, f)
        return path
",src/meta_agent/telemetry_db.py,TelemetryDB,1,1.9171715133907573e-10,"The method 'archive' is likely to survive because it provides a useful functionality of exporting telemetry records to a gzipped JSON file. This is a common requirement for data handling and archiving in many applications, especially those dealing with large datasets or needing to maintain historical records. The method is well-defined, uses standard libraries, and offers flexibility with an optional path parameter, making it a practical and reusable piece of code."
survived,"    async def func() -> str:
        calls[""n""] += 1
        if calls[""n""] < 2:
            raise ValueError(""boom"")
        return ""ok""
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_retry.py,,1,3.466327708641819e-07,"The method 'func' is designed to increment a counter and raise an exception on the first call, returning 'ok' on subsequent calls. This pattern can be useful for testing retry logic or handling transient errors. The method is simple, clear, and serves a specific purpose, which makes it likely to be retained in the codebase for testing or demonstration purposes."
survived,"        def __enter__(self) -> ""_Resp"":
            return self
",tests/test_check_env_network.py,_Resp,1,1.8189616842444243e-09,"The method is an implementation of the __enter__ method, which is part of the context management protocol in Python. This method is essential for objects that are intended to be used with the 'with' statement, allowing for setup and teardown actions. Since this is a standard and useful feature in Python, it is unlikely to be deleted unless the class itself is being removed or refactored significantly. Therefore, the method will likely survive."
survived,"def compute_score(data: dict) -> int:
    """"""Return a simplified Axe score (0-100).""""""
    total = 0
    for violation in data.get(""violations"", []):
        impact = violation.get(""impact"", ""minor"")
        total += WEIGHTS.get(impact, 1)
    score = max(0, 100 - total)
    return score
",scripts/axe_score.py,,1,5.211412485172657e-10,"The method 'compute_score' is a straightforward function that calculates a score based on the impact of violations. It is well-defined, with a clear purpose and a simple algorithm that uses a dictionary to map impact levels to weights. This kind of utility function is commonly used in data processing tasks, and there is no indication of redundancy or inefficiency that would necessitate its removal. Therefore, it is likely to be retained in the codebase."
survived,"def test_format_prompt_summary():
    messages = [
        {""role"": ""system"", ""content"": ""lorem ipsum dolor sit amet""},
        {
            ""role"": ""user"",
            ""content"": [
                {""type"": ""text"", ""text"": ""hello world""},
                {""type"": ""image_url"", ""image_url"": {""url"": ""data:image/png;base64,AAA""}},
                {""type"": ""image_url"", ""image_url"": {""url"": ""data:image/png;base64,BBB""}},
            ],
        },
    ]

    summary = format_prompt_summary(messages)
    assert ""system: lorem ipsum"" in summary
    assert ""[2 images]"" in summary",backend/tests/test_prompt_summary.py,,1,2.2159489282323004e-08,"The method `test_format_prompt_summary` is a unit test designed to verify the functionality of the `format_prompt_summary` function. It checks if the summary correctly includes a portion of the system message and indicates the presence of two images. Unit tests are crucial for ensuring code reliability and are typically retained unless the functionality they test is removed or significantly altered. Since the test is straightforward and serves a clear purpose, it is likely to be maintained as long as the `format_prompt_summary` function exists and requires validation."
survived,"    def test_run_demo_short(self) -> None:
        result = subprocess.run(
            [
                sys.executable,
                ""-m"",
                ""alpha_factory_v1.demos.meta_agentic_tree_search_v0.run_demo"",
                ""--episodes"",
                ""3"",
            ],
            capture_output=True,
            text=True,
        )
        self.assertEqual(result.returncode, 0, result.stderr)
        self.assertIn(""Best agents"", result.stdout)
",tests/test_meta_agentic_tree_search_demo.py,TestMetaAgenticTreeSearchDemo,1,3.160881453314576e-10,"The method `test_run_demo_short` is a unit test designed to verify the functionality of a demo script by running it as a subprocess and checking its output. This is a common practice in software development to ensure that scripts or modules behave as expected. The method checks that the subprocess completes successfully (return code 0) and that the expected output ('Best agents') is present in the standard output. Such tests are crucial for maintaining code quality and are unlikely to be deleted unless the functionality they test is removed or significantly altered. Therefore, the method is likely to survive."
survived,"    def test_env_rollout(self) -> None:
        from alpha_factory_v1.demos.meta_agentic_tree_search_v0.mats.env import NumberLineEnv

        env = NumberLineEnv(target=3)
        reward = env.rollout([3, 3, 3])
        self.assertGreaterEqual(reward, -0.1)
",tests/test_meta_agentic_tree_search_demo.py,TestMetaAgenticTreeSearchDemo,1,5.043472052266442e-07,"The method 'test_env_rollout' is a unit test function that tests the functionality of the 'NumberLineEnv' class from a specific module. It checks if the 'rollout' method of the 'NumberLineEnv' class returns a reward greater than or equal to -0.1 when given a specific input. This is a typical use case for unit tests, which are essential for ensuring code reliability and correctness. Since this method is a test function, it is likely to be retained as part of the test suite to ensure the continued correct behavior of the 'NumberLineEnv' class."
survived,"    def rollout(self, agents: List[int]) -> float:
        """"""Return a pseudo reward after a single rollout.""""""
        distance = sum(abs(a - self.target) for a in agents)
        noise = random.random() * 0.1
        return -distance + noise",alpha_factory_v1/demos/meta_agentic_tree_search_v0/mats/env.py,NumberLineEnv,1,4.0586521248284276e-10,"The method 'rollout' is likely to be Survived (1) because it appears to be a functional and meaningful part of a larger system, possibly related to reinforcement learning or simulation. The method calculates a pseudo reward based on the distance of agents from a target, which is a common operation in such contexts. The addition of noise introduces variability, which can be useful for exploration in learning algorithms. There are no obvious issues with the logic or implementation that would necessitate its deletion."
survived,"async def _sanitize_stream_async(
    data: Union[str, Iterable[str], Iterable[bytes]],
    intro_value: str = ""data:"",
    to_json: bool = True,
    skip_markers: Optional[List[str]] = None,
    strip_chars: Optional[str] = None,
    start_marker: Optional[str] = None,
    end_marker: Optional[str] = None,
    content_extractor: Optional[Callable[[Union[str, Dict[str, Any]]], Optional[Any]]] = None,
    yield_raw_on_error: bool = True,
    encoding: EncodingType = 'utf-8',
    encoding_errors: str = 'replace',
    buffer_size: int = 8192,
    line_delimiter: Optional[str] = None,
    error_handler: Optional[Callable[[Exception, str], Optional[Any]]] = None,
) -> Generator[Any, None, None]:
    """"""Asynchronous variant of :func:`sanitize_stream`.""""""

    if isinstance(data, str):
        for item in _sanitize_stream_sync(
            data,
            intro_value=intro_value,
            to_json=to_json,
            skip_markers=skip_markers,
            strip_chars=strip_chars,
            start_marker=start_marker,
            end_marker=end_marker,
            content_extractor=content_extractor,
            yield_raw_on_error=yield_raw_on_error,
            encoding=encoding,
            encoding_errors=encoding_errors,
            buffer_size=buffer_size,
            line_delimiter=line_delimiter,
            error_handler=error_handler,
        ):
            yield item
        return

    if not hasattr(data, ""__aiter__""):
        # Fallback to synchronous processing if possible
        for item in _sanitize_stream_sync(
            data,
            intro_value=intro_value,
            to_json=to_json,
            skip_markers=skip_markers,
            strip_chars=strip_chars,
            start_marker=start_marker,
            end_marker=end_marker,
            content_extractor=content_extractor,
            yield_raw_on_error=yield_raw_on_error,
            encoding=encoding,
            encoding_errors=encoding_errors,
            buffer_size=buffer_size,
            line_delimiter=line_delimiter,
            error_handler=error_handler,
        ):
            yield item
        return

    effective_skip_markers = skip_markers or []
    processing_active = start_marker is None
    buffer = """"
    found_start = False if start_marker else True

    iterator = data.__aiter__()
    first_item = None
    async for first_item in iterator:
        break
    if first_item is None:
        return
    async def _chain(first, it):
        yield first
        async for x in it:
            yield x

    stream = _chain(first_item, iterator)

    if isinstance(first_item, bytes):
        line_iterator = _decode_byte_stream_async(
            stream,
            encoding=encoding,
            errors=encoding_errors,
            buffer_size=buffer_size,
        )
    elif isinstance(first_item, str):
        line_iterator = stream
    else:
        raise TypeError(
            f""Stream must yield strings or bytes, not {type(first_item).__name__}""
        )

    async for line in line_iterator:
        if not line:
            continue
        buffer += line
        while True:
            if not found_start and start_marker:
                idx = buffer.find(start_marker)
                if idx != -1:
                    found_start = True
                    buffer = buffer[idx + len(start_marker) :]
                else:
                    buffer = buffer[-max(len(start_marker), 256) :]
                    break
            if found_start and end_marker:
                idx = buffer.find(end_marker)
                if idx != -1:
                    chunk = buffer[:idx]
                    buffer = buffer[idx + len(end_marker) :]
                    processing_active = False
                else:
                    chunk = buffer
                    buffer = """"
                    processing_active = True
                if chunk and processing_active:
                    for subline in (
                        chunk.split(line_delimiter)
                        if line_delimiter is not None
                        else chunk.splitlines()
                    ):
                        result = _process_chunk(
                            subline,
                            intro_value,
                            to_json,
                            effective_skip_markers,
                            strip_chars,
                            yield_raw_on_error,
                            error_handler,
                        )
                        if result is None:
                            continue
                        if content_extractor:
                            try:
                                final_content = content_extractor(result)
                                if final_content is not None:
                                    yield final_content
                            except Exception:
                                pass
                        else:
                            yield result
                if not processing_active:
                    found_start = False
                if idx == -1:
                    break
            elif found_start:
                chunk = buffer
                buffer = """"
                if chunk:
                    for subline in (
                        chunk.split(line_delimiter)
                        if line_delimiter is not None
                        else chunk.splitlines()
                    ):
                        result = _process_chunk(
                            subline,
                            intro_value,
                            to_json,
                            effective_skip_markers,
                            strip_chars,
                            yield_raw_on_error,
                            error_handler,
                        )
                        if result is None:
                            continue
                        if content_extractor:
                            try:
                                final_content = content_extractor(result)
                                if final_content is not None:
                                    yield final_content
                            except Exception:
                                pass
                        else:
                            yield result
                break
            else:
                break
",webscout/AIutel.py,,1,4.1399375473943306e-08,"The method `_sanitize_stream_async` is a comprehensive and well-structured asynchronous function designed to process streams of data. It includes error handling, supports both string and byte data, and provides flexibility through various parameters. The function is likely to be useful in scenarios where asynchronous data processing is required, such as in web applications or data pipelines. Given its utility and the increasing trend towards asynchronous programming in Python, it is more likely to be maintained and improved rather than deleted."
survived,"        async def wrapper_async(*args: P.args, **kwargs: P.kwargs) -> Any:
            for attempt in range(max_tries):
                try:
                    return await cast(Callable[P, Awaitable[T]], func)(*args, **kwargs)
                except Exception as exc:  # pragma: no cover - runtime errors
                    if attempt + 1 >= max_tries:
                        raise
                    _log_retry(
                        {
                            ""tries"": attempt + 1,
                            ""exception"": exc,
                            ""target"": func,
                        }
                    )
                    await asyncio.sleep(2**attempt * 0.1)
            raise AssertionError(""unreachable"")
",alpha_factory_v1/common/utils/retry.py,,1,1.2501528648238603e-09,"The method 'wrapper_async' is a robust implementation of a retry mechanism for asynchronous functions. It attempts to call the provided function up to 'max_tries' times, with exponential backoff in case of exceptions. This is a common pattern in asynchronous programming to handle transient errors gracefully. The use of logging for retries and the clear structure of the code make it a useful utility function. Therefore, it is likely to be retained in the codebase."
survived,"    def wrapper_sync(*args: P.args, **kwargs: P.kwargs) -> Any:
        for attempt in range(max_tries):
            try:
                return cast(Callable[P, T], func)(*args, **kwargs)
            except Exception as exc:  # pragma: no cover - runtime errors
                if attempt + 1 >= max_tries:
                    raise
                _log_retry(
                    {
                        ""tries"": attempt + 1,
                        ""exception"": exc,
                        ""target"": func,
                    }
                )
                time.sleep(2**attempt * 0.1)
        raise AssertionError(""unreachable"")
",alpha_factory_v1/common/utils/retry.py,,1,6.023574641292144e-08,"The method 'wrapper_sync' is a robust implementation of a retry mechanism for a function call. It attempts to execute a function multiple times (up to 'max_tries') and logs each retry attempt if an exception occurs. The exponential backoff strategy (using 'time.sleep(2**attempt * 0.1)') is a common and effective way to handle transient errors, making the method useful in scenarios where temporary issues might resolve themselves after a short delay. The use of type hints and exception handling further enhances its utility and maintainability. Given these factors, the method is likely to be retained as it provides a valuable functionality for improving the reliability of function calls."
survived,"    def __init__(self, broker: str | None, dev_mode: bool) -> None:
        self._bus = EventBus(broker, dev_mode)
",alpha_factory_v1/backend/services/kafka_service.py,KafkaService,1,3.2241866333029355e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting up initial states. The use of type hints for parameters also suggests that the code is modern and follows good practices. There is no indication that this constructor is redundant or unnecessary, so it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-h/compiler/py/q20.py,Auto1,1,3.653482080241728e-08,"The method is a simple implementation of the __getitem__ special method, which allows instances of the class to use the bracket notation (e.g., obj[key]) to access attributes dynamically. This is a common and useful pattern in Python, especially for classes that need to provide dictionary-like access to their attributes. It is likely to be retained as it provides flexibility and enhances the usability of the class."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-h/compiler/py/q18.py,Auto2,1,1.725782769012759e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via keys, similar to a dictionary. Since this method provides a clear and functional purpose, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-h/compiler/py/q2.py,Auto1,1,4.6911638017642294e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a flexible and Pythonic way to access object attributes, it is likely to be retained in the code."
survived,"def _hash_embed(text: str, dim: int) -> List[float]:
    """"""Create a simple hashed bag-of-words embedding.""""""
    vec = [0.0] * dim
    for word in text.lower().split():
        idx = hash(word) % dim
        vec[idx] += 1.0
    return vec
",src/meta_agent/embedding_models.py,,1,8.152020648014727e-09,"The method '_hash_embed' is a simple and efficient way to create a hashed bag-of-words embedding from a text input. It is useful for converting text data into a numerical format that can be used in machine learning models. The method is straightforward, does not rely on external libraries, and provides a quick way to generate embeddings with a specified dimension. Such utility functions are often retained in codebases for their simplicity and utility in preprocessing text data. Therefore, it is likely to be retained."
survived,"def test_alpha_factory_import():
    mod = importlib.import_module('alpha_factory_v1')
    assert hasattr(mod, '__version__')
",tests/test_imports.py,,1,9.736200303530205e-10,"The method 'test_alpha_factory_import' is a simple test function that checks if a module 'alpha_factory_v1' can be imported and if it has an attribute '__version__'. This is a basic test to ensure that the module is correctly set up and versioned. Such tests are common in software development to verify module integrity and are likely to be retained as they provide value in maintaining code quality and consistency. Therefore, the method is likely to survive."
survived,"            async def step(self):
                return None
",tests/test_agents_registry.py,TestRegisterDecorator.SkipAgent,0,0.9999999586006244,"The method 'step' is an asynchronous function that currently does nothing but return None. If this method is part of a larger codebase, it might be a placeholder for future implementation. However, if it remains unchanged and unused, it is likely to be deleted in future code clean-ups to maintain code quality and remove unnecessary parts. Without additional context on its intended use or future plans for implementation, the method is more likely to be deleted."
survived,"    def test_stub_after_errors(self):
        from alpha_factory_v1.backend.agents import _HEALTH_Q, StubAgent, _ERR_THRESHOLD

        class FailingAgent(AgentBase):
            NAME = ""fail""

            async def step(self):
                raise RuntimeError(""boom"")

        meta = AgentMetadata(name=""fail"", cls=FailingAgent, version=""0"", capabilities=[])  # type: ignore[list-item]
        register_agent(meta)
        # Pre-set error count to threshold -1
        object.__setattr__(AGENT_REGISTRY[""fail""], ""err_count"", _ERR_THRESHOLD - 1)
        _HEALTH_Q.put((""fail"", 0.0, False))
        # give the background thread a moment
        import time
        time.sleep(0.05)
        self.assertIs(AGENT_REGISTRY[""fail""].cls, StubAgent)
",tests/test_agents_registry.py,TestHealthQuarantine,1,1.955568070542584e-08,"The method 'test_stub_after_errors' is a unit test designed to verify the behavior of a system when an agent exceeds a predefined error threshold. It simulates an agent that consistently fails, checks if the error count reaches the threshold, and then asserts that the agent is replaced with a 'StubAgent'. This is a valid and useful test for ensuring system robustness and error handling, especially in systems that rely on multiple agents. Therefore, it is likely to be retained as part of the test suite."
survived,"    def set(self, val) -> None:
        self.value = val
",tests/test_agent_base.py,_Gauge,1,0.0001584362468454316,"The method 'set' is a simple setter method that assigns a value to an instance variable 'value'. Such methods are common in object-oriented programming to encapsulate the setting of attributes. However, in modern Python, direct attribute access is often preferred unless additional logic is needed during setting. Without additional context, such as the presence of additional logic in the setter or the need for encapsulation, this method might be considered redundant. However, it is not inherently harmful or incorrect, so it is likely to survive unless there is a specific reason to remove it, such as a shift to using properties or direct attribute access."
survived,"    def test_battery_optim_mismatch(self):
        with self.assertRaises(ValueError):
            energy_agent._battery_optim([1, 2], [3])
",tests/test_energy_utils.py,TestEnergyUtils,1,8.152020648014727e-09,"The method `test_battery_optim_mismatch` is a unit test designed to check if the `_battery_optim` method of the `energy_agent` raises a `ValueError` when given mismatched input lists. This is a valid and useful test case to ensure the robustness of the `_battery_optim` method against incorrect input. Unit tests are generally retained in codebases to ensure ongoing code quality and to catch regressions. Therefore, this method is likely to be retained."
survived,"    def test_backend_alias(self):
        a = importlib.import_module(""alpha_factory_v1.backend.agents"")
        b = importlib.import_module(""backend.agents"")
        self.assertIs(a, b)
        self.assertGreater(len(a.AGENT_REGISTRY), 1)
",tests/test_agents_alias.py,TestAgentsAlias,1,3.3982678079468468e-09,"The method `test_backend_alias` is a unit test that checks if two module imports refer to the same module and if the `AGENT_REGISTRY` has more than one entry. This test is useful for ensuring that the module aliasing works correctly and that the registry is populated, which are important aspects of the system's functionality. Therefore, it is likely to be retained as part of the test suite to ensure ongoing reliability and correctness of the codebase."
survived,"def compute_sliding_logits_tp_fp32(cfg: SlidingLogitsTPFP32Config) -> None:
    """"""Run tensor-parallel sliding window forward pass with FP32 precision.""""""

    compute_sliding_logits_tp(cfg)
",marin/generation/sliding_logits_tp_fp32.py,,1,3.160881453314576e-10,"The method `compute_sliding_logits_tp_fp32` is a wrapper around the `compute_sliding_logits_tp` function, adding a specific configuration for FP32 precision. This suggests that it serves a specific purpose in the codebase, likely related to ensuring precision in computations. Such methods are often retained because they provide a clear and specific interface for a common operation with a particular configuration. Unless there is a significant refactor or change in how precision is handled, this method is likely to survive."
survived,"  def update_counter(self, cur_count: int, cnt_size: int) -> bool:
    if ((self.counter + 1) & ((1 << cnt_size) - 1)) != cur_count:
      self.counter_fail = min(self.counter_fail + 1, MAX_BAD_COUNTER)
    elif self.counter_fail > 0:
      self.counter_fail -= 1
    self.counter = cur_count
    return self.counter_fail < MAX_BAD_COUNTER
",opendbc/can/parser.py,MessageState,1,1.6052280526088547e-09,"The method 'update_counter' is likely to survive because it contains logic that updates a counter and manages a failure count, which seems to be part of a larger system for tracking or validating counter states. The method includes conditions to increment or decrement a failure counter based on the current state, which suggests it is part of a robust error-handling or validation mechanism. Such functionality is typically essential in systems that require precise state management, making it unlikely to be removed unless the entire system is refactored or replaced."
survived,"    async def first(prompt, **kwargs):
        return 5
",tests/test_workflow.py,,1,6.023574641292144e-08,"The method 'first' is a simple asynchronous function that takes a 'prompt' and additional keyword arguments, and returns the integer 5. It is a basic implementation that doesn't perform any complex operations or have any dependencies. Such a method is likely to survive because it is straightforward, has no apparent issues, and could be useful in contexts where a constant return value is needed for testing or as a placeholder."
survived,"    async def runner(prompt, user_id=None, session_id=None, llm=None, sdk_context=None):
        called['params'] = (user_id, session_id, llm, sdk_context)
        return prompt + ""-done""
",tests/test_workflow.py,,1,9.237449576640118e-09,"The method 'runner' is a simple asynchronous function that appends '-done' to the input 'prompt' and stores some parameters in a dictionary. It is a utility function that could be useful in various contexts where asynchronous operations are needed, such as handling user prompts in a non-blocking manner. The function is straightforward and does not contain any deprecated or harmful practices, making it likely to be retained in the codebase."
survived,"    async def _execute_runner(
        self,
        runner: Any,
        prompt: Any,
        user_id: str,
        session_id: str,
        llm: Optional[LLM],
        sdk_context: SDKContext,
    ) -> Any:
        if hasattr(runner, ""chat""):
            result = runner.chat(prompt, user_id=user_id, session_id=session_id, llm=llm, sdk_context=sdk_context)
        else:
            result = runner(prompt, user_id=user_id, session_id=session_id, llm=llm, sdk_context=sdk_context)
        if asyncio.iscoroutine(result):
            return await result
        return result
",swarmzero/workflow.py,Workflow,1,6.69158608681505e-10,"The method '_execute_runner' is designed to handle both synchronous and asynchronous operations, which is a common requirement in modern software development. It checks if the 'runner' object has a 'chat' method and calls it if available, otherwise it calls 'runner' directly. It also checks if the result is a coroutine and awaits it if necessary. This flexibility and robustness in handling different types of operations make it a useful utility function that is likely to be retained in the codebase."
survived,"def test_offline_no_wheelhouse(monkeypatch: pytest.MonkeyPatch, capsys: pytest.CaptureFixture[str]) -> None:
    """"""Fail fast when offline without a wheelhouse.""""""
    _no_missing(monkeypatch)
    monkeypatch.setattr(check_env, ""has_network"", lambda: False)
    monkeypatch.delenv(""WHEELHOUSE"", raising=False)
    rc = check_env.main([""--auto-install""])
    out = capsys.readouterr().out
    assert rc == 1
    assert ""--wheelhouse <dir>"" in out
",tests/test_check_env_network.py,,1,2.8453347280241004e-08,"The method 'test_offline_no_wheelhouse' is a unit test function that checks the behavior of a system when it is offline and without a wheelhouse. It uses the 'monkeypatch' fixture to simulate an environment where there is no network and the 'WHEELHOUSE' environment variable is not set. The test then asserts that the system returns a specific error code and message. This is a typical and necessary test to ensure the robustness of the system in handling offline scenarios. Therefore, it is unlikely to be deleted as it serves a critical role in maintaining software quality."
survived,"def test_scalar_eliminates_axis():
    B, S, V = Axis(""batch"", 2), Axis(""seq"", 3), Axis(""vocab"", 4)
    x = hax.arange((B, S, V))
    out = x[""seq"", 1]
    assert out.axes == (B, V)
    assert jnp.array_equal(out.array, x.array[:, 1, :])
",tests/test_scatter_gather.py,,1,4.4508487281649027e-07,"The method 'test_scalar_eliminates_axis' is a unit test designed to verify the behavior of a tensor operation, specifically checking if selecting a specific index along an axis correctly reduces the dimensionality of the tensor. This is a common and useful operation in tensor manipulation libraries, and the test ensures that the implementation behaves as expected. Since this is a test function, it is unlikely to be deleted unless the functionality it tests is removed or significantly altered. However, such basic tensor operations are fundamental and unlikely to be removed from a library."
survived,"    def test_modbuspowermeter_float32(self, MockModbusTcpClient):
        mock_client = MockModbusTcpClient.return_value
        mock_client.read_holding_registers.return_value.isError.return_value = False
        mock_client.read_holding_registers.return_value.registers = [0x4120, 0x0000]

        modbuspowermeter = ModbusPowermeter(
            ""192.168.1.14"",
            502,
            1,
            0,
            2,
            data_type=""FLOAT32"",
            byte_order=""BIG"",
            word_order=""BIG"",
        )
        self.assertEqual(modbuspowermeter.get_powermeter_watts(), [10.0])
",powermeter/modbus_test.py,TestPowermeters,1,6.825604231969389e-08,"The method is a unit test for a specific functionality of a Modbus power meter, which is a common requirement in software that deals with industrial protocols. The test is well-structured, using a mock object to simulate the Modbus client and verify the correct behavior of the `get_powermeter_watts` method. Such tests are crucial for ensuring the reliability and correctness of the code, especially in systems that interact with hardware. Therefore, it is unlikely to be deleted as it serves an important purpose in the codebase."
survived,"    def add_sequence(self, state, tokens, length):
        """"""Add a new sequence to ``state``. Evicts the oldest if full.""""""
        import jax.numpy as jnp
        from jax import lax

        def _evict(state):
            idx = state.tail
            state.active = state.active.at[idx].set(False)
            state.tail = (state.tail + 1) % self.max_seqs
            return state

        def _add(state):
            idx = state.head
            state.token_ids = state.token_ids.at[idx, :length].set(tokens[:length])
            state.lengths = state.lengths.at[idx].set(length)
            state.active = state.active.at[idx].set(True)
            state.head = (state.head + 1) % self.max_seqs
            return state

        need_evict = jnp.logical_and(state.active[state.head], True)
        state = lax.cond(need_evict, _evict, lambda s: s, state)
        state = _add(state)
        return state
",src/levanter/inference/scheduler.py,JittedScheduler,1,7.194132978569833e-09,"The method 'add_sequence' is a well-defined function that manages a sequence buffer by adding new sequences and evicting the oldest ones when the buffer is full. It uses JAX for efficient computation, which is a modern and relevant library for numerical computing. The method is likely to be useful in scenarios where managing a fixed-size buffer of sequences is necessary, such as in machine learning or data processing tasks. There is no indication that this method is obsolete or redundant, and it appears to be a functional and efficient implementation. Therefore, it is likely to be retained."
survived,"def slide_print(p):
    n = int(round(len(p) ** 0.5))
    l = len(str(n*n))
    for i in range(0, len(p), n):
        print("" "".join(""{:>{}}"".format(x, l) for x in p[i:i+n]))
",tests/rosetta/x/Python/15-puzzle-solver/15-puzzle-solver-1.py,,1,1.955568070542584e-08,"The method 'slide_print' is a utility function that formats and prints a list of elements in a grid-like structure. It calculates the number of elements per row based on the square root of the list's length, ensuring a visually appealing output. This kind of function can be useful in various contexts where data needs to be displayed in a structured format, such as debugging or presenting results. Its functionality is generic and not tied to any specific application, making it a versatile tool. Therefore, it is likely to be retained in the codebase."
survived,"def slide_wd(n, goal):
    wd = gen_wd_table(n)
    goals = {i : goal.index(i) for i in goal}
    b = n.bit_length()

    def h(p):
        ht = 0 # Walking distance between rows.
        vt = 0 # Walking distance between columns.
        d = 0
        for i, c in enumerate(p):
            if c == 0: continue
            g = goals[c]
            xi, yi = i % n, i // n
            xg, yg = g % n, g // n
            ht += 1 << (b*(n*yi+yg))
            vt += 1 << (b*(n*xi+xg))

            if yg == yi:
                for k in range(i + 1, i - i%n + n): # Until end of row.
                    if p[k] and goals[p[k]] // n == yi and goals[p[k]] < g:
                        d += 2

            if xg == xi:
                for k in range(i + n, n * n, n): # Until end of column.
                    if p[k] and goals[p[k]] % n == xi and goals[p[k]] < g:
                        d += 2

        d += wd[ht] + wd[vt]

        return d
    return h
",tests/rosetta/x/Python/15-puzzle-solver/15-puzzle-solver-1.py,,1,1.3440409770490404e-08,"The method 'slide_wd' is a utility function that calculates a heuristic for a sliding puzzle problem. It is a specialized function that is likely part of a larger puzzle-solving algorithm. Such functions are typically retained because they encapsulate specific logic that is not easily replicated or replaced. Additionally, the function appears to be well-structured and serves a clear purpose in calculating walking distances, which is a common heuristic in puzzle-solving algorithms. Therefore, it is likely to be retained."
survived,"    def get_tag(self):
        python, abi, platform = super().get_tag()
        if python.startswith(""cp""):
            python, abi = ""cp39"", ""abi3""
        return python, abi, platform
",third_party/tree-sitter-racket/setup.py,BdistWheel,1,1.1032560311263802e-09,"The method `get_tag` is overriding a method from a superclass and modifies the behavior for specific conditions. It checks if the `python` variable starts with ""cp"" and then sets `python` to ""cp39"" and `abi` to ""abi3"". This kind of method is often used in packaging or compatibility scenarios, such as in Python package distribution where specific tags are needed for compatibility with different Python versions and platforms. Since this method provides a specific functionality that is likely necessary for the correct operation of the class it belongs to, it is unlikely to be deleted unless the entire class or its functionality is deprecated or refactored. Therefore, the method is more likely to survive."
survived,"    def Get() -> ""MoonrakerCredentialManager"":
        return MoonrakerCredentialManager._Instance
",moonraker_octoeverywhere/moonrakercredentialmanager.py,MoonrakerCredentialManager,1,1.1032560311263802e-09,"The method 'Get' is a simple getter for a singleton instance of 'MoonrakerCredentialManager'. Such methods are common in singleton patterns to provide a global point of access to the instance. This pattern is widely used and unlikely to be deleted unless the entire design pattern is refactored. Therefore, the method is likely to survive."
survived,"    def _GetParentDirectory(self, path:str) -> str:
        return os.path.abspath(os.path.join(path, os.pardir))
",moonraker_octoeverywhere/moonrakercredentialmanager.py,MoonrakerCredentialManager,1,3.850741907939403e-09,"The method _GetParentDirectory is a utility function that simplifies the process of obtaining the parent directory of a given path. It uses standard library functions from the os module, which are reliable and widely used. The method is straightforward, has a clear purpose, and is likely to be useful in various contexts where directory navigation is required. Therefore, it is likely to be retained in the codebase."
survived,"            def load(self):
                pass
",tests/test_agent_aiga_entrypoint.py,TestAgentAIGAEntry.DummyEvolver,0,0.9999945777825671,"The method 'load' is defined but not implemented, as indicated by the 'pass' statement. This suggests that the method is a placeholder for future implementation. If the method is part of a class that is still under development or if it is intended to be overridden in a subclass, it might survive. However, if it remains unimplemented and unused, it is likely to be deleted in future code clean-ups. Without additional context, it's more likely to be deleted if it remains as is."
survived,"    def test_sampling(self) -> None:
        if LEDGER.exists():
            LEDGER.unlink()
        result = subprocess.run([sys.executable, STUB, '-n', '2', '--seed', '1'], capture_output=True, text=True)
        self.assertEqual(result.returncode, 0)
        self.assertTrue(LEDGER.exists())
        logged = json.loads(LEDGER.read_text())
        self.assertIsInstance(logged, list)
        self.assertEqual(len(logged), 2)
",tests/test_alpha_discovery_stub.py,TestAlphaDiscoveryStub,1,8.592166611791576e-10,"The method 'test_sampling' is a unit test that verifies the functionality of a sampling process. It checks if a ledger file is created and contains the expected number of entries after running a subprocess. This is a typical test case that ensures the correct behavior of a feature, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained in the codebase."
survived,"def main() -> None:
    runtime = AgentRuntime(api_key=None)
    runtime.register(MetaSearchAgent())
    print(""Registered MetaSearchAgent with runtime"")
    runtime.run()
",alpha_factory_v1/demos/meta_agentic_agi/openai_agents_bridge.py,,1,1.955568070542584e-08,"The method 'main' is a simple entry point for setting up and running an agent runtime. It initializes an AgentRuntime object, registers a MetaSearchAgent, and then runs the runtime. This is a typical pattern for initializing and executing a process in many applications. There is no indication that this method is obsolete or redundant, and it seems to serve a clear purpose in the context of the application. Therefore, it is likely to be retained in the codebase."
survived,"def main() -> None:
    runtime = AgentRuntime(api_key=None)
    runtime.register(BusinessAgent())
    print(""Registered BusinessAgent with runtime"")
    runtime.run()
",alpha_factory_v1/demos/alpha_agi_business_v1/openai_agents_bridge.py,,1,1.1032560311263802e-09,"The method 'main' is a typical entry point for a Python script, and it is used to initialize and run an instance of 'AgentRuntime' with a 'BusinessAgent'. This setup suggests that the method is crucial for the operation of the script, as it handles the registration and execution of the agent. Unless there is a significant change in the design or purpose of the script, such as a shift to a different architecture or framework, the 'main' method is likely to be retained. Therefore, it is predicted to survive."
survived,"async def trigger_discovery() -> str:
    resp = requests.post(f""{HOST}/agent/alpha_discovery/trigger"", timeout=5)
    resp.raise_for_status()
    return ""alpha_discovery queued""
",alpha_factory_v1/demos/alpha_agi_business_v1/openai_agents_bridge.py,,0,0.9999997300421382,"The method 'trigger_discovery' is likely to be deleted because it uses the 'requests' library in an asynchronous function without using an asynchronous HTTP client like 'aiohttp'. This can lead to blocking behavior in an asynchronous context, which is generally considered a bad practice. To properly handle asynchronous HTTP requests, the method should be refactored to use an appropriate library that supports async operations."
survived,"    def test_sampling(self) -> None:
        with tempfile.TemporaryDirectory() as tmp:
            ledger = Path(tmp) / 'log.json'
            result = subprocess.run(
                [sys.executable, STUB, '-n', '2', '--seed', '1', '--ledger', str(ledger)],
                capture_output=True,
                text=True,
            )
            self.assertEqual(result.returncode, 0, result.stderr)
            self.assertTrue(ledger.exists())
            logged = json.loads(ledger.read_text())
            self.assertIsInstance(logged, list)
            self.assertEqual(len(logged), 2)
",tests/test_cross_alpha_discovery.py,TestCrossAlphaDiscoveryStub,1,1.9171715133907573e-10,"The method 'test_sampling' is a unit test designed to verify the functionality of a specific feature, likely related to a sampling process. It uses a temporary directory to store a log file, runs a subprocess, and checks the results. Unit tests are crucial for ensuring code reliability and are typically retained unless the feature they test is removed or significantly altered. Since the method is actively testing a feature and there is no indication that the feature is deprecated or the test is redundant, it is likely to survive."
survived,"    def test_aiga_bridge_compiles(self):
        """"""Ensure the AI-GA demo bridge compiles.""""""
        path = Path('alpha_factory_v1/demos/aiga_meta_evolution/openai_agents_bridge.py')
        py_compile.compile(path, doraise=True)
",tests/test_openai_bridge.py,TestOpenAIBridge,1,1.725782769012759e-08,"The method 'test_aiga_bridge_compiles' is a unit test that checks if a specific Python script compiles without syntax errors. This is a basic but important test to ensure that the code is syntactically correct before running more complex tests or deploying the code. Such tests are generally useful in a development environment to catch errors early in the development process. Therefore, it is likely to be retained as part of the test suite."
survived,"    def test_cli_runs_one_generation(self) -> None:
        result = subprocess.run(
            [sys.executable, '-m', 'alpha_factory_v1.demos.meta_agentic_agi_v2.meta_agentic_agi_demo_v2', '--gens', '1', '--provider', 'mock:echo'],
            capture_output=True,
            text=True,
        )
        self.assertEqual(result.returncode, 0)
        self.assertIn('Gen 00', result.stdout)
",tests/test_meta_agentic_cli_v2.py,TestMetaAgenticCLIV2,1,4.944450477491054e-09,"The method 'test_cli_runs_one_generation' is a unit test designed to verify that a command-line interface (CLI) runs correctly for one generation. It uses subprocess to execute a command and checks the output and return code. This is a typical pattern for testing CLI tools, ensuring they behave as expected. Such tests are crucial for maintaining software quality, especially in environments where CLI tools are used extensively. Therefore, this method is likely to be retained as it serves an important role in the testing suite."
survived,"def main(argv: list[str] | None = None) -> None:
    """"""Launch the MuZero dashboard with optional CLI overrides.""""""

    parser = argparse.ArgumentParser(description=""Run MuZero planning demo"")
    parser.add_argument(
        ""--env"",
        default=os.getenv(""MUZERO_ENV_ID"", ""CartPole-v1""),
        help=""Gymnasium environment ID"",
    )
    parser.add_argument(
        ""--episodes"",
        type=int,
        default=int(os.getenv(""MUZERO_EPISODES"", 3)),
        help=""Number of episodes to run"",
    )
    parser.add_argument(
        ""--port"",
        type=int,
        default=int(os.getenv(""HOST_PORT"", 7861)),
        help=""Dashboard port"",
    )
    args = parser.parse_args(argv)

    os.environ[""MUZERO_ENV_ID""] = args.env
    os.environ[""MUZERO_EPISODES""] = str(args.episodes)
    os.environ[""HOST_PORT""] = str(args.port)

    launch_dashboard()
",alpha_factory_v1/demos/muzero_planning/__main__.py,,1,5.60279640614594e-09,"The method 'main' is a typical entry point for a command-line application, which is a common pattern in Python scripts. It uses argparse to handle command-line arguments, which is a standard and widely used library for this purpose. The method sets environment variables based on the parsed arguments and then calls a function 'launch_dashboard', which is presumably responsible for starting the application. This method is well-structured, follows best practices, and is likely essential for the functionality of the application. Therefore, it is unlikely to be deleted."
survived,"def test_experience_launcher_gpu(tmp_path: Path, monkeypatch: pytest.MonkeyPatch) -> None:
    script = Path(""alpha_factory_v1/demos/era_of_experience/run_experience_demo.sh"")
    config = script.parent / ""config.env""
    docker_log = tmp_path / ""docker.log""
    curl_log = tmp_path / ""curl.log""
    bin_dir = tmp_path / ""bin""
    bin_dir.mkdir()

    docker_stub = bin_dir / ""docker""
    docker_stub.write_text(
        ""#!/usr/bin/env bash\n""
        'echo ""$@"" >> ""$DOCKER_LOG""\n'
        'if [ ""$1"" = ""info"" ]; then echo ""{""nvidia"":{}}""; fi\n'
        'if [ ""$1"" = ""version"" ]; then echo ""24.0.0""; fi\n'
        ""exit 0\n""
    )
    docker_stub.chmod(0o755)

    curl_stub = bin_dir / ""curl""
    curl_stub.write_text(
        ""#!/usr/bin/env bash\n""
        'echo ""$@"" >> ""$CURL_LOG""\n'
        'out=""""\n'
        ""for ((i=1;i<=$#;i++)); do\n""
        '  if [ ""${!i}"" = ""-o"" ]; then\n'
        ""    j=$((i+1))\n""
        ""    out=${!j}\n""
        ""  fi\n""
        ""done\n""
        'if [ -n ""$out"" ]; then echo sample > ""$out""; fi\n'
        'echo ""OK""\n'
    )
    curl_stub.chmod(0o755)

    env = os.environ.copy()
    env.update(
        {
            ""PATH"": f""{bin_dir}:{env['PATH']}"",
            ""SKIP_ENV_CHECK"": ""1"",
            ""SAMPLE_DATA_DIR"": str(tmp_path / ""samples""),
            ""DOCKER_LOG"": str(docker_log),
            ""CURL_LOG"": str(curl_log),
            ""OPENAI_API_KEY"": ""dummy"",
        }
    )

    if config.exists():
        config.unlink()
    try:
        result = subprocess.run([f""./{script.name}""], cwd=script.parent, env=env, capture_output=True, text=True)
        created = config.exists()
    finally:
        if config.exists():
            config.unlink()

    assert result.returncode == 0, result.stderr
    assert docker_log.exists()
    log = docker_log.read_text()
    assert ""--profile gpu"" in log
    assert created",tests/test_experience_launcher.py,,1,1.3440409770490404e-08,"The method 'test_experience_launcher_gpu' is a test function that sets up a testing environment using temporary paths and monkeypatching to simulate the behavior of external commands like 'docker' and 'curl'. It checks if a script runs successfully with a GPU profile and verifies the creation of a configuration file. This kind of test is crucial for ensuring that the script behaves correctly in a controlled environment, especially when dealing with external dependencies. Therefore, it is likely to be maintained as part of the test suite to ensure the reliability of the software."
survived,"def makeAdder(n):
    def adder(x):
        return x + n
    return adder
",tests/machine/x/python/closure.py,,1,2.0611536181902033e-09,"The method makeAdder is a higher-order function that returns a closure. It is a useful and common pattern in functional programming, allowing the creation of customized functions on the fly. This method is likely to be used in various scenarios where dynamic function creation is needed, such as in callbacks or when applying transformations to data. Its utility and simplicity make it a candidate for survival."
survived,"def sum_tree(t: Tree) -> int:
    if isinstance(t, Leaf):
        return 0
    elif isinstance(t, Node):
        return sum_tree(t.left) + t.value + sum_tree(t.right)
    else:
        raise TypeError(""Unknown node"")
",tests/machine/x/python/tree_sum.py,,1,1.955568070542584e-08,"The method `sum_tree` is a recursive function designed to calculate the sum of all values in a binary tree structure. It checks if the current node is a `Leaf` or a `Node`, and processes accordingly. The function is well-structured for its purpose, handling both base and recursive cases effectively. The only potential issue is the handling of unknown node types, which is managed by raising a `TypeError`. This is a reasonable approach to ensure the function only processes expected tree structures. Given its clear utility in tree data structure operations and proper error handling, it is likely to be retained."
survived,"def twoSum(nums, target):
    n = len(nums)
    for i in range(n):
        for j in range(i + 1, n):
            if nums[i] + nums[j] == target:
                return [i, j]
    return [-1, -1]
",tests/machine/x/python/two-sum.py,,1,1.3709568184771895e-06,"The method 'twoSum' is a straightforward implementation of a common algorithmic problem: finding two numbers in a list that add up to a specific target. This problem is frequently encountered in coding interviews and competitive programming. The method uses a simple nested loop approach to check each pair of numbers, which is easy to understand and works correctly for small input sizes. However, it has a time complexity of O(n^2), which is not optimal for large datasets. Despite this, the method is likely to survive because it correctly solves the problem and serves as a basic example of the two-sum problem. More efficient solutions exist, but this implementation is still valid and useful for educational purposes."
survived,"    async def run() -> None:
        await bus.start()
        try:
            creds = grpc.ssl_channel_credentials(root_certificates=ca)
            async with grpc.aio.secure_channel(f""localhost:{port}"", creds) as ch:
                stub = ch.unary_unary(""/bus.Bus/Send"")
                payload = {
                    ""sender"": ""a"",
                    ""recipient"": ""b"",
                    ""payload"": {},
                    ""ts"": 0.0,
                    ""token"": ""bad"",
                }
                with pytest.raises(grpc.aio.AioRpcError):
                    await stub(json.dumps(payload).encode())
        finally:
            await bus.stop()
",tests/test_agents.py,,1,4.599055376537186e-10,"The method is an asynchronous function that tests a gRPC communication by sending a payload and expecting an error. It uses modern Python features like async/await and context managers, which are widely adopted and recommended for writing non-blocking code. The use of pytest for exception handling indicates it's part of a test suite, which is essential for maintaining code quality. These factors suggest that the method is well-structured and follows current best practices, making it likely to survive."
survived,"    def __init__(self, alpha, make_plot=False):
        self.alpha = alpha
        self.make_plot = make_plot
",examples/synthetic_data.py,HldaDataGenerator,1,1.522997951276035e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. It initializes the instance variables 'alpha' and 'make_plot', which are likely used elsewhere in the class. Constructors are essential for setting up the initial state of an object, and there is no indication that this functionality is redundant or unnecessary. Therefore, it is unlikely to be deleted."
survived,"    def generate_document(
        self,
        word_dists,
        n_topics,
        vocab_size,
        document_length,
    ):

        # sample topic proportions with uniform dirichlet parameter alpha
        # of length n_topics
        theta = np.random.mtrand.dirichlet([self.alpha] * n_topics)

        # for every word in the vocab for this document
        d = np.zeros(vocab_size)
        for n in range(document_length):

            # sample a new topic index
            k = np.random.multinomial(1, theta).argmax()

            # sample a new word from the word distribution of topic k
            w = np.random.multinomial(1, word_dists[k, :]).argmax()

            # increase the occurrence of word w in document d
            d[w] += 1

        return d
",examples/synthetic_data.py,HldaDataGenerator,1,1.725782769012759e-08,"The method 'generate_document' is a core part of a topic modeling process, which is a common task in natural language processing and machine learning. It simulates the generation of a document based on topic distributions and word distributions, which is essential for understanding and implementing models like Latent Dirichlet Allocation (LDA). The method is well-structured, uses standard libraries like numpy, and performs a clear and specific function that is likely to be useful in various applications involving text data. Therefore, it is unlikely to be deleted as it serves a fundamental purpose in generating synthetic documents for testing or training models."
survived,"def load_acm_certificates(
    neo4j_session: neo4j.Session,
    data: List[Dict],
    region: str,
    current_aws_account_id: str,
    update_tag: int,
) -> None:
    logger.info(f""Loading {len(data)} ACM certificates for region {region} into graph."")
    load(
        neo4j_session,
        ACMCertificateSchema(),
        data,
        lastupdated=update_tag,
        Region=region,
        AWS_ID=current_aws_account_id,
    )
",cartography/intel/aws/acm.py,,1,6.69158608681505e-10,"The method 'load_acm_certificates' is a utility function that loads ACM certificate data into a Neo4j graph database. It is a straightforward function that logs the number of certificates being loaded and then calls another function 'load' with the necessary parameters. This method is likely part of a larger system that deals with AWS data and Neo4j, and it serves a specific purpose in that context. Unless there is a significant change in the system's architecture or a shift away from using Neo4j or handling ACM certificates, this method is likely to survive. It is functional, serves a clear purpose, and there is no indication of redundancy or obsolescence."
survived,"def transform_acm_certificates(certificates: List[Dict], region: str) -> List[Dict]:
    transformed: List[Dict] = []
    for cert in certificates:
        item: Dict[str, Any] = {
            ""Arn"": cert[""CertificateArn""],
            ""DomainName"": cert.get(""DomainName""),
            ""Type"": cert.get(""Type""),
            ""Status"": cert.get(""Status""),
            ""KeyAlgorithm"": cert.get(""KeyAlgorithm""),
            ""SignatureAlgorithm"": cert.get(""SignatureAlgorithm""),
            ""NotBefore"": (
                dict_date_to_epoch({""d"": dt_parser.parse(cert[""NotBefore""])}, ""d"")
                if cert.get(""NotBefore"")
                else None
            ),
            ""NotAfter"": (
                dict_date_to_epoch({""d"": dt_parser.parse(cert[""NotAfter""])}, ""d"")
                if cert.get(""NotAfter"")
                else None
            ),
            ""InUseBy"": cert.get(""InUseBy"", []),
            ""Region"": region,
        }
        # Extract ELBV2 Listener ARNs for relationship creation
        listener_arns = [a for a in item[""InUseBy""] if "":listener/"" in a]
        if listener_arns:
            item[""ELBV2ListenerArns""] = listener_arns
        transformed.append(item)
    return transformed
",cartography/intel/aws/acm.py,,1,3.3982678079468468e-09,"The method 'transform_acm_certificates' is a utility function that processes a list of ACM certificates, transforming them into a specific format with additional computed fields. It is well-structured, uses type hints, and includes logic to handle optional fields and extract specific data (like ELBV2 Listener ARNs). Such utility functions are common in data processing tasks, especially when dealing with AWS resources, and are likely to be reused in various contexts. Therefore, it is unlikely to be deleted unless the entire system it supports is deprecated or significantly refactored."
survived,"    def allocate_for_seqs(
        self,
        updated_seqs: ht.i32[NamedArray, "" seq""],  # type: ignore[name-defined]
        new_counts: ht.i32[NamedArray, "" seq""],  # type: ignore[name-defined]
        tokens: ht.i32[NamedArray, ""position""],  # type: ignore[name-defined]
    ) -> tuple[""PageTable"", ""PageBatchInfo""]:
        """"""Allocate pages for new sequences and update ``seq_lens``.""""""

        page_indices = self.page_indices
        page_owners = self.page_owners
        seq_lens = self.seq_lens

        padded_updated_seqs = hax.where(updated_seqs < 0, self.max_seqs, updated_seqs)
        current_lens = hax.where(seq_lens < 0, 0, seq_lens)
        new_lens_tmp = current_lens.at[""seq"", padded_updated_seqs].add(new_counts, mode=""drop"")
        new_lens = hax.where(seq_lens < 0, hax.where(new_lens_tmp > 0, new_lens_tmp, -1), new_lens_tmp)

        new_num_pages_needed = (new_lens + self.page_size - 1) // self.page_size
        old_num_pages_needed = (seq_lens + self.page_size - 1) // self.page_size

        def _alloc_pages_for_seq(seq_id, carry):
            page_indices, page_owners = carry
            num_needed = new_num_pages_needed[""seq"", seq_id].scalar()
            old_needed = old_num_pages_needed[""seq"", seq_id].scalar()

            def body(page_idx, state):
                page_indices, page_owners = state
                free_page_idx = hax.argmin(page_owners, ""page"")
                page_owners = page_owners.at[""page"", free_page_idx].set(seq_id)
                page_indices = page_indices.at[""seq"", seq_id, ""page"", page_idx].set(free_page_idx)
                return page_indices, page_owners

            new_page_indices, new_page_owners = jax.lax.fori_loop(
                old_needed, num_needed, body, (page_indices, page_owners)
            )
            return new_page_indices, new_page_owners

        page_indices, page_owners = jax.lax.fori_loop(
            0, self.max_seqs, _alloc_pages_for_seq, (page_indices, page_owners)
        )

        new_table = dataclasses.replace(
            self,
            page_indices=page_indices,
            page_owners=page_owners,
            seq_lens=new_lens,
        )

        batch_info = self._slice_batch_info(updated_seqs, self.seq_lens, new_table, new_counts, tokens)

        return new_table, batch_info
",src/levanter/layers/page_table.py,PageTable,1,3.2241866333029355e-08,"The method 'allocate_for_seqs' is a core part of a memory management or resource allocation system, likely within a larger framework or application. It handles the allocation of pages for sequences, updates sequence lengths, and manages page indices and owners. This functionality is essential for systems that require dynamic memory allocation and efficient resource management, such as databases, operating systems, or complex data processing applications. The method is well-structured, uses efficient operations like loops and conditionals, and integrates with other parts of the system (e.g., '_slice_batch_info'). Given its importance and integration, it is unlikely to be deleted unless the entire system undergoes a significant redesign or is deprecated."
survived,"        def _alloc_pages_for_seq(seq_id, carry):
            page_indices, page_owners = carry
            num_needed = new_num_pages_needed[""seq"", seq_id].scalar()
            old_needed = old_num_pages_needed[""seq"", seq_id].scalar()

            def body(page_idx, state):
                page_indices, page_owners = state
                free_page_idx = hax.argmin(page_owners, ""page"")
                page_owners = page_owners.at[""page"", free_page_idx].set(seq_id)
                page_indices = page_indices.at[""seq"", seq_id, ""page"", page_idx].set(free_page_idx)
                return page_indices, page_owners

            new_page_indices, new_page_owners = jax.lax.fori_loop(
                old_needed, num_needed, body, (page_indices, page_owners)
            )
            return new_page_indices, new_page_owners
",src/levanter/layers/page_table.py,PageTable,1,1.725782769012759e-08,"The method '_alloc_pages_for_seq' is a utility function that allocates pages for a sequence based on the number of pages needed. It uses JAX's 'lax.fori_loop' to efficiently iterate and update page indices and owners. The function is well-structured, uses efficient JAX operations, and is likely part of a larger system for managing resources or memory. Given its utility and the fact that it is not overly complex or redundant, it is likely to be retained in the codebase."
survived,"    def assign_seq_id_to_seq(self) -> tuple[""PageTable"", int]:
        seq_id = hax.argmin(self.seq_lens, ""seq"").scalar()
        new_seq_lens = self.seq_lens.at[""seq"", seq_id].set(0)
        return dataclasses.replace(self, seq_lens=new_seq_lens), seq_id
",src/levanter/layers/page_table.py,PageTable,1,3.3982678079468468e-09,"The method 'assign_seq_id_to_seq' is a utility function that assigns a sequence ID to a sequence by finding the minimum sequence length and updating the sequence lengths. This type of functionality is often essential in managing sequences or tasks in a system, especially when dealing with dynamic data structures. The method is likely to be used in scenarios where sequences need to be managed efficiently, and the use of dataclasses and tuple return type suggests a modern and efficient design. Therefore, it is likely to be retained in the codebase."
survived,"    async def input_guardrail(prompt: str):
        order.append(f""in:{prompt}"")
",tests/test_guardrail_router.py,,1,3.653482080241728e-08,"The method 'input_guardrail' is a simple asynchronous function that appends a formatted string to a list called 'order'. It is likely part of a larger system where input prompts are being tracked or logged. The method itself is straightforward and does not contain any obvious issues or redundancies that would necessitate its deletion. Additionally, the use of asynchronous functions is common in modern programming to handle I/O operations efficiently, suggesting that this method is designed with performance in mind. Therefore, it is likely to be retained in the codebase."
survived,"    async def run(self, *args: Any, **kwargs: Any) -> Dict[str, Any]:
        return {""status"": ""error"", ""error"": ""agents SDK unavailable""}
",src/meta_agent/agents/guardrail_designer_agent.py,AgentBase,0,0.9999998362622821,"The method is likely to be deleted because it returns a static error message indicating that a critical component ('agents SDK') is unavailable. This suggests that the method is not functional or useful in its current state, as it does not perform any meaningful operation or provide a successful outcome. Unless the underlying issue with the 'agents SDK' is resolved, maintaining this method in the codebase serves little purpose."
survived,"    def __init__(self):
        self.prompts: list[str] = []
",tests/test_guardrail_router.py,MockAdapter,1,2.8453347280241004e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting up initial states. The use of type hinting with 'list[str]' is a modern Python practice that improves code readability and maintainability. There is no indication that this constructor is redundant or unnecessary, so it is likely to be retained."
survived,"async def test_router_selects_model():
    a1 = MockAdapter()
    a2 = MockAdapter()
    router = GuardrailModelRouter({""a"": a1, ""b"": a2}, default_model=""a"")

    res = await router.invoke(""hi"", model=""b"")

    assert res == ""hi:ok""
    assert a2.prompts == [""hi""]
    assert not a1.prompts
",tests/test_guardrail_router.py,,1,5.3157849718487075e-08,"The method 'test_router_selects_model' is a unit test for the 'GuardrailModelRouter' class, specifically testing the model selection functionality. Unit tests are crucial for ensuring code reliability and are typically retained in the codebase to verify that changes do not break existing functionality. The test checks that the router correctly selects the specified model ('b') and that the expected behavior occurs (the response is 'hi:ok', and the prompts are correctly assigned to 'a2' and not 'a1'). This functionality is important for the correct operation of the router, and the test ensures that it works as intended. Therefore, it is likely to be retained."
survived,"    def f(t):
        return b.sum(b.mul(b.stop(t), t))
",tests/kgtests/autograd/helpers.py,,1,1.275190675769241e-07,"The method 'f' is a simple function that takes an input 't' and returns the result of a series of operations using methods 'sum', 'mul', and 'stop' from an object 'b'. Without additional context, such as the definition of 'b' or the purpose of these operations, it's difficult to determine the utility or correctness of this function. However, the function itself is syntactically correct and could be useful if 'b' is a well-defined object with these methods. Therefore, without evidence of redundancy or obsolescence, the method is likely to survive."
survived,"    def _check_vector_elemwise_grad(self, name: str):
        """"""Verify gradient of ∑(x+1)(x+2) = 2x+3 via the chain rule.""""""
        try:
            backend.set_backend(name)
        except ImportError:
            raise unittest.SkipTest(f""{name} backend not available"")
        b = backend.current()

        def f(x):
            return b.sum(b.mul(b.add(x, 1), b.add(x, 2)))

        g = b.grad(f)
        x = b.array([0.0, 1.0, 2.0], requires_grad=True)
        grad = to_numpy(g(x))
        expected = 2 * np.array([0.0, 1.0, 2.0]) + 3
        np.testing.assert_allclose(np.array(grad), expected)
",tests/test_autograd.py,TestAutograd,1,1.725782769012759e-08,"The method '_check_vector_elemwise_grad' is a unit test function designed to verify the gradient computation of a specific mathematical function using a backend library. It is a useful utility for ensuring the correctness of gradient calculations, which is crucial in many scientific and machine learning applications. The method is well-structured, includes error handling, and uses assertions to validate the results. These characteristics make it a valuable part of a testing suite, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained in the codebase."
survived,"    def test_vector_elemwise_grad_numpy(self):
        self._check_vector_elemwise_grad(""numpy"")
",tests/test_autograd.py,TestAutograd,1,5.3157849718487075e-08,"The method `test_vector_elemwise_grad_numpy` is a test function, likely part of a test suite for a larger codebase. Test functions are generally not deleted unless they are redundant, testing deprecated features, or replaced by more comprehensive tests. Since this function is specifically testing the element-wise gradient computation using numpy, it is likely still relevant and useful for ensuring the correctness of this functionality. Therefore, it is more likely to be maintained rather than deleted."
survived,"def test_sri_attributes() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri()
    with sync_playwright() as p:
        browser = p.chromium.launch()
        page = browser.new_page()
        page.goto(url)
        page.wait_for_selector(""#controls"")
        app_integrity = page.get_attribute(""script[src='app.js']"", ""integrity"")
        style_integrity = page.get_attribute(""link[href='style.css']"", ""integrity"")
        assert app_integrity and app_integrity.startswith(""sha384-"")
        assert style_integrity and style_integrity.startswith(""sha384-"")
        browser.close()",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_integrity.py,,1,1.8189616842444243e-09,"The method 'test_sri_attributes' is a test function that checks the Subresource Integrity (SRI) attributes of a web page's resources. This is a useful test to ensure that the resources have not been tampered with and are loaded securely. Given the increasing importance of security in web applications, such tests are likely to be retained to maintain the integrity and security of the application. Therefore, the method is likely to survive."
survived,"def sha384(path: Path) -> str:
    digest = hashlib.sha384(path.read_bytes()).digest()
    return ""sha384-"" + base64.b64encode(digest).decode()
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/manual_build.py,,1,9.736200303530205e-10,"The method 'sha384' is a utility function that computes the SHA-384 hash of a file's contents and returns it in a base64-encoded format. This is a common and useful operation in many applications, such as verifying file integrity or ensuring data consistency. The method is concise, uses standard libraries, and performs a clear, well-defined task. There is no indication that this method is redundant or obsolete, and it is likely to be useful in various contexts where file hashing is required. Therefore, it is likely to be retained."
survived,"    def __init__(self, *a, **k):
        pass
",tests/test_rate_lock.py,DummyOA,1,5.043472052266442e-07,"The method is a constructor (__init__) that takes any number of positional and keyword arguments but does nothing with them. This is often used as a placeholder or a base class constructor that doesn't need to initialize any attributes. While it might seem unnecessary, it can be useful in certain design patterns or when subclassing. Therefore, it is likely to survive as it serves a purpose in specific contexts."
survived,"    def test_jsonl_gz_load(dest_uri):
        """"""When the source URI is a gzipped JSONL file, the data should be ingested.""""""
        with (
            patch(target_fs) as target_fs_mock,
            patch(""ingestr.src.filesystem.glob_files"", wraps=glob_files_override),
        ):
            target_fs_mock.return_value = test_fs
            schema_rand_prefix = f""testschema_fs_{get_random_string(5)}""
            dest_table = f""{schema_rand_prefix}.fs_{get_random_string(5)}""
            result = invoke_ingest_command(
                f""{protocol}://bucket?{auth}"",
                ""/data.jsonl.gz"",
                dest_uri,
                dest_table,
            )
            assert result.exit_code == 0
            assert_rows(dest_uri, dest_table, 5)
",ingestr/main_test.py,,1,2.646573631904765e-09,"The method 'test_jsonl_gz_load' is a test function that verifies the functionality of loading a gzipped JSONL file into a destination URI. It uses mocking to simulate the file system and checks if the ingest command executes successfully and the expected number of rows are present. Test functions like this are crucial for ensuring code reliability and are typically retained unless the functionality they test is deprecated or replaced. Since the method is actively testing a specific feature, it is likely to survive."
survived,"def test_logistic_curve_parameters() -> None:
    """"""Custom ``k`` and ``x0`` should shift the curve.""""""
    base = forecast.logistic_curve(0.0)
    shifted = forecast.logistic_curve(0.5, x0=0.5)
    steep = forecast.logistic_curve(0.1, k=2.0)
    assert shifted == pytest.approx(base)
    assert steep > forecast.logistic_curve(0.1)
",tests/test_forecast.py,,1,4.363462233903899e-09,"The method `test_logistic_curve_parameters` is a unit test function that checks the behavior of the `logistic_curve` function with different parameters. It is important for ensuring that the `logistic_curve` function behaves as expected when parameters are varied. Unit tests are crucial for maintaining code quality and catching regressions, so this method is likely to be retained as part of the test suite."
survived,"    async def stop_merkle_task(self) -> None:  # pragma: no cover - test helper
        pass
",tests/test_agent_runner.py,_Ledger,1,1.6701415113938837e-05,"The method `stop_merkle_task` is marked with a comment indicating it is a test helper and is not covered by tests (`# pragma: no cover - test helper`). This suggests that the method is used for testing purposes or as a placeholder. Since it is an asynchronous method with no implementation (`pass`), it might be a stub for future development or testing. However, without further context on its usage or plans for future implementation, it is difficult to definitively say it will be deleted. It is common for such methods to remain in the codebase as placeholders or for future use, especially if they are part of a larger testing framework or suite. Therefore, it is more likely to survive unless there is a specific reason to remove it, such as refactoring or changes in the testing strategy."
survived,"    def scan_via(self, fn: Callable[..., tuple[CarryT, OutputT_co]]):
        """"""Return a function that scans over the sequence using ``fn``.

        ``fn`` should take a block and a carry and return ``(carry, output)``.
        Semantics match :func:`haliax.scan` over the block axis.
        """"""

        def do_scan(init: CarryT) -> tuple[CarryT, OutputT_co]:
            out = []
            carry = init
            for block in self.blocks:
                carry, extra = fn(block, carry)
                carry = tree_checkpoint_name(carry, self._carry_ckpt_name)
                extra = tree_checkpoint_name(extra, self._output_ckpt_name)
                out.append(extra)

            stacked_out = haliax.tree_util.tree_map(lambda *x: haliax.stack(self.Block, x), *out)
            return carry, stacked_out

        return do_scan
",src/haliax/nn/scan.py,BlockSeq,1,1.8189616842444243e-09,"The method 'scan_via' is a utility function that provides a way to scan over a sequence using a provided function 'fn'. It is well-documented, has a clear purpose, and is likely used in a broader context where scanning over sequences is necessary. The method is also flexible, allowing for different types of operations to be performed on the sequence by passing different functions. This kind of utility is common in functional programming and data processing tasks, making it a valuable part of a codebase. Therefore, it is likely to be retained."
survived,"    def fold_via(self, fn: Callable[..., CarryT]) -> Callable[[CarryT], CarryT]:
        ...
",src/haliax/nn/scan.py,BlockFoldable,1,3.3982678079468468e-09,"The method 'fold_via' is defined with a clear purpose, indicated by its name and the use of type hints. It appears to be a higher-order function that takes a callable 'fn' and returns another callable. This pattern is common in functional programming and can be useful in various contexts where operations need to be applied iteratively or recursively. The use of type hints suggests that the method is intended to be part of a well-structured codebase, likely making it a valuable utility function. Without additional context suggesting it is unused or redundant, it is reasonable to predict that this method will survive."
survived,"    def __init__(self, db_path: str | Path, window: int = 10) -> None:
        self.db = ArchiveDB(db_path)
        self.window = window
        self.history: deque[float] = deque(maxlen=window)
        self._dataset = self.db.get_state(""dataset"", self.MINI)
        self._log = logging.getLogger(__name__)
        self._log.info(""current dataset: %s"", self._dataset)
",src/eval/fitness.py,CurriculumSwitcher,1,1.8553915987649156e-07,"The method is a constructor (__init__) for a class, which is a fundamental part of object-oriented programming in Python. Constructors are essential for initializing new objects and setting up initial state, such as establishing database connections or setting default values for attributes. The presence of logging and database initialization indicates that this method is actively used for setting up important components of the class. Therefore, it is unlikely to be deleted as it serves a critical role in the class's functionality."
survived,"        def op(g):
            return g + 1
",tests/test_phase_order.py,TestPhaseOrder,1,7.194132978569833e-09,"The method 'op' is a simple utility function that increments a given number by 1. Such functions are often useful in various contexts, such as iterating over numbers or performing simple arithmetic operations. Its simplicity and potential utility in different scenarios suggest that it is likely to be retained in the codebase."
survived,"    async def __aenter__(self) -> ""A2ABus"":
        """"""Start the bus when entering an async context.""""""
        await self.start()
        return self
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/messaging.py,A2ABus,1,1.0467401685178159e-08,"The method `__aenter__` is part of the asynchronous context manager protocol in Python, which is used to define what should happen when entering an async context using the `async with` statement. This method is essential for setting up resources or starting processes that need to be managed asynchronously. Since it is a fundamental part of the async context management, it is unlikely to be deleted unless the entire context management functionality is being removed or refactored, which is not indicated here."
survived,"    def rebuild(self) -> None:
        """"""Rebuild the index from all registered templates.""""""
        self._index = []
        for entry in self.registry.list_templates():
            slug = entry[""slug""]
            for version_info in entry.get(""versions"", []):
                version = version_info[""version""]
                path = self.registry.templates_dir / version_info[""path""]
                metadata_path = path.parent / METADATA_FILE_NAME
                try:
                    content = path.read_text(encoding=""utf-8"")
                except OSError:  # pragma: no cover - file missing
                    continue
                checksum = sha256(content.encode(""utf-8"")).hexdigest()
                try:
                    with open(metadata_path, ""r"", encoding=""utf-8"") as f:
                        metadata = json.load(f)
                except (OSError, json.JSONDecodeError):
                    metadata = {}
                self._index.append(
                    {
                        ""slug"": slug,
                        ""version"": version,
                        ""path"": str(path.relative_to(self.registry.templates_dir)),
                        ""checksum"": checksum,
                        ""metadata"": metadata,
                        ""content"": content,
                    }
                )
        self.save()
",src/meta_agent/template_index.py,TemplateIndex,1,1.2501528648238603e-09,"The method 'rebuild' is likely to survive because it performs a crucial function of rebuilding an index from registered templates, which is essential for maintaining the integrity and accessibility of the data. It handles file reading, error management, and data processing, which are common and necessary operations in software dealing with file systems and data indexing. Additionally, the method is well-structured, with error handling for file operations and JSON parsing, making it robust and reliable."
survived,"def load_templates(path: str | Path) -> dict[str, Mapping[str, Any]]:
    """"""Return prompt templates loaded from ``path``.""""""
    raw = yaml.safe_load(Path(path).read_text(encoding=""utf-8""))
    if not isinstance(raw, Mapping):
        raise ValueError(""template file must map names to templates"")
    return {str(k): dict(v) for k, v in raw.items()}
",src/agents/prompt_sampler.py,,1,7.582560422162384e-10,"The method 'load_templates' is likely to survive because it performs a useful function of loading and validating YAML data from a file path, which is a common requirement in many applications. The method is well-defined, uses type hints for clarity, and includes error handling to ensure the data structure is as expected. These are good practices in software development, making the method robust and maintainable."
survived,"        async def my_resource(
            ctx: EnrichContext,
            name: str = EnrichParameter(description=""user name"", examples=[""bob""]),
        ) -> dict:
            return {}
",tests/test_enrichparameter.py,,1,0.00037998455641741793,"The method 'my_resource' is an asynchronous function that takes a context and a name parameter, returning an empty dictionary. It is likely a placeholder or a stub for future implementation. Since it is not currently performing any meaningful operation, it might be considered for deletion unless there is a plan to implement its functionality later. However, without further context on its intended use or any deprecation notices, it is more likely to survive as it could be part of a larger framework or system where it is expected to be implemented later."
survived,"    def run_generations(self, n: int = 5):
        for _ in range(n):
            scores = self._evaluate_population()
            self._last_scores = scores
            best_idx = int(np.argmax(scores))
            if scores[best_idx] > self._best_fitness:
                self._best_fitness = scores[best_idx]
                self.best_genome = self.population[best_idx]
            avg = float(np.mean(scores)); self.history.append((self.gen, avg))
            if _fitness_gauge: _fitness_gauge.set(avg)
            LOG.info(""gen=%d avg=%.3f best=%.2f"", self.gen, avg, self._best_fitness)
            if _A2A: _A2A.sendjson({""gen"": self.gen, ""avg"": avg, ""sha"": self.population_sha()})
            elite_idx = sorted(range(self.pop_size), key=lambda i: scores[i], reverse=True)[:self.elitism]
            new_pop = [self.population[i] for i in elite_idx]
            while len(new_pop) < self.pop_size:
                new_pop.append(self._select(scores).mutate())
            self.population = new_pop
            self.gen += 1
            self._save()
",alpha_factory_v1/demos/aiga_meta_evolution/meta_evolver.py,MetaEvolver,1,1.1861120010657661e-08,"The method 'run_generations' is a core part of a genetic algorithm implementation, which is a common and essential technique in optimization and machine learning tasks. It handles the main loop of evolving a population over several generations, evaluating fitness, selecting the best individuals, and creating new generations. This functionality is crucial for any system that relies on evolutionary algorithms, and thus, it is unlikely to be removed unless the entire system is being deprecated or replaced by a fundamentally different approach."
survived,"    def save(self) -> None:
        """"""Public wrapper for checkpoint persistence.""""""
        self._save()
",alpha_factory_v1/demos/aiga_meta_evolution/meta_evolver.py,MetaEvolver,1,3.850741907939403e-09,"The method 'save' is a public wrapper for a private method '_save', which suggests that it is part of a class that handles some form of data persistence or checkpointing. Public methods that serve as interfaces to private methods are generally important for maintaining encapsulation and providing a stable API for users of the class. This method is likely to be used by other parts of the code or by external users to trigger the save functionality without exposing the internal workings of '_save'. Therefore, it is unlikely to be deleted unless the entire functionality is being refactored or removed, which is not indicated here."
survived,"    def best_fitness(self) -> float:
        return self._best_fitness
",alpha_factory_v1/demos/aiga_meta_evolution/meta_evolver.py,MetaEvolver,1,6.69158608681505e-10,"The method 'best_fitness' is a simple getter method that returns the value of a private attribute '_best_fitness'. Such methods are typically retained in codebases because they provide a controlled way to access private data, which is a common practice in object-oriented programming to maintain encapsulation. Unless there is a significant refactor or change in design that makes this method redundant, it is likely to survive."
survived,"    def sha(self) -> str:
        return hashlib.sha256(self.to_json().encode()).hexdigest()[:12]
",alpha_factory_v1/demos/aiga_meta_evolution/meta_evolver.py,Genome,1,8.592166611791576e-10,"The method 'sha' is a utility function that generates a SHA-256 hash of the JSON representation of an object, truncated to 12 characters. This is a common practice for creating unique identifiers or checksums. Such methods are often useful in various applications for ensuring data integrity or creating short, unique keys. Therefore, it is likely to be retained in the codebase."
survived,"def check_python() -> bool:
    if sys.version_info < MIN_PY:
        banner(f""Python {MIN_PY[0]}.{MIN_PY[1]}+ required"", 'RED')
        return False
    banner(f""Python {sys.version.split()[0]} detected"", 'GREEN')
    return True
",alpha_factory_v1/scripts/preflight.py,,1,2.3355930333443423e-09,"The method 'check_python' is likely to survive because it performs a useful function: checking if the current Python version meets a minimum requirement. This is a common necessity in software development to ensure compatibility and prevent runtime errors. The method is straightforward, uses clear logic, and provides feedback to the user, which are all good practices in coding."
survived,"def test_cli_entrypoint() -> None:
    """"""Running the ``alpha-agi-business-3-v1`` script should output the ΔG message.""""""
    env = os.environ.copy()
    env[""OPENAI_API_KEY""] = ""dummy""
    result = subprocess.run(
        [""alpha-agi-business-3-v1"", ""--cycles"", ""1""],
        capture_output=True,
        text=True,
        env=env,
    )
    assert result.returncode == 0, result.stderr
    assert ""ΔG"" in (result.stdout + result.stderr)
",tests/test_alpha_agi_business_3_v1.py,,1,2.3355930333443423e-09,"The method `test_cli_entrypoint` is a unit test designed to verify the functionality of a command-line interface (CLI) script. It checks if the script runs successfully and outputs a specific message. This is a common practice in software development to ensure that code changes do not break existing functionality. The method is well-defined, uses environment variables securely, and checks for expected output, making it a valuable part of the test suite. Therefore, it is likely to be retained in the codebase."
survived,"def main() -> None:
    """"""Run the asynchronous ``_main`` function via ``asyncio.run``.""""""
    asyncio.run(_main())",alpha_factory_v1/demos/alpha_agi_business_3_v1/cli.py,,1,2.646573631904765e-09,"The method is a simple wrapper around an asynchronous function, using asyncio.run to execute it. This is a common pattern in Python for running asynchronous code in a synchronous context. The method is clear, concise, and serves a specific purpose, which is to initiate the asynchronous main function. There is no indication of redundancy or inefficiency that would warrant its deletion. Therefore, it is likely to be retained."
survived,"def test_jpeg(h, f):
    """"""Test for JPEG data with JFIF or Exif markers; and raw JPEG.""""""
    if h[6:10] in (b'JFIF', b'Exif'):
        return 'jpeg'
    elif h[:4] == b'\xff\xd8\xff\xdb':
        return 'jpeg'
",metaflow/_vendor/imghdr/__init__.py,,1,7.194132978569833e-09,"The method 'test_jpeg' is a simple utility function that checks for specific byte patterns in a header to determine if a file is a JPEG. This kind of function is useful in many applications where file type validation is necessary, such as image processing, uploading files, or media management systems. The function is straightforward, performs a specific task efficiently, and does not have any apparent issues or redundancies that would warrant its removal. Therefore, it is likely to be retained in the codebase."
survived,"def test_xbm(h, f):
    """"""Verify if the image is a X bitmap (X10 or X11).""""""
    if h.startswith(b'#define '):
        return 'xbm'
",metaflow/_vendor/imghdr/__init__.py,,1,9.237449576640118e-09,"The method 'test_xbm' is a simple utility function that checks if a given header 'h' starts with a specific byte sequence, indicating that the image is an X bitmap. This type of utility function is often useful in image processing or file format identification tasks. It is concise, serves a specific purpose, and does not have any apparent issues or redundancies that would warrant its deletion. Therefore, it is likely to be retained in the codebase."
survived,"def what(file, h=None):
    """"""Return the type of image contained in a file or byte stream.""""""
    f = None
    try:
        if h is None:
            if isinstance(file, (str, PathLike)):
                f = open(file, 'rb')
                h = f.read(32)
            else:
                location = file.tell()
                h = file.read(32)
                file.seek(location)
        for tf in tests:
            res = tf(h, f)
            if res:
                return res
    finally:
        if f: f.close()
    return None
",metaflow/_vendor/imghdr/__init__.py,,1,2.8453347280241004e-08,"The method 'what' is a utility function that determines the type of image contained in a file or byte stream. It is a useful function for image processing tasks, as it abstracts the complexity of identifying image types from raw data. The function is well-structured, handling both file paths and file-like objects, and includes error handling to ensure resources are properly managed. Such utility functions are commonly used in various applications that deal with image files, making it likely to be retained in the codebase."
survived,"def load_defaults():
    config = load_config()
    csv_path = """"
    if config.has_section(""gui""):
        csv_path = config.get(""gui"", ""default_csv"", fallback="""")
    return csv_path
",arr_gui.py,,1,5.60279640614594e-09,"The method 'load_defaults' is a simple utility function that loads a configuration and retrieves a default CSV path if it exists. It is a straightforward and useful function for applications that rely on configuration files to manage settings. Such utility functions are common in software projects to encapsulate configuration loading logic, making the codebase cleaner and more maintainable. There is no indication that this function is redundant or obsolete, and it serves a clear purpose in the context of configuration management."
survived,"def load_config():
    config = configparser.ConfigParser()
    config.read(CONFIG_PATH)
    return config
",arr_gui.py,,1,4.363462233903899e-09,"The method 'load_config' is a simple utility function that loads a configuration file using the 'configparser' module. This is a common and useful function in many applications that require configuration management. It is likely to be used frequently in the codebase to access configuration settings, making it a necessary part of the application. Therefore, it is unlikely to be deleted unless there is a significant change in how configurations are managed in the application."
survived,"    def __call__(self, code: str) -> str:
        suffix = ""# patched""
        if not code.endswith(""\n""):
            code += ""\n""
        return code + suffix + ""\n""",src/simulation/mats_ops.py,CodePatch,1,8.152020648014727e-09,"The method is a simple utility function that appends a specific suffix to a given string, ensuring it ends with a newline character. This kind of functionality is often useful in scenarios where code comments or annotations are needed, such as in code generation or modification tools. The method is straightforward, has a clear purpose, and is unlikely to be redundant or replaced by another utility. Therefore, it is likely to be retained in the codebase."
survived,"    def formula(person, period, parameters):
        employment_income = person(""employment_income"", period)
        self_employment_income = person(""self_employment_income"", period)
        earnings = employment_income + self_employment_income
        res = np.ones_like(earnings)
        mask = earnings > 0
        res[mask] = employment_income[mask] / earnings[mask]
        return res",policyengine_us/variables/input/income/emp_self_emp_ratio.py,emp_self_emp_ratio,1,3.850741907939403e-09,"The method 'formula' is a utility function that calculates the proportion of employment income relative to total earnings (employment income + self-employment income) for a given person over a specified period. This type of calculation is common in financial or economic analysis, and the method is straightforward, efficient, and uses numpy for vectorized operations, which is a best practice in Python for handling arrays. There is no indication that this method is redundant or poorly implemented, so it is likely to be useful in its context."
survived,"    def _run_main(self, wheel: Path) -> int:
        argv = [""verify_wheel_sig"", str(wheel)]
        with mock.patch.object(sys, ""argv"", argv):
            with self.assertRaises(SystemExit) as ctx:
                verify_wheel_sig.main()
            return ctx.exception.code  # type: ignore[no-any-return]
",tests/test_verify_wheel_sig.py,VerifyWheelSigTests,1,2.3355930333443423e-09,"The method '_run_main' is a private method (indicated by the underscore prefix) and is used for testing the 'verify_wheel_sig.main()' function by mocking command-line arguments and capturing the SystemExit exception. This is a common pattern in testing to ensure that the function behaves as expected when executed with specific arguments. Since it is a utility function for testing purposes, it is unlikely to be deleted unless the testing strategy changes or the function it tests is removed or significantly altered. Therefore, it is more likely to survive."
survived,"def react_ui():
    """"""Serve the minimal React-based interface.""""""
    csrf_token = generate_csrf_token()
    return render_template('react.html', csrf_token=csrf_token)
",routes.py,,1,4.363462233903899e-09,"The method 'react_ui' is a simple function that serves a React-based interface with CSRF protection. It is a minimal and straightforward implementation that is likely to be useful in web applications that require a React frontend. The use of CSRF tokens is a standard security practice, indicating that the function is designed with security in mind. There is no indication of redundancy or obsolescence in the code, suggesting that it will continue to be relevant and useful in its context."
survived,"def run(episodes: int = 5, *, target: int = 3) -> str:
    """"""Run a short search predicting the target sector index.""""""
    root_agents: List[int] = [0]
    env = NumberLineEnv(target=target)
    tree = Tree(Node(root_agents))
    for _ in range(episodes):
        node = tree.select()
        improved = meta_rewrite(node.agents)
        reward = evaluate(improved, env)
        child = Node(improved, reward=reward)
        tree.add_child(node, child)
        tree.backprop(child)
        idx = improved[0] % len(SECTORS)
        print(f""Episode {_+1}: candidate {SECTORS[idx]} → reward {reward:.3f}"")
    best = tree.best_leaf()
    sector = SECTORS[best.agents[0] % len(SECTORS)]
    score = best.reward / (best.visits or 1)
    summary = f""Best sector: {sector} score: {score:.3f}""
    print(summary)
    return summary
",alpha_factory_v1/demos/alpha_agi_insight_v0/insight_demo.py,,1,1.8553915987649156e-07,"The method 'run' is a well-defined function that appears to be part of a larger system involving a search algorithm, possibly for optimization or machine learning purposes. It includes a clear purpose, parameters, and a return value. The function is structured to perform a series of operations over a number of episodes, involving selection, evaluation, and backpropagation within a tree structure. It also provides informative print statements for each episode and a summary of the best result. Given its functionality and the fact that it is likely part of a larger, useful system, it is unlikely to be deleted unless the entire system is deprecated or significantly refactored."
survived,"def main(argv: List[str] | None = None) -> None:
    parser = argparse.ArgumentParser(description=""Run the α‑AGI Insight demo"")
    parser.add_argument(""--episodes"", type=int, default=5, help=""Search iterations"")
    parser.add_argument(""--target"", type=int, default=3, help=""Target sector index"")
    args = parser.parse_args(argv)
    run(args.episodes, target=args.target)
",alpha_factory_v1/demos/alpha_agi_insight_v0/insight_demo.py,,1,1.1032560311263802e-09,"The method 'main' is a standard entry point for Python scripts, especially those that use command-line arguments. It uses argparse to handle command-line inputs, which is a common and recommended practice in Python for scripts that require user input. The method is well-structured, with default values for arguments and a clear description of its purpose. There is no indication that this method is obsolete or redundant, and it serves a clear purpose in the context of running a demo. Therefore, it is likely to be retained in the codebase."
survived,"def parse_sectors(cfg_val: object | None, cli_val: str | None) -> List[str]:
    """"""Return a cleaned list of sector names.

    Parameters
    ----------
    cfg_val:
        Value loaded from ``default.yaml``. Can be a comma-separated string or
        a YAML array.
    cli_val:
        Optional value passed via ``--sectors``.
    """"""

    source = cli_val or cfg_val
    if isinstance(source, list):
        return [str(s).strip() for s in source if str(s).strip()]
    if isinstance(source, str):
        text = source.strip()
        file_candidate = Path(text)
        if file_candidate.exists():
            lines = file_candidate.read_text(encoding=""utf-8"").splitlines()
            return [line.strip() for line in lines if line.strip()]
        return [s.strip() for s in text.split(""\n"" if ""\n"" in text else "","") if s.strip()]
    return list(DEFAULT_SECTORS)
",alpha_factory_v1/demos/alpha_agi_insight_v0/insight_demo.py,,1,6.69158608681505e-10,"The method `parse_sectors` is a utility function that processes input from configuration files or command-line arguments to produce a cleaned list of sector names. This functionality is essential in many applications where configuration management and command-line interfaces are involved. The method is versatile, handling both string and list inputs, and even reading from files if necessary. Such utility functions are commonly used and are unlikely to be removed unless they are replaced by a more efficient or comprehensive solution. Therefore, the method is likely to survive."
survived,"def test_llm_comment_no_api_key(monkeypatch: pytest.MonkeyPatch) -> None:
    """"""Fallback to local LLM when ``OPENAI_API_KEY`` is empty.""""""
    mod = importlib.import_module(MODULE)

    class DummyAgent:
        def __init__(self, *_a: object, **_k: object) -> None:  # pragma: no cover - should not run
            raise AssertionError(""should not be instantiated"")

        async def __call__(self, prompt: str) -> str:  # pragma: no cover - should not run
            raise AssertionError(""should not be called"")

    monkeypatch.setattr(mod, ""OpenAIAgent"", DummyAgent)
    monkeypatch.setenv(""OPENAI_API_KEY"", """")
    monkeypatch.setattr(mod.local_llm, ""chat"", lambda _p: ""fallback"")

    result = asyncio.run(mod._llm_comment(0.1))

    assert result == ""fallback""
",tests/test_alpha_agi_business_3_v1.py,,1,6.023574641292144e-08,"The method is a test function that ensures the system falls back to a local LLM when the `OPENAI_API_KEY` is not set. This is a crucial test for systems that rely on external APIs but need to have a fallback mechanism for offline or API failure scenarios. Such tests are important for maintaining robustness and reliability in software systems, especially those that integrate with third-party services. Therefore, it is unlikely to be deleted as it serves an important purpose in ensuring the system's resilience."
survived,"        def fake_import(name, globals=None, locals=None, fromlist=(), level=0):
            if name == ""openai_agents"":
                raise ModuleNotFoundError(name)
            return orig_import(name, globals, locals, fromlist, level)
",tests/test_openai_bridge.py,TestOpenAIBridge,0,0.999999694097641,"The method 'fake_import' is a custom implementation of the import mechanism, specifically designed to raise a ModuleNotFoundError when attempting to import a module named 'openai_agents'. This is a very specific use case and not a general-purpose utility. Such methods are often used for testing or temporary workarounds and are not typically retained in production code unless they serve a critical, ongoing purpose. Given its narrow scope and the fact that it alters the standard import behavior, it is likely to be deleted once its specific purpose is fulfilled or if it causes issues with module imports."
survived,"  def deserialize(cls, data: dict):
    return cls(port=data[""port""])",pylabrobot/storage/cytomat/heraeus_cytomat_backend.py,HeraeusCytomatBackend,1,4.599055376537186e-10,"The method 'deserialize' is a common pattern used in object-oriented programming to convert a dictionary into an instance of a class. This is particularly useful for handling data serialization and deserialization, which are common tasks in many applications, especially those dealing with data transfer or storage. The method is simple, clear, and serves a specific purpose, making it unlikely to be deleted unless the class itself is being refactored or the method is replaced by a more comprehensive solution. Therefore, it is likely to survive."
survived,"  async def stop_shaking(self):
    print(""Stopping shaking"")",pylabrobot/storage/chatterbox.py,IncubatorChatterboxBackend,0,0.9525741246345829,"The method 'stop_shaking' is a simple asynchronous function that prints a message. It doesn't perform any complex operations or interact with other parts of a system, making it unlikely to be critical. However, its survival depends on its context within the application. If the application requires stopping a shaking mechanism, this method could be essential. Without additional context, it's difficult to determine its importance, but given its simplicity, it might be more prone to deletion if not used frequently or if the functionality is no longer needed."
survived,"  async def stop(self):
    print(""Stopping incubator backend"")
",pylabrobot/storage/chatterbox.py,IncubatorChatterboxBackend,1,4.944450477491054e-09,"The method 'stop' is a simple asynchronous function that prints a message indicating the stopping of an incubator backend. This method is likely part of a larger system where stopping the backend is a necessary operation. The method is straightforward and serves a clear purpose, which is to notify or log that the backend is stopping. Such methods are typically retained in codebases as they provide useful logging information and are part of the system's lifecycle management. Therefore, it is likely to be Survived."
survived,"  def get_num_free_sites(self) -> int:
    return sum(len(rack.get_free_sites()) for rack in self._racks)
",pylabrobot/storage/incubator.py,Incubator,1,1.9171715133907573e-10,"The method `get_num_free_sites` is a straightforward utility function that calculates the total number of free sites across all racks. It is likely to be a useful method in the context of managing resources or capacity in a system that involves racks and sites. The method is simple, efficient, and provides a clear purpose, which suggests it is likely to be retained in the codebase. There is no indication of redundancy or obsolescence, and it serves a clear functional need."
survived,"  async def stop_shaking(self):
    if self.model == CytomatType.C5C:
      raise NotImplementedError(""Shaking is not supported on this model"")
    return hex_to_binary(await self.send_command(""ll"", ""vd"", """"))
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend,1,4.6911638017642294e-08,"The method 'stop_shaking' is specific to a certain model type (CytomatType.C5C) and raises a NotImplementedError for this model, indicating that the functionality is not supported. However, for other models, it performs a command and returns a result. This suggests that the method is useful for models other than C5C, and thus, it is likely to be retained for those cases. The method is also asynchronous, which is a modern approach to handling I/O operations, further supporting its relevance."
survived,"  async def action_storage_to_wait(self, site: PlateHolder) -> OverviewRegisterState:
    """"""Retrieve from storage, move to wait position""""""
    return await self.send_action(""mv"", ""sw"", self._site_to_firmware_string(site))
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend,1,3.850741907939403e-09,"The method 'action_storage_to_wait' is an asynchronous function that performs a specific action of moving an item from storage to a wait position. It uses a helper method 'send_action' to perform the action, which suggests that it is part of a larger system or framework. The method is concise, has a clear purpose, and likely integrates with other parts of the system. There is no indication that it is obsolete or redundant, and it seems to fulfill a necessary role in the system's operation. Therefore, it is likely to be retained."
survived,"  def get_site_by_plate_name(self, plate_name: str) -> PlateHolder:
    for rack in self._racks:
      for site in rack.sites.values():
        if site.resource is not None and site.resource.name == plate_name:
          return site
    raise ResourceNotFoundError(f""Plate {plate_name} not found in incubator '{self.name}'"")
",pylabrobot/storage/incubator.py,Incubator,1,5.905303995456778e-10,"The method 'get_site_by_plate_name' is a utility function that searches through a collection of racks and their sites to find a specific site by the plate name. This is a common operation in systems that manage resources or inventory, such as laboratory equipment or storage systems. The method is well-defined, performs a specific task, and raises an appropriate exception if the plate is not found, which is good practice for error handling. There is no indication that this method is redundant or unnecessary, and it likely serves an important role in the system's functionality. Therefore, it is likely to be retained."
survived,"  async def fetch_plate_to_loading_tray(self, plate: Plate):
    print(f""Fetching plate {plate} to loading tray"")
",pylabrobot/storage/chatterbox.py,IncubatorChatterboxBackend,1,6.023574641292144e-08,"The method 'fetch_plate_to_loading_tray' is a simple asynchronous function that prints a message indicating that a plate is being fetched to a loading tray. It is likely part of a larger system where such operations are necessary, such as in a robotics or automation context. The method is straightforward and does not contain any obvious issues or redundancies that would necessitate its deletion. Additionally, the use of asynchronous programming suggests it is designed to handle operations that may involve waiting for I/O or other asynchronous tasks, which is a common requirement in modern software systems. Therefore, it is likely to be retained for its utility in the system."
survived,"  def _site_to_m_n(self, site: PlateHolder) -> Tuple[int, int]:
    rack = site.parent
    assert isinstance(rack, PlateCarrier), ""Site not in rack""
    assert self._racks is not None, ""Racks not set""
    rack_idx = self._racks.index(rack) + 1  # plr is 0-indexed, cytomat is 1-indexed
    site_idx = next(idx for idx, s in rack.sites.items() if s == site) + 1  # 1-indexed
    return rack_idx, site_idx
",pylabrobot/storage/cytomat/heraeus_cytomat_backend.py,HeraeusCytomatBackend,1,1.3440409770490404e-08,"The method '_site_to_m_n' is a utility function that converts a site object to a tuple of indices, which is likely used for mapping or referencing purposes in a larger system. It includes assertions to ensure the integrity of the input data, which is a good practice for maintaining robustness. The method is specific and seems to serve a clear purpose within its context, suggesting it is not redundant or obsolete. Therefore, it is likely to be retained in the codebase."
survived,"  async def action_wait_to_storage(self, site: PlateHolder) -> OverviewRegisterState:
    """"""Move from wait to storage, unload, return to wait""""""
    return await self.send_action(""mv"", ""ws"", self._site_to_firmware_string(site))
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend,1,1.3440409770490404e-08,"The method 'action_wait_to_storage' is an asynchronous function that performs a specific action of moving from 'wait' to 'storage', unloading, and then returning to 'wait'. It is likely part of a larger system that manages or controls hardware or processes, possibly in a laboratory or industrial setting. The method is concise, uses a clear naming convention, and appears to be well-integrated with the rest of the system (e.g., using 'send_action' and '_site_to_firmware_string'). There is no indication that this method is redundant, obsolete, or poorly implemented. Therefore, it is likely to be retained in the codebase."
survived,"      def separator_line(cross: str = ""+"", line: str = ""-"") -> str:
        return cross + cross.join(line * (width + 2) for width in col_widths) + cross
",pylabrobot/storage/incubator.py,Incubator,1,2.2159489282323004e-08,"The method 'separator_line' is a utility function that generates a string representing a separator line, which is often used in formatting tables or outputs. Such utility functions are generally useful and reusable in various contexts where formatted output is needed. The method is simple, has a clear purpose, and does not have any obvious issues or redundancies that would warrant its deletion. Therefore, it is likely to be retained in the codebase."
survived,"  async def send_command(self, command_type: str, command: str, params: str) -> str:
    async def _send_command(command_str) -> str:
      logging.debug(command_str.encode(self.serial_message_encoding))
      await self.io.write(command_str.encode(self.serial_message_encoding))
      resp = (await self.io.read(128)).decode(self.serial_message_encoding)
      if len(resp) == 0:
        raise RuntimeError(""Cytomat did not respond to command, is it turned on?"")
      key, *values = resp.split()
      value = "" "".join(values)

      if key == CytomatActionResponse.OK.value or key == command:
        # actions return an OK response, while checks return the command at the start of the response
        return value
      if key == CytomatActionResponse.ERROR.value:
        logger.error(""Command %s failed with: '%s'"", command_str, resp)
        if value == ""03"":
          error_register = await self.get_error_register()
          await self.reset_error_register()
          raise CytomatTelegramStructureError(f""Telegram structure error: {error_register}"")
        if int(value, base=16) in error_map:
          await self.reset_error_register()
          raise error_map[int(value, base=16)]
        await self.reset_error_register()
        raise Exception(f""Unknown cytomat error code in response: {resp}"")

      logging.error(""Command %s recieved an unknown response: '%s'"", command_str, resp)
      await self.reset_error_register()
      raise Exception(f""Unknown response from cytomat: {resp}"")

    # Cytomats sometimes return a busy or command not recognized error even when the overview
    # register says the machine is not busy, or if the command is known. We will retry a few times,
    # which costs 1s if there is a true error, but is necessary to avoid false negatives.
    command_str = self._assemble_command(command_type=command_type, command=command, params=params)
    n_retries = 10
    exc: Optional[BaseException] = None
    for _ in range(n_retries):
      try:
        return await _send_command(command_str)
      except (CytomatCommandUnknownError, CytomatBusyError) as e:
        exc = e
        await asyncio.sleep(0.1)
        continue
    assert exc is not None
    await self.reset_error_register()
    raise exc
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend,1,2.0611536181902033e-09,"The method 'send_command' is well-structured and handles various scenarios effectively, including retries for transient errors, logging, and error handling. It is likely a crucial part of a system that communicates with a Cytomat device, and its functionality is essential for ensuring reliable communication. The method's design, including retries and specific error handling, suggests it is a mature and necessary component of the codebase, making it unlikely to be deleted."
survived,"def test_template_validator_syntax_error() -> None:
    validator = TemplateValidator()
    result = validator.validate(""{% for x in %}"")
    assert not result.success
    assert any(""syntax error"" in e for e in result.errors)
",tests/test_template_validator.py,,1,1.0467401685178159e-08,"The method `test_template_validator_syntax_error` is a unit test designed to verify that the `TemplateValidator` correctly identifies a syntax error in a template string. Unit tests are crucial for ensuring code reliability and correctness, especially in validating error handling. This test checks for a specific error condition, which is an important aspect of robust software development. Therefore, it is likely to be retained as part of the test suite to ensure the validator's functionality remains intact."
survived,"    def _load_ratings(self) -> Dict[str, List[int]]:
        try:
            with open(self.ratings_path, ""r"", encoding=""utf-8"") as f:
                return json.load(f)
        except (OSError, json.JSONDecodeError):
            return {}
",src/meta_agent/template_sharing.py,TemplateSharingManager,1,1.955568070542584e-08,"The method _load_ratings is a utility function that attempts to load a JSON file containing ratings. It handles potential errors such as file access issues (OSError) and JSON decoding errors (json.JSONDecodeError) by returning an empty dictionary in such cases. This is a common pattern for robust file handling and error management, making the method useful and likely to be retained in the codebase. Additionally, the method is private (indicated by the underscore prefix), suggesting it is intended for internal use, which often means it serves a specific purpose within the class or module."
survived,"def test_strategy_agent_api_uses_oai_ctx(tmp_path: pathlib.Path) -> None:
    settings = config.Settings(openai_api_key=""k"")
    settings.offline = False
    settings.ledger_path = str(tmp_path / ""led.db"")
    bus = messaging.A2ABus(settings)
    ledger = Ledger(settings.ledger_path)
    agent = strategy_agent.StrategyAgent(bus, ledger)

    class Ctx:
        async def run(self, prompt: str) -> str:  # pragma: no cover - async stub
            return ""done""

    agent.oai_ctx = Ctx()
    env = messaging.Envelope(""a"", ""b"", {""research"": 1}, 0.0)

    async def _run() -> None:
        with mock.patch.object(agent.oai_ctx, ""run"", wraps=agent.oai_ctx.run) as m:
            await agent.handle(env)
            assert m.called

    asyncio.run(_run())",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_agents.py,,1,4.944450477491054e-09,"The method 'test_strategy_agent_api_uses_oai_ctx' is a test function that verifies the integration of a strategy agent with an OpenAI context. It uses mocking to ensure that the 'run' method of the 'oai_ctx' is called when handling an envelope. This is a typical pattern in testing to ensure that certain interactions occur, and it is crucial for maintaining the integrity of the system's behavior. Since testing is an essential part of software development, especially for ensuring the reliability of integrations, this method is likely to be retained."
survived,"def chat(prompt: str) -> str:
    """"""Return a completion using the local model or a simple echo.""""""
    if _CALL is None:
        _load_model()
    assert _CALL is not None
    try:
        return _CALL(prompt)
    except Exception:  # pragma: no cover - runtime error
        return f""[offline] {prompt}""",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/local_llm.py,,1,7.582560422162384e-10,"The method 'chat' is likely to survive because it provides a useful functionality of generating a response based on a given prompt. It includes error handling to ensure that even if the model call fails, it returns a fallback response. This makes the method robust and reliable, which are desirable traits in software development."
survived,"def format_values(node, values):
    return '{}({})'.format(node.__class__.__name__, ',\n    '.join(values))
",test/integration/samples_in/issue192.py,,1,2.1724399346070676e-10,"The method 'format_values' is a utility function that formats a string representation of a node and its values. It is a simple, clear, and useful function for creating readable outputs, especially in debugging or logging scenarios. Such utility functions are often retained in codebases because they encapsulate a common pattern of string formatting that might be reused in different parts of the application. There is no indication that this function is obsolete or redundant, so it is likely to survive."
survived,"def test_page_cache_extend_multi_page():
    Seq = Axis(""seq"", 2)
    Page = Axis(""page"", 3)
    MaxPage = Axis(""max_page"", 3)
    Slot = Axis(""slot"", 2)
    KVH = Axis(""kv_head"", 1)
    HD = Axis(""head_dim"", 1)

    cache = PageCache.init(Seq, Page, Slot, KVH, HD, MaxPage, dtype=jnp.float32)

    Tok = Axis(""tok"", 4)
    new_k = hax.arange(Tok).broadcast_axis((KVH, HD)).rearrange((Tok, KVH, HD)) + 1
    new_v = hax.arange(Tok).broadcast_axis((KVH, HD)).rearrange((Tok, KVH, HD)) + 101

    cu = jnp.array([0, 3, 4], dtype=jnp.int32)
    pages = jnp.array([0, 1, 2], dtype=jnp.int32)

    jit_extend = eqx.filter_jit(PageCache.extend)
    cache = jit_extend(cache, new_k, new_v, cu, pages, 2)

    assert jnp.all(cache.kv_lens.array == jnp.array([3, 1], dtype=jnp.int32))
    assert cache.page_indices.array[0, 0] == 0
    assert cache.page_indices.array[0, 1] == 1
    assert cache.page_indices.array[1, 0] == 2

    assert cache.kv_pages.array[0, 0, 0, 0] == 1
    assert cache.kv_pages.array[0, 1, 0, 0] == 2
    assert cache.kv_pages.array[1, 0, 0, 0] == 3
    assert cache.kv_pages.array[2, 0, 0, 0] == 4

    assert cache.kv_pages.array[0, 0, 1, 0] == 101
    assert cache.kv_pages.array[0, 1, 1, 0] == 102
    assert cache.kv_pages.array[1, 0, 1, 0] == 103
    assert cache.kv_pages.array[2, 0, 1, 0] == 104",tests/test_page_cache.py,,1,3.2887477414614998e-06,"The method is a test function for a specific feature of a caching mechanism, likely part of a larger system. Test functions are generally crucial for ensuring the correctness of code, especially in complex systems. This function tests the extension of a page cache with multiple pages, verifying that the cache behaves as expected when new keys and values are added. It uses assertions to validate the state of the cache after the operation, which is a common practice in test-driven development. Given its role in maintaining code quality and reliability, it is unlikely to be deleted unless the feature it tests is removed or significantly altered."
survived,"  def test_full_range(self):
    self.assertEqual(getbits(0b11010110, 0, 7), 0b11010110)
",test/unit/test_helpers.py,TestGetBits,1,3.850741907939403e-09,"The method `test_full_range` is a unit test for the function `getbits`. It checks if the function correctly extracts bits from a given binary number. This is a fundamental test case that ensures the function works as expected for a full range of bits. Such tests are crucial for verifying the correctness of code, especially in bit manipulation tasks. Therefore, it is likely to be retained as part of the test suite."
survived,"        async def run_live() -> None:
            os.environ[""LIVE_FEED""] = ""1""
            orig = data_feeds.aiohttp  # type: ignore[attr-defined]
            data_feeds.aiohttp = None  # type: ignore[attr-defined]
            try:
                it = data_feeds.stream_macro_events(live=True)
                await anext(it)
            finally:
                data_feeds.aiohttp = orig  # type: ignore[attr-defined]
                os.environ.pop(""LIVE_FEED"", None)
",tests/test_macro_sentinel.py,TestMacroSentinel,1,6.348800075736417e-09,"The method 'run_live' is likely to be Survived (1) because it appears to be a utility function designed to temporarily modify the environment and data feed settings for a specific purpose, such as running a live data stream. The use of environment variables and the restoration of the original state in a 'finally' block suggests careful handling of resources, which is a good practice. Additionally, the use of 'async' and 'await' indicates that it is designed to work with asynchronous data streams, which are common in modern applications. Unless there is a significant change in the application's requirements or architecture, this method is likely to remain useful."
survived,"def test_enqueue_and_pack():
    sched = JitScheduler.init(max_tokens=8, max_seqs=2, key=jax.random.PRNGKey(0))
    toks = hax.named(jnp.array([1, 2], dtype=jnp.int32), ""position"")
    seqs = hax.named(jnp.array([0, 1], dtype=jnp.int32), ""position"")
    sched = sched.enqueue_tokens(toks, seqs, 2)

    pack = eqx.filter_jit(lambda s: s.pack_next_sequence(2))
    sched, ptoks, pseqs = pack(sched)
    assert jnp.array_equal(ptoks.array, jnp.array([1, 2], dtype=jnp.int32))
    assert jnp.array_equal(pseqs.array, jnp.array([0, 1], dtype=jnp.int32))
    assert sched.num_queued_tokens == 0
",tests/test_jit_scheduler.py,,1,6.475946147757848e-07,"The method `test_enqueue_and_pack` is a unit test for the `JitScheduler` class, specifically testing the `enqueue_tokens` and `pack_next_sequence` methods. Unit tests are crucial for ensuring the correctness of code, especially in complex systems like schedulers. This test checks that tokens and sequences are enqueued and packed correctly, and that the number of queued tokens is updated appropriately. Since testing is an essential part of software development to maintain code quality and reliability, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly changed."
survived,"    def init(max_tokens: int, max_seqs: int, key: PRNGKeyArray) -> ""JitScheduler"":
        """"""Create a ``JitScheduler`` with empty buffers.""""""
        Pos = hax.Axis(""position"", max_tokens)
        Seq = hax.Axis(""seq"", max_seqs)
        return JitScheduler(
            generated_tokens=hax.full(Pos, -1, dtype=jnp.int32),
            generated_seq_ids=hax.full(Pos, -1, dtype=jnp.int32),
            num_generated_tokens=jnp.array(0, dtype=jnp.int32),
            queued_tokens=hax.full(Pos, -1, dtype=jnp.int16),
            queued_seq_ids=hax.full(Pos, -1, dtype=jnp.int32),
            num_queued_tokens=jnp.array(0, dtype=jnp.int32),
            finished=hax.zeros(Seq, dtype=jnp.bool_),
            key=jrandom.split(key, max_seqs),
        )
",src/levanter/inference/jit_scheduler.py,JitScheduler,1,7.73442280641062e-08,"The method 'init' is a constructor-like function for creating an instance of 'JitScheduler' with initialized buffers. It is a fundamental part of setting up the 'JitScheduler' object, which is likely a core component of the system it belongs to. Such methods are typically essential for the functionality of the class and are not removed unless the entire class is deprecated or refactored. Additionally, the method uses specific libraries and data structures (like 'hax' and 'jnp'), indicating it is part of a specialized implementation, further suggesting its necessity."
survived,"def _lambda10():
    draw.get(200)()
    draw.get(600)()
",tests/rosetta/transpiler/Python/cistercian-numerals.py,,0,0.9982992777753472,"The method _lambda10() is not a standard or commonly used method name, suggesting it might be a private or internal function. The function calls two methods from a 'draw' object, which are accessed using the 'get' method with specific arguments (200 and 600). Without additional context, it's unclear what 'draw' is or what these methods do. However, the function seems to be performing some action, possibly related to graphics or UI, given the name 'draw'. If this function is part of a larger system where these actions are necessary, it might be retained. However, if it's not used or if the 'draw' object is deprecated, it might be removed. Without more context, it's difficult to definitively predict its fate, but given the lack of context and specificity, it leans towards being non-essential."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/fork.py,,1,1.0677030767166749e-06,"The method _now() is a utility function that generates a pseudo-random number based on a seed if _now_seeded is True, or returns the current time in nanoseconds if not. This function is useful for testing or scenarios where deterministic behavior is needed. It is unlikely to be deleted because it serves a specific purpose in providing a controlled random number generation or time-based value, which can be crucial for debugging or testing purposes."
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    print(""The first 61 fusc numbers are:"")
    print(str(firstFusc(61)))
    print(""\nThe fusc numbers whose length > any previous fusc number length are:"")
    idxs = [0, 37, 1173, 35499, 699051, 19573419]
    i = 0
    while i < len(idxs):
        idx = idxs[i]
        val = fuscVal(idx)
        numStr = padLeft(commatize(val), 7)
        idxStr = padLeft(commatize(idx), 10)
        print(numStr + "" (index "" + idxStr + "")"")
        i = i + 1
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/fusc-sequence.py,,0,0.9999945777819207,"The method is likely to be deleted because it contains several issues that suggest it is not well-maintained or useful in its current form. Firstly, the code references functions like `firstFusc`, `fuscVal`, `padLeft`, `commatize`, and `_now` that are not defined within the provided code snippet, indicating that it may not be functional without additional context. Secondly, the use of `resource.getrusage` and `json.dumps` suggests an attempt to measure performance and output results in a structured format, but without the necessary context or definitions, this code is incomplete. Lastly, the hardcoded indices and lack of comments or documentation make it difficult to understand the purpose or functionality of the code, which could lead to its removal if it is not actively used or maintained."
survived,"def split(s, sep):
    parts = []
    cur = """"
    i = 0
    while i < len(s):
        if len(sep) > 0 and i + len(sep) <= len(s) and s[i:i + len(sep)] == sep:
            parts = parts + [cur]
            cur = """"
            i = i + len(sep)
        else:
            cur = cur + """".join(s[i:i + 1])
            i = i + 1
    parts = parts + [cur]
    return parts
",tests/rosetta/transpiler/Python/four-is-the-number-of-letters-in-the-....py,,0,0.9999724643101549,"The method is a custom implementation of a string split function, which is a common utility in programming. However, most modern programming languages, including Python, already have built-in methods for splitting strings (e.g., Python's str.split()). These built-in methods are typically more efficient and robust, handling edge cases and performance optimizations that a custom implementation might not. Therefore, unless there is a specific need for a custom implementation, such as educational purposes or specific behavior not covered by built-in methods, this method is likely to be deleted in favor of using the built-in functionality."
survived,"def wordLen(w):
    global idx, words
    while len(words) < w:
        idx = idx + 1
        n = countLetters(words[idx])
        parts = say(n).split("" "")
        j = 0
        while j < len(parts):
            words = words + [parts[j]]
            j = j + 1
        words = words + [""in""]
        words = words + [""the""]
        parts = sayOrdinal(idx + 1) + "","".split("" "")
        j = 0
        while j < len(parts):
            words = words + [parts[j]]
            j = j + 1
    word = words[w - 1]
    return [word, countLetters(word)]
",tests/rosetta/transpiler/Python/four-is-the-number-of-letters-in-the-....py,,0,0.999999922655772,"The method 'wordLen' is likely to be deleted because it relies on several undefined functions and variables such as 'countLetters', 'say', 'sayOrdinal', 'idx', and 'words'. Without these definitions, the function cannot operate correctly, making it non-functional in its current state. Additionally, the logic seems convoluted and not easily understandable, which could lead to maintenance issues. Therefore, unless these dependencies are defined elsewhere, the method is not useful and is likely to be removed."
survived,"def repeat(ch, n):
    s = """"
    i = 0
    while i < n:
        s = s + ch
        i = i + 1
    return s
",tests/rosetta/transpiler/Python/forest-fire.py,,1,2.1444939769331175e-05,"The method 'repeat' is a simple utility function that takes a character 'ch' and an integer 'n', and returns a string consisting of the character 'ch' repeated 'n' times. This is a basic and commonly used functionality in programming, often used for generating repeated patterns or padding strings. Although Python has built-in functionality to achieve this using string multiplication (e.g., 'ch * n'), the method itself is straightforward and serves a clear purpose. It is likely to survive because it provides a clear, understandable way to achieve the desired result, especially for educational purposes or in contexts where built-in operations are not preferred."
survived,"def bresenham(x0, y0, x1, y1, g):
    dx = x1 - x0
    if dx < 0:
        dx = -dx
    dy = y1 - y0
    if dy < 0:
        dy = -dy
    sx = -1
    if x0 < x1:
        sx = 1
    sy = -1
    if y0 < y1:
        sy = 1
    err = dx - dy
    while True:
        drawPoint(g, x0, y0)
        if x0 == x1 and y0 == y1:
            break
        e2 = 2 * err
        if e2 > (-dy):
            err = err - dy
            x0 = x0 + sx
        if e2 < dx:
            err = err + dx
            y0 = y0 + sy
",tests/rosetta/transpiler/Python/fractal-tree.py,,1,3.653482080241728e-08,"The method implements Bresenham's line algorithm, which is a well-known and efficient algorithm for drawing lines on a grid or raster display. This algorithm is fundamental in computer graphics for rendering lines and is widely used due to its simplicity and efficiency. The code provided is a correct implementation of this algorithm, and there is no indication that it is outdated or incorrect. Therefore, it is likely to be retained in any codebase that requires line drawing functionality."
survived,"def path(u, v, next):
    if next[u][v] < 0:
        return []
    p = [u]
    x = u
    while x != v:
        x = next[x][v]
        p = p + [x]
    return p
",tests/rosetta/transpiler/Python/floyd-warshall-algorithm2.py,,1,1.522997951276035e-08,"The method 'path' is a utility function that reconstructs the path between two nodes 'u' and 'v' using a 'next' matrix, which is typically used in algorithms like Floyd-Warshall for finding shortest paths in a graph. This function is useful in the context of graph algorithms and is likely to be retained as it provides a clear and necessary functionality for path reconstruction. It is a simple and efficient implementation for its purpose, and there is no indication that it is redundant or incorrect."
survived,"    async def get_latest(_: None = Depends(verify_token)) -> ResultsResponse:
        """"""Return the most recently completed simulation.""""""
        if _latest_id is None:
            raise HTTPException(status_code=404)
        result = _simulations.get(_latest_id)
        if result is None:
            raise HTTPException(status_code=404)
        return result
",src/interface/api_server.py,,1,5.211412485172657e-10,"The method 'get_latest' is likely to survive because it performs a critical function of retrieving the most recently completed simulation, which is essential for applications that rely on simulation data. The use of async and dependency injection with 'Depends' indicates modern and efficient coding practices, suggesting that the method is well-integrated into the system's architecture. Additionally, the method includes error handling with HTTP exceptions, which is important for robust API design."
survived,"    def test_missing_spec_skips_check_without_flag(self) -> None:
        fake_mod = types.SimpleNamespace(
            __version__=""0.0.17"",
            __spec__=None,
            OpenAIAgent=object,
        )

        def _fake_import(name: str, *args: Any, **kwargs: Any) -> object:
            if name == ""openai_agents"":
                return fake_mod
            return importlib.import_module(name, *args, **kwargs)

        def _fake_find_spec(name: str, *args: Any, **kwargs: Any) -> object:
            if name == ""openai_agents"":
                return object()
            if name == ""agents"":
                return None
            return importlib.util.find_spec(name, *args, **kwargs)

        def _raise() -> bool:
            raise AssertionError(""check_openai_agents_version should not run"")

        with (
            mock.patch(""importlib.import_module"", side_effect=_fake_import),
            mock.patch(""importlib.util.find_spec"", side_effect=_fake_find_spec),
            mock.patch.object(check_env, ""REQUIRED"", []),
            mock.patch.object(check_env, ""OPTIONAL"", [""openai_agents""]),
            mock.patch.object(check_env, ""warn_missing_core"", lambda: []),
            mock.patch.object(check_env, ""check_openai_agents_version"", _raise),
        ):
            self.assertEqual(check_env.main([]), 0)
",tests/test_check_env_openai_agents_version.py,TestCheckEnvOpenAIAgentsVersion,1,1.0467401685178159e-08,"The method 'test_missing_spec_skips_check_without_flag' is a unit test designed to verify that the 'check_openai_agents_version' function is not called when certain conditions are met. It uses mocking to simulate the environment and dependencies, ensuring that the test is isolated and does not rely on external factors. This is a common practice in software testing to ensure code reliability and correctness. The method is likely to be retained as it serves a specific purpose in the testing suite, ensuring that the code behaves as expected under certain conditions."
survived,"def test_run_cycle_closes_adk_client(monkeypatch) -> None:
    """"""`run_cycle_async` should close the ADK client when available.""""""
    mod = importlib.import_module(MODULE)

    class DummyADK:
        def __init__(self) -> None:
            self.closed = False

        async def run(self, _msg: str) -> None:
            pass

        def close(self) -> None:
            self.closed = True

    orchestrator = mod.Orchestrator()
    fin = mod.AgentFin()
    res = mod.AgentRes()
    ene = mod.AgentEne()
    gdl = mod.AgentGdl()
    model = mod.Model()

    monkeypatch.setattr(mod, ""_A2A"", None)
    monkeypatch.setattr(orchestrator, ""collect_signals"", lambda: {})
    monkeypatch.setattr(fin, ""latent_work"", lambda _b: 0.0)
    monkeypatch.setattr(res, ""entropy"", lambda _b: 1.0)
    monkeypatch.setattr(ene, ""market_temperature"", lambda _b: 1.0)

    async def _llm(_: float) -> str:
        return ""ok""

    monkeypatch.setattr(mod, ""_llm_comment"", _llm)

    adk = DummyADK()
    asyncio.run(mod.run_cycle_async(orchestrator, fin, res, ene, gdl, model, adk))

    assert adk.closed
",tests/test_alpha_agi_business_3_v1.py,,1,1.275190675769241e-07,"The method `test_run_cycle_closes_adk_client` is a unit test designed to verify that the `run_cycle_async` function properly closes the ADK client. This is a typical use case for unit tests, which are essential for ensuring code reliability and functionality. The test uses a mock object (`DummyADK`) and the `monkeypatch` fixture to simulate and control the environment, which is a common practice in testing asynchronous code. Given the importance of testing in software development, especially for asynchronous operations, it is unlikely that this method will be deleted. Instead, it serves a critical role in maintaining code quality."
survived,"        def close(self) -> None:
            self.closed = True
",tests/test_alpha_agi_business_3_v1.py,DummyADK,1,8.76424914819242e-08,"The method 'close' is a simple setter method that changes the state of an object by setting the 'closed' attribute to True. This is a common pattern in object-oriented programming for managing the state of an object, especially in classes that represent resources or connections that need to be explicitly closed. Such methods are typically essential for resource management and ensuring proper cleanup, so they are unlikely to be deleted unless the entire class is refactored or the method is replaced by a more comprehensive resource management strategy."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/group_by_multi_join_sort.py,,1,5.60279640614594e-09,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted for display or logging. Its simplicity and general applicability suggest that it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/inner_join.py,,1,4.363462233903899e-09,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in many programming contexts where data needs to be formatted for display or logging purposes. Its simplicity and general applicability suggest that it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/tail_recursion.py,,1,4.363462233903899e-09,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted for display or logging. Since it provides a clear and concise way to handle multiple data types, it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/typed_let.py,,1,1.522997951276035e-08,"The method _fmt is a utility function that formats different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other values directly to strings. This kind of utility function is generally useful in many programming scenarios where data needs to be formatted for display or logging. Its simplicity and general applicability suggest that it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/dataset_where_filter.py,,1,3.850741907939403e-09,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted for display or logging purposes. Its simplicity and general applicability suggest that it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/group_by_left_join.py,,1,1.8189616842444243e-09,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is often useful in data processing or logging tasks where consistent string representation is needed. Given its general utility and lack of any apparent issues, it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/map_nested_assign.py,,1,1.522997951276035e-08,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, and it converts floats that are whole numbers into integers before converting them to strings. This kind of utility function is often useful in various contexts where data needs to be consistently formatted for output or logging. Given its general utility and the fact that it handles common data types, it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/test_block.py,,1,3.3982678079468468e-09,"The method _fmt is a utility function that formats different types of input values into strings. It handles lists by recursively formatting each element, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted consistently for output or logging. Since it provides a clear and useful functionality, it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/user_type_literal.py,,1,1.0467401685178159e-08,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in many programming scenarios where data needs to be consistently formatted for output or logging. Given its utility and the fact that it handles common data types, it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/let_and_print.py,,1,4.944450477491054e-09,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted for display or logging. Its simplicity and general applicability suggest that it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/list_assign.py,,1,1.0467401685178159e-08,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in many programming scenarios where data needs to be consistently formatted for output or logging. Its versatility and simplicity make it a candidate for survival, as it can be reused across different parts of a codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/list_nested_assign.py,,1,4.944450477491054e-09,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted for display or logging. Its simplicity and general applicability suggest that it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/typed_var.py,,1,7.194132978569833e-09,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted for display or logging purposes. Its simplicity and general applicability suggest that it is likely to be retained in the codebase."
survived,"    def test_bridge_market_data(self) -> None:
        import tempfile

        with tempfile.NamedTemporaryFile(""w"", delete=False) as fh:
            fh.write(""6,6,6"")
            feed_path = fh.name

        result = subprocess.run(
            [
                sys.executable,
                ""-m"",
                ""alpha_factory_v1.demos.meta_agentic_tree_search_v0.openai_agents_bridge"",
                ""--episodes"",
                ""1"",
                ""--market-data"",
                feed_path,
            ],
            capture_output=True,
            text=True,
        )
        self.assertEqual(result.returncode, 0, result.stderr)
",tests/test_meta_agentic_tree_search_demo.py,TestMetaAgenticTreeSearchDemo,1,1.0467401685178159e-08,"The method 'test_bridge_market_data' is a unit test designed to verify the functionality of a specific module by running a subprocess and checking its return code. Unit tests are crucial for ensuring code reliability and are typically maintained as long as the functionality they test is relevant. Since this test checks the integration of market data with a specific module, it is likely to be retained unless the module itself is deprecated or significantly refactored."
survived,"    def inner(y: int) -> int:
        return x + y
",tests/human/x/python/nested_function.py,,0,0.9999785550602307,"The method 'inner' uses a variable 'x' that is not defined within its scope or passed as a parameter. This will lead to a NameError when the function is called unless 'x' is defined in the enclosing scope. Without additional context showing that 'x' is defined elsewhere, this function is likely to be deleted or refactored to include 'x' as a parameter."
deleted,"def transform_container_instances(instances: List[Dict[str, Any]], region: str) -> List[Dict[str, Any]]:
    transformed: List[Dict[str, Any]] = []
    for inst in instances:
        i = inst.copy()
        i[""registeredAt""] = dict_date_to_epoch(i, ""registeredAt"")
        i[""Region""] = region
        transformed.append(i)
    return transformed
",cartography/intel/aws/ecs.py,,1,5.211412485172657e-10,"The method 'transform_container_instances' is likely to survive because it performs a useful transformation on a list of container instances. It converts a date field to an epoch format and adds a region field, which are common tasks in data processing. The method is also well-structured, using type hints and a clear loop to process each instance. These factors suggest that the method is functional, maintainable, and likely to be used in its current or similar form."
survived,"    def poll(self, _):
        pass
",tests/test_world_model_kafka.py,DummyKafka,1,1.6701415113938837e-05,"The method 'poll' is defined but not implemented, as it only contains a 'pass' statement. This suggests that the method is either a placeholder for future implementation or is intentionally left empty because it is meant to be overridden in a subclass. Without additional context, it's difficult to determine the exact intention. However, if this method is part of a larger class that is meant to be extended, it might survive as a placeholder for subclasses to implement specific behavior. If it's not intended for future use or extension, it might be deleted. Given the lack of context, I'll predict it will survive as a placeholder."
survived,"def _validate_rel(rel: str) -> str:
    """"""Validate relationship name.""""""
    if not _REL_RE.match(rel):
        raise ValueError(f""Invalid relation name: {rel!r}"")
    return rel
",alpha_factory_v1/backend/memory_graph.py,,1,5.211412485172657e-10,"The method `_validate_rel` is a utility function that checks if a given relationship name matches a predefined pattern using a regular expression (`_REL_RE`). If the name does not match, it raises a `ValueError`. This kind of validation function is common in codebases to ensure data integrity and prevent errors from propagating. Since it serves a clear purpose and is likely used in multiple places where relationship names need to be validated, it is unlikely to be deleted unless the entire validation approach is refactored or the `_REL_RE` pattern is no longer relevant. Therefore, the method is likely to survive."
survived,"    def __init__(self):
        super().__init__(
            id=""21a79166-9df7-4b5f-9f36-96f639d86112"",
            description=""Get a full Gmail thread by ID"",
            categories={BlockCategory.COMMUNICATION},
            input_schema=GmailGetThreadBlock.Input,
            output_schema=GmailGetThreadBlock.Output,
            disabled=not GOOGLE_OAUTH_IS_CONFIGURED,
            test_input={""threadId"": ""t1"", ""credentials"": TEST_CREDENTIALS_INPUT},
            test_credentials=TEST_CREDENTIALS,
            test_output=[(""thread"", {""id"": ""t1"", ""messages"": []})],
            test_mock={""_get_thread"": lambda *args, **kwargs: {""id"": ""t1""}},
        )
",autogpt_platform/backend/backend/blocks/google/gmail.py,GmailGetThreadBlock,1,1.0467401685178159e-08,"The method is a constructor for a class that appears to be part of a larger system for handling Gmail threads. It initializes the object with specific parameters and configurations, including input and output schemas, test inputs, and mock functions. The presence of test configurations and the use of a superclass constructor suggest that this method is part of a well-structured codebase. Additionally, the method is not marked as deprecated or obsolete, and it seems to be functional and relevant to the system's purpose. Therefore, it is likely to survive."
survived,"def test_serialize_deserialize_special_floats():
  assert deserialize(serialize(float(""inf""))) == math.inf
  assert deserialize(serialize(float(""-inf""))) == -math.inf
  result = deserialize(serialize(float(""nan"")))
  assert math.isnan(result)",pylabrobot/tests/serializer_tests.py,,1,4.6911638017642294e-08,"The method tests the serialization and deserialization of special floating-point values like infinity and NaN. This is a common requirement in software systems that handle numerical data, as these special values can occur in various computations. Ensuring that these values are correctly serialized and deserialized is crucial for data integrity and correctness of numerical operations. Therefore, this method is likely to be retained as it serves an important purpose in validating the functionality of the serialization/deserialization process for special floats."
survived,"    def close(self) -> None:
        pass
",tests/test_adk_agent.py,DummyLedger,1,7.484619712816325e-05,"The method 'close' is defined but not implemented, as it only contains a 'pass' statement. This suggests that it is a placeholder for future implementation or is meant to be overridden in a subclass. If this method is part of a base class or interface that is intended to be extended, it is likely to survive. However, if it is part of a concrete class and remains unimplemented, it might be considered for deletion unless there is a specific reason to keep it as a no-op. Without additional context, it is more likely to survive if it serves a structural purpose in a class hierarchy."
survived,"        def __init__(self, *_a, **_kw) -> None:
            pass
",tests/test_orchestrator_backoff.py,DummyLedger,0,0.9999756997690634,"The method is a constructor (__init__) that takes any number of positional and keyword arguments but does nothing with them, as it only contains a 'pass' statement. This is typically a placeholder or a default implementation that might be intended for future expansion or to satisfy an interface requirement. However, if it remains unchanged and unused, it is likely to be deleted in a codebase focused on maintaining clean and efficient code."
survived,"def test_restart_backoff(monkeypatch):
    monkeypatch.setenv(""AGENT_ERR_THRESHOLD"", ""1"")
    monkeypatch.setenv(""AGENT_BACKOFF_EXP_AFTER"", ""1"")

    delays = []
    orig_sleep = asyncio.sleep

    async def fake_sleep(sec: float):
        delays.append(sec)
        await orig_sleep(0)

    monkeypatch.setattr(orchestrator.asyncio, ""sleep"", fake_sleep)
    monkeypatch.setattr(orchestrator.random, ""uniform"", lambda a, b: 1.0)

    events: list[str] = []

    class DummyLedger:
        def __init__(self, *_a, **_kw) -> None:
            pass

        def log(self, env) -> None:
            if env.payload.get(""event""):
                events.append(env.payload[""event""])

        def start_merkle_task(self, *_a, **_kw) -> None:
            pass

        async def stop_merkle_task(self) -> None:
            pass

        def close(self) -> None:
            pass

    settings = config.Settings(bus_port=0)
    monkeypatch.setattr(orchestrator, ""Ledger"", DummyLedger)
    monkeypatch.setattr(
        orchestrator.Orchestrator,
        ""_init_agents"",
        lambda self: [FailingAgent(self.bus, self.ledger)],
    )
    orch = orchestrator.Orchestrator(settings)
    runner = orch.runners[""fail""]

    async def run() -> None:
        async with orch.bus:
            runner.start(orch.bus, orch.ledger)
            monitor = asyncio.create_task(orch._monitor())
            for _ in range(6):
                await orig_sleep(0)
            monitor.cancel()
            with contextlib.suppress(asyncio.CancelledError):
                await monitor
            if runner.task:
                runner.task.cancel()
                with contextlib.suppress(asyncio.CancelledError):
                    await runner.task

    asyncio.run(run())

    restart_delays = [d for d in delays if d not in (0, 2)]
    assert restart_delays[:2] == [1.0, 2.0]
    assert events.count(""restart"") >= 2
",tests/test_orchestrator_backoff.py,,1,7.194132978569833e-09,"The method 'test_restart_backoff' is a unit test function that uses the 'monkeypatch' fixture to modify environment variables and mock certain behaviors for testing purposes. It is designed to test the backoff mechanism of a system by simulating failures and checking the delays and events. This kind of test is crucial for ensuring the reliability and robustness of the backoff logic in the system. Since it is a test function, it is unlikely to be deleted unless the functionality it tests is removed or significantly changed. Therefore, it is more likely to survive."
survived,"    def test_multibit_OpenCL_Brute(self):
        wallet_filename = os.path.join(WALLET_DIR, ""multibit-wallet.key"")
        temp_dir        = tempfile.mkdtemp(""-test-btcr"")
        temp_wallet_filename = os.path.join(temp_dir, os.path.basename(wallet_filename))
        shutil.copyfile(wallet_filename, temp_wallet_filename)

        btcrpass.loaded_wallet = btcrpass.WalletMultiBit.load_from_filename(temp_wallet_filename)

        btcrecover.opencl_helpers.auto_select_opencl_platform(btcrpass.loaded_wallet)

        btcrecover.opencl_helpers.init_opencl_contexts(btcrpass.loaded_wallet)

        self.assertEqual(btcrpass.WalletMultiBit._return_verified_password_or_false_opencl(btcrpass.loaded_wallet,
            [tstr(""btcr-wrong-password-1""), tstr(""btcr-wrong-password-2"")]), (False, 2),
            ""Platform:"" + str(btcrpass.loaded_wallet.opencl_platform) + "" found a false positive"")
        self.assertEqual(btcrpass.WalletMultiBit._return_verified_password_or_false_opencl(btcrpass.loaded_wallet,
            [tstr(""btcr-wrong-password-3""), tstr(""btcr-test-password""), tstr(""btcr-wrong-password-4"")]), (tstr(""btcr-test-password""), 2),
            ""Platform:"" + str(btcrpass.loaded_wallet.opencl_platform) + "" failed to find password"")

        del btcrpass.loaded_wallet
",btcrecover/test/test_passwords.py,Test07WalletDecryption,1,9.736200303530205e-10,"The method `test_multibit_OpenCL_Brute` is a unit test designed to verify the functionality of a specific feature related to OpenCL and password verification in a wallet application. Unit tests are crucial for ensuring code reliability and correctness, especially in security-sensitive applications like cryptocurrency wallets. The method is well-structured, uses assertions to validate expected outcomes, and cleans up resources after execution. These characteristics make it a valuable part of the test suite, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained."
survived,"def is_pocl_platform():
    if not has_any_opencl_devices():
        return False
    try:
        import pyopencl as cl
        return cl.get_platforms()[0].name.startswith(""Portable Computing Language"")
    except Exception:
        return False
",btcrecover/test/test_passwords.py,,1,2.7894680920908113e-10,"The method `is_pocl_platform()` is likely to survive because it serves a specific purpose: checking if the current platform is using the Portable Computing Language (POCL) for OpenCL. This can be useful in environments where different OpenCL platforms are available, and a specific behavior or optimization is needed for POCL. The method is straightforward, uses a try-except block to handle potential import errors, and checks for OpenCL devices before proceeding, which are good practices. Unless the context or requirements change significantly, this utility function is likely to remain useful."
survived,"def get_checksum_state(dbc_name: str) -> Optional[ChecksumState]:
    if dbc_name.startswith(('honda_', 'acura_')):
        return ChecksumState(4, 2, 3, 5, False, SignalType.HONDA_CHECKSUM, honda_checksum)
    elif dbc_name.startswith(('toyota_', 'lexus_')):
        return ChecksumState(8, -1, 7, -1, False, SignalType.TOYOTA_CHECKSUM, toyota_checksum)
    elif dbc_name.startswith('hyundai_canfd_generated'):
        return ChecksumState(16, -1, 0, -1, True, SignalType.HKG_CAN_FD_CHECKSUM, hkg_can_fd_checksum)
    elif dbc_name.startswith(('vw_mqb', 'vw_mqbevo', 'vw_meb')):
        return ChecksumState(8, 4, 0, 0, True, SignalType.VOLKSWAGEN_MQB_MEB_CHECKSUM, volkswagen_mqb_meb_checksum)
    elif dbc_name.startswith('vw_pq'):
        return ChecksumState(8, 4, 0, -1, True, SignalType.XOR_CHECKSUM, xor_checksum)
    elif dbc_name.startswith('subaru_global_'):
        return ChecksumState(8, -1, 0, -1, True, SignalType.SUBARU_CHECKSUM, subaru_checksum)
    elif dbc_name.startswith('chrysler_'):
        return ChecksumState(8, -1, 7, -1, False, SignalType.CHRYSLER_CHECKSUM, chrysler_checksum)
    elif dbc_name.startswith('fca_giorgio'):
        return ChecksumState(8, -1, 7, -1, False, SignalType.FCA_GIORGIO_CHECKSUM, fca_giorgio_checksum)
    elif dbc_name.startswith('comma_body'):
        return ChecksumState(8, 4, 7, 3, False, SignalType.BODY_CHECKSUM, body_checksum)
    elif dbc_name.startswith('tesla_model3_party'):
        return ChecksumState(8, -1, 0, -1, True, SignalType.TESLA_CHECKSUM, tesla_checksum, tesla_setup_signal)
    return None
",opendbc/can/packer.py,,1,7.194132978569833e-09,"The method `get_checksum_state` is a utility function that maps specific string patterns in the `dbc_name` to corresponding `ChecksumState` objects. It is well-structured, covers a variety of cases for different car manufacturers, and returns `None` if no match is found. This kind of method is essential for handling different checksum configurations based on the car model, which is a common requirement in automotive software dealing with CAN bus messages. Therefore, it is unlikely to be deleted as it serves a crucial role in the system."
survived,"def fca_giorgio_checksum(address: int, sig: Signal, d: bytearray) -> int:
    crc = 0
    for i in range(len(d) - 1):
        crc ^= d[i]
        crc = CRC8J1850[crc]
    if address == 0xDE:
        return crc ^ 0x10
    elif address == 0x106:
        return crc ^ 0xF6
    elif address == 0x122:
        return crc ^ 0xF1
    else:
        return crc ^ 0x0A
",opendbc/can/packer.py,,1,1.2501528648238603e-09,"The method 'fca_giorgio_checksum' is a utility function that calculates a checksum based on the input address and data. It uses a CRC8J1850 table for the calculation, which is a common approach in automotive and embedded systems for error-checking. The method is straightforward, performs a specific task, and does not have any apparent issues or redundancies that would warrant its deletion. It is likely to be useful in contexts where data integrity needs to be verified, especially in systems that use the J1850 protocol. Therefore, it is predicted to survive."
survived,"def volkswagen_mqb_meb_checksum(address: int, sig: Signal, d: bytearray) -> int:
    crc = 0xFF
    for i in range(1, len(d)):
        crc ^= d[i]
        crc = CRC8H2F[crc]
    counter = d[1] & 0x0F
    const = VOLKSWAGEN_MQB_MEB_CONSTANTS.get(address)
    if const:
        crc ^= const[counter]
        crc = CRC8H2F[crc]
    else:
        pass
    return crc ^ 0xFF
",opendbc/can/packer.py,,1,2.3355930333443423e-09,"The method is likely to survive because it appears to be a specialized function for calculating a checksum, which is a common requirement in automotive software for data integrity verification. The function is specific to Volkswagen's MQB and MEB platforms, indicating it serves a particular purpose in a larger system. Additionally, the use of constants and a lookup table suggests it is optimized for performance, which is crucial in automotive applications. Unless there is a significant change in the underlying protocol or a better method is developed, this function will likely remain useful."
survived,"def subaru_checksum(address: int, sig: Signal, d: bytearray) -> int:
    s = 0
    addr = address
    while addr:
        s += addr & 0xFF
        addr >>= 8
    for i in range(1, len(d)):
        s += d[i]
    return s & 0xFF
",opendbc/can/packer.py,,1,6.69158608681505e-10,"The method `subaru_checksum` is a utility function that calculates a checksum for a given address and data. This type of function is often used in communication protocols to ensure data integrity. The function is simple, efficient, and serves a specific purpose, which makes it likely to be retained in the codebase. It doesn't have any apparent issues or redundancies that would necessitate its removal."
survived,"    def make_can_msg(self, name_or_addr, bus: int, values: Dict[str, float]):
        if isinstance(name_or_addr, int):
            addr = name_or_addr
        else:
            msg = self.dbc.name_to_msg.get(name_or_addr)
            if msg is None:
                raise RuntimeError(f""Undefined message {name_or_addr}"")
            addr = msg.address
        dat = self.pack(addr, values)
        return addr, bytes(dat), bus
",opendbc/can/packer.py,CANPacker,1,7.05287985061473e-11,"The method 'make_can_msg' is likely to survive because it performs a specific and useful function: creating a CAN message from a given name or address, bus, and values. It handles both integer addresses and named messages, raising an error if the message name is undefined, which is a good practice for error handling. The method also uses a helper function 'pack' to convert the address and values into a byte format, which is a common requirement in systems dealing with CAN messages. Overall, the method is well-structured and serves a clear purpose, making it unlikely to be deleted."
survived,"def button_down_template(button_name):
    return f""""""
  - set-control:
      part-id: {button_name}
      control: pressed
      value: 1
  - delay: {hold_time}ms
  """"""
",.scripts/prepare_workflow.py,,1,1.0467401685178159e-08,"The method 'button_down_template' is a simple utility function that generates a string template for a button press action. It is likely to be useful in scenarios where button press actions need to be automated or scripted, such as in testing or automation scripts. The method is straightforward, does not have any apparent issues, and serves a clear purpose. Therefore, it is likely to be retained in the codebase."
survived,"def test_attachment_rejects_relative_path_input(mock_file_factory):
    test_media_file_document = mock_file_factory(MockFileFactoryMimeType.PDF)
    # the input path should be absolute, and we should reject relative paths
    with pytest.raises(ValueError):
        KilnAttachmentModel.from_file(
            test_media_file_document.relative_to(test_media_file_document.parent)
        )
",libs/core/kiln_ai/datamodel/test_attachment.py,,1,5.3157849718487075e-08,"The method is a test function that checks if the KilnAttachmentModel correctly raises a ValueError when a relative path is provided instead of an absolute path. This is a valid and necessary test to ensure the robustness of the KilnAttachmentModel's input validation. Test functions like this are crucial for maintaining code quality and preventing bugs related to incorrect file path handling. Therefore, it is unlikely to be deleted."
survived,"def reload_devicons():
    from ranger_devicons import devicons
    importlib.reload(devicons)
    return devicons
",tests/test_xdg.py,,1,1.725782769012759e-08,"The method 'reload_devicons' is a utility function that reloads a module, which can be useful in development environments where changes to the module need to be tested without restarting the entire application. This function is simple, has a clear purpose, and does not have any apparent issues or redundancies. Therefore, it is likely to be retained in the codebase."
survived,"    def _job() -> None:  # pragma: no cover - Rocketry callback
        publish_root(db_path=db_path, out_file=out_file)
",src/archive/cron.py,,1,1.2098660619383578e-06,"The method _job is a private method indicated by the underscore prefix, suggesting it is intended for internal use within a module or class. It is also marked with a pragma directive 'no cover', indicating that it is not covered by unit tests, which is common for methods that are either trivial or have side effects that are difficult to test. The method calls another function, publish_root, which suggests it performs a specific task, likely related to a scheduled job or callback in a task scheduling context (as indicated by 'Rocketry callback'). Since it serves a specific purpose and is part of a larger system, it is likely to be retained unless the functionality it provides is no longer needed or is replaced by a different implementation."
survived,"async def hb_watch(runners: Dict[str, AgentRunner]) -> None:
    while True:
        now = time.time()
        for n, r in runners.items():
            alive = int(now - r.last_beat < r.period * 3.0)
            MET_UP.labels(n).set(alive)
        await asyncio.sleep(5)
",alpha_factory_v1/backend/agent_manager.py,,1,2.3355930333443423e-09,"The method 'hb_watch' is an asynchronous function designed to monitor the heartbeat of agent runners. It iterates over a dictionary of runners, checks if each runner is alive based on the time since its last heartbeat, and updates a metric accordingly. This functionality is crucial for monitoring the health of distributed systems or services, ensuring that components are functioning as expected. Given its utility in system monitoring and the use of asynchronous programming to efficiently handle I/O-bound tasks, it is likely to be retained in the codebase."
survived,"        async def _cycle() -> None:
            t0 = time.time()
            span_cm = tracer.start_as_current_span(self.name) if tracer else contextlib.nullcontext()
            with span_cm:
                try:
                    await asyncio.wait_for(maybe_await(self.inst.run_cycle), timeout=self._max_cycle_sec)
                except asyncio.TimeoutError:
                    MET_ERR.labels(self.name).inc()
                    log.error(""%s run_cycle exceeded %ss budget – skipped"", self.name, self._max_cycle_sec)
                except Exception as exc:  # noqa: BLE001
                    MET_ERR.labels(self.name).inc()
                    log.exception(""%s.run_cycle crashed: %s"", self.name, exc)
                finally:
                    dur_ms = (time.time() - t0) * 1_000
                    MET_LAT.labels(self.name).observe(dur_ms)
                    self.last_beat = time.time()
                    self._publish(""agent.cycle"", {""agent"": self.name, ""latency_ms"": dur_ms, ""ts"": utc_now()})
",alpha_factory_v1/backend/agent_manager.py,AgentRunner,1,9.237449576640118e-09,"The method '_cycle' is an asynchronous function that handles the execution of a cycle with error handling and logging. It uses tracing, metrics, and publishes results, which are all important for monitoring and debugging in production systems. The method is well-structured, with clear error handling for timeouts and other exceptions, and it logs relevant metrics. These features are crucial for maintaining robust and reliable systems, especially in asynchronous environments. Therefore, it is unlikely to be deleted as it serves a critical role in the system's operation."
survived,"    async def run(self, stop_event: asyncio.Event) -> None:
        """"""Drive all runners until *stop_event* is set.""""""

        await self.start()
        try:
            while not stop_event.is_set():
                await asyncio.gather(*(r.maybe_step() for r in self.runners.values()))
                await asyncio.sleep(0.25)
        finally:
            await self.stop()
",alpha_factory_v1/backend/agent_manager.py,AgentManager,1,9.237449576640118e-09,"The method 'run' is an essential part of an asynchronous system, designed to manage and coordinate multiple 'runners' until a stop event is triggered. It includes starting and stopping mechanisms, which are crucial for resource management and ensuring that the system can be gracefully shut down. The use of asyncio.gather and asyncio.sleep indicates that it is handling concurrent tasks efficiently. Such methods are typically core to the functionality of systems that require continuous operation until a specific condition is met, making it unlikely to be deleted unless the entire system architecture changes."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/group_by_multi_join.py,Supplier,1,5.3157849718487075e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a flexible and Pythonic way to access object attributes, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/group_by_multi_join_sort.py,Lineitem,1,5.3157849718487075e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It allows for flexible and dynamic attribute access, which can be particularly useful in scenarios where the attributes are not known at compile time or are dynamically generated. Therefore, this method is likely to be retained as it provides a meaningful and functional feature."
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/dataset_where_filter.py,Person,1,9.736200303530205e-10,"The __repr__ method is a special method used to define a string representation of an object. In this case, it returns the string representation of the object's dictionary, which is a common and useful way to provide a detailed view of the object's attributes for debugging purposes. This implementation is straightforward and serves a clear purpose, making it likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/order_by_map.py,Data,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a clear and functional purpose, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/group_by_multi_join_sort.py,Nation,1,2.2159489282323004e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, this method is likely to be retained as it provides a clear and useful functionality."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/outer_join.py,Order,1,1.725782769012759e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. This implementation uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the codebase."
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/inner_join.py,Order,1,6.348800075736417e-09,"The __repr__ method is a special method used to define a string representation of an object. In this case, it returns the string representation of the object's dictionary, which is a common and useful way to provide a detailed view of the object's attributes for debugging purposes. This implementation is straightforward and serves a clear purpose, making it unlikely to be deleted unless there is a specific reason to change how the object is represented as a string."
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/inner_join.py,Customer,1,7.194132978569833e-09,"The __repr__ method is a special method used to define a string representation of an object. In this case, it returns the string representation of the object's __dict__, which is a dictionary containing all the attributes of the object. This is a common and useful implementation for debugging purposes, as it provides a clear and detailed view of the object's state. Therefore, it is likely to be retained in the code."
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/join_multi.py,Customer,1,1.955568070542584e-08,"The __repr__ method is a special method used to define a string representation of an object. In this case, it returns the string representation of the object's dictionary, which is a common and useful way to provide a detailed view of the object's attributes for debugging purposes. This implementation is straightforward and serves a clear purpose, making it unlikely to be deleted unless there is a specific reason to change how the object is represented as a string."
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/group_by_join.py,Customer,1,4.1399375473943306e-08,"The method `__repr__` is a special method in Python used to define a string representation of an object. The implementation provided here returns the string representation of the object's dictionary, which is a common and useful way to represent an object for debugging purposes. This method is likely to be retained because it provides a clear and concise way to inspect the internal state of an object, which is valuable for developers during debugging and logging."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/cross_join.py,Order,1,2.7894680920908113e-10,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, this method is likely to be Survived."
survived,"        def run(self) -> None:
            print(""OpenAI Agents bridge disabled."")
",alpha_factory_v1/demos/alpha_agi_business_v1/openai_agents_bridge.py,AgentRuntime,0,0.9999999006880476,"The method 'run' only contains a print statement that outputs a message indicating that the OpenAI Agents bridge is disabled. This suggests that the method is not performing any functional operations or logic beyond this print statement. In many cases, such methods are considered redundant or placeholders and may be removed if they do not serve a purpose in the overall application. Therefore, it is likely that this method will be deleted unless it is being used for debugging or logging purposes."
survived,"        def register(self, *a, **kw) -> None:
            pass
",alpha_factory_v1/demos/alpha_agi_business_v1/openai_agents_bridge.py,AgentRuntime,0,0.9999999634651793,"The method 'register' is defined but not implemented, as it only contains a 'pass' statement. This suggests that it is either a placeholder for future implementation or it is not needed. Without any additional context or usage, it is likely to be deleted in future refactoring to clean up the codebase."
survived,"    def _prepare_input(self, X: Any) -> Tuple[List[List[int]], Sequence[str]]:
        corpus: List[List[int]]
        vocab: Sequence[str] | None = None

        if isinstance(X, tuple) and len(X) == 2:
            corpus, vocab = X
        elif sparse.issparse(X) or (isinstance(X, np.ndarray) and X.ndim == 2):
            corpus = _dtm_to_corpus(X)
            vocab = self.vocab
        else:
            corpus = X  # assume already integer corpus
            vocab = self.vocab

        if vocab is None:
            raise ValueError(""Vocabulary is required to fit the model"")
        return corpus, vocab
",src/hlda/sklearn_wrapper.py,HierarchicalLDAEstimator,1,4.0586521248284276e-10,"The method '_prepare_input' is a utility function that processes input data into a specific format required by the model. It handles different types of input, such as tuples, sparse matrices, and numpy arrays, and ensures that a vocabulary is available. This kind of method is crucial for data preprocessing in machine learning pipelines, making it likely to be retained. Additionally, the method includes error handling to ensure that the necessary vocabulary is present, which is a good practice in robust code design. Therefore, it is likely to survive."
survived,"    async def run() -> None:
        bus.subscribe(""b"", lambda e: received.append(e))
        await bus.start()
        try:
            creds = grpc.ssl_channel_credentials(root_certificates=ca)
            async with grpc.aio.secure_channel(f""localhost:{port}"", creds) as ch:
                stub = ch.unary_unary(""/bus.Bus/Send"")
                payload = {
                    ""sender"": ""a"",
                    ""recipient"": ""b"",
                    ""payload"": {""v"": 1},
                    ""ts"": 0.0,
                    ""token"": token,
                }
                await stub(json.dumps(payload).encode())
            await asyncio.sleep(0.05)
        finally:
            await bus.stop()
            shutil.rmtree(tmp_path / ""certs"", ignore_errors=True)
",tests/test_bus_ssl_gen.py,,1,8.152020648014727e-09,"The method is likely to be Survived (1) because it is an asynchronous function that demonstrates a clear and structured use of gRPC for communication, which is a common and modern approach in distributed systems. The method includes proper resource management with try-finally blocks, ensuring that resources are cleaned up properly, which is a good practice in asynchronous programming. Additionally, the use of asyncio and gRPC suggests that this method is part of a larger, possibly microservices-based architecture, which is a prevalent design pattern in current software development."
survived,"    def test_tiny_drop_db_missing_file(self):
        fd, file_path = tempfile.mkstemp()
        os.close(fd)
        adapter = appier.TinyAdapter(file_path=file_path)
        adapter.get_db()
        os.remove(file_path)
        adapter.drop_db()",src/appier/test/data.py,DataTest,1,4.4508487281649027e-07,"The method 'test_tiny_drop_db_missing_file' is a test case that verifies the behavior of the 'TinyAdapter' when the database file is missing. It creates a temporary file, initializes the adapter with it, and then deletes the file before calling 'drop_db'. This is a valid test scenario to ensure the robustness of the 'drop_db' method when the file is unexpectedly missing. Such test cases are crucial for maintaining software quality and are unlikely to be deleted unless the functionality they test is removed or significantly altered."
survived,"async def get_entra_groups(client: GraphServiceClient) -> List[Group]:
    """"""Get all groups from Microsoft Graph API with pagination.""""""
    all_groups: List[Group] = []

    request_configuration = client.groups.GroupsRequestBuilderGetRequestConfiguration(
        query_parameters=client.groups.GroupsRequestBuilderGetQueryParameters(top=999)
    )
    page = await client.groups.get(request_configuration=request_configuration)
    while page:
        if page.value:
            all_groups.extend(page.value)
        if not page.odata_next_link:
            break
        page = await client.groups.with_url(page.odata_next_link).get()

    return all_groups
",cartography/intel/entra/groups.py,,1,9.736200303530205e-10,"The method 'get_entra_groups' is a well-defined asynchronous function that retrieves all groups from the Microsoft Graph API using pagination. It handles the API's pagination mechanism by checking for the 'odata_next_link' and continues fetching until all pages are retrieved. This is a common pattern for dealing with paginated API responses and is likely to be useful in many applications that need to interact with Microsoft Graph. Therefore, it is unlikely to be deleted as it serves a clear purpose and is implemented correctly."
survived,"def test_resolve_with_hashes():
    manager = DependencyManager()
    reqs, licenses, hashes = manager.resolve([""pydantic""], include_hashes=True)
    assert any(r.startswith(""pydantic=="") for r in reqs)
    assert isinstance(hashes, dict)
    assert ""pydantic"" in hashes
    assert re.fullmatch(r""[0-9a-f]{64}"", hashes[""pydantic""])",tests/test_dependency_manager.py,,1,3.2241866333029355e-08,"The method `test_resolve_with_hashes` is a unit test designed to verify the functionality of the `resolve` method in the `DependencyManager` class. It checks that the method correctly resolves dependencies with hashes, ensuring that the output includes a specific package ('pydantic') and that the hashes are in the expected format. This kind of test is crucial for maintaining the integrity of the dependency resolution process, especially when security (hash verification) is involved. Therefore, it is unlikely to be deleted as it serves an important role in validating the software's functionality."
survived,"def test_git_manager_init_and_commit(tmp_path: Path) -> None:
    gm = GitManager(tmp_path)
    gm.init()
    (tmp_path / ""foo.txt"").write_text(""hi"")
    sha = gm.commit_all(""init"")

    assert (tmp_path / "".git"").exists()
    out = subprocess.check_output(
        [""git"", ""-C"", str(tmp_path), ""rev-parse"", ""HEAD""], text=True
    ).strip()
    assert out == sha
",tests/test_git_utils.py,,1,1.725782769012759e-08,"The method 'test_git_manager_init_and_commit' is a unit test designed to verify the functionality of the 'GitManager' class, specifically its 'init' and 'commit_all' methods. This test is crucial for ensuring that the GitManager correctly initializes a repository and commits changes, which are fundamental operations in version control. The test checks for the existence of the '.git' directory and verifies that the commit SHA returned by 'commit_all' matches the actual HEAD commit SHA. These checks are essential for validating the integrity and correctness of the GitManager's operations. Therefore, this method is likely to be retained as it provides valuable testing for critical functionality."
survived,"    def __init__(self, *args: object, **kwargs: object) -> None:
        super().__init__(*args)
",tests/conftest.py,AuthenticationError,1,4.6911638017642294e-08,"The method is a constructor for a class, and it uses the `super()` function to call the constructor of the parent class. This is a common and necessary practice in object-oriented programming to ensure that the parent class is properly initialized. The method is correctly implemented and serves a fundamental purpose in class inheritance, so it is unlikely to be deleted."
survived,"def pow(c, d):
    di = toInt(d)
    prod = c
    i = 1
    while i < di:
        prod = mul(prod, c)
        i = i + 1
    return prod
",tests/rosetta/transpiler/Python/church-numerals-1.py,,0,0.9999810748526188,"The method 'pow' is a custom implementation of the power function, which raises a number 'c' to the power of 'd'. However, it relies on two undefined functions: 'toInt' and 'mul'. Without these functions being defined or imported, this code will not work as intended. Additionally, Python already has a built-in power function using the '**' operator or the 'pow()' function, which are more efficient and concise. Given these factors, the method is likely to be deleted or refactored to use the built-in functionality."
survived,"def bigMulSmall(a, m):
    if m == 0:
        return [0]
    res = []
    carry = 0
    i = 0
    while i < len(a):
        prod = a[i] * m + carry
        res = res + [prod % 10]
        carry = prod // 10
        i = i + 1
    while carry > 0:
        res = res + [carry % 10]
        carry = carry // 10
    return bigTrim(res)
",tests/rosetta/transpiler/Python/chernicks-carmichael-numbers.py,,1,5.3157849718487075e-08,"The method 'bigMulSmall' is a utility function that performs multiplication of a list of digits (representing a large number) by a single digit. This is a common operation in implementing large number arithmetic, which is not natively supported in many programming languages. The function handles edge cases like multiplication by zero and carries over digits correctly. It is a useful function for anyone dealing with large number calculations, especially in educational or competitive programming contexts. Therefore, it is likely to be retained."
survived,"def initN():
    global n
    i = 0
    while i < 15:
        row = []
        j = 0
        while j < 11:
            row = row + ["" ""]
            j = j + 1
        row[5] = ""x""
        n = n + [row]
        i = i + 1
",tests/rosetta/transpiler/Python/cistercian-numerals.py,,0,0.9999982396568657,"The method initN() is likely to be deleted because it contains several issues that make it inefficient and potentially problematic. Firstly, it uses global variables, which is generally discouraged as it can lead to code that is difficult to debug and maintain. Secondly, the method uses nested while loops to create a 2D list, which can be more efficiently done using list comprehensions. Additionally, the method appends to the global variable 'n' without initializing it within the function, which can lead to errors if 'n' is not defined before the function is called. These issues suggest that the method is not well-designed and may be removed or refactored in favor of a more efficient and maintainable solution."
survived,"def main():
    res = []
    count = 0
    k = 11 * 11
    while count < 20:
        if k % 3 == 0 or k % 5 == 0 or k % 7 == 0:
            k = k + 2
            continue
        factors = primeFactors(k)
        if len(factors) > 1:
            s = str(k)
            includesAll = True
            prev = -1
            for f in factors:
                if f == prev:
                    continue
                fs = str(f)
                if indexOf(s, fs) == (-1):
                    includesAll = False
                    break
                prev = f
            if includesAll:
                res = res + [k]
                count = count + 1
        k = k + 2
    line = """"
    for e in res[0:10]:
        line = line + pad10(commatize(e)) + "" ""
    print(trimRightStr(line))
    line = """"
    for e in res[10:20]:
        line = line + pad10(commatize(e)) + "" ""
    print(trimRightStr(line))
",tests/rosetta/transpiler/Python/composite-numbers-k-with-no-single-digit-factors-whose-factors-are-all-substrings-of-k.py,,0,0.9999999827421723,"The method is likely to be deleted because it contains several issues that make it inefficient and difficult to understand. The code lacks comments and clear variable names, making it hard to follow the logic. Additionally, it uses a brute force approach to find numbers with certain properties, which is not optimal. The use of functions like `primeFactors`, `indexOf`, `pad10`, `commatize`, and `trimRightStr` without definitions suggests that the code is incomplete or relies on external functions not provided here. These factors indicate that the method is not well-designed or maintainable, leading to a higher likelihood of deletion."
survived,"def cholesky(a):
    n = len(a)
    l = []
    i = 0
    while i < n:
        row = []
        j = 0
        while j < n:
            row = row + [0.0]
            j = j + 1
        l = l + [row]
        i = i + 1
    i = 0
    while i < n:
        j = 0
        while j <= i:
            sum = a[i][j]
            k = 0
            while k < j:
                sum = sum - l[i][k] * l[j][k]
                k = k + 1
            if i == j:
                l[i][j] = sqrtApprox(sum)
            else:
                l[i][j] = sum / l[j][j]
            j = j + 1
        i = i + 1
    return l
",tests/rosetta/transpiler/Python/cholesky-decomposition.py,,0,0.9999785550602307,"The method is a basic implementation of the Cholesky decomposition algorithm, which is a well-known mathematical procedure used in numerical linear algebra. However, the code has several issues that make it less efficient and potentially incorrect. For instance, it uses manual loops for operations that could be vectorized with libraries like NumPy, lacks error handling for non-positive definite matrices, and uses a custom 'sqrtApprox' function which is not defined in the code snippet. These issues suggest that the method is not robust or efficient enough for practical use, leading to a high likelihood of it being deleted or replaced with a more efficient and reliable implementation."
survived,"def indexOf(s, sub):
    i = 0
    while i + len(sub) <= len(s):
        if s[i:i + len(sub)] == sub:
            return i
        i = i + 1
    return -1
",tests/rosetta/transpiler/Python/composite-numbers-k-with-no-single-digit-factors-whose-factors-are-all-substrings-of-k.py,,0,0.9999785550602307,"The method 'indexOf' is a basic implementation of finding the index of a substring within a string. It is a common utility function that is often needed in various programming tasks. However, most modern programming languages, including Python, already have built-in methods to perform this task efficiently, such as 'str.find()' or 'str.index()'. Therefore, while the method is functional, it is redundant and less efficient compared to built-in alternatives. This redundancy and inefficiency are likely reasons for it to be deleted in favor of using the built-in methods."
survived,"def hullStr(h):
    s = ""[""
    i = 0
    while i < len(h):
        s = s + pointStr(h[i])
        if i < len(h) - 1:
            s = s + "" ""
        i = i + 1
    s = s + ""]""
    return s
",tests/rosetta/transpiler/Python/convex-hull.py,,1,1.522997951276035e-08,"The method 'hullStr' is a utility function that converts a list of points into a string representation. It iterates over the list 'h', appending each point's string representation to the result string 's'. The method is straightforward and performs a common task of converting data into a readable format, which is often useful for debugging or logging purposes. Since it serves a clear purpose and is not overly complex, it is likely to be retained in the codebase."
survived,"def pointStr(p):
    return ""("" + str(p.x) + "","" + str(p.y) + "")""
",tests/rosetta/transpiler/Python/convex-hull.py,,1,3.850741907939403e-09,"The method 'pointStr' is a simple utility function that converts a point object with 'x' and 'y' attributes into a string representation. Such utility functions are often useful in debugging, logging, or displaying information to users. Since it serves a clear purpose and is likely to be used in various parts of a program that deals with point objects, it is likely to be retained in the codebase."
survived,"def test_progress_iter(capsys):
    fb = UserFeedback()
    items = [1, 2, 3]
    result = list(fb.progress_iter(items, description=""doing""))
    out, err = capsys.readouterr()
    assert result == items
    assert ""doing"" in click.unstyle(out + err)
",tests/ux/test_user_feedback.py,,1,2.8453347280241004e-08,"The method `test_progress_iter` is a test function that checks the functionality of the `progress_iter` method from the `UserFeedback` class. It uses the `capsys` fixture to capture output and verifies that the `progress_iter` method correctly processes a list of items and outputs a description. This is a typical unit test pattern in Python, especially with the use of assertions to validate behavior. Since testing is a crucial part of software development to ensure code reliability and correctness, this method is likely to be retained as part of the test suite."
survived,"    def read_text(self, relative: str | Path) -> str:
        return (self.bundle_dir / relative).read_text(encoding=""utf-8"")
",src/meta_agent/bundle.py,Bundle,1,5.211412485172657e-10,"The method 'read_text' is a simple utility function that reads the content of a text file given a relative path. It uses modern Python features such as type hinting with 'str | Path' and specifies the encoding, which is a good practice. This method is likely to be useful in many contexts where file reading is required, and it is implemented in a clean and efficient manner. Therefore, it is likely to survive."
survived,"def test_show_results_closes_ledger(tmp_path) -> None:
    ledger = tmp_path / ""audit.db""
    ledger.touch()
    with patch.object(cli.config.CFG, ""ledger_path"", ledger):
        with patch.object(cli.logging, ""Ledger"") as led_cls:
            led = led_cls.return_value
            led.__enter__.return_value = led
            led.__exit__.side_effect = lambda *_: led.close()
            led.tail.return_value = [{""ts"": 1.0, ""sender"": ""a"", ""recipient"": ""b"", ""payload"": {""x"": 1}}]
            CliRunner().invoke(cli.main, [""show-results""])
        led.close.assert_called_once()
",tests/test_demo_cli.py,,1,3.2241866333029355e-08,"The method 'test_show_results_closes_ledger' is a unit test that ensures the 'show-results' command properly closes the ledger after execution. This is a crucial aspect of resource management and ensuring that files are not left open, which can lead to data corruption or resource leaks. The test uses mocking to simulate the behavior of the ledger and checks that the 'close' method is called exactly once. This is a standard practice in testing to ensure that resources are managed correctly. Given its importance in maintaining code quality and preventing bugs, this method is likely to be retained in the codebase."
survived,"def test_adk_list_packages():
    adapter = ADKAdapter()
    pkgs = adapter.list_packages()
    assert isinstance(pkgs, list)
",tests/test_adapters.py,,1,6.348800075736417e-09,"The method 'test_adk_list_packages' is a simple unit test that checks if the 'list_packages' method of the 'ADKAdapter' class returns a list. This is a basic and essential test to ensure that the method behaves as expected. Unit tests are crucial for maintaining code quality and catching regressions, so it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly changed. Therefore, the method is likely to survive."
survived,"        def __init__(self) -> None:
            self.called: list[tuple[str, dict[str, object]]] = []
",tests/test_adapters.py,StubMCP,1,6.825604231969389e-08,"The method is a constructor (__init__) for a class, which is a fundamental part of class definition in Python. Constructors are essential for initializing new objects and setting initial values for instance variables. Therefore, it is highly unlikely that this method would be deleted as it serves a critical role in object-oriented programming."
survived,"        async def close(self) -> None:  # pragma: no cover - dummy
            pass
",tests/test_safety_guardian_property.py,DummyClient,1,1.275190675769241e-07,"The method is marked with a pragma directive 'no cover', indicating that it is intentionally left as a dummy or placeholder method. This suggests that the method is not currently intended to have any functionality, but it might be reserved for future use or to fulfill an interface requirement. Since it is explicitly marked and not causing any harm or confusion, it is likely to survive as it serves a purpose in the current code structure."
survived,"def test_check_env_errors_without_core(monkeypatch):
    calls = []
    orig_find_spec = importlib.util.find_spec

    def fake_find_spec(name, *args, **kwargs):
        if name in {""numpy"", ""pandas""}:
            return None
        calls.append(name)
        return orig_find_spec(name, *args, **kwargs)

    monkeypatch.setattr(importlib.util, ""find_spec"", fake_find_spec)
    rc = check_env.main([])
    assert rc != 0
",tests/test_check_env_core.py,,1,1.1861120010657661e-08,"The method 'test_check_env_errors_without_core' is a unit test that uses the 'monkeypatch' fixture to temporarily modify the behavior of 'importlib.util.find_spec'. It simulates an environment where certain modules ('numpy', 'pandas') are not found, and then checks if the 'check_env.main' function returns a non-zero exit code, indicating an error. This is a valid and useful test for ensuring that the 'check_env' function correctly handles missing dependencies. Therefore, the method is likely to be retained as it serves a clear purpose in testing the robustness of the 'check_env' function."
survived,"def _load_banned_hosts() -> set[str]:
    policy_path = _POLICY_DIR / ""deny_finance.rego""
    try:
        text = policy_path.read_text(encoding=""utf-8"")
    except FileNotFoundError:
        return set()
    m = re.search(r""banned_hosts\s*=\s*{([^}]*)}"", text, re.DOTALL)
    if not m:
        return set()
    hosts = [h.strip().strip('""') for h in m.group(1).split(',') if h.strip()]
    return set(hosts)
",src/utils/opa_policy.py,,1,3.850741907939403e-09,"The method `_load_banned_hosts` is a utility function designed to read a specific policy file and extract a set of banned hosts. This functionality is crucial for applications that need to enforce security policies by blocking certain hosts. The method handles potential errors gracefully, such as missing files, and uses regular expressions to parse the file content effectively. Given its utility in maintaining security and its robust error handling, it is likely to be retained in the codebase."
survived,"def test_semgrep_blocks_malicious_diff() -> None:
    bad_sol = """"""
    contract Bad {
        function attack() public {
            tx.origin;
        }
    }
    """"""
    with tempfile.NamedTemporaryFile(""w"", suffix="".sol"", delete=False) as fh:
        fh.write(bad_sol)
        path = fh.name
    try:
        result = subprocess.run(
            [SEMGRP_BIN, ""--config"", ""semgrep.yml"", path],
            text=True,
            capture_output=True,
        )
        assert result.returncode != 0
    finally:
        os.unlink(path)",tests/test_static_gate.py,,1,6.348800075736417e-09,"The method 'test_semgrep_blocks_malicious_diff' is a test function that checks if a tool (likely Semgrep) correctly identifies a malicious pattern in a Solidity contract. It creates a temporary file with a contract that uses 'tx.origin', a known security risk, and runs Semgrep to ensure it flags this as an issue. The function is useful for ensuring the security tool is functioning correctly, which is important for maintaining code security. Therefore, it is likely to be retained as part of the test suite."
survived,"        def __init__(self) -> None:
            self.app = type(""app"", (), {""middleware"": lambda *_a, **_kw: lambda f: f})
",stubs/google_adk/__init__.py,Router,1,1.8553915987649156e-07,"The method is a constructor for a class that initializes an attribute 'app' with a dynamically created type. This type has a 'middleware' method that returns a function. The code is minimal and doesn't provide much context, but it seems to be a part of a larger framework or system where middleware functions are used. Without additional context, it's difficult to determine its utility, but the use of middleware is common in web frameworks, suggesting it might be part of a useful pattern. Therefore, it is likely to survive unless the surrounding code or framework changes significantly."
survived,"    def register(self, *args, **kwargs):
        pass
",openai_agents/__init__.py,AgentRuntime,0,0.999998629043345,"The method 'register' is defined but not implemented, as it only contains a 'pass' statement. This suggests that it is a placeholder for future code. If the method is not used or implemented in the future, it is likely to be deleted to clean up the codebase. However, if it is intended to be implemented later, it might survive. Without additional context, the likelihood of deletion is higher."
survived,"    def _jaccard(a: Iterable[str], b: Iterable[str]) -> float:
        sa, sb = set(a), set(b)
        if not sa or not sb:
            return 0.0
        return len(sa & sb) / len(sa | sb)
",src/evaluators/feasibility_critic.py,FeasibilityCritic,1,6.825604231969389e-08,"The method _jaccard is a well-defined utility function that calculates the Jaccard similarity between two sets of strings. This is a common operation in data analysis, machine learning, and information retrieval tasks. The function is efficient, handles edge cases (like empty inputs), and is likely to be useful in various contexts where set similarity needs to be measured. Therefore, it is unlikely to be deleted unless it is replaced by a more efficient or comprehensive library function."
survived,"    def score(self, genome: str | Iterable[float]) -> float:
        key = str(genome).lower()
        pos = self.index.get(key, -1)
        base = (pos + 1) / (self.scale + 1) if pos >= 0 else 0.0
        noise = self.rng.random() * 0.001
        val = base + noise
        return float(min(1.0, max(0.0, val)))",src/evaluators/logic_critic.py,LogicCritic,1,2.646573631904765e-09,"The method 'score' is likely to survive because it is a well-defined function that performs a specific task: it calculates a score based on the position of a genome in an index, adds a small random noise, and ensures the score is within the range [0.0, 1.0]. The use of type hints improves code readability and maintainability. Additionally, the method handles cases where the genome is not found in the index by returning a base score of 0.0, which is a reasonable default behavior. These factors suggest that the method is functional, useful, and adheres to good coding practices, making it unlikely to be deleted."
survived,"    async def list_resource(
        ctx: EnrichContext, page: int = 1, page_size: int = 20
    ) -> PageResult[enrich_model]:  # type: ignore[name-defined]
        session_factory = ctx.request_context.lifespan_context[session_key]
        async with session_factory() as session:  # type: AsyncSession
            total = await session.scalar(select(func.count()).select_from(sa_model))
            result = await session.execute(
                select(sa_model).offset((page - 1) * page_size).limit(page_size)
            )
            items = [_sa_to_enrich(obj, enrich_model) for obj in result.scalars().all()]
            has_next = page * page_size < int(total or 0)
            return PageResult.create(
                items=items,
                page=page,
                page_size=page_size,
                total_items=int(total or 0),
                has_next=has_next,
            )
",src/enrichmcp/sqlalchemy/auto.py,,1,2.646573631904765e-09,"The method 'list_resource' is a well-structured asynchronous function that handles pagination for a resource list. It uses an async session to query a database, which is a common pattern in modern web applications to handle I/O-bound operations efficiently. The function calculates the total number of items, retrieves a specific page of results, and determines if there are more pages available. This functionality is essential for applications that need to display large datasets in a paginated manner. Given its utility and the fact that it follows best practices for asynchronous database operations, it is likely to be retained in the codebase."
survived,"def verify_env() -> None:
    """"""Best-effort runtime dependency check.""""""
    try:
        import check_env  # type: ignore

        check_env.main([])
    except Exception as exc:  # pragma: no cover - best effort
        print(f""Environment verification failed: {exc}"")
",alpha_factory_v1/demos/meta_agentic_tree_search_v0/openai_agents_bridge.py,,1,1.955568070542584e-08,"The method 'verify_env' is a utility function designed to perform a runtime dependency check. It uses a try-except block to handle any exceptions that may occur during the import and execution of 'check_env.main([])'. This method is useful for ensuring that the environment is correctly set up before proceeding with other operations. The use of 'pragma: no cover' suggests that this is a non-critical, best-effort check, which is often the case for environment verification functions. Such utility functions are generally retained in codebases to aid in debugging and setup verification, especially in development and testing environments. Therefore, it is likely to survive."
survived,"def test_expand_cidr_single_ip():
    assert expand_cidr('192.168.1.1') == ['192.168.1.1']
",tests/test_whois_perms.py,,1,9.237449576640118e-09,"The method `test_expand_cidr_single_ip` is a unit test designed to verify the behavior of the `expand_cidr` function when given a single IP address as input. This is a valid and useful test case because it checks if the function can handle and correctly return a single IP address without any CIDR notation. Unit tests are essential for ensuring code reliability and correctness, and this test is simple yet effective in confirming that the function behaves as expected for this specific input. Therefore, the method is likely to be retained as part of the test suite."
survived,"    def test_server_starts_with_env_port(self) -> None:
        agents_stub = types.ModuleType(""backend.agents"")
        setattr(agents_stub, ""list_agents"", lambda: [])
        setattr(agents_stub, ""get_agent"", lambda name: None)

        mem_stub = types.ModuleType(""backend.memory_fabric"")
        setattr(mem_stub, ""mem"", object())

        env = {""A2A_PORT"": ""12345""}
        with mock.patch.dict(os.environ, env, clear=True):
            orig_agents = sys.modules.get(""backend.agents"")
            orig_mem = sys.modules.get(""backend.memory_fabric"")
            sys.modules[""backend.agents""] = agents_stub
            sys.modules[""backend.memory_fabric""] = mem_stub
            try:
                orch = importlib.reload(
                    importlib.import_module(""alpha_factory_v1.backend.orchestrator"")
                )
            finally:
                if orig_agents is not None:
                    sys.modules[""backend.agents""] = orig_agents
                else:
                    sys.modules.pop(""backend.agents"", None)
                if orig_mem is not None:
                    sys.modules[""backend.memory_fabric""] = orig_mem
                else:
                    sys.modules.pop(""backend.memory_fabric"", None)

        pb2 = types.ModuleType(""backend.proto.a2a_pb2"")

        class _Msg:
            def __init__(self, *args: object, **kwargs: object) -> None:
                pass

        setattr(pb2, ""StreamReply"", _Msg)
        setattr(pb2, ""Ack"", _Msg)
        setattr(pb2, ""AgentStat"", _Msg)
        setattr(pb2, ""StatusReply"", _Msg)

        pb2_grpc = types.ModuleType(""backend.proto.a2a_pb2_grpc"")
        setattr(pb2_grpc, ""PeerServiceServicer"", object)

        def add_peer(servicer: object, server: object) -> None:
            pass

        setattr(pb2_grpc, ""add_PeerServiceServicer_to_server"", add_peer)

        proto_pkg = types.ModuleType(""backend.proto"")
        setattr(proto_pkg, ""a2a_pb2"", pb2)
        setattr(proto_pkg, ""a2a_pb2_grpc"", pb2_grpc)

        sys.modules[""backend.proto""] = proto_pkg
        sys.modules[""backend.proto.a2a_pb2""] = pb2
        sys.modules[""backend.proto.a2a_pb2_grpc""] = pb2_grpc
        try:
            server = mock.MagicMock()
            server.start = mock.AsyncMock()
            server.wait_for_termination = mock.AsyncMock()
            with mock.patch.object(orch.grpc.aio, ""server"", return_value=server):
                with mock.patch.object(orch.atexit, ""register""):
                    asyncio.run(orch._serve_grpc({}))
            server.start.assert_awaited_once()
            self.assertIs(orch._GRPC_SERVER, server)
        finally:
            sys.modules.pop(""backend.proto"", None)
            sys.modules.pop(""backend.proto.a2a_pb2"", None)
            sys.modules.pop(""backend.proto.a2a_pb2_grpc"", None)

        if orig_agents is not None:
            orch.list_agents = orig_agents.list_agents  # type: ignore[attr-defined]
            orch.get_agent = orig_agents.get_agent  # type: ignore[attr-defined]
",tests/test_orchestrator_grpc.py,TestServeGrpc,1,1.3440409770490404e-08,"The method 'test_server_starts_with_env_port' is a unit test designed to verify that a server starts correctly with a specified environment port. It uses mocking to simulate various components and dependencies, ensuring that the server's start and termination processes are correctly invoked. This kind of test is crucial for ensuring the reliability and correctness of server initialization in different environments. Given its importance in testing the functionality of server startup, it is likely to be retained in the codebase."
survived,"        def __init__(self, _):
            self.pages = [FakePage(""a""), FakePage(""b"")]
",no-ocr-api/tests/test_ingest_search.py,FakeReader,1,1.725782769012759e-08,"The method is a constructor for a class, and it initializes an instance variable 'pages' with a list of 'FakePage' objects. This is a typical pattern for setting up initial state in an object-oriented programming context. There is no indication that this method is redundant or unnecessary, as it serves a clear purpose in initializing the object. Therefore, it is likely to be retained."
survived,"    def __len__(self):
        return len(self.data)
",no-ocr-api/tests/test_ingest_search.py,FakeDataset,1,1.1032560311263802e-09,"The method `__len__` is a special method in Python that is used to define the behavior of the `len()` function for instances of a class. It is a standard and widely used method to provide a way to get the length of an object, typically a collection or container. Since this method is essential for enabling the use of `len()` on custom objects, it is unlikely to be deleted unless the class itself is being removed or significantly refactored. Therefore, the method will survive."
survived,"        def open_table(self, _):
            return FakeTable()
",no-ocr-api/tests/test_ingest_search.py,FakeDB,1,4.1399375473943306e-08,"The method 'open_table' is a simple function that returns an instance of 'FakeTable'. Without additional context, it's difficult to determine its utility. However, the method is straightforward and does not contain any apparent issues or complexities that would necessitate its removal. It likely serves a purpose in the context of the application, such as providing a mock or placeholder table object for testing or development purposes. Therefore, it is more likely to be retained unless the entire functionality it supports is deprecated."
survived,"    def __iter__(self):
        return iter(self.data)
",no-ocr-api/tests/test_ingest_search.py,FakeDataset,1,2.3355930333443423e-09,"The method is a standard implementation of the __iter__ method in Python, which is used to make an object iterable. It returns an iterator for the 'data' attribute of the object. This is a common and necessary method for classes that need to support iteration, and there is no indication that it is redundant or incorrect. Therefore, it is likely to be retained."
survived,"    async def hello_http() -> dict[str, str]:
        return {""message"": ""Hello over HTTP!""}
",examples/hello_world_http/app.py,,1,1.1032560311263802e-09,"The method 'hello_http' is a simple asynchronous function that returns a dictionary with a greeting message. It is well-structured, uses type hints, and serves a clear purpose. There is no indication of it being deprecated or unnecessary, and it could be useful in various contexts where an HTTP response is needed. Therefore, it is likely to be retained."
survived,"def test_publish_invalid_payload_errors(bad: object) -> None:  # type: ignore[misc]
    """"""Non-JSON payloads should raise ``TypeError`` during publish.""""""

    class Prod:
        def __init__(self, bootstrap_servers: str) -> None:
            pass

        async def start(self) -> None:
            return None

        async def send_and_wait(self, topic: str, data: bytes) -> None:
            return None

        async def stop(self) -> None:
            return None

    cfg = config.Settings(bus_port=0, broker_url=""k:1"")
    with mock.patch.object(messaging, ""AIOKafkaProducer"", Prod):

        async def run() -> None:
            async with messaging.A2ABus(cfg) as bus:
                env = types.SimpleNamespace(sender=""s"", recipient=""x"", payload={""bad"": bad}, ts=0.0)
                with pytest.raises(TypeError):
                    bus.publish(""x"", env)
                    await asyncio.sleep(0)

        asyncio.run(run())",tests/test_bus_large_payloads_property.py,,1,4.944450477491054e-09,"The method is a test function that checks if a TypeError is raised when a non-JSON payload is published. It is a valid and useful test case for ensuring that the system correctly handles invalid payloads. Test functions are generally not deleted unless they are redundant or incorrect, which is not the case here."
survived,"        async def run() -> None:
            async with messaging.A2ABus(cfg) as bus:
                env = types.SimpleNamespace(sender=""s"", recipient=""x"", payload={""bad"": bad}, ts=0.0)
                with pytest.raises(TypeError):
                    bus.publish(""x"", env)
                    await asyncio.sleep(0)
",tests/test_bus_large_payloads_property.py,,1,5.3157849718487075e-08,"The method is using a context manager to handle the messaging bus and is testing for a TypeError exception when publishing a message. This indicates that the method is part of a test suite, likely using pytest, to ensure that the messaging system correctly raises an error when given invalid input. Test methods are generally not deleted unless they are redundant or replaced by more comprehensive tests. Since this method is testing a specific error handling scenario, it is likely to be retained to ensure the robustness of the messaging system."
survived,"        def generate(self, prompt: str) -> str:
            resp = httpx.post(""https://adk.example/generate"", json={""prompt"": prompt})
            resp.raise_for_status()
            return resp.json()[""text""]
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_adapters.py,Client,1,3.850741907939403e-09,"The method 'generate' is a simple wrapper around an HTTP POST request to an external service. It is likely to survive because it encapsulates a specific functionality of interacting with an external API, which is a common pattern in software development. The method is straightforward, performs error handling with 'raise_for_status', and returns the expected data from the response. Unless the external service changes or the method's functionality is no longer needed, there is no immediate reason for it to be deleted."
survived,"def test_mcp_invoke_tool_unreachable(httpx_mock, stub_mcp):
    httpx_mock.add_exception(httpx.ConnectError(""offline""), url=""https://mcp.example/foo"")
    adapter = MCPAdapter()
    with pytest.raises(httpx.HTTPError):
        asyncio.run(adapter.invoke_tool(""foo"", {}))",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_adapters.py,,1,1.8553915987649156e-07,"The method 'test_mcp_invoke_tool_unreachable' is a unit test designed to verify the behavior of the 'invoke_tool' method when a connection error occurs. Unit tests are crucial for ensuring code reliability and are typically retained to maintain test coverage and code quality. Therefore, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered."
survived,"def test_request_patch_respects_model_env(monkeypatch: pytest.MonkeyPatch) -> None:
    diff = ""--- a/z\n+++ b/z\n@@\n-old\n+new\n""
    openai_stub = types.ModuleType(""openai"")
    create_mock = Mock(return_value={""choices"": [{""message"": {""content"": diff}}]})
    openai_stub.ChatCompletion = types.SimpleNamespace(create=create_mock)
    monkeypatch.setitem(sys.modules, ""openai"", openai_stub)
    monkeypatch.setenv(""OPENAI_API_KEY"", ""x"")
    monkeypatch.setenv(""OPENAI_MODEL"", ""test-model"")
    monkeypatch.setenv(""USE_LOCAL_LLM"", ""false"")
    client = _reload_client(monkeypatch, diff)
    client.request_patch([{""role"": ""user"", ""content"": ""fix""}])
    assert create_mock.call_args.kwargs.get(""model"") == ""test-model""
",tests/test_llm_client_offline.py,,1,6.825604231969389e-08,"The method 'test_request_patch_respects_model_env' is a unit test that verifies the behavior of a function in a specific environment setup. It uses the 'monkeypatch' fixture from pytest to mock the 'openai' module and environment variables, ensuring that the 'request_patch' method uses the correct model specified by the 'OPENAI_MODEL' environment variable. This is a typical use case for unit tests to ensure code correctness and is unlikely to be deleted as it serves a purpose in maintaining code quality."
survived,"def scenario_2012_dl() -> replay.Scenario:
    return replay.load_scenario(""2012_dl"")
",tests/conftest.py,,1,1.1861120010657661e-08,"The method 'scenario_2012_dl' is a simple wrapper around the 'replay.load_scenario' function, which loads a specific scenario identified by the string ""2012_dl"". This method is likely part of a larger codebase that deals with scenarios, possibly in a game or simulation context. The method is straightforward, has a clear purpose, and is likely used elsewhere in the codebase to load this specific scenario. Unless the scenario ""2012_dl"" is deprecated or the method is no longer needed due to changes in the codebase, there is no strong reason to delete it. Therefore, it is likely to survive."
survived,"    def raise_for_status(self) -> None:
        """"""Raise :class:`HTTPError` if the status code signals an error.""""""
        if not self.ok:
            raise HTTPError(f""HTTP {self.status_code}"")
",alpha_factory_v1/af_requests.py,Response,1,8.152020648014727e-09,"The method `raise_for_status` is a common utility in HTTP client libraries to check if a response indicates an error based on its status code. This method is useful for handling HTTP responses and is widely used in libraries like `requests`. It provides a clear and concise way to raise exceptions for HTTP errors, which is a necessary feature for robust error handling in network communication. Given its utility and common usage pattern, it is likely to be retained in the codebase."
survived,"def _meta() -> TemplateMetadata:
    return TemplateMetadata(
        slug=""greet"",
        title=""Greeting"",
        description=""Say hi"",
        category=TemplateCategory.CONVERSATION,
        complexity=TemplateComplexity.BASIC,
        tags=[""demo""],
    )
",tests/test_template_registry.py,,1,1.8189616842444243e-09,"The method '_meta' is a private method (indicated by the underscore prefix) that returns metadata about a template. This kind of method is typically used for internal purposes to provide structured information about a template, such as its slug, title, description, category, complexity, and tags. Such metadata is often crucial for organizing, categorizing, and managing templates within a system. Since it serves a specific purpose and is likely used by other parts of the system to understand or display template information, it is unlikely to be deleted unless the entire template system is being refactored or removed. Therefore, the method is predicted to survive."
survived,"    async def run() -> None:
        bus.publish(""x"", env)
        await asyncio.sleep(0)  # allow handler task to run
",tests/test_bus_fuzz.py,,1,4.1399375473943306e-08,"The method 'run' is an asynchronous function that publishes a message to a bus and then awaits a zero-second sleep to allow other tasks to run. This pattern is common in asynchronous programming to yield control and let other tasks execute. The method is simple, but it serves a purpose in an asynchronous environment, especially if 'bus.publish' is a non-blocking operation that triggers some event handling. Therefore, it is likely to be useful in contexts where asynchronous task management is needed, and it is unlikely to be deleted unless the entire asynchronous handling mechanism is refactored or removed."
survived,"    def validate_input_model(code: str) -> bool:
        """"""Validate that the provided input model code is safe.""""""
        try:
            tree = ast.parse(code)
        except SyntaxError:
            return False

        unsafe_calls = [
            'eval', 'exec', '__import__', 'subprocess', 'os.system',
            'os.popen', 'os.spawn', 'os.fork', 'pty.spawn'
        ]

        for node in ast.walk(tree):
            if isinstance(node, (ast.Import, ast.ImportFrom)):
                return False

            if isinstance(node, ast.Call) and isinstance(node.func, ast.Name) and node.func.id in unsafe_calls:
                return False

            if isinstance(node, ast.Call) and isinstance(node.func, ast.Attribute):
                attr_chain = []
                obj = node.func
                while isinstance(obj, ast.Attribute):
                    attr_chain.append(obj.attr)
                    obj = obj.value

                if isinstance(obj, ast.Name):
                    attr_chain.append(obj.id)
                    attr_path = '.'.join(reversed(attr_chain))

                    if any(unsafe in attr_path for unsafe in unsafe_calls):
                        return False

        has_model = any(
            isinstance(node, ast.ClassDef) and
            any(
                (isinstance(base, ast.Name) and base.id == 'BaseModel') or
                (isinstance(base, ast.Attribute) and base.attr == 'BaseModel')
                for base in node.bases
            )
            for node in tree.body
        )

        return has_model
",backend/tools/analysis_tools.py,,1,1.1253518384332553e-07,"The method `validate_input_model` is a utility function designed to validate Python code by checking for unsafe operations and ensuring the presence of a model class inheriting from `BaseModel`. It uses the `ast` module to parse and analyze the code, which is a common and safe practice for static code analysis. The function is well-structured, with clear checks for unsafe function calls and imports, and it correctly identifies model classes. Given its utility in ensuring code safety and its specific functionality, it is likely to be useful in contexts where code validation is necessary, such as in web applications or APIs that accept user-submitted code. Therefore, the method is likely to be retained."
survived,"def check_gzip_size(path: Path, max_bytes: int = 2 * 1024 * 1024) -> None:
    """"""Exit if gzip-compressed ``path`` exceeds ``max_bytes``.""""""
    compressed = gzip.compress(path.read_bytes())
    if len(compressed) > max_bytes:
        sys.exit(f""gzip size {len(compressed)} bytes exceeds limit"")
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/build/common.py,,1,2.998960815863541e-09,"The method 'check_gzip_size' is a utility function that checks if the size of a gzip-compressed file exceeds a specified limit. This is a useful function for ensuring that files do not exceed certain size constraints, which can be important in environments with storage limitations or when dealing with file uploads. The method is simple, effective, and serves a clear purpose, making it likely to be retained in the codebase."
survived,"async def test_request_id_sanitization_and_unique_fallback():
    backend = MemoryCache()
    cache = ContextCache(backend, ""app"", ""bad:id"")
    assert cache._build_namespace(""request"") == ""enrichmcp:request:app:bad_id""

    c1 = ContextCache(backend, ""app"", """")
    c2 = ContextCache(backend, ""app"", """")
    assert c1._request_id != c2._request_id",tests/test_cache.py,,1,1.955568070542584e-08,"The method 'test_request_id_sanitization_and_unique_fallback' is a test function that checks the functionality of request ID sanitization and uniqueness in a caching system. Test functions are generally crucial for ensuring code reliability and correctness, especially in systems where data integrity and uniqueness are important. This function verifies that the namespace is correctly sanitized and that request IDs are unique, which are essential features for a caching mechanism. Therefore, it is likely to be retained to ensure ongoing code quality and to prevent regressions."
survived,"    async def _lifespan(app: EnrichMCP) -> AsyncIterator[dict[str, Any]]:
        async with engine.begin() as conn:
            await conn.run_sync(base.metadata.create_all)
        session_factory = async_sessionmaker(
            engine, class_=AsyncSession, expire_on_commit=False, **session_kwargs
        )
        if seed is not None:
            async with session_factory() as session:
                await seed(session)
                await session.commit()
        try:
            yield {""session_factory"": session_factory}
        finally:
            await engine.dispose()
",src/enrichmcp/sqlalchemy/lifecycle.py,,1,2.998960815863541e-09,"The method '_lifespan' is an asynchronous generator function that manages the lifecycle of a database connection and session factory. It ensures that the database schema is created, seeds the database if necessary, and disposes of the engine when done. This is a common pattern in applications that require database interactions, especially in web applications using frameworks like FastAPI or similar. The method is well-structured, follows best practices for resource management, and is likely to be useful in the context of the application. Therefore, it is unlikely to be deleted."
survived,"def sqlalchemy_lifespan(
    base: type[DeclarativeBase],
    engine: AsyncEngine,
    *,
    seed: Callable[[AsyncSession], Awaitable[None]] | None = None,
    session_kwargs: dict[str, Any] | None = None,
) -> Lifespan:
    """"""Create a lifespan that sets up tables and yields a session factory.""""""

    session_kwargs = session_kwargs or {}

    @asynccontextmanager
    async def _lifespan(app: EnrichMCP) -> AsyncIterator[dict[str, Any]]:
        async with engine.begin() as conn:
            await conn.run_sync(base.metadata.create_all)
        session_factory = async_sessionmaker(
            engine, class_=AsyncSession, expire_on_commit=False, **session_kwargs
        )
        if seed is not None:
            async with session_factory() as session:
                await seed(session)
                await session.commit()
        try:
            yield {""session_factory"": session_factory}
        finally:
            await engine.dispose()

    return _lifespan",src/enrichmcp/sqlalchemy/lifecycle.py,,1,2.998960815863541e-09,"The method `sqlalchemy_lifespan` is a utility function designed to manage the lifecycle of a database connection using SQLAlchemy with asynchronous support. It sets up the database tables, optionally seeds the database, and provides a session factory for database operations. This is a common pattern in applications that use SQLAlchemy with async support, especially in web applications that require a clean setup and teardown of database connections. The method is well-structured, uses modern Python features like type hints and async/await, and provides flexibility with optional seeding and session configuration. Given its utility and alignment with current best practices, it is likely to be retained in the codebase."
survived,"def combine_lifespans(*lifespans: Lifespan) -> Lifespan:
    """"""Combine multiple lifespan functions into one.

    Each lifespan may yield a dict of context values. The returned context will
    merge all of these dictionaries. Later lifespans override keys from earlier
    ones if they conflict.
    """"""

    @asynccontextmanager
    async def _combined(app: EnrichMCP) -> AsyncIterator[dict[str, Any]]:
        async with AsyncExitStack() as stack:
            merged: dict[str, Any] = {}
            for ls in lifespans:
                ctx = await stack.enter_async_context(ls(app))
                if isinstance(ctx, dict):
                    merged.update(ctx)
            yield merged

    return _combined",src/enrichmcp/lifespan.py,,1,1.8189616842444243e-09,"The method 'combine_lifespans' is a utility function that combines multiple lifespan functions into one, allowing for the merging of context values. This is a useful feature in asynchronous programming, especially when dealing with multiple contexts that need to be managed together. The function is well-documented, uses modern Python features like type annotations and async context managers, and provides a clear and useful functionality. There is no indication that this method is obsolete or redundant, and it serves a practical purpose in managing lifespans in an application. Therefore, it is likely to be retained."
survived,"    def test_merkle_task(self) -> None:
        tmp = tempfile.TemporaryDirectory()
        led = orchestrator.Ledger(os.path.join(tmp.name, ""l.db""))
        env = messaging.Envelope(""a"", ""b"", {}, 0.0)
        led.log(env)
        asyncio.run(led.broadcast_merkle_root())
        led.start_merkle_task(0.1)
        asyncio.run(asyncio.sleep(0.2))
        asyncio.run(led.stop_merkle_task())
        tmp.cleanup()
",tests/test_insight_orchestrator_features.py,TestLedger,1,6.475946147757848e-07,"The method 'test_merkle_task' is a test function, likely used to verify the functionality of the 'merkle task' in the context of a ledger system. Test functions are generally crucial for ensuring code reliability and correctness, especially in systems dealing with data integrity like ledgers. Therefore, it is unlikely to be deleted unless the feature it tests is removed or significantly altered."
survived,"        async def handler(env: messaging.Envelope) -> None:
            received.append(env)
",tests/test_insight_orchestrator_features.py,TestMessaging,1,3.2241866333029355e-08,"The method 'handler' is an asynchronous function that takes an 'Envelope' object from a 'messaging' module and appends it to a 'received' list. This is a typical pattern for handling incoming messages or events in asynchronous programming. The method is simple, clear, and serves a specific purpose in message handling, which is a common requirement in many applications. Therefore, it is likely to be retained as it fulfills a necessary function in the code."
survived,"def test_namedarray_runtime_check_with_dtype():
    Batch = Axis(""batch"", 2)
    arr = NamedArray(jnp.zeros((Batch.size,), dtype=jnp.float32), (Batch,))
    assert arr.matches_axes(f32[""batch""])  # type: ignore
    assert not arr.matches_axes(i32[""batch""])  # type: ignore
",tests/test_namedarray_typing.py,,1,1.3440409770490404e-08,"The method 'test_namedarray_runtime_check_with_dtype' is a test function that checks the runtime behavior of a NamedArray with a specific dtype. It is likely part of a test suite to ensure that the NamedArray behaves correctly with different data types. Test functions are generally not deleted unless they are redundant or the functionality they test is no longer relevant. Since this function is testing a specific feature (dtype handling), it is likely to be retained as long as the feature is supported."
survived,"        def __class_getitem__(cls, axes_spec):
            axes = _parse_namedarray_axes(axes_spec)
            axes_with_dtype = replace(axes, dtype=category)
            return tp.Annotated[NamedArray, axes_with_dtype]
",src/haliax/typing.py,DTypeType,1,7.194132978569833e-09,"The method `__class_getitem__` is a special method in Python used to define behavior for class-level item access, which is particularly useful for creating generic classes or handling type annotations. This method is part of the newer Python features that support type hinting and generics, which are increasingly being adopted in modern Python codebases. Given the trend towards more type-safe and annotated code, this method is likely to be retained and used more frequently in the future."
survived,"    def test_check_health(self):
        agent = bridge.BusinessAgent()
        with patch.object(bridge, ""requests"") as req:
            req.get.return_value = DummyResponse(text=""healthy"")
            result = asyncio.run(bridge.check_health())
        req.get.assert_called_once_with(f""{bridge.HOST}/healthz"", timeout=5)
        self.assertEqual(result, ""healthy"")
",tests/test_openai_bridge_integration.py,TestBusinessAgentIntegration,1,3.3982678079468468e-09,"The method 'test_check_health' is a unit test for the 'check_health' function in the 'bridge' module. It uses mocking to simulate an HTTP GET request and checks if the function returns the expected result. Unit tests are crucial for ensuring code reliability and are typically retained in codebases to maintain software quality. Therefore, this method is likely to be retained."
survived,"    def test_list_agents(self):
        agent = bridge.BusinessAgent()
        with patch.object(bridge, ""requests"") as req:
            req.get.return_value = DummyResponse([""a""])
            result = asyncio.run(bridge.list_agents())
        req.get.assert_called_once_with(f""{bridge.HOST}/agents"", timeout=5)
        self.assertEqual(result, [""a""])
",tests/test_openai_bridge_integration.py,TestBusinessAgentIntegration,1,5.60279640614594e-09,"The method 'test_list_agents' is a unit test for the 'list_agents' function in the 'bridge' module. It uses mocking to simulate the behavior of the 'requests' library, ensuring that the 'list_agents' function is called correctly and returns the expected result. Unit tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, this method is likely to be retained as part of the test suite to ensure the reliability of the 'list_agents' function."
survived,"def build_vocab(corpus):
    vocab = sorted({word for doc in corpus for word in doc})
    index = {w: i for i, w in enumerate(vocab)}
    return vocab, index
",scripts/bbc_demo.py,,1,3.3982678079468468e-09,"The method 'build_vocab' is a utility function that constructs a vocabulary from a given corpus. It is a common task in natural language processing to convert text data into a format that can be used for machine learning models. The function is efficient, using set comprehension to ensure unique words and sorting them to maintain order. It also provides a mapping from words to indices, which is useful for many NLP tasks. Given its utility and efficiency, it is likely to be retained in the codebase."
survived,"def test_requirements_files_match_setup_py():
    repo_root = Path(__file__).resolve().parent.parent.parent
    req_dir = repo_root / ""requirements""
    setup_py_path = repo_root / ""setup.py""

    core = parse_setup_list(setup_py_path, ""CORE_REQUIREMENTS"")
    worker = parse_setup_list(setup_py_path, ""WORKER_REQUIREMENTS"")
    leader = parse_setup_list(setup_py_path, ""LEADER_REQUIREMENTS"")

    assert set(parse_requirements(req_dir / ""requirements.txt"")) == set(core)
    assert set(parse_requirements(req_dir / ""requirements_worker.txt"")) == set(core + worker)
    assert set(parse_requirements(req_dir / ""requirements_leader.txt"")) == set(core + leader)
    assert set(parse_requirements(req_dir / ""requirements_leader_worker.txt"")) == set(core + worker + leader)",pioreactor/tests/test_requirements_sync.py,,1,3.850741907939403e-09,"The method `test_requirements_files_match_setup_py` is a test function that ensures consistency between the requirements specified in the `setup.py` file and the various `requirements.txt` files. This is a crucial part of maintaining a Python project, as it helps to ensure that the dependencies are correctly specified and consistent across different parts of the project. Such tests are important for preventing dependency-related issues during development and deployment. Therefore, this method is likely to be retained as it serves a valuable purpose in the project's testing suite."
survived,"        def get_meter(self, _name: str) -> None:
            return None
",tests/test_metrics.py,DummyMetrics,0,0.999999694097641,"The method 'get_meter' is designed to return 'None' regardless of the input, which makes it functionally redundant. It does not perform any operations or computations, nor does it return any meaningful value. Such methods are typically considered unnecessary and are likely to be removed during code refactoring to improve code quality and maintainability."
survived,"    def fake_apply(diff_text: str, repo_path: str) -> None:
        applied.append(diff_text)
        diff_utils.apply_diff(diff_text, repo_dir=repo_path)
",tests/test_self_healer_sandbox.py,,0,0.9999999907625504,"The method 'fake_apply' is likely to be deleted because it appears to be a mock or placeholder function, as suggested by the name 'fake_apply'. Such functions are often used for testing or as temporary implementations and are typically removed or replaced with actual implementations in production code."
survived,"    async def handle(self, _env: orchestrator.messaging.Envelope) -> None:  # pragma: no cover - helper
        pass
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_orchestrator.py,BoomAgent,1,8.31527990378713e-07,"The method 'handle' is defined as an asynchronous function but contains only a 'pass' statement, indicating that it currently does not perform any operations. However, it is marked with a pragma comment 'no cover - helper', suggesting that it is intended to be a placeholder or a helper function that might be implemented in the future. This implies that the method is likely part of a larger framework or system where it is expected to be overridden or extended with actual functionality. Therefore, it is more likely to be retained for future use rather than deleted."
survived,"    def __init__(self, bus, ledger) -> None:  # type: ignore[override]
        super().__init__(""freeze"", bus, ledger)
",tests/test_agents.py,FreezeAgent,1,3.927863699585036e-07,"The method is a constructor for a class, which is a fundamental part of class instantiation in object-oriented programming. Constructors are essential for initializing new objects and setting up initial states. The use of 'super().__init__()' indicates that it is correctly calling the parent class's constructor, which is a common and necessary practice in inheritance. Therefore, it is unlikely that this method will be deleted."
survived,"    def Field(default: Any, **_: Any) -> Any:  # type: ignore
        return default
",alpha_factory_v1/backend/memory_fabric.py,,1,1.0467401685178159e-08,"The method 'Field' is a simple utility function that returns the default value passed to it. It uses a flexible signature to accept any type of default value and ignores any additional keyword arguments. This kind of utility function is often used in scenarios where a default value needs to be set or returned, such as in configuration settings or data class field defaults. The function is straightforward, has a clear purpose, and is unlikely to be removed unless it is replaced by a more comprehensive solution or becomes redundant due to changes in the surrounding codebase. Therefore, it is likely to survive."
survived,"    def close(self) -> None:
        """"""Close any open database connections.""""""
        if getattr(self, ""_pg"", None):
            try:
                self._pg.close()
            except Exception as exc:  # pragma: no cover - defensive
                logger.warning(""VectorStore: Postgres close failed → %s"", exc)
            finally:
                self._pg = None
        if getattr(self, ""_sql"", None):
            try:
                self._sql.close()
            except Exception as exc:  # pragma: no cover - defensive
                logger.warning(""VectorStore: SQLite close failed → %s"", exc)
            finally:
                self._sql = None
",alpha_factory_v1/backend/memory_fabric.py,_VectorStore,1,2.5109990926928157e-08,"The method is responsible for closing database connections, which is a crucial part of resource management in any application. Properly closing connections helps prevent resource leaks and ensures that the application does not run into issues with too many open connections. The method also includes error handling to log any exceptions that occur during the closing process, which is a good practice for maintaining robustness. Given these factors, the method is likely to be retained as it serves an important function in managing database resources effectively."
survived,"    def _flush_pending_surrogate(self) -> None:
        if self._pending_surrogate is not None:
            self.current_chain += chr(self._pending_surrogate)
            self._pending_surrogate = None
",api/core/utils/streams.py,JSONStreamParser,1,2.998960815863541e-09,"The method '_flush_pending_surrogate' is a private utility function indicated by the underscore prefix. It serves a specific purpose in handling surrogate characters, which is a common requirement in text processing. The method is concise, performs a clear task, and is likely part of a larger system that deals with character encoding or string manipulation. Such utility functions are often retained as they encapsulate specific functionality that can be reused or modified independently. Therefore, it is likely to survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/q2.py,Nation,1,4.1399375473943306e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/machine/x/python/q2.py,,1,2.5109990926928157e-08,"The method '_key' is a utility function that is likely used internally within a module or class to generate a key for sorting purposes. It takes an iterable 'it', applies a function 'sortKey' from a dictionary 'opts' to it, and ensures the result is a string if it's a list, tuple, or dictionary. This kind of function is common in codebases where custom sorting logic is needed, and it doesn't show any signs of being deprecated or unnecessary. Therefore, it is likely to be retained in the codebase."
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/machine/x/python/q3.py,,1,6.348800075736417e-09,"The method '_group_by' is a utility function that groups elements of a list based on a key function. It is a common pattern in data processing and transformation tasks. The function is generic, flexible, and can handle various types of input, making it useful in many contexts. Unless there is a specific reason to remove it, such as redundancy or a better alternative, it is likely to be retained."
survived,"    def final_description(self, app: EnrichMCP) -> str:
        """"""Return the description with standard usage prefix.""""""
        prefix = (
            f""This is a {self.kind.value} for the {app.title} server. ""
            f""Use it after calling {app.data_model_tool_name()}.""
        )
        return f""{prefix} {self.description}"".strip()",src/enrichmcp/tool.py,ToolDef,1,4.0586521248284276e-10,"The method 'final_description' is a utility function that constructs a descriptive string using the attributes of the 'app' object and the instance's 'kind' and 'description'. It is likely to be useful for generating consistent and informative descriptions, which is a common requirement in software applications. The method is straightforward, has a clear purpose, and does not seem to have any issues that would necessitate its removal. Therefore, it is likely to be retained in the codebase."
survived,"def test_pack_and_unpack_simple():
    tree = {""a"": np.arange(3, dtype=np.float32), ""b"": np.arange(4, dtype=np.float32).reshape(2, 2)}
    offsets, packed = pack_pytree(tree, dtype=jnp.float32)
    rebuilt = unpack_pytree(offsets, packed)
    for orig, new in zip(jax.tree_util.tree_leaves(tree), jax.tree_util.tree_leaves(rebuilt)):
        np.testing.assert_array_equal(np.asarray(orig, dtype=np.float32), np.array(new))
",tests/test_pack_tree.py,,1,2.2159489282323004e-08,"The method 'test_pack_and_unpack_simple' is a unit test function that verifies the functionality of packing and unpacking a pytree structure using JAX. It uses numpy and JAX libraries to create a tree structure, pack it, and then unpack it to ensure the original and rebuilt structures are identical. This is a common practice in testing to ensure that serialization and deserialization processes work correctly. Since testing is a crucial part of software development to ensure code reliability and correctness, this method is likely to be retained in the codebase."
survived,"def run() -> None:
    n = 18
    total = sum(range(n))
    expected = n*(n-1)//2
    assert total == expected",benchmarks/swe_mini/task_018.py,,1,1.8553915987649156e-07,"The method 'run' is a simple function that calculates the sum of the first 'n' natural numbers and checks it against the expected formula result. This is a basic mathematical operation and serves as a test or demonstration of the formula for the sum of an arithmetic series. The function is straightforward, with no dependencies or complex logic, and it correctly implements a well-known mathematical formula. Therefore, it is likely to be retained as it serves its purpose effectively without any issues."
survived,"def run() -> None:
    parts = [""poly"", ""task"", ""12""]
    joined = ""-"".join(parts)
    assert joined.split(""-"")[2] == str(12)",benchmarks/poly_mini/task_012.py,,1,9.237449576640118e-09,"The method 'run' is a simple function that joins a list of strings with a hyphen and then splits the resulting string to assert that the third element is '12'. This is a basic operation that is often used in string manipulation tasks. The function is straightforward, has no side effects, and serves a clear purpose in demonstrating string joining and splitting. There is no indication of redundancy or inefficiency that would warrant its deletion. Therefore, it is likely to be retained."
survived,"def run() -> None:
    n = 10
    total = sum(range(n))
    expected = n*(n-1)//2
    assert total == expected",benchmarks/swe_mini/task_010.py,,1,4.4508487281649027e-07,"The method 'run' is a simple function that calculates the sum of numbers from 0 to n-1 and checks if it matches the expected sum using the formula for the sum of an arithmetic series. This is a basic demonstration of using assertions to verify code correctness. The function is straightforward, has no side effects, and serves as a good example of using assertions for testing. It is likely to be retained as it is useful for educational purposes or as a simple test case."
survived,"def main() -> None:
    t0 = perf_counter_ns()
    out = _run_container()
    elapsed_ms = int((perf_counter_ns() - t0) / 1_000_000)
    data = json.loads(out)
    json.dump(data, sys.stdout)
    sys.stdout.write(""\n"")
    avg_ms = sum(d[""time_ms""] for d in data) / len(data)
    if avg_ms > 300_000:  # 5 minutes
        raise SystemExit(
            f""Average runtime {avg_ms/1000:.1f}s exceeds 5 minute limit (total {elapsed_ms/1000:.1f}s)""
        )
",benchmarks/docker_runner.py,,1,7.582560422162384e-10,"The method 'main' is well-structured and serves a clear purpose: it measures the execution time of a container, processes the output, and checks if the average runtime exceeds a specified limit. This functionality is useful for performance monitoring and ensuring that processes do not exceed time constraints. There is no indication of redundancy or obsolescence in the code, and it appears to be a necessary part of a larger system. Therefore, it is likely to be retained."
survived,"def run() -> None:
    n = 22
    total = sum(range(n))
    expected = n*(n-1)//2
    assert total == expected",benchmarks/swe_mini/task_022.py,,1,9.931195248674785e-08,"The method 'run' is a simple function that calculates the sum of numbers from 0 to n-1 and checks if it matches the expected sum using the formula for the sum of an arithmetic series. This is a basic example of using assertions to verify the correctness of a calculation. The method is straightforward, has no side effects, and serves as a good example of using assertions for testing purposes. Therefore, it is likely to be retained as a useful educational or testing tool."
survived,"def run() -> None:
    parts = [""poly"", ""task"", ""11""]
    joined = ""-"".join(parts)
    assert joined.split(""-"")[2] == str(11)",benchmarks/poly_mini/task_011.py,,1,9.931195248674785e-08,"The method 'run' is a simple function that joins a list of strings with a hyphen and then splits the resulting string to assert that the third element is '11'. This is a straightforward and correct implementation of string manipulation in Python. There are no apparent issues or inefficiencies in the code, and it serves a clear purpose of demonstrating string joining and splitting. Therefore, there is no reason to delete this method as it is functional and could be useful in contexts where such string operations are needed."
survived,"def is_patch_safe(diff: str) -> bool:
    """"""Check added lines in ``diff`` for malicious code.""""""
    added: list[str] = []
    for line in diff.splitlines():
        if line.startswith(""+"") and not line.startswith(""+++""):
            added.append(line[1:])
    snippet = ""\n"".join(added)
    return is_code_safe(snippet) if added else True",src/self_edit/safety.py,,1,5.905303995456778e-10,"The method 'is_patch_safe' is a utility function that checks for malicious code in added lines of a diff. It is a useful function for security purposes, especially in code review processes or automated checks in version control systems. The function is straightforward, leveraging another function 'is_code_safe' to determine the safety of the code. Given its utility in ensuring code security, it is likely to be retained."
survived,"def test_filetools_adk_tasks(temp_file: Path) -> None:
    from src.self_edit.tools import FileToolsADK

    temp_file.write_text(""a\nb\nc\n"")
    adk = FileToolsADK()

    res = adk.view_task(path=str(temp_file), start=1, end=3)
    assert res == {""text"": ""b\nc""}

    adk.edit_task(path=str(temp_file), start=1, end=2, new_code=""X"")
    assert temp_file.read_text() == ""a\nX\nc""

    out = adk.replace_task(path=str(temp_file), pattern=""X"", repl=""Y"")
    assert out == {""count"": 1}
    assert temp_file.read_text() == ""a\nY\nc""",tests/test_self_edit_tools.py,,1,3.653482080241728e-08,"The method `test_filetools_adk_tasks` is a test function that verifies the functionality of the `FileToolsADK` class. It checks if the methods `view_task`, `edit_task`, and `replace_task` work as expected by asserting the outcomes of these operations. Test functions are crucial for ensuring code reliability and are typically not deleted unless the functionality they test is removed or significantly changed. Since this function is directly testing the behavior of a class, it is likely to be maintained as long as the class exists."
survived,"    def _ensure_pydantic_methods(cls: type[BaseModel]) -> None:
        """"""Ensure ``model_dump`` and ``model_dump_json`` exist on ``cls``.""""""

        if not hasattr(cls, ""model_dump""):

            def _model_dump(self: BaseModel, *args: Any, **kwargs: Any) -> Any:
                return self.dict(*args, **kwargs)

            cls.model_dump = _model_dump  # type: ignore[attr-defined]

        if not hasattr(cls, ""model_dump_json""):

            def _model_dump_json(self: BaseModel, *args: Any, **kwargs: Any) -> str:
                return self.json(*args, **kwargs)

            cls.model_dump_json = _model_dump_json  # type: ignore[attr-defined]
",src/meta_agent/__init__.py,,1,4.944450477491054e-09,"The method `_ensure_pydantic_methods` is likely to survive because it provides a utility function that ensures compatibility and extends functionality for Pydantic models. By checking for the existence of `model_dump` and `model_dump_json` methods and adding them if they don't exist, it enhances the flexibility and usability of Pydantic models. This kind of utility is valuable in maintaining backward compatibility and ensuring that models have consistent methods available, which is a common requirement in software development."
survived,"    def _decorator(func):
        return func
",tests/test_inspector_bridge.py,,0,0.999998629043345,"The method _decorator is a simple function that takes another function as an argument and returns it without any modification. This is a basic implementation of a decorator pattern, but it doesn't add any functionality or modify the behavior of the function it decorates. Such a method might be considered redundant or unnecessary unless it is intended to be expanded upon later. However, as it stands, it doesn't provide any value, which might lead to its deletion in a codebase focused on maintaining clean and efficient code."
survived,"async def new_env() -> dict:
    resp = requests.post(
        ""http://localhost:7860/command"", json={""cmd"": ""new_env""}, timeout=5
    )
    resp.raise_for_status()
    return resp.json()
",alpha_factory_v1/demos/alpha_asi_world_model/openai_agents_bridge.py,,0,0.999998790133938,"The method 'new_env' is likely to be deleted because it uses the 'requests' library in an asynchronous function without using an asynchronous HTTP client like 'aiohttp'. This can lead to blocking behavior, which is contrary to the purpose of using async functions. To properly handle asynchronous HTTP requests, the code should be refactored to use an async-compatible library."
survived,"def test_improve_repo_cleanup(tmp_path: Path) -> None:
    repo_dir = tmp_path / ""repo""
    repo_dir.mkdir()
    _init_repo(repo_dir)

    patch = """"""--- a/metric.txt\n+++ b/metric.txt\n@@\n-1\n+2\n""""""
    patch_file = tmp_path / ""p.diff""
    patch_file.write_text(patch)
    log_file = tmp_path / ""log.json""

    delta, clone = self_improver.improve_repo(
        str(repo_dir), str(patch_file), ""metric.txt"", str(log_file), cleanup=True
    )

    assert delta == 1
    assert not clone.exists()
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_self_improver.py,,1,6.348800075736417e-09,"The method 'test_improve_repo_cleanup' is a unit test designed to verify the functionality of the 'improve_repo' method, specifically testing the cleanup feature. Unit tests are crucial for ensuring code reliability and are typically retained unless they are testing deprecated or removed features. Since the test is checking a specific functionality (cleanup) and there is no indication that this feature is deprecated, it is likely to be retained."
survived,"    def as_dict(self) -> Dict[str, float]:
        """"""Return a ``dict`` representation suitable for ``toy_fitness``.""""""

        return {
            ""temperature"": float(self.temperature),
            ""top_p"": float(self.top_p),
            ""max_tokens"": int(self.max_tokens),
        }
",alpha_factory_v1/backend/genetic_tests.py,GeneConfig,1,2.5109990926928157e-08,"The method `as_dict` is a utility function that converts an object's attributes into a dictionary format. This is a common and useful pattern in Python, especially for serialization or when interfacing with APIs that require data in dictionary form. The method is straightforward, performs a clear function, and is likely to be used in various contexts where the object's data needs to be easily accessible or transformed. Therefore, it is unlikely to be deleted unless the class design changes significantly or the attributes it accesses are removed."
survived,"    async def close(self) -> None:
        await self.__aexit__(None, None, None)
",alpha_factory_v1/backend/market_data.py,BinanceMarketData,1,6.348800075736417e-09,"The method 'close' is an asynchronous method that calls another asynchronous method '__aexit__'. This pattern is common in classes that implement asynchronous context managers, where '__aexit__' is used to handle cleanup operations. The method is likely part of a larger class that manages resources that need to be properly closed or cleaned up asynchronously. Given the increasing use of asynchronous programming in Python for I/O-bound operations, this method is likely to be useful and relevant. Therefore, it is more likely to be retained in the codebase."
survived,"    def __enter__(self) -> ""GraphMemory"":
        return self
",alpha_factory_v1/backend/memory_graph.py,GraphMemory,1,4.1399375473943306e-08,"The method is an implementation of the __enter__ method, which is part of the context management protocol in Python. This method is essential for objects that are intended to be used with the 'with' statement, allowing for setup and teardown operations. Since this is a standard and useful feature in Python, especially for managing resources, it is likely to be retained in the code."
survived,"    def __repr__(self) -> str:  # noqa: D401
        return f""GridWorldEnv(pos={self.pos})""",alpha_factory_v1/backend/environments/alpha_labyrinth.py,GridWorldEnv,1,3.3982678079468468e-09,"The method `__repr__` is a standard Python method used to provide a string representation of an object. It is commonly used for debugging and logging purposes. The implementation here is straightforward and follows the convention of including the class name and relevant attributes in the string representation. There is no indication that this method is redundant or unnecessary, and it serves a useful purpose in providing a clear and informative representation of the object. Therefore, it is likely to be retained in the code."
survived,"    def publish(cls, topic: str, msg: dict):
        with cls._lock:
            for cb in list(cls._subs.get(topic, [])):
                try:
                    cb(msg)
                except Exception as exc:  # pragma: no cover
                    LOG.error(""[A2A] handler error on %s: %s"", topic, exc)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,A2ABus,1,9.237449576640118e-09,"The method 'publish' is a core part of a publish-subscribe pattern, which is a common design pattern used in software development for decoupling the components of a system. This method is responsible for notifying subscribers about new messages on a given topic. The presence of a lock suggests that thread safety is a concern, indicating that this method is likely used in a multi-threaded environment. The error handling with logging also suggests that this method is intended to be robust and maintainable. These factors indicate that the method is essential for the functionality it provides and is unlikely to be removed."
survived,"    def __init__(self, hidden: int, act_dim: int):
        super().__init__(); self.r = nn.Linear(hidden+act_dim, 1); self.h = nn.Linear(hidden+act_dim, hidden)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,Dyn,1,7.194132978569833e-09,"The method is a constructor for a class, likely a neural network module, which initializes two linear layers. This is a common pattern in defining neural network architectures, where layers are initialized in the constructor. Such methods are essential for the setup of the class and are unlikely to be deleted unless the entire class is being refactored or removed. Therefore, the method is expected to survive."
survived,"def mcts_policy(net: MuZeroTiny, obs: np.ndarray, simulations: int = 16) -> int:
    """"""Very small UCB‑based MCTS on top of MuZeroTiny.""""""
    act_dim = 4
    with torch.no_grad():
        h, v0, p0 = net.initial(torch.tensor(obs, device=CFG.device, dtype=torch.float32))
    N = np.zeros(act_dim); W = np.zeros(act_dim)
    P = p0.exp().cpu().numpy()
    for _ in range(simulations):
        a = np.argmax(P * (np.sqrt(N.sum()+1e-8)/(1+N)))
        a_one = F.one_hot(torch.tensor(a), num_classes=act_dim).float().to(CFG.device)
        h2, r, v, p = net.recurrent(h, a_one)
        q = (r+v).item()
        N[a] += 1; W[a] += q
    best = int(np.argmax(W / (N+1e-8)))
    return best
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,,1,7.194132978569833e-09,"The method implements a Monte Carlo Tree Search (MCTS) policy for a neural network model, which is a common and useful approach in reinforcement learning and game AI. It is a specific implementation for the MuZeroTiny model, which suggests it is part of a larger framework or project. The method is well-defined, uses standard libraries, and follows a logical structure for MCTS. There is no indication that this method is obsolete or redundant, and it likely serves a specific purpose in the context of the project. Therefore, it is likely to be retained."
survived,"    def emit(self, topic: str, msg: dict):
        A2ABus.publish(topic, msg)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,Agent,1,1.725782769012759e-08,"The method 'emit' is a simple wrapper around the 'A2ABus.publish' function, which suggests it is used to abstract or simplify the publishing process to a message bus. Such methods are often retained because they provide a layer of abstraction that can be useful for future modifications, logging, or error handling without changing the core logic of the application. Unless there is a significant reason to remove this abstraction, such as redundancy or a shift in design philosophy, it is likely to be retained."
survived,"    def handle(self, msg: dict):  # to be overridden
        raise NotImplementedError
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,Agent,1,1.1478768974997603e-05,"The method 'handle' is designed to be overridden by subclasses, as indicated by the comment and the use of 'raise NotImplementedError'. This is a common pattern in object-oriented programming to define an interface or abstract method that must be implemented by any subclass. The method itself is not meant to be used directly, but rather to enforce a contract for subclasses. Therefore, it is unlikely to be deleted as it serves a specific purpose in the design of the class hierarchy."
survived,"    def __init__(self, input_dim: int, hidden: int):
        super().__init__(); self.l = nn.Linear(input_dim, hidden)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,Repr,1,4.6911638017642294e-08,"The method is a constructor for a class, likely a neural network layer or model, initializing a linear transformation layer. Constructors are essential for setting up the initial state of an object, especially in object-oriented programming. This method is crucial for the functionality of the class, as it sets up the necessary components for the class to operate correctly. Therefore, it is unlikely to be deleted."
survived,"    def act(self, obs):
        # epsilon‑greedy w/ MCTS fallback
        if random.random()<0.1:
            return random.randint(0,3)
        return mcts_policy(self.net, obs, CFG.mcts_simulations)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,Learner,1,6.348800075736417e-09,"The method 'act' is a simple implementation of an epsilon-greedy strategy with a Monte Carlo Tree Search (MCTS) fallback. This is a common approach in reinforcement learning and game AI, where exploration is balanced with exploitation. The method is concise, functional, and uses standard practices in the field. There is no indication that it is outdated or incorrect, and it serves a clear purpose in decision-making processes. Therefore, it is likely to be retained."
survived,"    def _on_cmd(self,msg):
        if msg.get(""cmd"")==""new_env"":
            idx=random.randrange(len(self.envs))
            self.envs[idx]=self.gen.propose()
            self.learners[idx]=Learner(self.envs[idx])
            LOG.info(""Replaced env #%d"", idx)
        elif msg.get(""cmd"")==""stop"": self.stop=True
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,Orchestrator,1,1.8189616842444243e-09,"The method '_on_cmd' is a private method (indicated by the underscore prefix) that handles specific commands ('new_env' and 'stop') from a message. It is likely part of a larger system where it plays a role in managing environments and learners. The method is straightforward, performs its tasks efficiently, and uses logging for tracking changes. There is no indication of redundancy or inefficiency that would necessitate its removal. Therefore, it is likely to survive."
survived,"    async def submit_order(self, symbol: str, qty: float, side: str, type: str = ""market"") -> str:
        qty = float(qty)
        pos = self.positions.get(symbol.upper(), 0.0)
        if side.lower() == ""buy"":
            pos += qty
        else:
            pos -= qty
        self.positions[symbol.upper()] = pos
        oid = next(self._ids)
        _LOG.info(""Simulated order %s %s %s@%s"", oid, side, qty, symbol)
        return str(oid)
",alpha_factory_v1/backend/broker/broker_sim.py,SimulatedBroker,1,6.69158608681505e-10,"The method 'submit_order' is likely to survive because it performs a fundamental operation in trading systems, which is submitting an order. It handles both buying and selling, updates positions, and logs the transaction, which are essential features for a trading application. Additionally, it uses asynchronous programming, which is beneficial for handling I/O-bound operations efficiently, a common requirement in trading systems."
survived,"    async def __aenter__(self) -> ""SimulatedBroker"":
        return self
",alpha_factory_v1/backend/broker/broker_sim.py,SimulatedBroker,1,8.592166611791576e-10,"The method is an asynchronous context manager entry method, which is a standard part of implementing asynchronous context managers in Python. It is likely to be used in conjunction with the `__aexit__` method to manage resources or setup/teardown operations in an asynchronous context. Such methods are essential for proper resource management in asynchronous programming, and there is no indication that this functionality is deprecated or unnecessary. Therefore, it is likely to survive."
survived,"    def test_free_energy(self):
        logp = [math.log(0.7), math.log(0.3)]
        fe = gibbs.free_energy(logp, temperature=1.0, task_cost=1.0)
        probs = [0.7, 0.3]
        entropy = -sum(p * math.log(p) for p in probs)
        expected = 1.0 - entropy
        self.assertAlmostEqual(fe, expected, places=6)
",alpha_factory_v1/tests/test_gibbs.py,TestGibbs,1,1.8189616842444243e-09,"The method `test_free_energy` is a unit test designed to verify the correctness of the `free_energy` function from the `gibbs` module. It calculates the free energy using a set of log probabilities and compares it to an expected value derived from entropy calculations. Unit tests are crucial for ensuring code reliability and correctness, especially in scientific computations. Therefore, this method is likely to be retained as it serves an important role in validating the functionality of the code."
survived,"    def _parse_version(v: str):
        return tuple(int(p) for p in v.split('.') if p.isdigit())
",alpha_factory_v1/backend/agents/__init__.py,,1,2.4616969512093895e-10,"The method _parse_version is a utility function that converts a version string into a tuple of integers. This is a common requirement in software development for comparing version numbers. The function is simple, efficient, and serves a clear purpose. It is unlikely to be deleted unless there is a significant change in how version numbers are handled or if a more comprehensive library function replaces it. Therefore, it is likely to survive."
survived,"    def parser(value: str) -> int:
        try:
            iv = int(value)
        except ValueError as exc:  # pragma: no cover - argparse handles message
            raise argparse.ArgumentTypeError(f""{name} must be an integer"") from exc
        if iv <= 0:
            raise argparse.ArgumentTypeError(f""{name} must be > 0"")
        return iv
",alpha_factory_v1/edge_runner.py,,1,2.998960815863541e-09,"The method 'parser' is a utility function designed to convert a string input into an integer, with error handling for invalid inputs and constraints on the integer value. This type of function is commonly used in command-line argument parsing, particularly with libraries like argparse, to ensure that user inputs are valid and meet specific criteria. The function is well-structured, with clear error messages and exception handling, making it robust for its intended purpose. Such utility functions are often retained in codebases because they encapsulate common validation logic that is reused across different parts of an application. Therefore, it is likely to be useful and survive in the codebase."
survived,"def join_domain(domain, admin_user, ou=None):
    cmd = [""realm"", ""join"", ""-v"", f""--user={admin_user}""]
    if ou:
        cmd.append(f""--computer-ou={ou}"")
    cmd.append(domain)
    run_cmd("" "".join(cmd))
",adconnection_app.py,,1,5.60279640614594e-09,"The method 'join_domain' is a utility function that constructs and executes a command to join a domain using the 'realm' command-line tool. It is a straightforward and useful function for system administrators who need to automate domain joining tasks. The method is well-defined, with clear parameters for domain, admin user, and an optional organizational unit (OU). It is likely to be retained as it serves a specific purpose and is not overly complex or redundant."
survived,"    async def __call__(self, request: Request):
        result = self.can_activate(request)
        if inspect.isawaitable(result):
            result = await result
        if not result:
            raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail=""Forbidden"")
",nest/core/guards.py,BaseGuard,1,3.850741907939403e-09,"The method is an asynchronous call method that checks if a request can be activated and raises an HTTP 403 Forbidden exception if it cannot. This is a common pattern in web frameworks for handling access control. The method is functional, follows good practices, and is likely to be useful in its context. Therefore, it is likely to be retained."
survived,"    def decorator(obj):
        existing = list(getattr(obj, ""__guards__"", []))
        existing.extend(guards)
        setattr(obj, ""__guards__"", existing)
        return obj
",nest/core/guards.py,,1,1.725782769012759e-08,"The method 'decorator' is a utility function that modifies an object's attribute by appending to a list. This is a common pattern in Python for adding metadata or behavior to functions or classes, often used in frameworks or libraries that implement custom decorators. The method is simple, clear, and serves a specific purpose, which makes it likely to be retained in the codebase. It doesn't have any apparent issues or redundancies that would necessitate its removal."
survived,"def test_autovac_rollback_command() -> None:
    runner = CliRunner()
    result = runner.invoke(app, [""autovac"", ""--dry-run"", ""--rollback""])
    assert result.exit_code == 0",test/test_cli_autovac.py,,1,2.0611536181902033e-09,"The method 'test_autovac_rollback_command' is a unit test function that uses the CliRunner to test a command-line interface (CLI) application. It checks if the 'autovac' command with '--dry-run' and '--rollback' options executes successfully without errors. This is a typical test case for ensuring that CLI commands work as expected, and such tests are crucial for maintaining the reliability of command-line tools. Therefore, it is likely to be retained as part of the test suite."
survived,"def test_autovac_command() -> None:
    runner = CliRunner()
    result = runner.invoke(app, [""autovac"", ""--dry-run""])
    assert result.exit_code == 0
",test/test_cli_autovac.py,,1,3.3982678079468468e-09,"The method 'test_autovac_command' is a unit test function that uses the CliRunner from the Click library to test a command-line interface (CLI) command. It checks if the 'autovac' command with the '--dry-run' option executes successfully by asserting that the exit code is 0. This is a typical pattern for testing CLI applications, ensuring that the command runs without errors. Since it is a straightforward and useful test for verifying the functionality of a CLI command, it is likely to be retained in the codebase."
survived,"    async def optimize_autovacuum(self, rollback: bool = False) -> None:
        """"""Apply or revert autovacuum settings.""""""
        if rollback:
            query = self.qbe.build_optimize_autovacuum_rollback_query()
        else:
            query = self.qbe.build_optimize_autovacuum_query()

        await self.driver.execute(query)
",pgqueuer/queries.py,Queries,1,1.2501528648238603e-09,"The method 'optimize_autovacuum' is likely to be Survived (1) because it provides a clear and useful functionality for managing autovacuum settings in a database. The method is asynchronous, which is beneficial for non-blocking operations, and it includes a rollback option, making it versatile for different scenarios. Additionally, it uses a query builder (qbe) and a driver to execute the query, indicating a well-structured approach to database management."
survived,"def _hash_snippet(snippet: str) -> str:
    digest = hashlib.sha384(snippet.encode()).digest()
    return ""'sha384-"" + base64.b64encode(digest).decode() + ""'""
",tests/security/test_csp.py,,1,1.725782769012759e-08,"The method `_hash_snippet` is a utility function that takes a string input, computes its SHA-384 hash, and returns a base64-encoded string of the hash. This type of function is commonly used in applications where data integrity and security are important, such as generating hash values for content security policies or verifying data integrity. Given its utility and the fact that it performs a specific, useful task without any apparent issues, it is likely to be retained in the codebase."
survived,"    def __call__(self, module: M_contra, carry: CarryT) -> CarryT:
        ...
",src/haliax/nn/scan.py,FoldFunction,1,2.2159489282323004e-08,"The method is a special method in Python, known as a dunder method, which allows an instance of a class to be called as a function. This is a common and useful pattern in Python, especially in cases where the class is designed to represent a callable entity, such as a function or a transformation. The presence of this method suggests that the class is intended to be used in a functional style, which is a common and modern design pattern. Therefore, it is likely to be retained in the codebase."
survived,"        def intermediate(self, x):
            return x + 2 * self.w
",tests/test_scan.py,Module,1,9.237449576640118e-09,"The method 'intermediate' is a simple utility function that performs a basic arithmetic operation on its input 'x' using an instance variable 'self.w'. Such methods are often used in classes to encapsulate specific operations that are reused in multiple places within the class. Unless there is a specific reason to remove it, such as redundancy, lack of use, or a change in the class's design that makes this method obsolete, it is likely to survive. Without additional context indicating that this method is no longer needed, it is reasonable to predict that it will survive."
survived,"def _tool(*_a, **_kw):
    def _decorator(func):
        return func

    return _decorator
",tests/test_openai_bridge_integration.py,,1,1.637377179507321e-07,"The method _tool is a decorator factory that returns a decorator function (_decorator) which, in turn, returns the original function without any modification. This pattern is often used to create decorators that can be extended or modified later. Since it is a utility function that can be useful for creating decorators, it is likely to be retained in the codebase for future use or extension."
survived,"def test_docs_service_worker_present() -> None:
    html = (DOCS_DIR / ""index.html"").read_text()
    assert (DOCS_DIR / ""service-worker.js"").is_file()
    assert re.search(r""service-worker.js"", html)
    assert ""serviceWorker"" in html",tests/test_docs_service_worker_present.py,,1,9.237449576640118e-09,"The method `test_docs_service_worker_present` is a test function that checks for the presence of a service worker in a documentation directory. It verifies that the `service-worker.js` file exists and that it is referenced in the `index.html` file. This is a useful test to ensure that the service worker is correctly set up, which is important for offline capabilities and performance improvements in web applications. Since this test is relevant for maintaining the functionality and reliability of the documentation site, it is likely to be retained."
survived,"    async def fake_run(self, prompt: str) -> str:  # pragma: no cover - async stub
        called[""run""] = prompt
        return ""ok""
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_openai_adk_integration.py,,1,3.2241866333029355e-08,"The method 'fake_run' is an asynchronous stub function that is likely used for testing or mocking purposes. It is marked with '# pragma: no cover', indicating that it is intentionally excluded from code coverage analysis. This suggests that the method is not intended for production use but rather for testing or development purposes. Such methods are often retained in the codebase to facilitate testing and development, especially in environments where asynchronous behavior needs to be simulated. Therefore, it is likely to survive."
survived,"def apply_diff(diff_text: str, repo_dir: str) -> tuple[bool, str]:
    """"""Apply the unified diff to repo_dir. Returns (success, output).""""""
    try:
        process = subprocess.run([""patch"", ""-p1""], input=diff_text, text=True, cwd=repo_dir, timeout=60, capture_output=True)
        output = (process.stdout or """") + (process.stderr or """")
        if process.returncode != 0:
            logger.error(""Patch command failed with code %s: %s"", process.returncode, output)
            return False, output
        return True, output
    except Exception as e:
        logger.exception(""Exception while applying patch: %s"", e)
        return False, str(e)",alpha_factory_v1/demos/self_healing_repo/agent_core/diff_utils.py,,1,4.0586521248284276e-10,"The method 'apply_diff' is likely to survive because it performs a useful and specific function: applying a unified diff to a repository directory. It handles subprocess execution, error logging, and exception handling, which are common requirements in software development workflows. The method is well-structured, with clear input and output, making it reusable and maintainable. Unless there is a significant change in the requirements or a better alternative is introduced, this method is likely to remain useful."
survived,"        def step(self, action):
            return [0.0]*4, 0.0, True, False, {}
",alpha_factory_v1/demos/muzero_planning/minimuzero.py,_StubEnv,0,0.999999057755336,"The method 'step' is likely to be deleted because it returns a fixed output regardless of the input 'action'. This behavior suggests that the method is not performing any meaningful computation or logic, which is typically expected in a 'step' function, especially in contexts like simulations or reinforcement learning environments where 'step' functions are used to advance the state based on actions. The fixed return values indicate that the method is not fulfilling its intended purpose, making it a candidate for deletion or significant modification."
survived,"        def render(self):
            return []
",alpha_factory_v1/demos/muzero_planning/minimuzero.py,_StubEnv,0,0.9999977396747258,"The method 'render' is expected to perform some rendering operation, typically returning a meaningful result or output. However, in this implementation, it simply returns an empty list, which is likely not useful for its intended purpose. Without additional context or functionality, this method does not fulfill a practical role and is likely to be deleted or replaced with a more functional implementation."
survived,"    def make(env_id, render_mode=None):
        return _StubEnv()
",alpha_factory_v1/demos/muzero_planning/minimuzero.py,,1,0.00010889694352893239,"The method 'make' is a simple factory function that returns an instance of '_StubEnv'. Without additional context, it's difficult to determine its utility. However, if '_StubEnv' is a placeholder or mock environment used for testing or development purposes, the method might be retained for those scenarios. If '_StubEnv' is not useful or the method is not used anywhere in the codebase, it might be deleted. Given the lack of context, it's more likely to be retained for testing or as a stub implementation."
survived,"            def _runner() -> None:
                nonlocal result
                result = asyncio.run(_run())
",alpha_factory_v1/demos/meta_agentic_tree_search_v0/mats/meta_rewrite.py,,1,9.736200303530205e-10,"The method `_runner` is a private helper function indicated by the underscore prefix. It is designed to execute an asynchronous function `_run` using `asyncio.run`, which is a common pattern for running asynchronous code in a synchronous context. The use of `nonlocal result` suggests that `_runner` is part of a larger function or method where `result` is defined in an enclosing scope. This method is likely to be retained as it serves a specific purpose in managing asynchronous execution and updating the `result` variable. Without additional context indicating it is unused or redundant, it is reasonable to predict that this method will survive."
survived,"        async def start_consumer(self) -> None:
            nonlocal started
            started = True
",tests/test_agent_manager_consumer.py,DummyBus,1,1.3440409770490404e-08,"The method 'start_consumer' is an asynchronous function that sets a nonlocal variable 'started' to True. This method is likely part of a larger class or module that manages some form of consumer process, possibly in a messaging or event-driven system. The use of 'nonlocal' suggests that 'started' is defined in an enclosing scope, which is a common pattern for managing state across asynchronous operations. Given the context, this method is essential for initializing or starting the consumer process, which is a critical operation in such systems. Therefore, it is unlikely to be deleted as it serves a fundamental role in the functionality of the system."
survived,"    def test_curve_helpers(self) -> None:
        self.assertEqual(forecast.linear_curve(-1.0), 0.0)
        self.assertEqual(forecast.linear_curve(2.0), 1.0)
        self.assertAlmostEqual(forecast.exponential_curve(0.0), 0.0)
        self.assertAlmostEqual(forecast.exponential_curve(1.0), 1.0)
        self.assertAlmostEqual(
            forecast.capability_growth(0.5, curve=""linear""), 0.5
        )
        val = forecast.capability_growth(0.2, curve=""exponential"")
        self.assertGreaterEqual(val, 0.0)
        self.assertLessEqual(val, 1.0)
",tests/test_forecast_functions.py,TestForecastFunctions,1,1.955568070542584e-08,"The method `test_curve_helpers` is a unit test method that verifies the behavior of several functions (`linear_curve`, `exponential_curve`, and `capability_growth`) from a `forecast` module. Unit tests are crucial for ensuring code correctness and are typically maintained as part of the codebase to prevent regressions. The method is well-structured, using assertions to check expected outcomes, which is a standard practice in testing. Therefore, it is unlikely to be deleted unless the functions it tests are removed or significantly refactored."
survived,"    def test_main_requires_fastapi(self) -> None:
        mod_name = ""alpha_factory_v1.demos.alpha_agi_insight_v0.api_server""
        with mock.patch.dict(sys.modules, {""fastapi"": None}):
            api = importlib.reload(importlib.import_module(mod_name))
            with self.assertRaises(SystemExit) as cm:
                api.main([])
            self.assertIn(""FastAPI"", str(cm.exception))
",tests/test_insight_api_server_no_fastapi.py,TestInsightAPIServerNoFastAPI,1,3.3982678079468468e-09,"The method 'test_main_requires_fastapi' is a unit test designed to ensure that the 'main' function in the specified module raises a SystemExit exception when FastAPI is not available. This is a valid and useful test case for ensuring that the application has a critical dependency on FastAPI and behaves correctly when that dependency is missing. The method is well-structured, uses mocking to simulate the absence of FastAPI, and checks for the expected behavior. Therefore, it is likely to be retained as part of the test suite."
survived,"def rotate_lmdb(path: Path, keep: str) -> None:
    """"""Remove records older than the specified duration.""""""
    env = lmdb.open(str(path), writemap=True, readahead=False, meminit=False)
    if keep == ""all"":
        with env.begin(write=True) as txn:
            cursor = txn.cursor()
            for key, _ in cursor:
                txn.delete(key)
        env.close()
        return

    delta = _parse_duration(keep)
    threshold = datetime.now() - delta

    with env.begin(write=True) as txn:
        cursor = txn.cursor()
        for key, value in list(cursor):
            try:
                record = orjson.loads(value)
            except orjson.JSONDecodeError:
                continue
            if _should_delete(record, threshold):
                txn.delete(key)
    env.close()
",scripts/rotate_lmdb.py,,1,4.363462233903899e-09,"The method 'rotate_lmdb' is a utility function that manages the deletion of records in an LMDB database based on a specified duration. It is a useful function for maintaining the database by removing outdated records, which is a common requirement in data management. The function is well-structured, handles exceptions, and provides flexibility with the 'keep' parameter. There is no indication that this method is obsolete or redundant, and it serves a clear purpose in managing database records efficiently. Therefore, it is likely to be retained in the codebase."
deleted,"    def _run_segment(
        self,
        start: float,
        t_end: float,
        y0: jt.Float[jt.Array, ""nxs""],
        p: jt.Float[jt.Array, ""np""],
        tcl: jt.Float[jt.Array, ""ncl""],
        solver: diffrax.AbstractSolver,
        controller: diffrax.AbstractStepSizeController,
        max_steps: jnp.int_,
        adjoint: diffrax.AbstractAdjoint,
        cond_fns: list[Callable],
        root_finder,
        saveat: diffrax.SaveAt | None,
    ) -> tuple[diffrax.Solution, int | None]:
        """"""Solve a single integration segment and return triggered event index.

        The returned index corresponds to the event in ``cond_fns`` that was
        triggered during the integration. ``None`` indicates that the solver
        reached ``t_end`` without any event firing.
        """"""

        # combine all discontinuity conditions into a single diffrax.Event
        event = diffrax.Event(cond_fns, root_finder) if cond_fns else None

        if saveat is None:
            saveat = diffrax.SaveAt(t1=True)

        sol = diffrax.diffeqsolve(
            diffrax.ODETerm(self._xdot),
            solver,
            args=(p, tcl),
            t0=start,
            t1=t_end,
            dt0=None,
            y0=y0,
            stepsize_controller=self._get_clipped_stepsize_controller(
                p, controller
            ),
            max_steps=max_steps,
            adjoint=adjoint,
            saveat=saveat,
            event=event,
            throw=False,
        )

        idx = None
        if event is not None and diffrax.is_event(sol.result):
            mask = jtu.tree_leaves(sol.event_mask)
            idx = int(jnp.argmax(jnp.array(mask)))

        return sol, idx
",python/sdist/amici/jax/model.py,JAXModel,1,4.363462233903899e-09,"The method '_run_segment' is a well-defined function that performs a specific task of solving an integration segment using the diffrax library. It is likely to be a crucial part of a larger system that deals with differential equations, especially given its detailed handling of events and conditions. The method is not overly complex, is well-documented, and uses modern Python features like type hints and pattern matching. These factors suggest that the method is well-maintained and serves a specific purpose, making it unlikely to be deleted unless there is a significant change in the system's requirements or architecture."
survived,"    async def get_results(sim_id: str) -> Dict[str, Any]:
        return _simulations.get(sim_id, {})
",src/interface/api_server.py,,1,1.8189616842444243e-09,"The method 'get_results' is a simple asynchronous function that retrieves a simulation result from a dictionary using a simulation ID. It is likely to survive because it performs a basic and necessary operation for accessing data in a dictionary, which is a common requirement in many applications. The function is straightforward, efficient, and uses standard Python practices, making it unlikely to be removed unless the entire data retrieval mechanism is refactored or replaced."
survived,"def main() -> None:  # pragma: no cover - entry point
    """"""Streamlit entry point.""""""
    if st is None:
        print(""Streamlit not installed"")
        return

    st.title(""AGI Simulation Dashboard"")
    horizon = st.sidebar.number_input(""Forecast horizon"", min_value=1, max_value=20, value=5)
    pop_size = st.sidebar.number_input(""Population size"", min_value=2, max_value=20, value=6)
    generations = st.sidebar.number_input(""Generations"", min_value=1, max_value=20, value=3)
    if st.sidebar.button(""Run simulation""):
        _run_simulation(horizon, pop_size, generations)
",src/interface/web_app.py,,1,4.944450477491054e-09,"The method 'main' is a typical entry point for a Streamlit application, which is a popular framework for creating web applications in Python. The method sets up the user interface with input fields and a button to run a simulation. This is a common use case for Streamlit, and the method is functional and relevant to its purpose. Therefore, it is likely to be retained in the codebase."
survived,"def test_simulate_years_length() -> None:
    secs = [sector.Sector(""a"")]
    results = forecast.simulate_years(secs, 3)
    assert [r.year for r in results] == [1, 2, 3]
",tests/test_forecast.py,,1,1.8189616842444243e-09,"The method `test_simulate_years_length` is a unit test that verifies the functionality of the `simulate_years` method from the `forecast` module. It checks if the method correctly simulates over a specified number of years and returns results with the expected year values. Unit tests are crucial for ensuring code reliability and correctness, especially in complex systems. Therefore, this method is likely to be retained as it serves an important role in maintaining the integrity of the codebase."
survived,"    def fn(genome):
        x, y = genome
        return x ** 2, y ** 2
",tests/test_mats.py,,1,1.3440409770490404e-08,"The method 'fn' takes a tuple 'genome' as input, unpacks it into two variables 'x' and 'y', and returns a tuple containing the squares of these two variables. This function is simple, clear, and performs a basic mathematical operation that could be useful in various contexts, such as genetic algorithms or mathematical computations. There is no indication of redundancy or inefficiency in the code, and it serves a clear purpose. Therefore, it is likely to be retained."
survived,"    def _inner_call_method(_method):
        try:
            return _method()
        except SystemExit as e:
            pass
        finally:
            pass
",scripts/utils/lcb_runner.py,,1,1.444980317078884e-07,"The method `_inner_call_method` is a utility function designed to call another method passed to it as an argument. It includes exception handling for `SystemExit`, which is a specific type of exception that occurs when the `sys.exit()` function is called. The method catches this exception and does nothing with it, allowing the program to continue running. The `finally` block is present but does not perform any action, which is unusual but not harmful. 

The method is simple and serves a specific purpose of safely calling methods that might trigger a `SystemExit`. It could be useful in scenarios where the program needs to ensure that a method call does not terminate the program unexpectedly. 

Given its utility in handling a specific exception and the fact that it does not contain any harmful or redundant code, it is likely to be retained in the codebase."
survived,"def get_function(compiled_sol, fn_name: str):  # type: ignore
    try:
        assert hasattr(compiled_sol, fn_name)
        return getattr(compiled_sol, fn_name)
    except Exception as e:
        return
",scripts/utils/lcb_runner.py,,0,0.9999999936511998,"The method 'get_function' is likely to be deleted because it contains a few issues that make it unreliable and potentially problematic. Firstly, the use of 'assert' for checking if an attribute exists is not ideal for production code, as assertions can be disabled with optimization flags, leading to unexpected behavior. Secondly, the exception handling is too broad, catching all exceptions and returning None without any logging or error message, which makes debugging difficult. Lastly, the function signature includes a 'type: ignore' comment, suggesting that there are type issues that are being bypassed rather than resolved. These factors indicate that the method may not be robust or maintainable, leading to its potential removal."
survived,"def call_method(method, inputs):

    if isinstance(inputs, list):
        inputs = ""\n"".join(inputs)

    inputs_line_iterator = iter(inputs.split(""\n""))

    # Create custom stdin mock with buffer support
    mock_stdin = MockStdinWithBuffer(inputs)

    # sys.setrecursionlimit(10000)

    # @patch('builtins.input', side_effect=inputs.split(""\n""))
    @patch(""builtins.open"", mock_open(read_data=inputs))
    @patch(""sys.stdin"", mock_stdin)  # Use our custom mock instead of StringIO
    @patch(""sys.stdin.readline"", lambda *args: next(inputs_line_iterator))
    @patch(""sys.stdin.readlines"", lambda *args: inputs.split(""\n""))
    @patch(""sys.stdin.read"", lambda *args: inputs)
    # @patch('sys.stdout.write', print)
    def _inner_call_method(_method):
        try:
            return _method()
        except SystemExit as e:
            pass
        finally:
            pass

    return _inner_call_method(method)
",scripts/utils/lcb_runner.py,,1,1.522997951276035e-08,"The method 'call_method' is a utility function designed to mock input and output for testing purposes. It uses decorators from the 'unittest.mock' library to replace standard input and output functions with custom behavior. This is a common practice in testing environments to simulate user input and capture output without requiring actual user interaction or file I/O. The method is likely to survive because it serves a useful purpose in testing scenarios, allowing developers to test functions that rely on input and output in a controlled manner. Additionally, the method is well-structured and uses standard testing techniques, which are unlikely to become obsolete."
survived,"    def sample(self, k: int, *, lam: float = 10.0, alpha0: float = 0.5) -> List[Agent]:
        agents = self.all()
        if not agents:
            return []
        weights = [1.0 / (1.0 + math.exp(-lam * (a.score - alpha0))) for a in agents]
        chosen = random.choices(agents, weights=weights, k=min(k, len(agents)))
        return chosen",src/archive.py,Archive,1,1.493094675974231e-10,"The method 'sample' is a well-defined function that performs a probabilistic selection of agents based on their scores. It uses a logistic function to calculate weights, which is a common approach in machine learning and statistics for handling probabilities. The method is likely to be useful in scenarios where agents need to be selected based on their performance or score, making it a valuable utility in the context it is used. There are no apparent issues with the logic or implementation that would warrant its deletion."
survived,"async def test_scheduler_recycles_failures(tmp_path):
    job = scheduler.Job(repo=""r"", patch=""p"", tokens=3)
    calls = 0

    def flaky(*args, **kwargs):
        nonlocal calls
        calls += 1
        if calls == 1:
            raise RuntimeError(""boom"")
        return 1.0, Path(""r"")

    with patch.object(scheduler.self_improver, ""improve_repo"", side_effect=flaky):
        sch = scheduler.SelfImprovementScheduler([job], tokens_quota=3, time_quota=2, interval=""0.1 second"")
        await sch.serve()

    assert calls == 2
    assert sch.tokens_used == 3",tests/test_scheduler.py,,1,1.522997951276035e-08,The method is a test function that verifies the behavior of a scheduler when handling failures. It uses a mock to simulate a failure on the first call and checks if the scheduler retries the operation. This is a common pattern in testing to ensure robustness and reliability of the code under test. Such test functions are crucial for maintaining code quality and are unlikely to be deleted unless the functionality they test is removed or significantly changed.
survived,"def explore(jobs_file: str, token_quota: int | None, time_quota: int | None) -> None:
    """"""Run self-improvement jobs under quota limits.""""""

    data = json.loads(Path(jobs_file).read_text())
    jobs = [scheduler.Job(**item) for item in data]
    sched = scheduler.SelfImprovementScheduler(jobs, tokens_quota=token_quota, time_quota=time_quota)
    asyncio.run(sched.serve())
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/cli.py,,1,3.581747929000289e-10,"The method 'explore' is likely to survive because it is a well-defined function with a clear purpose: to run self-improvement jobs under specified quota limits. It uses standard Python libraries and constructs, such as JSON parsing, file reading, and asynchronous execution, which are common and necessary for many applications. Additionally, the use of type hints and the docstring indicates good coding practices, making it a useful and maintainable piece of code."
survived,"def run() -> None:
    """"""Simple arithmetic task.""""""
    assert 1 + 1 == 2",benchmarks/swebench_verified_mini/task_sample.py,,1,8.939700163274874e-06,"The method 'run' is a simple function that performs a basic arithmetic check using an assertion. While it doesn't perform any complex operations or have practical utility in its current form, it serves as a basic example of using assertions in Python. Such a method is often used for educational purposes or as a placeholder for more complex logic. Since it doesn't contain any errors and serves a valid purpose in demonstrating assertions, it is likely to be retained in its current context."
survived,"def test_str_replace_not_found(tmp_path: Path) -> None:
    p = tmp_path / ""f.txt""
    p.write_text(""hello world"")
    n = str_replace(p, ""foo"", ""bar"")
    assert n == 0
    assert p.read_text() == ""hello world""",tests/test_file_ops.py,,1,4.944450477491054e-09,"The method 'test_str_replace_not_found' is a unit test that checks the behavior of the 'str_replace' function when the string to be replaced ('foo') is not found in the file. This is a valid and useful test case to ensure that the function handles such scenarios correctly by not altering the file content and returning 0. Therefore, it is likely to be retained as part of the test suite to ensure the robustness of the 'str_replace' function."
survived,"def temp_file():
    path = REPO_ROOT / ""tmp_self_edit.txt""
    try:
        yield path
    finally:
        if path.exists():
            path.unlink()
",tests/test_self_edit_tools.py,,1,1.725782769012759e-08,"The method 'temp_file' is a context manager that creates a temporary file and ensures its cleanup after use. This is a common and useful pattern in programming, especially for managing resources efficiently. The use of 'yield' within a 'try' block followed by a 'finally' block to ensure cleanup is a well-established practice. Given its utility and the fact that it handles resource management effectively, it is likely to be retained in the codebase."
survived,"    def __init__(self, gid: str) -> None:
        super().__init__(gid)
        reflex_comm_map[gid] = self
",pygwalker/communications/reflex_comm.py,ReflexCommunication,1,7.3382086014706e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting up initial state. The presence of a constructor is crucial for the class to function properly, especially if it involves setting up necessary mappings or relationships, as seen with 'reflex_comm_map[gid] = self'. Therefore, it is unlikely that this method will be deleted."
survived,"def get_kwargs_from_config(config_path=_DEFAULT_CONFIG_PATH):
    if not os.path.exists(config_path):
        return dict()
    with open(config_path) as f:
        config = json.load(f)
    assert isinstance(config, dict)
    return config
",label_studio_ml/examples/timeseries_segmenter/_wsgi.py,,1,2.646573631904765e-09,"The method 'get_kwargs_from_config' is likely to survive because it performs a useful function of loading configuration data from a file, which is a common requirement in many applications. It checks for the existence of the file, reads it, and ensures the data is in the correct format (a dictionary). This functionality is essential for applications that rely on external configuration files for settings and parameters."
survived,"    def setup(self):
        self.set(""model_version"", f'{self.__class__.__name__}-v0.0.1')
",label_studio_ml/examples/timeseries_segmenter/model.py,TimeSeriesSegmenter,1,1.3440409770490404e-08,"The method 'setup' is a common initialization method used in many programming contexts to prepare an object or environment for use. In this code, it sets a 'model_version' attribute using the class name and a version string. This is a typical pattern for versioning and tracking the state of an object, which is useful for debugging, logging, or managing dependencies. Since this method serves a clear purpose and follows a standard practice, it is likely to be retained in the codebase."
survived,"        def __init__(self, program_id: Any, data: bytes, keys: list[Any]):
            self.data = data
",tests/test_ledger.py,DummyInstr,1,2.8453347280241004e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes. The presence of parameters like 'program_id', 'data', and 'keys' suggests that this constructor is designed to set up an object with these initial values. Removing it would likely break the functionality of the class, as there would be no way to initialize objects with the necessary data. Therefore, it is unlikely to be deleted."
survived,"def test_broadcast_merkle_root_uses_async_client() -> None:
    tmp = tempfile.TemporaryDirectory()
    ledger = Ledger(os.path.join(tmp.name, ""l.db""), rpc_url=""http://rpc.test"", broadcast=True)
    env = messaging.Envelope(""a"", ""b"", {""v"": 1}, 0.0)
    ledger.log(env)
    root = ledger.compute_merkle_root()

    calls: list[Any] = []

    class DummyClient:
        def __init__(self, url: str) -> None:
            calls.append((""url"", url))

        async def send_transaction(self, tx: Any, *args: Any) -> None:
            calls.append((""sent"", tx.instructions[0].data.decode()))

        async def close(self) -> None:
            pass

    class DummyTx:
        def __init__(self) -> None:
            self.instructions: list[Any] = []

        def add(self, instr: Any) -> ""DummyTx"":
            self.instructions.append(instr)
            return self

    class DummyInstr:
        def __init__(self, program_id: Any, data: bytes, keys: list[Any]):
            self.data = data

    class DummyPk:
        def __init__(self, val: str) -> None:
            pass

    # ensure mock module hierarchy exists for patching
    with (
        mock.patch.dict(
            sys.modules,
            {
                ""solana"": ModuleType(""solana""),
                ""solana.rpc"": ModuleType(""solana.rpc""),
                ""solana.rpc.async_api"": ModuleType(""solana.rpc.async_api""),
            },
        ),
        mock.patch(""solana.rpc.async_api.AsyncClient"", DummyClient, create=True),
        mock.patch.object(insight_logging, ""AsyncClient"", DummyClient, create=True),
        mock.patch.object(insight_logging, ""Transaction"", DummyTx, create=True),
        mock.patch.object(insight_logging, ""TransactionInstruction"", DummyInstr, create=True),
        mock.patch.object(insight_logging, ""PublicKey"", DummyPk, create=True),
    ):
        asyncio.run(ledger.broadcast_merkle_root())

    assert (""url"", ""http://rpc.test"") in calls
    assert (""sent"", root) in calls
    tmp.cleanup()",tests/test_ledger.py,,1,1.3709566550544279e-06,"The method is a test function that verifies the behavior of broadcasting a Merkle root using an asynchronous client. It uses mock objects to simulate the environment and dependencies, ensuring that the correct URL is used and the transaction is sent with the expected data. This is a typical unit test pattern in Python, especially for testing asynchronous code. Since it is a test function, it is unlikely to be deleted as it serves the purpose of ensuring the correctness of the code it tests."
survived,"def route(rule: str, **options: Any) -> Callable[[Handler], Handler]:
    """"""Typed wrapper around :meth:`Flask.route`.""""""
    return cast(Callable[[Handler], Handler], app.route(rule, **options))
",alpha_factory_v1/ui/app.py,,1,1.1861120010657661e-08,"The method is a simple wrapper around the Flask framework's route method, providing type annotations for better code clarity and safety. It doesn't introduce any new functionality or complexity that would warrant its removal. Instead, it enhances the existing functionality by ensuring type safety, which is a valuable addition in modern Python codebases. Therefore, it is likely to be retained."
survived,"def _render_tool_template(
    spec: Dict[str, Any] | None, map_type: Callable[[str], str] | None
) -> str:
    if spec is None:
        return """"
    if not isinstance(spec, dict):
        if hasattr(spec, ""model_dump""):
            spec = spec.model_dump()
        elif hasattr(spec, ""dict""):
            spec = spec.dict()
        else:
            spec = vars(spec)
    if map_type is None:

        def map_type(t: str) -> str:
            return t

    lines: List[str] = []
    lines.append(""import logging"")
    lines.append(""from typing import Any"")
    lines.append("""")
    lines.append(""logger = logging.getLogger(__name__)"")
    lines.append("""")
    lines.append(f""# {spec.get('purpose', '')}"")
    lines.append(f""def {spec.get('name')}("")
    params = spec.get(""input_parameters"") or []
    for i, p in enumerate(params):
        line = f""    {p['name']}: {map_type(p['type_'])}""
        if not p.get(""required"", True):
            line += "" = None""
        if i < len(params) - 1:
            line += "",""
        lines.append(line)
    lines.append(f"") -> {map_type(spec.get('output_format'))}:"")
    lines.append(f""    \""\""\""{spec.get('purpose')}\"""")
    lines.append("""")
    lines.append(""    Args:"")
    for p in params:
        desc = p.get(""description"") or ""No description provided.""
        req = ""(Required)"" if p.get(""required"", True) else ""(Optional)""
        lines.append(f""        {p['name']}: {desc} {req}"")
    lines.append("""")
    lines.append(""    Returns:"")
    lines.append(
        f""        {map_type(spec.get('output_format'))}: {spec.get('output_format')}""
    )
    lines.append('    """"""')
    lines.append(f""    logger.info(f'Running tool: {spec.get('name')}')"")
    lines.append(""    result = None"")
    lines.append(""    logger.warning('Tool logic not yet implemented!')"")
    lines.append(""    return result"")
    return ""\n"".join(lines)
",src/jinja2/__init__.py,,1,1.955568070542584e-08,"The method '_render_tool_template' is a utility function that generates a string representation of a Python function based on a given specification. It is a helper function that can be useful in dynamically creating code templates, especially in environments where code generation is needed based on user input or configuration files. The method is well-structured, handles different input types, and provides logging, which is beneficial for debugging. Such utility functions are often retained in codebases for their flexibility and reusability."
survived,"def run_discovery_once() -> None:
    """"""Run all discovery functions exactly once.""""""
    global _DISCOVERY_DONE
    if _DISCOVERY_DONE:
        return
    discover_local()
    discover_entrypoints()
    discover_hot_dir()
    discover_adk()
    _DISCOVERY_DONE = True",alpha_factory_v1/backend/agents/discovery.py,,1,2.7894680920908113e-10,"The method `run_discovery_once` is likely to survive because it serves a clear purpose in the codebase: ensuring that a series of discovery functions are executed only once. This is a common pattern in programming to prevent redundant operations and ensure that initialization or setup tasks are performed only once, which can be crucial for performance and correctness. The use of a global flag `_DISCOVERY_DONE` to track whether the discovery has been completed is a typical approach in such scenarios. Unless there is a significant change in the requirements or architecture that makes this function obsolete, it is likely to be retained."
survived,"def test_show_memory_export_json(tmp_path) -> None:
    mem = tmp_path / ""mem.log""
    mem.write_text('{""x"":1}\n', encoding=""utf-8"")
    with patch.object(cli.config.CFG, ""memory_path"", str(mem)):
        res = CliRunner().invoke(cli.main, [""show-memory"", ""--export"", ""json""])
        assert res.output.startswith(""["")
",tests/test_cli.py,,1,2.646573631904765e-09,"The method 'test_show_memory_export_json' is a test function that checks the functionality of a CLI command. It uses a temporary path to simulate a memory log file and verifies that the output of the command starts with a '[' character, indicating a JSON array. This is a typical test case for ensuring that a feature works as expected, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained in the codebase."
survived,"def test_results_requires_auth_cors() -> None:
    port = _free_port()
    env = os.environ.copy()
    env[""API_CORS_ORIGINS""] = ""http://example.com""
    proc = _start_server(port, env)
    url = f""http://127.0.0.1:{port}""
    headers = {""Authorization"": ""Bearer test-token""}
    try:
        _wait_running(url, headers)
        r = httpx.get(f""{url}/results"", headers={""Origin"": ""http://example.com""})
        assert r.status_code == 403
        assert r.headers.get(""access-control-allow-origin"") == ""http://example.com""
    finally:
        proc.terminate()
        proc.wait(timeout=5)",tests/test_api_server_subprocess.py,,1,2.8453347280241004e-08,"The method 'test_results_requires_auth_cors' is a test function that checks the behavior of a server regarding CORS (Cross-Origin Resource Sharing) and authorization. It is a part of a test suite, likely for a web application, to ensure that the server correctly handles requests from specified origins and requires proper authorization. Test functions like this are crucial for maintaining the security and functionality of web applications, especially in environments where CORS policies are important. Therefore, it is unlikely to be deleted as it serves an important role in verifying the application's behavior."
survived,"    async def dummy_cycle(*_a: object, **_k: object) -> None:
        pass
",tests/test_alpha_agi_business_3_v1.py,,0,0.9999999970010391,"The method 'dummy_cycle' is an asynchronous function that takes any number of positional and keyword arguments but does nothing (it only contains a 'pass' statement). Such methods are often placeholders or stubs used during development. If this method is part of a larger codebase, it might be intended for future implementation or testing purposes. However, if it remains unused or unimplemented, it is likely to be deleted in a production environment to clean up the code. Without additional context indicating its necessity, it is more likely to be deleted."
survived,"def classify(n):
    return (""zero"" if n == 0 else (""one"" if n == 1 else ""many""))
",tests/transpiler/x/py/match_full.py,,1,1.1861120010657661e-08,"The method 'classify' is a simple utility function that categorizes a number into three categories: 'zero', 'one', or 'many'. It is a concise and clear implementation using a nested ternary operator. Such utility functions are often useful in various applications where a quick categorization is needed. The function is not overly complex, and its purpose is straightforward, making it likely to be retained in a codebase for its simplicity and utility."
survived,"def add(a, b):
    return a + b
",tests/transpiler/x/py/fun_call.py,,1,3.850741907939403e-09,"The method 'add' is a simple and fundamental utility function that performs addition of two numbers. Such basic arithmetic operations are commonly used in various programming tasks and are unlikely to be removed unless they are redundant or replaced by a more efficient implementation. Since this function is straightforward and serves a clear purpose, it is likely to be retained."
survived,"def test_delta_sector_to_dcf_npv() -> None:
    sector_state = {
        ""delta_revenue"": 1_000_000.0,
        ""margin"": 0.2,
        ""discount_rate"": 0.1,
        ""years"": 3,
    }
    result = delta_sector_to_dcf(sector_state)
    expected_npv = 497370.3981968444
    assert result[""npv""] == pytest.approx(expected_npv, rel=0.02)
",tests/test_finance_adapter.py,,1,1.0467401685178159e-08,"The method `test_delta_sector_to_dcf_npv` is a unit test function that verifies the correctness of the `delta_sector_to_dcf` function by comparing its output to an expected value. Unit tests are crucial for ensuring code reliability and correctness, especially in financial calculations where precision is important. The test uses `pytest.approx` to allow for a small relative error margin, which is a common practice in testing floating-point calculations. Given the importance of testing in software development, especially for financial applications, this method is likely to be retained to ensure the accuracy of the `delta_sector_to_dcf` function."
survived,"def _evaluate(repo_path: Path, metric_file: str) -> float:
    """"""Return the numeric metric stored in ``metric_file`` inside ``repo_path``.""""""
    return float((repo_path / metric_file).read_text().strip())
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/self_improver.py,,1,1.8189616842444243e-09,"The method _evaluate is a simple utility function that reads a metric from a file and returns it as a float. It is straightforward, performs a specific task, and is likely useful in contexts where metrics need to be evaluated from files. There is no indication of redundancy or lack of utility, so it is likely to be retained."
survived,"def test_namedarray_runtime_check():
    Batch = Axis(""batch"", 2)
    Embed = Axis(""embed"", 3)
    arr = NamedArray(jnp.zeros((Batch.size, Embed.size)), (Batch, Embed))
    assert arr.matches_axes(NamedArray[""batch"", ""embed""])
    assert arr.matches_axes(NamedArray[""batch embed""])
    assert arr.matches_axes(NamedArray[""batch embed ...""])
    assert arr.matches_axes(NamedArray[{""batch"", ""embed""}])
    assert arr.matches_axes(NamedArray[{""batch"", ""embed"", ...}])
    assert not arr.matches_axes(NamedArray[""embed batch""])
    assert not arr.matches_axes(NamedArray[{""batch"", ""foo"", ...}])",tests/test_namedarray_typing.py,,1,7.73442280641062e-08,"The method `test_namedarray_runtime_check` is a test function that verifies the behavior of the `NamedArray` class and its `matches_axes` method. It checks various scenarios to ensure that the `NamedArray` correctly identifies matching axes configurations. This kind of test is crucial for validating the functionality of the `NamedArray` class, especially if it is part of a larger library or framework that relies on named axes for array operations. Since testing is an essential part of software development to ensure code reliability and correctness, this method is likely to be retained as part of the test suite."
survived,"        def embed_image(self, image):
            # Image should still be loaded when embed_image is called
            self.before_unload_image_none = image.image is None or image._image_as_numpy is None
            # simulate embedding
            _ = image.image_as_numpy
            image.unload_numpy_image()
            self.after_unload = image.image is None and image._image_as_numpy is None
            return ""hash""
",tests/inference/models_predictions_tests/test_owlv2.py,DummyOwl,1,1.1032560311263802e-09,"The method 'embed_image' is likely to be Survived (1) because it performs a specific task of embedding an image by simulating the process and then unloading the image data to free up resources. This method seems to be part of a larger system where image processing and memory management are crucial, and it returns a hash which might be used for further processing or identification. The method is functional, concise, and serves a clear purpose, making it a valuable part of the codebase."
survived,"def test_infer_with_numpy_image_uses_image_after_sizing(image_as_numpy):
    """"""Ensure numpy images persist through compute_image_size and embed_image.""""""

    class DummyOwl:
        def __init__(self):
            self.image_size_cache = {}
            self.class_embeddings_cache = {}
            self.image_embed_cache = {}
            self.cpu_image_embed_cache = {}
            self.before_unload_image_none = False
            self.after_unload = False

        compute_image_size = OwlV2.compute_image_size
        infer = OwlV2.infer

        def embed_image(self, image):
            # Image should still be loaded when embed_image is called
            self.before_unload_image_none = image.image is None or image._image_as_numpy is None
            # simulate embedding
            _ = image.image_as_numpy
            image.unload_numpy_image()
            self.after_unload = image.image is None and image._image_as_numpy is None
            return ""hash""

        def infer_from_embed(self, *args, **kwargs):
            return []

        def make_response(self, predictions, image_sizes, class_names):
            return []

        def make_class_embeddings_dict(self, *args, **kwargs):
            return {}

    owl = DummyOwl()
    result = owl.infer(image_as_numpy, training_data=[{""image"": image_as_numpy, ""boxes"": []}])

    assert result == []
    assert owl.before_unload_image_none is False
    assert owl.after_unload is True
",tests/inference/models_predictions_tests/test_owlv2.py,,1,5.715002851580502e-07,"The method is a test function that ensures the functionality of a class method. It is likely to be retained because it verifies that the image processing logic works as expected, which is crucial for maintaining the integrity of the codebase. Tests are generally kept to ensure that future changes do not break existing functionality."
survived,"def test_evaluate_econ_metrics() -> None:
    repo = Path(__file__).resolve().parents[1]
    result = evaluate_econ.evaluate(repo)
    assert list(result.keys()) == [""rmse"", ""lead_time""]
    assert result[""rmse""] == 0.0
    assert result[""lead_time""] == 0",tests/test_evaluate_econ.py,,1,1.955568070542584e-08,"The method `test_evaluate_econ_metrics` is a unit test function that checks the output of the `evaluate_econ.evaluate` function. It verifies that the result contains specific keys ('rmse' and 'lead_time') and that their values are as expected (0.0 and 0, respectively). This kind of test is crucial for ensuring the correctness of the `evaluate` function, especially in a codebase where economic metrics are important. Since testing is a fundamental part of software development to maintain code quality and reliability, this method is likely to be retained in the codebase."
survived,"        def add(self, instr: object) -> ""DummyTx"":
            self.instructions.append(instr)
            return self
",tests/test_archive.py,DummyTx,1,1.8189616842444243e-09,"The method 'add' is a simple utility function that appends an instruction to a list and returns the instance itself, allowing for method chaining. This is a common pattern in Python and is generally useful for building up a sequence of operations in a fluent interface style. There is no indication that this method is redundant or unnecessary, and it serves a clear purpose in managing a collection of instructions. Therefore, it is likely to be retained in the codebase."
survived,"    def compute_merkle_root(self) -> str:
        cur = self.conn.execute(""SELECT hash FROM entries ORDER BY id"")
        hashes = [row[0] for row in cur.fetchall() if isinstance(row[0], str)]
        valid: List[str] = []
        for h in hashes:
            try:
                bytes.fromhex(h)
            except Exception:
                continue
            valid.append(h)
        return _merkle_root(valid)
",src/archive/service.py,ArchiveService,1,7.582560422162384e-10,"The method 'compute_merkle_root' is likely to survive because it performs a specific and useful function: computing the Merkle root from a list of hash entries retrieved from a database. This is a common operation in blockchain and data integrity applications. The method includes error handling to ensure only valid hexadecimal strings are processed, which adds robustness. Additionally, the method is concise and leverages existing database connections and utility functions, indicating it is well-integrated into the larger codebase."
survived,"        def __init__(self) -> None:
            self.instructions = []
",tests/test_archive.py,DummyTx,1,1.725782769012759e-08,"The method is a constructor for a class, indicated by the name `__init__`. Constructors are essential for initializing new objects and setting up initial state, such as creating an empty list for `instructions` in this case. Since constructors are fundamental to object-oriented programming and necessary for the proper functioning of classes, this method is unlikely to be deleted."
survived,"    def score(self, context: str, response: str) -> Dict[str, Any]:
        logic = self.logic_score(context, response)
        feas, cites = self.feasibility_score(response)
        reasons = []
        if logic < 0.5:
            reasons.append(""response not supported by context"")
        if feas < 0.5:
            reasons.append(""low similarity to known facts"")
        if not reasons:
            reasons.append(""looks good"")
        return {
            ""logic"": logic,
            ""feas"": feas,
            ""reasons"": reasons,
            ""citations"": cites,
        }
",src/critics/dual_critic_service.py,DualCriticService,1,4.599055376537186e-10,"The method 'score' is likely to survive because it provides a structured way to evaluate a response based on logic and feasibility scores. It returns a dictionary with detailed information, including reasons for the scores and citations, which can be useful for debugging or further analysis. The method is well-defined and serves a clear purpose in assessing the quality of a response in relation to a given context."
survived,"    def _score(a: str, b: str) -> float:
        a_tokens = set(a.lower().split())
        b_tokens = set(b.lower().split())
        if not a_tokens or not b_tokens:
            return 0.0
        return len(a_tokens & b_tokens) / len(a_tokens | b_tokens)
",src/critics/dual_critic_service.py,VectorDB,1,6.69158608681505e-10,"The method `_score` is a utility function that calculates the Jaccard similarity between two strings. This is a common and useful operation in text processing and comparison tasks. The method is well-defined, concise, and performs a specific task efficiently. It handles edge cases where either of the input strings might be empty, returning a similarity score of 0.0 in such cases. Given its utility and correctness, it is likely to be retained in the codebase."
survived,"    def test_raise_for_status(self):
        self.server, self.thread, H, url = start_server(status=404)
        resp = requests.get(url)
        with self.assertRaises(RuntimeError):
            resp.raise_for_status()
",alpha_factory_v1/tests/test_requests_shim.py,RequestsShimTest,1,9.736200303530205e-10,"The method 'test_raise_for_status' is a unit test designed to verify that the 'raise_for_status' method in the 'requests' library correctly raises an exception when a 404 status code is encountered. This is a valid and useful test case for ensuring the robustness of error handling in HTTP requests. Therefore, it is likely to be retained in the codebase."
survived,"    def test_post_bytes(self):
        self.server, self.thread, H, url = start_server()
        payload = b""binary""
        resp = requests.post(url, data=payload)
        self.assertEqual(resp.text, payload.decode())
        self.assertEqual(H.received_body, payload)
        self.assertEqual(
            H.received_headers.get(""Content-Type""),
            ""application/x-www-form-urlencoded"",
        )
",alpha_factory_v1/tests/test_requests_shim.py,RequestsShimTest,1,1.0467401685178159e-08,"The method 'test_post_bytes' is a unit test designed to verify the behavior of a server when handling POST requests with binary data. It checks if the server correctly receives and processes the binary payload, and if the content type is set as expected. This is a valid and useful test case for ensuring server functionality, especially in applications where binary data handling is crucial. Therefore, it is likely to be retained in the codebase."
survived,"        def __init__(self, host: str, port: int, app_id: str) -> None:
            captured[""a2a""] = f""{host}:{port}""  # pragma: no cover - record args
",tests/test_alpha_agi_business_3_v1.py,DummySock,1,1.444980317078884e-07,"The method is a constructor (__init__) for a class, which is essential for initializing class instances. It sets up initial values and configurations needed for the object to function correctly. The line of code within the constructor is capturing and storing a formatted string of host and port, which is likely used elsewhere in the class or application. Constructors are fundamental to object-oriented programming, and unless there is a significant reason to remove it (such as a complete refactor of the class structure), it is unlikely to be deleted."
survived,"            def __init__(self, val: str) -> None:
                pass
",tests/test_insight_orchestrator_features.py,TestLedger.DummyPk,0,0.9999980052698925,"The method is a constructor for a class, but it does not perform any initialization or store the 'val' parameter. This makes it effectively useless in its current form, as it does not contribute to the functionality of the class. Typically, constructors are used to set up initial state or store parameters for later use. Without any implementation, this constructor does not fulfill its intended purpose, making it likely to be deleted or replaced with a more functional version."
survived,"            def __init__(self) -> None:
                self.instructions = []
",tests/test_insight_orchestrator_features.py,TestLedger.DummyTx,1,8.592166611791576e-10,"The method is a constructor for a class, indicated by the name `__init__`. Constructors are essential for initializing new objects and setting up initial state, such as the `instructions` list in this case. Since constructors are fundamental to class functionality, they are unlikely to be deleted unless the entire class is being removed or refactored significantly. Therefore, this method will survive."
survived,"def test_get_kill_after_minutes_yaml(tmp_path, monkeypatch):
    yaml_file = tmp_path / ""dagster.yaml""
    yaml_file.write_text(""kill_sensor:\n  kill_after_minutes: 45\n"")
    monkeypatch.setenv(""DAGSTER_HOME"", str(tmp_path))
    assert get_kill_after_minutes() == 45
    monkeypatch.delenv(""DAGSTER_HOME"")
",tests/test_timeout_sensor.py,,1,8.152020648014727e-09,"The method `test_get_kill_after_minutes_yaml` is a unit test function that verifies the behavior of the `get_kill_after_minutes` function when a specific YAML configuration is set. It uses `tmp_path` to create a temporary file and `monkeypatch` to set and delete environment variables, which are common practices in testing to ensure isolation and no side effects. The function is well-structured for its purpose and does not contain any deprecated or harmful practices. Therefore, it is likely to be retained as it serves a clear purpose in testing the functionality of the code."
survived,"def test_authorize_button_success(monkeypatch):
    st.session_state.clear()
    client = OAuth2(""id"", ""secret"", ""auth"", ""token"")
    oauth = OAuth2Component(client=client)

    # Mock async client methods
    monkeypatch.setattr(oauth.client, ""get_authorization_url"", AsyncMock(return_value=""http://auth""))
    monkeypatch.setattr(oauth.client, ""get_access_token"", AsyncMock(return_value={""access_token"": ""tok""}))

    # Force deterministic state and component output
    monkeypatch.setattr(""streamlit_oauth._generate_state"", lambda key=None: ""STATE"")
    monkeypatch.setattr(""streamlit_oauth._authorize_button"", lambda **kwargs: {""code"": ""CODE"", ""state"": ""STATE""})

    result = oauth.authorize_button(""Login"", ""http://cb"", ""scope"", key=""k"")
    assert result[""token""][""access_token""] == ""tok""
    assert f""state-k"" not in st.session_state
",tests/test_oauth_component.py,,1,2.998960815863541e-09,"The method 'test_authorize_button_success' is a unit test function that uses the 'monkeypatch' fixture to mock certain methods and attributes. It is testing the 'authorize_button' method of an 'OAuth2Component' instance to ensure it behaves as expected. The test is well-structured, uses mocking effectively, and includes assertions to verify the expected outcomes. There is no indication that this test is redundant or incorrect, and it serves a clear purpose in verifying the functionality of the 'authorize_button' method. Therefore, it is likely to be retained in the codebase."
survived,"def test_generate_state_different_key():
    st.session_state.clear()
    s1 = _generate_state(key=""a"")
    s2 = _generate_state(key=""b"")
    assert s1 != s2
",tests/test_internal.py,,1,1.955568070542584e-08,"The method 'test_generate_state_different_key' is a unit test designed to verify that the '_generate_state' function produces different outputs when called with different keys. This is a typical and necessary test to ensure that the function behaves correctly and as expected. Unit tests are crucial for maintaining code quality and reliability, especially in larger projects. Therefore, this method is likely to be retained as it serves an important role in the testing suite."
survived,"def rotate_half(x):
    x1 = x[..., : x.shape[-1] // 2]
    x2 = x[..., x.shape[-1] // 2 :]
    return torch.cat((-x2, x1), dim=-1)
",src/model/u2tokenizer/rope.py,,1,7.73442280641062e-08,"The method `rotate_half` is a utility function that takes a tensor `x` and splits it into two halves along the last dimension. It then concatenates these halves in reverse order, effectively rotating the tensor by half its size along the last dimension. This kind of operation can be useful in various tensor manipulation tasks, such as data augmentation or specific algorithmic requirements. The function is simple, efficient, and leverages PyTorch's tensor operations, making it a useful tool in a PyTorch-based codebase. Therefore, it is likely to be retained as it provides a clear and potentially reusable functionality."
survived,"def _innovation_gain(
    pop_size: int = 6,
    generations: int = 1,
    *,
    seed: int | None = None,
    mut_rate: float = 0.1,
    xover_rate: float = 0.5,
) -> float:
    """"""Return a small gain from a short MATS run.

    Args:
        pop_size: Number of individuals in the MATS population.
        generations: Number of evolution steps.
        seed: Optional RNG seed for deterministic output.
        mut_rate: Probability of mutating a gene.
        xover_rate: Probability of performing crossover.
    """"""

    def fn(genome: list[float]) -> tuple[float, float, float, float]:
        x, y = genome
        effectiveness = x**2
        negative_evar = y**2
        complexity = (x + y) ** 2
        history = [1.0, 1.0, 1.0]
        base = lead_time._arima_baseline(history, 3)
        forecast_series = [b + x + y for b in base]
        lead_impr = lead_time.lead_signal_improvement(history, forecast_series, months=3, threshold=1.1)
        lead_penalty = 1.0 - lead_impr
        return effectiveness, negative_evar, complexity, lead_penalty

    pop = mats.run_evolution(
        fn,
        2,
        population_size=pop_size,
        mutation_rate=mut_rate,
        crossover_rate=xover_rate,
        generations=generations,
        seed=seed,
    )
    m = len(pop[0].fitness or ())
    best = min(pop, key=lambda ind: sum(ind.fitness or (0.0,) * m))
    return 0.1 / (1.0 + sum(best.fitness or (0.0,) * m))
",alpha_factory_v1/core/simulation/forecast.py,,1,6.023574641292144e-08,"The method '_innovation_gain' is a specialized function that calculates a small gain from a short MATS (Multi-Agent Temporal Simulation) run. It is designed to be flexible with parameters like population size, mutation rate, and crossover rate, which are typical in evolutionary algorithms. The function also includes a deterministic option with a seed, which is useful for reproducibility in simulations. The method is well-documented and seems to be part of a larger system that involves evolutionary computation and time series forecasting. Given its specific purpose and integration with other components (like 'lead_time' and 'mats'), it is likely to be useful in its context and not redundant. Therefore, it is more likely to be retained in the codebase."
survived,"    def close(self) -> None:
        """"""Unsubscribe the agent from the bus.""""""
        self.bus.unsubscribe(self.name, self._handler)
",alpha_factory_v1/core/agents/base_agent.py,BaseAgent,1,2.998960815863541e-09,"The method 'close' is a standard way to clean up resources or unsubscribe from events in many programming contexts. It is a part of the class's interface to ensure that the object can properly detach itself from external dependencies, which is crucial for preventing memory leaks or unwanted behavior. The method is simple, clear, and serves a necessary purpose in managing the lifecycle of the object. Therefore, it is likely to be retained."
survived,"def evaluate(
    pop: Population,
    fn: Callable[[List[float]], Tuple[float, ...]],
    novelty: NoveltyIndex | None = None,
    critics: Iterable[Callable[[List[float]], float]] | None = None,
) -> None:
    """"""Assign fitness scores using ``fn`` plus ``critics`` and optional novelty.""""""

    for ind in pop:
        base = fn(ind.genome)
        extra = tuple(c(ind.genome) for c in (critics or []))
        if novelty is not None:
            spec = "","".join(f""{g:.3f}"" for g in ind.genome)
            div = novelty.divergence(spec)
            ind.fitness = base + extra + (div,)
        else:
            ind.fitness = base + extra

    fits = [ind.fitness or () for ind in pop]
    scores = surrogate_fitness.aggregate(fits)
    for ind, sc in zip(pop, scores):
        ind.score = sc
",alpha_factory_v1/core/simulation/mats.py,,1,7.582560422162384e-10,"The method 'evaluate' is likely to survive because it is a well-structured and useful function for evaluating a population of individuals in an evolutionary algorithm context. It assigns fitness scores based on a provided function, optional critics, and novelty index, which are common requirements in genetic algorithms and evolutionary strategies. The method is flexible, allowing for different evaluation strategies, and it integrates well with the concept of novelty search, which is a popular technique in evolutionary computation. Additionally, the code is clear and follows good practices, making it maintainable and understandable."
survived,"def thermodynamic_trigger(sector: Sector, capability: float) -> bool:
    return free_energy(sector, capability) < 0
",alpha_factory_v1/core/simulation/forecast.py,,1,6.69158608681505e-10,"The method `thermodynamic_trigger` is a simple utility function that checks if the free energy of a given sector with a certain capability is negative. This type of function is often useful in simulations or calculations involving thermodynamics, physics, or energy systems. It encapsulates a specific logic that might be reused in different parts of a program dealing with energy calculations. Unless the entire context or the use case for this function is removed, such utility functions are generally retained for their specific purpose and reusability. Therefore, it is likely to survive."
survived,"def test_non_learning_event_zero() -> None:
    state = DummyState()
    value = ed.reward(state, None, {""context"": ""watch tv""})
    assert value == 0.0",tests/test_education_reward.py,,1,5.60279640614594e-09,"The method 'test_non_learning_event_zero' is a unit test that checks if the 'reward' function returns 0.0 when given a specific state and context. Unit tests are generally crucial for ensuring code reliability and are not typically deleted unless they are redundant or replaced by more comprehensive tests. Since this test seems to serve a specific purpose of validating the behavior of the 'reward' function, it is likely to be retained."
survived,"def test_unhandled_violation_penalty() -> None:
    _reset()
    res = {""request_id"": ""r2"", ""violation"": True, ""severity"": 10, ""autocorrected"": False}
    value = sc.reward(None, None, res)
    assert value <= -1.0
    assert value >= -2.0
",tests/test_safety_compliance_reward.py,,1,7.73442280641062e-08,"The method `test_unhandled_violation_penalty` is a unit test function that checks the behavior of a system when a violation occurs. It ensures that the penalty value returned by the `sc.reward` function falls within a specific range (-1.0 to -2.0). This kind of test is crucial for maintaining the integrity of the system's response to violations, especially in systems where penalties are applied based on certain conditions. Since testing is a fundamental part of software development to ensure code reliability and correctness, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered."
survived,"def test_first_occurrence_positive() -> None:
    _reset()
    res = {""context"": ""run 5k"", ""time"": ""2025-04-22T07:00:00Z""}
    value = hc.reward(None, None, res)
    assert isinstance(value, float)
    assert 0.0 <= value <= 1.0
",tests/test_habit_consistency_reward.py,,1,1.8189616842444243e-09,"The method `test_first_occurrence_positive` is a unit test function that checks the behavior of the `hc.reward` function. It ensures that the return value is a float and falls within a specific range. Unit tests are crucial for maintaining code quality and ensuring that functions behave as expected. Therefore, this method is likely to be retained as it serves an important role in testing the functionality of the code."
survived,"def test_non_dict_returns_zero() -> None:
    assert er.reward(None, None, 123) == 0.0",tests/test_efficiency_reward.py,,1,3.850741907939403e-09,"The method 'test_non_dict_returns_zero' is a test function that checks if the 'reward' method of the 'er' object returns 0.0 when passed non-dictionary arguments. This is a valid test case to ensure that the 'reward' method handles unexpected input types correctly. Test functions are generally not deleted unless they are redundant or incorrect, and this test seems to serve a clear purpose in validating the behavior of the 'reward' method. Therefore, it is likely to be retained."
survived,"def test_chat_exception_logs_error(monkeypatch, caplog):
    caplog.set_level(logging.ERROR)
    monkeypatch.setattr(local_llm, ""_CALL"", lambda _p, _c: (_ for _ in ()).throw(RuntimeError(""boom"")))

    out = local_llm.chat(""hello"", local_llm.config.CFG)

    assert out == ""[offline] hello""
    assert any(""boom"" in r.getMessage() for r in caplog.records)",tests/test_local_llm_logging.py,,1,1.522997951276035e-08,"The method 'test_chat_exception_logs_error' is a unit test designed to verify that a specific error handling behavior is correctly implemented in the 'local_llm' module. It uses the 'monkeypatch' fixture to simulate an exception being thrown during a call to 'local_llm._CALL', and then checks that the error is logged correctly. This is a common and useful pattern in testing to ensure robustness and reliability of error handling in code. Since it serves a clear purpose in testing the logging of exceptions, it is likely to be retained in the codebase."
survived,"    def __init__(self) -> None:
        self.logged: list[messaging.Envelope] = []
",tests/test_safety_guardian_property.py,DummyLedger,1,1.955568070542584e-08,"The method is a constructor for a class, indicated by the name `__init__`. Constructors are essential for initializing new objects and setting up initial state, such as initializing the `logged` attribute in this case. Therefore, it is unlikely to be deleted as it is a fundamental part of the class structure."
survived,"    def publish(self, topic: str, env: messaging.Envelope) -> None:
        self.published.append((topic, env))
",tests/test_safety_guardian_property.py,DummyBus,1,1.4166087846364157e-09,"The method 'publish' is a simple utility function that appends a tuple of a topic and an envelope to a list called 'published'. This method is likely part of a larger system that deals with messaging or event handling. The method itself is straightforward and serves a clear purpose in tracking or logging published messages. There is no indication that this functionality is obsolete or redundant, and it seems to be a necessary part of the system's operation. Therefore, it is likely to be retained."
survived,"def _disruption_df(traj: list[Any]) -> ""pd.DataFrame"":
    """"""Return the first disruption year per sector.""""""
    import pandas as pd

    years: dict[str, int] = {}
    for point in traj:
        for sec in point.sectors:
            if sec.disrupted and sec.name not in years:
                years[sec.name] = point.year
    return pd.DataFrame({""sector"": list(years.keys()), ""year"": list(years.values())})
",src/interface/minimal_ui.py,,1,1.6052280526088547e-09,"The method '_disruption_df' is a utility function that processes a list of trajectory data to extract the first year of disruption for each sector. It uses a dictionary to track the first occurrence of a disruption and then converts this information into a pandas DataFrame. This type of function is useful for data analysis and reporting, especially in contexts where understanding the timing of disruptions is important. Given its utility and the fact that it is well-defined and uses standard libraries, it is likely to be retained in the codebase."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/transpiler/x/py/bench_block.py,,1,9.931195248674785e-08,"The method _now() is a utility function that generates a pseudo-random number based on a global seed if it is set, or returns the current time in nanoseconds if not. This kind of function can be useful in scenarios where deterministic behavior is needed for testing or simulation purposes. The use of a global seed allows for repeatable results, which is a common requirement in testing environments. Since this function provides a specific utility that can be useful in various contexts, it is likely to be retained in the codebase."
survived,"    def test_warn_without_numpy(self) -> None:
        os.environ[""VECTOR_STORE_USE_SQLITE""] = ""true""
        os.environ.pop(""PGHOST"", None)
        with mock.patch.object(memf, ""np"", None, create=True):
            with self.assertLogs(""AlphaFactory.MemoryFabric"", level=""WARNING"") as cm:
                fabric = memf.MemoryFabric()
                fabric.close()
        os.environ.pop(""VECTOR_STORE_USE_SQLITE"", None)
        self.assertTrue(any(""numpy required for SQLite"" in msg for msg in cm.output))
",tests/test_memory_fabric_sqlite.py,TestMemoryFabricSQLiteWarning,1,7.582560422162384e-10,"The method 'test_warn_without_numpy' is a unit test designed to check if a warning is logged when numpy is not available and SQLite is used. It uses environment variables and mocking to simulate the absence of numpy and then verifies if the appropriate warning message is logged. This is a valid and useful test case to ensure that the system behaves correctly under specific conditions. Therefore, it is likely to be retained in the codebase."
survived,"def test_standard_json_format():
    source_files = {
        ""src/Contract.sol"": {""content"": ""contract C {}""},
        ""src/Dependency.sol"": {""content"": ""contract D {}""},
    }
    assert is_standard_json_contract(source_files)",tests/test_utils.py,,1,1.522997951276035e-08,"The method 'test_standard_json_format' is a test function that checks if a given set of source files adhere to a standard JSON contract format. This type of function is typically used in testing frameworks to ensure code quality and correctness. Test functions are generally essential for maintaining robust software, as they help catch errors and ensure that code changes do not break existing functionality. Therefore, it is unlikely that this method will be deleted, as it serves a critical role in the development process."
survived,"    def subscribe(self, topic: str, handler: Callable[[Envelope], Awaitable[None] | None]) -> None:
        self._subs.setdefault(topic, []).append(handler)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/messaging.py,A2ABus,1,2.998960815863541e-09,"The method 'subscribe' is a common pattern in event-driven or message-passing systems where handlers are registered to respond to specific topics or events. This method is likely to be essential for the functionality of such systems, allowing dynamic and flexible handling of messages. The use of 'setdefault' ensures that the topic has a list to append handlers to, which is a robust way to manage subscriptions. Therefore, it is unlikely to be deleted as it provides core functionality."
survived,"    async def handle(self, env):
        pass",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/strategy_agent.py,StrategyAgent,0,0.9999999586006244,"The method 'handle' is defined as an asynchronous function but contains only a 'pass' statement, meaning it currently does nothing. Without any implementation or documentation indicating future use or purpose, it is likely to be considered dead code. Unless there is a specific plan to implement this method in the future, it is likely to be deleted to maintain code cleanliness and efficiency."
survived,"    def __init__(self, name: str, bus: messaging.A2ABus, ledger: ""Ledger"") -> None:
        self.name = name
        self.bus = bus
        self.ledger = ledger
        self.oai_ctx = AgentContext() if isinstance(AgentContext, type) else None
        self.adk_client = adk.Client() if adk else None
        self.bus.subscribe(name, self._on_envelope)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/base_agent.py,BaseAgent,1,1.444980317078884e-07,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class with specific attributes. It sets up important components like 'name', 'bus', 'ledger', and subscribes to a messaging bus, which are likely crucial for the class's functionality. Constructors are fundamental to object-oriented programming, and unless the class itself is deprecated or refactored, the constructor is unlikely to be deleted."
survived,"    async def handle(self, env):
        pass",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/market_agent.py,MarketAgent,0,0.999999922655772,"The method 'handle' is defined but not implemented, as it only contains a 'pass' statement. Without any functionality, it doesn't serve any purpose in its current state. Unless there is a specific reason to keep a placeholder method, such as future implementation plans or interface requirements, it is likely to be deleted to clean up the codebase."
survived,"def test_cli_exec() -> None:
    assert True",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_demo_cli.py,,0,0.9999998144608401,"The method `test_cli_exec` is a placeholder test function that only contains an assertion that always passes (`assert True`). This kind of test does not provide any meaningful validation or coverage for the codebase. Typically, such placeholder tests are either expanded with actual test logic or removed if they serve no purpose. Given that this function currently does not contribute to testing any functionality, it is likely to be deleted unless it is expanded with real test cases."
survived,"def test_nsga2_step_runs() -> None:
    pop = [mats.Individual([0.0, 0.0]) for _ in range(4)]

    def fn(g):
        return (g[0] ** 2, g[1] ** 2)

    new = mats.nsga2_step(pop, fn, mu=4)
    assert len(new) == 4",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_mats.py,,1,1.0261879630648829e-10,"The method `test_nsga2_step_runs` is a unit test designed to verify the functionality of the `nsga2_step` function from the `mats` module. It checks that the function returns a population of the expected size. Unit tests are crucial for ensuring code reliability and are typically retained in the codebase to prevent future regressions. Therefore, it is likely that this method will be Survived (1)."
survived,"    def __init__(self, bus, ledger) -> None:
        super().__init__(""safety"", bus, ledger)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/safety_agent.py,SafetyGuardianAgent,1,9.931195248674785e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting up initial states. Therefore, it is unlikely to be deleted unless the entire class is being refactored or removed, which is not indicated here."
survived,"    def __init__(self) -> None:
        self._clients: List[GeminiClientWrapper] = []
        self._id_map: Dict[str, GeminiClientWrapper] = {}
        self._round_robin = deque()

        for c in g_config.gemini.clients:
            client = GeminiClientWrapper(
                client_id=c.id,
                secure_1psid=c.secure_1psid,
                secure_1psidts=c.secure_1psidts,
            )
            self._clients.append(client)
            self._id_map[c.id] = client
            self._round_robin.append(client)
",app/services/pool.py,GeminiClientPool,1,3.850741907939403e-09,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class. It sets up important attributes like _clients, _id_map, and _round_robin, and populates them with instances of GeminiClientWrapper based on the configuration. Constructors are fundamental to object-oriented programming and are rarely deleted unless the entire class is being refactored or removed. Therefore, it is highly likely to survive."
survived,"def fix_paths(target: Path) -> None:
    """"""Adjust relative links in the mirrored demo.""""""
    index = target / ""index.html""
    if index.exists():
        data = index.read_text()
        for old, new in REPLACEMENTS.items():
            data = data.replace(old, new)
        index.write_text(data)

    script = target / ""script.js""
    if script.exists():
        txt = script.read_text()
        txt = txt.replace(""../assets/"", ""../../../assets/"")
        script.write_text(txt)
",scripts/mirror_demo_pages.py,,1,1.8189616842444243e-09,"The method 'fix_paths' is a utility function that adjusts file paths in a mirrored demo by modifying the contents of 'index.html' and 'script.js' files if they exist. This type of function is often useful in scenarios where file structures are mirrored or copied, and relative paths need to be corrected to ensure proper linking. The function is straightforward, performs a specific task, and does not have any apparent issues or redundancies that would warrant its removal. Therefore, it is likely to be retained in the codebase."
survived,"    def test_has_version(self) -> None:
        mod = importlib.import_module(""alpha_factory_v1.demos.cross_industry_alpha_factory"")
        self.assertTrue(hasattr(mod, ""__version__""))
",tests/test_cross_industry_version.py,TestCrossIndustryVersion,1,2.998960815863541e-09,"The method `test_has_version` is a unit test that checks if the module 'alpha_factory_v1.demos.cross_industry_alpha_factory' has an attribute '__version__'. This is a common practice to ensure that modules have versioning information, which is crucial for maintaining and managing dependencies. The test is simple, non-intrusive, and serves a clear purpose in the context of software development and version control. Therefore, it is likely to be retained as part of the test suite."
survived,"def pytest_runtest_setup(item: pytest.Item) -> None:
    if ""requires_torch"" in item.keywords and not _HAS_TORCH:
        pytest.skip(""torch required"", allow_module_level=True)
",tests/conftest.py,,1,1.522997951276035e-08,"The method `pytest_runtest_setup` is a hook function used in pytest to set up test items before they are run. The function checks if a test item has the keyword 'requires_torch' and if the torch library is not available, it skips the test. This is a common pattern in testing frameworks to conditionally skip tests based on the environment or dependencies. The method is useful for ensuring that tests which require certain dependencies are not run when those dependencies are not available, preventing unnecessary test failures. This functionality is likely to be useful and relevant for projects that use PyTorch, and thus, the method is likely to be retained."
survived,"    def get_player_location_on_minimap(self):
        """"""
        Get the player's location on the minimap by detecting a unique 4-pixel color.
        Return the player's location in minimap coordinates.
        """"""
        # Crop the minimap from the game screen
        x0, y0 = self.loc_minimap
        h, w, _ = self.img_route.shape
        img_minimap = self.img_frame[y0:y0 + h//4, x0:x0 + w//4]

        # Find pixels matching the player color
        mask = cv2.inRange(img_minimap,
                           self.cfg.minimap_player_color,
                           self.cfg.minimap_player_color)
        coords = cv2.findNonZero(mask)
        if coords is None or len(coords) < 4:
            logger.warning(""Fail to locate player location on minimap"")
            return None

        # Calculate the average location of the matching pixels
        avg = coords.mean(axis=0)[0]  # shape (1,2), so we take [0]
        loc_player_minimap = (int(round(avg[0] * self.cfg.minimap_upscale_factor)),
                              int(round(avg[1] * self.cfg.minimap_upscale_factor)))
        # Draw red circle to mark player's location on minimap
        cv2.circle(self.img_route_debug, loc_player_minimap,
                   radius=4, color=(0, 255, 255), thickness=2)

        return loc_player_minimap
",src/legacy/mapleStoryAutoLevelUp_legacy.py,MapleStoryBot,1,1.3440409770490404e-08,"The method 'get_player_location_on_minimap' is a crucial part of a game automation or analysis tool, as it determines the player's position on the minimap by detecting a specific color. This functionality is essential for tracking player movements and making decisions based on their location. The method is well-structured, uses OpenCV for image processing, and includes error handling for cases where the player cannot be located. These factors suggest that the method is useful and likely to be retained in the codebase."
survived,"    def run_once(self):
        '''
        Process one game window frame
        '''
        # Get window game raw frame
        self.frame = self.capture.get_frame()
        if self.frame is None:
            logger.warning(""Failed to capture game frame."")
            return

        # Make sure resolution is as expected
        if self.cfg[""game_window""][""size""] != self.frame.shape[:2]:
            text = (
                f""Unexpeted window size: {self.frame.shape[:2]} ""
                f""(expect {self.cfg['game_window']['size']})""
            )
            logger.error(text)
            return

        # Resize raw frame to working size
        self.img_frame = cv2.resize(self.frame, WINDOW_WORKING_SIZE,
                                    interpolation=cv2.INTER_NEAREST)

        # Grayscale game window
        self.img_frame_gray = cv2.cvtColor(self.img_frame, cv2.COLOR_BGR2GRAY)

        # Image for debug use
        self.img_frame_debug = self.img_frame.copy()

        # Enable cached location since second frame
        self.is_first_frame = False

        # Check if user want to disable dice rolling
        if self.kb.is_pressed_func_key[0]: # 'F1' is pressed
            self.is_enable = not self.is_enable
            logger.info(f""User press F1, is_enable = {self.is_enable}"")
            self.kb.is_pressed_func_key[0] = False

        # Check if need to save screenshot
        if self.kb.is_pressed_func_key[1]: # 'F2' is pressed
            screenshot(self.img_frame)
            self.kb.is_pressed_func_key[1] = False

        if self.is_enable and self.kb.is_game_window_active():
            loc_dice = (981, 445)
            loc_first_box = (890, 371)
            box_size = (22, 37) # (h ,w)
            box_y_interval = 25
            window_title = self.cfg[""game_window""][""title""]

            # Parse the attribute number
            attibutes_info = []
            for i, attibute in enumerate([""STR"", ""DEX"", ""INT"", ""LUK""]):
                # Calculate the box position
                p0 = (loc_first_box[0], loc_first_box[1] + i * box_y_interval)
                p1 = (p0[0] + box_size[1], p0[1] + box_size[0])

                # Crop the box region from the image
                img_roi = self.img_frame_gray[p0[1]:p1[1], p0[0]:p1[0]]

                # Match with each number template (from 4 to 11)
                best_score = float('inf')
                best_digit = None
                for idx, img_number in enumerate(self.img_numbers, start=4):
                    _, score, _ = find_pattern_sqdiff(img_roi, img_number)
                    if score < best_score:
                        best_score = score
                        best_digit = idx
                logger.info(f""[{attibute}]: {best_digit} (score: {round(best_score, 2)})"")
                attibutes_info.append((best_digit, best_score))

                # Draw box and put text on debug image
                cv2.rectangle(self.img_frame_debug, p0, p1, (0, 0, 255), 1)
                cv2.putText(
                    self.img_frame_debug,
                    f""{best_digit}"",
                    (p0[0], p0[1] - 5),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.5,
                    (0, 255, 255),
                    1,
                    cv2.LINE_AA
                )

            # for val, score in attibutes_info:
            #     if score > 0.11:
            #         logger.warning(f""Stop! Unable to recognize number: {(val, score)})"")
            #         self.is_enable = False

            # Check if is equal to target
            is_jackpot = True
            for i, (val, score) in enumerate(attibutes_info):
                target = self.args.attribute[i]
                if target is not None and target != val:
                    is_jackpot = False

            # Stop rolling dice if reach target
            if is_jackpot:
                self.is_enable = False
                logger.info(""Hit Jackpot! Stop!"")

            # Click to roll the dice or not
            if self.is_enable:
                click_in_game_window(window_title, loc_dice)
                logger.info(""Roll the dice"")

        # Show debug image on window
        self.update_img_frame_debug()
",tools/AutoDiceRoller.py,AutoDiceRoller,1,5.3157849718487075e-08,"The method 'run_once' is a crucial part of the game automation process, handling the capture and processing of game frames, user input handling, and decision-making for game actions. It includes error handling, logging, and user interaction features, making it a well-rounded and necessary function for the application's functionality. Removing it would likely break the core functionality of the application, as it seems to be the main loop for processing game frames and responding to user inputs. Therefore, it is unlikely to be deleted."
survived,"    def on_closed(self):
        '''
        捕捉結束後的回調
        '''
        logger.warning(""Capture session closed."")
        cv2.destroyAllWindows()
",src/input/GameWindowCapturorForMac.py,GameWindowCapturor,1,3.3982678079468468e-09,"The method `on_closed` is a simple callback function that logs a warning message and closes all OpenCV windows. This is a common and useful functionality in applications that use OpenCV for image or video processing, as it ensures that resources are properly released when a session ends. The method is straightforward, does not have any apparent issues, and serves a clear purpose in the context of managing OpenCV sessions. Therefore, it is likely to be retained in the codebase."
survived,"    def is_player_stuck_minimap(self):
        """"""
        Detect if the player is stuck (not moving).
        If stuck for more than WATCH_DOG_TIMEOUT seconds, performs a random action.
        """"""
        dx = abs(self.loc_player_minimap[0] - self.loc_watch_dog[0])
        dy = abs(self.loc_player_minimap[1] - self.loc_watch_dog[1])

        current_time = time.time()
        if dx + dy > self.cfg.watch_dog_range:
            # Player moved, reset watchdog timer
            self.loc_watch_dog = self.loc_player_minimap
            self.t_watch_dog = current_time
            return False

        dt = current_time - self.t_watch_dog
        if dt > self.cfg.watch_dog_timeout:
            # watch dog idle for too long, player stuck
            self.loc_watch_dog = self.loc_player_minimap
            self.t_watch_dog = current_time
            logger.warning(f""[is_player_stuck] Player stuck for {dt} seconds."")
            return True
        return False
",src/legacy/mapleStoryAutoLevelUp_legacy.py,MapleStoryBot,1,5.211412485172657e-10,"The method 'is_player_stuck_minimap' is likely to survive because it provides a useful functionality in a game or simulation context. It detects if a player is stuck by monitoring their movement on a minimap and takes action if the player has not moved for a specified timeout period. This can enhance user experience by preventing the player from being stuck indefinitely, which is a common issue in games. Additionally, the method is well-documented and uses clear logic to determine if the player is stuck, making it a valuable part of the codebase."
survived,"    def __init__(self, args):
        self.cfg = Config # Configuration
        self.args = args
        self.status = ""hunting"" # 'resting', 'finding_rune', 'near_rune', 'solving_rune'
        self.idx_routes = 0 # Index of route
        self.hp_ratio = 1.0 # HP bar ratio
        self.mp_ratio = 1.0 # MP bar ratio
        self.exp_ratio = 1.0 # EXP bar ratio
        self.monster_info = [] # monster information
        self.fps = 0 # Frame per second
        self.is_first_frame = True # Disable cached location for first frame
        self.rune_detect_level = 0
        # Coordinate (top-left coordinate)
        self.loc_nametag = (0, 0) # nametag location on window
        self.loc_camera = (0, 0) # camera location on map
        self.loc_watch_dog = (0, 0) # watch dog
        self.loc_player_global = (0, 0) # player location on map
        self.loc_player = (0, 0) # player location on window
        self.loc_player_minimap = (0, 0) # Player's location on minimap
        self.loc_minimap = (0, 0)
        # Images
        self.frame = None # raw image
        self.img_frame = None # game window frame
        self.img_frame_gray = None # game window frame graysale
        self.img_frame_debug = None
        self.img_route = None # route map
        self.img_route_debug = None
        # Timers
        self.t_last_frame = time.time() # Last frame timer, for fps calculation
        self.t_last_switch_status = time.time() # Last status switches timer
        self.t_watch_dog = time.time() # Last movement timer
        self.t_last_teleport = time.time() # Last teleport timer
        self.t_patrol_last_attack = time.time() # Last patrol attack timer
        self.t_last_camera_missed = time.time() # Last camera loc missed
        # Patrol mode
        self.is_patrol_to_left = True
        self.patrol_turn_point_cnt = 0
        self.img_frame_gray_last = None

        # Set status to hunting for start
        self.switch_status(""hunting"")

        map_dir = ""minimaps"" if self.cfg.is_use_minimap else ""maps""

        if args.patrol:
            # Patrol mode doesn't need map or route
            self.img_map = None
            self.img_routes = []
            self.img_route_rest = None
        else:
            # Load map for camera localization
            if self.cfg.is_use_minimap:
                self.img_map = load_image(f""{map_dir}/{args.map}/map.png"",
                                        cv2.IMREAD_COLOR)
            else:
                self.img_map = load_image(f""{map_dir}/{args.map}/map.png"",
                                        cv2.IMREAD_GRAYSCALE)
                self.img_map_resized = cv2.resize(
                    self.img_map, (0, 0),
                    fx=self.cfg.localize_downscale_factor,
                    fy=self.cfg.localize_downscale_factor)
            # Load route*.png images
            route_files = sorted(glob.glob(f""{map_dir}/{args.map}/route*.png""))
            route_files = [p for p in route_files if not p.endswith(""route_rest.png"")]
            self.img_routes = [
                cv2.cvtColor(load_image(p), cv2.COLOR_BGR2RGB) for p in route_files
            ]
            # Load rest route
            self.img_route_rest = cv2.cvtColor(
                load_image(f""{map_dir}/{args.map}/route_rest.png""), cv2.COLOR_BGR2RGB)

            # Upscale minimap route map for better debug visualization
            if self.cfg.is_use_minimap:
                img_routes_resized = []
                for img_route in self.img_routes:
                    img_routes_resized.append(cv2.resize(
                        img_route, (0, 0),
                        fx=self.cfg.minimap_upscale_factor,
                        fy=self.cfg.minimap_upscale_factor,
                        interpolation=cv2.INTER_NEAREST))
                self.img_routes = img_routes_resized
                self.img_route_rest = cv2.resize(
                            self.img_route_rest, (0, 0),
                            fx=self.cfg.minimap_upscale_factor,
                            fy=self.cfg.minimap_upscale_factor,
                            interpolation=cv2.INTER_NEAREST)

        # Load other images
        self.img_nametag = load_image(""name_tag.png"")
        self.img_nametag_gray = load_image(""name_tag.png"", cv2.IMREAD_GRAYSCALE)
        self.img_rune_warning = load_image(""rune/rune_warning.png"", cv2.IMREAD_GRAYSCALE)
        self.img_rune = load_image(""rune/rune.png"")
        self.img_rune_gray = load_image(""rune/rune.png"", cv2.IMREAD_GRAYSCALE)
        self.img_arrows = {
            ""left"":
                [load_image(""rune/arrow_left_1.png""),
                load_image(""rune/arrow_left_2.png""),
                load_image(""rune/arrow_left_3.png""),],
            ""right"":
                [load_image(""rune/arrow_right_1.png""),
                load_image(""rune/arrow_right_2.png""),
                load_image(""rune/arrow_right_3.png""),],
            ""up"":
                [load_image(""rune/arrow_up_1.png""),
                load_image(""rune/arrow_up_2.png""),
                load_image(""rune/arrow_up_3.png"")],
            ""down"":
                [load_image(""rune/arrow_down_1.png""),
                load_image(""rune/arrow_down_2.png""),
                load_image(""rune/arrow_down_3.png""),],
        }

        # Load monsters images from monster/{monster_name}
        self.monsters = {}
        for monster_name in args.monsters.split("",""):
            imgs = []
            for file in glob.glob(f""monster/{monster_name}/{monster_name}*.png""):
                # Add original image
                img = load_image(file)
                imgs.append((img, get_mask(img, (0, 255, 0))))
                # Add flipped image
                img_flip = cv2.flip(img, 1)
                imgs.append((img_flip, get_mask(img_flip, (0, 255, 0))))
            if imgs:
                self.monsters[monster_name] = imgs
            else:
                logger.error(f""No images found in monster/{monster_name}/{monster_name}*"")
                raise RuntimeError(f""No images found in monster/{monster_name}/{monster_name}*"")
        logger.info(f""Loaded monsters: {list(self.monsters.keys())}"")

        # Start keyboard controller thread
        self.kb = KeyBoardController(self.cfg, args)
        if args.disable_control:
            self.kb.disable()

        # Start game window capturing thread
        logger.info(""Waiting for game window to activate, please click on game window"")
        self.capture = GameWindowCapturor(self.cfg)
",src/legacy/mapleStoryAutoLevelUp_legacy.py,MapleStoryBot,1,2.9023122007764653e-06,"The method is a constructor (__init__) for a class, which is a fundamental part of object-oriented programming. It initializes various attributes and sets up the initial state of an object. This method is essential for the proper functioning of the class it belongs to, as it prepares the object for use by setting up necessary configurations, loading resources, and starting threads. Deleting this method would break the class's functionality, making it unable to initialize objects correctly. Therefore, it is unlikely to be deleted."
survived,"    def get_player_location(self):
        '''
        get player location by detecting player's nametag
        '''
        img_roi = self.img_frame_gray[self.cfg.camera_ceiling:self.cfg.camera_floor, :]

        # Pad search region to avoid edge cut-off issue (full template size)
        (pad_y, pad_x) = self.img_nametag.shape[:2]
        img_roi_padded = cv2.copyMakeBorder(
            img_roi,
            pad_y, pad_y, pad_x, pad_x,
            borderType=cv2.BORDER_REPLICATE  # replicate border for safe matching
        )

        # Adjust previous location
        if self.is_first_frame:
            last_result = None
        else:
            last_result = (
                self.loc_nametag[0] + pad_x,
                self.loc_nametag[1] - self.cfg.camera_ceiling + pad_y
            )

        # Split nametag into left and right half, detect seperately and pick highest socre
        # This localization method is more robust for occluded nametag
        h, w = self.img_nametag_gray.shape
        mask_full = get_mask(self.img_nametag, (0, 255, 0))
        nametag_variants = {
            ""left"": {
                ""img_pattern"": self.img_nametag_gray[:, :w // 2],
                ""mask"": mask_full[:, :w // 2],
                ""last_result"": last_result,
                ""score_penalty"": 0.0
            },
            ""right"": {
                ""img_pattern"": self.img_nametag_gray[:, w // 2:],
                ""mask"": mask_full[:, w // 2:],
                ""last_result"": (last_result[0] + w // 2, last_result[1]) if last_result else None,
                ""score_penalty"": 0.0
            }
        }

        # Match template for each split nametag
        matches = []
        for tag_type, data in nametag_variants.items():
            loc, score, is_cached = find_pattern_sqdiff(
                img_roi_padded,
                data[""img_pattern""],
                last_result=data[""last_result""],
                mask=data[""mask""],
                global_threshold=0.3
            )
            w_match = data[""img_pattern""].shape[1]
            h_match = data[""img_pattern""].shape[0]
            score += data[""score_penalty""]
            matches.append((tag_type, loc, score, w_match, h_match, is_cached))

        # Choose the best match
        matches.sort(key=lambda x: (not x[5], x[2]))
        tag_type, loc_nametag, score, w_match, h_match, is_cached = matches[0]
        if tag_type == ""right"":
            loc_nametag = (loc_nametag[0] - w_match, loc_nametag[1])

        # Convert back to original (unpadded) coordinates
        loc_nametag = (
            loc_nametag[0] - pad_x,
            loc_nametag[1] - pad_y + self.cfg.camera_ceiling
        )

        # Update name tag location if confidence is good
        if score < self.cfg.nametag_diff_thres:
            self.loc_nametag = loc_nametag
        loc_player = (
            self.loc_nametag[0] - self.cfg.nametag_offset[0],
            self.loc_nametag[1] - self.cfg.nametag_offset[1]
        )

        # Draw name tag detection box for debug
        draw_rectangle(
            self.img_frame_debug, self.loc_nametag, self.img_nametag.shape,
            (0, 255, 0), """")
        text = f""NameTag,{round(score, 2)},"" + \
                f""{'cached' if is_cached else 'missed'},"" + \
                f""{tag_type}""
        cv2.putText(self.img_frame_debug, text,
                    (self.loc_nametag[0], self.loc_nametag[1] + self.img_nametag.shape[0] + 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

        # Draw player center
        cv2.circle(self.img_frame_debug,
                loc_player, radius=3,
                color=(0, 0, 255), thickness=-1)

        return loc_player
",src/legacy/mapleStoryAutoLevelUp_legacy.py,MapleStoryBot,1,3.2241866333029355e-08,"The method `get_player_location` is a well-structured function that performs a specific task of detecting a player's location by analyzing the player's nametag in an image. It includes image processing techniques such as template matching and masking, which are common in computer vision tasks. The method is detailed, with comments explaining each step, and it includes error handling for the first frame and adjustments for previous locations. Additionally, it provides visual debugging information by drawing on the image. These characteristics suggest that the method is functional, useful, and likely to be retained in the codebase."
survived,"def test_new_async_manager_merges_tags_with_config() -> None:
    config = {""callbacks"": None, ""tags"": [""a""]}
    manager = get_async_callback_manager_for_config(config, tags=[""b""])
    assert manager.inheritable_tags == [""a"", ""b""]",libs/langgraph/tests/test_config_async.py,,1,1.6052280526088547e-09,"The method `test_new_async_manager_merges_tags_with_config` is a test function that checks the functionality of merging tags in an asynchronous callback manager. Test functions are generally not deleted unless they are redundant or the functionality they test is removed. Since this function is testing a specific feature (merging tags), it is likely to be retained to ensure that this feature works correctly. Therefore, the method will survive."
survived,"        def __init__(self, *a, base_url: str | None = None, **_k) -> None:
            self.base_url = base_url.rstrip(""/"") if base_url else None
",tests/test_aiga_openai_bridge_offline.py,OpenAIAgent,1,1.0467401685178159e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming in Python. Constructors are essential for initializing new objects and setting initial values for instance variables. The use of type hinting with 'str | None' is a modern Python feature that improves code readability and maintainability. The method is concise and performs a necessary function of setting up the 'base_url' attribute. There is no indication that this method is redundant or unnecessary, so it is likely to be retained."
survived,"        def __call__(self, prompt: str) -> str:
            if not self.base_url:
                return ""no base url""
            r = requests.post(
                f""{self.base_url}/chat/completions"",
                json={""model"": ""stub"", ""messages"": [{""role"": ""user"", ""content"": prompt}]},
                timeout=5,
            )
            r.raise_for_status()
            return r.json()[""choices""][0][""message""][""content""]
",tests/test_aiga_openai_bridge_offline.py,OpenAIAgent,1,1.0467401685178159e-08,"The method is likely to survive because it implements a common pattern for making HTTP POST requests to an API endpoint. It checks for a base URL, constructs a request with a JSON payload, handles potential errors with `raise_for_status`, and returns a specific part of the JSON response. This is a typical and necessary functionality for interacting with APIs, especially in applications that require dynamic content generation or interaction with external services."
survived,"    async def run() -> None:
        task = asyncio.create_task(runner.loop(bus, ledger))
        await asyncio.sleep(0.05)
        task.cancel()
        with contextlib.suppress(asyncio.CancelledError):
            await task
",tests/test_alert_webhook.py,,0,0.9999977396747258,"The method is likely to be deleted because it creates a task and immediately cancels it after a very short sleep period. This pattern suggests that the task is not intended to perform any meaningful work, or the logic is incomplete or incorrect. Additionally, the use of `contextlib.suppress` to ignore the `CancelledError` indicates that the cancellation is expected and handled, but without a clear purpose for the task, the method seems redundant."
survived,"def send_alert(message: str, url: str | None = None) -> None:
    """"""Post *message* to ``url`` or ``ALERT_WEBHOOK_URL`` if set.""""""

    hook = url or os.getenv(""ALERT_WEBHOOK_URL"")
    if not hook:
        return

    payload = {""content"": message}
    if ""slack.com"" in hook:
        payload = {""text"": message}

    try:
        requests.post(hook, json=payload, timeout=5)
    except Exception as exc:  # pragma: no cover - network errors
        _log.warning(""alert failed: %s"", exc)",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/alerts.py,,1,7.582560422162384e-10,"The method `send_alert` is likely to survive because it provides a useful functionality of sending alerts to a specified URL or a default webhook URL. This is a common requirement in many applications for notifying users or systems about important events or errors. The method is also well-structured, handling different payload formats based on the URL and catching exceptions to log any failures, which makes it robust and reliable."
survived,"def test_forecast_disruptions_seed_deterministic() -> None:
    sec1 = sector.Sector(""x"", energy=1.0, entropy=2.0, growth=0.1)
    sec2 = sector.Sector(""x"", energy=1.0, entropy=2.0, growth=0.1)
    traj1 = forecast.forecast_disruptions([sec1], 2, curve=""linear"", pop_size=2, generations=1, seed=123)
    traj2 = forecast.forecast_disruptions([sec2], 2, curve=""linear"", pop_size=2, generations=1, seed=123)
    result1 = [ (p.year, p.sectors[0].energy, p.sectors[0].disrupted) for p in traj1 ]
    result2 = [ (p.year, p.sectors[0].energy, p.sectors[0].disrupted) for p in traj2 ]
    assert result1 == result2",tests/test_forecast.py,,1,4.363462233903899e-09,"The method `test_forecast_disruptions_seed_deterministic` is a unit test designed to verify the deterministic behavior of the `forecast_disruptions` function when a specific seed is used. This is a common practice in testing to ensure that functions relying on random processes produce consistent results when given the same seed. The method is straightforward, does not have any apparent issues, and serves a clear purpose in the testing suite. Therefore, it is likely to be retained as part of the test suite to ensure the reliability and predictability of the `forecast_disruptions` function."
survived,"def test_innovation_gain_seed_deterministic() -> None:
    gain1 = forecast._innovation_gain(pop_size=2, generations=1, seed=123)
    gain2 = forecast._innovation_gain(pop_size=2, generations=1, seed=123)
    assert gain1 == gain2
",tests/test_forecast.py,,1,7.194132978569833e-09,"The method `test_innovation_gain_seed_deterministic` is a unit test designed to verify the deterministic behavior of the `_innovation_gain` function when a specific seed is used. This is a common practice in testing to ensure that functions relying on random processes produce consistent results when the same seed is provided. Such tests are crucial for validating the reliability and predictability of functions that involve randomness. Therefore, this method is likely to be retained as it serves an important role in maintaining the integrity of the codebase."
survived,"def replace_str(path: str | Path, old: str, new: str) -> int:
    """"""Replace occurrences of ``old`` with ``new`` inside ``path``.""""""
    p = _safe_path(path)
    text = p.read_text(encoding=""utf-8"", errors=""replace"")
    count = text.count(old)
    if count:
        _record_history(p)
        p.write_text(text.replace(old, new), encoding=""utf-8"")
    return count
",src/self_edit/tools.py,,1,3.581747929000289e-10,"The method 'replace_str' is a utility function that performs a common task of replacing occurrences of a substring within a file. It is well-structured, uses type hints, and handles file reading and writing with encoding considerations. Additionally, it includes a mechanism to record history, which suggests it is part of a larger system that tracks changes. These factors indicate that the method is useful, maintainable, and likely to be retained in the codebase."
survived,"def insert_after(path: str | Path, anchor: str, code: str) -> None:
    """"""Insert ``code`` after the first line containing ``anchor``.""""""
    p = _safe_path(path)
    lines = p.read_text(encoding=""utf-8"", errors=""replace"").splitlines()
    for idx, line in enumerate(lines):
        if anchor in line:
            _record_history(p)
            insert_lines = code.splitlines()
            lines[idx + 1 : idx + 1] = insert_lines
            p.write_text(""\n"".join(lines), encoding=""utf-8"")
            return
    raise ValueError(f""anchor '{anchor}' not found in {p}"")
",src/self_edit/tools.py,,1,3.3982678079468468e-09,"The method 'insert_after' is a utility function that performs a specific and useful task: inserting code into a file after a specified anchor line. This kind of functionality is often needed in various programming tasks, such as code generation, configuration file updates, or automated script modifications. The method is well-defined, with clear input parameters and error handling for cases where the anchor is not found. It also includes encoding handling and a history recording step, which suggests it is part of a larger system that tracks changes. These characteristics make it a valuable and reusable piece of code, increasing its likelihood of being retained in the codebase."
survived,"def _replace_str_tool(ctx: RunContextWrapper | dict, path: str, old: str, new: str) -> int:
    return replace_str(path, old, new)
",src/self_edit/tools.py,,0,0.9999999677581336,"The method '_replace_str_tool' is a simple wrapper around the 'replace_str' function, adding no additional functionality or value. It takes a context parameter 'ctx' which is not used within the method, indicating that it might be part of a larger framework or system where context is typically required. However, since the context is not utilized, the method does not leverage it to enhance or modify the behavior of 'replace_str'. This redundancy suggests that the method could be removed without affecting the overall functionality, as calls to '_replace_str_tool' could be directly replaced with calls to 'replace_str'. Therefore, the method is likely to be deleted."
survived,"def _convert_scalar(value: str) -> Any:
    """"""Convert a YAML scalar to a Python type.""""""

    lowered = value.lower()
    if lowered == ""true"":
        return True
    if lowered == ""false"":
        return False
    try:
        if ""."" in value:
            return float(value)
        return int(value)
    except ValueError:
        return value
",src/yaml/__init__.py,,1,1.3440409770490404e-08,"The method `_convert_scalar` is a utility function that converts a YAML scalar value to a corresponding Python type. This is a common requirement when parsing YAML files, as YAML supports various data types like booleans, integers, and floats, which need to be converted to Python's native types for further processing. The function is well-defined, handling boolean values, numeric conversions, and defaulting to a string if no conversion is possible. Such utility functions are often essential in data processing libraries or applications that deal with configuration files or data serialization formats like YAML. Therefore, it is likely to be retained in the codebase."
survived,"def subaru_checksum(address: int, sig, d: bytearray) -> int:
  s = 0
  addr = address
  while addr:
    s += addr & 0xFF
    addr >>= 8
  for i in range(1, len(d)):
    s += d[i]
  return s & 0xFF",opendbc/car/subaru/subarucan.py,,1,3.850741907939403e-09,"The method 'subaru_checksum' is a utility function that calculates a checksum based on an address and a bytearray. This type of function is often used in data integrity checks, especially in communication protocols or data storage systems. The function is simple, efficient, and performs a specific task that is likely to be reused in various parts of a system dealing with data transmission or storage. Given its utility and the fact that it doesn't have any apparent issues or redundancies, it is likely to be retained in the codebase."
survived,"def chrysler_checksum(address: int, sig, d: bytearray) -> int:
  checksum = 0xFF
  for j in range(len(d) - 1):
    curr = d[j]
    shift = 0x80
    for _ in range(8):
      bit_sum = curr & shift
      temp_chk = checksum & 0x80
      if bit_sum:
        bit_sum = 0x1C
        if temp_chk:
          bit_sum = 1
        checksum = (checksum << 1) & 0xFF
        temp_chk = checksum | 1
        bit_sum ^= temp_chk
      else:
        if temp_chk:
          bit_sum = 0x1D
        checksum = (checksum << 1) & 0xFF
        bit_sum ^= checksum
      checksum = bit_sum & 0xFF
      shift >>= 1
  return (~checksum) & 0xFF
",opendbc/car/chrysler/chryslercan.py,,1,2.5109990926928157e-08,"The method 'chrysler_checksum' is a specialized function that calculates a checksum for a given byte array, which is a common requirement in data integrity and error-checking processes, especially in automotive and embedded systems. The function is well-defined, performs a specific task, and does not have any apparent issues or redundancies that would necessitate its deletion. Additionally, checksum calculations are often critical in ensuring data integrity, making this function valuable in its context."
survived,"async def test_sampling_alias_and_type_error():
    ctx = EnrichContext.model_construct(_request_context=Mock(session=Mock()))

    # Alias should delegate to ask_llm
    with patch.object(EnrichContext, ""ask_llm"", AsyncMock(return_value=""ok"")) as mock:
        result = await ctx.sampling(""hello"")
        assert result == ""ok""
        mock.assert_awaited_once()

    # Invalid message type raises TypeError
    with pytest.raises(TypeError):
        await ctx.sampling([123])",tests/test_llm.py,,1,3.0590235908148916e-07,"The method `test_sampling_alias_and_type_error` is a test function that verifies the behavior of the `sampling` method in the `EnrichContext` class. It checks two scenarios: one where the method is called with a valid string argument and another where it is called with an invalid list argument. The test uses mocking to simulate the behavior of the `ask_llm` method and asserts that the correct exceptions are raised. This is a typical unit test pattern in Python, especially with the use of `pytest` and `unittest.mock`. Since testing is a crucial part of software development to ensure code reliability and correctness, this method is likely to be retained to maintain the integrity of the codebase."
survived,"def prefer_smart_model() -> ModelPreferences:
    """"""Model preferences optimized for intelligence and capability.""""""

    return ModelPreferences(
        hints=[ModelHint(name=""gpt-4o""), ModelHint(name=""claude-3-opus"")],
        costPriority=0.2,
        speedPriority=0.3,
        intelligencePriority=0.9,
    )",src/enrichmcp/context.py,,1,8.152020648014727e-09,"The method 'prefer_smart_model' is a utility function that returns a 'ModelPreferences' object with specific preferences for model selection. It is designed to prioritize intelligence, which is a common requirement in many AI applications. The method is straightforward, well-defined, and serves a clear purpose in configuring model preferences. Given the increasing demand for intelligent AI models, this method is likely to be useful in various contexts where model selection is critical. Therefore, it is unlikely to be deleted."
survived,"def test_html_single_disclaimer_passes(tmp_path: Path) -> None:
    html = ""<p><a href='docs/DISCLAIMER_SNIPPET.md'>See docs/DISCLAIMER_SNIPPET.md</a></p>""
    repo = _create_html_repo(tmp_path, html)
    missing, duplicates = verify_disclaimer_snippet.check_repo(repo)
    assert missing == []
    assert duplicates == []
",tests/test_verify_disclaimer_snippet.py,,1,1.493094675974231e-10,"The method 'test_html_single_disclaimer_passes' is a unit test designed to verify that a specific HTML snippet containing a disclaimer link is correctly processed by the 'verify_disclaimer_snippet.check_repo' function. It checks that there are no missing or duplicate disclaimers in the repository. This kind of test is essential for ensuring the integrity and correctness of the disclaimer verification process in the codebase. Since testing is a crucial part of software development to maintain code quality, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered. Therefore, the method will likely survive."
survived,"def _create_html_repo(tmpdir: Path, content: str) -> Path:
    docs = tmpdir / ""docs""
    docs.mkdir()
    (docs / ""DISCLAIMER_SNIPPET.md"").write_text(SNIPPET_TEXT)
    (tmpdir / ""index.html"").write_text(content)
    return tmpdir
",tests/test_verify_disclaimer_snippet.py,,1,4.599055376537186e-10,"The method '_create_html_repo' is a utility function that creates a temporary directory structure for HTML documentation. It is likely used in testing or generating temporary documentation setups. Such utility functions are often retained because they encapsulate a specific, reusable task that can be useful in various contexts, especially in testing environments. Unless there is a significant change in the project's requirements or structure that makes this function obsolete, it is likely to survive."
survived,"def _env_int(name: str, default: int) -> int:
    """"""Return ``int`` environment value or ``default`` if conversion fails.""""""

    try:
        return int(ENV(name, default))
    except (TypeError, ValueError):
        return default
",alpha_factory_v1/backend/orchestrator.py,,1,6.348800075736417e-09,"The method _env_int is a utility function that attempts to retrieve an environment variable by name and convert it to an integer. If the conversion fails due to a TypeError or ValueError, it returns a default integer value. This is a common pattern in programming for safely handling environment variables, which are often used in configuration settings. The function is useful, concise, and handles potential errors gracefully, making it likely to be retained in the codebase."
survived,"def test_init_creates_execution_module(monkeypatch):
    fake_cls = MagicMock()
    fake_instance = MagicMock()
    fake_cls.return_value = fake_instance
    monkeypatch.setattr(rc_mod, ""ExecutionModule"", fake_cls)
    module = ResultCollectionModule()
    assert module.execution_module is fake_instance
",tests/unit/test_result_collection_module.py,,1,3.2241866333029355e-08,"The method 'test_init_creates_execution_module' is a unit test that verifies the initialization behavior of a class. It uses the 'monkeypatch' fixture to replace the 'ExecutionModule' class in the 'rc_mod' module with a mock object. This allows the test to check if the 'ResultCollectionModule' correctly assigns an instance of 'ExecutionModule' to its 'execution_module' attribute. The test is well-structured, uses mocking appropriately, and serves a clear purpose in ensuring the correct behavior of the class initialization. Therefore, it is likely to be retained in the codebase as it provides value in maintaining code quality and reliability."
survived,"def test_setup_logging_rotation(tmp_path):
    log_file = tmp_path / ""rotate.log""
    logger = setup_logging(
        name=""rotate_logger"",
        level=""INFO"",
        log_file=str(log_file),
        max_bytes=10,
        backup_count=1,
    )
    assert isinstance(logger.handlers[0], RotatingFileHandler)
    logger.info(""rotated message"")
    assert log_file.exists()
    assert log_file.read_text()",tests/test_utils_logging.py,,1,5.3157849718487075e-08,"The method `test_setup_logging_rotation` is a test function that verifies the setup of a rotating file handler for logging. It checks if the logger is correctly configured to rotate logs when they reach a certain size. This is a common requirement in applications to prevent log files from growing indefinitely. The test ensures that the logger is set up with a `RotatingFileHandler`, writes a log message, and verifies that the log file exists and contains text. Such tests are crucial for maintaining the reliability of logging mechanisms in software applications. Therefore, this method is likely to be retained as it serves an important purpose in ensuring the correct functionality of the logging setup."
survived,"def ruleBit(ruleNum, idx):
    r = ruleNum
    i = 0
    while i < idx:
        r = r // 2
        i = i + 1
    return r % 2
",tests/rosetta/transpiler/Python/elementary-cellular-automaton-random-number-generator.py,,1,7.194132978569833e-09,"The method 'ruleBit' is a simple utility function that extracts a specific bit from a binary representation of a number. This type of function is often used in various applications, such as cellular automata, bit manipulation tasks, or any scenario where binary operations are needed. The function is straightforward, efficient, and serves a clear purpose. It is unlikely to be deleted unless it is redundant or replaced by a more efficient library function. However, given its simplicity and utility, it is more likely to survive."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/empty-directory.py,,1,5.3157849718487075e-08,"The method _now() is a utility function that generates a pseudo-random number based on a seed if _now_seeded is True, or returns the current time in nanoseconds if not. This function is likely part of a larger system that requires either a random number or a timestamp, depending on the state of _now_seeded. Such utility functions are common in systems that need to simulate time or generate random numbers for testing or other purposes. Since it provides a dual functionality that can be useful in various scenarios, it is likely to be retained in the codebase."
survived,"def cbrtApprox(x):
    guess = x
    i = 0
    while i < 40:
        guess = (2.0 * guess + x // (guess * guess)) / 3.0
        i = i + 1
    return guess
",tests/rosetta/transpiler/Python/elliptic-curve-arithmetic.py,,1,6.144172127844639e-06,"The method cbrtApprox is an implementation of the cube root approximation using the Newton-Raphson method. This method is a common numerical technique for finding roots and is generally useful for educational purposes or when a quick approximation is needed without using built-in functions. However, the method has a few issues: it uses integer division (//) which can lead to incorrect results for non-integer inputs, and it lacks error handling or convergence checks. Despite these issues, the method is likely to survive because it serves as a basic example of numerical approximation techniques and can be improved or used as a learning tool."
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    a = fromY(1.0)
    b = fromY(2.0)
    show(""a = "", a)
    show(""b = "", b)
    c = add(a, b)
    show(""c = a + b = "", c)
    d = neg(c)
    show(""d = -c = "", d)
    show(""c + d = "", add(c, d))
    show(""a + b + d = "", add(a, add(b, d)))
    show(""a * 12345 = "", mul(a, 12345))
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/elliptic-curve-arithmetic.py,,1,4.1399375473943306e-08,"The method 'main' is a complete function that performs a series of operations and outputs the results. It includes benchmarking code to measure execution time and memory usage, which is useful for performance analysis. The function is well-structured and provides valuable insights into the performance of the operations it performs. Therefore, it is likely to be retained for its utility in performance testing and analysis."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/enforced-immutability.py,,1,9.931195248674785e-08,"The method `_now()` is a utility function that generates a pseudo-random number based on a seed if `_now_seeded` is True, otherwise it returns the current time in nanoseconds. This function is likely part of a larger system that requires a consistent and repeatable sequence of numbers for testing or simulation purposes when seeded, and real-time timestamps otherwise. Such utility functions are common in software development for testing and simulation, and they provide useful functionality. Therefore, it is likely to be retained in the codebase."
survived,"def elem(r, cells, generations, state):
    outputState(state)
    g = 0
    s = state
    while g < generations:
        s = step(s, r)
        outputState(s)
        g = g + 1
",tests/rosetta/transpiler/Python/elementary-cellular-automaton.py,,1,4.363462233903899e-09,"The method 'elem' is a simple function that simulates cellular automata for a given number of generations. It uses a loop to update the state of the cells and outputs the state at each step. The function is straightforward and serves a clear purpose in the context of simulating cellular automata, which is a common computational task. There is no indication that this method is redundant or unnecessary, and it appears to be functional and correctly implemented for its intended purpose. Therefore, it is likely to be retained in the codebase."
survived,"            def return_verified_password_or_false(self, pw_list):
                pass
",btcrecover/test/test_passwords.py,TestOuterIterations.DummyWallet,0,0.9999998144608401,"The method `return_verified_password_or_false` is currently a placeholder with no implementation (indicated by the `pass` statement). Without any logic or functionality, it doesn't serve any purpose in its current state. Unless there is a plan to implement this method in the future, it is likely to be deleted as it doesn't contribute to the codebase."
survived,"            async def close(self) -> None:
                pass
",tests/test_ledger_broadcast.py,DummyClient,1,8.31527990378713e-07,"The method 'close' is defined as an asynchronous function but contains only a 'pass' statement, meaning it currently does nothing. However, the presence of this method suggests that it might be intended for future implementation, especially in contexts where resource management or cleanup is necessary. In many cases, such placeholder methods are kept in the codebase to maintain a consistent interface or to be implemented later. Therefore, it is likely to survive as it may be part of a larger interface or class structure that anticipates future functionality."
survived,"def test_new_connection_requires_handshake() -> None:
    port = _free_port()
    cfg = config.Settings(bus_port=port, allow_insecure=True)
    bus = messaging.A2ABus(cfg)
    received: list[messaging.Envelope] = []

    def handler(env: messaging.Envelope) -> None:
        received.append(env)

    bus.subscribe(""x"", handler)

    async def run() -> None:
        async with bus:
            # first client performs handshake and sends message
            async with grpc.aio.insecure_channel(f""localhost:{port}"") as ch1:
                stub1 = ch1.unary_unary(""/bus.Bus/Send"")
                await stub1(b""proto_schema=1"")
                payload = {
                    ""sender"": ""a"",
                    ""recipient"": ""x"",
                    ""payload"": {""v"": 1},
                    ""ts"": 0.0,
                }
                await stub1(json.dumps(payload).encode())

            # second client should fail without handshake
            async with grpc.aio.insecure_channel(f""localhost:{port}"") as ch2:
                stub2 = ch2.unary_unary(""/bus.Bus/Send"")
                payload = {
                    ""sender"": ""b"",
                    ""recipient"": ""x"",
                    ""payload"": {""v"": 2},
                    ""ts"": 0.0,
                }
                with pytest.raises(grpc.aio.AioRpcError):
                    await stub2(json.dumps(payload).encode())

    asyncio.run(run())

    assert len(received) == 1
    assert received[0].payload[""v""] == 1",tests/test_message_bus.py,,1,3.653482080241728e-08,"The method is a well-structured test function that verifies the requirement of a handshake for new connections in a messaging system. It uses a mock setup to simulate client-server interactions and checks that a message is only received if the handshake is performed. The test is clear, uses appropriate assertions, and is likely part of a test suite ensuring the robustness of the system. Such test functions are crucial for maintaining software quality and are typically retained in the codebase."
survived,"def test_results_dir_permissions(tmp_path: Path, monkeypatch: pytest.MonkeyPatch) -> None:
    path = tmp_path / ""results""
    monkeypatch.setenv(""SIM_RESULTS_DIR"", str(path))

    from alpha_factory_v1.demos.alpha_agi_insight_v1.src.interface import api_server

    api_server = importlib.reload(api_server)

    assert path.exists()
    assert (path.stat().st_mode & 0o777) == 0o700",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_results_dir_permissions.py,,1,3.581747929000289e-10,"The method `test_results_dir_permissions` is a test function that checks the permissions of a directory created in a temporary path. It uses `pytest` fixtures like `tmp_path` and `monkeypatch`, which are common in testing environments. The function sets an environment variable, reloads a module, and asserts conditions on the directory's existence and permissions. This is a typical pattern for a unit test, and such functions are generally retained as they are crucial for ensuring code correctness and stability. Therefore, it is likely to survive."
survived,"def test_as_proxy_with_url():
    """"""FastMCP.as_proxy should accept a URL without connecting.""""""
    proxy = FastMCP.as_proxy(""http://example.com/mcp"")
    assert isinstance(proxy, FastMCPProxy)
    assert repr(proxy.client.transport).startswith(""<StreamableHttp("")
",tests/server/test_proxy.py,,1,5.3157849718487075e-08,"The method 'test_as_proxy_with_url' is a unit test for the 'FastMCP.as_proxy' function. Unit tests are crucial for ensuring code reliability and are typically retained in the codebase to verify functionality. The test checks if the 'as_proxy' method correctly handles a URL and returns an instance of 'FastMCPProxy', which is a valid and necessary test case for maintaining code quality. Therefore, it is unlikely to be deleted."
survived,"    def save(self, project: str, note: MemoryNote) -> None:
        """"""Persist ``note`` under ``project``.""""""
",examples/basic_memory/memory.py,MemoryStore,1,9.237449576640118e-09,"The method 'save' is a fundamental operation for persisting data, which is a common requirement in software applications. The method is likely part of a larger system that manages notes or data entries, and the ability to save or persist data is crucial for the functionality of such systems. Therefore, it is unlikely that this method will be deleted as it serves an essential purpose."
survived,"    def _scan_licenses(self, metadata: TemplateMetadata) -> List[str]:
        issues: List[str] = []
        if not metadata.tools:
            return issues
        try:
            _, licenses, _ = self.dep_manager.resolve(metadata.tools)
        except Exception as exc:  # pragma: no cover - dependency errors rare
            issues.append(f""dependency resolution failed: {exc}"")
            return issues
        for pkg, lic in licenses.items():
            if any(tag in lic for tag in self._DISALLOWED_LICENSES):
                issues.append(f""non-permissive license for {pkg}: {lic}"")
        return issues
",src/meta_agent/template_validator.py,TemplateValidator,1,1.6918979223288786e-10,"The method '_scan_licenses' is a utility function that checks for disallowed licenses in a given set of tools' metadata. It is useful for ensuring compliance with licensing policies, which is a common requirement in software development. The method handles exceptions gracefully and provides detailed error messages, making it robust and informative. These characteristics suggest that the method is likely to be retained as it serves a practical purpose in maintaining software quality and compliance."
survived,"    def close(self) -> None:
        pass
",tests/test_agent_handle_methods.py,DummyLedger,1,4.785094849865141e-06,"The method 'close' is defined but not implemented, as it only contains a 'pass' statement. This suggests that it is a placeholder for future implementation or is meant to be overridden in a subclass. If the class is intended to be abstract or part of a framework where subclasses are expected to provide specific implementations, the method will likely survive. However, if this is a concrete class and the method is never implemented or used, it might be deleted in the future. Without additional context, it's more likely to survive as a placeholder or abstract method."
survived,"    async def run() -> None:
        await bus.start()
        try:
            creds = grpc.ssl_channel_credentials(root_certificates=ca)
            async with grpc.aio.secure_channel(f""localhost:{port}"", creds) as ch:
                stub = ch.unary_unary(""/bus.Bus/Send"")
                payload = {
                    ""sender"": ""a"",
                    ""recipient"": ""b"",
                    ""payload"": {},
                    ""ts"": 0.0,
                    ""token"": ""bad"",
                }
                with pytest.raises(grpc.aio.AioRpcError):
                    await stub(json.dumps(payload).encode())
        finally:
            await bus.stop()
",tests/test_bus_tls.py,,1,9.736200303530205e-10,"The method is likely to survive because it is an asynchronous function that is well-structured and uses modern Python features such as async/await and context managers. It also includes error handling with pytest to ensure robustness. These are all good practices in contemporary Python programming, suggesting that the method is up-to-date and useful."
survived,"    def _analyze_memory_maps(self, memory_maps) -> Dict[str, float]:
        """"""
        分析内存映射，按类型分类统计
        """"""
        regions = {}
        for mmap in memory_maps:
            size_mb = mmap.size / 1024 / 1024
            perms = mmap.perms
            
            if 'r' in perms and 'w' in perms:
                region_type = ""读写内存""
            elif 'r' in perms and 'x' in perms:
                region_type = ""代码段""
            elif 'r' in perms:
                region_type = ""只读内存""
            else:
                region_type = ""其他内存""
            
            if region_type in regions:
                regions[region_type] += size_mb
            else:
                regions[region_type] = size_mb
        
        return regions
",app/helper/memory.py,MemoryHelper,1,2.2159489282323004e-08,"The method '_analyze_memory_maps' is a utility function that analyzes memory maps and categorizes them based on their permissions. It is a useful function for understanding memory usage patterns, which can be critical for performance optimization and debugging. The method is well-defined, with a clear purpose and implementation. It is likely to be retained as it provides valuable insights into memory usage, which is a common requirement in software development, especially in systems programming and performance analysis."
survived,"    def create_detailed_memory_analysis(self):
        """"""
        创建详细的内存分析报告，专门用于诊断内存问题
        """"""
        try:
            timestamp = datetime.now().strftime(""%Y%m%d_%H%M%S"")
            analysis_file = self._memory_snapshot_dir / f""detailed_memory_analysis_{timestamp}.txt""
            
            logger.info(f""开始创建详细内存分析: {analysis_file}"")
            
            with open(analysis_file, 'w', encoding='utf-8') as f:
                f.write(f""详细内存分析报告 - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"")
                f.write(""="" * 100 + ""\n\n"")
                
                # 1. 系统级内存分析
                self._write_detailed_system_analysis(f)
                
                # 2. Python对象深度分析
                self._write_detailed_python_analysis(f)
                
                # 3. 内存映射详细分析
                self._write_detailed_memory_maps(f)
                
                # 4. 大对象分析
                self._write_detailed_large_objects(f)
                
                # 5. 内存泄漏检测
                self._write_memory_leak_detection(f)
                
            logger.info(f""详细内存分析已保存: {analysis_file}"")
            return analysis_file
            
        except Exception as e:
            logger.error(f""创建详细内存分析失败: {e}"")
            return None
",app/helper/memory.py,MemoryHelper,1,1.8189616842444243e-09,"The method 'create_detailed_memory_analysis' is likely to survive because it provides a comprehensive and structured approach to diagnosing memory issues, which is a critical task in software development and maintenance. The method includes detailed steps for system-level analysis, Python object analysis, memory mapping, large object analysis, and memory leak detection, making it a valuable tool for developers. Additionally, it includes logging for tracking the process and error handling to manage exceptions, which are good practices in software development."
survived,"def create_decision_prompt(scenario: str, available_actions: List[str]) -> str:
    """"""Create a prompt for decision making.""""""
    return f""""""
You are a strategic decision-making agent. You need to analyze the current scenario and choose the best action from the available options.

Current Scenario:
{scenario}

Available Actions:
{chr(10).join(f""- {action}"" for action in available_actions)}

Your goal is to make the best strategic decision based on the scenario. Consider:
1. The immediate benefits of each action
2. Potential long-term consequences
3. Risk vs reward trade-offs
4. Strategic positioning

Reason carefully about the best action to take and explain your reasoning.
""""""
",examples/openai/o3_responses_example.py,,1,1.8189616842444243e-09,"The method 'create_decision_prompt' is a utility function that generates a structured prompt for decision-making scenarios. It is well-defined, with a clear purpose and a straightforward implementation. The function is useful for applications involving AI or human decision-making processes, where structured prompts can guide the decision-making process. Given the increasing interest in AI and decision-support systems, this method is likely to be retained for its utility in creating consistent and informative prompts."
survived,"def create_pull_request(task_id):
    """"""Create a pull request for a completed task""""""
    try:
        if task_id not in tasks:
            return jsonify({'error': 'Task not found'}), 404
        
        task = tasks[task_id]
        
        if task['status'] != TaskStatus.COMPLETED:
            return jsonify({'error': 'Task not completed yet'}), 400
        
        data = request.get_json() or {}
        pr_title = data.get('title', f""Claude Code: {task['prompt'][:50]}..."")
        pr_body = data.get('body', f""Automated changes generated by Claude Code.\n\nPrompt: {task['prompt']}"")
        
        # Extract repo info from URL
        repo_parts = task['repo_url'].replace('https://github.com/', '').replace('.git', '')
        
        # Create GitHub client
        g = Github(task['github_token'])
        repo = g.get_repo(repo_parts)
        
        # Get the commit
        commit = repo.get_commit(task['commit_hash'])
        
        # Create a new branch for the PR
        pr_branch = f""claude-code-{task_id[:8]}""
        base_branch = repo.get_branch(task['branch'])
        repo.create_git_ref(f""refs/heads/{pr_branch}"", commit.sha)
        
        # Create pull request
        pr = repo.create_pull(
            title=pr_title,
            body=pr_body,
            head=pr_branch,
            base=task['branch']
        )
        
        return jsonify({
            'status': 'success',
            'pr_url': pr.html_url,
            'pr_number': pr.number
        })
        
    except Exception as e:
        logger.error(f""Error creating PR: {str(e)}"")
        return jsonify({'error': str(e)}), 500
",server/main.py,,1,1.0261879630648829e-10,"The method 'create_pull_request' is a crucial part of a workflow that automates the creation of pull requests for completed tasks. This functionality is essential for integrating changes into a codebase, especially in environments where automation and continuous integration are prioritized. The method handles error checking, interacts with the GitHub API, and provides feedback on success or failure, making it a valuable tool in a development pipeline. Given its utility and the increasing trend towards automation in software development, it is likely to be retained."
deleted,"    def _canonicalize_url(self, url: str) -> str:
        """"""Canonicalize URL using transformer logic""""""
        from package_managers.pkgx.transformer import PkgxTransformer

        temp_transformer = PkgxTransformer(self.config, None)
        return temp_transformer.canonicalize(url)
",package_managers/pkgx/diff.py,PkgxDiff,0,0.9999999936511998,"The method `_canonicalize_url` is likely to be deleted (0) because it appears to be a simple wrapper around the `canonicalize` method of the `PkgxTransformer` class. If this method is not adding any additional logic or value beyond calling another method, it might be considered redundant. Additionally, if the `PkgxTransformer` class is directly accessible and its `canonicalize` method can be used directly, this wrapper method may be deemed unnecessary and removed to simplify the codebase."
deleted,"    def _get_homepage_url(self, import_id: str, pkg: PkgxPackage) -> str | None:
        """"""Get homepage URL for a package using the existing transformer logic""""""
        # Import the transformer methods for URL handling
        # TODO: this should use the url.py function
        from package_managers.pkgx.transformer import PkgxTransformer

        # Create a temporary transformer instance to use its methods
        temp_transformer = PkgxTransformer(self.config, None)

        # Try to get homepage from pkgx API
        homepage = temp_transformer.ask_pkgx(import_id)
        if not homepage:
            homepage = temp_transformer.special_case(import_id)

        if homepage:
            return temp_transformer.canonicalize(homepage)

        return None
",package_managers/pkgx/diff.py,PkgxDiff,0,0.9999999006880476,"The method is likely to be deleted because it contains a TODO comment indicating that the current implementation is not the intended final solution. The comment suggests that the method should use a function from 'url.py' instead of the current approach, implying that this method is a temporary workaround. Once the proper implementation is in place, this method will likely be removed."
survived,"    def __init__(self, config: Config, caches: Cache, logger: Logger):
        self.config = config
        self.now = datetime.now()
        self.caches = caches
        self.logger = logger
",package_managers/pkgx/diff.py,PkgxDiff,1,4.363462233903899e-09,"The method is a constructor (__init__) for a class, which is a fundamental part of object-oriented programming in Python. Constructors are essential for initializing new objects with specific attributes and are unlikely to be removed unless the class itself is being deprecated or refactored significantly. Since this method is responsible for setting up the initial state of an object with configuration, cache, and logging capabilities, it is crucial for the functionality of the class. Therefore, it is expected to survive."
survived,"    def test_dependency_type_change_runtime_to_build(self, mock_config, mock_logger):
        """"""Test case 2: p1 has runtime dependency to p2 in cache,
        p1 has build dependency to p2 in parsed data.
        Expect removed runtime dependency and new build dependency.""""""

        p1_id = uuid4()
        p2_id = uuid4()

        p1_pkg = Package(id=p1_id, derived_id=""pkgx/p1"", name=""p1"", import_id=""p1"")
        p2_pkg = Package(id=p2_id, derived_id=""pkgx/p2"", name=""p2"", import_id=""p2"")

        # Existing runtime dependency
        existing_runtime_dep = LegacyDependency(
            package_id=p1_id,
            dependency_id=p2_id,
            dependency_type_id=mock_config.dependency_types.runtime,
        )

        cache = Cache(
            package_map={""p1"": p1_pkg, ""p2"": p2_pkg},
            url_map={},
            package_urls={},
            dependencies={p1_id: {existing_runtime_dep}},
        )

        # Parsed data only has build dependency
        new_pkg_data = create_pkgx_package(
            dependencies=[],  # no runtime deps
            build_deps=[""p2""],  # only build
        )

        diff = PkgxDiff(mock_config, cache, mock_logger)
        new_deps, removed_deps = diff.diff_deps(""p1"", new_pkg_data)

        # Should remove runtime and add build
        assert len(removed_deps) == 1
        assert removed_deps[0].dependency_id == p2_id
        assert (
            removed_deps[0].dependency_type_id == mock_config.dependency_types.runtime
        )

        assert len(new_deps) == 1
        assert new_deps[0].dependency_id == p2_id
        assert new_deps[0].dependency_type_id == mock_config.dependency_types.build
",tests/package_managers/pkgx/test_pkgx_diff.py,TestPkgxDifferentialLoading,1,1.522997951276035e-08,"The method is a well-defined test case that checks the functionality of changing a dependency type from runtime to build. It is useful for ensuring the correct behavior of the dependency management system, which is a critical part of many software projects. Such test cases are essential for maintaining code quality and are unlikely to be deleted unless the functionality they test is removed or significantly altered."
survived,"    def test_dependency_type_priority_no_change(self, mock_config, mock_logger):
        """"""Test case 1: p1 has runtime dependency to p2 in cache,
        p1 depends on p2 as both runtime and build in parsed data.
        Expect no change (runtime has priority).""""""

        # Setup existing package and dependencies
        p1_id = uuid4()
        p2_id = uuid4()

        p1_pkg = Package(id=p1_id, derived_id=""pkgx/p1"", name=""p1"", import_id=""p1"")
        p2_pkg = Package(id=p2_id, derived_id=""pkgx/p2"", name=""p2"", import_id=""p2"")

        # Existing runtime dependency in cache
        existing_runtime_dep = LegacyDependency(
            package_id=p1_id,
            dependency_id=p2_id,
            dependency_type_id=mock_config.dependency_types.runtime,
        )

        cache = Cache(
            package_map={""p1"": p1_pkg, ""p2"": p2_pkg},
            url_map={},
            package_urls={},
            dependencies={p1_id: {existing_runtime_dep}},
        )

        # Parsed data has p2 as both runtime and build dependency
        new_pkg_data = create_pkgx_package(
            dependencies=[""p2""],  # runtime
            build_deps=[""p2""],  # build
        )

        diff = PkgxDiff(mock_config, cache, mock_logger)
        new_deps, removed_deps = diff.diff_deps(""p1"", new_pkg_data)

        # Should have no changes - runtime priority means no change needed
        assert len(new_deps) == 0
        assert len(removed_deps) == 0
",tests/package_managers/pkgx/test_pkgx_diff.py,TestPkgxDifferentialLoading,1,1.955568070542584e-08,"The method is a unit test that verifies the behavior of a dependency management system. It checks that when a package has both runtime and build dependencies, the runtime dependency takes priority and no changes are made to the existing dependencies. This is a valid and useful test case to ensure the system behaves as expected, especially in complex dependency scenarios. Therefore, it is likely to be retained."
survived,"    async def apply(self):
        # Drop the old index with incorrect partial filter expression
        await self._drop_index_if_exists(self._organization_collection, ""org_settings_api_key_id_index"")

        # Create new index with correct partial filter expression
        await self._organization_collection.create_index(
            [(""api_keys.id"", 1)],
            name=""unique_api_key_id"",
            unique=True,
            partialFilterExpression={
                ""api_keys.id"": {""$exists"": True},
            },
        )
",api/core/storage/mongo/migrations/migrations/m2025_05_06_fix_api_key_id_index.py,FixAPIKeyIdIndexMigration,1,7.194132978569833e-09,"The method 'apply' is performing a necessary database operation by first dropping an incorrect index and then creating a new one with the correct partial filter expression. This is a common task in database management to ensure data integrity and query performance. The method is likely to be essential for maintaining the correct structure and functionality of the database, especially if the index is used frequently in queries. Therefore, it is unlikely to be deleted."
survived,"    def test_perplexity_reasoning_api_base_configuration(self, model, expected_api_base):
        """"""
        Test that Perplexity reasoning models use the correct API base
        """"""
        from litellm.llms.perplexity.chat.transformation import PerplexityChatConfig
        
        config = PerplexityChatConfig()
        api_base, _ = config._get_openai_compatible_provider_info(
            api_base=None, api_key=""test-key""
        )
        
        assert api_base == expected_api_base
",tests/llm_translation/test_perplexity_reasoning.py,TestPerplexityReasoning,1,1.0467401685178159e-08,"The method 'test_perplexity_reasoning_api_base_configuration' is a unit test designed to verify that the Perplexity reasoning models are using the correct API base. Unit tests are crucial for ensuring code reliability and correctness, especially in configurations and integrations with external services. This method is likely to be retained as it serves an important role in maintaining the integrity of the system by checking that the configuration aligns with expectations."
survived,"    def test_perplexity_reasoning_effort_in_supported_params(self):
        """"""
        Test that reasoning_effort is in the list of supported parameters for Perplexity
        """"""
        from litellm.llms.perplexity.chat.transformation import PerplexityChatConfig
        
        config = PerplexityChatConfig()
        supported_params = config.get_supported_openai_params(model=""perplexity/sonar-reasoning"")
        
        assert ""reasoning_effort"" in supported_params",tests/llm_translation/test_perplexity_reasoning.py,TestPerplexityReasoning,1,8.152020648014727e-09,"The method 'test_perplexity_reasoning_effort_in_supported_params' is a unit test that verifies if 'reasoning_effort' is included in the supported parameters for a specific model configuration. Unit tests are crucial for ensuring code reliability and correctness, especially in complex systems. This test checks the integrity of the configuration setup, which is important for maintaining the expected functionality of the system. Therefore, it is likely to be retained as part of the test suite."
survived,"def test_perplexity_reasoning_support():
    """"""Test that supports_reasoning function works for perplexity models""""""
    print(""Testing supports_reasoning function..."")
    
    from litellm.utils import supports_reasoning
    
    os.environ[""LITELLM_LOCAL_MODEL_COST_MAP""] = ""True""
    litellm.model_cost = litellm.get_model_cost_map(url="""")
    
    reasoning_models = [
        ""perplexity/sonar-reasoning"",
        ""perplexity/sonar-reasoning-pro"",
    ]
    
    for model in reasoning_models:
        try:
            result = supports_reasoning(model, None)
            print(f""✓ {model}: supports_reasoning = {result}"")
            assert result, f""{model} should support reasoning""
        except Exception as e:
            print(f""✗ {model}: Error checking reasoning support: {e}"")
    
    print(""✓ Supports reasoning test passed!\n"")
",verify_perplexity_reasoning.py,,1,5.3157849718487075e-08,"The method is a test function that verifies the functionality of the 'supports_reasoning' function for specific models. Test functions are generally useful for ensuring code reliability and correctness, especially in a development or testing environment. They help catch errors and validate that the code behaves as expected. Therefore, it is likely to be retained as part of the codebase to maintain software quality."
survived,"    def unnest(
        self,
        unnest_key: str,
        keep_empty: bool = False,
        expand_fields: Optional[List[str]] = None,
        recursive: bool = False,
        depth: Optional[int] = None,
        **kwargs
    ) -> pd.DataFrame:
        """"""
        Unnest list-like or dictionary values into multiple rows.

        Documentation: https://ucbepic.github.io/docetl/operators/unnest/

        Args:
            unnest_key: The column containing list-like or dictionary values to unnest
            keep_empty: Whether to keep rows with empty/null values (default: False)
            expand_fields: For dictionary values, which fields to expand (default: all)
            recursive: Whether to recursively unnest nested structures (default: False)
            depth: Maximum depth for recursive unnesting (default: 1, or unlimited if recursive=True)
            **kwargs: Additional configuration options

        Returns:
            pd.DataFrame: DataFrame with unnested values, where:
                - For lists: Each list element becomes a separate row
                - For dicts: Specified fields are expanded into the parent row

        Examples:
            >>> # Unnest a list column
            >>> df.semantic.unnest(
            ...     unnest_key=""tags""
            ... )
            # Input:  [{""id"": 1, ""tags"": [""a"", ""b""]}]
            # Output: [{""id"": 1, ""tags"": ""a""}, {""id"": 1, ""tags"": ""b""}]

            >>> # Unnest a dictionary column with specific fields
            >>> df.semantic.unnest(
            ...     unnest_key=""user_info"",
            ...     expand_fields=[""name"", ""age""]
            ... )
            # Input:  [{""id"": 1, ""user_info"": {""name"": ""Alice"", ""age"": 30, ""email"": ""alice@example.com""}}]
            # Output: [{""id"": 1, ""user_info"": {...}, ""name"": ""Alice"", ""age"": 30}]

            >>> # Recursive unnesting
            >>> df.semantic.unnest(
            ...     unnest_key=""nested_lists"",
            ...     recursive=True,
            ...     depth=2
            ... )
        """"""
        # Convert DataFrame to list of dicts
        input_data = self._df.to_dict(""records"")

        # Create unnest operation config
        unnest_config = {
            ""type"": ""unnest"",
            ""name"": f""semantic_unnest_{len(self._history)}"",
            ""unnest_key"": unnest_key,
            ""keep_empty"": keep_empty,
            ""recursive"": recursive,
            **kwargs,
        }

        # Add optional parameters if provided
        if expand_fields is not None:
            unnest_config[""expand_fields""] = expand_fields
        if depth is not None:
            unnest_config[""depth""] = depth

        # Create and execute unnest operation
        unnest_op = UnnestOperation(
            runner=self.runner,
            config=unnest_config,
            default_model=self.runner.config[""default_model""],
            max_threads=self.runner.max_threads,
            console=self.runner.console,
            status=self.runner.status,
        )
        results, cost = unnest_op.execute(input_data)

        return self._record_operation(results, ""unnest"", unnest_config, cost)
",docetl/apis/pd_accessors.py,SemanticAccessor,1,4.944450477491054e-09,"The method 'unnest' is well-documented, has a clear purpose, and provides useful functionality for data manipulation in a DataFrame. It includes detailed docstrings, examples, and handles various configurations, making it a valuable tool for users working with nested data structures. There is no indication that it is deprecated or redundant, so it is likely to be retained."
survived,"def create_workflow(db_session):
    """"""Fixture to create a workflow with a specific CEL expression""""""

    def _create_workflow(workflow_id, cel_expression):
        workflow_definition = f""""""workflow:
  id: {workflow_id}
  description: Test severity CEL expressions
  triggers:
    - type: alert
      cel: {cel_expression}
  actions:
    - name: test-action
      provider:
        type: console
        with:
          message: ""Alert matched CEL expression""
""""""
        workflow = Workflow(
            id=workflow_id,
            name=workflow_id,
            tenant_id=SINGLE_TENANT_UUID,
            description=""Test severity CEL expressions"",
            created_by=""test@keephq.dev"",
            interval=0,
            workflow_raw=workflow_definition,
        )
        db_session.add(workflow)
        db_session.commit()
        return workflow

    return _create_workflow
",tests/test_workflow_severity_comparisons.py,,1,1.0467401685178159e-08,"The method 'create_workflow' is a fixture function designed to create a workflow with a specific CEL expression. It is useful for testing purposes, allowing developers to easily set up workflows with different configurations. This kind of utility function is often essential in test environments to ensure that various scenarios can be tested efficiently. Since it serves a clear purpose in facilitating testing and does not have any apparent issues or redundancies, it is likely to be retained in the codebase."
survived,"def test_case_insensitive_severity_comparisons(
    db_session, workflow_manager, create_workflow, create_alert
):
    """"""Test that severity comparisons are case-insensitive after preprocessing""""""
    workflow = create_workflow(""test-severity-case"", ""severity > 'INFO'"")

    # Should match despite case difference in CEL expression
    high_alert = create_alert(severity=AlertSeverity.HIGH, fingerprint=""fp-high"")
    
    workflows_to_run_before = len(workflow_manager.scheduler.workflows_to_run)
    workflow_manager.insert_events(SINGLE_TENANT_UUID, [high_alert])
    assert len(workflow_manager.scheduler.workflows_to_run) == workflows_to_run_before + 1
",tests/test_workflow_severity_comparisons.py,,1,1.955568070542584e-08,"The method is a test function that verifies the functionality of case-insensitive severity comparisons in a workflow system. Test functions are crucial for ensuring code reliability and correctness, especially in systems that handle alerts and workflows. This function is likely part of a test suite that ensures the system behaves as expected when processing alerts with different severity levels. Deleting this function could lead to undetected bugs or regressions in the system's behavior. Therefore, it is important to retain such test functions."
survived,"async def async_rollout_tau_bench_task(
    model: art.Model[TauBenchPolicyConfig],
    task_index: int,
) -> art.Trajectory:
    """"""
    Async wrapper for rollout_tau_bench_task using asyncio.to_thread().
    This allows the sync tau-bench infrastructure to work with the async ART framework.
    """"""
    return await asyncio.to_thread(rollout_tau_bench_task, model, task_index)
",dev/tau-bench/run_rl.py,,1,2.3355930333443423e-09,"The method is an asynchronous wrapper that allows synchronous code to be executed in an asynchronous context using asyncio.to_thread(). This is a common pattern in modern Python programming to improve performance and responsiveness of applications by offloading blocking operations to separate threads. Given the increasing adoption of asynchronous programming in Python, this method is likely to be useful and relevant, especially in frameworks that need to integrate synchronous and asynchronous code. Therefore, it is likely to be retained."
survived,"def simple_package():
    return """"""Package: 0ad
Version: 0.0.26-1
Installed-Size: 19162
Maintainer: Debian Games Team <pkg-games-devel@lists.alioth.debian.org>
Architecture: amd64
Depends: 0ad-data (>= 0.0.26), 0ad-data-common (>= 0.0.26), libc6 (>= 2.29), libcurl4 (>= 7.16.2), libenet7 (>= 1.3.13), libgloox18, libjsoncpp25 (>= 1.9.5), libminiupnpc17 (>= 1.9.20140610), libnspr4 (>= 2:4.9.2), libnss3 (>= 2:3.22)
Recommends: fonts-freefont-ttf, fonts-texgyre
Suggests: 0ad-dbg
Description: Real-time strategy game of ancient warfare
Homepage: https://play0ad.com/
Section: games
Priority: optional
Filename: pool/main/0/0ad/0ad_0.0.26-1_amd64.deb
Size: 6050744
MD5sum: a777ddf01c18dbdef15c589f8325d7a3
SHA256: 9da19833c1a51e890aa8a11f82ec1e383c0e79410c3d2f6845fd2ec3e23249b8


""""""
",tests/package_managers/debian/test_debian_parser.py,,1,1.3440409770490404e-08,"The method `simple_package` is a straightforward function that returns a string containing metadata about a software package. This type of function is useful for generating or retrieving static data, which can be used in various contexts such as testing, documentation, or as part of a larger system that requires package information. Since it serves a clear purpose and is not overly complex, there is no immediate reason to delete it unless the data becomes outdated or the method is replaced by a more dynamic solution. Therefore, it is likely to survive."
survived,"    def test_package_exists_dependency_change(self, mock_config, mock_logger, mock_db):
        """"""
        Tests that diff correctly records:

          - New dependency
          - Changes to existing dependencies
          - Removed dependencies
        """"""

        # Setup existing package and dependencies
        existing_pkg_id = uuid4()
        dep1_id = uuid4()
        dep2_id = uuid4()
        dep3_id = uuid4()

        existing_import_id = ""debian/dep-pkg""
        existing_package = Package(
            id=existing_pkg_id,
            derived_id=existing_import_id,
            name=""dep-pkg"",
            package_manager_id=mock_config.pm_config.pm_id,
            import_id=existing_import_id,
            readme="""",
        )

        # Create dependency packages
        dep1_pkg = Package(
            id=dep1_id, derived_id=""debian/dep1"", name=""dep1"", import_id=""debian/dep1""
        )
        dep2_pkg = Package(
            id=dep2_id, derived_id=""debian/dep2"", name=""dep2"", import_id=""debian/dep2""
        )
        dep3_pkg = Package(
            id=dep3_id, derived_id=""debian/dep3"", name=""dep3"", import_id=""debian/dep3""
        )

        # Create existing dependencies (dep1 as runtime, dep2 as build)
        existing_dep1 = LegacyDependency(
            package_id=existing_pkg_id,
            dependency_id=dep1_id,
            dependency_type_id=mock_config.dependency_types.runtime,
        )
        existing_dep2 = LegacyDependency(
            package_id=existing_pkg_id,
            dependency_id=dep2_id,
            dependency_type_id=mock_config.dependency_types.build,
        )

        # Create cache
        cache = Cache(
            package_map={
                existing_import_id: existing_package,
                ""debian/dep1"": dep1_pkg,
                ""debian/dep2"": dep2_pkg,
                ""debian/dep3"": dep3_pkg,
            },
            url_map={},
            package_urls={},
            dependencies={existing_pkg_id: {existing_dep1, existing_dep2}},
        )

        # Create new package data with changed dependencies
        # Remove dep2, keep dep1, add dep3 as runtime
        new_pkg_data = create_debian_package(
            package=""dep-pkg"",
            depends=[""dep1"", ""dep3""],  # runtime deps
            build_depends=[],  # no build deps (removes dep2)
        )

        # Test the diff
        diff = DebianDiff(mock_config, cache, mock_db, mock_logger)
        new_deps, removed_deps = diff.diff_deps(existing_import_id, new_pkg_data)

        # Assertions
        assert len(new_deps) == 1  # dep3 should be added
        assert new_deps[0].dependency_id == dep3_id
        assert new_deps[0].dependency_type_id == mock_config.dependency_types.runtime

        assert len(removed_deps) == 1  # dep2 should be removed
        assert removed_deps[0].dependency_id == dep2_id
        assert removed_deps[0].dependency_type_id == mock_config.dependency_types.build
",tests/package_managers/debian/test_debian_diff.py,TestDebianDifferentialLoading,1,1.725782769012759e-08,"The method is a well-structured unit test that verifies the functionality of a dependency management system. It checks the correct recording of new, changed, and removed dependencies, which is a crucial aspect of package management. The test is specific, uses mock objects effectively, and includes assertions to validate the expected behavior. Such tests are essential for maintaining software quality and ensuring that changes in dependencies are handled correctly. Therefore, it is likely to be retained as part of the test suite."
survived,"    def diff_deps(
        self, import_id: str, debian_data: DebianData
    ) -> tuple[list[LegacyDependency], list[LegacyDependency]]:
        """"""
        Takes in a debian package and figures out what dependencies have changed.

        The process is:
           1. Build a view of what the package's dependencies are according to
              the parsed debian data, using priority-based deduplication
           2. Get this package's ID from CHAI
           3. Get this package's existing dependencies from CHAI
           4. Compare the two sets, and identify new and removed dependencies

        Note: The database has a unique constraint on (package_id, dependency_id),
        so if a package depends on the same dependency with multiple types (e.g.,
        both runtime and build), we choose the highest priority type:
        Runtime > Build > Test

        Returns:
          - new_deps: a list of new dependencies
          - removed_deps: a list of removed dependencies
        """"""
        # First, collect all dependencies and deduplicate by dependency name
        # choosing the highest priority dependency type for each unique dependency
        dependency_map: dict[str, UUID] = {}

        # Priority order: Runtime > Build > Test
        priority_order = {
            self.config.dependency_types.runtime: 1,
            self.config.dependency_types.build: 2,
            self.config.dependency_types.test: 3,
        }

        def process_deps(dependencies: list[Depends], dep_type: UUID) -> None:
            """"""Helper to process dependencies of a given type with priority""""""
            for dep in dependencies:
                dep_name = f""debian/{dep.package}""  # bc the map is by import_id

                # Get the dependency package from cache
                dependency = self.caches.package_map.get(dep_name)

                # try debian/dependency
                if not dependency:
                    self.logger.debug(f""{dep_name} not loaded, will catch next time"")
                    continue

                # If this dependency already exists in our map, choose higher priority
                if dep_name in dependency_map:
                    existing_priority = priority_order.get(
                        dependency_map[dep_name], 999
                    )
                    new_priority = priority_order.get(dep_type, 999)

                    if new_priority < existing_priority:  # Lower is better!
                        old_type_id = dependency_map[dep_name]
                        dependency_map[dep_name] = dep_type
                        self.logger.debug(
                            f""Updated dependency type for {dep_name} from ""
                            f""{old_type_id} to {dep_type} (higher priority)""
                        )
                else:
                    dependency_map[dep_name] = dep_type

        # Process different types of dependencies with priority handling
        # Debian has: depends (runtime), build_depends (build), recommends, suggests, etc.
        process_deps(debian_data.depends, self.config.dependency_types.runtime)
        process_deps(debian_data.build_depends, self.config.dependency_types.build)
        # Map recommends and suggests to runtime for simplicity
        process_deps(debian_data.recommends, self.config.dependency_types.runtime)
        process_deps(debian_data.suggests, self.config.dependency_types.runtime)

        # Now build the actual set of dependencies with resolved types
        actual: set[tuple[UUID, UUID]] = set()
        for dep_name, dep_type in dependency_map.items():
            dependency = self.caches.package_map.get(dep_name)
            if dependency:  # Double-check it still exists
                actual.add((dependency.id, dep_type))

        # get the package ID for what we are working with
        package = self.caches.package_map.get(import_id)
        if not package:
            self.logger.debug(f""New package {import_id}, will grab its deps next time"")
            return [], []

        pkg_id: UUID = package.id

        # what are its existing dependencies?
        # specifically, existing dependencies IN THE SAME STRUCTURE as `actual`,
        # so we can do an easy comparison
        existing: set[tuple[UUID, UUID]] = {
            (dep.dependency_id, dep.dependency_type_id)
            for dep in self.caches.dependencies.get(pkg_id, set())
        }

        # we have two sets!
        # actual minus existing = new_deps
        # existing minus actual = removed_deps
        new = actual - existing
        removed = existing - actual

        new_deps: list[LegacyDependency] = [
            LegacyDependency(
                package_id=pkg_id,
                dependency_id=dep[0],
                dependency_type_id=dep[1],
                created_at=self.now,
                updated_at=self.now,
            )
            for dep in new
        ]

        # get the existing legacy dependency, and add it to removed_deps
        removed_deps: list[LegacyDependency] = []
        cache_deps: set[LegacyDependency] = self.caches.dependencies.get(pkg_id, set())
        for removed_dep_id, removed_dep_type in removed:
            try:
                existing_dep = next(
                    dep
                    for dep in cache_deps
                    if dep.dependency_id == removed_dep_id
                    and dep.dependency_type_id == removed_dep_type
                )
                removed_deps.append(existing_dep)
            except StopIteration as exc:
                cache_deps_str = ""\n"".join(
                    [
                        f""{dep.dependency_id} / {dep.dependency_type_id}""
                        for dep in cache_deps
                    ]
                )
                raise ValueError(
                    f""Removing {removed_dep_id} / {removed_dep_type} for {pkg_id} but not in Cache: \n{cache_deps_str}""
                ) from exc

        return new_deps, removed_deps
",package_managers/debian/diff.py,DebianDiff,1,2.8453347280241004e-08,"The method `diff_deps` is a well-defined function that serves a specific purpose: it calculates the differences in dependencies for a Debian package by comparing the current dependencies with those stored in a cache. This functionality is crucial for maintaining accurate dependency records, especially in systems that manage package dependencies. The method is detailed, with clear steps and comments explaining its logic, making it maintainable and understandable. Additionally, it handles edge cases, such as missing packages, and uses priority-based deduplication, which is a sophisticated feature. Given its utility and the fact that it is well-implemented, it is unlikely to be deleted."
survived,"def validate_github_token():
    """"""Validate GitHub token and check permissions""""""
    try:
        data = request.get_json()
        github_token = data.get('github_token')
        repo_url = data.get('repo_url', '')
        
        if not github_token:
            return jsonify({'error': 'github_token is required'}), 400
        
        # Create GitHub client
        g = Github(github_token)
        
        # Test basic authentication
        user = g.get_user()
        logger.info(f""🔐 Token belongs to user: {user.login}"")
        
        # Test token scopes
        rate_limit = g.get_rate_limit()
        logger.info(f""📊 Rate limit info: {rate_limit.core.remaining}/{rate_limit.core.limit}"")
        
        # If repo URL provided, test repo access
        repo_info = {}
        if repo_url:
            try:
                repo_parts = repo_url.replace('https://github.com/', '').replace('.git', '')
                repo = g.get_repo(repo_parts)
                
                # Test various permissions
                permissions = {
                    'read': True,  # If we got here, we can read
                    'write': False,
                    'admin': False
                }
                
                try:
                    # Test if we can read branches
                    branches = list(repo.get_branches())
                    permissions['read_branches'] = True
                    logger.info(f""✅ Can read branches ({len(branches)} found)"")
                    
                    # Test if we can create branches (this is what's actually failing)
                    test_branch_name = f""test-permissions-{int(time.time())}""
                    try:
                        # Try to create a test branch
                        main_branch = repo.get_branch(repo.default_branch)
                        test_ref = repo.create_git_ref(f""refs/heads/{test_branch_name}"", main_branch.commit.sha)
                        permissions['create_branches'] = True
                        logger.info(f""✅ Can create branches - test successful"")
                        
                        # Clean up test branch immediately
                        test_ref.delete()
                        logger.info(f""🧹 Cleaned up test branch"")
                        
                    except Exception as branch_error:
                        permissions['create_branches'] = False
                        logger.warning(f""❌ Cannot create branches: {branch_error}"")
                        
                except Exception as e:
                    permissions['read_branches'] = False
                    permissions['create_branches'] = False
                    logger.warning(f""❌ Cannot read branches: {e}"")
                
                try:
                    # Check if we can write (without actually writing)
                    repo_perms = repo.permissions
                    permissions['write'] = repo_perms.push
                    permissions['admin'] = repo_perms.admin
                    logger.info(f""📋 Repo permissions: push={repo_perms.push}, admin={repo_perms.admin}"")
                except Exception as e:
                    logger.warning(f""⚠️ Could not check repo permissions: {e}"")
                
                repo_info = {
                    'name': repo.full_name,
                    'private': repo.private,
                    'permissions': permissions,
                    'default_branch': repo.default_branch
                }
                
            except Exception as repo_error:
                return jsonify({
                    'error': f'Cannot access repository: {str(repo_error)}',
                    'user': user.login
                }), 403
        
        return jsonify({
            'status': 'success',
            'user': user.login,
            'repo': repo_info,
            'message': 'Token is valid and has repository access'
        })
        
    except Exception as e:
        logger.error(f""Token validation error: {str(e)}"")
        return jsonify({'error': f'Token validation failed: {str(e)}'}), 401
",server/github_integration.py,,1,3.3982678079468468e-09,"The method `validate_github_token` is a comprehensive function that validates a GitHub token, checks user authentication, and verifies repository access and permissions. It includes error handling, logging, and returns detailed JSON responses based on the validation results. This functionality is crucial for applications interacting with GitHub APIs, ensuring that tokens are valid and have the necessary permissions for operations. Given its utility and the detailed implementation, it is likely to be retained in the codebase."
survived,"def load_tasks():
    """"""Load tasks from file""""""
    global tasks
    try:
        if os.path.exists(TASKS_FILE):
            with open(TASKS_FILE, 'r') as f:
                tasks = json.load(f)
            logger.info(f""📂 Loaded {len(tasks)} tasks from {TASKS_FILE}"")
        else:
            logger.info(f""📂 No tasks file found, starting fresh"")
    except Exception as e:
        logger.warning(f""⚠️ Failed to load tasks: {e}"")
        tasks = {}
",server/utils.py,,1,4.0586521248284276e-10,"The method 'load_tasks' is a utility function that loads tasks from a file into a global variable. It includes error handling and logging, which are good practices for maintaining robustness and traceability in code. The method is likely to be useful in applications where task persistence is needed, and it handles the absence of a file gracefully by initializing an empty task list. These characteristics make it a well-structured and necessary part of a task management system, suggesting it will survive."
deleted,"    def mock_graph_with_execution(self):
        """"""Create a mock graph that simulates execution.""""""
        graph = MagicMock()
        
        def mock_run(inputs=None, tweaks=None):
            """"""Mock graph execution.""""""
            input_value = inputs.get(""input_value"", """") if inputs else """"
            if ""error"" in input_value.lower():
                raise ValueError(""Simulated execution error"")
            return f""Processed: {input_value}""
        
        graph.run = mock_run
        return graph
",src/backend/tests/unit/test_mcp_server.py,TestMCPServerIntegration,1,1.0467401685178159e-08,"The method 'mock_graph_with_execution' is a utility function that creates a mock object for testing purposes. It is useful for simulating the behavior of a graph execution without needing the actual implementation. Such methods are often retained in codebases to facilitate unit testing and ensure that other parts of the code can be tested in isolation. Therefore, it is likely to be retained."
survived,"    def test_mcp_folder_invalid_flow(self, mock_load_graph, runner, tmp_path):
        """"""Test MCP mode with folder containing invalid flow files.""""""
        # Create a JSON file
        flow_file = tmp_path / ""invalid_flow.json""
        flow_file.write_text('{""invalid"": ""flow""}')
        
        # Mock graph loading to raise an error
        mock_load_graph.side_effect = ValueError(""Invalid flow structure"")
        
        result = runner.invoke(app, [
            ""serve"", str(tmp_path),
            ""--mcp"", ""--verbose""
        ])
        
        assert result.exit_code == 1
        assert ""Failed loading flow"" in result.output
",src/backend/tests/unit/test_cli.py,TestMCPServeCommand,1,7.582560422162384e-10,"The method is a test case for a specific functionality, which is to test the behavior of the system when it encounters invalid flow files in MCP mode. Test cases are crucial for ensuring the reliability and correctness of the code, especially when dealing with error handling. Removing this test would reduce the coverage and potentially allow bugs to go unnoticed. Therefore, it is likely to be retained."
survived,"    def test_rest_api_mode_requires_api_key(self, runner, temp_python_script):
        """"""Test that REST API mode (default) still requires API key.""""""
        # Ensure no API key is set
        with patch.dict(""os.environ"", {}, clear=True):
            result = runner.invoke(app, [
                ""serve"", str(temp_python_script),
                ""--no-mcp"", ""--verbose""
            ])
            
            # Should fail due to missing API key
            assert result.exit_code == 1
            assert ""LANGFLOW_API_KEY"" in result.output
",src/backend/tests/unit/test_cli.py,TestMCPServeCommand,1,9.237449576640118e-09,"The method is a test case that verifies the behavior of a REST API mode when no API key is provided. It is essential for ensuring the security and proper functioning of the application by confirming that an API key is required. Test cases like this are crucial for maintaining the integrity of the application, especially in environments where security is a concern. Therefore, it is unlikely to be deleted as it serves an important role in the testing suite."
deleted,"    def test_transform_request_temperature_n_limitation(self):
        """"""Test that n is set to 1 when temperature is low""""""
        config = MoonshotChatConfig()
        
        optional_params = {
            ""temperature"": 0.2,  # Low temperature
            ""n"": 3  # Multiple results requested
        }
        
        result = config.transform_request(
            model=""moonshot-v1-8k"",
            messages=[{""role"": ""user"", ""content"": ""test""}],
            optional_params=optional_params,
            litellm_params={},
            headers={}
        )
        
        # n should be set to 1 when temperature is low
        assert result.get(""n"") == 1
        assert result.get(""temperature"") == 0.2
",tests/test_litellm/llms/moonshot/test_moonshot_chat_transformation.py,TestMoonshotConfig,1,9.237449576640118e-09,"The method is a unit test that verifies the behavior of the `transform_request` function in the `MoonshotChatConfig` class. It checks that when a low temperature is set, the number of results (`n`) is automatically adjusted to 1, regardless of the initial request for multiple results. This is a specific and useful test to ensure the function behaves correctly under certain conditions, which is important for maintaining the integrity of the application. Therefore, it is likely to be retained as part of the test suite."
survived,"    async def transfer_traces_to_project(
        self,
        info: Info[Context, None],
        trace_ids: list[GlobalID],
        project_id: GlobalID,
    ) -> Query:
        if not trace_ids:
            raise BadRequest(""Must provide at least one trace ID to transfer"")
        trace_ids = list(set(trace_ids))
        try:
            trace_rowids = [
                from_global_id_with_expected_type(global_id=id, expected_type_name=""Trace"")
                for id in trace_ids
            ]
            dest_project_rowid = from_global_id_with_expected_type(
                global_id=project_id, expected_type_name=""Project""
            )
        except ValueError as error:
            raise BadRequest(str(error))
        
        async with info.context.db() as session:
            dest_project = await session.get(models.Project, dest_project_rowid)
            if dest_project is None:
                raise BadRequest(""Destination project does not exist"")
            
            traces = (
                await session.scalars(
                    select(models.Trace).where(models.Trace.id.in_(trace_rowids))
                )
            ).all()
            if len(traces) < len(trace_rowids):
                raise BadRequest(""Invalid trace IDs provided"")
            
            source_project_ids = set(trace.project_rowid for trace in traces)
            if len(source_project_ids) > 1:
                raise BadRequest(""Cannot transfer traces from multiple projects"")
            
            await session.execute(
                update(models.Trace)
                .where(models.Trace.id.in_(trace_rowids))
                .values(project_rowid=dest_project_rowid)
            )
            
        return Query()",src/phoenix/server/api/mutations/trace_mutations.py,TraceMutationMixin,1,4.944450477491054e-09,"The method 'transfer_traces_to_project' is well-structured and performs a specific and useful function: transferring trace records from one project to another within a database. It includes error handling for various scenarios, such as invalid trace IDs, non-existent destination projects, and attempts to transfer traces from multiple projects. These checks ensure data integrity and provide meaningful feedback to the user. The method also uses asynchronous database operations, which is a modern and efficient approach for handling I/O-bound tasks. Given these factors, the method is likely to be retained as it provides necessary functionality with robust error handling."
survived,"    def test_csharp_simple(self):
        patch = """"""
@@ -152,10 +152,6 @@ public void MethodOne()

@@ -152,10 +152,6 @@ private static int MethodTwo(int x)

@@ -152,10 +152,6 @@ protected virtual string MethodThree()

@@ -152,10 +152,6 @@ internal async Task<string> MethodFour()

@@ -152,10 +152,6 @@ public async Task MethodFive()

@@ -152,10 +152,6 @@ static void MethodSix()

@@ -152,10 +152,6 @@ public override bool MethodSeven()

@@ -152,10 +152,6 @@ public abstract void MethodEight()

@@ -152,10 +152,6 @@ public ClassName()

@@ -152,10 +152,6 @@ static ClassName()

@@ -152,10 +152,6 @@ ~ClassName()

@@ -152,10 +152,6 @@ get { return _value; }

@@ -152,10 +152,6 @@ set { _value = value; }

@@ -152,10 +152,6 @@ public int Add(int x, int y) => x + y;

@@ -152,10 +152,6 @@ void LocalFunction()

@@ -152,10 +152,6 @@ async Task<string> AsyncLocalFunction()

""""""

        assert CSharpParser.extract_functions_from_patch(patch) == {
            ""MethodOne"",
            ""MethodTwo"",
            ""MethodThree"",
            ""MethodFour"",
            ""MethodFive"",
            ""MethodSix"",
            ""MethodSeven"",
            ""MethodEight"",
            ""ClassName"",
            ""get"",
            ""set"",
            ""Add"",
            ""LocalFunction"",
            ""AsyncLocalFunction"",
        }
",tests/sentry/integrations/source_code_management/test_language_parsers.py,CSharpParserTestCase,1,9.931195248674785e-08,"The method `test_csharp_simple` is a unit test designed to verify the functionality of the `CSharpParser.extract_functions_from_patch` method. It checks if the method correctly extracts function names from a given patch string. Unit tests are crucial for ensuring code reliability and correctness, especially in parsing logic. Since this test is essential for validating the parser's functionality, it is unlikely to be deleted unless the underlying functionality is removed or significantly changed."
survived,"    def test_csharp_interface_implementations(self):
        patch = """"""
@@ -152,10 +152,6 @@ void IDisposable.Dispose()

@@ -152,10 +152,6 @@ string IFormattable.ToString(string format, IFormatProvider provider)

@@ -152,10 +152,6 @@ int IComparable<T>.CompareTo(T other)

@@ -152,10 +152,6 @@ bool IEquatable<T>.Equals(T other)

""""""

        assert CSharpParser.extract_functions_from_patch(patch) == {
            ""Dispose"",
            ""ToString"",
            ""CompareTo"",
            ""Equals"",
        }
",tests/sentry/integrations/source_code_management/test_language_parsers.py,CSharpParserTestCase,1,1.1032560311263802e-09,"The method 'test_csharp_interface_implementations' is a unit test that verifies the functionality of the 'CSharpParser.extract_functions_from_patch' method. It checks if the method correctly extracts function names from a given patch. Unit tests are crucial for ensuring code reliability and are generally not deleted unless they are redundant or replaced by more comprehensive tests. Since this test seems to be directly testing a specific functionality, it is likely to be retained."
survived,"        def func2(completion, **kwargs):
            return 0.6
",tests/test_env_group.py,TestEnvGroupRubric,0,0.9999991684720096,"The method 'func2' is very simple and returns a constant value (0.6) regardless of the input parameters. This suggests that it might not be very useful or flexible in its current form. Without additional context or usage, it seems like a placeholder or a stub for a more complex function that hasn't been implemented yet. Therefore, it is likely to be deleted or replaced in the future as the codebase evolves to meet more specific requirements."
survived,"    def test_process_completion_format(self, mock_openai_client, sample_dataset):
        """"""Test processing completion format text.""""""
        env = SimpleEnvironment(
            client=mock_openai_client,
            model=""test-model"",
            dataset=sample_dataset,
            parser=Parser(),
            rubric=Rubric()
        )
        
        # Create a mock tokenizer
        mock_tokenizer = Mock()
        mock_tokenizer.encode = Mock(side_effect=lambda text: list(range(len(text))))
        
        prompt = ""Complete this: 2+2=""
        completion = ""4""
        
        prompt_ids, prompt_mask, completion_ids, completion_mask = env.process_completion_format(
            prompt, completion, mock_tokenizer
        )
        
        assert isinstance(prompt_ids, list)
        assert isinstance(prompt_mask, list)
        assert isinstance(completion_ids, list)
        assert isinstance(completion_mask, list)
        assert len(prompt_ids) == len(prompt)
        assert len(completion_ids) == len(completion)
        assert all(m == 0 for m in prompt_mask)
        assert all(m == 1 for m in completion_mask)
",tests/test_environment.py,TestEnvironmentBase,1,1.3709566550544279e-06,"The method `test_process_completion_format` is a unit test designed to verify the functionality of the `process_completion_format` method in the `SimpleEnvironment` class. Unit tests are crucial for ensuring code reliability and are typically retained to maintain code quality. The test checks if the method correctly processes and formats the prompt and completion into token IDs and masks, which is a fundamental part of the functionality being tested. Therefore, it is unlikely to be deleted unless the functionality it tests is removed or significantly altered."
survived,"def print_step_info(step):
    """"""Print formatted step information""""""
    status_symbol = ""✓"" if step[""status""] == ""success"" else ""✗""
    print(f""\n[{step['progress']}] {status_symbol} Step {step['step']}: {step['tool_name']}"")
    print(f""  Started:  {format_timestamp(step['started_at'])}"")
    print(f""  Completed: {format_timestamp(step['completed_at'])}"")
    print(f""  Duration: {step['duration_ms']}ms"")
    
    if step[""status""] != ""success"" and ""result"" in step and ""error"" in step[""result""]:
        print(f""  Error: {step['result']['error']}"")
",examples/python_mcp_chunk_stream.py,,1,2.998960815863541e-09,"The method 'print_step_info' is a utility function that formats and prints information about a step in a process. It is useful for logging or displaying step progress in a readable format. The method is well-structured, provides clear output, and handles error cases by checking the status and printing error messages if present. Such utility functions are commonly used in applications to provide feedback to users or developers, making it likely to be retained in the codebase."
deleted,"    def parse_response(
        self, 
        response: Any, 
        schema: Dict[str, Any], 
        output_mode: OutputMode,
        tools: Optional[List[Dict[str, str]]] = None,
        manually_fix_errors: bool = False
    ) -> List[Dict[str, Any]]:
        """"""Parse response based on the output mode.""""""
        try:
            if not response:
                raise InvalidOutputError(""No response from LLM"", ""{}"", schema, [], [])

            results = []
            for index in range(len(response.choices)):
                if output_mode == OutputMode.STRUCTURED_OUTPUT:
                    results.extend(self._parse_structured_output(response, schema, index))
                else:  # OutputMode.TOOLS
                    results.extend(self._parse_tool_response(response, schema, tools, index))
            
            return results
            
        except InvalidOutputError as e:
            if manually_fix_errors:
                rprint(f""[bold red]Could not parse LLM output:[/bold red] {e.message}\n""
                       f""\tExpected Schema: {e.expected_schema}\n""
                       f""\tPlease manually set this output."")
                rprint(f""\n[bold yellow]LLM-Generated Response:[/bold yellow]\n{response}"")
                output = get_user_input_for_schema(schema)
                return [output]
            else:
                raise e
",docetl/operations/utils/api.py,ResponseParser,1,1.3440409770490404e-08,"The method 'parse_response' is well-structured and handles different output modes effectively. It includes error handling for invalid outputs and provides a mechanism for manual error correction if needed. This flexibility and robustness make it a valuable part of the codebase, suggesting it is likely to survive."
deleted,"    def _extract_snowflake_tool_calls(self, response: Any, index: int) -> List[ChatCompletionMessageToolCall]:
        """"""Extract tool calls from Snowflake model response.""""""
        if not hasattr(response.choices[index].message, ""content_list""):
            return []
        
        return [
            ChatCompletionMessageToolCall(
                function=Function(
                    name=content.get(""tool_use"", {}).get(""name""),
                    arguments=content.get(""tool_use"", {}).get(""input""),
                )
            )
            for content in response.choices[index].message.content_list
            if content.get(""type"") == ""tool_use""
        ]
",docetl/operations/utils/api.py,ResponseParser,1,5.211412485172657e-10,"The method '_extract_snowflake_tool_calls' is a utility function that extracts specific data from a response object. It is likely part of a larger system that processes responses from a Snowflake model. The method is well-defined, has a clear purpose, and is likely used in multiple places within the codebase to handle responses consistently. Unless there is a significant change in how responses are structured or a shift in the overall architecture that makes this method obsolete, it is likely to survive."
survived,"    def test_invalid_field_types(self):
        """"""Test XMLParser initialization with invalid field types.""""""
        with pytest.raises(TypeError):
            XMLParser([123])  # Invalid field type
        
        # Empty fields is actually allowed - it just creates a parser with no fields
        empty_parser = XMLParser([])  # This works
        assert empty_parser.get_fields() == []
        
        with pytest.raises(ValueError):
            XMLParser([""field1"", ""field1""])  # Duplicate fields
",tests/test_xml_parser.py,TestXMLParser,1,9.237449576640118e-09,"The method 'test_invalid_field_types' is a unit test designed to ensure that the XMLParser class handles invalid input correctly. It checks for exceptions when invalid field types or duplicate fields are provided. Such tests are crucial for maintaining code quality and ensuring robustness against incorrect usage. Therefore, it is likely to be retained as part of the test suite to prevent future regressions."
survived,"        def simple_func(completion, **kwargs):
            return 1.0
",tests/test_rubric.py,TestRubric,0,0.9999999936511998,"The method `simple_func` is very basic and does not perform any meaningful operation other than returning a constant value (1.0). It also accepts a parameter `completion` and arbitrary keyword arguments (`**kwargs`) which are not used within the function. This suggests that the function is either incomplete or not useful in its current form. Without any additional context or functionality, it is likely to be considered redundant or unnecessary in a codebase, leading to its deletion."
survived,"def mock_multiturn_env_max_turns(mock_openai_client, sample_chat_dataset):
    """"""Return a MultiTurnEnv that tests max_turns limiting.""""""
    return SimpleMultiTurnEnv(
        client=mock_openai_client,
        model=""test-model"",
        dataset=sample_chat_dataset,
        max_turns=2,
        completion_condition=""max_turns"",  # Never complete naturally
        parser=Parser(),
        rubric=Rubric()
    )",tests/conftest.py,,1,1.4166087846364157e-09,"The method 'mock_multiturn_env_max_turns' is a utility function designed to create a test environment for a multi-turn conversation model. It is likely to be retained because it serves a specific purpose in testing the behavior of a model under a condition where the number of turns is limited. Such utility functions are crucial for ensuring that models behave as expected under various scenarios, which is an important aspect of software development and testing. Unless there is a significant change in the testing framework or the method becomes obsolete due to changes in the model or testing requirements, it is likely to survive."
survived,"    async def _handle_chat_completion(self, messages, **kwargs):
        """"""Handle chat completion requests.""""""
        key = self._messages_to_key(messages)
        
        if key in self.chat_completions:
            response_data = self.chat_completions[key]
        else:
            response_data = {
                ""content"": self.default_chat_response,
                ""finish_reason"": ""stop""
            }
        
        # Create mock response
        mock_response = MagicMock()
        mock_response.choices = [MagicMock()]
        mock_response.choices[0].message.content = response_data[""content""]
        mock_response.choices[0].finish_reason = response_data[""finish_reason""]
        return mock_response
",tests/conftest.py,MockAsyncOpenAI,1,4.599055376537186e-10,"The method '_handle_chat_completion' is likely to survive because it implements a specific functionality for handling chat completion requests, which is a common requirement in applications involving chatbots or conversational agents. The method includes logic for checking cached responses and creating mock responses, indicating it is part of a testing or simulation framework. Such methods are typically essential for ensuring the robustness and reliability of chat systems."
survived,"    async def test_get_model_response_completion(self, mock_openai_client):
        """"""Test get_model_response with completion format.""""""
        env = TestEnvironment(
            client=mock_openai_client,
            model=""test-model"",
            eval_dataset=Dataset.from_dict({""prompt"": [""test""], ""answer"": [""test""]}),
            message_type=""completion"",
            parser=Parser(),
            rubric=Rubric()
        )
        
        prompt = ""Complete this:""
        response = await env.get_model_response(
            prompt=prompt,
            client=mock_openai_client,
            model=""test-model"",
            message_type=""completion""
        )
        
        assert response == ""This is a test completion""
        mock_openai_client.completions.create.assert_called_once()
",tests/test_environment.py,TestEnvironmentBase,1,2.998960815863541e-09,"The method `test_get_model_response_completion` is a unit test designed to verify the functionality of the `get_model_response` method in a specific scenario. Unit tests are crucial for ensuring code reliability and correctness, especially in environments where changes are frequent. This test checks if the method correctly handles a completion message type and if the mock client is called as expected. Since testing is an integral part of software development and maintenance, this method is likely to be retained to ensure the continued correctness of the codebase."
survived,"    def test_rubric_group_get_reward_funcs(self):
        """"""Test getting aggregated reward functions from all rubrics.""""""
        def func1(completion, **kwargs):
            return 1.0
        
        def func2(completion, **kwargs):
            return 0.5
        
        rubric1 = Rubric(funcs=[func1], weights=[1.0])
        rubric2 = Rubric(funcs=[func2], weights=[0.8])
        
        group = RubricGroup(rubrics=[rubric1, rubric2])
        funcs = group.get_reward_funcs()
        
        assert len(funcs) == 2
        assert funcs[0] == func1
        assert funcs[1] == func2
",tests/test_rubric_group.py,TestRubricGroup,1,1.1861120010657661e-08,"The method `test_rubric_group_get_reward_funcs` is a unit test designed to verify the functionality of the `get_reward_funcs` method in the `RubricGroup` class. It checks if the method correctly aggregates reward functions from multiple rubrics. Unit tests are crucial for ensuring code reliability and correctness, especially in complex systems. Since this test is specific, clear, and directly related to the functionality of the code, it is likely to be maintained as part of the test suite to ensure ongoing code quality."
survived,"    def test_environment_initialization(self, mock_openai_client, sample_dataset):
        """"""Test that Environment initializes correctly.""""""
        env = TestEnvironment(
            client=mock_openai_client,
            model=""test-model"",
            dataset=sample_dataset,
            parser=Parser(),
            rubric=Rubric()
        )
        assert env.client == mock_openai_client
        assert env.model == ""test-model""
        assert env.message_type == 'chat'
        assert isinstance(env.parser, Parser)
        assert isinstance(env.rubric, Rubric)
",tests/test_environment.py,TestEnvironmentBase,1,1.1861120010657661e-08,"The method is a unit test for the initialization of an environment object. Unit tests are crucial for ensuring code reliability and are typically maintained as part of the codebase to prevent regressions. The method is straightforward, checks essential properties, and uses mock objects, which is a common practice in testing. Therefore, it is likely to be retained."
survived,"    async def test_sampling_args_passed_through(self, mock_multiturn_env):
        """"""Test that sampling arguments are passed to model calls.""""""
        mock_multiturn_env.client.add_chat_response(
            messages=[{""role"": ""user"", ""content"": ""Test sampling""}],
            response=""Quick DONE""
        )
        
        prompt = [{""role"": ""user"", ""content"": ""Test sampling""}]
        sampling_args = {""temperature"": 0.8, ""max_tokens"": 50}
        
        completion, state = await mock_multiturn_env.rollout(
            client=mock_multiturn_env.client,
            model=""test-model"",
            prompt=prompt,
            answer=""test_answer"",
            sampling_args=sampling_args
        )
        
        # Verify sampling args were passed
        call_args = mock_multiturn_env.client.chat.completions.create.call_args
        assert ""temperature"" in call_args.kwargs
        assert ""max_tokens"" in call_args.kwargs
",tests/test_multiturn_env.py,TestMultiTurnEnv,1,1.725782769012759e-08,"The method 'test_sampling_args_passed_through' is a unit test designed to verify that certain arguments (sampling arguments) are correctly passed to a model call. Unit tests are crucial for ensuring code reliability and correctness, especially in environments where changes can frequently occur. This test checks for specific functionality and is likely part of a larger test suite. Given its role in maintaining code quality and preventing regressions, it is unlikely to be deleted unless the functionality it tests is removed or significantly altered."
survived,"    def test_parser_with_kwargs(self):
        """"""Test that Parser accepts arbitrary kwargs.""""""
        parser = Parser(custom_attr=""test_value"", number=42)
        assert parser.custom_attr == ""test_value""
        assert parser.number == 42
",tests/test_parser.py,TestParser,1,7.194132978569833e-09,"The method 'test_parser_with_kwargs' is a unit test designed to verify that the 'Parser' class can accept and correctly handle arbitrary keyword arguments. This is a useful test to ensure the flexibility and robustness of the 'Parser' class, especially if it is intended to be used in various contexts where different configurations might be needed. Since testing is a crucial part of software development to ensure code quality and reliability, this method is likely to be retained as part of the test suite."
survived,"    def test_parser_initialization(self, basic_parser):
        """"""Test that Parser initializes correctly.""""""
        assert isinstance(basic_parser, Parser)
        assert hasattr(basic_parser, 'logger')
",tests/test_parser.py,TestParser,1,6.023574641292144e-08,"The method `test_parser_initialization` is a unit test that checks the initialization of a `Parser` object. It verifies that the `basic_parser` is an instance of `Parser` and that it has a `logger` attribute. This is a fundamental test to ensure that the `Parser` class is set up correctly, which is crucial for any further testing or development. Such tests are typically retained as they provide a basic validation of object construction and attribute presence, which are essential for debugging and maintaining code quality."
survived,"    def test_rubric_group_with_max_concurrent(self):
        """"""Test RubricGroup with max_concurrent parameter.""""""
        # Note: This test is skipped because RubricGroup.score_rollouts() has a bug
        pass
",tests/test_rubric_group.py,TestRubricGroup,0,0.9999997897565932,"The method is currently not functional due to a known bug in the RubricGroup.score_rollouts() method, as indicated by the comment. Since it is skipped and not providing any value in its current state, it is likely to be deleted unless the bug is fixed and the test is updated to be meaningful."
survived,"    def test_environment_no_datasets_raises_error(self, mock_openai_client):
        """"""Test that Environment raises error when no datasets provided.""""""
        with pytest.raises(ValueError, match=""Either dataset or eval_dataset must be provided""):
            TestEnvironment(
                client=mock_openai_client,
                model=""test-model"",
                parser=Parser(),
                rubric=Rubric()
            )
",tests/test_environment.py,TestEnvironmentBase,1,8.152020648014727e-09,"The method `test_environment_no_datasets_raises_error` is a unit test designed to ensure that the `TestEnvironment` class raises a `ValueError` when neither a dataset nor an eval_dataset is provided. This is a crucial test to verify the robustness and correctness of the `TestEnvironment` class, ensuring it handles missing data inputs appropriately. Unit tests like this are essential for maintaining code quality and preventing regressions, especially in environments where data integrity is critical. Therefore, this method is likely to be retained as part of the test suite."
survived,"    def test_abstract_methods_not_implemented(self):
        """"""Test that MultiTurnEnv cannot be instantiated directly (abstract class).""""""
        # MultiTurnEnv is abstract and should not be instantiable without implementing abstract methods
        with pytest.raises(TypeError):
            # This should fail because MultiTurnEnv has abstract methods
            MultiTurnEnv(
                model=""test-model"",
                parser=Parser(),
                rubric=Rubric()
            )
",tests/test_multiturn_env.py,TestMultiTurnEnv,1,4.944450477491054e-09,"The method is a test case that ensures the abstract class MultiTurnEnv cannot be instantiated directly without implementing its abstract methods. This is a valid and necessary test to ensure the integrity of the class design, especially in object-oriented programming where abstract classes are used to define interfaces. Therefore, the method is likely to be retained as it serves a critical role in testing the correct behavior of the class."
survived,"    async def test_state_management(self, mock_multiturn_env):
        """"""Test that state is properly initialized and maintained.""""""
        mock_multiturn_env.client.add_chat_response(
            messages=[{""role"": ""user"", ""content"": ""Test state""}],
            response=""Quick DONE""
        )
        
        prompt = [{""role"": ""user"", ""content"": ""Test state""}]
        completion, state = await mock_multiturn_env.rollout(
            client=mock_multiturn_env.client,
            model=""test-model"",
            prompt=prompt,
            answer=""test_answer""
        )
        
        # State should contain the answer
        assert ""answer"" in state
        assert state[""answer""] == ""test_answer""
",tests/test_multiturn_env.py,TestMultiTurnEnv,1,6.825604231969389e-08,"The method `test_state_management` is a unit test designed to verify that the state is properly initialized and maintained during a conversation with a mock environment. Unit tests are crucial for ensuring code reliability and functionality, especially in complex systems involving state management. This test checks that the state contains the expected answer after a rollout, which is a fundamental aspect of the system's behavior. Therefore, it is unlikely to be deleted as it serves an important role in maintaining code quality and preventing regressions."
survived,"    async def test_env_response_integration(self, mock_multiturn_env):
        """"""Test that environment responses are properly integrated.""""""
        # Set up responses for the conversation turns
        mock_multiturn_env.client.add_chat_response(
            messages=[{""role"": ""user"", ""content"": ""Start conversation""}],
            response=""First response""
        )
        mock_multiturn_env.client.add_chat_response(
            messages=[
                {""role"": ""user"", ""content"": ""Start conversation""},
                {""role"": ""assistant"", ""content"": ""First response""},
                {""role"": ""user"", ""content"": ""Continue (turn 1)""}
            ],
            response=""Final response DONE""
        )
        
        prompt = [{""role"": ""user"", ""content"": ""Start conversation""}]
        completion, state = await mock_multiturn_env.rollout(
            client=mock_multiturn_env.client,
            model=""test-model"",
            prompt=prompt,
            answer=""target_answer""
        )
        
        # Verify environment responses are included
        assert len(completion) >= 3
        user_messages = [msg for msg in completion if msg[""role""] == ""user""]
        assert len(user_messages) >= 1
        assert ""Continue (turn 1)"" in user_messages[0][""content""]
",tests/test_multiturn_env.py,TestMultiTurnEnv,1,1.1861120010657661e-08,"The method is a test function that verifies the integration of environment responses in a multi-turn conversation. It uses mock objects to simulate the environment and checks if the responses are correctly integrated into the conversation flow. Test functions like this are crucial for ensuring the reliability and correctness of the code, especially in complex systems involving asynchronous operations and external dependencies. Therefore, it is likely to be retained as part of the test suite to maintain code quality."
survived,"    def test_parse_missing_fields(self, xml_parser):
        """"""Test parsing XML with missing fields.""""""
        xml_text = ""<reasoning>Only reasoning here</reasoning>""
        result = xml_parser.parse(xml_text)
        assert result.reasoning == ""Only reasoning here""
        assert result.answer is None
",tests/test_xml_parser.py,TestXMLParser,1,1.0467401685178159e-08,"The method 'test_parse_missing_fields' is a unit test designed to verify the behavior of an XML parser when certain fields are missing. Unit tests are crucial for ensuring code reliability and are typically maintained as long as the functionality they test is relevant. Since this test checks for a specific edge case (missing fields in XML), it is likely to be retained to ensure the parser handles such cases correctly."
survived,"    def test_rubric_group_score_rollouts_duplicate_names(self):
        """"""Test that duplicate reward function names are summed up.""""""
        # Note: This test is skipped because RubricGroup.score_rollouts() has a bug
        pass
",tests/test_rubric_group.py,TestRubricGroup,0,0.9999785550602307,"The method is currently skipped due to a known bug in the RubricGroup.score_rollouts() function. This indicates that the test is not functional or relevant until the bug is fixed. If the bug is not addressed, the test may be considered redundant and could be deleted. However, if the bug is fixed, the test could be updated and used to verify the fix. Without further context on the development priorities or plans to fix the bug, it's more likely to be deleted if it remains unaddressed."
survived,"    async def test_completion_detection_before_env_response(self, mock_openai_client, sample_chat_dataset):
        """"""Test completion detection works before env_response is called.""""""
        class ImmediateCompletionEnv(MultiTurnEnv):
            def is_completed(self, messages, state, **kwargs):
                # Complete if we have any assistant message
                return any(msg.get(""role"") == ""assistant"" for msg in messages)
            
            def env_response(self, messages, state, **kwargs):
                # This should never be called due to immediate completion
                return {""role"": ""user"", ""content"": ""Should not appear""}, state
        
        env = ImmediateCompletionEnv(
            client=mock_openai_client,
            model=""test-model"",
            dataset=sample_chat_dataset,
            max_turns=5,
            parser=Parser(),
            rubric=Rubric()
        )
        
        env.client.add_chat_response(
            messages=[{""role"": ""user"", ""content"": ""Start""}],
            response=""First response""
        )
        
        prompt = [{""role"": ""user"", ""content"": ""Start""}]
        completion, state = await env.rollout(
            client=env.client,
            model=""test-model"",
            prompt=prompt,
            answer=""test""
        )
        
        # Should complete immediately after first assistant response
        assert len(completion) == 1
        assert completion[0][""role""] == ""assistant""
        assert completion[0][""content""] == ""First response""",tests/test_multiturn_env.py,TestMultiTurnEnv,1,1.955568070542584e-08,"The method is a unit test designed to verify the behavior of a specific environment class (ImmediateCompletionEnv) in a chat simulation. It ensures that the environment correctly identifies completion based on the presence of an assistant message and does not proceed to call the env_response method. This is a valid and useful test for ensuring the correct functionality of the environment's completion logic. As such, it is likely to be retained in the codebase to maintain test coverage and ensure the reliability of the system."
survived,"    def test_get_dataset(self, mock_openai_client, sample_dataset):
        """"""Test dataset retrieval.""""""
        env = TestEnvironment(
            client=mock_openai_client,
            model=""test-model"",
            dataset=sample_dataset,
            parser=Parser(),
            rubric=Rubric()
        )
        
        # Get full dataset
        full_dataset = env.get_dataset()
        assert len(full_dataset) == 2
        
        # Get subset
        subset = env.get_dataset(n=1)
        assert len(subset) == 1
",tests/test_environment.py,TestEnvironmentBase,1,1.522997951276035e-08,"The method `test_get_dataset` is a unit test designed to verify the functionality of the `get_dataset` method within a `TestEnvironment` class. Unit tests are crucial for ensuring code reliability and correctness, especially in a testing framework. This method is likely to be maintained as it serves the purpose of validating that the dataset retrieval works as expected, both for full datasets and subsets. Therefore, it is unlikely to be deleted unless the functionality it tests is removed or significantly altered."
survived,"    def _timeout_handler(self, signum, frame):
        """"""超时信号处理器""""""
        raise TimeoutException(""内存分析超时"")
",app/helper/memory.py,MemoryHelper,1,4.944450477491054e-09,"The method `_timeout_handler` is a private method (indicated by the underscore prefix) designed to handle timeout signals by raising a `TimeoutException`. This is a common pattern in Python for managing operations that may exceed a certain time limit. The method is concise, serves a specific purpose, and is likely part of a larger system that requires timeout management. There is no indication that this method is redundant or unnecessary, so it is likely to be retained in the codebase."
survived,"def test_packages(ids):
    """"""Fixture providing test package objects.""""""
    return {
        ""package1"": Package(
            id=ids[""pkg1""],
            name=""package1"",
            package_manager_id=ids[""package_manager""],
            import_id=""pkg1"",
            derived_id=""npm/package1"",
            created_at=datetime.now(),
            updated_at=datetime.now(),
        ),
        ""package2"": Package(
            id=ids[""pkg2""],
            name=""package2"",
            package_manager_id=ids[""package_manager""],
            import_id=""pkg2"",
            derived_id=""npm/package2"",
            created_at=datetime.now(),
            updated_at=datetime.now(),
        ),
        ""package3"": Package(
            id=ids[""pkg3""],
            name=""package3"",
            package_manager_id=ids[""package_manager""],
            import_id=""pkg3"",
            derived_id=""npm/package3"",
            created_at=datetime.now(),
            updated_at=datetime.now(),
        ),
    }
",tests/ranker/test_dedupe.py,,1,6.348800075736417e-09,"The method 'test_packages' is a fixture function that creates and returns a dictionary of test package objects. This is a common pattern in testing frameworks to provide reusable test data. The method is likely to be used in multiple test cases to ensure consistency and reduce redundancy in test setup. Since it serves a clear purpose in the context of testing, it is unlikely to be deleted unless the testing strategy or framework changes significantly."
survived,"def test_map_operation_instance(
    map_config_with_batching, default_model, max_threads, runner
):
    return MapOperation(
        runner, map_config_with_batching, default_model, max_threads
    )
",tests/basic/test_basic_map.py,,1,2.0611536181902033e-09,"The method 'test_map_operation_instance' is a simple utility function that creates and returns an instance of 'MapOperation'. It is likely used in a testing context to verify the behavior of 'MapOperation' with different configurations. Such utility functions are common in test suites to reduce code duplication and improve readability. Unless the 'MapOperation' class or its usage is deprecated or significantly refactored, this method is likely to survive as it serves a clear purpose in testing."
survived,"def test_optimized_schema():
	""""""Test the optimized schema generation and save to file.""""""

	# Create controller and get all registered actions
	controller = Controller()
	ActionModel = controller.registry.create_action_model()

	# Create the agent output model with custom actions
	agent_output_model = AgentOutput.type_with_custom_actions(ActionModel)

	# Get original schema for comparison
	original_schema = agent_output_model.model_json_schema()

	# Create the optimized schema
	optimized_schema = SchemaOptimizer.create_optimized_json_schema(agent_output_model)

	# Create tmp directory if it doesn't exist
	os.makedirs('./tmp', exist_ok=True)

	# Save optimized schema
	with open('./tmp/optimized_schema.json', 'w') as f:
		json.dump(optimized_schema, f, separators=(',', ':'), indent=2)

	print('✅ Optimized schema generated and saved to ./tmp/optimized_schema.json')

	# Compare token counts of both
	try:
		enc = tiktoken.encoding_for_model('gpt-4o')
	except KeyError:
		enc = tiktoken.get_encoding('cl100k_base')

	original_tokens = len(enc.encode(json.dumps(original_schema)))
	optimized_tokens = len(enc.encode(json.dumps(optimized_schema, separators=(',', ':'))))

	savings = original_tokens - optimized_tokens
	savings_percentage = (savings / original_tokens * 100) if original_tokens > 0 else 0

	print('\n📊 Token Count Comparison:')
	print(f'   Original schema: {original_tokens:,} tokens')
	print(f'   Optimized schema: {optimized_tokens:,} tokens')
	print(f'   Token savings: {savings:,} tokens ({savings_percentage:.1f}% reduction)')

	# Count tokens per action in optimized schema
	print('\n🔍 Tokens per Action in Optimized Schema:')

	if 'properties' in optimized_schema and 'action' in optimized_schema['properties']:
		action_prop = optimized_schema['properties']['action']
		if 'items' in action_prop and 'anyOf' in action_prop['items']:
			actions = action_prop['items']['anyOf']

			total_action_tokens = 0
			for i, action in enumerate(actions):
				action_json = json.dumps(action, separators=(',', ':'))
				action_tokens = len(enc.encode(action_json))
				total_action_tokens += action_tokens

				# Try to get action name from the schema
				action_name = 'Unknown'
				if 'properties' in action:
					# Get the first property that's not common ones like 'index', 'reasoning'
					for prop_name in action['properties'].keys():
						if prop_name not in ['index', 'reasoning']:
							action_name = prop_name
							break

				print(f'   Action {i + 1} ({action_name}): {action_tokens:,} tokens')

			print('\n📈 Summary:')
			print(f'   Total actions: {len(actions)}')
			print(f'   Total action tokens: {total_action_tokens:,} tokens')
			print(f'   Average tokens per action: {total_action_tokens // len(actions):,} tokens')
			print(f'   Action tokens as % of total: {(total_action_tokens / optimized_tokens * 100):.1f}%')
		else:
			print('   No actions found in expected schema structure')
	else:
		print('   No action property found in optimized schema')
",tests/ci/test_custom_structured_ouput.py,,1,1.275190675769241e-07,"The method `test_optimized_schema` is a comprehensive test function that validates the process of generating an optimized JSON schema, saving it to a file, and comparing it with the original schema in terms of token count. It includes detailed logging and error handling, making it useful for debugging and ensuring the optimization process is effective. Such utility functions are often retained in codebases for testing and validation purposes."
survived,"    def test_send_email_without_body_or_html_raises_error(self, mock_smtp_class, smtp_provider):
        """"""Test that sending an email without body or html raises an error.""""""
        # Setup mock SMTP instance
        mock_smtp = MagicMock()
        mock_smtp_class.return_value = mock_smtp

        # Attempt to send email without body or html
        with pytest.raises(ValueError, match=""Either 'body' or 'html' must be provided""):
            smtp_provider._notify(
                from_email=""sender@example.com"",
                from_name=""Test Sender"",
                to_email=""recipient@example.com"",
                subject=""Test Subject"",
            )
",tests/test_smtp_provider.py,TestSmtpProvider,1,1.6052280526088547e-09,"The method is a unit test designed to ensure that the email sending functionality correctly raises an error when neither a body nor HTML content is provided. This is a valid and important test case to ensure robustness and correctness of the email sending feature. It helps in maintaining the integrity of the application by preventing emails from being sent without content, which could lead to confusion or errors in communication. Therefore, this method is likely to be retained as part of the test suite."
deleted,"def test_agg_partition_by_string_notation(test_session):
    """"""Test that agg method supports string notation for partition_by.""""""
    class _ImageGroup(BaseModel):
        name: str
        size: int

    def func(key, val) -> Iterator[tuple[File, _ImageGroup]]:
        n = ""-"".join(key)
        v = sum(val)
        yield File(path=n), _ImageGroup(name=n, size=v)

    keys = [""n1"", ""n2"", ""n1""]
    values = [1, 5, 9]
    
    # Test using string notation (NEW functionality)
    ds = dc.read_values(key=keys, val=values, session=test_session).agg(
        x=func, partition_by=""key""  # String notation instead of C(""key"")
    )

    assert ds.order_by(""x_1.name"").to_values(""x_1.name"") == [""n1-n1"", ""n2""]
    assert ds.order_by(""x_1.size"").to_values(""x_1.size"") == [5, 10]
",tests/unit/lib/test_datachain.py,,1,5.3157849718487075e-08,"The method is a test function that verifies the functionality of a new feature (string notation for partition_by) in a data processing library. Test functions are generally kept as long as the feature they are testing is relevant and the test itself is valid. Since this test is checking a new feature, it is likely to be retained to ensure the feature works as expected."
survived,"def test_top_level_start_session_basic(sentry_init, capture_envelopes):
    """"""Test that top-level start_session starts a session on the isolation scope.""""""
    sentry_init(release=""test-release"", environment=""test-env"")
    envelopes = capture_envelopes()

    # Start a session using the top-level API
    sentry_sdk.start_session()

    # End the session
    sentry_sdk.end_session()
    sentry_sdk.flush()

    # Check that we got a session envelope
    assert len(envelopes) == 1
    sess = envelopes[0]
    assert len(sess.items) == 1
    sess_event = sess.items[0].payload.json

    assert sess_event[""attrs""] == {
        ""release"": ""test-release"",
        ""environment"": ""test-env"",
    }
    assert sess_event[""status""] == ""exited""
",tests/test_sessions.py,,1,1.1861120010657661e-08,"The method is a test function that verifies the functionality of starting and ending a session using the Sentry SDK. It checks that a session envelope is created with the correct attributes and status. This is a basic and essential test to ensure that the session management in the SDK works as expected. Such tests are crucial for maintaining the reliability of the SDK, especially in production environments. Therefore, it is unlikely to be deleted as it serves an important role in the testing suite."
survived,"def check_server(url: str) -> bool:
    """"""Check if a server is running at the given URL.""""""
    try:
        response = requests.get(f""{url}/"", timeout=2)
        return response.status_code < 500
    except Exception:
        return False
",benchmarks/benchmark.py,,1,7.194132978569833e-09,"The method 'check_server' is a simple utility function that checks if a server is running at a given URL by making an HTTP GET request. It is a useful function for monitoring server availability and can be used in various applications that require server status checks. The function is straightforward, handles exceptions, and provides a boolean output indicating the server's status. These characteristics make it a practical and reusable piece of code, which is likely to be retained in a codebase."
survived,"def run_benchmark(name: str, url: str, method: str, path: str, data: Optional[Dict],
                 headers: Optional[Dict], concurrency: int, duration: int) -> BenchmarkResult:
    """"""Run a benchmark for a specific endpoint.""""""
    console.print(f""Running benchmark: [bold]{name}[/bold] with concurrency {concurrency}..."")
    
    start_time = time.time()
    end_time = start_time + duration
    
    latencies = []
    errors = 0
    requests_count = 0
    
    with ThreadPoolExecutor(max_workers=concurrency) as executor:
        futures = []
        
        for _ in range(concurrency):
            futures.append(executor.submit(
                make_request, url, method, path, data, headers
            ))
        
        while time.time() < end_time:
            for i, future in enumerate(futures):
                if future.done():
                    latency, success = future.result()
                    latencies.append(latency)
                    requests_count += 1
                    
                    if not success:
                        errors += 1
                    
                    if time.time() < end_time:
                        futures[i] = executor.submit(
                            make_request, url, method, path, data, headers
                        )
            
            time.sleep(0.01)  # Small sleep to prevent CPU spinning
    
    actual_duration = time.time() - start_time
    
    return BenchmarkResult(
        name=name,
        concurrency=concurrency,
        requests=requests_count,
        duration=actual_duration,
        latencies=latencies,
        errors=errors
    )
",benchmarks/benchmark.py,,1,5.211412485172657e-10,"The method 'run_benchmark' is a well-structured and useful function for running performance benchmarks on web endpoints. It uses concurrency to simulate multiple requests, collects latency data, and tracks errors, which are essential for performance testing. The method is likely to be used in various scenarios where performance metrics are needed, making it a valuable tool in a developer's toolkit. Additionally, the use of a ThreadPoolExecutor for managing concurrent requests is a common and efficient pattern in Python. Therefore, the method is likely to survive."
survived,"def test_markdown_option_in_task_prompt():
    """"""Test that when markdown=True, the task prompt includes markdown formatting instructions.""""""
    
    researcher = Agent(
        role=""Researcher"",
        goal=""Research a topic"",
        backstory=""You're a researcher specialized in providing well-formatted content."",
        allow_delegation=False,
    )

    task = Task(
        description=""Research advances in AI in 2023"",
        expected_output=""A summary of key AI advances in 2023"",
        markdown=True,
        agent=researcher,
    )

    prompt = task.prompt()
    
    assert ""Research advances in AI in 2023"" in prompt
    assert ""A summary of key AI advances in 2023"" in prompt
    assert ""Your final answer MUST be formatted in Markdown syntax."" in prompt
",tests/test_markdown_task.py,,1,1.522997951276035e-08,"The method is a unit test that verifies the functionality of a specific feature (markdown option) in a task prompt. It is well-defined, has a clear purpose, and is likely part of a test suite to ensure code quality and correctness. Such tests are crucial for maintaining software reliability, especially when dealing with formatting requirements. Therefore, it is unlikely to be deleted."
survived,"    def _calculate_with_price(
        price: Dict[str, float], token_usage_input: int, token_usage_output: int
    ) -> float:
        """"""
        価格情報とトークン使用量から推定コストを計算する

        Args:
            price: 価格情報（inputとoutputの価格）
            token_usage_input: 入力トークン使用量
            token_usage_output: 出力トークン使用量

        Returns:
            float: 推定コスト（USD）
        """"""
        input_cost = (token_usage_input / 1_000_000) * price[""input""]
        output_cost = (token_usage_output / 1_000_000) * price[""output""]
        total_cost = input_cost + output_cost
        return total_cost
",server/src/services/llm_pricing.py,LLMPricing,1,4.599055376537186e-10,"The method '_calculate_with_price' is a utility function that calculates the estimated cost based on token usage and price information. It is well-documented, with clear arguments and return values, and performs a straightforward calculation that is likely to be useful in various contexts where cost estimation is needed. There is no indication that this method is obsolete or redundant, and it serves a clear purpose in its context. Therefore, it is likely to be retained in the codebase."
survived,"def opensea(options: OpenSeaPluginOptions) -> OpenSeaPlugin:
    return OpenSeaPlugin(options)",python/src/plugins/opensea/goat_plugins/opensea/__init__.py,,1,2.998960815863541e-09,"The method 'opensea' is a simple factory function that takes an 'OpenSeaPluginOptions' object as an argument and returns an 'OpenSeaPlugin' object. This kind of method is typically useful for encapsulating the creation logic of an object, which can be beneficial for maintaining clean and modular code. Unless there is a significant change in the design or requirements that makes this method redundant or unnecessary, it is likely to survive. Additionally, the method is straightforward and does not contain any apparent issues or complexities that would necessitate its removal."
survived,"    def supports_chain(self, chain) -> bool:
        # Dexscreener is a data provider for multiple chains
        return True
",python/src/plugins/dexscreener/goat_plugins/dexscreener/__init__.py,DexscreenerPlugin,1,3.927863699585036e-07,"The method 'supports_chain' is a simple implementation that always returns True, indicating that it supports any chain passed to it. This is a common placeholder or default implementation when the actual logic for determining support is not yet implemented. However, the method is functional and does not contain any errors or deprecated practices. It is likely to survive unless there is a specific requirement to implement more complex logic for chain support in the future."
survived,"    async def get_pairs_by_chain_and_pair(self, parameters: dict):
        url = f""{self.base_url}/pairs/{parameters['chainId']}/{parameters['pairId']}""
        return await self._fetch(url, ""fetch pairs"")
",python/src/plugins/dexscreener/goat_plugins/dexscreener/service.py,DexscreenerService,1,1.493094675974231e-10,"The method 'get_pairs_by_chain_and_pair' is likely to survive because it is a straightforward asynchronous function that constructs a URL using parameters and calls another method '_fetch' to perform the actual data retrieval. This pattern is common in API client libraries, and unless there are changes in the API structure or the method '_fetch' is deprecated, there is no immediate reason to remove this method."
survived,"def farcaster(options: FarcasterPluginOptions) -> FarcasterPlugin:
    return FarcasterPlugin(options)",python/src/plugins/farcaster/goat_plugins/farcaster/__init__.py,,1,1.725782769012759e-08,"The method 'farcaster' is a simple factory function that takes an instance of 'FarcasterPluginOptions' and returns a new instance of 'FarcasterPlugin'. This pattern is common and useful for creating objects with specific configurations. There is no indication that this method is redundant or unnecessary, as it encapsulates the creation logic of 'FarcasterPlugin' objects, which can be beneficial for maintaining clean and modular code. Therefore, it is likely to be retained."
survived,"def main(_):
    base_temp_dir = FLAGS.temp_dir or tempfile.gettempdir()
    with tempfile.TemporaryDirectory(dir=base_temp_dir) as temp_dir:
        zip_path = os.path.join(temp_dir, ""test_dataset.zip"")
        download_file(FLAGS.url, zip_path)
        
        extract_dir = os.path.join(temp_dir, ""extracted"")
        os.makedirs(extract_dir, exist_ok=True)
        extract_zip(zip_path, extract_dir)
        
        results = test_parsing_equality(extract_dir)
        
        print(""\nTest Summary:"")
        print(f""  Passed: {results['passed']}"")
        print(f""  Failed: {results['failed']}"")
        
        if results[""errors""]:
            print(""\nFailures:"")
            for name, error in results[""errors""]:
                print(f""  {name}: {error}"")
        
        if FLAGS.keep_files:
            keep_dir = os.path.join(os.getcwd(), ""test_dataset"")
            print(f""\nKeeping files in {keep_dir}"")
            if not os.path.exists(keep_dir):
                os.makedirs(keep_dir)
            os.system(f""cp -r {extract_dir}/* {keep_dir}/"")
        
        return 0 if results[""failed""] == 0 else 1
",tests/replay_parser_test.py,,1,4.6911638017642294e-08,"The method is a well-structured function that performs a series of operations: downloading a file, extracting it, testing the contents, and optionally keeping the files. It handles temporary directories and provides a summary of the test results. The functionality is clear and useful for testing purposes, and there are no obvious issues or redundancies that would necessitate its deletion. Additionally, it includes error handling and a conditional file-keeping feature, which adds to its robustness and utility."
survived,"def test_parsing_equality(directory):
    """"""Test that libmelee and peppi parse SLP files the same way.""""""
    files = utils.traverse_slp_files(directory)
    print(f""Found {len(files)} .slp files to test"")
    
    results = {
        ""passed"": 0,
        ""failed"": 0,
        ""errors"": []
    }
    
    for i, file in enumerate(files):
        print(f""Testing file {i+1}/{len(files)}: {file.name}"")
        try:
            with file.extract("""") as path:
                preprocessing.assert_same_parse(path)
                results[""passed""] += 1
        except AssertionError as e:
            print(f""  FAIL: {e}"")
            results[""failed""] += 1
            results[""errors""].append((file.name, str(e)))
        except Exception as e:
            print(f""  ERROR: {e}"")
            results[""failed""] += 1
            results[""errors""].append((file.name, str(e)))
    
    return results
",tests/replay_parser_test.py,,1,1.725782769012759e-08,"The method 'test_parsing_equality' is a utility function designed to test the consistency of parsing between two libraries, 'libmelee' and 'peppi', for SLP files. It is a specific and useful function for ensuring data integrity and consistency in applications that rely on these libraries for parsing. Such testing functions are crucial in development and maintenance processes to catch discrepancies early. Therefore, it is likely to be retained as part of the codebase to ensure ongoing reliability and correctness of the parsing logic."
survived,"def download_file(url, destination):
    """"""Download a file from a URL to a local destination.""""""
    print(f""Downloading from {url} to {destination}..."")
    response = requests.get(url, stream=True)
    response.raise_for_status()
    
    with open(destination, ""wb"") as f:
        for chunk in response.iter_content(chunk_size=8192):
            f.write(chunk)
    
    print(f""Download complete: {destination}"")
    return destination
",tests/replay_parser_test.py,,1,1.725782769012759e-08,"The method 'download_file' is a utility function that performs a common task of downloading a file from a given URL to a specified local destination. This functionality is widely used in various applications and scripts, making it a valuable and reusable piece of code. The method is straightforward, uses standard libraries, and handles potential errors with 'raise_for_status'. Therefore, it is likely to be retained in the codebase for its utility and simplicity."
survived,"    def create_source_tables(
        self,
        source: Source,
        streams: Literal[""*""] | list[str] | None = None,
    ) -> None:
        """"""Create tables in the cache for the provided source if they do not exist already.

        Tables are created based upon the Source's catalog.

        Args:
            source: The source to create tables for.
            streams: Stream names to create tables for. If None, use the Source's selected_streams
                or ""*"" if neither is set. If ""*"", all available streams will be used.
        """"""
        if streams is None:
            streams = source.get_selected_streams() or ""*""

        catalog_provider = CatalogProvider(source.get_configured_catalog(streams=streams))

        # Ensure schema exists
        self.processor._ensure_schema_exists()  # noqa: SLF001  # Accessing non-public member

        # Create tables for each stream if they don't exist
        for stream_name in catalog_provider.stream_names:
            self.processor._ensure_final_table_exists(  # noqa: SLF001
                stream_name=stream_name,
                create_if_missing=True,
            )
",airbyte/caches/base.py,CacheBase,1,9.736200303530205e-10,"The method 'create_source_tables' is well-documented and serves a clear purpose of creating tables based on a source's catalog. It includes flexibility in handling different stream inputs and ensures that necessary schemas and tables are created if they don't exist. This functionality is essential for managing data sources and is likely to be a core part of the system's operations. Therefore, it is unlikely to be deleted."
deleted,"    def description(self) -> str:
        return ""Validates the connector version.""
",airbyte-ci/connectors/connectors_qa/src/connectors_qa/checks/version.py,VersionCheck,1,7.194132978569833e-09,"The method 'description' is a simple method that returns a string describing its purpose. It is likely part of a larger class or module that deals with connector validation. Such methods are often used to provide metadata or documentation about the functionality of a class or module. Since it serves a clear purpose and is not redundant or obsolete, it is likely to be retained in the codebase."
deleted,"    def test_run_release_candidates_different_versions(self, mock_current_version, mock_master_version, version_increment_check, connector):
        mock_master_version.return_value = semver.Version.parse(""1.0.0-rc.1"")
        mock_current_version.return_value = semver.Version.parse(""1.1.0-rc.1"")
        
        result = version_increment_check._run(connector)
        
        assert result.status == CheckStatus.FAILED
        assert ""Release candidates should only differ in the prerelease part"" in result.message
",airbyte-ci/connectors/connectors_qa/tests/checks/test_version.py,TestVersionIncrementCheck,1,6.69158608681505e-10,"The method is a unit test that checks a specific condition related to versioning of release candidates. It ensures that the version increment check fails when the major or minor version changes between release candidates, which is a valid and important test case for maintaining versioning standards. Such tests are crucial for ensuring software quality and are unlikely to be deleted unless the functionality they test is removed or significantly altered."
survived,"async def setup_ycell():
    """"""Setup and teardown for ycell tests""""""
    # Clear any existing ycells
    ycells.clear()
    yield
    # Cleanup after test
    ycells.clear()
",marimo/_server/api/endpoints/tests/test_ws_rtc.py,,1,2.0611536181902033e-09,"The method 'setup_ycell' is an asynchronous generator function used for setting up and tearing down test environments for 'ycell' tests. It clears the 'ycells' before and after the tests, ensuring a clean state for each test run. This is a common pattern in testing to avoid side effects between tests. The method is likely to survive because it is a utility function that provides a necessary setup and teardown mechanism for tests, which is a standard practice in test-driven development."
survived,"def save_json_result(json_path, results):
    output = []
    for r in results:
        output.append({
            'yaw': r['yaw'].tolist(),
            'pitch': r['pitch'].tolist(),
            'roll': r['roll'].tolist(),
        })
    with open(json_path, 'w') as f:
        json.dump(output, f, indent=2)",face_recognition/6d_repnet_360/utils_6d_repnet_360/utils.py,,1,1.1032560311263802e-09,"The method 'save_json_result' is a utility function that converts a list of results into a JSON format and saves it to a specified file path. This is a common and useful operation in data processing and machine learning workflows, where results need to be stored in a structured format for later analysis or sharing. The method is straightforward, uses standard libraries, and performs a clear and necessary task. There is no indication that this method is redundant or obsolete, and it is likely to be useful in many contexts where JSON serialization is required. Therefore, it is likely to survive."
survived,"def get_ypr_from_mat(mat_path):
    mat = sio.loadmat(mat_path)
    pre_pose_params = mat['Pose_Para'][0]
    pose_params = pre_pose_params[:3]
    return pose_params
",face_recognition/6d_repnet_360/utils_6d_repnet_360/utils.py,,1,2.998960815863541e-09,"The method `get_ypr_from_mat` is a simple utility function that loads a MATLAB file and extracts specific pose parameters. It is likely to be useful in contexts where pose estimation or analysis is required, especially in fields like computer vision or robotics. The function is straightforward, performs a clear task, and does not have any apparent issues or redundancies that would necessitate its removal. Therefore, it is likely to be retained in the codebase."
survived,"    def __init__(
        self,
        model
    ):
        self.model = model
",face_recognition/6d_repnet_360/utils_6d_repnet_360/functions.py,RetinaFaceOnnx,1,5.60279640614594e-09,"The method is a constructor for a class, which is a fundamental part of object-oriented programming in Python. It initializes the instance of the class with a given model, which is a common pattern for setting up objects with necessary attributes. Such methods are essential for the functionality of classes and are unlikely to be removed unless the entire class is being refactored or removed. Therefore, it is expected to survive."
survived,"    def sync_no_stream():
        litellm.completion(
            model=""gpt-3.5-turbo"",
            messages=[{""content"": ""Hello from sync no stream"", ""role"": ""user""}],
            session=session
        )
",tests/core_manual_tests/providers/litellm_canary.py,,1,4.6911638017642294e-08,"The method `sync_no_stream` is a simple function that calls the `litellm.completion` method with a specific model and message. It doesn't have any complex logic or dependencies that would make it obsolete or unnecessary. The function is likely to be used as a utility to send a predefined message to the GPT-3.5-turbo model, which is a common use case in applications that interact with language models. Therefore, it is likely to survive as it serves a clear purpose and is straightforward in its implementation."
deleted,"                def __iter__(self):
                    self.stream = original_method(self_client, *args, **kwargs_copy)
                    return self
",agentops/llms/providers/cohere.py,CohereProvider.StreamWrapper,1,1.1253518384332553e-07,"The method is implementing the __iter__ method, which is a special method in Python used to make an object iterable. This is a fundamental part of Python's iterator protocol. The method is returning 'self', which is typical for an iterator's __iter__ method, indicating that the object itself is the iterator. This is a standard and necessary implementation for any class that needs to be iterable, and there is no indication of redundancy or obsolescence. Therefore, it is likely to be retained."
survived,"    def sync_stream():
        stream_response = groq_client.chat.completions.create(
            model=""llama3-70b-8192"",
            messages=[
                {""role"": ""user"", ""content"": ""Hello from sync streaming""},
            ],
            stream=True,
            session=session
        )
        for _ in stream_response:
            pass
",tests/core_manual_tests/providers/groq_canary.py,,1,4.363462233903899e-09,"The method 'sync_stream' is likely to be Survived (1) because it is a functional piece of code that demonstrates how to use a client library to create a streaming chat completion. It uses a specific model and handles the response in a loop, which is a common pattern for handling streaming data. There is no indication of deprecated functionality or errors in the code that would necessitate its deletion."
survived,"    def is_primitive(value: Any) -> bool:
        return isinstance(
            value,
            (
                str,
                int,
                float,
                bool,
                type(None),
                datetime.datetime,
                datetime.date,
            ),
        )
",tests/_plugins/ui/_impl/tables/test_narwhals.py,,1,6.69158608681505e-10,"The method 'is_primitive' is a utility function that checks if a given value is of a primitive type or a few additional types like datetime and date. Such utility functions are often useful in various programming scenarios, such as data validation, serialization, or type checking. The method is simple, clear, and serves a common purpose, which makes it likely to be retained in the codebase."
survived,"    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = ""https://quote-api.jup.ag/v6""
        self._timeout = aiohttp.ClientTimeout(total=10)  # 10 second timeout
        self._session_kwargs = {""timeout"": self._timeout}
",python/src/plugins/jupiter/goat_plugins/jupiter/service.py,JupiterService,1,3.466327708641819e-07,"The method is a constructor for a class, which is essential for initializing instances of the class with specific attributes. It sets up important properties like the API key, base URL, and session timeout, which are likely crucial for the functionality of the class. Constructors are fundamental components of class design in object-oriented programming, and removing it would likely break the class's functionality. Therefore, it is unlikely to be deleted."
survived,"    def __init__(self, options: SplTokenPluginOptions):
        super().__init__(""spl_token"", [
            SplTokenService(
                api_key=options.api_key,
                network=options.network,
                tokens=options.tokens
            )
        ])
",python/src/plugins/spl_token/goat_plugins/spl_token/__init__.py,SplTokenPlugin,1,1.1253518384332553e-07,"The method is a constructor for a class that initializes an instance with specific options. It is a fundamental part of the class's functionality, setting up necessary services with the provided configuration. Such methods are typically essential for the operation of the class and are unlikely to be removed unless the entire class is refactored or deprecated."
survived,"    async def get_token_info_by_symbol(self, parameters: dict):
        """"""Get token info including mint address, decimals, and name by symbol.""""""
        try:
            token = next(
                (token for token in self.tokens 
                 if token[""symbol""] == parameters[""symbol""] or 
                 token[""symbol""].lower() == parameters[""symbol""].lower()),
                None
            )
            return {
                ""symbol"": token[""symbol""] if token else None,
                ""mintAddress"": token[""mintAddresses""][self.network] if token else None,
                ""decimals"": token[""decimals""] if token else None,
                ""name"": token[""name""] if token else None,
            }
        except Exception as error:
            raise Exception(f""Failed to get token info: {error}"")
",python/src/plugins/spl_token/goat_plugins/spl_token/service.py,SplTokenService,1,2.7894680920908113e-10,"The method 'get_token_info_by_symbol' is likely to survive because it provides a useful functionality of retrieving token information based on a symbol, which is a common requirement in applications dealing with cryptocurrencies or tokens. The method is well-structured, uses asynchronous programming which is suitable for I/O operations, and includes error handling to manage exceptions. These factors contribute to its utility and robustness, making it a valuable part of the codebase."
survived,"def _remove_reference(parent: Any, key: str | int | None, loader: JsonLoaderNode, path: List[str]) -> bool:  # noqa: ANN401
    logger = main_logger
    if key is None:
        data = parent
    else:
        data = parent[key]

    if isinstance(data, dict):
        ref = f""#/{'/'.join(path)}""
        if ref == loader.ref:
            logger.info(f""        Removing reference: {ref}"")
            return True
        elif ""$ref"" in data and data[""$ref""] == loader.ref:
            logger.info(f""        Found reference: {ref}"")
            return True
        else:
            todelete = []
            for key, value in data.items():
                if _remove_reference(data, key, loader, path + [str(key)]):
                    todelete.append(key)
            for key in todelete:
                del data[key]
    elif isinstance(data, list):
        for i, value in enumerate(data):
            ref = f""Array[{str(i)}]""
            _remove_reference(data, i, loader, path + [ref])

    return False
",airbyte-ci/connectors/pipelines/pipelines/airbyte_ci/connectors/migrate_to_inline_schemas/pipeline.py,,1,8.152020648014727e-09,"The method '_remove_reference' is a utility function that recursively traverses a data structure (either a dictionary or a list) to find and remove references that match a specific reference path. This kind of functionality is often crucial in applications dealing with JSON or similar data formats where references need to be resolved or removed. The method is well-structured, uses logging for traceability, and handles both dictionaries and lists, making it versatile. Such utility functions are generally retained as they provide essential functionality for data manipulation and integrity checks."
survived,"async def run_connector_migrate_to_inline_schemas_pipeline(context: ConnectorContext, semaphore: ""Semaphore"") -> Report:
    restore_original_state = RestoreInlineState(context)

    context.targeted_platforms = [LOCAL_BUILD_PLATFORM]

    steps_to_run: STEP_TREE = []

    steps_to_run.append(
        [
            StepToRun(
                id=CONNECTOR_TEST_STEP_ID.INLINE_CANDIDATE,
                step=CheckIsInlineCandidate(context),
            )
        ]
    )

    steps_to_run.append(
        [
            StepToRun(
                id=CONNECTOR_TEST_STEP_ID.INLINE_MIGRATION,
                step=InlineSchemas(context),
                depends_on=[CONNECTOR_TEST_STEP_ID.INLINE_CANDIDATE],
            )
        ]
    )

    steps_to_run.append(
        [
            StepToRun(
                id=CONNECTOR_TEST_STEP_ID.INLINE_CLEANUP,
                step=RemoveUnusedJsonSchamas(context),
                depends_on=[CONNECTOR_TEST_STEP_ID.INLINE_MIGRATION],
            )
        ]
    )

    return await run_connector_steps(context, semaphore, steps_to_run, restore_original_state=restore_original_state)",airbyte-ci/connectors/pipelines/pipelines/airbyte_ci/connectors/migrate_to_inline_schemas/pipeline.py,,1,1.8189616842444243e-09,"The method `run_connector_migrate_to_inline_schemas_pipeline` is well-structured and appears to be part of a larger system for managing connector migrations. It defines a clear sequence of steps to be executed asynchronously, with dependencies between them, which is a common pattern in modern software development. The method is likely to be useful for managing complex migration processes in a modular and maintainable way. Additionally, there is no indication of deprecated functionality or lack of use, suggesting it is still relevant and necessary for the system's operation."
survived,"    def test_resume_live_updates_when_not_paused(self):
        """"""Test resuming when not paused does nothing.""""""
        formatter = ConsoleFormatter()
        
        formatter._live_paused = False
        
        formatter.resume_live_updates()
        
        assert not formatter._live_paused
",tests/utilities/test_console_formatter_pause_resume.py,TestConsoleFormatterPauseResume,1,6.825604231969389e-08,"The method 'test_resume_live_updates_when_not_paused' is a unit test that checks the behavior of the 'resume_live_updates' method when the '_live_paused' attribute is set to False. This test is useful to ensure that calling 'resume_live_updates' does not alter the state when it is already not paused. Such tests are important for verifying the correctness of the code and preventing regressions. Therefore, it is likely to be retained in the codebase."
survived,"def test_export_overwrite_confirm(temp_marimo_file: str, existing_file: str) -> None:
    """"""Test export command with file overwrite confirmation (user confirms).""""""
    p = subprocess.Popen(
        [
            ""marimo"",
            ""export"",
            ""html"",
            temp_marimo_file,
            ""--output"",
            existing_file,
        ],
        stdin=subprocess.PIPE,
    )
    
    assert p.poll() is None
    assert p.stdin is not None
    
    # Simulate user confirming overwrite
    p.stdin.write(b""y\n"")
    p.stdin.flush()
    
    # Wait for process to complete
    p.wait(timeout=5)
    
    # Check that the file was overwritten
    assert os.path.exists(existing_file)
    assert p.returncode == 0
",tests/_cli/test_file_overwrite.py,,1,9.237449576640118e-09,"The method is a test function that simulates a user confirming an overwrite during an export operation. It is a useful test case for ensuring that the export functionality works correctly when a file overwrite is confirmed by the user. Such test cases are important for maintaining software quality and ensuring that user interactions are handled correctly. Therefore, it is likely to be retained as part of the test suite."
survived,"    def generate(cls, seed: Optional[str] = None, metadata: Optional[Dict[str, Any]] = None) -> 'Fingerprint':
        """"""
        Static factory method to create a new Fingerprint.

        Args:
            seed (Optional[str]): A string to use as seed for the UUID generation.
                If None, a random UUID is generated.
            metadata (Optional[Dict[str, Any]]): Additional metadata to store with the fingerprint.

        Returns:
            Fingerprint: A new Fingerprint instance
        """"""
        fingerprint = cls(metadata=metadata or {})
        if seed:
            # For seed-based generation, we need to manually set the uuid_str after creation
            object.__setattr__(fingerprint, 'uuid_str', cls._generate_uuid(seed))
        return fingerprint
",src/crewai/security/fingerprint.py,Fingerprint,1,4.944450477491054e-09,"The method 'generate' is a static factory method designed to create instances of the 'Fingerprint' class. It provides flexibility by allowing optional seed-based UUID generation and metadata storage. Such methods are common in object-oriented programming for controlled instance creation and are unlikely to be deleted unless the class design changes significantly. Additionally, the method is well-documented, indicating its importance and intended use."
survived,"    def __init__(self, **data):
        """"""Initialize a Fingerprint with auto-generated uuid_str and created_at.""""""
        # Remove uuid_str and created_at from data to ensure they're auto-generated
        if 'uuid_str' in data:
            data.pop('uuid_str')
        if 'created_at' in data:
            data.pop('created_at')

        # Call the parent constructor with the modified data
        super().__init__(**data)
",src/crewai/security/fingerprint.py,Fingerprint,1,9.931195248674785e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. It ensures that certain attributes ('uuid_str' and 'created_at') are auto-generated, which is likely a critical part of the class's functionality. Removing these attributes from the input data ensures that they are not manually set, maintaining data integrity and consistency. This kind of functionality is essential for many applications, especially those dealing with unique identifiers and timestamps. Therefore, it is unlikely that this method will be deleted."
survived,"    def uuid(self) -> uuid.UUID:
        """"""Get the UUID object for this fingerprint.""""""
        return uuid.UUID(self.uuid_str)
",src/crewai/security/fingerprint.py,Fingerprint,1,2.998960815863541e-09,"The method 'uuid' is a simple getter that converts a string representation of a UUID into a UUID object. This is a common and useful utility in many applications where UUIDs are used for unique identification. The method is straightforward, has a clear purpose, and is likely to be used frequently in contexts where UUIDs are handled. Therefore, it is unlikely to be deleted."
survived,"    def to_dict(self) -> Dict[str, Any]:
        """"""
        Convert the fingerprint to a dictionary representation.

        Returns:
            Dict[str, Any]: Dictionary representation of the fingerprint
        """"""
        return {
            ""uuid_str"": self.uuid_str,
            ""created_at"": self.created_at.isoformat(),
            ""metadata"": self.metadata
        }
",src/crewai/security/fingerprint.py,Fingerprint,1,4.599055376537186e-10,"The method 'to_dict' is a utility function that converts an object into a dictionary representation. This is a common and useful pattern in Python, especially for serialization purposes, such as converting objects to JSON format for API responses or data storage. The method is straightforward, well-documented, and serves a clear purpose, making it unlikely to be removed unless the entire class or its structure is deprecated. Therefore, it is predicted to survive."
deleted,"    async def get_embeddings_models(self) -> list[dict]:
        result = await self.ap.persistence_mgr.execute_async(sqlalchemy.select(persistence_model.EmbeddingsModel))

        models = result.all()
        return [self.ap.persistence_mgr.serialize_model(persistence_model.EmbeddingsModel, model) for model in models]
",pkg/api/http/service/model.py,EmbeddingsModelsService,1,1.9171715133907573e-10,"The method 'get_embeddings_models' is likely to survive because it is a well-structured asynchronous function that retrieves and serializes data from a database. It uses modern Python features such as type hinting and asynchronous programming, which are considered best practices. Additionally, the method is specific in its purpose and does not contain any obvious flaws or deprecated practices that would necessitate its removal."
survived,"    def __init__(self, ap: app.Application) -> None:
        self.ap = ap
",pkg/api/http/service/model.py,EmbeddingsModelsService,1,5.3157849718487075e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting up initial state. Therefore, it is unlikely to be deleted as it serves a critical purpose in the class design."
deleted,"    async def get_embeddings_model(self, model_uuid: str) -> dict | None:
        result = await self.ap.persistence_mgr.execute_async(
            sqlalchemy.select(persistence_model.EmbeddingsModel).where(persistence_model.EmbeddingsModel.uuid == model_uuid)
        )

        model = result.first()

        if model is None:
            return None

        return self.ap.persistence_mgr.serialize_model(persistence_model.EmbeddingsModel, model)
",pkg/api/http/service/model.py,EmbeddingsModelsService,1,5.4927883506529765e-11,"The method 'get_embeddings_model' is likely to survive because it is a well-structured asynchronous function that performs a specific task: retrieving and serializing an embeddings model from a database using a UUID. It uses modern Python features such as type hinting and asynchronous programming, which are considered best practices. Additionally, it handles the case where the model is not found by returning None, which is a common pattern for such retrieval functions. There is no indication of deprecated practices or inefficiencies that would necessitate its deletion."
survived,"def test_task_output_import():
    """"""Test that TaskOutput can be imported from crewai.""""""
    from crewai import TaskOutput
    
    assert TaskOutput is not None
",tests/imports_test.py,,1,6.348800075736417e-09,"The method is a simple test function that checks if the 'TaskOutput' can be imported from the 'crewai' module. This is a basic test to ensure that the import statement works correctly and that the 'TaskOutput' class or function is available in the 'crewai' module. Such tests are common in software development to verify module imports and dependencies. There is no indication that this method is redundant or unnecessary, so it is likely to be retained."
survived,"    def set_cursor_keys(
        self,
        *,
        kwargs: dict[str, str],
    ) -> None:
        """"""Override the cursor key for one or more streams.

        This does not unset previously set cursors.
        """"""
        self._cursor_key_overrides.update(kwargs)
",airbyte/sources/base.py,Source,1,6.69158608681505e-10,"The method `set_cursor_keys` is a utility function that updates a dictionary with new key-value pairs. It is a straightforward and useful method for managing cursor keys in a system that likely deals with streams or data processing. The method is simple, has a clear purpose, and is likely to be used in various parts of the codebase where cursor management is needed. There is no indication that this method is redundant or unnecessary, and it provides a clear functionality that is likely to be needed in the context it is used. Therefore, it is likely to survive."
survived,"def test_tool_usage_limit():
    """"""Test that tools respect usage limits.""""""
    class LimitedTool(BaseTool):
        name: str = ""Limited Tool""
        description: str = ""A tool with usage limits for testing""
        max_usage_count: int = 2

        def _run(self, input_text: str) -> str:
            return f""Processed {input_text}""

    tool = LimitedTool()
    
    result1 = tool.run(input_text=""test1"")
    assert result1 == ""Processed test1""
    assert tool.current_usage_count == 1
    
    result2 = tool.run(input_text=""test2"")
    assert result2 == ""Processed test2""
    assert tool.current_usage_count == 2
",tests/tools/test_tool_usage_limit.py,,1,9.931195248674785e-08,"The method `test_tool_usage_limit` is a unit test designed to verify that a tool respects its usage limits. Unit tests are crucial for ensuring code reliability and functionality, especially when dealing with constraints like usage limits. This test is well-structured and serves a clear purpose in validating the behavior of the `LimitedTool` class. Therefore, it is likely to be retained as part of the codebase to ensure ongoing correctness and to prevent regressions."
survived,"        def _run(self, input_text: str) -> str:
            return f""Processed {input_text}""
",tests/tools/test_tool_usage_limit.py,UnlimitedTool,1,1.2501528648238603e-09,"The method '_run' is a simple utility function that takes an input string and returns a formatted string. It is likely to be a part of a larger class or module where such processing is required. The method is straightforward, has a clear purpose, and does not contain any obvious issues or redundancies. Therefore, it is likely to be retained in the codebase."
survived,"    def setup_method(self) -> None:
        """"""Set up a temporary directory for each test.""""""
        self.temp_dir = tempfile.TemporaryDirectory()
        self.save_path = self.temp_dir.name
",tests/_save/loaders/test_json_loader.py,TestJsonLoader,1,1.522997951276035e-08,"The method 'setup_method' is a common pattern in testing frameworks to set up a test environment before each test case is run. It is used to ensure that each test has a clean and isolated environment, which is crucial for reliable and repeatable tests. The use of a temporary directory is a standard practice to avoid side effects between tests. Therefore, this method is likely to be retained as it serves an important purpose in the testing process."
survived,"    def test_init_with_max_size_zero(self) -> None:
        """"""Test initialization with max_size=0.""""""
        loader = MemoryLoader(""test"", max_size=0)
        assert loader.max_size == 0
        assert loader.is_lru is False
        assert not isinstance(loader._cache, OrderedDict)
        assert loader._cache_lock is None
",tests/_save/loaders/test_memory_loader.py,TestMemoryLoader,1,1.8553915987649156e-07,"The method 'test_init_with_max_size_zero' is a unit test designed to verify the behavior of the 'MemoryLoader' class when initialized with a 'max_size' of 0. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with edge cases like a zero size. This test checks multiple aspects of the 'MemoryLoader' initialization, such as the 'max_size' attribute, the 'is_lru' flag, the type of '_cache', and the '_cache_lock'. These checks are important for validating that the class behaves as expected under these conditions. Therefore, this method is likely to be retained as part of the test suite to ensure ongoing code quality and to prevent regressions."
survived,"    def load_cache(self, hashed_context: str, cache_type: str) -> Cache:
        key = f""{cache_type}_{hashed_context}""
        if key not in self.saved_caches:
            raise LoaderError(""Unexpected cache miss."")
        return self.saved_caches[key]
",tests/_save/loaders/test_loader.py,MockLoader,1,1.1032560311263802e-09,"The method 'load_cache' is a utility function that retrieves a cached item based on a hashed context and cache type. It is likely to be a core part of a caching mechanism, which is essential for performance optimization in many applications. The method is straightforward, performs a necessary check for cache existence, and raises an appropriate error if the cache is not found. These characteristics suggest that the method is well-designed for its purpose and is unlikely to be removed unless there is a significant change in the caching strategy or architecture."
survived,"    def test_init(self) -> None:
        """"""Test initialization.""""""
        loader = JsonLoader(""test"", self.save_path)
        assert loader.name == ""test""
        assert loader.suffix == ""json""
        assert str(loader.save_path).endswith(""/test"")
        
        # Check that the directory was created
        assert os.path.exists(os.path.join(self.save_path, ""test""))
",tests/_save/loaders/test_json_loader.py,TestJsonLoader,1,1.0467401685178159e-08,"The method `test_init` is a unit test designed to verify the initialization of a `JsonLoader` object. It checks that the object is correctly initialized with the expected name, suffix, and save path, and also verifies that the directory is created. This is a typical and necessary test to ensure that the `JsonLoader` class behaves as expected during initialization. Since testing is a crucial part of software development to maintain code quality and reliability, this method is likely to be retained."
survived,"def setup_test_environment():
    """"""Set up test environment with a temporary directory for SQLite storage.""""""
    with tempfile.TemporaryDirectory() as temp_dir:
        # Create the directory with proper permissions
        storage_dir = Path(temp_dir) / ""crewai_test_storage""
        storage_dir.mkdir(parents=True, exist_ok=True)
        
        # Set environment variable to point to the test storage directory
        os.environ[""CREWAI_STORAGE_DIR""] = str(storage_dir)
        
        yield
",tests/conftest.py,,1,2.3355930333443423e-09,"The method 'setup_test_environment' is likely to survive because it is a utility function that sets up a temporary test environment, which is a common requirement in software testing. It uses a context manager to ensure that resources are properly cleaned up after use, which is a good practice. Additionally, it sets an environment variable, which is often necessary for configuring test environments. These characteristics make it a useful and reusable piece of code in a testing suite."
survived,"def create_service_file(goat_plugins_dir: Path, plugin_name: str, is_evm: bool) -> None:
    """"""Create the service.py file with an empty tool.""""""
    # Start with common imports
    service_content = '''from goat.decorators.tool import Tool
from .parameters import ExampleQueryParameters, ExampleActionParameters
'''

    # Add EVM-specific imports if needed
    if is_evm:
        service_content += '''from goat_wallets.evm import EVMWalletClient

'''

    # Create the service class
    class_name = f""{plugin_name.title()}Service""
    service_content += f'''
class {class_name}:
    def __init__(self, api_key: str):
        self.api_key = api_key

    @Tool({{
        ""description"": ""Example query tool that demonstrates parameter usage"",
        ""parameters_schema"": ExampleQueryParameters
    }})
    async def example_query(self{"", wallet_client: EVMWalletClient"" if is_evm else """"}, parameters: dict):
        """"""An example query method that shows how to use parameters.""""""
        try:
            # Example implementation
            query = parameters[""query""]
            limit = parameters.get(""limit"")
            include_metadata = parameters.get(""include_metadata"", False)
            
            # Placeholder for actual implementation
            return {{""status"": ""success"", ""query"": query, ""limit"": limit, ""metadata_included"": include_metadata}}
        except Exception as error:
            raise Exception(f""Failed to execute query: {{error}}"")

    @Tool({{
        ""description"": ""Example action tool that demonstrates parameter usage"",
        ""parameters_schema"": ExampleActionParameters
    }})
    async def example_action(self{"", wallet_client: EVMWalletClient"" if is_evm else """"}, parameters: dict):
        """"""An example action method that shows how to use parameters.""""""
        try:
            # Example implementation
            target_id = parameters[""target_id""]
            action_type = parameters[""action_type""]
            action_params = parameters.get(""parameters"", {{}})
            
            # Placeholder for actual implementation
            return {{""status"": ""success"", ""action"": action_type, ""target"": target_id, ""params"": action_params}}
        except Exception as error:
            raise Exception(f""Failed to execute action: {{error}}"")
'''

    with open(goat_plugins_dir / ""service.py"", ""w"") as f:
        f.write(service_content)
",python/create_plugin.py,,1,1.8189616842444243e-09,"The method `create_service_file` is likely to survive because it provides a clear and useful functionality: generating a service file with a structured template for plugins. This method is flexible, allowing for EVM-specific imports and functionality, which makes it adaptable to different use cases. Additionally, it handles exceptions and provides a basic structure for query and action methods, which can be easily extended. Such utility functions are often retained as they simplify repetitive tasks and ensure consistency across generated files."
survived,"    def send_transaction(self, transaction: SolanaTransaction) -> Dict[str, str]:
        """"""Send a transaction on the Solana chain.

        Args:
            transaction: Transaction parameters including instructions and optional lookup tables

        Returns:
            Dict containing the transaction hash
        """"""
        pass
",python/src/wallets/solana/goat_wallets/solana/wallet.py,SolanaWalletClient,1,9.42244663976186e-07,"The method `send_transaction` is a placeholder function that is not yet implemented. However, it is a crucial part of interacting with the Solana blockchain, as sending transactions is a fundamental operation. The method signature and docstring suggest that it is intended to send a transaction and return a transaction hash, which is a common requirement in blockchain applications. Therefore, it is likely that this method will be implemented in the future rather than deleted, as it serves an essential purpose in the context of blockchain operations."
survived,"def serialize_decimal(value: decimal.Decimal) -> float:
    """"""Serialize a Decimal to a float.

    Args:
        value: The Decimal to serialize.

    Returns:
        The serialized Decimal as a float.
    """"""
    return float(value)
",reflex/utils/serializers.py,,1,8.152020648014727e-09,"The method 'serialize_decimal' is a simple utility function that converts a Decimal object to a float. This is a common requirement in many applications where Decimal objects need to be converted to floats for compatibility with other systems or libraries that do not support Decimals. The method is straightforward, has a clear purpose, and is likely to be useful in various contexts where precision handling is necessary. Therefore, it is likely to be retained in the codebase."
deleted,"    def test_sanitize_collection_name_special_chars(self):
        """"""Test sanitizing a name with special characters.""""""
        special_chars = ""Agent@123!#$%^&*()""
        sanitized = sanitize_collection_name(special_chars)
        self.assertTrue(sanitized[0].isalnum())
        self.assertTrue(sanitized[-1].isalnum())
        self.assertTrue(all(c.isalnum() or c in [""_"", ""-""] for c in sanitized))
",tests/utilities/test_string_utils.py,TestStringUtils,1,2.5109990926928157e-08,"The method 'test_sanitize_collection_name_special_chars' is a unit test designed to verify the functionality of the 'sanitize_collection_name' function. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with input sanitization, which is important for security and data integrity. The test checks that the sanitized name starts and ends with alphanumeric characters and only contains alphanumeric characters, underscores, or hyphens. This is a common requirement for collection names in databases or similar systems. Given its importance in maintaining code quality and preventing potential bugs, this method is likely to be retained."
survived,"def find_relevant_page_via_map(objective, url, app, client):
    try:
        print(f""{Colors.CYAN}Understood. The objective is: {objective}{Colors.RESET}"")
        print(f""{Colors.CYAN}Initiating search on the website: {url}{Colors.RESET}"")
        
        map_prompt = f""""""
        The map function generates a list of URLs from a website and it accepts a search parameter. Based on the objective of: {objective}, come up with a 1-2 word search parameter that will help us find the information we need. Only respond with 1-2 words nothing else.
        """"""

        print(f""{Colors.YELLOW}Analyzing objective to determine optimal search parameter...{Colors.RESET}"")
        completion = client.chat.completions.create(
            model=""qwen/qwen3-30b-a3b:free"",
            messages=[
                {
                    ""role"": ""user"",
                    ""content"": [
                        {
                            ""type"": ""text"",
                            ""text"": map_prompt
                        }
                    ]
                }
            ]
        )

        map_search_parameter = completion.choices[0].message.content
        print(f""{Colors.GREEN}Optimal search parameter identified: {map_search_parameter}{Colors.RESET}"")

        print(f""{Colors.YELLOW}Mapping website using the identified search parameter...{Colors.RESET}"")
        map_website = app.map_url(url, params={""search"": map_search_parameter})
        print(f""{Colors.GREEN}Website mapping completed successfully.{Colors.RESET}"")
        print(f""{Colors.GREEN}Located {len(map_website)} relevant links.{Colors.RESET}"")
        return map_website
    except Exception as e:
        print(f""{Colors.RED}Error encountered during relevant page identification: {str(e)}{Colors.RESET}"")
        return None
",examples/qwen3-web-crawler/qwen3_web_crawler.py,,1,2.646573631904765e-09,"The method 'find_relevant_page_via_map' is a well-structured function that performs a specific task of finding relevant pages on a website using a search parameter derived from an objective. It includes error handling, logging, and uses an AI model to determine the search parameter, which adds value to its functionality. The method is likely to be useful in applications that require dynamic content retrieval from websites based on user objectives. Therefore, it is likely to be retained in the codebase."
survived,"def test_telemetry_disable_after_singleton_creation():
    """"""Test that telemetry operations are disabled when env var is set after singleton creation.""""""
    Telemetry._instance = None
    
    with patch.dict(os.environ, {}, clear=True):
        with patch(""crewai.telemetry.telemetry.TracerProvider""):
            telemetry = Telemetry()
            assert telemetry.ready is True
            
            mock_operation = MagicMock()
            telemetry._safe_telemetry_operation(mock_operation)
            mock_operation.assert_called_once()
            
            mock_operation.reset_mock()
            
            os.environ['CREWAI_DISABLE_TELEMETRY'] = 'true'
            
            telemetry._safe_telemetry_operation(mock_operation)
            mock_operation.assert_not_called()
",tests/telemetry/test_telemetry_disable.py,,1,1.8553915987649156e-07,"The method is a test function that verifies the behavior of a telemetry system when an environment variable is set to disable telemetry after a singleton instance is created. Test functions are generally crucial for ensuring code reliability and are not typically deleted unless they are redundant or replaced by a more comprehensive test. This test checks a specific scenario that is likely important for the functionality of the telemetry system, making it unlikely to be removed without a replacement."
survived,"    def check_link(self, url, source_page):
        """"""Check if a single link is working.""""""
        if url in self.checked_links:
            return True
            
        self.checked_links.add(url)
        
        parsed = urlparse(url)
        if parsed.netloc in ['fonts.googleapis.com', 'fonts.gstatic.com']:
            return True
        
        try:
            response = self.session.head(url, timeout=self.timeout, allow_redirects=True)
            
            if response.status_code == 405:
                response = self.session.get(url, timeout=self.timeout, allow_redirects=True)
            
            if response.status_code == 403 and 'twitter.com' in url:
                print(f""Warning: Twitter link may be blocked by bot detection: {url}"")
                return True
            
            if response.status_code >= 400:
                self.dead_links.append({
                    'url': url,
                    'status_code': response.status_code,
                    'source_page': source_page,
                    'error': f""HTTP {response.status_code}""
                })
                return False
                
        except requests.exceptions.RequestException as e:
            self.dead_links.append({
                'url': url,
                'status_code': None,
                'source_page': source_page,
                'error': str(e)
            })
            return False
            
        return True
",scripts/check_dead_links.py,DeadLinkChecker,1,1.2501528648238603e-09,"The method 'check_link' is a utility function that checks the validity of a URL by making HTTP requests. It handles various scenarios such as checking if a link has already been checked, dealing with specific domains, and managing HTTP errors. This functionality is essential for applications that need to verify the availability of links, such as web crawlers or link checkers. The method is well-structured, handles exceptions, and provides useful feedback on link status, making it a valuable part of any codebase that requires link validation. Therefore, it is likely to be retained."
survived,"def main():
    parser = argparse.ArgumentParser(description='Check for dead links on a website')
    parser.add_argument('url', help='Base URL to start crawling from')
    parser.add_argument('--max-pages', type=int, default=500, help='Maximum pages to crawl')
    parser.add_argument('--timeout', type=int, default=10, help='Request timeout in seconds')
    parser.add_argument('--delay', type=float, default=0.5, help='Delay between requests')
    
    args = parser.parse_args()
    
    checker = DeadLinkChecker(
        base_url=args.url,
        max_pages=args.max_pages,
        timeout=args.timeout,
        delay=args.delay
    )
    
    success = checker.run()
    sys.exit(0 if success else 1)
",scripts/check_dead_links.py,,1,4.944450477491054e-09,"The method 'main()' is a typical entry point for a command-line script that uses argparse to handle command-line arguments. It is well-structured, with clear argument definitions and default values, and it integrates with a 'DeadLinkChecker' class to perform its main functionality. This kind of method is essential for scripts that are intended to be run from the command line, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained in the codebase."
survived,"    def test_call_empty_content(
        self, mock_anthropic_class: MagicMock, mock_require_api_key: MagicMock
    ) -> None:
        """"""Test calling the anthropic class with empty content.""""""
        mock_require_api_key.return_value = ""test-key""
        mock_client = MagicMock()
        mock_anthropic_class.return_value = mock_client
        mock_response = MagicMock()
        mock_response.content = []
        mock_client.messages.create.return_value = mock_response

        model = anthropic(""claude-3-opus-20240229"")
        messages = [ChatMessage(role=""user"", content=""Test prompt"")]
        config = ChatModelConfig()

        result = model(messages, config)
        assert result == """"
",tests/_ai/llm/_impl.py,TestAnthropic,1,1.1861120010657661e-08,"The method 'test_call_empty_content' is a unit test designed to verify the behavior of a function when it receives empty content. Unit tests are crucial for ensuring code reliability and are typically retained to maintain test coverage. The test uses mock objects to simulate dependencies, which is a common practice in testing. Since the method is a test case, it is unlikely to be deleted unless the functionality it tests is removed or significantly altered. Therefore, the method is expected to survive."
survived,"    def test_require_api_key_config(self, mock_get_context: MagicMock) -> None:
        """"""Test _require_api_key with config.""""""
        mock_context = MagicMock()
        mock_context.marimo_config = {""ai"": {""anthropic"": {""api_key"": ""config-key""}}}
        mock_get_context.return_value = mock_context

        model = anthropic(""claude-3-opus-20240229"")
        assert model._require_api_key == ""config-key""
",tests/_ai/llm/_impl.py,TestAnthropic,1,4.599055376537186e-10,"The method `test_require_api_key_config` is a unit test designed to verify that the `_require_api_key` method correctly retrieves an API key from a configuration. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with configurations and external dependencies. This test uses mocking to simulate the context and checks the behavior of the code under test conditions. Such tests are typically retained in the codebase to maintain software quality and facilitate future development and debugging. Therefore, it is likely to be Survived."
survived,"    def test_buffered_writer_basic(self) -> None:
        # Test basic functionality of buffered writer
        stream = MockStream()
        msg_queue: deque[Optional[ConsoleMsg]] = deque()
        cv = threading.Condition()

        # Start the buffered writer in a separate thread
        thread = threading.Thread(
            target=buffered_writer, args=(msg_queue, stream, cv)
        )
        thread.daemon = True
        thread.start()

        try:
            # Add a message to the queue
            with cv:
                msg_queue.append(
                    ConsoleMsg(
                        stream=CellChannel.STDOUT,
                        cell_id=""cell1"",
                        data=""Hello"",
                        mimetype=""text/plain"",
                    )
                )
                cv.notify()

            # Wait for the timeout to expire and the message to be written
            time.sleep(TIMEOUT_S * 2)

            # Check that the message was written to the stream
            assert len(stream.messages) == 1
            assert stream.messages[0][1][""console""][""data""] == ""Hello""

        finally:
            # Signal the writer to terminate
            with cv:
                msg_queue.append(None)
                cv.notify()
            thread.join(timeout=1.0)
",tests/_messaging/test_console_output_worker.py,TestConsoleOutputWorker,1,2.8453347280241004e-08,"The method `test_buffered_writer_basic` is a unit test designed to verify the basic functionality of a buffered writer. Unit tests are crucial for ensuring code reliability and are typically retained in the codebase to facilitate ongoing testing and validation of functionality. This test method is well-structured, using a mock stream and threading to simulate real-world conditions, and it includes assertions to verify expected outcomes. Therefore, it is likely to be retained as part of the test suite."
survived,"        def accepts_mime_bundle_or_tuple(
            bundle_or_tuple: MimeBundleOrTuple
        ) -> MimeBundleOrTuple:
            return bundle_or_tuple
",tests/_messaging/test_mimetypes.py,TestMimeTypes,0,0.9999999468421502,"The method 'accepts_mime_bundle_or_tuple' is a simple function that takes an argument of type 'MimeBundleOrTuple' and returns it without any modification. This kind of function is often used as a placeholder or for type-checking purposes. Since it doesn't perform any operations or transformations, it might be considered redundant in a production codebase unless it serves a specific purpose such as enforcing type constraints or being part of a larger framework where such functions are necessary. Without additional context indicating its necessity, it is likely to be deleted as it doesn't add any functional value."
survived,"        def __init__(self) -> None:
            self.written_data: list[tuple[str, KnownMimeType]] = []
",tests/_messaging/test_types.py,TestStdoutStderr.MockStderr,1,1.725782769012759e-08,"The method is a constructor (__init__) for a class, which is essential for initializing object instances in Python. It sets up an instance variable 'written_data' as an empty list, which is likely used to store tuples of strings and KnownMimeType objects. Constructors are fundamental to class functionality, so they are rarely deleted unless the entire class is being removed or refactored significantly."
survived,"    def test_add_output_to_buffer_merge(self) -> None:
        # Test merging output for an existing cell with same stream and mimetype
        outputs_buffered_per_cell = {
            ""cell1"": [
                ConsoleMsg(
                    stream=CellChannel.STDOUT,
                    cell_id=""cell1"",
                    data=""Hello"",
                    mimetype=""text/plain"",
                )
            ]
        }
        msg = ConsoleMsg(
            stream=CellChannel.STDOUT,
            cell_id=""cell1"",
            data="" World"",
            mimetype=""text/plain"",
        )

        _add_output_to_buffer(msg, outputs_buffered_per_cell)

        assert len(outputs_buffered_per_cell[""cell1""]) == 1
        assert outputs_buffered_per_cell[""cell1""][0].data == ""Hello World""
",tests/_messaging/test_console_output_worker.py,TestConsoleOutputWorker,1,3.2241866333029355e-08,"The method `test_add_output_to_buffer_merge` is a unit test designed to verify the functionality of merging console messages in a buffer. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with data manipulation. This test checks that when a new message with the same stream and mimetype is added to an existing cell, it correctly merges the data. Such tests are typically retained to maintain code quality and prevent regressions."
survived,"    def test_print_override_with_thread_no_execution_context(self) -> None:
        # Test print_override when in a marimo thread with context but no execution context
        thread_id = threading.get_ident()
        THREADS.add(thread_id)

        try:
            # Create a mock context with no execution context
            context = MagicMock(spec=RuntimeContext)
            context.execution_context = None

            with patch(""marimo._messaging.print_override._original_print"") as mock_print:
                with patch(
                    ""marimo._messaging.print_override.get_context"",
                    return_value=context,
                ):
                    print_override(""Hello, world!"")

                    # Original print should be called
                    mock_print.assert_called_once_with(""Hello, world!"")
        finally:
            # Clean up
            if thread_id in THREADS:
                THREADS.remove(thread_id)
",tests/_messaging/test_print_override.py,TestPrintOverride,1,2.2159489282323004e-08,"The method is a unit test designed to verify the behavior of a specific function (`print_override`) under certain conditions. Unit tests are crucial for ensuring code reliability and are typically maintained as long as the functionality they test is relevant. Since this test checks the behavior of `print_override` in a specific threading context, it is likely to be useful for maintaining the integrity of the codebase."
survived,"    def test_add_output_to_buffer_new_cell(self) -> None:
        # Test adding output for a new cell
        outputs_buffered_per_cell = {}
        msg = ConsoleMsg(
            stream=CellChannel.STDOUT,
            cell_id=""cell1"",
            data=""Hello"",
            mimetype=""text/plain"",
        )

        _add_output_to_buffer(msg, outputs_buffered_per_cell)

        assert ""cell1"" in outputs_buffered_per_cell
        assert len(outputs_buffered_per_cell[""cell1""]) == 1
        assert outputs_buffered_per_cell[""cell1""][0].data == ""Hello""
",tests/_messaging/test_console_output_worker.py,TestConsoleOutputWorker,1,1.637377179507321e-07,"The method `test_add_output_to_buffer_new_cell` is a unit test designed to verify the functionality of adding output to a buffer for a new cell. Unit tests are crucial for ensuring code reliability and correctness, especially in larger codebases. This test checks that the output is correctly added to the buffer and that the buffer behaves as expected when a new cell is introduced. Since testing is an integral part of software development and maintenance, this method is likely to be retained to ensure the continued correctness of the `_add_output_to_buffer` function."
survived,"    def write(self, op: str, data: dict) -> None:
        self.messages.append((op, data))
",tests/_messaging/test_console_output_worker.py,MockStream,1,2.7894680920908113e-10,"The method 'write' is a simple utility function that appends a tuple of operation and data to a list called 'messages'. This kind of method is commonly used for logging or queuing operations and is generally useful in many applications. It is unlikely to be deleted unless the entire logging or message handling mechanism is refactored or removed, which is not indicated here. Therefore, the method is likely to survive."
survived,"def test_get_network_url() -> None:
    """"""Test the _get_network_url function.""""""
    # Test with a simple URL
    with patch(""socket.gethostname"") as mock_gethostname:
        mock_gethostname.return_value = ""test-host""
        with patch(""socket.gethostbyname"") as mock_gethostbyname:
            mock_gethostbyname.return_value = ""192.168.1.100""
            result = _get_network_url(""http://localhost:8000"")
            assert result == ""http://192.168.1.100:8000""
    
    # Test with a URL with a path
    with patch(""socket.gethostname"") as mock_gethostname:
        mock_gethostname.return_value = ""test-host""
        with patch(""socket.gethostbyname"") as mock_gethostbyname:
            mock_gethostbyname.return_value = ""192.168.1.100""
            result = _get_network_url(""http://localhost:8000/path"")
            assert result == ""http://192.168.1.100:8000/path""
    
    # Test with a URL with a query string
    with patch(""socket.gethostname"") as mock_gethostname:
        mock_gethostname.return_value = ""test-host""
        with patch(""socket.gethostbyname"") as mock_gethostbyname:
            mock_gethostbyname.return_value = ""192.168.1.100""
            result = _get_network_url(""http://localhost:8000/path?query=value"")
            assert result == ""http://192.168.1.100:8000/path?query=value""
    
    # Test with socket.gethostbyname raising an exception
    with patch(""socket.gethostname"") as mock_gethostname:
        mock_gethostname.return_value = ""test-host""
        with patch(""socket.gethostbyname"") as mock_gethostbyname:
            mock_gethostbyname.side_effect = Exception(""Test exception"")
            result = _get_network_url(""http://localhost:8000"")
            assert result == ""http://test-host:8000""
",tests/_server/test_print.py,,1,1.522997951276035e-08,"The method `test_get_network_url` is a well-structured unit test for the `_get_network_url` function. It covers various scenarios, including different URL formats and exception handling. This comprehensive testing approach is essential for ensuring the reliability of the `_get_network_url` function. Since the method is useful for maintaining code quality and does not have any apparent issues, it is likely to be retained in the codebase."
survived,"def test_print_startup() -> None:
    """"""Test the print_startup function.""""""
    # Test with file_name and not run
    with patch(""marimo._server.print.print_"") as mock_print:
        with patch(""marimo._server.print.print_tabbed"") as mock_print_tabbed:
            with patch(""marimo._server.print._utf8"") as mock_utf8:
                mock_utf8.side_effect = lambda x: x
                with patch(""marimo._server.print._colorized_url"") as mock_colorized_url:
                    mock_colorized_url.return_value = ""COLORIZED_URL""
                    with patch(""marimo._server.print.green"") as mock_green:
                        mock_green.return_value = ""GREEN_TEXT""
                        print_startup(
                            file_name=""test.py"",
                            url=""http://localhost:8000"",
                            run=False,
                            new=False,
                            network=False,
                        )
                        mock_print.assert_called()
                        mock_print_tabbed.assert_any_call(""➜  GREEN_TEXT: COLORIZED_URL"")
    
    # Test with file_name and run
    with patch(""marimo._server.print.print_"") as mock_print:
        with patch(""marimo._server.print.print_tabbed"") as mock_print_tabbed:
            with patch(""marimo._server.print._utf8"") as mock_utf8:
                mock_utf8.side_effect = lambda x: x
                with patch(""marimo._server.print._colorized_url"") as mock_colorized_url:
                    mock_colorized_url.return_value = ""COLORIZED_URL""
                    with patch(""marimo._server.print.green"") as mock_green:
                        mock_green.return_value = ""GREEN_TEXT""
                        print_startup(
                            file_name=""test.py"",
                            url=""http://localhost:8000"",
                            run=True,
                            new=False,
                            network=False,
                        )
                        mock_print.assert_called()
                        mock_print_tabbed.assert_any_call(""➜  GREEN_TEXT: COLORIZED_URL"")
    
    # Test with new=True
    with patch(""marimo._server.print.print_"") as mock_print:
        with patch(""marimo._server.print.print_tabbed"") as mock_print_tabbed:
            with patch(""marimo._server.print._utf8"") as mock_utf8:
                mock_utf8.side_effect = lambda x: x
                with patch(""marimo._server.print._colorized_url"") as mock_colorized_url:
                    mock_colorized_url.return_value = ""COLORIZED_URL""
                    with patch(""marimo._server.print.green"") as mock_green:
                        mock_green.return_value = ""GREEN_TEXT""
                        print_startup(
                            file_name=None,
                            url=""http://localhost:8000"",
                            run=False,
                            new=True,
                            network=False,
                        )
                        mock_print.assert_called()
                        mock_print_tabbed.assert_any_call(""➜  GREEN_TEXT: COLORIZED_URL"")
    
    # Test with network=True
    with patch(""marimo._server.print.print_"") as mock_print:
        with patch(""marimo._server.print.print_tabbed"") as mock_print_tabbed:
            with patch(""marimo._server.print._utf8"") as mock_utf8:
                mock_utf8.side_effect = lambda x: x
                with patch(""marimo._server.print._colorized_url"") as mock_colorized_url:
                    mock_colorized_url.return_value = ""COLORIZED_URL""
                    with patch(""marimo._server.print.green"") as mock_green:
                        mock_green.return_value = ""GREEN_TEXT""
                        with patch(""marimo._server.print._get_network_url"") as mock_get_network_url:
                            mock_get_network_url.return_value = ""http://192.168.1.100:8000""
                            print_startup(
                                file_name=None,
                                url=""http://localhost:8000"",
                                run=False,
                                new=False,
                                network=True,
                            )
                            mock_print.assert_called()
                            mock_print_tabbed.assert_any_call(""➜  GREEN_TEXT: COLORIZED_URL"")
                            mock_get_network_url.assert_called_once_with(""http://localhost:8000"")
    
    # Test with network=True and _get_network_url raising an exception
    with patch(""marimo._server.print.print_"") as mock_print:
        with patch(""marimo._server.print.print_tabbed"") as mock_print_tabbed:
            with patch(""marimo._server.print._utf8"") as mock_utf8:
                mock_utf8.side_effect = lambda x: x
                with patch(""marimo._server.print._colorized_url"") as mock_colorized_url:
                    mock_colorized_url.return_value = ""COLORIZED_URL""
                    with patch(""marimo._server.print.green"") as mock_green:
                        mock_green.return_value = ""GREEN_TEXT""
                        with patch(""marimo._server.print._get_network_url"") as mock_get_network_url:
                            mock_get_network_url.side_effect = Exception(""Test exception"")
                            print_startup(
                                file_name=None,
                                url=""http://localhost:8000"",
                                run=False,
                                new=False,
                                network=True,
                            )
                            mock_print.assert_called()
                            mock_print_tabbed.assert_any_call(""➜  GREEN_TEXT: COLORIZED_URL"")
                            mock_get_network_url.assert_called_once_with(""http://localhost:8000"")
",tests/_server/test_print.py,,1,2.5109990926928157e-08,"The method `test_print_startup` is a comprehensive test function that uses mocking to test various scenarios of the `print_startup` function. It covers different combinations of parameters and ensures that the expected functions are called with the correct arguments. This level of testing is crucial for maintaining code quality and ensuring that changes do not introduce regressions. The method is well-structured and serves a clear purpose in the test suite, making it unlikely to be deleted."
survived,"    def __init__(self, options: UniswapPluginOptions):
        super().__init__(""uniswap"", [UniswapService(options.api_key, options.base_url)])
",python/src/plugins/uniswap/goat_plugins/uniswap/__init__.py,UniswapPlugin,1,2.5109990926928157e-08,"The method is a constructor for a class that initializes an instance with specific options. It uses inheritance to call the parent class's constructor and sets up a service with the provided options. This is a standard and necessary part of object-oriented programming, especially when dealing with plugins or services that require configuration. There is no indication that this method is redundant or unnecessary, so it is likely to be retained."
survived,"    def condition1(task_output: TaskOutput) -> bool:
        return ""success"" in task_output.raw.lower()
",tests/crew_test.py,,1,9.237449576640118e-09,"The method 'condition1' is a simple utility function that checks if the string ""success"" is present in the 'raw' attribute of a 'TaskOutput' object, after converting it to lowercase. This kind of method is often useful in various contexts where task outputs need to be evaluated for success or failure. It is a straightforward and efficient way to perform this check, and such utility functions are commonly used in codebases to improve readability and maintainability. Therefore, it is likely to be retained in the codebase."
survived,"    def condition2(task_output: TaskOutput) -> bool:
        return ""proceed"" in task_output.raw.lower()
",tests/crew_test.py,,1,7.194132978569833e-09,"The method 'condition2' is a simple utility function that checks if the string 'proceed' is present in the 'raw' attribute of a 'TaskOutput' object, converted to lowercase. This type of method is often useful in filtering or decision-making processes, especially in systems that handle tasks or commands. It is likely to be used in various parts of a codebase where such a condition needs to be checked. Therefore, it is a generic and reusable function that is likely to survive."
survived,"def test_smart_wallet_with_admin_signer(smart_api, test_keypair):
    """"""Test smart wallet creation with admin signer.""""""
    wallet = smart_api.create_smart_wallet({
        ""adminSigner"": {
            ""type"": ""evm-keypair"",
            ""address"": test_keypair[""address""]
        }
    })
    assert wallet[""address""].startswith(""0x"")
    assert wallet[""type""] == ""evm-smart-wallet""
",python/src/wallets/crossmint/tests/test_smart_wallet.py,,1,5.3157849718487075e-08,"The method `test_smart_wallet_with_admin_signer` is a test function that verifies the creation of a smart wallet using an admin signer. It is a part of a test suite, likely used to ensure the functionality of the `create_smart_wallet` method in the `smart_api`. Test functions are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is unlikely to be deleted unless the functionality it tests is removed or significantly changed."
survived,"def custodial_api():
    """"""Fixture providing CrossmintWalletsAPI instance with custodial wallet API key.""""""
    return CrossmintWalletsAPI(
        api_key=os.environ[""CROSSMINT_STAGING_API_KEY_CUSTODIAL""],
        base_url=""https://staging.crossmint.com""
    )
",python/src/wallets/crossmint/tests/conftest.py,,1,9.931195248674785e-08,"The method 'custodial_api' is a utility function that provides an instance of 'CrossmintWalletsAPI' with a specific API key for a custodial wallet. This is a common pattern in software development where environment variables are used to manage sensitive information like API keys. The method is likely to be used in a testing or staging environment, as indicated by the use of a staging URL and API key. Such methods are typically retained as they are essential for setting up and managing API connections in a controlled environment. Therefore, it is unlikely to be deleted unless the entire API or its usage is deprecated."
survived,"def test_message():
    """"""Fixture providing a test message for signing.""""""
    return ""Test message to sign""
",python/src/wallets/crossmint/tests/conftest.py,,1,1.1861120010657661e-08,"The method `test_message` is a simple utility function that returns a static string. It is likely used as a fixture in testing environments to provide a consistent message for testing purposes, such as signing operations. Such utility functions are common in test suites to ensure consistency and reusability of test data. Since it serves a clear purpose in testing, it is likely to be retained in the codebase."
survived,"def test_url_encoding_special_chars(custodial_api):
    """"""Test URL parameter encoding with special characters.""""""
    special_chars = ""test:user+@example.com""
    encoded = quote(special_chars)
    with pytest.raises(Exception) as exc:
        custodial_api.get_wallet(f""email:{encoded}:solana-custodial-wallet"")
    # Verify the special characters were properly encoded
    assert ""+"" not in str(exc.value)
    assert ""@"" not in str(exc.value)
",python/src/wallets/crossmint/tests/test_api_client.py,,1,4.363462233903899e-09,"The method 'test_url_encoding_special_chars' is a unit test function that checks the URL encoding of special characters. It is a useful test to ensure that the API handles special characters in URLs correctly, which is a common requirement in web applications. The test uses pytest to assert that an exception is raised and verifies that certain characters are not present in the exception message, indicating proper encoding. This kind of test is essential for maintaining the robustness of the API, especially when dealing with user inputs that may contain special characters. Therefore, it is likely to be retained as part of the test suite."
survived,"def test_request_timeout_handling(custodial_api):
    """"""Test request timeout handling.""""""
    with pytest.raises(Exception) as exc:
        custodial_api._request(
            ""/wallets"",
            method=""GET"",
            timeout=0.001  # Very short timeout
        )
    assert ""timeout"" in str(exc.value).lower() or ""timed out"" in str(exc.value).lower()",python/src/wallets/crossmint/tests/test_api_client.py,,1,1.4166087846364157e-09,"The method 'test_request_timeout_handling' is a unit test designed to verify the behavior of the 'custodial_api' when a request times out. This is a crucial aspect of robust API interaction, ensuring that the system can gracefully handle network issues. Such tests are essential for maintaining the reliability and resilience of the software, especially in production environments where network instability can occur. Therefore, this method is likely to be retained as part of the test suite to ensure ongoing quality assurance."
survived,"def test_incremental_stream():
    assert True",airbyte-integrations/connectors/source-box-data-extract/unit_tests/test_incremental_streams.py,,0,0.999999998394772,"The method `test_incremental_stream` is a placeholder test function that only contains an assertion of `True`. This means it doesn't actually test any functionality or logic, making it effectively useless in its current state. Typically, such placeholder tests are either expanded to include real test logic or removed if they serve no purpose. Given that this function does not contribute to any meaningful testing, it is likely to be deleted unless further developed."
survived,"    def __init__(self, client: BoxClient, folder_id: str, prompt: str, is_recursive: bool = False):
        self.client = client
        self.folder_id = folder_id
        self.is_recursive = is_recursive
        self.prompt = prompt
",airbyte-integrations/connectors/source-box-data-extract/source_box_data_extract/source.py,StreamAIAskFolder,1,8.592166611791576e-10,"The method is a constructor for a class, which is essential for initializing instances of the class with specific attributes. Constructors are fundamental components of class definitions in object-oriented programming, and they are unlikely to be deleted unless the entire class is being refactored or removed. Since the method is performing a standard task of setting up initial values for an object, it is expected to survive."
survived,"def box_folder_ai_extract(
    client: BoxClient, folder_id: str, prompt: str, is_recursive: bool = False, by_pass_text_extraction: bool = False
) -> Iterable[BoxFileExtended]:
    # folder items iterator
    for item in client.folders.get_folder_items(folder_id).entries:
        if item.type == ""file"":
            file = box_file_get_by_id(client=client, file_id=item.id)
            if not by_pass_text_extraction:
                text_representation = box_file_ai_extract(client=client, file_id=item.id, prompt=prompt)
            else:
                text_representation = """"
            yield BoxFileExtended(file=file, text_representation=text_representation)
        elif item.type == ""folder"" and is_recursive:
            yield from box_folder_ai_extract(
                client=client, folder_id=item.id, prompt=prompt, is_recursive=is_recursive, by_pass_text_extraction=by_pass_text_extraction
            )
",airbyte-integrations/connectors/source-box-data-extract/source_box_data_extract/box_api.py,,1,1.1032560311263802e-09,"The method is likely to survive because it provides a useful functionality for extracting AI-generated text representations from files within a Box folder. It supports both recursive folder traversal and optional text extraction, making it flexible for different use cases. The method is well-structured, leveraging existing functions like 'box_file_get_by_id' and 'box_file_ai_extract', and it uses Python's generator feature to efficiently handle potentially large datasets. These characteristics make it a valuable utility in applications that need to process and analyze files stored in Box."
survived,"def box_file_ai_extract(client: BoxClient, file_id: str, prompt: str) -> str:
    ai_item = AiItemBase(id=file_id, type=AiItemBaseTypeField.FILE)
    response = client.ai.create_ai_extract(prompt=prompt, items=[ai_item])
    return response.answer
",airbyte-integrations/connectors/source-box-data-extract/source_box_data_extract/box_api.py,,1,5.905303995456778e-10,"The method 'box_file_ai_extract' is a straightforward utility function that interacts with an AI service to extract information from a file. It uses a client object to send a request and returns the response. This type of method is generally useful in applications that require AI-driven data extraction from files, which is a common requirement in many modern applications. The method is also simple, with a clear purpose and minimal complexity, making it less likely to be removed unless the underlying service or API changes significantly. Therefore, it is likely to survive."
survived,"    def primary_key(self) -> Optional[Union[str, List[str], List[List[str]]]]:
        """"""
        :return: string if single primary key, list of strings if composite primary key, list of list of strings if composite primary key consisting of nested fields.
          If the stream has no primary keys, return None.
        """"""
        return ""id""
",airbyte-integrations/connectors/source-box-data-extract/source_box_data_extract/source.py,StreamAIAskFolder,1,2.0611536181902033e-09,"The method 'primary_key' is a utility function that provides a way to retrieve the primary key(s) of a data stream. It is useful for identifying unique records in a dataset, which is a common requirement in data processing and database management. The method is well-documented, indicating its purpose and return types clearly. It also handles different scenarios by returning a string, list, or None, making it versatile. Such functionality is often essential in data handling applications, suggesting that it is likely to be retained."
survived,"    def __init__(self, client: BoxClient, folder_id: str, prompt: str, is_recursive: bool = False):
        self.client = client
        self.folder_id = folder_id
        self.is_recursive = is_recursive
        self.prompt = prompt
",airbyte-integrations/connectors/source-box-data-extract/source_box_data_extract/source.py,StreamAIExtractFolder,1,4.363462233903899e-09,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes, and this one sets up the object with a client, folder ID, prompt, and a recursive flag. There is no indication that this constructor is redundant or unnecessary, so it is likely to be retained."
survived,"async def run_function_tool_agent(prompt: str) -> str:
    """"""
    Run the travel assistant agent with the given prompt.
    
    Args:
        prompt: The user's query or prompt
        
    Returns:
        The agent's response as a string
    """"""
    # Create the agent with function tools
    agent = create_travel_assistant()
    
    # Run the agent with the prompt
    result = await Runner.run(agent, prompt)
    
    # Return the response
    return result.final_output
",openai-agents-examples/05_agent_with_function_tools.py,,1,1.493094675974231e-10,"The method 'run_function_tool_agent' is likely to survive because it is a well-structured asynchronous function that serves a clear purpose: running a travel assistant agent with a given prompt. It uses modern Python features such as async/await, which are increasingly common in handling I/O-bound operations. Additionally, the function is documented with a docstring, making it easier to understand and maintain. Unless there are changes in the requirements or the underlying architecture, this method is likely to remain useful and relevant."
survived,"def create_coordinator_agent(specialists: List[Agent]) -> Agent:
    """"""
    Create a coordinator agent that manages the research and blog writing process.
    
    Args:
        specialists: List of specialist agents to coordinate
        
    Returns:
        An Agent instance that coordinates the content creation process
    """"""
    instructions = """"""
    You are a content coordinator who manages the process of creating research-based blog posts.
    Your task is to:
    1. Understand the blog topic request
    2. Delegate research to the Research Specialist
    3. Provide the research to the Blog Specialist to create a blog post
    4. Ensure the final blog post is comprehensive, engaging, and based on solid research
    5. Deliver the final markdown blog post
    
    Manage the workflow efficiently and ensure each specialist has the information they need.
    """"""
    
    # Create handoffs to specialist agents
    handoffs = [handoff(agent) for agent in specialists]
    
    return Agent(
        name=""ContentCoordinator"",
        instructions=instructions,
        model=""gpt-4o-mini"",
        handoffs=handoffs
    )
",openai-agents-examples/13_research_blog_system.py,,1,7.582560422162384e-10,"The method `create_coordinator_agent` is likely to survive because it encapsulates a clear and useful functionality: creating a coordinator agent that manages a content creation process. This is a common requirement in systems that involve multiple specialized agents working together, such as in content management or automated writing systems. The method is well-documented, specifying its purpose, arguments, and return value, which makes it easy to understand and maintain. Additionally, it uses a structured approach to delegate tasks to specialist agents, which is a scalable and efficient design pattern."
survived,"async def orchestrate_content_creation(prompt: str) -> str:
    """"""
    Orchestrate the content creation process with multiple specialized agents.
    
    Args:
        prompt: The content request
        
    Returns:
        The final polished content
    """"""
    # Create specialist agents
    research_agent = create_research_agent()
    outline_agent = create_outline_agent()
    content_agent = create_content_agent()
    editor_agent = create_editor_agent()
    
    # Create manager agent with specialists
    manager = create_manager_agent([research_agent, outline_agent, content_agent, editor_agent])
    
    # Create a context to track the workflow
    context = Context()
    
    # Run the manager agent with the prompt and context
    result = await Runner.run(manager, prompt, context=context)
    
    # Return the final content
    return result.final_output
",openai-agents-examples/11_agent_orchestration.py,,1,5.905303995456778e-10,"The method 'orchestrate_content_creation' is likely to survive because it encapsulates a complex and useful functionality for content creation using multiple specialized agents. This approach is modular and scalable, allowing for easy updates or improvements to individual agents without affecting the overall system. Additionally, the use of asynchronous programming suggests that the method is designed to handle potentially time-consuming operations efficiently, which is valuable in modern software development."
survived,"def analyze_topic(topic: str) -> str:
    """"""
    Analyze a topic to identify key aspects for research.
    
    Args:
        topic: The topic to analyze
        
    Returns:
        A string containing analysis of the topic with key aspects to research
    """"""
    # This is a mock implementation - in a real application, this would be more sophisticated
    topic_analyses = {
        ""artificial intelligence ethics"": """"""
            Topic Analysis: Artificial Intelligence Ethics
            
            Key aspects to research:
            1. Ethical frameworks and principles for AI development
            2. Bias and fairness in AI systems
            3. Privacy implications of AI technologies
            4. Accountability and transparency in AI decision-making
            5. Regulatory approaches and governance models
            6. Economic and social impacts of AI deployment
            7. Case studies of ethical failures and successes
            8. Future challenges and emerging ethical concerns
        """""",
        
        ""climate change solutions"": """"""
            Topic Analysis: Climate Change Solutions
            
            Key aspects to research:
            1. Renewable energy technologies and implementation
            2. Carbon capture and sequestration approaches
            3. Policy mechanisms (carbon pricing, regulations, incentives)
            4. Adaptation strategies for vulnerable communities
            5. Agricultural and land use changes
            6. Behavioral and lifestyle modifications
            7. Economic considerations and just transition
            8. International cooperation frameworks
        """""",
        
        ""quantum computing"": """"""
            Topic Analysis: Quantum Computing
            
            Key aspects to research:
            1. Fundamental quantum mechanics principles relevant to computing
            2. Quantum computing architectures and hardware approaches
            3. Quantum algorithms and computational advantages
            4. Potential applications across industries
            5. Current state of development and key players
            6. Challenges and limitations of quantum systems
            7. Quantum programming languages and software tools
            8. Timeline and roadmap for practical quantum computing
        """"""
    }
    
    # Find the most relevant analysis
    for key, value in topic_analyses.items():
        if any(word in topic.lower() for word in key.split()):
            return value.strip()
    
    # Default analysis if no match found
    return f""""""
        Topic Analysis: {topic}
        
        Key aspects to research:
        1. Historical context and development
        2. Current state and major concepts
        3. Key stakeholders and perspectives
        4. Challenges and controversies
        5. Future trends and developments
        6. Practical applications and implications
        7. Related fields and intersections
        8. Resources for further learning
    """""".strip()
",openai-agents-examples/13_research_blog_system.py,,1,5.60279640614594e-09,"The method 'analyze_topic' is a useful utility function that provides structured information and key aspects for research on various topics. It is designed to be easily extendable by adding more topics and their analyses. The method is not overly complex and serves a clear purpose, making it likely to be retained in a codebase where topic analysis is needed. Additionally, the method includes a default analysis for topics not explicitly covered, ensuring it can handle a wide range of inputs. These factors suggest that the method will survive."
survived,"def test_run_traced_agent():
    """"""Test that the agent can run with tracing and produce a response.""""""
    import pytest
    
    # Skip this test if no API key is available
    if not os.environ.get(""OPENAI_API_KEY""):
        pytest.skip(""OPENAI_API_KEY not set"")
    
    # Set up tracing
    tracer = setup_tracing()
    
    # Run a simple test query
    response = asyncio.run(run_traced_agent(""What is the capital of Japan?"", tracer))
    
    # Verify we got a non-empty response
    assert response
    assert len(response) > 0
    # The response should contain ""Tokyo""
    assert ""Tokyo"" in response
",openai-agents-examples/04_agent_with_tracing.py,,1,8.152020648014727e-09,"The method 'test_run_traced_agent' is a test function that checks the functionality of an agent with tracing capabilities. It includes a check for an API key, sets up tracing, runs a test query, and verifies the response. These are standard practices in testing to ensure the code works as expected. The method is likely to be useful for maintaining code quality and ensuring the agent's functionality, so it is unlikely to be deleted."
survived,"def test_create_manager_agent():
    """"""Test that the manager agent is created with the correct configuration.""""""
    research_agent = create_research_agent()
    outline_agent = create_outline_agent()
    content_agent = create_content_agent()
    editor_agent = create_editor_agent()
    
    manager = create_manager_agent([research_agent, outline_agent, content_agent, editor_agent])
    
    assert manager.name == ""ContentManager""
    assert ""content manager"" in manager.instructions.lower()
    assert len(manager.handoffs) == 4
",openai-agents-examples/11_agent_orchestration.py,,1,3.850741907939403e-09,"The method 'test_create_manager_agent' is a unit test function that verifies the creation of a 'manager agent' with the correct configuration. It checks the name, instructions, and the number of handoffs of the manager agent. Unit tests are crucial for ensuring code reliability and correctness, especially in complex systems where multiple components interact. Since this function serves a clear purpose in testing the functionality of the 'create_manager_agent' method, it is likely to be retained in the codebase to maintain software quality."
survived,"def create_coordinator_agent(specialists: List[Agent]) -> Agent:
    """"""
    Create a coordinator agent that can delegate to specialists.
    
    Args:
        specialists: List of specialist agents to which tasks can be delegated
        
    Returns:
        An Agent instance that coordinates between specialists
    """"""
    instructions = """"""
    You are a coordinator who determines which specialist should handle a user's question.
    Analyze the user's query and decide which specialist would be best suited to respond.
    For questions that span multiple domains, choose the specialist most relevant to the core of the question.
    """"""
    
    # Create handoffs to specialist agents
    handoffs = [handoff(agent) for agent in specialists]
    
    return Agent(
        name=""Coordinator"",
        instructions=instructions,
        model=""gpt-4o-mini"",
        handoffs=handoffs
    )
",openai-agents-examples/02_multi_agent.py,,1,1.1032560311263802e-09,"The method 'create_coordinator_agent' is well-defined and serves a clear purpose in creating a coordinator agent that delegates tasks to specialist agents. It is likely to be useful in systems where task delegation is necessary, such as in customer support or complex query handling. The method is also documented with a docstring explaining its functionality, which is a good practice. There is no indication that this method is obsolete or redundant, so it is likely to be retained."
survived,"def run_sync_agent(prompt: str, agent: Optional[Agent] = None) -> str:
    """"""
    Run an agent synchronously with the given prompt.
    
    Args:
        prompt: The user's query or prompt
        agent: Optional pre-configured agent. If None, a health advisor agent is created.
        
    Returns:
        The agent's response as a string
    """"""
    # Create agent if not provided
    if agent is None:
        agent = create_health_agent()
    
    # Run the agent synchronously with the prompt
    result = Runner.run_sync(agent, prompt)
    
    # Return the response
    return result.final_output
",openai-agents-examples/03_sync_agent.py,,1,5.905303995456778e-10,"The method 'run_sync_agent' is likely to survive because it provides a clear and useful functionality: running an agent synchronously with a given prompt. It includes flexibility by allowing an optional agent parameter, defaulting to a health advisor agent if none is provided. This makes it versatile for different use cases. Additionally, the method is well-documented, which is a good practice for maintainability and understanding of the code."
survived,"def setup_tracing():
    """"""Set up OpenTelemetry tracing with console exporter.""""""
    # Create a tracer provider
    provider = TracerProvider()
    
    # Add a console exporter to see spans in the console
    console_exporter = ConsoleSpanExporter()
    processor = SimpleSpanProcessor(console_exporter)
    provider.add_span_processor(processor)
    
    # Set the global tracer provider
    trace.set_tracer_provider(provider)
    
    # Get a tracer
    return trace.get_tracer(""agent_tracer"")
",openai-agents-examples/04_agent_with_tracing.py,,1,8.592166611791576e-10,"The method 'setup_tracing' is likely to survive because it provides a clear and useful functionality for setting up OpenTelemetry tracing with a console exporter. This is a common requirement in applications that need to monitor and debug distributed systems. The method is well-defined, follows standard practices for setting up tracing, and does not contain any deprecated or obsolete code. Additionally, OpenTelemetry is a widely used tool for observability, making this method relevant and useful."
survived,"def test_blog_tools():
    """"""Test that the blog tools work correctly.""""""
    # Test outline tool
    outline = generate_blog_outline(
        ""AI Ethics"",
        ""AI Ethics involves principles like transparency, fairness, and accountability.""
    )
    assert ""introduction"" in outline.lower()
    assert ""conclusion"" in outline.lower()
    
    # Test markdown formatting tool
    markdown = format_blog_as_markdown(
        ""AI Ethics"",
        ""# AI Ethics\n\nThis is a blog post about AI ethics.""
    )
    assert ""title"" in markdown.lower()
    assert ""date"" in markdown.lower()
    assert ""ai ethics"" in markdown.lower()
",openai-agents-examples/13_research_blog_system.py,,1,2.8453347280241004e-08,"The method 'test_blog_tools' is a unit test function that verifies the functionality of two tools: 'generate_blog_outline' and 'format_blog_as_markdown'. It checks if the generated outline contains 'introduction' and 'conclusion', and if the markdown formatting includes 'title', 'date', and 'ai ethics'. This is a typical test function that ensures the tools work as expected, which is crucial for maintaining code quality and reliability. Therefore, it is likely to be retained as part of the test suite."
survived,"def search_for_information(query: str, depth: int = 3) -> str:
    """"""
    Simulated search for information on a topic.
    
    Args:
        query: The search query
        depth: The depth of the search (1-5, with 5 being most comprehensive)
        
    Returns:
        A string containing the search results
    """"""
    # This is a mock implementation - in a real application, you would call a search API
    search_results = {
        ""artificial intelligence ethics"": """"""
            Artificial Intelligence Ethics is a field focused on ensuring AI systems are developed and used responsibly.
            
            Key principles include:
            1. Transparency - AI systems should be explainable and understandable
            2. Fairness - AI should not perpetuate or amplify biases
            3. Privacy - AI systems should respect user privacy and data rights
            4. Accountability - Clear responsibility for AI decisions and impacts
            5. Safety - AI systems should be reliable and minimize harm
            
            Current challenges include:
            - Algorithmic bias in facial recognition and criminal justice systems
            - Privacy concerns with data collection and surveillance
            - Autonomous weapons and military applications
            - Job displacement due to automation
            - Concentration of AI power among few tech companies
            
            Organizations like the IEEE, EU Commission, and various academic institutions have developed ethical frameworks for AI development.
        """""",
        
        ""climate change solutions"": """"""
            Climate Change Solutions encompass various approaches to mitigate and adapt to global warming.
            
            Key mitigation strategies include:
            1. Renewable energy transition (solar, wind, hydro, geothermal)
            2. Energy efficiency improvements in buildings and industry
            3. Sustainable transportation (electric vehicles, public transit)
            4. Carbon capture and storage technologies
            5. Reforestation and ecosystem restoration
            
            Adaptation strategies include:
            - Climate-resilient infrastructure
            - Water conservation and management
            - Sustainable agriculture practices
            - Early warning systems for extreme weather
            - Planned relocation of vulnerable communities
            
            Policy approaches include carbon pricing, regulations, subsidies for clean technology, and international agreements like the Paris Climate Accord.
            
            Emerging technologies such as green hydrogen, advanced batteries, and direct air capture show promise for addressing climate challenges.
        """""",
        
        ""quantum computing"": """"""
            Quantum Computing leverages quantum mechanics principles to process information in fundamentally new ways.
            
            Key concepts:
            1. Qubits - Unlike classical bits (0 or 1), qubits can exist in superposition of states
            2. Entanglement - Quantum particles become correlated, enabling complex computations
            3. Quantum gates - Operations that manipulate qubits to perform calculations
            
            Potential applications:
            - Cryptography and security (both breaking existing systems and creating new ones)
            - Drug discovery and materials science through molecular simulation
            - Optimization problems in logistics, finance, and energy
            - Machine learning and AI acceleration
            - Climate modeling and complex system simulation
            
            Current state: Quantum computers remain in early development with 50-100+ qubit systems from IBM, Google, and others. Quantum advantage (surpassing classical computers) has been demonstrated for specific problems.
            
            Challenges include error correction, qubit stability (decoherence), and scaling systems to practical sizes.
            
            Major players include IBM, Google, Microsoft, IonQ, Rigetti, and various academic research groups.
        """"""
    }
    
    # Find the most relevant result based on the query
    for key, value in search_results.items():
        if any(word in query.lower() for word in key.split()):
            # Adjust the depth of information
            lines = value.strip().split('\n')
            result_depth = max(5, min(len(lines), depth * 5))
            return '\n'.join(lines[:result_depth])
    
    # Default response if no match found
    return ""No specific information found on this topic. Please try a more general query.""
",openai-agents-examples/13_research_blog_system.py,,1,1.275190675769241e-07,"The method 'search_for_information' is a simulated search function that provides predefined responses based on specific queries. It is a useful utility for educational or demonstration purposes, especially in environments where real API access is not feasible. The method is well-documented, has a clear purpose, and provides a structured way to simulate search results. Given its utility in controlled environments and its potential for expansion or adaptation, it is likely to be retained in the codebase."
survived,"def create_geography_agent() -> Agent:
    """"""
    Create a geography specialist agent.
    
    Returns:
        An Agent instance specialized in geography topics.
    """"""
    instructions = """"""
    You are a geography specialist with knowledge about countries, capitals, landmarks, and geographical features.
    Provide accurate, concise information about geographical topics.
    Include interesting facts when relevant but prioritize accuracy.
    """"""
    
    return Agent(
        name=""GeographySpecialist"",
        instructions=instructions,
        model=""gpt-4o-mini"",
    )
",openai-agents-examples/04_agent_with_tracing.py,,1,1.1032560311263802e-09,"The method 'create_geography_agent' is likely to survive because it is a well-defined function that creates an instance of an 'Agent' specialized in geography. It includes clear documentation, a specific purpose, and uses a model ('gpt-4o-mini') that suggests it is part of a larger system or application. The function is straightforward, with no apparent issues or redundancies that would necessitate its deletion. Additionally, the use of specialized agents is common in applications requiring domain-specific knowledge, indicating its utility."
survived,"def main():
    """"""Main function to parse arguments and run the agent with function tools.""""""
    parser = argparse.ArgumentParser(description=""Agent with Function Tools Example"")
    parser.add_argument(""--prompt"", ""-p"", type=str, required=True, 
                        help=""The prompt to send to the agent"")
    
    args = parser.parse_args()
    
    # Ensure API key is available
    if not os.environ.get(""OPENAI_API_KEY""):
        console.print(Panel(""[bold red]Error: OPENAI_API_KEY environment variable not set[/bold red]""))
        sys.exit(1)
    
    try:
        # Run the agent and get response
        response = asyncio.run(run_function_tool_agent(args.prompt))
        
        # Display the response
        console.print(Panel(response, title=""Travel Assistant Response"", border_style=""green""))
    
    except Exception as e:
        console.print(Panel(f""[bold red]Error: {str(e)}[/bold red]""))
        sys.exit(1)
",openai-agents-examples/05_agent_with_function_tools.py,,1,1.1861120010657661e-08,"The method 'main()' is a well-structured entry point for a command-line application. It includes argument parsing, environment variable checking, and error handling, which are essential components for robust CLI tools. The method is likely to be retained because it serves a clear purpose in initializing and running the application, and it follows good practices for handling user input and potential errors."
survived,"    async def generate(
        self,
        messages: List[Dict[str, Any]],
        model: str,
        temperature: float = 0.7,
        max_tokens: int = 1024,
        **kwargs
    ) -> ModelResponse:
        """"""
        Generate a response using Anthropic's Claude model.
        
        Args:
            messages: List of messages in the conversation
            model: Model name (will be mapped to Anthropic model)
            temperature: Sampling temperature
            max_tokens: Maximum number of tokens to generate
            **kwargs: Additional arguments to pass to the model
            
        Returns:
            A ModelResponse containing the model's response
        """"""
        # Map OpenAI model names to Anthropic model names
        model_mapping = {
            ""gpt-4o-mini"": ""claude-3-haiku-20240307"",
            ""gpt-4o"": ""claude-3-opus-20240229"",
            ""gpt-3.5-turbo"": ""claude-3-sonnet-20240229"",
        }
        
        # Use the mapped model or default to claude-3-haiku
        anthropic_model = model_mapping.get(model, ""claude-3-haiku-20240307"")
        
        # Convert OpenAI message format to Anthropic message format
        anthropic_messages = []
        for message in messages:
            role = message[""role""]
            # Map OpenAI roles to Anthropic roles
            if role == ""system"":
                # System messages are handled differently in Anthropic
                system_content = message.get(""content"", """")
                continue
            elif role == ""user"":
                anthropic_role = ""user""
            elif role == ""assistant"":
                anthropic_role = ""assistant""
            else:
                # Skip unsupported roles
                continue
            
            # Add the message
            anthropic_messages.append({
                ""role"": anthropic_role,
                ""content"": message.get(""content"", """")
            })
        
        # Create the message with system prompt if available
        try:
            response = await self.client.messages.create(
                model=anthropic_model,
                messages=anthropic_messages,
                system=system_content if 'system_content' in locals() else """",
                temperature=temperature,
                max_tokens=max_tokens,
                **kwargs
            )
            
            # Convert Anthropic response to OpenAI format
            output_message = {
                ""role"": ""assistant"",
                ""content"": response.content[0].text
            }
            
            # Create a ModelResponse
            return ModelResponse(
                output=[output_message],
                usage={
                    ""prompt_tokens"": response.usage.input_tokens,
                    ""completion_tokens"": response.usage.output_tokens,
                    ""total_tokens"": response.usage.input_tokens + response.usage.output_tokens
                },
                referenceable_id=None
            )
        
        except Exception as e:
            raise Exception(f""Error generating response from Anthropic: {str(e)}"")
",openai-agents-examples/12_anthropic_agent.py,AnthropicModelProvider,1,2.0611536181902033e-09,"The method is well-structured and provides a clear functionality of generating responses using Anthropic's Claude model. It includes error handling, model mapping, and message format conversion, which are essential for its operation. The method is likely to be useful in applications that require integration with Anthropic's models, and there is no indication of it being deprecated or replaced. Therefore, it is likely to survive."
survived,"async def test_websocket_invalid_token():
    with client.websocket_connect(""/api/ws"") as websocket:
        websocket.send_text(""invalid-token"")
        
        data = websocket.receive_json()
        assert data[""cmd""] == ""error""
        assert ""Invalid token"" in data[""msg""]
",backend/tests/test_endpoints.py,,1,1.3440409770490404e-08,"The method 'test_websocket_invalid_token' is a test function that checks the behavior of a websocket connection when an invalid token is sent. This is a common and necessary test to ensure that the system correctly handles authentication errors. Such tests are crucial for maintaining the security and robustness of the application, especially in systems that rely on token-based authentication. Therefore, it is unlikely to be deleted as it serves an important purpose in the testing suite."
survived,"    def get_debug_messages(self, session_type: str) -> list[dict]:
        """"""获取调试消息历史""""""
        session_key = f'webchat{session_type}'
        return self.debug_messages.get(session_key, [])
",pkg/platform/sources/webchat.py,WebChatAdapter,1,7.582560422162384e-10,"The method 'get_debug_messages' is a simple utility function that retrieves debug messages based on a session type. It is straightforward, performs a clear task, and is likely useful for debugging purposes. There is no indication that it is redundant or problematic, so it is likely to be retained."
survived,"async def delete_report(slug: str, api_key: str = Depends(verify_admin_api_key)):
    try:
        set_status(slug, ReportStatus.DELETED.value)
        return ORJSONResponse(
            content={""message"": f""Report {slug} marked as deleted""},
            headers={
                ""Content-Type"": ""application/json"",
                ""Access-Control-Allow-Origin"": ""*"",
            },
        )
    except ValueError as e:
        slogger.error(f""ValueError: {e}"", exc_info=True)
        raise HTTPException(status_code=404, detail=str(e)) from e
    except Exception as e:
        slogger.error(f""Exception: {e}"", exc_info=True)
        raise HTTPException(status_code=500, detail=""Internal server error"") from e",server/src/routers/admin_report.py,,1,5.60279640614594e-09,"The method 'delete_report' is well-structured and handles both successful and error scenarios effectively. It uses dependency injection for API key verification, which is a good practice for security. The method also logs errors and raises appropriate HTTP exceptions, making it robust for handling unexpected issues. These factors suggest that the method is likely to be useful and maintainable in the codebase."
survived,"def test_create_directory_default():
    """"""Test that create_directory defaults to True for backward compatibility.""""""
    task = Task(
        description=""Test task"",
        expected_output=""Test output"",
        output_file=""output.txt"",
    )
    
    assert task.create_directory is True
",tests/task_test.py,,1,1.955568070542584e-08,"The method `test_create_directory_default` is a unit test that checks the default behavior of the `create_directory` attribute in a `Task` object. Unit tests are crucial for ensuring code reliability and backward compatibility, especially when default behaviors are involved. This test ensures that the `create_directory` attribute defaults to `True`, which is important for maintaining expected functionality in existing systems. Therefore, this method is likely to be retained as it serves a critical role in verifying the integrity of the codebase."
survived,"            def embed_query(self, text):
                return [0.1] * OPEN_AI_VECTOR_SIZE
",airbyte-integrations/connectors/destination-milvus/integration_tests/milvus_integration_test.py,MilvusIntegrationTest.FakeEmbeddings,0,0.999999694097641,"The method 'embed_query' is a placeholder implementation that returns a fixed vector of 0.1 values, which is not a meaningful or functional embedding of the input text. It lacks any real processing or transformation of the input, making it unlikely to be useful in a production environment. Without further development to provide actual embedding functionality, it is likely to be deleted or replaced with a more sophisticated implementation."
survived,"def test_solana_smart_wallet_with_user_id(smart_api, test_user_id, test_solana_wallet_options):
    """"""Test Solana smart wallet creation with user ID.""""""
    wallet = smart_api.create_wallet(
        wallet_type=WalletType.SOLANA_SMART_WALLET,
        linked_user=f""userId:{test_user_id}""
    )
    assert wallet[""type""] == ""solana-smart-wallet""
    assert ""linkedUser"" in wallet",python/src/wallets/crossmint/tests/test_solana_smart_wallet.py,,1,3.653482080241728e-08,"The method 'test_solana_smart_wallet_with_user_id' is a test function that verifies the creation of a Solana smart wallet with a user ID. Test functions are generally crucial for ensuring the correctness of code, especially in a development environment where changes are frequent. This function checks that the wallet created is of the correct type and is linked to a user, which are important aspects of functionality that need to be validated. Therefore, it is likely to be retained as part of the test suite to ensure ongoing reliability of the wallet creation feature."
survived,"def validate_required_fields(data: Dict[str, Any], required_fields: List[str]) -> List[str]:
    """"""
    Validate that all required fields are present in the data.
    
    Args:
        data: The data to validate
        required_fields: List of required field names
        
    Returns:
        List of missing field names, empty if all required fields are present
    """"""
    return [field for field in required_fields if field not in data or data[field] is None]
",codebase-architectures/atomic-composable-architecture/modules/validation.py,,1,1.6052280526088547e-09,"The method 'validate_required_fields' is a utility function that checks for the presence of required fields in a given data dictionary. This is a common and useful operation in data validation processes, especially in applications dealing with form submissions, API requests, or any structured data input. The method is simple, efficient, and serves a clear purpose, making it likely to be retained in the codebase. It is also well-documented, which enhances its usability and maintainability."
survived,"    def delete(self, table_name, item_id):
        """"""Delete an item from a table.""""""
        if table_name not in self.data or item_id not in self.data[table_name]:
            Logger.warning(self.logger, f""Cannot delete: Item with ID {item_id} not found in '{table_name}'"")
            return False
        
        del self.data[table_name][item_id]
        Logger.info(self.logger, f""Deleted item with ID {item_id} from '{table_name}'"")
        return True
",codebase-architectures/layered-architecture/data/database.py,InMemoryDatabase,1,1.1861120010657661e-08,"The method is well-defined for its purpose, which is to delete an item from a specified table. It includes checks to ensure the item exists before attempting deletion, and it logs both unsuccessful and successful attempts. This kind of functionality is essential in data management systems, making it unlikely to be removed unless the entire system undergoes a significant redesign or the method is replaced by a more efficient or secure alternative."
survived,"    def get_all(self, collection_name):
        """"""Get all items from a collection.""""""
        if collection_name not in self.data:
            return []
        return list(self.data[collection_name].values())
",codebase-architectures/vertical-slice-architecture/shared/db.py,InMemoryDB,1,1.3176514268359263e-10,"The method 'get_all' is a straightforward utility function that retrieves all items from a specified collection within a data structure. It checks if the collection exists and returns an empty list if it doesn't, ensuring robustness. This method is likely to be useful in various contexts where data retrieval is needed, making it a candidate for survival. Additionally, it is well-defined and serves a clear purpose, which are characteristics of methods that tend to be retained in codebases."
survived,"    def __init__(self, username, email, name=None, id=None):
        self.id = id or generate_id()
        self.username = username
        self.email = email
        self.name = name
        self.created_at = get_timestamp()
        self.updated_at = self.created_at
",codebase-architectures/vertical-slice-architecture/features/users/model.py,User,1,1.0467401685178159e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. It initializes an object's attributes and is essential for creating instances of the class. The use of default values and utility functions like 'generate_id()' and 'get_timestamp()' suggests it is well-designed for flexibility and tracking object creation and updates. Such methods are typically retained unless there is a significant change in design or requirements."
survived,"    def process(self, input_result):
        """"""
        Process the data from the input stage.
        
        Args:
            input_result: Result from the input stage
        
        Returns:
            dict: Stage result with processed data and metadata
        """"""
        # Check if input stage had errors
        if input_result[""metadata""][""status""] in [""error"", ""validation_failed""]:
            self.metadata[""status""] = ""skipped""
            self.metadata[""errors""].append(""Input stage had errors, processing skipped"")
            return self._create_result()
        
        # Get data from input stage
        self.data = input_result[""data""]
        self.metadata[""input_metadata""] = input_result[""metadata""]
        
        # Initialize processing
        self.metadata[""status""] = ""processing""
        self.metadata[""started_at""] = datetime.now().isoformat()
        
        return self._create_result()
",codebase-architectures/pipeline-architecture/pipeline/processing_stage.py,ProcessingStage,1,1.3440409770490404e-08,"The method 'process' is well-documented and structured, handling both error and success cases. It checks for errors in the input, updates metadata accordingly, and processes the data if no errors are found. This kind of method is essential in data processing pipelines, making it unlikely to be deleted unless the entire processing logic is refactored or replaced."
survived,"    def delete_alert(token: str, notification_id: str) -> Dict:
        """"""
        Delete an alert.
        
        Args:
            token: Authentication token
            notification_id: The ID of the notification
            
        Returns:
            Response with success status or error message
        """"""
        # Validate token
        success, user_data = validate_user_token(token)
        if not success:
            return {
                ""status"": ""error"",
                ""message"": ""Invalid or expired token"",
                ""data"": None
            }
        
        # Delete alert
        success = delete_user_alert(user_data[""id""], notification_id)
        
        if success:
            return {
                ""status"": ""success"",
                ""message"": ""Alert deleted successfully"",
                ""data"": None
            }
        else:
            return {
                ""status"": ""error"",
                ""message"": ""Alert not found"",
                ""data"": None
            }
",codebase-architectures/atomic-composable-architecture/endpoints/alerts_api.py,AlertsAPI,1,2.646573631904765e-09,"The method 'delete_alert' is likely to survive because it performs a necessary function of deleting alerts, which is a common requirement in applications that handle notifications. The method includes token validation, which is crucial for security, and provides clear responses for both success and failure cases, making it robust and user-friendly. Additionally, the method is well-documented, which aids in maintainability and understanding for future developers."
survived,"    def update_task(task_id, task_data):
        """"""Update a task.""""""
        task = TaskService.update_task(task_id, task_data)
        if not task:
            return {""error"": f""Task with ID {task_id} not found""}
        return task
",codebase-architectures/vertical-slice-architecture/features/tasks/api.py,TaskAPI,1,2.998960815863541e-09,"The method 'update_task' is a straightforward function that updates a task using a service and handles the case where the task is not found by returning an error message. This is a common and necessary functionality in applications that manage tasks or similar entities. The method is simple, clear, and serves a specific purpose, which makes it likely to be retained in the codebase."
survived,"def send_system_notification(user_id: str, notification_type: str, 
                            data: Dict, email: Optional[str] = None) -> Tuple[bool, Dict]:
    """"""
    Send a system notification to a user.
    
    Args:
        user_id: The ID of the user
        notification_type: The type of notification (welcome, password_reset, new_login)
        data: Data for the notification template
        email: Optional email address to send the notification to
        
    Returns:
        Tuple of (success, result) with notification details
    """"""
    # Validate required fields
    missing_fields = validate_required_fields(
        {""user_id"": user_id, ""notification_type"": notification_type},
        [""user_id"", ""notification_type""]
    )
    
    if missing_fields:
        return False, {""error"": f""Missing required fields: {', '.join(missing_fields)}""}
    
    # Validate notification type
    valid_types = [""welcome"", ""password_reset"", ""new_login""]
    if notification_type not in valid_types:
        return False, {""error"": f""Notification type must be one of: {', '.join(valid_types)}""}
    
    # Create the notification
    notification = create_notification(
        user_id=user_id,
        notification_type=notification_type,
        data=data
    )
    
    # Send email if provided
    email_sent = False
    if email:
        if validate_email(email):
            # Get the notification message
            message = notification[""message""]
            subject = f""Notification: {notification_type.replace('_', ' ').title()}""
            email_sent = send_email_notification(email, subject, message)
        else:
            return False, {""error"": ""Invalid email format""}
    
    return True, {
        ""notification"": notification,
        ""channels"": {
            ""in_app"": True,
            ""email"": email_sent
        }
    }",codebase-architectures/atomic-composable-architecture/capabilities/alerting.py,,1,5.211412485172657e-10,"The method 'send_system_notification' is well-structured and serves a clear purpose of sending notifications to users. It includes validation for required fields and notification types, handles optional email notifications, and returns a detailed result. These features make it a useful utility function in a system that requires user notifications. There is no indication of redundancy or obsolescence, suggesting it will likely be retained in the codebase."
survived,"def register_user(username: str, password: str, email: str) -> Dict:
    """"""
    Register a new user.
    
    Args:
        username: The username for the new user
        password: The password for the new user
        email: The email for the new user
        
    Returns:
        User data dictionary
    
    Raises:
        ValueError: If the username already exists
    """"""
    if username in USER_STORE:
        raise ValueError(f""Username '{username}' already exists"")
    
    hashed_password, salt = hash_password(password)
    user_id = str(uuid.uuid4())
    
    user_data = {
        ""id"": user_id,
        ""username"": username,
        ""email"": email,
        ""hashed_password"": hashed_password,
        ""salt"": salt,
        ""created_at"": time.time()
    }
    
    USER_STORE[username] = user_data
    return {k: v for k, v in user_data.items() if k not in [""hashed_password"", ""salt""]}
",codebase-architectures/atomic-composable-architecture/modules/auth.py,,1,5.60279640614594e-09,"The method 'register_user' is a fundamental part of user management systems, handling the registration process by creating new user accounts. It includes essential features such as checking for existing usernames, hashing passwords for security, and generating unique user IDs. These functionalities are crucial for any application that requires user authentication and management. Therefore, it is unlikely to be deleted as it serves a core purpose in the system."
survived,"    def configure_output(self, config):
        """"""
        Configure the output stage.
        
        Args:
            config: Dictionary with output configuration
        """"""
        self.output_config = config",codebase-architectures/pipeline-architecture/pipeline/pipeline_manager.py,DataProcessingPipeline,1,1.0261879630648829e-10,"The method 'configure_output' is a basic setter method that assigns a configuration dictionary to an instance variable. Such methods are common in object-oriented programming for setting up or modifying the state of an object. It is likely to be used in various parts of the code where the output configuration needs to be set or updated. Unless there is a significant change in the design or architecture that makes this method redundant, it is likely to survive."
survived,"def display_result(result):
    """"""Display a result.""""""
    if result.get(""success""):
        print(""✅ "" + result.get(""message"", ""Operation successful""))
        
        if ""data"" in result:
            data = result[""data""]
            if isinstance(data, list):
                for item in data:
                    print_item(item)
            else:
                print_item(data)
    else:
        print(""❌ "" + result.get(""message"", ""Operation failed""))
",codebase-architectures/layered-architecture/main.py,,1,2.646573631904765e-09,"The method 'display_result' is a utility function that provides a clear and structured way to display the results of an operation, including handling both success and failure cases. It checks for the presence of a 'success' key in the result and prints an appropriate message. Additionally, it handles both list and non-list data types, making it versatile for different result structures. Such utility functions are commonly used in applications to standardize output and improve readability, which suggests it is likely to be retained in the codebase."
survived,"def validate_pattern(value: str, pattern: str) -> bool:
    """"""
    Validate that a string matches a regular expression pattern.
    
    Args:
        value: The string to validate
        pattern: Regular expression pattern to match
        
    Returns:
        True if the string matches the pattern, False otherwise
    """"""
    return bool(re.match(pattern, value))
",codebase-architectures/atomic-composable-architecture/modules/validation.py,,1,9.736200303530205e-10,"The method `validate_pattern` is a simple utility function that checks if a given string matches a specified regular expression pattern. This is a common requirement in many applications for input validation, data processing, and ensuring data integrity. The function is straightforward, leveraging Python's `re.match` function, and provides a clear and useful purpose. Such utility functions are often reused across different projects and are unlikely to be deleted unless there is a significant change in the requirements or a better alternative is introduced. Therefore, the method is likely to survive."
survived,"    def update_profile(token: str, profile_data: Dict) -> Dict:
        """"""
        Update a user's profile.
        
        Args:
            token: Authentication token
            profile_data: The profile data to update
            
        Returns:
            Response with success status and updated user data or error message
        """"""
        # Validate token
        success, user_data = validate_user_token(token)
        if not success:
            return {
                ""status"": ""error"",
                ""message"": ""Invalid or expired token"",
                ""data"": None
            }
        
        # Update profile
        success, result = update_user_profile(user_data[""id""], profile_data)
        
        if success:
            return {
                ""status"": ""success"",
                ""message"": ""Profile updated successfully"",
                ""data"": result
            }
        else:
            return {
                ""status"": ""error"",
                ""message"": result.get(""error"", ""Profile update failed""),
                ""data"": None
            }
",codebase-architectures/atomic-composable-architecture/endpoints/user_api.py,UserAPI,1,2.4616969512093895e-10,"The method `update_profile` is a well-structured function that performs a common and necessary operation in many applications: updating a user's profile. It includes token validation, which is crucial for security, and handles both success and error cases effectively. The method is likely to be retained as it provides essential functionality for user management in applications."
survived,"    def insert(self, table_name, item):
        """"""Insert an item into a table.""""""
        if table_name not in self.data:
            self.create_table(table_name)
        
        # Generate ID if not provided
        if ""id"" not in item:
            item[""id""] = str(uuid.uuid4())
        
        self.data[table_name][item[""id""]] = item
        Logger.info(self.logger, f""Item inserted into '{table_name}' with ID {item['id']}"")
        return item
",codebase-architectures/layered-architecture/data/database.py,InMemoryDatabase,1,2.0611536181902033e-09,"The method 'insert' is a fundamental part of any database-like system, as it allows for adding new entries to a table. It includes functionality to create a table if it doesn't exist, generate a unique ID if one isn't provided, and log the insertion. These features make it versatile and essential for maintaining and expanding the dataset. Therefore, it is unlikely to be deleted."
survived,"def generate_id():
    """"""Generate a unique ID.""""""
    return str(uuid.uuid4())
",codebase-architectures/vertical-slice-architecture/shared/utils.py,,1,1.8189616842444243e-09,"The method `generate_id` is a simple utility function that generates a unique identifier using the `uuid` module. Such functions are commonly used in various applications to ensure unique identification of resources, sessions, or objects. The function is straightforward, has a clear purpose, and is likely to be useful in many contexts where unique IDs are needed. Therefore, it is likely to be retained in the codebase."
survived,"    def get_all_tasks():
        """"""Get all tasks.""""""
        return db.get_all(""tasks"")
",codebase-architectures/vertical-slice-architecture/features/tasks/service.py,TaskService,1,2.646573631904765e-09,"The method `get_all_tasks` is a simple wrapper around a database call to retrieve all tasks. It is likely to survive because it provides a clear and specific functionality that is commonly needed in applications that manage tasks. The method is straightforward, has a clear purpose, and is likely to be used frequently in the codebase, making it a candidate for survival."
survived,"def validate_user_token(token: str) -> Tuple[bool, Optional[Dict]]:
    """"""
    Validate a user token and return user data.
    
    Args:
        token: The token to validate
        
    Returns:
        Tuple of (success, user_data) where user_data is None if validation fails
    """"""
    if not token:
        return False, None
    
    user_id = validate_token(token)
    if not user_id:
        return False, None
    
    user_data = get_user_by_id(user_id)
    if not user_data:
        return False, None
    
    return True, user_data
",codebase-architectures/atomic-composable-architecture/capabilities/user_management.py,,1,2.3355930333443423e-09,"The method `validate_user_token` is likely to survive because it performs a crucial function of validating user tokens, which is a common requirement in applications that involve authentication and authorization. The method is well-structured, with clear input and output, and handles different failure cases effectively. It checks for the presence of a token, validates it, and retrieves user data, which are essential steps in ensuring secure access to user-specific resources. Such functionality is fundamental in many systems, making it unlikely to be removed unless replaced by a more advanced or integrated solution."
survived,"    def create_table(self, table_name):
        """"""Create a new table if it doesn't exist.""""""
        if table_name not in self.data:
            self.data[table_name] = {}
            Logger.info(self.logger, f""Table '{table_name}' created"")
",codebase-architectures/layered-architecture/data/database.py,InMemoryDatabase,1,4.599055376537186e-10,"The method 'create_table' is likely to survive because it performs a fundamental operation of creating a new table in a data structure if it doesn't already exist. This is a common and necessary functionality in many applications that manage collections of data. Additionally, the method includes logging, which is useful for tracking operations and debugging, further indicating its utility and relevance."
survived,"    def get_all_tasks():
        """"""Get all tasks.""""""
        return TaskService.get_all_tasks()
",codebase-architectures/vertical-slice-architecture/features/tasks/api.py,TaskAPI,0,0.9999910602998366,"The method `get_all_tasks` is a simple wrapper around `TaskService.get_all_tasks()`. If `TaskService.get_all_tasks()` is a stable and reliable method, this wrapper might be considered redundant unless it serves a specific purpose such as abstraction or future extensibility. Without additional context indicating a need for this wrapper, it is likely to be deleted to reduce unnecessary code duplication."
survived,"    def delete_task(task_id):
        """"""Delete a task.""""""
        return db.delete(""tasks"", task_id)",codebase-architectures/vertical-slice-architecture/features/tasks/service.py,TaskService,1,9.237449576640118e-09,"The method 'delete_task' is a straightforward utility function that performs a specific and necessary operation: deleting a task from a database. Such functions are typically essential in applications that manage tasks or records, as they provide a way to remove obsolete or completed entries. The method is simple, clear, and directly tied to a common use case in task management systems, making it unlikely to be removed unless the entire task management feature is deprecated or significantly refactored."
survived,"def create_token(user_id: str, expires_in: int = 3600) -> str:
    """"""
    Create an authentication token for a user.
    
    Args:
        user_id: The user ID to create a token for
        expires_in: Token expiration time in seconds
        
    Returns:
        Authentication token
    """"""
    token = str(uuid.uuid4())
    expiration = time.time() + expires_in
    
    TOKEN_STORE[token] = {
        ""user_id"": user_id,
        ""expires_at"": expiration
    }
    
    return token
",codebase-architectures/atomic-composable-architecture/modules/auth.py,,1,1.6052280526088547e-09,"The method 'create_token' is a fundamental utility function for generating authentication tokens, which are crucial for user session management in web applications. It provides a clear and necessary functionality by creating a unique token for a user with an expiration time, storing it in a token store. This is a common requirement in authentication systems, and the method is well-documented and straightforward. Therefore, it is likely to be retained as it serves an essential purpose in managing user authentication."
survived,"def get_user_notifications(user_id: str, unread_only: bool = False) -> List[Dict]:
    """"""
    Get notifications for a user.
    
    Args:
        user_id: The ID of the user
        unread_only: Whether to return only unread notifications
        
    Returns:
        List of notifications
    """"""
    if user_id not in NOTIFICATION_STORE:
        return []
    
    if unread_only:
        return [n for n in NOTIFICATION_STORE[user_id] if not n[""is_read""]]
    
    return NOTIFICATION_STORE[user_id]
",codebase-architectures/atomic-composable-architecture/modules/notifications.py,,1,4.599055376537186e-10,"The method 'get_user_notifications' is a useful utility function that retrieves notifications for a user, with an option to filter for unread notifications only. This functionality is common in applications that handle user notifications, making it a valuable part of the codebase. The method is well-documented, with clear arguments and return types, and it efficiently handles cases where a user has no notifications. There is no indication of redundancy or obsolescence, suggesting that it will likely be retained in the codebase."
survived,"def display_file_content(path: str, content: str) -> None:
    """"""
    Display file content with syntax highlighting.

    Args:
        path: The path to the file
        content: The content to display
    """"""
    # Get file extension for syntax highlighting
    extension = os.path.splitext(path)[1][1:] if os.path.splitext(path)[1] else """"
    
    # Default to Python if no extension
    if not extension:
        extension = ""python""
        
    # Display the content with syntax highlighting
    syntax = Syntax(content, extension, theme=""monokai"", line_numbers=True)
    console.print(syntax)
",example-agent-codebase-arch/vertical-slice-architecture/shared/utils.py,,1,1.6052280526088547e-09,"The method 'display_file_content' is likely to survive because it provides a useful functionality of displaying file content with syntax highlighting, which is a common requirement in many applications, especially those dealing with code files. The method is well-documented, specifying the purpose and arguments clearly, and it uses the 'Syntax' and 'console.print' functions, which are likely part of a library designed for this purpose. This indicates that the method is leveraging existing tools effectively, making it a practical and reusable piece of code."
survived,"def main():
    """"""Main entry point for the application.""""""
    # Set up argument parser
    parser = argparse.ArgumentParser(description=""Claude 3.7 File Editor Agent"")
    parser.add_argument(
        ""--prompt"",
        ""-p"",
        required=True,
        help=""The prompt for what file operations to perform"",
    )
    parser.add_argument(
        ""--max-loops"",
        ""-l"",
        type=int,
        default=15,
        help=""Maximum number of tool use loops (default: 15)"",
    )
    parser.add_argument(
        ""--thinking"",
        ""-t"",
        type=int,
        default=DEFAULT_THINKING_TOKENS,
        help=f""Maximum thinking tokens (default: {DEFAULT_THINKING_TOKENS})"",
    )
    parser.add_argument(
        ""--efficiency"",
        ""-e"",
        action=""store_true"",
        help=""Enable token-efficient tool use (beta feature)"",
    )
    args = parser.parse_args()

    console.print(Panel.fit(""Claude 3.7 File Editor Agent (Atomic/Composable Architecture)""))
    console.print(f""\n[bold]Prompt:[/bold] {args.prompt}\n"")
    console.print(f""[dim]Thinking tokens: {args.thinking}[/dim]"")
    console.print(f""[dim]Max loops: {args.max_loops}[/dim]"")
    
    if args.efficiency:
        console.print(f""[dim]Token-efficient tools: Enabled[/dim]\n"")
    else:
        console.print(f""[dim]Token-efficient tools: Disabled[/dim]\n"")

    # For testing purposes, we'll just print a success message
    console.print(""[green]Successfully loaded the Atomic/Composable Architecture implementation![/green]"")
    console.print(""[yellow]This is a mock implementation for testing the architecture structure.[/yellow]"")
    console.print(""[yellow]In a real implementation, this would connect to the Claude API.[/yellow]"")

    # Display mock token usage
    display_token_usage(1000, 500)
",example-agent-codebase-arch/atomic-composable-architecture/main.py,,1,1.0467401685178159e-08,"The method 'main()' is a well-structured entry point for a command-line application. It sets up an argument parser, handles command-line arguments, and provides informative console output. The method is essential for the application's functionality, as it initializes the program's execution flow and user interaction. There is no indication that this method is redundant or obsolete, and it appears to be a core part of the application's architecture. Therefore, it is likely to be retained in the codebase."
survived,"def display_token_usage(input_tokens: int, output_tokens: int) -> None:
    """"""
    Display token usage in a table.

    Args:
        input_tokens: Number of input tokens used
        output_tokens: Number of output tokens used
    """"""
    table = Table(title=""Token Usage"")
    table.add_column(""Type"", style=""cyan"")
    table.add_column(""Count"", style=""green"")
    
    table.add_row(""Input Tokens"", str(input_tokens))
    table.add_row(""Output Tokens"", str(output_tokens))
    table.add_row(""Total Tokens"", str(input_tokens + output_tokens))
    
    console.print(table)
",example-agent-codebase-arch/layered-architecture/main.py,,1,8.592166611791576e-10,"The method 'display_token_usage' is likely to survive because it provides a clear and useful functionality: displaying token usage in a formatted table. This is a common requirement in applications that deal with token-based systems, such as APIs or language models, where tracking and displaying token usage is important for monitoring and optimization purposes. The method is well-documented, with clear arguments and a straightforward implementation using a table format, which enhances readability and usability."
survived,"    def handle_tool_use(self, tool_use: Dict[str, Any]) -> Dict[str, Any]:
        """"""
        Handle text editor tool use from Claude.

        Args:
            tool_use: The tool use request from Claude

        Returns:
            Dictionary with result or error to send back to Claude
        """"""
        console.log(f""[file_editor_pipeline] Handling tool use: {tool_use.get('command', 'unknown')}"")
        
        # Process the tool use through the pipeline
        result = self.pipeline.process(tool_use)
        
        console.log(f""[file_editor_pipeline] Tool use result: {result}"")
        return result",example-agent-codebase-arch/pipeline-architecture/pipeline_manager/file_editor_pipeline.py,FileEditorPipeline,1,2.1724399346070676e-10,"The method 'handle_tool_use' is a well-defined function that processes a tool use request and logs the process. It is likely to be useful in scenarios where tool use needs to be handled and logged, especially in a system that involves interaction with a text editor or similar tools. The method is straightforward, uses logging for tracking, and returns a result, which are all good practices in software development. There is no indication that this method is obsolete or redundant, so it is likely to be retained."
survived,"    def from_dict(cls, data: Dict[str, Any]) -> 'ToolUseRequest':
        """"""
        Create a tool use request from a dictionary.
        
        Args:
            data: Dictionary containing the tool use request
            
        Returns:
            A ToolUseRequest instance
        """"""
        command = data.get(""command"")
        path = data.get(""path"")
        
        # Extract all other keys as kwargs
        kwargs = {k: v for k, v in data.items() if k not in [""command"", ""path""]}
        
        return cls(command, path, **kwargs)",example-agent-codebase-arch/vertical-slice-architecture/features/file_operations/model.py,ToolUseRequest,1,3.3982678079468468e-09,"The method 'from_dict' is a common and useful pattern for creating instances of a class from a dictionary, especially in scenarios where data is often received in JSON format and needs to be converted into class instances. This method is likely to be used frequently in applications that deal with data serialization and deserialization. It provides a clear and structured way to instantiate objects, making it easier to manage and understand the flow of data within the application. Therefore, it is unlikely to be deleted."
survived,"def display_file_content(path: str, content: str) -> None:
    """"""
    Display file content with syntax highlighting
    
    Args:
        path: Path to the file
        content: Content of the file
    """"""
    from rich.console import Console
    from rich.panel import Panel
    from rich.syntax import Syntax
    
    console = Console()
    file_extension = os.path.splitext(path)[1][1:]  # Get extension without the dot
    syntax = Syntax(content, file_extension or ""text"", line_numbers=True)
    console.print(Panel(syntax, title=f""File: {path}""))
",example-agent-codebase-arch/layered-architecture/utils/path_utils.py,,1,1.0261879630648829e-10,"The method 'display_file_content' is likely to survive because it provides a useful functionality of displaying file content with syntax highlighting, which is a common requirement for developers and users who need to read and understand code or text files. The use of the 'rich' library for syntax highlighting and panel display is modern and efficient, making the method relevant and valuable. Additionally, the method is well-documented and straightforward, enhancing its maintainability and usability."
survived,"    def handle_tool_use(tool_use: Dict[str, Any]) -> Dict[str, Any]:
        """"""
        Handle text editor tool use from Claude.

        Args:
            tool_use: The tool use request from Claude

        Returns:
            Dictionary with result or error to send back to Claude
        """"""
        try:
            # Convert the tool use dictionary to a ToolUseRequest object
            request = ToolUseRequest.from_dict(tool_use)
            
            Logger.info(app_logger, f""Received command: {request.command}, path: {request.path}"")

            if not request.command:
                error_msg = ""No command specified in tool use request""
                Logger.error(app_logger, error_msg)
                return {""error"": error_msg}

            if not request.path and request.command != ""undo_edit"":  # undo_edit might not need a path
                error_msg = ""No path specified in tool use request""
                Logger.error(app_logger, error_msg)
                return {""error"": error_msg}

            result = None
            
            if request.command == ""view"":
                view_range = request.kwargs.get(""view_range"")
                Logger.info(app_logger, f""Calling view_file with view_range: {view_range}"")
                result = FileService.view_file(request.path, view_range)

            elif request.command == ""str_replace"":
                old_str = request.kwargs.get(""old_str"")
                new_str = request.kwargs.get(""new_str"")
                Logger.info(app_logger, ""Calling str_replace"")
                result = FileService.str_replace(request.path, old_str, new_str)

            elif request.command == ""create"":
                file_text = request.kwargs.get(""file_text"")
                Logger.info(app_logger, ""Calling create_file"")
                result = FileService.create_file(request.path, file_text)

            elif request.command == ""insert"":
                insert_line = request.kwargs.get(""insert_line"")
                new_str = request.kwargs.get(""new_str"")
                Logger.info(app_logger, f""Calling insert_text at line: {insert_line}"")
                result = FileService.insert_text(request.path, insert_line, new_str)

            elif request.command == ""undo_edit"":
                Logger.info(app_logger, ""Calling undo_edit"")
                result = FileService.undo_edit(request.path)

            else:
                error_msg = f""Unknown command: {request.command}""
                Logger.error(app_logger, error_msg)
                return {""error"": error_msg}
            
            # Convert the result to a response for Claude
            return result.to_response()
                
        except Exception as e:
            error_msg = f""Error handling tool use: {str(e)}""
            Logger.error(app_logger, error_msg, exc_info=True)
            return {""error"": error_msg}",example-agent-codebase-arch/layered-architecture/api/file_editor_api.py,FileEditorAPI,1,1.2501528648238603e-09,"The method 'handle_tool_use' is well-structured and serves a clear purpose of handling different text editor commands. It includes error handling, logging, and supports multiple commands like 'view', 'str_replace', 'create', 'insert', and 'undo_edit'. The method is likely part of a larger system that interacts with a text editor, and its functionality is essential for processing tool use requests. Given its comprehensive implementation and utility, it is likely to be retained in the codebase."
survived,"    def from_dict(cls, data: Dict[str, Any]) -> 'ToolUseRequest':
        """"""
        Create a tool use request from a dictionary.
        
        Args:
            data: Dictionary containing the tool use request
            
        Returns:
            A ToolUseRequest instance
        """"""
        command = data.get(""command"")
        path = data.get(""path"")
        
        # Extract all other keys as kwargs
        kwargs = {k: v for k, v in data.items() if k not in [""command"", ""path""]}
        
        return cls(command, path, **kwargs)
",example-agent-codebase-arch/layered-architecture/models/tool_models.py,ToolUseRequest,1,8.592166611791576e-10,"The method 'from_dict' is a factory method that allows for the creation of a 'ToolUseRequest' object from a dictionary. This is a common and useful pattern in Python, especially when dealing with data that is often received in dictionary form, such as JSON data from APIs. The method is well-documented, clearly structured, and provides flexibility by allowing additional keyword arguments. There is no indication that this method is redundant or unnecessary, and it serves a clear purpose in the context of object creation. Therefore, it is likely to be retained in the codebase."
survived,"    def str_replace(path: str, old_str: str, new_str: str) -> FileOperationResult:
        """"""
        Replace a specific string in a file.

        Args:
            path: The path to the file to modify
            old_str: The text to replace
            new_str: The new text to insert

        Returns:
            FileOperationResult with result or error message
        """"""
        try:
            # Normalize the path
            path = normalize_path(path)

            if not os.path.exists(path):
                error_msg = f""File {path} does not exist""
                Logger.error(app_logger, f""[str_replace] {error_msg}"")
                return FileOperationResult(False, error_msg)

            with open(path, ""r"") as f:
                content = f.read()

            if old_str not in content:
                error_msg = f""The specified string was not found in the file {path}""
                Logger.error(app_logger, f""[str_replace] {error_msg}"")
                return FileOperationResult(False, error_msg)

            new_content = content.replace(old_str, new_str, 1)

            with open(path, ""w"") as f:
                f.write(new_content)

            Logger.info(app_logger, f""[str_replace] Successfully replaced text in {path}"")
            return FileOperationResult(True, f""Successfully replaced text in {path}"")
        except Exception as e:
            error_msg = f""Error replacing text: {str(e)}""
            Logger.error(app_logger, f""[str_replace] {error_msg}"", exc_info=True)
            return FileOperationResult(False, error_msg)
",example-agent-codebase-arch/layered-architecture/services/file_service.py,FileService,1,2.998960815863541e-09,"The method 'str_replace' is a utility function that performs a common task of replacing a string in a file. It includes error handling, logging, and returns a result object indicating success or failure. These features make it robust and useful in various applications. Additionally, the method is well-documented, which enhances its maintainability. Given these factors, it is likely to be retained in the codebase."
survived,"def test_create_folder_structure_handles_complex_name_with_trailing_slash():
    with tempfile.TemporaryDirectory() as temp_dir:
        os.chdir(temp_dir)
        folder_path, folder_name, class_name = create_folder_structure(""my-awesome_project/"")
        
        assert folder_name == ""my_awesome_project""
        assert class_name == ""MyAwesomeProject""
        assert folder_path.name == ""my_awesome_project""
        assert folder_path.exists()
",tests/cli/test_create_crew.py,,1,2.5109990926928157e-08,"The method is a test function that verifies the behavior of the `create_folder_structure` function when given a complex folder name with a trailing slash. Test functions are crucial for ensuring code reliability and correctness, especially when dealing with edge cases like special characters or formatting in inputs. This test checks if the function correctly handles the input by asserting the expected folder name, class name, and folder path. Such tests are typically retained to maintain code quality and prevent regressions."
survived,"        def will_fail(self):
            self.state.value = ""test""
",tests/test_flow_persistence.py,InvalidFlow,0,0.999988521231025,"The method 'will_fail' directly modifies an attribute 'state.value' without any checks or conditions. This could lead to unintended side effects or errors if 'state' or 'state.value' are not properly initialized or if 'state' is expected to be immutable. Additionally, the method name 'will_fail' suggests that it is intended to demonstrate or test failure conditions, which might not be useful in a production environment. Therefore, it is likely to be deleted or refactored to ensure better error handling and clarity."
survived,"    def init_db(self) -> None:
        """"""Initialize the persistence backend.
        
        This method should handle any necessary setup, such as:
        - Creating tables
        - Establishing connections
        - Setting up indexes
        """"""
        pass
",src/crewai/flow/persistence/base.py,FlowPersistence,1,2.1024340680345882e-07,"The method `init_db` is a placeholder for initializing a database, which is a crucial part of many applications. Although it currently lacks implementation, it is likely intended to be filled in with code that sets up the database environment. Such methods are typically essential for setting up the persistence layer of an application, and thus, it is unlikely to be deleted. Instead, it will probably be implemented in the future."
survived,"def test_knowledge_included_in_planning():
    """"""Test that verifies knowledge sources are properly included in planning.""""""
    # Create an agent with knowledge
    agent = Agent(
        role=""AI Researcher"",
        goal=""Research and explain AI concepts"",
        backstory=""Expert in artificial intelligence"",
        knowledge_sources=[
            StringKnowledgeSource(
                content=""AI systems require careful training and validation.""
            )
        ]
    )

    # Create a task for the agent
    task = Task(
        description=""Explain the basics of AI systems"",
        expected_output=""A clear explanation of AI fundamentals"",
        agent=agent
    )

    # Create a crew planner
    planner = CrewPlanner([task], None)

    # Get the task summary
    task_summary = planner._create_tasks_summary()

    # Verify that knowledge is included in planning
    assert ""AI systems require careful training"" in task_summary
    assert '""agent_knowledge""' in task_summary

    # Verify that knowledge is properly formatted
    assert isinstance(task.agent.knowledge_sources, list)
    assert len(task.agent.knowledge_sources) > 0
    assert task.agent.knowledge_sources[0].content in task_summary

    # Verify that other expected components are still present
    assert task.description in task_summary
    assert task.expected_output in task_summary
    assert agent.role in task_summary",tests/utilities/test_knowledge_planning.py,,1,6.825604231969389e-08,"The method `test_knowledge_included_in_planning` is a unit test designed to verify that knowledge sources are properly included in the planning process of an AI agent. It checks various aspects such as the inclusion of specific knowledge content, the format of the knowledge sources, and the presence of other task components in the task summary. This test is crucial for ensuring that the system behaves as expected when integrating knowledge into planning. Since it serves a clear purpose in validating the functionality of the system, it is likely to be retained in the codebase."
survived,"def test_manager_agent_delegates_with_varied_role_cases():
    """"""
    Test that the manager agent can delegate to agents regardless of case or whitespace variations in role names.
    This test verifies the fix for issue #1503 where role matching was too strict.
    """"""
    # Create agents with varied case and whitespace in roles
    researcher_spaced = Agent(
        role="" Researcher "",  # Extra spaces
        goal=""Research with spaces in role"",
        backstory=""A researcher with spaces in role name"",
        allow_delegation=False,
    )
    
    writer_caps = Agent(
        role=""SENIOR WRITER"",  # All caps
        goal=""Write with caps in role"",
        backstory=""A writer with caps in role name"",
        allow_delegation=False,
    )

    task = Task(
        description=""Research and write about AI. The researcher should do the research, and the writer should write it up."",
        expected_output=""A well-researched article about AI."",
        agent=researcher_spaced,  # Assign to researcher with spaces
    )

    crew = Crew(
        agents=[researcher_spaced, writer_caps],
        process=Process.hierarchical,
        manager_llm=""gpt-4o"",
        tasks=[task],
    )

    mock_task_output = TaskOutput(
        description=""Mock description"",
        raw=""mocked output"",
        agent=""mocked agent""
    )
    task.output = mock_task_output

    with patch.object(Task, 'execute_sync', return_value=mock_task_output) as mock_execute_sync:
        crew.kickoff()

        # Verify execute_sync was called once
        mock_execute_sync.assert_called_once()

        # Get the tools argument from the call
        _, kwargs = mock_execute_sync.call_args
        tools = kwargs['tools']

        # Verify the delegation tools were passed correctly and can handle case/whitespace variations
        assert len(tools) == 2
        
        # Check delegation tool descriptions (should work despite case/whitespace differences)
        delegation_tool = tools[0]
        question_tool = tools[1]
        
        assert ""Delegate a specific task to one of the following coworkers:"" in delegation_tool.description
        assert "" Researcher "" in delegation_tool.description or ""SENIOR WRITER"" in delegation_tool.description
        
        assert ""Ask a specific question to one of the following coworkers:"" in question_tool.description
        assert "" Researcher "" in question_tool.description or ""SENIOR WRITER"" in question_tool.description
",tests/crew_test.py,,1,9.237449576640118e-09,"The method is a test function that verifies a specific functionality related to role matching in a system. It is important for ensuring that the system can handle variations in role names, which is a common issue in software systems. Test functions are generally not deleted unless they are redundant or the functionality they test is no longer relevant. Since this test addresses a specific issue (#1503) and ensures robustness in role matching, it is likely to be retained."
survived,"    def __init__(self):
        """"""Initialize the BaseLLM with default attributes.
        
        This constructor sets default values for attributes that are expected
        by the CrewAgentExecutor and other components.
        """"""
        self.stop = []
",src/crewai/llm.py,BaseLLM,1,3.0590235908148916e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing objects with default or initial values. The presence of a docstring explaining its purpose further indicates that it is a well-documented and intentional part of the class design. Therefore, it is unlikely to be deleted."
survived,"    def call(
        self,
        messages: Union[str, List[Dict[str, str]]],
        tools: Optional[List[dict]] = None,
        callbacks: Optional[List[Any]] = None,
        available_functions: Optional[Dict[str, Any]] = None,
    ) -> Union[str, Any]:
        """"""Record the call and return the predefined response.""""""
        self.calls.append({
            ""messages"": messages, 
            ""tools"": tools,
            ""callbacks"": callbacks,
            ""available_functions"": available_functions
        })
        return self.response
",tests/custom_llm_test.py,CustomLLM,1,5.905303995456778e-10,"The method 'call' is likely to survive because it serves a clear purpose in the code. It records the call details by appending them to 'self.calls' and returns a predefined response stored in 'self.response'. This functionality is useful for logging or tracking calls and their parameters, which can be essential for debugging, auditing, or analytics purposes. Additionally, the method is flexible, accepting various types of inputs and optional parameters, making it adaptable to different use cases."
survived,"    def __init__(self, response: str = ""Custom LLM response""):
        self.response = response
        self.calls = []
        self.stop = []
",tests/custom_llm_test.py,CustomLLM,1,1.444980317078884e-07,"The method is a constructor for a class, initializing instance variables. Constructors are fundamental to class definitions in object-oriented programming, and this one sets up default values for 'response', 'calls', and 'stop'. It is unlikely to be deleted as it is essential for creating instances of the class with initial states."
survived,"def test_serialize_session_with_dict_error():
    """"""Test serialization of a session with a dictionary error""""""
    view = SessionView()
    view.cell_operations[""cell1""] = CellOp(
        cell_id=""cell1"",
        status=""idle"",
        output=CellOutput(
            channel=CellChannel.MARIMO_ERROR,
            mimetype=""text/plain"",
            data=[{""type"": ""unknown"", ""msg"": ""Something went wrong""}],  # Dictionary instead of Error object
        ),
        console=[],
        timestamp=0,
    )
    view.last_executed_code[""cell1""] = (
        ""raise RuntimeError('Something went wrong')""
    )

    result = serialize_session_view(view)
    assert len(result[""cells""]) == 1
    assert len(result[""cells""][0][""outputs""]) == 1
    assert result[""cells""][0][""outputs""][0][""type""] == ""error""
    assert result[""cells""][0][""outputs""][0][""ename""] == ""unknown""
    assert result[""cells""][0][""outputs""][0][""evalue""] == ""Something went wrong""
",tests/_server/session/test_serialize_session.py,,1,1.1861120010657661e-08,"The method is a test function that checks the serialization of a session with a dictionary error. It is likely part of a test suite to ensure that the serialization process correctly handles errors represented as dictionaries. Test functions are generally not deleted unless they are redundant or the functionality they test is no longer relevant. Since error handling is a critical part of software robustness, this test is likely to be retained to ensure the system behaves correctly in the presence of errors."
